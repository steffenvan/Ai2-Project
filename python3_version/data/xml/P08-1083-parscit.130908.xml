<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003329">
<title confidence="0.998505">
Unsupervised Lexicon-Based Resolution of Unknown Words for Full
Morphological Analysis
</title>
<author confidence="0.973428">
Meni Adler and Yoav Goldberg and David Gabay and Michael Elhadad
</author>
<affiliation confidence="0.998385">
Ben Gurion University of the Negev
Department of Computer Science*
</affiliation>
<address confidence="0.892218">
POB 653 Be’er Sheva, 84105, Israel
</address>
<email confidence="0.999394">
{adlerm,goldberg,gabayd,elhadad}@cs.bgu.ac.il
</email>
<sectionHeader confidence="0.998615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9708834375">
Morphological disambiguation proceeds in 2
stages: (1) an analyzer provides all possible
analyses for a given token and (2) a stochastic
disambiguation module picks the most likely
analysis in context. When the analyzer does
not recognize a given token, we hit the prob-
lem of unknowns. In large scale corpora, un-
knowns appear at a rate of 5 to 10% (depend-
ing on the genre and the maturity of the lexi-
con).
We address the task of computing the distribu-
tion p(tjw) for unknown words for full mor-
phological disambiguation in Hebrew. We in-
troduce a novel algorithm that is language in-
dependent: it exploits a maximum entropy let-
ters model trained over the known words ob-
served in the corpus and the distribution of
the unknown words in known tag contexts,
through iterative approximation. The algo-
rithm achieves 30% error reduction on dis-
ambiguation of unknown words over a com-
petitive baseline (to a level of 70% accurate
full disambiguation of unknown words). We
have also verified that taking advantage of a
strong language-specific model of morpholog-
ical patterns provides the same level of disam-
biguation. The algorithm we have developed
exploits distributional information latent in a
wide-coverage lexicon and large quantities of
unlabeled data.
This work is supported in part by the Lynn and William
Frankel Center for Computer Science.
</bodyText>
<sectionHeader confidence="0.999328" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994972870967742">
The term unknowns denotes tokens in a text that can-
not be resolved in a given lexicon. For the task of
full morphological analysis, the lexicon must pro-
vide all possible morphological analyses for any
given token. In this case, unknown tokens can be
categorized into two classes of missing informa-
tion: unknown tokens are not recognized at all by
the lexicon, and unknown analyses, where the set
of analyses for a lexeme does not contain the cor-
rect analysis for a given token. Despite efforts on
improving the underlying lexicon, unknowns typi-
cally represent 5% to 10% of the number of tokens
in large-scale corpora. The alternative to continu-
ously investing manual effort in improving the lex-
icon is to design methods to learn possible analy-
ses for unknowns from observable features: their
letter structure and their context. In this paper, we
investigate the characteristics of Hebrew unknowns
for full morphological analysis, and propose a new
method for handling such unavoidable lack of in-
formation. Our method generates a distribution of
possible analyses for unknowns. In our evaluation,
these learned distributions include the correct anal-
ysis for unknown words in 85% of the cases, con-
tributing an error reduction of over 30% over a com-
petitive baseline for the overall task of full morpho-
logical analysis in Hebrew.
The task of a morphological analyzer is to pro-
duce all possible analyses for a given token. In
Hebrew, the analysis for each token is of the form
lexeme-and-features1: lemma, affixes, lexical cate-
</bodyText>
<footnote confidence="0.968611">
1In contrast to the prefix-stem-suffix analysis format of
</footnote>
<page confidence="0.866344">
728
</page>
<note confidence="0.73634">
Proceedings of ACL-08: HLT, pages 728–736,
</note>
<page confidence="0.539869">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999607431818182">
gory (POS), and a set of inflection properties (ac-
cording to the POS) – gender, number, person, sta-
tus and tense. In this work, we refer to the mor-
phological analyzer of MILA – the Knowledge Cen-
ter for Processing Hebrew2 (hereafter KC analyzer).
It is a synthetic analyzer, composed of two data re-
sources – a lexicon of about 2,400 lexemes, and a
set of generation rules (see (Adler, 2007, Section
4.2)). In addition, we use an unlabeled text cor-
pus, composed of stories taken from three Hebrew
daily news papers (Aruts 7, Haaretz, The Marker),
of 42M tokens. We observed 3,561 different com-
posite tags (e.g., noun-sing-fem-prepPrefix:be) over
this corpus. These 3,561 tags form the large tagset
over which we train our learner. On the one hand,
this tagset is much larger than the largest tagset used
in English (from 17 tags in most unsupervised POS
tagging experiments, to the 46 tags of the WSJ cor-
pus and the about 150 tags of the LOB corpus). On
the other hand, our tagset is intrinsically factored as
a set of dependent sub-features, which we explicitly
represent.
The task we address in this paper is morphologi-
cal disambiguation: given a sentence, obtain the list
of all possible analyses for each word from the an-
alyzer, and disambiguate each word in context. On
average, each token in the 42M corpus is given 2.7
possible analyses by the analyzer (much higher than
the average 1.41 POS tag ambiguity reported in En-
glish (Dermatas and Kokkinakis, 1995)). In previ-
ous work, we report disambiguation rates of 89%
for full morphological disambiguation (using an un-
supervised EM-HMM model) and 92.5% for part of
speech and segmentation (without assigning all the
inflectional features of the words).
In order to estimate the importance of unknowns
in Hebrew, we analyze tokens in several aspects: (1)
the number of unknown tokens, as observed on the
corpus of 42M tokens; (2) a manual classification
of a sample of 10K unknown token types out of the
200K unknown types identified in the corpus; (3) the
number of unknown analyses, based on an annotated
corpus of 200K tokens, and their classification.
About 4.5% of the 42M token instances in the
</bodyText>
<footnote confidence="0.5661565">
Buckwalter’s Arabic analyzer (2004), which looks for any le-
gal combination of prefix-stem-suffix, but does not provide full
morphological features such as gender, number, case etc.
2http://mila.cs.technion.ac.il.html
</footnote>
<bodyText confidence="0.9999448">
training corpus were unknown tokens (45% of the
450K token types). For less edited text, such as ran-
dom text sampled from the Web, the percentage is
much higher – about 7.5%. In order to classify these
unknown tokens, we sampled 10K unknown token
types and examined them manually. The classifica-
tion of these tokens with their distribution is shown
in Table 13. As can be seen, there are two main
classes of unknown token types: Neologisms (32%)
and Proper nouns (48%), which cover about 80%
of the unknown token instances. The POS distribu-
tion of the unknown tokens of our annotated corpus
is shown in Table 2. As expected, most unknowns
are open class words: proper names, nouns or adjec-
tives.
Regarding unknown analyses, in our annotated
corpus, we found 3% of the 100K token instances
were missing the correct analysis in the lexicon
(3.65% of the token types). The POS distribution of
the unknown analyses is listed in Table 2. The high
rate of unknown analyses for prepositions at about
3% is a specific phenomenon in Hebrew, where
prepositions are often prefixes agglutinated to the
first word of the noun phrase they head. We observe
the very low rate of unknown verbs (2%) – which are
well marked morphologically in Hebrew, and where
the rate of neologism introduction seems quite low.
This evidence illustrates the need for resolution
of unknowns: The naive policy of selecting ‘proper
name’ for all unknowns will cover only half of the
errors caused by unknown tokens, i.e., 30% of the
whole unknown tokens and analyses. The other 70%
of the unknowns ( 5.3% of the words in the text in
our experiments) will be assigned a wrong tag.
As a result of this observation, our strategy is to
focus on full morphological analysis for unknown
tokens and apply a proper name classifier for un-
known analyses and unknown tokens. In this paper,
we investigate various methods for achieving full
morphological analysis distribution for unknown to-
kens. The methods are not based on an annotated
corpus, nor on hand-crafted rules, but instead ex-
ploit the distribution of words in an available lexicon
and the letter similarity of the unknown words with
known words.
</bodyText>
<footnote confidence="0.816684">
3Transcription according to Ornan (2002)
</footnote>
<page confidence="0.989634">
729
</page>
<table confidence="0.999751523809524">
Category Examples Distribution
Types Instances
Proper names ’asulin (family name) ♦✐ 51DK o 48%
’a’udi (Audi) ✐❝❡❵❵ 40/0
Neologisms 30% 32%
’agabi (incidental) ✐❛❜❵
tizmur (orchestration) ①❡♥❢③
Abbreviation 2.4% 7.8%
mz”p (DIFS) t✧❢♥
kb”t (security officer) ❤✧❛✇
Foreign presentacyah (presentation) ❞✐✈❤♣❢①t 3.8% 5.8%
’a’ut (out) ❤❡❵❵
right
Wrong spelling ’abibba’ah. ronah (springatlast) ❞♣❡①❣❵❛❛✐❛❵ 1.2% 4%
’idiqacyot (idication) ③❡✐✈✇✐❝✐❵
ryusalaim (Rejusalem) ♠✐❧②❡✐①
Alternative spelling ’opyynim (typical) ♠✐♣✐✐t❡❵ 3.5% 3%
priwwilegyah (privilege )❞✐❜❧✐❡❡✐①t
Tokenization 8% 2%
ha”sap (the”threshold) sq✧❞
‘al/17 (on/17) ✼✶✴❧r
</table>
<tableCaption confidence="0.996655">
Table 1: Unknown Hebrew token categories and distribution.
</tableCaption>
<table confidence="0.9999729">
Part of Speech Unknown Tokens Unknown Analyses Total
Proper name 31.8% 24.4% 56.2%
Noun 12.6% 1.6% 14.2%
Adjective 7.1% 1.7% 8.8%
Junk 3.0% 1.3% 4.3%
Numeral 1.1% 2.3% 3.4%
Preposition 0.3% 2.8% 3.1%
Verb 1.8% 0.4% 2.2%
Adverb 0.9% 0.9% 1.8%
Participle 0.4% 0.8% 1.2%
Copula / 0.8% 0.8%
Quantifier 0.3% 0.4% 0.7%
Modal 0.3% 0.4% 0.7%
Conjunction 0.1% 0.5% 0.6%
Negation / 0.6% 0.6%
Foreign 0.2% 0.4% 0.6%
Interrogative 0.1% 0.4% 0.5%
Prefix 0.3% 0.2% 0.5%
Pronoun / 0.5% 0.5%
Total 60% 40% 100%
</table>
<tableCaption confidence="0.998954">
Table 2: Unknowns Hebrew POS Distribution.
</tableCaption>
<page confidence="0.995392">
730
</page>
<sectionHeader confidence="0.99626" genericHeader="method">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999986138297873">
Most of the work that dealt with unknowns in the last
decade focused on unknown tokens (OOV). A naive
approach would assign all possible analyses for each
unknown token with uniform distribution, and con-
tinue disambiguation on the basis of a learned model
with this initial distribution. The performance of a
tagger with such a policy is actually poor: there are
dozens of tags in the tagset (3,561 in the case of He-
brew full morphological disambiguation) and only
a few of them may match a given token. Several
heuristics were developed to reduce the possibility
space and to assign a distribution for the remaining
analyses.
Weischedel et al. (1993) combine several heuris-
tics in order to estimate the token generation prob-
ability according to various types of information –
such as the characteristics of particular tags with
respect to unknown tokens (basically the distribu-
tion shown in Table 2), and simple spelling fea-
tures: capitalization, presence of hyphens and spe-
cific suffixes. An accuracy of 85% in resolving un-
known tokens was reported. Dermatas and Kokki-
nakis (1995) suggested a method for guessing un-
known tokens based on the distribution of the ha-
pax legomenon, and reported an accuracy of 66% for
English. Mikheev (1997) suggested a guessing-rule
technique, based on prefix morphological rules, suf-
fix morphological rules, and ending-guessing rules.
These rules are learned automatically from raw text.
They reported a tagging accuracy of about 88%.
Thede and Harper (1999) extended a second-order
HMM model with a C = ck�i matrix, in order to en-
code the probability of a token with a suffix sk to
be generated by a tag ti. An accuracy of about 85%
was reported.
Nakagawa (2004) combine word-level and
character-level information for Chinese and
Japanese word segmentation. At the word level, a
segmented word is attached to a POS, where the
character model is based on the observed characters
and their classification: Begin of word, In the
middle of a word, End of word, the character is a
word itself S. They apply Baum-Welch training over
a segmented corpus, where the segmentation of each
word and its character classification is observed, and
the POS tagging is ambiguous. The segmentation
(of all words in a given sentence) and the POS
tagging (of the known words) is based on a Viterbi
search over a lattice composed of all possible word
segmentations and the possible classifications of
all observed characters. Their experimental results
show that the method achieves high accuracy over
state-of-the-art methods for Chinese and Japanese
word segmentation. Hebrew also suffers from
ambiguous segmentation of agglutinated tokens into
significant words, but word formation rules seem to
be quite different from Chinese and Japanese. We
also could not rely on the existence of an annotated
corpus of segmented word forms.
Habash and Rambow (2006) used the
root+pattern+features representation of Arabic
tokens for morphological analysis and generation
of Arabic dialects, which have no lexicon. They
report high recall (95%–98%) but low precision
(37%–63%) for token types and token instances,
against gold-standard morphological analysis. We
also exploit the morphological patterns characteris-
tic of semitic morphology, but extend the guessing
of morphological features by using contextual
features. We also propose a method that relies
exclusively on learned character-level features and
contextual features, and eventually reaches the same
performance as the patterns-based approach.
Mansour et al. (2007) combine a lexicon-based
tagger (such as MorphTagger (Bar-Haim et al.,
2005)), and a character-based tagger (such as the
data-driven ArabicSVM (Diab et al., 2004)), which
includes character features as part of its classifica-
tion model, in order to extend the set of analyses
suggested by the analyzer. For a given sentence, the
lexicon-based tagger is applied, selecting one tag for
a token. In case the ranking of the tagged sentence is
lower than a threshold, the character-based tagger is
applied, in order to produce new possible analyses.
They report a very slight improvement on Hebrew
and Arabic supervised POS taggers.
Resolution of Hebrew unknown tokens, over a
large number of tags in the tagset (3,561) requires
a much richer model than the the heuristics used
for English (for example, the capitalization feature
which is dominant in English does not exist in He-
brew). Unlike Nakagawa, our model does not use
any segmented text, and, on the other hand, it aims
to select full morphological analysis for each token,
</bodyText>
<page confidence="0.952055">
731
</page>
<bodyText confidence="0.974383666666667">
including unknowns. model application is a set of possible full morpho-
logical analyses for the token – in exactly the same
3 Method format as the morphological analyzer provides.
Our objective is: given an unknown word, provide
a distribution of possible tags that can serve as the
analysis of the unknown word. This unknown anal-
ysis step is performed at training and testing time.
We do not attempt to disambiguate the word – but
only to provide a distribution of tags that will be dis-
ambiguated by the regular EM-HMM mechanism.
We examined three models to construct the distri-
bution of tags for unknown words, that is, whenever
the KC analyzer does not return any candidate anal-
ysis, we apply these models to produce possible tags
for the token p(t|w):
Letters A maximum entropy model is built for
all unknown tokens in order to estimate their tag
distribution. The model is trained on the known
tokens that appear in the corpus. For each anal-
ysis of a known token, the following features are
extracted: (1) unigram, bigram, and trigram letters
of the base-word (for each analysis, the base-word
is the token without prefixes), together with their
index relative to the start and end of the word. For
example, the n-gram features extracted for the word
abc are { a:1 b:2 c:3 a:-3 b:-2 c:-1
ab:1 bc:2 ab:-2 bc:-1 abc:1 abc:-1
} ; (2) the prefixes of the base-word (as a single
feature); (3) the length of the base-word. The class
assigned to this set of features, is the analysis of the
base-word. The model is trained on all the known
tokens of the corpus, each token is observed with its
possible POS-tags once for each of its occurrences.
When an unknown token is found, the model
is applied as follows: all the possible linguistic
prefixes are extracted from the token (one of the 76
prefix sequences that can occur in Hebrew); if more
than one such prefix is found, the token is analyzed
for each possible prefix. For each possible such
segmentation, the full feature vector is constructed,
and submitted to the Maximum Entropy model.
We hypothesize a uniform distribution among the
possible segmentations and aggregate a distribution
of possible tags for the analysis. If the proposed
tag of the base-word is never found in the corpus
preceded by the identified prefix, we remove this
possible analysis. The eventual outcome of the
Patterns Word formation in Hebrew is based on
root+pattern and affixation. Patterns can be used to
identify the lexical category of unknowns, as well
as other inflectional properties. Nir (1993) investi-
gated word-formation in Modern Hebrew with a spe-
cial focus on neologisms; the most common word-
formation patterns he identified are summarized in
Table 3. A naive approach for unknown resolution
would add all analyses that fit any of these patterns,
for any given unknown token. As recently shown by
Habash and Rambow (2006), the precision of such
a strategy can be pretty low. To address this lack of
precision, we learn a maximum entropy model on
the basis of the following binary features: one fea-
ture for each pattern listed in column Formation of
Table 3 (40 distinct patterns) and one feature for “no
pattern”.
Pattern-Letters This maximum entropy model is
learned by combining the features of the letters
model and the patterns model.
Linear-Context-based p(t|c) approximation
The three models above are context free. The
linear-context model exploits information about the
lexical context of the unknown words: to estimate
the probability for a tag t given a context c – p(t|c)
– based on all the words in which a context occurs,
the algorithm works on the known words in the
corpus, by starting with an initial tag-word estimate
p(t|w) (such as the morpho-lexical approximation,
suggested by Levinger et al. (1995)), and iteratively
re-estimating:
</bodyText>
<equation confidence="0.998444166666667">
&amp; ��W p(t|w)p(w|c)
ˆp(t|c) =
Z
&amp; ��C p(t|c)p(c|w)allow(t, w)
ˆp(t|w) =
Z
</equation>
<bodyText confidence="0.999792714285714">
where Z is a normalization factor, W is the set of
all words in the corpus, C is the set of contexts.
allow(t, w) is a binary function indicating whether t
is a valid tag for w. p(c|w) and p(w|c) are estimated
via raw corpus counts.
Loosely speaking, the probability of a tag given a
context is the average probability of a tag given any
</bodyText>
<page confidence="0.993393">
732
</page>
<table confidence="0.999810756097561">
Category Formation Example
Verb Template ’iCCeC ’ibh. en (diagnosed) ♦❣❛❵
miCCeC mihzer (recycled) ①❢❣♥
CiCCen timren (manipulated) ♦①♥③
CiCCet tiknet (programmed) ③♣❦③
tiCCeC ti’arek (dated) ❥①❵③
Participle Template meCuCaca mswh. zar (reconstructed) ①❢❣❡②♥
muCCaC muqlat. (recorded) ❤❧✇❡♥
maCCiC malbin (whitening) ♦✐❛❧♥
Noun Suffixation ut haluciyut (pioneership) ③❡✐✈❡❧❣
ay yomanay (duty officer) ✐❵♣♥❡✐
an ’egropan (boxer) ♦t❡①❜❵
on pahon (shack) ♦❡❣t
iya marakiyah (soup tureen)❞✐✐✇①♥
it tiyulit (open touring vehicle) ③✐❧❡✐❤
a lomdah (courseware) ❞❝♥❡❧
Template maCCeC masneq (choke) ✇♣②♥
maCCeCa madgera (incubator) ❞①❜❝♥
miCCaC mis‘ap (branching) srq♥
miCCaCa mignana (defensive fighting) ❞♣♣❜♥
CeCeCa pelet (output) ❤❧t
tiCCoCet tiproset (distribution) ③q❡①t③
taCCiC tahrit (engraving) ❤✐①❣③
taCCuCa tabru’ah (sanitation) ❞❵❡①❛③
miCCeCet micrepet (leotard) ③t①✈♥
CCiC crir (dissonance) ①✐①✈
CaCCan balsan (linguist) ♦②❧❛
CaCeCet sah. emet (cirrhosis) ③♥❣②
CiCul t.ibu‘ (ringing) r❡❛✐❤
haCCaCa hanpasa (animation) ❞②t♣❞
heCCeC het’em (agreement) ♠❵③❞
Adjective Suffixationb i nora’i (awful) ✐❵①❡♣
ani yehidani (individual) ✐♣❝✐❣✐
oni telewizyonic (televisional) ✐♣❡✐❢✐❡❡❧❤
a’i yed. ida’i (unique) ✐❵❝✐❣✐
ali studentiali (student) ✐❧❵✐❤♣❝❡❤q
Template C1C2aC3C2aC3d metaqtaq (sweetish) ✇③✇③♥
CaCuC rapus (flaccid) q❡t①
Adverb Suffixation ot qcarot (briefly) ③❡①✈✇
it miyadit (immediately) ③✐❝✐♥
Prefixation b bekeip (with fun) s✐❦❛
</table>
<tableCaption confidence="0.6676428">
aCoCeC variation: ✇③❡r ‘wyeq (a copy).
bThe feminine form is made by the t and iya suffixes: ✐♣❝✐❣✐ yehidanit (individual), ❞✐①✈❡♣ nwcriya (Christian).
cIn the feminine form, the last h of the original noun is omitted.
dC1C2aC3C2oC3 variation: ♦❡❤♣❤✇ qt.ant.wn (tiny).
Table 3: Common Hebrew Neologism Formations.
</tableCaption>
<page confidence="0.961268">
733
</page>
<table confidence="0.999717307692308">
Model Analysis Set Morphological
Disambiguation
Coverage Ambiguity Probability
Baseline 50.8% 1.5 0.48 57.3%
Pattern 82.8% 20.4 0.10 66.8%
Letter 76.7% 5.9 0.32 69.1%
Pattern-Letter 84.1% 10.4 0.25 69.8%
WordContext-Pattern 84.4% 21.7 0.12 66.5%
TagContext-Pattern 85.3% 23.5 0.19 64.9%
WordContext-Letter 80.7% 7.94 0.30 69.7%
TagContext-Letter 83.1% 7.8 0.22 66.9%
WordContext-Pattern-Letter 85.2% 12.0 0.24 68.8%
TagContext-Pattern-Letter 86.1% 14.3 0.18 62.1%
</table>
<tableCaption confidence="0.999926">
Table 4: Evaluation of unknown token full morphological analysis.
</tableCaption>
<bodyText confidence="0.999799416666666">
of the words appearing in that context, and similarly
the probability of a tag given a word is the averaged
probability of that tag in all the (reliable) contexts
in which the word appears. We use the function
allow(t, w) to control the tags (ambiguity class) al-
lowed for each word, as given by the lexicon.
For a given word wi in a sentence, we examine
two types of contexts: word context wi−1, wi+1,
and tag context ti−1, ti+1. For the case of word con-
text, the estimation of p(w|c) and p(c|w) is simply
the relative frequency over all the events w1, w2, w3
occurring at least 10 times in the corpus. Since the
corpus is not tagged, the relative frequency of the
tag contexts is not observed, instead, we use the
context-free approximation of each word-tag, in or-
der to determine the frequency weight of each tag
context event. For example, given the sequence
no5 nmolv5 elan tgubah l‘umatit lmadai (a quite
oppositional response), and the analyses set pro-
duced by the context-free approximation: tgubah
[NN 1.0] l‘umatit [] lmadai [RB 0.8, P1-NN 0.2].
The frequency weight of the context {NN RB} is
1 * 0.8 = 0.8 and the frequency weight of the con-
text {NN P1-NN} is 1 * 0.2 = 0.2.
</bodyText>
<sectionHeader confidence="0.998274" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999986684210526">
For testing, we manually tagged the text which is
used in the Hebrew Treebank (consisting of about
90K tokens), according to our tagging guideline (?).
We measured the effectiveness of the three mod-
els with respect to the tags that were assigned to the
unknown tokens in our test corpus (the ‘correct tag’),
according to three parameters: (1) The coverage of
the model, i.e., we count cases where p(t|w) con-
tains the correct tag with a probability larger than
0.01; (2) the ambiguity level of the model, i.e., the
average number of analyses suggested for each to-
ken; (3) the average probability of the ‘correct tag’,
according to the predicted p(t|w). In addition, for
each experiment, we run the full morphology dis-
ambiguation system where unknowns are analyzed
according by the model.
Our baseline proposes the most frequent tag
(proper name) for all possible segmentations of the
token, in a uniform distribution. We compare the
following models: the 3 context free models (pat-
terns, letters and the combined patterns and letters)
and the same models combined with the word and
tag context models. Note that the context models
have low coverage (about 40% for the word context
and 80% for the tag context models), and therefore,
the context models cannot be used on their own. The
highest coverage is obtained for the combined model
(tag context, pattern, letter) at 86.1%.
We first show the results for full morphological
disambiguation, over 3,561 distinct tags in Table 4.
The highest coverage is obtained for the model com-
bining the tag context, patterns and letters models.
The tag context model is more effective because
it covers 80% of the unknown words, whereas the
word context model only covers 40%. As expected,
our simple baseline has the highest precision, since
the most frequent proper name tag covers over 50%
of the unknown words. The eventual effectiveness of
</bodyText>
<page confidence="0.993528">
734
</page>
<table confidence="0.997384833333333">
Model Analysis Set POS Tagging
Coverage Ambiguity Probability
Baseline 52.9% 1.5 0.52 60.6%
Pattern 87.4% 8.7 0.19 76.0%
Letter 80% 4.0 0.39 77.6%
Pattern-Letter 86.7% 6.2 0.32 78.5%
WordContext-Pattern 88.7% 8.8 0.21 75.8%
TagContext-Pattern 89.5% 9.1 0.14 73.8%
WordContext-Letter 83.8% 4.5 0.37 78.2%
TagContext-Letter 87.1% 5.7 0.28 75.2%
WordContext-Pattern-Letter 87.8 6.5 0.32 77.5%
TagContext-Pattern-Letter 89.0% 7.2 0.25 74%
</table>
<tableCaption confidence="0.99989">
Table 5: Evaluation of unknown token POS tagging.
</tableCaption>
<bodyText confidence="0.999976628571429">
the method is measured by its impact on the eventual
disambiguation of the unknown words. For full mor-
phological disambiguation, our method achieves an
error reduction of 30% (57% to 70%). Overall, with
the level of 4.5% of unknown words observed in our
corpus, the algorithm we have developed contributes
to an error reduction of 5.5% for full morphological
disambiguation.
The best result is obtained for the model com-
bining pattern and letter features. However, the
model combining the word context and letter fea-
tures achieves almost identical results. This is an
interesting result, as the pattern features encapsulate
significant linguistic knowledge, which apparently
can be approximated by a purely distributional ap-
proximation.
While the disambiguation level of 70% is lower
than the rate of 85% achieved in English, it must
be noted that the task of full morphological disam-
biguation in Hebrew is much harder – we manage
to select one tag out of 3,561 for unknown words as
opposed to one out of 46 in English. Table 5 shows
the result of the disambiguation when we only take
into account the POS tag of the unknown tokens.
The same models reach the best results in this case
as well (Pattern+Letters and WordContext+Letters).
The best disambiguation result is 78.5% – still much
lower than the 85% achieved in English. The main
reason for this lower level is that the task in He-
brew includes segmentation of prefixes and suffixes
in addition to POS classification. We are currently
investigating models that will take into account the
specific nature of prefixes in Hebrew (which encode
conjunctions, definite articles and prepositions) to
better predict the segmentation of unknown words.
</bodyText>
<sectionHeader confidence="0.999348" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999944153846154">
We have addressed the task of computing the distri-
bution p(tlw) for unknown words for full morpho-
logical disambiguation in Hebrew. The algorithm
we have proposed is language independent: it ex-
ploits a maximum entropy letters model trained over
the known words observed in the corpus and the dis-
tribution of the unknown words in known tag con-
texts, through iterative approximation. The algo-
rithm achieves 30% error reduction on disambigua-
tion of unknown words over a competitive baseline
(to a level of 70% accurate full disambiguation of
unknown words). We have also verified that tak-
ing advantage of a strong language-specific model
of morphological patterns provides the same level
of disambiguation. The algorithm we have devel-
oped exploits distributional information latent in a
wide-coverage lexicon and large quantities of unla-
beled data.
We observe that the task of analyzing unknown to-
kens for POS in Hebrew remains challenging when
compared with English (78% vs. 85%). We hy-
pothesize this is due to the highly ambiguous pattern
of prefixation that occurs widely in Hebrew and are
currently investigating syntagmatic models that ex-
ploit the specific nature of agglutinated prefixes in
Hebrew.
</bodyText>
<page confidence="0.997638">
735
</page>
<sectionHeader confidence="0.998337" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999904517857143">
Meni Adler. 2007. Hebrew Morphological Disambigua-
tion: An Unsupervised Stochastic Word-based Ap-
proach. Ph.D. thesis, Ben-Gurion University of the
Negev, Beer-Sheva, Israel.
Roy Bar-Haim, Khalil Sima’an, and Yoad Winter. 2005.
Choosing an optimal architecture for segmentation and
pos-tagging of modern Hebrew. In Proceedings of
ACL-05 Workshop on Computational Approaches to
Semitic Languages.
Tim Buckwalter. 2004. Buckwalter Arabic morphologi-
cal analyzer, version 2.0.
Evangelos Dermatas and George Kokkinakis. 1995. Au-
tomatic stochastic tagging of natural language texts.
Computational Linguistics, 21(2):137–163.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.
Automatic tagging of Arabic text: From raw text to
base phrase chunks. In Proceeding of HLT-NAACL-
04.
Michael Elhadad, Yael Netzer, David Gabay, and Meni
Adler. 2005. Hebrew morphological tagging guide-
lines. Technical report, Ben-Gurion University, Dept.
of Computer Science.
Nizar Habash and Owen Rambow. 2006. Magead: A
morphological analyzer and generator for the arabic
dialects. In Proceedings of the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Association for Computational Linguis-
tics, pages 681–688, Sydney, Australia, July. Associa-
tion for Computational Linguistics.
Moshe Levinger, Uzi Ornan, and Alon Itai. 1995. Learn-
ing morpholexical probabilities from an untagged cor-
pus with an application to Hebrew. Computational
Linguistics, 21:383–404.
Saib Mansour, Khalil Sima’an, and Yoad Winter. 2007.
Smoothing a lexicon-based pos tagger for Arabic and
Hebrew. In ACL07 Workshop on Computational Ap-
proaches to Semitic Languages, Prague, Czech Repub-
lic.
Andrei Mikheev. 1997. Automatic rule induction for
unknown-word guessing. Computational Linguistics,
23(3):405–423.
Tetsuji Nakagawa. 2004. Chinese and Japanese word
segmentation using word-level and character-level in-
formation. In Proceedings of the 20th international
conference on Computational Linguistics, Geneva.
Raphael Nir. 1993. Word-Formation in Modern Hebrew.
The Open University of Israel, Tel-Aviv, Israel.
Uzi Ornan. 2002. Hebrew in Latin script. L˘eˇson´enu,
LXIV:137–151. (in Hebrew).
Scott M. Thede and Mary P. Harper. 1999. A second-
order hidden Markov model for part-of-speech tag-
ging. In Proceeding ofACL-99.
R. Weischedel, R. Schwartz, J. Palmucci, M. Meteer, and
L. Ramshaw. 1993. Coping with ambiguity and un-
known words through probabilistic models. Computa-
tional Linguistics, 19:359–382.
</reference>
<page confidence="0.998562">
736
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.566561">
<title confidence="0.998921">Unsupervised Lexicon-Based Resolution of Unknown Words for Full Morphological Analysis</title>
<author confidence="0.970165">Adler Goldberg Gabay Elhadad Ben Gurion University of the Negev</author>
<affiliation confidence="0.958644">of Computer</affiliation>
<address confidence="0.921231">POB 653 Be’er Sheva, 84105, Israel</address>
<abstract confidence="0.999938064516129">Morphological disambiguation proceeds in 2 stages: (1) an analyzer provides all possible analyses for a given token and (2) a stochastic disambiguation module picks the most likely analysis in context. When the analyzer does not recognize a given token, we hit the problem of unknowns. In large scale corpora, unknowns appear at a rate of 5 to 10% (depending on the genre and the maturity of the lexicon). We address the task of computing the distribuunknown words for full morphological disambiguation in Hebrew. We introduce a novel algorithm that is language independent: it exploits a maximum entropy letters model trained over the known words observed in the corpus and the distribution of the unknown words in known tag contexts, through iterative approximation. The algorithm achieves 30% error reduction on disambiguation of unknown words over a competitive baseline (to a level of 70% accurate full disambiguation of unknown words). We have also verified that taking advantage of a strong language-specific model of morphological patterns provides the same level of disambiguation. The algorithm we have developed exploits distributional information latent in a wide-coverage lexicon and large quantities of unlabeled data.</abstract>
<note confidence="0.699618">work is supported in part by the Lynn and William Frankel Center for Computer Science.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
</authors>
<title>Hebrew Morphological Disambiguation: An Unsupervised Stochastic Word-based Approach.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Ben-Gurion University of the Negev,</institution>
<location>Beer-Sheva, Israel.</location>
<contexts>
<context position="3762" citStr="Adler, 2007" startWordPosition="609" endWordPosition="610">atures1: lemma, affixes, lexical cate1In contrast to the prefix-stem-suffix analysis format of 728 Proceedings of ACL-08: HLT, pages 728–736, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics gory (POS), and a set of inflection properties (according to the POS) – gender, number, person, status and tense. In this work, we refer to the morphological analyzer of MILA – the Knowledge Center for Processing Hebrew2 (hereafter KC analyzer). It is a synthetic analyzer, composed of two data resources – a lexicon of about 2,400 lexemes, and a set of generation rules (see (Adler, 2007, Section 4.2)). In addition, we use an unlabeled text corpus, composed of stories taken from three Hebrew daily news papers (Aruts 7, Haaretz, The Marker), of 42M tokens. We observed 3,561 different composite tags (e.g., noun-sing-fem-prepPrefix:be) over this corpus. These 3,561 tags form the large tagset over which we train our learner. On the one hand, this tagset is much larger than the largest tagset used in English (from 17 tags in most unsupervised POS tagging experiments, to the 46 tags of the WSJ corpus and the about 150 tags of the LOB corpus). On the other hand, our tagset is intrin</context>
</contexts>
<marker>Adler, 2007</marker>
<rawString>Meni Adler. 2007. Hebrew Morphological Disambiguation: An Unsupervised Stochastic Word-based Approach. Ph.D. thesis, Ben-Gurion University of the Negev, Beer-Sheva, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Choosing an optimal architecture for segmentation and pos-tagging of modern Hebrew.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<marker>Bar-Haim, Sima’an, Winter, 2005</marker>
<rawString>Roy Bar-Haim, Khalil Sima’an, and Yoad Winter. 2005. Choosing an optimal architecture for segmentation and pos-tagging of modern Hebrew. In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic morphological analyzer, version 2.0.</title>
<date>2004</date>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic morphological analyzer, version 2.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evangelos Dermatas</author>
<author>George Kokkinakis</author>
</authors>
<title>Automatic stochastic tagging of natural language texts.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="4836" citStr="Dermatas and Kokkinakis, 1995" startWordPosition="790" endWordPosition="793">st unsupervised POS tagging experiments, to the 46 tags of the WSJ corpus and the about 150 tags of the LOB corpus). On the other hand, our tagset is intrinsically factored as a set of dependent sub-features, which we explicitly represent. The task we address in this paper is morphological disambiguation: given a sentence, obtain the list of all possible analyses for each word from the analyzer, and disambiguate each word in context. On average, each token in the 42M corpus is given 2.7 possible analyses by the analyzer (much higher than the average 1.41 POS tag ambiguity reported in English (Dermatas and Kokkinakis, 1995)). In previous work, we report disambiguation rates of 89% for full morphological disambiguation (using an unsupervised EM-HMM model) and 92.5% for part of speech and segmentation (without assigning all the inflectional features of the words). In order to estimate the importance of unknowns in Hebrew, we analyze tokens in several aspects: (1) the number of unknown tokens, as observed on the corpus of 42M tokens; (2) a manual classification of a sample of 10K unknown token types out of the 200K unknown types identified in the corpus; (3) the number of unknown analyses, based on an annotated cor</context>
<context position="10282" citStr="Dermatas and Kokkinakis (1995)" startWordPosition="1668" endWordPosition="1672">on) and only a few of them may match a given token. Several heuristics were developed to reduce the possibility space and to assign a distribution for the remaining analyses. Weischedel et al. (1993) combine several heuristics in order to estimate the token generation probability according to various types of information – such as the characteristics of particular tags with respect to unknown tokens (basically the distribution shown in Table 2), and simple spelling features: capitalization, presence of hyphens and specific suffixes. An accuracy of 85% in resolving unknown tokens was reported. Dermatas and Kokkinakis (1995) suggested a method for guessing unknown tokens based on the distribution of the hapax legomenon, and reported an accuracy of 66% for English. Mikheev (1997) suggested a guessing-rule technique, based on prefix morphological rules, suffix morphological rules, and ending-guessing rules. These rules are learned automatically from raw text. They reported a tagging accuracy of about 88%. Thede and Harper (1999) extended a second-order HMM model with a C = ck�i matrix, in order to encode the probability of a token with a suffix sk to be generated by a tag ti. An accuracy of about 85% was reported. </context>
</contexts>
<marker>Dermatas, Kokkinakis, 1995</marker>
<rawString>Evangelos Dermatas and George Kokkinakis. 1995. Automatic stochastic tagging of natural language texts. Computational Linguistics, 21(2):137–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of Arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In Proceeding of HLT-NAACL04.</booktitle>
<contexts>
<context position="12895" citStr="Diab et al., 2004" startWordPosition="2071" endWordPosition="2074">63%) for token types and token instances, against gold-standard morphological analysis. We also exploit the morphological patterns characteristic of semitic morphology, but extend the guessing of morphological features by using contextual features. We also propose a method that relies exclusively on learned character-level features and contextual features, and eventually reaches the same performance as the patterns-based approach. Mansour et al. (2007) combine a lexicon-based tagger (such as MorphTagger (Bar-Haim et al., 2005)), and a character-based tagger (such as the data-driven ArabicSVM (Diab et al., 2004)), which includes character features as part of its classification model, in order to extend the set of analyses suggested by the analyzer. For a given sentence, the lexicon-based tagger is applied, selecting one tag for a token. In case the ranking of the tagged sentence is lower than a threshold, the character-based tagger is applied, in order to produce new possible analyses. They report a very slight improvement on Hebrew and Arabic supervised POS taggers. Resolution of Hebrew unknown tokens, over a large number of tags in the tagset (3,561) requires a much richer model than the the heuris</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In Proceeding of HLT-NAACL04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Yael Netzer</author>
<author>David Gabay</author>
<author>Meni Adler</author>
</authors>
<title>Hebrew morphological tagging guidelines.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>Ben-Gurion University, Dept. of Computer Science.</institution>
<marker>Elhadad, Netzer, Gabay, Adler, 2005</marker>
<rawString>Michael Elhadad, Yael Netzer, David Gabay, and Meni Adler. 2005. Hebrew morphological tagging guidelines. Technical report, Ben-Gurion University, Dept. of Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Magead: A morphological analyzer and generator for the arabic dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>681--688</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="12071" citStr="Habash and Rambow (2006)" startWordPosition="1958" endWordPosition="1961">e) and the POS tagging (of the known words) is based on a Viterbi search over a lattice composed of all possible word segmentations and the possible classifications of all observed characters. Their experimental results show that the method achieves high accuracy over state-of-the-art methods for Chinese and Japanese word segmentation. Hebrew also suffers from ambiguous segmentation of agglutinated tokens into significant words, but word formation rules seem to be quite different from Chinese and Japanese. We also could not rely on the existence of an annotated corpus of segmented word forms. Habash and Rambow (2006) used the root+pattern+features representation of Arabic tokens for morphological analysis and generation of Arabic dialects, which have no lexicon. They report high recall (95%–98%) but low precision (37%–63%) for token types and token instances, against gold-standard morphological analysis. We also exploit the morphological patterns characteristic of semitic morphology, but extend the guessing of morphological features by using contextual features. We also propose a method that relies exclusively on learned character-level features and contextual features, and eventually reaches the same per</context>
<context position="16628" citStr="Habash and Rambow (2006)" startWordPosition="2703" endWordPosition="2706">s preceded by the identified prefix, we remove this possible analysis. The eventual outcome of the Patterns Word formation in Hebrew is based on root+pattern and affixation. Patterns can be used to identify the lexical category of unknowns, as well as other inflectional properties. Nir (1993) investigated word-formation in Modern Hebrew with a special focus on neologisms; the most common wordformation patterns he identified are summarized in Table 3. A naive approach for unknown resolution would add all analyses that fit any of these patterns, for any given unknown token. As recently shown by Habash and Rambow (2006), the precision of such a strategy can be pretty low. To address this lack of precision, we learn a maximum entropy model on the basis of the following binary features: one feature for each pattern listed in column Formation of Table 3 (40 distinct patterns) and one feature for “no pattern”. Pattern-Letters This maximum entropy model is learned by combining the features of the letters model and the patterns model. Linear-Context-based p(t|c) approximation The three models above are context free. The linear-context model exploits information about the lexical context of the unknown words: to es</context>
</contexts>
<marker>Habash, Rambow, 2006</marker>
<rawString>Nizar Habash and Owen Rambow. 2006. Magead: A morphological analyzer and generator for the arabic dialects. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 681–688, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Levinger</author>
<author>Uzi Ornan</author>
<author>Alon Itai</author>
</authors>
<title>Learning morpholexical probabilities from an untagged corpus with an application to Hebrew. Computational Linguistics,</title>
<date>1995</date>
<pages>21--383</pages>
<contexts>
<context position="17527" citStr="Levinger et al. (1995)" startWordPosition="2851" endWordPosition="2854">r “no pattern”. Pattern-Letters This maximum entropy model is learned by combining the features of the letters model and the patterns model. Linear-Context-based p(t|c) approximation The three models above are context free. The linear-context model exploits information about the lexical context of the unknown words: to estimate the probability for a tag t given a context c – p(t|c) – based on all the words in which a context occurs, the algorithm works on the known words in the corpus, by starting with an initial tag-word estimate p(t|w) (such as the morpho-lexical approximation, suggested by Levinger et al. (1995)), and iteratively re-estimating: &amp; ��W p(t|w)p(w|c) ˆp(t|c) = Z &amp; ��C p(t|c)p(c|w)allow(t, w) ˆp(t|w) = Z where Z is a normalization factor, W is the set of all words in the corpus, C is the set of contexts. allow(t, w) is a binary function indicating whether t is a valid tag for w. p(c|w) and p(w|c) are estimated via raw corpus counts. Loosely speaking, the probability of a tag given a context is the average probability of a tag given any 732 Category Formation Example Verb Template ’iCCeC ’ibh. en (diagnosed) ♦❣❛❵ miCCeC mihzer (recycled) ❢❣♥ CiCCen timren (manipulated) ♦♥ CiCCet tiknet </context>
</contexts>
<marker>Levinger, Ornan, Itai, 1995</marker>
<rawString>Moshe Levinger, Uzi Ornan, and Alon Itai. 1995. Learning morpholexical probabilities from an untagged corpus with an application to Hebrew. Computational Linguistics, 21:383–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saib Mansour</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Smoothing a lexicon-based pos tagger for Arabic and Hebrew.</title>
<date>2007</date>
<booktitle>In ACL07 Workshop on Computational Approaches to Semitic Languages,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Mansour, Sima’an, Winter, 2007</marker>
<rawString>Saib Mansour, Khalil Sima’an, and Yoad Winter. 2007. Smoothing a lexicon-based pos tagger for Arabic and Hebrew. In ACL07 Workshop on Computational Approaches to Semitic Languages, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Mikheev</author>
</authors>
<title>Automatic rule induction for unknown-word guessing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="10439" citStr="Mikheev (1997)" startWordPosition="1698" endWordPosition="1699">. Weischedel et al. (1993) combine several heuristics in order to estimate the token generation probability according to various types of information – such as the characteristics of particular tags with respect to unknown tokens (basically the distribution shown in Table 2), and simple spelling features: capitalization, presence of hyphens and specific suffixes. An accuracy of 85% in resolving unknown tokens was reported. Dermatas and Kokkinakis (1995) suggested a method for guessing unknown tokens based on the distribution of the hapax legomenon, and reported an accuracy of 66% for English. Mikheev (1997) suggested a guessing-rule technique, based on prefix morphological rules, suffix morphological rules, and ending-guessing rules. These rules are learned automatically from raw text. They reported a tagging accuracy of about 88%. Thede and Harper (1999) extended a second-order HMM model with a C = ck�i matrix, in order to encode the probability of a token with a suffix sk to be generated by a tag ti. An accuracy of about 85% was reported. Nakagawa (2004) combine word-level and character-level information for Chinese and Japanese word segmentation. At the word level, a segmented word is attache</context>
</contexts>
<marker>Mikheev, 1997</marker>
<rawString>Andrei Mikheev. 1997. Automatic rule induction for unknown-word guessing. Computational Linguistics, 23(3):405–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
</authors>
<title>Chinese and Japanese word segmentation using word-level and character-level information.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<location>Geneva.</location>
<contexts>
<context position="10897" citStr="Nakagawa (2004)" startWordPosition="1775" endWordPosition="1776"> suggested a method for guessing unknown tokens based on the distribution of the hapax legomenon, and reported an accuracy of 66% for English. Mikheev (1997) suggested a guessing-rule technique, based on prefix morphological rules, suffix morphological rules, and ending-guessing rules. These rules are learned automatically from raw text. They reported a tagging accuracy of about 88%. Thede and Harper (1999) extended a second-order HMM model with a C = ck�i matrix, in order to encode the probability of a token with a suffix sk to be generated by a tag ti. An accuracy of about 85% was reported. Nakagawa (2004) combine word-level and character-level information for Chinese and Japanese word segmentation. At the word level, a segmented word is attached to a POS, where the character model is based on the observed characters and their classification: Begin of word, In the middle of a word, End of word, the character is a word itself S. They apply Baum-Welch training over a segmented corpus, where the segmentation of each word and its character classification is observed, and the POS tagging is ambiguous. The segmentation (of all words in a given sentence) and the POS tagging (of the known words) is bas</context>
</contexts>
<marker>Nakagawa, 2004</marker>
<rawString>Tetsuji Nakagawa. 2004. Chinese and Japanese word segmentation using word-level and character-level information. In Proceedings of the 20th international conference on Computational Linguistics, Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Nir</author>
</authors>
<title>Word-Formation in Modern Hebrew. The Open University of Israel,</title>
<date>1993</date>
<location>Tel-Aviv,</location>
<contexts>
<context position="16297" citStr="Nir (1993)" startWordPosition="2650" endWordPosition="2651"> each possible such segmentation, the full feature vector is constructed, and submitted to the Maximum Entropy model. We hypothesize a uniform distribution among the possible segmentations and aggregate a distribution of possible tags for the analysis. If the proposed tag of the base-word is never found in the corpus preceded by the identified prefix, we remove this possible analysis. The eventual outcome of the Patterns Word formation in Hebrew is based on root+pattern and affixation. Patterns can be used to identify the lexical category of unknowns, as well as other inflectional properties. Nir (1993) investigated word-formation in Modern Hebrew with a special focus on neologisms; the most common wordformation patterns he identified are summarized in Table 3. A naive approach for unknown resolution would add all analyses that fit any of these patterns, for any given unknown token. As recently shown by Habash and Rambow (2006), the precision of such a strategy can be pretty low. To address this lack of precision, we learn a maximum entropy model on the basis of the following binary features: one feature for each pattern listed in column Formation of Table 3 (40 distinct patterns) and one fe</context>
</contexts>
<marker>Nir, 1993</marker>
<rawString>Raphael Nir. 1993. Word-Formation in Modern Hebrew. The Open University of Israel, Tel-Aviv, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uzi Ornan</author>
</authors>
<date>2002</date>
<booktitle>Hebrew in Latin script. L˘eˇson´enu, LXIV:137–151. (in Hebrew).</booktitle>
<contexts>
<context position="7945" citStr="Ornan (2002)" startWordPosition="1308" endWordPosition="1309">text in our experiments) will be assigned a wrong tag. As a result of this observation, our strategy is to focus on full morphological analysis for unknown tokens and apply a proper name classifier for unknown analyses and unknown tokens. In this paper, we investigate various methods for achieving full morphological analysis distribution for unknown tokens. The methods are not based on an annotated corpus, nor on hand-crafted rules, but instead exploit the distribution of words in an available lexicon and the letter similarity of the unknown words with known words. 3Transcription according to Ornan (2002) 729 Category Examples Distribution Types Instances Proper names ’asulin (family name) ♦✐ 51DK o 48% ’a’udi (Audi) ✐❝❡❵❵ 40/0 Neologisms 30% 32% ’agabi (incidental) ✐❛❜❵ tizmur (orchestration) ❡♥❢ Abbreviation 2.4% 7.8% mz”p (DIFS) t✧❢♥ kb”t (security officer) ❤✧❛✇ Foreign presentacyah (presentation) ❞✐✈❤♣❢t 3.8% 5.8% ’a’ut (out) ❤❡❵❵ right Wrong spelling ’abibba’ah. ronah (springatlast) ❞♣❡❣❵❛❛✐❛❵ 1.2% 4% ’idiqacyot (idication) ❡✐✈✇✐❝✐❵ ryusalaim (Rejusalem) ♠✐❧❡✐ Alternative spelling ’opyynim (typical) ♠✐♣✐✐t❡❵ 3.5% 3% priwwilegyah (privilege )❞✐❜❧✐❡❡✐t Tokenization 8% 2% ha”sap (the</context>
</contexts>
<marker>Ornan, 2002</marker>
<rawString>Uzi Ornan. 2002. Hebrew in Latin script. L˘eˇson´enu, LXIV:137–151. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott M Thede</author>
<author>Mary P Harper</author>
</authors>
<title>A secondorder hidden Markov model for part-of-speech tagging.</title>
<date>1999</date>
<booktitle>In Proceeding ofACL-99.</booktitle>
<contexts>
<context position="10692" citStr="Thede and Harper (1999)" startWordPosition="1732" endWordPosition="1735"> distribution shown in Table 2), and simple spelling features: capitalization, presence of hyphens and specific suffixes. An accuracy of 85% in resolving unknown tokens was reported. Dermatas and Kokkinakis (1995) suggested a method for guessing unknown tokens based on the distribution of the hapax legomenon, and reported an accuracy of 66% for English. Mikheev (1997) suggested a guessing-rule technique, based on prefix morphological rules, suffix morphological rules, and ending-guessing rules. These rules are learned automatically from raw text. They reported a tagging accuracy of about 88%. Thede and Harper (1999) extended a second-order HMM model with a C = ck�i matrix, in order to encode the probability of a token with a suffix sk to be generated by a tag ti. An accuracy of about 85% was reported. Nakagawa (2004) combine word-level and character-level information for Chinese and Japanese word segmentation. At the word level, a segmented word is attached to a POS, where the character model is based on the observed characters and their classification: Begin of word, In the middle of a word, End of word, the character is a word itself S. They apply Baum-Welch training over a segmented corpus, where the </context>
</contexts>
<marker>Thede, Harper, 1999</marker>
<rawString>Scott M. Thede and Mary P. Harper. 1999. A secondorder hidden Markov model for part-of-speech tagging. In Proceeding ofACL-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weischedel</author>
<author>R Schwartz</author>
<author>J Palmucci</author>
<author>M Meteer</author>
<author>L Ramshaw</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--359</pages>
<contexts>
<context position="9851" citStr="Weischedel et al. (1993)" startWordPosition="1600" endWordPosition="1603"> with unknowns in the last decade focused on unknown tokens (OOV). A naive approach would assign all possible analyses for each unknown token with uniform distribution, and continue disambiguation on the basis of a learned model with this initial distribution. The performance of a tagger with such a policy is actually poor: there are dozens of tags in the tagset (3,561 in the case of Hebrew full morphological disambiguation) and only a few of them may match a given token. Several heuristics were developed to reduce the possibility space and to assign a distribution for the remaining analyses. Weischedel et al. (1993) combine several heuristics in order to estimate the token generation probability according to various types of information – such as the characteristics of particular tags with respect to unknown tokens (basically the distribution shown in Table 2), and simple spelling features: capitalization, presence of hyphens and specific suffixes. An accuracy of 85% in resolving unknown tokens was reported. Dermatas and Kokkinakis (1995) suggested a method for guessing unknown tokens based on the distribution of the hapax legomenon, and reported an accuracy of 66% for English. Mikheev (1997) suggested a</context>
</contexts>
<marker>Weischedel, Schwartz, Palmucci, Meteer, Ramshaw, 1993</marker>
<rawString>R. Weischedel, R. Schwartz, J. Palmucci, M. Meteer, and L. Ramshaw. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19:359–382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>