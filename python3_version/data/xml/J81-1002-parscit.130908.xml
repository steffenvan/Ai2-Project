<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.82031">
Computer Generation of Multiparagraph English Text&apos;
</title>
<author confidence="0.751755">
William C. Mann
James A. Moore
</author>
<affiliation confidence="0.900367333333333">
Information Sciences Institute
University of Southern California
Marina del Rey, California 90291
</affiliation>
<bodyText confidence="0.988845272727273">
This paper reports recent research into methods for creating natural language text. A
new processing paradigm called Fragment-and-Compose has been created and an experi-
mental system implemented in it. The knowledge to be expressed in text is first divided
into small propositional units, which are then composed into appropriate combinations and
converted into text.
KDS (Knowledge Delivery System), which embodies this paradigm, has distinct parts
devoted to creation of the propositional units, to organization of the text, to prevention of
excess redundancy, to creation of combinations of units, to evaluation of these combina-
tions as potential sentences, to selection of the best among competing combinations, and to
creation of the final text. The Fragment-and-Compose paradigm and the computational
methods of KDS are described.
</bodyText>
<sectionHeader confidence="0.813149" genericHeader="abstract">
Introduction
</sectionHeader>
<bodyText confidence="0.981319053571429">
Computer users have difficulties in understanding
what knowledge is stored in their computers; the sys-
tems have corresponding difficulties in delivering their
knowledge. The knowledge in the machine may be
represented in an incomprehensible notation, or we
may want to share the knowledge with a large group
of people who lack the training to understand the
computer&apos;s formal notation. For example, there are
large simulation programs that get into very complicat-
ed states we would like to be able to understand easi-
ly. There are data base systems with complex know-
ledge buried in them, but real problems in extracting
it. There are status-keeping systems from which we
would like to get snapshots. There are systems that
try to prove things, from which we would like to have
progress reports and justifications for various actions.
Many other kinds of systems have knowledge-delivery
difficulties.
1 This research was supported in part by National Science
Foundation grant No. MCS76-07332 and in part by the Air Force
Office of Scientific Research contract No. F49620-79-c-0181. The
participation of Neil Goldman and James Levin is gratefully ac-
knowledged. The views and conclusions contained in this document
are those of the authors and should not be interpreted as necessari-
ly representing the official policies or endorsements, either ex-
pressed or implied, of the Air Force Office of Scientific Research of
the U.S. Government.
The circumstances that make it particularly attrac-
tive to deliver this knowledge in natural language are:
a) complexity of the source knowledge, so that its
notation is not easily learned, b) unpredictability of
the demands for knowledge, so that the actual de-
mands cannot be met with specific preprogrammed
output, and c) the need to serve a large pool of un-
trained or lightly trained users of these systems.
For a number of the kinds of systems mentioned
above, getting the information out is one of the princi-
pal limitations on the systems&apos; uses. If the information
could be accessed more easily, then far more people
could use the systems. So we are talking in part about
facilitating existing systems, but much more about
creating new opportunities for systems to serve people.
If computer systems could express themselves in
fluent natural language, many of these difficulties
would disappear. However, the necessary processes
for such expression do not exist, and there are formi-
dable obstacles even to designing such processes. The
theory of writing is sketchy and vague, and there are
few interesting computer systems to serve as preced-
ents. Any research effort to create such systems —
systems that know how to write — can be significant
both in its practical implications and for the knowl-
edge of writing that it produces.
Copyright 1981 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on
the first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<page confidence="0.400743">
0362-613X/81/010017-13$01.00
</page>
<note confidence="0.842307">
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 17
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
</note>
<bodyText confidence="0.999866763157895">
Writing is an intellectually interesting task, though
poorly understood. If we want to have a better theo-
ry, a better characterization of this task, then we can
use computer program design and test as a discovery
procedure for exploring the subject. In the present
state of the art, the same research can create both
theoretical knowledge and practical computational
methods.
Of course, in a limited sense, programs already
deliver knowledge in natural language by using
&amp;quot;canned text.&amp;quot; A person writes some text, possibly
with the use of blank segments, and the text is stored
for use in association with a particular demand. The
machine fills in the blanks as needed in a way antici-
pated as sufficient for the demand. This is a very
useful technique, but it does not tell us much about
the task of writing, and it does not generalize to situa-
tions in which the need for text has not been well
anticipated in the programming stage. The basic or-
ganization and writing of canned text are done by a
person, so that sort of &amp;quot;writing&amp;quot; falls outside the scope
of this paper.
The idea that natural language would be a useful
output medium for a computer system is quite old, but
the research to make such output possible is still in a
very primitive state. Most of it has concentrated on
sentence generation, in which problems such as word
selection or translation to natural language from logi-
cal formulas have been chosen for study. These are
important, but the needs for knowledge delivery sim-
ply cannot be satisfied by single sentences. It is nec-
essary to have multiple sentences to communicate
complex information, and multiple paragraphs would
be even more valuable.
The remainder of this paper thus focuses on com-
puter generation of multisentence text. We present
some examples of multisentence output from past sys-
tems and then discuss our own research.
</bodyText>
<subsectionHeader confidence="0.995119">
Multisentential Text Generation in Past Research
</subsectionHeader>
<bodyText confidence="0.9993119">
Several systems have generated multisentence text
[2,5,8,10,111.2 3 Sample texts from three of these are
shown in Figure 1. One example is the SCHOLAR
system, which describes aspects of South American
geography. SCHOLAR&apos;s description of a South
American country was several sentences long [2]. The
SAM system, a story generator operating from a con-
ceptual dependency script, also created multisentential
output [10]. More recently, Meehan developed
TALE-SPIN, a fable generator that worked in a differ-
</bodyText>
<footnote confidence="0.997244">
2 Since this paper was written in 1979, additional work in-
volving multisentential generation has been done or published
[3,4,71 Only the references have been updated.
3 All of the cited research has worked with English, but other
languages would have served as well.
</footnote>
<note confidence="0.772245">
SCHOLAR:
*TELL ME ABOUT THE LOCATION OF URUGUAY.*
THE LOCATION IN URUGUAY IS SOUTH AMERICA.
THE LATITUDE RANGES FROM -30 TO -35 DEGREES.
THE LONGITUDE RANGES FROM -53 TO -58 DEGREES.
THE NORTHERN AND EASTERN BORDERING COUNTRY IS BRAZIL.
THE WESTERN BORDERING COUNTRY IS ARGENTINA.
THE BOUNDARY IS THE URUGUAY RIVER.
THE SOUTHEASTERN COAST IS THE ATLANTIC OCEAN.
THE SOUTHERN COAST IS THE RIO DE LA PLATA.
</note>
<sectionHeader confidence="0.278402" genericHeader="keywords">
SAM:
</sectionHeader>
<bodyText confidence="0.997204545454546">
John decided he was going to a restaurant. He went to one.
He asked the hostess for a table. She told him he could go
to it. He went to it. She went to it. He sat down in a
chair. He got a menu from her. He read it. A waiter saw
John was at the table. The waiter went to it. John
ordered a lobster. A chef cooked it. The waiter got it
from the chef. The waiter served it to John quickly. He
ate it. He asked the waiter for a check. John got it from
the waiter. John remembered the waiter had served the
lobster to him quickly. John left the waiter a large tip.
John paid the check. He left the restaurant.
</bodyText>
<construct confidence="0.9085148">
TALESPIN:
ONCE UPON A TIME GEORGE ANT LIVED NEAR A PATCH OF GROUND.
THERE WAS A NEST IN AN ASH TREE. WILMA BIRD LIVED IN THE
NEST. THERE WAS SOME WATER IN A RIVER. WILMA KNEW THAT
THE WATER WAS IN THE RIVER. GEORGE KNEW THAT THE WATER WAS
IN THE RIVER. ONE DAY WILMA WAS VERY THIRSTY. WILMA
WANTED TO GET NEAR SOME WATER. WILMA FLEW FROM HER NEST
ACROSS A MEADOW THROUGH A VALLEY TO THE RIVER. WILMA DRANK
THE WATER. WILMA WASN&apos;T THIRSTY ANY MORE.
GEORGE WAS VERY THIRSTY. GEORGE WANTED TO GET NEAR SOME
WATER. GEORGE WALKED FROM HIS PATCH OF GROUND ACROSS THE
MEADOW THROUGH THE VALLEY TO A RIVER BANK. GEORGE FELL
INTO THE WATER. GEORGE WANTED TO GET NEAR THE VALLEY.
GEORGE COULDN&apos;T GET NEAR THE VALLEY. GEORGE WANTED TO GET
NEAR THE MEADOW. GEORGE COULDN&apos;T GET NEAR THE MEADOW.
WILMA WANTED TO GET NEAR GEORGE. WILMA GRABBED GEORGE WITH
HER CLAW. WILMA TOOK GEORGE FROM THE RIVER THROUGH THE
VALLEY TO THE MEADOW. GEORGE WAS DEVOTED TO WILMA. GEORGE
OWED EVERYTHING TO WILMA. WILMA LET GO OF GEORGE. GEORGE
FELL TO THE MEADOW. THE END.
</construct>
<figureCaption confidence="0.995532">
Figure 1. Some published multisentence text samples.
</figureCaption>
<bodyText confidence="0.993763777777778">
ent way, also based on a conceptual dependency rep-
resentation [8].
These systems share several features. First, the
data structures that are the basis of the generation
were designed for text processing; many of the special
demands of text processing were anticipated and ac-
commodated in the design of the knowledge structures
themselves. Second, the sentence boundaries in these
systems were direct correlates of internal features of
</bodyText>
<page confidence="0.888824">
18 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
</page>
<note confidence="0.292036">
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
</note>
<bodyText confidence="0.98556825">
the data structures themselves. Often the sentence
order arose in the same way.4 Third, these systems
had fixed generation goals, implicit in the code. Thus,
the reader&apos;s needs were taken to be fixed and pre-
known by the system. Fourth, although goal-pursuit
could sometimes be described in the material being
generated, the systems themselves did not operate on a
goal-pursuit algorithm. Finally, none of these systems
chose the particular sentences to use in their output on
the bases of quality assessment or comparisons among
alternatives.
In all five of these points, the KDS research con-
trasts with these previous efforts. We have worked
with data structures not designed for text generation;
the sentence boundaries we develop are not direct
correlates of internal features of the data structures;
there are explicit goals for the generation process to
satisfy; the system itself pursues goals; and the final
text is chosen through quality comparisons among
alternative ways of saying things.
The Task for the Knowledge Delivery System
In the light of these considerations, the problem
can be restated more specifically as follows:
Given
</bodyText>
<listItem confidence="0.9769226">
1. An explicit goal of knowledge expression,
2. A computer-internal knowledge base ade-
quate for some non-text purpose, and
3. Identification of the parts of the knowledge
base that are relevant to the goal,
</listItem>
<bodyText confidence="0.9986825">
the task is to produce clean, multiparagraph text, in
English, which satisfies the goal.
</bodyText>
<subsectionHeader confidence="0.999237">
The Partitioning Paradigm
</subsectionHeader>
<bodyText confidence="0.999842">
When we have stated this task to AT workers famil-
iar with natural language processing, with no further
specification, they have expected a particular kind of
solution. They say, &amp;quot;Well, there are some sentence
generators around, but the given information struc-
tures are too large to be expressed in single sentences.
Therefore what we need is a method for dividing up the
input structure into sentence-size pieces. Then we can
give the pieces to a suitable sentence generator and
get the desired text.&amp;quot; This is the expected solution,
and people will simply presume that it is the line of
development being taken.
</bodyText>
<footnote confidence="0.84382475">
4 This is not to say that sentence boundaries are always one
for one with data structures, nor that the data structures always
contain all the information used in making a sentence. But the
forms of data structures in these systems have been shaped almost
exclusively by natural language processing tasks, which tends to
make sentence boundary determination easy. The content of those
structures has often been filled in manually, leaving indeterminable
the relative contributions of program and programmer.
</footnote>
<bodyText confidence="0.998136">
That approach, which we call the Partitioning para-
digm for text generation, was used in all the systems
described above. For the Partitioning paradigm to
work, the generation task must be simplified by fea-
tures of the knowledge base:
</bodyText>
<listItem confidence="0.985072727272727">
1. The knowledge base data structures have
features that indicate appropriate sen-
tence boundaries, and
2. The pieces of information appropriate to
be expressed in an individual sentence are
adjacent. That is, a process can access all
of the information appropriate to be ex-
pressed in a single sentence by following
the data structure, without being required
to traverse information to be expressed in
other sentences.
</listItem>
<bodyText confidence="0.996879714285714">
These conditions prevail (by design) in all of the
systems described above, but they are not generally
typical of information storage in computers. As we
will see, KDS takes an entirely different approach to
the problem.
Several inherent difficulties become apparent when
we attempt to use partitioning:
</bodyText>
<listItem confidence="0.997989375">
1. Missing adjacencies — Since (by our
problem definition) the knowledge comes
from a structure not prestructured for the
generation task, what is and what is not
adjacent in the knowledge base may be quite
arbitrary. We may wish to include several
widely scattered items in a sentence, so that
it is not possible to carve out a piece with
those items in it at all. The adjacencies that
we need in order to partition the structure
into sentence-size parts may simply be
absent.
2. Intractable residues — Even though we
may be able to find some way to start cutting
out sentence-size objects from the data
structure, there is no assurance at all that we
will be able to run that method to completion
and carve the entire structure into sentence-
size pieces. Think of the comparable prob-
lem of carving statues from a block of mar-
ble. We may be able to get one statue or
several, but if every part of the original block
must end up looking like a statue, ordinary
carving methods are insufficient. The resi-
dues left after carving out the first few stat-
ues may be intractable. A comparable sort
of thing can happen in attempting to parti-
tion data structures.
3. Lack of boundary correlates — In some
ways the worst difficulty is that an arbitrary
given data structure does not contain struc-
tural correlates of good sentence boundaries.
</listItem>
<bodyText confidence="0.915359875">
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 19
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
One cannot inspect the data structure and
tell in any way where the sentence bounda-
ries ought to be. Along with the other diffi-
culties, this has led us to reject the expected
solution, the Partitioning paradigm, and to
create another.
</bodyText>
<subsectionHeader confidence="0.692492">
The Fragment-and-Compose Paradigm
</subsectionHeader>
<bodyText confidence="0.955822">
Our solution comes in two steps:
</bodyText>
<listItem confidence="0.992021666666667">
1. Find methods for fragmenting the given
data structure into little pieces, small prop-
ositional parts.
2. Find methods for composing good sentences
and good paragraphs out of those little
parts.
</listItem>
<bodyText confidence="0.999918652173913">
We call this the Fragment-and-Compose paradigm.
It is interesting to note that other systems employ a
Fragment-and-Compose approach — e.g., building
construction, papermaking, and digestion. In each,
one begins by producing small, easily manipulated
objects much smaller than the desired end-product
structures, and then assembles these into the desired
end products in a planned, multistage way. For the
block of marble, the comparable processes are crush-
ing and casting.
We may not be very encouraged in our text genera-
tion task by such precedents. However, there are
precedents much closer to our actual task. The task of
natural language translation resembles in many ways
the task of translating from a computational knowl-
edge source (although it has a comprehension subtask
which we lack). Consider the (annotated) quotation
below from Toward a Science of Translating [9].
The process by which one determines
equivalence (faithfully translates) between
source and receptor languages is obviously a
highly complex one. However, it may be
reduced to two quite simple procedures:
</bodyText>
<listItem confidence="0.9812664">
(1) &amp;quot;decomposition&amp;quot; of the message into the
simplest semantic structure, with the most
explicit statement of relationships; and
(2) &amp;quot;recomposition&amp;quot; of the message into the
receptor language.
</listItem>
<bodyText confidence="0.997849913043478">
The quotation is from Nida&apos;s chapter on translation
procedures. Notice particularly the two steps:
decomposition and recomposition, and the emphasis on
simple, explicit semantic structures in the results of the
decomposition.
It turns out that this is the central procedural state-
ment of Nida&apos;s book, and the remainder of the book
can be seen as giving constraints and considerations on
how this decomposition and recomposition ought to
take place. We have very good reasons here for
expecting that Fragment-and-Compose is an
appropriate paradigm for natural language knowledge
delivery.
To give a sense of what can be done using
Fragment-and-Compose, here is a piece of a machine-
generated text (created by KDS) about what happens
when fire breaks out in the computer room.
Whenever there is a fire, the alarm system is
started, which sounds a bell and starts a timer.
Ninety seconds after the timer starts, unless the
alarm system is cancelled, the system calls Wells
Fargo. When Wells Fargo is called, they, in
turn, call the Fire Department.
</bodyText>
<subsectionHeader confidence="0.949628">
Description of KDS
</subsectionHeader>
<bodyText confidence="0.999974733333333">
Figure 2 is a block diagram of KDS, which simply
says that KDS takes in an Expressive Goal (telling
what the text should accomplish relative to its reader)
and also a pre-identified body of Relevant Knowledge
in the notation of its source. The output is multipara-
graph text that is expected to satisfy the goal.
We will be carrying a single example through this
description of KDS. It is the most complex example
handled by KDS, and it incorporates many ideas from
previous studies on description of computer message
systems.
A small contingency-plans data base contains
knowledge about what happens in various circum-
stances, and about people&apos;s actions, responsibilities,
authorities, and resources. The particular knowledge
to be delivered concerns a computer room in which
there may be some indication of fire and in which
there is a computer operator who should know what to
do if that happens. This operator is the nominal read-
er of the text.
The general Expressive Goal is that the computer
operator will know what to do in all of the predictable
contingencies that can arise starting with an indication
of fire. The contingencies are represented in the &amp;quot;Fire
Alarm Scene,&amp;quot; part of the knowledge base. A sche-
matic sketch of the Fire Alarm Scene is given in Fig-
ure 3. (The figure is expository and contains far less
information than the actual Scene. The Scene is a
&amp;quot;semantic net,&amp;quot; a collection of LISP expressions that
refer to the same objects.)
</bodyText>
<figure confidence="0.99891275">
Expressive 1 KDS Multiparagraph
goal text
Relevant
knowledge
</figure>
<figureCaption confidence="0.998975">
Figure 2. Input and output of KDS.
</figureCaption>
<figure confidence="0.986419346153846">
20 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
IN IT
timer elapses (evaluate situation)
(bell sounds or
fire detected;
timer starts)
(Wells Fargo called)
(Fire Dept. called)
RESPONSE
(Fire Dept. responds)
I
IPERMIT
(don&apos;t cancel) cancel alarm
t 4
I CALL2 I BACK-TO-WORK
(resume work)
FLIGHT
(evacuate)
call Fire Dept.)
GOHOME
(Fire Dept. fights fire)
(Fire Dept.
goes home)
ITERMINATE
(end of scene)
</figure>
<figureCaption confidence="0.999665">
Figure 3. Events in the Fire-Alarm scene.
</figureCaption>
<table confidence="0.801192666666667">
American Journal of Computational Linguistics, Volume 7, Numb nuary-March 1981 21
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
KDS MODULES
FRAGMENT ER
PROBLEM SOLVER
KNOWLEDGE FILTER
HILL CLIMBER
SURFACE SENTENCE MAKER
MODULE RESPONSIBILITIES
</table>
<listItem confidence="0.999846875">
• Extraction of knowledge from external notation
• Division into expressible clauses
• Style selection
• Gross organization of text
• Cognitive redundancy removal
• Composition of concepts
• Sentence quality seeking
• Final text creation
</listItem>
<figureCaption confidence="0.996833">
Figure 4. KDS module responsibilities.
</figureCaption>
<bodyText confidence="0.999825375">
The knowledge identified as relevant includes not
only the events of this scene but also enough informa-
tion to support another computational task. In this
example the knowledge is sufficient to support an
alternate task, which we call the Motivation Exhibit
task, i.e., to exhibit, for each action in the scene, the
actor&apos;s reasons for performing the action. So, for
example, the relevant knowledge includes the knowl-
edge that fires destroy property, that destroying prop-
erty is bad, that the amount of property destroyed
increases with the duration of the fire, and that the
Fire Department is able to employ methods for
stopping fires. This is sufficient to be able to explain
why the Fire Department attempts to stop fires. KDS
does not perform the Motivation Exhibit task, but its
knowledge is sufficient for it. We generate from a
knowledge base sufficient for multiple tasks in order
to explore the problems created when the knowledge
representation is not designed for text processing.
The content of the scene is as follows:
In the beginning state, INIT, the fire
alarm sounds a bell. As we follow down the
left side of the figure, we see that the fire
alarm starts an interval timer, and at the end
of the interval, the timer automatically
phones Wells Fargo Company, the alarm sys-
tem manager. Wells Fargo phones the Fire
Department, and the Fire Department comes.
The Fire Department fjghts the fire if there
is one, and otherwise goes home.
Meanwhile, the computer operator must
pay attention to the alarm and decide what
to do. He can block the alarm system&apos;s ac-
tion, cancelling the alarm, or he can let the
alarm system take its course. In the latter
case, his next duty is to call the Fire Depart-
ment himself, which has the same effect as
Wells Fargo calling it. After that, his next
duty is to flee. If he blocks the alarm then
he is to go back to his previous task.
</bodyText>
<subsectionHeader confidence="0.993635">
Major Modules of KDS
</subsectionHeader>
<bodyText confidence="0.960818851851852">
KDS consists of five major modules, as indicated in
Figure 4. A Fragmenter is responsible for extracting
the relevant knowledge from the notation given to it
and dividing that knowledge into small expressible
units, which we call fragments or protosentences. A
Problem Solver, a goal-pursuit engine in the Al tradi-
tion, is responsible for selecting the presentational
style of the text and also for imposing the gross organ-
ization onto the text according to that style. A
Knowledge Filter removes protosentences that need
not be expressed because they would be redundant to
the reader.
The largest and most interesting module is the Hill
Climber, which has three responsibilities: to compose
22 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
complex protosentences from simple ones, to judge
relative quality among the units resulting from com-
position, and to repeatedly improve the set of proto-
sentences on the basis of those judgments so that it is
of the highest overall quality. Finally, a very simple
Surface Sentence Maker creates the sentences of the
final text out of protosentences.
The data flow of these modules can be thought of
as a simple pipeline, each module processing the rele-
vant knowledge in turn. We will describe each of
these modules individually.
</bodyText>
<subsectionHeader confidence="0.984406">
Fragmenter Module
</subsectionHeader>
<bodyText confidence="0.997697125">
The Fragmenter (Figure 5) takes in the relevant
knowledge as it exists externally and produces a set of
independent protosentences, called the Sayset. These
primitive fragments, the protosentences, have no in-
tended order. (In our final tests, they are presented in
a list that is immediately randomized.) Each primitive
protosentence can, if necessary, be expressed by an
English sentence.
</bodyText>
<figure confidence="0.500809">
Knowledge 1FRAGMENTERJ ISAYSETI
</figure>
<figureCaption confidence="0.993852">
Figure 5. Fragmenter module input and output.
</figureCaption>
<bodyText confidence="0.999427352941177">
To help the reader understand the level of these
fragments, were they to be expressed in English, they
would look like:
&amp;quot;Fire destroys objects.&amp;quot;
&amp;quot;Fire causes death.&amp;quot;
&amp;quot;Death is bad.&amp;quot;
&amp;quot;Destroying objects is bad.&amp;quot; etc.
So the problem for the remainder of the system is
to express well what can surely be expressed badly. It
is important to note that this is an improvement prob-
lem rather than a problem of making expression in
English feasible.
The protosentences the Fragmenter produces are
propositional and typically carry much less information
than a sentence of smooth English text. In our exam-
ple, the fragmenter produces the list structures shown
in part below for two of its fragments.
</bodyText>
<equation confidence="0.41492425">
((CONSTIT (WHEN (CALLS NIL WELLS-FARGO)
(CALLS WELLS-FARGO FIRE-DEPT)))...)
((CONSTIT (WHENEVER (STARTS NIL ALARM-SYSTEM)
(PROB (SOUNDS ALARM-SYSTEM BELL)...)
</equation>
<bodyText confidence="0.9332625">
These fragments encode: &amp;quot;When {unspecified} calls
Wells Fargo, Wells Fargo calls the Fire Department.&amp;quot;
and &amp;quot;Whenever {unspecified} starts the alarm system,
the alarm system probably sounds the bell.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.891907">
Problem Solver Module
</subsectionHeader>
<bodyText confidence="0.9990349">
The second major module is the Problem Solver
(Figure 6). The primary responsibilities of the Prob-
lem Solver are to select a text presentation style and to
organize the text content according to the selected style.
For this purpose, it has a built-in taxonomy of styles
from which it selects. Although the taxonomy and
selection processes are very rudimentary in this partic-
ular system, they are significant as representatives of
the kinds of structures needed for style selection and
style imposition.
</bodyText>
<figure confidence="0.98682025">
Expressive
Goal
(SAYLIST with
ADVICE)
</figure>
<figureCaption confidence="0.999686">
Figure 6. Problem Solver input and output.
</figureCaption>
<bodyText confidence="0.9995028">
We believe that text style should be selected on the
basis of the expected effects. In simple cases this is so
obvious as to go unrecognized; in more complex cases,
which correspond to complex texts, there are many
stylistic choices. In order to select a style, one needs:
</bodyText>
<listItem confidence="0.985425666666667">
1. A description of the effect the text should
have on the reader,
2. Knowledge of how to apply stylistic
choices, and
3. A description of the effects to be expected
from each stylistic choice.
</listItem>
<bodyText confidence="0.9994344375">
Note that these are required whether stylistic
choices are distributed or holistic, i.e., whether they
are made in terms of attributes of the final text or in
terms of particular methods for creating or organizing
the text.
The first requirement above, a description of de-
sired effects, is (more or less by definition) a goal.
The second item is the set of applicable methods, and
the third is the knowledge of their effects. The Prob-
lem Solver is a goal-pursuit process that performs
means-ends analysis in a manner long familiar in Al.
The information organization is significant partly be-
cause of the demand it puts on the knowledge of style:
Knowledge of style must be organized according to ex-
pected effect. Otherwise, the program has no adequate
basis for selecting style.
</bodyText>
<figure confidence="0.9602652">
Relevant
ISAYSETI
PROBLEM
SOLVER
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 23
</figure>
<figureCaption confidence="0.559065">
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
</figureCaption>
<bodyText confidence="0.9995437">
The Problem Solver takes in the Sayset produced
by the Fragmenter and the Expressive Goal given to
the system and produces a Saylist, which is an ordered
list of the protosentences, some of which have been
marked with Advice. The Problem Solver pursues
given goals. It has several submodules that specialize
in particular kinds of goals, including modules Tell and
Instructional-narrate, which are active on this example.
The Problem Solver can operate on the current Saylist
with three kinds of actions in any of its modules:
</bodyText>
<listItem confidence="0.846157444444445">
1. It can Factor the Saylist into two sublists
separated by a paragraph break. It ex-
tracts all protosentences with a particular
character or attribute and places them
above the paragraph break, which is
above all those that lack that attribute.
Order within each sublist is retained.
2. It can impose an order on some or all of
the elements of the Saylist.
3. It can mark protosentences with Advice.
Sometimes the Problem Solver knows
some attribute of the final text that ought
to be achieved, perhaps because of a de-
mand of the chosen style, but it has no
way to effect this directly. In this case it
marks all the affected protosentences with
Advice, which will be acted on after the
Problem Solver has finished.
</listItem>
<figureCaption confidence="0.513756">
Figure 7 describes the rules used in the Problem
</figureCaption>
<bodyText confidence="0.93422332">
Solver that carry out these three kinds of actions. In
this example, the Tell module acts before
Instructional-narrate. The Factoring rules are applied
sequentially, so that the last one prevails over previous
ones.
The first Tell rule corresponds to the heuristic that
the existence of something ought to be mentioned
before its involvement with other things is described.
The third rule corresponds to the heuristic that the
writer (KDS) ought to reveal its own goals of writing
before pursuing those goals.
Instructional-narrate uses a presentational tech-
nique that makes the reader a participant in the text.
So, for example, the final text says, &amp;quot;When you hear
the alarm bell ...,&amp;quot; rather than &amp;quot;When the operator
hears the alarm bell...,&amp;quot; Instructional-narrate knows
that the role of &amp;quot;you&amp;quot; should be emphasized in the
final text, but it has no direct way to achieve this. To
every protosentence that refers to &amp;quot;you,&amp;quot; it attaches
advice saying that explicit reference to the reader,
which is done by mentioning &amp;quot;you&amp;quot; in the final text,
has positive value. This advice is taken inside the
Hill-climber.
In our example the Problem Solver creates the
following fragment:
</bodyText>
<table confidence="0.9443105">
(PARAGRAPH-BREAK (REASON: (BOUNDARY NON-H-ACTOR)))
((CONSTIT (WHEN (IF (POSSIBLE)
(CALL YOU FIRE-DEPT))
(EVOKE YOU EVAC-SCENE)))...
(ADVISORS FRAG INST-NARRATE)
(ADVICE ...(00OD YOU)))
</table>
<bodyText confidence="0.993521166666667">
These represent: &amp;quot;(Put a paragraph break here be-
cause the actions of agents other than the hearer end
here)&amp;quot; and &amp;quot;If possible, call the Fire Department;
then, in either case, evacuate. (Advised by FRAG and
INST-NARRATE Modules) (Advised that YOU is
GOOD)&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.784222">
Knowledge Filter Module
</subsectionHeader>
<bodyText confidence="0.909903076923077">
The Knowledge Filter is a necessary part of KDS
because as soon as we attempt to create text from a
knowledge base suitable to support some other compu-
tational purpose, we find a great deal of information
there that ought not to be expressed, because the
reader already knows it.
This is a general phenomenon that will be encoun-
tered whenever we generate from an ordinary compu-
tational knowledge base. As an illustration, consider
Badler&apos;s work on getting a program to describe a
movie in English.
Factoring Rules:
TELL
</bodyText>
<listItem confidence="0.994924">
1. Place all (EXISTS ...) propositions in an upper
section.
2. Place all propositions involving anyone&apos;s goals
in an upper section.
3. Place all propositions involving the author&apos;s
goals in an upper section.
INSTRUCTIONAL-NARRATE
1. Place all propositions with non-reader actor in
an upper section.
2. Place all time dependent propositions in a low-
er section.
</listItem>
<figure confidence="0.901623333333333">
Ordering Rules:
INSTRUCTIONAL-NARRATE
1. Order time-dependent propositions according
to the (NEXT ...) propositions.
Advice-giving Rules:
INSTRUCTIONAL-NARRATE
</figure>
<footnote confidence="0.6450925">
1. YOU is a good thing to make explicit in the
text.
</footnote>
<figureCaption confidence="0.993893">
Figure 7. Rules used in the Problem Solver.
</figureCaption>
<page confidence="0.804873">
24 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
</page>
<note confidence="0.523732">
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
</note>
<figureCaption confidence="0.999726">
Figure 8. Badler&apos;s &amp;quot;Moving Car Scenario&amp;quot;.
</figureCaption>
<figure confidence="0.999027333333333">
5
15
-f=
II
12
Czt..37
13
14
[La)
</figure>
<figureCaption confidence="0.866239">
Figure 8 is reproduced from [1]. It shows fifteen
</figureCaption>
<bodyText confidence="0.989918692307692">
successive scenes from a short computer-generated
movie. The graphics system that generates the movie
provides a stock of propositional knowledge about it.
The objects in the scene are known to the machine
unambiguously and in sufficient detail to generate the
movie. The research task is to create a computer pro-
gram that will describe in English the physical activi-
ties in this and similar movies. The detail is volumi-
nous, and so Badler is faced with a serious information
suppression problem. After several stages of applying
various filtering heuristics, such as &amp;quot;Don&apos;t describe
directly anything that doesn&apos;t move,&amp;quot; he can represent
the movie by the five statements below.
</bodyText>
<listItem confidence="0.8734135">
1. There is a car.
2. The car starts moving toward the observer
and eastward, then onto the road.
3. The car, while going forward, starts turn-
ing, moves toward the observer and-east-
ward, then northward-and-eastward, then
from the driveway and out-of the drive-
way, then off-of the driveway.
4. The car, while going forward, moves
northward-and-eastward, then northward,
</listItem>
<bodyText confidence="0.976476059701493">
then around the house and away-from the
driveway, then away-from the house and
stops turning.
5. The car, while going forward, moves
northward, then away.
These are still too cumbersome, so additional stages
of reduction are applied, yielding the single statement:
The car approaches, then moves onto the
road, then leaves the driveway, then turns
around the house, then drives away from the
house, then stops turning, then drives away.
Even the longer text above contains only a fraction
of the available information about the car and the
other objects. Information on their types, their sub-
parts, visibility, mobility, location, orientation and size
are available from Badler&apos;s source. He also develops a
sequence of events to describe the movie, based on
certain indicators of continuity and discontinuity. The
volume of information available, the predictability of its
parts, and the insignificance of some of its details are
such that all of it could not have been expressed in a
smooth text.
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 25
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
One of the principal activities of Badler&apos;s system is
selection of information to be removed from the set of
ideas to be expressed. Some things need not be ex-
pressed because they follow from the reader&apos;s general
knowledge about motion of objects; others are re-
moved because they represent noise, rather than sig-
nificant events, generated by the processes that dis-
cern motion.
The point for us is simply that the demands of
smooth text production are incompatible with expression
of all of the available information. Text production
requires condensation and selectivity, the process we
call knowledge filtering, on any reasonably complete
body of knowledge. Knowledge filtering is a signifi-
cant intellectual task. It requires coordinated use of a
diversity of knowledge about the reader, the knowl-
edge to be delivered, and the world in which all reside.
We now recognize the necessity of sophisticated
knowledge filtering as part of the process of producing
quality text.
KDS&apos;s Knowledge Filter (Figure 9) inputs the Say-
list, including Advice, from the Problem Solver, and
outputs the Saylist with additional Advice, called
&amp;quot;Don&apos;t Express&amp;quot; advice, on some of the protosenten-
ces. So some of the items have been marked for omis-
sion from the final text. (They are marked rather than
deleted so that they are available for use if needed as
transitional material or to otherwise make the resulting
text coherent.) The knowledge filter decides which
protosentences to mark by consulting its internal mod-
el of the reader to see whether the propositional con-
tent is known or obvious. The model of the reader, in
this implementation, is very simple: a collection of
propositions believed to be known by him. Although
KDS&apos;s reader model does not contain any inference
capabilities about what is obvious, a more robust mod-
el certainly would. We recognize that the work of the
Knowledge Filter is a serious intellectual task, and we
expect that such a filter will be an identifiable part of
future text creation programs.
In our example the Knowledge Filter produces the
DON&apos;T-EXPRESS advice in the following element of
the Saylist:
</bodyText>
<table confidence="0.621788666666667">
((CONSTIT (WHENEVER (SOUNDS NIL ALARM-BELL)
(HEARS YOU ALARM-BELL)
(PROB)))...
(ADVISORS INST-NARRATE NONEXP)
(ADVICE (GOOD YOU)
DON&apos;T-EXPRESS))
</table>
<bodyText confidence="0.8228476">
In this case, the involvement of the reader in
(HEARS YOU ALARM-BELL) arises from the
Advice-giving rule for Instructional-Narrate. It indi-
cates that it is good to express this. The DON&apos;T-
EXPRESS arises from the Knowledge Filter, indicating
</bodyText>
<figure confidence="0.97935675">
(SAYLIST
(SAYLIST KNOWLEDGE with added
with
FILTER DON&apos;T-EXPRESS
ADVICE)
advice)
Reader
Model
</figure>
<figureCaption confidence="0.999863">
Figure 9. Knowledge Filter module input and output.
</figureCaption>
<bodyText confidence="0.783707">
that it is unnecessary to express this. DON&apos;T-
EXPRESS prevails.
</bodyText>
<subsectionHeader confidence="0.910649">
Hill Climber Module
</subsectionHeader>
<bodyText confidence="0.881453">
The Hill Climber module (Figure 10) consists of
three parts:
</bodyText>
<listItem confidence="0.949440105263158">
1. A somewhat unconventional hill-climbing
algorithm that repeatedly selects which
one of an available set of changes to
make on the Saylist.
2. A set of Aggregation rules (with an inter-
preter) telling how the protosentences
may legally be combined. These corre-
spond roughly to the clause-combining
rules of English, and the collection repre-
sents something similar to the writer&apos;s
competence at clause coordination. Each
Aggregation rule consumes one or more
protosentences and produces one proto-
sentence. Advice propagates onto the
protosentences produced.
3. A set of Preference rules (with an inter-
preter) able to assign a numerical quality
score to any protosentence. The score
computation is sensitive to Advice.
</listItem>
<bodyText confidence="0.997162266666667">
The algorithm is equivalent to the following:
Scores are assigned to all of the primitive protosen-
tences; then the Aggregation rules are applied to the
Saylist in all possible ways to generate potential next
steps up the hill. The resultant protosentences are
also evaluated, and the Hill Climber algorithm then
compares the scores of units consumed and produced
and calculates a net gain or loss for each potential
application of an Aggregation rule. The best one is
executed, which means that the consumed units are
removed from the Saylist, and the new unit is added
(in one of the positions vacated, which one being
specified in the Aggregation rule).
This process is applied repeatedly until improve-
ment ceases. The output of the Hill Climber is a Say-
</bodyText>
<page confidence="0.846112">
26 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
</page>
<figure confidence="0.980565833333333">
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
1 HILL CLIMBING 1...
(SAY LIST)
Primitive
protosentences
Primitive and composite
protosentences
(SAYLIST)
ALGORITHM
Aggregation Rule Applier
AGGREGATION RULES
(The allowable clause-
combining methods of English)
Preference Rule Applier
PREFERENCE RULES
(A numerical score for
each protosentence)
(ADVICE taken here)
</figure>
<figureCaption confidence="0.999533">
Figure 10. Hill Climber module.
</figureCaption>
<bodyText confidence="0.9990073">
list for which there are no remaining beneficial poten-
tial applications of Aggregation rules.
The selection algorithm of the Hill Climber is
somewhat unconventional in that it does not select the
Aggregation rule application with the largest increase
in collective score, which would be the usual practice.
The hill of collective scores has many local maxima,
which can be traced to the fact that one application of
an aggregation rule will preclude several others. Be-
cause protosentences are consumed, the various appli-
cations are in competition, and so a rule that produces
a large gain may preclude even more gain.
The Hill Climber selects the rule application to use
based on an equation that includes competitive terms.
It computes the amount of gain surely precluded by
each application and makes its selection on the basis
of maximum net gain, with the precluded gain sub-
tracted.
The use of hill climbing avoids the combinatorial
explosion involved in searching for the best of all pos-
sible ways to express the content. In general only a
tiny fraction of the possibilities are actually examined.
This Saylist improvement activity is the technical
heart of the text production process; it develops the
final sentence boundaries and establishes the smooth-
ness of the text.
Figure 11 shows a few of the Aggregation rules.
(Each of them has been rewritten into an informal
notation suggesting its content.) Aggregation rules are
intended to be meaning-preserving in the reader&apos;s
</bodyText>
<reference confidence="0.890211555555556">
1. COMMON CAUSE.
Whenever C then X.
Whenever C then X and Y.
Whenever C then Y.
2. CONJOIN MID-STATE
Whenever X then Y.
Whenever X then Y
Whenever Y then Z. and then Z.
3. DELETE MID-STATE
Whenever X then Y.
Whenever X then Z.
Whenever Y then Z.
4. DELETE EXISTENTIAL
There is a Y.
&lt;mention of Y&gt; &lt;mention of Y&gt;
(Y is known unique)
5. IF-THEN-ELSE
If P then Q.
</reference>
<figure confidence="0.95618">
If P then Q otherwise R.
If not P then R.
6. TEST AND BRANCH
When P then determine if X.
If X then Q. When P then determine X
If not X then R. and decide Q or R.
</figure>
<figureCaption confidence="0.999407">
Figure 11. Sample Aggregation rules.
</figureCaption>
<bodyText confidence="0.927151357142857">
comprehension, but are not intended to preserve
explicitness.
These are only a few of the Aggregation rules that
have been used in KDS; others have been developed in
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 27
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
the course of working on this and other examples.
Coverage of English is still very sparse. In other
examples, an aggregation rule has been used to pro-
duce a multiple-sentence structure with intersentential
dependencies.
Figure 12 shows the Preference rules. They were
derived empirically, to correspond to those used by the
author of some comparable human-produced text.
</bodyText>
<reference confidence="0.903787533333333">
1. Every protosentence gets an initial value of
-1000.
2. Every primitive protosentence embedded in a
composite protosentence decreases value by
10.
3. If there is advice that a term is good, each oc-
currence of that term increases value by 100.
4. Each time-sequentially linked protosentence
after the first increases value by 100.
5. Certain constructions get bonuses of 200: the
if-then-else construct and the when-X-
determine-Y.
6. Any protosentence produced by multiple appli-
cations of the same aggregation rule gets a
large negative value.
</reference>
<figureCaption confidence="0.981922">
Figure 12. Preference rules.
</figureCaption>
<bodyText confidence="0.972856235294118">
One of the surprising discoveries of this work, seen
in all of the cases investigated, is that the task of text
generation is dominated by the need for brevity: How
to avoid saying things is at least as important as how
to say things. Preference Rule 1 introduces a tenden-
cy toward brevity, because most of the Aggregation
rules consume two or three protosentences but pro-
duce only one, yielding a large gain in score. Sen-
tences produced from aggregated protosentences are
generally briefer than the corresponding sentences for
the protosentences consumed. For example, applying
Rule 1 to the pair:
&amp;quot;When you permit5 the alarm system, call the
Fire Department if possible. When you per-
mit the alarm system then evacuate.&amp;quot;
yields,
&amp;quot;When you permit the alarm system, call the
Fire Department if possible, then evacuate.&amp;quot;
Rule 3 introduces the sensitivity to advice. We
expect that this sort of advice taking does not need to
5 This way of using &apos;&apos;permit&apos;&apos; is unfamiliar to many people,
but it is exactly the usage that we found in a manual of instruction
for computer operators on what they should do in case of fire. In
the course of attempting to produce comparable text we accepted
the usage.
be elaborate — that being able to advise that a term is
good or a term is bad is adequate.
Rule 6 is somewhat of a puzzle. Empirically, a
sentence produced by reapplication of an Aggregation
rule was always definitely unacceptable, primarily be-
cause it was awkward or confusing. We do not under-
stand technically why this should be the case, and
some say it should not be. We do know that this rule
contributes significantly to overall quality.
</bodyText>
<subsectionHeader confidence="0.828897">
Sentence Generator Module
</subsectionHeader>
<bodyText confidence="0.9995922">
The Sentence Generator (Figure 13) takes the final
ordered set of protosentences produced by the Hill
Climber and produces the final text, one sentence at a
time. Each sentence is produced independently, using
a simple context-free grammar and semantic testing
rules. Because sentence generation has not been the
focus of our work, this module does not represent
much innovation, but merely establishes that the text
formation work has been completed and does not
depend on further complex processing.
</bodyText>
<figure confidence="0.636399">
(Protosentence
list)
</figure>
<figureCaption confidence="0.996871">
Figure 13. Sentence Generator module input and output.
</figureCaption>
<bodyText confidence="0.9995232">
The single significant innovation in the Sentence
Generator is the Referring Phrase Generator, the only
part in which prior sentences affect the current sen-
tence. The Referring Phrase Generator keeps track of
what objects have been referred to, and how. It pre-
sumes that objects previously referred to are in the
reader&apos;s attention and that after they have been identi-
fied by the first reference, subsequent references need
only distinguish the object from others in attention.
This process is equivalent to the one described by [6]
developed for this research. It knows how to intro-
duce terms, refer to objects by incomplete descrip-
tions, and introduce pronouns. However, none of our
examples has exercised all of the features of Levin and
Goldman&apos;s algorithm.
</bodyText>
<subsectionHeader confidence="0.900718">
Output Text
</subsectionHeader>
<bodyText confidence="0.999546">
Applying all of this machinery in our example, we
get the result shown in Figure 14. Note the paragraph
break, a product of a factoring rule (the first rule in
Instructional-narrate) in the Problem Solver module.
</bodyText>
<figure confidence="0.9812986">
SENTENCE Final text
GENERATOR
Referring-
Phrase
Generator
</figure>
<page confidence="0.866406">
28 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
</page>
<note confidence="0.294488">
William C. Mann and James A. Moore Computer Generation of Multiparagraph English Text
</note>
<bodyText confidence="0.999795333333333">
Whenever there is a fire, the alarm system is
started, which sounds a bell and starts a timer.
Ninety seconds after the timer starts, unless the
alarm system is cancelled, the system calls Wells
Fargo. When Wells Fargo is called, they, in
turn, call the Fire Department.
When you hear the alarm bell or smell smoke,
stop whatever you are doing, determine whether or
not there is a fire, and decide whether to permit
the alarm system or to cancel it. When you
determine whether there is a fire, if there is,
permit the alarm system, otherwise cancel it.
When you permit the alarm system, call the Fire
Department if possible, then evacuate. When you
cancel the alarm system, if it is more than 90
seconds since the timer started, the system will
have called Wells Fargo already, otherwise
continue what you were doing.
</bodyText>
<figureCaption confidence="0.960634">
Figure 14. Final fire-alarm text from KDS.
</figureCaption>
<sectionHeader confidence="0.583482" genericHeader="conclusions">
Conclusions and Prospects
</sectionHeader>
<bodyText confidence="0.999981186046512">
The development of KDS highlights several aspects
of the task of writing that strongly influence text qual-
ity. The overwhelming importance of brevity, seen in
both the Knowledge Filter and the Preference rules, is
striking. Writing is seen here as a constructive activity
rather than simply as interpretive. That is, it is not so
much a mapping between knowledge representations
as it is the creation of new symbolic objects, not
equivalent to older ones, but suitable for achieving
particular effects. The image of writing as a kind of
goal pursuit activity helps us to factor the task into
parts. The task (and the program) is occupied with
finding a good way to say things, not with establishing
feasibility of saying them.
The KDS development has also identified important
features of the problem of designing a knowledge-
delivery program. The defects of the Partitioning par-
adigm are newly appreciated; the Fragment-and-
Compose paradigm is much more manageable. It is
easy to understand, and the creation of Aggregation
rules is not difficult. The separation of Aggregation
and Preference actions seems essential to the task, or
at least to making the task manageable. As a kind of
competence/performance separation it is also of theo-
retical interest. Knowledge filtering, as one kind of
responsiveness of the writer to the reader, is essential
to producing good text.
The importance of fragmenting is clear, and the
kinds of demands placed on the Fragmenter have been
clarified, but effective methods of fragmenting arbi-
trary knowledge sources are still not well understood.
In the future, we expect to see the Fragment-and-
Compose paradigm reapplied extensively. We expect
to see goal-pursuing processes applied to text organi-
zation and style selection. We expect distinct process-
es for aggregating fragments and selecting combina-
tions on a preference basis. We also expect a well
developed model of the reader, including inference
capabilities and methods for keeping the model up to
date as the text progresses. Finally, we expect a great
deal of elaboration of the kinds of aggregation per-
formed and of the kinds of considerations to which
preference selection responds.
</bodyText>
<sectionHeader confidence="0.996812" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9954365">
[1] Badler, N.J., &amp;quot;The Conceptual Description of Physical Activi-
ties,&amp;quot; In Proceedings of the 13th Annual Meeting of the Associa-
tion for Computational Linguistics, AJCL Microfiche, 35, 1975.
[2] Carbonell J.R., and A.M. Collins, &amp;quot;Natural Semantics in Artifi-
cial Intelligence,&amp;quot; In Proceedings of the Third International Joint
Conference on Artificial Intelligence, 1973, 344-351.
[3] Davey, Anthony, Discourse Production, Edinburgh University
Press, Edinburgh, 1979.
[4] Swartout, William R., &amp;quot;Producing Explanations and Justifica-
tions of Expert Consulting Programs,&amp;quot; Technical Report TR-251,
MIT Laboratory for Computer Science, January 1981.
[5] Heidorn, George E., &amp;quot;Natural Language Inputs to a Simulation
Programming System,&amp;quot; Technical Report NPS-55HD72101A,
Naval Postgraduate School, 1972.
[6] Levin, J.A., and N.M. Goldman, &amp;quot;Process Models of Reference
in Context,&amp;quot; Research Report 78-72, USC/Information Sciences
Institute, 1978.
[7] McDonald, D.D., &amp;quot;Natural Language Production as a Process of
Decision-Making Under Constraints,&amp;quot; PhD Thesis, MIT, Dept.
of Electrical Engineering and Computer Science, 1980.
[8] Meehan, James R., &amp;quot;TALE-SPIN, An Interactive Program that
Writes Stories.&amp;quot; In Proceedings of the Fifth International Joint
Conference on Artificial Intelligence, 1977.
[9] Nida, Eugene, Toward a Science of Translating, E.J. Brill, Leid-
en, 1964.
[10] Schank, Roger C., and the Yale A.I. Project, &amp;quot;SAM — A Story
Understander,&amp;quot; Research Report 43, Yale University, Dept. of
Computer Science, 1975.
[11] Simmons, R., and J. Slocum, &amp;quot;Generating English Discourse
from Semantic Networks,&amp;quot; Comm. ACM 15, 10 (October
1972), 891-905.
William C. Mann is a member of the research staff
of Information Sciences Institute at the University of
Southern California. He received the Ph.D. degree in
computer science from Carnegie-Mellon University in
1973.
James A. Moore is a member of the research staff of
Information Sciences Institute at the University of
Southern California. He received the Ph.D. degree in
computer science from Carnegie-Mellon University in
1974.
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 29
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921987">
<title confidence="0.99792">Computer Generation of Multiparagraph English Text&apos;</title>
<author confidence="0.9943075">William C James A Moore</author>
<affiliation confidence="0.9987795">Information Sciences University of Southern</affiliation>
<address confidence="0.993145">Marina del Rey, California 90291</address>
<abstract confidence="0.994752909090909">This paper reports recent research into methods for creating natural language text. A new processing paradigm called Fragment-and-Compose has been created and an experimental system implemented in it. The knowledge to be expressed in text is first divided into small propositional units, which are then composed into appropriate combinations and converted into text. KDS (Knowledge Delivery System), which embodies this paradigm, has distinct parts devoted to creation of the propositional units, to organization of the text, to prevention of excess redundancy, to creation of combinations of units, to evaluation of these combinations as potential sentences, to selection of the best among competing combinations, and to creation of the final text. The Fragment-and-Compose paradigm and the computational methods of KDS are described.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>COMMON CAUSE</author>
</authors>
<marker>CAUSE, </marker>
<rawString>1. COMMON CAUSE.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Whenever C then X Whenever C then X</author>
<author>Y Whenever C then Y</author>
</authors>
<marker>X, Y, </marker>
<rawString>Whenever C then X. Whenever C then X and Y. Whenever C then Y.</rawString>
</citation>
<citation valid="false">
<authors>
<author>CONJOIN MID-STATE Whenever X then Y</author>
</authors>
<journal>Whenever X then Y Whenever Y</journal>
<marker>Y, </marker>
<rawString>2. CONJOIN MID-STATE Whenever X then Y. Whenever X then Y Whenever Y then Z. and then Z.</rawString>
</citation>
<citation valid="false">
<authors>
<author>DELETE MID-STATE Whenever X then Y Whenever X then Z Whenever Y then Z</author>
</authors>
<title>DELETE EXISTENTIAL There is a Y.</title>
<journal>of Y&gt; of Y&gt; (Y is known unique) 5. IF-THEN-ELSE If P then Q.</journal>
<marker>Z, </marker>
<rawString>3. DELETE MID-STATE Whenever X then Y. Whenever X then Z. Whenever Y then Z. 4. DELETE EXISTENTIAL There is a Y. &lt;mention of Y&gt; &lt;mention of Y&gt; (Y is known unique) 5. IF-THEN-ELSE If P then Q.</rawString>
</citation>
<citation valid="false">
<title>Every protosentence gets an initial value of -1000.</title>
<marker></marker>
<rawString>1. Every protosentence gets an initial value of -1000.</rawString>
</citation>
<citation valid="false">
<title>Every primitive protosentence embedded in a composite protosentence decreases value by 10.</title>
<marker></marker>
<rawString>2. Every primitive protosentence embedded in a composite protosentence decreases value by 10.</rawString>
</citation>
<citation valid="false">
<title>If there is advice that a term is good, each occurrence of that term increases value by 100.</title>
<marker></marker>
<rawString>3. If there is advice that a term is good, each occurrence of that term increases value by 100.</rawString>
</citation>
<citation valid="false">
<title>Each time-sequentially linked protosentence after the first increases value by 100.</title>
<marker></marker>
<rawString>4. Each time-sequentially linked protosentence after the first increases value by 100.</rawString>
</citation>
<citation valid="false">
<title>Certain constructions get bonuses of 200: the if-then-else construct and the when-Xdetermine-Y.</title>
<marker></marker>
<rawString>5. Certain constructions get bonuses of 200: the if-then-else construct and the when-Xdetermine-Y.</rawString>
</citation>
<citation valid="false">
<title>Any protosentence produced by multiple applications of the same aggregation rule gets a large negative value.</title>
<marker></marker>
<rawString>6. Any protosentence produced by multiple applications of the same aggregation rule gets a large negative value.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N J Badler</author>
</authors>
<title>The Conceptual Description of Physical Activities,&amp;quot;</title>
<date>1975</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Association for Computational Linguistics, AJCL Microfiche,</booktitle>
<volume>35</volume>
<marker>Badler, 1975</marker>
<rawString>[1] Badler, N.J., &amp;quot;The Conceptual Description of Physical Activities,&amp;quot; In Proceedings of the 13th Annual Meeting of the Association for Computational Linguistics, AJCL Microfiche, 35, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Carbonell</author>
<author>A M Collins</author>
</authors>
<title>Natural Semantics in Artificial Intelligence,&amp;quot;</title>
<date>1973</date>
<booktitle>In Proceedings of the Third International Joint Conference on Artificial Intelligence,</booktitle>
<pages>344--351</pages>
<marker>Carbonell, Collins, 1973</marker>
<rawString>[2] Carbonell J.R., and A.M. Collins, &amp;quot;Natural Semantics in Artificial Intelligence,&amp;quot; In Proceedings of the Third International Joint Conference on Artificial Intelligence, 1973, 344-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Davey</author>
</authors>
<title>Discourse Production,</title>
<date>1979</date>
<publisher>University Press,</publisher>
<location>Edinburgh</location>
<marker>Davey, 1979</marker>
<rawString>[3] Davey, Anthony, Discourse Production, Edinburgh University Press, Edinburgh, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William R Swartout</author>
</authors>
<title>Producing Explanations and Justifications of Expert Consulting Programs,&amp;quot;</title>
<date>1981</date>
<tech>Technical Report TR-251,</tech>
<institution>MIT Laboratory for Computer Science,</institution>
<marker>Swartout, 1981</marker>
<rawString>[4] Swartout, William R., &amp;quot;Producing Explanations and Justifications of Expert Consulting Programs,&amp;quot; Technical Report TR-251, MIT Laboratory for Computer Science, January 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Natural Language Inputs to a Simulation Programming System,&amp;quot;</title>
<date>1972</date>
<tech>Technical Report NPS-55HD72101A,</tech>
<institution>Naval Postgraduate School,</institution>
<marker>Heidorn, 1972</marker>
<rawString>[5] Heidorn, George E., &amp;quot;Natural Language Inputs to a Simulation Programming System,&amp;quot; Technical Report NPS-55HD72101A, Naval Postgraduate School, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Levin</author>
<author>N M Goldman</author>
</authors>
<title>Process Models of Reference in Context,&amp;quot; Research Report 78-72, USC/Information Sciences Institute,</title>
<date>1978</date>
<marker>Levin, Goldman, 1978</marker>
<rawString>[6] Levin, J.A., and N.M. Goldman, &amp;quot;Process Models of Reference in Context,&amp;quot; Research Report 78-72, USC/Information Sciences Institute, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D McDonald</author>
</authors>
<title>Natural Language Production as a Process of Decision-Making Under Constraints,&amp;quot;</title>
<date>1980</date>
<tech>PhD Thesis,</tech>
<institution>MIT, Dept. of Electrical Engineering and Computer Science,</institution>
<marker>McDonald, 1980</marker>
<rawString>[7] McDonald, D.D., &amp;quot;Natural Language Production as a Process of Decision-Making Under Constraints,&amp;quot; PhD Thesis, MIT, Dept. of Electrical Engineering and Computer Science, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Meehan</author>
</authors>
<title>TALE-SPIN, An Interactive Program that Writes Stories.&amp;quot;</title>
<date>1977</date>
<booktitle>In Proceedings of the Fifth International Joint Conference on Artificial Intelligence,</booktitle>
<marker>Meehan, 1977</marker>
<rawString>[8] Meehan, James R., &amp;quot;TALE-SPIN, An Interactive Program that Writes Stories.&amp;quot; In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Nida</author>
</authors>
<title>Toward a Science of Translating,</title>
<date>1964</date>
<publisher>E.J. Brill,</publisher>
<location>Leiden,</location>
<marker>Nida, 1964</marker>
<rawString>[9] Nida, Eugene, Toward a Science of Translating, E.J. Brill, Leiden, 1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
<author>the Yale A I Project</author>
</authors>
<title>SAM — A Story Understander,&amp;quot;</title>
<date>1975</date>
<journal>Research Report</journal>
<volume>43</volume>
<institution>Yale University, Dept. of Computer Science,</institution>
<marker>Schank, Project, 1975</marker>
<rawString>[10] Schank, Roger C., and the Yale A.I. Project, &amp;quot;SAM — A Story Understander,&amp;quot; Research Report 43, Yale University, Dept. of Computer Science, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Simmons</author>
<author>J Slocum</author>
</authors>
<title>Generating English Discourse from Semantic Networks,&amp;quot;</title>
<date>1972</date>
<journal>Comm. ACM</journal>
<volume>15</volume>
<pages>10</pages>
<marker>Simmons, Slocum, 1972</marker>
<rawString>[11] Simmons, R., and J. Slocum, &amp;quot;Generating English Discourse from Semantic Networks,&amp;quot; Comm. ACM 15, 10 (October 1972), 891-905.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C William</author>
</authors>
<title>Mann is a member of the research staff of Information Sciences Institute at the University of Southern California. He received the Ph.D. degree in computer science from Carnegie-Mellon University in</title>
<date>1973</date>
<marker>William, 1973</marker>
<rawString>William C. Mann is a member of the research staff of Information Sciences Institute at the University of Southern California. He received the Ph.D. degree in computer science from Carnegie-Mellon University in 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A James</author>
</authors>
<title>Moore is a member of the research staff of Information Sciences Institute at the University of Southern California. He received the Ph.D. degree in computer science from Carnegie-Mellon University in</title>
<date>1974</date>
<marker>James, 1974</marker>
<rawString>James A. Moore is a member of the research staff of Information Sciences Institute at the University of Southern California. He received the Ph.D. degree in computer science from Carnegie-Mellon University in 1974.</rawString>
</citation>
<citation valid="true">
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>7</volume>
<pages>29</pages>
<marker>1981</marker>
<rawString>American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 29</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>