<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008875">
<title confidence="0.9997245">
A Machine Learning Approach to Extract Temporal Information from
Texts in Swedish and Generate Animated 3D Scenes
</title>
<author confidence="0.999458">
Anders Berglund Richard Johansson Pierre Nugues
</author>
<affiliation confidence="0.97766">
Department of Computer Science, LTH
Lund University
</affiliation>
<address confidence="0.974083">
SE-221 00 Lund, Sweden
</address>
<email confidence="0.994689">
d98ab@efd.lth.se, {richard, pierre}@cs.lth.se
</email>
<sectionHeader confidence="0.995586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999926263157895">
Carsim is a program that automatically
converts narratives into 3D scenes. Carsim
considers authentic texts describing road
accidents, generally collected from web
sites of Swedish newspapers or transcribed
from hand-written accounts by victims of
accidents. One of the program’s key fea-
tures is that it animates the generated scene
to visualize events.
To create a consistent animation, Carsim
extracts the participants mentioned in a
text and identifies what they do. In this
paper, we focus on the extraction of tem-
poral relations between actions. We first
describe how we detect time expressions
and events. We then present a machine
learning technique to order the sequence
of events identified in the narratives. We
finally report the results we obtained.
</bodyText>
<sectionHeader confidence="0.878124" genericHeader="keywords">
1 Extraction of Temporal Information
and Scene Visualization
</sectionHeader>
<bodyText confidence="0.999564214285714">
Carsim is a program that generates 3D scenes from
narratives describing road accidents (Johansson et
al., 2005; Dupuy et al., 2001). It considers au-
thentic texts, generally collected from web sites
of Swedish newspapers or transcribed from hand-
written accounts by victims of accidents.
One of Carsim’s key features is that it animates
the generated scene to visualize events described
in the narrative. The text below, a newspaper arti-
cle with its translation into English, illustrates the
goals and challenges of it. We bracketed the enti-
ties, time expressions, and events and we anno-
tated them with identifiers, denoted respectively
oz, tj, and ek:
</bodyText>
<figure confidence="0.984554181818182">
En {bussolycka}e1 i södra Afghanistan
krävdee2 {på torsdagen}t1 {20
dödsoffer}o1. Ytterligare {39
personer}o2 skadadese3 i olyckane4.
Busseno3 {var på väg}e5 från Kanda-
har mot huvudstaden Kabul när deno4
under en omkörninge6 kördee7
av vägbanano5 och voltadee8,
meddeladee9 general Salim Khan,
biträdande polischef i Kandahar.
TT-AFP &amp; Dagens Nyheter, July 8,
</figure>
<page confidence="0.385625">
2004
</page>
<bodyText confidence="0.7708443125">
{20 persons}o1 diede2 in a {bus
accident}e1 in southern Afghanistan
{on Thursday}t1. In addition, {39
persons}o2 {were injured}e3 in the
accidente4.
The buso3 {was on its way}e5 from
Kandahar to the capital Kabul when
ito4 {drove off}e7 the roado5 while
overtakinge6 and {flipped over}e8,
saide9 General Salim Khan, assistant
head of police in Kandahar.
The text above, our translation.
To create a consistent animation, the program
needs to extract and understand who the partici-
pants are and what they do. In the case of the ac-
cident above, it has to:
</bodyText>
<footnote confidence="0.98113425">
1. Detect the involved physical entities o3, o4,
and o5.
2. Understand that the pronoun o4 refers to o3.
3. Detect the events e6, e7, and e8.
</footnote>
<page confidence="0.996039">
385
</page>
<listItem confidence="0.865559285714286">
4. Link the participants to the events using se-
mantic roles or grammatical functions and in-
fer the unmentioned vehicle that is overtaken.
5. Understand that the order of the events is e6-
e7-e8.
6. Detect the time expression t1 to anchor tem-
porally the animation.
</listItem>
<bodyText confidence="0.99857925">
In this paper, we describe how we address tasks
3, 5, and 6 within the Carsim program, i.e., how
we detect, interpret, and order events and how we
process time expressions.
</bodyText>
<sectionHeader confidence="0.993416" genericHeader="method">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999353607843137">
Research on the representation of time, events,
and temporal relations dates back the beginning
of logic. It resulted in an impressive number of
formulations and models. In a review of contem-
porary theories and an attempt to unify them, Ben-
nett and Galton (2004) classified the most influen-
tial formalisms along three lines. A first approach
is to consider events as transitions between states
as in STRIPS (Fikes and Nilsson, 1971). A sec-
ond one is to map events on temporal intervals
and to define relations between pairs of intervals.
Allen’s (1984) 13 temporal relations are a widely
accepted example of this. A third approach is to
reify events, to quantify them existentially, and
to connect them to other objects using predicates
based on action verbs and their modifiers (David-
son, 1967). The sentence John saw Mary in Lon-
don on Tuesday is then translated into the logical
form: ∃E[Saw(E, j, m)∧Place(E, l)∧Time(E, t)].
Description of relations between time, events,
and verb tenses has also attracted a considerable
interest, especially in English. Modern work on
temporal event analysis probably started with Re-
ichenbach (1947), who proposed the distinction
between the point of speech, point of reference,
and point of event in utterances. This separation
allows for a systematic description of tenses and
proved to be very powerful.
Many authors proposed general principles to
extract automatically temporal relations between
events. A basic observation is that the tempo-
ral order of events is related to their narrative or-
der. Dowty (1986) investigated it and formulated a
Temporal Discourse Interpretation Principle to in-
terpret the advance of narrative time in a sequence
of sentences. Lascarides and Asher (1993) de-
scribed a complex logical framework to deal with
events in simple past and pluperfect sentences.
Hitzeman et al. (1995) proposed a constraint-
based approach taking into account tense, aspect,
temporal adverbials, and rhetorical structure to an-
alyze a discourse.
Recently, groups have used machine learn-
ing techniques to determine temporal relations.
They trained automatically classifiers on hand-
annotated corpora. Mani et al. (2003) achieved
the best results so far by using decision trees to
order partially events of successive clauses in En-
glish texts. Boguraev and Ando (2005) is another
example of it for English and Li et al. (2004) for
Chinese.
</bodyText>
<sectionHeader confidence="0.9923325" genericHeader="method">
3 Annotating Texts with Temporal
Information
</sectionHeader>
<bodyText confidence="0.999250047619048">
Several schemes have been proposed to anno-
tate temporal information in texts, see Setzer and
Gaizauskas (2002), inter alia. Many of them were
incompatible or incomplete and in an effort to rec-
oncile and unify the field, Ingria and Pustejovsky
(2002) introduced the XML-based Time markup
language (TimeML).
TimeML is a specification language whose
goal is to capture most aspects of temporal rela-
tions between events in discourses. It is based
on Allen’s (1984) relations and a variation of
Vendler’s (1967) classification of verbs. It de-
fines XML elements to annotate time expressions,
events, and “signals”. The SIGNAL tag marks sec-
tions of text indicating a temporal relation. It
includes function words such as later and not.
TimeML also features elements to connect entities
using different types of links, most notably tem-
poral links, TLINKs, that describe the temporal re-
lation holding between events or between an event
and a time.
</bodyText>
<sectionHeader confidence="0.986457" genericHeader="method">
4 A System to Convert Narratives of
Road Accidents into 3D Scenes
</sectionHeader>
<subsectionHeader confidence="0.998112">
4.1 Carsim
</subsectionHeader>
<bodyText confidence="0.999817111111111">
Carsim is a text-to-scene converter. From a nar-
rative, it creates a complete and unambiguous 3D
geometric description, which it renders visually.
Carsim considers authentic texts describing road
accidents, generally collected from web sites of
Swedish newspapers or transcribed from hand-
written accounts by victims of accidents. One of
the program’s key features is that it animates the
generated scene to visualize events.
</bodyText>
<page confidence="0.994529">
386
</page>
<bodyText confidence="0.9996925">
The Carsim architecture is divided into two
parts that communicate using a frame representa-
tion of the text. Carsim’s first part is a linguistic
module that extracts information from the report
and fills the frame slots. The second part is a vir-
tual scene generator that takes the structured rep-
resentation as input, creates the visual entities, and
animates them.
</bodyText>
<subsectionHeader confidence="0.998978">
4.2 Knowledge Representation in Carsim
</subsectionHeader>
<bodyText confidence="0.814560321428571">
The Carsim language processing module reduces
the text content to a frame representation – a tem-
plate – that outlines what happened and enables a
conversion to a symbolic scene. It contains:
• Objects. They correspond to the physical en-
tities mentioned in the text. They also include
abstract symbols that show in the scene. Each
object has a type, that is selected from a pre-
defined, finite set. An object’s semantics is
a separate geometric entity, where its shape
(and possibly its movement) is determined by
its type.
• Events. They correspond intuitively to an ac-
tivity that goes on during a period in time
and here to the possible object behaviors. We
represent events as entities with a type taken
from a predefined set, where an event’s se-
mantics will be a proposition paired with a
point or interval in time during which the
proposition is true.
• Relations and Quantities. They describe spe-
cific features of objects and events and how
they are related to each other. The most obvi-
ous examples of such information are spatial
information about objects and temporal in-
formation about events. Other meaningful re-
lations and quantities include physical prop-
erties such as velocity, color, and shape.
</bodyText>
<sectionHeader confidence="0.982779" genericHeader="method">
5 Time and Event Processing
</sectionHeader>
<bodyText confidence="0.99998585">
We designed and implemented a generic com-
ponent to extract temporal information from the
texts. It sits inside the natural language part of
Carsim and proceeds in two steps. The first step
uses a pipeline of finite-state machines and phrase-
structure rules that identifies time expressions, sig-
nals, and events. This step also generates a feature
vector for each element it identifies. Using the
vectors, the second step determines the temporal
relations between the extracted events and orders
them in time. The result is a text annotated using
the TimeML scheme.
We use a set of decision trees and a machine
learning approach to find the relations between
events. As input to the second step, the decision
trees take sequences of events extracted by the
first step and decide the temporal relation, possi-
bly none, between pairs of them. To run the learn-
ing algorithm, we manually annotated a small set
of texts on which we trained the trees.
</bodyText>
<subsectionHeader confidence="0.999793">
5.1 Processing Structure
</subsectionHeader>
<bodyText confidence="0.999866727272727">
We use phrase-structure rules and finite state ma-
chines to mark up events and time expressions. In
addition to the identification of expressions, we of-
ten need to interpret them, for instance to com-
pute the absolute time an expression refers to. We
therefore augmented the rules with procedural at-
tachments.
We wrote a parser to control the processing flow
where the rules, possibly recursive, apply regular
expressions, call procedures, and create TimeML
entities.
</bodyText>
<subsectionHeader confidence="0.999849">
5.2 Detection of Time Expressions
</subsectionHeader>
<bodyText confidence="0.99997336">
We detect and interpret time expressions with a
two-level structure. The first level processes in-
dividual tokens using a dictionary and regular ex-
pressions. The second level uses the results from
the token level to compute the meaning of multi-
word expressions.
Token-Level Rules. In Swedish, time expres-
sions such as en tisdagseftermiddag ‘a Tuesday
afternoon’ use nominal compounds. To decode
them, we automatically generate a comprehensive
dictionary with mappings from strings onto com-
pound time expressions. We decode other types
of expressions such as 2005-01-14 using regular
expressions
Multiword-Level Rules. We developed a
grammar to interpret the meaning of multiword
time expressions. It includes instructions on how
to combine the values of individual tokens for ex-
pressions such as {vid lunchtid}t1 {en tisdagefter-
middag}t2 ‘{at noon}t1 {a Tuesday afternoon}t2’.
The most common case consists in merging the to-
kens’ attributes to form a more specific expression.
However, relative time expressions such as i tors-
dags ‘last Tuesday’ are more complex. Our gram-
mar handles the most frequent ones, mainly those
</bodyText>
<page confidence="0.991879">
387
</page>
<bodyText confidence="0.9978335">
that need the publishing date for their interpreta-
tion.
</bodyText>
<subsectionHeader confidence="0.999562">
5.3 Detection of Signals
</subsectionHeader>
<bodyText confidence="0.999994285714286">
We detect signals using a lexicon and naïve string
matching. We annotate each signal with a sense
where the possible values are: negation, before, af-
ter, later, when, and continuing. TimeML only de-
fines one attribute for the SIGNAL tag, an identifier,
and encodes the sense as an attribute of the LINKs
that refer to it. We found it more appropriate to
store the sense directly in the SIGNAL element, and
so we extended it with a second attribute.
We use the sense information in decision trees
as a feature to determine the order of events. Our
strategy based on string matching results in a lim-
ited overdetection. However, it does not break the
rest of the process.
</bodyText>
<subsectionHeader confidence="0.996943">
5.4 Detection of Events
</subsectionHeader>
<bodyText confidence="0.99999015">
We detect the TimeML events using a part-of-
speech tagger and phrase-structure rules. We con-
sider that all verbs and verb groups are events. We
also included some nouns or compounds, which
are directly relevant to Carsim’s application do-
main, such as bilolycka ‘car accident’ or krock
‘collision’. We detect these nouns through a set
of six morphemes.
TimeML annotates events with three features:
aspect, tense, and “class”, where the class corre-
sponds to the type of the event. The TimeML spec-
ifications define seven classes. We kept only the
two most frequent ones: states and occurrences.
We determine the features using procedures at-
tached to each grammatical construct we extract.
The grammatical features aspect and tense are
straightforward and a direct output of the phrase-
structure rules. To infer the TimeML class, we use
heuristics such as these ones: predicative clauses
(copulas) are generally states and verbs in preterit
are generally occurrences.
The domain, reports of car accidents, makes
this approach viable. The texts describe sequences
of real events. They are generally simple, to the
point, and void of speculations and hypothetical
scenarios. This makes the task of feature identifi-
cation simpler than it is in more general cases.
In addition to the TimeML features, we extract
the grammatical properties of events. Our hypoth-
esis is that specific sequences of grammatical con-
structs are related to the temporal order of the de-
scribed events. The grammatical properties con-
sist of the part of speech, noun (NOUN) or verb
(VB). Verbs can be finite (FIN) or infinitive (INF).
They can be reduced to a single word or part of a
group (GR). They can be a copula (COP), a modal
(MOD), or a lexical verb. We combine these prop-
erties into eight categories that we use in the fea-
ture vectors of the decision trees (see ...EventStruc-
ture in Sect. 6.2).
</bodyText>
<sectionHeader confidence="0.991274" genericHeader="method">
6 Event Ordering
</sectionHeader>
<bodyText confidence="0.999936933333334">
TimeML defines three different types of links:
subordinate (SLINK), temporal (TLINK), and aspec-
tual (ALINK). Aspectual links connect two event in-
stances, one being aspectual and the other the ar-
gument. As its significance was minor in the visu-
alization of car accidents, we set aside this type of
link.
Subordinate links generally connect signals to
events, for instance to mark polarity by linking a
not to its main verb. We identify these links simul-
taneously with the event detection. We augmented
the phrase-structure rules to handle subordination
cases at the same time they annotate an event. We
restricted the cases to modality and polarity and
we set aside the other ones.
</bodyText>
<subsectionHeader confidence="0.999378">
6.1 Generating Temporal Links
</subsectionHeader>
<bodyText confidence="0.999988285714286">
To order the events in time and create the tempo-
ral links, we use a set of decision trees. We apply
each tree to sequences of events where it decides
the order between two of the events in each se-
quence. If e1,..., en are the events in the sequence
they appear in the text, the trees correspond to the
following functions:
</bodyText>
<equation confidence="0.999268">
fdt1(ei, ei+1) trel(ei, ei+1)
fdt2(ei, ei+1, ei+2) trel(ei, ei+1)
fdt3(ei, ei+1, ei+2) trel(ei+1, ei+2)
fdt4(ei, ei+1, ei+2) trel(ei, ei+2)
fdt5(ei, ei+1, ei+2, ei+3) trel(ei, ei+3)
</equation>
<bodyText confidence="0.999801727272727">
The possible output values of the trees are: si-
multaneous, after, before, is_included, includes,
and none. These values correspond to the relations
described by Setzer and Gaizauskas (2001).
The first decision tree should capture more gen-
eral relations between two adjacent events with-
out the need of a context. Decision trees dt2 and
dt3 extend the context by one event to the left re-
spectively one event to the right. They should cap-
ture more specific phenomena. However, they are
not always applicable as we never apply a decision
</bodyText>
<page confidence="0.997456">
388
</page>
<bodyText confidence="0.999826071428571">
tree when there is a time expression between any
of the events involved. In effect, time expressions
“reanchor” the narrative temporally, and we no-
ticed that the decision trees performed very poorly
across time expressions.
We complemented the decision trees with a
small set of domain-independent heuristic rules
that encode common-sense knowledge. We as-
sume that events in the present tense occur after
events in the past tense and that all mentions of
events such as olycka ‘accident’ refer to the same
event. In addition, the Carsim event interpreter
recognizes some semantically motivated identity
relations.
</bodyText>
<subsectionHeader confidence="0.996675">
6.2 Feature Vectors
</subsectionHeader>
<bodyText confidence="0.999909625">
The decision trees use a set of features correspond-
ing to certain attributes of the considered events,
temporal signals between them, and some other
parameters such as the number of tokens separat-
ing the pair of events to be linked. We list below
the features of fdti together with their values. The
first event in the pair is denoted by a mainEvent pre-
fix and the second one by relatedEvent:
</bodyText>
<listItem confidence="0.9982782">
• mainEventTense: none, past, present, future,
NOT_DETERMINED.
• mainEventAspect: progressive, perfective, per-
fective_progressive, none, NOT_DETERMINED.
• mainEventStructure: NOUN, VB_GR_COP_INF,
</listItem>
<bodyText confidence="0.851662333333333">
VB_GR_COP_FIN, VB_GR_MOD_INF,
VB_GR_MOD_FIN, VB_GR, VB_INF, VB_FIN,
UNKNOWN.
</bodyText>
<listItem confidence="0.9942722">
• relatedEventTense: (as mainEventTense)
• relatedEventAspect: (as mainEventAspect)
• relatedEventStructure: (as mainEventStructure)
• temporalSignalInbetween: none, before, after,
later, when, continuing, several.
• tokenDistance: 1, 2 to 3, 4 to 6, 7 to 10, greater
than 10.
• sentenceDistance: 0, 1, 2, 3, 4, greater than 4.
• punctuationSignDistance: 0, 1, 2, 3, 4, 5, greater
than 5.
</listItem>
<bodyText confidence="0.999402666666667">
The four other decision trees consider more
events but use similar features. The values for the
...Distance features are of course greater.
</bodyText>
<subsectionHeader confidence="0.997916">
6.3 Temporal Loops
</subsectionHeader>
<bodyText confidence="0.999985823529412">
The process described above results in an overgen-
eration of temporal links. As some of them may be
conflicting, a post-processing module reorganizes
them and discards the temporal loops.
The initial step of the loop resolution assigns
each link with a score. This score is created by the
decision trees and is derived from the C4.5 metrics
(Quinlan, 1993). It reflects the accuracy of the leaf
as well as the overall accuracy of the decision tree
in question. The score for links generated from
heuristics is rule dependent.
The loop resolution algorithm begins with an
empty set of orderings. It adds the partial order-
ings to the set if their inclusion doesn’t introduce
a temporal conflict. It first adds the links with the
highest scores, and thus, in each temporal loop, the
ordering with the lowest score is discarded.
</bodyText>
<sectionHeader confidence="0.957009" genericHeader="method">
7 Experimental Setup and Evaluation
</sectionHeader>
<bodyText confidence="0.9999932">
As far as we know, there is no available time-
annotated corpus in Swedish, which makes the
evaluation more difficult. As development and
test sets, we collected approximately 300 reports
of road accidents from various Swedish newspa-
pers. Each report is annotated with its publishing
date. Analyzing the reports is complex because
of their variability in style and length. Their size
ranges from a couple of sentences to more than a
page. The amount of details is overwhelming in
some reports, while in others most of the informa-
tion is implicit. The complexity of the accidents
described ranges from simple accidents with only
one vehicle to multiple collisions with several par-
ticipating vehicles and complex movements.
We manually annotated a subset of our corpus
consisting of 25 texts, 476 events and 1,162 tem-
poral links. We built the trees automatically from
this set using the C4.5 program (Quinlan, 1993).
Our training set is relatively small and the num-
ber of features we use relatively large for the set
size. This can produce a training overfit. However,
C4.5, to some extent, makes provision for this and
prunes the decision trees.
We evaluated three aspects of the temporal in-
formation extraction modules: the detection and
interpretation of time expressions, the detection
and interpretation of events, and the quality of the
final ordering. We report here the detection of
events and the final ordering.
</bodyText>
<page confidence="0.996566">
389
</page>
<table confidence="0.9998715">
Feature Ncorrect Nerroneous Correct
Tense 179 1 99.4%
Aspect 161 19 89.4%
Class 150 30 83.3%
</table>
<tableCaption confidence="0.99939">
Table 1: Feature detection for 180 events.
</tableCaption>
<subsectionHeader confidence="0.971407">
7.1 Event Detection
</subsectionHeader>
<bodyText confidence="0.999910857142857">
We evaluated the performance of the event detec-
tion on a test corpus of 40 previously unseen texts.
It should be noted that we used a simplified defi-
nition of what an event is, and that the manual an-
notation and evaluation were both done using the
same definition (i.e. all verbs, verb groups, and a
small number of nouns are events). The system
detected 584 events correctly, overdetected 3, and
missed 26. This gives a recall of 95.7%, a preci-
sion of 99.4%, and an F-measure of 97.5%.
The feature detection is more interesting and
Table 1 shows an evaluation of it. We carried out
this evaluation on the first 20 texts of the test cor-
pus.
</bodyText>
<subsectionHeader confidence="0.999437">
7.2 Evaluation of Final Ordering
</subsectionHeader>
<bodyText confidence="0.999469388888889">
We evaluated the final ordering with the method
proposed by Setzer and Gaizauskas (2001). Their
scheme is comprehensive and enables to compare
the performance of different systems.
Description of the Evaluation Method. Set-
zer and Gaizauskas carried out an inter-annotator
agreement test for temporal relation markup.
When evaluating the final ordering of a text, they
defined the set E of all the events in the text and
the set T of all the time expressions. They com-
puted the set (E ∪ T) × (E ∪ T) and they defined
the sets S`, I`, and B` as the transitive closures
for the relations simultaneous, includes, and be-
fore, respectively.
If S`k and S`rrepresent the set S` for the an-
swer key (“Gold Standard”) and system response,
respectively, the measures of precision and recall
for the simultaneous relation are:
</bodyText>
<equation confidence="0.977673666666667">
R =
|S` k ∩ S` r  |P = |S` k ∩ S` r |
|S` k  ||S` r |
</equation>
<bodyText confidence="0.999492">
For an overall measure of recall and precision,
Setzer and Gaizauskas proposed the following for-
mulas:
</bodyText>
<equation confidence="0.999859">
R = |S`k ∩ S`r  |+ |B`k ∩ B`r  |+ |I` k ∩ I` r |
|S`k  |+ |B`k |+ |I`k |
P = |S`k ∩ S`r  |+ |B`k ∩ B`r  |+ |I`k ∩ I`r |
|S`r  |+ |B`r  |+ |I` r |
</equation>
<bodyText confidence="0.99987834883721">
They used the classical definition of the F-
measure: the harmonic means of precision and re-
call. Note that the precision and recall are com-
puted per text, not for all relations in the test set
simultaneously.
Results. We evaluated the output of the Car-
sim system on 10 previously unseen texts against
our Gold Standard. As a baseline, we used a sim-
ple algorithm that assumes that all events occur in
the order they are introduced in the narrative. For
comparison, we also did an inter-annotator evalu-
ation on the same texts, where we compared the
Gold Standard, annotated by one of us, with the
annotation produced by another member in our
group.
As our system doesn’t support comparisons of
time expressions, we evaluated the relations con-
tained in the set E × E. We only counted the
reflexive simultaneous relation once per tuples
(ex, ey) and (ey, ex) and we didn’t count relations
(ex, ex).
Table 2 shows our results averaged over the
10 texts. As a reference, we also included Set-
zer and Gaizauskas’ averaged results for inter-
annotator agreement on temporal relations in six
texts. Their results are not directly comparable
however as they did the evaluation over the set
(E ∪ T) × (E ∪ T) for English texts of another
type.
Comments. The computation of ratios on the
transitive closure makes Setzer and Gaizauskas’
evaluation method extremely sensitive. Missing a
single link often results in a loss of scores of gener-
ated transitive links and thus has a massive impact
on the final evaluation figures.
As an example, one of our texts contains six
events whose order is e4 &lt; e5 &lt; e6 &lt; e1 &lt; e2 &lt;
e3. The event module automatically detects the
chains e4 &lt; e5 &lt; e6 and e1 &lt; e2 &lt; e3 correctly,
but misses the link e6 &lt; e1. This gives a recall of
6/15 = 0.40. When considering evaluations per-
formed using the method above, it is meaningful
to have this in mind.
</bodyText>
<sectionHeader confidence="0.987242" genericHeader="method">
8 Carsim Integration
</sectionHeader>
<bodyText confidence="0.9893645">
The visualization module considers a subset of the
detected events that it interprets graphically. We
</bodyText>
<page confidence="0.989913">
390
</page>
<table confidence="0.9991398">
Evaluation Average nwords Average nevents Pmean Rmean Fmean
Gold vs. Baseline 98.5 14.3 49.42 29.23 35.91
Gold vs. Automatic &amp;quot; &amp;quot; 54.85 37.72 43.97
Gold vs. Other Annotator &amp;quot; &amp;quot; 85.55 58.02 68.01
Setzer and Gaizauskas 312.2 26.7 67.72 40.07 49.13
</table>
<tableCaption confidence="0.999527">
Table 2: Evaluation results for final ordering averaged per text (with P, R, and F in %).
</tableCaption>
<bodyText confidence="0.9999462">
call this subset the Carsim events. Once the event
processing has been done, Carsim extracts these
specific events from the full set using a small do-
main ontology and inserts them into the template.
We use the event relations resulting from temporal
information extraction module to order them. For
all pairs of events in the template, Carsim queries
the temporal graph to determine their relation.
Figure 1 shows a part of the template represent-
ing the accident described in Section 1. It lists
the participants, with the unmentioned vehicle in-
ferred to be a car. It also shows the events and
their temporal order. Then, the visualization mod-
ule synthesizes a 3D scene and animates it. Fig-
ure 2 shows four screenshots picturing the events.
</bodyText>
<figureCaption confidence="0.982575">
Figure 1: Representation of the accident in the ex-
ample text.
</figureCaption>
<sectionHeader confidence="0.905633" genericHeader="conclusions">
9 Conclusion and Perspectives
</sectionHeader>
<bodyText confidence="0.999981481481481">
We have developed a method for detecting time
expressions, events, and for ordering these events
temporally. We have integrated it in a text-to-
scene converter enabling the animation of generic
actions.
The module to detect time expression and inter-
pret events performs significantly better than the
baseline technique used in previous versions of
Carsim. In addition, it should to be easy to sep-
arate it from the Carsim framework and reuse it in
other domains.
The central task, the ordering of all events,
leaves lots of room for improvement. The accu-
racy of the decision trees should improve with a
larger training set. It would result in a better over-
all performance. Switching from decision trees to
other training methods such as Support Vector Ma-
chines or using semantically motivated features, as
suggested by Mani (2003), could also be sources
of improvements.
More fundamentally, the decision tree method
we have presented is not able to take into account
long-distance links. Investigation into new strate-
gies to extract such links directly without the com-
putation of a transitive closure would improve re-
call and, given the evaluation procedure, increase
the performance.
</bodyText>
<sectionHeader confidence="0.999283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999827529411765">
James F. Allen. 1984. Towards a general theory of
action and time. Artificial Intelligence, 23(2):123–
154.
Brandon Bennett and Antony P. Galton. 2004. A uni-
fying semantics for time and events. Artificial Intel-
ligence, 153(1-2):13–48.
Branimir Boguraev and Rie Kubota Ando. 2005.
TimeML-compliant text analysis for temporal rea-
soning. In IJCAI-05, Proceedings of the Nineteenth
International Joint Conference on Artificial Intelli-
gence, pages 997–1003, Edinburgh, Scotland.
Donald Davidson. 1967. The logical form of action
sentences. In N. Rescher, editor, The Logic of Deci-
sion and Action. University of Pittsburgh Press.
David R. Dowty. 1986. The effects of aspectual class
on the temporal structure of discourse: Semantics or
pragmatics? Linguistics and Philosophy, 9:37–61.
</reference>
<page confidence="0.998622">
391
</page>
<figureCaption confidence="0.989786">
Figure 2: Animation of the scene and event visualization.
</figureCaption>
<reference confidence="0.998626071428571">
Sylvain Dupuy, Arjan Egges, Vincent Legendre, and
Pierre Nugues. 2001. Generating a 3D simulation
of a car accident from a written description in nat-
ural language: The Carsim system. In ACL 2001,
Workshop on Temporal and Spatial Information Pro-
cessing, pages 1–8, Toulouse, France.
Richard Fikes and Nils J. Nilsson. 1971. Strips: A
new approach to the application of theorem proving
to problem solving. Artificial Intelligence, 2:189–
208.
Janet Hitzeman, Marc Noels Moens, and Clare Grover.
1995. Algorithms for analyzing the temporal struc-
ture of discourse. In Proceedings of the Annual
Meeting of the European Chapter of the Associa-
tion of Computational Linguistics, pages 253–260,
Dublin, Ireland.
Bob Ingria and James Pustejovsky. 2002. Specification
for TimeML 1.0.
Richard Johansson, Anders Berglund, Magnus
Danielsson, and Pierre Nugues. 2005. Automatic
text-to-scene conversion in the traffic accident
domain. In IJCAI-05, Proceedings of the Nineteenth
International Joint Conference on Artificial Intelli-
gence, pages 1073–1078, Edinburgh, Scotland.
Alex Lascarides and Nicholas Asher. 1993. Tem-
poral interpretation, discourse relations, and com-
mon sense entailment. Linguistics &amp; Philosophy,
16(5):437–493.
Wenjie Li, Kam-Fai Wong, Guihong Cao, and Chunfa
Yuan. 2004. Applying machine learning to Chinese
temporal relation resolution. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04), pages 582–588, Barcelona.
Inderjeet Mani, Barry Schiffman, and Jianping Zhang.
2003. Inferring temporal ordering of events in
news. In Human Language Technology Conference
(HLT’03), Edmonton, Canada.
Inderjeet Mani. 2003. Recent developments in tempo-
ral information extraction. In Nicolas Nicolov and
Ruslan Mitkov, editors, Proceedings of RANLP’03.
John Benjamins.
John Ross Quinlan. 1993. C4.5: Programs for Ma-
chine Learning. Morgan Kauffman.
Hans Reichenbach. 1947. Elements of Symbolic Logic.
Academic Press, New York.
Andrea Setzer and Robert Gaizauskas. 2001. A pi-
lot study on annotating temporal relations in text. In
ACL 2001, Workshop on Temporal and Spatial Infor-
mation Processing, pages 73–80, Toulouse, France.
Andrea Setzer and Robert Gaizauskas. 2002. On the
importance of annotating temporal event-event rela-
tions in text. In LREC 2002, Workshop on Annota-
tion Standards for Temporal Information in Natural
Language.
Zeno Vendler. 1967. Linguistics in Philosophy. Cor-
nell University Press, Ithaca, New York.
</reference>
<page confidence="0.998334">
392
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.9973185">A Machine Learning Approach to Extract Temporal Information from Texts in Swedish and Generate Animated 3D Scenes</title>
<author confidence="0.998949">Anders Berglund Richard Johansson Pierre Nugues</author>
<affiliation confidence="0.9999065">Department of Computer Science, LTH Lund University</affiliation>
<address confidence="0.994956">SE-221 00 Lund, Sweden</address>
<email confidence="0.806947">d98ab@efd.lth.se,{richard,pierre}@cs.lth.se</email>
<abstract confidence="0.9882868">Carsim is a program that automatically converts narratives into 3D scenes. Carsim considers authentic texts describing road accidents, generally collected from web sites of Swedish newspapers or transcribed from hand-written accounts by victims of accidents. One of the program’s key features is that it animates the generated scene to visualize events. To create a consistent animation, Carsim extracts the participants mentioned in a text and identifies what they do. In this paper, we focus on the extraction of temporal relations between actions. We first describe how we detect time expressions and events. We then present a machine learning technique to order the sequence of events identified in the narratives. We finally report the results we obtained. 1 Extraction of Temporal Information and Scene Visualization Carsim is a program that generates 3D scenes from narratives describing road accidents (Johansson et al., 2005; Dupuy et al., 2001). It considers authentic texts, generally collected from web sites of Swedish newspapers or transcribed from handwritten accounts by victims of accidents. One of Carsim’s key features is that it animates the generated scene to visualize events described in the narrative. The text below, a newspaper article with its translation into English, illustrates the goals and challenges of it. We bracketed the entities, time expressions, and events and we annotated them with identifiers, denoted respectively and södra Afghanistan på Kandamot huvudstaden Kabul när en Salim Khan, biträdande polischef i Kandahar. TT-AFP &amp; Dagens Nyheter, July 8, 2004 a {bus southern Afghanistan In addition, {39 the {was on its Kandahar to the capital Kabul when {flipped Salim Khan, assistant head of police in Kandahar. The text above, our translation. To create a consistent animation, the program needs to extract and understand who the participants are and what they do. In the case of the accident above, it has to: Detect the involved physical entities Understand that the pronoun to Detect the events and 385 4. Link the participants to the events using semantic roles or grammatical functions and infer the unmentioned vehicle that is overtaken. Understand that the order of the events is Detect the time expression anchor temporally the animation. In this paper, we describe how we address tasks 3, 5, and 6 within the Carsim program, i.e., how we detect, interpret, and order events and how we process time expressions. 2 Previous Work Research on the representation of time, events, and temporal relations dates back the beginning of logic. It resulted in an impressive number of formulations and models. In a review of contemporary theories and an attempt to unify them, Bennett and Galton (2004) classified the most influential formalisms along three lines. A first approach is to consider events as transitions between states as in STRIPS (Fikes and Nilsson, 1971). A second one is to map events on temporal intervals and to define relations between pairs of intervals. Allen’s (1984) 13 temporal relations are a widely accepted example of this. A third approach is to reify events, to quantify them existentially, and to connect them to other objects using predicates based on action verbs and their modifiers (David- 1967). The sentence saw Mary in Lonon Tuesday then translated into the logical j, Description of relations between time, events, and verb tenses has also attracted a considerable interest, especially in English. Modern work on temporal event analysis probably started with Reichenbach (1947), who proposed the distinction between the point of speech, point of reference, and point of event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extract automatically temporal relations between events. A basic observation is that the temporal order of events is related to their narrative order. Dowty (1986) investigated it and formulated a Discourse Interpretation Principle interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and (2002), Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses. It is based on Allen’s (1984) relations and a variation of Vendler’s (1967) classification of verbs. It defines XML elements to annotate time expressions, and “signals”. The marks sections of text indicating a temporal relation. It function words such as TimeML also features elements to connect entities using different types of links, most notably temlinks, that describe the temporal relation holding between events or between an event and a time. 4 A System to Convert Narratives of Road Accidents into 3D Scenes 4.1 Carsim Carsim is a text-to-scene converter. From a narrative, it creates a complete and unambiguous 3D geometric description, which it renders visually. Carsim considers authentic texts describing road accidents, generally collected from web sites of Swedish newspapers or transcribed from handwritten accounts by victims of accidents. One of the program’s key features is that it animates the generated scene to visualize events. 386 The Carsim architecture is divided into two parts that communicate using a frame representation of the text. Carsim’s first part is a linguistic module that extracts information from the report and fills the frame slots. The second part is a virtual scene generator that takes the structured representation as input, creates the visual entities, and animates them. 4.2 Knowledge Representation in Carsim The Carsim language processing module reduces the text content to a frame representation – a template – that outlines what happened and enables a conversion to a symbolic scene. It contains: • They correspond to the physical entities mentioned in the text. They also include abstract symbols that show in the scene. Each has a that is selected from a predefined, finite set. An object’s semantics is a separate geometric entity, where its shape (and possibly its movement) is determined by its type. • They correspond intuitively to an activity that goes on during a period in time and here to the possible object behaviors. We represent events as entities with a type taken from a predefined set, where an event’s semantics will be a proposition paired with a point or interval in time during which the proposition is true. Relations and They describe specific features of objects and events and how they are related to each other. The most obviexamples of such information are about objects and information about events. Other meaningful relations and quantities include physical properties such as velocity, color, and shape. 5 Time and Event Processing We designed and implemented a generic component to extract temporal information from the texts. It sits inside the natural language part of Carsim and proceeds in two steps. The first step uses a pipeline of finite-state machines and phrasestructure rules that identifies time expressions, signals, and events. This step also generates a feature vector for each element it identifies. Using the vectors, the second step determines the temporal relations between the extracted events and orders them in time. The result is a text annotated using the TimeML scheme. We use a set of decision trees and a machine learning approach to find the relations between events. As input to the second step, the decision trees take sequences of events extracted by the first step and decide the temporal relation, possibly none, between pairs of them. To run the learning algorithm, we manually annotated a small set of texts on which we trained the trees. 5.1 Processing Structure We use phrase-structure rules and finite state machines to mark up events and time expressions. In addition to the identification of expressions, we often need to interpret them, for instance to compute the absolute time an expression refers to. We therefore augmented the rules with procedural attachments. We wrote a parser to control the processing flow where the rules, possibly recursive, apply regular expressions, call procedures, and create TimeML entities. 5.2 Detection of Time Expressions We detect and interpret time expressions with a two-level structure. The first level processes individual tokens using a dictionary and regular expressions. The second level uses the results from the token level to compute the meaning of multiword expressions. Token-Level Rules. In Swedish, time expressuch as tisdagseftermiddag Tuesday afternoon’ use nominal compounds. To decode them, we automatically generate a comprehensive dictionary with mappings from strings onto compound time expressions. We decode other types expressions such as regular expressions Multiword-Level Rules. We developed a grammar to interpret the meaning of multiword time expressions. It includes instructions on how to combine the values of individual tokens for exsuch as tisdagefter- Tuesday The most common case consists in merging the tokens’ attributes to form a more specific expression. relative time expressions such as tors- Tuesday’ are more complex. Our grammar handles the most frequent ones, mainly those 387 that need the publishing date for their interpretation. 5.3 Detection of Signals We detect signals using a lexicon and naïve string matching. We annotate each signal with a sense the possible values are: afand TimeML only deone attribute for the an identifier, encodes the sense as an attribute of the that refer to it. We found it more appropriate to the sense directly in the and so we extended it with a second attribute. We use the sense information in decision trees as a feature to determine the order of events. Our strategy based on string matching results in a limited overdetection. However, it does not break the rest of the process. 5.4 Detection of Events We detect the TimeML events using a part-ofspeech tagger and phrase-structure rules. We consider that all verbs and verb groups are events. We also included some nouns or compounds, which are directly relevant to Carsim’s application dosuch as accident’ or ‘collision’. We detect these nouns through a set of six morphemes. TimeML annotates events with three features: aspect, tense, and “class”, where the class corresponds to the type of the event. The TimeML specifications define seven classes. We kept only the two most frequent ones: states and occurrences. We determine the features using procedures attached to each grammatical construct we extract. The grammatical features aspect and tense are straightforward and a direct output of the phrasestructure rules. To infer the TimeML class, we use heuristics such as these ones: predicative clauses (copulas) are generally states and verbs in preterit are generally occurrences. The domain, reports of car accidents, makes this approach viable. The texts describe sequences of real events. They are generally simple, to the point, and void of speculations and hypothetical scenarios. This makes the task of feature identification simpler than it is in more general cases. In addition to the TimeML features, we extract the grammatical properties of events. Our hypothesis is that specific sequences of grammatical constructs are related to the temporal order of the described events. The grammatical properties conof the part of speech, noun or verb Verbs can be finite or infinitive They can be reduced to a single word or part of a They can be a copula a modal or a lexical verb. We combine these properties into eight categories that we use in the feavectors of the decision trees (see ...EventStruc- Sect. 6.2). 6 Event Ordering TimeML defines three different types of links: temporal and aspec- Aspectual links connect two event instances, one being aspectual and the other the argument. As its significance was minor in the visualization of car accidents, we set aside this type of link. Subordinate links generally connect signals to events, for instance to mark polarity by linking a its main verb. We identify these links simultaneously with the event detection. We augmented the phrase-structure rules to handle subordination cases at the same time they annotate an event. We restricted the cases to modality and polarity and we set aside the other ones. 6.1 Generating Temporal Links To order the events in time and create the temporal links, we use a set of decision trees. We apply each tree to sequences of events where it decides the order between two of the events in each se- If are the events in the sequence they appear in the text, the trees correspond to the following functions: possible output values of the trees are: si- These values correspond to the relations described by Setzer and Gaizauskas (2001). The first decision tree should capture more general relations between two adjacent events withthe need of a context. Decision trees the context by one event to the left respectively one event to the right. They should capture more specific phenomena. However, they are not always applicable as we never apply a decision 388 tree when there is a time expression between any of the events involved. In effect, time expressions “reanchor” the narrative temporally, and we noticed that the decision trees performed very poorly across time expressions. We complemented the decision trees with a small set of domain-independent heuristic rules that encode common-sense knowledge. We assume that events in the present tense occur after events in the past tense and that all mentions of such as refer to the same event. In addition, the Carsim event interpreter recognizes some semantically motivated identity relations. 6.2 Feature Vectors The decision trees use a set of features corresponding to certain attributes of the considered events, temporal signals between them, and some other parameters such as the number of tokens separating the pair of events to be linked. We list below features of together with their values. The event in the pair is denoted by a preand the second one by • • per- • • (as • (as • (as • • to to to • than • The four other decision trees consider more events but use similar features. The values for the are of course greater. 6.3 Temporal Loops The process described above results in an overgeneration of temporal links. As some of them may be conflicting, a post-processing module reorganizes them and discards the temporal loops. The initial step of the loop resolution assigns each link with a score. This score is created by the decision trees and is derived from the C4.5 metrics (Quinlan, 1993). It reflects the accuracy of the leaf as well as the overall accuracy of the decision tree in question. The score for links generated from heuristics is rule dependent. The loop resolution algorithm begins with an empty set of orderings. It adds the partial orderings to the set if their inclusion doesn’t introduce a temporal conflict. It first adds the links with the highest scores, and thus, in each temporal loop, the ordering with the lowest score is discarded. 7 Experimental Setup and Evaluation As far as we know, there is no available timeannotated corpus in Swedish, which makes the evaluation more difficult. As development and test sets, we collected approximately 300 reports of road accidents from various Swedish newspapers. Each report is annotated with its publishing date. Analyzing the reports is complex because of their variability in style and length. Their size ranges from a couple of sentences to more than a page. The amount of details is overwhelming in some reports, while in others most of the information is implicit. The complexity of the accidents described ranges from simple accidents with only one vehicle to multiple collisions with several participating vehicles and complex movements. We manually annotated a subset of our corpus consisting of 25 texts, 476 events and 1,162 temporal links. We built the trees automatically from this set using the C4.5 program (Quinlan, 1993). Our training set is relatively small and the number of features we use relatively large for the set size. This can produce a training overfit. However, C4.5, to some extent, makes provision for this and prunes the decision trees. We evaluated three aspects of the temporal information extraction modules: the detection and interpretation of time expressions, the detection and interpretation of events, and the quality of the final ordering. We report here the detection of events and the final ordering. 389 Feature Correct Tense 179 1 99.4% Aspect 161 19 89.4% Class 150 30 83.3% Table 1: Feature detection for 180 events. 7.1 Event Detection We evaluated the performance of the event detection on a test corpus of 40 previously unseen texts. It should be noted that we used a simplified definition of what an event is, and that the manual annotation and evaluation were both done using the same definition (i.e. all verbs, verb groups, and a small number of nouns are events). The system detected 584 events correctly, overdetected 3, and missed 26. This gives a recall of 95.7%, a preciof 99.4%, and an of 97.5%. The feature detection is more interesting and Table 1 shows an evaluation of it. We carried out this evaluation on the first 20 texts of the test corpus. 7.2 Evaluation of Final Ordering We evaluated the final ordering with the method proposed by Setzer and Gaizauskas (2001). Their scheme is comprehensive and enables to compare the performance of different systems. Description of the Evaluation Method. Setzer and Gaizauskas carried out an inter-annotator agreement test for temporal relation markup. When evaluating the final ordering of a text, they the set all the events in the text and set all the time expressions. They comthe set they defined sets and the transitive closures the relations and berespectively. and the set the answer key (“Gold Standard”) and system response, respectively, the measures of precision and recall the are: R = = For an overall measure of recall and precision, Setzer and Gaizauskas proposed the following formulas: = ∩ |+ ∩ |+ k  || = ∩ |+ ∩ |+ ∩ |  || used the classical definition of the measure: the harmonic means of precision and recall. Note that the precision and recall are computed per text, not for all relations in the test set simultaneously. Results. We evaluated the output of the Carsim system on 10 previously unseen texts against our Gold Standard. As a baseline, we used a simple algorithm that assumes that all events occur in the order they are introduced in the narrative. For comparison, we also did an inter-annotator evaluation on the same texts, where we compared the Gold Standard, annotated by one of us, with the annotation produced by another member in our group. As our system doesn’t support comparisons of time expressions, we evaluated the relations conin the set We only counted the once per tuples we didn’t count relations Table 2 shows our results averaged over the 10 texts. As a reference, we also included Setzer and Gaizauskas’ averaged results for interannotator agreement on temporal relations in six texts. Their results are not directly comparable however as they did the evaluation over the set English texts of another type. Comments. The computation of ratios on the transitive closure makes Setzer and Gaizauskas’ evaluation method extremely sensitive. Missing a single link often results in a loss of scores of generated transitive links and thus has a massive impact on the final evaluation figures. As an example, one of our texts contains six whose order is The event module automatically detects the misses the link This gives a recall of = When considering evaluations performed using the method above, it is meaningful to have this in mind. 8 Carsim Integration The visualization module considers a subset of the detected events that it interprets graphically. We 390 Evaluation Average Gold vs. Baseline 98.5 14.3 49.42 29.23 35.91 Gold vs. Automatic &amp;quot; &amp;quot; 54.85 37.72 43.97 Gold vs. Other Annotator &amp;quot; &amp;quot; 85.55 58.02 68.01 Setzer and Gaizauskas 312.2 26.7 67.72 40.07 49.13 2: Evaluation results for final ordering averaged per text (with and %). call this subset the Carsim events. Once the event processing has been done, Carsim extracts these specific events from the full set using a small domain ontology and inserts them into the template. We use the event relations resulting from temporal information extraction module to order them. For all pairs of events in the template, Carsim queries the temporal graph to determine their relation. Figure 1 shows a part of the template representing the accident described in Section 1. It lists the participants, with the unmentioned vehicle inferred to be a car. It also shows the events and their temporal order. Then, the visualization module synthesizes a 3D scene and animates it. Figure 2 shows four screenshots picturing the events. Figure 1: Representation of the accident in the example text. 9 Conclusion and Perspectives We have developed a method for detecting time expressions, events, and for ordering these events We have integrated it in a text-toscene converter enabling the animation of generic actions. The module to detect time expression and interpret events performs significantly better than the baseline technique used in previous versions of Carsim. In addition, it should to be easy to separate it from the Carsim framework and reuse it in other domains. The central task, the ordering of all events, leaves lots of room for improvement. The accuracy of the decision trees should improve with a larger training set. It would result in a better overall performance. Switching from decision trees to other training methods such as Support Vector Machines or using semantically motivated features, as suggested by Mani (2003), could also be sources of improvements. More fundamentally, the decision tree method we have presented is not able to take into account long-distance links. Investigation into new strategies to extract such links directly without the computation of a transitive closure would improve recall and, given the evaluation procedure, increase the performance.</abstract>
<note confidence="0.745307257142857">References James F. Allen. 1984. Towards a general theory of and time. 23(2):123– 154. Brandon Bennett and Antony P. Galton. 2004. A unisemantics for time and events. Intel- 153(1-2):13–48. Branimir Boguraev and Rie Kubota Ando. 2005. TimeML-compliant text analysis for temporal rea- In Proceedings of the Nineteenth International Joint Conference on Artificial Intellipages 997–1003, Edinburgh, Scotland. Donald Davidson. 1967. The logical form of action In N. Rescher, editor, Logic of Deciand University of Pittsburgh Press. David R. Dowty. 1986. The effects of aspectual class on the temporal structure of discourse: Semantics or and 9:37–61. 391 Figure 2: Animation of the scene and event visualization. Sylvain Dupuy, Arjan Egges, Vincent Legendre, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident from a written description in natlanguage: The Carsim system. In 2001, Workshop on Temporal and Spatial Information Propages 1–8, Toulouse, France. Richard Fikes and Nils J. Nilsson. 1971. Strips: A new approach to the application of theorem proving problem solving. 2:189– 208. Janet Hitzeman, Marc Noels Moens, and Clare Grover. 1995. Algorithms for analyzing the temporal strucof discourse. In of the Annual Meeting of the European Chapter of the Associaof Computational pages 253–260, Dublin, Ireland. Bob Ingria and James Pustejovsky. 2002. Specification for TimeML 1.0. Richard Johansson, Anders Berglund, Magnus Danielsson, and Pierre Nugues. 2005. Automatic text-to-scene conversion in the traffic accident In Proceedings of the Nineteenth International Joint Conference on Artificial Intellipages 1073–1078, Edinburgh, Scotland. Alex Lascarides and Nicholas Asher. 1993. Temporal interpretation, discourse relations, and comsense entailment. &amp; 16(5):437–493. Wenjie Li, Kam-Fai Wong, Guihong Cao, and Chunfa Yuan. 2004. Applying machine learning to Chinese relation resolution. In of the 42nd Meeting of the Association for Computational pages 582–588, Barcelona. Inderjeet Mani, Barry Schiffman, and Jianping Zhang. 2003. Inferring temporal ordering of events in In Language Technology Conference Edmonton, Canada. Inderjeet Mani. 2003. Recent developments in temporal information extraction. In Nicolas Nicolov and Mitkov, editors, of John Benjamins. Ross Quinlan. 1993. Programs for Ma- Morgan Kauffman. Reichenbach. 1947. of Symbolic Academic Press, New York. Andrea Setzer and Robert Gaizauskas. 2001. A pilot study on annotating temporal relations in text. In ACL 2001, Workshop on Temporal and Spatial Inforpages 73–80, Toulouse, France. Andrea Setzer and Robert Gaizauskas. 2002. On the</note>
<abstract confidence="0.5287872">importance of annotating temporal event-event relain text. In 2002, Workshop on Annotation Standards for Temporal Information in Natural Vendler. 1967. in Cornell University Press, Ithaca, New York.</abstract>
<intro confidence="0.326578">392</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Towards a general theory of action and time.</title>
<date>1984</date>
<journal>Artificial Intelligence,</journal>
<volume>23</volume>
<issue>2</issue>
<pages>154</pages>
<marker>Allen, 1984</marker>
<rawString>James F. Allen. 1984. Towards a general theory of action and time. Artificial Intelligence, 23(2):123– 154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brandon Bennett</author>
<author>Antony P Galton</author>
</authors>
<title>A unifying semantics for time and events.</title>
<date>2004</date>
<journal>Artificial Intelligence,</journal>
<pages>153--1</pages>
<contexts>
<context position="3546" citStr="Bennett and Galton (2004)" startWordPosition="557" endWordPosition="561">nfer the unmentioned vehicle that is overtaken. 5. Understand that the order of the events is e6- e7-e8. 6. Detect the time expression t1 to anchor temporally the animation. In this paper, we describe how we address tasks 3, 5, and 6 within the Carsim program, i.e., how we detect, interpret, and order events and how we process time expressions. 2 Previous Work Research on the representation of time, events, and temporal relations dates back the beginning of logic. It resulted in an impressive number of formulations and models. In a review of contemporary theories and an attempt to unify them, Bennett and Galton (2004) classified the most influential formalisms along three lines. A first approach is to consider events as transitions between states as in STRIPS (Fikes and Nilsson, 1971). A second one is to map events on temporal intervals and to define relations between pairs of intervals. Allen’s (1984) 13 temporal relations are a widely accepted example of this. A third approach is to reify events, to quantify them existentially, and to connect them to other objects using predicates based on action verbs and their modifiers (Davidson, 1967). The sentence John saw Mary in London on Tuesday is then translate</context>
</contexts>
<marker>Bennett, Galton, 2004</marker>
<rawString>Brandon Bennett and Antony P. Galton. 2004. A unifying semantics for time and events. Artificial Intelligence, 153(1-2):13–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir Boguraev</author>
<author>Rie Kubota Ando</author>
</authors>
<title>TimeML-compliant text analysis for temporal reasoning.</title>
<date>2005</date>
<booktitle>In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>997--1003</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="5595" citStr="Boguraev and Ando (2005)" startWordPosition="878" endWordPosition="881">of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and Gaizauskas (2002), inter alia. Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses. It is based on Allen’s (1984) relations and a variat</context>
</contexts>
<marker>Boguraev, Ando, 2005</marker>
<rawString>Branimir Boguraev and Rie Kubota Ando. 2005. TimeML-compliant text analysis for temporal reasoning. In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, pages 997–1003, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Davidson</author>
</authors>
<title>The logical form of action sentences.</title>
<date>1967</date>
<booktitle>The Logic of Decision and Action.</booktitle>
<editor>In N. Rescher, editor,</editor>
<publisher>University of Pittsburgh Press.</publisher>
<contexts>
<context position="4079" citStr="Davidson, 1967" startWordPosition="647" endWordPosition="649">w of contemporary theories and an attempt to unify them, Bennett and Galton (2004) classified the most influential formalisms along three lines. A first approach is to consider events as transitions between states as in STRIPS (Fikes and Nilsson, 1971). A second one is to map events on temporal intervals and to define relations between pairs of intervals. Allen’s (1984) 13 temporal relations are a widely accepted example of this. A third approach is to reify events, to quantify them existentially, and to connect them to other objects using predicates based on action verbs and their modifiers (Davidson, 1967). The sentence John saw Mary in London on Tuesday is then translated into the logical form: ∃E[Saw(E, j, m)∧Place(E, l)∧Time(E, t)]. Description of relations between time, events, and verb tenses has also attracted a considerable interest, especially in English. Modern work on temporal event analysis probably started with Reichenbach (1947), who proposed the distinction between the point of speech, point of reference, and point of event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extrac</context>
</contexts>
<marker>Davidson, 1967</marker>
<rawString>Donald Davidson. 1967. The logical form of action sentences. In N. Rescher, editor, The Logic of Decision and Action. University of Pittsburgh Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>The effects of aspectual class on the temporal structure of discourse: Semantics or pragmatics? Linguistics and Philosophy,</title>
<date>1986</date>
<pages>9--37</pages>
<contexts>
<context position="4836" citStr="Dowty (1986)" startWordPosition="765" endWordPosition="766">of relations between time, events, and verb tenses has also attracted a considerable interest, especially in English. Modern work on temporal event analysis probably started with Reichenbach (1947), who proposed the distinction between the point of speech, point of reference, and point of event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extract automatically temporal relations between events. A basic observation is that the temporal order of events is related to their narrative order. Dowty (1986) investigated it and formulated a Temporal Discourse Interpretation Principle to interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et</context>
</contexts>
<marker>Dowty, 1986</marker>
<rawString>David R. Dowty. 1986. The effects of aspectual class on the temporal structure of discourse: Semantics or pragmatics? Linguistics and Philosophy, 9:37–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Dupuy</author>
<author>Arjan Egges</author>
<author>Vincent Legendre</author>
<author>Pierre Nugues</author>
</authors>
<title>Generating a 3D simulation of a car accident from a written description in natural language: The Carsim system.</title>
<date>2001</date>
<booktitle>In ACL 2001, Workshop on Temporal and Spatial Information Processing,</booktitle>
<pages>1--8</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="1246" citStr="Dupuy et al., 2001" startWordPosition="181" endWordPosition="184"> visualize events. To create a consistent animation, Carsim extracts the participants mentioned in a text and identifies what they do. In this paper, we focus on the extraction of temporal relations between actions. We first describe how we detect time expressions and events. We then present a machine learning technique to order the sequence of events identified in the narratives. We finally report the results we obtained. 1 Extraction of Temporal Information and Scene Visualization Carsim is a program that generates 3D scenes from narratives describing road accidents (Johansson et al., 2005; Dupuy et al., 2001). It considers authentic texts, generally collected from web sites of Swedish newspapers or transcribed from handwritten accounts by victims of accidents. One of Carsim’s key features is that it animates the generated scene to visualize events described in the narrative. The text below, a newspaper article with its translation into English, illustrates the goals and challenges of it. We bracketed the entities, time expressions, and events and we annotated them with identifiers, denoted respectively oz, tj, and ek: En {bussolycka}e1 i södra Afghanistan krävdee2 {på torsdagen}t1 {20 dödsoffer}o1</context>
</contexts>
<marker>Dupuy, Egges, Legendre, Nugues, 2001</marker>
<rawString>Sylvain Dupuy, Arjan Egges, Vincent Legendre, and Pierre Nugues. 2001. Generating a 3D simulation of a car accident from a written description in natural language: The Carsim system. In ACL 2001, Workshop on Temporal and Spatial Information Processing, pages 1–8, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Fikes</author>
<author>Nils J Nilsson</author>
</authors>
<title>Strips: A new approach to the application of theorem proving to problem solving.</title>
<date>1971</date>
<journal>Artificial Intelligence,</journal>
<volume>2</volume>
<pages>208</pages>
<contexts>
<context position="3716" citStr="Fikes and Nilsson, 1971" startWordPosition="585" endWordPosition="588">n. In this paper, we describe how we address tasks 3, 5, and 6 within the Carsim program, i.e., how we detect, interpret, and order events and how we process time expressions. 2 Previous Work Research on the representation of time, events, and temporal relations dates back the beginning of logic. It resulted in an impressive number of formulations and models. In a review of contemporary theories and an attempt to unify them, Bennett and Galton (2004) classified the most influential formalisms along three lines. A first approach is to consider events as transitions between states as in STRIPS (Fikes and Nilsson, 1971). A second one is to map events on temporal intervals and to define relations between pairs of intervals. Allen’s (1984) 13 temporal relations are a widely accepted example of this. A third approach is to reify events, to quantify them existentially, and to connect them to other objects using predicates based on action verbs and their modifiers (Davidson, 1967). The sentence John saw Mary in London on Tuesday is then translated into the logical form: ∃E[Saw(E, j, m)∧Place(E, l)∧Time(E, t)]. Description of relations between time, events, and verb tenses has also attracted a considerable interes</context>
</contexts>
<marker>Fikes, Nilsson, 1971</marker>
<rawString>Richard Fikes and Nils J. Nilsson. 1971. Strips: A new approach to the application of theorem proving to problem solving. Artificial Intelligence, 2:189– 208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Hitzeman</author>
<author>Marc Noels Moens</author>
<author>Clare Grover</author>
</authors>
<title>Algorithms for analyzing the temporal structure of discourse.</title>
<date>1995</date>
<booktitle>In Proceedings of the Annual Meeting of the European Chapter of the Association of Computational Linguistics,</booktitle>
<pages>253--260</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="5134" citStr="Hitzeman et al. (1995)" startWordPosition="809" endWordPosition="812">f event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extract automatically temporal relations between events. A basic observation is that the temporal order of events is related to their narrative order. Dowty (1986) investigated it and formulated a Temporal Discourse Interpretation Principle to interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have b</context>
</contexts>
<marker>Hitzeman, Moens, Grover, 1995</marker>
<rawString>Janet Hitzeman, Marc Noels Moens, and Clare Grover. 1995. Algorithms for analyzing the temporal structure of discourse. In Proceedings of the Annual Meeting of the European Chapter of the Association of Computational Linguistics, pages 253–260, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Ingria</author>
<author>James Pustejovsky</author>
</authors>
<date>2002</date>
<journal>Specification for TimeML</journal>
<volume>1</volume>
<contexts>
<context position="5961" citStr="Ingria and Pustejovsky (2002)" startWordPosition="939" endWordPosition="942">o determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and Gaizauskas (2002), inter alia. Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses. It is based on Allen’s (1984) relations and a variation of Vendler’s (1967) classification of verbs. It defines XML elements to annotate time expressions, events, and “signals”. The SIGNAL tag marks sections of text indicating a temporal relation. It includes function words such as later and not. TimeML also features elements to connect entities using different types of links, most notably temporal links, TLINKs, t</context>
</contexts>
<marker>Ingria, Pustejovsky, 2002</marker>
<rawString>Bob Ingria and James Pustejovsky. 2002. Specification for TimeML 1.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Anders Berglund</author>
<author>Magnus Danielsson</author>
<author>Pierre Nugues</author>
</authors>
<title>Automatic text-to-scene conversion in the traffic accident domain.</title>
<date>2005</date>
<booktitle>In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1073--1078</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="1225" citStr="Johansson et al., 2005" startWordPosition="177" endWordPosition="180">s the generated scene to visualize events. To create a consistent animation, Carsim extracts the participants mentioned in a text and identifies what they do. In this paper, we focus on the extraction of temporal relations between actions. We first describe how we detect time expressions and events. We then present a machine learning technique to order the sequence of events identified in the narratives. We finally report the results we obtained. 1 Extraction of Temporal Information and Scene Visualization Carsim is a program that generates 3D scenes from narratives describing road accidents (Johansson et al., 2005; Dupuy et al., 2001). It considers authentic texts, generally collected from web sites of Swedish newspapers or transcribed from handwritten accounts by victims of accidents. One of Carsim’s key features is that it animates the generated scene to visualize events described in the narrative. The text below, a newspaper article with its translation into English, illustrates the goals and challenges of it. We bracketed the entities, time expressions, and events and we annotated them with identifiers, denoted respectively oz, tj, and ek: En {bussolycka}e1 i södra Afghanistan krävdee2 {på torsdage</context>
</contexts>
<marker>Johansson, Berglund, Danielsson, Nugues, 2005</marker>
<rawString>Richard Johansson, Anders Berglund, Magnus Danielsson, and Pierre Nugues. 2005. Automatic text-to-scene conversion in the traffic accident domain. In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, pages 1073–1078, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Lascarides</author>
<author>Nicholas Asher</author>
</authors>
<title>Temporal interpretation, discourse relations, and common sense entailment.</title>
<date>1993</date>
<journal>Linguistics &amp; Philosophy,</journal>
<volume>16</volume>
<issue>5</issue>
<contexts>
<context position="5012" citStr="Lascarides and Asher (1993)" startWordPosition="789" endWordPosition="792">ably started with Reichenbach (1947), who proposed the distinction between the point of speech, point of reference, and point of event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extract automatically temporal relations between events. A basic observation is that the temporal order of events is related to their narrative order. Dowty (1986) investigated it and formulated a Temporal Discourse Interpretation Principle to interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another examp</context>
</contexts>
<marker>Lascarides, Asher, 1993</marker>
<rawString>Alex Lascarides and Nicholas Asher. 1993. Temporal interpretation, discourse relations, and common sense entailment. Linguistics &amp; Philosophy, 16(5):437–493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenjie Li</author>
<author>Kam-Fai Wong</author>
<author>Guihong Cao</author>
<author>Chunfa Yuan</author>
</authors>
<title>Applying machine learning to Chinese temporal relation resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04),</booktitle>
<pages>582--588</pages>
<location>Barcelona.</location>
<contexts>
<context position="5653" citStr="Li et al. (2004)" startWordPosition="890" endWordPosition="893">cal framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and Gaizauskas (2002), inter alia. Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses. It is based on Allen’s (1984) relations and a variation of Vendler’s (1967) classification of verbs. It define</context>
</contexts>
<marker>Li, Wong, Cao, Yuan, 2004</marker>
<rawString>Wenjie Li, Kam-Fai Wong, Guihong Cao, and Chunfa Yuan. 2004. Applying machine learning to Chinese temporal relation resolution. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), pages 582–588, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Barry Schiffman</author>
<author>Jianping Zhang</author>
</authors>
<title>Inferring temporal ordering of events in news.</title>
<date>2003</date>
<booktitle>In Human Language Technology Conference (HLT’03),</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="5447" citStr="Mani et al. (2003)" startWordPosition="853" endWordPosition="856"> (1986) investigated it and formulated a Temporal Discourse Interpretation Principle to interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) described a complex logical framework to deal with events in simple past and pluperfect sentences. Hitzeman et al. (1995) proposed a constraintbased approach taking into account tense, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and Gaizauskas (2002), inter alia. Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification lan</context>
</contexts>
<marker>Mani, Schiffman, Zhang, 2003</marker>
<rawString>Inderjeet Mani, Barry Schiffman, and Jianping Zhang. 2003. Inferring temporal ordering of events in news. In Human Language Technology Conference (HLT’03), Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Recent developments in temporal information extraction.</title>
<date>2003</date>
<booktitle>In Nicolas Nicolov and Ruslan Mitkov, editors, Proceedings of RANLP’03.</booktitle>
<publisher>John Benjamins.</publisher>
<marker>Mani, 2003</marker>
<rawString>Inderjeet Mani. 2003. Recent developments in temporal information extraction. In Nicolas Nicolov and Ruslan Mitkov, editors, Proceedings of RANLP’03. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kauffman.</publisher>
<contexts>
<context position="18000" citStr="Quinlan, 1993" startWordPosition="2894" endWordPosition="2895">stance: 0, 1, 2, 3, 4, greater than 4. • punctuationSignDistance: 0, 1, 2, 3, 4, 5, greater than 5. The four other decision trees consider more events but use similar features. The values for the ...Distance features are of course greater. 6.3 Temporal Loops The process described above results in an overgeneration of temporal links. As some of them may be conflicting, a post-processing module reorganizes them and discards the temporal loops. The initial step of the loop resolution assigns each link with a score. This score is created by the decision trees and is derived from the C4.5 metrics (Quinlan, 1993). It reflects the accuracy of the leaf as well as the overall accuracy of the decision tree in question. The score for links generated from heuristics is rule dependent. The loop resolution algorithm begins with an empty set of orderings. It adds the partial orderings to the set if their inclusion doesn’t introduce a temporal conflict. It first adds the links with the highest scores, and thus, in each temporal loop, the ordering with the lowest score is discarded. 7 Experimental Setup and Evaluation As far as we know, there is no available timeannotated corpus in Swedish, which makes the evalu</context>
<context position="19416" citStr="Quinlan, 1993" startWordPosition="3128" endWordPosition="3129"> the reports is complex because of their variability in style and length. Their size ranges from a couple of sentences to more than a page. The amount of details is overwhelming in some reports, while in others most of the information is implicit. The complexity of the accidents described ranges from simple accidents with only one vehicle to multiple collisions with several participating vehicles and complex movements. We manually annotated a subset of our corpus consisting of 25 texts, 476 events and 1,162 temporal links. We built the trees automatically from this set using the C4.5 program (Quinlan, 1993). Our training set is relatively small and the number of features we use relatively large for the set size. This can produce a training overfit. However, C4.5, to some extent, makes provision for this and prunes the decision trees. We evaluated three aspects of the temporal information extraction modules: the detection and interpretation of time expressions, the detection and interpretation of events, and the quality of the final ordering. We report here the detection of events and the final ordering. 389 Feature Ncorrect Nerroneous Correct Tense 179 1 99.4% Aspect 161 19 89.4% Class 150 30 83</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kauffman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Reichenbach</author>
</authors>
<title>Elements of Symbolic Logic.</title>
<date>1947</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="4421" citStr="Reichenbach (1947)" startWordPosition="699" endWordPosition="701">airs of intervals. Allen’s (1984) 13 temporal relations are a widely accepted example of this. A third approach is to reify events, to quantify them existentially, and to connect them to other objects using predicates based on action verbs and their modifiers (Davidson, 1967). The sentence John saw Mary in London on Tuesday is then translated into the logical form: ∃E[Saw(E, j, m)∧Place(E, l)∧Time(E, t)]. Description of relations between time, events, and verb tenses has also attracted a considerable interest, especially in English. Modern work on temporal event analysis probably started with Reichenbach (1947), who proposed the distinction between the point of speech, point of reference, and point of event in utterances. This separation allows for a systematic description of tenses and proved to be very powerful. Many authors proposed general principles to extract automatically temporal relations between events. A basic observation is that the temporal order of events is related to their narrative order. Dowty (1986) investigated it and formulated a Temporal Discourse Interpretation Principle to interpret the advance of narrative time in a sequence of sentences. Lascarides and Asher (1993) describe</context>
</contexts>
<marker>Reichenbach, 1947</marker>
<rawString>Hans Reichenbach. 1947. Elements of Symbolic Logic. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Setzer</author>
<author>Robert Gaizauskas</author>
</authors>
<title>A pilot study on annotating temporal relations in text.</title>
<date>2001</date>
<booktitle>In ACL 2001, Workshop on Temporal and Spatial Information Processing,</booktitle>
<pages>73--80</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="15448" citStr="Setzer and Gaizauskas (2001)" startWordPosition="2495" endWordPosition="2498">a set of decision trees. We apply each tree to sequences of events where it decides the order between two of the events in each sequence. If e1,..., en are the events in the sequence they appear in the text, the trees correspond to the following functions: fdt1(ei, ei+1) trel(ei, ei+1) fdt2(ei, ei+1, ei+2) trel(ei, ei+1) fdt3(ei, ei+1, ei+2) trel(ei+1, ei+2) fdt4(ei, ei+1, ei+2) trel(ei, ei+2) fdt5(ei, ei+1, ei+2, ei+3) trel(ei, ei+3) The possible output values of the trees are: simultaneous, after, before, is_included, includes, and none. These values correspond to the relations described by Setzer and Gaizauskas (2001). The first decision tree should capture more general relations between two adjacent events without the need of a context. Decision trees dt2 and dt3 extend the context by one event to the left respectively one event to the right. They should capture more specific phenomena. However, they are not always applicable as we never apply a decision 388 tree when there is a time expression between any of the events involved. In effect, time expressions “reanchor” the narrative temporally, and we noticed that the decision trees performed very poorly across time expressions. We complemented the decisio</context>
<context position="20845" citStr="Setzer and Gaizauskas (2001)" startWordPosition="3372" endWordPosition="3375">simplified definition of what an event is, and that the manual annotation and evaluation were both done using the same definition (i.e. all verbs, verb groups, and a small number of nouns are events). The system detected 584 events correctly, overdetected 3, and missed 26. This gives a recall of 95.7%, a precision of 99.4%, and an F-measure of 97.5%. The feature detection is more interesting and Table 1 shows an evaluation of it. We carried out this evaluation on the first 20 texts of the test corpus. 7.2 Evaluation of Final Ordering We evaluated the final ordering with the method proposed by Setzer and Gaizauskas (2001). Their scheme is comprehensive and enables to compare the performance of different systems. Description of the Evaluation Method. Setzer and Gaizauskas carried out an inter-annotator agreement test for temporal relation markup. When evaluating the final ordering of a text, they defined the set E of all the events in the text and the set T of all the time expressions. They computed the set (E ∪ T) × (E ∪ T) and they defined the sets S`, I`, and B` as the transitive closures for the relations simultaneous, includes, and before, respectively. If S`k and S`rrepresent the set S` for the answer key</context>
</contexts>
<marker>Setzer, Gaizauskas, 2001</marker>
<rawString>Andrea Setzer and Robert Gaizauskas. 2001. A pilot study on annotating temporal relations in text. In ACL 2001, Workshop on Temporal and Spatial Information Processing, pages 73–80, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Setzer</author>
<author>Robert Gaizauskas</author>
</authors>
<title>On the importance of annotating temporal event-event relations in text.</title>
<date>2002</date>
<booktitle>In LREC 2002, Workshop on Annotation Standards for Temporal Information in Natural Language.</booktitle>
<contexts>
<context position="5822" citStr="Setzer and Gaizauskas (2002)" startWordPosition="915" endWordPosition="918">se, aspect, temporal adverbials, and rhetorical structure to analyze a discourse. Recently, groups have used machine learning techniques to determine temporal relations. They trained automatically classifiers on handannotated corpora. Mani et al. (2003) achieved the best results so far by using decision trees to order partially events of successive clauses in English texts. Boguraev and Ando (2005) is another example of it for English and Li et al. (2004) for Chinese. 3 Annotating Texts with Temporal Information Several schemes have been proposed to annotate temporal information in texts, see Setzer and Gaizauskas (2002), inter alia. Many of them were incompatible or incomplete and in an effort to reconcile and unify the field, Ingria and Pustejovsky (2002) introduced the XML-based Time markup language (TimeML). TimeML is a specification language whose goal is to capture most aspects of temporal relations between events in discourses. It is based on Allen’s (1984) relations and a variation of Vendler’s (1967) classification of verbs. It defines XML elements to annotate time expressions, events, and “signals”. The SIGNAL tag marks sections of text indicating a temporal relation. It includes function words such</context>
</contexts>
<marker>Setzer, Gaizauskas, 2002</marker>
<rawString>Andrea Setzer and Robert Gaizauskas. 2002. On the importance of annotating temporal event-event relations in text. In LREC 2002, Workshop on Annotation Standards for Temporal Information in Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Linguistics in Philosophy.</title>
<date>1967</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, New York.</location>
<marker>Vendler, 1967</marker>
<rawString>Zeno Vendler. 1967. Linguistics in Philosophy. Cornell University Press, Ithaca, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>