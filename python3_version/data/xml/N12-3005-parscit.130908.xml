<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012202">
<title confidence="0.99118">
An Interactive Humanoid Robot Exhibiting Flexible Sub-Dialogues*
</title>
<author confidence="0.869629">
Heriberto Cuay´ahuitl Ivana Kruijff-Korbayov´a
</author>
<affiliation confidence="0.690755">
DFKI GmbH DFKI GmbH
</affiliation>
<email confidence="0.94">
hecu01@dfki.de ivana.kruijff@dfki.de
</email>
<sectionHeader confidence="0.992634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999913833333333">
We demonstrate a conversational humanoid
robot that allows users to follow their own
dialogue structures. Our system uses a hi-
erarchy of reinforcement learning dialogue
agents, which support transitions across
sub-dialogues in order to relax the strict-
ness of hierarchical control and therefore
support flexible interactions. We demon-
strate our system with the Nao robot play-
ing two versions of a Quiz game. Whilst
language input and dialogue control is au-
tonomous or wizarded, language output is
provided by the robot combining verbal and
non-verbal contributions. The novel fea-
tures in our system are (a) the flexibility
given to users to navigate flexibly in the in-
teraction; and (b) a framework for investi-
gating adaptive and flexible dialogues.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999471266666667">
Hierarchical Dialogue Control (HDC) consists of
behaviours or discourse segments at different lev-
els of granularity executed from higher to lower
level. For example, a dialogue agent can invoke a
sub-dialogue agent, which can also invoke a sub-
sub-dialogue agent, and so on. Task-oriented di-
alogues have shown evidence of following hierar-
chical structures (Grosz and Sidner, 1986; Litman
and Allen, 1987; Clark, 1996). Practically speak-
ing, HDC offers the following benefits. First,
modularity helps to specify sub-dialogues that
may be easier to specify than the entire full dia-
logues. Second, sub-dialogues may include only
relevant dialogue knowledge (e.g. subsets of dia-
logue acts), thus reducing significantly their com-
</bodyText>
<footnote confidence="0.649066">
•Funding by the EU-FP7 project ALIZ-E (ICT-248116)
is gratefully acknowledged.
</footnote>
<figureCaption confidence="0.997395">
Figure 1: Hierarchies of dialogue agents with strict
(top down) and flexible control (partial top down).
</figureCaption>
<bodyText confidence="0.998198115384615">
plexity. Third, sub-dialogues can be reused when
dealing with new behaviours. In this paper we dis-
tinguish two types of hierarchical dialogue con-
trol: strict and flexible. These two forms of dia-
logue control are shown in Figure 1. It can be ob-
served that strict HDC is based on a pure top down
execution, and flexible HDC is based on a com-
bined hierarchical and graph-based execution.
The main limitation of strict HDC is that
human-machine interactions are rigid, i.e. the
user cannot change the imposed dialogue struc-
ture. A more natural way of interaction is by re-
laxing the dialogue structure imposed by the con-
versational machine. The advantage of flexible
HDC is that interactions become less rigid be-
cause it follows a partially specified hierarchical
control, i.e. the user is allowed to navigate across
the available sub-dialogues. In addition, another
important property of the latter form of HDC is
that we can model flexible dialogue structures not
only driven by the user but also by the machine.
The latter requires the machine to learn the dia-
logue structure in order to behave in an adaptive
way. The rest of the paper describes a demo sys-
tem exhibiting both types of behaviour, based on
a reinforcement learning dialogue framework.
</bodyText>
<figure confidence="0.999238666666667">
(a) strict hierachical (b) flexible hierachical
dialogue control dialogue control
Sub-dialogue1 Sub-dialogue2
Dialogue
Sub-dialogue1 Sub-dialogue2
Dialogue
</figure>
<page confidence="0.987403">
17
</page>
<note confidence="0.772769">
Proceedings of the NAACL-HLT 2012: Demonstration Session, pages 17–20,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.849833" genericHeader="method">
2 Hierarchical Reinforcement Learning
</sectionHeader>
<subsectionHeader confidence="0.758272">
Dialogue Agents with Flexible Control
</subsectionHeader>
<bodyText confidence="0.9999335">
Our dialogue controllers use hierarchical rein-
forcement learning as in (Cuay´ahuitl et al., 2010).
We extend such a formalization through a hierar-
chy of dialogue agents defined with the following
</bodyText>
<equation confidence="0.5214795">
tuples:Mi = &lt;Si Ai Ti R, 3&amp;quot; Lz. Ui ryi 8i &gt;
j j, j, j&apos; 7&apos; 7&apos; j, j, j ,
</equation>
<bodyText confidence="0.999921512820513">
where Sij is a set of states, Aij is a set of actions,
Tji is a stochastic state transition function, Rij is
a reward function, Lij is a grammar that specifies
tree-based state representations, Uij is a finite set
of user actions (e.g. user dialogue acts), ryij is a
finite set of models that subtask Mij is being al-
lowed to transition to, and 8ij = P(m′ E ryij|m E
ryij, u E Uij) is a stochastic model transition func-
tion1 that specifies the next model m′ given model
m and user action u. Although the hierarchy of
agents can be fully-connected when all models
are allowed to transition from a given particu-
lar model (avoiding self-transitions), in practice,
we may want our hierarchy of agents partially-
connected, i.e. when ryij is a subset of subtasks
that agent Mij is allowed to transition to.
We implemented a modified version of the
HSMQ-Learning algorithm (Dietterich, 2000) to
simultaneously learn a hierarchy of policies 71ij.
This algorithm uses a stack of subtasks and op-
erates as illustrated in Figure 2. If during the ex-
ecution of a subtask the user decides to jump to
another subtask, i.e. to change to another sub-
dialogue, the flexible execution of subtasks allows
each subtask to be interrupted in two ways. In the
first case, we check whether the new (active) sub-
task is already on the stack of subtasks to execute.
This would be the case if it was a parent of the
current subtask. In this case, we terminate exe-
cution of all intervening subtasks until we reach
the parent subtask, which would be the new ac-
tive subtask. Notice that termination of all inter-
vening subtasks prevents the stack from growing
infinitely. In the second case, the current subtask
is put on hold, and if the new active subtask is
not already on the stack of subtasks to execute, it
is pushed onto the stack and control is passed to
it. Once the new subtask terminates its execution,
control is transferred back to the subtask on hold.
</bodyText>
<footnote confidence="0.988055666666667">
1This is a very relevant feature in dialogue agents in order
to allow users to say and/or do anything at anytime, and the
learning agents have to behave accordingly.
</footnote>
<figureCaption confidence="0.913173">
Figure 2: Hypothetical operations of stack-based hier-
archical dialogue controllers. Whilst the fourth opera-
tion from left to right is not allowed in strict HDC, all
stack operations are allowed in flexible HDC.
</figureCaption>
<bodyText confidence="0.999937538461538">
These kinds of transitions can be seen as high-
level transitions in the state space. They can also
be seen as the mechanism to transition from any
state to any other in the hierarchy. To do that we
maintain an activity status for each subtask Mij,
where only one subtask is allowed to be active at
a time. We maintain a knowledge-rich state that
keeps the dialogue history in order to initialize
or reinitialize states of each subtask accordingly.
Since there is learning when new subtasks are in-
voked and no learning when they are interrupted,
this algorithm maintains its convergence proper-
ties to optimal context-independent policies.
</bodyText>
<sectionHeader confidence="0.94438" genericHeader="method">
3 A Hierarchy of Dialogue Agents for
</sectionHeader>
<subsectionHeader confidence="0.559512">
Playing Quiz Games
</subsectionHeader>
<bodyText confidence="0.99750775">
We use a small hierarchy of dialogue agents—
for illustration purposes—with one parent agent
and two children agents (‘robot asks’ and ‘user
asks’). Thus, the hierarchy of agents can ask the
user questions, and vice-versa, the user can ask
the robot questions (described in the next section).
Both conversants can play multiple rounds with a
predefined number of questions.
Due to space restrictions, we describe the hi-
erarchy of agents only briefly. The set of states
and actions use relational representations (they
can be seen as trees) in order to specify the
state-action space compactly, which can grow as
more features or games are integrated. Dialogue
and game features are included so as to inform
the agents of possible situations in the interac-
tion. The action sets use constrained spaces, i.e.
only a subset of actions is available at each state
based on the relational representations. For ex-
ample, the action Request(PlayGame) +— x0
is valid for the dialogue state x0 expressed as
Salutation(greeting) n UserName(known) n
PlayGame(unknown). The sets of primitive
actions (80 in total) assume verbal behaviours
</bodyText>
<figure confidence="0.997908178571429">
dialogue
sub-
dialogue1
dialogue
sub-
dialogue2
sub-
dialogue1
dialogue
sub-
dialogue1
dialogue
dialogue
Initial
stack
Popping
Pushing
&apos;dialogue&apos;
Popping
&apos;sub-dialogue1&apos; &apos;dialogue&apos;
Pushing
&apos;sub-dialogue1&apos;
Popping
&apos;sub-dialogue2&apos;
Pushing
&apos;sub-dialogue2&apos;
(two siblings
in the stack)
</figure>
<page confidence="0.990183">
18
</page>
<bodyText confidence="0.999328214285714">
with a mapping to non-verbal ones, some sam-
ple dialogue act types are as follows: requests,
apologies, confirmations, provide information,
acknowledgements, feedback, non-verbal expres-
sions, game-related actions. The transition func-
tions use pre-defined parameters, their training
from data is left as future work. The reward func-
tion addresses efficient and effective interactions
by penalizing dialogue length and encouraging to
continue playing. The dialogue agents learnt their
behaviour by interacting with a stochastic simu-
lated user, where the user responses eventually
required transitions across agents. A sample dia-
logue with flexible interaction is shown in Fig. 3.
</bodyText>
<sectionHeader confidence="0.996475" genericHeader="method">
4 A Humanoid Robot Integrated System
</sectionHeader>
<bodyText confidence="0.959073944444445">
Figure 4 shows the robot’s integrated system,
which equips the robot with the following capa-
bilities: listening, talking, seeing and moving.2 A
sample interaction assuming wizarded behaviour
is as follows. The user says something to the robot
(e.g. ‘ask me a question’) and the wizard selects
a user dialogue act for the corresponding utter-
ance such as ‘Request(Question)’. Then the di-
alogue manager selects and executes the learned
action by querying/updating the game move gen-
erator and user model components, and by pass-
ing a dialogue act to the language generation and
motor control components. The former provides
the corresponding text to the speech synthesizer
and the latter provides the corresponding non-
verbal behaviour. Then the dialogue manager ob-
serves its new dialogue state, and suggests the
next actions—based on its dialogue policies and
user simulations—in the wizard-of-Oz GUI, see
Figure 5. From this setting, if we remove the
wizard then the system can behave autonomously,
where user inputs are derived from the language
and gesture understanding components.
The attractiveness of this kind of set-up is the
smooth transition from purely wizarded conver-
sational behaviour to fully autonomous behaviour,
where the dialogue policies can be tested and eval-
2We use off-the-shelf technologies such as Sphinx /
Julius / HTK for speech recognition, OpenCV for ges-
ture recognition, Acapela and Mary for speech synthe-
sis, HRL-based dialogue management (as described above),
OpenCCG for language parsing and language generation,
Weka and JavaBayes for maintaining a probabilistic and per-
sonalized user profile of asked and answered questions, the
URBI middleware (www.gostai.com), and the NAO hu-
manoid robot (www.aldebaran-robotics.com).
</bodyText>
<table confidence="0.997368195121951">
SYS Hi, my name is NAO, and you?
USR I am Peter
SYS Nice to meet you Peter
USR Do you want to Play a Quiz game?
Ask me questions [jump to ‘robot asks’]
SYS The first question is.
USR What is a typical magic instrument?
SYS Your choices are: One, guitar. Two, drums.
USR Three ,violin. Four, flute. What is your choice?
SYS Number two
USR That is not quite right. Do you have another choice?
Maybe number three
The correct answer is number four, flute.
The next question is: which one of these is
an important artificial channel of the central America?
Your choices are: One, channel five. Two, Panama canal.
Three, Suez canal. Four, English channel.
What is your choice?
Now I want to ask you questions [jump to ‘user asks’]
SYS Ask me the first question.
USR What does water become at the temperature of
SYS zero degrees?
USR What are my choices?
SYS Your choices are:
USR One, condensation. Two, ice. Three, steam.
SYS I choose number one
USR That is incorrect.
SYS So what is the right answer?
USR The correct answer is number two.
SYS Okay, ask me another question.
USR The next question is: through which breach did
the Italian army entered into Rome in 1870?
Your choices are: One, porta venezia. Two, porta pia.
Three, porta pazienza. Four, porta nuova.
What is your choice?
Paris
Let’s stop playing. [jump to ‘root’]
SYS Did you like playing the Quiz Game?
USR Yes
SYS I am glad to hear that.
SYS It was nice playing with you, see you soon. Bye!
</table>
<figureCaption confidence="0.948624333333333">
Figure 3: Sample dialogue with non-strict hierarchical
control. The groups of utterances represent activity
in different sub-dialogues in the hierarchy of agents.
Note that the user is allowed to override the imposed
dialogue structure. For instance, when the user says
‘Ask me questions’ the agent interrupts the execution
of the root subtask and transitions to the subtask ‘robot
asks’. Similarly, the sub-dialogues do not need to follow
their imposed structure and the user is allowed to talk
about previous and unadressed sub-dialogues such as
the sudden switch from ‘robot asks’ to ‘user asks’.
Figure 4: High-level architecture of our talking robot.
</figureCaption>
<figure confidence="0.9975884">
Game Move
Generator
Parser,
Dialogue Act
Classifier
Speech Recognizer,
Voice Act. Detector,
Audio Front End
ASR
result
ASR
result
query,
questions,
answers
User
dialogue
act
Gesture
Act
Dialogue Manager
Gesture
Recognizer
Wizard-of-Oz
GUI
Dialogue acts System
dialogue
act
Middleware
Gesture
act
Motor
Control
System
dialogue
Act
System
Dialogue
act
user,
game
results
Speech
Synthesizer
Language
Generator
User
Model
Text
Text
</figure>
<page confidence="0.775713">
19
</page>
<figureCaption confidence="0.999111857142857">
Figure 5: Screen shot of the wizard-of-Oz GUI, where
the dialogue policies and user simulations suggest
highlighted actions to the wizard. This setting allows
fully-wizarded and (semi-) autonomous behaviour.
Figure 6: The Nao robot greeting a user prior to play-
ing a Quiz game. The pieces of paper on the table are
the Quiz questions the child asks the robot.
</figureCaption>
<bodyText confidence="0.999822125">
uated with (semi-) autonomous behaviour. We use
this framework to investigate long-term human-
robot interaction, in particular child-robot inter-
actions for educational purposes. Figure 6 shows
a scene from a pilot evaluation, where the robot
and a child are visibly engaged with each other. A
complete evaluation with simulated and real dia-
logues will be reported in a forthcoming paper.
</bodyText>
<sectionHeader confidence="0.99556" genericHeader="conclusions">
5 Discussion and Summary
</sectionHeader>
<bodyText confidence="0.999979787878788">
Typically, conversational interfaces impose a di-
alogue structure on the user. Even in dialogue
systems with mixed-initiative interaction that give
flexibility to the user in terms of providing more
than one piece of information at a time, the
user is hardly allowed to navigate flexibly during
the interaction. Notable exceptions without dia-
logue optimization are (Rudnicky and Wu, 1999;
Lemon et al., 2001; Larsson, 2002; Foster et al.,
2006). We believe that Hierarchical Reinforce-
ment Learning with global state transitions is an
interesting method to optimize (sub-) dialogues at
different levels of granularity, where the design of
action selection might not be easy to hand-craft.
On the one hand, our HDCs can be applied to
dialogues with user-driven topic shift, where the
user can take control of the interaction by navigat-
ing across sub-dialogues and the system has to re-
spond accordingly. On the other hand, our HDCs
can be applied to dialogues with system-driven
topic shift, where the system can itself terminate a
sub-dialogue, perhaps by inferring the user’s emo-
tional and/or situational state, and the system has
to switch itself to another sub-dialogue.
We have described a conversational humanoid
robot that allows users to follow their own dia-
logue structures. The novelty in our system is
its flexible hierarchical dialogue controller, which
extends strict hierarchical control with transitions
across sub-controllers. Suggested future work
consists in training and evaluating our humanoid
robot from real interactions using either partially
specified or fully learnt dialogue structures.
</bodyText>
<sectionHeader confidence="0.999111" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999459103448276">
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
H. Cuay´ahuitl, S. Renals, O. Lemon, and H. Shi-
modaira. 2010. Evaluation of a hierarchical rein-
forcement learning spoken dialogue system. Com-
puter Speech and Language, 24(2):395–429.
T. Dietterich. 2000. An overview of MAXQ hi-
erarchical reinforcement learning. In Symposium
on Abstraction, Reformulation, and Approximation
(SARA), pages 26–44.
M. E. Foster, T. By, M. Rickert, and A. Knoll. 2006.
Human-robot dialogue for joint construction tasks.
In ICMI, pages 68–71.
B. Grosz and C. Sidner. 1986. Attention, intentions
and the structure of discourse. Computational Lin-
guistics, 12(3):175–204.
S. Larsson. 2002. Issue-Based Dialogue Manage-
ment. Ph.D. thesis, University of Goteborg.
O. Lemon, A. Bracy, A. Gruenstein, and S. Peters.
2001. The WITAS multi-modal dialogue system I.
In EUROSPEECH, Aalborg, Denmark.
D. Litman and J. Allen. 1987. A plan recognition
model for subdialogues in conversations. Cognitive
Science, 11:163–200.
A. Rudnicky and W. Wu. 1999. An agenda-based
dialogue management architecture for spoken lan-
guage systems. In IEEE Workshop on Automatic
Speech Recognition and Understanding (ASRU),
pages 337–340, Keystone, Colorado, USA, Dec.
</reference>
<page confidence="0.994868">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.437131">
<title confidence="0.999969">Interactive Humanoid Robot Exhibiting Flexible</title>
<author confidence="0.996325">Heriberto Cuay´ahuitl Ivana Kruijff-Korbayov´a</author>
<affiliation confidence="0.996059">DFKI GmbH DFKI GmbH</affiliation>
<address confidence="0.45845">hecu01@dfki.de ivana.kruijff@dfki.de</address>
<abstract confidence="0.997649631578947">We demonstrate a conversational humanoid robot that allows users to follow their own dialogue structures. Our system uses a hierarchy of reinforcement learning dialogue agents, which support transitions across sub-dialogues in order to relax the strictness of hierarchical control and therefore support flexible interactions. We demonstrate our system with the Nao robot playing two versions of a Quiz game. Whilst language input and dialogue control is autonomous or wizarded, language output is provided by the robot combining verbal and non-verbal contributions. The novel features in our system are (a) the flexibility given to users to navigate flexibly in the interaction; and (b) a framework for investigating adaptive and flexible dialogues.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1359" citStr="Clark, 1996" startWordPosition="200" endWordPosition="201"> novel features in our system are (a) the flexibility given to users to navigate flexibly in the interaction; and (b) a framework for investigating adaptive and flexible dialogues. 1 Introduction Hierarchical Dialogue Control (HDC) consists of behaviours or discourse segments at different levels of granularity executed from higher to lower level. For example, a dialogue agent can invoke a sub-dialogue agent, which can also invoke a subsub-dialogue agent, and so on. Task-oriented dialogues have shown evidence of following hierarchical structures (Grosz and Sidner, 1986; Litman and Allen, 1987; Clark, 1996). Practically speaking, HDC offers the following benefits. First, modularity helps to specify sub-dialogues that may be easier to specify than the entire full dialogues. Second, sub-dialogues may include only relevant dialogue knowledge (e.g. subsets of dialogue acts), thus reducing significantly their com•Funding by the EU-FP7 project ALIZ-E (ICT-248116) is gratefully acknowledged. Figure 1: Hierarchies of dialogue agents with strict (top down) and flexible control (partial top down). plexity. Third, sub-dialogues can be reused when dealing with new behaviours. In this paper we distinguish tw</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cuay´ahuitl</author>
<author>S Renals</author>
<author>O Lemon</author>
<author>H Shimodaira</author>
</authors>
<title>Evaluation of a hierarchical reinforcement learning spoken dialogue system.</title>
<date>2010</date>
<journal>Computer Speech and Language,</journal>
<volume>24</volume>
<issue>2</issue>
<marker>Cuay´ahuitl, Renals, Lemon, Shimodaira, 2010</marker>
<rawString>H. Cuay´ahuitl, S. Renals, O. Lemon, and H. Shimodaira. 2010. Evaluation of a hierarchical reinforcement learning spoken dialogue system. Computer Speech and Language, 24(2):395–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dietterich</author>
</authors>
<title>An overview of MAXQ hierarchical reinforcement learning. In</title>
<date>2000</date>
<booktitle>Symposium on Abstraction, Reformulation, and Approximation (SARA),</booktitle>
<pages>26--44</pages>
<contexts>
<context position="4638" citStr="Dietterich, 2000" startWordPosition="734" endWordPosition="735">a finite set of models that subtask Mij is being allowed to transition to, and 8ij = P(m′ E ryij|m E ryij, u E Uij) is a stochastic model transition function1 that specifies the next model m′ given model m and user action u. Although the hierarchy of agents can be fully-connected when all models are allowed to transition from a given particular model (avoiding self-transitions), in practice, we may want our hierarchy of agents partiallyconnected, i.e. when ryij is a subset of subtasks that agent Mij is allowed to transition to. We implemented a modified version of the HSMQ-Learning algorithm (Dietterich, 2000) to simultaneously learn a hierarchy of policies 71ij. This algorithm uses a stack of subtasks and operates as illustrated in Figure 2. If during the execution of a subtask the user decides to jump to another subtask, i.e. to change to another subdialogue, the flexible execution of subtasks allows each subtask to be interrupted in two ways. In the first case, we check whether the new (active) subtask is already on the stack of subtasks to execute. This would be the case if it was a parent of the current subtask. In this case, we terminate execution of all intervening subtasks until we reach th</context>
</contexts>
<marker>Dietterich, 2000</marker>
<rawString>T. Dietterich. 2000. An overview of MAXQ hierarchical reinforcement learning. In Symposium on Abstraction, Reformulation, and Approximation (SARA), pages 26–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Foster</author>
<author>T By</author>
<author>M Rickert</author>
<author>A Knoll</author>
</authors>
<title>Human-robot dialogue for joint construction tasks.</title>
<date>2006</date>
<booktitle>In ICMI,</booktitle>
<pages>68--71</pages>
<contexts>
<context position="14375" citStr="Foster et al., 2006" startWordPosition="2302" endWordPosition="2305">robot and a child are visibly engaged with each other. A complete evaluation with simulated and real dialogues will be reported in a forthcoming paper. 5 Discussion and Summary Typically, conversational interfaces impose a dialogue structure on the user. Even in dialogue systems with mixed-initiative interaction that give flexibility to the user in terms of providing more than one piece of information at a time, the user is hardly allowed to navigate flexibly during the interaction. Notable exceptions without dialogue optimization are (Rudnicky and Wu, 1999; Lemon et al., 2001; Larsson, 2002; Foster et al., 2006). We believe that Hierarchical Reinforcement Learning with global state transitions is an interesting method to optimize (sub-) dialogues at different levels of granularity, where the design of action selection might not be easy to hand-craft. On the one hand, our HDCs can be applied to dialogues with user-driven topic shift, where the user can take control of the interaction by navigating across sub-dialogues and the system has to respond accordingly. On the other hand, our HDCs can be applied to dialogues with system-driven topic shift, where the system can itself terminate a sub-dialogue, p</context>
</contexts>
<marker>Foster, By, Rickert, Knoll, 2006</marker>
<rawString>M. E. Foster, T. By, M. Rickert, and A. Knoll. 2006. Human-robot dialogue for joint construction tasks. In ICMI, pages 68–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1321" citStr="Grosz and Sidner, 1986" startWordPosition="192" endWordPosition="195">mbining verbal and non-verbal contributions. The novel features in our system are (a) the flexibility given to users to navigate flexibly in the interaction; and (b) a framework for investigating adaptive and flexible dialogues. 1 Introduction Hierarchical Dialogue Control (HDC) consists of behaviours or discourse segments at different levels of granularity executed from higher to lower level. For example, a dialogue agent can invoke a sub-dialogue agent, which can also invoke a subsub-dialogue agent, and so on. Task-oriented dialogues have shown evidence of following hierarchical structures (Grosz and Sidner, 1986; Litman and Allen, 1987; Clark, 1996). Practically speaking, HDC offers the following benefits. First, modularity helps to specify sub-dialogues that may be easier to specify than the entire full dialogues. Second, sub-dialogues may include only relevant dialogue knowledge (e.g. subsets of dialogue acts), thus reducing significantly their com•Funding by the EU-FP7 project ALIZ-E (ICT-248116) is gratefully acknowledged. Figure 1: Hierarchies of dialogue agents with strict (top down) and flexible control (partial top down). plexity. Third, sub-dialogues can be reused when dealing with new behav</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention, intentions and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
</authors>
<title>Issue-Based Dialogue Management.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Goteborg.</institution>
<contexts>
<context position="14353" citStr="Larsson, 2002" startWordPosition="2300" endWordPosition="2301">ion, where the robot and a child are visibly engaged with each other. A complete evaluation with simulated and real dialogues will be reported in a forthcoming paper. 5 Discussion and Summary Typically, conversational interfaces impose a dialogue structure on the user. Even in dialogue systems with mixed-initiative interaction that give flexibility to the user in terms of providing more than one piece of information at a time, the user is hardly allowed to navigate flexibly during the interaction. Notable exceptions without dialogue optimization are (Rudnicky and Wu, 1999; Lemon et al., 2001; Larsson, 2002; Foster et al., 2006). We believe that Hierarchical Reinforcement Learning with global state transitions is an interesting method to optimize (sub-) dialogues at different levels of granularity, where the design of action selection might not be easy to hand-craft. On the one hand, our HDCs can be applied to dialogues with user-driven topic shift, where the user can take control of the interaction by navigating across sub-dialogues and the system has to respond accordingly. On the other hand, our HDCs can be applied to dialogues with system-driven topic shift, where the system can itself termi</context>
</contexts>
<marker>Larsson, 2002</marker>
<rawString>S. Larsson. 2002. Issue-Based Dialogue Management. Ph.D. thesis, University of Goteborg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Lemon</author>
<author>A Bracy</author>
<author>A Gruenstein</author>
<author>S Peters</author>
</authors>
<title>The WITAS multi-modal dialogue system I. In EUROSPEECH,</title>
<date>2001</date>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="14338" citStr="Lemon et al., 2001" startWordPosition="2296" endWordPosition="2299">from a pilot evaluation, where the robot and a child are visibly engaged with each other. A complete evaluation with simulated and real dialogues will be reported in a forthcoming paper. 5 Discussion and Summary Typically, conversational interfaces impose a dialogue structure on the user. Even in dialogue systems with mixed-initiative interaction that give flexibility to the user in terms of providing more than one piece of information at a time, the user is hardly allowed to navigate flexibly during the interaction. Notable exceptions without dialogue optimization are (Rudnicky and Wu, 1999; Lemon et al., 2001; Larsson, 2002; Foster et al., 2006). We believe that Hierarchical Reinforcement Learning with global state transitions is an interesting method to optimize (sub-) dialogues at different levels of granularity, where the design of action selection might not be easy to hand-craft. On the one hand, our HDCs can be applied to dialogues with user-driven topic shift, where the user can take control of the interaction by navigating across sub-dialogues and the system has to respond accordingly. On the other hand, our HDCs can be applied to dialogues with system-driven topic shift, where the system c</context>
</contexts>
<marker>Lemon, Bracy, Gruenstein, Peters, 2001</marker>
<rawString>O. Lemon, A. Bracy, A. Gruenstein, and S. Peters. 2001. The WITAS multi-modal dialogue system I. In EUROSPEECH, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>J Allen</author>
</authors>
<title>A plan recognition model for subdialogues in conversations.</title>
<date>1987</date>
<journal>Cognitive Science,</journal>
<pages>11--163</pages>
<contexts>
<context position="1345" citStr="Litman and Allen, 1987" startWordPosition="196" endWordPosition="199">erbal contributions. The novel features in our system are (a) the flexibility given to users to navigate flexibly in the interaction; and (b) a framework for investigating adaptive and flexible dialogues. 1 Introduction Hierarchical Dialogue Control (HDC) consists of behaviours or discourse segments at different levels of granularity executed from higher to lower level. For example, a dialogue agent can invoke a sub-dialogue agent, which can also invoke a subsub-dialogue agent, and so on. Task-oriented dialogues have shown evidence of following hierarchical structures (Grosz and Sidner, 1986; Litman and Allen, 1987; Clark, 1996). Practically speaking, HDC offers the following benefits. First, modularity helps to specify sub-dialogues that may be easier to specify than the entire full dialogues. Second, sub-dialogues may include only relevant dialogue knowledge (e.g. subsets of dialogue acts), thus reducing significantly their com•Funding by the EU-FP7 project ALIZ-E (ICT-248116) is gratefully acknowledged. Figure 1: Hierarchies of dialogue agents with strict (top down) and flexible control (partial top down). plexity. Third, sub-dialogues can be reused when dealing with new behaviours. In this paper we </context>
</contexts>
<marker>Litman, Allen, 1987</marker>
<rawString>D. Litman and J. Allen. 1987. A plan recognition model for subdialogues in conversations. Cognitive Science, 11:163–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rudnicky</author>
<author>W Wu</author>
</authors>
<title>An agenda-based dialogue management architecture for spoken language systems.</title>
<date>1999</date>
<booktitle>In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),</booktitle>
<pages>337--340</pages>
<location>Keystone, Colorado, USA,</location>
<contexts>
<context position="14318" citStr="Rudnicky and Wu, 1999" startWordPosition="2292" endWordPosition="2295">Figure 6 shows a scene from a pilot evaluation, where the robot and a child are visibly engaged with each other. A complete evaluation with simulated and real dialogues will be reported in a forthcoming paper. 5 Discussion and Summary Typically, conversational interfaces impose a dialogue structure on the user. Even in dialogue systems with mixed-initiative interaction that give flexibility to the user in terms of providing more than one piece of information at a time, the user is hardly allowed to navigate flexibly during the interaction. Notable exceptions without dialogue optimization are (Rudnicky and Wu, 1999; Lemon et al., 2001; Larsson, 2002; Foster et al., 2006). We believe that Hierarchical Reinforcement Learning with global state transitions is an interesting method to optimize (sub-) dialogues at different levels of granularity, where the design of action selection might not be easy to hand-craft. On the one hand, our HDCs can be applied to dialogues with user-driven topic shift, where the user can take control of the interaction by navigating across sub-dialogues and the system has to respond accordingly. On the other hand, our HDCs can be applied to dialogues with system-driven topic shift</context>
</contexts>
<marker>Rudnicky, Wu, 1999</marker>
<rawString>A. Rudnicky and W. Wu. 1999. An agenda-based dialogue management architecture for spoken language systems. In IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 337–340, Keystone, Colorado, USA, Dec.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>