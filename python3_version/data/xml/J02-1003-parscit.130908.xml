<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997541">
Generating Referring Expressions:
Boolean Extensions of the Incremental
Algorithm
</title>
<author confidence="0.98928">
Kees van Deemter*
</author>
<affiliation confidence="0.987299">
University of Brighton
</affiliation>
<bodyText confidence="0.976764166666667">
This paper brings a logical perspective to the generation of referring expressions, addressing
the incompleteness of existing algorithms in this area. After studying references to individual
objects, we discuss references to sets, including Boolean descriptions that make use of negated
and disjoined properties. To guarantee that a distinguishing description is generated whenever
such descriptions exist, the paper proposes generalizations and extensions of the Incremental
Algorithm of Dale and Reiter (1995).
</bodyText>
<sectionHeader confidence="0.996533" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999958730769231">
Generation of referring expressions (GRE) is a key task of most natural language gener-
ation (NLG) systems (e.g., Reiter and Dale 2000, Section 5.4). Regardless of the type of
knowledge base (KB) forming the input to the generator, many objects will not be des-
ignated in it via an ordinary proper name. A person like Mr. Jones, for example, may
be designated using an artificial name like #Jones083, if the name Jones is not uniquely
distinguishing. The same is true for a piece of furniture, a tree, or an atomic particle,
for instance, for which no proper name is in common use at all, or (in most cases) if
the generator tries to refer to an entire set of objects. In all such cases, the generator
has to “invent” a description that enables the hearer to identify the intended referent.
In the case of Mr. Jones, for example, the program could identify him by providing his
full name and address; in the case of a tree, some longer description may be necessary.
Henceforth, we will call the intended referent the target of the GRE algorithm.
The question that we set out to answer is whether existing GRE algorithms pro-
duce adequate descriptions whenever such descriptions exist: in short, whether these
algorithms are, as we shall say, complete. The paper brings a degree of formal preci-
sion to this issue and reveals a number of reasons why current GRE algorithms are
incomplete; we sketch remedies and discuss their consequences in terms of linguistic
coverage and computational tractability. We take the Incremental Algorithm (Dale and
Reiter 1995) to represent the state of the art in this area, and we minimize the devi-
ations from this algorithm. As a result, this paper might be read as an investigation
into how widely the ideas underlying the Incremental Algorithm can be used, and
the extent to which they may be generalized. The main generalization that we will
investigate involves complex Boolean combinations of properties, that is, descriptions
that involve more than a merely intersective (i.e., logically conjunctive) combination
of properties. Such generalizations are natural because the properties involved are im-
plicitly present in the KB, as we will explain; they become especially relevant when the
</bodyText>
<note confidence="0.87806925">
* Information Technology Research Institute (ITRI), University of Brighton, Lewes Road, Brighton BN2
4GJ, UK. E-mail: Kees.van.Deemter@itri.brighton.ac.uk.
© 2002 Association for Computational Linguistics
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.999177516129032">
algorithms are also generalized to generate references to sets, rather than individual
objects. But, before we arrive at these generalizations, we will identify and confront a
number of cases in which current GRE algorithms are incomplete even with respect
to merely intersective descriptions.
In this paper, we will deal with “first mention” descriptions only (unlike Dale
1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used
for generating the description is limited to a KB containing complete information about
which properties are true of each object. Also, we focus on “one shot” descriptions,
disregarding cases where an object is described through its relations with other ob-
jects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001).
More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content
of a description (i.e., the problem of content determination, for short), assuming that
any combination of properties can be expressed by the NLG module responsible for
linguistic realization. This modular approach allows us to separate logical aspects of
generation (which are largely language independent) from purely linguistic aspects,
and it allows the realization module to base its decisions on complete information
about which combination of properties is to be realized. Accordingly, when we write
Generation of Referring Expressions or GRE, we will refer specifically to determination of
the semantic content of a description. Analogously, the word description will refer to
the semantic content of a linguistic expression only. Note that our modular approach
makes it unnatural to assume that a description is always expressed by a single noun
phrase: if several sentences are needed, then so be it.
After summarizing the Incremental Algorithm in Section 2, in Section 3 we take a
closer look at the algorithm in its standard, “intersective” form, in which it identifies
an object by intersecting a number of atomic properties. We discuss cases in which
this algorithm fails to find an adequate description even though such a description
exists, and we propose a number of possible remedies. Having extablished a com-
pleteness result for a version of the intersective Incremental Algorithm, we turn to
questions of completeness that involve more complex Boolean combinations in Sec-
tion 4. In Section 5, we summarize the main results of our exploration and put them
in perspective.
</bodyText>
<sectionHeader confidence="0.792483" genericHeader="categories and subject descriptors">
2. Dale and Reiter (1995): The Incremental Algorithm
</sectionHeader>
<bodyText confidence="0.999657583333333">
The Incremental Algorithm of Dale and Reiter (1995) singles out a target object from
among some larger domain of entities. It does this by logically conjoining a num-
ber of properties found in a part of the KB that represents information shared be-
tween speaker and hearer. The authors observed that the problem of finding a (“Full
Brevity”) description that contains the minimum number of properties is computation-
ally intractable (i.e., NP Hard). They combined this with the known fact that speakers
often produce nonminimal descriptions anyway (e.g., Pechman 1989). Accordingly,
they proposed an algorithm that only approximates Full Brevity, while being of only
linear complexity. Our summary of the algorithm glosses over many details, yet still
allows us to discuss completeness. In particular, we disregard any special provisions
that might be made for the selection of head nouns because, arguably, this has to
involve realizational issues.1
</bodyText>
<footnote confidence="0.91242875">
1 Compare Dale and Reiter (1995), where head nouns are taken into account during content
determination. Head nouns can also be selected during linguistic realization or by interleaving of
content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and
Theune 1999).
</footnote>
<page confidence="0.994072">
38
</page>
<note confidence="0.372034">
van Deemter Generating Referring Expressions
</note>
<bodyText confidence="0.999324423076923">
The Incremental Algorithm produces a set L of properties P1,. . . , Pn such that their
logical conjunction forms a “distinguishing description” (Dale 1989) of the target object
r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have
the property Q), the intersection [[P1]] n · · · n [[Pn]] must equal the singleton set {r}.
It is a “hillclimbing” algorithm, which finds better and better approximations of the
target set {r} by accumulating more and more properties—hence the term Incremental.
There is no backtracking. Consequently, if some property Pi in L is made redundant
by later additions (i.e., when ([[P1]] n · · · n [[Pi − 1]] n [[Pi + 1]] n · · · n [[Pn]]) C [[Pi]]),
then Pi is retained as a member of L nevertheless.
In the full algorithm (see below, D&amp;RAtt), properties are analyzed as pairs consist-
ing of an Attribute and a Value. Attributes are ordered in a list A. If Ai precedes Aj in
A, then Ai is “more preferred than” Aj; as a consequence, Ai will be considered before
Aj by the algorithm. Suppose r is the target object, and D (the “domain”) is the set
of elements from which r is to be selected. The algorithm iterates through A; for each
Attribute Ai, it checks whether specifying a Value for that Attribute would rule out
at least one object that has not already been ruled out; if so, the Attribute is added
to L, with a suitable Value (FindBestValue, below). C is the set of “confusables” at
any given stage of the algorithm.2 Objects that are ruled out are removed from C. The
process of expanding L and contracting C continues until C = {r}; if and when this
condition is met, L is a distinguishing set of properties.
For easy generalizability, the algorithm will be cast in set-theoretic terms. We first
present a version that focuses on properties, without separating these into Attributes
and Values, and assume the properties themselves are ordered in a list P (cf. Reiter
and Dale 2000). This version of the algorithm will be called D&amp;RProp, or D&amp;R when
there is no risk of confusion. We assume that the domain contains one or more objects
other than the target object, the so-called distractors: thus, r E D but {r} =� D.
</bodyText>
<equation confidence="0.998030428571429">
L := 0 {L is initialized to the empty set}
C := D {C is initialized to the domain}
For each Pi E P do
If r E [[Pi]] &amp; C C� [[Pi]] {Pi removes distractors from C} then do
L := L U {Pi} {Property Pi is added to L}
C := C n [[Pi]] {All elements outside [[Pi]] are removed}
If C = {r} then Return L {Success}
</equation>
<bodyText confidence="0.954329545454546">
Return Failure {All properties in P have been tested, and still C =� {r}}
Assuming (as do Dale and Reiter [1995]) that the tests in the body of the loop take
some constant amount of time, the worst-case running time is on the order of na (i.e.,
O(na)), where na is the total number of properties. So, the algorithm has only linear
complexity.
A slightly closer approximation of Full Brevity can be achieved if Attributes and
Values are separated (Dale and Reiter 1995), allowing the algorithm to choose the
“best” Value for each Attribute. Given an Attribute, FindBestValue selects the Value
that removes most distractors while still including the target r. If no Value includes r,
the function returns nil. In case of a tie (i.e., no Value removes more distractors than
all others), FindBestValue chooses the least specific of the contestants. For example,
</bodyText>
<page confidence="0.9411435">
2 Thus, C contains r, unlike in Dale and Reiter (1995). The difference is purely presentational.
39
</page>
<note confidence="0.442394">
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.990415666666667">
when dog rules out as many distractors as chihuahua, chihuahua cannot be chosen. A
is the list of Attributes; L is the set of Attribute/Value combinations returned by the
algorithm. A further notational convention will be useful: Values will be identified
by two indices, the first of which identifies the Attribute. Thus, to denote Value j of
Attribute Ai, we write Vi,j. This version of the algorithm will be called D&amp;RAtt. The
initializations of L and D are omitted for brevity.
</bodyText>
<equation confidence="0.930680714285714">
For each Ai E A do
Vi,j = FindBestValue(r,Ai)
If r E [[Vi,j]]&amp; C �Z [[Vi,j]] then do
L := L U {Vi,j}
C := C n [[Vi,j]]
If C = {r} then Return L
Return Failure
</equation>
<bodyText confidence="0.999796333333333">
We will switch back and forth between D&amp;R and D&amp;RAtt, depending on what is
at stake. Like D&amp;R, D&amp;RAtt has linear complexity. This can be made precise in the
following way.3 If the running time of a call of FindBestValue(r,Ai) is a constant
times the number of Values of the Attribute Ai, then the worst-case running time of
D&amp;RAtt is O(nvna), where na equals the number of Attributes in the language and nv
the average number of Values of all Attributes.
</bodyText>
<listItem confidence="0.427481">
3. Completeness of the Incremental Algorithm
</listItem>
<bodyText confidence="0.99981975">
Some new definitions will be useful. A GRE algorithm is successful with respect to a
given situation (i.e., with respect to a KB and a target) if it produces a distinguishing
description of r in that situation. We will call an algorithm complete if it is successful
in every situation in which a distinguishing description exists. Success is not always
possible: the properties in the KB may not be sufficient for individuating a given object.
Such no-win situations will not be held against an algorithm.
The Incremental Algorithm generates descriptions that contain set intersection as
their only Boolean operation. We define a GRE algorithm to be intersectively complete
if it has the following property: whenever an object can be characterized by intersecting
a finite number of properties, the algorithm will find such an intersection. We would
like to prove the Incremental Algorithm to be intersectively complete, but we will
meet a few obstacles before we get there.
</bodyText>
<subsectionHeader confidence="0.999737">
3.1 Completeness and Overlapping Values
</subsectionHeader>
<bodyText confidence="0.998433">
One assumption without which the Incremental Algorithm cannot be proven to be
intersectively complete concerns the semantic relation between different Values of a
given Attribute: their extensions should not “overlap” in the following precise sense:
</bodyText>
<footnote confidence="0.905963142857143">
Values Vi,j and Vi,k (and equally, their extensions) overlap iff
Vi,j n Vi,k, Vi,j − Vi,k, and Vi,k − Vi,j are all nonempty.
3 Dale and Reiter arrived at linearity via the difficult concept of typical running time. They assumed that,
typically, nl (i.e., the number of properties in the description) is proportional to the number of
Attributes examined by the algorithm (Ehud Reiter, personal communication). This allowed them to
argue that the typical running time is O(ndnl), where nd is the number of distractors (Dale and Reiter
1995, Section 3.1). Our own worst-case assessment does not rely on assumptions of typicality.
</footnote>
<page confidence="0.994357">
40
</page>
<bodyText confidence="0.940215333333333">
van Deemter Generating Referring Expressions
(If Vi,j and Vi,k do not overlap, then either [[Vi,j]]  [[Vi,k]], or [[Vi,k]]  [[Vi,j]], or [[Vi,j]]
and [[Vi,k]] have an empty intersection.) Values can overlap for different reasons. Some
Attributes (e.g., COLOR) have “vague” Values (e.g., RED, ORANGE), which may be mod-
eled as overlapping: some objects may count as both red and orange. Also, Values may
derive from particular parts or aspects of an object; for example, if an object counts as
METAL (PLASTIC) because it has some METAL (PLASTIC) parts, then it may be listed as both
METAL and PLASTIC. Further examples arise if the KB models relations through unana-
lyzed properties. For example, a desk, or a particular type of desk, can stand in a given
relation (e.g., “being considered by” or “being bought by”) to more than one other
company. To see the problems arising from overlapping Values, consider a KB that
models which customer bought which types of desks, and where C = {a, b, c, d, e, f}:
</bodyText>
<sectionHeader confidence="0.427295" genericHeader="method">
BOUGHT-BY: PHILIPS ({a, b, e}), SONY ({a, c, d,f})
COLOR: BROWN ({a,b}), YELLOW ({c,d})
</sectionHeader>
<bodyText confidence="0.999970625">
(Desks of types a, b, and e were bought by Philips, and so on. Note that desks of
type a were bought by two different companies.) Suppose a is the target, while the
Attribute BOUGHT-BY is more “preferred” than COLOR. The Value PHILIPS (being the
BestValue of BOUGHT-BY, since it removes more distractors than the Value SONY) is
chosen first, reducing the initial set C to {a, b, e}. Now, the algorithm is doomed to end
in Failure, since the different Values of COLOR are unable to remove the unwanted b
without also sacrificing a. None of this can be corrected, since the algorithm does not
use backtracking. Note that a uniquely identifying description of a would have been
possible if only SONY had been chosen instead of PHILIPS, leading to a description like
the brown desk bought by Sony. The algorithm does not just fail: it fails in a situation
where Success was perfectly achievable!
How can this limitation be remedied? One might introduce a limited kind of back-
tracking, which “remembers” where the algorithm has encountered overlapping Val-
ues and, when it results in Failure, goes back to the last-encountered situation where
it has made a choice between overlapping Values; if this does not lead to Success,
the algorithm backtracks to the previous choice situation, and so on until no more
choice situations are left (Failure) or a distinguishing description has been reached
(Success). Unfortunately, this algorithm becomes intractable if Values overlap too of-
ten: in the worst case, we are back to having to check all combinations of properties.
A simpler and computationally more efficient algorithm would include all over-
lapping Values that are true of the target while also removing some distractors. This
could be done as follows: whenever a Value Vi,j of an Attribute Ai is selected for in-
clusion in L, search for other Values of the same Attribute that have the target r as an
element; if such a Value Vi,k is found, check whether it stands in the subset relation to
Vi,j (i.e., either [[Vi,j]]  [[Vi,k]] or [[Vi,k]]  [[Vi,j]]); if not, then include Vi,k as well; next,
search for yet another Value Vi,l of the same Attribute that has r as an element, and
include Vi,l if it does not stand in the subset relation to Vi,j or Vi,k; and so on until no
other Values of Ai exist that have r as an element; then move on to the next Attribute.
This algorithm has a worst-case running time of O(nan2v).4
In our example, this algorithm would produce a set consisting of the properties
BOUGHT BY SONY and BOUGHT BY PHILIPS, which can be realized as the desk bought by
Sony and by Philips; if we change the example by letting Philips buy c as well as a, the
</bodyText>
<footnote confidence="0.978877">
4 This assumes that, once FindBestValue has found a Value V that removes distractors, one may need to
inspect all the other Values of the same Attribute to find Values overlapping with V. Shortcuts are
possible if Values are stored using a structure that reflects their semantic relationships.
</footnote>
<page confidence="0.996805">
41
</page>
<note confidence="0.433874">
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.999727">
algorithm will go on to select the property BROWN, resulting in a set of properties that
may be realized as the brown desk bought by Sony and by Philips. Such descriptions appear
to be quite natural. One might even argue, on Gricean grounds (Grice 1975), that
identifying a simply as being bought by Philips can give rise to the false implicature
that a was not bought by Sony. This suggests that the proposed algorithm might also
be empirically more accurate than the one using limited backtracking provided, of
course, properties are properly aggregated (e.g., Dalianis and Hovy 1996).
</bodyText>
<subsectionHeader confidence="0.999935">
3.2 Assumptions Concerning Infinite Sets
</subsectionHeader>
<bodyText confidence="0.999987652173913">
To prove intersective completeness, certain assumptions concerning the cardinality of
sets need to be made. To give an extreme example, suppose one wanted to refer to
a real number that does not have a “proper name” (unlike, e.g., 7r); then the class of
potentially useful properties is so vast that no GRE algorithm can take them all into
consideration. As long as the number of properties (i.e., Attribute/Value combina-
tions) is denumerably infinite (Kleene 1971), only termination becomes problematic: if a
uniquely referring description [[P1]] n · · · n [[Pn]] exists, then the algorithm will find one
in finite time, since each of the n properties in the description will be found in finite
time; if no distinguishing description exists, however, the algorithm never terminates.
In the less likely case where the set of properties is nondenumerably infinite (i.e., it
does not stand in a 1-1 relation to any set of natural numbers), completeness becomes
problematic as well, since it is impossible for the algorithm to consider all properties;
hence, successful combinations may be overlooked (cf. Kleene 1971,pages 6–8).
Infinity of the set of distractors results in a different problem. The key question
is whether there exists an effective procedure for removing distractors (i.e., for cal-
culating C n [[Pi]]). If no such procedure exists, the Incremental Algorithm can only
be applied after a property has been found that cuts down the set of distractors to a
manageable size. To be on the safe side when we prove completeness, we will assume
that the set of properties is at most denumerably infinite, while the set of distractors
is finite. These assumptions are harmless in connection with present NLG systems, all
of which work with relatively small sets. It is unclear how human speakers cope with
large sets of properties and/or distractors, but this question goes beyond our present
concerns.
</bodyText>
<subsectionHeader confidence="0.999817">
3.3 Proving Intersective Completeness
</subsectionHeader>
<bodyText confidence="0.999692214285714">
Based on these considerations, we prove intersective completeness under some as-
sumptions concerning infinity and overlapping Values. We deal first with D&amp;R, then
with the more complex D&amp;RAtt.
Theorem 1: Completeness of D&amp;R Suppose there are at most denumerably many
properties, and finitely many (one or more) distractors. Then if an object can be individ-
uated by intersecting a finite number of properties, D&amp;R will find such an intersection.
Proof Suppose [[Q1]] n ··· n [[Qm]] = {r}, where the properties Q1,...,Qm occur in P
in the order indicated by the subscripts. Now either D&amp;R returns Success before it has
inspected all of Q1, ... , Qm, or it reaches the point where all of Q1, ... , Qm have been
inspected. This does not mean that all of Q1, ... , Qm have necessarily been included in
L, since other properties in P may have been selected that cause some of Q1, ... , Qm not
to remove any distractors. Yet, when all of Q1,...,Qm have been inspected, Success
must have been achieved. To see this, let Desi be the description that results after
processing (i.e., inspecting and possibly including) Qi. Then a proof by induction over
</bodyText>
<page confidence="0.971193">
42
</page>
<bodyText confidence="0.953708923076923">
van Deemter Generating Referring Expressions
i shows that [[Desi]] c [[Q1]] n · · · n [[Qi]], for all i &lt; m. (Consider the basic case,
where i = 1, and assume that Q1 E� [[Des1]]. Q1 was rejected, so it did not remove any
distractors; hence, [[Des1]] c [[Q1]]. The induction step is analogous.) It follows that
[[Desm]] c [[Q1]] n · · · n [[Qm]] = {r}. But r E [[Desm]], so [[Desm]] = {r}.
Theorem 2: Completeness of D&amp;RAtt Assume (1) Attributes have no overlapping
Values (see Section 3.1), and (2) there are at most denumerably many Attributes and
Values, and finitely many (one or more) distractors. Then if an object can be individu-
ated by intersecting a finite number of properties, D&amp;RAtt will find such an intersection.
Proof Given Assumption (1), if D&amp;R is complete, then so is D&amp;RAtt. To see this, let
BV abbreviate FindBestValue(r,Ai). Suppose there is a Value Vi,j of Attribute Ai that
leads to a distinguishing description whereas BV does not. Then a contradiction is
derived as follows. For certain Vi,a1, . . . , Vi,an,
</bodyText>
<equation confidence="0.412182">
[[Vi,a1]] n · · · n [[Vi,an]] n [[Vi,j]] = {r}, whereas
[[Vi,a1]] n ··· n [[Vi,an]] n [[BV]] =� {r}.
</equation>
<bodyText confidence="0.681427333333333">
So, either (i) r E� BV or (ii) there exists x =� r for which x E [[Vi,a1]] n · · · n [[Vi,an]] n BV .
But Case (i) contradicts the definition of FindBestValue (see Section 2); Case (ii), on
the other hand, implies that
</bodyText>
<equation confidence="0.7631795">
x E [[Vi,a1]] n ··· n [[Vi,an]] n [[BV ]], whereas
x E� [[Vi,a1]] n ··· n [[Vi,an]] n [[Vi,j]];
</equation>
<bodyText confidence="0.9700806">
hence, x E [[BV ]] while x E� [[Vi,j]]. But r E [[BV]] n [[Vi,j]], so [[BV]] and [[Vi,j]] are
not disjoint. Consequently, by Assumption (1), Case (ii) implies that [[Vi,a1]] n · · · n
[[Vi,an]] n [[Vi,j]] is a real subset of [[Vi,a1]] n · · · n [[Vi,an]] n [[BV ]], contradicting the fact
that FindBestValue prefers a more general Value (i.e., BV ) over a more specific one
(i.e., Vi,j) only if it removes the same distractors.
</bodyText>
<sectionHeader confidence="0.909316" genericHeader="method">
4. Generalizing the Incremental Algorithm
</sectionHeader>
<bodyText confidence="0.999918727272727">
Both versions of the Incremental Algorithm have been proven to be intersectively com-
plete. Now we widen the issue to include all other Boolean combinations, involving
negation (i.e., complementation) and disjunction (i.e., union).5 This is natural, since
properties expressed by Boolean combinations are implicit in the KB: if the KB lists the
property POODLE and the property ALSATIAN, then it implicitly contains the property
of being either a poodle or an Alsatian. This move will, however, only have its full
impact when we also widen the issue to reference to sets of objects.
In the new setting, it will be useful to generalize our earlier notion of intersec-
tive completeness (Section 3), calling a GRE algorithm Boolean complete iff it finds a
Boolean description of a set whenever one can be given on the basis of the properties
in the KB.
</bodyText>
<footnote confidence="0.6397145">
5 The well-known correspondence between set-theoretical operations like set union and propositional
operators like disjunction will allow us to “mix and match” the two terminologies.
</footnote>
<page confidence="0.998401">
43
</page>
<note confidence="0.601811">
Computational Linguistics Volume 28, Number 1
</note>
<subsectionHeader confidence="0.996399">
4.1 Describing Sets
</subsectionHeader>
<bodyText confidence="0.99988675">
Generating descriptions is even more important if the target is a set than if it is a single
object: even if the objects in the set have proper names, the set as a whole may lack
a name (and enumerating the objects may be cumbersome). Yet, reference to sets has
long been disregarded in NLG. In this section, we sketch generalizations of D&amp;R that
produce descriptions of sets. To begin with, the algorithm D&amp;RPlural finds intersections
P1 n· · ·nPn of atomic properties P1,. . . , Pn whose extension equals a given target set S
(van Deemter 2000). Since S may or may not be a singleton, D&amp;RPlural subsumes D&amp;R.
As before, we assume a nonempty set of distractors; that is, S C D but S =� D.6
</bodyText>
<equation confidence="0.963757142857143">
L := 0
C := D
For each Pi E P do
If S C [[Pill &amp; C C� [[Pill then do
L := L U {Pi}
C := C n [[Pill
If C = S then Return L {Success}
</equation>
<bodyText confidence="0.979678315789474">
Return Failure {All properties in P have been tested, yet C =� S}
Note that S takes the place of the target object r in the earlier algorithms; the process
of expanding L and contracting C continues until C = S. Because this is basically the
same algorithm as D&amp;R, it has the same computational complexity of O(na), where na
is the cardinality of P.
D&amp;RPlural characterizes a set by scrutinizing its elements. This does not work for
properties like BEING OF THE SAME AGE, which crucially pertain to sets of objects (cf.
Stone 2000). The algorithm can, however, be generalized to cover such cases if we
initialize C not to D but to the powerset of D, after which the algorithm selects properties
of sets, removing from P(D) all those sets for which the property is false. For example,
selection of BEING OF THE SAME AGE removes all those sets whose elements are not of
the same age as each other, selection of FORMING A FOOTBALL TEAM removes all sets
that do not make up a football team, and so on. As a result, the algorithm generates
descriptions of sets of collective entities (i.e., sets of sets). In this way, descriptions such
as those teams all of whose members are of the same age can be generated. In this collective
version of D&amp;RPlural, the target S is a set of sets; P is a list of properties of sets, so
if Pi E P, then [[Pill is also a set of sets. As in the case of distributive properties,
describing one entity (in this case, one set) is a special case of describing a set of
entities.
</bodyText>
<equation confidence="0.9787996">
L := 0
C := P(D)
For each Pi E P do
If S C [[Pill &amp; C C� [[Pill then do
L := L U {Pi}
</equation>
<footnote confidence="0.9326345">
6 We continue to disregard special provisions for head nouns (see footnote 1). Note, however, that a
head noun must be selected that suits every element of the target set.
</footnote>
<page confidence="0.993806">
44
</page>
<figure confidence="0.84824825">
van Deemter Generating Referring Expressions
C := C n [[Pill
If C = S then Return L {Success}
Return Failure
</figure>
<bodyText confidence="0.992349347826087">
Once again, these adaptations leave the algorithm structurally unchanged: sets replace
objects throughout. Yet, they cause the complexity of the algorithm to become expo-
nential, since testing whether C = S involves inspecting all elements of C, of which
there can be up to 2nd (where nd is the cardinality of the domain D).
This algorithm can also be applied to distributive properties if these are upgraded
to the level of sets: Let a newfangled distributive property be true of a set iff the
property (in ordinary parlance) is true of all its elements (Kamp and Reyle 1993,
page 338). This requires that the target S is always cast as a set of sets, even if it
is viewed distributively. For example, if a set of players—say, a, b, and c—are to
be characterized as a collection (e.g., to say that they won as a team of three), then
S = {{a, b, c}}; if they are to be characterized distributively (e.g., to say that each of
them has the flu), then S = {{a, b, c}, {a, b}, {a, c}, {b, c}, {a}, {b}, {c}}. In this way, the
algorithm is able to combine collective and distributive properties, as in those football
teams whose members are British.
We will not explore collective versions of the Incremental Algorithm further here,
focusing instead on the relatively simple case of D&amp;RPlural, in which all properties
are distributive. As in the case of D&amp;R, it is easy to separate Attributes and Values
when referring to sets, allowing a closer approximation of Full Brevity: the resulting
algorithm, D&amp;RPlural,Att, is to D&amp;RPlural as D&amp;RAtt is to D&amp;R; overlapping Values can be
treated as described in Section 3.1. In what follows, we will once again take property-
oriented versions of the Incremental Algorithm as our starting point, but implications
for the separation between Attributes and Values will be mentioned where they are
nontrivial.
</bodyText>
<subsectionHeader confidence="0.999813">
4.2 Using Negations and Disjunctions
</subsectionHeader>
<bodyText confidence="0.9707759375">
Now that we are able to generate references to sets, let us move away from purely
intersective descriptions, on to full Boolean combinations of properties. Consider a KB
whose domain is a set of animals (a, b, c, d, e) and whose only Attributes are TYPE and
COLOR:
TYPE: DOG ({a, b, c, d, e}), POODLE ({a, b})
COLOR: BLACK ({a, b, c}), WHITE ({d, e})
(All domain elements happen to be dogs.) In this situation, the Incremental Algorithm
does not allow us to individuate any of the animals. Intuitively, however, the KB
should enable one to refer to c, for example, since it is the only black dog that is not
a poodle:
{c} = BLACK n POODLE
A similar gap exists where disjunctions might be used. For example, the Incremental
Algorithm does not make the set of dogs that are either white or poodles referrable,
whereas it is referrable in English—for example, the white dogs and the poodles.
In the next two sections, we will investigate how negation and disjunction can
be taken into account in GRE. But first we introduce a trick for determining whether
</bodyText>
<page confidence="0.995329">
45
</page>
<note confidence="0.639756">
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.9997875">
unique identification of an entity is possible, in a given situation.7 The idea is to
calculate, for each element d in the domain, the Satellite set of d, that is, the intersection
of the extensions of all the properties true of d. Taking all extensions from our dog
example, we have
</bodyText>
<equation confidence="0.999961">
Satellites(a) = Satellites(b) = DOG n POODLE n BLACK = {a, b}
Satellites(c) = DOG n BLACK = {a, b, c}
Satellites(d) = Satellites(e) = DOG n WHITE = {d,e}
</equation>
<bodyText confidence="0.999930071428571">
Satellite sets show which sets can be uniquely identified and which ones cannot. In the
case of the dogs, for example, no intersective description of {c} is possible because,
in the Satellite sets, c is always accompanied by other objects (i.e., a and b); more
generally, in this example, no object in the domain is uniquely identifiable, since no
object occurs in a Satellite set that is a singleton.
Satellite sets can also be applied to the construction of descriptions. The entity {a, b},
for example, is uniquely described by the intersection DOG n POODLE n BLACK, and this
can be read off the list of Satellite sets. Two of the three properties in DOG n POODLE n
BLACK are redundant, however. Using Satellites sets for the construction of descriptions
can be particularly useful when properly generalized to Boolean descriptions, but
shortening the resulting descriptions in a computationally efficient way is difficult (van
Deemter and Halld ´orsson 2001). The present paper will focus on another approach to
Boolean descriptions, which takes the Incremental Algorithm as its point of departure
(van Deemter 2001).
</bodyText>
<subsectionHeader confidence="0.998164">
4.3 Generating Boolean Descriptions
</subsectionHeader>
<bodyText confidence="0.999785238095238">
In this section, we will show how full Boolean descriptions can be generated. This
can be done in many different ways depending, among other things, on what form of
descriptions are preferred, for example, disjunctions of conjunctions, or conjunctions
of disjunctions. We will aim for the latter, while staying as close as possible to the
Incremental Algorithm. The algorithm proceeds as follows. First we add negations to
the list of atomic properties. Then D&amp;RPlural runs a number of times: first, in Phase 1,
the algorithm is performed using all positive and negative literals; if this algorithm
ends before C = S, Phase 2 is entered in which further distractors are removed from
C by making use of negations of intersections of two literals, and so on, until either
C = S (Success) or all combinations have been tried (Failure). Observe that the
negation of an intersection comes down to set union, because of De Morgan’s Law:
P1 n · · · n Pn = P1 U · · · U Pn. Thus, Phase 2 of the algorithm deals with disjunctions of
length 2, Phase 3 deals with disjunctions of length 3, and so on. Optimizations may be
applied to shorten the resulting descriptions. For instance, a description of the form
(P U Q) n (P U R) can be simplified to (P U (Q n R)) using standard algorithms (e.g.,
McCluskey 1965). Such optimizations, however, are less urgent than in the case of
the more verbose descriptions generated using Satellite sets (see above), and we will
disregard optimizations here.
A schematic presentation may be useful, in which P+1_ stands for any literal,
that is, any atomic property or its negation. (Different occurrences of P+1_ denote
potentially different literals.) The length of a property will equal the number of literals
</bodyText>
<page confidence="0.9423115">
7 The idea of Satellite sets is due to Magn´us Halld´orsson (personal communication).
46
</page>
<bodyText confidence="0.880827">
van Deemter Generating Referring Expressions
occurring in it. We will say that a D&amp;RPlural phase uses a set of properties X if it loops
through the properties in X (i.e., X takes the place of P in the original D&amp;RPlural).
D&amp;RB.,e�
Phase 1. Perform D&amp;RPlural using all properties of the form P+/_. If this is
successful, then stop; otherwise, go to Phase 2.
Phase 2. Based on the Values of L and C coming out of Phase 1, perform
D&amp;RPlural using all properties of the form P+/_ U P+/_. If this is successful,
then stop; otherwise, go to Phase 3.
Phase 3. Based on the Values of L and C coming out of Phase 2, perform
D&amp;RPlural using all properties of the form P+/_ U P+/_ U P+/_. If this is
successful, then stop; otherwise, go to Phase 4.
Etc.
One can require without loss of generality that no property, considered at any phase,
may have different occurrences of the same atom. (For example, it is useless to consider
the property P1 U P2 U P1, which must be true of any element in the domain, or the
property P1 U P2 U P1, which is equivalent to the earlier-considered property P1 U P2.)
Therefore, since at phase n there is room for properties of length n, the maximal number
of phases equals the total number of atomic properties.
Consider our old example, where the preference order of atomic properties cor-
responds with the order in which they are listed, and where the same order extends
to their negations, all of which are less preferred. Abbreviating B = BLACK, D = DOG,
P = POODLE, and W = WHITE, we have P = (B, D, P, W, B, D, P, W). Now, if S = {c, d, e}
and S = {c} (as before) are to be characterized, nothing eventful happens. In both
cases, a description is found during Phase 1: P in the first case, B n P in the second.
The situation gets more interesting if S = {a, b, d, e}, which triggers Phase 2. For in-
stance, if positive literals precede negative literals, the properties relevant for Phase 2
might be ordered as follows:
(BUD,BUP,BUW,DUP,DUW,PUW,BUD,BUP,BUW,DUB,
DUP,DUW,PUB,PUD,PUW, WUB, WUD, WUP,BUD,BUP,
BUW,DUP,DUW,PUW)
During Phase 1, no property is selected, since the only property true of all elements in
S = {a, b, d, e} is D, which fails to remove any distractors. During Phase 2, one property
after another is rejected. For example, the property BUD is rejected because it does not
remove any distractors. The first property that is true of all elements of S while also
removing distractors is P U W. This property removes all distractors at once, causing
the algorithm to end with L = {POODLE U WHITE} as the complete description. If we
modify the example by letting [[BLACK]] = {a, c} (rather than {a, b, c}) and S = {b, c, d, e}
(rather than S = {a, b, d, e}), then the description L = {BLACK U POODLE} is found.
D&amp;RBoolean is incremental not only within a phase, but also from one phase to
the next, which causes shorter disjunctions to be favored over longer ones. Once a
property has been selected, it will not be abandoned even if properties selected during
later phases make it logically superfluous. As a result, one may generate descriptions
like X n (Y U Z) (e.g., white (cats and dogs)) in a situation where Y U Z (e.g., cats and
dogs) would have sufficed (because (Y U Z) C_ X). This is not unlike some of the
redundancies generated by Dale and Reiter’s algorithm and, as in their case, it is
</bodyText>
<page confidence="0.998102">
47
</page>
<note confidence="0.646415">
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.999547666666667">
unclear whether this is descriptively adequate. Adaptations can be made if needed.
For instance, phases might run separately before running in combination: first (as
usual) Phase 1, then 2, then (as usual) 1&amp;2, then 3, then 1&amp;3, then 2&amp;3, then (as usual)
1&amp;2&amp;3, and so on.8 As a result of this adaptation, the description Y U Z would be
generated because of Phase 2 alone.
Double incrementality, however, does not save D&amp;RBoolean from intractability. To
estimate running time as a function of the number of properties (na) in the KB and
those in the description (nl), we can mirror an argument in Dale and Reiter (1995,
Section 3.1.1) to show that the maximal number of properties to be considered equals
</bodyText>
<equation confidence="0.980809666666667">
�nl n
i=1 (na) = n, na!2 2 na − i)!.
i i=1
</equation>
<bodyText confidence="0.999876055555555">
(The factor of 2 derives from inspecting both each atom and its negation.) If nl « na,
then this is on the order of nnl
a . To avoid intractability, the algorithm can be pruned.
No matter where this is done, the result is a polynomial algorithm. By cutting off
after Phase 1, for example, only (negations of) atomic properties are combined, pro-
ducing such descriptions as the black dog that is not a poodle, disregarding more complex
descriptions; as a result, completeness is lost, but only for references to nonsingle-
ton sets, because set union does not add descriptive power where the description of
singletons is concerned. The number of properties to be considered by this simpler
algorithm equals (na)2 + 2na −1. To produce descriptions like WHITE n (CAT U DOG) (i.e.,
white (cats and dogs)) as well, the algorithm can be cut off one phase later, leading to a
worst-case running time of O(n3a), and so on for more and more complex descriptions.
D&amp;RBoolea can, of course, be modified to take advantage of the distinction between
Attributes and Values. Suppose, for example, that V1 U · · · U Vn takes precedence over
W1 U · · · U Wn whenever there are more negative Values among V1, ... , Vn than among
W1, ... , Wn. Then the preference ordering between Attributes may be taken into ac-
count if the number of negative Values is the same in both unions; in case of a tie, the
number of distractors removed by each of the two unions may decide; if all this fails to
tip the balance, the relative specificity of Attributes may be used. The situation resem-
bles that of D&amp;RAtt but, in the case of the new algorithm, D&amp;RBoolean,Att, there is more
scope for choice, because it compares combinations (i.e., unions) of properties: when the
preference order of individual Attributes has been decided, it can happen that [[Vi]] is
more preferred than [[Wj]], while [[Wk]] is more preferred than [[Vl]], in which case it is
unclear whether V1 U · · · U Vn should be more preferred or W1 U · · · U Wn. (Problems of
this kind are not specific to Boolean combinations. For example, if an object x is iden-
tified through the relation R(xy) and the predicate P(y), then the degrees of preference
of both R and P are relevant, and it is unclear which of the two is more important.)
Once D&amp;RBoolean,Att is constructed along these lines, the question of overlapping
Values arises in exactly the same way as in the case of D&amp;RAtt and D&amp;RPlural,Att. The
problem arises if components of different unions overlap, as when the algorithm com-
pares Vi,jUVk,l and Vi,jUVk,l,, where Vk,l and Vk,l, overlap in the sense of Section 3.1: as in
the case of D&amp;RAtt, simply choosing the option that removes the most distractors may
cause the algorithm to become incomplete. This problem can be overcome as before, us-
ing either limited backtracking or inclusion of all relevant options (Section 3.1). Instead
of exploring D&amp;RBoolean,Att any further, we will return to its predecessor, D&amp;RBoolean,
to prove that it is powerful enough to do its job.
</bodyText>
<footnote confidence="0.540529">
8 This possibility was suggested to me by Richard Power (personal communication).
</footnote>
<page confidence="0.996041">
48
</page>
<note confidence="0.288461">
van Deemter Generating Referring Expressions
</note>
<subsectionHeader confidence="0.99909">
4.4 Proving Boolean Completeness
</subsectionHeader>
<bodyText confidence="0.993339346153846">
In Section 3.3, we proved intersective completeness for two versions of Dale and Re-
iter’s Incremental Algorithm, D&amp;R and D&amp;RAtt. We now prove Boolean completeness
for D&amp;RBoolean, the Boolean extension of D&amp;RPlural.
Theorem 3: Completeness of D&amp;RBOOk. Assume there are at most denumerably
many properties, and finitely many distractors (one or more). Then if a set can be
individuated distributively by any Boolean combination of properties, D&amp;RBoolean will
find such a combination.
Proof Any Boolean expression can be written in conjunctive normal form (CNF), that
is, as an intersection of unions of literals (e.g., Fitting 1996). Theorem 3 follows from
the following lemma.
Lemma Let cp be a CNF formula whose longest union has a length of n (i.e., it conjoins
n literals). Then D&amp;RBoolean will find a description cp&apos; that is coextensive with cp, in at
most n phases. This is proven by induction on the size of n.
Basic case: If n = 1, the lemma is equivalent to completeness of D&amp;RPlural, the proof of
which is analogous to that of the completeness of D&amp;R, replacing {r} by S.
Induction step: Suppose the lemma is true for all n &lt; i. Now consider a CNF cp whose
longest union has length i; let cp contain m unions of length i, namely, cp1 n · · · n cpm.
Then cp can be written as the CNF x n cp1 n · · · n cpm, where all the unions in x have
length &lt; i. The lemma is true for all n &lt; i, so if x is sent to D&amp;RBoolean, then the
output is some x&apos; such that [[x&apos;]] = [[x]], in fewer than i phases; so if, instead, cp is
sent to D&amp;RBoolean, then, after i − 1 phases, some possibly incomplete description 77
has been found, such that [[77]] C [[x]]. Also, [[cp]] C [77]]. Phase i inspects all unions of
length i, including each of cp1, ... , cpm. Therefore, unless a description coextensive with
cp is found before phase i, one will be found during phase i. To see this, suppose the
algorithm finds 0 such that [[0]] = [[cp1]] n · · · n [[cpm]]. Then [[x]] n [[0]] = [[cp]]; but
[[cp]] C [77]] C [[x]], therefore also [[77]] n [[0]] = [[cp]].
</bodyText>
<sectionHeader confidence="0.984863" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999348076923077">
The GRE algorithms discussed in this paper are fairly limited in their aspirations. For
example, they do not involve relational descriptions (Dale and Haddock 1991; Horacek
1997; Krahmer, van Erk, and Verleg 2001) or properties that are vague or context
dependent (van Deemter 2000). Moreover, they disregard shades of salience (unlike
algorithms proposed in Krahmer and Theune [1999], Theune [2000]), relying instead
on a simple dichotomy between those objects that are salient enough (which end up
in the domain D) and those that are not (Reiter and Dale 2000, Section 5.4). Finally,
like all other GRE algorithms that we are aware of, they disregard the generation of
descriptions in intensional contexts (e.g., John knows that x is the murderer ofJones; Dowty,
Wall, and Peters 1981).
But even within this limited brief, existing algorithms are incomplete. In particular,
we have shown Dale and Reiter’s (1995) Incremental Algorithm to be intersectively
incomplete with respect to Attributes that have overlapping Values and (less surpris-
</bodyText>
<page confidence="0.998573">
49
</page>
<note confidence="0.73574">
Computational Linguistics Volume 28, Number 1
</note>
<bodyText confidence="0.999841980392157">
ingly) in some situations where the class of properties is infinitely large. Furthermore,
the Incremental Algorithm excludes reference to sets and limits itself to purely in-
tersective combinations of atomic properties, causing the algorithm to be incomplete
with respect to the set of all Boolean combinations. Having noted these shortcomings,
we have modified the Incremental Algorithm in such a way that these limitations are
removed. The result is a set of generalizations of the Incremental Algorithm, for which
we have proven completeness under appropriate assumptions.
Integration of these different algorithms into one unified algorithm would be a
nontrivial enterprise, as we have shown in Section 4.3. Integration with previously
proposed extensions of the Incremental Algorithm would raise further questions, stem-
ming from the fact that our descriptions are structurally complex. For example, con-
sider the treatment of relational properties. Which is better: adding a relational property
to a given incomplete description (... in the wooden shed) or adding a negated property
(... which is not a poodle)? Making informed decisions about such questions, with proper
attention to their combined effects, is a difficult task that is perhaps best tackled us-
ing the graph-theoretical approach outlined by Krahmer, van Erk, and Verleg (2001).
Their approach is specifically suitable for accommodating different GRE algorithms
and treats relations in the same way as properties
Brevity. We have assumed that, on the whole, descriptions ought to be as brief as
they can, as long as they are uniquely identifying. But in fact, a description can contain
much more than is logically necessary for identification, even beyond the redundan-
cies allowed by the Incremental Algorithm. Logically superfluous properties can, for
example, be motivated by “overloading” if they serve communicative purposes other
than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber
1998; Jordan 1999). A description may also contain fewer properties than would be
necessary for identification—for example, when no distinguishing description exists.
A nondistinguishing description may take the form either of a definite description (as
in John’s son, when John has several sons) or of an indefinite description (as in one of
John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both
cases, the description may be useful even though it fails to be distinguishing.
Tractability. Computational tractability has also been paramount in our explo-
rations. There is no agreement on the extent to which computational linguists should
worry about the computational complexity of algorithms, or about the precise way in
which complexity is most relevant (e.g., “typical” or worst-case complexity, cf. foot-
note 3). Far from aiming to speak the last word on these issues, the material discussed
here does shed some light on them. For example, even a fast algorithm can require
a large number of calculations, in which case a solution may never be found; in the
case of GRE, this happens when the set of distractors or the set of properties becomes
extremely large (Section 3.2). Conversely, a complex algorithm can be safe to use if the
domain is small (or if key calculations can be performed offline; e.g., Bateman 1999).
This may be achieved by putting a bound on the size of the search space, and this may
be justifiable on empirical grounds (see the discussion of D&amp;RBoolean in Section 4.3).
One might, on the other hand, argue that bounding does not eliminate the disadvan-
tages of an otherwise intractable algorithm, because the true nature of an algorithm is
best revealed “by considering how it operates on unlimited cases” (Barton, Berwick,
and Ristad 1987, Section 1.4.1). Be this as it may, we believe that complexity theory
can offer valuable insights into the structure of GRE algorithms and that the grow-
ing attention to complexity in this area is a healthy development even if the practical
implications are not always straightforward.
Recent work also highlights an interesting mirror image of GRE complexity: a
logically superfluous property may make it easier for the reader to find the referent.
</bodyText>
<page confidence="0.93258">
50
</page>
<bodyText confidence="0.9467135">
van Deemter Generating Referring Expressions
An interesting class of cases is explored in Paraboni (2000), which focuses on de-
scriptions of document parts. Consider the description the medicine depicted in Section
2.3. If Section 2 happens to contain only one figure, then the description the medicine
depicted in Section 2 would have been logically sufficient, but this description would
have made it necessary for the reader, in the worst case, to search through all of Sec-
tion 2, making it less useful. Examples of this kind suggest that GRE should also take
the computational complexity of interpretation into account. Experimental research on
“minimal cooperative effort” (Clark 1992; Cremers 1996) points in the same direc-
tion.
</bodyText>
<sectionHeader confidence="0.982883" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997797857142857">
Thanks are due to Robert Dale, Magn´us
Halld´orsson, Emiel Krahmer, Paul Piwek,
Richard Power, Ehud Reiter, and Matthew
Stone for useful discussions. Helpful
comments from the reviewers of
Computational Linguistics are also gratefully
acknowledged.
</bodyText>
<sectionHeader confidence="0.99419" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999818275862069">
Barton, G. Edward, Robert C. Berwick, and
Eric Sven Ristad. 1987. Computational
Complexity and Natural Language. MIT
Press, Cambridge, MA.
Bateman, John A. 1999. Using aggregation
for selecting content when generating
referring expressions. In Proceedings of the
37th Annual Meeting of the Association for
Computational Linguistics, pages 127–134,
College Park, MD.
Clark, Herbert H. 1992. Arenas of Language
Use. CSLI Publications, Stanford, CA.
Cremers, Anita. 1996. Reference to Objects: An
Empirically Based Study of Task-Oriented
Dialogues. Ph.D. thesis, University of
Eindhoven.
Dale, Robert. 1989. Cooking up referring
expressions. In Proceedings of the 27th
Annual Meeting of Association for
Computational Linguistics, pages 68–75,
Vancouver.
Dale, Robert. 1992. Generating Referring
Expressions: Constructing Descriptions in a
Domain of Objects and Processes. MIT Press,
Cambridge, MA.
Dale, Robert and N. Haddock. 1991.
Generating referring expressions
involving relations. In Proceedings of the
9th Meeting of the European Chapter of the
Association for Computational Linguistics,
pages 161–166, Berlin.
Dale, Robert and Ehud Reiter. 1995.
Computational interpretations of the
Gricean maxims in the generation of
referring expressions. Cognitive Science, 18,
233–263.
Dalianis, Hercules and Eduard Hovy. 1996.
Aggregation in natural language
generation. In G. Adorni and M. Zock,
editors, Trends in Natural Language
Generation: An Artificial Intelligence
Perspective. Springer-Verlag, New York,
pages 88–105.
Dowty, David, Robert Wall, and Stanley
Peters. 1981. Introduction to Montague
Semantics. D. Reidel, Dordrecht.
Fitting, Melvin. 1996. First-Order Logic and
Automated Theorem Proving.
Springer-Verlag, New York.
Grice, Paul. 1975. Logic and conversation. In
P. Cole and J. Morgan, editors, Syntax and
Semantics: Vol. 3: Speech Acts. Academic
Press, New York, pages 43–58.
Horacek, Helmut. 1997. An algorithm for
generating referential descriptions with
flexible interfaces. In Proceedings of the 35th
Annual Meeting of the Association for
Computational Linguistics, pages 206–213.
Madrid.
Jordan, Pamela. 1999. Contextual influences
on the attributes included in repeated
descriptions. In Proceedings of the Workshop
“Generation of Nominal Expressions,” 11th
European Summer School in Logic, Language,
and Information (ESSLLI’99), Utrecht.
Augmented version to appear in K. van
Deemter and R. Kibble, editors,
Information Sharing. CSLI Publications,
Stanford, CA.
Kamp, Hans and Uwe Reyle. 1993. From
Discourse to Logic. Kluwer, Dordrecht.
Kibble, Rodger. 1999. Cb or not Cb?
Centering Theory applied to NLG. In
Proceedings of the ACL Workshop
“Discourse/Dialogue Structure and
Reference,” College Park, MD.
Kleene, Stephen C. 1971. Introduction to
Metamathematics. Wolters-Noordhoff.
Groningen.
Krahmer, Emiel and Mari¨et Theune. 1999.
Generating descriptions in context. In
Proceedings of the Workshop “Generation of
Nominal Expressions,” 11th European
Summer School in Logic, Language, and
Information (ESSLLI’99), Utrecht.
Augmented version to appear in K. van
Deemter and R. Kibble, editors,
</reference>
<page confidence="0.958704">
51
</page>
<note confidence="0.35776">
Computational Linguistics Volume 28, Number 1
</note>
<reference confidence="0.999681606060606">
Information Sharing. CSLI Publications,
Stanford, CA.
Krahmer, Emiel, Sebastiaan van Erk, and
Andre´ Verleg. 2001. A meta-algorithm for
the generation of referring expressions. In
Proceedings of the 8th European Workshop on
Natural Language Generation (EWNLG’01),
pages 29–38, Toulouse, France.
McCluskey, Edward J. 1965. Introduction to
the Theory of Switching. McGraw-Hill, New
York.
Mittal, Vibhu O., Joanna D. Moore,
Giuseppe Carenini, and Steven Roth.
1998. Describing complex charts in
natural language: A caption generation
system. Computational Linguistics, 24,
431–468.
Paraboni, Ivandr ´e. 2000. An algorithm for
generating document-deictic references.
In Proceedings of the Workshop “Coherence in
Generated Multimedia,” 1st International
Conference on Natural Language Generation
(INLG’00), pages 27–31, Mitzpe Ramon,
Israel.
Pechman, Thomas. 1989. Incremental speech
production and referential overspecifi-
cation. Linguistics, 27, 89–110.
Pollack, Martha E. 1991. Overloading
intentions for efficient practical reasoning.
No ˆus, 25: 513–536.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge,
UK.
Stone, Matthew. 2000. On identifying sets. In
Proceedings of the 1st International Conference
on Natural Language Generation (INLG’00),
pages 116–123, Mitzpe Ramon, Israel.
Stone, Matthew and Bonnie Webber. 1998.
Textual economy through close coupling
of syntax and semantics. In Proceedings of
the 9th International Workshop on Natural
Language Generation (INLG’98),
pages 178–187, Niagara-on-the-Lake,
Canada.
Theune, Mari¨et. 2000. From Data to Speech:
Language Generation in Context. Ph.D.
thesis, University of Eindhoven.
van Deemter, Kees. 2000. Generating vague
descriptions. In Proceedings of the 1st
International Conference on Natural Language
Generation (INLG’00), pages 179–185,
Mitzpe Ramon, Israel.
van Deemter, Kees. 2001. Generating
referring expressions: Beyond the
incremental algorithm. In Proceedings of the
4th International Workshop on Computational
Semantics (IWCS’01), pages 50–66, Tilburg,
The Netherlands.
van Deemter, Kees and Magn ´us
Halld ´orsson. 2001. Logical form
equivalence: The case of referring
expressions generation. In Proceedings of
the 8th European Workshop on Natural
Language Generation (EWNLG’01),
pages 21–28, Toulouse, France.
</reference>
<page confidence="0.998851">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.440140">
<title confidence="0.995958">Generating Referring Expressions: Boolean Extensions of the Incremental Algorithm</title>
<author confidence="0.995272">van</author>
<affiliation confidence="0.9705">University of Brighton</affiliation>
<abstract confidence="0.9656342">This paper brings a logical perspective to the generation of referring expressions, addressing the incompleteness of existing algorithms in this area. After studying references to individual objects, we discuss references to sets, including Boolean descriptions that make use of negated and disjoined properties. To guarantee that a distinguishing description is generated whenever such descriptions exist, the paper proposes generalizations and extensions of the Incremental</abstract>
<note confidence="0.550371">Algorithm of Dale and Reiter (1995).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Edward Barton</author>
<author>Robert C Berwick</author>
<author>Eric Sven Ristad</author>
</authors>
<date>1987</date>
<booktitle>Computational Complexity and Natural Language.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Barton, Berwick, Ristad, 1987</marker>
<rawString>Barton, G. Edward, Robert C. Berwick, and Eric Sven Ristad. 1987. Computational Complexity and Natural Language. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>Using aggregation for selecting content when generating referring expressions.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>127--134</pages>
<location>College Park, MD.</location>
<contexts>
<context position="47230" citStr="Bateman 1999" startWordPosition="8072" endWordPosition="8073">ecise way in which complexity is most relevant (e.g., “typical” or worst-case complexity, cf. footnote 3). Far from aiming to speak the last word on these issues, the material discussed here does shed some light on them. For example, even a fast algorithm can require a large number of calculations, in which case a solution may never be found; in the case of GRE, this happens when the set of distractors or the set of properties becomes extremely large (Section 3.2). Conversely, a complex algorithm can be safe to use if the domain is small (or if key calculations can be performed offline; e.g., Bateman 1999). This may be achieved by putting a bound on the size of the search space, and this may be justifiable on empirical grounds (see the discussion of D&amp;RBoolean in Section 4.3). One might, on the other hand, argue that bounding does not eliminate the disadvantages of an otherwise intractable algorithm, because the true nature of an algorithm is best revealed “by considering how it operates on unlimited cases” (Barton, Berwick, and Ristad 1987, Section 1.4.1). Be this as it may, we believe that complexity theory can offer valuable insights into the structure of GRE algorithms and that the growing </context>
</contexts>
<marker>Bateman, 1999</marker>
<rawString>Bateman, John A. 1999. Using aggregation for selecting content when generating referring expressions. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 127–134, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Arenas of Language Use.</title>
<date>1992</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>Clark, 1992</marker>
<rawString>Clark, Herbert H. 1992. Arenas of Language Use. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anita Cremers</author>
</authors>
<title>Reference to Objects: An Empirically Based Study of Task-Oriented Dialogues.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Eindhoven.</institution>
<marker>Cremers, 1996</marker>
<rawString>Cremers, Anita. 1996. Reference to Objects: An Empirically Based Study of Task-Oriented Dialogues. Ph.D. thesis, University of Eindhoven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Cooking up referring expressions.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting of Association for Computational Linguistics,</booktitle>
<pages>68--75</pages>
<location>Vancouver.</location>
<contexts>
<context position="7099" citStr="Dale 1989" startWordPosition="1099" endWordPosition="1100">at might be made for the selection of head nouns because, arguably, this has to involve realizational issues.1 1 Compare Dale and Reiter (1995), where head nouns are taken into account during content determination. Head nouns can also be selected during linguistic realization or by interleaving of content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). 38 van Deemter Generating Referring Expressions The Incremental Algorithm produces a set L of properties P1,. . . , Pn such that their logical conjunction forms a “distinguishing description” (Dale 1989) of the target object r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have the property Q), the intersection [[P1]] n · · · n [[Pn]] must equal the singleton set {r}. It is a “hillclimbing” algorithm, which finds better and better approximations of the target set {r} by accumulating more and more properties—hence the term Incremental. There is no backtracking. Consequently, if some property Pi in L is made redundant by later additions (i.e., when ([[P1]] n · · · n [[Pi − 1]] n [[Pi + 1]] n · · · n [[Pn]]) C [[Pi]]), then Pi is retained as a member of L ne</context>
</contexts>
<marker>Dale, 1989</marker>
<rawString>Dale, Robert. 1989. Cooking up referring expressions. In Proceedings of the 27th Annual Meeting of Association for Computational Linguistics, pages 68–75, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3505" citStr="Dale 1992" startWordPosition="541" endWordPosition="542">logy Research Institute (ITRI), University of Brighton, Lewes Road, Brighton BN2 4GJ, UK. E-mail: Kees.van.Deemter@itri.brighton.ac.uk. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 algorithms are also generalized to generate references to sets, rather than individual objects. But, before we arrive at these generalizations, we will identify and confront a number of cases in which current GRE algorithms are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combi</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>Dale, Robert. 1992. Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>N Haddock</author>
</authors>
<title>Generating referring expressions involving relations.</title>
<date>1991</date>
<booktitle>In Proceedings of the 9th Meeting of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>161--166</pages>
<location>Berlin.</location>
<contexts>
<context position="3871" citStr="Dale and Haddock 1991" startWordPosition="597" endWordPosition="600">ese generalizations, we will identify and confront a number of cases in which current GRE algorithms are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combination of properties can be expressed by the NLG module responsible for linguistic realization. This modular approach allows us to separate logical aspects of generation (which are largely language independent) from purely linguistic aspects, and it allows the realization module to base its decisions on complete information about which combination of properties is</context>
<context position="42959" citStr="Dale and Haddock 1991" startWordPosition="7409" endWordPosition="7412">ption 77 has been found, such that [[77]] C [[x]]. Also, [[cp]] C [77]]. Phase i inspects all unions of length i, including each of cp1, ... , cpm. Therefore, unless a description coextensive with cp is found before phase i, one will be found during phase i. To see this, suppose the algorithm finds 0 such that [[0]] = [[cp1]] n · · · n [[cpm]]. Then [[x]] n [[0]] = [[cp]]; but [[cp]] C [77]] C [[x]], therefore also [[77]] n [[0]] = [[cp]]. 5. Conclusion The GRE algorithms discussed in this paper are fairly limited in their aspirations. For example, they do not involve relational descriptions (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001) or properties that are vague or context dependent (van Deemter 2000). Moreover, they disregard shades of salience (unlike algorithms proposed in Krahmer and Theune [1999], Theune [2000]), relying instead on a simple dichotomy between those objects that are salient enough (which end up in the domain D) and those that are not (Reiter and Dale 2000, Section 5.4). Finally, like all other GRE algorithms that we are aware of, they disregard the generation of descriptions in intensional contexts (e.g., John knows that x is the murderer ofJones; Dowty</context>
</contexts>
<marker>Dale, Haddock, 1991</marker>
<rawString>Dale, Robert and N. Haddock. 1991. Generating referring expressions involving relations. In Proceedings of the 9th Meeting of the European Chapter of the Association for Computational Linguistics, pages 161–166, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the Gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>18</volume>
<pages>233--263</pages>
<contexts>
<context position="634" citStr="Dale and Reiter (1995)" startWordPosition="81" endWordPosition="84">eferring Expressions: Boolean Extensions of the Incremental Algorithm Kees van Deemter* University of Brighton This paper brings a logical perspective to the generation of referring expressions, addressing the incompleteness of existing algorithms in this area. After studying references to individual objects, we discuss references to sets, including Boolean descriptions that make use of negated and disjoined properties. To guarantee that a distinguishing description is generated whenever such descriptions exist, the paper proposes generalizations and extensions of the Incremental Algorithm of Dale and Reiter (1995). 1. Introduction Generation of referring expressions (GRE) is a key task of most natural language generation (NLG) systems (e.g., Reiter and Dale 2000, Section 5.4). Regardless of the type of knowledge base (KB) forming the input to the generator, many objects will not be designated in it via an ordinary proper name. A person like Mr. Jones, for example, may be designated using an artificial name like #Jones083, if the name Jones is not uniquely distinguishing. The same is true for a piece of furniture, a tree, or an atomic particle, for instance, for which no proper name is in common use at </context>
<context position="2206" citStr="Dale and Reiter 1995" startWordPosition="348" endWordPosition="351"> description may be necessary. Henceforth, we will call the intended referent the target of the GRE algorithm. The question that we set out to answer is whether existing GRE algorithms produce adequate descriptions whenever such descriptions exist: in short, whether these algorithms are, as we shall say, complete. The paper brings a degree of formal precision to this issue and reveals a number of reasons why current GRE algorithms are incomplete; we sketch remedies and discuss their consequences in terms of linguistic coverage and computational tractability. We take the Incremental Algorithm (Dale and Reiter 1995) to represent the state of the art in this area, and we minimize the deviations from this algorithm. As a result, this paper might be read as an investigation into how widely the ideas underlying the Incremental Algorithm can be used, and the extent to which they may be generalized. The main generalization that we will investigate involves complex Boolean combinations of properties, that is, descriptions that involve more than a merely intersective (i.e., logically conjunctive) combination of properties. Such generalizations are natural because the properties involved are implicitly present in</context>
<context position="3971" citStr="Dale and Reiter (1995)" startWordPosition="613" endWordPosition="616">s are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combination of properties can be expressed by the NLG module responsible for linguistic realization. This modular approach allows us to separate logical aspects of generation (which are largely language independent) from purely linguistic aspects, and it allows the realization module to base its decisions on complete information about which combination of properties is to be realized. Accordingly, when we write Generation of Referring Expressions or GRE, we will refe</context>
<context position="5624" citStr="Dale and Reiter (1995)" startWordPosition="872" endWordPosition="875">oser look at the algorithm in its standard, “intersective” form, in which it identifies an object by intersecting a number of atomic properties. We discuss cases in which this algorithm fails to find an adequate description even though such a description exists, and we propose a number of possible remedies. Having extablished a completeness result for a version of the intersective Incremental Algorithm, we turn to questions of completeness that involve more complex Boolean combinations in Section 4. In Section 5, we summarize the main results of our exploration and put them in perspective. 2. Dale and Reiter (1995): The Incremental Algorithm The Incremental Algorithm of Dale and Reiter (1995) singles out a target object from among some larger domain of entities. It does this by logically conjoining a number of properties found in a part of the KB that represents information shared between speaker and hearer. The authors observed that the problem of finding a (“Full Brevity”) description that contains the minimum number of properties is computationally intractable (i.e., NP Hard). They combined this with the known fact that speakers often produce nonminimal descriptions anyway (e.g., Pechman 1989). Accor</context>
<context position="9911" citStr="Dale and Reiter 1995" startWordPosition="1621" endWordPosition="1624">s from C} then do L := L U {Pi} {Property Pi is added to L} C := C n [[Pi]] {All elements outside [[Pi]] are removed} If C = {r} then Return L {Success} Return Failure {All properties in P have been tested, and still C =� {r}} Assuming (as do Dale and Reiter [1995]) that the tests in the body of the loop take some constant amount of time, the worst-case running time is on the order of na (i.e., O(na)), where na is the total number of properties. So, the algorithm has only linear complexity. A slightly closer approximation of Full Brevity can be achieved if Attributes and Values are separated (Dale and Reiter 1995), allowing the algorithm to choose the “best” Value for each Attribute. Given an Attribute, FindBestValue selects the Value that removes most distractors while still including the target r. If no Value includes r, the function returns nil. In case of a tie (i.e., no Value removes more distractors than all others), FindBestValue chooses the least specific of the contestants. For example, 2 Thus, C contains r, unlike in Dale and Reiter (1995). The difference is purely presentational. 39 Computational Linguistics Volume 28, Number 1 when dog rules out as many distractors as chihuahua, chihuahua c</context>
<context position="13390" citStr="Dale and Reiter 1995" startWordPosition="2196" endWordPosition="2199">n Attribute: their extensions should not “overlap” in the following precise sense: Values Vi,j and Vi,k (and equally, their extensions) overlap iff Vi,j n Vi,k, Vi,j − Vi,k, and Vi,k − Vi,j are all nonempty. 3 Dale and Reiter arrived at linearity via the difficult concept of typical running time. They assumed that, typically, nl (i.e., the number of properties in the description) is proportional to the number of Attributes examined by the algorithm (Ehud Reiter, personal communication). This allowed them to argue that the typical running time is O(ndnl), where nd is the number of distractors (Dale and Reiter 1995, Section 3.1). Our own worst-case assessment does not rely on assumptions of typicality. 40 van Deemter Generating Referring Expressions (If Vi,j and Vi,k do not overlap, then either [[Vi,j]]  [[Vi,k]], or [[Vi,k]]  [[Vi,j]], or [[Vi,j]] and [[Vi,k]] have an empty intersection.) Values can overlap for different reasons. Some Attributes (e.g., COLOR) have “vague” Values (e.g., RED, ORANGE), which may be modeled as overlapping: some objects may count as both red and orange. Also, Values may derive from particular parts or aspects of an object; for example, if an object counts as METAL (PLASTI</context>
<context position="37434" citStr="Dale and Reiter (1995" startWordPosition="6419" endWordPosition="6422"> 1 unclear whether this is descriptively adequate. Adaptations can be made if needed. For instance, phases might run separately before running in combination: first (as usual) Phase 1, then 2, then (as usual) 1&amp;2, then 3, then 1&amp;3, then 2&amp;3, then (as usual) 1&amp;2&amp;3, and so on.8 As a result of this adaptation, the description Y U Z would be generated because of Phase 2 alone. Double incrementality, however, does not save D&amp;RBoolean from intractability. To estimate running time as a function of the number of properties (na) in the KB and those in the description (nl), we can mirror an argument in Dale and Reiter (1995, Section 3.1.1) to show that the maximal number of properties to be considered equals �nl n i=1 (na) = n, na!2 2 na − i)!. i i=1 (The factor of 2 derives from inspecting both each atom and its negation.) If nl « na, then this is on the order of nnl a . To avoid intractability, the algorithm can be pruned. No matter where this is done, the result is a polynomial algorithm. By cutting off after Phase 1, for example, only (negations of) atomic properties are combined, producing such descriptions as the black dog that is not a poodle, disregarding more complex descriptions; as a result, completen</context>
<context position="45845" citStr="Dale and Reiter 1995" startWordPosition="7846" endWordPosition="7849"> (2001). Their approach is specifically suitable for accommodating different GRE algorithms and treats relations in the same way as properties Brevity. We have assumed that, on the whole, descriptions ought to be as brief as they can, as long as they are uniquely identifying. But in fact, a description can contain much more than is logically necessary for identification, even beyond the redundancies allowed by the Incremental Algorithm. Logically superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractability has also been paramo</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Dale, Robert and Ehud Reiter. 1995. Computational interpretations of the Gricean maxims in the generation of referring expressions. Cognitive Science, 18, 233–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
<author>Eduard Hovy</author>
</authors>
<title>Aggregation in natural language generation.</title>
<date>1996</date>
<booktitle>Trends in Natural Language Generation: An Artificial Intelligence Perspective.</booktitle>
<pages>88--105</pages>
<editor>In G. Adorni and M. Zock, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>New York,</location>
<contexts>
<context position="18174" citStr="Dalianis and Hovy 1996" startWordPosition="3017" endWordPosition="3020">onal Linguistics Volume 28, Number 1 algorithm will go on to select the property BROWN, resulting in a set of properties that may be realized as the brown desk bought by Sony and by Philips. Such descriptions appear to be quite natural. One might even argue, on Gricean grounds (Grice 1975), that identifying a simply as being bought by Philips can give rise to the false implicature that a was not bought by Sony. This suggests that the proposed algorithm might also be empirically more accurate than the one using limited backtracking provided, of course, properties are properly aggregated (e.g., Dalianis and Hovy 1996). 3.2 Assumptions Concerning Infinite Sets To prove intersective completeness, certain assumptions concerning the cardinality of sets need to be made. To give an extreme example, suppose one wanted to refer to a real number that does not have a “proper name” (unlike, e.g., 7r); then the class of potentially useful properties is so vast that no GRE algorithm can take them all into consideration. As long as the number of properties (i.e., Attribute/Value combinations) is denumerably infinite (Kleene 1971), only termination becomes problematic: if a uniquely referring description [[P1]] n · · · n</context>
</contexts>
<marker>Dalianis, Hovy, 1996</marker>
<rawString>Dalianis, Hercules and Eduard Hovy. 1996. Aggregation in natural language generation. In G. Adorni and M. Zock, editors, Trends in Natural Language Generation: An Artificial Intelligence Perspective. Springer-Verlag, New York, pages 88–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
<author>Robert Wall</author>
<author>Stanley Peters</author>
</authors>
<title>Introduction to Montague Semantics.</title>
<date>1981</date>
<location>D. Reidel, Dordrecht.</location>
<marker>Dowty, Wall, Peters, 1981</marker>
<rawString>Dowty, David, Robert Wall, and Stanley Peters. 1981. Introduction to Montague Semantics. D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melvin Fitting</author>
</authors>
<title>First-Order Logic and Automated Theorem Proving.</title>
<date>1996</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="41371" citStr="Fitting 1996" startWordPosition="7098" endWordPosition="7099">e proved intersective completeness for two versions of Dale and Reiter’s Incremental Algorithm, D&amp;R and D&amp;RAtt. We now prove Boolean completeness for D&amp;RBoolean, the Boolean extension of D&amp;RPlural. Theorem 3: Completeness of D&amp;RBOOk. Assume there are at most denumerably many properties, and finitely many distractors (one or more). Then if a set can be individuated distributively by any Boolean combination of properties, D&amp;RBoolean will find such a combination. Proof Any Boolean expression can be written in conjunctive normal form (CNF), that is, as an intersection of unions of literals (e.g., Fitting 1996). Theorem 3 follows from the following lemma. Lemma Let cp be a CNF formula whose longest union has a length of n (i.e., it conjoins n literals). Then D&amp;RBoolean will find a description cp&apos; that is coextensive with cp, in at most n phases. This is proven by induction on the size of n. Basic case: If n = 1, the lemma is equivalent to completeness of D&amp;RPlural, the proof of which is analogous to that of the completeness of D&amp;R, replacing {r} by S. Induction step: Suppose the lemma is true for all n &lt; i. Now consider a CNF cp whose longest union has length i; let cp contain m unions of length i, </context>
</contexts>
<marker>Fitting, 1996</marker>
<rawString>Fitting, Melvin. 1996. First-Order Logic and Automated Theorem Proving. Springer-Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>Syntax and Semantics:</booktitle>
<volume>3</volume>
<pages>43--58</pages>
<editor>In P. Cole and J. Morgan, editors,</editor>
<publisher>Speech Acts. Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="17841" citStr="Grice 1975" startWordPosition="2966" endWordPosition="2967">well as a, the 4 This assumes that, once FindBestValue has found a Value V that removes distractors, one may need to inspect all the other Values of the same Attribute to find Values overlapping with V. Shortcuts are possible if Values are stored using a structure that reflects their semantic relationships. 41 Computational Linguistics Volume 28, Number 1 algorithm will go on to select the property BROWN, resulting in a set of properties that may be realized as the brown desk bought by Sony and by Philips. Such descriptions appear to be quite natural. One might even argue, on Gricean grounds (Grice 1975), that identifying a simply as being bought by Philips can give rise to the false implicature that a was not bought by Sony. This suggests that the proposed algorithm might also be empirically more accurate than the one using limited backtracking provided, of course, properties are properly aggregated (e.g., Dalianis and Hovy 1996). 3.2 Assumptions Concerning Infinite Sets To prove intersective completeness, certain assumptions concerning the cardinality of sets need to be made. To give an extreme example, suppose one wanted to refer to a real number that does not have a “proper name” (unlike,</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Grice, Paul. 1975. Logic and conversation. In P. Cole and J. Morgan, editors, Syntax and Semantics: Vol. 3: Speech Acts. Academic Press, New York, pages 43–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Horacek</author>
</authors>
<title>An algorithm for generating referential descriptions with flexible interfaces.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>206--213</pages>
<location>Madrid.</location>
<contexts>
<context position="3885" citStr="Horacek 1997" startWordPosition="601" endWordPosition="602"> will identify and confront a number of cases in which current GRE algorithms are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combination of properties can be expressed by the NLG module responsible for linguistic realization. This modular approach allows us to separate logical aspects of generation (which are largely language independent) from purely linguistic aspects, and it allows the realization module to base its decisions on complete information about which combination of properties is to be realize</context>
<context position="6845" citStr="Horacek 1997" startWordPosition="1060" endWordPosition="1061">hey proposed an algorithm that only approximates Full Brevity, while being of only linear complexity. Our summary of the algorithm glosses over many details, yet still allows us to discuss completeness. In particular, we disregard any special provisions that might be made for the selection of head nouns because, arguably, this has to involve realizational issues.1 1 Compare Dale and Reiter (1995), where head nouns are taken into account during content determination. Head nouns can also be selected during linguistic realization or by interleaving of content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). 38 van Deemter Generating Referring Expressions The Incremental Algorithm produces a set L of properties P1,. . . , Pn such that their logical conjunction forms a “distinguishing description” (Dale 1989) of the target object r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have the property Q), the intersection [[P1]] n · · · n [[Pn]] must equal the singleton set {r}. It is a “hillclimbing” algorithm, which finds better and better approximations of the target set {r} by accumulating more and more propertie</context>
<context position="42973" citStr="Horacek 1997" startWordPosition="7413" endWordPosition="7414">, such that [[77]] C [[x]]. Also, [[cp]] C [77]]. Phase i inspects all unions of length i, including each of cp1, ... , cpm. Therefore, unless a description coextensive with cp is found before phase i, one will be found during phase i. To see this, suppose the algorithm finds 0 such that [[0]] = [[cp1]] n · · · n [[cpm]]. Then [[x]] n [[0]] = [[cp]]; but [[cp]] C [77]] C [[x]], therefore also [[77]] n [[0]] = [[cp]]. 5. Conclusion The GRE algorithms discussed in this paper are fairly limited in their aspirations. For example, they do not involve relational descriptions (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001) or properties that are vague or context dependent (van Deemter 2000). Moreover, they disregard shades of salience (unlike algorithms proposed in Krahmer and Theune [1999], Theune [2000]), relying instead on a simple dichotomy between those objects that are salient enough (which end up in the domain D) and those that are not (Reiter and Dale 2000, Section 5.4). Finally, like all other GRE algorithms that we are aware of, they disregard the generation of descriptions in intensional contexts (e.g., John knows that x is the murderer ofJones; Dowty, Wall, and Pe</context>
<context position="46245" citStr="Horacek 1997" startWordPosition="7909" endWordPosition="7910">ed by the Incremental Algorithm. Logically superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractability has also been paramount in our explorations. There is no agreement on the extent to which computational linguists should worry about the computational complexity of algorithms, or about the precise way in which complexity is most relevant (e.g., “typical” or worst-case complexity, cf. footnote 3). Far from aiming to speak the last word on these issues, the material discussed here does shed some light on them. For exa</context>
</contexts>
<marker>Horacek, 1997</marker>
<rawString>Horacek, Helmut. 1997. An algorithm for generating referential descriptions with flexible interfaces. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 206–213. Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Jordan</author>
</authors>
<title>Contextual influences on the attributes included in repeated descriptions.</title>
<date>1999</date>
<booktitle>In Proceedings of the Workshop “Generation of Nominal Expressions,” 11th European Summer School in Logic, Language, and Information (ESSLLI’99),</booktitle>
<editor>in K. van Deemter and R. Kibble, editors, Information Sharing.</editor>
<publisher>CSLI Publications,</publisher>
<location>Utrecht.</location>
<note>Augmented version to appear</note>
<contexts>
<context position="45895" citStr="Jordan 1999" startWordPosition="7856" endWordPosition="7857">modating different GRE algorithms and treats relations in the same way as properties Brevity. We have assumed that, on the whole, descriptions ought to be as brief as they can, as long as they are uniquely identifying. But in fact, a description can contain much more than is logically necessary for identification, even beyond the redundancies allowed by the Incremental Algorithm. Logically superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractability has also been paramount in our explorations. There is no agreement on </context>
</contexts>
<marker>Jordan, 1999</marker>
<rawString>Jordan, Pamela. 1999. Contextual influences on the attributes included in repeated descriptions. In Proceedings of the Workshop “Generation of Nominal Expressions,” 11th European Summer School in Logic, Language, and Information (ESSLLI’99), Utrecht. Augmented version to appear in K. van Deemter and R. Kibble, editors, Information Sharing. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="27598" citStr="Kamp and Reyle 1993" startWordPosition="4691" endWordPosition="4694">C = S then Return L {Success} Return Failure Once again, these adaptations leave the algorithm structurally unchanged: sets replace objects throughout. Yet, they cause the complexity of the algorithm to become exponential, since testing whether C = S involves inspecting all elements of C, of which there can be up to 2nd (where nd is the cardinality of the domain D). This algorithm can also be applied to distributive properties if these are upgraded to the level of sets: Let a newfangled distributive property be true of a set iff the property (in ordinary parlance) is true of all its elements (Kamp and Reyle 1993, page 338). This requires that the target S is always cast as a set of sets, even if it is viewed distributively. For example, if a set of players—say, a, b, and c—are to be characterized as a collection (e.g., to say that they won as a team of three), then S = {{a, b, c}}; if they are to be characterized distributively (e.g., to say that each of them has the flu), then S = {{a, b, c}, {a, b}, {a, c}, {b, c}, {a}, {b}, {c}}. In this way, the algorithm is able to combine collective and distributive properties, as in those football teams whose members are British. We will not explore collective</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, Hans and Uwe Reyle. 1993. From Discourse to Logic. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodger Kibble</author>
</authors>
<title>Cb or not Cb? Centering Theory applied to NLG.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL Workshop “Discourse/Dialogue Structure and Reference,”</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="3550" citStr="Kibble 1999" startWordPosition="549" endWordPosition="550"> of Brighton, Lewes Road, Brighton BN2 4GJ, UK. E-mail: Kees.van.Deemter@itri.brighton.ac.uk. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 algorithms are also generalized to generate references to sets, rather than individual objects. But, before we arrive at these generalizations, we will identify and confront a number of cases in which current GRE algorithms are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combination of properties can be expressed by the </context>
</contexts>
<marker>Kibble, 1999</marker>
<rawString>Kibble, Rodger. 1999. Cb or not Cb? Centering Theory applied to NLG. In Proceedings of the ACL Workshop “Discourse/Dialogue Structure and Reference,” College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen C Kleene</author>
</authors>
<title>Introduction to Metamathematics.</title>
<date>1971</date>
<location>Wolters-Noordhoff. Groningen.</location>
<contexts>
<context position="18682" citStr="Kleene 1971" startWordPosition="3099" endWordPosition="3100">ited backtracking provided, of course, properties are properly aggregated (e.g., Dalianis and Hovy 1996). 3.2 Assumptions Concerning Infinite Sets To prove intersective completeness, certain assumptions concerning the cardinality of sets need to be made. To give an extreme example, suppose one wanted to refer to a real number that does not have a “proper name” (unlike, e.g., 7r); then the class of potentially useful properties is so vast that no GRE algorithm can take them all into consideration. As long as the number of properties (i.e., Attribute/Value combinations) is denumerably infinite (Kleene 1971), only termination becomes problematic: if a uniquely referring description [[P1]] n · · · n [[Pn]] exists, then the algorithm will find one in finite time, since each of the n properties in the description will be found in finite time; if no distinguishing description exists, however, the algorithm never terminates. In the less likely case where the set of properties is nondenumerably infinite (i.e., it does not stand in a 1-1 relation to any set of natural numbers), completeness becomes problematic as well, since it is impossible for the algorithm to consider all properties; hence, successfu</context>
</contexts>
<marker>Kleene, 1971</marker>
<rawString>Kleene, Stephen C. 1971. Introduction to Metamathematics. Wolters-Noordhoff. Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Mari¨et Theune</author>
</authors>
<title>Generating descriptions in context.</title>
<date>1999</date>
<booktitle>In Proceedings of the Workshop “Generation of Nominal Expressions,” 11th European Summer School in Logic, Language, and Information (ESSLLI’99),</booktitle>
<editor>in K. van Deemter and R. Kibble, editors, Information Sharing.</editor>
<publisher>CSLI Publications,</publisher>
<location>Utrecht.</location>
<note>Augmented version to appear</note>
<contexts>
<context position="6894" citStr="Krahmer and Theune 1999" startWordPosition="1066" endWordPosition="1069">pproximates Full Brevity, while being of only linear complexity. Our summary of the algorithm glosses over many details, yet still allows us to discuss completeness. In particular, we disregard any special provisions that might be made for the selection of head nouns because, arguably, this has to involve realizational issues.1 1 Compare Dale and Reiter (1995), where head nouns are taken into account during content determination. Head nouns can also be selected during linguistic realization or by interleaving of content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). 38 van Deemter Generating Referring Expressions The Incremental Algorithm produces a set L of properties P1,. . . , Pn such that their logical conjunction forms a “distinguishing description” (Dale 1989) of the target object r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have the property Q), the intersection [[P1]] n · · · n [[Pn]] must equal the singleton set {r}. It is a “hillclimbing” algorithm, which finds better and better approximations of the target set {r} by accumulating more and more properties—hence the term Incremental. There is no backtra</context>
<context position="46294" citStr="Krahmer and Theune 1999" startWordPosition="7915" endWordPosition="7918">cally superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractability has also been paramount in our explorations. There is no agreement on the extent to which computational linguists should worry about the computational complexity of algorithms, or about the precise way in which complexity is most relevant (e.g., “typical” or worst-case complexity, cf. footnote 3). Far from aiming to speak the last word on these issues, the material discussed here does shed some light on them. For example, even a fast algorithm can require a large n</context>
</contexts>
<marker>Krahmer, Theune, 1999</marker>
<rawString>Krahmer, Emiel and Mari¨et Theune. 1999. Generating descriptions in context. In Proceedings of the Workshop “Generation of Nominal Expressions,” 11th European Summer School in Logic, Language, and Information (ESSLLI’99), Utrecht. Augmented version to appear in K. van Deemter and R. Kibble, editors, Information Sharing. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Sebastiaan van Erk</author>
<author>Andre´ Verleg</author>
</authors>
<title>A meta-algorithm for the generation of referring expressions.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th European Workshop on Natural Language Generation (EWNLG’01),</booktitle>
<pages>29--38</pages>
<location>Toulouse, France.</location>
<marker>Krahmer, van Erk, Verleg, 2001</marker>
<rawString>Krahmer, Emiel, Sebastiaan van Erk, and Andre´ Verleg. 2001. A meta-algorithm for the generation of referring expressions. In Proceedings of the 8th European Workshop on Natural Language Generation (EWNLG’01), pages 29–38, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward J McCluskey</author>
</authors>
<title>Introduction to the Theory of Switching.</title>
<date>1965</date>
<publisher>McGraw-Hill,</publisher>
<location>New York.</location>
<contexts>
<context position="32899" citStr="McCluskey 1965" startWordPosition="5611" endWordPosition="5612"> by making use of negations of intersections of two literals, and so on, until either C = S (Success) or all combinations have been tried (Failure). Observe that the negation of an intersection comes down to set union, because of De Morgan’s Law: P1 n · · · n Pn = P1 U · · · U Pn. Thus, Phase 2 of the algorithm deals with disjunctions of length 2, Phase 3 deals with disjunctions of length 3, and so on. Optimizations may be applied to shorten the resulting descriptions. For instance, a description of the form (P U Q) n (P U R) can be simplified to (P U (Q n R)) using standard algorithms (e.g., McCluskey 1965). Such optimizations, however, are less urgent than in the case of the more verbose descriptions generated using Satellite sets (see above), and we will disregard optimizations here. A schematic presentation may be useful, in which P+1_ stands for any literal, that is, any atomic property or its negation. (Different occurrences of P+1_ denote potentially different literals.) The length of a property will equal the number of literals 7 The idea of Satellite sets is due to Magn´us Halld´orsson (personal communication). 46 van Deemter Generating Referring Expressions occurring in it. We will say </context>
</contexts>
<marker>McCluskey, 1965</marker>
<rawString>McCluskey, Edward J. 1965. Introduction to the Theory of Switching. McGraw-Hill, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vibhu O Mittal</author>
<author>Joanna D Moore</author>
<author>Giuseppe Carenini</author>
<author>Steven Roth</author>
</authors>
<title>Describing complex charts in natural language: A caption generation system.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<pages>431--468</pages>
<contexts>
<context position="3536" citStr="Mittal et al. 1998" startWordPosition="545" endWordPosition="548">e (ITRI), University of Brighton, Lewes Road, Brighton BN2 4GJ, UK. E-mail: Kees.van.Deemter@itri.brighton.ac.uk. © 2002 Association for Computational Linguistics Computational Linguistics Volume 28, Number 1 algorithms are also generalized to generate references to sets, rather than individual objects. But, before we arrive at these generalizations, we will identify and confront a number of cases in which current GRE algorithms are incomplete even with respect to merely intersective descriptions. In this paper, we will deal with “first mention” descriptions only (unlike Dale 1992, Chapter 5; Mittal et al. 1998; Kibble 1999), assuming that the information used for generating the description is limited to a KB containing complete information about which properties are true of each object. Also, we focus on “one shot” descriptions, disregarding cases where an object is described through its relations with other objects (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001). More crucially, we follow Dale and Reiter (1995) in focusing on the semantic content of a description (i.e., the problem of content determination, for short), assuming that any combination of properties can be exp</context>
</contexts>
<marker>Mittal, Moore, Carenini, Roth, 1998</marker>
<rawString>Mittal, Vibhu O., Joanna D. Moore, Giuseppe Carenini, and Steven Roth. 1998. Describing complex charts in natural language: A caption generation system. Computational Linguistics, 24, 431–468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivandr ´e Paraboni</author>
</authors>
<title>An algorithm for generating document-deictic references.</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop “Coherence in Generated Multimedia,” 1st International Conference on Natural Language Generation (INLG’00),</booktitle>
<pages>27--31</pages>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="48231" citStr="Paraboni (2000)" startWordPosition="8234" endWordPosition="8235">tes on unlimited cases” (Barton, Berwick, and Ristad 1987, Section 1.4.1). Be this as it may, we believe that complexity theory can offer valuable insights into the structure of GRE algorithms and that the growing attention to complexity in this area is a healthy development even if the practical implications are not always straightforward. Recent work also highlights an interesting mirror image of GRE complexity: a logically superfluous property may make it easier for the reader to find the referent. 50 van Deemter Generating Referring Expressions An interesting class of cases is explored in Paraboni (2000), which focuses on descriptions of document parts. Consider the description the medicine depicted in Section 2.3. If Section 2 happens to contain only one figure, then the description the medicine depicted in Section 2 would have been logically sufficient, but this description would have made it necessary for the reader, in the worst case, to search through all of Section 2, making it less useful. Examples of this kind suggest that GRE should also take the computational complexity of interpretation into account. Experimental research on “minimal cooperative effort” (Clark 1992; Cremers 1996) p</context>
</contexts>
<marker>Paraboni, 2000</marker>
<rawString>Paraboni, Ivandr ´e. 2000. An algorithm for generating document-deictic references. In Proceedings of the Workshop “Coherence in Generated Multimedia,” 1st International Conference on Natural Language Generation (INLG’00), pages 27–31, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Pechman</author>
</authors>
<title>Incremental speech production and referential overspecification.</title>
<date>1989</date>
<journal>Linguistics,</journal>
<volume>27</volume>
<pages>89--110</pages>
<contexts>
<context position="6217" citStr="Pechman 1989" startWordPosition="967" endWordPosition="968">le and Reiter (1995): The Incremental Algorithm The Incremental Algorithm of Dale and Reiter (1995) singles out a target object from among some larger domain of entities. It does this by logically conjoining a number of properties found in a part of the KB that represents information shared between speaker and hearer. The authors observed that the problem of finding a (“Full Brevity”) description that contains the minimum number of properties is computationally intractable (i.e., NP Hard). They combined this with the known fact that speakers often produce nonminimal descriptions anyway (e.g., Pechman 1989). Accordingly, they proposed an algorithm that only approximates Full Brevity, while being of only linear complexity. Our summary of the algorithm glosses over many details, yet still allows us to discuss completeness. In particular, we disregard any special provisions that might be made for the selection of head nouns because, arguably, this has to involve realizational issues.1 1 Compare Dale and Reiter (1995), where head nouns are taken into account during content determination. Head nouns can also be selected during linguistic realization or by interleaving of content determination and rea</context>
</contexts>
<marker>Pechman, 1989</marker>
<rawString>Pechman, Thomas. 1989. Incremental speech production and referential overspecification. Linguistics, 27, 89–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha E Pollack</author>
</authors>
<title>Overloading intentions for efficient practical reasoning.</title>
<date>1991</date>
<journal>No ˆus,</journal>
<volume>25</volume>
<pages>513--536</pages>
<contexts>
<context position="45823" citStr="Pollack 1991" startWordPosition="7844" endWordPosition="7845">rk, and Verleg (2001). Their approach is specifically suitable for accommodating different GRE algorithms and treats relations in the same way as properties Brevity. We have assumed that, on the whole, descriptions ought to be as brief as they can, as long as they are uniquely identifying. But in fact, a description can contain much more than is logically necessary for identification, even beyond the redundancies allowed by the Incremental Algorithm. Logically superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractabilit</context>
</contexts>
<marker>Pollack, 1991</marker>
<rawString>Pollack, Martha E. 1991. Overloading intentions for efficient practical reasoning. No ˆus, 25: 513–536.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="785" citStr="Reiter and Dale 2000" startWordPosition="105" endWordPosition="108"> the generation of referring expressions, addressing the incompleteness of existing algorithms in this area. After studying references to individual objects, we discuss references to sets, including Boolean descriptions that make use of negated and disjoined properties. To guarantee that a distinguishing description is generated whenever such descriptions exist, the paper proposes generalizations and extensions of the Incremental Algorithm of Dale and Reiter (1995). 1. Introduction Generation of referring expressions (GRE) is a key task of most natural language generation (NLG) systems (e.g., Reiter and Dale 2000, Section 5.4). Regardless of the type of knowledge base (KB) forming the input to the generator, many objects will not be designated in it via an ordinary proper name. A person like Mr. Jones, for example, may be designated using an artificial name like #Jones083, if the name Jones is not uniquely distinguishing. The same is true for a piece of furniture, a tree, or an atomic particle, for instance, for which no proper name is in common use at all, or (in most cases) if the generator tries to refer to an entire set of objects. In all such cases, the generator has to “invent” a description tha</context>
<context position="8901" citStr="Reiter and Dale 2000" startWordPosition="1424" endWordPosition="1427">out; if so, the Attribute is added to L, with a suitable Value (FindBestValue, below). C is the set of “confusables” at any given stage of the algorithm.2 Objects that are ruled out are removed from C. The process of expanding L and contracting C continues until C = {r}; if and when this condition is met, L is a distinguishing set of properties. For easy generalizability, the algorithm will be cast in set-theoretic terms. We first present a version that focuses on properties, without separating these into Attributes and Values, and assume the properties themselves are ordered in a list P (cf. Reiter and Dale 2000). This version of the algorithm will be called D&amp;RProp, or D&amp;R when there is no risk of confusion. We assume that the domain contains one or more objects other than the target object, the so-called distractors: thus, r E D but {r} =� D. L := 0 {L is initialized to the empty set} C := D {C is initialized to the domain} For each Pi E P do If r E [[Pi]] &amp; C C� [[Pi]] {Pi removes distractors from C} then do L := L U {Pi} {Property Pi is added to L} C := C n [[Pi]] {All elements outside [[Pi]] are removed} If C = {r} then Return L {Success} Return Failure {All properties in P have been tested, and </context>
<context position="43357" citStr="Reiter and Dale 2000" startWordPosition="7473" endWordPosition="7476">x]], therefore also [[77]] n [[0]] = [[cp]]. 5. Conclusion The GRE algorithms discussed in this paper are fairly limited in their aspirations. For example, they do not involve relational descriptions (Dale and Haddock 1991; Horacek 1997; Krahmer, van Erk, and Verleg 2001) or properties that are vague or context dependent (van Deemter 2000). Moreover, they disregard shades of salience (unlike algorithms proposed in Krahmer and Theune [1999], Theune [2000]), relying instead on a simple dichotomy between those objects that are salient enough (which end up in the domain D) and those that are not (Reiter and Dale 2000, Section 5.4). Finally, like all other GRE algorithms that we are aware of, they disregard the generation of descriptions in intensional contexts (e.g., John knows that x is the murderer ofJones; Dowty, Wall, and Peters 1981). But even within this limited brief, existing algorithms are incomplete. In particular, we have shown Dale and Reiter’s (1995) Incremental Algorithm to be intersectively incomplete with respect to Attributes that have overlapping Values and (less surpris49 Computational Linguistics Volume 28, Number 1 ingly) in some situations where the class of properties is infinitely </context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Reiter, Ehud and Robert Dale. 2000. Building Natural Language Generation Systems. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
</authors>
<title>On identifying sets.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Conference on Natural Language Generation (INLG’00),</booktitle>
<pages>116--123</pages>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="25683" citStr="Stone 2000" startWordPosition="4334" endWordPosition="4335">� [[Pill then do L := L U {Pi} C := C n [[Pill If C = S then Return L {Success} Return Failure {All properties in P have been tested, yet C =� S} Note that S takes the place of the target object r in the earlier algorithms; the process of expanding L and contracting C continues until C = S. Because this is basically the same algorithm as D&amp;R, it has the same computational complexity of O(na), where na is the cardinality of P. D&amp;RPlural characterizes a set by scrutinizing its elements. This does not work for properties like BEING OF THE SAME AGE, which crucially pertain to sets of objects (cf. Stone 2000). The algorithm can, however, be generalized to cover such cases if we initialize C not to D but to the powerset of D, after which the algorithm selects properties of sets, removing from P(D) all those sets for which the property is false. For example, selection of BEING OF THE SAME AGE removes all those sets whose elements are not of the same age as each other, selection of FORMING A FOOTBALL TEAM removes all sets that do not make up a football team, and so on. As a result, the algorithm generates descriptions of sets of collective entities (i.e., sets of sets). In this way, descriptions such</context>
</contexts>
<marker>Stone, 2000</marker>
<rawString>Stone, Matthew. 2000. On identifying sets. In Proceedings of the 1st International Conference on Natural Language Generation (INLG’00), pages 116–123, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
<author>Bonnie Webber</author>
</authors>
<title>Textual economy through close coupling of syntax and semantics.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation (INLG’98),</booktitle>
<contexts>
<context position="6868" citStr="Stone and Webber 1998" startWordPosition="1062" endWordPosition="1065">n algorithm that only approximates Full Brevity, while being of only linear complexity. Our summary of the algorithm glosses over many details, yet still allows us to discuss completeness. In particular, we disregard any special provisions that might be made for the selection of head nouns because, arguably, this has to involve realizational issues.1 1 Compare Dale and Reiter (1995), where head nouns are taken into account during content determination. Head nouns can also be selected during linguistic realization or by interleaving of content determination and realization (e.g., Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). 38 van Deemter Generating Referring Expressions The Incremental Algorithm produces a set L of properties P1,. . . , Pn such that their logical conjunction forms a “distinguishing description” (Dale 1989) of the target object r. In other words, writing [[Q]] for the extension of Q (i.e., the set of objects that have the property Q), the intersection [[P1]] n · · · n [[Pn]] must equal the singleton set {r}. It is a “hillclimbing” algorithm, which finds better and better approximations of the target set {r} by accumulating more and more properties—hence the term Increm</context>
<context position="45881" citStr="Stone and Webber 1998" startWordPosition="7852" endWordPosition="7855">ally suitable for accommodating different GRE algorithms and treats relations in the same way as properties Brevity. We have assumed that, on the whole, descriptions ought to be as brief as they can, as long as they are uniquely identifying. But in fact, a description can contain much more than is logically necessary for identification, even beyond the redundancies allowed by the Incremental Algorithm. Logically superfluous properties can, for example, be motivated by “overloading” if they serve communicative purposes other than identification (Pollack 1991; Dale and Reiter 1995, Section 2.4; Stone and Webber 1998; Jordan 1999). A description may also contain fewer properties than would be necessary for identification—for example, when no distinguishing description exists. A nondistinguishing description may take the form either of a definite description (as in John’s son, when John has several sons) or of an indefinite description (as in one of John’s sons; Horacek 1997; Stone and Webber 1998; Krahmer and Theune 1999). In both cases, the description may be useful even though it fails to be distinguishing. Tractability. Computational tractability has also been paramount in our explorations. There is no</context>
</contexts>
<marker>Stone, Webber, 1998</marker>
<rawString>Stone, Matthew and Bonnie Webber. 1998. Textual economy through close coupling of syntax and semantics. In Proceedings of the 9th International Workshop on Natural Language Generation (INLG’98),</rawString>
</citation>
<citation valid="false">
<pages>178--187</pages>
<location>Niagara-on-the-Lake, Canada.</location>
<marker></marker>
<rawString>pages 178–187, Niagara-on-the-Lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari¨et Theune</author>
</authors>
<title>From Data to Speech: Language Generation in Context.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Eindhoven.</institution>
<marker>Theune, 2000</marker>
<rawString>Theune, Mari¨et. 2000. From Data to Speech: Language Generation in Context. Ph.D. thesis, University of Eindhoven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Generating vague descriptions.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Conference on Natural Language Generation (INLG’00),</booktitle>
<pages>179--185</pages>
<location>Mitzpe Ramon,</location>
<marker>van Deemter, 2000</marker>
<rawString>van Deemter, Kees. 2000. Generating vague descriptions. In Proceedings of the 1st International Conference on Natural Language Generation (INLG’00), pages 179–185, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Generating referring expressions: Beyond the incremental algorithm.</title>
<date>2001</date>
<booktitle>In Proceedings of the 4th International Workshop on Computational Semantics (IWCS’01),</booktitle>
<pages>50--66</pages>
<location>Tilburg, The Netherlands.</location>
<marker>van Deemter, 2001</marker>
<rawString>van Deemter, Kees. 2001. Generating referring expressions: Beyond the incremental algorithm. In Proceedings of the 4th International Workshop on Computational Semantics (IWCS’01), pages 50–66, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>van Deemter</author>
</authors>
<title>Kees and Magn ´us Halld ´orsson.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th European Workshop on Natural Language Generation (EWNLG’01),</booktitle>
<pages>21--28</pages>
<location>Toulouse, France.</location>
<marker>van Deemter, 2001</marker>
<rawString>van Deemter, Kees and Magn ´us Halld ´orsson. 2001. Logical form equivalence: The case of referring expressions generation. In Proceedings of the 8th European Workshop on Natural Language Generation (EWNLG’01), pages 21–28, Toulouse, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>