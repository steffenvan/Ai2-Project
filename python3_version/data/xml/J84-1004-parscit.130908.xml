<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.954158">
The FINITE STRING Newsletter
</title>
<author confidence="0.900157">
Site Report
</author>
<affiliation confidence="0.8414555">
Computational Linguistics Research at Duke
University
</affiliation>
<author confidence="0.5795825">
Faculty: Bruce Ballard, Alan Biermann
Consultants: Robert Rodman (Ph.D. in Linguistics),
David Rubin (Ph.D. in Psychology), Fran Heidlage
(Ph.D. in Physiology)
</author>
<affiliation confidence="0.846426666666667">
Students: William Cohen, Amr Fahmy, Linda Fineman,
Pamela Fink, Casey Gilbert, Gary Jackoway, Barry
Koster, John Lusth, Karen Stone, Nancy Tinkham
</affiliation>
<sectionHeader confidence="0.992945" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999927846153846">
Research in natural language (NL) processing at Duke
University began in the summer of 1977 with the de-
sign of the Natural Language Computer (NLC, an
extant automatic programming system that provides an
English-language programming environment for matrix
problems. An initial implementation of NLC was com-
pleted early in 1979, and a report on this first version
of the system appeared in AJCL the following year
(Biermann and Ballard 1980).
Since 1979 the number of persons doing computa-
tional linguistics research at Duke has grown from
three to somewhere over a dozen. During this time
our goals have grown to include interests in
</bodyText>
<listItem confidence="0.79292175">
(a) the design of task-oriented NL processors;
(b) facilities to respond to voice inputs;
(c) methods that enable an NL system to be easily
customized for new applications or for new users;
(d) human factors testing of NL processors; and
(e) the development of various formalisms that will
prove useful outside the context of the Duke sys-
tems.
</listItem>
<bodyText confidence="0.99752">
We summarize our activities in each of these areas
below.
</bodyText>
<sectionHeader confidence="0.985924" genericHeader="keywords">
2. Task-Oriented Systems
</sectionHeader>
<bodyText confidence="0.999808256410256">
This work assumes a user is seated behind a computer
display with a problem to be solved. The objects relat-
ed to the task domain are visible on the screen and
can be manipulated via natural language commands.
The effect of each user input is immediately indicated
on the screen, so the user can continuously verify that
correct action is taking place. If an undesired result is
noticed, the user can request a backup and then re-
phrase the command.
The first task-oriented natural language system built at
Duke, the NLC, was designed to do matrix calcula-
tions. A user of NLC can request the display of one or
several matrices, enter data into them, label rows and
columns, and perform a variety of arithmetic opera-
tions. For example, if a certain matrix is currently in
focus, the user might say
&amp;quot;Add the sum of the positive entries in row 1 to
the last negative element of the matrix.&amp;quot;
In addition to providing a fairly broad coverage of
pronouns and conjunctions, NLC includes special
&amp;quot;programming&amp;quot; features to allow for procedure defini-
tion (Ballard 1979), loops (Sigmon 1981), and condi-
tionals (Fink 1983).
Our second task-oriented system, VIPS, represents
a greatly simplified redesign of NLC and is aimed at
office automation applications (Biermann and Ballard
1983). VIPS has been implemented to handle text
manipulations from voice commands supplemented by
touch inputs. For example,
&amp;quot;Put this sentence [touch] after the last sen-
tence in this [touch] paragraph.&amp;quot;
Touch inputs to VIPS are currently handled via a Car-
roll 19-inch high-resolution color display unit with
touch-sensitive screen.
Current work related to task-oriented systems in-
cludes the evolution of a &amp;quot;micro-model&amp;quot; of a generic
processor which will enable precise statements to be
made concerning the construction and capabilities of
specific systems.
</bodyText>
<sectionHeader confidence="0.975833" genericHeader="introduction">
3. Voice-Interactive Processing
</sectionHeader>
<bodyText confidence="0.972581173913044">
Based upon our experience with typed English inputs,
we became interested in developing high quality real-
time voice interactive natural language processors. In
1982, we purchased a Nippon DP-200 connected
speech recognizer and a Votan V-5000 speech recog-
nizer and voice response unit, and have invested con-
siderable effort in learning their characteristics. During
this period, the VIPS system mentioned above was
designed, and NLC was redesigned for voice input. A
tape of the resulting VNLC system was played last
year at the Applied Natural Language meeting in San-
ta Monica (Biermann et al. 1983) and the VNLC sys-
tem was given its first public demonstration at an
ACM regional meeting in April 1983.
More recently we have begun to work with a Ver-
bex 3000 continuous speech recognizer, and some in-
teresting research questions have arisen. For instance,
we are investigating the possible advantages of
&amp;quot;discrete&amp;quot; speech, where a 300 millisecond pause must
follow every word, over the more natural &amp;quot;connected&amp;quot;
speech, where word boundaries may merge. Though
slow and unnatural, discrete speech has the advantage
Computational Linguistics, Volume 10, Number 1, January-March 1984 33
</bodyText>
<subsectionHeader confidence="0.921934">
The FINITE STRING Newsletter
</subsectionHeader>
<bodyText confidence="0.9987548">
that its increased recognizability makes it possible to
use larger vocabularies and still maintain robust behav-
ior. Connected speech allows much faster and more
comfortable input, but with an accompanying loss of
reliability and/or vocabulary size.
</bodyText>
<sectionHeader confidence="0.678878" genericHeader="method">
4. Adaptability and Transportability
</sectionHeader>
<bodyText confidence="0.999974">
Although several natural language processors provide
customization facilities that allow users to specify syno-
nyms, syntactic paraphrases, and the like, most exist-
ing systems are restricted to a particular domain of
data to be accessed. Thus, users are unable to access
novel data without acquiring a new or modified proc-
essor specifically tailored to the new domain from the
system designer(s). For this reason, we have become
interested in allowing users to adapt an existing system
for a new domain of data. In addition to overt custom-
ization by users, we have also been interested in how a
system might adapt itself to the style and needs of an
individual user.
</bodyText>
<subsectionHeader confidence="0.99963">
4.1 The layered domain class (WC) system
</subsectionHeader>
<bodyText confidence="0.999753851851852">
The Layered Domain Class system (LDC) seeks to
allow users of a natural language system to customize
a processor to work with types of data unknown to the
initial system designers (Ballard, Lusth and Tinkham
1984a, 1984b). A secondary but also important fea-
ture of LDC is its ability to work with loosely-
structured input files, as opposed to more formal
structures required by conventional database manage-
ment systems and assumed by typical NL front-ends.
Besides the obvious technological advantage of a user-
customizable system, in terms of time and cost needed
to acquire a specialized processor, efforts at providing
transportable systems have scientific value in that they
disallow ad hoc solutions to seemingly domain-specific
problems in favor or methods based upon an under-
standing of the relation between the conceptual struc-
ture of a domain and the mechanisms needed to proc-
ess the language used in discussing it.
To render the customization problem tractable,
LDC restricts itself to &amp;quot;layered&amp;quot; domains (Ballard
1982), which emphasize containment relationships
among domain objects and thus generalize upon the
domains of LDC and VIPS. The initial interaction
between a user and LDC, which involves telling the
system about a new domain, consists of a knowledge-
acquisition session with the preprocessor, which we
call &amp;quot;Prep&amp;quot;. In particular, Prep asks for
</bodyText>
<listItem confidence="0.99674">
(1) the names of each type of &amp;quot;entity&amp;quot; (object) of
the domain;
(2) the nature of the relationships among entities;
(3) the English words that will be used as nouns,
verbs, and modifiers; and
(4) morphological and semantic properties of these
new words.
</listItem>
<bodyText confidence="0.998768666666667">
Having completed a session with the user, Prep digests
its newly acquired information to produce files that
will be used during subsequent processing of English
inputs.
Among the primary tasks to be undertaken in the
foreseeable future are
</bodyText>
<listItem confidence="0.990350071428571">
(a) implementation of certain exotic and anaphoric
modifier types, as described in Ballard 1984;
(b) user testing of the existing system, both in cus-
tomization and in user mode;
(c) provisions for limited use of coordinate conjunc-
tion;
(d) introduction of a generic hierarchy (taxonomy) so
that, for example, a &amp;quot;large office&amp;quot; can be as-
sumed to be a large room that is also an office,
unless special provisions have been made to the
effect that &amp;quot;large&amp;quot; applies differently to offices
than to other types of rooms; and
(e) incorporation of the voice recognition capabilities
developed for VNLC and VIPS.
</listItem>
<subsectionHeader confidence="0.991293">
4.2 Automatic adaptation to new users
</subsectionHeader>
<bodyText confidence="0.999981515151515">
Dialogues of the type that occur when one calls a trav-
el agent, gives a weather report, or instructs a secre-
tary in a routine task often manifest a repetitive or
stereotypic structure, especially when the utterances of
a single speaker are being considered. We call the set
of all dialogues that may occur in a given environment
a &amp;quot;dialogue type&amp;quot;. While individual dialogues within a
dialogue type may differ in content and style, they
often have rather noticeable resemblances. For in-
stance, reasonably stereotyped utterances may open a
dialogue, convey significant facts, move from one sub-
ject to another, and close the interaction. The exact
wording and ordering of sentences may change from
one dialogue to another, but often enough a basic
pattern can be identified and used to create an
&amp;quot;expectation&amp;quot; as to which of several possible continu-
ations (e.g. at some point in a sentence or dialogue)
are most likely for the current user.
With these thoughts in mind, we have attempted to
utilize such information to enable error correction in
the context of on-line voice-interactive natural lan-
guage processors of the type discussed above. In par-
ticular, we have devised methods that monitor incom-
ing inputs to a voice-interactive natural language sys-
tem and build up a graphical structure to capture the
relevant portions of a dialogue type. This frame-like
structure is then used as a predictor when a suspected
voice recognition error has occurred. Experience indi-
cates that speakers can in fact speak more rapidly (and
less carefully) and still obtain acceptable recognition
rates. Thoughts are being given to more liberal ways
of utilizing the expectations built up during sessions
with a user.
</bodyText>
<page confidence="0.896035">
34 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.488801">
The FINITE STRING Newsletter
</note>
<sectionHeader confidence="0.604694" genericHeader="method">
5. Human Factors Testing
</sectionHeader>
<bodyText confidence="0.999960545454545">
The system development work described above has
been accompanied by a series of tests to determine
how well users can actually use a prototype system to
solve real problems. For instance, we have investigated
the degree of training required to make productive use
of task-oriented systems, how habitable the presuma-
bly broad vocabulary and grammar turns out to be,
how robust the processor is, and the reaction of users
to the experience of using an English language system.
For the most part, our results have been encouraging.
For example, in one user study of NLC (Biermann,
Ballard and Sigmon 1983), it was found that subjects
had learned to use the system quite effectively after
only 50 minutes of training. The system responded
correctly to about 81 percent of all user inputs, and
people seemed to enjoy working with the system. An-
other interesting performance study gives information
about the usefulness of NLC by students in a
sophomore-level linear algebra course at Duke (Geist,
Kraines, and Fink 1983).
One important observation that came out of our
human factors work was that subjects spent an unex-
pectedly large portion of their time typing the inputs.
Thus a typical input-output cycle lasted about 50 sec-
onds: 20 seconds for typing, 3 second waiting for a
computer response, and the remaining 27 seconds
thinking about what to do next. On the basis of this,
we decided to purchase the voice equipment men-
tioned above. The effect has been both to shorten the
time required to input a command and to encourage
continuous eye contact with the objects being manipu-
lated. In fact, users now input sentences at least twice
as fast with voice input than with typed input.
</bodyText>
<sectionHeader confidence="0.986293" genericHeader="method">
6. Formalisms for NL System Design
</sectionHeader>
<bodyText confidence="0.9999757">
In the course of designing the processors summarized
above, we have developed a number of formalisms, i.e.
specification languages, intended for use outside the
immediate environment of the Duke systems. Our pri-
mary intention has been to reduce and simplify the
effort needed to mediate between the syntactic and
retrieval portions of a natural language interface. To-
ward this goal, we have developed a phrase-structured
grammatical formalism and a high-powered but
domain-independent retrieval query language.
</bodyText>
<subsectionHeader confidence="0.999829">
6.1 A phrase-structured grammatical formalism
</subsectionHeader>
<bodyText confidence="0.999996095238095">
Seeking to take advantage of the benefits of both the
familiar ATN formalism of Woods and the augmented
phrase-structured grammars of Heidorn, we have de-
veloped a hybrid grammatical formalism based on aug-
mented phrase-structure rules that allows a simple but
general parser to make its domain-specific decisions by
reference to auxiliary files produced during a learning
session of the sort carried out during the knowledge
acquisition phase of LDC. Our grammatical formalism
(Ballard and Tinkham 1984) is built around seven
command types. Three of these are used to specify
words, parts of speech, and syntactic categories, while
the remaining four provide control facilities for option-
ality, possible repetition, alternation, and sequence. In
addition to the main function of each of the com-
mands, through which the grammar writer can specify
any context-free grammar, most commands allow for
various forms of augmentations, useful in specifying
the constraints needed for the parser to perform useful
disambiguations. We are currently engaged in a rede-
sign of our parser to be run on a Symbolics 3670.
</bodyText>
<subsectionHeader confidence="0.999915">
6.2 A high-level retrieval query language
</subsectionHeader>
<bodyText confidence="0.999976357142857">
In the context of our work on the LDC system de-
scribed above, we have abandoned the common prac-
tice of building a front end to an pre-existing retrieval
system (e.g. DBMS). Instead, we have sought to de-
velop methods whereby the sophisticated processing
required by English inputs can be handled directly by a
retrieval component. Roughly speaking, this allows an
English processing component to concentrate upon
syntactic matters, and relegate matters of semantic
processing to the database retrieval component, where
ideally they belong.
To accomplish this, we have designed a powerful
but simple query language called DOMINO (Lusth and
Ballard 1984), some of whose novel features are
</bodyText>
<listItem confidence="0.82870525">
(1) facilities to access text-edited files, as opposed to
more restrictive database structures,
(2) several high-powered operators to loop through
selected portions of the data file, with arbitrary
levels of nesting permitted, and
(3) capabilities for &amp;quot;macro&amp;quot; specifications by users,
wherein arbitrarily complex operations can be
entered once, either before or during a session,
and subsequently accessed in a single step, at any
meaningful place within a query, just as though
they had been supplied by the initial retrieval
processor.
</listItem>
<bodyText confidence="0.9997305">
Current work with DOMINO involves the addition of
further and still more powerful built-in looping capa-
bilities, anaphoric macro calls, and a possible redesign
for the Symbolics environment.
</bodyText>
<sectionHeader confidence="0.96113" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.964566355932204">
Ballard, B. 1979 Semantic and Procedural Processing for a Natu-
ral Language Programming System (Ph.D. dissertation). Techni-
cal Report CS-1979-5, Department of Computer Science, Duke
University, Durham, North Carolina.
Ballard, B. 1982 A Domain-Class Approach to Transportable
Natural Language Processing. Cognition and Brain Theory 5 (3):
269-287.
Ballard, B. 1984 The Syntax and Semantics of User-Defined
Modifiers in a Transportable Natural Language Processor.
Proceedings of COLING 84.
Computational Linguistics, Volume 10, Number 1, January-March 1984 35
The FINITE STRING Newsletter
Ballard, B. and Lusth, J. 1983 An English-Language Processing
System That &amp;quot;Learns&amp;quot; About New Domains. AFIPS National
Computer Conference. Anaheim, California: 39-46.
Ballard, B.; Lusth, J.; and Tinkham, N. 1984a A Transportable,
Knowledge-Based Natural Language Processor for Office Envi-
ronments. ACM Transactions on Office Information Systems
2(1): 1-25.
Ballard, B.; Lusth, J.; and Tinkham, N. 1984b An English-
Language Processor for Office Environments. AFIPS National
Computer Conference. Las Vegas, Nevada.
Ballard, B. and Tinkham, N. 1984 A Phrase-Structured Grammati-
cal Formalism for Transportable Natural Language Processing.
Computational Linguistics (to appear).
Biermann, A. 1981 Natural Language Programming. Proceedings
of the NATO Advanced Study Institute on Automatic Program
Construction. Bonas, France.
Biermann, A. and Ballard, B. 1980 Toward Natural Language
Computation. American Journal of Computational Linguistics
6(2): 71-86.
Biermann, A. and Ballard, B. 1983 A Natural Language Interac-
tive Computer System. Army Conference on Applications of
. Artificial Intelligence to Battlefield Information Management.
White Oak, Maryland: 135-143.
Biermann, A.; Ballard, B.; and Sigmon, A. 1983; An Experimental
Study of Natural Language Programming. Int. Journal of Man-
Machine Studies 18(1): 71-87.
Biermann, A.; Rodman, R.; Ballard, B.; Betancourt, T.; Bilbro, G.;
Deas, H.; Fineman, L.; Fink, P.; Gilbert, K.; and Heidlage, F.
1983 Interactive Natural Language Problem Solving: A Prag-
matic Approach. Applied Natural Language Processing. Santa
Monica, California: 180-191.
Fink, P. 1983 Conditionals in a Natural Language System.
Master&apos;s Thesis. Department of Computer Science, Duke Uni-
versity, Durham, North Carolina.
Geist, R.; Kraines, D.; and Fink, P. 1982 Natural Language Com-
putation in a Linear Algebra Course. National Educational
Computer Conference: 203-208.
Lusth, J. and Ballard, B. 1983 Knowledge Acquisition for a Natu-
ral Language Processor. Conference on Artificial Intelligence.
Rochester, Michigan: 859-870.
Lusth, J. and Ballard, B. 1984 The Design of DOMINO: A
Knowledge-Based Information Retrieval Processor for Office
Environments. Technical Report CS-1984-2, Department of
Computer Science, Duke University, Durham, North Carolina.
Sigmon, A. 1981 The Semantics of Looping Structures in Natural
Language Computation. Master&apos;s Thesis. Department of Com-
puter Science, Duke University, Durham, North Carolina.
</reference>
<sectionHeader confidence="0.955126" genericHeader="method">
Announcements
</sectionHeader>
<subsectionHeader confidence="0.979541">
Nominations for 1985 ACL Slate
</subsectionHeader>
<bodyText confidence="0.984726">
The Nominating Committee has submitted the follow-
ing slate for consideration during the 22nd ACL Annu-
</bodyText>
<figure confidence="0.829284615384615">
al Meeting, to be held during COLING84:
President
Madeleine Bates, Bolt Beranek and Newman
Vice President
Ralph M. Weischedel, University of Delaware
Secretary-Treasurer
Donald E. Walker, Bell Communications Research
Executive Committee
1985-1987
Alan W. Biermann, Duke University
1985 (to complete Weischedel&apos;s unexpired term)
Richard I. Kittredge, University of Montreal
Nominating Committee (1985-1987)
</figure>
<subsectionHeader confidence="0.393299">
Martha W. Evens, Illinois Institute of Technology
</subsectionHeader>
<bodyText confidence="0.961303333333333">
As usual, nominations will be accepted from the floor,
provided that the person nominated has indicated will-
ingness to service, if elected.
</bodyText>
<sectionHeader confidence="0.948195" genericHeader="method">
13 CI
</sectionHeader>
<reference confidence="0.66907425">
Workshop on Relational Models
Stanford University — 29 June 1984
09:00 LEXICAL DATABASES AS DYNAMIC SYSTEMS OF
REPRESENTATION
Nicoletta Calzolari, University of Pisa
09:30 A LEXICON FOR A STROKE DATABASE
Thomas Ahlswede and Martha Evens, Illinois
Institute of Technology
</reference>
<sectionHeader confidence="0.964612" genericHeader="method">
10:00 DETERMINATION OF LEXICAL-SEMANTIC RELA-
TIONS FOR MULTILINGUAL TERMINOLOGY
STRUCTURES
</sectionHeader>
<reference confidence="0.861651666666667">
John White, Siemens
10:30 BREAK
11:00 LEXICAL, SYNTACTIC, AND SEMANTIC ACQUISI-
TION IN A TRANSPORTABLE NATURAL LAN-
GUAGE PROCESSOR
Bruce Ballard, Duke University
</reference>
<sectionHeader confidence="0.914139666666667" genericHeader="method">
11:30 IMPROVED RETRIEVAL USING A RELATIONAL
THESAURUS FOR AUTOMATIC EXPANSION OF
BOOLEAN LOGIC QUERIES
</sectionHeader>
<reference confidence="0.88737125">
Edward Fox, Virginia Polytechnic Institute
12:00 THE BASELINE UNDERSTANDING MODEL (BUM)
Burghard Rieger, Technical Unviersity of
Aachen
12:30 LUNCH
02:00 HOW TO TEACH A NETWORK
Oswald Werner, Northwestern University
02:30 THE HIERARCHICAL SCHEMA OF A DAILY
NEWSPAPER
Alexander Nakhimovsky, SUNY Oswego
03:00 FACTORING A KNOWLEDGE BASE
John Sowa, IBM
03:30 BREAK
04:00 COLLOCATIONAL RELATIONS IN A MEDICAL
SUBLANGUAGE
Raoul Smith, Northeastern University
</reference>
<sectionHeader confidence="0.881631" genericHeader="method">
04:30 EXTENSIONS OF LEXICAL COHESION: SYSTEM-
ATIC, INSTANTIAL, AND FIELD-BOUND RELA-
TIONS IN TEXTS ABOUT LITERATURE
</sectionHeader>
<reference confidence="0.685298571428572">
Mary Ann Eiler, American Medical Association
05:00 AN EXPLORATION OF GRADED SET
MEMBERSHIP
Judith Markowitz, Erikson Institute
05:30 RELATIONAL MODELS AND THE PHILOSOPHY OF
SCIENCE
William Frawley, University of Delaware
</reference>
<page confidence="0.965206">
36 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.037689">
<title confidence="0.7761475">The FINITE STRING Newsletter Site Report</title>
<affiliation confidence="0.8874925">Computational Linguistics Research at Duke University</affiliation>
<author confidence="0.701632">Faculty Bruce Ballard</author>
<author confidence="0.701632">Alan Biermann</author>
<title confidence="0.839831">Consultants: Robert Rodman (Ph.D. in Linguistics),</title>
<author confidence="0.620103">Fran Heidlage Students William Cohen</author>
<author confidence="0.620103">Amr Fahmy</author>
<author confidence="0.620103">Linda Fineman</author>
<author confidence="0.620103">Pamela Fink</author>
<author confidence="0.620103">Casey Gilbert</author>
<author confidence="0.620103">Gary Jackoway</author>
<author confidence="0.620103">Barry Koster</author>
<author confidence="0.620103">John Lusth</author>
<author confidence="0.620103">Karen Stone</author>
<author confidence="0.620103">Nancy Tinkham</author>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Ballard</author>
</authors>
<title>Semantic and Procedural Processing for a Natural Language Programming System (Ph.D.</title>
<date>1979</date>
<tech>dissertation). Technical Report CS-1979-5,</tech>
<institution>Department of Computer Science, Duke University,</institution>
<location>Durham, North Carolina.</location>
<contexts>
<context position="2535" citStr="Ballard 1979" startWordPosition="412" endWordPosition="413">nd. The first task-oriented natural language system built at Duke, the NLC, was designed to do matrix calculations. A user of NLC can request the display of one or several matrices, enter data into them, label rows and columns, and perform a variety of arithmetic operations. For example, if a certain matrix is currently in focus, the user might say &amp;quot;Add the sum of the positive entries in row 1 to the last negative element of the matrix.&amp;quot; In addition to providing a fairly broad coverage of pronouns and conjunctions, NLC includes special &amp;quot;programming&amp;quot; features to allow for procedure definition (Ballard 1979), loops (Sigmon 1981), and conditionals (Fink 1983). Our second task-oriented system, VIPS, represents a greatly simplified redesign of NLC and is aimed at office automation applications (Biermann and Ballard 1983). VIPS has been implemented to handle text manipulations from voice commands supplemented by touch inputs. For example, &amp;quot;Put this sentence [touch] after the last sentence in this [touch] paragraph.&amp;quot; Touch inputs to VIPS are currently handled via a Carroll 19-inch high-resolution color display unit with touch-sensitive screen. Current work related to task-oriented systems includes the</context>
</contexts>
<marker>Ballard, 1979</marker>
<rawString>Ballard, B. 1979 Semantic and Procedural Processing for a Natural Language Programming System (Ph.D. dissertation). Technical Report CS-1979-5, Department of Computer Science, Duke University, Durham, North Carolina.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
</authors>
<title>A Domain-Class Approach to Transportable Natural Language Processing.</title>
<date>1982</date>
<journal>Cognition and Brain Theory</journal>
<volume>5</volume>
<issue>3</issue>
<pages>269--287</pages>
<contexts>
<context position="6564" citStr="Ballard 1982" startWordPosition="1039" endWordPosition="1040">tems and assumed by typical NL front-ends. Besides the obvious technological advantage of a usercustomizable system, in terms of time and cost needed to acquire a specialized processor, efforts at providing transportable systems have scientific value in that they disallow ad hoc solutions to seemingly domain-specific problems in favor or methods based upon an understanding of the relation between the conceptual structure of a domain and the mechanisms needed to process the language used in discussing it. To render the customization problem tractable, LDC restricts itself to &amp;quot;layered&amp;quot; domains (Ballard 1982), which emphasize containment relationships among domain objects and thus generalize upon the domains of LDC and VIPS. The initial interaction between a user and LDC, which involves telling the system about a new domain, consists of a knowledgeacquisition session with the preprocessor, which we call &amp;quot;Prep&amp;quot;. In particular, Prep asks for (1) the names of each type of &amp;quot;entity&amp;quot; (object) of the domain; (2) the nature of the relationships among entities; (3) the English words that will be used as nouns, verbs, and modifiers; and (4) morphological and semantic properties of these new words. Having co</context>
</contexts>
<marker>Ballard, 1982</marker>
<rawString>Ballard, B. 1982 A Domain-Class Approach to Transportable Natural Language Processing. Cognition and Brain Theory 5 (3): 269-287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
</authors>
<title>The Syntax and Semantics of User-Defined Modifiers in a Transportable Natural Language Processor.</title>
<date>1984</date>
<journal>Proceedings of COLING</journal>
<volume>84</volume>
<contexts>
<context position="7490" citStr="Ballard 1984" startWordPosition="1186" endWordPosition="1187">rticular, Prep asks for (1) the names of each type of &amp;quot;entity&amp;quot; (object) of the domain; (2) the nature of the relationships among entities; (3) the English words that will be used as nouns, verbs, and modifiers; and (4) morphological and semantic properties of these new words. Having completed a session with the user, Prep digests its newly acquired information to produce files that will be used during subsequent processing of English inputs. Among the primary tasks to be undertaken in the foreseeable future are (a) implementation of certain exotic and anaphoric modifier types, as described in Ballard 1984; (b) user testing of the existing system, both in customization and in user mode; (c) provisions for limited use of coordinate conjunction; (d) introduction of a generic hierarchy (taxonomy) so that, for example, a &amp;quot;large office&amp;quot; can be assumed to be a large room that is also an office, unless special provisions have been made to the effect that &amp;quot;large&amp;quot; applies differently to offices than to other types of rooms; and (e) incorporation of the voice recognition capabilities developed for VNLC and VIPS. 4.2 Automatic adaptation to new users Dialogues of the type that occur when one calls a trave</context>
<context position="13934" citStr="Ballard 1984" startWordPosition="2224" endWordPosition="2225">system described above, we have abandoned the common practice of building a front end to an pre-existing retrieval system (e.g. DBMS). Instead, we have sought to develop methods whereby the sophisticated processing required by English inputs can be handled directly by a retrieval component. Roughly speaking, this allows an English processing component to concentrate upon syntactic matters, and relegate matters of semantic processing to the database retrieval component, where ideally they belong. To accomplish this, we have designed a powerful but simple query language called DOMINO (Lusth and Ballard 1984), some of whose novel features are (1) facilities to access text-edited files, as opposed to more restrictive database structures, (2) several high-powered operators to loop through selected portions of the data file, with arbitrary levels of nesting permitted, and (3) capabilities for &amp;quot;macro&amp;quot; specifications by users, wherein arbitrarily complex operations can be entered once, either before or during a session, and subsequently accessed in a single step, at any meaningful place within a query, just as though they had been supplied by the initial retrieval processor. Current work with DOMINO in</context>
</contexts>
<marker>Ballard, 1984</marker>
<rawString>Ballard, B. 1984 The Syntax and Semantics of User-Defined Modifiers in a Transportable Natural Language Processor. Proceedings of COLING 84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Computational Linguistics</author>
</authors>
<date>1984</date>
<journal>35 The FINITE STRING Newsletter</journal>
<volume>10</volume>
<marker>Linguistics, 1984</marker>
<rawString>Computational Linguistics, Volume 10, Number 1, January-March 1984 35 The FINITE STRING Newsletter</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
<author>J Lusth</author>
</authors>
<title>An English-Language Processing System That &amp;quot;Learns&amp;quot; About New Domains.</title>
<date>1983</date>
<booktitle>AFIPS National Computer Conference.</booktitle>
<pages>39--46</pages>
<location>Anaheim, California:</location>
<marker>Ballard, Lusth, 1983</marker>
<rawString>Ballard, B. and Lusth, J. 1983 An English-Language Processing System That &amp;quot;Learns&amp;quot; About New Domains. AFIPS National Computer Conference. Anaheim, California: 39-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
<author>J Lusth</author>
<author>N Tinkham</author>
</authors>
<title>A Transportable, Knowledge-Based Natural Language Processor for Office Environments.</title>
<date>1984</date>
<journal>ACM Transactions on Office Information Systems</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--25</pages>
<marker>Ballard, Lusth, Tinkham, 1984</marker>
<rawString>Ballard, B.; Lusth, J.; and Tinkham, N. 1984a A Transportable, Knowledge-Based Natural Language Processor for Office Environments. ACM Transactions on Office Information Systems 2(1): 1-25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
<author>J Lusth</author>
<author>N Tinkham</author>
</authors>
<title>An EnglishLanguage Processor for Office Environments.</title>
<date>1984</date>
<booktitle>AFIPS National Computer Conference. Las Vegas,</booktitle>
<location>Nevada.</location>
<marker>Ballard, Lusth, Tinkham, 1984</marker>
<rawString>Ballard, B.; Lusth, J.; and Tinkham, N. 1984b An EnglishLanguage Processor for Office Environments. AFIPS National Computer Conference. Las Vegas, Nevada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ballard</author>
<author>N Tinkham</author>
</authors>
<title>A Phrase-Structured Grammatical Formalism for Transportable Natural Language Processing. Computational Linguistics</title>
<date>1984</date>
<note>(to appear).</note>
<contexts>
<context position="12638" citStr="Ballard and Tinkham 1984" startWordPosition="2018" endWordPosition="2021">ormalism and a high-powered but domain-independent retrieval query language. 6.1 A phrase-structured grammatical formalism Seeking to take advantage of the benefits of both the familiar ATN formalism of Woods and the augmented phrase-structured grammars of Heidorn, we have developed a hybrid grammatical formalism based on augmented phrase-structure rules that allows a simple but general parser to make its domain-specific decisions by reference to auxiliary files produced during a learning session of the sort carried out during the knowledge acquisition phase of LDC. Our grammatical formalism (Ballard and Tinkham 1984) is built around seven command types. Three of these are used to specify words, parts of speech, and syntactic categories, while the remaining four provide control facilities for optionality, possible repetition, alternation, and sequence. In addition to the main function of each of the commands, through which the grammar writer can specify any context-free grammar, most commands allow for various forms of augmentations, useful in specifying the constraints needed for the parser to perform useful disambiguations. We are currently engaged in a redesign of our parser to be run on a Symbolics 367</context>
</contexts>
<marker>Ballard, Tinkham, 1984</marker>
<rawString>Ballard, B. and Tinkham, N. 1984 A Phrase-Structured Grammatical Formalism for Transportable Natural Language Processing. Computational Linguistics (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
</authors>
<title>Natural Language Programming.</title>
<date>1981</date>
<booktitle>Proceedings of the NATO Advanced Study Institute on Automatic Program Construction.</booktitle>
<location>Bonas, France.</location>
<marker>Biermann, 1981</marker>
<rawString>Biermann, A. 1981 Natural Language Programming. Proceedings of the NATO Advanced Study Institute on Automatic Program Construction. Bonas, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>B Ballard</author>
</authors>
<title>Toward Natural Language Computation.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>6</volume>
<issue>2</issue>
<pages>71--86</pages>
<contexts>
<context position="857" citStr="Biermann and Ballard 1980" startWordPosition="122" endWordPosition="125">e (Ph.D. in Physiology) Students: William Cohen, Amr Fahmy, Linda Fineman, Pamela Fink, Casey Gilbert, Gary Jackoway, Barry Koster, John Lusth, Karen Stone, Nancy Tinkham 1. Introduction Research in natural language (NL) processing at Duke University began in the summer of 1977 with the design of the Natural Language Computer (NLC, an extant automatic programming system that provides an English-language programming environment for matrix problems. An initial implementation of NLC was completed early in 1979, and a report on this first version of the system appeared in AJCL the following year (Biermann and Ballard 1980). Since 1979 the number of persons doing computational linguistics research at Duke has grown from three to somewhere over a dozen. During this time our goals have grown to include interests in (a) the design of task-oriented NL processors; (b) facilities to respond to voice inputs; (c) methods that enable an NL system to be easily customized for new applications or for new users; (d) human factors testing of NL processors; and (e) the development of various formalisms that will prove useful outside the context of the Duke systems. We summarize our activities in each of these areas below. 2. T</context>
</contexts>
<marker>Biermann, Ballard, 1980</marker>
<rawString>Biermann, A. and Ballard, B. 1980 Toward Natural Language Computation. American Journal of Computational Linguistics 6(2): 71-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>B Ballard</author>
</authors>
<title>A Natural Language Interactive Computer System.</title>
<date>1983</date>
<booktitle>Army Conference on Applications of . Artificial Intelligence to Battlefield Information Management. White Oak,</booktitle>
<pages>135--143</pages>
<location>Maryland:</location>
<contexts>
<context position="2749" citStr="Biermann and Ballard 1983" startWordPosition="441" endWordPosition="444">m, label rows and columns, and perform a variety of arithmetic operations. For example, if a certain matrix is currently in focus, the user might say &amp;quot;Add the sum of the positive entries in row 1 to the last negative element of the matrix.&amp;quot; In addition to providing a fairly broad coverage of pronouns and conjunctions, NLC includes special &amp;quot;programming&amp;quot; features to allow for procedure definition (Ballard 1979), loops (Sigmon 1981), and conditionals (Fink 1983). Our second task-oriented system, VIPS, represents a greatly simplified redesign of NLC and is aimed at office automation applications (Biermann and Ballard 1983). VIPS has been implemented to handle text manipulations from voice commands supplemented by touch inputs. For example, &amp;quot;Put this sentence [touch] after the last sentence in this [touch] paragraph.&amp;quot; Touch inputs to VIPS are currently handled via a Carroll 19-inch high-resolution color display unit with touch-sensitive screen. Current work related to task-oriented systems includes the evolution of a &amp;quot;micro-model&amp;quot; of a generic processor which will enable precise statements to be made concerning the construction and capabilities of specific systems. 3. Voice-Interactive Processing Based upon our </context>
</contexts>
<marker>Biermann, Ballard, 1983</marker>
<rawString>Biermann, A. and Ballard, B. 1983 A Natural Language Interactive Computer System. Army Conference on Applications of . Artificial Intelligence to Battlefield Information Management. White Oak, Maryland: 135-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>B Ballard</author>
<author>A Sigmon</author>
</authors>
<title>An Experimental Study of Natural Language Programming.</title>
<date>1983</date>
<journal>Int. Journal of ManMachine Studies</journal>
<volume>18</volume>
<issue>1</issue>
<pages>71--87</pages>
<contexts>
<context position="3933" citStr="Biermann et al. 1983" startWordPosition="621" endWordPosition="624">nteractive Processing Based upon our experience with typed English inputs, we became interested in developing high quality realtime voice interactive natural language processors. In 1982, we purchased a Nippon DP-200 connected speech recognizer and a Votan V-5000 speech recognizer and voice response unit, and have invested considerable effort in learning their characteristics. During this period, the VIPS system mentioned above was designed, and NLC was redesigned for voice input. A tape of the resulting VNLC system was played last year at the Applied Natural Language meeting in Santa Monica (Biermann et al. 1983) and the VNLC system was given its first public demonstration at an ACM regional meeting in April 1983. More recently we have begun to work with a Verbex 3000 continuous speech recognizer, and some interesting research questions have arisen. For instance, we are investigating the possible advantages of &amp;quot;discrete&amp;quot; speech, where a 300 millisecond pause must follow every word, over the more natural &amp;quot;connected&amp;quot; speech, where word boundaries may merge. Though slow and unnatural, discrete speech has the advantage Computational Linguistics, Volume 10, Number 1, January-March 1984 33 The FINITE STRING</context>
</contexts>
<marker>Biermann, Ballard, Sigmon, 1983</marker>
<rawString>Biermann, A.; Ballard, B.; and Sigmon, A. 1983; An Experimental Study of Natural Language Programming. Int. Journal of ManMachine Studies 18(1): 71-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>R Rodman</author>
<author>B Ballard</author>
<author>T Betancourt</author>
<author>G Bilbro</author>
<author>H Deas</author>
<author>L Fineman</author>
<author>P Fink</author>
<author>K Gilbert</author>
<author>F Heidlage</author>
</authors>
<title>Interactive Natural Language Problem Solving: A Pragmatic Approach. Applied Natural Language Processing.</title>
<date>1983</date>
<pages>180--191</pages>
<location>Santa Monica, California:</location>
<contexts>
<context position="3933" citStr="Biermann et al. 1983" startWordPosition="621" endWordPosition="624">nteractive Processing Based upon our experience with typed English inputs, we became interested in developing high quality realtime voice interactive natural language processors. In 1982, we purchased a Nippon DP-200 connected speech recognizer and a Votan V-5000 speech recognizer and voice response unit, and have invested considerable effort in learning their characteristics. During this period, the VIPS system mentioned above was designed, and NLC was redesigned for voice input. A tape of the resulting VNLC system was played last year at the Applied Natural Language meeting in Santa Monica (Biermann et al. 1983) and the VNLC system was given its first public demonstration at an ACM regional meeting in April 1983. More recently we have begun to work with a Verbex 3000 continuous speech recognizer, and some interesting research questions have arisen. For instance, we are investigating the possible advantages of &amp;quot;discrete&amp;quot; speech, where a 300 millisecond pause must follow every word, over the more natural &amp;quot;connected&amp;quot; speech, where word boundaries may merge. Though slow and unnatural, discrete speech has the advantage Computational Linguistics, Volume 10, Number 1, January-March 1984 33 The FINITE STRING</context>
</contexts>
<marker>Biermann, Rodman, Ballard, Betancourt, Bilbro, Deas, Fineman, Fink, Gilbert, Heidlage, 1983</marker>
<rawString>Biermann, A.; Rodman, R.; Ballard, B.; Betancourt, T.; Bilbro, G.; Deas, H.; Fineman, L.; Fink, P.; Gilbert, K.; and Heidlage, F. 1983 Interactive Natural Language Problem Solving: A Pragmatic Approach. Applied Natural Language Processing. Santa Monica, California: 180-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fink</author>
</authors>
<title>Conditionals in a Natural Language System. Master&apos;s Thesis.</title>
<date>1983</date>
<institution>Department of Computer Science, Duke University,</institution>
<location>Durham, North Carolina.</location>
<contexts>
<context position="2586" citStr="Fink 1983" startWordPosition="420" endWordPosition="421">ilt at Duke, the NLC, was designed to do matrix calculations. A user of NLC can request the display of one or several matrices, enter data into them, label rows and columns, and perform a variety of arithmetic operations. For example, if a certain matrix is currently in focus, the user might say &amp;quot;Add the sum of the positive entries in row 1 to the last negative element of the matrix.&amp;quot; In addition to providing a fairly broad coverage of pronouns and conjunctions, NLC includes special &amp;quot;programming&amp;quot; features to allow for procedure definition (Ballard 1979), loops (Sigmon 1981), and conditionals (Fink 1983). Our second task-oriented system, VIPS, represents a greatly simplified redesign of NLC and is aimed at office automation applications (Biermann and Ballard 1983). VIPS has been implemented to handle text manipulations from voice commands supplemented by touch inputs. For example, &amp;quot;Put this sentence [touch] after the last sentence in this [touch] paragraph.&amp;quot; Touch inputs to VIPS are currently handled via a Carroll 19-inch high-resolution color display unit with touch-sensitive screen. Current work related to task-oriented systems includes the evolution of a &amp;quot;micro-model&amp;quot; of a generic processo</context>
<context position="10875" citStr="Fink 1983" startWordPosition="1740" endWordPosition="1741">ction of users to the experience of using an English language system. For the most part, our results have been encouraging. For example, in one user study of NLC (Biermann, Ballard and Sigmon 1983), it was found that subjects had learned to use the system quite effectively after only 50 minutes of training. The system responded correctly to about 81 percent of all user inputs, and people seemed to enjoy working with the system. Another interesting performance study gives information about the usefulness of NLC by students in a sophomore-level linear algebra course at Duke (Geist, Kraines, and Fink 1983). One important observation that came out of our human factors work was that subjects spent an unexpectedly large portion of their time typing the inputs. Thus a typical input-output cycle lasted about 50 seconds: 20 seconds for typing, 3 second waiting for a computer response, and the remaining 27 seconds thinking about what to do next. On the basis of this, we decided to purchase the voice equipment mentioned above. The effect has been both to shorten the time required to input a command and to encourage continuous eye contact with the objects being manipulated. In fact, users now input sent</context>
</contexts>
<marker>Fink, 1983</marker>
<rawString>Fink, P. 1983 Conditionals in a Natural Language System. Master&apos;s Thesis. Department of Computer Science, Duke University, Durham, North Carolina.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Geist</author>
<author>D Kraines</author>
<author>P Fink</author>
</authors>
<title>Natural Language Computation in a Linear Algebra Course.</title>
<date>1982</date>
<booktitle>National Educational Computer Conference:</booktitle>
<pages>203--208</pages>
<marker>Geist, Kraines, Fink, 1982</marker>
<rawString>Geist, R.; Kraines, D.; and Fink, P. 1982 Natural Language Computation in a Linear Algebra Course. National Educational Computer Conference: 203-208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lusth</author>
<author>B Ballard</author>
</authors>
<title>Knowledge Acquisition for a Natural Language</title>
<date>1983</date>
<booktitle>Processor. Conference on Artificial Intelligence.</booktitle>
<pages>859--870</pages>
<location>Rochester, Michigan:</location>
<marker>Lusth, Ballard, 1983</marker>
<rawString>Lusth, J. and Ballard, B. 1983 Knowledge Acquisition for a Natural Language Processor. Conference on Artificial Intelligence. Rochester, Michigan: 859-870.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lusth</author>
<author>B Ballard</author>
</authors>
<title>The Design of DOMINO: A Knowledge-Based Information Retrieval Processor for Office Environments.</title>
<date>1984</date>
<tech>Technical Report CS-1984-2,</tech>
<institution>Department of Computer Science, Duke University,</institution>
<location>Durham, North Carolina.</location>
<contexts>
<context position="13934" citStr="Lusth and Ballard 1984" startWordPosition="2222" endWordPosition="2225">n the LDC system described above, we have abandoned the common practice of building a front end to an pre-existing retrieval system (e.g. DBMS). Instead, we have sought to develop methods whereby the sophisticated processing required by English inputs can be handled directly by a retrieval component. Roughly speaking, this allows an English processing component to concentrate upon syntactic matters, and relegate matters of semantic processing to the database retrieval component, where ideally they belong. To accomplish this, we have designed a powerful but simple query language called DOMINO (Lusth and Ballard 1984), some of whose novel features are (1) facilities to access text-edited files, as opposed to more restrictive database structures, (2) several high-powered operators to loop through selected portions of the data file, with arbitrary levels of nesting permitted, and (3) capabilities for &amp;quot;macro&amp;quot; specifications by users, wherein arbitrarily complex operations can be entered once, either before or during a session, and subsequently accessed in a single step, at any meaningful place within a query, just as though they had been supplied by the initial retrieval processor. Current work with DOMINO in</context>
</contexts>
<marker>Lusth, Ballard, 1984</marker>
<rawString>Lusth, J. and Ballard, B. 1984 The Design of DOMINO: A Knowledge-Based Information Retrieval Processor for Office Environments. Technical Report CS-1984-2, Department of Computer Science, Duke University, Durham, North Carolina.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sigmon</author>
</authors>
<title>The Semantics of Looping Structures in Natural Language Computation. Master&apos;s Thesis.</title>
<date>1981</date>
<booktitle>Workshop on Relational Models Stanford University — 29</booktitle>
<institution>Department of Computer Science, Duke University,</institution>
<location>Durham, North Carolina.</location>
<contexts>
<context position="2556" citStr="Sigmon 1981" startWordPosition="415" endWordPosition="416">ented natural language system built at Duke, the NLC, was designed to do matrix calculations. A user of NLC can request the display of one or several matrices, enter data into them, label rows and columns, and perform a variety of arithmetic operations. For example, if a certain matrix is currently in focus, the user might say &amp;quot;Add the sum of the positive entries in row 1 to the last negative element of the matrix.&amp;quot; In addition to providing a fairly broad coverage of pronouns and conjunctions, NLC includes special &amp;quot;programming&amp;quot; features to allow for procedure definition (Ballard 1979), loops (Sigmon 1981), and conditionals (Fink 1983). Our second task-oriented system, VIPS, represents a greatly simplified redesign of NLC and is aimed at office automation applications (Biermann and Ballard 1983). VIPS has been implemented to handle text manipulations from voice commands supplemented by touch inputs. For example, &amp;quot;Put this sentence [touch] after the last sentence in this [touch] paragraph.&amp;quot; Touch inputs to VIPS are currently handled via a Carroll 19-inch high-resolution color display unit with touch-sensitive screen. Current work related to task-oriented systems includes the evolution of a &amp;quot;micr</context>
</contexts>
<marker>Sigmon, 1981</marker>
<rawString>Sigmon, A. 1981 The Semantics of Looping Structures in Natural Language Computation. Master&apos;s Thesis. Department of Computer Science, Duke University, Durham, North Carolina. Workshop on Relational Models Stanford University — 29 June 1984</rawString>
</citation>
<citation valid="false">
<journal>09:00 LEXICAL DATABASES AS DYNAMIC SYSTEMS OF REPRESENTATION</journal>
<marker></marker>
<rawString>09:00 LEXICAL DATABASES AS DYNAMIC SYSTEMS OF REPRESENTATION</rawString>
</citation>
<citation valid="false">
<booktitle>09:30 A LEXICON FOR A STROKE DATABASE Thomas Ahlswede and Martha Evens, Illinois Institute of Technology</booktitle>
<institution>Nicoletta Calzolari, University of Pisa</institution>
<marker></marker>
<rawString>Nicoletta Calzolari, University of Pisa 09:30 A LEXICON FOR A STROKE DATABASE Thomas Ahlswede and Martha Evens, Illinois Institute of Technology</rawString>
</citation>
<citation valid="false">
<authors>
<author>John White</author>
</authors>
<booktitle>Siemens 10:30 BREAK 11:00 LEXICAL, SYNTACTIC, AND SEMANTIC ACQUISI-</booktitle>
<marker>White, </marker>
<rawString>John White, Siemens 10:30 BREAK 11:00 LEXICAL, SYNTACTIC, AND SEMANTIC ACQUISI-</rawString>
</citation>
<citation valid="false">
<journal>TION IN A TRANSPORTABLE NATURAL LANGUAGE PROCESSOR Bruce</journal>
<institution>Ballard, Duke University</institution>
<marker></marker>
<rawString>TION IN A TRANSPORTABLE NATURAL LANGUAGE PROCESSOR Bruce Ballard, Duke University</rawString>
</citation>
<citation valid="false">
<authors>
<author>Edward Fox</author>
</authors>
<title>Virginia Polytechnic Institute 12:00</title>
<journal>THE BASELINE UNDERSTANDING MODEL (BUM)</journal>
<marker>Fox, </marker>
<rawString>Edward Fox, Virginia Polytechnic Institute 12:00 THE BASELINE UNDERSTANDING MODEL (BUM)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Burghard Rieger</author>
</authors>
<institution>Technical Unviersity of</institution>
<marker>Rieger, </marker>
<rawString>Burghard Rieger, Technical Unviersity of</rawString>
</citation>
<citation valid="false">
<authors>
<author>Oswald Werner</author>
</authors>
<journal>Northwestern University 02:30 THE HIERARCHICAL SCHEMA OF A DAILY NEWSPAPER</journal>
<marker>Werner, </marker>
<rawString>Oswald Werner, Northwestern University 02:30 THE HIERARCHICAL SCHEMA OF A DAILY NEWSPAPER</rawString>
</citation>
<citation valid="false">
<authors>
<author>Alexander Nakhimovsky</author>
</authors>
<journal>SUNY Oswego 03:00 FACTORING A KNOWLEDGE BASE</journal>
<marker>Nakhimovsky, </marker>
<rawString>Alexander Nakhimovsky, SUNY Oswego 03:00 FACTORING A KNOWLEDGE BASE</rawString>
</citation>
<citation valid="false">
<authors>
<author>John Sowa</author>
</authors>
<booktitle>IBM 03:30 BREAK 04:00 COLLOCATIONAL RELATIONS IN A MEDICAL SUBLANGUAGE</booktitle>
<marker>Sowa, </marker>
<rawString>John Sowa, IBM 03:30 BREAK 04:00 COLLOCATIONAL RELATIONS IN A MEDICAL SUBLANGUAGE</rawString>
</citation>
<citation valid="false">
<authors>
<author>Raoul Smith</author>
</authors>
<journal>American Medical Association 05:00 AN EXPLORATION OF GRADED SET MEMBERSHIP</journal>
<institution>Northeastern University Mary Ann Eiler,</institution>
<marker>Smith, </marker>
<rawString>Raoul Smith, Northeastern University Mary Ann Eiler, American Medical Association 05:00 AN EXPLORATION OF GRADED SET MEMBERSHIP</rawString>
</citation>
<citation valid="false">
<authors>
<author>Judith Markowitz</author>
</authors>
<title>Erikson Institute 05:30</title>
<journal>RELATIONAL MODELS AND THE PHILOSOPHY OF SCIENCE</journal>
<marker>Markowitz, </marker>
<rawString>Judith Markowitz, Erikson Institute 05:30 RELATIONAL MODELS AND THE PHILOSOPHY OF SCIENCE</rawString>
</citation>
<citation valid="false">
<authors>
<author>William Frawley</author>
</authors>
<institution>University of Delaware</institution>
<marker>Frawley, </marker>
<rawString>William Frawley, University of Delaware</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>