<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.049465">
<title confidence="0.954934">
WebCAGe – A Web-Harvested Corpus Annotated with GermaNet Senses
</title>
<author confidence="0.999598">
Verena Henrich, Erhard Hinrichs, and Tatiana Vodolazova
</author>
<affiliation confidence="0.995343">
University of T¨ubingen
Department of Linguistics
</affiliation>
<email confidence="0.888563">
{firstname.lastname}@uni-tuebingen.de
</email>
<sectionHeader confidence="0.997816" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997051421052631">
This paper describes an automatic method
for creating a domain-independent sense-
annotated corpus harvested from the web.
As a proof of concept, this method has
been applied to German, a language for
which sense-annotated corpora are still in
short supply. The sense inventory is taken
from the German wordnet GermaNet. The
web-harvesting relies on an existing map-
ping of GermaNet to the German version
of the web-based dictionary Wiktionary.
The data obtained by this method consti-
tute WebCAGe (short for: Web-Harvested
Corpus Annotated with GermaNet Senses),
a resource which currently represents the
largest sense-annotated corpus available for
German. While the present paper focuses
on one particular language, the method as
such is language-independent.
</bodyText>
<sectionHeader confidence="0.99087" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.97242080952381">
The availability of large sense-annotated corpora
is a necessary prerequisite for any supervised and
many semi-supervised approaches to word sense
disambiguation (WSD). There has been steady
progress in the development and in the perfor-
mance of WSD algorithms for languages such as
English for which hand-crafted sense-annotated
corpora have been available (Agirre et al., 2007;
Erk and Strapparava, 2012; Mihalcea et al., 2004),
while WSD research for languages that lack these
corpora has lagged behind considerably or has
been impossible altogether.
Thus far, sense-annotated corpora have typi-
cally been constructed manually, making the cre-
ation of such resources expensive and the com-
pilation of larger data sets difficult, if not com-
pletely infeasible. It is therefore timely and ap-
propriate to explore alternatives to manual anno-
tation and to investigate automatic means of cre-
ating sense-annotated corpora. Ideally, any auto-
matic method should satisfy the following crite-
ria:
(1) The method used should be language inde-
pendent and should be applicable to as many
languages as possible for which the neces-
sary input resources are available.
(2) The quality of the automatically generated
data should be extremely high so as to be us-
able as is or with minimal amount of manual
post-correction.
(3) The resulting sense-annotated materials (i)
should be non-trivial in size and should be
dynamically expandable, (ii) should not be
restricted to a narrow subject domain, but
be as domain-independent as possible, and
(iii) should be freely available for other re-
searchers.
The method presented below satisfies all of
the above criteria and relies on the following re-
sources as input: (i) a sense inventory and (ii) a
mapping between the sense inventory in question
and a web-based resource such as Wiktionary1 or
</bodyText>
<footnote confidence="0.98562">
1http://www.wiktionary.org/
</footnote>
<page confidence="0.92058">
387
</page>
<note confidence="0.9787055">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 387–396,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998570114285714">
Wikipedia2.
As a proof of concept, this automatic method
has been applied to German, a language for which
sense-annotated corpora are still in short supply
and fail to satisfy most if not all of the crite-
ria under (3) above. While the present paper
focuses on one particular language, the method
as such is language-independent. In the case
of German, the sense inventory is taken from
the German wordnet GermaNet3 (Henrich and
Hinrichs, 2010; Kunze and Lemnitzer, 2002).
The web-harvesting relies on an existing map-
ping of GermaNet to the German version of the
web-based dictionary Wiktionary. This mapping
is described in Henrich et al. (2011). The
resulting resource consists of a web-harvested
corpus WebCAGe (short for: Web-Harvested
Corpus Annotated with GermaNet Senses),
which is freely available at: http://www.sfs.uni-
tuebingen.de/en/webcage.shtml
The remainder of this paper is structured as
follows: Section 2 provides a brief overview of
the resources GermaNet and Wiktionary. Sec-
tion 3 introduces the mapping of GermaNet to
Wiktionary and how this mapping can be used
to automatically harvest sense-annotated materi-
als from the web. The algorithm for identifying
the target words in the harvested texts is described
in Section 4. In Section 5, the approach of au-
tomatically creating a web-harvested corpus an-
notated with GermaNet senses is evaluated and
compared to existing sense-annotated corpora for
German. Related work is discussed in Section 6,
together with concluding remarks and an outlook
on future work.
</bodyText>
<sectionHeader confidence="0.995853" genericHeader="introduction">
2 Resources
</sectionHeader>
<subsectionHeader confidence="0.942792">
2.1 GermaNet
</subsectionHeader>
<bodyText confidence="0.9998245">
GermaNet (Henrich and Hinrichs, 2010; Kunze
and Lemnitzer, 2002) is a lexical semantic net-
work that is modeled after the Princeton Word-
Net for English (Fellbaum, 1998). It partitions the
</bodyText>
<footnote confidence="0.9901902">
2http://www.wikipedia.org/
3Using a wordnet as the gold standard for the sense inven-
tory is fully in line with standard practice for English where
the Princeton WordNet (Fellbaum, 1998) is typically taken
as the gold standard.
</footnote>
<bodyText confidence="0.999952739130435">
lexical space into a set of concepts that are inter-
linked by semantic relations. A semantic concept
is represented as a synset, i.e., as a set of words
whose individual members (referred to as lexical
units) are taken to be (near) synonyms. Thus, a
synset is a set-representation of the semantic rela-
tion of synonymy.
There are two types of semantic relations in
GermaNet. Conceptual relations hold between
two semantic concepts, i.e. synsets. They in-
clude relations such as hypernymy, part-whole re-
lations, entailment, or causation. Lexical rela-
tions hold between two individual lexical units.
Antonymy, a pair of opposites, is an example of a
lexical relation.
GermaNet covers the three word categories of
adjectives, nouns, and verbs, each of which is
hierarchically structured in terms of the hyper-
nymy relation of synsets. The development of
GermaNet started in 1997, and is still in progress.
GermaNet’s version 6.0 (release of April 2011)
contains 93407 lexical units, which are grouped
into 69594 synsets.
</bodyText>
<subsectionHeader confidence="0.997426">
2.2 Wiktionary
</subsectionHeader>
<bodyText confidence="0.99974205">
Wiktionary is a web-based dictionary that is avail-
able for many languages, including German. As
is the case for its sister project Wikipedia, it
is written collaboratively by volunteers and is
freely available4. The dictionary provides infor-
mation such as part-of-speech, hyphenation, pos-
sible translations, inflection, etc. for each word.
It includes, among others, the same three word
classes of adjectives, nouns, and verbs that are
also available in GermaNet. Distinct word senses
are distinguished by sense descriptions and ac-
companied with example sentences illustrating
the sense in question.
Further, Wiktionary provides relations to
other words, e.g., in the form of synonyms,
antonyms, hypernyms, hyponyms, holonyms, and
meronyms. In contrast to GermaNet, the relations
are (mostly) not disambiguated.
For the present project, a dump of the Ger-
man Wiktionary as of February 2, 2011 is uti-
</bodyText>
<footnote confidence="0.999906333333333">
4Wiktionary is available under the Cre-
ative Commons Attribution/Share-Alike license
http://creativecommons.org/licenses/by-sa/3.0/deed.en
</footnote>
<page confidence="0.995218">
388
</page>
<figureCaption confidence="0.999727">
Figure 1: Sense mapping of GermaNet and Wiktionary using the example of Bogen.
</figureCaption>
<bodyText confidence="0.99910025">
lized, consisting of 46457 German words com-
prising 70339 word senses. The Wiktionary data
was extracted by the freely available Java-based
library JWKTL5.
</bodyText>
<sectionHeader confidence="0.740196" genericHeader="method">
3 Creation of a Web-Harvested Corpus
</sectionHeader>
<bodyText confidence="0.9998796">
The starting point for creating WebCAGe is an
existing mapping of GermaNet senses with Wik-
tionary sense definitions as described in Henrich
et al. (2011). This mapping is the result of a
two-stage process: i) an automatic word overlap
alignment algorithm in order to match GermaNet
senses with Wiktionary sense descriptions, and
ii) a manual post-correction step of the automatic
alignment. Manual post-correction can be kept at
a reasonable level of effort due to the high accu-
racy (93.8%) of the automatic alignment.
The original purpose of this mapping was to
automatically add Wiktionary sense descriptions
to GermaNet. However, the alignment of these
two resources opens up a much wider range of
</bodyText>
<footnote confidence="0.592047">
5http://www.ukp.tu-darmstadt.de/software/jwktl
</footnote>
<bodyText confidence="0.99983825">
possibilities for data mining community-driven
resources such as Wikipedia and web-generated
content more generally. It is precisely this poten-
tial that is fully exploited for the creation of the
WebCAGe sense-annotated corpus.
Fig. 1 illustrates the existing GermaNet-
Wiktionary mapping using the example word Bo-
gen. The polysemous word Bogen has three dis-
tinct senses in GermaNet which directly corre-
spond to three separate senses in Wiktionary6.
Each Wiktionary sense entry contains a definition
and one or more example sentences illustrating
the sense in question. The examples in turn are
often linked to external references, including sen-
tences contained in the German Gutenberg text
archive7 (see link in the topmost Wiktionary sense
entry in Fig. 1), Wikipedia articles (see link for
the third Wiktionary sense entry in Fig. 1), and
other textual sources (see the second sense en-
try in Fig. 1). It is precisely this collection of
</bodyText>
<footnote confidence="0.999742">
6Note that there are further senses in both resources not
displayed here for reasons of space.
7http://gutenberg.spiegel.de/
</footnote>
<page confidence="0.997214">
389
</page>
<figureCaption confidence="0.999299">
Figure 2: Sense mapping of GermaNet and Wiktionary using the example of Archiv.
</figureCaption>
<bodyText confidence="0.998028416666667">
heterogeneous material that can be harvested for
the purpose of compiling a sense-annotated cor-
pus. Since the target word (rendered in Fig. 1
in bold face) in the example sentences for a par-
ticular Wiktionary sense is linked to a GermaNet
sense via the sense mapping of GermaNet with
Wiktionary, the example sentences are automati-
cally sense-annotated and can be included as part
of WebCAGe.
Additional material for WebCAGe is harvested
by following the links to Wikipedia, the Guten-
berg archive, and other web-based materials. The
external webpages and the Gutenberg texts are ob-
tained from the web by a web-crawler that takes
some URLs as input and outputs the texts of the
corresponding web sites. The Wikipedia articles
are obtained by the open-source Java Wikipedia
Library JWPL 8. Since the links to Wikipedia, the
Gutenberg archive, and other web-based materials
also belong to particular Wiktionary sense entries
that in turn are mapped to GermaNet senses, the
target words contained in these materials are au-
tomatically sense-annotated.
Notice that the target word often occurs more
</bodyText>
<footnote confidence="0.739606">
8http://www.ukp.tu-darmstadt.de/software/jwpl/
</footnote>
<bodyText confidence="0.99967404">
than once in a given text. In keeping with
the widely used heuristic of “one sense per dis-
course”, multiple occurrences of a target word in
a given text are all assigned to the same GermaNet
sense. An inspection of the annotated data shows
that this heuristic has proven to be highly reliable
in practice. It is correct in 99.96% of all target
word occurrences in the Wiktionary example sen-
tences, in 96.75% of all occurrences in the exter-
nal webpages, and in 95.62% of the Wikipedia
files.
WebCAGe is developed primarily for the pur-
pose of the word sense disambiguation task.
Therefore, only those target words that are gen-
uinely ambiguous are included in this resource.
Since WebCAGe uses GermaNet as its sense in-
ventory, this means that each target word has at
least two GermaNet senses, i.e., belongs to at least
two distinct synsets.
The GermaNet-Wiktionary mapping is not al-
ways one-to-one. Sometimes one GermaNet
sense is mapped to more than one sense in Wik-
tionary. Fig. 2 illustrates such a case. For
the word Archiv each resource records three dis-
tinct senses. The first sense (‘data repository’)
</bodyText>
<page confidence="0.987874">
390
</page>
<bodyText confidence="0.999953260869565">
in GermaNet corresponds to the first sense in
Wiktionary, and the second sense in GermaNet
(‘archive’) corresponds to both the second and
third senses in Wiktionary. The third sense in
GermaNet (‘archived file’) does not map onto any
sense in Wiktionary at all. As a result, the word
Archiv is included in the WebCAGe resource with
precisely the sense mappings connected by the
arrows shown in Fig. 2. The fact that the sec-
ond GermaNet sense corresponds to two sense
descriptions in Wiktionary simply means that the
target words in the example are both annotated by
the same sense. Furthermore, note that the word
Archiv is still genuinely ambiguous since there is
a second (one-to-one) mapping between the first
senses recorded in GermaNet and Wiktionary, re-
spectively. However, since the third GermaNet
sense is not mapped onto any Wiktionary sense at
all, WebCAGe will not contain any example sen-
tences for this particular GermaNet sense.
The following section describes how the target
words within these textual materials can be auto-
matically identified.
</bodyText>
<sectionHeader confidence="0.994782" genericHeader="method">
4 Automatic Detection of Target Words
</sectionHeader>
<bodyText confidence="0.999993411764706">
For highly inflected languages such as German,
target word identification is more complex com-
pared to languages with an impoverished inflec-
tional morphology, such as English, and thus re-
quires automatic lemmatization. Moreover, the
target word in a text to be sense-annotated is
not always a simplex word but can also appear
as subpart of a complex word such as a com-
pound. Since the constituent parts of a compound
are not usually separated by blank spaces or hy-
phens, German compounding poses a particular
challenge for target word identification. Another
challenging case for automatic target word detec-
tion in German concerns particle verbs such as an-
k¨undigen ‘announce’. Here, the difficulty arises
when the verbal stem (e.g., k¨undigen) is separated
from its particle (e.g., an) in German verb-initial
and verb-second clause types.
As a preprocessing step for target word identi-
fication, the text is split into individual sentences,
tokenized, and lemmatized. For this purpose, the
sentence detector and the tokenizer of the suite
of Apache OpenNLP tools9 and the TreeTagger
(Schmid, 1994) are used. Further, compounds
are split by using BananaSplit10. Since the au-
tomatic lemmatization obtained by the tagger and
the compound splitter are not 100% accurate, tar-
get word identification also utilizes the full set of
inflected forms for a target word whenever such
information is available. As it turns out, Wik-
tionary can often be used for this purpose as well
since the German version of Wiktionary often
contains the full set of word forms in tables11 such
as the one shown in Fig. 3 for the word Bogen.
</bodyText>
<figureCaption confidence="0.996281">
Figure 3: Wiktionary inflection table for Bogen.
</figureCaption>
<bodyText confidence="0.99670405">
Fig. 4 shows an example of such a sense-
annotated text for the target word Bogen ‘vi-
olin bow’. The text is an excerpt from the
Wikipedia article Violine ‘violin’, where the target
word (rendered in bold face) appears many times.
Only the second occurrence shown in the figure
(marked with a 2 on the left) exactly matches the
word Bogen as is. All other occurrences are ei-
ther the plural form B¨ogen (4 and 7), the geni-
tive form Bogens (8), part of a compound such
as Bogenstange (3), or the plural form as part
of a compound such as in Fernambukb¨ogen and
Sch¨ulerb¨ogen (5 and 6). The first occurrence
of the target word in Fig. 4 is also part of a
compound. Here, the target word occurs in the
singular as part of the adjectival compound bo-
gengestrichenen.
For expository purposes, the data format shown
in Fig. 4 is much simplified compared to the ac-
tual, XML-based format in WebCAGe. The infor-
</bodyText>
<footnote confidence="0.9966452">
9http://incubator.apache.org/opennlp/
10http://niels.drni.de/s9y/pages/bananasplit.html
11The inflection table cannot be extracted with the Java
Wikipedia Library JWPL. It is rather extracted from the Wik-
tionary dump file.
</footnote>
<page confidence="0.996903">
391
</page>
<figureCaption confidence="0.999535">
Figure 4: Excerpt from Wikipedia article Violine ‘violin’ tagged with target word Bogen ‘violin bow’.
</figureCaption>
<bodyText confidence="0.9999312">
mation for each occurrence of a target word con-
sists of the GermaNet sense, i.e., the lexical unit
ID, the lemma of the target word, and the Ger-
maNet word category information, i.e., ADJ for
adjectives, NN for nouns, and VB for verbs.
</bodyText>
<sectionHeader confidence="0.999063" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999882135135135">
In order to assess the effectiveness of the ap-
proach, we examine the overall size of WebCAGe
and the relative size of the different text col-
lections (see Table 1), compare WebCAGe to
other sense-annotated corpora for German (see
Table 2), and present a precision- and recall-based
evaluation of the algorithm that is used for auto-
matically identifying target words in the harvested
texts (see Table 3).
Table 1 shows that Wiktionary (7644 tagged
word tokens) and Wikipedia (1732) contribute
by far the largest subsets of the total number of
tagged word tokens (10750) compared with the
external webpages (589) and the Gutenberg texts
(785). These tokens belong to 2607 distinct pol-
ysemous words contained in GermaNet, among
which there are 211 adjectives, 1499 nouns, and
897 verbs (see Table 2). On average, these words
have 2.9 senses in GermaNet (2.4 for adjectives,
2.6 for nouns, and 3.6 for verbs).
Table 2 also shows that WebCAGe is consid-
erably larger than the other two sense-annotated
corpora available for German ((Broscheit et al.,
2010) and (Raileanu et al., 2002)). It is impor-
tant to keep in mind, though, that the other two
resources were manually constructed, whereas
WebCAGe is the result of an automatic harvesting
method. Such an automatic method will only con-
stitute a viable alternative to the labor-intensive
manual method if the results are of sufficient qual-
ity so that the harvested data set can be used as is
or can be further improved with a minimal amount
of manual post-editing.
For the purpose of the present evaluation, we
conducted a precision- and recall-based analy-
sis for the text types of Wiktionary examples,
external webpages, and Wikipedia articles sep-
</bodyText>
<page confidence="0.998671">
392
</page>
<tableCaption confidence="0.999863">
Table 1: Current size of WebCAGe.
</tableCaption>
<table confidence="0.999853619047619">
Wiktionary External Wikipedia Gutenberg All
examples webpages articles texts texts
Number of adjectives 575 31 79 28 713
tagged
word
tokens
nouns 4103 446 1643 655 6847
verbs 2966 112 10 102 3190
all word classes 7644 589 1732 785 10750
Number of adjectives 565 31 76 26 698
tagged
sentences
nouns 3965 420 1404 624 6413
verbs 2945 112 10 102 3169
all word classes 7475 563 1490 752 10280
Total adjectives 623 1297 430 65030 67380
number of
sentences
nouns 4184 9630 6851 376159 396824
verbs 3087 5285 263 146755 155390
all word classes 7894 16212 7544 587944 619594
</table>
<tableCaption confidence="0.985129">
Table 2: Comparing WebCAGe to other sense-tagged corpora of German.
</tableCaption>
<table confidence="0.983600888888889">
WebCAGe Broscheit et Raileanu et
al., 2010 al., 2002
Sense adjectives 211 6 0
tagged nouns 1499 18 25
words verbs 897 16 0
all word classes 2607 40 25
Number of tagged word tokens 10750 approx. 800 2421
Domain independent yes yes medical
domain
</table>
<bodyText confidence="0.99978245">
arately for the three word classes of adjectives,
nouns, and verbs. Table 3 shows that precision
and recall for all three word classes that occur
for Wiktionary examples, external webpages, and
Wikipedia articles lies above 92%. The only size-
able deviations are the results for verbs that occur
in the Gutenberg texts. Apart from this one excep-
tion, the results in Table 3 prove the viability of
the proposed method for automatic harvesting of
sense-annotated data. The average precision for
all three word classes is of sufficient quality to be
used as-is if approximately 2-5% noise in the an-
notated data is acceptable. In order to eliminate
such noise, manual post-editing is required. How-
ever, such post-editing is within acceptable lim-
its: it took an experienced research assistant a to-
tal of 25 hours to hand-correct all the occurrences
of sense-annotated target words and to manually
sense-tag any missing target words for the four
text types.
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="related work">
6 Related Work and Future Directions
</sectionHeader>
<bodyText confidence="0.99999425">
With relatively few exceptions to be discussed
shortly, the construction of sense-annotated cor-
pora has focussed on purely manual methods.
This is true for SemCor, the WordNet Gloss Cor-
pus, and for the training sets constructed for En-
glish as part of the SensEval and SemEval shared
task competitions (Agirre et al., 2007; Erk and
Strapparava, 2012; Mihalcea et al., 2004). Purely
manual methods were also used for the German
sense-annotated corpora constructed by Broscheit
et al. (2010) and Raileanu et al. (2002) as well as
for other languages including the Bulgarian and
</bodyText>
<page confidence="0.999514">
393
</page>
<tableCaption confidence="0.999886">
Table 3: Evaluation of the algorithm of identifying the target words.
</tableCaption>
<table confidence="0.997985">
Wiktionary External Wikipedia Gutenberg
examples webpages articles texts
Precision adjectives 97.70% 95.83% 99.34% 100%
nouns 98.17% 98.50% 95.87% 92.19%
verbs 97.38% 92.26% 100% 69.87%
all word classes 97.32% 96.19% 96.26% 87.43%
Recall adjectives 97.70% 97.22% 98.08% 97.14%
nouns 98.30% 96.03% 92.70.% 97.38%
verbs 97.51% 99.60% 100% 89.20%
all word classes 97.94% 97.32% 93.36% 95.42%
</table>
<bodyText confidence="0.998764455882353">
the Chinese sense-tagged corpora (Koeva et al.,
2006; Wu et al., 2006). The only previous at-
tempts of harvesting corpus data for the purpose
of constructing a sense-annotated corpus are the
semi-supervised method developed by Yarowsky
(1995), the knowledge-based approach of Lea-
cock et al. (1998), later also used by Agirre and
Lopez de Lacalle (2004), and the automatic asso-
ciation of Web directories (from the Open Direc-
tory Project, ODP) to WordNet senses by Santa-
maria et al. (2003).
The latter study (Santamaria et al., 2003) is
closest in spirit to the approach presented here.
It also relies on an automatic mapping between
wordnet senses and a second web resource. While
our approach is based on automatic mappings be-
tween GermaNet and Wiktionary, their mapping
algorithm maps WordNet senses to ODP subdi-
rectories. Since these ODP subdirectories contain
natural language descriptions of websites relevant
to the subdirectory in question, this textual mate-
rial can be used for harvesting sense-specific ex-
amples. The ODP project also covers German so
that, in principle, this harvesting method could be
applied to German in order to collect additional
sense-tagged data for WebCAGe.
The approach of Yarowsky (1995) first collects
all example sentences that contain a polysemous
word from a very large corpus. In a second step,
a small number of examples that are representa-
tive for each of the senses of the polysemous tar-
get word is selected from the large corpus from
step 1. These representative examples are manu-
ally sense-annotated and then fed into a decision-
list supervised WSD algorithm as a seed set for it-
eratively disambiguating the remaining examples
collected in step 1. The selection and annotation
of the representative examples in Yarowsky’s ap-
proach is performed completely manually and is
therefore limited to the amount of data that can
reasonably be annotated by hand.
Leacock et al. (1998), Agirre and Lopez de La-
calle (2004), and Mihalcea and Moldovan (1999)
propose a set of methods for automatic harvesting
of web data for the purposes of creating sense-
annotated corpora. By focusing on web-based
data, their work resembles the research described
in the present paper. However, the underlying har-
vesting methods differ. While our approach re-
lies on a wordnet to Wiktionary mapping, their
approaches all rely on the monosemous relative
heuristic. Their heuristic works as follows: In or-
der to harvest corpus examples for a polysemous
word, the WordNet relations such as synonymy
and hypernymy are inspected for the presence of
unambiguous words, i.e., words that only appear
in exactly one synset. The examples found for
these monosemous relatives can then be sense-
annotated with the particular sense of its ambigu-
ous word relative. In order to increase coverage
of the monosemous relatives approach, Mihalcea
and Moldovan (1999) have developed a gloss-
based extension, which relies on word overlap of
the gloss and the WordNet sense in question for
all those cases where a monosemous relative is
not contained in the WordNet dataset.
The approaches of Leacock et al., Agirre and
Lopez de Lacalle, and Mihalcea and Moldovan as
</bodyText>
<page confidence="0.99633">
394
</page>
<bodyText confidence="0.999978394736842">
well as Yarowsky’s approach provide interesting
directions for further enhancing the WebCAGe re-
source. It would be worthwhile to use the au-
tomatically harvested sense-annotated examples
as the seed set for Yarowsky’s iterative method
for creating a large sense-annotated corpus. An-
other fruitful direction for further automatic ex-
pansion of WebCAGe is to use the heuristic of
monosemous relatives used by Leacock et al., by
Agirre and Lopez de Lacalle, and by Mihalcea
and Moldovan. However, we have to leave these
matters for future research.
In order to validate the language independence
of our approach, we plan to apply our method to
sense inventories for languages other than Ger-
man. A precondition for such an experiment is an
existing mapping between the sense inventory in
question and a web-based resource such as Wik-
tionary or Wikipedia. With BabelNet, Navigli and
Ponzetto (2010) have created a multilingual re-
source that allows the testing of our approach to
languages other than German. As a first step in
this direction, we applied our approach to English
using the mapping between the Princeton Word-
Net and the English version of Wiktionary pro-
vided by Meyer and Gurevych (2011). The re-
sults of these experiments, which are reported in
Henrich et al. (2012), confirm the general appli-
cability of our approach.
To conclude: This paper describes an automatic
method for creating a domain-independent sense-
annotated corpus harvested from the web. The
data obtained by this method for German have
resulted in the WebCAGe resource which cur-
rently represents the largest sense-annotated cor-
pus available for this language. The publication of
this paper is accompanied by making WebCAGe
freely available.
</bodyText>
<sectionHeader confidence="0.996491" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999963928571429">
The research reported in this paper was jointly
funded by the SFB 833 grant of the DFG and by
the CLARIN-D grant of the BMBF. We would
like to thank Christina Hoppermann, Marie Hin-
richs as well as three anonymous EACL 2012 re-
viewers for their helpful comments on earlier ver-
sions of this paper. We are very grateful to Rein-
hild Barkey, Sarah Schulz, and Johannes Wahle
for their help with the evaluation reported in Sec-
tion 5. Special thanks go to Yana Panchenko and
Yannick Versley for their support with the web-
crawler and to Emanuel Dima and Klaus Sut-
tner for helping us to obtain the Gutenberg and
Wikipedia texts.
</bodyText>
<sectionHeader confidence="0.998702" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995410738095238">
Agirre, E., Lopez de Lacalle, O. 2004. Publicly
available topic signatures for all WordNet nominal
senses. Proceedings of the 4th International Con-
ference on Languages Resources and Evaluations
(LREC’04), Lisbon, Portugal, pp. 1123–1126
Agirre, E., Marquez, L., Wicentowski, R. 2007. Pro-
ceedings of the 4th International Workshop on Se-
mantic Evaluations. Assoc. for Computational Lin-
guistics, Stroudsburg, PA, USA
Broscheit, S., Frank, A., Jehle, D., Ponzetto, S. P.,
Rehl, D., Summa, A., Suttner, K., Vola, S. 2010.
Rapid bootstrapping of Word Sense Disambigua-
tion resources for German. Proceedings of the 10.
Konferenz zur Verarbeitung Nat¨urlicher Sprache,
Saarbr¨ucken, Germany, pp. 19–27
Erk, K., Strapparava, C. 2010. Proceedings of the 5th
International Workshop on Semantic Evaluation.
Assoc. for Computational Linguistics, Stroudsburg,
PA, USA
Fellbaum, C. (ed.). 1998. WordNet An Electronic
Lexical Database. The MIT Press.
Henrich, V., Hinrichs, E. 2010. GernEdiT – The Ger-
maNet Editing Tool. Proceedings of the Seventh
Conference on International Language Resources
and Evaluation (LREC’10), Valletta, Malta, pp.
2228–2235
Henrich, V., Hinrichs, E., Vodolazova, T. 2011. Semi-
Automatic Extension of GermaNet with Sense Def-
initions from Wiktionary. Proceedings of the 5th
Language &amp; Technology Conference: Human Lan-
guage Technologies as a Challenge for Computer
Science and Linguistics (LTC’11), Poznan, Poland,
pp. 126–130
Henrich, V., Hinrichs, E., Vodolazova, T. 2012. An
Automatic Method for Creating a Sense-Annotated
Corpus Harvested from the Web. Poster pre-
sented at 13th International Conference on Intelli-
gent Text Processing and Computational Linguistics
(CICLing-2012), New Delhi, India, March 2012
Koeva, S., Leseva, S., Todorova, M. 2006. Bul-
garian Sense Tagged Corpus. Proceedings of the
5th SALTMIL Workshop on Minority Languages:
</reference>
<page confidence="0.999326">
395
</page>
<bodyText confidence="0.989607">
for Computational Linguistics (ACL’95), Associ-
ation for Computational Linguistics, Stroudsburg,
PA, USA, pp. 189–196
</bodyText>
<reference confidence="0.989687754716981">
Strategies for Developing Machine Translation for
Minority Languages, Genoa, Italy, pp. 79–87
Kunze, C., Lemnitzer, L. 2002. GermaNet rep-
resentation, visualization, application. Proceed-
ings of the 3rd International Language Resources
and Evaluation (LREC’02), Las Palmas, Canary Is-
lands, pp. 1485–1491
Leacock, C., Chodorow, M., Miller, G. A. 1998.
Using corpus statistics and wordnet relations for
sense identification. Computational Linguistics,
24(1):147–165
Meyer, C. M., Gurevych, I. 2011. What Psycholin-
guists Know About Chemistry: Aligning Wik-
tionary and WordNet for Increased Domain Cov-
erage. Proceedings of the 5th International Joint
Conference on Natural Language Processing (IJC-
NLP), Chiang Mai, Thailand, pp. 883–892
Mihalcea, R., Moldovan, D. 1999. An Auto-
matic Method for Generating Sense Tagged Cor-
pora. Proceedings of the American Association for
Artificial Intelligence (AAAI’99), Orlando, Florida,
pp. 461–466
Mihalcea, R., Chklovski, T., Kilgarriff, A. 2004. Pro-
ceedings of Senseval-3: Third International Work-
shop on the Evaluation of Systems for the Semantic
Analysis of Text, Barcelona, Spain
Navigli, R., Ponzetto, S. P. 2010. BabelNet: Build-
ing a Very Large Multilingual Semantic Network.
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’10),
Uppsala, Sweden, pp. 216–225
Raileanu, D., Buitelaar, P., Vintar, S., Bay, J. 2002.
Evaluation Corpora for Sense Disambiguation in
the Medical Domain. Proceedings of the 3rd In-
ternational Language Resources and Evaluation
(LREC’02), Las Palmas, Canary Islands, pp. 609–
612
Santamar´ıa, C., Gonzalo, J., Verdejo, F. 2003. Au-
tomatic Association of Web Directories to Word
Senses. Computational Linguistics 29 (3), MIT
Press, PP. 485–502
Schmid, H. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. Proceedings of the In-
ternational Conference on New Methods in Lan-
guage Processing, Manchester, UK
Wu, Y., Jin, P., Zhang, Y., Yu, S. 2006. A Chinese
Corpus with Word Sense Annotation. Proceedings
of 21st International Conference on Computer Pro-
cessing of Oriental Languages (ICCPOL’06), Sin-
gapore, pp. 414–421
Yarowsky, D. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. Proceed-
ings of the 33rd Annual Meeting on Association
</reference>
<page confidence="0.999063">
396
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.999646">WebCAGe – A Web-Harvested Corpus Annotated with GermaNet Senses</title>
<author confidence="0.997799">Verena Henrich</author>
<author confidence="0.997799">Erhard Hinrichs</author>
<author confidence="0.997799">Tatiana</author>
<affiliation confidence="0.982988">University of Department of</affiliation>
<abstract confidence="0.99167561821366">This paper describes an automatic method for creating a domain-independent senseannotated corpus harvested from the web. As a proof of concept, this method has been applied to German, a language for which sense-annotated corpora are still in short supply. The sense inventory is taken from the German wordnet GermaNet. The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. The data obtained by this method consti- WebCAGe (short for: Annotated with GermaNet a resource which currently represents the largest sense-annotated corpus available for German. While the present paper focuses on one particular language, the method as such is language-independent. 1 Motivation The availability of large sense-annotated corpora is a necessary prerequisite for any supervised and many semi-supervised approaches to word sense disambiguation (WSD). There has been steady progress in the development and in the performance of WSD algorithms for languages such as English for which hand-crafted sense-annotated corpora have been available (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004), while WSD research for languages that lack these corpora has lagged behind considerably or has been impossible altogether. Thus far, sense-annotated corpora have typically been constructed manually, making the creation of such resources expensive and the compilation of larger data sets difficult, if not completely infeasible. It is therefore timely and appropriate to explore alternatives to manual annotation and to investigate automatic means of creating sense-annotated corpora. Ideally, any automatic method should satisfy the following criteria: (1) The method used should be language independent and should be applicable to as many languages as possible for which the necessary input resources are available. (2) The quality of the automatically generated data should be extremely high so as to be usable as is or with minimal amount of manual post-correction. (3) The resulting sense-annotated materials (i) should be non-trivial in size and should be dynamically expandable, (ii) should not be restricted to a narrow subject domain, but be as domain-independent as possible, and (iii) should be freely available for other researchers. The method presented below satisfies all of the above criteria and relies on the following resources as input: (i) a sense inventory and (ii) a mapping between the sense inventory in question a web-based resource such as or 387 of the 13th Conference of the European Chapter of the Association for Computational pages 387–396, France, April 23 - 27 2012. Association for Computational Linguistics As a proof of concept, this automatic method has been applied to German, a language for which sense-annotated corpora are still in short supply and fail to satisfy most if not all of the criteria under (3) above. While the present paper focuses on one particular language, the method as such is language-independent. In the case of German, the sense inventory is taken from German wordnet (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002). The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. This mapping is described in Henrich et al. (2011). The resulting resource consists of a web-harvested WebCAGe (short for: Annotated with GermaNet which is freely available at: http://www.sfs.unituebingen.de/en/webcage.shtml The remainder of this paper is structured as follows: Section 2 provides a brief overview of the resources GermaNet and Wiktionary. Section 3 introduces the mapping of GermaNet to Wiktionary and how this mapping can be used to automatically harvest sense-annotated materials from the web. The algorithm for identifying the target words in the harvested texts is described in Section 4. In Section 5, the approach of automatically creating a web-harvested corpus annotated with GermaNet senses is evaluated and compared to existing sense-annotated corpora for German. Related work is discussed in Section 6, together with concluding remarks and an outlook on future work. 2 Resources 2.1 GermaNet GermaNet (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002) is a lexical semantic network that is modeled after the Princeton Word- Net for English (Fellbaum, 1998). It partitions the a wordnet as the gold standard for the sense inventory is fully in line with standard practice for English where the Princeton WordNet (Fellbaum, 1998) is typically taken as the gold standard. lexical space into a set of concepts that are interlinked by semantic relations. A semantic concept represented as a i.e., as a set of words individual members (referred to as are taken to be (near) synonyms. Thus, a synset is a set-representation of the semantic relation of synonymy. There are two types of semantic relations in relations between two semantic concepts, i.e. synsets. They include relations such as hypernymy, part-whole reentailment, or causation. relabetween two individual lexical units. Antonymy, a pair of opposites, is an example of a lexical relation. GermaNet covers the three word categories of adjectives, nouns, and verbs, each of which is hierarchically structured in terms of the hypernymy relation of synsets. The development of GermaNet started in 1997, and is still in progress. GermaNet’s version 6.0 (release of April 2011) contains 93407 lexical units, which are grouped into 69594 synsets. 2.2 Wiktionary Wiktionary is a web-based dictionary that is available for many languages, including German. As is the case for its sister project Wikipedia, it is written collaboratively by volunteers and is The dictionary provides information such as part-of-speech, hyphenation, possible translations, inflection, etc. for each word. It includes, among others, the same three word classes of adjectives, nouns, and verbs that are also available in GermaNet. Distinct word senses are distinguished by sense descriptions and accompanied with example sentences illustrating the sense in question. Further, Wiktionary provides relations to other words, e.g., in the form of synonyms, antonyms, hypernyms, hyponyms, holonyms, and meronyms. In contrast to GermaNet, the relations are (mostly) not disambiguated. For the present project, a dump of the Ger- Wiktionary as of February 2, 2011 is utiis available under the Creative Commons Attribution/Share-Alike license http://creativecommons.org/licenses/by-sa/3.0/deed.en 388 1: Sense mapping of GermaNet and Wiktionary using the example of lized, consisting of 46457 German words comprising 70339 word senses. The Wiktionary data was extracted by the freely available Java-based 3 Creation of a Web-Harvested Corpus The starting point for creating WebCAGe is an existing mapping of GermaNet senses with Wiktionary sense definitions as described in Henrich et al. (2011). This mapping is the result of a two-stage process: i) an automatic word overlap alignment algorithm in order to match GermaNet senses with Wiktionary sense descriptions, and ii) a manual post-correction step of the automatic alignment. Manual post-correction can be kept at a reasonable level of effort due to the high accuracy (93.8%) of the automatic alignment. The original purpose of this mapping was to automatically add Wiktionary sense descriptions to GermaNet. However, the alignment of these two resources opens up a much wider range of possibilities for data mining community-driven resources such as Wikipedia and web-generated content more generally. It is precisely this potential that is fully exploited for the creation of the WebCAGe sense-annotated corpus. Fig. 1 illustrates the existing GermaNetmapping using the example word Bo- The polysemous word three distinct senses in GermaNet which directly correto three separate senses in Each Wiktionary sense entry contains a definition and one or more example sentences illustrating the sense in question. The examples in turn are often linked to external references, including sentences contained in the German Gutenberg text (see link in the topmost Wiktionary sense entry in Fig. 1), Wikipedia articles (see link for the third Wiktionary sense entry in Fig. 1), and other textual sources (see the second sense entry in Fig. 1). It is precisely this collection of that there are further senses in both resources not displayed here for reasons of space. 389 2: Sense mapping of GermaNet and Wiktionary using the example of heterogeneous material that can be harvested for the purpose of compiling a sense-annotated corpus. Since the target word (rendered in Fig. 1 in bold face) in the example sentences for a particular Wiktionary sense is linked to a GermaNet sense via the sense mapping of GermaNet with Wiktionary, the example sentences are automatically sense-annotated and can be included as part of WebCAGe. Additional material for WebCAGe is harvested by following the links to Wikipedia, the Gutenberg archive, and other web-based materials. The external webpages and the Gutenberg texts are obtained from the web by a web-crawler that takes some URLs as input and outputs the texts of the corresponding web sites. The Wikipedia articles are obtained by the open-source Java Wikipedia JWPL Since the links to Wikipedia, the Gutenberg archive, and other web-based materials also belong to particular Wiktionary sense entries that in turn are mapped to GermaNet senses, the target words contained in these materials are automatically sense-annotated. Notice that the target word often occurs more than once in a given text. In keeping with the widely used heuristic of “one sense per discourse”, multiple occurrences of a target word in a given text are all assigned to the same GermaNet sense. An inspection of the annotated data shows that this heuristic has proven to be highly reliable in practice. It is correct in 99.96% of all target word occurrences in the Wiktionary example sentences, in 96.75% of all occurrences in the external webpages, and in 95.62% of the Wikipedia files. WebCAGe is developed primarily for the purpose of the word sense disambiguation task. Therefore, only those target words that are genuinely ambiguous are included in this resource. Since WebCAGe uses GermaNet as its sense inventory, this means that each target word has at least two GermaNet senses, i.e., belongs to at least two distinct synsets. The GermaNet-Wiktionary mapping is not always one-to-one. Sometimes one GermaNet sense is mapped to more than one sense in Wiktionary. Fig. 2 illustrates such a case. For word resource records three distinct senses. The first sense (‘data repository’) 390 in GermaNet corresponds to the first sense in Wiktionary, and the second sense in GermaNet (‘archive’) corresponds to both the second and third senses in Wiktionary. The third sense in GermaNet (‘archived file’) does not map onto any sense in Wiktionary at all. As a result, the word included in the WebCAGe resource with precisely the sense mappings connected by the arrows shown in Fig. 2. The fact that the second GermaNet sense corresponds to two sense descriptions in Wiktionary simply means that the target words in the example are both annotated by the same sense. Furthermore, note that the word still genuinely ambiguous since there is a second (one-to-one) mapping between the first senses recorded in GermaNet and Wiktionary, respectively. However, since the third GermaNet sense is not mapped onto any Wiktionary sense at all, WebCAGe will not contain any example sentences for this particular GermaNet sense. The following section describes how the target words within these textual materials can be automatically identified. 4 Automatic Detection of Target Words For highly inflected languages such as German, target word identification is more complex compared to languages with an impoverished inflectional morphology, such as English, and thus requires automatic lemmatization. Moreover, the target word in a text to be sense-annotated is not always a simplex word but can also appear as subpart of a complex word such as a compound. Since the constituent parts of a compound are not usually separated by blank spaces or hyphens, German compounding poses a particular challenge for target word identification. Another challenging case for automatic target word detecin German concerns particle verbs such as an- Here, the difficulty arises the verbal stem (e.g., is separated its particle (e.g., in German verb-initial and verb-second clause types. As a preprocessing step for target word identification, the text is split into individual sentences, tokenized, and lemmatized. For this purpose, the sentence detector and the tokenizer of the suite Apache OpenNLP and the TreeTagger (Schmid, 1994) are used. Further, compounds split by using Since the automatic lemmatization obtained by the tagger and the compound splitter are not 100% accurate, target word identification also utilizes the full set of inflected forms for a target word whenever such information is available. As it turns out, Wiktionary can often be used for this purpose as well since the German version of Wiktionary often the full set of word forms in such the one shown in Fig. 3 for the word 3: Wiktionary inflection table for Fig. 4 shows an example of such a sensetext for the target word ‘violin bow’. The text is an excerpt from the article where the target word (rendered in bold face) appears many times. Only the second occurrence shown in the figure with a the left) exactly matches the is. All other occurrences are eithe plural form the geniform part of a compound such or the plural form as part a compound such as in The first occurrence of the target word in Fig. 4 is also part of a compound. Here, the target word occurs in the as part of the adjectival compound bo- For expository purposes, the data format shown in Fig. 4 is much simplified compared to the ac- XML-based format in WebCAGe. The inforinflection table cannot be extracted with the Java Wikipedia Library JWPL. It is rather extracted from the Wiktionary dump file. 391 4: Excerpt from Wikipedia article tagged with target word bow’. mation for each occurrence of a target word consists of the GermaNet sense, i.e., the lexical unit ID, the lemma of the target word, and the Gerword category information, i.e., nouns, and verbs. 5 Evaluation In order to assess the effectiveness of the approach, we examine the overall size of WebCAGe and the relative size of the different text collections (see Table 1), compare WebCAGe to other sense-annotated corpora for German (see Table 2), and present a precisionand recall-based evaluation of the algorithm that is used for automatically identifying target words in the harvested texts (see Table 3). Table 1 shows that Wiktionary (7644 tagged word tokens) and Wikipedia (1732) contribute by far the largest subsets of the total number of tagged word tokens (10750) compared with the external webpages (589) and the Gutenberg texts (785). These tokens belong to 2607 distinct polysemous words contained in GermaNet, among which there are 211 adjectives, 1499 nouns, and 897 verbs (see Table 2). On average, these words have 2.9 senses in GermaNet (2.4 for adjectives, 2.6 for nouns, and 3.6 for verbs). Table 2 also shows that WebCAGe is considerably larger than the other two sense-annotated corpora available for German ((Broscheit et al., 2010) and (Raileanu et al., 2002)). It is important to keep in mind, though, that the other two resources were manually constructed, whereas WebCAGe is the result of an automatic harvesting method. Such an automatic method will only constitute a viable alternative to the labor-intensive manual method if the results are of sufficient quality so that the harvested data set can be used as is or can be further improved with a minimal amount of manual post-editing. For the purpose of the present evaluation, we conducted a precisionand recall-based analysis for the text types of Wiktionary examples, webpages, and Wikipedia articles sep- 392 Table 1: Current size of WebCAGe. Wiktionary examples webpages Wikipedia articles Gutenberg All texts texts Number of tagged word tokens adjectives 575 31 79 28 713 nouns 4103 446 1643 655 6847 verbs 2966 112 10 102 3190 all word classes 7644 589 1732 785 10750 Number of tagged sentences adjectives 565 31 76 26 698 nouns 3965 420 1404 624 6413 verbs 2945 112 10 102 3169 all word classes 7475 563 1490 752 10280 Total adjectives 623 1297 430 65030 67380 number sentences nouns 4184 9630 6851 376159 396824 verbs 3087 5285 263 146755 155390 all word classes 7894 16212 7544 587944 619594 Table 2: Comparing WebCAGe to other sense-tagged corpora of German. WebCAGe Broscheit et al., 2010 Raileanu et al., 2002 Sense adjectives 211 6 0 tagged nouns 1499 18 25 words verbs 897 16 0 all word classes 2607 40 25 Number of tagged word tokens 10750 approx. 800 2421 Domain independent yes yes domain arately for the three word classes of adjectives, nouns, and verbs. Table 3 shows that precision and recall for all three word classes that occur for Wiktionary examples, external webpages, and Wikipedia articles lies above 92%. The only sizeable deviations are the results for verbs that occur in the Gutenberg texts. Apart from this one exception, the results in Table 3 prove the viability of the proposed method for automatic harvesting of sense-annotated data. The average precision for all three word classes is of sufficient quality to be used as-is if approximately 2-5% noise in the annotated data is acceptable. In order to eliminate such noise, manual post-editing is required. However, such post-editing is within acceptable limits: it took an experienced research assistant a total of 25 hours to hand-correct all the occurrences of sense-annotated target words and to manually sense-tag any missing target words for the four text types. 6 Related Work and Future Directions With relatively few exceptions to be discussed shortly, the construction of sense-annotated corpora has focussed on purely manual methods. This is true for SemCor, the WordNet Gloss Corpus, and for the training sets constructed for English as part of the SensEval and SemEval shared task competitions (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004). Purely manual methods were also used for the German sense-annotated corpora constructed by Broscheit et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary examples webpages Wikipedia articles Gutenberg texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The only previous attempts of harvesting corpus data for the purpose of constructing a sense-annotated corpus are the semi-supervised method developed by Yarowsky (1995), the knowledge-based approach of Leacock et al. (1998), later also used by Agirre and Lopez de Lacalle (2004), and the automatic association of Web directories (from the Open Directory Project, ODP) to WordNet senses by Santamaria et al. (2003). The latter study (Santamaria et al., 2003) is closest in spirit to the approach presented here. It also relies on an automatic mapping between wordnet senses and a second web resource. While our approach is based on automatic mappings between GermaNet and Wiktionary, their mapping algorithm maps WordNet senses to ODP subdirectories. Since these ODP subdirectories contain natural language descriptions of websites relevant to the subdirectory in question, this textual material can be used for harvesting sense-specific examples. The ODP project also covers German so that, in principle, this harvesting method could be applied to German in order to collect additional sense-tagged data for WebCAGe. The approach of Yarowsky (1995) first collects all example sentences that contain a polysemous word from a very large corpus. In a second step, a small number of examples that are representative for each of the senses of the polysemous target word is selected from the large corpus from step 1. These representative examples are manually sense-annotated and then fed into a decisionlist supervised WSD algorithm as a seed set for iteratively disambiguating the remaining examples collected in step 1. The selection and annotation of the representative examples in Yarowsky’s approach is performed completely manually and is therefore limited to the amount of data that can reasonably be annotated by hand. Leacock et al. (1998), Agirre and Lopez de Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating senseannotated corpora. By focusing on web-based data, their work resembles the research described in the present paper. However, the underlying harvesting methods differ. While our approach relies on a wordnet to Wiktionary mapping, their approaches all rely on the monosemous relative heuristic. Their heuristic works as follows: In order to harvest corpus examples for a polysemous word, the WordNet relations such as synonymy and hypernymy are inspected for the presence of unambiguous words, i.e., words that only appear in exactly one synset. The examples found for these monosemous relatives can then be senseannotated with the particular sense of its ambiguous word relative. In order to increase coverage of the monosemous relatives approach, Mihalcea and Moldovan (1999) have developed a glossbased extension, which relies on word overlap of the gloss and the WordNet sense in question for all those cases where a monosemous relative is not contained in the WordNet dataset. The approaches of Leacock et al., Agirre and Lopez de Lacalle, and Mihalcea and Moldovan as 394 well as Yarowsky’s approach provide interesting directions for further enhancing the WebCAGe resource. It would be worthwhile to use the automatically harvested sense-annotated examples as the seed set for Yarowsky’s iterative method for creating a large sense-annotated corpus. Another fruitful direction for further automatic expansion of WebCAGe is to use the heuristic of monosemous relatives used by Leacock et al., by Agirre and Lopez de Lacalle, and by Mihalcea and Moldovan. However, we have to leave these matters for future research. In order to validate the language independence of our approach, we plan to apply our method to sense inventories for languages other than German. A precondition for such an experiment is an existing mapping between the sense inventory in question and a web-based resource such as Wiktionary or Wikipedia. With BabelNet, Navigli and Ponzetto (2010) have created a multilingual resource that allows the testing of our approach to languages other than German. As a first step in this direction, we applied our approach to English using the mapping between the Princeton Word- Net and the English version of Wiktionary provided by Meyer and Gurevych (2011). The results of these experiments, which are reported in Henrich et al. (2012), confirm the general applicability of our approach. To conclude: This paper describes an automatic method for creating a domain-independent senseannotated corpus harvested from the web. The data obtained by this method for German have resulted in the WebCAGe resource which currently represents the largest sense-annotated corpus available for this language. The publication of this paper is accompanied by making WebCAGe freely available. Acknowledgements The research reported in this paper was jointly funded by the SFB 833 grant of the DFG and by the CLARIN-D grant of the BMBF. We would like to thank Christina Hoppermann, Marie Hinrichs as well as three anonymous EACL 2012 reviewers for their helpful comments on earlier verof this paper. We are very grateful to Reinhild Barkey, Sarah Schulz, and Johannes Wahle for their help with the evaluation reported in Section 5. Special thanks go to Yana Panchenko and Yannick Versley for their support with the webcrawler and to Emanuel Dima and Klaus Suttner for helping us to obtain the Gutenberg and Wikipedia texts.</abstract>
<note confidence="0.891420368421053">References Agirre, E., Lopez de Lacalle, O. 2004. Publicly available topic signatures for all WordNet nominal of the 4th International Conference on Languages Resources and Evaluations (LREC’04), Lisbon, Portugal, pp. 1123–1126 E., Marquez, L., Wicentowski, R. 2007. Proceedings of the 4th International Workshop on Se- Assoc. for Computational Linguistics, Stroudsburg, PA, USA Broscheit, S., Frank, A., Jehle, D., Ponzetto, S. P., Rehl, D., Summa, A., Suttner, K., Vola, S. 2010. Rapid bootstrapping of Word Sense Disambiguaresources for German. of the 10. zur Verarbeitung Nat¨urlicher Saarbr¨ucken, Germany, pp. 19–27 K., Strapparava, C. 2010. of the 5th Workshop on Semantic Assoc. for Computational Linguistics, Stroudsburg,</note>
<address confidence="0.795263">PA, USA</address>
<note confidence="0.723346125">C. (ed.). 1998. An Electronic The MIT Press. Henrich, V., Hinrichs, E. 2010. GernEdiT – The Ger- Editing Tool. of the Seventh Conference on International Language Resources Evaluation Valletta, Malta, pp. 2228–2235 Henrich, V., Hinrichs, E., Vodolazova, T. 2011. Semi-</note>
<title confidence="0.501444">Automatic Extension of GermaNet with Sense Def-</title>
<author confidence="0.392123">of the th Language</author>
<author confidence="0.392123">Technology Conference Human Lan-</author>
<affiliation confidence="0.6337675">guage Technologies as a Challenge for Computer and Linguistics Poznan, Poland,</affiliation>
<address confidence="0.465784">pp. 126–130</address>
<note confidence="0.893103127272727">Henrich, V., Hinrichs, E., Vodolazova, T. 2012. An Automatic Method for Creating a Sense-Annotated Corpus Harvested from the Web. Poster preat International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2012), New Delhi, India, March 2012 Koeva, S., Leseva, S., Todorova, M. 2006. Bul- Sense Tagged Corpus. of the 5th SALTMIL Workshop on Minority Languages: 395 Computational Linguistics Association for Computational Linguistics, Stroudsburg, PA, USA, pp. 189–196 Strategies for Developing Machine Translation for Genoa, Italy, pp. 79–87 Kunze, C., Lemnitzer, L. 2002. GermaNet repvisualization, application. Proceedings of the 3rd International Language Resources Evaluation Las Palmas, Canary Islands, pp. 1485–1491 Leacock, C., Chodorow, M., Miller, G. A. 1998. Using corpus statistics and wordnet relations for identification. 24(1):147–165 Meyer, C. M., Gurevych, I. 2011. What Psycholinguists Know About Chemistry: Aligning Wiktionary and WordNet for Increased Domain Covof the 5th International Joint on Natural Language Processing (IJC- NLP), Chiang Mai, Thailand, pp. 883–892 Mihalcea, R., Moldovan, D. 1999. An Automatic Method for Generating Sense Tagged Corof the American Association for Intelligence Orlando, Florida, pp. 461–466 R., Chklovski, T., Kilgarriff, A. 2004. Proceedings of Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic of Barcelona, Spain Navigli, R., Ponzetto, S. P. 2010. BabelNet: Building a Very Large Multilingual Semantic Network. Proceedings of the 48th Annual Meeting of the Asfor Computational Linguistics Uppsala, Sweden, pp. 216–225 Raileanu, D., Buitelaar, P., Vintar, S., Bay, J. 2002. Evaluation Corpora for Sense Disambiguation in Medical Domain. of the 3rd International Language Resources and Evaluation (LREC’02), Las Palmas, Canary Islands, pp. 609– 612 Santamar´ıa, C., Gonzalo, J., Verdejo, F. 2003. Automatic Association of Web Directories to Word Linguistics (3), MIT Press, PP. 485–502 Schmid, H. 1994. Probabilistic Part-of-Speech Tag-</note>
<affiliation confidence="0.7094385">Using Decision Trees. of the International Conference on New Methods in Lan-</affiliation>
<address confidence="0.876009">Manchester, UK</address>
<note confidence="0.676725444444444">Wu, Y., Jin, P., Zhang, Y., Yu, S. 2006. A Chinese with Word Sense Annotation. of 21st International Conference on Computer Proof Oriental Languages Singapore, pp. 414–421 Yarowsky, D. 1995. Unsupervised word sense disrivaling supervised methods. Proceedings of the 33rd Annual Meeting on Association 396</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>Lopez de Lacalle</author>
<author>O</author>
</authors>
<title>Publicly available topic signatures for all WordNet nominal senses.</title>
<date>2004</date>
<booktitle>Proceedings of the 4th International Conference on Languages Resources and Evaluations (LREC’04),</booktitle>
<pages>1123--1126</pages>
<location>Lisbon,</location>
<marker>Agirre, de Lacalle, O, 2004</marker>
<rawString>Agirre, E., Lopez de Lacalle, O. 2004. Publicly available topic signatures for all WordNet nominal senses. Proceedings of the 4th International Conference on Languages Resources and Evaluations (LREC’04), Lisbon, Portugal, pp. 1123–1126</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>L Marquez</author>
<author>R Wicentowski</author>
</authors>
<date>2007</date>
<booktitle>Proceedings of the 4th International Workshop on Semantic Evaluations. Assoc. for Computational Linguistics,</booktitle>
<location>Stroudsburg, PA, USA</location>
<contexts>
<context position="1366" citStr="Agirre et al., 2007" startWordPosition="190" endWordPosition="193">otated with GermaNet Senses), a resource which currently represents the largest sense-annotated corpus available for German. While the present paper focuses on one particular language, the method as such is language-independent. 1 Motivation The availability of large sense-annotated corpora is a necessary prerequisite for any supervised and many semi-supervised approaches to word sense disambiguation (WSD). There has been steady progress in the development and in the performance of WSD algorithms for languages such as English for which hand-crafted sense-annotated corpora have been available (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004), while WSD research for languages that lack these corpora has lagged behind considerably or has been impossible altogether. Thus far, sense-annotated corpora have typically been constructed manually, making the creation of such resources expensive and the compilation of larger data sets difficult, if not completely infeasible. It is therefore timely and appropriate to explore alternatives to manual annotation and to investigate automatic means of creating sense-annotated corpora. Ideally, any automatic method should satisfy the following crit</context>
<context position="19649" citStr="Agirre et al., 2007" startWordPosition="3126" endWordPosition="3129">owever, such post-editing is within acceptable limits: it took an experienced research assistant a total of 25 hours to hand-correct all the occurrences of sense-annotated target words and to manually sense-tag any missing target words for the four text types. 6 Related Work and Future Directions With relatively few exceptions to be discussed shortly, the construction of sense-annotated corpora has focussed on purely manual methods. This is true for SemCor, the WordNet Gloss Corpus, and for the training sets constructed for English as part of the SensEval and SemEval shared task competitions (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004). Purely manual methods were also used for the German sense-annotated corpora constructed by Broscheit et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97</context>
</contexts>
<marker>Agirre, Marquez, Wicentowski, 2007</marker>
<rawString>Agirre, E., Marquez, L., Wicentowski, R. 2007. Proceedings of the 4th International Workshop on Semantic Evaluations. Assoc. for Computational Linguistics, Stroudsburg, PA, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Broscheit</author>
<author>A Frank</author>
<author>D Jehle</author>
<author>S P Ponzetto</author>
<author>D Rehl</author>
<author>A Summa</author>
<author>K Suttner</author>
<author>S Vola</author>
</authors>
<title>Rapid bootstrapping of Word Sense Disambiguation resources for German.</title>
<date>2010</date>
<booktitle>Proceedings of the 10. Konferenz zur Verarbeitung Nat¨urlicher Sprache,</booktitle>
<pages>pp.</pages>
<location>Saarbr¨ucken, Germany,</location>
<contexts>
<context position="16779" citStr="Broscheit et al., 2010" startWordPosition="2641" endWordPosition="2644">ionary (7644 tagged word tokens) and Wikipedia (1732) contribute by far the largest subsets of the total number of tagged word tokens (10750) compared with the external webpages (589) and the Gutenberg texts (785). These tokens belong to 2607 distinct polysemous words contained in GermaNet, among which there are 211 adjectives, 1499 nouns, and 897 verbs (see Table 2). On average, these words have 2.9 senses in GermaNet (2.4 for adjectives, 2.6 for nouns, and 3.6 for verbs). Table 2 also shows that WebCAGe is considerably larger than the other two sense-annotated corpora available for German ((Broscheit et al., 2010) and (Raileanu et al., 2002)). It is important to keep in mind, though, that the other two resources were manually constructed, whereas WebCAGe is the result of an automatic harvesting method. Such an automatic method will only constitute a viable alternative to the labor-intensive manual method if the results are of sufficient quality so that the harvested data set can be used as is or can be further improved with a minimal amount of manual post-editing. For the purpose of the present evaluation, we conducted a precision- and recall-based analysis for the text types of Wiktionary examples, ex</context>
<context position="19816" citStr="Broscheit et al. (2010)" startWordPosition="3151" endWordPosition="3154">nnotated target words and to manually sense-tag any missing target words for the four text types. 6 Related Work and Future Directions With relatively few exceptions to be discussed shortly, the construction of sense-annotated corpora has focussed on purely manual methods. This is true for SemCor, the WordNet Gloss Corpus, and for the training sets constructed for English as part of the SensEval and SemEval shared task competitions (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004). Purely manual methods were also used for the German sense-annotated corpora constructed by Broscheit et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 20</context>
</contexts>
<marker>Broscheit, Frank, Jehle, Ponzetto, Rehl, Summa, Suttner, Vola, 2010</marker>
<rawString>Broscheit, S., Frank, A., Jehle, D., Ponzetto, S. P., Rehl, D., Summa, A., Suttner, K., Vola, S. 2010. Rapid bootstrapping of Word Sense Disambiguation resources for German. Proceedings of the 10. Konferenz zur Verarbeitung Nat¨urlicher Sprache, Saarbr¨ucken, Germany, pp. 19–27</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>C Strapparava</author>
</authors>
<date>2010</date>
<booktitle>Proceedings of the 5th International Workshop on Semantic Evaluation. Assoc. for Computational Linguistics,</booktitle>
<location>Stroudsburg, PA, USA</location>
<marker>Erk, Strapparava, 2010</marker>
<rawString>Erk, K., Strapparava, C. 2010. Proceedings of the 5th International Workshop on Semantic Evaluation. Assoc. for Computational Linguistics, Stroudsburg, PA, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="4766" citStr="Fellbaum, 1998" startWordPosition="722" endWordPosition="723"> sense-annotated materials from the web. The algorithm for identifying the target words in the harvested texts is described in Section 4. In Section 5, the approach of automatically creating a web-harvested corpus annotated with GermaNet senses is evaluated and compared to existing sense-annotated corpora for German. Related work is discussed in Section 6, together with concluding remarks and an outlook on future work. 2 Resources 2.1 GermaNet GermaNet (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002) is a lexical semantic network that is modeled after the Princeton WordNet for English (Fellbaum, 1998). It partitions the 2http://www.wikipedia.org/ 3Using a wordnet as the gold standard for the sense inventory is fully in line with standard practice for English where the Princeton WordNet (Fellbaum, 1998) is typically taken as the gold standard. lexical space into a set of concepts that are interlinked by semantic relations. A semantic concept is represented as a synset, i.e., as a set of words whose individual members (referred to as lexical units) are taken to be (near) synonyms. Thus, a synset is a set-representation of the semantic relation of synonymy. There are two types of semantic rel</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (ed.). 1998. WordNet An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Henrich</author>
<author>E Hinrichs</author>
</authors>
<title>GernEdiT – The GermaNet Editing Tool.</title>
<date>2010</date>
<booktitle>Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>2228--2235</pages>
<location>Valletta, Malta,</location>
<contexts>
<context position="3488" citStr="Henrich and Hinrichs, 2010" startWordPosition="526" endWordPosition="529">nference of the European Chapter of the Association for Computational Linguistics, pages 387–396, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics Wikipedia2. As a proof of concept, this automatic method has been applied to German, a language for which sense-annotated corpora are still in short supply and fail to satisfy most if not all of the criteria under (3) above. While the present paper focuses on one particular language, the method as such is language-independent. In the case of German, the sense inventory is taken from the German wordnet GermaNet3 (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002). The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. This mapping is described in Henrich et al. (2011). The resulting resource consists of a web-harvested corpus WebCAGe (short for: Web-Harvested Corpus Annotated with GermaNet Senses), which is freely available at: http://www.sfs.unituebingen.de/en/webcage.shtml The remainder of this paper is structured as follows: Section 2 provides a brief overview of the resources GermaNet and Wiktionary. Section 3 introduces the mapping of GermaNet to Wikti</context>
</contexts>
<marker>Henrich, Hinrichs, 2010</marker>
<rawString>Henrich, V., Hinrichs, E. 2010. GernEdiT – The GermaNet Editing Tool. Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, pp. 2228–2235</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Henrich</author>
<author>E Hinrichs</author>
<author>T Vodolazova</author>
</authors>
<title>SemiAutomatic Extension of GermaNet with Sense Definitions from Wiktionary.</title>
<date>2011</date>
<booktitle>Proceedings of the 5th Language &amp; Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics (LTC’11),</booktitle>
<pages>126--130</pages>
<location>Poznan,</location>
<contexts>
<context position="3691" citStr="Henrich et al. (2011)" startWordPosition="558" endWordPosition="561">f concept, this automatic method has been applied to German, a language for which sense-annotated corpora are still in short supply and fail to satisfy most if not all of the criteria under (3) above. While the present paper focuses on one particular language, the method as such is language-independent. In the case of German, the sense inventory is taken from the German wordnet GermaNet3 (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002). The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. This mapping is described in Henrich et al. (2011). The resulting resource consists of a web-harvested corpus WebCAGe (short for: Web-Harvested Corpus Annotated with GermaNet Senses), which is freely available at: http://www.sfs.unituebingen.de/en/webcage.shtml The remainder of this paper is structured as follows: Section 2 provides a brief overview of the resources GermaNet and Wiktionary. Section 3 introduces the mapping of GermaNet to Wiktionary and how this mapping can be used to automatically harvest sense-annotated materials from the web. The algorithm for identifying the target words in the harvested texts is described in Section 4. In</context>
<context position="7506" citStr="Henrich et al. (2011)" startWordPosition="1137" endWordPosition="1140"> of the German Wiktionary as of February 2, 2011 is uti4Wiktionary is available under the Creative Commons Attribution/Share-Alike license http://creativecommons.org/licenses/by-sa/3.0/deed.en 388 Figure 1: Sense mapping of GermaNet and Wiktionary using the example of Bogen. lized, consisting of 46457 German words comprising 70339 word senses. The Wiktionary data was extracted by the freely available Java-based library JWKTL5. 3 Creation of a Web-Harvested Corpus The starting point for creating WebCAGe is an existing mapping of GermaNet senses with Wiktionary sense definitions as described in Henrich et al. (2011). This mapping is the result of a two-stage process: i) an automatic word overlap alignment algorithm in order to match GermaNet senses with Wiktionary sense descriptions, and ii) a manual post-correction step of the automatic alignment. Manual post-correction can be kept at a reasonable level of effort due to the high accuracy (93.8%) of the automatic alignment. The original purpose of this mapping was to automatically add Wiktionary sense descriptions to GermaNet. However, the alignment of these two resources opens up a much wider range of 5http://www.ukp.tu-darmstadt.de/software/jwktl possi</context>
</contexts>
<marker>Henrich, Hinrichs, Vodolazova, 2011</marker>
<rawString>Henrich, V., Hinrichs, E., Vodolazova, T. 2011. SemiAutomatic Extension of GermaNet with Sense Definitions from Wiktionary. Proceedings of the 5th Language &amp; Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics (LTC’11), Poznan, Poland, pp. 126–130</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Henrich</author>
<author>E Hinrichs</author>
<author>T Vodolazova</author>
</authors>
<title>An Automatic Method for Creating a Sense-Annotated Corpus Harvested from the Web. Poster presented at</title>
<date>2012</date>
<booktitle>13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2012),</booktitle>
<location>New Delhi, India,</location>
<contexts>
<context position="24799" citStr="Henrich et al. (2012)" startWordPosition="3952" endWordPosition="3955">ries for languages other than German. A precondition for such an experiment is an existing mapping between the sense inventory in question and a web-based resource such as Wiktionary or Wikipedia. With BabelNet, Navigli and Ponzetto (2010) have created a multilingual resource that allows the testing of our approach to languages other than German. As a first step in this direction, we applied our approach to English using the mapping between the Princeton WordNet and the English version of Wiktionary provided by Meyer and Gurevych (2011). The results of these experiments, which are reported in Henrich et al. (2012), confirm the general applicability of our approach. To conclude: This paper describes an automatic method for creating a domain-independent senseannotated corpus harvested from the web. The data obtained by this method for German have resulted in the WebCAGe resource which currently represents the largest sense-annotated corpus available for this language. The publication of this paper is accompanied by making WebCAGe freely available. Acknowledgements The research reported in this paper was jointly funded by the SFB 833 grant of the DFG and by the CLARIN-D grant of the BMBF. We would like to</context>
</contexts>
<marker>Henrich, Hinrichs, Vodolazova, 2012</marker>
<rawString>Henrich, V., Hinrichs, E., Vodolazova, T. 2012. An Automatic Method for Creating a Sense-Annotated Corpus Harvested from the Web. Poster presented at 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2012), New Delhi, India, March 2012</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Koeva</author>
<author>S Leseva</author>
<author>M Todorova</author>
</authors>
<title>Bulgarian Sense Tagged Corpus.</title>
<date>2006</date>
<booktitle>Proceedings of the 5th SALTMIL Workshop on Minority Languages: Strategies for Developing Machine Translation for Minority Languages,</booktitle>
<pages>79--87</pages>
<location>Genoa,</location>
<contexts>
<context position="20418" citStr="Koeva et al., 2006" startWordPosition="3240" endWordPosition="3243">it et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The only previous attempts of harvesting corpus data for the purpose of constructing a sense-annotated corpus are the semi-supervised method developed by Yarowsky (1995), the knowledge-based approach of Leacock et al. (1998), later also used by Agirre and Lopez de Lacalle (2004), and the automatic association of Web directories (from the Open Directory Project, ODP) to WordNet senses by Santamaria et al. (2003). The latter study (Santamaria et al., 2003) is closest in spirit to the approach presented here. It also relies on an automatic mapping between wordnet senses and a </context>
</contexts>
<marker>Koeva, Leseva, Todorova, 2006</marker>
<rawString>Koeva, S., Leseva, S., Todorova, M. 2006. Bulgarian Sense Tagged Corpus. Proceedings of the 5th SALTMIL Workshop on Minority Languages: Strategies for Developing Machine Translation for Minority Languages, Genoa, Italy, pp. 79–87</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kunze</author>
<author>L Lemnitzer</author>
</authors>
<title>GermaNet representation, visualization, application.</title>
<date>2002</date>
<booktitle>Proceedings of the 3rd International Language Resources and Evaluation (LREC’02), Las Palmas, Canary Islands,</booktitle>
<pages>1485--1491</pages>
<contexts>
<context position="3516" citStr="Kunze and Lemnitzer, 2002" startWordPosition="530" endWordPosition="533">pter of the Association for Computational Linguistics, pages 387–396, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics Wikipedia2. As a proof of concept, this automatic method has been applied to German, a language for which sense-annotated corpora are still in short supply and fail to satisfy most if not all of the criteria under (3) above. While the present paper focuses on one particular language, the method as such is language-independent. In the case of German, the sense inventory is taken from the German wordnet GermaNet3 (Henrich and Hinrichs, 2010; Kunze and Lemnitzer, 2002). The web-harvesting relies on an existing mapping of GermaNet to the German version of the web-based dictionary Wiktionary. This mapping is described in Henrich et al. (2011). The resulting resource consists of a web-harvested corpus WebCAGe (short for: Web-Harvested Corpus Annotated with GermaNet Senses), which is freely available at: http://www.sfs.unituebingen.de/en/webcage.shtml The remainder of this paper is structured as follows: Section 2 provides a brief overview of the resources GermaNet and Wiktionary. Section 3 introduces the mapping of GermaNet to Wiktionary and how this mapping c</context>
</contexts>
<marker>Kunze, Lemnitzer, 2002</marker>
<rawString>Kunze, C., Lemnitzer, L. 2002. GermaNet representation, visualization, application. Proceedings of the 3rd International Language Resources and Evaluation (LREC’02), Las Palmas, Canary Islands, pp. 1485–1491</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
<author>G A Miller</author>
</authors>
<title>Using corpus statistics and wordnet relations for sense identification.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="20662" citStr="Leacock et al. (1998)" startWordPosition="3277" endWordPosition="3281">es texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The only previous attempts of harvesting corpus data for the purpose of constructing a sense-annotated corpus are the semi-supervised method developed by Yarowsky (1995), the knowledge-based approach of Leacock et al. (1998), later also used by Agirre and Lopez de Lacalle (2004), and the automatic association of Web directories (from the Open Directory Project, ODP) to WordNet senses by Santamaria et al. (2003). The latter study (Santamaria et al., 2003) is closest in spirit to the approach presented here. It also relies on an automatic mapping between wordnet senses and a second web resource. While our approach is based on automatic mappings between GermaNet and Wiktionary, their mapping algorithm maps WordNet senses to ODP subdirectories. Since these ODP subdirectories contain natural language descriptions of w</context>
<context position="22283" citStr="Leacock et al. (1998)" startWordPosition="3542" endWordPosition="3545"> very large corpus. In a second step, a small number of examples that are representative for each of the senses of the polysemous target word is selected from the large corpus from step 1. These representative examples are manually sense-annotated and then fed into a decisionlist supervised WSD algorithm as a seed set for iteratively disambiguating the remaining examples collected in step 1. The selection and annotation of the representative examples in Yarowsky’s approach is performed completely manually and is therefore limited to the amount of data that can reasonably be annotated by hand. Leacock et al. (1998), Agirre and Lopez de Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating senseannotated corpora. By focusing on web-based data, their work resembles the research described in the present paper. However, the underlying harvesting methods differ. While our approach relies on a wordnet to Wiktionary mapping, their approaches all rely on the monosemous relative heuristic. Their heuristic works as follows: In order to harvest corpus examples for a polysemous word, the WordNet relations such as synonymy and hype</context>
</contexts>
<marker>Leacock, Chodorow, Miller, 1998</marker>
<rawString>Leacock, C., Chodorow, M., Miller, G. A. 1998. Using corpus statistics and wordnet relations for sense identification. Computational Linguistics, 24(1):147–165</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M Meyer</author>
<author>I Gurevych</author>
</authors>
<title>What Psycholinguists Know About Chemistry: Aligning Wiktionary and WordNet for Increased Domain Coverage.</title>
<date>2011</date>
<booktitle>Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP), Chiang Mai, Thailand,</booktitle>
<pages>883--892</pages>
<contexts>
<context position="24720" citStr="Meyer and Gurevych (2011)" startWordPosition="3938" endWordPosition="3941">language independence of our approach, we plan to apply our method to sense inventories for languages other than German. A precondition for such an experiment is an existing mapping between the sense inventory in question and a web-based resource such as Wiktionary or Wikipedia. With BabelNet, Navigli and Ponzetto (2010) have created a multilingual resource that allows the testing of our approach to languages other than German. As a first step in this direction, we applied our approach to English using the mapping between the Princeton WordNet and the English version of Wiktionary provided by Meyer and Gurevych (2011). The results of these experiments, which are reported in Henrich et al. (2012), confirm the general applicability of our approach. To conclude: This paper describes an automatic method for creating a domain-independent senseannotated corpus harvested from the web. The data obtained by this method for German have resulted in the WebCAGe resource which currently represents the largest sense-annotated corpus available for this language. The publication of this paper is accompanied by making WebCAGe freely available. Acknowledgements The research reported in this paper was jointly funded by the S</context>
</contexts>
<marker>Meyer, Gurevych, 2011</marker>
<rawString>Meyer, C. M., Gurevych, I. 2011. What Psycholinguists Know About Chemistry: Aligning Wiktionary and WordNet for Increased Domain Coverage. Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP), Chiang Mai, Thailand, pp. 883–892</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D Moldovan</author>
</authors>
<title>An Automatic Method for Generating Sense Tagged Corpora.</title>
<date>1999</date>
<booktitle>Proceedings of the American Association for Artificial Intelligence (AAAI’99),</booktitle>
<pages>461--466</pages>
<location>Orlando, Florida,</location>
<contexts>
<context position="22353" citStr="Mihalcea and Moldovan (1999)" startWordPosition="3554" endWordPosition="3557">s that are representative for each of the senses of the polysemous target word is selected from the large corpus from step 1. These representative examples are manually sense-annotated and then fed into a decisionlist supervised WSD algorithm as a seed set for iteratively disambiguating the remaining examples collected in step 1. The selection and annotation of the representative examples in Yarowsky’s approach is performed completely manually and is therefore limited to the amount of data that can reasonably be annotated by hand. Leacock et al. (1998), Agirre and Lopez de Lacalle (2004), and Mihalcea and Moldovan (1999) propose a set of methods for automatic harvesting of web data for the purposes of creating senseannotated corpora. By focusing on web-based data, their work resembles the research described in the present paper. However, the underlying harvesting methods differ. While our approach relies on a wordnet to Wiktionary mapping, their approaches all rely on the monosemous relative heuristic. Their heuristic works as follows: In order to harvest corpus examples for a polysemous word, the WordNet relations such as synonymy and hypernymy are inspected for the presence of unambiguous words, i.e., words</context>
</contexts>
<marker>Mihalcea, Moldovan, 1999</marker>
<rawString>Mihalcea, R., Moldovan, D. 1999. An Automatic Method for Generating Sense Tagged Corpora. Proceedings of the American Association for Artificial Intelligence (AAAI’99), Orlando, Florida, pp. 461–466</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Chklovski</author>
<author>A Kilgarriff</author>
</authors>
<date>2004</date>
<booktitle>Proceedings of Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<location>Barcelona, Spain</location>
<contexts>
<context position="1417" citStr="Mihalcea et al., 2004" startWordPosition="198" endWordPosition="201">urrently represents the largest sense-annotated corpus available for German. While the present paper focuses on one particular language, the method as such is language-independent. 1 Motivation The availability of large sense-annotated corpora is a necessary prerequisite for any supervised and many semi-supervised approaches to word sense disambiguation (WSD). There has been steady progress in the development and in the performance of WSD algorithms for languages such as English for which hand-crafted sense-annotated corpora have been available (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004), while WSD research for languages that lack these corpora has lagged behind considerably or has been impossible altogether. Thus far, sense-annotated corpora have typically been constructed manually, making the creation of such resources expensive and the compilation of larger data sets difficult, if not completely infeasible. It is therefore timely and appropriate to explore alternatives to manual annotation and to investigate automatic means of creating sense-annotated corpora. Ideally, any automatic method should satisfy the following criteria: (1) The method used should be language indepe</context>
<context position="19700" citStr="Mihalcea et al., 2004" startWordPosition="3134" endWordPosition="3137">imits: it took an experienced research assistant a total of 25 hours to hand-correct all the occurrences of sense-annotated target words and to manually sense-tag any missing target words for the four text types. 6 Related Work and Future Directions With relatively few exceptions to be discussed shortly, the construction of sense-annotated corpora has focussed on purely manual methods. This is true for SemCor, the WordNet Gloss Corpus, and for the training sets constructed for English as part of the SensEval and SemEval shared task competitions (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004). Purely manual methods were also used for the German sense-annotated corpora constructed by Broscheit et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51</context>
</contexts>
<marker>Mihalcea, Chklovski, Kilgarriff, 2004</marker>
<rawString>Mihalcea, R., Chklovski, T., Kilgarriff, A. 2004. Proceedings of Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>S P Ponzetto</author>
</authors>
<title>BabelNet: Building a Very Large Multilingual Semantic Network.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL’10),</booktitle>
<pages>216--225</pages>
<location>Uppsala,</location>
<contexts>
<context position="24417" citStr="Navigli and Ponzetto (2010)" startWordPosition="3886" endWordPosition="3889">otated corpus. Another fruitful direction for further automatic expansion of WebCAGe is to use the heuristic of monosemous relatives used by Leacock et al., by Agirre and Lopez de Lacalle, and by Mihalcea and Moldovan. However, we have to leave these matters for future research. In order to validate the language independence of our approach, we plan to apply our method to sense inventories for languages other than German. A precondition for such an experiment is an existing mapping between the sense inventory in question and a web-based resource such as Wiktionary or Wikipedia. With BabelNet, Navigli and Ponzetto (2010) have created a multilingual resource that allows the testing of our approach to languages other than German. As a first step in this direction, we applied our approach to English using the mapping between the Princeton WordNet and the English version of Wiktionary provided by Meyer and Gurevych (2011). The results of these experiments, which are reported in Henrich et al. (2012), confirm the general applicability of our approach. To conclude: This paper describes an automatic method for creating a domain-independent senseannotated corpus harvested from the web. The data obtained by this metho</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Navigli, R., Ponzetto, S. P. 2010. BabelNet: Building a Very Large Multilingual Semantic Network. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL’10), Uppsala, Sweden, pp. 216–225</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Raileanu</author>
<author>P Buitelaar</author>
<author>S Vintar</author>
<author>J Bay</author>
</authors>
<title>Evaluation Corpora for Sense Disambiguation in the Medical Domain.</title>
<date>2002</date>
<booktitle>Proceedings of the 3rd International Language Resources and Evaluation (LREC’02), Las Palmas, Canary Islands,</booktitle>
<pages>609--612</pages>
<contexts>
<context position="16807" citStr="Raileanu et al., 2002" startWordPosition="2646" endWordPosition="2649">ns) and Wikipedia (1732) contribute by far the largest subsets of the total number of tagged word tokens (10750) compared with the external webpages (589) and the Gutenberg texts (785). These tokens belong to 2607 distinct polysemous words contained in GermaNet, among which there are 211 adjectives, 1499 nouns, and 897 verbs (see Table 2). On average, these words have 2.9 senses in GermaNet (2.4 for adjectives, 2.6 for nouns, and 3.6 for verbs). Table 2 also shows that WebCAGe is considerably larger than the other two sense-annotated corpora available for German ((Broscheit et al., 2010) and (Raileanu et al., 2002)). It is important to keep in mind, though, that the other two resources were manually constructed, whereas WebCAGe is the result of an automatic harvesting method. Such an automatic method will only constitute a viable alternative to the labor-intensive manual method if the results are of sufficient quality so that the harvested data set can be used as is or can be further improved with a minimal amount of manual post-editing. For the purpose of the present evaluation, we conducted a precision- and recall-based analysis for the text types of Wiktionary examples, external webpages, and Wikiped</context>
<context position="19843" citStr="Raileanu et al. (2002)" startWordPosition="3156" endWordPosition="3159"> manually sense-tag any missing target words for the four text types. 6 Related Work and Future Directions With relatively few exceptions to be discussed shortly, the construction of sense-annotated corpora has focussed on purely manual methods. This is true for SemCor, the WordNet Gloss Corpus, and for the training sets constructed for English as part of the SensEval and SemEval shared task competitions (Agirre et al., 2007; Erk and Strapparava, 2012; Mihalcea et al., 2004). Purely manual methods were also used for the German sense-annotated corpora constructed by Broscheit et al. (2010) and Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The o</context>
</contexts>
<marker>Raileanu, Buitelaar, Vintar, Bay, 2002</marker>
<rawString>Raileanu, D., Buitelaar, P., Vintar, S., Bay, J. 2002. Evaluation Corpora for Sense Disambiguation in the Medical Domain. Proceedings of the 3rd International Language Resources and Evaluation (LREC’02), Las Palmas, Canary Islands, pp. 609– 612</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Santamar´ıa</author>
<author>J Gonzalo</author>
<author>F Verdejo</author>
</authors>
<title>Automatic Association of Web Directories to Word Senses.</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<issue>3</issue>
<pages>485--502</pages>
<publisher>MIT Press,</publisher>
<marker>Santamar´ıa, Gonzalo, Verdejo, 2003</marker>
<rawString>Santamar´ıa, C., Gonzalo, J., Verdejo, F. 2003. Automatic Association of Web Directories to Word Senses. Computational Linguistics 29 (3), MIT Press, PP. 485–502</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<location>Manchester, UK</location>
<contexts>
<context position="13690" citStr="Schmid, 1994" startWordPosition="2124" endWordPosition="2125">nding poses a particular challenge for target word identification. Another challenging case for automatic target word detection in German concerns particle verbs such as ank¨undigen ‘announce’. Here, the difficulty arises when the verbal stem (e.g., k¨undigen) is separated from its particle (e.g., an) in German verb-initial and verb-second clause types. As a preprocessing step for target word identification, the text is split into individual sentences, tokenized, and lemmatized. For this purpose, the sentence detector and the tokenizer of the suite of Apache OpenNLP tools9 and the TreeTagger (Schmid, 1994) are used. Further, compounds are split by using BananaSplit10. Since the automatic lemmatization obtained by the tagger and the compound splitter are not 100% accurate, target word identification also utilizes the full set of inflected forms for a target word whenever such information is available. As it turns out, Wiktionary can often be used for this purpose as well since the German version of Wiktionary often contains the full set of word forms in tables11 such as the one shown in Fig. 3 for the word Bogen. Figure 3: Wiktionary inflection table for Bogen. Fig. 4 shows an example of such a </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. 1994. Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of the International Conference on New Methods in Language Processing, Manchester, UK</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wu</author>
<author>P Jin</author>
<author>Y Zhang</author>
<author>S Yu</author>
</authors>
<title>A Chinese Corpus with Word Sense Annotation.</title>
<date>2006</date>
<booktitle>Proceedings of 21st International Conference on Computer Processing of Oriental Languages (ICCPOL’06), Singapore,</booktitle>
<pages>414--421</pages>
<contexts>
<context position="20436" citStr="Wu et al., 2006" startWordPosition="3244" endWordPosition="3247"> Raileanu et al. (2002) as well as for other languages including the Bulgarian and 393 Table 3: Evaluation of the algorithm of identifying the target words. Wiktionary External Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The only previous attempts of harvesting corpus data for the purpose of constructing a sense-annotated corpus are the semi-supervised method developed by Yarowsky (1995), the knowledge-based approach of Leacock et al. (1998), later also used by Agirre and Lopez de Lacalle (2004), and the automatic association of Web directories (from the Open Directory Project, ODP) to WordNet senses by Santamaria et al. (2003). The latter study (Santamaria et al., 2003) is closest in spirit to the approach presented here. It also relies on an automatic mapping between wordnet senses and a second web resourc</context>
</contexts>
<marker>Wu, Jin, Zhang, Yu, 2006</marker>
<rawString>Wu, Y., Jin, P., Zhang, Y., Yu, S. 2006. A Chinese Corpus with Word Sense Annotation. Proceedings of 21st International Conference on Computer Processing of Oriental Languages (ICCPOL’06), Singapore, pp. 414–421</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>Proceedings of the 33rd Annual Meeting on Association</booktitle>
<contexts>
<context position="20607" citStr="Yarowsky (1995)" startWordPosition="3271" endWordPosition="3272">rnal Wikipedia Gutenberg examples webpages articles texts Precision adjectives 97.70% 95.83% 99.34% 100% nouns 98.17% 98.50% 95.87% 92.19% verbs 97.38% 92.26% 100% 69.87% all word classes 97.32% 96.19% 96.26% 87.43% Recall adjectives 97.70% 97.22% 98.08% 97.14% nouns 98.30% 96.03% 92.70.% 97.38% verbs 97.51% 99.60% 100% 89.20% all word classes 97.94% 97.32% 93.36% 95.42% the Chinese sense-tagged corpora (Koeva et al., 2006; Wu et al., 2006). The only previous attempts of harvesting corpus data for the purpose of constructing a sense-annotated corpus are the semi-supervised method developed by Yarowsky (1995), the knowledge-based approach of Leacock et al. (1998), later also used by Agirre and Lopez de Lacalle (2004), and the automatic association of Web directories (from the Open Directory Project, ODP) to WordNet senses by Santamaria et al. (2003). The latter study (Santamaria et al., 2003) is closest in spirit to the approach presented here. It also relies on an automatic mapping between wordnet senses and a second web resource. While our approach is based on automatic mappings between GermaNet and Wiktionary, their mapping algorithm maps WordNet senses to ODP subdirectories. Since these ODP su</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, D. 1995. Unsupervised word sense disambiguation rivaling supervised methods. Proceedings of the 33rd Annual Meeting on Association</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>