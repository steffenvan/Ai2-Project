<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.972679666666667">
Squibs and Discussions
Efficient Parsing for Korean and English:
A Parameterized Message-Passing Approach
</title>
<author confidence="0.999137">
Bonnie J. Dorr* Dekang Lint
</author>
<affiliation confidence="0.999781">
University of Maryland University of Manitoba—Winnipeg
</affiliation>
<author confidence="0.99625">
Jye-hoon Leet Sungki Suh§
</author>
<affiliation confidence="0.998153">
University of Maryland Seoul National University
</affiliation>
<sectionHeader confidence="0.993057" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999847807692308">
This article presents an efficient, implemented approach to cross-linguistic parsing
based on Government Binding (GB) Theory (Chomsky 1986) and followers. One of the
drawbacks to alternative GB-based parsing approaches is that they generally adopt
a filter-based paradigm. These approaches typically generate all possible candidate
structures of the sentence that satisfy X theory, and then subsequently apply filters
in order to eliminate those structures that violate GB principles. (See, for example,
Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an
alternative to filter-based designs that avoids these difficulties by applying principles
to descriptions of structures without actually building the structures themselves. Our
approach is similar to that of Lin (1993) in that structure-building is deferred until
the descriptions satisfy all principles; however, the current approach differs in that
it provides a parameterization mechanism along the lines of Dorr (1994) that allows
the system to be ported to languages other than English. We focus particularly on the
problem of processing head-final languages such as Korean.
We are currently incorporating the parser into a machine translation (MT) system
called PRINCITRAN.1 In general, parsers of existing principle-based interlingual MT
systems are exceedingly inefficient, since they tend to adopt the filter-based paradigm.
We combine the benefits of the message-passing paradigm with the benefits of the
parameterized approach to build a more efficient, but easily extensible system, that
will ultimately be used for MT. The algorithm has been implemented in C++ and
successfully tested on well-known, translationally divergent sentences.
We present a general framework for parsing by message passing and describe our
implementation of GB principles as attribute-value constraints. We then present the
parameterization framework, demonstrating the feasibility of handling cross-linguistic
variation within the message-passing framework. A technique for automatic precom-
pilation of parameter settings is described. Finally, we compare the efficiency of the
</bodyText>
<affiliation confidence="0.903572">
* Department of Computer Science, University of Maryland, College Park, Maryland 20742. E-mail:
bonnie@cs.umd.edu
t Department of Computer Science, University of Manitoba, Winnipeg, Manitoba, Canada, R3T 2N2.
</affiliation>
<email confidence="0.778854">
E-mail: lindek@cs.umanitoba.ca
</email>
<affiliation confidence="0.986216">
Department of Computer Science, University of Maryland, College Park, MD 20742. E-mail:
</affiliation>
<email confidence="0.611843">
jlee@cs.umd.edu
</email>
<footnote confidence="0.75586025">
§ Language Research Institute, Seoul National University, Seoul, 151-742, Korea. E-mail:
sksuh@alliant.snu.ac.kr
1 The name PRINCITRAN is derived from the names of two systems, UNITRAN (Door 1993) and
PRINCIPAR (Lin 1993).
</footnote>
<note confidence="0.528378666666667">
© 1995 Association for Computational Linguistics
Computational Linguistics Volume 21, Number 2
head dominance adjunct dominance complement dominance
</note>
<figureCaption confidence="0.998648">
Figure 1 specialization specifier dominance barrier
</figureCaption>
<bodyText confidence="0.988659333333333">
Network representation of English and Korean grammar.
parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita
1986) on a test suite of representative sentences. We argue that the efficiency of the
system is not simply a side effect of using an efficient programming language (i.e.,
C++), but that the algorithm is inherently efficient, independent of the programming
language used for the implementation.
</bodyText>
<sectionHeader confidence="0.790971" genericHeader="keywords">
2. Message Passing Paradigm
</sectionHeader>
<bodyText confidence="0.999771">
There has been a great deal of interest in exploring new paradigms of parsing, es-
pecially nontraditional parallel architectures for natural language processing (Abney
1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Steven-
son 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches. Steven-
son&apos;s model comes the closest in design to the current principle-based message-passing
model in that it uses distributed message passing as the basic underlying mechanism
and it encodes GB principles directly (i.e., there are precise correspondences between
functional components and linguistic principles). However, the fundamental goals of
the two approaches are different: Stevenson&apos;s objective concerns the modeling of hu-
man processing behavior and producing a single parse at the end. Her system in-
corporates, a number of psycholinguistic-based processing mechanisms for handling
ambiguity and making attachment decisions. Our model, on the other hand, is more
concerned with efficiency issues, broad-scale coverage, and cross-linguistic applica-
bility; we produce all possible parse alternatives wherever disambiguation requires
extra-sentential information.
We provide a language-independent processing mechanism that accommodates
</bodyText>
<figure confidence="0.8171585">
Korean Grammar Network
English Grammar Network
</figure>
<page confidence="0.99442">
256
</page>
<note confidence="0.913304">
Dorr et al. Efficient Parsing for Korean and English
</note>
<bodyText confidence="0.999906068965517">
structurally different languages (e.g., head-initial vs. head-final) with equally efficient
run times. The grammar for each language is encoded as a network of nodes that
represent grammatical categories (e.g., NP, Nbar, N) or subcategories, such as V:NP
(i.e., a transitive verb that takes an NP as complement). Figure 1 depicts portions of
the grammar networks used for English and Korean.
There are two types of links in the network: subsumption links (e.g., V to V:NP)
and dominance links (e.g., Nbar to N). A dominance link from a to (3 is associated
with an integer id that determines the linear order between 0 and other categories
immediately dominated by a, and a binary attribute to specify whether 0 is optional
or obligatory.&apos;
Input sentences are parsed by passing messages in the grammar network. The
nodes in the network are computing agents that communicate with each other by
sending messages in the reverse direction of the links. Each node locally stores a set of
items. An item is a triplet that represents an g structure a: &lt;surface-string, attribute-
values, source-messages&gt;, where surface-string is an integer interval [i,j] denoting the
i&apos;th to j&apos; th word in the input sentence; attribute-values specifies syntactic features of
the root node (13); and source-messages is a set of messages that represent immediate
constituents of /3 and from which this item is combined. Each node has a completion
predicate that determines whether an item at the node is &amp;quot;complete,&amp;quot; in which case
the item is sent as a message to other nodes.
When a node receives an item, it attempts to form new items by combining it
with items from other nodes. Two items, &lt;[ii,ji ], A1, Sl &gt; and &lt;R2,j2l, A2, S2&gt;, can
be combined if: (1) their surface strings are adjacent to each other: i2 = ji +1; (2) their
attribute values A1 and A2 are unifiable; and (3) the source messages come via different
links: links(Si) n links(S2) = 0, where links(S) is a function that, given a set of messages,
returns the set of links via which the messages arrived. The result of the combination
is a new item, &lt;[i1 1, unify(Ai, A2), SI U S2&gt;. Once a sentence has been parsed, the
corresponding parse trees are retrieved from a parse forest one by one. Details are
given in Lin (1993).
</bodyText>
<listItem confidence="0.424086">
3. Implementation of Principles
</listItem>
<bodyText confidence="0.986831">
GB principles are implemented as local constraints attached to nodes and percolation
constraints attached to links. All items at a node must satisfy the node&apos;s local con-
straint. A message can be sent across a link only if it satisfies the link&apos;s percolation
constraint.3 We will discuss three examples to illustrate the general idea of how GB
principles are interpreted as local and percolation constraints. See Lin (1993) for more
details.
</bodyText>
<subsectionHeader confidence="0.986304">
3.1 X Theory
</subsectionHeader>
<bodyText confidence="0.958632818181818">
The central idea behind X theory is that a phrasal constituent has a layered structure.
Every phrasal constituent is considered to have a head (X° X), which determines the
2 For the purpose of readability, we have omitted integer id&apos;s in the graphical representation of the
grammar network. Linear ordering is indicated by the starting points of links. For example, C precedes
IP in the English network of Figure 1.
3 The idea of constraint application through feature passing among nodes is analogous to techniques
applied in the TINA spoken language system (Seneff 1992) except that, in our design, the grammar
network is a static data structure; it is not dynamically modified during the parsing process. Thus, we
achieve a reduction space requirements. Moreover, our design achieves a reduction in time
requirements because we do not retrieve a structure until the resulting parse descriptions satisfy all the
network constraints.
</bodyText>
<page confidence="0.954162">
257
</page>
<note confidence="0.434847">
Computational Linguistics Volume 21, Number 2
</note>
<bodyText confidence="0.99771">
properties of the phrase containing it. A phrase potentially contains a complement,
resulting in a one-bar level (X Xbar) projection; it may also contain a specifier (or
modifier), resulting in a double-bar level (X E-: XP) projection. The phrasal representa-
tion assumed in the current framework is the following:
</bodyText>
<listItem confidence="0.790888">
1. [xp Specifier [Xbar Complement XII
</listItem>
<bodyText confidence="0.999581">
We implement the relative positioning of Specifier, Complement, and Head constituents
by means of dominance links as shown in each of the networks of Figure 1. In addi-
tion, adjuncts are associated with the Xbar level by means of an adjunct-dominance
link in the grammar network. The structure in 1 represents the relative order observed
in Korean.
</bodyText>
<subsectionHeader confidence="0.999953">
3.2 Trace Theory
</subsectionHeader>
<bodyText confidence="0.999989583333333">
A trace represents a position from which some element has been extracted.&apos; The main
constraint of Trace Theory is the Subjacency Condition, which prohibits movement
across &amp;quot;too many&amp;quot; barriers. (The notion of &amp;quot;too many&amp;quot; is specified on a per-language
basis, as we will see shortly.)
An attribute named barrier is used to implement this principle. A message con-
taining the attribute value -barrier is used to represent an X structure containing a
position out of which a wh-constituent has moved, but without yet crossing a barrier.
The value +barrier means that the movement has already crossed one barrier. Certain
dominance links in the network are designated as barrier links (indicated in Figure 1
by solid rectangles). The Subjacency condition is implemented by the percolation con-
straints attached to the barrier links, which block any message with +barrier and
changes -barrier to +barrier (i.e., it allows the message to pass through).
</bodyText>
<subsectionHeader confidence="0.999982">
3.3 Case Theory
</subsectionHeader>
<bodyText confidence="0.9999837">
Case theory requires that every NP be assigned abstract case. The Case Filter rules out
sentences containing an NP with no case. Case is assigned structurally to a syntactic
position governed by a case assigner. Roughly, a preposition assigns Oblique Case to
a prepositional object NP; a transitive verb assigns Accusative Case to a direct object
NP; and tensed Infl(ection) assigns Nominative Case to a subject NP.
The implementation of case theory in our system is based on the following at-
tribute values: ca, govern, cm. The attribute values +c a and +govern are assigned by
local constraints to items representing phrases whose heads are case assigners (e.g.,
tensed I) and governors (e.g., V), respectively. A Case Filter violation is detected if an
item containing -cm is combined with another item containing -Ca +govern.
</bodyText>
<subsectionHeader confidence="0.845412">
4. Implementation of Parameters
</subsectionHeader>
<bodyText confidence="0.999861285714286">
While the principles described in the previous section are intended to be language-
independent, the structure of each grammar network in Figure 1 is too language-
specific to be applicable to languages other than the one for which it is designated.
The most obvious language-specific feature is the ordering of head links with respect
to complement links; in the graphical representation, link ordering of this type is
indicated by the starting points of links, e.g., C precedes IP under Cbar since the
link leading to C is to the left of the link leading to IP. In the English network, all
</bodyText>
<page confidence="0.8416385">
4 A trace is represented as ti, where i is a unique index referring to an antecedent.
258
</page>
<note confidence="0.955402">
Dorr et al. Efficient Parsing for Korean and English
</note>
<bodyText confidence="0.999986666666667">
phrasal heads precede their complements. In head-final languages such as Korean,
the reverse order is required. In order to capture this distinction, we incorporate the
parameterization approach of Dorr (1994) into the message-passing framework so that
grammar networks can be automatically generated on a per-language basis.
The reason the message-passing paradigm is so well-suited to a parameterized
model of language parsing is that, unlike head-driven models of parsing, the main
message-passing operation is capable of combining two nodes (in any order) in the
grammar network. The result is that a head-final language such as Korean is as ef-
ficiently parsed as a head-initial language such as English. What is most interesting
about this approach is that the parameterized model is consistent with experimental
results (see, for example, Suh [19931) that suggest that constituent structure is com-
puted prior to the appearance of the head in Korean.
We will first present our approach to parameterization of each subtheory of gram-
mar and then describe the automatic construction of grammar networks for English
and Korean using the parameter settings.
</bodyText>
<subsectionHeader confidence="0.99048">
4.1 -5-( Theory
</subsectionHeader>
<bodyText confidence="0.9960895">
X theory assumes that a constituent order parameter is used for specifying phrasal
ordering on a per-language basis:
</bodyText>
<listItem confidence="0.998111666666667">
2. Constituent Order: The relative order between the head and its
complement can vary, depending on whether the language in question is
(i) head-initial or (ii) head-final.
</listItem>
<bodyText confidence="0.99995425">
The structure above represents the relative order observed in Korean, i.e., the head-
final parameter setting (ii). In English, the setting of this parameter is (i). This ordering
information is encoded in the grammar network by virtue of the relative ordering of
integer id&apos;s associated with network links.
</bodyText>
<subsectionHeader confidence="0.999264">
4.2 Trace Theory
</subsectionHeader>
<bodyText confidence="0.999198">
In general, adjunct nodes are considered to be barriers to movement. However, Korean
allows the head noun of a relative clause to be construed with the empty category
across more than one intervening adjunct node (CP), as shown in the following:
</bodyText>
<listItem confidence="0.678864">
3. [cp [c t1 t2 kyengyengha-ten] hoysa2-ka manghayperi-n] Billi -un
yocum uykisochimhay issta
</listItem>
<bodyText confidence="0.9667526">
[cp [cp managed-Rel] company-Nom is bankrupt-Rel] Bill-Top
these days depressed is
&apos;Bill, who is such a person that the company he was managing has been
bankrupt, is depressed these days&apos;
The subject NP &apos;Bill&apos; is coindexed with the trace in the more deeply embedded
relative clause. If we assume, following Chomsky (1986), that relative clause formation
involves movement from an inner clause into an outer subject position, then the gram-
maticality of the above example suggests that the Trace theory must be parameterized
so that crossing more than one barrier is allowed in Korean. Our formulation of this
parametric distinction is as follows:
</bodyText>
<listItem confidence="0.9432215">
4. Barriers: (i) only one crossing permitted; (ii) more than one crossing
permitted.
</listItem>
<page confidence="0.9892">
259
</page>
<note confidence="0.638752">
Computational Linguistics Volume 21, Number 2
</note>
<bodyText confidence="0.857966">
In English the setting would be (i); in Korean the setting would be (ii).
</bodyText>
<subsectionHeader confidence="0.999857">
4.3 Case Theory
</subsectionHeader>
<bodyText confidence="0.998227">
In general, it is assumed that the relation between a case assigner and a case assignee is
biunique. However, this assumption rules out so-called multiple subject constructions,
which are commonly used in Korean:
</bodyText>
<listItem confidence="0.904818">
5. John-i phal-i pwureciessta
-Nom arm-Nom was broken
&apos;John is in the situation that his arm has been broken&apos;
</listItem>
<bodyText confidence="0.998245">
The grammaticality of the above example suggests that nominative case in Korean
must be assigned by something other than tensed Infl(ection). Thus, we parameterize
case assignment as follows:
</bodyText>
<listItem confidence="0.976195">
6. Case Assignment: Accusative case is assigned by transitive V;
Nominative case is assigned by (i) tensed Infl(ection); (ii) IP predication.
</listItem>
<bodyText confidence="0.9946615">
In a biunique case-assignment language such as English, the setting for Nomina-
tive case assignment would be (i); in Korean, the settings would be (i) and (ii).
</bodyText>
<subsectionHeader confidence="0.999962">
4.4 Construction of Grammar Network from Parameter Settings
</subsectionHeader>
<bodyText confidence="0.999937666666667">
We have just seen that certain types of syntactic parameterization may be captured in
the grammar network. In addition to these, there are syntactic parameters that must
be programmed into the message-passing mechanism itself, not just into the gram-
mar network. Our focus is on the automatic construction of the Korean and English
grammar networks from X parameter settings. The grammar network construction
algorithm consists of two steps: the first defines the basic structural description (i.e.,
bar-level nodes); and the second defines the satellites (i.e., adjunct and specifier nodes).
The English and Korean grammar networks in Figure 1 are the result of executing this
algorithm on the Korean X parameter settings.
</bodyText>
<sectionHeader confidence="0.956491" genericHeader="introduction">
5. Results of Time Test Comparisons
</sectionHeader>
<bodyText confidence="0.999102529411765">
As a broad-coverage system, PRINCITRAN is very efficient. The parsing component
(PRINCIPAR) processes real-world sentences 20-30 words long from sources such
as the Wall Street Journal within a couple of seconds. The complexity of the current
version of the system has not yet been formally determined. However, we claim that
the efficiency of the system is not purely a result of using an efficient programming
language (C++); this has been achieved by running experiments that compare the
performance of the parser with two alternative CFG parsers. Since PRINCIPAR has a
much broader coverage than these alternative approaches, the absolute measurements
do not provide a complete picture of how these three systems compare. However,
the most interesting point is that the trends of the three performance levels relative to
sentence length are essentially the same. If PRINCIPAR had an average case complexity
that was exponential relative to sentence length, but had only managed to be efficient
because of the implementation language, the sentence length vs. performance curve
would clearly be different from the curves for CFG parsers, which are known to have
a worst case complexity that is polynomial relative to sentence length.
The two CFG parsers used for comparison are: a C implementation of Tomita&apos;s
parser by Mark Hopkins (University of Wisconsin-Milwaukee, 1993) and the CFG
</bodyText>
<page confidence="0.982377">
260
</page>
<figure confidence="0.983901045454545">
Efficient Parsing for Korean and English
Dorr et al.
8.00
7.00
6.00
5.00
0 0
4.00 •
U
• •
3.00 I •
• 0 N a
1■11 wi
0 •
•
1.00 •ii 011 0
S B
0.00 IW I 1 A 1 ■ ii
1 I 1 1 1
0 5 10 15 20
Sentence length
Principar Tomita
</figure>
<figureCaption confidence="0.813191">
Figure 2
Adjusted timings of three parsers.
</figureCaption>
<bodyText confidence="0.99981775">
parser in Lin and Goebel (1993). The test sentences are from Tomita (1986). There are
40 of them. The sentence lengths vary from 1 to 34 words with an average of 15.18.
Both CFG parsers use the Grammar III in Tomita (1986, pp. 172-6), which contains 220
rules, and a small lexicon containing only the words that appear in the test sentences.
The lexicon in PRINCIPAR, on the other hand, contains about 90,000 entries extracted
from machine-readable dictionaries.
Tomita&apos;s parser runs about 10 times faster than PRINCIPAR; Lin and Goebel&apos;s
runs about twice as fast. To make the parsing time vs. sentence length distribution
of these three parsers more comparable, we normalized the curves; the parsing time
of each of the CFG parses was multiplied by a constant so that they would have the
same average time as PRINCIPAR. The adjusted timings are plotted in Figure 2. These
results show that PRINCIPAR compares quite well with both CFG parsers.
</bodyText>
<sectionHeader confidence="0.951677" genericHeader="method">
6. Implications for Machine Translation
</sectionHeader>
<bodyText confidence="0.999584833333333">
Our ultimate objective is to incorporate the parameterized parser into an interlingual
MT system. The current framework is well suited to an interlingual design, since the
linking rules between the syntactic representations given above and the underlying
lexical-semantic representation are well defined. We adopt Lexical Conceptual Struc-
ture (LCS) and use a parameter-setting approach to handle well-known, translationally
divergent sentences.
</bodyText>
<figure confidence="0.980399166666667">
n
2.00 • . 1 i• 0
N 0
g
25 30 35
• Lin-Goebel
</figure>
<page confidence="0.939568">
261
</page>
<table confidence="0.949299533333334">
Computational Linguistics Volume 21, Number 2
Consider the following English and Korean sentences:5
7. Structural Divergence:
E: John married Sally .15 seconds
K: John-i Sally-wa kyelhonhayssta .12 seconds
-Nom -with married
&apos;John married with Sally&apos;
8. Conflational Divergence:
E: John helped Bill .10 seconds
K: John-i Bill-eykey towum-ul cwuessta .19 seconds
-Nom -Dative help-Acc gave
&apos;John gave help to Bill&apos;
9. Categorial Divergence:
E: John is fond of music .12 seconds
K: John-un umak-ul coahanta .07 seconds
</table>
<bodyText confidence="0.8659293">
-Nom music-Acc like
&apos;It is John (who) likes music&apos;
In general, the times demonstrate a speedup of two to three orders of magnitude over
previous principle-based parsers on analogous examples such as those given in Dorr
(1993). Even more significant is the negligible difference in processing time between
the two languages, despite radical differences in structure, particularly with respect to
head-complement positioning. This is an improvement over previous parameterized
approaches in which cross-linguistic divergences frequently induced timing discrep-
ancies of one to two orders of magnitude due to the head-initial bias that underlies
most parsing designs.
</bodyText>
<sectionHeader confidence="0.912725" genericHeader="discussions">
7. Future Work and Conclusions
</sectionHeader>
<bodyText confidence="0.9995275">
Three areas of future work are relevant to the current framework: (1) scaling up the
Korean dictionary, which currently has only a handful of entries for testing purposes;6
</bodyText>
<listItem confidence="0.978886333333333">
(2) the installation of a Kimmo-based processor for handling Korean morphology; and
(3) the incorporation of nonstructural parameterization (i.e., parameters not pertaining
to X theory such as barriers and case assignment).
</listItem>
<bodyText confidence="0.973886461538462">
A preliminary investigation has indicated that the message-passing paradigm is
useful for generation as well as parsing, thus providing a suitable framework for
bidirectional translation. Our algorithm for generation is similar to that of parsing in
that both construct a syntactic parse tree over an unstructured or partially structured
set of lexical items. The difference is characterized as follows: in parsing, the inputs
are sequences of words and the output is a structure produced by combining two
adjacent trees into a single tree at each processing step; in generation, the inputs are
a set of unordered words with dependency relationships derived from the interlingua
5 The results shown above were obtained from running the program on a Sparcstation ELC. These are
not necessarily geared toward demonstrating the full capability of the parser, which handles many
types of syntactic phenomena, including complex movement types. (See Lin [1993] for more details.)
Rather, these examples are intended to illustrate that the parser is able to handle translationally
contrastive sentences equally efficiently.
</bodyText>
<footnote confidence="0.621168666666667">
6 Our English dictionary has 90,000 entries, constructed automatically by applying a set of conversion
routines to OALD entries. We have begun negotiations with the LDC for the acquisition of a Korean
MRD, for which we intend to construct similar routines.
</footnote>
<page confidence="0.981456">
262
</page>
<note confidence="0.966967">
Dorr et al. Efficient Parsing for Korean and English
</note>
<bodyText confidence="0.998678666666667">
(LCS). The generation algorithm must produce structures that satisfy the same set of
principles and constraints as the parsing algorithm.
In summary, we have shown that the parametric message-passing design is an ef-
ficient and portable approach to parsing. We have automated the process of grammar-
network construction and have demonstrated that the system handles well-known,
translationally divergent sentences.
</bodyText>
<sectionHeader confidence="0.99737" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.898294230769231">
Bonnie Dorr and her students, Jye-hoon Lee
and Sungki Sub, have been partially
supported by the Army Research Office
under contract DAAL03-91-C-0034 through
Battelle Corporation, by the National
Science Foundation under grant IRI-9120788
and NYI IRI-9357731, and by the Army
Research Institute under contract
MDA-903-92-R-0035 through
Microelectronics and Design, Inc.
Dekang Lin has been supported by Natural
Sciences and Engineering Research Council
of Canada grant 0GP121338.
</reference>
<sectionHeader confidence="0.679709" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999816612244898">
Abney, S. (1989). &amp;quot;A computational model
of human parsing.&amp;quot; Journal of
Psycholinguistic Research, 18(1), 129-144.
Chomsky, N. (1986). Knowledge of Language:
Its Nature, Origin and Use. MIT Press.
Correa, N. (1991). &amp;quot;Empty categories, chains,
and parsing.&amp;quot; In Principle-Based Parsing:
Computation and Psycholinguistics, edited
by R. Berwick, S. Abney, and C. Tenny,
83-121. Kluwer Academic Publishers.
Cottrell, G. (1989). A Connectionist Approach
to Word Sense Disambiguation. Morgan
Kaufmann.
Dorr, B. (1993). Machine Translation: A View
from the Lexicon. MIT Press.
Dorr, B. (1994). &amp;quot;Machine translation
divergences: A formal description and
proposed solution.&amp;quot; Computational
Linguistics, 20(4), 597-633.
Fong, S. (1991). &amp;quot;The computational
implementation of principle-based
parsers.&amp;quot; In Principle-Based Parsing:
Computation and Psycholinguistics, edited
by R. Berwick, S. Abney, and C. Tenny,
65-82. Kluwer Academic Publishers.
Lin, D. (1993). &amp;quot;Principle-based parsing
without overgeneration.&amp;quot; In Proceedings,
ACL-93. Columbus, Ohio, 112-120.
Lin, D., and Goebel, R. (1993). &amp;quot;Context-free
grammar parsing by message passing.&amp;quot; In
Proceedings, PACLING-93. Vancouver, BC.
Selman, B., and Hirst, G. (1985). &amp;quot;A
rule-based connectionist parsing system.&amp;quot;
In Proceedings, Seventh Annual Conference of
the Cognitive Science Society. 212-219.
Seneff, S. (1992). &amp;quot;Tina: A natural language
system for spoken language applications.&amp;quot;
Computational Linguistics, 18(1), 61-86.
Stevenson, S. (1994). A competitive attachment
model for resolving syntactic ambiguities in
natural language parsing. Doctoral
dissertation, University of Maryland,
College Park, MD.
Suh, S. (1993). &amp;quot;How to process constituent
structure in head final languages: The
case of Korean.&amp;quot; In Proceedings, Chicago
Linguistic Society, No. 29.
Tomita, M. (1986). Efficient Parsing for Natural
Language. Kluwer Academic Publishers.
</reference>
<page confidence="0.998909">
263
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.548781">
<title confidence="0.997981">Squibs and Discussions Efficient Parsing for Korean and English: A Parameterized Message-Passing Approach</title>
<author confidence="0.998815">Bonnie J Dorr Dekang Lint</author>
<affiliation confidence="0.849408">University of Maryland University of Manitoba—Winnipeg Jye-hoon Leet Sungki Suh§ University of Maryland Seoul National University</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Bonnie Dorr</author>
<author>her students</author>
<author>Jye-hoon Lee</author>
<author>Sungki Sub</author>
</authors>
<title>have been partially supported by the Army Research Office under contract DAAL03-91-C-0034 through Battelle Corporation, by the National Science Foundation under grant</title>
<booktitle>IRI-9120788 and NYI IRI-9357731, and by the Army Research Institute under contract MDA-903-92-R-0035 through Microelectronics and Design, Inc. Dekang Lin has been supported by Natural Sciences and Engineering Research Council of Canada grant 0GP121338.</booktitle>
<marker>Dorr, students, Lee, Sub, </marker>
<rawString>Bonnie Dorr and her students, Jye-hoon Lee and Sungki Sub, have been partially supported by the Army Research Office under contract DAAL03-91-C-0034 through Battelle Corporation, by the National Science Foundation under grant IRI-9120788 and NYI IRI-9357731, and by the Army Research Institute under contract MDA-903-92-R-0035 through Microelectronics and Design, Inc. Dekang Lin has been supported by Natural Sciences and Engineering Research Council of Canada grant 0GP121338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>A computational model of human parsing.&amp;quot;</title>
<date>1989</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>129--144</pages>
<contexts>
<context position="794" citStr="Abney 1989" startWordPosition="106" endWordPosition="107">ipeg Jye-hoon Leet Sungki Suh§ University of Maryland Seoul National University 1. Introduction This article presents an efficient, implemented approach to cross-linguistic parsing based on Government Binding (GB) Theory (Chomsky 1986) and followers. One of the drawbacks to alternative GB-based parsing approaches is that they generally adopt a filter-based paradigm. These approaches typically generate all possible candidate structures of the sentence that satisfy X theory, and then subsequently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem </context>
<context position="3831" citStr="Abney 1989" startWordPosition="529" endWordPosition="530">n of English and Korean grammar. parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming language used for the implementation. 2. Message Passing Paradigm There has been a great deal of interest in exploring new paradigms of parsing, especially nontraditional parallel architectures for natural language processing (Abney 1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Stevenson 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches. Stevenson&apos;s model comes the closest in design to the current principle-based message-passing model in that it uses distributed message passing as the basic underlying mechanism and it encodes GB principles directly (i.e., there are precise correspondences between functional components and linguistic principles). However, the fundamental goals of the two approaches are different: Stevenson&apos;s objective concerns the modeling of human processin</context>
</contexts>
<marker>Abney, 1989</marker>
<rawString>Abney, S. (1989). &amp;quot;A computational model of human parsing.&amp;quot; Journal of Psycholinguistic Research, 18(1), 129-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Knowledge of Language: Its Nature, Origin and Use.</title>
<date>1986</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="14484" citStr="Chomsky (1986)" startWordPosition="2230" endWordPosition="2231">barriers to movement. However, Korean allows the head noun of a relative clause to be construed with the empty category across more than one intervening adjunct node (CP), as shown in the following: 3. [cp [c t1 t2 kyengyengha-ten] hoysa2-ka manghayperi-n] Billi -un yocum uykisochimhay issta [cp [cp managed-Rel] company-Nom is bankrupt-Rel] Bill-Top these days depressed is &apos;Bill, who is such a person that the company he was managing has been bankrupt, is depressed these days&apos; The subject NP &apos;Bill&apos; is coindexed with the trace in the more deeply embedded relative clause. If we assume, following Chomsky (1986), that relative clause formation involves movement from an inner clause into an outer subject position, then the grammaticality of the above example suggests that the Trace theory must be parameterized so that crossing more than one barrier is allowed in Korean. Our formulation of this parametric distinction is as follows: 4. Barriers: (i) only one crossing permitted; (ii) more than one crossing permitted. 259 Computational Linguistics Volume 21, Number 2 In English the setting would be (i); in Korean the setting would be (ii). 4.3 Case Theory In general, it is assumed that the relation betwee</context>
</contexts>
<marker>Chomsky, 1986</marker>
<rawString>Chomsky, N. (1986). Knowledge of Language: Its Nature, Origin and Use. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Correa</author>
</authors>
<title>Empty categories, chains, and parsing.&amp;quot; In Principle-Based Parsing: Computation and Psycholinguistics, edited by</title>
<date>1991</date>
<pages>83--121</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="807" citStr="Correa 1991" startWordPosition="108" endWordPosition="109">n Leet Sungki Suh§ University of Maryland Seoul National University 1. Introduction This article presents an efficient, implemented approach to cross-linguistic parsing based on Government Binding (GB) Theory (Chomsky 1986) and followers. One of the drawbacks to alternative GB-based parsing approaches is that they generally adopt a filter-based paradigm. These approaches typically generate all possible candidate structures of the sentence that satisfy X theory, and then subsequently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing</context>
</contexts>
<marker>Correa, 1991</marker>
<rawString>Correa, N. (1991). &amp;quot;Empty categories, chains, and parsing.&amp;quot; In Principle-Based Parsing: Computation and Psycholinguistics, edited by R. Berwick, S. Abney, and C. Tenny, 83-121. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Cottrell</author>
</authors>
<title>A Connectionist Approach to Word Sense Disambiguation.</title>
<date>1989</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3846" citStr="Cottrell 1989" startWordPosition="531" endWordPosition="532"> and Korean grammar. parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming language used for the implementation. 2. Message Passing Paradigm There has been a great deal of interest in exploring new paradigms of parsing, especially nontraditional parallel architectures for natural language processing (Abney 1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Stevenson 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches. Stevenson&apos;s model comes the closest in design to the current principle-based message-passing model in that it uses distributed message passing as the basic underlying mechanism and it encodes GB principles directly (i.e., there are precise correspondences between functional components and linguistic principles). However, the fundamental goals of the two approaches are different: Stevenson&apos;s objective concerns the modeling of human processing behavior and </context>
</contexts>
<marker>Cottrell, 1989</marker>
<rawString>Cottrell, G. (1989). A Connectionist Approach to Word Sense Disambiguation. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
</authors>
<title>Machine Translation: A View from the Lexicon.</title>
<date>1993</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="818" citStr="Dorr 1993" startWordPosition="110" endWordPosition="111"> Suh§ University of Maryland Seoul National University 1. Introduction This article presents an efficient, implemented approach to cross-linguistic parsing based on Government Binding (GB) Theory (Chomsky 1986) and followers. One of the drawbacks to alternative GB-based parsing approaches is that they generally adopt a filter-based paradigm. These approaches typically generate all possible candidate structures of the sentence that satisfy X theory, and then subsequently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final</context>
<context position="20545" citStr="Dorr (1993)" startWordPosition="3209" endWordPosition="3210">hn married Sally .15 seconds K: John-i Sally-wa kyelhonhayssta .12 seconds -Nom -with married &apos;John married with Sally&apos; 8. Conflational Divergence: E: John helped Bill .10 seconds K: John-i Bill-eykey towum-ul cwuessta .19 seconds -Nom -Dative help-Acc gave &apos;John gave help to Bill&apos; 9. Categorial Divergence: E: John is fond of music .12 seconds K: John-un umak-ul coahanta .07 seconds -Nom music-Acc like &apos;It is John (who) likes music&apos; In general, the times demonstrate a speedup of two to three orders of magnitude over previous principle-based parsers on analogous examples such as those given in Dorr (1993). Even more significant is the negligible difference in processing time between the two languages, despite radical differences in structure, particularly with respect to head-complement positioning. This is an improvement over previous parameterized approaches in which cross-linguistic divergences frequently induced timing discrepancies of one to two orders of magnitude due to the head-initial bias that underlies most parsing designs. 7. Future Work and Conclusions Three areas of future work are relevant to the current framework: (1) scaling up the Korean dictionary, which currently has only a</context>
</contexts>
<marker>Dorr, 1993</marker>
<rawString>Dorr, B. (1993). Machine Translation: A View from the Lexicon. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
</authors>
<title>Machine translation divergences: A formal description and proposed solution.&amp;quot;</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>597--633</pages>
<contexts>
<context position="1287" citStr="Dorr (1994)" startWordPosition="176" endWordPosition="177">quently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final languages such as Korean. We are currently incorporating the parser into a machine translation (MT) system called PRINCITRAN.1 In general, parsers of existing principle-based interlingual MT systems are exceedingly inefficient, since they tend to adopt the filter-based paradigm. We combine the benefits of the message-passing paradigm with the benefits of the parameterized approach to build a more efficient, but easily extensible system, that will ultimately be use</context>
<context position="12245" citStr="Dorr (1994)" startWordPosition="1878" endWordPosition="1879">ct to complement links; in the graphical representation, link ordering of this type is indicated by the starting points of links, e.g., C precedes IP under Cbar since the link leading to C is to the left of the link leading to IP. In the English network, all 4 A trace is represented as ti, where i is a unique index referring to an antecedent. 258 Dorr et al. Efficient Parsing for Korean and English phrasal heads precede their complements. In head-final languages such as Korean, the reverse order is required. In order to capture this distinction, we incorporate the parameterization approach of Dorr (1994) into the message-passing framework so that grammar networks can be automatically generated on a per-language basis. The reason the message-passing paradigm is so well-suited to a parameterized model of language parsing is that, unlike head-driven models of parsing, the main message-passing operation is capable of combining two nodes (in any order) in the grammar network. The result is that a head-final language such as Korean is as efficiently parsed as a head-initial language such as English. What is most interesting about this approach is that the parameterized model is consistent with expe</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Dorr, B. (1994). &amp;quot;Machine translation divergences: A formal description and proposed solution.&amp;quot; Computational Linguistics, 20(4), 597-633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fong</author>
</authors>
<title>The computational implementation of principle-based parsers.&amp;quot;</title>
<date>1991</date>
<booktitle>In Principle-Based Parsing: Computation and Psycholinguistics, edited</booktitle>
<pages>65--82</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="829" citStr="Fong 1991" startWordPosition="112" endWordPosition="113">rsity of Maryland Seoul National University 1. Introduction This article presents an efficient, implemented approach to cross-linguistic parsing based on Government Binding (GB) Theory (Chomsky 1986) and followers. One of the drawbacks to alternative GB-based parsing approaches is that they generally adopt a filter-based paradigm. These approaches typically generate all possible candidate structures of the sentence that satisfy X theory, and then subsequently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final languages </context>
</contexts>
<marker>Fong, 1991</marker>
<rawString>Fong, S. (1991). &amp;quot;The computational implementation of principle-based parsers.&amp;quot; In Principle-Based Parsing: Computation and Psycholinguistics, edited by R. Berwick, S. Abney, and C. Tenny, 65-82. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Principle-based parsing without overgeneration.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, ACL-93.</booktitle>
<pages>112--120</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1083" citStr="Lin (1993)" startWordPosition="147" endWordPosition="148">-based parsing approaches is that they generally adopt a filter-based paradigm. These approaches typically generate all possible candidate structures of the sentence that satisfy X theory, and then subsequently apply filters in order to eliminate those structures that violate GB principles. (See, for example, Abney 1989; Correa 1991; Dorr 1993; Fong 1991.) The current approach provides an alternative to filter-based designs that avoids these difficulties by applying principles to descriptions of structures without actually building the structures themselves. Our approach is similar to that of Lin (1993) in that structure-building is deferred until the descriptions satisfy all principles; however, the current approach differs in that it provides a parameterization mechanism along the lines of Dorr (1994) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final languages such as Korean. We are currently incorporating the parser into a machine translation (MT) system called PRINCITRAN.1 In general, parsers of existing principle-based interlingual MT systems are exceedingly inefficient, since they tend to adopt the filter-</context>
<context position="2997" citStr="Lin 1993" startWordPosition="409" endWordPosition="410">. Finally, we compare the efficiency of the * Department of Computer Science, University of Maryland, College Park, Maryland 20742. E-mail: bonnie@cs.umd.edu t Department of Computer Science, University of Manitoba, Winnipeg, Manitoba, Canada, R3T 2N2. E-mail: lindek@cs.umanitoba.ca Department of Computer Science, University of Maryland, College Park, MD 20742. E-mail: jlee@cs.umd.edu § Language Research Institute, Seoul National University, Seoul, 151-742, Korea. E-mail: sksuh@alliant.snu.ac.kr 1 The name PRINCITRAN is derived from the names of two systems, UNITRAN (Door 1993) and PRINCIPAR (Lin 1993). © 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 2 head dominance adjunct dominance complement dominance Figure 1 specialization specifier dominance barrier Network representation of English and Korean grammar. parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming lan</context>
<context position="7295" citStr="Lin (1993)" startWordPosition="1080" endWordPosition="1081">s. Two items, &lt;[ii,ji ], A1, Sl &gt; and &lt;R2,j2l, A2, S2&gt;, can be combined if: (1) their surface strings are adjacent to each other: i2 = ji +1; (2) their attribute values A1 and A2 are unifiable; and (3) the source messages come via different links: links(Si) n links(S2) = 0, where links(S) is a function that, given a set of messages, returns the set of links via which the messages arrived. The result of the combination is a new item, &lt;[i1 1, unify(Ai, A2), SI U S2&gt;. Once a sentence has been parsed, the corresponding parse trees are retrieved from a parse forest one by one. Details are given in Lin (1993). 3. Implementation of Principles GB principles are implemented as local constraints attached to nodes and percolation constraints attached to links. All items at a node must satisfy the node&apos;s local constraint. A message can be sent across a link only if it satisfies the link&apos;s percolation constraint.3 We will discuss three examples to illustrate the general idea of how GB principles are interpreted as local and percolation constraints. See Lin (1993) for more details. 3.1 X Theory The central idea behind X theory is that a phrasal constituent has a layered structure. Every phrasal constituen</context>
</contexts>
<marker>Lin, 1993</marker>
<rawString>Lin, D. (1993). &amp;quot;Principle-based parsing without overgeneration.&amp;quot; In Proceedings, ACL-93. Columbus, Ohio, 112-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>R Goebel</author>
</authors>
<title>Context-free grammar parsing by message passing.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, PACLING-93.</booktitle>
<location>Vancouver, BC.</location>
<contexts>
<context position="18355" citStr="Lin and Goebel (1993)" startWordPosition="2859" endWordPosition="2862">rformance curve would clearly be different from the curves for CFG parsers, which are known to have a worst case complexity that is polynomial relative to sentence length. The two CFG parsers used for comparison are: a C implementation of Tomita&apos;s parser by Mark Hopkins (University of Wisconsin-Milwaukee, 1993) and the CFG 260 Efficient Parsing for Korean and English Dorr et al. 8.00 7.00 6.00 5.00 0 0 4.00 • U • • 3.00 I • • 0 N a 1■11 wi 0 • • 1.00 •ii 011 0 S B 0.00 IW I 1 A 1 ■ ii 1 I 1 1 1 0 5 10 15 20 Sentence length Principar Tomita Figure 2 Adjusted timings of three parsers. parser in Lin and Goebel (1993). The test sentences are from Tomita (1986). There are 40 of them. The sentence lengths vary from 1 to 34 words with an average of 15.18. Both CFG parsers use the Grammar III in Tomita (1986, pp. 172-6), which contains 220 rules, and a small lexicon containing only the words that appear in the test sentences. The lexicon in PRINCIPAR, on the other hand, contains about 90,000 entries extracted from machine-readable dictionaries. Tomita&apos;s parser runs about 10 times faster than PRINCIPAR; Lin and Goebel&apos;s runs about twice as fast. To make the parsing time vs. sentence length distribution of these</context>
</contexts>
<marker>Lin, Goebel, 1993</marker>
<rawString>Lin, D., and Goebel, R. (1993). &amp;quot;Context-free grammar parsing by message passing.&amp;quot; In Proceedings, PACLING-93. Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Selman</author>
<author>G Hirst</author>
</authors>
<title>A rule-based connectionist parsing system.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, Seventh Annual Conference of the Cognitive Science Society.</booktitle>
<pages>212--219</pages>
<contexts>
<context position="3869" citStr="Selman and Hirst 1985" startWordPosition="533" endWordPosition="536">mmar. parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming language used for the implementation. 2. Message Passing Paradigm There has been a great deal of interest in exploring new paradigms of parsing, especially nontraditional parallel architectures for natural language processing (Abney 1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Stevenson 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches. Stevenson&apos;s model comes the closest in design to the current principle-based message-passing model in that it uses distributed message passing as the basic underlying mechanism and it encodes GB principles directly (i.e., there are precise correspondences between functional components and linguistic principles). However, the fundamental goals of the two approaches are different: Stevenson&apos;s objective concerns the modeling of human processing behavior and producing a single pars</context>
</contexts>
<marker>Selman, Hirst, 1985</marker>
<rawString>Selman, B., and Hirst, G. (1985). &amp;quot;A rule-based connectionist parsing system.&amp;quot; In Proceedings, Seventh Annual Conference of the Cognitive Science Society. 212-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
</authors>
<title>Tina: A natural language system for spoken language applications.&amp;quot;</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>61--86</pages>
<contexts>
<context position="8355" citStr="Seneff 1992" startWordPosition="1252" endWordPosition="1253">n (1993) for more details. 3.1 X Theory The central idea behind X theory is that a phrasal constituent has a layered structure. Every phrasal constituent is considered to have a head (X° X), which determines the 2 For the purpose of readability, we have omitted integer id&apos;s in the graphical representation of the grammar network. Linear ordering is indicated by the starting points of links. For example, C precedes IP in the English network of Figure 1. 3 The idea of constraint application through feature passing among nodes is analogous to techniques applied in the TINA spoken language system (Seneff 1992) except that, in our design, the grammar network is a static data structure; it is not dynamically modified during the parsing process. Thus, we achieve a reduction space requirements. Moreover, our design achieves a reduction in time requirements because we do not retrieve a structure until the resulting parse descriptions satisfy all the network constraints. 257 Computational Linguistics Volume 21, Number 2 properties of the phrase containing it. A phrase potentially contains a complement, resulting in a one-bar level (X Xbar) projection; it may also contain a specifier (or modifier), result</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Seneff, S. (1992). &amp;quot;Tina: A natural language system for spoken language applications.&amp;quot; Computational Linguistics, 18(1), 61-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stevenson</author>
</authors>
<title>A competitive attachment model for resolving syntactic ambiguities in natural language parsing. Doctoral dissertation,</title>
<date>1994</date>
<institution>University of Maryland, College Park, MD.</institution>
<contexts>
<context position="3919" citStr="Stevenson 1994" startWordPosition="542" endWordPosition="544">ll as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming language used for the implementation. 2. Message Passing Paradigm There has been a great deal of interest in exploring new paradigms of parsing, especially nontraditional parallel architectures for natural language processing (Abney 1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Stevenson 1994) provides a survey of symbolic, nonsymbolic, and hybrid approaches. Stevenson&apos;s model comes the closest in design to the current principle-based message-passing model in that it uses distributed message passing as the basic underlying mechanism and it encodes GB principles directly (i.e., there are precise correspondences between functional components and linguistic principles). However, the fundamental goals of the two approaches are different: Stevenson&apos;s objective concerns the modeling of human processing behavior and producing a single parse at the end. Her system incorporates, a number of</context>
</contexts>
<marker>Stevenson, 1994</marker>
<rawString>Stevenson, S. (1994). A competitive attachment model for resolving syntactic ambiguities in natural language parsing. Doctoral dissertation, University of Maryland, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Suh</author>
</authors>
<title>How to process constituent structure in head final languages: The case of Korean.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, Chicago Linguistic Society,</booktitle>
<volume>29</volume>
<marker>Suh, 1993</marker>
<rawString>Suh, S. (1993). &amp;quot;How to process constituent structure in head final languages: The case of Korean.&amp;quot; In Proceedings, Chicago Linguistic Society, No. 29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="3342" citStr="Tomita 1986" startWordPosition="455" endWordPosition="456">llege Park, MD 20742. E-mail: jlee@cs.umd.edu § Language Research Institute, Seoul National University, Seoul, 151-742, Korea. E-mail: sksuh@alliant.snu.ac.kr 1 The name PRINCITRAN is derived from the names of two systems, UNITRAN (Door 1993) and PRINCIPAR (Lin 1993). © 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 2 head dominance adjunct dominance complement dominance Figure 1 specialization specifier dominance barrier Network representation of English and Korean grammar. parser to that of the original CFG algorithm as well as Tomita&apos;s algorithm (Tomita 1986) on a test suite of representative sentences. We argue that the efficiency of the system is not simply a side effect of using an efficient programming language (i.e., C++), but that the algorithm is inherently efficient, independent of the programming language used for the implementation. 2. Message Passing Paradigm There has been a great deal of interest in exploring new paradigms of parsing, especially nontraditional parallel architectures for natural language processing (Abney 1989; Cottrell 1989; Selman and Hirst 1985, among many others). Recent work (Stevenson 1994) provides a survey of s</context>
<context position="18398" citStr="Tomita (1986)" startWordPosition="2868" endWordPosition="2869"> curves for CFG parsers, which are known to have a worst case complexity that is polynomial relative to sentence length. The two CFG parsers used for comparison are: a C implementation of Tomita&apos;s parser by Mark Hopkins (University of Wisconsin-Milwaukee, 1993) and the CFG 260 Efficient Parsing for Korean and English Dorr et al. 8.00 7.00 6.00 5.00 0 0 4.00 • U • • 3.00 I • • 0 N a 1■11 wi 0 • • 1.00 •ii 011 0 S B 0.00 IW I 1 A 1 ■ ii 1 I 1 1 1 0 5 10 15 20 Sentence length Principar Tomita Figure 2 Adjusted timings of three parsers. parser in Lin and Goebel (1993). The test sentences are from Tomita (1986). There are 40 of them. The sentence lengths vary from 1 to 34 words with an average of 15.18. Both CFG parsers use the Grammar III in Tomita (1986, pp. 172-6), which contains 220 rules, and a small lexicon containing only the words that appear in the test sentences. The lexicon in PRINCIPAR, on the other hand, contains about 90,000 entries extracted from machine-readable dictionaries. Tomita&apos;s parser runs about 10 times faster than PRINCIPAR; Lin and Goebel&apos;s runs about twice as fast. To make the parsing time vs. sentence length distribution of these three parsers more comparable, we normaliz</context>
</contexts>
<marker>Tomita, 1986</marker>
<rawString>Tomita, M. (1986). Efficient Parsing for Natural Language. Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>