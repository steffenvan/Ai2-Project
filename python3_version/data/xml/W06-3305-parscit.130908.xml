<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.964829">
A Priority Model for Named Entities
</title>
<author confidence="0.473413">
Lorraine Tanabe W. John Wilbur
</author>
<bodyText confidence="0.9377495">
National Center for Biotechnology
Information
National Center for Biotechnology
Information
Bethesda, MD 20894 Bethesda, MD 20894
tanabe@ncbi.nlm.nih.gov wilbur@ncbi.nlm.nih.gov
</bodyText>
<sectionHeader confidence="0.924644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999509">
We introduce a new approach to named
entity classification which we term a Pri-
ority Model. We also describe the con-
struction of a semantic database called
SemCat consisting of a large number of
semantically categorized names relevant
to biomedicine. We used SemCat as train-
ing data to investigate name classification
techniques. We generated a statistical lan-
guage model and probabilistic context-
free grammars for gene and protein name
classification, and compared the results
with the new model. For all three meth-
ods, we used a variable order Markov
model to predict the nature of strings not
represented in the training data. The Pri-
ority Model achieves an F-measure of
0.958-0.960, consistently higher than the
statistical language model and probabilis-
tic context-free grammar.
</bodyText>
<sectionHeader confidence="0.992205" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9990146">
Automatic recognition of gene and protein names
is a challenging first step towards text mining the
biomedical literature. Advances in the area of gene
and protein named entity recognition (NER) have
been accelerated by freely available tagged corpora
(Kim et al., 2003, Cohen et al., 2005, Smith et al.,
2005, Tanabe et al., 2005). Such corpora have
made it possible for standardized evaluations such
as Task 1A of the first BioCreative Workshop
(Yeh et al., 2005).
Although state-of-the-art systems now perform
at the level of 80-83% F-measure, this is still well
below the range of 90-97% for non-biomedical
NER. The main reasons for this performance dis-
parity are 1) the complexity of the genetic nomen-
clature and 2) the confusion of gene and protein
names with other biomedical entities, as well as
with common English words. In an effort to allevi-
ate the confusion with other biomedical entities we
have assembled a database consisting of named
entities appearing in the literature of biomedicine
together with information on their ontological
categories. We use this information in an effort to
better understand how to classify names as repre-
senting genes/proteins or not.
</bodyText>
<sectionHeader confidence="0.972733" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999974833333333">
A successful gene and protein NER system must
address the complexity and ambiguity inherent in
this domain. Hand-crafted rules alone are unable
to capture these phenomena in large biomedical
text collections. Most biomedical NER systems
use some form of language modeling, consisting of
an observed sequence of words and a hidden se-
quence of tags. The goal is to find the tag se-
quence with maximal probability given the
observed word sequence. McDonald and Pereira
(2005) use conditional random fields (CRF) to
identify the beginning, inside and outside of gene
and protein names. GuoDong et al. (2005) use an
ensemble of one support vector machine and two
Hidden Markov Models (HMMs). Kinoshita et al.
(2005) use a second-order Markov model. Dingare
et al. (2005) use a maximum entropy Markov
model (MEMM) with large feature sets.
</bodyText>
<page confidence="0.542044">
33
</page>
<note confidence="0.9936205">
Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 33–40,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999896543478261">
NER is a difficult task because it requires both
the identification of the boundaries of an entity in
text, and the classification of that entity. In this
paper, we focus on the classification step. Spasic
et al. (2005) use the MaSTerClass case-based rea-
soning system for biomedical term classification.
MaSTerClass uses term contexts from an annotated
corpus of 2072 MEDLINE abstracts related to nu-
clear receptors as a basis for classifying new
terms. Its set of classes is a subset of the UMLS
Semantic Network (McCray, 1989), that does not
include genes and proteins. Liu et al. (2002) clas-
sified terms that represent multiple UMLS con-
cepts by examining the conceptual relatives of the
concepts. Hatzivassiloglou et al. (2001) classified
terms known to belong to the classes Protein, Gene
and/or RNA using unsupervised learning, achieving
accuracy rates up to 85%. The AZuRE system
(Podowski et al., 2004) uses a separate modified
Naive Bayes model for each of 20K genes. A term
is disambiguated based on its contextual similarity
to each model. Nenadic et al. (2003) recognized
the importance of terminological knowledge for
biomedical text mining. They used the C/NC-
methods, calculating both the intrinsic characteris-
tics of terms (such as their frequency of occurrence
as substrings of other terms), and the context of
terms as linear combinations. These biomedical
classification systems all rely on the context sur-
rounding named entities. While we recognize the
importance of context, we believe one must strive
for the appropriate blend of information coming
from the context and information that is inherent in
the name itself. This explains our focus on names
without context in this work.
We believe one can improve gene and protein
entity classification by using more training data
and/or using a more appropriate model for names.
Current sources of training data are deficient in
important biomedical terminologies like cell line
names. To address this deficiency, we constructed
the SemCat database, based on a subset of the
UMLS Semantic Network enriched with categories
from the GENIA Ontology (Kim et al, 2003), and a
few new semantic types. We have populated Sem-
Cat with over 5 million entities of interest from
</bodyText>
<figureCaption confidence="0.7583785">
Figure 1. SemCat Physical Object Hierarchy. White = UMLS SN, Light Grey = GENIA semantic
types, Dark Grey = New semantic types.
</figureCaption>
<page confidence="0.857973">
34
</page>
<bodyText confidence="0.999877857142857">
standard knowledge sources like the UMLS
(Lindberg et al., 1993), the Gene Ontology (GO)
(The Gene Ontology Consortium, 2000), Entrez
Gene (Maglott et al., 2005), and GENIA, as well as
from the World Wide Web. In this paper, we use
SemCat data to compare three probabilistic frame-
works for named entity classification.
</bodyText>
<sectionHeader confidence="0.996289" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.9999753">
We constructed the SemCat database of biomedical
entities, and used these entities to train and test
three probabilistic approaches to gene and protein
name classification: 1) a statistical language model
with Witten-Bell smoothing, 2) probabilistic con-
text-free grammars (PCFGs) and 3) a new ap-
proach we call a Priority Model for named entities.
As one component in all of our classification algo-
rithms we use a variable order Markov Model for
strings.
</bodyText>
<subsectionHeader confidence="0.999612">
3.1 SemCat Database Construction
</subsectionHeader>
<bodyText confidence="0.999932016666667">
The UMLS Semantic Network (SN) is an ongoing
project at the National Library of Medicine. Many
users have modified the SN for their own research
domains. For example, Yu et al. (1999) found that
the SN was missing critical components in the ge-
nomics domain, and added six new semantic types
including Protein Structure and Chemical Com-
plex. We found that a subset of the SN would be
sufficient for gene and protein name classification,
and added some new semantic types for better cov-
erage. We shifted some semantic types from
suboptimal nodes to ones that made more sense
from a genomics standpoint. For example, there
were two problems with Gene or Genome. Firstly,
genes and genomes are not synonymous, and sec-
ondly, placement under the semantic type Fully
Formed Anatomical Structure is suboptimal from a
genomics perspective. Since a gene in this context
is better understood as an organic chemical, we
deleted Gene or Genome, and added the GENIA
semantic types for genomics entities under Or-
ganic Chemical. The SemCat Physical Object hier-
archy is shown in Figure 1. Similar hierarchies
exist for the SN Conceptual Entity and Event trees.
A number of the categories have been supple-
mented with automatically extracted entities from
MEDLINE, derived from regular expression pat-
tern matching. Currently, SemCat has 77 semantic
types, and 5.11M non-unique entries. Additional
entities from MEDLINE are being manually classi-
fied via an annotation website. Unlike the Ter-
mino database (Harkema et al. (2004), which
contains terminology annotated with morpho-
syntactic and conceptual information, SemCat cur-
rently consists of gazetteer lists only.
For our experiments, we generated two sets of
training data from SemCat, Gene-Protein (GP) and
Not-Gene-Protein (NGP). GP consists of specific
terms from the semantic types DNA MOLECULE,
PROTEIN MOLECULE, DNA FAMILY,
PROTEIN FAMILY, PROTEIN COMPLEX and
PROTEIN SUBUNIT. NGP consists of entities
from all other SemCat types, along with generic
entities from the GP semantic types. Generic enti-
ties were automatically eliminated from GP using
pattern matching to manually tagged generic
phrases like abnormal protein, acid domain, and
RNA.
Many SemCat entries contain commas and pa-
rentheses, for example, “receptors, tgf beta.” A
better form for natural language processing would
be “tgf beta receptors.” To address this problem,
we automatically generated variants of phrases in
GP with commas and parentheses, and found their
counts in MEDLINE. We empirically determined
the heuristic rule of replacing the phrase with its
second most frequent variant, based on the obser-
vation that the most frequent variant is often too
generic. For example, the following are the phrase
variant counts for “heat shock protein (dnaj)”:
</bodyText>
<listItem confidence="0.99897625">
• heat shock protein (dnaj) 0
• dnaj heat shock protein 84
• heat shock protein 122954
• heat shock protein dnaj 41
</listItem>
<bodyText confidence="0.999796875">
Thus, the phrase kept for GP is dnaj heat shock
protein.
After purifying the sets and removing ambigu-
ous full phrases (ambiguous words were retained),
GP contained 1,001,188 phrases, and NGP con-
tained 2,964,271 phrases. From these, we ran-
domly generated three train/test divisions of 90%
train/10% test (gp1, gp2, gp3), for the evaluation.
</bodyText>
<subsectionHeader confidence="0.999883">
3.2 Variable Order Markov Model for Strings
</subsectionHeader>
<bodyText confidence="0.9566578">
As one component in our classification algorithms
we use a variable order Markov Model for strings.
Suppose C represents a class and x1x2x3... xn repre-
35
sents a string of characters. In order to estimate the
probability that x1x2x3... xn belongs to we apply
CBayes’ Theorem to write
beginnings of strings to come from estimates based
on the beginnings of strings. We use this approach
in all of our classification algorithms.
</bodyText>
<equation confidence="0.997851666666667">
p(C p(x1x2x3 ... xn  |C)p(C)  |... (1)
=
1 2 3 np (x1x2x3...xn )
</equation>
<bodyText confidence="0.997015166666667">
Because p(x1x2x3...xn) does not depend on the
class and because we are generally comparing
probability estimates between classes, we ignore
this factor in our calculations and concentrate our
efforts on evaluating p (x1x2x3... xn  |C) p (C) .
First we write
</bodyText>
<equation confidence="0.881968">
n (2)
p (x1x2x3...xn  |C) =∏ k=1 p (xk  |x1x2x3...xk−1 , C)
</equation>
<bodyText confidence="0.9978834">
which is an exact equality. The final step is to give
our best approximation to each of the num-
bers p (xk  |x1x2x3 ... x k−1, C) . To make these ap-
proximations we assume that we are given a set of
strings and associated probabilities { ( )} 1
</bodyText>
<equation confidence="0.996325666666667">
s p =
, M
i i i
</equation>
<bodyText confidence="0.8488998">
where for each i , pi &gt; 0 and pi is assumed to
represent the probability that belongs to the
si
class C . Then for the given string x1x2x3... xn and
a given we let be the smallest integer for
</bodyText>
<equation confidence="0.924546">
k r ≥ 1
</equation>
<bodyText confidence="0.980345625">
which xrxr+1xr+2... xk is a contiguous substring in
at least one of the strings si . Now let N′ be the
set of all i for which xrxr+1xr+2...xk is a substring
of si and let N be the set of all i for which
xrxr+1 xr+2...xk −1 is a substring of si . We set
In some cases it is appropriate to assume that
p(C) is proportional to 1
∑= or there may be
</bodyText>
<equation confidence="0.957684">
M i pi
</equation>
<bodyText confidence="0.901236538461539">
other ways to make this estimate. This basic
scheme works well, but we have found that we can
obtain a modest improvement by adding a unique
start character to the beginning of each string. This
character is assumed to occur nowhere else but as
the first character in all strings dealt with including
any string whose probability we are estimating.
This forces the estimates of probabilities near the
Table 1. Each fragment in the left column appears in the
training data and the probability in the right column
represents the probability of seeing the underlined por-
tion of the string given the occurrence of the initial un-
underlined portion of the string in a training string.
</bodyText>
<table confidence="0.999398538461538">
GP
!apoe 9.55× 10−7
oe-e 2.09× 10−3
e-epsilon 4.00× 10−2
p ( apoe − epsilon  |GP) 7.98 × 10− 11
p (GP  |apoe − epsilon) 0.98448
NGP
!apoe 8.88 × 10−8
poe- 1.21 × 10−2
oe-e 6.10× 10−2
e-epsilon 6.49 × 10−3
p ( apoe −epsilon  |NGP) 4.25 × 10− 13
p ( NGP  |apoe − epsilon) 0.01552
</table>
<bodyText confidence="0.965648">
In Table 1, we give an illustrative example of
the string apoe-epsilon which does not appear in
the training data. A PubMed search for apoe-
epsilon gene returns 269 hits showing the name is
known. But it does not appear in this exact form in
SemCat.
3.3 Language Model with Witten-Bell Smooth-
ing
A statistical n-gram model is challenged when a
bigram in the test set is absent from the training
set, an unavoidable situation in natural language
due to Zipf’s law. Therefore, some method for
assigning nonzero probability to novel n-grams is
required. For our language model (LM), we used
Witten-Bell smoothing, which reserves probability
mass for out of vocabulary values (Witten and
Bell, 1991, Chen and Goodman, 1998). The dis-
counted probability is calculated as
</bodyText>
<equation confidence="0.78157347368421">
P(win−+1...wi−1) = # # (wi−n+1...wi ) ( ... ) ( ...
ww+Dww
i n−
i − 1 i n− + 1 i
+1
p (xk  |x1x2x3 ... xk−1 ,
p
) i N i
′
C = ∑
∑
∈ . (3)
p
i N i
∈
(4)
1
)−
36
</equation>
<bodyText confidence="0.999449857142857">
where D(wi−n+1 ... wi−1) is the number of distinct
words that can appear after wi−n+1... wi−1 in the
training data. Actual values assigned to tokens out-
side the training data are not assigned uniformly
but are filled in using a variable order Markov
Model based on the strings seen in the training
data.
</bodyText>
<subsectionHeader confidence="0.970025">
3.4 Probabilistic Context-Free Grammar
</subsectionHeader>
<bodyText confidence="0.99966525">
The Probabilistic Context-Free Grammar
(PCFG) or Stochastic Context-Free Grammar
(SCFG) was originally formulated by Booth
(1969). For technical details we refer the reader to
Charniak (1993). For gene and protein name classi-
fication, we tried two different approaches. In the
first PCFG method (PCFG-3), we used the follow-
ing simple productions:
</bodyText>
<listItem confidence="0.998748">
1) CATP → CATP CATP
2) CATP → CATP postCATP
3) CATP → preCATP CATP
</listItem>
<bodyText confidence="0.9939361875">
CATP refers to the category of the phrase, GP
or NGP. The prefixes pre and post refer to begin-
nings and endings of the respective strings. We
trained two separate grammars, one for the positive
examples, GP, and one for the negative examples,
NGP. Test cases were tagged based on their score
from each of the two grammars.
In the second PCFG method (PCFG-8), we
combined the positive and negative training exam-
ples into one grammar. The minimum number of
non-terminals necessary to cover the training sets
gp1-3 was six {CATP, preCATP, postCATP, Not-
CATP, preNotCATP, postNotCATP}. CATP
represents a string from GP, and NotCATP repre-
sents a string from NGP. We used the following
production rules:
</bodyText>
<listItem confidence="0.999213375">
1) CATP → CATP CATP
2) CATP → CATP postCATP
3) CATP → preCATP CATP
4) CATP → NotCATP CATP
5) NotCATP → NotCATP NotCATP
6) NotCATP → NotCATP postNotCATP
7) NotCATP→ preNotCATP NotCATP
8) NotCATP → CATP NotCATP
</listItem>
<bodyText confidence="0.9988045">
It can be seen that (4) is necessary for strings like
“human p53,” and (8) covers strings like “p53
pathway.”
In order to deal with tokens that do not ap-
pear in the training data we use variable order
Markov Models for strings. First the grammar is
trained on the training set of names. Then any to-
ken appearing in the training data will have as-
signed to it the tags appearing on the right side of
any rule of the grammar (essentially part-of-speech
tags) with probabilities that are a product of the
training. We then construct a variable order
Markov Model for each tag type based on the to-
kens in the training data and the assigned prob-
abilities for that tag type. These Models (three for
PCFG-3 and six for PCFG-8) are then used to as-
sign the basic tags of the grammar to any token not
seen in training. In this way the grammars can be
used to classify any name even if its tokens are not
in the training data.
</bodyText>
<subsectionHeader confidence="0.653068">
3.5 Priority Model
</subsectionHeader>
<bodyText confidence="0.97772425">
There are problems with the previous ap-
proaches when applied to names. For example,
suppose one is dealing with the name “human liver
alkaline phosphatase” and class represents pro-
</bodyText>
<equation confidence="0.445904">
C1
</equation>
<bodyText confidence="0.831399">
tein names and class anatomical names. In that
</bodyText>
<equation confidence="0.544744">
C2
</equation>
<bodyText confidence="0.940631470588235">
case a language model is no more likely to favor
C1 than C2. We have experimented with PCFGs
and have found the biggest challenge to be how to
choose the grammar. After a number of attempts
we have still found problems of the “human liver
alkaline phosphatase” type to persist.
The difficulties we have experienced with lan-
guage models and PCFGs have led us to try a dif-
ferent approach to model named entities. As a
general rule in a phrase representing a named en-
tity a word to the right is more likely to be the head
word or the word determining the nature of the
entity than a word to the left. We follow this rule
and construct a model which we will call a Priority
Model. Let be the set of training data (names)
T1
for class and likewise for . Let
</bodyText>
<equation confidence="0.9266435">
C1 T2 C2 { } A
tα α∈
</equation>
<bodyText confidence="0.997417">
denote the set of all tokens used in names con-
tained in T1 ∪ T2. Then for each token tα , α ∈ A,
we assume there are associated two probabilities
pα and qα with the interpretation that pα is the
</bodyText>
<page confidence="0.91624">
37
</page>
<bodyText confidence="0.999744333333333">
probability that the appearance of the token tα in a
name indicates that name belongs to class C1 and
qα is the probability that tα is a reliable indicator
of the class of a name. Let n = tα(1)tα(2) ... tα(k) be
composed of the tokens on the right in the given
order. Then we compute the probability
</bodyText>
<equation confidence="0.840741">
kp(C1 |n)=pα(1)∏ j=2(1− qα(j))+∑k 2qα(i)pα(i)∏j=i+1(1−qα(j)).
</equation>
<bodyText confidence="0.99851275">
This formula comes from a straightforward in-
terpretation of priority in which we start on the
right side of a name and compute the probability
the name belongs to class stepwise. If is
</bodyText>
<equation confidence="0.749056">
C1 tα(k)
</equation>
<bodyText confidence="0.968935545454546">
the rightmost token we multiple the reliability
qα(k) times the significance pα(k) to obtain
qα(k)pα(k) , which represents the contribution of
tα(k) . The remaining or unused probability is
1 − qα k
( ) and this is passed to the next token to the
left, tα(k−1) . The probability 1 − qα k is scaled by
( )
the reliability and then the significance of tα(k−1) to
obtain (1− qα(k))qα(k−1) pα(k−1) , which is the contri-
bution of toward the probability that the
</bodyText>
<equation confidence="0.89127775">
tα (k−1)
name is of class C1. The remaining probability is
now (1−qα(k−1))( α k ) and this is again
1− q ( )
</equation>
<bodyText confidence="0.999917571428571">
passed to the next token to the left, etc. At the last
token on the left the reliability is not used to scale
because there are no further tokens to the left and
only significance pα(1) is used.
We want to choose all the parameters pα and
qα to maximize the probability of the data. Thus
we seek to maximize
</bodyText>
<equation confidence="0.997257">
F = ∑,�T log(p(C1  |n))+∑.T log (p(C2  |n)).
1 2
</equation>
<bodyText confidence="0.999932666666667">
Because probabilities are restricted to be in the
interval [ 0, 1] , it is convenient to make a change of
variables through the definitions
</bodyText>
<equation confidence="0.9890694">
e
pα = , qα =
x
1 e 1 ey
α + α
+
Then it is a simple exercise to show that
dpα = pα (1 pα ), dqα dyα = qα (1 qα )
dx
α
</equation>
<bodyText confidence="0.992546285714286">
From (5), (6), and (8) it is straightforward to com-
pute the gradient of F as a function of xα and yα
and because of (8) it is most naturally expressed in
terms of pα and qα . Before we carry out the op-
timization one further step is important. Let B
denote the subset of α ∈ A for which all the oc-
currences of tα either occur in names in or all
</bodyText>
<equation confidence="0.8594015">
T1
occurrences occur in names in . For any such
T2 α
we set qα =1 and if all occurrences of tα are in
names in T1 we set pα =1, while if all occur-
rences are in names in we set
T2 pα = 0. These
choices are optimal and because of the form of (8)
it is easily seen that
0 (9)
</equation>
<bodyText confidence="0.989131625">
for such an α . Thus we may ignore all the α ∈ B
in our optimization process because the values of
pα and qα are already set optimally. We therefore
carry out optimization of F using the
xα , yα , α ∈ A − B. For the optimization we have
had good success using a Limited Memory BFGS
method (Nash et al., 1991).
When the optimization of is complete we
</bodyText>
<equation confidence="0.565889">
F
</equation>
<bodyText confidence="0.9745092">
will have estimates for all the pα and qα , α ∈ A.
We still must deal with tokens tβ that are not in-
cluded among the tα . For this purpose we train
variable order Markov Models MP1 based on the
weighted set of strings { ( , )} A
</bodyText>
<equation confidence="0.974571590909091">
tα pα α∈ and MP2
based on { (tα ,1− pα) } α∈ A . Likewise we train
MQ1 based on { ( , )} A
tα qα α∈ and MQ2 based on
{ ( ,1 ) } A
tα qα α∈ −. Then if we allow mpi (tβ ) to
represent the prediction from model MPi and
mqi (tβ ) that from model MQi, we set
x ey
α α
. (7)
. (8)
∂ ∂
F F
= =
∂ ∂
x α yα
38
mn(tβ)
mq1(tβ)
(tβ)+mq2(tβ)
(10)
</equation>
<bodyText confidence="0.981497333333333">
This allows us to apply the priority model to
any name to predict its classification based on
equation 5.
</bodyText>
<sectionHeader confidence="0.999665" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.99994375">
We ran all three methods on the SemCat sets gp1,
gp2 and gp3. Results are shown in Table 2. For
evaluation we applied the standard information
retrieval measures precision, recall and F-measure.
</bodyText>
<equation confidence="0.9882484">
rel ret
_
( _
rel ret non rel ret
+ − _ )
rel ret
_
( _
rel ret rel not ret
+ _ _ )
</equation>
<bodyText confidence="0.670659285714286">
For name classification, rel_ret refers to true posi-
tive entities, non-rel_ret to false positive entities
and rel_ not_ret to false negative entities.
Table 2. Three-fold cross validation results. P = Preci-
sion, R = Recall, F = F-measure. PCFG = Probabilistic
Context-Free Grammar, LM = Bigram Model with Wit-
ten-Bell smoothing, PM = Priority Model.
</bodyText>
<sectionHeader confidence="0.998481" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999966764705882">
Using a variable order Markov model for strings
improved the results for all methods (results not
shown). The gp1-3 results are similar within each
method, yet it is clear that the overall performance
of these methods is PM &gt; PCFG-8 &gt; LM &gt; PCFG-
3. The very large size of the database and the very
uniform results obtained over the three independ-
ent random splits of the data support this conclu-
sion.
The improvement of PCFG-8 over PCFG-3 can
be attributed to the considerable ambiguity in this
domain. Since there are many cases of term over-
lap in the training data, a grammar incorporating
some of this ambiguity should outperform one that
does not. In PCFG-8, additional production rules
allow phrases beginning as CATPs to be overall
NotCATPs, and vice versa.
The Priority Model outperformed all other meth-
ods using F-measure. This supports our impres-
sion that the right-most words in a name should be
given higher priority when classifying names. A
decrease in performance for the model is expected
when applying this model to the named entity ex-
traction (NER) task, since the model is based on
terminology alone and not on the surrounding
natural language text. In our classification experi-
ments, there is no context, so disambiguation is not
an issue. However, the application of our model to
NER will require addressing this problem.
SemCat has not been tested for accuracy, but
we retain a set of manually-assigned scores that
attest to the reliability of each contributing list of
terms. Table 2 indicates that good results can be
obtained even with noisy training data.
</bodyText>
<sectionHeader confidence="0.998212" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999897571428571">
In this paper, we have concentrated on the infor-
mation inherent in gene and protein names versus
other biomedical entities. We have demonstrated
the utility of the SemCat database in training prob-
abilistic methods for gene and protein entity classi-
fication. We have also introduced a new model for
named entity prediction that prioritizes the contri-
bution of words towards the right end of terms.
The Priority Model shows promise in the domain
of gene and protein name classification. We plan
to apply the Priority Model, along with appropriate
contextual and meta-level information, to gene and
protein named entity recognition in future work.
We intend to make SemCat freely available.
</bodyText>
<table confidence="0.974256222222222">
PCFG-3 gp1 0.883 0.934 0.908
gp2 0.882 0.937 0.909
gp3 0.877 0.936 0.906
PCFG-8 gp1 0.939 0.966 0.952
gp2 0.938 0.967 0.952
gp3 0.939 0.966 0.952
LM gp1 0.920 0.968 0.944
gp2 0.923 0.968 0.945
PM gp1 0.949 0.968 0.958
</table>
<figure confidence="0.954134793103448">
Method Run P R F
gp3 0.917
gp2
gp3
0.950
0.950
0.971
0.968
0.967 0.958
0.943
0.960
t
)+mp2(t
), q
mq
=
β
β
β
1
pβ =
mA (
precision =
recall =
F measure 2* precision recall
− = *
(precision recall
+ )
39
</figure>
<sectionHeader confidence="0.983937" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.841009666666667">
This research was supported in part by the Intra-
mural Research Program of the NIH, National Li-
brary of Medicine.
</bodyText>
<sectionHeader confidence="0.96039" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999905268292683">
T. L. Booth. 1969. Probabilistic representation of for-
mal languages. In: IEEE Conference Record of the
1969 Tenth Annual Symposium on Switching and
Automata Theory, 74-81.
Stanley F. Chen and Joshua T. Goodman. 1998. An
empirical study of smoothing techniques for lan-
guage modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University.
Eugene Charniak. 1993. Statistical Language Learn-
ing. The MIT Press, Cambridge, Massachusetts.
K. Bretonnel Cohen, Lynne Fox, Philip V. Ogren and
Lawrence Hunter. 2005. Corpus design for biomedi-
cal natural language processing. Proceedings of the
ACL-ISMB Workshop on Linking Biological Litera-
ture, Ontologies and Databases, 38-45.
The Gene Ontology Consortium. 2000. Gene Ontology:
tool for the unification of biology, Nat Genet. 25: 25-
29.
Henk Harkema, Robert Gaizauskas, Mark Hepple, An-
gus Roberts, Ian Roberts, Neil Davis and Yikun Guo.
2004. A large scale terminology resource for bio-
medical text processing. Proc BioLINK 2004, 53-60.
Vasileios Hatzivassiloglou, Pablo A. Duboué and An-
drey Rzhetsky. 2001. Disambiguating proteins,
genes, and RNA in text: a machine learning ap-
proach. Bioinformatics 17 Suppl 1:S97-106.
J.-D. Kim, Tomoko Ohta, Yuka Tateisi and Jun-ichi
Tsujii. 2003. GENIA corpus--semantically annotated
corpus for bio-textmining. Bioinformatics 19 Suppl
1:i180-2.
Donald A. Lindberg, Betsy L. Humphreys and Alexa T.
McCray. 1993. The Unified Medical Language Sys-
tem. Methods Inf Med 32(4):281-91.
Hongfang Liu, Stephen B. Johnson, and Carol Fried-
man. 2002. Automatic resolution of ambiguous terms
based on machine learning and conceptual relations in
the UMLS. J Am Med Inform Assoc 9(6): 621–636.
Donna Maglott, Jim Ostell, Kim D. Pruitt and Tatiana
Tatusova. 2005. Entrez Gene: gene-centered informa-
tion at NCBI. Nucleic Acids Res. 33:D54-8.
Alexa T. McCray. 1989. The UMLS semantic network.
In: Kingsland LC (ed). Proc 13rd Annu Symp Com-
put Appl Med Care. Washington, DC: IEEE Com-
puter Society Press, 503-7.
Ryan McDonald and Fernando Pereira. 2005. Identify-
ing gene and protein mentions in text using condi-
tional random fields. BMC Bioinformatics 6 Supp
1:S6.
S. Nash and J. Nocedal. 1991. A numerical study of the
limited memory BFGS method and the truncated-
Newton method for large scale optimization, SIAM J.
Optimization1(3): 358-372.
Goran Nenadic, Irena Spasic and Sophia Ananiadou.
2003. Terminology-driven mining of biomedical lit-
erature. Bioinformatics 19:8, 938-943.
Raf M. Podowski, John G. Cleary, Nicholas T. Gon-
charoff, Gregory Amoutzias and William S. Hayes.
2004. AZuRE, a scalable system for automated term
disambiguation of gene and protein Names IEEE
Computer Society Bioinformatics Conference, 415-
424.
Lawrence H. Smith, Lorraine Tanabe, Thomas C. Rind-
flesch and W. John Wilbur. 2005. MedTag: A collec-
tion of biomedical annotations. Proceedings of the
ACL-ISMB Workshop on Linking Biological Litera-
ture, Ontologies and Databases, 32-37.
Lorraine Tanabe, Natalie Xie, Lynne H. Thom, Wayne
Matten and W. John Wilbur. 2005. GENETAG: a
tagged corpus for gene/protein named entity recogni-
tion. BMC Bioinformatics 6 Suppl 1:S3.
I. Witten and T. Bell, 1991. The zero-frequency prob-
lem: Estimating the probabilities of novel events in
adaptive text compression. IEEE Transactions on In-
formation Theory 37(4).
Alexander Yeh, Alexander Morgan, Mark Colosimo and
Lynette Hirschman. 2005. BioCreAtIvE Task 1A:
gene mention finding evaluation. BMC Bioinformat-
ics 6 Suppl 1:S2.
Hong Yu, Carol Friedman, Andrey Rhzetsky and
Pauline Kra. 1999. Representing genomic knowledge
in the UMLS semantic network. Proc AMIA Symp.
181-5.
</reference>
<page confidence="0.913833">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.700799">
<title confidence="0.999093">A Priority Model for Named Entities</title>
<author confidence="0.99537">Lorraine Tanabe W John Wilbur</author>
<affiliation confidence="0.894152">National Center for Biotechnology Information National Center for Biotechnology Information</affiliation>
<address confidence="0.999274">Bethesda, MD 20894 Bethesda, MD 20894</address>
<email confidence="0.96783">tanabe@ncbi.nlm.nih.govwilbur@ncbi.nlm.nih.gov</email>
<abstract confidence="0.99494080952381">We introduce a new approach to named entity classification which we term a Priority Model. We also describe the construction of a semantic database called SemCat consisting of a large number of semantically categorized names relevant to biomedicine. We used SemCat as training data to investigate name classification techniques. We generated a statistical language model and probabilistic contextfree grammars for gene and protein name classification, and compared the results with the new model. For all three methods, we used a variable order Markov model to predict the nature of strings not represented in the training data. The Priority Model achieves an F-measure of 0.958-0.960, consistently higher than the statistical language model and probabilistic context-free grammar.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T L Booth</author>
</authors>
<title>Probabilistic representation of formal languages. In:</title>
<date>1969</date>
<booktitle>IEEE Conference Record of the 1969 Tenth Annual Symposium on Switching and Automata Theory,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="13679" citStr="Booth (1969)" startWordPosition="2280" endWordPosition="2281"># # (wi−n+1...wi ) ( ... ) ( ... ww+Dww i n− i − 1 i n− + 1 i +1 p (xk |x1x2x3 ... xk−1 , p ) i N i ′ C = ∑ ∑ ∈ . (3) p i N i ∈ (4) 1 )− 36 where D(wi−n+1 ... wi−1) is the number of distinct words that can appear after wi−n+1... wi−1 in the training data. Actual values assigned to tokens outside the training data are not assigned uniformly but are filled in using a variable order Markov Model based on the strings seen in the training data. 3.4 Probabilistic Context-Free Grammar The Probabilistic Context-Free Grammar (PCFG) or Stochastic Context-Free Grammar (SCFG) was originally formulated by Booth (1969). For technical details we refer the reader to Charniak (1993). For gene and protein name classification, we tried two different approaches. In the first PCFG method (PCFG-3), we used the following simple productions: 1) CATP → CATP CATP 2) CATP → CATP postCATP 3) CATP → preCATP CATP CATP refers to the category of the phrase, GP or NGP. The prefixes pre and post refer to beginnings and endings of the respective strings. We trained two separate grammars, one for the positive examples, GP, and one for the negative examples, NGP. Test cases were tagged based on their score from each of the two gr</context>
</contexts>
<marker>Booth, 1969</marker>
<rawString>T. L. Booth. 1969. Probabilistic representation of formal languages. In: IEEE Conference Record of the 1969 Tenth Annual Symposium on Switching and Automata Theory, 74-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua T Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Computer Science Group, Harvard University.</institution>
<contexts>
<context position="13002" citStr="Chen and Goodman, 1998" startWordPosition="2147" endWordPosition="2150"> the training data. A PubMed search for apoeepsilon gene returns 269 hits showing the name is known. But it does not appear in this exact form in SemCat. 3.3 Language Model with Witten-Bell Smoothing A statistical n-gram model is challenged when a bigram in the test set is absent from the training set, an unavoidable situation in natural language due to Zipf’s law. Therefore, some method for assigning nonzero probability to novel n-grams is required. For our language model (LM), we used Witten-Bell smoothing, which reserves probability mass for out of vocabulary values (Witten and Bell, 1991, Chen and Goodman, 1998). The discounted probability is calculated as P(win−+1...wi−1) = # # (wi−n+1...wi ) ( ... ) ( ... ww+Dww i n− i − 1 i n− + 1 i +1 p (xk |x1x2x3 ... xk−1 , p ) i N i ′ C = ∑ ∑ ∈ . (3) p i N i ∈ (4) 1 )− 36 where D(wi−n+1 ... wi−1) is the number of distinct words that can appear after wi−n+1... wi−1 in the training data. Actual values assigned to tokens outside the training data are not assigned uniformly but are filled in using a variable order Markov Model based on the strings seen in the training data. 3.4 Probabilistic Context-Free Grammar The Probabilistic Context-Free Grammar (PCFG) or Sto</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen and Joshua T. Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98, Computer Science Group, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical Language Learning.</title>
<date>1993</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="13741" citStr="Charniak (1993)" startWordPosition="2290" endWordPosition="2291"> i +1 p (xk |x1x2x3 ... xk−1 , p ) i N i ′ C = ∑ ∑ ∈ . (3) p i N i ∈ (4) 1 )− 36 where D(wi−n+1 ... wi−1) is the number of distinct words that can appear after wi−n+1... wi−1 in the training data. Actual values assigned to tokens outside the training data are not assigned uniformly but are filled in using a variable order Markov Model based on the strings seen in the training data. 3.4 Probabilistic Context-Free Grammar The Probabilistic Context-Free Grammar (PCFG) or Stochastic Context-Free Grammar (SCFG) was originally formulated by Booth (1969). For technical details we refer the reader to Charniak (1993). For gene and protein name classification, we tried two different approaches. In the first PCFG method (PCFG-3), we used the following simple productions: 1) CATP → CATP CATP 2) CATP → CATP postCATP 3) CATP → preCATP CATP CATP refers to the category of the phrase, GP or NGP. The prefixes pre and post refer to beginnings and endings of the respective strings. We trained two separate grammars, one for the positive examples, GP, and one for the negative examples, NGP. Test cases were tagged based on their score from each of the two grammars. In the second PCFG method (PCFG-8), we combined the po</context>
</contexts>
<marker>Charniak, 1993</marker>
<rawString>Eugene Charniak. 1993. Statistical Language Learning. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bretonnel Cohen</author>
<author>Lynne Fox</author>
<author>Philip V Ogren</author>
<author>Lawrence Hunter</author>
</authors>
<title>Corpus design for biomedical natural language processing.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases,</booktitle>
<pages>38--45</pages>
<contexts>
<context position="1340" citStr="Cohen et al., 2005" startWordPosition="197" endWordPosition="200"> results with the new model. For all three methods, we used a variable order Markov model to predict the nature of strings not represented in the training data. The Priority Model achieves an F-measure of 0.958-0.960, consistently higher than the statistical language model and probabilistic context-free grammar. 1 Introduction Automatic recognition of gene and protein names is a challenging first step towards text mining the biomedical literature. Advances in the area of gene and protein named entity recognition (NER) have been accelerated by freely available tagged corpora (Kim et al., 2003, Cohen et al., 2005, Smith et al., 2005, Tanabe et al., 2005). Such corpora have made it possible for standardized evaluations such as Task 1A of the first BioCreative Workshop (Yeh et al., 2005). Although state-of-the-art systems now perform at the level of 80-83% F-measure, this is still well below the range of 90-97% for non-biomedical NER. The main reasons for this performance disparity are 1) the complexity of the genetic nomenclature and 2) the confusion of gene and protein names with other biomedical entities, as well as with common English words. In an effort to alleviate the confusion with other biomedi</context>
</contexts>
<marker>Cohen, Fox, Ogren, Hunter, 2005</marker>
<rawString>K. Bretonnel Cohen, Lynne Fox, Philip V. Ogren and Lawrence Hunter. 2005. Corpus design for biomedical natural language processing. Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases, 38-45.</rawString>
</citation>
<citation valid="true">
<title>The Gene Ontology Consortium.</title>
<date>2000</date>
<journal>Nat Genet.</journal>
<volume>25</volume>
<pages>25--29</pages>
<marker>2000</marker>
<rawString>The Gene Ontology Consortium. 2000. Gene Ontology: tool for the unification of biology, Nat Genet. 25: 25-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henk Harkema</author>
<author>Robert Gaizauskas</author>
<author>Mark Hepple</author>
<author>Angus Roberts</author>
<author>Ian Roberts</author>
<author>Neil Davis</author>
<author>Yikun Guo</author>
</authors>
<title>A large scale terminology resource for biomedical text processing. Proc BioLINK</title>
<date>2004</date>
<pages>53--60</pages>
<contexts>
<context position="7956" citStr="Harkema et al. (2004)" startWordPosition="1262" endWordPosition="1265"> organic chemical, we deleted Gene or Genome, and added the GENIA semantic types for genomics entities under Organic Chemical. The SemCat Physical Object hierarchy is shown in Figure 1. Similar hierarchies exist for the SN Conceptual Entity and Event trees. A number of the categories have been supplemented with automatically extracted entities from MEDLINE, derived from regular expression pattern matching. Currently, SemCat has 77 semantic types, and 5.11M non-unique entries. Additional entities from MEDLINE are being manually classified via an annotation website. Unlike the Termino database (Harkema et al. (2004), which contains terminology annotated with morphosyntactic and conceptual information, SemCat currently consists of gazetteer lists only. For our experiments, we generated two sets of training data from SemCat, Gene-Protein (GP) and Not-Gene-Protein (NGP). GP consists of specific terms from the semantic types DNA MOLECULE, PROTEIN MOLECULE, DNA FAMILY, PROTEIN FAMILY, PROTEIN COMPLEX and PROTEIN SUBUNIT. NGP consists of entities from all other SemCat types, along with generic entities from the GP semantic types. Generic entities were automatically eliminated from GP using pattern matching to </context>
</contexts>
<marker>Harkema, Gaizauskas, Hepple, Roberts, Roberts, Davis, Guo, 2004</marker>
<rawString>Henk Harkema, Robert Gaizauskas, Mark Hepple, Angus Roberts, Ian Roberts, Neil Davis and Yikun Guo. 2004. A large scale terminology resource for biomedical text processing. Proc BioLINK 2004, 53-60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Pablo A Duboué</author>
<author>Andrey Rzhetsky</author>
</authors>
<title>Disambiguating proteins, genes, and RNA in text: a machine learning approach.</title>
<date>2001</date>
<journal>Bioinformatics</journal>
<volume>17</volume>
<pages>1--97</pages>
<contexts>
<context position="4000" citStr="Hatzivassiloglou et al. (2001)" startWordPosition="625" endWordPosition="628">in text, and the classification of that entity. In this paper, we focus on the classification step. Spasic et al. (2005) use the MaSTerClass case-based reasoning system for biomedical term classification. MaSTerClass uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms. Its set of classes is a subset of the UMLS Semantic Network (McCray, 1989), that does not include genes and proteins. Liu et al. (2002) classified terms that represent multiple UMLS concepts by examining the conceptual relatives of the concepts. Hatzivassiloglou et al. (2001) classified terms known to belong to the classes Protein, Gene and/or RNA using unsupervised learning, achieving accuracy rates up to 85%. The AZuRE system (Podowski et al., 2004) uses a separate modified Naive Bayes model for each of 20K genes. A term is disambiguated based on its contextual similarity to each model. Nenadic et al. (2003) recognized the importance of terminological knowledge for biomedical text mining. They used the C/NCmethods, calculating both the intrinsic characteristics of terms (such as their frequency of occurrence as substrings of other terms), and the context of term</context>
</contexts>
<marker>Hatzivassiloglou, Duboué, Rzhetsky, 2001</marker>
<rawString>Vasileios Hatzivassiloglou, Pablo A. Duboué and Andrey Rzhetsky. 2001. Disambiguating proteins, genes, and RNA in text: a machine learning approach. Bioinformatics 17 Suppl 1:S97-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
</authors>
<title>Tomoko Ohta, Yuka Tateisi and Jun-ichi Tsujii.</title>
<date>2003</date>
<journal>Bioinformatics</journal>
<volume>19</volume>
<pages>1--180</pages>
<marker>Kim, 2003</marker>
<rawString>J.-D. Kim, Tomoko Ohta, Yuka Tateisi and Jun-ichi Tsujii. 2003. GENIA corpus--semantically annotated corpus for bio-textmining. Bioinformatics 19 Suppl 1:i180-2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald A Lindberg</author>
<author>Betsy L Humphreys</author>
<author>Alexa T McCray</author>
</authors>
<title>The Unified Medical Language System. Methods Inf Med 32(4):281-91.</title>
<date>1993</date>
<contexts>
<context position="5697" citStr="Lindberg et al., 1993" startWordPosition="897" endWordPosition="900">ing a more appropriate model for names. Current sources of training data are deficient in important biomedical terminologies like cell line names. To address this deficiency, we constructed the SemCat database, based on a subset of the UMLS Semantic Network enriched with categories from the GENIA Ontology (Kim et al, 2003), and a few new semantic types. We have populated SemCat with over 5 million entities of interest from Figure 1. SemCat Physical Object Hierarchy. White = UMLS SN, Light Grey = GENIA semantic types, Dark Grey = New semantic types. 34 standard knowledge sources like the UMLS (Lindberg et al., 1993), the Gene Ontology (GO) (The Gene Ontology Consortium, 2000), Entrez Gene (Maglott et al., 2005), and GENIA, as well as from the World Wide Web. In this paper, we use SemCat data to compare three probabilistic frameworks for named entity classification. 3 Methods We constructed the SemCat database of biomedical entities, and used these entities to train and test three probabilistic approaches to gene and protein name classification: 1) a statistical language model with Witten-Bell smoothing, 2) probabilistic context-free grammars (PCFGs) and 3) a new approach we call a Priority Model for name</context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>Donald A. Lindberg, Betsy L. Humphreys and Alexa T. McCray. 1993. The Unified Medical Language System. Methods Inf Med 32(4):281-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongfang Liu</author>
<author>Stephen B Johnson</author>
<author>Carol Friedman</author>
</authors>
<title>Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS.</title>
<date>2002</date>
<journal>J Am Med Inform Assoc</journal>
<volume>9</volume>
<issue>6</issue>
<pages>621--636</pages>
<contexts>
<context position="3859" citStr="Liu et al. (2002)" startWordPosition="604" endWordPosition="607">or Computational Linguistics NER is a difficult task because it requires both the identification of the boundaries of an entity in text, and the classification of that entity. In this paper, we focus on the classification step. Spasic et al. (2005) use the MaSTerClass case-based reasoning system for biomedical term classification. MaSTerClass uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms. Its set of classes is a subset of the UMLS Semantic Network (McCray, 1989), that does not include genes and proteins. Liu et al. (2002) classified terms that represent multiple UMLS concepts by examining the conceptual relatives of the concepts. Hatzivassiloglou et al. (2001) classified terms known to belong to the classes Protein, Gene and/or RNA using unsupervised learning, achieving accuracy rates up to 85%. The AZuRE system (Podowski et al., 2004) uses a separate modified Naive Bayes model for each of 20K genes. A term is disambiguated based on its contextual similarity to each model. Nenadic et al. (2003) recognized the importance of terminological knowledge for biomedical text mining. They used the C/NCmethods, calculat</context>
</contexts>
<marker>Liu, Johnson, Friedman, 2002</marker>
<rawString>Hongfang Liu, Stephen B. Johnson, and Carol Friedman. 2002. Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS. J Am Med Inform Assoc 9(6): 621–636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna Maglott</author>
<author>Jim Ostell</author>
<author>Kim D Pruitt</author>
<author>Tatiana Tatusova</author>
</authors>
<title>Entrez Gene: gene-centered information at NCBI. Nucleic Acids Res.</title>
<date>2005</date>
<pages>33--54</pages>
<contexts>
<context position="5794" citStr="Maglott et al., 2005" startWordPosition="912" endWordPosition="915">t biomedical terminologies like cell line names. To address this deficiency, we constructed the SemCat database, based on a subset of the UMLS Semantic Network enriched with categories from the GENIA Ontology (Kim et al, 2003), and a few new semantic types. We have populated SemCat with over 5 million entities of interest from Figure 1. SemCat Physical Object Hierarchy. White = UMLS SN, Light Grey = GENIA semantic types, Dark Grey = New semantic types. 34 standard knowledge sources like the UMLS (Lindberg et al., 1993), the Gene Ontology (GO) (The Gene Ontology Consortium, 2000), Entrez Gene (Maglott et al., 2005), and GENIA, as well as from the World Wide Web. In this paper, we use SemCat data to compare three probabilistic frameworks for named entity classification. 3 Methods We constructed the SemCat database of biomedical entities, and used these entities to train and test three probabilistic approaches to gene and protein name classification: 1) a statistical language model with Witten-Bell smoothing, 2) probabilistic context-free grammars (PCFGs) and 3) a new approach we call a Priority Model for named entities. As one component in all of our classification algorithms we use a variable order Mark</context>
</contexts>
<marker>Maglott, Ostell, Pruitt, Tatusova, 2005</marker>
<rawString>Donna Maglott, Jim Ostell, Kim D. Pruitt and Tatiana Tatusova. 2005. Entrez Gene: gene-centered information at NCBI. Nucleic Acids Res. 33:D54-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexa T McCray</author>
</authors>
<title>The UMLS semantic network. In:</title>
<date>1989</date>
<booktitle>Kingsland LC (ed). Proc 13rd Annu Symp Comput Appl Med Care.</booktitle>
<pages>503--7</pages>
<publisher>IEEE Computer Society Press,</publisher>
<location>Washington, DC:</location>
<contexts>
<context position="3798" citStr="McCray, 1989" startWordPosition="595" endWordPosition="596">ges 33–40, New York City, June 2006. c�2006 Association for Computational Linguistics NER is a difficult task because it requires both the identification of the boundaries of an entity in text, and the classification of that entity. In this paper, we focus on the classification step. Spasic et al. (2005) use the MaSTerClass case-based reasoning system for biomedical term classification. MaSTerClass uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms. Its set of classes is a subset of the UMLS Semantic Network (McCray, 1989), that does not include genes and proteins. Liu et al. (2002) classified terms that represent multiple UMLS concepts by examining the conceptual relatives of the concepts. Hatzivassiloglou et al. (2001) classified terms known to belong to the classes Protein, Gene and/or RNA using unsupervised learning, achieving accuracy rates up to 85%. The AZuRE system (Podowski et al., 2004) uses a separate modified Naive Bayes model for each of 20K genes. A term is disambiguated based on its contextual similarity to each model. Nenadic et al. (2003) recognized the importance of terminological knowledge fo</context>
</contexts>
<marker>McCray, 1989</marker>
<rawString>Alexa T. McCray. 1989. The UMLS semantic network. In: Kingsland LC (ed). Proc 13rd Annu Symp Comput Appl Med Care. Washington, DC: IEEE Computer Society Press, 503-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Identifying gene and protein mentions in text using conditional random fields.</title>
<date>2005</date>
<journal>BMC Bioinformatics</journal>
<volume>6</volume>
<note>Supp 1:S6.</note>
<contexts>
<context position="2716" citStr="McDonald and Pereira (2005)" startWordPosition="419" endWordPosition="422">ontological categories. We use this information in an effort to better understand how to classify names as representing genes/proteins or not. 2 Background A successful gene and protein NER system must address the complexity and ambiguity inherent in this domain. Hand-crafted rules alone are unable to capture these phenomena in large biomedical text collections. Most biomedical NER systems use some form of language modeling, consisting of an observed sequence of words and a hidden sequence of tags. The goal is to find the tag sequence with maximal probability given the observed word sequence. McDonald and Pereira (2005) use conditional random fields (CRF) to identify the beginning, inside and outside of gene and protein names. GuoDong et al. (2005) use an ensemble of one support vector machine and two Hidden Markov Models (HMMs). Kinoshita et al. (2005) use a second-order Markov model. Dingare et al. (2005) use a maximum entropy Markov model (MEMM) with large feature sets. 33 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 33–40, New York City, June 2006. c�2006 Association for Computational Linguistics NER is a difficult task because it requires b</context>
</contexts>
<marker>McDonald, Pereira, 2005</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2005. Identifying gene and protein mentions in text using conditional random fields. BMC Bioinformatics 6 Supp 1:S6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nash</author>
<author>J Nocedal</author>
</authors>
<title>A numerical study of the limited memory BFGS method and the truncatedNewton method for large scale optimization,</title>
<date>1991</date>
<journal>SIAM J.</journal>
<volume>1</volume>
<issue>3</issue>
<pages>358--372</pages>
<marker>Nash, Nocedal, 1991</marker>
<rawString>S. Nash and J. Nocedal. 1991. A numerical study of the limited memory BFGS method and the truncatedNewton method for large scale optimization, SIAM J. Optimization1(3): 358-372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goran Nenadic</author>
</authors>
<title>Irena Spasic and Sophia Ananiadou.</title>
<date>2003</date>
<journal>Bioinformatics</journal>
<volume>19</volume>
<pages>938--943</pages>
<marker>Nenadic, 2003</marker>
<rawString>Goran Nenadic, Irena Spasic and Sophia Ananiadou. 2003. Terminology-driven mining of biomedical literature. Bioinformatics 19:8, 938-943.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raf M Podowski</author>
<author>John G Cleary</author>
<author>Nicholas T Goncharoff</author>
<author>Gregory Amoutzias</author>
<author>William S Hayes</author>
</authors>
<title>AZuRE, a scalable system for automated term disambiguation of gene and protein</title>
<date>2004</date>
<booktitle>Names IEEE Computer Society Bioinformatics Conference,</booktitle>
<pages>415--424</pages>
<contexts>
<context position="4179" citStr="Podowski et al., 2004" startWordPosition="653" endWordPosition="656">m classification. MaSTerClass uses term contexts from an annotated corpus of 2072 MEDLINE abstracts related to nuclear receptors as a basis for classifying new terms. Its set of classes is a subset of the UMLS Semantic Network (McCray, 1989), that does not include genes and proteins. Liu et al. (2002) classified terms that represent multiple UMLS concepts by examining the conceptual relatives of the concepts. Hatzivassiloglou et al. (2001) classified terms known to belong to the classes Protein, Gene and/or RNA using unsupervised learning, achieving accuracy rates up to 85%. The AZuRE system (Podowski et al., 2004) uses a separate modified Naive Bayes model for each of 20K genes. A term is disambiguated based on its contextual similarity to each model. Nenadic et al. (2003) recognized the importance of terminological knowledge for biomedical text mining. They used the C/NCmethods, calculating both the intrinsic characteristics of terms (such as their frequency of occurrence as substrings of other terms), and the context of terms as linear combinations. These biomedical classification systems all rely on the context surrounding named entities. While we recognize the importance of context, we believe one </context>
</contexts>
<marker>Podowski, Cleary, Goncharoff, Amoutzias, Hayes, 2004</marker>
<rawString>Raf M. Podowski, John G. Cleary, Nicholas T. Goncharoff, Gregory Amoutzias and William S. Hayes. 2004. AZuRE, a scalable system for automated term disambiguation of gene and protein Names IEEE Computer Society Bioinformatics Conference, 415-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence H Smith</author>
<author>Lorraine Tanabe</author>
<author>Thomas C Rindflesch</author>
<author>W John Wilbur</author>
</authors>
<title>MedTag: A collection of biomedical annotations.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases,</booktitle>
<pages>32--37</pages>
<contexts>
<context position="1360" citStr="Smith et al., 2005" startWordPosition="201" endWordPosition="204">w model. For all three methods, we used a variable order Markov model to predict the nature of strings not represented in the training data. The Priority Model achieves an F-measure of 0.958-0.960, consistently higher than the statistical language model and probabilistic context-free grammar. 1 Introduction Automatic recognition of gene and protein names is a challenging first step towards text mining the biomedical literature. Advances in the area of gene and protein named entity recognition (NER) have been accelerated by freely available tagged corpora (Kim et al., 2003, Cohen et al., 2005, Smith et al., 2005, Tanabe et al., 2005). Such corpora have made it possible for standardized evaluations such as Task 1A of the first BioCreative Workshop (Yeh et al., 2005). Although state-of-the-art systems now perform at the level of 80-83% F-measure, this is still well below the range of 90-97% for non-biomedical NER. The main reasons for this performance disparity are 1) the complexity of the genetic nomenclature and 2) the confusion of gene and protein names with other biomedical entities, as well as with common English words. In an effort to alleviate the confusion with other biomedical entities we have</context>
</contexts>
<marker>Smith, Tanabe, Rindflesch, Wilbur, 2005</marker>
<rawString>Lawrence H. Smith, Lorraine Tanabe, Thomas C. Rindflesch and W. John Wilbur. 2005. MedTag: A collection of biomedical annotations. Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases, 32-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorraine Tanabe</author>
<author>Natalie Xie</author>
<author>Lynne H Thom</author>
<author>Wayne Matten</author>
<author>W John Wilbur</author>
</authors>
<title>GENETAG: a tagged corpus for gene/protein named entity recognition.</title>
<date>2005</date>
<journal>BMC Bioinformatics</journal>
<volume>6</volume>
<note>Suppl 1:S3.</note>
<contexts>
<context position="1382" citStr="Tanabe et al., 2005" startWordPosition="205" endWordPosition="208">ee methods, we used a variable order Markov model to predict the nature of strings not represented in the training data. The Priority Model achieves an F-measure of 0.958-0.960, consistently higher than the statistical language model and probabilistic context-free grammar. 1 Introduction Automatic recognition of gene and protein names is a challenging first step towards text mining the biomedical literature. Advances in the area of gene and protein named entity recognition (NER) have been accelerated by freely available tagged corpora (Kim et al., 2003, Cohen et al., 2005, Smith et al., 2005, Tanabe et al., 2005). Such corpora have made it possible for standardized evaluations such as Task 1A of the first BioCreative Workshop (Yeh et al., 2005). Although state-of-the-art systems now perform at the level of 80-83% F-measure, this is still well below the range of 90-97% for non-biomedical NER. The main reasons for this performance disparity are 1) the complexity of the genetic nomenclature and 2) the confusion of gene and protein names with other biomedical entities, as well as with common English words. In an effort to alleviate the confusion with other biomedical entities we have assembled a database </context>
</contexts>
<marker>Tanabe, Xie, Thom, Matten, Wilbur, 2005</marker>
<rawString>Lorraine Tanabe, Natalie Xie, Lynne H. Thom, Wayne Matten and W. John Wilbur. 2005. GENETAG: a tagged corpus for gene/protein named entity recognition. BMC Bioinformatics 6 Suppl 1:S3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Witten</author>
<author>T Bell</author>
</authors>
<title>The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression.</title>
<date>1991</date>
<journal>IEEE Transactions on Information Theory</journal>
<volume>37</volume>
<issue>4</issue>
<contexts>
<context position="12977" citStr="Witten and Bell, 1991" startWordPosition="2143" endWordPosition="2146">hich does not appear in the training data. A PubMed search for apoeepsilon gene returns 269 hits showing the name is known. But it does not appear in this exact form in SemCat. 3.3 Language Model with Witten-Bell Smoothing A statistical n-gram model is challenged when a bigram in the test set is absent from the training set, an unavoidable situation in natural language due to Zipf’s law. Therefore, some method for assigning nonzero probability to novel n-grams is required. For our language model (LM), we used Witten-Bell smoothing, which reserves probability mass for out of vocabulary values (Witten and Bell, 1991, Chen and Goodman, 1998). The discounted probability is calculated as P(win−+1...wi−1) = # # (wi−n+1...wi ) ( ... ) ( ... ww+Dww i n− i − 1 i n− + 1 i +1 p (xk |x1x2x3 ... xk−1 , p ) i N i ′ C = ∑ ∑ ∈ . (3) p i N i ∈ (4) 1 )− 36 where D(wi−n+1 ... wi−1) is the number of distinct words that can appear after wi−n+1... wi−1 in the training data. Actual values assigned to tokens outside the training data are not assigned uniformly but are filled in using a variable order Markov Model based on the strings seen in the training data. 3.4 Probabilistic Context-Free Grammar The Probabilistic Context-F</context>
</contexts>
<marker>Witten, Bell, 1991</marker>
<rawString>I. Witten and T. Bell, 1991. The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression. IEEE Transactions on Information Theory 37(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
<author>Alexander Morgan</author>
<author>Mark Colosimo</author>
<author>Lynette Hirschman</author>
</authors>
<title>BioCreAtIvE Task 1A: gene mention finding evaluation.</title>
<date>2005</date>
<journal>BMC Bioinformatics</journal>
<volume>6</volume>
<note>Suppl 1:S2.</note>
<contexts>
<context position="1516" citStr="Yeh et al., 2005" startWordPosition="227" endWordPosition="230">el achieves an F-measure of 0.958-0.960, consistently higher than the statistical language model and probabilistic context-free grammar. 1 Introduction Automatic recognition of gene and protein names is a challenging first step towards text mining the biomedical literature. Advances in the area of gene and protein named entity recognition (NER) have been accelerated by freely available tagged corpora (Kim et al., 2003, Cohen et al., 2005, Smith et al., 2005, Tanabe et al., 2005). Such corpora have made it possible for standardized evaluations such as Task 1A of the first BioCreative Workshop (Yeh et al., 2005). Although state-of-the-art systems now perform at the level of 80-83% F-measure, this is still well below the range of 90-97% for non-biomedical NER. The main reasons for this performance disparity are 1) the complexity of the genetic nomenclature and 2) the confusion of gene and protein names with other biomedical entities, as well as with common English words. In an effort to alleviate the confusion with other biomedical entities we have assembled a database consisting of named entities appearing in the literature of biomedicine together with information on their ontological categories. We </context>
</contexts>
<marker>Yeh, Morgan, Colosimo, Hirschman, 2005</marker>
<rawString>Alexander Yeh, Alexander Morgan, Mark Colosimo and Lynette Hirschman. 2005. BioCreAtIvE Task 1A: gene mention finding evaluation. BMC Bioinformatics 6 Suppl 1:S2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Carol Friedman</author>
<author>Andrey Rhzetsky</author>
<author>Pauline Kra</author>
</authors>
<title>Representing genomic knowledge in the UMLS semantic network.</title>
<date>1999</date>
<booktitle>Proc AMIA Symp.</booktitle>
<pages>181--5</pages>
<contexts>
<context position="6632" citStr="Yu et al. (1999)" startWordPosition="1049" endWordPosition="1052">ies, and used these entities to train and test three probabilistic approaches to gene and protein name classification: 1) a statistical language model with Witten-Bell smoothing, 2) probabilistic context-free grammars (PCFGs) and 3) a new approach we call a Priority Model for named entities. As one component in all of our classification algorithms we use a variable order Markov Model for strings. 3.1 SemCat Database Construction The UMLS Semantic Network (SN) is an ongoing project at the National Library of Medicine. Many users have modified the SN for their own research domains. For example, Yu et al. (1999) found that the SN was missing critical components in the genomics domain, and added six new semantic types including Protein Structure and Chemical Complex. We found that a subset of the SN would be sufficient for gene and protein name classification, and added some new semantic types for better coverage. We shifted some semantic types from suboptimal nodes to ones that made more sense from a genomics standpoint. For example, there were two problems with Gene or Genome. Firstly, genes and genomes are not synonymous, and secondly, placement under the semantic type Fully Formed Anatomical Struc</context>
</contexts>
<marker>Yu, Friedman, Rhzetsky, Kra, 1999</marker>
<rawString>Hong Yu, Carol Friedman, Andrey Rhzetsky and Pauline Kra. 1999. Representing genomic knowledge in the UMLS semantic network. Proc AMIA Symp. 181-5.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>