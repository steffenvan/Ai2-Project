<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000075">
<note confidence="0.443499333333333">
Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), Philadelphia, July 2002, pp. 304-311.
Association for Computational Linguistics.
</note>
<title confidence="0.976841">
Phrasal Cohesion and Statistical Machine Translation
</title>
<author confidence="0.994803">
Heidi J. Fox
</author>
<affiliation confidence="0.882222666666667">
Brown Laboratory for Linguistic Information Processing
Department of Computer Science
Brown University, Box 1910, Providence, RI 02912
</affiliation>
<email confidence="0.998276">
hjf@cs.brown.edu
</email>
<sectionHeader confidence="0.995632" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972642857143">
There has been much interest in us-
ing phrasal movement to improve statis-
tical machine translation. We explore
how well phrases cohere across two lan-
guages, specifically English and French,
and examine the particular conditions un-
der which they do not. We demonstrate
that while there are cases where coherence
is poor, there are many regularities which
can be exploited by a statistical machine
translation system. We also compare three
variant syntactic representations to deter-
mine which one has the best properties
with respect to cohesion.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997104740740741">
Statistical machine translation (SMT) seeks to de-
velop mathematical models of the translation pro-
cess whose parameters can be automatically esti-
mated from a parallel corpus. The first work in
SMT, done at IBM (Brown et al., 1993), developed
a noisy-channel model, factoring the translation pro-
cess into two portions: the translation model and the
language model. The translation model captures the
translation of source language words into the target
language and the reordering of those words. The
language model ranks the outputs of the translation
model by how well they adhere to the syntactic con-
straints of the target language.1
The prime deficiency of the IBM model is the re-
ordering component. Even in the most complex of
&apos;Though usually a simple word n-gram model is used for the
language model.
the five IBM models, the reordering operation pays
little attention to context and none at all to higher-
level syntactic structures. Many attempts have been
made to remedy this by incorporating syntactic in-
formation into translation models. These have taken
several different forms, but all share the basic as-
sumption that phrases in one language tend to stay
together (i.e. cohere) during translation and thus the
word-reordering operation can move entire phrases,
rather than moving each word independently.
(Yarowsky et al., 2001) states that during their
work on noun phrase bracketing they found a strong
cohesion among noun phrases, even when compar-
ing English to Czech, a relatively free word or-
der language. Other than this, there is little in the
SMT literature to validate the coherence assump-
tion. Several studies have reported alignment or
translation performance for syntactically augmented
translation models (Wu, 1997; Wang, 1998; Alshawi
et al., 2000; Yamada and Knight, 2001; Jones and
Havrilla, 1998) and these results have been promis-
ing. However, without a focused study of the be-
havior of phrases across languages, we cannot know
how far these models can take us and what specific
pitfalls they face.
The particulars of cohesion will clearly depend
upon the pair of languages being compared. Intu-
itively, we expect that while French and Spanish will
have a high degree of cohesion, French and Japanese
may not. It is also clear that if the cohesion between
two closely related languages is not high enough
to be useful, then there is no hope for these meth-
ods when applied to distantly related languages. For
this reason, we have examined phrasal cohesion for
French and English, two languages which are fairly
close syntactically but have enough differences to be
interesting.
</bodyText>
<sectionHeader confidence="0.559567" genericHeader="method">
2 Alignments, Spans and Crossings
</sectionHeader>
<bodyText confidence="0.999571363636364">
An alignment is a mapping between the words in a
string in one language and the translations of those
words in a string in another language. Given an En-
glish string, , and a French
string, , an alignment a can
be represented by . Each is
a set of indices into where
indicates that word in the French sentence is
aligned with word in the English sentence.
indicates that English word has no corresponding
French word.
Given an alignment and an English phrase cov-
ering words , the span is a pair where the
first element is and the second el-
ement is . Thus, the span includes
all words between the two extrema of the alignment,
whether or not they too are part of the translation. If
phrases cohere perfectly across languages, the span
of one phrase will never overlap the span of another.
If two spans do overlap, we call this a crossing.
Figure 1 shows an example of an English parse
along with the alignment between the English and
French words (shown with dotted lines). The En-
glish word “not” is aligned to the two French words
“ne” and “pas” and thus has a span of [1,3]. The
main English verb “change” is aligned to the French
“modifie” and has a span of [2,2]. The two spans
overlap and thus there is a crossing. This definition
is asymmetric (i.e. what is a crossing when mov-
ing from English to French is not guaranteed to be
a crossing when moving from French to English).
However, we only pursue translation direction since
that is the one for which we have parsed data.
</bodyText>
<sectionHeader confidence="0.999281" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.989258">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999724875">
To calculate spans, we need aligned pairs of En-
glish and French sentences along with parses for the
English sentences. Our aligned data comes from
a corpus described in (Och and Ney, 2000) which
contains 500 sentence pairs randomly selected from
the Canadian Hansard corpus and manually aligned.
The alignments are of two types: sure (S) and pos-
sible (P). S alignments are those which are unam-
</bodyText>
<figure confidence="0.947664444444445">
S
VP
VP
NP
ADVP NP
PRP AUX RB RB VB DT NN .
they do not really change the status .
on [ne [modifie] .pas vraiment la situation .
0 1 2ge3 4 5 6 7
</figure>
<figureCaption confidence="0.999938">
Figure 1: Alignment Example with Crossing
</figureCaption>
<bodyText confidence="0.999854153846154">
biguous while P alignments are those which are less
certain. P alignments often appear when a phrase in
one language translates as a unit into a phrase in the
other language (e.g. idioms, free translations, miss-
ing function words) but can also be the result of gen-
uine ambiguity. When two annotators disagree, the
union of the P alignments produced by each anno-
tator is recorded as the P alignment in the corpus.
When an S alignment exists, there will always also
exist a P alignment such that P S. The English sen-
tences were parsed using a state-of-the-art statistical
parser (Charniak, 2000) trained on the University of
Pennsylvania Treebank (Marcus et al., 1993).
</bodyText>
<subsectionHeader confidence="0.996255">
3.2 Phrasal Translation Filtering
</subsectionHeader>
<bodyText confidence="0.680963">
je invoque le R`eglement
</bodyText>
<figureCaption confidence="0.994453">
Figure 2: Phrasal Translation Example
</figureCaption>
<bodyText confidence="0.279697">
Since P alignments often align phrasal transla-
</bodyText>
<equation confidence="0.3625125">
NP
NP
NP
VP
PP
NP
PP
PRP VBP IN DT NN IN NN
S
I rise on a point of order
</equation>
<table confidence="0.8125108">
Alignment Type Phrasal Filter Off Phrasal Filter On
S S P P S S P P
Head Crossings 0.236 4.790 5.284 0.172 2.772 2.492
Modifier Crossings 0.056 0.880 0.988 0.048 0.516 0.362
Phrasal Translations – – – 0.072 2.382 3.418
</table>
<tableCaption confidence="0.997907">
Table 1: Average Number of Crossings per Sentence
</tableCaption>
<bodyText confidence="0.997806769230769">
tions, the number of crossings when P alignments
are used will be artificially inflated. For example, in
Figure 2 note that every pair of English and French
words under the verb phrase is aligned. This will
generate five crossings, one each between the pairs
VBP-PP, IN-NP, NP -PP, NN-DT, and IN-NP .
However, what is really happening is that the whole
verb phrase is first being moved without crossing
anything else and then being translated as a unit. For
our purposes we want to count this example as pro-
ducing zero crossings. To accomplish this, we de-
fined a simple heuristic to detect phrasal translations
so we can filter them if desired.
</bodyText>
<subsectionHeader confidence="0.999557">
3.3 Calculating Crossings
</subsectionHeader>
<bodyText confidence="0.999176636363636">
After calculating the French spans from the English
parses and alignment information, we counted cross-
ings for all pairs of child constituents in each con-
stituent in the sentence, maintaining separate counts
for those involving the head constituent of the phrase
and for crossings involving modifiers only. We did
this while varying conditions along two axes: align-
ment type and phrasal translation filtering. Recalling
the two different types of alignments, S and P, we
examined three different conditions: S alignments
only, P alignments only, or S alignments where
present falling back to P alignments (S P). For
each of these conditions, we counted crossings both
with and without using the phrasal translation filter.
For a given alignment type S,S P,P, let
if phrases and cross each other
and otherwise. Let if the phrasal
translation filter is turned off. If the filter is on,
, modifier constituents , and child constituents
and for a particular alignment type
, the number of head crossings and modifier
crossings can be calculated recursively:
</bodyText>
<sectionHeader confidence="0.999971" genericHeader="method">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999605">
4.1 Average Crossings
</subsectionHeader>
<bodyText confidence="0.999656814814815">
Table 1 shows the average number of crossings per
sentence. The table is split into two sections, one
for results when the phrasal filter was used and one
for when it was not. “Alignment Type” refers to
whether we used S, P or S P as the alignment
data. The “Head Crossings” line shows the results
when comparing the span of the head constituent of
a phrase with the spans of its modifier constituents,
and “Modifier Crossings” refers to the case where
we compare the spans of pairs of modifiers. The
“Phrasal Translations” line shows the average num-
ber of phrasal translations detected per sentence.
For S alignments, the results are quite promising,
with an average of only 0.236 head crossings per
sentence and an even smaller average for modifier
crossings (0.056). However, these results are overly
optimistic since often many words in a sentence will
not have an S alignment at all, such as “coming”,
“in”, and “before” in following example:
the full report will be coming in before the fall
le rapport complet sera d´epos´e de ici le automne prochain
When we use P alignments for these unaligned
words (the S P case), we get a more meaningful
result. Both types of crossings are much more fre-
quent (4.790 for heads and 0.88 for modifiers) and
Then, for a given phrase with head constituent
if and are part
of a phrasal translation
in alignment
otherwise
phrasal translation filtering has a much larger effect
(reducing head average to 2.772 and modifier aver-
age to 0.516). Phrasal translations account for al-
most half of all crossings, on average. This effect is
even more pronounced in the case where we use P
alignments only. This reinforces the importance of
phrasal translation in the development of any trans-
lation system.
Even after filtering, the number of crossings in
the S P case is quite large. This is discouraging,
however there are reasons why this result should be
looked on as more of an upper bound than anything
precise. For one thing, there are cases of phrasal
translation which our heuristic fails to recognize, an
example of which is shown in Figure 3. The align-
ment of “explorer” with “this” and “matter” seems
to indicate that the intention of the annotator was to
align the phrase “work this matter out”, as a unit, to
“de explorer la question”. However, possibly due to
an error during the coding of the alignment, “work”
and “out” align with “de” (indicated by the solid
lines) while “this” and “matter” do not. This causes
the phrasal translation heuristic to fail resulting in a
crossing where there should be none.
</bodyText>
<figure confidence="0.4998705">
VP
VB DT NN RP
</figure>
<figureCaption confidence="0.997998">
Figure 3: Phrasal Translation Heuristic Failure
</figureCaption>
<bodyText confidence="0.999968166666667">
Also, due to the annotation guidelines, P align-
ments are not as consistent as would be ideal. Re-
call that in cases of annotator disagreement, the P
alignment is taken to be the union of the P align-
ments of both annotators. Thus, it is possible for
the P alignment to contain two mutually conflict-
ing alignments. These composite alignments will
likely generate crossings even where the alignments
of each individual annotator would not. While re-
flecting genuine ambiguity, an SMT system would
likely pursue only one of the alternatives and only a
portion of the crossings would come into play.
</bodyText>
<subsectionHeader confidence="0.981385">
4.2 Percentage Crossings
</subsectionHeader>
<bodyText confidence="0.999921483870968">
Our results show a significantly larger number of
head crossings than modifier crossings. One possi-
bility is that this is due to most phrases having a head
and modifier pair to test, while many do not have
multiple modifiers and therefore there are fewer op-
portunities for modifier crossings. Thus, it is infor-
mative to examine how many potential crossings ac-
tually turn out to be crossings. Table 2 provides this
result in the form of the percentage of crossing tests
which result in detection of a crossing.
To calculate this, we kept totals for the number
of head ( ) and modifier ( ) crossing tests per-
formed as well as the number of phrasal translations
detected ( ). Note that when the phrasal transla-
tion filter is turned on, these totals differ for each of
the different alignment types (S, S P, and P).
The percentages are calculated after summing over
all sentencesin the corpus:
There are still many more crossings in the S P
and P alignments than in the S alignments. The S
alignment has 1.58% head crossings while the S P
and P alignments have 32.16% and 35.47% respec-
tively, with similar relative percentages for modi-
fier crossings. Also as before, half to two-thirds of
crossings in the S P and P alignments are due to
phrasal translations. More interestingly, we see that
modifier crossings remain significantly less preva-
lent than head crossings (e.g. 14.45% vs. 32.16% for
the S P case) and that this is true uniformly across
all parameter settings. This indicates that heads are
more intimately involved with their modifiers than
</bodyText>
<table confidence="0.995765272727273">
PRT
NP
work this matter out
de explorer
la
question
Alignment Type Phrasal Filter Off Phrasal Filter On
S S P P S S P P
Head Crossings 1.58% 32.16% 35.47% 1.15% 18.61% 16.73%
Modifier Crossings 0.92% 14.45% 16.23% 0.78% 8.47% 5.94%
Phrasal Translations – – – 0.34% 11.35% 16.29%
</table>
<tableCaption confidence="0.917991">
Table 2: Percent Crossings per Chance
</tableCaption>
<table confidence="0.999772333333333">
Cause Count
Ne Pas 13
Modal 9
Adverb 8
Possessive 2
Pronoun 2
Adjective 1
Parser Error 16
Reword 16
Reorder 13
Translation Error 5
Total 86
</table>
<tableCaption confidence="0.999071">
Table 3: Causes of Head Crossings
</tableCaption>
<figureCaption confidence="0.99852">
Figure 4: Crossing Due to Rewording
</figureCaption>
<figure confidence="0.998319">
be
there
will
more
aura de les effets plus destructifs que positifs
en fait , elle
VP
VP
ADJP
PP
ADVP
NP ADJP NP
RB
indeed ,
NN
JJ NNS
effects
EX
MD
AUX
JJR
IN
than
,
positive
S
divisiveness
</figure>
<bodyText confidence="0.822767">
modifiers are with each other and therefore are more
likely to be involved in semi-phrasal constructions.
</bodyText>
<sectionHeader confidence="0.566161" genericHeader="method">
5 Analysis of Causes
</sectionHeader>
<bodyText confidence="0.9872005">
Since it is clear that crossings are too prevalent to
ignore, it is informative to try to understand exactly
what constructions give rise to them. To that end, we
examined by hand all of the head crossings produced
using the S alignments with phrasal filtering. Table 3
shows the results of this analysis.
The first thing to note is that by far most of
the crossings do not reflect lack of phrasal cohe-
sion between the two languages. Instead, they are
caused either by errors in the syntactic analysis or
the fact that translation as done by humans is a much
richer process than just replication of the source sen-
tence in another language. Sentences are reworded,
clauses are reordered, and sometimes human trans-
lators even make mistakes.
Errors in syntactic analysis consist mostly of at-
tachment errors. Rewording and reordering ac-
counted for a large number of crossings as well. In
most of the cases of rewording (see Figure 4) or re-
lorsque nous avons pr´epar´e le budget , nous avons pris cela en consid´eration
</bodyText>
<figureCaption confidence="0.993669">
Figure 5: Crossing Due to Reordering of Clauses
</figureCaption>
<bodyText confidence="0.999702333333333">
ordering (see Figure 5) a more “parallel” translation
would also be valid. Thus, while it would be difficult
for a statistical model to learn from these examples,
there is nothing to preclude production of a valid
translation from a system using phrasal movement
in the reordering phase. The rewording and reorder-
ing examples were so varied that we were unable to
find any regularities which might be exploited by a
translation model.
</bodyText>
<figure confidence="0.994308375">
NP
NP WHADVP
ADVP
NP
NP
NP
VP
VP
SBAR
S
ADVP
VP
PP
PRP AUX VBN DT NNS RB RB IN NN WRB PRP VBD DT NN
we have taken these considerations very much into account when we designed the Budget
S
</figure>
<bodyText confidence="0.999863608695652">
Among the cases which do result from language
differences, the most common is the “ne ... pas”
construction (e.g. Figure 1). Fifteen percent of the
86 total crossings are due to this construction. Be-
cause “ne ... pas” wraps around the verb, it will al-
ways result in a crossing. However, the types of syn-
tactic structures (categorized as context-free gram-
mar rules) which are present in cases of negation are
rather restricted. Of the 47 total distinct syntactic
structures which resulted in crossings, only three of
them involved negation. In addition, the crossings
associated with these particular structures were un-
ambiguously caused by negation (i.e. for each struc-
ture, only negation-related crossings were present).
Next most common is the case where the En-
glish contains a modal verb which is aligned with
the main verb in the French. In the example in Fig-
ure 6, “will be” is aligned to “sera” (indicated by
the solid lines) and because of the constituent struc-
ture of the English parse there is a crossing. As with
negation, this type of crossing is quite regular, re-
sulting uniquely from only two different syntactic
structures.
</bodyText>
<figureCaption confidence="0.996039">
Figure 7: Crossing Due to Adverb
</figureCaption>
<sectionHeader confidence="0.981439" genericHeader="method">
6 Further Experiments
</sectionHeader>
<subsectionHeader confidence="0.999738">
6.1 Flattening Verb Phrases
</subsectionHeader>
<bodyText confidence="0.999814375">
Many of the causes listed above are related to verb
phrases. In particular, some of the adverb-related
crossings (e.g. Figure 1) and all of the modal-related
crossings (e.g. Figure 6) are artifacts of the nested
verb phrase structure of our parser. This nesting usu-
ally does not provide any extra information beyond
what could be gleaned from word order. Therefore,
we surmised that flattening verb phrases would elim-
inate some types of crossings without reducing the
utility of the parse.
The flattening operation consists of identifying all
nested verb phrases and splicing the children of the
nested phrase into the parent phrase in its place. This
procedure is applied recursively until there are no
nested verb phrases. An example is shown in Fig-
ure 8. Crossings can be calculated as before.
</bodyText>
<figure confidence="0.983728581395349">
S
VP
VP
VP
PP
NP
DT JJ NN MD AUX VBG RB IN
NP
ADVP
DT NN
le rapport complet sera d´epos´e de ici le automne prochain
the full report will be coming in before
the fall
S
VP
NP
SBAR
S
VP
ADJP
PP
ADVP NP WHNP NP
NP
that Government simply tells the people what is good for them
le gouvernement dit tout simplement a` les gens ce qui est bon pour eux
DT NN
RB
VBZ DT
NNS WP AUX
JJ IN
PRP
VP
VP
VP
PP
NP
VP
PP
NP
MD AUX VBG IN DT NN
will be coming before the fall
MD AUX VBG IN DT NN
will be coming before the fall
</figure>
<figureCaption confidence="0.999785">
Figure 6: Crossing Due to Modal
</figureCaption>
<bodyText confidence="0.999914222222222">
Adverbs are a third common cause, as they typ-
ically follow the verb in French while preceding it
in English. Figure 7 shows an example where the
span of “simplement” overlaps with the span of the
verb phrase beginning with “tells” (indicated by the
solid lines). Unlike negation and modals, this case
is far less regular. It arises from six different syntac-
tic constructions and two of those constructions are
implicated in other types of crossings as well.
</bodyText>
<figureCaption confidence="0.950992">
Figure 8: Verb Phrase Flattening
</figureCaption>
<table confidence="0.999053">
Alignment Type S S P P
Baseline 0.172 2.772 2.492
Flattened VPs 0.136 2.252 1.91
Dependencies 0.078 1.88 1.476
</table>
<tableCaption confidence="0.746255">
Table 4: Average Head Crossings per Sentence
(Phrasal Filter On)
</tableCaption>
<table confidence="0.999829">
Alignment Type S S P P
Baseline 0.78% 8.47% 5.94%
Flattened VPs 0.73% 10.59% 8.55%
Dependencies 0.61% 9.22% 7.62%
</table>
<tableCaption confidence="0.6404945">
Table 7: Percent Modifier Crossings per Chance
(Phrasal Filter On)
</tableCaption>
<table confidence="0.999836">
Alignment Type S S P P
Baseline 0.048 0.516 0.362
Flattened VPs 0.06 0.86 0.694
Dependencies 0.1 1.498 1.238
</table>
<tableCaption confidence="0.9162205">
Table 5: Average Modifier Crossings per Sentence
(Phrasal Filter On)
</tableCaption>
<bodyText confidence="0.999844684210527">
Flattening reduces the number of potential head
crossings while increasing the number of potential
modifier crossings. Therefore, we would expect to
see a comparable change to the number of cross-
ings measured, and this is exactly what we find, as
shown in Tables 4 and 5. For example, for S P
alignments, the average number of head crossings
decreases from 2.772 to 2.252, while the average
number of modifier crossings increases from 0.516
to 0.86. We see similar behavior when we look at the
percentage of crossings per chance (Tables 6 and 7).
For the same alignment type, the percentage of head
crossings decreases from 18.61% to 15.12%, while
the percentage of modifier crossings increases from
8.47% to 10.59%. One thing to note, however, is that
the total number of crossings of both types detected
in the corpus decreases as compared to the baseline,
and thus the benefits to head crossings outweigh the
detriments to modifier crossings.
</bodyText>
<table confidence="0.99480575">
Alignment Type S S P P
Baseline 1.15% 18.61% 16.73%
Flattened VPs 0.91% 15.12% 12.82%
Dependencies 0.52% 12.62% 9.91%
</table>
<tableCaption confidence="0.8614345">
Table 6: Percent Head Crossings per Chance
(Phrasal Filter On)
</tableCaption>
<subsectionHeader confidence="0.981615">
6.2 Dependencies
</subsectionHeader>
<bodyText confidence="0.999971">
Our intuitions about the cohesion of syntactic struc-
tures follow from the notion that translation, as a
meaning-preserving operation, preserves the depen-
dencies between words, and that syntactic structures
encode these dependencies. Therefore, dependency
structures should cohere as well as, or better than,
their corresponding syntactic structures. To exam-
ine the validity of this, we extracted dependency
structures from the parse trees (with flattened verb
phrases) and calculated crossings for them. Figure 9
shows a parse tree and its corresponding dependency
structure.
The procedure for counting modifier crossings in
a dependency structure is identical to the procedure
for parse trees. For head crossings, the only differ-
ence is that rather than comparing spans of two sib-
lings, we compare the spans of a child and its parent.
</bodyText>
<figureCaption confidence="0.995329">
Figure 9: Extracting Dependencies
</figureCaption>
<bodyText confidence="0.999974272727273">
Again focusing on the S P alignment case, we
see that the average number of head crossings (see
Table 4) continues to decrease compared to the pre-
vious case (from 2.252 to 1.88), and that the aver-
age number of modifier crossings (see Table 5) con-
tinues to increase (from 0.86 to 1.498). This time,
however, the percentages for both types of crossings
(see Tables 6 and 7) decrease relative to the case
of flattened verb phrases (from 15.12% to 12.62%
for heads and from 10.59% to 9.22% for modifiers).
The percentage of modifier crossings is still higher
</bodyText>
<figure confidence="0.981382333333333">
the
will be coming before the fall
VP
MD AUX VBG IN DT NN
coming
will be before
fall
PP
NP
</figure>
<bodyText confidence="0.954243571428571">
than in the base case (9.22% vs. 8.47%). Overall,
however, the dependency representation has the best
cohesion properties.
ernment.
We would like to thank Franz Och for providing
us with the manually annotated data used in these
experiments.
</bodyText>
<sectionHeader confidence="0.99948" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999948125">
We have examined the issue of phrasal cohesion be-
tween English and French and discovered that while
there is less cohesion than we might desire, there is
still a large amount of regularity in the constructions
where breakdowns occur. This reassures us that re-
ordering words by phrasal movement is a reasonable
strategy. Many of the initially daunting number of
crossings were due to non-linguistic reasons, such
as rewording during translation or errors in syntactic
analysis. Among the rest, there are a small number
of syntactic constructions which result in the major-
ity of the crossings examined in our analysis. One
practical result of this skewed distribution is that
one could hope to discover the major problem ar-
eas for a new language pair by manually aligning a
small number of sentences. This information could
be used to filter a training corpus to remove sen-
tences which would cause problems in training the
translation model, or for identifying areas to focus
on when working to improve the model itself. We
are interested in examining different language pairs
as the opportunity arises.
We have also examined the differences in cohe-
sion between Treebank-style parse trees, trees with
flattened verb phrases, and dependency structures.
Our results indicate that the highest degree of co-
hesion is present in dependency structures. There-
fore, in an SMT system which is using some type
of phrasal movement during reordering, dependency
structures should produce better results than raw
parse trees. In the future, we plan to explore this
hypothesis in an actual translation system.
</bodyText>
<sectionHeader confidence="0.999199" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999511125">
The work reported here was supported in part by the
Defense Advanced Research Projects Agency under
contract number N66001-00-C-8008. The views and
conclusions contained in this document are those of
the author and should not be interpreted as neces-
sarily representing the official policies, either ex-
pressed or implied, of the Defense Advanced Re-
search Projects Agency or the United States Gov-
</bodyText>
<sectionHeader confidence="0.999162" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999372975609756">
Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.
2000. Learning dependency translation models as col-
lections of finite-state head transducers. Computa-
tional Linguistics, 26(1):45–60, March.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The math-
ematics of machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311, June.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st Meeting of the North
American Chapter of the Association for Computa-
tional Linguistics.
Douglas Jones and Rick Havrilla. 1998. Twisted pair
grammar: Support for rapid development of machine
translation for low density languages. In Proceed-
ings of the Conference of the Association for Machine
Translation in the Americas.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English: The Penn Treebank. Computational
Linguistics, 13(2):313–330, June.
Franz Josef Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics, pages 440–447.
Ye-Yi Wang. 1998. Grammar Inference and Statistical
Machine Translation. Ph.D. thesis, Carnegie Mellon
University.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403, Septem-
ber.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proceedings of the
39th Annual Meeting of the Association for Compu-
tational Linguistics.
David Yarowsky, Grace Ngai, and Richard Wicentowski.
2001. Inducing multilingual text analysis tools via ro-
bust projection across aligned corpora. In Proceedings
of the ARPA Human Language Technology Workshop,
pages 109–116.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.502285">
<note confidence="0.915386">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Philadelphia, July 2002, pp. 304-311. Association for Computational Linguistics.</note>
<title confidence="0.994924">Phrasal Cohesion and Statistical Machine Translation</title>
<author confidence="0.99996">J Heidi</author>
<affiliation confidence="0.893998">Brown Laboratory for Linguistic Information Department of Computer Brown University, Box 1910, Providence, RI</affiliation>
<email confidence="0.997104">hjf@cs.brown.edu</email>
<abstract confidence="0.9987654">There has been much interest in using phrasal movement to improve statistical machine translation. We explore how well phrases cohere across two languages, specifically English and French, and examine the particular conditions under which they do not. We demonstrate that while there are cases where coherence is poor, there are many regularities which can be exploited by a statistical machine translation system. We also compare three variant syntactic representations to determine which one has the best properties with respect to cohesion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>Srinivas Bangalore</author>
<author>Shona Douglas</author>
</authors>
<title>Learning dependency translation models as collections of finite-state head transducers.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="2728" citStr="Alshawi et al., 2000" startWordPosition="415" endWordPosition="418"> tend to stay together (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face. The particulars of cohesion will clearly depend upon the pair of languages being compared. Intuitively, we expect that while French and Spanish will have a high degree of cohesion, French and Japanese may not. It is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for</context>
</contexts>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas. 2000. Learning dependency translation models as collections of finite-state head transducers. Computational Linguistics, 26(1):45–60, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1187" citStr="Brown et al., 1993" startWordPosition="171" endWordPosition="174">English and French, and examine the particular conditions under which they do not. We demonstrate that while there are cases where coherence is poor, there are many regularities which can be exploited by a statistical machine translation system. We also compare three variant syntactic representations to determine which one has the best properties with respect to cohesion. 1 Introduction Statistical machine translation (SMT) seeks to develop mathematical models of the translation process whose parameters can be automatically estimated from a parallel corpus. The first work in SMT, done at IBM (Brown et al., 1993), developed a noisy-channel model, factoring the translation process into two portions: the translation model and the language model. The translation model captures the translation of source language words into the target language and the reordering of those words. The language model ranks the outputs of the translation model by how well they adhere to the syntactic constraints of the target language.1 The prime deficiency of the IBM model is the reordering component. Even in the most complex of &apos;Though usually a simple word n-gram model is used for the language model. the five IBM models, the</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6271" citStr="Charniak, 2000" startWordPosition="1053" endWordPosition="1054">Example with Crossing biguous while P alignments are those which are less certain. P alignments often appear when a phrase in one language translates as a unit into a phrase in the other language (e.g. idioms, free translations, missing function words) but can also be the result of genuine ambiguity. When two annotators disagree, the union of the P alignments produced by each annotator is recorded as the P alignment in the corpus. When an S alignment exists, there will always also exist a P alignment such that P S. The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al., 1993). 3.2 Phrasal Translation Filtering je invoque le R`eglement Figure 2: Phrasal Translation Example Since P alignments often align phrasal translaNP NP NP VP PP NP PP PRP VBP IN DT NN IN NN S I rise on a point of order Alignment Type Phrasal Filter Off Phrasal Filter On S S P P S S P P Head Crossings 0.236 4.790 5.284 0.172 2.772 2.492 Modifier Crossings 0.056 0.880 0.988 0.048 0.516 0.362 Phrasal Translations – – – 0.072 2.382 3.418 Table 1: Average Number of Crossings per Sentence tions, the number of crossings when P al</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Jones</author>
<author>Rick Havrilla</author>
</authors>
<title>Twisted pair grammar: Support for rapid development of machine translation for low density languages.</title>
<date>1998</date>
<booktitle>In Proceedings of the Conference of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="2780" citStr="Jones and Havrilla, 1998" startWordPosition="423" endWordPosition="426">nslation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face. The particulars of cohesion will clearly depend upon the pair of languages being compared. Intuitively, we expect that while French and Spanish will have a high degree of cohesion, French and Japanese may not. It is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for these methods when applied to distantly related lan</context>
</contexts>
<marker>Jones, Havrilla, 1998</marker>
<rawString>Douglas Jones and Rick Havrilla. 1998. Twisted pair grammar: Support for rapid development of machine translation for low density languages. In Proceedings of the Conference of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="6344" citStr="Marcus et al., 1993" startWordPosition="1062" endWordPosition="1065"> less certain. P alignments often appear when a phrase in one language translates as a unit into a phrase in the other language (e.g. idioms, free translations, missing function words) but can also be the result of genuine ambiguity. When two annotators disagree, the union of the P alignments produced by each annotator is recorded as the P alignment in the corpus. When an S alignment exists, there will always also exist a P alignment such that P S. The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al., 1993). 3.2 Phrasal Translation Filtering je invoque le R`eglement Figure 2: Phrasal Translation Example Since P alignments often align phrasal translaNP NP NP VP PP NP PP PRP VBP IN DT NN IN NN S I rise on a point of order Alignment Type Phrasal Filter Off Phrasal Filter On S S P P S S P P Head Crossings 0.236 4.790 5.284 0.172 2.772 2.492 Modifier Crossings 0.056 0.880 0.988 0.048 0.516 0.362 Phrasal Translations – – – 0.072 2.382 3.418 Table 1: Average Number of Crossings per Sentence tions, the number of crossings when P alignments are used will be artificially inflated. For example, in Figure 2</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 13(2):313–330, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="5285" citStr="Och and Ney, 2000" startWordPosition="871" endWordPosition="874">]. The main English verb “change” is aligned to the French “modifie” and has a span of [2,2]. The two spans overlap and thus there is a crossing. This definition is asymmetric (i.e. what is a crossing when moving from English to French is not guaranteed to be a crossing when moving from French to English). However, we only pursue translation direction since that is the one for which we have parsed data. 3 Experiments 3.1 Data To calculate spans, we need aligned pairs of English and French sentences along with parses for the English sentences. Our aligned data comes from a corpus described in (Och and Ney, 2000) which contains 500 sentence pairs randomly selected from the Canadian Hansard corpus and manually aligned. The alignments are of two types: sure (S) and possible (P). S alignments are those which are unamS VP VP NP ADVP NP PRP AUX RB RB VB DT NN . they do not really change the status . on [ne [modifie] .pas vraiment la situation . 0 1 2ge3 4 5 6 7 Figure 1: Alignment Example with Crossing biguous while P alignments are those which are less certain. P alignments often appear when a phrase in one language translates as a unit into a phrase in the other language (e.g. idioms, free translations, </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-Yi Wang</author>
</authors>
<title>Grammar Inference and Statistical Machine Translation.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="2706" citStr="Wang, 1998" startWordPosition="413" endWordPosition="414">one language tend to stay together (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face. The particulars of cohesion will clearly depend upon the pair of languages being compared. Intuitively, we expect that while French and Spanish will have a high degree of cohesion, French and Japanese may not. It is also clear that if the cohesion between two closely related languages is not high enough to be useful, the</context>
</contexts>
<marker>Wang, 1998</marker>
<rawString>Ye-Yi Wang. 1998. Grammar Inference and Statistical Machine Translation. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="2694" citStr="Wu, 1997" startWordPosition="411" endWordPosition="412">hrases in one language tend to stay together (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face. The particulars of cohesion will clearly depend upon the pair of languages being compared. Intuitively, we expect that while French and Spanish will have a high degree of cohesion, French and Japanese may not. It is also clear that if the cohesion between two closely related languages is not high enough to be</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2753" citStr="Yamada and Knight, 2001" startWordPosition="419" endWordPosition="422"> (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across languages, we cannot know how far these models can take us and what specific pitfalls they face. The particulars of cohesion will clearly depend upon the pair of languages being compared. Intuitively, we expect that while French and Spanish will have a high degree of cohesion, French and Japanese may not. It is also clear that if the cohesion between two closely related languages is not high enough to be useful, then there is no hope for these methods when appli</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop,</booktitle>
<pages>109--116</pages>
<contexts>
<context position="2295" citStr="Yarowsky et al., 2001" startWordPosition="347" endWordPosition="350">ost complex of &apos;Though usually a simple word n-gram model is used for the language model. the five IBM models, the reordering operation pays little attention to context and none at all to higherlevel syntactic structures. Many attempts have been made to remedy this by incorporating syntactic information into translation models. These have taken several different forms, but all share the basic assumption that phrases in one language tend to stay together (i.e. cohere) during translation and thus the word-reordering operation can move entire phrases, rather than moving each word independently. (Yarowsky et al., 2001) states that during their work on noun phrase bracketing they found a strong cohesion among noun phrases, even when comparing English to Czech, a relatively free word order language. Other than this, there is little in the SMT literature to validate the coherence assumption. Several studies have reported alignment or translation performance for syntactically augmented translation models (Wu, 1997; Wang, 1998; Alshawi et al., 2000; Yamada and Knight, 2001; Jones and Havrilla, 1998) and these results have been promising. However, without a focused study of the behavior of phrases across language</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the ARPA Human Language Technology Workshop, pages 109–116.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>