<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.052192">
<title confidence="0.997382">
Active Learning with Confidence
</title>
<author confidence="0.995639">
Mark Dredze and Koby Crammer
</author>
<affiliation confidence="0.9985765">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.881725">
Philadelphia, PA 19104
</address>
<email confidence="0.999768">
{mdredze,crammer}@cis.upenn.edu
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999560909090909">
Active learning is a machine learning ap-
proach to achieving high-accuracy with a
small amount of labels by letting the learn-
ing algorithm choose instances to be labeled.
Most of previous approaches based on dis-
criminative learning use the margin for choos-
ing instances. We present a method for in-
corporating confidence into the margin by us-
ing a newly introduced online learning algo-
rithm and show empirically that confidence
improves active learning.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999783714285714">
Successful applications of supervised machine
learning to natural language rely on quality labeled
training data, but annotation can be costly, slow and
difficult. One popular solution is Active Learning,
which maximizes learning accuracy while minimiz-
ing labeling efforts. In active learning, the learning
algorithm itself selects unlabeled examples for anno-
tation. A variety of techniques have been proposed
for selecting examples that maximize system perfor-
mance as compared to selecting instances randomly.
Two learning methodologies dominate NLP ap-
plications: probabilistic methods — naive Bayes,
logistic regression — and margin methods — sup-
port vector machines and passive-aggressive. Active
learning for probabilistic methods often uses uncer-
tainty sampling: label the example with the lowest
probability prediction (the most “uncertain”) (Lewis
and Gale, 1994). The equivalent technique for mar-
gin learning associates the margin with prediction
certainty: label the example with the lowest margin
(Tong and Koller, 2001). Common intuition equates
large margins with high prediction confidence.
However, confidence and margin are two distinct
properties. For example, an instance may receive
a large margin based on a single feature which has
been updated only a small number of times. Another
example may receive a small margin, but its features
have been learned from a large number of examples.
While the first example has a larger margin it has
low confidence compared to the second. Both the
margin value and confidence should be considered
in choosing which example to label.
We present active learning with confidence us-
ing a recently introduced online learning algo-
rithm called Confidence-Weighted linear classifica-
tion. The classifier assigns labels according to a
Gaussian distribution over margin values instead of
a single value, which arises from parameter confi-
dence (variance). The variance of this distribution
represents the confidence in the mean (margin). We
then employ this distribution for a new active learn-
ing criteria, which in turn could improve other mar-
gin based active learning techniques. Additionally,
we favor the use of an online method since online
methods have achieved good NLP performance and
are fast to train — an important property for inter-
active learning. Experimental validation on a num-
ber of datasets shows that active learning with con-
fidence can improve standard methods.
</bodyText>
<sectionHeader confidence="0.934919" genericHeader="method">
2 Confidence-Weighted Linear Classifiers
</sectionHeader>
<bodyText confidence="0.994726333333333">
Common online learning algorithms, popular in
many NLP tasks, are not designed to deal with
the particularities of natural language data. Fea-
</bodyText>
<page confidence="0.987305">
233
</page>
<reference confidence="0.2219905">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 233–236,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.998047886363636">
ture representations have very high dimension and
most features are observed on a small fraction of in-
stances. Confidence-weighted (CW) linear classifi-
cation (Dredze et al., 2008), a new online algorithm,
maintains a probabilistic measure of parameter con-
fidence leading to a measure of prediction confi-
dence, potentially useful for active learning. We
summarize CW learning to familiarize the reader.
Parameter confidence is formalized with a distri-
bution over weight vectors, specifically a Gaussian
distribution with mean µ ∈ RN and diagonal co-
variance E ∈ RN,N. The values µj and Ej,j repre-
sent knowledge of and confidence in the parameter
for feature j. The smaller Ej,j, the more confidence
we have in the mean parameter value µj.
A model predicts the label with the highest prob-
ability, maxyE{f1} PrwN N(µ,E) [y(w · x) ≥ 0] .
The Gaussian distribution over parameter vectors w
induces a univariate Gaussian distribution over the
unsigned-margin M = w · x parameterized by µ,
E and the instance x: M ∼ N (M, V ), where the
mean is M = µ · x and the variance V = xTEx.
CW is an online algorithm inspired by the Passive
Aggressive (PA) update (Crammer et al., 2006) —
which ensures a positive margin while minimizing
parameter change. CW replaces the Euclidean dis-
tance used in the PA update with the KL divergence
over Gaussian distributions. It also replaces the min-
imal margin constraint with a minimal probability
constraint: with some given probability η ∈ (0.5,1]
a drawn classifier will assign the correct label. This
strategy yields the following objective solved on
each round of learning:
(µi+1, Ei+1) = min DKL (N (µ, E) kN (µi, Ei))
s.t. Pr [yi (µ · xi) ≥ 0] ≥ η ,
where (µi, Ei) are the parameters on round i and
(µi+1, Ei+1) are the new parameters after update.
The constraint ensures that the resulting parameters
will correctly classify xi with probability at least η.
For convenience we write φ = 4b−1 (η), where 4b is
the cumulative function of the normal distribution.
The optimization problem above is not convex, but
a closed form approximation of its solution has the
following additive form: µi+1 = µi +αiyiEixi and
</bodyText>
<equation confidence="0.937086666666667">
E−1
i+1 = E−1
i + 2αiφxixz for,
�−(1+2φMi)+ (1+2φMi)2−8φ (Mi−φVi)
.
4φVi
</equation>
<bodyText confidence="0.999003">
Each update changes the feature weights µ, and in-
creases confidence (variance E always decreases).
</bodyText>
<sectionHeader confidence="0.996285" genericHeader="method">
3 Active Learning with Confidence
</sectionHeader>
<bodyText confidence="0.996309315789474">
We consider pool based active learning. An active
learning algorithm is given a pool of unlabeled in-
stances U = {xi}Z1, a learning algorithm A and a
set of labeled examples initially set to be L = ∅ . On
each round the active learner uses its selection crite-
ria to return a single instance xi to be labeled by an
annotator with yi ∈ {−1, +1} (for binary classifica-
tion). The instance and label are added to the labeled
set L ← L ∪ {(xi, yi)} and passed to the learning
algorithm A, which in turn generates a new model.
At the end of labeling the algorithm returns a classi-
fier trained on the final labeled set. Effective active
learning minimizes prediction error and the number
of labeled examples.
Most active learners for margin based algorithms
rely on the magnitude of the margin. Tong and
Koller (2001) motivate this approach by consider-
ing the half-space representation of the hypothesis
space for learning. They suggest three margin based
active learning methods: Simple margin, MaxMin
margin, and Ratio margin. In Simple margin, the al-
gorithm predicts an unsigned margin M for each in-
stance in U and returns for labeling the instance with
the smallest margin. The intuition is that instances
for which the classifier is uncertain (small margin)
provide the most information for learning. Active
learning based on PA algorithms runs in a similar
fashion but full SVM retraining on every round is
replaced with a single PA update using the new la-
beled example, greatly increasing learning speed.
Maintaining a distribution over prediction func-
tions makes the CW algorithm attractive for ac-
tive learning. Instead of using a geometrical
quantity (“margin”), it use a probabilistic quan-
tity and picks the example whose label is pre-
dicted with the lowest probability. Formally,
the margin criteria, x = argminzEU(w · z),
is replaced with a probabilistic criteria x =
</bodyText>
<equation confidence="0.8536345">
argminxEU  |(Prw_Ar({b:,E:) [sign(w · z) = 1]) − 1� |.
αi =
</equation>
<page confidence="0.98721">
234
</page>
<bodyText confidence="0.940504666666667">
The selection criteria naturally captures the notion
that we should label the example with the highest
uncertainty. Interestingly, we can show (omitted due
to lack of space) that the probabilistic criteria can be
translated into a corrected geometrical criteria. In
practice, we can compute this normalized margin as
�
M� = M/ V . We call this selection criteria Active
Confident Learning (ACL).
</bodyText>
<sectionHeader confidence="0.998574" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999919861111111">
To evaluate our active learning methods we used
a similar experimental setup to Tong and Koller
(2001). Each active learning algorithm was given
two labeled examples, one from each class, for ini-
tial training of a classifier, and remaining data as un-
labeled examples. On each round the algorithm se-
lected a single instance for which it was then given
the correct label. The algorithm updated the online
classifier and evaluated it on held out test data to
measure learning progress.
We selected four binary NLP datasets for evalu-
ation: 20 Newsgroups1 and Reuters (Lewis et al.,
2004) (used by Tong and Koller) and sentiment clas-
sification (Blitzer et al., 2007) and spam (Bickel,
2006). For each dataset we extracted binary uni-
gram features and sentiment was prepared accord-
ing to Blitzer et al. (2007). From 20 Newsgroups
we created 3 binary decision tasks to differentiate
between two similar labels from computers, sci-
ence and talk. We created 3 similar problems from
Reuters from insurance, business services and re-
tail distribution. Sentiment used 4 Amazon domains
(book, dvd, electronics, kitchen). Spam used the
three users from task A data. Each problem had
2000 instances except for 20 Newsgroups, which
used between 1850 and 1971 instances. This created
13 classification problems across four tasks.
Each active learning algorithm was evaluated us-
ing a PA (with slack variable c = 1) or CW classifier
(0 = 1) using 10-fold cross validation. We eval-
uated several methods in the Simple margin frame-
work: PA Margin and CW Margin, which select ex-
amples with the smallest margin, and ACL. As a
baseline we included selecting a random instance.
We also evaluated CW and a PA classifier trained on
all training instances. Each method was evaluated by
</bodyText>
<footnote confidence="0.924279">
1http://people.csail.mit.edu/jrennie/20Newsgroups/
</footnote>
<bodyText confidence="0.999843055555556">
labeling up to 500 labels, about 25% of the training
data. The 10 runs on each dataset for each problem
appear in the left and middle panel of Fig. 1, which
show the test accuracy after each round of active
learning. Horizontal lines indicate CW (solid) and
PA (dashed) training on all instances. Legend num-
bers are accuracy after 500 labels. The left panel av-
erages results over 20 Newsgroups, and the middle
panel averages results over all 13 datasets.
To achieve 80% of the accuracy of training on all
data, a realistic goal for less than 100 labels, PA
Margin required 93% the number of labels of PA
Random, while CW Margin needed only 73% of
the labels of CW Random. By using fewer labels
compared to random selection baselines, CW Mar-
gin learns faster in the active learning setting as com-
pared with PA. Furthermore, adding confidence re-
duced labeling cost compared to margin alone. ACL
improved over CW Margin on every task and after
almost every round; it required 63% of the labels of
CW Random to reach the 80% mark.
We computed the fraction of labels CW Margin
and ACL required (compared to CW Random) to
achieve the 80% accuracy mark of training with all
data. The results are summarized in the right panel
of Fig. 1, where we plot one point per dataset. Points
above the diagonal-line demonstrate the superiority
of ACL over CW Margin. ACL required fewer la-
bels than CW margin twice as often as the opposite
occurred (8 vs 4). Note that CW Margin used more
labels than CW Random in three cases, while ACL
only once, and this one time only about a dozen la-
bels were needed. To conclude, not only does CW
Margin outperforms PA Margin for active-learning,
CW maintains additional valuable information (con-
fidence), which further improves performance.
</bodyText>
<sectionHeader confidence="0.999925" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999752222222222">
Active learning has been widely used for NLP tasks
such as part of speech tagging (Ringger et al., 2007),
parsing (Tang et al., 2002) and word sense disam-
biguation (Chan and Ng, 2007). Many methods rely
on entropy-based scores such as uncertainty sam-
pling (Lewis and Gale, 1994). Others use margin
based methods, such as Kim et al. (2006), who com-
bined margin scores with corpus diversity, and Sas-
sano (2002), who considered SVM active learning
</bodyText>
<page confidence="0.998083">
235
</page>
<figureCaption confidence="0.988158666666667">
Figure 1: Results averaged over 20 Newsgroups (left) and all datasets (center) showing test accuracy over active
learning rounds. The right panel shows the amount of labels needed by CW Margin and ACL to achieve 80% of the
accuracy of training on all data - each points refers to a different dataset.
</figureCaption>
<figure confidence="0.99881056097561">
20 Newsgroups All
100 150 200 250 300 350 400 450 500
Labels
100 150 200 250 300 350 400 450 500
Labels
Test Accuracy
0.90
0.80
0.85
0.75
PA Random (81.30)
CW Random (86.67)
PA Margin (83.99)
CW Margin (88.61)
ACL (88.79)
Test Accuracy
0.90
0.80
0.70
0.95
0.85
0.75
0.65
PA Random (82.53)
CW Random (92.92)
PA Margin (88.06)
CW Margin (95.39)
ACL (95.51)
CW Margin Labels
0.8
0.6
0.4
0.20.2 0.4 0.6 0.8 1.0 1.2 1.4
ACL Labels
1.4
1.2
1.0
Reuters
20 Newsgroups
Sentiment
Spam
</figure>
<bodyText confidence="0.998647133333333">
for Japanese word segmentation. Our confidence
based approach can be used to improve these tasks.
Furthermore, margin methods can outperform prob-
abilistic methods; CW beats maximum entropy on
many NLP tasks (Dredze et al., 2008).
A theoretical analysis of margin based methods
selected labels that maximize the reduction of the
version space, the hypothesis set consistent with the
training data (Tong and Koller, 2001). Another ap-
proach selects instances that minimize the future er-
ror in probabilistic algorithms (Roy and McCallum,
2001). Since we consider an online learning algo-
rithm our techniques can be easily extended to on-
line active learning (Cesa-Bianchi et al., 2005; Das-
gupta et al., 2005; Sculley, 2007).
</bodyText>
<sectionHeader confidence="0.99954" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999906333333333">
We have presented techniques for incorporating con-
fidence into the margin for active learning and have
shown that CW selects better examples than PA, a
popular online algorithm. This approach creates op-
portunities for new active learning frameworks that
depend on margin confidence.
</bodyText>
<sectionHeader confidence="0.999645" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9989396">
S. Bickel. 2006. Ecml-pkdd discovery challenge
overview. In The Discovery Challenge Workshop.
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies,
bollywood, boom-boxes and blenders: Domain adap-
tation for sentiment classification. In ACL.
Nicol`o Cesa-Bianchi, G´abor Lugosi, and Gilles Stolt.
2005. Minimizing regret with label efficient predic-
tion. IEEE Tran. on Inf. Theory, 51(6), June.
Y. S. Chan and H. T. Ng. 2007. Domain adaptation with
active learning for word sense disambiguation. In As-
sociation for Computational Linguistics (ACL).
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. JMLR, 7:551–585.
S. Dasgupta, A.T. Kalai, and C. Monteleoni. 2005. Anal-
ysis of perceptron-based active learning. In COLT.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
ICML.
S. Kim, Yu S., K. Kim, J-W Cha, and G.G. Lee. 2006.
Mmr-based active machine learning for bio named en-
tity recognition. In NAACL/HLT.
D. D. Lewis and W. A. Gale. 1994. A sequential algo-
rithm for training text classifiers. In SIGIR.
D. D. Lewis, Y. Yand, T. Rose, and F. Li. 2004. Rcv1:
A new benchmark collection for text categorization re-
search. JMLR, 5:361–397.
E. Ringger, P. McClanahan, R. Haertel, G. Busby,
M. Carmen, J. Carroll, K. Seppi, and D. Lonsdale.
2007. Active learning for part-of-speech tagging: Ac-
celerating corpus annotation. In ACL Linguistic Anno-
tation Workshop.
N. Roy and A. McCallum. 2001. Toward optimal active
learning through sampling estimation of error reduc-
tion. In ICML.
Manabu Sassano. 2002. An empirical study of active
learning with support vector machines for japanese
word segmentation. In ACL.
D. Sculley. 2007. Online active learning methods for fast
label-efficient spam filtering. In CEAS.
M. Tang, X. Luo, and S. Roukos. 2002. Active learning
for statistical natural language parsing. In ACL.
S. Tong and D. Koller. 2001. Supprt vector machine
active learning with applications to text classification.
JMLR.
</reference>
<page confidence="0.998529">
236
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.951261">
<title confidence="0.994375">Active Learning with Confidence</title>
<author confidence="0.964096">Dredze Crammer</author>
<affiliation confidence="0.9998965">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999626">Philadelphia, PA 19104</address>
<abstract confidence="0.9990955">Active learning is a machine learning approach to achieving high-accuracy with a small amount of labels by letting the learning algorithm choose instances to be labeled. Most of previous approaches based on discriminative learning use the margin for choosing instances. We present a method for incorporating confidence into the margin by using a newly introduced online learning algorithm and show empirically that confidence improves active learning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>233--236</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 233–236,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bickel</author>
</authors>
<title>Ecml-pkdd discovery challenge overview.</title>
<date>2006</date>
<booktitle>In The Discovery Challenge Workshop.</booktitle>
<marker>Bickel, 2006</marker>
<rawString>S. Bickel. 2006. Ecml-pkdd discovery challenge overview. In The Discovery Challenge Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicol`o Cesa-Bianchi</author>
<author>G´abor Lugosi</author>
<author>Gilles Stolt</author>
</authors>
<title>Minimizing regret with label efficient prediction.</title>
<date>2005</date>
<journal>IEEE Tran. on Inf. Theory,</journal>
<volume>51</volume>
<issue>6</issue>
<marker>Cesa-Bianchi, Lugosi, Stolt, 2005</marker>
<rawString>Nicol`o Cesa-Bianchi, G´abor Lugosi, and Gilles Stolt. 2005. Minimizing regret with label efficient prediction. IEEE Tran. on Inf. Theory, 51(6), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
</authors>
<title>Domain adaptation with active learning for word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<marker>Chan, Ng, 2007</marker>
<rawString>Y. S. Chan and H. T. Ng. 2007. Domain adaptation with active learning for word sense disambiguation. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>O Dekel</author>
<author>J Keshet</author>
<author>S Shalev-Shwartz</author>
<author>Y Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>JMLR,</journal>
<pages>7--551</pages>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. 2006. Online passive-aggressive algorithms. JMLR, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>A T Kalai</author>
<author>C Monteleoni</author>
</authors>
<title>Analysis of perceptron-based active learning.</title>
<date>2005</date>
<booktitle>In COLT.</booktitle>
<marker>Dasgupta, Kalai, Monteleoni, 2005</marker>
<rawString>S. Dasgupta, A.T. Kalai, and C. Monteleoni. 2005. Analysis of perceptron-based active learning. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>S Yu</author>
<author>K Kim</author>
<author>J-W Cha</author>
<author>G G Lee</author>
</authors>
<title>Mmr-based active machine learning for bio named entity recognition.</title>
<date>2006</date>
<booktitle>In NAACL/HLT.</booktitle>
<marker>Kim, Yu, Kim, Cha, Lee, 2006</marker>
<rawString>S. Kim, Yu S., K. Kim, J-W Cha, and G.G. Lee. 2006. Mmr-based active machine learning for bio named entity recognition. In NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
<author>W A Gale</author>
</authors>
<title>A sequential algorithm for training text classifiers.</title>
<date>1994</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="1536" citStr="Lewis and Gale, 1994" startWordPosition="216" endWordPosition="219">mizing labeling efforts. In active learning, the learning algorithm itself selects unlabeled examples for annotation. A variety of techniques have been proposed for selecting examples that maximize system performance as compared to selecting instances randomly. Two learning methodologies dominate NLP applications: probabilistic methods — naive Bayes, logistic regression — and margin methods — support vector machines and passive-aggressive. Active learning for probabilistic methods often uses uncertainty sampling: label the example with the lowest probability prediction (the most “uncertain”) (Lewis and Gale, 1994). The equivalent technique for margin learning associates the margin with prediction certainty: label the example with the lowest margin (Tong and Koller, 2001). Common intuition equates large margins with high prediction confidence. However, confidence and margin are two distinct properties. For example, an instance may receive a large margin based on a single feature which has been updated only a small number of times. Another example may receive a small margin, but its features have been learned from a large number of examples. While the first example has a larger margin it has low confiden</context>
</contexts>
<marker>Lewis, Gale, 1994</marker>
<rawString>D. D. Lewis and W. A. Gale. 1994. A sequential algorithm for training text classifiers. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
<author>Y Yand</author>
<author>T Rose</author>
<author>F Li</author>
</authors>
<title>Rcv1: A new benchmark collection for text categorization research.</title>
<date>2004</date>
<journal>JMLR,</journal>
<pages>5--361</pages>
<marker>Lewis, Yand, Rose, Li, 2004</marker>
<rawString>D. D. Lewis, Y. Yand, T. Rose, and F. Li. 2004. Rcv1: A new benchmark collection for text categorization research. JMLR, 5:361–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ringger</author>
<author>P McClanahan</author>
<author>R Haertel</author>
<author>G Busby</author>
<author>M Carmen</author>
<author>J Carroll</author>
<author>K Seppi</author>
<author>D Lonsdale</author>
</authors>
<title>Active learning for part-of-speech tagging: Accelerating corpus annotation.</title>
<date>2007</date>
<booktitle>In ACL Linguistic Annotation Workshop.</booktitle>
<marker>Ringger, McClanahan, Haertel, Busby, Carmen, Carroll, Seppi, Lonsdale, 2007</marker>
<rawString>E. Ringger, P. McClanahan, R. Haertel, G. Busby, M. Carmen, J. Carroll, K. Seppi, and D. Lonsdale. 2007. Active learning for part-of-speech tagging: Accelerating corpus annotation. In ACL Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>A McCallum</author>
</authors>
<title>Toward optimal active learning through sampling estimation of error reduction.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<marker>Roy, McCallum, 2001</marker>
<rawString>N. Roy and A. McCallum. 2001. Toward optimal active learning through sampling estimation of error reduction. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Sassano</author>
</authors>
<title>An empirical study of active learning with support vector machines for japanese word segmentation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<marker>Sassano, 2002</marker>
<rawString>Manabu Sassano. 2002. An empirical study of active learning with support vector machines for japanese word segmentation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sculley</author>
</authors>
<title>Online active learning methods for fast label-efficient spam filtering. In</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<marker>Sculley, 2007</marker>
<rawString>D. Sculley. 2007. Online active learning methods for fast label-efficient spam filtering. In CEAS. M. Tang, X. Luo, and S. Roukos. 2002. Active learning for statistical natural language parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tong</author>
<author>D Koller</author>
</authors>
<title>Supprt vector machine active learning with applications to text classification.</title>
<date>2001</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="1696" citStr="Tong and Koller, 2001" startWordPosition="240" endWordPosition="243">d for selecting examples that maximize system performance as compared to selecting instances randomly. Two learning methodologies dominate NLP applications: probabilistic methods — naive Bayes, logistic regression — and margin methods — support vector machines and passive-aggressive. Active learning for probabilistic methods often uses uncertainty sampling: label the example with the lowest probability prediction (the most “uncertain”) (Lewis and Gale, 1994). The equivalent technique for margin learning associates the margin with prediction certainty: label the example with the lowest margin (Tong and Koller, 2001). Common intuition equates large margins with high prediction confidence. However, confidence and margin are two distinct properties. For example, an instance may receive a large margin based on a single feature which has been updated only a small number of times. Another example may receive a small margin, but its features have been learned from a large number of examples. While the first example has a larger margin it has low confidence compared to the second. Both the margin value and confidence should be considered in choosing which example to label. We present active learning with confide</context>
</contexts>
<marker>Tong, Koller, 2001</marker>
<rawString>S. Tong and D. Koller. 2001. Supprt vector machine active learning with applications to text classification. JMLR.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>