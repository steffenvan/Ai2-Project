<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012859">
<title confidence="0.9904305">
Toward finer-grained sentiment identification in product reviews
through linguistic and ontological analyses
</title>
<author confidence="0.995299">
Hye-Jin Min
</author>
<affiliation confidence="0.991325">
Computer Science Department
</affiliation>
<address confidence="0.55732">
KAIST, Daejeon, KOREA
</address>
<email confidence="0.997766">
hjmin@nlp.kiast.ac.kr
</email>
<author confidence="0.972676">
Jong C. Park
</author>
<affiliation confidence="0.973952">
Computer Science Department
</affiliation>
<address confidence="0.552158">
KAIST, Daejeon, KOREA
</address>
<email confidence="0.997164">
park@nlp.kaist.ac.kr
</email>
<sectionHeader confidence="0.995615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916125">
We propose categories of finer-grained polari-
ty for a more effective aspect-based sentiment
summary, and describe linguistic and ontolog-
ical clues that may affect such fine-grained po-
larity. We argue that relevance for satisfaction,
contrastive weight clues, and certain adver-
bials work to affect the polarity, as evidenced
by the statistical analysis.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992334375">
Sentiment analysis have been widely conducted
in several domains such as movie reviews, prod-
uct reviews, news and blog reviews (Pang et al.,
2002; Turney, 2002). The unit of the sentiment
varies from a document level to a sentence level
to a phrase-level, where a more fine-grained ap-
proach has been receiving more attention for its
accuracy. Sentiment analysis on product reviews
identifies or summarizes sentiment from reviews
by extracting relevant opinions about certain
attributes of products such as their parts, or prop-
erties (Hu and Liu, 2004; Popescu and Etzioni,
2005). Aspect-based sentiment analysis summa-
rizes sentiments with diverse attributes, so that
customers may have to look more closely into
analyzed sentiments (Titov and McDonald,
2008). However, there are additional problems.
First, it is rather hard to choose the right level
of detail. If concepts corresponding to attributes
are too general, the level of detail may not be so
much finer than the ones on a document level.
On the other hand, if concepts are too specific,
there may be some attributes that are hardly men-
tioned in the reviews, resulting in the data
sparseness problem. Second, there are cases
when some crucial information is lost. For ex-
ample, suppose that two product attributes are
mentioned in a sentence with a coordinated or
subordinated structure. In this case, the informa-
tion about their relation may not be shown in the
summary if they are classified into different up-
per-level attributes. Consider (1).
</bodyText>
<equation confidence="0.428422166666667">
(1) a. Q° pcA1&apos;a/pc?1 !Nl, 111-01 1--1T
OlTTj$. osun macciman, sayksangi nemwu
etwuweyo. ‘It fits me okay, but the color is too
dark.’ (size: barely positive, color: negative)
b. -1�41V_v- p ?JA1&apos;a, IZ1011 rl -:� OJL
79Ll71 44 X11 °79 �aO}$. sayngkakpota
</equation>
<bodyText confidence="0.938008103448276">
com yalpciman, aney patchye ipnun kenikka
nalum kwaynchanhunke kathayo. ‘It’s a bit
thinner than I thought, but it is good enough
for layering.’ (thickness: negative but accepta-
ble, overall: positive)
Example (1) shows sample customer reviews
about clothes, each first in Korean, followed by a
Yale Romanized form, and an English translation.
Note that the weight of the polarity in the senti-
ment about size e.g. in (1a) is overcome by the
one about color. However, if the overall senti-
ment is computed by considering only the num-
ber of semantically identical phrases in the re-
views, it misses the big picture.
In particular, when opinions regarding
attributes are described with respect to expres-
sions whose polarities are dependent on the spe-
cific contexts such as the weather or user prefe-
rence, an overestimated or underestimated
weight of the sentiment for each attribute may be
assigned. In our example, ?Jv-/yalpta/‘thin’ has
an ambiguous polarity, i.e., either positive or
negative, whose real value depends on the ex-
pected utility of the clothes. In this case, the neg-
ative polarity is the intended one, as shown in
(1b). In order to reflect this possibility, we need
to adjust the weight of each polarity accordingly.
In this paper, we propose to look into the kind
of linguistic and ontological clues that may in-
</bodyText>
<page confidence="0.984244">
169
</page>
<note confidence="0.9259485">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 169–172,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999973095238095">
fluence the use of polarities, or the relevance for
‘satisfaction of purchase’ inspired by Kano’s
theory of quality element classification (Huisko-
nen and Pirttila, 1998), the conceptual granulari-
ties, and such syntactic and lexical clues as con-
junction items and adverbs. They may play sig-
nificant roles in putting together the identified
polarity information, so as to assess correctly
what the customers consider most important. We
conducted several one-way Analysis of Variance
(ANOVA) tests to identify the effects of each
clue on deriving categories of polarity and quan-
tification method 2 to see whether these clues
can distinguish fine-grained polarities correctly.
Section 2 introduces categories of polarity.
Section 3 analyzes ontological and linguistic
clues for identifying the proper category. Section
4 describes our method to extract such clues for a
statistical analysis. Section 5 discusses the results
of the analysis and implications of the results.
Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.46999" genericHeader="method">
2 Categories of polarity
</sectionHeader>
<bodyText confidence="0.9999245">
We suggest two more fine-grained categories of
polarity, or ‘barely positive’ (BP) and ‘accepta-
bly negative’ (AN), in addition to positive (P),
negative (N) and neutral (NEU). We distinguish
‘barely positive’ from normal positive and dis-
tinguish ‘acceptably negative’ from normal nega-
tive in order to derive finer-grained sentiments.
Wilson and colleagues (2006) identified the
strength of news articles in the MPQA corpus,
where they separated intensity (low, medium,
high) from categories (private states). For the
purpose of identifying each attribute’s contribu-
tion to the satisfaction after purchase, we believe
that it is not necessary to have so many degrees
of intensity. We argue that the polarity of ‘barely
positive’ may hold attributes that must be satis-
fied and that ‘acceptably negative’ may hold
those that are somewhat optional.
</bodyText>
<sectionHeader confidence="0.982047" genericHeader="method">
3 Linguistic and Ontological Analyses
</sectionHeader>
<bodyText confidence="0.999908166666667">
In this section, we discuss linguistic and ontolog-
ical clues that influence the process of identify-
ing finer-grained polarity. For the purpose of ex-
position, we build hierarchical and aspect-based
review structure as shown in Figure 1. Major
aspects include Price, Delivery, Service, and
Product. If we go down another level, Product is
divided into Quality and Comfortableness. In
defining relevant attributes, we consider all the
lower-level concepts of major aspects, which
contain the characteristics of the product with a
description of the associated sentiment.
</bodyText>
<figureCaption confidence="0.998075">
Figure 1. Review structure
</figureCaption>
<bodyText confidence="0.998751">
Relevance for Satisfaction: We consider re-
levant attributes that affect the quality and satis-
faction of the products as one of the important
clues. Quality elements classified by Kano as
shown in Table 1 can be base indicators of rele-
vant attributes for satisfaction in real review text.
For example, while completeness of the product
may become crucial if the product has a defect, it
is usually not the case that it would contribute
much to the overall satisfaction of the customer.
</bodyText>
<table confidence="0.99861075">
Quality Elements Example features
Must-be Quality (MQ) Durability, Completeness
1-dimension Quality (1DQ) Design, Color, Material
Attractive Quality (AQ) Luxurious look
</table>
<tableCaption confidence="0.999315">
Table 1. Kano&apos;s Quality Elements
</tableCaption>
<bodyText confidence="0.996501642857143">
Conceptual Granularity: The concepts cor-
responding to attributes have a different level of
detail. If the customer wants to comment on
some attributes in detail, she could use a fine-
grained concept (e.g., the width of the thigh part
of the pants) rather than a coarse-grained one
(e.g., just the size of the pants). To deal properly
with the changing granularity of such concepts,
we constructed a domain specific semi-
hierarchical network for clothes of the Clothing-
Type structure, in addition to the Review struc-
ture, by utilizing hierarchical category informa-
tion in online shopping malls. Figure 2 shows an
example for “pants”.
</bodyText>
<figure confidence="0.994240666666667">
Material+
Length+
Color
Design:
Line+
Design:
Style*
Design:
Pattern*
Design:
Detail*
Size
</figure>
<figureCaption confidence="0.99998">
Figure 2. ClothingType structure for pants
</figureCaption>
<bodyText confidence="0.9221705">
Syntactic and Lexical Clues: Descriptions of
each attribute in the reviews are often expressed
</bodyText>
<figure confidence="0.919847333333333">
Hip Waist Thigh Calf
Sub_p
Sub_f
Pants
Bottom
ClothingType
</figure>
<page confidence="0.9773">
170
</page>
<bodyText confidence="0.999899076923077">
in a phrase or clause, so that conjunctions, or
endings of a word with a conjunctive marker in
Korean, play a significant role in connecting one
attribute to another. They also convey a subtle
meaning of the sentiment about relations be-
tween two or more connected attributes. We
classified such syntactic clues into 4 groups of
likeness (L), contrary (C), cause-effect (CE), and
contrary with contrastive markers (CC).
Wilson and colleagues (2006) selected some
syntactic clues as features for intensity classifica-
tion. The selected features are shown to improve
the accuracy, but the set of clues may vary to the
nature of the given corpus, so that some other-
wise useful clues that reflect a particular focused
structure may not be selected. We argue that
some syntactic clues such as the use of certain
conjunctions can be identified manually to make
up for the limitation of feature selection.
Adverbs modifying adjectives or verbs such as
too, and very also strengthen the polarity of a
given sentiment, so such clues work to differen-
tiate normal positive or negative from ‘barely
positive’ and ‘acceptably negative’. Table 2
summarizes linguistic clues in the present analy-
sis.
</bodyText>
<table confidence="0.998109333333333">
Clues Examples
CONJ/ L -37- -ko ‘and’
END
C -AlR} -ciman ‘but’,
=el4 kulena ‘however’
CE -OlAi -ese ‘so’, =4Ai
kulayse ‘therefore’
CC -7,1 –AlR} -kin -ciman ‘It’s
..., ‘but’, ‘though’
ADV Strong pN-or maywu ‘very’,
l-1T nemwu ‘too’
Mild p com ‘a little’
</table>
<tableCaption confidence="0.999676">
Table 2. Syntactic and Lexical Clues
</tableCaption>
<bodyText confidence="0.999987958333333">
All these three types of clue that appear in the
review text may interact with one another. For
example, attributes with ‘barely positive’ tend to
be described with a concept on a coarse level,
and may belong to Must-be Quality (e,g., size in
(1a)). However, if such attributes are negative,
customers may explain them with a very fine-
grained concept (e.g., the width of thigh is okay,
but the calf part is too wide; interaction between
relevance for satisfaction and conceptual granu-
larity). They may also use adverbs such as ‘too’
to emphasize such unexpected polarity informa-
tion. For emphasis, a contrastive structure can be
used to indicate which attribute has a more
weight (e.g., ‘A but B’; interaction between syn-
tactic clues and relevance for satisfaction). In
addition, an unfocused attribute A may be the
attribute with ‘acceptably negative’ if the polari-
ty of the attribute B is positive. We believe that
the interaction between lexical and syntactic
clues and relevance for satisfaction are the most
important and that this correlation information
may be utilized with such fine-grained polarity
as ‘barely positive’ or ‘acceptably negative’.
</bodyText>
<sectionHeader confidence="0.980624" genericHeader="method">
4 Clue Acquisition
</sectionHeader>
<bodyText confidence="0.999992264705882">
We acquired data semi-automatically for each
clue from the extracted attributes and their de-
scriptions from 500 product reviews of several
types of pants and annotated polarities manually.
We obtained raw text reviews from one of the
major online shopping malls in Korea1 and per-
formed a morphology analysis and POS-tagging.
After POS-tagging, we collected all the noun
phrases as candidates of attributes. We regarded
some of them as attributes with the following
guidelines and filtered out the rest: 1) NP with
frequent adjectives 2) NP with frequent non-
functional and intransitive verbs. In the case of
subject omission, we converted adjectives or
verbs into their corresponding nouns, such as
‘thin’ into ‘thickness’. Hu and Liu (2004) identi-
fied attributes of IT products based on frequent
noun phrases and Popescu and Etzioni (2005)
utilized PMI values between product class (ho-
tels and scanners) and some phrases including
product. In our case, we used attributes that be-
long only to the Product concept in the Review
structure, because most attributes we consider
are sub-types or sub-attribute of Product. The
total number of &lt;attribute, polarity&gt; pairs is 474.
For relevance for satisfaction, we converted
extracted attributes into one of the types of Ka-
no’s quality elements by the mapping table we
built. For conceptual granularity we regarded all
the attributes with a depth less than 2 as ‘coarse’
and those more than 2 as ‘fine’. Syntactic and
lexical clues are identified from the context in-
formation around extracted adjective or verbs by
the patterns based on POS information.
</bodyText>
<sectionHeader confidence="0.574257" genericHeader="method">
5 Statistical Analysis and Discussion
</sectionHeader>
<bodyText confidence="0.999855166666667">
We conducted one-way Analysis of Variance
(ANOVA) tests using relevance for satisfaction
(ReV), conceptual granularity (Granul), and two
linguistic clues, ADV and CONJ/END, in order
to assess the effects of each clue on identifying
categories of polarity. The ANOVA suggests
</bodyText>
<footnote confidence="0.971294">
1 http://www.11st.co.kr
</footnote>
<page confidence="0.996885">
171
</page>
<bodyText confidence="0.993991508474576">
reliable effects of ReV (F(2,474) = 22.2; p
= .000), ADV (F(2, 474) = 41.3; p = .000), and
CONJ/END (F(3, 474) = 6.1; p = .000). We also
performed post-hoc tests to test significant dif-
ferences. For ReV, there are significant differ-
ences between ‘MQ’ and ‘1DQ’ (p=.000), and
between ‘MQ’ and ‘AQ’ (p =.032). AQ is related
to ‘positive’ and MQ to ‘acceptably negative’ by
the result. For ADV, there are significant differ-
ences between all pairs (p &lt;.05). For CONJ/END,
there are significant differences between ‘like-
ness’ and ‘contrary’ (p = .015), and between
‘likeness’ and ‘contrary with contrastive mark-
ers’ (p = .025). The ‘contrary’ and ‘contrary
with contrastive markers’ types of conjunctions
are related to ‘acceptably negative’.
We also conducted Quantification method 2 to
see if these clues can discriminate between BP
and P and discriminate between AN and N. The
regression equation for distinguishing AN from
N is statistically significant at the 5% level
(F(7,177) = 12,2; R2=0.335; Std. error of the es-
timate = 0.821; error rate for discriminant =
0.21). The coefficients for ‘mild’ (t2=30.8), ‘con-
trary’ (t2=17.8) and ‘contrary with contrastive
markers’ (t2=14.1) are significant.
The results lead us to conclude that we can
identify ‘acceptably negative’ from the clothes
reviews by extracting the particular lexical clue,
adverbs of ‘mild’ category and syntactic clue,
such as conjunctions of ‘contrary’, and ‘contrary
with contrastive markers’, or contrastive weight.
This clue may convey the customer’s argumenta-
tive intention toward the product, or argumenta-
tive orientation, for instance, A and B in ‘A but B.
C’ have different influence on the following dis-
course C (Elhadad and McKeown, 1990).
Although ‘contrary with contrastive markers’
plays an important role in identifying ‘acceptably
negative’, it could also be used to identify anoth-
er type of ‘positive’ as shNown1 in example (2).
(2) P Tl� �L �V 7��1 Li��, �1
rq&apos;4Ll 4A$, com twukkeptanun sayng-
kaki tupnita. kulayto ttattushakin haneyyo. ‘It
is a bit thick, but it keeps me warm.’
It is a positive feature, but neither fully positive
nor barely positive. It seems to be somewhere in-
between. The order of appearance in reviews
may also affect the strength of polarity. In addi-
tion, particular cue phrases such as ­i�!
0131/kesman ppayko/‘except that ...’ can also
convey ‘acceptably negative’, too.
In the future, we need to assess the importance
of each proposed clue relative to others and to
the existing ones. We also need to investigate the
nature of interactions among linguistic, ontologi-
cal and relevance for satisfaction clues, which
may influence the actual performance for identi-
fying finer-grained polarity.
</bodyText>
<sectionHeader confidence="0.993012" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999924454545455">
We proposed further categories of polarity in
order to make aspect-based sentiment summary
more effective. Our linguistic and ontological
analyses suggest that there are clues, such as ‘re-
levance for satisfaction’, ‘contrastive weight’ and
certain adverbials, that work to affect polarity in
a more subtle but crucial manner, as evidenced
also by the statistical analysis. We plan to find
out product attributes that contribute most to
modeling the interaction among the proposed
clues in effective sentiment summarization.
</bodyText>
<sectionHeader confidence="0.998598" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9989516">
This work was funded in part by the Intelligent
Robotics Development Program, a 21st Century
Frontier R&amp;D Program by the Ministry of
Knowledge Economy in Korea, and in part by
the 2nd stage of the Brain Korea 21 project.
</bodyText>
<sectionHeader confidence="0.999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993868">
Ana-Maria Popescu and Oren Etzioni 2005. Extract-
ing Product Features and Opinions from Reviews.
Proc. HLT/EMNLP 2005, 339-346.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. Proc. EMNLP.
Ivan Titov and Ryan McDonald 2008. A Joint Model
of Text and Aspect Ratings for Sentiment Summari-
zation. Proc. ACL-08: HLT, 308-316.
Janne Huiskonen and Timo Pirttila. 1998. Sharpening
logistic customer service strategy planning by ap-
plying Kano’s quality element classification. Inter-
national Journal of Producion Economics, 56-57,
253-260, Elsevier Science B.V.
Michael Elhadad and Kathleen R. McKeown. 1990.
Generating Connectives. Proc. COLING’97-101.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. Proc. ACM SIGKDD,
168–177. ACM Press.
Peter D. Turney. 2002. Thumbs up or thumbs down?
Sentiment orientation applied to unsupervised
classification of reviews. Proc. ACL, 417-424.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.
2006. Recognizing Strong and Weak Opinion
Clauses. Computational Linguistics, 22 (2): 73-99.
</reference>
<page confidence="0.99786">
172
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.496123">
<title confidence="0.9917775">Toward finer-grained sentiment identification in product reviews through linguistic and ontological analyses</title>
<author confidence="0.986117">Hye-Jin Min</author>
<affiliation confidence="0.996608">Computer Science Department</affiliation>
<address confidence="0.743175">KAIST, Daejeon, KOREA</address>
<email confidence="0.888433">hjmin@nlp.kiast.ac.kr</email>
<author confidence="0.998676">Jong C Park</author>
<affiliation confidence="0.999105">Computer Science Department</affiliation>
<address confidence="0.767831">KAIST, Daejeon, KOREA</address>
<email confidence="0.961737">park@nlp.kaist.ac.kr</email>
<abstract confidence="0.999328">We propose categories of finer-grained polarity for a more effective aspect-based sentiment summary, and describe linguistic and ontological clues that may affect such fine-grained polarity. We argue that relevance for satisfaction, contrastive weight clues, and certain adverbials work to affect the polarity, as evidenced by the statistical analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews.</title>
<date>2005</date>
<booktitle>Proc. HLT/EMNLP</booktitle>
<pages>339--346</pages>
<contexts>
<context position="1232" citStr="Popescu and Etzioni, 2005" startWordPosition="174" endWordPosition="177">ced by the statistical analysis. 1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002). The unit of the sentiment varies from a document level to a sentence level to a phrase-level, where a more fine-grained approach has been receiving more attention for its accuracy. Sentiment analysis on product reviews identifies or summarizes sentiment from reviews by extracting relevant opinions about certain attributes of products such as their parts, or properties (Hu and Liu, 2004; Popescu and Etzioni, 2005). Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008). However, there are additional problems. First, it is rather hard to choose the right level of detail. If concepts corresponding to attributes are too general, the level of detail may not be so much finer than the ones on a document level. On the other hand, if concepts are too specific, there may be some attributes that are hardly mentioned in the reviews, resulting in the data sparseness problem. Second, there are</context>
<context position="11473" citStr="Popescu and Etzioni (2005)" startWordPosition="1801" endWordPosition="1804">iews from one of the major online shopping malls in Korea1 and performed a morphology analysis and POS-tagging. After POS-tagging, we collected all the noun phrases as candidates of attributes. We regarded some of them as attributes with the following guidelines and filtered out the rest: 1) NP with frequent adjectives 2) NP with frequent nonfunctional and intransitive verbs. In the case of subject omission, we converted adjectives or verbs into their corresponding nouns, such as ‘thin’ into ‘thickness’. Hu and Liu (2004) identified attributes of IT products based on frequent noun phrases and Popescu and Etzioni (2005) utilized PMI values between product class (hotels and scanners) and some phrases including product. In our case, we used attributes that belong only to the Product concept in the Review structure, because most attributes we consider are sub-types or sub-attribute of Product. The total number of &lt;attribute, polarity&gt; pairs is 474. For relevance for satisfaction, we converted extracted attributes into one of the types of Kano’s quality elements by the mapping table we built. For conceptual granularity we regarded all the attributes with a depth less than 2 as ‘coarse’ and those more than 2 as ‘</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni 2005. Extracting Product Features and Opinions from Reviews. Proc. HLT/EMNLP 2005, 339-346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>Proc. EMNLP.</booktitle>
<contexts>
<context position="799" citStr="Pang et al., 2002" startWordPosition="106" endWordPosition="109">iast.ac.kr Jong C. Park Computer Science Department KAIST, Daejeon, KOREA park@nlp.kaist.ac.kr Abstract We propose categories of finer-grained polarity for a more effective aspect-based sentiment summary, and describe linguistic and ontological clues that may affect such fine-grained polarity. We argue that relevance for satisfaction, contrastive weight clues, and certain adverbials work to affect the polarity, as evidenced by the statistical analysis. 1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002). The unit of the sentiment varies from a document level to a sentence level to a phrase-level, where a more fine-grained approach has been receiving more attention for its accuracy. Sentiment analysis on product reviews identifies or summarizes sentiment from reviews by extracting relevant opinions about certain attributes of products such as their parts, or properties (Hu and Liu, 2004; Popescu and Etzioni, 2005). Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and Mc</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A Joint Model of Text and Aspect Ratings for Sentiment Summarization.</title>
<date>2008</date>
<booktitle>Proc. ACL-08: HLT,</booktitle>
<pages>308--316</pages>
<contexts>
<context position="1412" citStr="Titov and McDonald, 2008" startWordPosition="199" endWordPosition="202">et al., 2002; Turney, 2002). The unit of the sentiment varies from a document level to a sentence level to a phrase-level, where a more fine-grained approach has been receiving more attention for its accuracy. Sentiment analysis on product reviews identifies or summarizes sentiment from reviews by extracting relevant opinions about certain attributes of products such as their parts, or properties (Hu and Liu, 2004; Popescu and Etzioni, 2005). Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008). However, there are additional problems. First, it is rather hard to choose the right level of detail. If concepts corresponding to attributes are too general, the level of detail may not be so much finer than the ones on a document level. On the other hand, if concepts are too specific, there may be some attributes that are hardly mentioned in the reviews, resulting in the data sparseness problem. Second, there are cases when some crucial information is lost. For example, suppose that two product attributes are mentioned in a sentence with a coordinated or subordinated structure. In this cas</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald 2008. A Joint Model of Text and Aspect Ratings for Sentiment Summarization. Proc. ACL-08: HLT, 308-316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janne Huiskonen</author>
<author>Timo Pirttila</author>
</authors>
<title>Sharpening logistic customer service strategy planning by applying Kano’s quality element classification.</title>
<date>1998</date>
<journal>International Journal of Producion Economics,</journal>
<volume>56</volume>
<pages>253--260</pages>
<institution>Elsevier Science B.V.</institution>
<contexts>
<context position="4041" citStr="Huiskonen and Pirttila, 1998" startWordPosition="631" endWordPosition="635">real value depends on the expected utility of the clothes. In this case, the negative polarity is the intended one, as shown in (1b). In order to reflect this possibility, we need to adjust the weight of each polarity accordingly. In this paper, we propose to look into the kind of linguistic and ontological clues that may in169 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 169–172, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP fluence the use of polarities, or the relevance for ‘satisfaction of purchase’ inspired by Kano’s theory of quality element classification (Huiskonen and Pirttila, 1998), the conceptual granularities, and such syntactic and lexical clues as conjunction items and adverbs. They may play significant roles in putting together the identified polarity information, so as to assess correctly what the customers consider most important. We conducted several one-way Analysis of Variance (ANOVA) tests to identify the effects of each clue on deriving categories of polarity and quantification method 2 to see whether these clues can distinguish fine-grained polarities correctly. Section 2 introduces categories of polarity. Section 3 analyzes ontological and linguistic clues</context>
</contexts>
<marker>Huiskonen, Pirttila, 1998</marker>
<rawString>Janne Huiskonen and Timo Pirttila. 1998. Sharpening logistic customer service strategy planning by applying Kano’s quality element classification. International Journal of Producion Economics, 56-57, 253-260, Elsevier Science B.V.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Generating Connectives.</title>
<date>1990</date>
<booktitle>Proc.</booktitle>
<pages>97--101</pages>
<contexts>
<context position="14287" citStr="Elhadad and McKeown, 1990" startWordPosition="2247" endWordPosition="2250"> ‘mild’ (t2=30.8), ‘contrary’ (t2=17.8) and ‘contrary with contrastive markers’ (t2=14.1) are significant. The results lead us to conclude that we can identify ‘acceptably negative’ from the clothes reviews by extracting the particular lexical clue, adverbs of ‘mild’ category and syntactic clue, such as conjunctions of ‘contrary’, and ‘contrary with contrastive markers’, or contrastive weight. This clue may convey the customer’s argumentative intention toward the product, or argumentative orientation, for instance, A and B in ‘A but B. C’ have different influence on the following discourse C (Elhadad and McKeown, 1990). Although ‘contrary with contrastive markers’ plays an important role in identifying ‘acceptably negative’, it could also be used to identify another type of ‘positive’ as shNown1 in example (2). (2) P Tl� �L �V 7��1 Li��, �1 rq&apos;4Ll 4A$, com twukkeptanun sayngkaki tupnita. kulayto ttattushakin haneyyo. ‘It is a bit thick, but it keeps me warm.’ It is a positive feature, but neither fully positive nor barely positive. It seems to be somewhere inbetween. The order of appearance in reviews may also affect the strength of polarity. In addition, particular cue phrases such as i�! 0131/kesman ppay</context>
</contexts>
<marker>Elhadad, McKeown, 1990</marker>
<rawString>Michael Elhadad and Kathleen R. McKeown. 1990. Generating Connectives. Proc. COLING’97-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>Proc. ACM SIGKDD,</booktitle>
<pages>168--177</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="1204" citStr="Hu and Liu, 2004" startWordPosition="170" endWordPosition="173">olarity, as evidenced by the statistical analysis. 1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002). The unit of the sentiment varies from a document level to a sentence level to a phrase-level, where a more fine-grained approach has been receiving more attention for its accuracy. Sentiment analysis on product reviews identifies or summarizes sentiment from reviews by extracting relevant opinions about certain attributes of products such as their parts, or properties (Hu and Liu, 2004; Popescu and Etzioni, 2005). Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008). However, there are additional problems. First, it is rather hard to choose the right level of detail. If concepts corresponding to attributes are too general, the level of detail may not be so much finer than the ones on a document level. On the other hand, if concepts are too specific, there may be some attributes that are hardly mentioned in the reviews, resulting in the data sparsenes</context>
<context position="11374" citStr="Hu and Liu (2004)" startWordPosition="1785" endWordPosition="1788">iews of several types of pants and annotated polarities manually. We obtained raw text reviews from one of the major online shopping malls in Korea1 and performed a morphology analysis and POS-tagging. After POS-tagging, we collected all the noun phrases as candidates of attributes. We regarded some of them as attributes with the following guidelines and filtered out the rest: 1) NP with frequent adjectives 2) NP with frequent nonfunctional and intransitive verbs. In the case of subject omission, we converted adjectives or verbs into their corresponding nouns, such as ‘thin’ into ‘thickness’. Hu and Liu (2004) identified attributes of IT products based on frequent noun phrases and Popescu and Etzioni (2005) utilized PMI values between product class (hotels and scanners) and some phrases including product. In our case, we used attributes that belong only to the Product concept in the Review structure, because most attributes we consider are sub-types or sub-attribute of Product. The total number of &lt;attribute, polarity&gt; pairs is 474. For relevance for satisfaction, we converted extracted attributes into one of the types of Kano’s quality elements by the mapping table we built. For conceptual granula</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. Proc. ACM SIGKDD, 168–177. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>Proc. ACL,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="814" citStr="Turney, 2002" startWordPosition="110" endWordPosition="111">Park Computer Science Department KAIST, Daejeon, KOREA park@nlp.kaist.ac.kr Abstract We propose categories of finer-grained polarity for a more effective aspect-based sentiment summary, and describe linguistic and ontological clues that may affect such fine-grained polarity. We argue that relevance for satisfaction, contrastive weight clues, and certain adverbials work to affect the polarity, as evidenced by the statistical analysis. 1 Introduction Sentiment analysis have been widely conducted in several domains such as movie reviews, product reviews, news and blog reviews (Pang et al., 2002; Turney, 2002). The unit of the sentiment varies from a document level to a sentence level to a phrase-level, where a more fine-grained approach has been receiving more attention for its accuracy. Sentiment analysis on product reviews identifies or summarizes sentiment from reviews by extracting relevant opinions about certain attributes of products such as their parts, or properties (Hu and Liu, 2004; Popescu and Etzioni, 2005). Aspect-based sentiment analysis summarizes sentiments with diverse attributes, so that customers may have to look more closely into analyzed sentiments (Titov and McDonald, 2008). </context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews. Proc. ACL, 417-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Recognizing Strong and Weak Opinion Clauses.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>73--99</pages>
<marker>Wilson, Wiebe, Hwa, 2006</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2006. Recognizing Strong and Weak Opinion Clauses. Computational Linguistics, 22 (2): 73-99.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>