<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011499">
<title confidence="0.994154">
Exploiting Non-local Features for Spoken Language Understanding
</title>
<author confidence="0.991421">
Minwoo Jeong and Gary Geunbae Lee
</author>
<affiliation confidence="0.999914">
Department of Computer Science &amp; Engineering
Pohang University of Science and Technology,
</affiliation>
<address confidence="0.985014">
San 31 Hyoja-dong, Nam-gu
Pohang 790-784, Korea
</address>
<email confidence="0.999113">
{stardust,gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.993901" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973125">
In this paper, we exploit non-local fea-
tures as an estimate of long-distance de-
pendencies to improve performance on the
statistical spoken language understanding
(SLU) problem. The statistical natural
language parsers trained on text perform
unreliably to encode non-local informa-
tion on spoken language. An alternative
method we propose is to use trigger pairs
that are automatically extracted by a fea-
ture induction algorithm. We describe a
light version of the inducer in which a sim-
ple modification is efficient and success-
ful. We evaluate our method on an SLU
task and show an error reduction of up to
27% over the base local model.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999829285714286">
For most sequential labeling problems in natural
language processing (NLP), a decision is made
based on local information. However, processing
that relies on the Markovian assumption cannot
represent higher-order dependencies. This long-
distance dependency problem has been considered
at length in computational linguistics. It is the key
limitation in bettering sequential models in vari-
ous natural language tasks. Thus, we need new
methods to import non-local information into se-
quential models.
There are two types of method for using non-
local information. One is to add edges to structure
to allow higher-order dependencies and another is
to add features (or observable variables) to encode
the non-locality. An additional consistent edge of
a linear-chain conditional random field (CRF) ex-
plicitly models the dependencies between distant
occurrences of similar words (Sutton and McCal-
lum, 2004; Finkel et al., 2005). However, this
approach requires additional time complexity in
inference/learning time and it is only suitable for
representing constraints by enforcing label consis-
tency. We wish to identify ambiguous labels with
more general dependency without additional time
cost in inference/learning time.
Another approach to modeling non-locality is
to use observational features which can capture
non-local information. Traditionally, many sys-
tems prefer to use a syntactic parser. In a language
understanding task, the head word dependencies
or parse tree path are successfully applied to learn
and predict semantic roles, especially those with
ambiguous labels (Gildea and Jurafsky, 2002). Al-
though the power of syntactic structure is impres-
sive, using the parser-based feature fails to encode
correct global information because of the low ac-
curacy of a modern parser. Furthermore the inac-
curate result of parsing is more serious in a spoken
language understanding (SLU) task. In contrast
to written language, spoken language loses much
information including grammar, structure or mor-
phology and contains some errors in automatically
recognized speech.
To solve the above problems, we present one
method to exploit non-local information – the trig-
ger feature. In this paper, we incorporate trig-
ger pairs into a sequential model, a linear-chain
CRF. Then we describe an efficient algorithm to
extract the trigger feature from the training data it-
self. The framework for inducing trigger features
is based on the Kullback-Leibler divergence cri-
terion which measures the improvement of log-
likelihood on the current parameters by adding a
new feature (Pietra et al., 1997). To reduce the
cost of feature selection, we suggest a modified
</bodyText>
<page confidence="0.971893">
412
</page>
<note confidence="0.725172">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 412–419,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999809714285714">
version of an inducing algorithm which is quite ef-
ficient. We evaluate our method on an SLU task,
and demonstrate the improvements on both tran-
scripts and recognition outputs. On a real-world
problem, our modified version of a feature selec-
tion algorithm is very efficient for both perfor-
mance and time complexity.
</bodyText>
<sectionHeader confidence="0.9360115" genericHeader="method">
2 Spoken Language Understanding as a
Sequential Labeling Problem
</sectionHeader>
<subsectionHeader confidence="0.999496">
2.1 Spoken Language Understanding
</subsectionHeader>
<bodyText confidence="0.971443901960785">
The goal of SLU is to extract semantic mean-
ings from recognized utterances and to fill the
correct values into a semantic frame structure.
A semantic frame (or template) is a well-formed
and machine readable structure of extracted in-
formation consisting of slot/value pairs. An ex-
ample of such a reference frame is as follows.
&lt;s&gt; i wanna go from denver to new york on
november eighteenth &lt;/s&gt;
FROMLOC.CITY NAME = denver
TOLOC.CITY NAME = new york
MONTH NAME = november
DAY NUMBER = eighteenth
This example from air travel data (CU-
Communicator corpus) was automatically gener-
ated by a Phoenix parser and manually corrected
(Pellom et al., 2000; He and Young, 2005). In this
example, the slot labels are two-level hierarchi-
cal; such as FROMLOC.CITY NAME. This hier-
archy differentiates the semantic frame extraction
problem from the named entity recognition (NER)
problem.
Regardless of the fact that there are some
differences between SLU and NER, we can
still apply well-known techniques used in NER
to an SLU problem. Following (Ramshaw
and Marcus, 1995), the slot labels are drawn
from a set of classes constructed by extending
each label by three additional symbols, Begin-
ning/Inside/Outside (B/I/O). A two-level hierar-
chical slot can be considered as an integrated flat-
tened slot. For example, FROMLOC.CITY NAME
and TOLOC.CITY NAME are different on this slot
definition scheme.
Now, we can formalize the SLU prob-
lem as a sequential labeling problem, y* =
arg maxy P(y|x). In this case, input word se-
quences x are not only lexical strings, but also
multiple linguistic features. To extract semantic
frames from utterance inputs, we use a linear-
chain CRF model; a model that assigns a joint
probability distribution over labels which is con-
ditional on the input sequences, where the distri-
bution respects the independent relations encoded
in a graph (Lafferty et al., 2001).
A linear-chain CRF is defined as follows. Let
G be an undirected model over sets of random
variables x and y. The graph G with parameters
A = {A,...} defines a conditional probability for
a state (or label) sequence y = y1, ... , yT, given
an input x = x1, ... , xT, to be
</bodyText>
<equation confidence="0.995717666666667">
1 T
Pn(y|x) = Zx exp (EEAt=1
kfk(yt−1, yt, x, t)
</equation>
<bodyText confidence="0.999927862068966">
where Zx is the normalization factor that makes
the probability of all state sequences sum to one.
fk(yt−1, yt, x, t) is an arbitrary linguistic feature
function which is often binary-valued in NLP
tasks. Ak is a trained parameter associated with
feature fk. The feature functions can encode any
aspect of a state transition, yt−1 → yt, and the
observation (a set of observable features), x, cen-
tered at the current time, t. Large positive val-
ues for Ak indicate a preference for such an event,
while large negative values make the event un-
likely.
Parameter estimation of a linear-chain CRF is
typically performed by conditional maximum log-
likelihood. To avoid overfitting, the 2-norm reg-
ularization is applied to penalize on weight vec-
tor whose norm is too large. We used a limited
memory version of the quasi-Newton method (L-
BFGS) to optimize this objective function. The
L-BFGS method converges super-linearly to the
solution, so it can be an efficient optimization
technique on large-scale NLP problems (Sha and
Pereira, 2003).
A linear-chain CRF has been previously applied
to obtain promising results in various natural lan-
guage tasks, but the linear-chain structure is defi-
cient in modeling long-distance dependencies be-
cause of its limited structure (n-th order Markov
chains).
</bodyText>
<subsectionHeader confidence="0.9998895">
2.2 Long-distance Dependency in Spoken
Language Understanding
</subsectionHeader>
<bodyText confidence="0.96757">
In most sequential supervised learning prob-
lems including SLU, the feature function
fk(yt−1, yt, xt, t) indicates only local information
</bodyText>
<equation confidence="0.857812">
k
</equation>
<page confidence="0.994458">
413
</page>
<bodyText confidence="0.999942086956522">
for practical reasons. With sufficient local context
(e.g. a sliding window of width 5), inference and
learning are both efficient.
However, if we only use local features, then
we cannot model long-distance dependencies.
Thus, we should incorporate non-local infor-
mation into the model. For example, figure
1 shows the long-distance dependency problem
in an SLU task. The same two word to-
kens “dec.” should be classified differently,
DEPART.MONTH and RETURN.MONTH. The
dotted line boxes represent local information at the
current decision point (“dec.”), but they are ex-
actly the same in two distinct examples. More-
over, the two states share the same previous
sequence (O, O, FROMLOC.CITY NAME-B,
O, TOLOC.CITY NAME-B, O). If we cannot
obtain higher-order dependencies such as “fly”
and “return,” then the linear-chain CRF cannot
classify the correct labels between the two same
tokens. To solve this problem, we propose an ap-
proach to exploit non-local information in the next
section.
</bodyText>
<sectionHeader confidence="0.921757" genericHeader="method">
3 Incorporating Non-local Information
</sectionHeader>
<subsectionHeader confidence="0.999935">
3.1 Using Trigger Features
</subsectionHeader>
<bodyText confidence="0.998974631578948">
To exploit non-local information to sequential la-
beling for a statistical SLU, we can use two ap-
proaches; a syntactic parser-based and a data-
driven approach. Traditionally, information ex-
traction and language understanding fields have
usually used a syntactic parser to encode global
information (e.g. parse tree path, governing cat-
egory, or head word) over a local model. In a se-
mantic role labeling task, the syntax and semantics
are correlated with each other (Gildea and Juraf-
sky, 2002), that is, the global structure of the sen-
tence is useful for identifying ambiguous semantic
roles. However the problem is the poor accuracy
of the syntactic parser with this type of feature. In
addition, recognized utterances are erroneous and
the spoken language has no capital letters, no ad-
ditional symbols, and sometimes no grammar, so
it is difficult to use a parser in an SLU problem.
Another solution is a data-driven method, which
uses statistics to find features that are approxi-
mately modeling long-distance dependencies. The
simplest way is to use identical words in history or
lexical co-occurrence, but we wish to use a more
general tool; triggering. The trigger word pairs
are introduced by (Rosenfeld, 1994). A trigger
pair is the basic element for extracting informa-
tion from the long-distance document history. In
language modeling, n-gram based on the Marko-
vian assumption cannot represent higher-order de-
pendencies, but it can automatically extract trigger
word pairs from data. The pair (A → B) means
that word A and B are significantly correlated, that
is, when A occurs in the document, it triggers B,
causing its probability estimate to change.
To select reasonable pairs from arbitrary word
pairs, (Rosenfeld, 1994) used averaged mutual in-
formation (MI). In this scheme, the MI score of
one pair is MI(A; B) _
</bodyText>
<equation confidence="0.9472875">
P(B|A) P ( �B|A)
P(A, B) log P (B) + P(A, �B) log P( B) +
</equation>
<bodyText confidence="0.999869230769231">
Using the MI criterion, we can select corre-
lated word pairs. For example, the trigger pair
(dec.→return) was extracted with score 0.001179
in the training data1. This trigger word pair can
represent long-distance dependency and provide a
cue to identify ambiguous classes. The MI ap-
proach, however, considers only lexical colloca-
tion without reference labels y, and MI based se-
lection tends to excessively select the irrelevant
triggers. Recall that our goal is to find the signif-
icantly correlated trigger pairs which improve the
model. Therefore, we use a more appropriate se-
lection method for sequential supervised learning.
</bodyText>
<subsectionHeader confidence="0.999961">
3.2 Selecting Trigger Feature
</subsectionHeader>
<bodyText confidence="0.999973466666667">
We present another approach to extract relevant
triggers and exploit them in a linear-chain CRF.
Our approach is based on an automatic feature in-
duction algorithm, which is a novel method to se-
lect a feature in an exponential model (Pietra et al.,
1997; McCallum, 2003). We follow McCallum’s
work which is an efficient method to induce fea-
tures in a linear-chain CRF model. Following the
framework of feature inducing, we start the algo-
rithm with an empty set, and iteratively increase
the bundle of features including local features and
trigger features. Our basic assumption, however,
is that the local information should be included
because the local features are the basis of the de-
cision to identify the classes, and they reduce the
</bodyText>
<footnote confidence="0.95285975">
1In our experiment, the pair (dec. fly) cannot be selected
because this MI score is too low. However, the trigger pair is
a binary type feature, so the pair (dec.--+return) is enough to
classify the two cases in the previous example.
</footnote>
<equation confidence="0.7205125">
P( B) + P(
A, B) log P(
P(A, B) log P(B|
B |A)
A)
P( B) .
</equation>
<page confidence="0.848635">
414
</page>
<figure confidence="0.998653428571429">
DEPART.MONTH
... fly from denver to chicago on
dec. 10th
1999
...
... return from denver to chicago on dec. 10th 1999 ...
RETURN.MONTH
</figure>
<figureCaption confidence="0.994010333333333">
Figure 1: An example of a long-distance dependency problem in spoken language understanding. In
this case, a word token “dec.” with local feature set (dotted line box) is ambiguous for determining the
correct label (DEPART.MONTH or RETURN.MONTH).
</figureCaption>
<bodyText confidence="0.992870692307692">
mismatch between training and testing tasks. Fur-
thermore, this assumption leads us to faster train-
ing in the inducing procedure because we can only
consider additional trigger features.
Now, we start the inducing process with local
features rather than an empty set. After training
the base model AM, we should calculate the gains,
which measure the effect of adding a trigger fea-
ture, based on the local model parameter AM. The
gain of the trigger feature is defined as the im-
provement in log-likelihood of the current model
AW at the i-th iteration according to the following
formula:
</bodyText>
<equation confidence="0.96832675">
�GA(i)(g) = max GA(i)(g, µ)
µ { }
= max LA(i)+g,µ − LA(i)
µ
</equation>
<bodyText confidence="0.999987258064516">
where µ is a parameter of a trigger feature to
be found and g is a corresponding trigger feature
function. The optimal value of µ can be calculated
by Newton’s method.
By adding a new candidate trigger, the equation
of the linear-chain CRF model is changed to an
additional feature model as PA(i)+g,µ(y|x) =
Here, we introduce a second approximation. We
use the individual inference problem over the un-
structured maximum entropy (ME) model whose
state variable is independent from other states in
history. The background of our approximation is
that the state independent problem of CRF can
be relaxed to ME inference problem without the
state-structured model. In the result, we calculate
the gain of candidate triggers, and select trigger
features over a light ME model instead of a huge
computational CRF model2.
We can efficiently assess many candidate trig-
ger features in parallel by assuming that the old
features remain fixed while estimating the gain.
The gain of trigger features can be calculated on
the old model that is trained with the local and
added trigger pairs in previous iterations. Rather
than summing over all training instances, we only
need to use the mislabeled N tokens by the cur-
rent parameter AW (McCallum, 2003). From mis-
classified instances, we generate the candidates of
trigger pairs, that is, all pairs of current words and
others within the sentence. With the candidate fea-
ture set, the gain is
</bodyText>
<equation confidence="0.9964968">
�GA(i)(g) = N µ��E[g]
(fiT ) − N log (EA(i)[exp(wg)|xj]) − µ2
PA(i)(y|x) exp t=1 µg(yt−1, yt, x, t) E
j=1
Z.(AW, g, µ) . 2σ2.
</equation>
<bodyText confidence="0.9997835">
Note that Z.(AW, g, µ) is the marginal sum over
all states of y&apos;. Following (Pietra et al., 1997; Mc-
Callum, 2003), the mean field approximation and
agglomerated features allows us to treat the above
calculation as the independent inference problem
rather than sequential inference. We can evaluate
the probability of state y with an adding trigger
pair given observation x separately as follows.
</bodyText>
<equation confidence="0.954791666666667">
PA(i)(y|x, t) exp (µg(yt, x, t))
PA(i)+g,µ(y|x, t) =
Z.(AW, g, µ)
</equation>
<bodyText confidence="0.9996185">
Using the estimated gains, we can select a small
portion of all candidates, and retrain the model
with selected features. We iteratively perform the
selection algorithm with some stop conditions (ex-
cess of maximum iteration or no added feature up
to the gain threshold). The outline of the induction
</bodyText>
<footnote confidence="0.917329">
2The ME model cannot represent the sequential structure
and the resulting model is different from CRF. Nevertheless,
we empirically prove that the effect of additional trigger fea-
tures on both ME and approximated CRF (without regarding
edge-state) are similar (see the experiment section).
</footnote>
<page confidence="0.990681">
415
</page>
<equation confidence="0.889727846153846">
Algorithm InduceLearn(x,y)
triggers +- {e} and i +- 0
while |pairs |&gt; 0 and i &lt; maxiter do
A(i) +- TrainME(x, y)
P(ye|xe) +- Evaluate(x, y, A(i))
c +- MakeCandidate(xe)
GAM +- EstimateGain(c, P(ye|xe))
pairs +- SelectTrigger(c, GAM)
x +- UpdateObs(x, pairs)
triggers +- triggers U pairs and i +- i + 1
end while
A(i+1) +- TrainCRF(x, y)
return A(i+1)
</equation>
<figureCaption confidence="0.9453165">
Figure 2: Outline of trigger feature induction al-
gorithm
</figureCaption>
<bodyText confidence="0.988288933333333">
algorithms is described in figure 2. In the next sec-
tion, we empirically prove the effectiveness of our
algorithm.
The trigger pairs introduced by (Rosenfeld,
1994) are just word pairs. Here, we can gen-
eralize the trigger pairs to any arbitrary pairs of
features. For example, the feature pair (of-*B-
PP) is useful in deciding the correct answer
PERIOD OF DAY-I in “in the middle of the day.”
Without constraints on generating the pairs (e.g.
at most 3 distant tokens), the candidates can be
arbitrary conjunctions of features3. Therefore we
can explore any features including local conjunc-
tion or non-local singleton features in a uniform
framework.
</bodyText>
<sectionHeader confidence="0.999897" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996998">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999220166666667">
We evaluate our method on the CU-Communicator
corpus. It consists of 13,983 utterances. The se-
mantic categories correspond to city names, time-
related information, airlines and other miscella-
neous entities. The semantic labels are automat-
ically generated by a Phoenix parser and manually
corrected. In the data set, the semantic category
has a two-level hierarchy: 31 first level classes
and 7 second level classes, for a total of 62 class
combinations. The data set is 630k words with
29k entities. Roughly half of the entities are time-
related information, a quarter of the entities are
</bodyText>
<footnote confidence="0.817146333333333">
3In our experiment, we do not consider the local conjunc-
tions because we wish to capture the effect of long-distance
entities.
</footnote>
<bodyText confidence="0.999955">
city names, a tenth are state and country names,
and a fifth are airline and airport names. For
the second level hierarchy, approximately three
quarters of the entities are “NONE”, a tenth are
“TOLOC”, a tenth are “FROMLOC”, and the re-
maining are “RETURN”, “DEPERT”, “ARRIVE”,
and “STOPLOC.”
For spoken inputs, we used the open source
speech recognizer Sphinx2. We trained the recog-
nizer with only the domain-specific speech corpus.
The reported accuracy for Sphinx2 speech recog-
nition is about 85%, but the accuracy of our speech
recognizer is 76.27%; we used only a subset of the
data without tuning and the sentences of this sub-
set are longer and more complex than those of the
removed ones, most of which are single-word re-
sponses.
All of our results have averaged over 5-fold
cross validation with an 80/20 split of the data.
As it is standard, we compute precision and re-
call, which are evaluated on a per-entity basis and
combined into a micro-averaged F1 score (F1 =
2PR/(P+R)).
A final model (a first-order linear chain CRF)
is trained for 100 iterations with a Gaussian prior
variance of 20, and 200 or fewer trigger features
(down to a gain threshold of 1.0) for each round of
inducing iteration (100 iterations of L-BFGS for
the ME inducer and 10∼20 iterations of L-BFGS
for the CRF inducer). All experiments are imple-
mented in C++ and executed on Linux with XEON
2.8 GHz dual processors and 2.0 Gbyte of main
memory.
</bodyText>
<subsectionHeader confidence="0.987671">
4.2 Empirical Results
</subsectionHeader>
<bodyText confidence="0.9998593125">
We list the feature templates used by our experi-
ment in figure 3. For local features, we use the
indicators for specific words at location i, or lo-
cations within five words of i (−2,−1,0,+1,+2
words on current position i). We also use the part-
of-speech (POS) tags and phrase labels with par-
tial parsing. Like words, the two basic linguis-
tic features are located within five tokens. For
comparison, we exploit the two groups of non-
local syntax parser-based features; we use Collins
parser and extract this type of features from the
parse trees. The first consists of the head word
and POS-tag of the head word. The second group
includes governing category and parse tree paths
introduced by semantic role labeling (Gildea and
Jurafsky, 2002). Following the previous studies
</bodyText>
<page confidence="0.997198">
416
</page>
<table confidence="0.98934525">
Local feature templates
-lexical words
-part-of-speech (POS) tags
-phrase chunk labels
Grammar-based feature templates
-head word / POS-tag
-parse tree path and governing category
Trigger feature templates
-word pairs (wi → wj), |i − j |&gt; 2
-feature pairs between words, POS-tags, and
chunk labels (fi → fj), |i − j |&gt; 2
-null pairs (e → wj)
</table>
<figureCaption confidence="0.991085">
Figure 3: Feature templates
</figureCaption>
<bodyText confidence="0.997977166666667">
of semantic role labeling, the parse tree path im-
proves the classification performance of semantic
role labeling. Finally, we use the trigger pairs that
are automatically extracted from the training data.
Avoiding the overlap of local features, we add the
constraint |i − j |&gt; 2 for the target word wj. Note
that null pairs are equivalent to long-distance sin-
gleton word features wj.
To compute feature performance, we begin with
word features and iteratively add them one-by-one
so that we achieve the best performance. Table 1
shows the empirical results of local features, syn-
tactic parser-based features, and trigger features
respectively. The two F1 scores for text tran-
scripts (Text) and outputs recognized by an au-
tomatic speech recognizer (ASR) are listed. We
achieved F1 scores of 94.79 and 71.79 for Text and
ASR inputs using only word features. The perfor-
mance is decreased by adding the additional local
features (POS-tags and chunk labels) because the
pre-processor brings more errors to the system for
spoken dialog.
The parser-based and trigger features are added
to two baselines: word only and all local features.
The result shows that the trigger feature is more
robust to an SLU task than the features generated
from the syntactic parser. The parse tree path and
governing category show a small improvement of
performance over local features, but it is rather in-
significant (word vs. word+path, McNemar’s test
(Gillick and Cox, 1989); p = 0.022). In contrast,
the trigger features significantly improve the per-
formance of the system for both Text and ASR
inputs. The differences between the trigger and
the others are statistically significant (McNemar’s
test; p &lt; 0.001 for both Text and ASR).
</bodyText>
<tableCaption confidence="0.9898965">
Table 1: The result of local features, parser-based
features and trigger features
</tableCaption>
<table confidence="0.999190538461538">
Feature set F1 (Text) F1 (ASR)
word (w) 94.79 71.79
w + POStag (p) 94.57 71.61
w + chunk (c) 94.70 71.64
local (w+p+c) 94.41 71.60
w + head (h) 94.55 71.76
w + path (t) 95.07 72.17
w + h + t 94.84 72.09
local + head (h) 94.17 71.39
local + path (t) 94.80 71.89
local + h + t 94.51 71.67
w + trigger 96.18 72.95
local + trigger 96.04 72.72
</table>
<bodyText confidence="0.999945393939394">
Next, we compared the two trigger selection
methods; mutual information (MI) and feature in-
duction (FI). Table 2 shows the experimental re-
sults of the comparison between MI and FI ap-
proaches (with the local feature set; w+p+c). For
the MI-based approach, we should calculate an av-
eraged MI for each word pair appearing in a sen-
tence and cut the unreliable pairs (down to thresh-
old of 0.0001) before training the model. In con-
trast, the FI-based approach selects reliable trig-
gers which should improve the model in train-
ing time. Our method based on the feature in-
duction algorithm outperforms simple MI-based
methods. Fewer features are selected by FI, that
is, our method prunes the event pairs which are
highly correlated, but not relevant to models. The
extended feature trigger (fi → fj) and null trig-
gers (e → wj) improve the performance over word
trigger pairs (wi → wj), but they are not statisti-
cally significant (vs. (fi → fj); p = 0.749, vs.
({e, wi} → wj); p = 0.294). Nevertheless, the
null pairs are effective in reducing the size of trig-
ger features.
Figure 4 shows a sample of triggers selected by
MI and FI approaches. For example, the trigger
“morning → return” is ranked in first of FI but
66th of MI. Moreover, the top 5 pairs of MI are
not meaningful, that is, MI selects many functional
word pairs. The MI approach considers only lexi-
cal collocation without reference labels, so the FI
method is more appropriate to sequential super-
vised learning.
Finally, we wish to justify that our modified
</bodyText>
<page confidence="0.998853">
417
</page>
<tableCaption confidence="0.998411">
Table 2: Result of the trigger selection methods
</tableCaption>
<table confidence="0.968567733333333">
Method Avg. # triggers F1 (Text) F1 (ASR) McNemar’s test (vs. MI)
MI (wi —* wj) 1,713 95.20 72.12 -
FI (wi —* wj) 702 96.04 72.72 p &lt; 0.001
FI (fi —* fj) 805 96.04 72.76 p &lt; 0.001
FI ({e, wiI —* wj) 545 96.14 72.80 p &lt; 0.001
Mutual Information Feature Induction
[1] from→like [1] morning→return
[2] on→to [2] morning→on
[3] to→i [3] morning→to
[4] on→from [4] afternoon→on
[5] from→i [5] afternoon→return
[41] afternoon→return [6] afternoon→to
[66] morning→return [15] morning→leaving
[89] morning→leaving [349] december→return
[1738] london→fly [608] illinois→airport
</table>
<figureCaption confidence="0.978989">
Figure 4: A sample of triggers extracted by two
methods
</figureCaption>
<bodyText confidence="0.999823285714286">
version of an inducing algorithm is efficient and
maintains performance without any drawbacks.
We proposed two approximations: starting with
local features (Approx. 1) and using an unstruc-
tured model on the selection stage (Approx. 2),
Table 3 shows the results of variant versions of
the algorithm. Surprisingly, the selection crite-
rion based on ME (the unstructured model) is bet-
ter than CRF (the structured model) not only for
time cost but also for the performance on our ex-
periment4. This result shows that local informa-
tion provides the fundamental decision clues. Our
modification of the algorithm to induce features
for CRF is sufficiently fast for practical usage.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="method">
5 Related Work and Discussion
</sectionHeader>
<bodyText confidence="0.999643230769231">
The most relevant previous work is (He and
Young, 2005) who describes an generative ap-
proach – hidden vector state (HVS) model. They
used 1,178 test utterances with 18 classes for 1st
level label, and published the resulting F1 score
of 88.07. Using the same test data and classes,
we achieved the 92.77 F1-performance, as well
4In our analysis, 10∼20 iterations for each round of in-
ducing procedure are insufficient in optimizing the model in
CRF (empty) inducer. Thus, the resulting parameters are
under-fitted and selected features are infeasible. We need
more iteration to fit the parameters, but they require too much
learning time (&gt; 1 day).
as 39% of error reduction compared to the previ-
ous result. Our system uses a discriminative ap-
proach, which directly models the conditional dis-
tribution, and it is sufficient for classification task.
To capture long-distance dependency, HVS uses a
context-free model, which increases the complex-
ity of models. In contrast, we use non-local trigger
features, which are relatively easy to use without
having additional complexity of models.
Trigger word pairs are introduced and success-
fully applied in a language modeling task. (Rosen-
feld, 1994) demonstrated that the trigger word
pairs improve the perplexity in ME-based lan-
guage models. Our method extends this idea to
sequential supervised learning problems. Our trig-
ger selection criterion is based on the automatic
feature inducing algorithm, and it allows us to gen-
eralize the arbitrary pairs of features.
Our method is based on two works of fea-
ture induction on an exponential model, (Pietra et
al., 1997) and (McCallum, 2003). Our induction
algorithm builds on McCallum’s method which
presents an efficient procedure to induce features
on CRF. (McCallum, 2003) suggested using only
the mislabeled events rather than the whole train-
ing events. This intuitional suggestion has offered
us fast training. We added two additional approx-
imations to reduce the time cost; 1) an inducing
procedure over a conditional non-structured infer-
ence problem rather than an approximated sequen-
tial inference problem, and 2) training with a local
feature set, which is the basic information to iden-
tify the labels.
In this paper, our approach describes how to
exploit non-local information to a SLU prob-
lem. The trigger features are more robust than
grammar-based features, and are easily extracted
from the data itself by using an efficient selection
algorithm.
</bodyText>
<page confidence="0.99876">
418
</page>
<tableCaption confidence="0.988804333333333">
Table 3: Comparison of variations in the induction algorithm (performed on one of the 5-fold validation
sets); columns are induction and total training time (h:m:s), number of trigger and total features, and
f-score on test data.
</tableCaption>
<table confidence="0.9994288">
Inducer type Approx. Induction/total time # triggers/features F1 (Text) F1 (ASR)
CRF (empty) No approx. 3:55:01 / 5:27:13 682 / 2,693 90.23 67.60
CRF (local) Approx. 1 1:25:28 / 2:56:49 750 / 5,241 94.87 71.65
ME (empty) Approx. 2 20:57 / 1:54:22 618 / 2,080 94.85 71.46
ME (local) Approx. 1+2 6:30 / 1:36:14 608 / 5,099 95.17 71.81
</table>
<sectionHeader confidence="0.998665" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99997512">
We have presented a method to exploit non-local
information into a sequential supervised learning
task. In a real-world problem such as statistical
SLU, our model performs significantly better than
the traditional models which are based on syntac-
tic parser-based features. In comparing our se-
lection criterion, we find that the mutual informa-
tion tends to excessively select the triggers while
our feature induction algorithm alleviates this is-
sue. Furthermore, the modified version of the al-
gorithm is practically fast enough to maintain its
performance particularly when the local features
are offered by the starting position of the algo-
rithm.
In this paper, we have focused on a sequential
model such as a linear-chain CRF. However, our
method can also be naturally applied to arbitrary
structured models, thus the first alternative is to
combine our methods with a skip-chain CRF (Sut-
ton and McCallum, 2004). Applying and extend-
ing our approach to other natural language tasks
(which are difficult to apply a parser to) such as in-
formation extraction from e-mail data or biomed-
ical named entity recognition is a topic of future
work.
</bodyText>
<sectionHeader confidence="0.996548" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99862675">
We thank three anonymous reviewers for helpful
comments. This research was supported by the
MIC (Ministry of Information and Communica-
tion), Korea, under the ITRC (Information Tech-
nology Research Center) support program super-
vised by the IITA (Institute of Information Tech-
nology Assessment). (IITA-2005-C1090-0501-
0018)
</bodyText>
<sectionHeader confidence="0.998959" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999157025">
J. R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information
extraction systems by gibbs sampling. In Proceed-
ings ofACL’05, pages 363–370.
D. Gildea and D. Jurafsky. 2002. Automatic label-
ing of semantic roles. Computational Linguistics,
28(3):245–288.
L. Gillick and S. Cox. 1989. Some statistical issues in
the comparison of speech recognition algorithms. In
Proceedings ofICASSP, pages 532–535.
Y. He and S. Young. 2005. Semantic processing using
the hidden vector state model. Computer Speech &amp;
Language, 19(1):85–106.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings
ofICML, pages 282–289.
A. McCallum. 2003. Efficiently inducing features of
conditional random fields. In Proceedings of UAI,
page 403.
B. L. Pellom, W. Ward, and S. S. Pradhan. 2000. The
cu communicator: An architecture for dialogue sys-
tems. In Proceedings ofICSLP.
S. Della Pietra, V. J. Della Pietra, and J. Lafferty. 1997.
Inducing features of random fields. IEEE Trans.
Pattern Anal. Mach. Intell, 19(4):380–393.
L. A. Ramshaw and M. P. Marcus. 1995. Text chunk-
ing using transformation-based learning. In 3rd
Workshop on Very Large Corpora, pages 82–94.
R. Rosenfeld. 1994. Adaptive statistical language
modeling: A maximum entropy approach. Tech-
nical report, School of Computer Science Carnegie
Mellon University.
F. Sha and F. Pereira. 2003. Shallow parsing
with conditional random fields. In Proceedings of
HLT/NAACL’03.
C. Sutton and A. McCallum. 2004. Collective segmen-
tation and labeling of distant entities in information
extraction. In ICML Workshop on Statistical Rela-
tional Learning.
</reference>
<page confidence="0.998671">
419
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.689504">
<title confidence="0.999923">Exploiting Non-local Features for Spoken Language Understanding</title>
<author confidence="0.998306">Jeong Geunbae Lee</author>
<affiliation confidence="0.9976575">Department of Computer Science &amp; Engineering Pohang University of Science and Technology,</affiliation>
<address confidence="0.912041">San 31 Hyoja-dong, Nam-gu Pohang 790-784, Korea</address>
<abstract confidence="0.989993823529412">In this paper, we exploit non-local features as an estimate of long-distance dependencies to improve performance on the statistical spoken language understanding (SLU) problem. The statistical natural language parsers trained on text perform unreliably to encode non-local information on spoken language. An alternative method we propose is to use trigger pairs that are automatically extracted by a feature induction algorithm. We describe a light version of the inducer in which a simple modification is efficient and successful. We evaluate our method on an SLU task and show an error reduction of up to 27% over the base local model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL’05,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="1848" citStr="Finkel et al., 2005" startWordPosition="274" endWordPosition="277">mputational linguistics. It is the key limitation in bettering sequential models in various natural language tasks. Thus, we need new methods to import non-local information into sequential models. There are two types of method for using nonlocal information. One is to add edges to structure to allow higher-order dependencies and another is to add features (or observable variables) to encode the non-locality. An additional consistent edge of a linear-chain conditional random field (CRF) explicitly models the dependencies between distant occurrences of similar words (Sutton and McCallum, 2004; Finkel et al., 2005). However, this approach requires additional time complexity in inference/learning time and it is only suitable for representing constraints by enforcing label consistency. We wish to identify ambiguous labels with more general dependency without additional time cost in inference/learning time. Another approach to modeling non-locality is to use observational features which can capture non-local information. Traditionally, many systems prefer to use a syntactic parser. In a language understanding task, the head word dependencies or parse tree path are successfully applied to learn and predict </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>J. R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings ofACL’05, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="2530" citStr="Gildea and Jurafsky, 2002" startWordPosition="370" endWordPosition="373">xity in inference/learning time and it is only suitable for representing constraints by enforcing label consistency. We wish to identify ambiguous labels with more general dependency without additional time cost in inference/learning time. Another approach to modeling non-locality is to use observational features which can capture non-local information. Traditionally, many systems prefer to use a syntactic parser. In a language understanding task, the head word dependencies or parse tree path are successfully applied to learn and predict semantic roles, especially those with ambiguous labels (Gildea and Jurafsky, 2002). Although the power of syntactic structure is impressive, using the parser-based feature fails to encode correct global information because of the low accuracy of a modern parser. Furthermore the inaccurate result of parsing is more serious in a spoken language understanding (SLU) task. In contrast to written language, spoken language loses much information including grammar, structure or morphology and contains some errors in automatically recognized speech. To solve the above problems, we present one method to exploit non-local information – the trigger feature. In this paper, we incorporat</context>
<context position="9376" citStr="Gildea and Jurafsky, 2002" startWordPosition="1473" endWordPosition="1477">pose an approach to exploit non-local information in the next section. 3 Incorporating Non-local Information 3.1 Using Trigger Features To exploit non-local information to sequential labeling for a statistical SLU, we can use two approaches; a syntactic parser-based and a datadriven approach. Traditionally, information extraction and language understanding fields have usually used a syntactic parser to encode global information (e.g. parse tree path, governing category, or head word) over a local model. In a semantic role labeling task, the syntax and semantics are correlated with each other (Gildea and Jurafsky, 2002), that is, the global structure of the sentence is useful for identifying ambiguous semantic roles. However the problem is the poor accuracy of the syntactic parser with this type of feature. In addition, recognized utterances are erroneous and the spoken language has no capital letters, no additional symbols, and sometimes no grammar, so it is difficult to use a parser in an SLU problem. Another solution is a data-driven method, which uses statistics to find features that are approximately modeling long-distance dependencies. The simplest way is to use identical words in history or lexical co</context>
<context position="20102" citStr="Gildea and Jurafsky, 2002" startWordPosition="3274" endWordPosition="3277">ecific words at location i, or locations within five words of i (−2,−1,0,+1,+2 words on current position i). We also use the partof-speech (POS) tags and phrase labels with partial parsing. Like words, the two basic linguistic features are located within five tokens. For comparison, we exploit the two groups of nonlocal syntax parser-based features; we use Collins parser and extract this type of features from the parse trees. The first consists of the head word and POS-tag of the head word. The second group includes governing category and parse tree paths introduced by semantic role labeling (Gildea and Jurafsky, 2002). Following the previous studies 416 Local feature templates -lexical words -part-of-speech (POS) tags -phrase chunk labels Grammar-based feature templates -head word / POS-tag -parse tree path and governing category Trigger feature templates -word pairs (wi → wj), |i − j |&gt; 2 -feature pairs between words, POS-tags, and chunk labels (fi → fj), |i − j |&gt; 2 -null pairs (e → wj) Figure 3: Feature templates of semantic role labeling, the parse tree path improves the classification performance of semantic role labeling. Finally, we use the trigger pairs that are automatically extracted from the tra</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Gillick</author>
<author>S Cox</author>
</authors>
<title>Some statistical issues in the comparison of speech recognition algorithms.</title>
<date>1989</date>
<booktitle>In Proceedings ofICASSP,</booktitle>
<pages>532--535</pages>
<contexts>
<context position="21961" citStr="Gillick and Cox, 1989" startWordPosition="3577" endWordPosition="3580">using only word features. The performance is decreased by adding the additional local features (POS-tags and chunk labels) because the pre-processor brings more errors to the system for spoken dialog. The parser-based and trigger features are added to two baselines: word only and all local features. The result shows that the trigger feature is more robust to an SLU task than the features generated from the syntactic parser. The parse tree path and governing category show a small improvement of performance over local features, but it is rather insignificant (word vs. word+path, McNemar’s test (Gillick and Cox, 1989); p = 0.022). In contrast, the trigger features significantly improve the performance of the system for both Text and ASR inputs. The differences between the trigger and the others are statistically significant (McNemar’s test; p &lt; 0.001 for both Text and ASR). Table 1: The result of local features, parser-based features and trigger features Feature set F1 (Text) F1 (ASR) word (w) 94.79 71.79 w + POStag (p) 94.57 71.61 w + chunk (c) 94.70 71.64 local (w+p+c) 94.41 71.60 w + head (h) 94.55 71.76 w + path (t) 95.07 72.17 w + h + t 94.84 72.09 local + head (h) 94.17 71.39 local + path (t) 94.80 7</context>
</contexts>
<marker>Gillick, Cox, 1989</marker>
<rawString>L. Gillick and S. Cox. 1989. Some statistical issues in the comparison of speech recognition algorithms. In Proceedings ofICASSP, pages 532–535.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y He</author>
<author>S Young</author>
</authors>
<title>Semantic processing using the hidden vector state model.</title>
<date>2005</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="4808" citStr="He and Young, 2005" startWordPosition="734" endWordPosition="737">gs from recognized utterances and to fill the correct values into a semantic frame structure. A semantic frame (or template) is a well-formed and machine readable structure of extracted information consisting of slot/value pairs. An example of such a reference frame is as follows. &lt;s&gt; i wanna go from denver to new york on november eighteenth &lt;/s&gt; FROMLOC.CITY NAME = denver TOLOC.CITY NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (Pellom et al., 2000; He and Young, 2005). In this example, the slot labels are two-level hierarchical; such as FROMLOC.CITY NAME. This hierarchy differentiates the semantic frame extraction problem from the named entity recognition (NER) problem. Regardless of the fact that there are some differences between SLU and NER, we can still apply well-known techniques used in NER to an SLU problem. Following (Ramshaw and Marcus, 1995), the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O). A two-level hierarchical slot can be considered as an integr</context>
<context position="25596" citStr="He and Young, 2005" startWordPosition="4205" endWordPosition="4208"> local features (Approx. 1) and using an unstructured model on the selection stage (Approx. 2), Table 3 shows the results of variant versions of the algorithm. Surprisingly, the selection criterion based on ME (the unstructured model) is better than CRF (the structured model) not only for time cost but also for the performance on our experiment4. This result shows that local information provides the fundamental decision clues. Our modification of the algorithm to induce features for CRF is sufficiently fast for practical usage. 5 Related Work and Discussion The most relevant previous work is (He and Young, 2005) who describes an generative approach – hidden vector state (HVS) model. They used 1,178 test utterances with 18 classes for 1st level label, and published the resulting F1 score of 88.07. Using the same test data and classes, we achieved the 92.77 F1-performance, as well 4In our analysis, 10∼20 iterations for each round of inducing procedure are insufficient in optimizing the model in CRF (empty) inducer. Thus, the resulting parameters are under-fitted and selected features are infeasible. We need more iteration to fit the parameters, but they require too much learning time (&gt; 1 day). as 39% </context>
</contexts>
<marker>He, Young, 2005</marker>
<rawString>Y. He and S. Young. 2005. Semantic processing using the hidden vector state model. Computer Speech &amp; Language, 19(1):85–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings ofICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="6019" citStr="Lafferty et al., 2001" startWordPosition="929" endWordPosition="932">s an integrated flattened slot. For example, FROMLOC.CITY NAME and TOLOC.CITY NAME are different on this slot definition scheme. Now, we can formalize the SLU problem as a sequential labeling problem, y* = arg maxy P(y|x). In this case, input word sequences x are not only lexical strings, but also multiple linguistic features. To extract semantic frames from utterance inputs, we use a linearchain CRF model; a model that assigns a joint probability distribution over labels which is conditional on the input sequences, where the distribution respects the independent relations encoded in a graph (Lafferty et al., 2001). A linear-chain CRF is defined as follows. Let G be an undirected model over sets of random variables x and y. The graph G with parameters A = {A,...} defines a conditional probability for a state (or label) sequence y = y1, ... , yT, given an input x = x1, ... , xT, to be 1 T Pn(y|x) = Zx exp (EEAt=1 kfk(yt−1, yt, x, t) where Zx is the normalization factor that makes the probability of all state sequences sum to one. fk(yt−1, yt, x, t) is an arbitrary linguistic feature function which is often binary-valued in NLP tasks. Ak is a trained parameter associated with feature fk. The feature funct</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings ofICML, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>Efficiently inducing features of conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of UAI,</booktitle>
<pages>403</pages>
<contexts>
<context position="11696" citStr="McCallum, 2003" startWordPosition="1858" endWordPosition="1859">y lexical collocation without reference labels y, and MI based selection tends to excessively select the irrelevant triggers. Recall that our goal is to find the significantly correlated trigger pairs which improve the model. Therefore, we use a more appropriate selection method for sequential supervised learning. 3.2 Selecting Trigger Feature We present another approach to extract relevant triggers and exploit them in a linear-chain CRF. Our approach is based on an automatic feature induction algorithm, which is a novel method to select a feature in an exponential model (Pietra et al., 1997; McCallum, 2003). We follow McCallum’s work which is an efficient method to induce features in a linear-chain CRF model. Following the framework of feature inducing, we start the algorithm with an empty set, and iteratively increase the bundle of features including local features and trigger features. Our basic assumption, however, is that the local information should be included because the local features are the basis of the decision to identify the classes, and they reduce the 1In our experiment, the pair (dec. fly) cannot be selected because this MI score is too low. However, the trigger pair is a binary </context>
<context position="14730" citStr="McCallum, 2003" startWordPosition="2374" endWordPosition="2375"> without the state-structured model. In the result, we calculate the gain of candidate triggers, and select trigger features over a light ME model instead of a huge computational CRF model2. We can efficiently assess many candidate trigger features in parallel by assuming that the old features remain fixed while estimating the gain. The gain of trigger features can be calculated on the old model that is trained with the local and added trigger pairs in previous iterations. Rather than summing over all training instances, we only need to use the mislabeled N tokens by the current parameter AW (McCallum, 2003). From misclassified instances, we generate the candidates of trigger pairs, that is, all pairs of current words and others within the sentence. With the candidate feature set, the gain is �GA(i)(g) = N µ��E[g] (fiT ) − N log (EA(i)[exp(wg)|xj]) − µ2 PA(i)(y|x) exp t=1 µg(yt−1, yt, x, t) E j=1 Z.(AW, g, µ) . 2σ2. Note that Z.(AW, g, µ) is the marginal sum over all states of y&apos;. Following (Pietra et al., 1997; McCallum, 2003), the mean field approximation and agglomerated features allows us to treat the above calculation as the independent inference problem rather than sequential inference. We </context>
<context position="27171" citStr="McCallum, 2003" startWordPosition="4459" endWordPosition="4460"> relatively easy to use without having additional complexity of models. Trigger word pairs are introduced and successfully applied in a language modeling task. (Rosenfeld, 1994) demonstrated that the trigger word pairs improve the perplexity in ME-based language models. Our method extends this idea to sequential supervised learning problems. Our trigger selection criterion is based on the automatic feature inducing algorithm, and it allows us to generalize the arbitrary pairs of features. Our method is based on two works of feature induction on an exponential model, (Pietra et al., 1997) and (McCallum, 2003). Our induction algorithm builds on McCallum’s method which presents an efficient procedure to induce features on CRF. (McCallum, 2003) suggested using only the mislabeled events rather than the whole training events. This intuitional suggestion has offered us fast training. We added two additional approximations to reduce the time cost; 1) an inducing procedure over a conditional non-structured inference problem rather than an approximated sequential inference problem, and 2) training with a local feature set, which is the basic information to identify the labels. In this paper, our approach </context>
</contexts>
<marker>McCallum, 2003</marker>
<rawString>A. McCallum. 2003. Efficiently inducing features of conditional random fields. In Proceedings of UAI, page 403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Pellom</author>
<author>W Ward</author>
<author>S S Pradhan</author>
</authors>
<title>The cu communicator: An architecture for dialogue systems.</title>
<date>2000</date>
<booktitle>In Proceedings ofICSLP.</booktitle>
<contexts>
<context position="4787" citStr="Pellom et al., 2000" startWordPosition="730" endWordPosition="733">tract semantic meanings from recognized utterances and to fill the correct values into a semantic frame structure. A semantic frame (or template) is a well-formed and machine readable structure of extracted information consisting of slot/value pairs. An example of such a reference frame is as follows. &lt;s&gt; i wanna go from denver to new york on november eighteenth &lt;/s&gt; FROMLOC.CITY NAME = denver TOLOC.CITY NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (Pellom et al., 2000; He and Young, 2005). In this example, the slot labels are two-level hierarchical; such as FROMLOC.CITY NAME. This hierarchy differentiates the semantic frame extraction problem from the named entity recognition (NER) problem. Regardless of the fact that there are some differences between SLU and NER, we can still apply well-known techniques used in NER to an SLU problem. Following (Ramshaw and Marcus, 1995), the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O). A two-level hierarchical slot can be co</context>
</contexts>
<marker>Pellom, Ward, Pradhan, 2000</marker>
<rawString>B. L. Pellom, W. Ward, and S. S. Pradhan. 2000. The cu communicator: An architecture for dialogue systems. In Proceedings ofICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Della Pietra</author>
<author>V J Della Pietra</author>
<author>J Lafferty</author>
</authors>
<title>Inducing features of random fields.</title>
<date>1997</date>
<journal>IEEE Trans. Pattern Anal. Mach. Intell,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="3510" citStr="Pietra et al., 1997" startWordPosition="525" endWordPosition="528"> including grammar, structure or morphology and contains some errors in automatically recognized speech. To solve the above problems, we present one method to exploit non-local information – the trigger feature. In this paper, we incorporate trigger pairs into a sequential model, a linear-chain CRF. Then we describe an efficient algorithm to extract the trigger feature from the training data itself. The framework for inducing trigger features is based on the Kullback-Leibler divergence criterion which measures the improvement of loglikelihood on the current parameters by adding a new feature (Pietra et al., 1997). To reduce the cost of feature selection, we suggest a modified 412 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 412–419, Sydney, July 2006. c�2006 Association for Computational Linguistics version of an inducing algorithm which is quite efficient. We evaluate our method on an SLU task, and demonstrate the improvements on both transcripts and recognition outputs. On a real-world problem, our modified version of a feature selection algorithm is very efficient for both performance and time complexity. 2 Spoken Language Understanding as a Sequential Labeling Problem </context>
<context position="11679" citStr="Pietra et al., 1997" startWordPosition="1854" endWordPosition="1857">owever, considers only lexical collocation without reference labels y, and MI based selection tends to excessively select the irrelevant triggers. Recall that our goal is to find the significantly correlated trigger pairs which improve the model. Therefore, we use a more appropriate selection method for sequential supervised learning. 3.2 Selecting Trigger Feature We present another approach to extract relevant triggers and exploit them in a linear-chain CRF. Our approach is based on an automatic feature induction algorithm, which is a novel method to select a feature in an exponential model (Pietra et al., 1997; McCallum, 2003). We follow McCallum’s work which is an efficient method to induce features in a linear-chain CRF model. Following the framework of feature inducing, we start the algorithm with an empty set, and iteratively increase the bundle of features including local features and trigger features. Our basic assumption, however, is that the local information should be included because the local features are the basis of the decision to identify the classes, and they reduce the 1In our experiment, the pair (dec. fly) cannot be selected because this MI score is too low. However, the trigger </context>
<context position="15141" citStr="Pietra et al., 1997" startWordPosition="2449" endWordPosition="2452">trained with the local and added trigger pairs in previous iterations. Rather than summing over all training instances, we only need to use the mislabeled N tokens by the current parameter AW (McCallum, 2003). From misclassified instances, we generate the candidates of trigger pairs, that is, all pairs of current words and others within the sentence. With the candidate feature set, the gain is �GA(i)(g) = N µ��E[g] (fiT ) − N log (EA(i)[exp(wg)|xj]) − µ2 PA(i)(y|x) exp t=1 µg(yt−1, yt, x, t) E j=1 Z.(AW, g, µ) . 2σ2. Note that Z.(AW, g, µ) is the marginal sum over all states of y&apos;. Following (Pietra et al., 1997; McCallum, 2003), the mean field approximation and agglomerated features allows us to treat the above calculation as the independent inference problem rather than sequential inference. We can evaluate the probability of state y with an adding trigger pair given observation x separately as follows. PA(i)(y|x, t) exp (µg(yt, x, t)) PA(i)+g,µ(y|x, t) = Z.(AW, g, µ) Using the estimated gains, we can select a small portion of all candidates, and retrain the model with selected features. We iteratively perform the selection algorithm with some stop conditions (excess of maximum iteration or no adde</context>
<context position="27150" citStr="Pietra et al., 1997" startWordPosition="4454" endWordPosition="4457">rigger features, which are relatively easy to use without having additional complexity of models. Trigger word pairs are introduced and successfully applied in a language modeling task. (Rosenfeld, 1994) demonstrated that the trigger word pairs improve the perplexity in ME-based language models. Our method extends this idea to sequential supervised learning problems. Our trigger selection criterion is based on the automatic feature inducing algorithm, and it allows us to generalize the arbitrary pairs of features. Our method is based on two works of feature induction on an exponential model, (Pietra et al., 1997) and (McCallum, 2003). Our induction algorithm builds on McCallum’s method which presents an efficient procedure to induce features on CRF. (McCallum, 2003) suggested using only the mislabeled events rather than the whole training events. This intuitional suggestion has offered us fast training. We added two additional approximations to reduce the time cost; 1) an inducing procedure over a conditional non-structured inference problem rather than an approximated sequential inference problem, and 2) training with a local feature set, which is the basic information to identify the labels. In this</context>
</contexts>
<marker>Pietra, Pietra, Lafferty, 1997</marker>
<rawString>S. Della Pietra, V. J. Della Pietra, and J. Lafferty. 1997. Inducing features of random fields. IEEE Trans. Pattern Anal. Mach. Intell, 19(4):380–393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In 3rd Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<contexts>
<context position="5199" citStr="Ramshaw and Marcus, 1995" startWordPosition="795" endWordPosition="798">Y NAME = new york MONTH NAME = november DAY NUMBER = eighteenth This example from air travel data (CUCommunicator corpus) was automatically generated by a Phoenix parser and manually corrected (Pellom et al., 2000; He and Young, 2005). In this example, the slot labels are two-level hierarchical; such as FROMLOC.CITY NAME. This hierarchy differentiates the semantic frame extraction problem from the named entity recognition (NER) problem. Regardless of the fact that there are some differences between SLU and NER, we can still apply well-known techniques used in NER to an SLU problem. Following (Ramshaw and Marcus, 1995), the slot labels are drawn from a set of classes constructed by extending each label by three additional symbols, Beginning/Inside/Outside (B/I/O). A two-level hierarchical slot can be considered as an integrated flattened slot. For example, FROMLOC.CITY NAME and TOLOC.CITY NAME are different on this slot definition scheme. Now, we can formalize the SLU problem as a sequential labeling problem, y* = arg maxy P(y|x). In this case, input word sequences x are not only lexical strings, but also multiple linguistic features. To extract semantic frames from utterance inputs, we use a linearchain CR</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. P. Marcus. 1995. Text chunking using transformation-based learning. In 3rd Workshop on Very Large Corpora, pages 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
</authors>
<title>Adaptive statistical language modeling: A maximum entropy approach.</title>
<date>1994</date>
<tech>Technical report,</tech>
<institution>School of Computer Science Carnegie Mellon University.</institution>
<contexts>
<context position="10099" citStr="Rosenfeld, 1994" startWordPosition="1593" endWordPosition="1594"> the problem is the poor accuracy of the syntactic parser with this type of feature. In addition, recognized utterances are erroneous and the spoken language has no capital letters, no additional symbols, and sometimes no grammar, so it is difficult to use a parser in an SLU problem. Another solution is a data-driven method, which uses statistics to find features that are approximately modeling long-distance dependencies. The simplest way is to use identical words in history or lexical co-occurrence, but we wish to use a more general tool; triggering. The trigger word pairs are introduced by (Rosenfeld, 1994). A trigger pair is the basic element for extracting information from the long-distance document history. In language modeling, n-gram based on the Markovian assumption cannot represent higher-order dependencies, but it can automatically extract trigger word pairs from data. The pair (A → B) means that word A and B are significantly correlated, that is, when A occurs in the document, it triggers B, causing its probability estimate to change. To select reasonable pairs from arbitrary word pairs, (Rosenfeld, 1994) used averaged mutual information (MI). In this scheme, the MI score of one pair is</context>
<context position="16673" citStr="Rosenfeld, 1994" startWordPosition="2697" endWordPosition="2698">e similar (see the experiment section). 415 Algorithm InduceLearn(x,y) triggers +- {e} and i +- 0 while |pairs |&gt; 0 and i &lt; maxiter do A(i) +- TrainME(x, y) P(ye|xe) +- Evaluate(x, y, A(i)) c +- MakeCandidate(xe) GAM +- EstimateGain(c, P(ye|xe)) pairs +- SelectTrigger(c, GAM) x +- UpdateObs(x, pairs) triggers +- triggers U pairs and i +- i + 1 end while A(i+1) +- TrainCRF(x, y) return A(i+1) Figure 2: Outline of trigger feature induction algorithm algorithms is described in figure 2. In the next section, we empirically prove the effectiveness of our algorithm. The trigger pairs introduced by (Rosenfeld, 1994) are just word pairs. Here, we can generalize the trigger pairs to any arbitrary pairs of features. For example, the feature pair (of-*BPP) is useful in deciding the correct answer PERIOD OF DAY-I in “in the middle of the day.” Without constraints on generating the pairs (e.g. at most 3 distant tokens), the candidates can be arbitrary conjunctions of features3. Therefore we can explore any features including local conjunction or non-local singleton features in a uniform framework. 4 Experiments 4.1 Experimental Setup We evaluate our method on the CU-Communicator corpus. It consists of 13,983 u</context>
<context position="26733" citStr="Rosenfeld, 1994" startWordPosition="4387" endWordPosition="4389"> fit the parameters, but they require too much learning time (&gt; 1 day). as 39% of error reduction compared to the previous result. Our system uses a discriminative approach, which directly models the conditional distribution, and it is sufficient for classification task. To capture long-distance dependency, HVS uses a context-free model, which increases the complexity of models. In contrast, we use non-local trigger features, which are relatively easy to use without having additional complexity of models. Trigger word pairs are introduced and successfully applied in a language modeling task. (Rosenfeld, 1994) demonstrated that the trigger word pairs improve the perplexity in ME-based language models. Our method extends this idea to sequential supervised learning problems. Our trigger selection criterion is based on the automatic feature inducing algorithm, and it allows us to generalize the arbitrary pairs of features. Our method is based on two works of feature induction on an exponential model, (Pietra et al., 1997) and (McCallum, 2003). Our induction algorithm builds on McCallum’s method which presents an efficient procedure to induce features on CRF. (McCallum, 2003) suggested using only the m</context>
</contexts>
<marker>Rosenfeld, 1994</marker>
<rawString>R. Rosenfeld. 1994. Adaptive statistical language modeling: A maximum entropy approach. Technical report, School of Computer Science Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/NAACL’03.</booktitle>
<contexts>
<context position="7373" citStr="Sha and Pereira, 2003" startWordPosition="1166" endWordPosition="1169">current time, t. Large positive values for Ak indicate a preference for such an event, while large negative values make the event unlikely. Parameter estimation of a linear-chain CRF is typically performed by conditional maximum loglikelihood. To avoid overfitting, the 2-norm regularization is applied to penalize on weight vector whose norm is too large. We used a limited memory version of the quasi-Newton method (LBFGS) to optimize this objective function. The L-BFGS method converges super-linearly to the solution, so it can be an efficient optimization technique on large-scale NLP problems (Sha and Pereira, 2003). A linear-chain CRF has been previously applied to obtain promising results in various natural language tasks, but the linear-chain structure is deficient in modeling long-distance dependencies because of its limited structure (n-th order Markov chains). 2.2 Long-distance Dependency in Spoken Language Understanding In most sequential supervised learning problems including SLU, the feature function fk(yt−1, yt, xt, t) indicates only local information k 413 for practical reasons. With sufficient local context (e.g. a sliding window of width 5), inference and learning are both efficient. However</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>F. Sha and F. Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of HLT/NAACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sutton</author>
<author>A McCallum</author>
</authors>
<title>Collective segmentation and labeling of distant entities in information extraction.</title>
<date>2004</date>
<booktitle>In ICML Workshop on Statistical Relational Learning.</booktitle>
<contexts>
<context position="1826" citStr="Sutton and McCallum, 2004" startWordPosition="269" endWordPosition="273"> considered at length in computational linguistics. It is the key limitation in bettering sequential models in various natural language tasks. Thus, we need new methods to import non-local information into sequential models. There are two types of method for using nonlocal information. One is to add edges to structure to allow higher-order dependencies and another is to add features (or observable variables) to encode the non-locality. An additional consistent edge of a linear-chain conditional random field (CRF) explicitly models the dependencies between distant occurrences of similar words (Sutton and McCallum, 2004; Finkel et al., 2005). However, this approach requires additional time complexity in inference/learning time and it is only suitable for representing constraints by enforcing label consistency. We wish to identify ambiguous labels with more general dependency without additional time cost in inference/learning time. Another approach to modeling non-locality is to use observational features which can capture non-local information. Traditionally, many systems prefer to use a syntactic parser. In a language understanding task, the head word dependencies or parse tree path are successfully applied</context>
</contexts>
<marker>Sutton, McCallum, 2004</marker>
<rawString>C. Sutton and A. McCallum. 2004. Collective segmentation and labeling of distant entities in information extraction. In ICML Workshop on Statistical Relational Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>