<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9997085">
A Bottom-up Approach to Sentence Ordering
for Multi-document Summarization
</title>
<author confidence="0.987261">
Danushka Bollegala Naoaki Okazaki * Mitsuru Ishizuka
</author>
<affiliation confidence="0.993123">
Graduate School of Information Science and Technology
The University of Tokyo
</affiliation>
<address confidence="0.845031">
7-3-1, Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan
</address>
<email confidence="0.99522">
{danushka,okazaki}@mi.ci.i.u-tokyo.ac.jp
ishizuka@i.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.99468" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902777777778">
Ordering information is a difficult but
important task for applications generat-
ing natural-language text. We present
a bottom-up approach to arranging sen-
tences extracted for multi-document sum-
marization. To capture the association and
order of two textual segments (eg, sen-
tences), we define four criteria, chronol-
ogy, topical-closeness, precedence, and
succession. These criteria are integrated
into a criterion by a supervised learning
approach. We repeatedly concatenate two
textual segments into one segment based
on the criterion until we obtain the overall
segment with all sentences arranged. Our
experimental results show a significant im-
provement over existing sentence ordering
strategies.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.97227864">
Multi-document summarization (MDS) (Radev
and McKeown, 1999) tackles the information
overload problem by providing a condensed ver-
sion of a set of documents. Among a number
of sub-tasks involved in MDS, eg, sentence ex-
traction, topic detection, sentence ordering, infor-
mation extraction, sentence generation, etc., most
MDS systems have been based on an extraction
method, which identifies important textual seg-
ments (eg, sentences or paragraphs) in source doc-
uments. It is important for such MDS systems
to determine a coherent arrangement of the tex-
tual segments extracted from multi-documents in
order to reconstruct the text structure for summa-
rization. Ordering information is also essential for
Research Fellow of the Japan Society for the Promotion
of Science (JSPS)
other text-generation applications such as Ques-
tion Answering.
A summary with improperly ordered sen-
tences confuses the reader and degrades the qual-
ity/reliability of the summary itself. Barzi-
lay (2002) has provided empirical evidence that
proper order of extracted sentences improves their
readability significantly. However, ordering a
set of sentences into a coherent text is a non-
trivial task. For example, identifying rhetorical
relations (Mann and Thompson, 1988) in an or-
dered text has been a difficult task for computers,
whereas our task is even more complicated: to
reconstruct such relations from unordered sets of
sentences. Source documents for a summary may
have been written by different authors, by different
writing styles, on different dates, and based on dif-
ferent background knowledge. We cannot expect
that a set of extracted sentences from such diverse
documents will be coherent on their own.
Several strategies to determine sentence order-
ing have been proposed as described in section 2.
However, the appropriate way to combine these
strategies to achieve more coherent summaries re-
mains unsolved. In this paper, we propose four
criteria to capture the association of sentences in
the context of multi-document summarization for
newspaper articles. These criteria are integrated
into one criterion by a supervised learning ap-
proach. We also propose a bottom-up approach
in arranging sentences, which repeatedly concate-
nates textual segments until the overall segment
with all sentences arranged, is achieved.
</bodyText>
<sectionHeader confidence="0.999866" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997094333333333">
Existing methods for sentence ordering are di-
vided into two approaches: making use of chrono-
logical information (McKeown et al., 1999; Lin
</bodyText>
<page confidence="0.985727">
385
</page>
<note confidence="0.541553">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385–392,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.998545793650794">
and Hovy, 2001; Barzilay et al., 2002; Okazaki
et al., 2004); and learning the natural order of sen-
tences from large corpora not necessarily based on
chronological information (Lapata, 2003; Barzi-
lay and Lee, 2004). A newspaper usually dissem-
inates descriptions of novel events that have oc-
curred since the last publication. For this reason,
ordering sentences according to their publication
date is an effective heuristic for multidocument
summarization (Lin and Hovy, 2001; McKeown
et al., 1999). Barzilay et al. (2002) have proposed
an improved version of chronological ordering by
first grouping sentences into sub-topics discussed
in the source documents and then arranging the
sentences in each group chronologically.
Okazaki et al. (2004) have proposed an algo-
rithm to improve chronological ordering by re-
solving the presuppositional information of ex-
tracted sentences. They assume that each sen-
tence in newspaper articles is written on the basis
that presuppositional information should be trans-
ferred to the reader before the sentence is inter-
preted. The proposed algorithm first arranges sen-
tences in a chronological order and then estimates
the presuppositional information for each sentence
by using the content of the sentences placed before
each sentence in its original article. The evaluation
results show that the proposed algorithm improves
the chronological ordering significantly.
Lapata (2003) has suggested a probabilistic
model of text structuring and its application to the
sentence ordering. Her method calculates the tran-
sition probability from one sentence to the next
from a corpus based on the Cartesian product be-
tween two sentences defined using the following
features: verbs (precedent relationships of verbs
in the corpus); nouns (entity-based coherence by
keeping track of the nouns); and dependencies
(structure of sentences). Although she has not
compared her method with chronological order-
ing, it could be applied to generic domains, not re-
lying on the chronological clue provided by news-
paper articles.
Barzilay and Lee (2004) have proposed con-
tent models to deal with topic transition in do-
main specific text. The content models are formal-
ized by Hidden Markov Models (HMMs) in which
the hidden state corresponds to a topic in the do-
main of interest (eg, earthquake magnitude or pre-
vious earthquake occurrences), and the state tran-
sitions capture possible information-presentation
orderings. The evaluation results showed that
their method outperformed Lapata’s approach by a
wide margin. They did not compare their method
with chronological ordering as an application of
multi-document summarization.
As described above, several good strate-
gies/heuristics to deal with the sentence ordering
problem have been proposed. In order to integrate
multiple strategies/heuristics, we have formalized
them in a machine learning framework and have
considered an algorithm to arrange sentences us-
ing the integrated strategy.
</bodyText>
<sectionHeader confidence="0.970624" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.9921192">
We define notation a &gt;- b to represent that sen-
tence a precedes sentence b. We use the term seg-
ment to describe a sequence of ordered sentences.
When segment A consists of sentences a1, a2, ...,
am in this order, we denote as:
</bodyText>
<figure confidence="0.5558124">
A = (a1 &gt;-a2&gt;- ... &gt;-am). (1)
The two segments A and B can be ordered either
B after A or A after B. We define the notation
A &gt;- B to show that segment A precedes segment
B.
</figure>
<bodyText confidence="0.9990432">
Let us consider a bottom-up approach in arrang-
ing sentences. Starting with a set of segments ini-
tialized with a sentence for each, we concatenate
two segments, with the strongest association (dis-
cussed later) of all possible segment pairs, into
one segment. Repeating the concatenating will
eventually yield a segment with all sentences ar-
ranged. The algorithm is considered as a variation
of agglomerative hierarchical clustering with the
ordering information retained at each concatenat-
ing process.
The underlying idea of the algorithm, a bottom-
up approach to text planning, was proposed by
Marcu (1997). Assuming that the semantic units
(sentences) and their rhetorical relations (eg, sen-
tence a is an elaboration of sentenced) are given,
he transcribed a text structuring task into the prob-
lem of finding the best discourse tree that satisfied
the set of rhetorical relations. He stated that global
coherence could be achieved by satisfying local
coherence constraints in ordering and clustering,
thereby ensuring that the resultant discourse tree
was well-formed.
Unfortunately, identifying the rhetorical rela-
tion between two sentences has been a difficult
</bodyText>
<page confidence="0.987164">
386
</page>
<figure confidence="0.890501">
G = (b a c d)
E = (b a)
Segments
A B C D
f (association strength)
F = (c d)
Sentences
a b c d
</figure>
<figureCaption confidence="0.995541">
Figure 1: Arranging four sentences A, B, C, and
D with a bottom-up approach.
</figureCaption>
<bodyText confidence="0.999347571428571">
task for computers. However, the bottom-up algo-
rithm for arranging sentences can still be applied
only if the direction and strength of the associa-
tion of the two segments (sentences) are defined.
Hence, we introduce a function f(A &gt;- B) to rep-
resent the direction and strength of the association
of two segments A and B,
</bodyText>
<equation confidence="0.710737">
f (A &gt;- B) = ! p (if A precedes B) (2)
l 0 (if B precedes A) ,
</equation>
<bodyText confidence="0.9280996">
where p (0 &lt; p &lt; 1) denotes the association
strength of the segments A and B. The associa-
tion strengths of the two segments with different
directions, eg, f(A &gt;- B) and f(B &gt;- A), are not
always identical in our definition,
</bodyText>
<equation confidence="0.786764">
f(A &gt;- B) =� f(B &gt;- A). (3)
</equation>
<figureCaption confidence="0.827406">
Figure 1 shows the process of arranging four
sentences a, b, c, and d. Firstly, we initialize four
segments with a sentence for each,
</figureCaption>
<bodyText confidence="0.88525725">
A = (a), B = (b), C = (c), D = (d). (4)
Suppose that f(B &gt;- A) has the highest value of
all possible pairs, eg, f(A &gt;- B), f(C &gt;- D), etc,
we concatenate B and A to obtain a new segment,
</bodyText>
<equation confidence="0.996764">
E = (b &gt;- a). (5)
</equation>
<bodyText confidence="0.99996225">
Then we search for the segment pair with the
strongest association. Supposing that f(C &gt;- D)
has the highest value, we concatenate C and D to
obtain a new segment,
</bodyText>
<equation confidence="0.993308">
F = (c &gt;- d). (6)
</equation>
<bodyText confidence="0.9957905">
Finally, comparing f(E &gt;- F) and f(F &gt;- E), we
obtain the global sentence ordering,
</bodyText>
<equation confidence="0.979261">
G = (b &gt;- a &gt;- c &gt;- d). (7)
</equation>
<bodyText confidence="0.999425083333333">
In the above description, we have not defined
the association of the two segments. The previ-
ous work described in Section 2 has addressed the
association of textual segments (sentences) to ob-
tain coherent orderings. We define four criteria to
capture the association of two segments: chronol-
ogy; topical-closeness; precedence; and succes-
sion. These criteria are integrated into a function
f(A &gt;- B) by using a machine learning approach.
The rest of this section explains the four criteria
and an integration method with a Support Vector
Machine (SVM) (Vapnik, 1998) classifier.
</bodyText>
<subsectionHeader confidence="0.999058">
3.1 Chronology criterion
</subsectionHeader>
<bodyText confidence="0.999965142857143">
Chronology criterion reflects the chronological or-
dering (Lin and Hovy, 2001; McKeown et al.,
1999), which arranges sentences in a chronologi-
cal order of the publication date. We define the as-
sociation strength of arranging segments B after A
measured by a chronology criterion fchro(A &gt;- B)
in the following formula,
</bodyText>
<equation confidence="0.9668575">
fchro(A &gt;- B)
1 T(am) &lt; T(b1)
1 [D(am) = D(b1)] n [N(am) &lt; N(b1)]
0.5 [T(am) = T(b1)] n [D(am) =� D(b1)] .
0 otherwise
(8)
</equation>
<bodyText confidence="0.933195421052631">
Here, am represents the last sentence in segment
A; b1 represents the first sentence in segment B;
T (s) is the publication date of the sentence s;
D(s) is the unique identifier of the document to
which sentence s belongs: and N(s) denotes the
line number of sentence s in the original docu-
ment. The chronological order of arranging seg-
ment B after A is determined by the comparison
between the last sentence in the segment A and the
first sentence in the segment B.
The chronology criterion assesses the appropri-
ateness of arranging segment B after A if: sen-
tence am is published earlier than b1; or sentence
am appears before b1 in the same article. If sen-
tence am and b1 are published on the same day but
appear in different articles, the criterion assumes
the order to be undefined. If none of the above
conditions are satisfied, the criterion estimates that
segment B will precede A.
</bodyText>
<subsectionHeader confidence="0.995808">
3.2 Topical-closeness criterion
</subsectionHeader>
<bodyText confidence="0.9995455">
The topical-closeness criterion deals with the as-
sociation, based on the topical similarity, of two
</bodyText>
<equation confidence="0.476877666666667">
�
�� �
���
</equation>
<page confidence="0.826059">
387
</page>
<figureCaption confidence="0.999985">
Figure 2: Precedence criterion
Figure 3: Succession criterion
</figureCaption>
<figure confidence="0.89867275">
a1
a2
?
a4
Segment A
a3
average
.... .. .. .... .. ....... .....
, . ... ...... .. .., .... ... ....
.... .. .. .... .. ....... ......
,
. ... ...... .. .., .... ... ....
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
Pb1 Pb2 Pb3
b3
b1
b2
Original article
for sentence b
max
max
Original article
for sentence b3
1
max
Original article
for sentence b2
b1
b2
b3
Segment B
b1
average
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
b2
?
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
b3
Segment A
Segment B
....
,
. ... ...... .. .., .... ... ....
a
3
a1
Sa1
a2
Sa2 Sa3
Original article
for sentence a1
Original article
for sentence a3
max
max
max
Original article
for a2
sentence
</figure>
<equation confidence="0.740391625">
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
.... .. .. .... .. ....... ......
. ... ...... .. .., .... ... ....
.... .. .. .... .. ....... ......
a3 . ... ...... .. .., .... ... ....
a1
a2
</equation>
<bodyText confidence="0.999668875">
segments. The criterion reflects the ordering strat-
egy proposed by Barzilay et al (2002), which
groups sentences referring to the same topic. To
measure the topical closeness of two sentences, we
represent each sentence with a vector whose ele-
ments correspond to the occurrence1 of the nouns
and verbs in the sentence. We define the topical
closeness of two segments A and B as follows,
</bodyText>
<equation confidence="0.988895">
ftopic(A &gt;- B) =|B |bE m aAxsim(a, b). (9)
∈B
</equation>
<bodyText confidence="0.999555555555556">
Here, sim(a, b) denotes the similarity of sentences
a and b, which is calculated by the cosine similar-
ity of two vectors corresponding to the sentences.
For sentence b E B, maxa∈A sim(a, b) chooses
the sentence a E A most similar to sentence b and
yields the similarity. The topical-closeness crite-
rion ftopic(A &gt;- B) assigns a higher value when
the topic referred by segment B is the same as seg-
ment A.
</bodyText>
<subsectionHeader confidence="0.998361">
3.3 Precedence criterion
</subsectionHeader>
<bodyText confidence="0.999879909090909">
Let us think of the case where we arrange seg-
ment A before B. Each sentence in segment B
has the presuppositional information that should
be conveyed to a reader in advance. Given sen-
tence b E B, such presuppositional information
may be presented by the sentences appearing be-
fore the sentence b in the original article. How-
ever, we cannot guarantee whether a sentence-
extraction method for multi-document summa-
rization chooses any sentences before b for a sum-
mary because the extraction method usually deter-
</bodyText>
<footnote confidence="0.998903">
1The vector values are represented by boolean values, i.e.,
1 if the sentence contains a word, otherwise 0.
</footnote>
<bodyText confidence="0.999277636363636">
mines a set of sentences, within the constraint of
summary length, that maximizes information cov-
erage and excludes redundant information. Prece-
dence criterion measures the substitutability of the
presuppositional information of segment B (eg,
the sentences appearing before sentence b) as seg-
ment A. This criterion is a formalization of the
sentence-ordering algorithm proposed by Okazaki
et al, (2004).
We define the precedence criterion in the fol-
lowing formula,
</bodyText>
<equation confidence="0.895784">
1 �
fpre(A &gt;- B) = max sim(a, p).
b∈B a∈A,p∈P,
|
Pb and A by the maximum similari
</equation>
<bodyText confidence="0.99674175">
ty of the pos-
sible sentence combinations, Formula 10 is inter-
preted as the average similarity of the precedent
sentences bPb(b E B) to the segment A.
</bodyText>
<subsectionHeader confidence="0.968406">
3.4 Succession criterion
</subsectionHeader>
<bodyText confidence="0.975402625">
(10)
Here, Pb is a set of sentences appearing before sen-
tence b in the original article; and sim(a, b) de-
notes the cosine similarity of sentences a and b
(defined as in the topical-closeness criterion). Fig-
ure 2 shows an example of calculating the prece-
dence criterion for arranging segment B after A.
We approximate the presuppositional information
for sentence b by sentences Pb, ie, sentences ap-
pearing before the sentence b in the original arti-
cle. Calculating the similarity among sentences in
The idea of succession criterion is the exact op-
posite of the precedence criterion. The succession
criterion assesses the coverage of the succedent in-
formation for segment A by arran
ging segment B
</bodyText>
<figure confidence="0.976117375">
|
B
388
segment before the
partitioning point
Partitioning point
segment after the
partitioning point
a
b
c
d
Partitioning
window
+1 [fchro(A &gt;- B), ftopic(A &gt;- B), fpre(A &gt;- B), fsucc(A &gt;- B)]
−1 [fchro(B &gt;- A), ftopic(B &gt;- A), fpre(B &gt;- A), fsucc(B &gt;- A)]
</figure>
<figureCaption confidence="0.9986715">
Figure 5: Two vectors in a training data generated
from two ordered segments A &gt;- B
Figure 4: Partitioning a human-ordered extract
into pairs of segments
</figureCaption>
<equation confidence="0.92823975">
after A:
fsucc(A &gt;- B) =|S |max sim(s, b).
aEA
(11)
</equation>
<bodyText confidence="0.978992823529412">
Here, Sa is a set of sentences appearing after sen-
tence a in the original article; and sim(a, b) de-
notes the cosine similarity of sentences a and b
(defined as in the topical-closeness criterion). Fig-
ure 3 shows an example of calculating the succes-
sion criterion to arrange segments B after A. The
succession criterion measures the substitutability
of the succedent information (eg, the sentences ap-
pearing after the sentence a E A) as segment B.
3.5 SVM classifier to assess the integrated
criterion
We integrate the four criteria described above
to define the function f(A &gt;- B) to represent
the association direction and strength of the two
segments A and B (Formula 2). More specifi-
cally, given the two segments A and B, function
f(A &gt;- B) is defined to yield the integrated asso-
ciation strength from four values, fchro(A &gt;- B),
ftopic(A &gt;- B), fpre(A &gt;- B), and fsucc(A &gt;- B).
We formalize the integration task as a binary clas-
sification problem and employ a Support Vector
Machine (SVM) as the classifier. We conducted a
supervised learning as follows.
We partition a human-ordered extract into pairs
each of which consists of two non-overlapping
segments. Let us explain the partitioning process
taking four human-ordered sentences, a &gt;- b &gt;-
c &gt;- d shown in Figure 4. Firstly, we place the
partitioning point just after the first sentence a.
Focusing on sentence a arranged just before the
partition point and sentence b arranged just after
we identify the pair {(a), (b)} of two segments
(a) and (b). Enumerating all possible pairs of two
segments facing just before/after the partitioning
point, we obtain the following pairs, {(a), (b &gt;-
c)} and {(a), (b &gt;- c &gt;- d)}. Similarly, segment
pairs, {(b), (c)}, {(a &gt;- b), (c)}, {(b), (c &gt;- d)},
{(a &gt;- b), (c &gt;- d)}, are obtained from the parti-
tioning point between sentence b and c. Collect-
ing the segment pairs from the partitioning point
between sentences c and d (i.e., {(c), (d)}, {(b &gt;-
c), (d)} and {(a &gt;- b &gt;- c), (d)}), we identify ten
pairs in total form the four ordered sentences. In
general, this process yields n(n2−1)/6 pairs from
ordered n sentences. From each pair of segments,
we generate one positive and one negative training
instance as follows.
Given a pair of two segments A and B arranged
in an order A &gt;- B, we calculate four values,
fchro(A &gt;- B), ftopic(A &gt;- B), fpre(A &gt;- B),
and fsucc(A &gt;- B) to obtain the instance with
the four-dimensional vector (Figure 5). We label
the instance (corresponding to A &gt;- B) as a posi-
tive class (ie, +1). Simultaneously, we obtain an-
other instance with a four-dimensional vector cor-
responding to B &gt;- A. We label it as a negative
class (ie, −1). Accumulating these instances as
training data, we obtain a binary classifier by using
a Support Vector Machine with a quadratic kernel.
The SVM classifier yields the association direc-
tion of two segments (eg, A &gt;- B or B &gt;- A) with
the class information (ie, +1 or −1). We assign
the association strength of two segments by using
the class probability estimate that the instance be-
longs to a positive (+1) class. When an instance
is classified into a negative (−1) class, we set the
association strength as zero (see the definition of
Formula 2).
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.988005">
We evaluated the proposed method by using the
3rd Text Summarization Challenge (TSC-3) cor-
pus2. The TSC-3 corpus contains 30 sets of ex-
tracts, each of which consists of unordered sen-
tences3 extracted from Japanese newspaper arti-
cles relevant to a topic (query). We arrange the
extracts by using different algorithms and evaluate
</bodyText>
<footnote confidence="0.997718">
2http://lr-www.pi.titech.ac.jp/tsc/tsc3-en.html
3Each extract consists of ca. 15 sentences on average.
</footnote>
<equation confidence="0.340331">
sESa,bEB
</equation>
<page confidence="0.871939">
389
</page>
<figure confidence="0.772130833333333">
Perfect
Acceptable
RND
CHR
AGL
HUM
</figure>
<tableCaption confidence="0.855878">
Table 1: Correlation between two sets of human-
ordered extracts
</tableCaption>
<table confidence="0.971791285714286">
Metric Mean Std. Dev Min Max
Spearman 0.739 0.304 -0.2 1
Kendall 0.694 0.290 0 1
Average Continuity 0.401 0.404 0.001 1
Poor
Unacceptable
%
</table>
<bodyText confidence="0.999459">
the readability of the ordered extracts by a subjec-
tive grading and several metrics.
In order to construct training data applica-
ble to the proposed method, we asked two hu-
man subjects to arrange the extracts and obtained
30(topics) x 2(humans) = 60 sets of ordered
extracts. Table 1 shows the agreement of the or-
dered extracts between the two subjects. The cor-
relation is measured by three metrics, Spearman’s
rank correlation, Kendall’s rank correlation, and
average continuity (described later). The mean
correlation values (0.74 for Spearman’s rank cor-
relation and 0.69 for Kendall’s rank correlation)
indicate a certain level of agreement in sentence
orderings made by the two subjects. 8 out of 30
extracts were actually identical.
We applied the leave-one-out method to the pro-
posed method to produce a set of sentence or-
derings. In this experiment, the leave-out-out
method arranges an extract by using an SVM
model trained from the rest of the 29 extracts. Re-
peating this process 30 times with a different topic
for each iteration, we generated a set of 30 ex-
tracts for evaluation. In addition to the proposed
method, we prepared six sets of sentence orderings
produced by different algorithms for comparison.
We describe briefly the seven algorithms (includ-
ing the proposed method):
Agglomerative ordering (AGL) is an ordering
arranged by the proposed method;
Random ordering (RND) is the lowest anchor,
in which sentences are arranged randomly;
Human-made ordering (HUM) is the highest
anchor, in which sentences are arranged by
a human subject;
Chronological ordering (CHR) arranges sen-
tences with the chronology criterion defined
in Formula 8. Sentences are arranged in
chronological order of their publication date;
Topical-closeness ordering (TOP) arranges sen-
tences with the topical-closeness criterion de-
fined in Formula 9;
</bodyText>
<figure confidence="0.983881">
0 20 40 60 80 100
</figure>
<figureCaption confidence="0.999949">
Figure 6: Subjective grading
</figureCaption>
<bodyText confidence="0.9993645">
Precedence ordering (PRE) arranges sentences
with the precedence criterion defined in For-
mula 10;
Suceedence ordering (SUC) arranges sentences
with the succession criterion defined in For-
mula 11.
The last four algorithms (CHR, TOP, PRE, and
SUC) arrange sentences by the corresponding cri-
terion alone, each of which uses the association
strength directly to arrange sentences without the
integration of other criteria. These orderings are
expected to show the performance of each expert
independently and their contribution to solving the
sentence ordering problem.
</bodyText>
<subsectionHeader confidence="0.998746">
4.1 Subjective grading
</subsectionHeader>
<bodyText confidence="0.999831869565217">
Evaluating a sentence ordering is a challenging
task. Intrinsic evaluation that involves human
judges to rank a set of sentence orderings is a nec-
essary approach to this task (Barzilay et al., 2002;
Okazaki et al., 2004). We asked two human judges
to rate sentence orderings according to the follow-
ing criteria. A perfect summary is a text that we
cannot improve any further by re-ordering. An ac-
ceptable summary is one that makes sense and is
unnecessary to revise even though there is some
room for improvement in terms of readability. A
poor summary is one that loses a thread of the
story at some places and requires minor amend-
ment to bring it up to an acceptable level. An un-
acceptable summary is one that leaves much to be
improved and requires overall restructuring rather
than partial revision. To avoid any disturbance in
rating, we inform the judges that the summaries
were made from a same set of extracted sentences
and only the ordering of sentences is different.
Figure 6 shows the distribution of the subjective
grading made by two judges to four sets of order-
ings, RND, CHR, AGL and HUM. Each set of or-
</bodyText>
<page confidence="0.978925">
390
</page>
<figure confidence="0.7783485">
Teval = (e &gt;- a &gt;- b &gt;- c &gt;- d)
Tref = (a&gt;-b&gt;-c&gt;-d&gt;-e)
</figure>
<figureCaption confidence="0.9850255">
Figure 7: An example of an ordering under evalu-
ation Teval and its reference Tref.
</figureCaption>
<bodyText confidence="0.9986021875">
derings has 30(topics) x 2(judges) = 60 ratings.
Most RND orderings are rated as unacceptable.
Although CHR and AGL orderings have roughly
the same number of perfect orderings (ca. 25%),
the AGL algorithm gained more acceptable order-
ings (47%) than the CHR alghrotihm (30%). This
fact shows that integration of CHR experts with
other experts worked well by pushing poor order-
ing to an acceptable level. However, a huge gap
between AGL and HUM orderings was also found.
The judges rated 28% AGL orderings as perfect
while the figure rose as high as 82% for HUM
orderings. Kendall’s coefficient of concordance
(Kendall’s W), which asses the inter-judge agree-
ment of overall ratings, reported a higher agree-
ment between the two judges (W = 0.939).
</bodyText>
<subsectionHeader confidence="0.790811">
4.2 Metrics for semi-automatic evaluation
</subsectionHeader>
<bodyText confidence="0.99996984">
We also evaluated sentence orderings by reusing
two sets of gold-standard orderings made for the
training data. In general, subjective grading con-
sumes much time and effort, even though we
cannot reproduce the evaluation afterwards. The
previous studies (Barzilay et al., 2002; Lapata,
2003) employ rank correlation coefficients such
as Spearman’s rank correlation and Kendall’s rank
correlation, assuming a sentence ordering to be
a rank. Okazaki et al. (2004) propose a metric
that assess continuity of pairwise sentences com-
pared with the gold standard. In addition to Spear-
man’s and Kendall’s rank correlation coefficients,
we propose an average continuity metric, which
extends the idea of the continuity metric to contin-
uous k sentences.
A text with sentences arranged in proper order
does not interrupt a human’s reading while moving
from one sentence to the next. Hence, the qual-
ity of a sentence ordering can be estimated by the
number of continuous sentences that are also re-
produced in the reference sentence ordering. This
is equivalent to measuring a precision of continu-
ous sentences in an ordering against the reference
ordering. We define Pn to measure the precision of
</bodyText>
<tableCaption confidence="0.999206">
Table 2: Comparison with human-made ordering
</tableCaption>
<table confidence="0.999058375">
Method Spearman Kendall Average
coefficient coefficient Continuity
RND -0.127 -0.069 0.011
TOP 0.414 0.400 0.197
PRE 0.415 0.428 0.293
SUC 0.473 0.476 0.291
CHR 0.583 0.587 0.356
AGL 0.603 0.612 0.459
</table>
<bodyText confidence="0.892879">
n continuous sentences in an ordering to be evalu-
ated as,
</bodyText>
<equation confidence="0.9685085">
Pn = N − n + 1.
m (12)
</equation>
<bodyText confidence="0.998436285714286">
Here, N is the number of sentences in the refer-
ence ordering; n is the length of continuous sen-
tences on which we are evaluating; m is the num-
ber of continuous sentences that appear in both the
evaluation and reference orderings. In Figure 7,
the precision of 3 continuous sentences P3 is cal-
culated as:
</bodyText>
<equation confidence="0.939989">
P3 = 5 − 3 + 1
2 = 0.67. (13)
</equation>
<bodyText confidence="0.615653">
The Average Continuity (AC) is defined as the
logarithmic average of Pn over 2 to k:
</bodyText>
<equation confidence="0.941667">
k l
AC = exp Ck 1 1 log(Pn + a) I . (14)
n=2 /
</equation>
<bodyText confidence="0.999653066666667">
Here, k is a parameter to control the range of the
logarithmic average; and a is a small value in case
if Pn is zero. We set k = 4 (ie, more than five
continuous sentences are not included for evalua-
tion) and a = 0.01. Average Continuity becomes
0 when evaluation and reference orderings share
no continuous sentences and 1 when the two or-
derings are identical. In Figure 7, Average Conti-
nuity is calculated as 0.63. The underlying idea of
Formula 14 was proposed by Papineni et al. (2002)
as the BLEU metric for the semi-automatic evalu-
ation of machine-translation systems. The origi-
nal definition of the BLEU metric is to compare a
machine-translated text with its reference transla-
tion by using the word n-grams.
</bodyText>
<subsectionHeader confidence="0.990687">
4.3 Results of semi-automatic evaluation
</subsectionHeader>
<bodyText confidence="0.9941686">
Table 2 reports the resemblance of orderings pro-
duced by six algorithms to the human-made ones
with three metrics, Spearman’s rank correlation,
Kendall’s rank correlation, and Average Continu-
ity. The proposed method (AGL) outperforms the
</bodyText>
<page confidence="0.986043">
391
</page>
<figure confidence="0.998593">
SUC
RND
PRE
CHR AGL
TOP
0.6
0.5
0.4
0.3
0.2
0.1
0.0
</figure>
<figureCaption confidence="0.9763055">
Figure 8: Precision vs unit of measuring continu-
ity.
</figureCaption>
<bodyText confidence="0.999913518518518">
rest in all evaluation metrics, although the chrono-
logical ordering (CHR) appeared to play the major
role. The one-way analysis of variance (ANOVA)
verified the effects of different algorithms for sen-
tence orderings with all metrics (p &lt; 0.01). We
performed Tukey Honest Significant Differences
(HSD) test to compare differences among these al-
gorithms. The Tukey test revealed that AGL was
significantly better than the rest. Even though we
could not compare our experiment with the prob-
abilistic approach (Lapata, 2003) directly due to
the difference of the text corpora, the Kendall co-
efficient reported higher agreement than Lapata’s
experiment (Kendall=0.48 with lemmatized nouns
and Kendall=0.56 with verb-noun dependencies).
Figure 8 shows precision P,,, with different
length values of continuous sentence n for the six
methods compared in Table 2. The number of
continuous sentences becomes sparse for a higher
value of length n. Therefore, the precision values
decrease as the length n increases. Although RND
ordering reported some continuous sentences for
lower n values, no continuous sentences could be
observed for the higher n values. Four criteria de-
scribed in Section 3 (ie, CHR, TOP, PRE, SUC)
produce segments of continuous sentences at all
values of n.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999856">
We present a bottom-up approach to arrange sen-
tences extracted for multi-document summariza-
tion. Our experimental results showed a signif-
icant improvement over existing sentence order-
ing strategies. However, the results also implied
that chronological ordering played the major role
in arranging sentences. A future direction of this
study would be to explore the application of the
proposed framework to more generic texts, such
as documents without chronological information.
</bodyText>
<sectionHeader confidence="0.970799" genericHeader="references">
Acknowledgment
</sectionHeader>
<reference confidence="0.977810173913043">
We used Mainichi Shinbun and Yomiuri Shinbun
newspaper articles, and the TSC-3 test collection.
Regina Barzilay and Lillian Lee. 2004. Catching the
drift: Probabilistic content models, with applications
to generation and summarization. In HLT-NAACL
2004: Proceedings of the Main Conference, pages
113–120.
Regina Barzilay, Noemie Elhadad, and Kathleen McK-
eown. 2002. Inferring strategies for sentence order-
ing in multidocument news summarization. Journal
ofArtificial Intelligence Research, 17:35–55.
Mirella Lapata. 2003. Probabilistic text structuring:
Experiments with sentence ordering. Proceedings of
the annual meeting ofACL, 2003., pages 545–552.
C.Y. Lin and E. Hovy. 2001. Neats:a multidocument
summarizer. Proceedings of the Document Under-
standing Workshop(DUC).
W. Mann and S. Thompson. 1988. Rhetorical structure
theory: Toward a functional theory of text organiza-
tion. Text, 8:243–281.
Daniel Marcu. 1997. From local to global coherence:
A bottom-up approach to text planning. In Proceed-
ings of the 14th National Conference on Artificial
Intelligence, pages 629–635, Providence, Rhode Is-
land.
Kathleen McKeown, Judith Klavans, Vasileios Hatzi-
vassiloglou, Regina Barzilay, and Eleazar Eskin.
1999. Towards multidocument summarization by
reformulation: Progress and prospects. AAAI/IAAI,
pages 453–460.
Naoaki Okazaki, Yutaka Matsuo, and Mitsuru
Ishizuka. 2004. Improving chronological sentence
ordering by precedence relation. In Proceedings
of 20th International Conference on Computational
Linguistics (COLING 04), pages 750–756.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu:a method for automatic eval-
uation of machine translation. Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 311–318.
Dragomir R. Radev and Kathy McKeown. 1999.
Generating natural language summaries from mul-
tiple on-line sources. Computational Linguistics,
24:469–500.
V. Vapnik. 1998. Statistical Learning Theory. Wiley,
Chichester, GB.
</reference>
<figure confidence="0.995731">
0.8
0.7
2 3 4 5 6 7 8 References
Length n
</figure>
<page confidence="0.967994">
392
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.621523">
<title confidence="0.999709">A Bottom-up Approach to Sentence Ordering for Multi-document Summarization</title>
<author confidence="0.986268">Bollegala Naoaki Okazaki Ishizuka</author>
<affiliation confidence="0.9793135">Graduate School of Information Science and Technology The University of Tokyo</affiliation>
<address confidence="0.995893">7-3-1, Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan</address>
<email confidence="0.806898">danushka@mi.ci.i.u-tokyo.ac.jpishizuka@i.u-tokyo.ac.jp</email>
<email confidence="0.806898">okazaki@mi.ci.i.u-tokyo.ac.jpishizuka@i.u-tokyo.ac.jp</email>
<abstract confidence="0.998049684210526">Ordering information is a difficult but important task for applications generating natural-language text. We present a bottom-up approach to arranging sentences extracted for multi-document summarization. To capture the association and order of two textual segments (eg, senwe define four criteria, chronoland These criteria are integrated into a criterion by a supervised learning approach. We repeatedly concatenate two textual segments into one segment based on the criterion until we obtain the overall segment with all sentences arranged. Our experimental results show a significant improvement over existing sentence ordering strategies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>We used Mainichi Shinbun and Yomiuri Shinbun newspaper articles, and the TSC-3 test collection.</title>
<marker></marker>
<rawString>We used Mainichi Shinbun and Yomiuri Shinbun newspaper articles, and the TSC-3 test collection.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Proceedings of the Main Conference,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="3921" citStr="Barzilay and Lee, 2004" startWordPosition="568" endWordPosition="572">all segment with all sentences arranged, is achieved. 2 Related Work Existing methods for sentence ordering are divided into two approaches: making use of chronological information (McKeown et al., 1999; Lin 385 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385–392, Sydney, July 2006. c�2006 Association for Computational Linguistics and Hovy, 2001; Barzilay et al., 2002; Okazaki et al., 2004); and learning the natural order of sentences from large corpora not necessarily based on chronological information (Lapata, 2003; Barzilay and Lee, 2004). A newspaper usually disseminates descriptions of novel events that have occurred since the last publication. For this reason, ordering sentences according to their publication date is an effective heuristic for multidocument summarization (Lin and Hovy, 2001; McKeown et al., 1999). Barzilay et al. (2002) have proposed an improved version of chronological ordering by first grouping sentences into sub-topics discussed in the source documents and then arranging the sentences in each group chronologically. Okazaki et al. (2004) have proposed an algorithm to improve chronological ordering by reso</context>
<context position="5772" citStr="Barzilay and Lee (2004)" startWordPosition="847" endWordPosition="850">ic model of text structuring and its application to the sentence ordering. Her method calculates the transition probability from one sentence to the next from a corpus based on the Cartesian product between two sentences defined using the following features: verbs (precedent relationships of verbs in the corpus); nouns (entity-based coherence by keeping track of the nouns); and dependencies (structure of sentences). Although she has not compared her method with chronological ordering, it could be applied to generic domains, not relying on the chronological clue provided by newspaper articles. Barzilay and Lee (2004) have proposed content models to deal with topic transition in domain specific text. The content models are formalized by Hidden Markov Models (HMMs) in which the hidden state corresponds to a topic in the domain of interest (eg, earthquake magnitude or previous earthquake occurrences), and the state transitions capture possible information-presentation orderings. The evaluation results showed that their method outperformed Lapata’s approach by a wide margin. They did not compare their method with chronological ordering as an application of multi-document summarization. As described above, sev</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In HLT-NAACL 2004: Proceedings of the Main Conference, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument news summarization.</title>
<date>2002</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>17--35</pages>
<contexts>
<context position="3744" citStr="Barzilay et al., 2002" startWordPosition="541" endWordPosition="544">nto one criterion by a supervised learning approach. We also propose a bottom-up approach in arranging sentences, which repeatedly concatenates textual segments until the overall segment with all sentences arranged, is achieved. 2 Related Work Existing methods for sentence ordering are divided into two approaches: making use of chronological information (McKeown et al., 1999; Lin 385 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385–392, Sydney, July 2006. c�2006 Association for Computational Linguistics and Hovy, 2001; Barzilay et al., 2002; Okazaki et al., 2004); and learning the natural order of sentences from large corpora not necessarily based on chronological information (Lapata, 2003; Barzilay and Lee, 2004). A newspaper usually disseminates descriptions of novel events that have occurred since the last publication. For this reason, ordering sentences according to their publication date is an effective heuristic for multidocument summarization (Lin and Hovy, 2001; McKeown et al., 1999). Barzilay et al. (2002) have proposed an improved version of chronological ordering by first grouping sentences into sub-topics discussed i</context>
<context position="12931" citStr="Barzilay et al (2002)" startWordPosition="2142" endWordPosition="2145"> ....... ...... . ... ...... .. .., .... ... .... b2 ? .... .. .. .... .. ....... ...... . ... ...... .. .., .... ... .... b3 Segment A Segment B .... , . ... ...... .. .., .... ... .... a 3 a1 Sa1 a2 Sa2 Sa3 Original article for sentence a1 Original article for sentence a3 max max max Original article for a2 sentence .... .. .. .... .. ....... ...... . ... ...... .. .., .... ... .... .... .. .. .... .. ....... ...... . ... ...... .. .., .... ... .... .... .. .. .... .. ....... ...... a3 . ... ...... .. .., .... ... .... a1 a2 segments. The criterion reflects the ordering strategy proposed by Barzilay et al (2002), which groups sentences referring to the same topic. To measure the topical closeness of two sentences, we represent each sentence with a vector whose elements correspond to the occurrence1 of the nouns and verbs in the sentence. We define the topical closeness of two segments A and B as follows, ftopic(A &gt;- B) =|B |bE m aAxsim(a, b). (9) ∈B Here, sim(a, b) denotes the similarity of sentences a and b, which is calculated by the cosine similarity of two vectors corresponding to the sentences. For sentence b E B, maxa∈A sim(a, b) chooses the sentence a E A most similar to sentence b and yields </context>
<context position="22785" citStr="Barzilay et al., 2002" startWordPosition="3793" endWordPosition="3796">iterion defined in Formula 11. The last four algorithms (CHR, TOP, PRE, and SUC) arrange sentences by the corresponding criterion alone, each of which uses the association strength directly to arrange sentences without the integration of other criteria. These orderings are expected to show the performance of each expert independently and their contribution to solving the sentence ordering problem. 4.1 Subjective grading Evaluating a sentence ordering is a challenging task. Intrinsic evaluation that involves human judges to rank a set of sentence orderings is a necessary approach to this task (Barzilay et al., 2002; Okazaki et al., 2004). We asked two human judges to rate sentence orderings according to the following criteria. A perfect summary is a text that we cannot improve any further by re-ordering. An acceptable summary is one that makes sense and is unnecessary to revise even though there is some room for improvement in terms of readability. A poor summary is one that loses a thread of the story at some places and requires minor amendment to bring it up to an acceptable level. An unacceptable summary is one that leaves much to be improved and requires overall restructuring rather than partial rev</context>
<context position="24912" citStr="Barzilay et al., 2002" startWordPosition="4159" endWordPosition="4162"> orderings was also found. The judges rated 28% AGL orderings as perfect while the figure rose as high as 82% for HUM orderings. Kendall’s coefficient of concordance (Kendall’s W), which asses the inter-judge agreement of overall ratings, reported a higher agreement between the two judges (W = 0.939). 4.2 Metrics for semi-automatic evaluation We also evaluated sentence orderings by reusing two sets of gold-standard orderings made for the training data. In general, subjective grading consumes much time and effort, even though we cannot reproduce the evaluation afterwards. The previous studies (Barzilay et al., 2002; Lapata, 2003) employ rank correlation coefficients such as Spearman’s rank correlation and Kendall’s rank correlation, assuming a sentence ordering to be a rank. Okazaki et al. (2004) propose a metric that assess continuity of pairwise sentences compared with the gold standard. In addition to Spearman’s and Kendall’s rank correlation coefficients, we propose an average continuity metric, which extends the idea of the continuity metric to continuous k sentences. A text with sentences arranged in proper order does not interrupt a human’s reading while moving from one sentence to the next. Henc</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen McKeown. 2002. Inferring strategies for sentence ordering in multidocument news summarization. Journal ofArtificial Intelligence Research, 17:35–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>Proceedings of the annual meeting ofACL,</booktitle>
<pages>545--552</pages>
<contexts>
<context position="3896" citStr="Lapata, 2003" startWordPosition="566" endWordPosition="567">until the overall segment with all sentences arranged, is achieved. 2 Related Work Existing methods for sentence ordering are divided into two approaches: making use of chronological information (McKeown et al., 1999; Lin 385 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385–392, Sydney, July 2006. c�2006 Association for Computational Linguistics and Hovy, 2001; Barzilay et al., 2002; Okazaki et al., 2004); and learning the natural order of sentences from large corpora not necessarily based on chronological information (Lapata, 2003; Barzilay and Lee, 2004). A newspaper usually disseminates descriptions of novel events that have occurred since the last publication. For this reason, ordering sentences according to their publication date is an effective heuristic for multidocument summarization (Lin and Hovy, 2001; McKeown et al., 1999). Barzilay et al. (2002) have proposed an improved version of chronological ordering by first grouping sentences into sub-topics discussed in the source documents and then arranging the sentences in each group chronologically. Okazaki et al. (2004) have proposed an algorithm to improve chron</context>
<context position="5121" citStr="Lapata (2003)" startWordPosition="748" endWordPosition="749">ering by resolving the presuppositional information of extracted sentences. They assume that each sentence in newspaper articles is written on the basis that presuppositional information should be transferred to the reader before the sentence is interpreted. The proposed algorithm first arranges sentences in a chronological order and then estimates the presuppositional information for each sentence by using the content of the sentences placed before each sentence in its original article. The evaluation results show that the proposed algorithm improves the chronological ordering significantly. Lapata (2003) has suggested a probabilistic model of text structuring and its application to the sentence ordering. Her method calculates the transition probability from one sentence to the next from a corpus based on the Cartesian product between two sentences defined using the following features: verbs (precedent relationships of verbs in the corpus); nouns (entity-based coherence by keeping track of the nouns); and dependencies (structure of sentences). Although she has not compared her method with chronological ordering, it could be applied to generic domains, not relying on the chronological clue prov</context>
<context position="24927" citStr="Lapata, 2003" startWordPosition="4163" endWordPosition="4164">nd. The judges rated 28% AGL orderings as perfect while the figure rose as high as 82% for HUM orderings. Kendall’s coefficient of concordance (Kendall’s W), which asses the inter-judge agreement of overall ratings, reported a higher agreement between the two judges (W = 0.939). 4.2 Metrics for semi-automatic evaluation We also evaluated sentence orderings by reusing two sets of gold-standard orderings made for the training data. In general, subjective grading consumes much time and effort, even though we cannot reproduce the evaluation afterwards. The previous studies (Barzilay et al., 2002; Lapata, 2003) employ rank correlation coefficients such as Spearman’s rank correlation and Kendall’s rank correlation, assuming a sentence ordering to be a rank. Okazaki et al. (2004) propose a metric that assess continuity of pairwise sentences compared with the gold standard. In addition to Spearman’s and Kendall’s rank correlation coefficients, we propose an average continuity metric, which extends the idea of the continuity metric to continuous k sentences. A text with sentences arranged in proper order does not interrupt a human’s reading while moving from one sentence to the next. Hence, the quality </context>
<context position="28239" citStr="Lapata, 2003" startWordPosition="4734" endWordPosition="4735">CHR AGL TOP 0.6 0.5 0.4 0.3 0.2 0.1 0.0 Figure 8: Precision vs unit of measuring continuity. rest in all evaluation metrics, although the chronological ordering (CHR) appeared to play the major role. The one-way analysis of variance (ANOVA) verified the effects of different algorithms for sentence orderings with all metrics (p &lt; 0.01). We performed Tukey Honest Significant Differences (HSD) test to compare differences among these algorithms. The Tukey test revealed that AGL was significantly better than the rest. Even though we could not compare our experiment with the probabilistic approach (Lapata, 2003) directly due to the difference of the text corpora, the Kendall coefficient reported higher agreement than Lapata’s experiment (Kendall=0.48 with lemmatized nouns and Kendall=0.56 with verb-noun dependencies). Figure 8 shows precision P,,, with different length values of continuous sentence n for the six methods compared in Table 2. The number of continuous sentences becomes sparse for a higher value of length n. Therefore, the precision values decrease as the length n increases. Although RND ordering reported some continuous sentences for lower n values, no continuous sentences could be obse</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. Proceedings of the annual meeting ofACL, 2003., pages 545–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Y Lin</author>
<author>E Hovy</author>
</authors>
<title>Neats:a multidocument summarizer.</title>
<date>2001</date>
<booktitle>Proceedings of the Document Understanding Workshop(DUC).</booktitle>
<contexts>
<context position="4181" citStr="Lin and Hovy, 2001" startWordPosition="607" endWordPosition="610">omputational Linguistics and 44th Annual Meeting of the ACL, pages 385–392, Sydney, July 2006. c�2006 Association for Computational Linguistics and Hovy, 2001; Barzilay et al., 2002; Okazaki et al., 2004); and learning the natural order of sentences from large corpora not necessarily based on chronological information (Lapata, 2003; Barzilay and Lee, 2004). A newspaper usually disseminates descriptions of novel events that have occurred since the last publication. For this reason, ordering sentences according to their publication date is an effective heuristic for multidocument summarization (Lin and Hovy, 2001; McKeown et al., 1999). Barzilay et al. (2002) have proposed an improved version of chronological ordering by first grouping sentences into sub-topics discussed in the source documents and then arranging the sentences in each group chronologically. Okazaki et al. (2004) have proposed an algorithm to improve chronological ordering by resolving the presuppositional information of extracted sentences. They assume that each sentence in newspaper articles is written on the basis that presuppositional information should be transferred to the reader before the sentence is interpreted. The proposed a</context>
<context position="10359" citStr="Lin and Hovy, 2001" startWordPosition="1649" endWordPosition="1652"> of the two segments. The previous work described in Section 2 has addressed the association of textual segments (sentences) to obtain coherent orderings. We define four criteria to capture the association of two segments: chronology; topical-closeness; precedence; and succession. These criteria are integrated into a function f(A &gt;- B) by using a machine learning approach. The rest of this section explains the four criteria and an integration method with a Support Vector Machine (SVM) (Vapnik, 1998) classifier. 3.1 Chronology criterion Chronology criterion reflects the chronological ordering (Lin and Hovy, 2001; McKeown et al., 1999), which arranges sentences in a chronological order of the publication date. We define the association strength of arranging segments B after A measured by a chronology criterion fchro(A &gt;- B) in the following formula, fchro(A &gt;- B) 1 T(am) &lt; T(b1) 1 [D(am) = D(b1)] n [N(am) &lt; N(b1)] 0.5 [T(am) = T(b1)] n [D(am) =� D(b1)] . 0 otherwise (8) Here, am represents the last sentence in segment A; b1 represents the first sentence in segment B; T (s) is the publication date of the sentence s; D(s) is the unique identifier of the document to which sentence s belongs: and N(s) den</context>
</contexts>
<marker>Lin, Hovy, 2001</marker>
<rawString>C.Y. Lin and E. Hovy. 2001. Neats:a multidocument summarizer. Proceedings of the Document Understanding Workshop(DUC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>S Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8:243–281.</tech>
<contexts>
<context position="2288" citStr="Mann and Thompson, 1988" startWordPosition="318" endWordPosition="321"> the text structure for summarization. Ordering information is also essential for Research Fellow of the Japan Society for the Promotion of Science (JSPS) other text-generation applications such as Question Answering. A summary with improperly ordered sentences confuses the reader and degrades the quality/reliability of the summary itself. Barzilay (2002) has provided empirical evidence that proper order of extracted sentences improves their readability significantly. However, ordering a set of sentences into a coherent text is a nontrivial task. For example, identifying rhetorical relations (Mann and Thompson, 1988) in an ordered text has been a difficult task for computers, whereas our task is even more complicated: to reconstruct such relations from unordered sets of sentences. Source documents for a summary may have been written by different authors, by different writing styles, on different dates, and based on different background knowledge. We cannot expect that a set of extracted sentences from such diverse documents will be coherent on their own. Several strategies to determine sentence ordering have been proposed as described in section 2. However, the appropriate way to combine these strategies </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>W. Mann and S. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8:243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>From local to global coherence: A bottom-up approach to text planning.</title>
<date>1997</date>
<booktitle>In Proceedings of the 14th National Conference on Artificial Intelligence,</booktitle>
<pages>629--635</pages>
<location>Providence, Rhode Island.</location>
<contexts>
<context position="7677" citStr="Marcu (1997)" startWordPosition="1160" endWordPosition="1161">ent B. Let us consider a bottom-up approach in arranging sentences. Starting with a set of segments initialized with a sentence for each, we concatenate two segments, with the strongest association (discussed later) of all possible segment pairs, into one segment. Repeating the concatenating will eventually yield a segment with all sentences arranged. The algorithm is considered as a variation of agglomerative hierarchical clustering with the ordering information retained at each concatenating process. The underlying idea of the algorithm, a bottomup approach to text planning, was proposed by Marcu (1997). Assuming that the semantic units (sentences) and their rhetorical relations (eg, sentence a is an elaboration of sentenced) are given, he transcribed a text structuring task into the problem of finding the best discourse tree that satisfied the set of rhetorical relations. He stated that global coherence could be achieved by satisfying local coherence constraints in ordering and clustering, thereby ensuring that the resultant discourse tree was well-formed. Unfortunately, identifying the rhetorical relation between two sentences has been a difficult 386 G = (b a c d) E = (b a) Segments A B C</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. From local to global coherence: A bottom-up approach to text planning. In Proceedings of the 14th National Conference on Artificial Intelligence, pages 629–635, Providence, Rhode Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
</authors>
<title>Judith Klavans, Vasileios Hatzivassiloglou, Regina Barzilay, and Eleazar Eskin.</title>
<date>1999</date>
<pages>453--460</pages>
<publisher>AAAI/IAAI,</publisher>
<contexts>
<context position="1105" citStr="McKeown, 1999" startWordPosition="142" endWordPosition="143">xtracted for multi-document summarization. To capture the association and order of two textual segments (eg, sentences), we define four criteria, chronology, topical-closeness, precedence, and succession. These criteria are integrated into a criterion by a supervised learning approach. We repeatedly concatenate two textual segments into one segment based on the criterion until we obtain the overall segment with all sentences arranged. Our experimental results show a significant improvement over existing sentence ordering strategies. 1 Introduction Multi-document summarization (MDS) (Radev and McKeown, 1999) tackles the information overload problem by providing a condensed version of a set of documents. Among a number of sub-tasks involved in MDS, eg, sentence extraction, topic detection, sentence ordering, information extraction, sentence generation, etc., most MDS systems have been based on an extraction method, which identifies important textual segments (eg, sentences or paragraphs) in source documents. It is important for such MDS systems to determine a coherent arrangement of the textual segments extracted from multi-documents in order to reconstruct the text structure for summarization. Or</context>
</contexts>
<marker>McKeown, 1999</marker>
<rawString>Kathleen McKeown, Judith Klavans, Vasileios Hatzivassiloglou, Regina Barzilay, and Eleazar Eskin. 1999. Towards multidocument summarization by reformulation: Progress and prospects. AAAI/IAAI, pages 453–460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
<author>Yutaka Matsuo</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Improving chronological sentence ordering by precedence relation.</title>
<date>2004</date>
<booktitle>In Proceedings of 20th International Conference on Computational Linguistics (COLING 04),</booktitle>
<pages>750--756</pages>
<contexts>
<context position="3767" citStr="Okazaki et al., 2004" startWordPosition="545" endWordPosition="548">supervised learning approach. We also propose a bottom-up approach in arranging sentences, which repeatedly concatenates textual segments until the overall segment with all sentences arranged, is achieved. 2 Related Work Existing methods for sentence ordering are divided into two approaches: making use of chronological information (McKeown et al., 1999; Lin 385 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 385–392, Sydney, July 2006. c�2006 Association for Computational Linguistics and Hovy, 2001; Barzilay et al., 2002; Okazaki et al., 2004); and learning the natural order of sentences from large corpora not necessarily based on chronological information (Lapata, 2003; Barzilay and Lee, 2004). A newspaper usually disseminates descriptions of novel events that have occurred since the last publication. For this reason, ordering sentences according to their publication date is an effective heuristic for multidocument summarization (Lin and Hovy, 2001; McKeown et al., 1999). Barzilay et al. (2002) have proposed an improved version of chronological ordering by first grouping sentences into sub-topics discussed in the source documents </context>
<context position="14723" citStr="Okazaki et al, (2004)" startWordPosition="2443" endWordPosition="2446">ocument summarization chooses any sentences before b for a summary because the extraction method usually deter1The vector values are represented by boolean values, i.e., 1 if the sentence contains a word, otherwise 0. mines a set of sentences, within the constraint of summary length, that maximizes information coverage and excludes redundant information. Precedence criterion measures the substitutability of the presuppositional information of segment B (eg, the sentences appearing before sentence b) as segment A. This criterion is a formalization of the sentence-ordering algorithm proposed by Okazaki et al, (2004). We define the precedence criterion in the following formula, 1 � fpre(A &gt;- B) = max sim(a, p). b∈B a∈A,p∈P, | Pb and A by the maximum similari ty of the possible sentence combinations, Formula 10 is interpreted as the average similarity of the precedent sentences bPb(b E B) to the segment A. 3.4 Succession criterion (10) Here, Pb is a set of sentences appearing before sentence b in the original article; and sim(a, b) denotes the cosine similarity of sentences a and b (defined as in the topical-closeness criterion). Figure 2 shows an example of calculating the precedence criterion for arrangi</context>
<context position="22808" citStr="Okazaki et al., 2004" startWordPosition="3797" endWordPosition="3800">ula 11. The last four algorithms (CHR, TOP, PRE, and SUC) arrange sentences by the corresponding criterion alone, each of which uses the association strength directly to arrange sentences without the integration of other criteria. These orderings are expected to show the performance of each expert independently and their contribution to solving the sentence ordering problem. 4.1 Subjective grading Evaluating a sentence ordering is a challenging task. Intrinsic evaluation that involves human judges to rank a set of sentence orderings is a necessary approach to this task (Barzilay et al., 2002; Okazaki et al., 2004). We asked two human judges to rate sentence orderings according to the following criteria. A perfect summary is a text that we cannot improve any further by re-ordering. An acceptable summary is one that makes sense and is unnecessary to revise even though there is some room for improvement in terms of readability. A poor summary is one that loses a thread of the story at some places and requires minor amendment to bring it up to an acceptable level. An unacceptable summary is one that leaves much to be improved and requires overall restructuring rather than partial revision. To avoid any dis</context>
<context position="25097" citStr="Okazaki et al. (2004)" startWordPosition="4186" endWordPosition="4189">h asses the inter-judge agreement of overall ratings, reported a higher agreement between the two judges (W = 0.939). 4.2 Metrics for semi-automatic evaluation We also evaluated sentence orderings by reusing two sets of gold-standard orderings made for the training data. In general, subjective grading consumes much time and effort, even though we cannot reproduce the evaluation afterwards. The previous studies (Barzilay et al., 2002; Lapata, 2003) employ rank correlation coefficients such as Spearman’s rank correlation and Kendall’s rank correlation, assuming a sentence ordering to be a rank. Okazaki et al. (2004) propose a metric that assess continuity of pairwise sentences compared with the gold standard. In addition to Spearman’s and Kendall’s rank correlation coefficients, we propose an average continuity metric, which extends the idea of the continuity metric to continuous k sentences. A text with sentences arranged in proper order does not interrupt a human’s reading while moving from one sentence to the next. Hence, the quality of a sentence ordering can be estimated by the number of continuous sentences that are also reproduced in the reference sentence ordering. This is equivalent to measuring</context>
</contexts>
<marker>Okazaki, Matsuo, Ishizuka, 2004</marker>
<rawString>Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka. 2004. Improving chronological sentence ordering by precedence relation. In Proceedings of 20th International Conference on Computational Linguistics (COLING 04), pages 750–756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu:a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>311--318</pages>
<contexts>
<context position="27104" citStr="Papineni et al. (2002)" startWordPosition="4552" endWordPosition="4555"> The Average Continuity (AC) is defined as the logarithmic average of Pn over 2 to k: k l AC = exp Ck 1 1 log(Pn + a) I . (14) n=2 / Here, k is a parameter to control the range of the logarithmic average; and a is a small value in case if Pn is zero. We set k = 4 (ie, more than five continuous sentences are not included for evaluation) and a = 0.01. Average Continuity becomes 0 when evaluation and reference orderings share no continuous sentences and 1 when the two orderings are identical. In Figure 7, Average Continuity is calculated as 0.63. The underlying idea of Formula 14 was proposed by Papineni et al. (2002) as the BLEU metric for the semi-automatic evaluation of machine-translation systems. The original definition of the BLEU metric is to compare a machine-translated text with its reference translation by using the word n-grams. 4.3 Results of semi-automatic evaluation Table 2 reports the resemblance of orderings produced by six algorithms to the human-made ones with three metrics, Spearman’s rank correlation, Kendall’s rank correlation, and Average Continuity. The proposed method (AGL) outperforms the 391 SUC RND PRE CHR AGL TOP 0.6 0.5 0.4 0.3 0.2 0.1 0.0 Figure 8: Precision vs unit of measuri</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu:a method for automatic evaluation of machine translation. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Kathy McKeown</author>
</authors>
<title>Generating natural language summaries from multiple on-line sources.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<pages>24--469</pages>
<contexts>
<context position="1105" citStr="Radev and McKeown, 1999" startWordPosition="140" endWordPosition="143">entences extracted for multi-document summarization. To capture the association and order of two textual segments (eg, sentences), we define four criteria, chronology, topical-closeness, precedence, and succession. These criteria are integrated into a criterion by a supervised learning approach. We repeatedly concatenate two textual segments into one segment based on the criterion until we obtain the overall segment with all sentences arranged. Our experimental results show a significant improvement over existing sentence ordering strategies. 1 Introduction Multi-document summarization (MDS) (Radev and McKeown, 1999) tackles the information overload problem by providing a condensed version of a set of documents. Among a number of sub-tasks involved in MDS, eg, sentence extraction, topic detection, sentence ordering, information extraction, sentence generation, etc., most MDS systems have been based on an extraction method, which identifies important textual segments (eg, sentences or paragraphs) in source documents. It is important for such MDS systems to determine a coherent arrangement of the textual segments extracted from multi-documents in order to reconstruct the text structure for summarization. Or</context>
</contexts>
<marker>Radev, McKeown, 1999</marker>
<rawString>Dragomir R. Radev and Kathy McKeown. 1999. Generating natural language summaries from multiple on-line sources. Computational Linguistics, 24:469–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley,</publisher>
<location>Chichester, GB.</location>
<contexts>
<context position="10245" citStr="Vapnik, 1998" startWordPosition="1636" endWordPosition="1637"> sentence ordering, G = (b &gt;- a &gt;- c &gt;- d). (7) In the above description, we have not defined the association of the two segments. The previous work described in Section 2 has addressed the association of textual segments (sentences) to obtain coherent orderings. We define four criteria to capture the association of two segments: chronology; topical-closeness; precedence; and succession. These criteria are integrated into a function f(A &gt;- B) by using a machine learning approach. The rest of this section explains the four criteria and an integration method with a Support Vector Machine (SVM) (Vapnik, 1998) classifier. 3.1 Chronology criterion Chronology criterion reflects the chronological ordering (Lin and Hovy, 2001; McKeown et al., 1999), which arranges sentences in a chronological order of the publication date. We define the association strength of arranging segments B after A measured by a chronology criterion fchro(A &gt;- B) in the following formula, fchro(A &gt;- B) 1 T(am) &lt; T(b1) 1 [D(am) = D(b1)] n [N(am) &lt; N(b1)] 0.5 [T(am) = T(b1)] n [D(am) =� D(b1)] . 0 otherwise (8) Here, am represents the last sentence in segment A; b1 represents the first sentence in segment B; T (s) is the publicati</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. Vapnik. 1998. Statistical Learning Theory. Wiley, Chichester, GB.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>