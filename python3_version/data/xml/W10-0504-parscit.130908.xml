<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.184583">
<title confidence="0.9995235">
An Information-Retrieval Approach to Language Modeling:
Applications to Social Data
</title>
<author confidence="0.936336">
Juan M. Huerta
</author>
<affiliation confidence="0.636704">
IBM T. J.Watson Research Center
</affiliation>
<address confidence="0.914885">
1101 Kitchawan Road
Yorktown Heights, NY 10598, USA
</address>
<email confidence="0.991084">
huerta@us.ibm.com
</email>
<sectionHeader confidence="0.994484" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9706469">
In this paper we propose the IR-LM
(Information Retrieval Language Model)
which is an approach to carrying out language
modeling based on large volumes of
constantly changing data as is the case of
social media data. Our approach addresses
specific characteristics of social data: large
volume of constantly generated content as well
as the need to frequently integrating and
removing data from the model.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999666875">
We describe the Information Retrieval
Language Model (IR-LM) which is a novel
approach to language modeling motivated by
domains with constantly changing large volumes
of linguistic data. Our approach is based on
information retrieval methods and constitutes a
departure from the traditional statistical n-gram
language modeling (SLM) approach. We believe
the IR-LM is more adequate than SLM when: (a)
language models need to be updated constantly,
(b) very large volumes of data are constantly being
generated and (c) it is possible and likely that the
sentence we are trying to score has been observed
in the data (albeit with small possible variations).
These three characteristics are inherent of social
domains such as blogging and micro-blogging.
</bodyText>
<sectionHeader confidence="0.805867" genericHeader="method">
2 N-gram SLM and IR-LM
</sectionHeader>
<bodyText confidence="0.98965">
Statistical language models are widely used in
main computational linguistics tasks to compute
the probability of a string of words: p(w1 ...wi )
To facilitate its computation, this probability is
expressed as:
</bodyText>
<equation confidence="0.9493625">
p w w P w P w w
( ... ) ( ) (  |) ... (  |... )
   P w w w
1 i 1 2 1 i 1 i1
</equation>
<bodyText confidence="0.999260333333333">
Assuming that only the most immediate word
history affects the probability of any given word,
and focusing on a trigram language model:
</bodyText>
<equation confidence="0.9890096">
P(wi  |w1 ... wi1)  P(wi  |wi2wi1 )
This leads to:
 p(wk  |wk1 wk2 )
k i
1..
</equation>
<bodyText confidence="0.999663266666667">
Language models are typically applied in ASR,
MT and other tasks in which multiple hypotheses
need to be rescored according to their likelihood
(i.e., ranked). In a smoothed backoff SLM (e.g.,
Goodman (2001)), all the n-grams up to order n are
computed and smoothed and backoff probabilities
are calculated. If new data is introduced or
removed from the corpus, the whole model, the
counts and weights would need to be recalculated.
Levenberg and Osborne (2009) proposed an
approach for incorporating new data as it is seen in
the stream. Language models have been used to
support IR as a method to extend queries
(Lavrenko et al. 2001); in this paper we focus on
using IR to carry out language modeling.
</bodyText>
<subsectionHeader confidence="0.98029">
2.1 The IR Language Model
</subsectionHeader>
<bodyText confidence="0.999985833333333">
The IR-LM approach consists of two steps: the
first is the identification of a set of matches from a
corpus given a query sentence, and second is the
estimation of a likelihood-like value for the query.
In the first step, given a corpus C and a query
sentence S, we identify the k-closest matching
sentences in the corpus through an information
retrieval approach. We propose the use of a
modified String Edit Distance as score in the IR
process. To efficiently carry out the search of the
closest sentences in the corpus we propose the use
of an inverted index with word position
</bodyText>
<equation confidence="0.981407">
P(
w1 ... wi)
</equation>
<page confidence="0.969657">
7
</page>
<note confidence="0.874393">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 7–8,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999980515151515">
information and a stack based search approach
described in Huerta (2010). A modification of the
SED allows queries to match portions of long
sentences (considering local insertion deletions
and substitutions) without penalizing for missing
the non-local portion of the matching sentence.
In the second step, in general, we would like to
compute a likelihood-like value of S through a
function of the distances (or alternatively,
similarity scores) of the query S to the top k-
hypotheses. However, for now we will focus on
the more particular problem of ranking multiple
sentences in order of matching scores, which,
while not directly producing likelihood estimates it
will allow us to implement n-best rescoring.
Specifically, our ranking is based on the level of
matching between each sentence to be ranked and
its best matching hypothesis in the corpus. In this
case, integrating and removing data from the
model simply involve adding to or pruning the
index which generally are simpler than n-gram re-
estimation.
There is an important fundamental difference
between the classic n-gram SLM approach and our
approach. The n-gram approach says that a
sentence S1 is more likely than another sentence S2
given a model if the n-grams that constitute S1
have been observed more times than the n-grams
of S2. Our approach, on the other hand, says that a
sentence S1 is more likely than S2 if the closest
match to S1 in C resembles S1 better than the closes
match of S2 resembles S2 regardless of how many
times these sentences have been observed.
</bodyText>
<sectionHeader confidence="0.999112" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999882454545455">
We carried out experiments using the blog
corpus provided by Spinn3r (Burton et al (2009)).
It consists of 44 million blog posts that originated
during August and September 2008 from which we
selected, cleaned, normalized and segmented 2
million English language blogs. We reserved the
segments originating from blogs dated September
30 for testing.
We took 1000 segments from the test subset and
for each of these segments we built a 16-
hypothesis cohort (by creating 16 overlapping sub-
segments of the constant length from the segment).
We built a 5-gram SLM using a 20k word
dictionary and Knesser-Ney smoothing using the
SRILM toolkit (Stolcke (2002)). We then ranked
each of the 1000 test cohorts using each of the
model&apos;s n-gram levels (unigram, bigram, etc.). Our
goal is to determine to what extent our approach
correlates with an n-gram SLM-based rescoring.
For testing purposes we re-ranked each of the
test cohorts using the IR-LM approach. We then
compared the rankings produced by n-grams and
by IR-LM for every n-gram order and several IR
configurations. For this, we computed the
Spearman rank correlation coefficient (SRCC).
SRCC averages for each configuration are shown
in table 1. Row 1 shows the SRCC for the best
overall IR configuration and row 2 shows the
SRCC for the IR configuration producing the best
results for each particular n-gram model. We can
see that albeit simple, IR-LM can produce results
consistent with a language model based on
fundamentally different assumptions.
</bodyText>
<table confidence="0.944085333333333">
n=1 n=2 n=3 n=4 n=5
overall 0.53 0.42 0.40 0.40 0.38
individual 0.68 0.47 0.40 0.40 0.39
</table>
<tableCaption confidence="0.963299">
Table 1. Spearman rank correlation coefficient for
several n-gram IR configurations
</tableCaption>
<sectionHeader confidence="0.997616" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999965230769231">
The IR-LM can be beneficial when the language
model needs to be updated with added and
removed data. This is particularly important in
social data where new content is constantly
generated. Our approach also introduces a
different interpretation of the concept of likelihood
of a sentence: instead of assuming the frequentist
assumption underlying n-gram models, it is based
on sentence feasibility based on the closest
segment similarity. Future work will look into:
integrating information from the top k-matches,
likelihood regression, as well as leveraging other
approaches to information retrieval.
</bodyText>
<sectionHeader confidence="0.999283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999624">
Burton K., Java A., and Soboroff I. (2009) The ICWSM
2009 Spinn3r Dataset. Proc. ICWSM 2009
Goodman J. (2001) A Bit of Progress in Language
Modeling, MS Res. Tech. Rpt. MSR-TR-2001-72.
Huerta J. (2010) A Stack Decoder Approach to
Approximate String Matching, Proc. of SIGIR 2010
Lavrenko V. and Croft W. B. (2001) Relevance based
language models. Proc. of SIGIR 2001
Levenberg A. and Osborne M. (2009), Stream-based
Randomised Lang. Models for SMT, EMNLP 2009
Stolcke A. (2002)s SRILM -- An Extensible Language
Modeling Toolkit. Proc. ICSLP 2002
</reference>
<page confidence="0.99849">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732856">
<title confidence="0.999512">An Information-Retrieval Approach to Language Applications to Social Data</title>
<author confidence="0.999918">M Juan</author>
<affiliation confidence="0.995053">IBM T. J.Watson Research</affiliation>
<address confidence="0.849375">1101 Kitchawan Yorktown Heights, NY 10598,</address>
<email confidence="0.999105">huerta@us.ibm.com</email>
<abstract confidence="0.999163545454546">In this paper we propose the IR-LM (Information Retrieval Language Model) which is an approach to carrying out language modeling based on large volumes of constantly changing data as is the case of social media data. Our approach addresses specific characteristics of social data: large volume of constantly generated content as well as the need to frequently integrating and removing data from the model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Burton</author>
<author>A Java</author>
<author>I Soboroff</author>
</authors>
<date>2009</date>
<booktitle>The ICWSM 2009 Spinn3r Dataset. Proc. ICWSM</booktitle>
<contexts>
<context position="5084" citStr="Burton et al (2009)" startWordPosition="850" endWordPosition="853"> important fundamental difference between the classic n-gram SLM approach and our approach. The n-gram approach says that a sentence S1 is more likely than another sentence S2 given a model if the n-grams that constitute S1 have been observed more times than the n-grams of S2. Our approach, on the other hand, says that a sentence S1 is more likely than S2 if the closest match to S1 in C resembles S1 better than the closes match of S2 resembles S2 regardless of how many times these sentences have been observed. 3 Experiments We carried out experiments using the blog corpus provided by Spinn3r (Burton et al (2009)). It consists of 44 million blog posts that originated during August and September 2008 from which we selected, cleaned, normalized and segmented 2 million English language blogs. We reserved the segments originating from blogs dated September 30 for testing. We took 1000 segments from the test subset and for each of these segments we built a 16- hypothesis cohort (by creating 16 overlapping subsegments of the constant length from the segment). We built a 5-gram SLM using a 20k word dictionary and Knesser-Ney smoothing using the SRILM toolkit (Stolcke (2002)). We then ranked each of the 1000 </context>
</contexts>
<marker>Burton, Java, Soboroff, 2009</marker>
<rawString>Burton K., Java A., and Soboroff I. (2009) The ICWSM 2009 Spinn3r Dataset. Proc. ICWSM 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<title>A Bit of Progress in Language Modeling,</title>
<date>2001</date>
<journal>MS Res. Tech. Rpt.</journal>
<pages>2001--72</pages>
<contexts>
<context position="2122" citStr="Goodman (2001)" startWordPosition="352" endWordPosition="353">obability of a string of words: p(w1 ...wi ) To facilitate its computation, this probability is expressed as: p w w P w P w w ( ... ) ( ) ( |) ... ( |... )    P w w w 1 i 1 2 1 i 1 i1 Assuming that only the most immediate word history affects the probability of any given word, and focusing on a trigram language model: P(wi |w1 ... wi1)  P(wi |wi2wi1 ) This leads to:  p(wk |wk1 wk2 ) k i 1.. Language models are typically applied in ASR, MT and other tasks in which multiple hypotheses need to be rescored according to their likelihood (i.e., ranked). In a smoothed backoff SLM (e.g., Goodman (2001)), all the n-grams up to order n are computed and smoothed and backoff probabilities are calculated. If new data is introduced or removed from the corpus, the whole model, the counts and weights would need to be recalculated. Levenberg and Osborne (2009) proposed an approach for incorporating new data as it is seen in the stream. Language models have been used to support IR as a method to extend queries (Lavrenko et al. 2001); in this paper we focus on using IR to carry out language modeling. 2.1 The IR Language Model The IR-LM approach consists of two steps: the first is the identification of</context>
</contexts>
<marker>Goodman, 2001</marker>
<rawString>Goodman J. (2001) A Bit of Progress in Language Modeling, MS Res. Tech. Rpt. MSR-TR-2001-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huerta</author>
</authors>
<title>A Stack Decoder Approach to</title>
<date>2010</date>
<contexts>
<context position="3511" citStr="Huerta (2010)" startWordPosition="591" endWordPosition="592">entence S, we identify the k-closest matching sentences in the corpus through an information retrieval approach. We propose the use of a modified String Edit Distance as score in the IR process. To efficiently carry out the search of the closest sentences in the corpus we propose the use of an inverted index with word position P( w1 ... wi) 7 Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 7–8, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics information and a stack based search approach described in Huerta (2010). A modification of the SED allows queries to match portions of long sentences (considering local insertion deletions and substitutions) without penalizing for missing the non-local portion of the matching sentence. In the second step, in general, we would like to compute a likelihood-like value of S through a function of the distances (or alternatively, similarity scores) of the query S to the top khypotheses. However, for now we will focus on the more particular problem of ranking multiple sentences in order of matching scores, which, while not directly producing likelihood estimates it will</context>
</contexts>
<marker>Huerta, 2010</marker>
<rawString>Huerta J. (2010) A Stack Decoder Approach to</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Lavrenko</author>
<author>W B Croft</author>
</authors>
<title>Approximate String Matching,</title>
<date>2010</date>
<booktitle>Proc. of SIGIR</booktitle>
<marker>Lavrenko, Croft, 2010</marker>
<rawString>Approximate String Matching, Proc. of SIGIR 2010 Lavrenko V. and Croft W. B. (2001) Relevance based language models. Proc. of SIGIR 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Levenberg</author>
<author>M Osborne</author>
</authors>
<date>2009</date>
<location>Stream-based</location>
<contexts>
<context position="2376" citStr="Levenberg and Osborne (2009)" startWordPosition="392" endWordPosition="395">affects the probability of any given word, and focusing on a trigram language model: P(wi |w1 ... wi1)  P(wi |wi2wi1 ) This leads to:  p(wk |wk1 wk2 ) k i 1.. Language models are typically applied in ASR, MT and other tasks in which multiple hypotheses need to be rescored according to their likelihood (i.e., ranked). In a smoothed backoff SLM (e.g., Goodman (2001)), all the n-grams up to order n are computed and smoothed and backoff probabilities are calculated. If new data is introduced or removed from the corpus, the whole model, the counts and weights would need to be recalculated. Levenberg and Osborne (2009) proposed an approach for incorporating new data as it is seen in the stream. Language models have been used to support IR as a method to extend queries (Lavrenko et al. 2001); in this paper we focus on using IR to carry out language modeling. 2.1 The IR Language Model The IR-LM approach consists of two steps: the first is the identification of a set of matches from a corpus given a query sentence, and second is the estimation of a likelihood-like value for the query. In the first step, given a corpus C and a query sentence S, we identify the k-closest matching sentences in the corpus through </context>
</contexts>
<marker>Levenberg, Osborne, 2009</marker>
<rawString>Levenberg A. and Osborne M. (2009), Stream-based</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randomised Lang</author>
</authors>
<title>Models for SMT, EMNLP</title>
<date>2009</date>
<booktitle>Proc. ICSLP</booktitle>
<marker>Lang, 2009</marker>
<rawString>Randomised Lang. Models for SMT, EMNLP 2009 Stolcke A. (2002)s SRILM -- An Extensible Language Modeling Toolkit. Proc. ICSLP 2002</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>