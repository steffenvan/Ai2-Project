<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001137">
<title confidence="0.937882">
Symbolic Preference Using Simple Scoring
</title>
<author confidence="0.369275">
Paula S. Newman
</author>
<email confidence="0.828453">
newmanp@acm.org
</email>
<sectionHeader confidence="0.973988" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954045454546">
Despite the popularity of stochastic parsers,
symbolic parsing still has some advantages,
but is not practical without an effective
mechanism for selecting among alternative
analyses. This paper describes the symbolic
preference system of a hybrid parser that
combines a shallow parser with an overlay
parser that builds on the chunks. The hy-
brid currently equals or exceeds most sto-
chastic parsers in speed and is approaching
them in accuracy. The preference system is
novel in using a simple, three-valued scor-
ing method (-1, 0, or +1) for assigning
preferences to constituents viewed in the
context of their containing constituents.
The approach addresses problems associ-
ated with earlier preference systems, and
has considerably facilitated development. It
is ultimately based on viewing preference
scoring as an engineering mechanism, and
only indirectly related to cognitive princi-
ples or corpus-based frequencies.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978719298246">
Despite the popularity of stochastic parsers, sym-
bolic parsing still has some advantages, but is not
practical without an effective mechanism for se-
lecting among alternative analyses. Without it, ac-
cept/fail grammar rules must either be overly
strong or admit very large numbers of parses. .
Symbolic parsers have recently been augmented
by stochastic post-processors for output disam-
biguation, which reduces their independence from
corpora. Both the LFG XLE parser (Kaplan et.al.
2004), and the HPSG LinGO ERG parser (Tou-
tanova et al. 2005) have such additions.
This paper examines significant aspects of a
purely symbolic alternative: the preference and
pruning system of the RH (Retro-Hybrid) parser
(Newman, 2007). The parser combines a pre-
existing, efficient shallow parser with an overlay
parser that builds on the emitted chunks. The over-
lay parser is &amp;quot;retro&amp;quot; in that the grammar is related
to ATNs (Augmented Transition Networks) origi-
nated by Woods (1970).
RH delivers single &amp;quot;best&amp;quot; parses providing syn-
tactic categories, syntactic functions, head features,
and other information (Figure 1). The parenthe-
sized numbers following the category labels in the
figure are preference scores, and are explained fur-
ther on. While the parses are not quite as detailed
as those obtained using &amp;quot;deep&amp;quot; grammars, the
missing information, mostly relating to long dis-
tance dependencies, can be added at far less cost in
a post-parse phase that operates only on a single
best parse. Methods for doing so, for stochastic
parser output, are described by Johnson (2002) and
Cahill et al (2004).
The hybrid parser exceeds most stochastic pars-
ers in speed, and approaches them in accuracy,
even based on limited manual &amp;quot;training&amp;quot; on a par-
ticular idiom, so the preference system is a suc-
cessful one (see Section 6), and continues to im-
prove.
The RH preference system builds on earlier
methods. The major difference is a far simpler
scoring system, which has considerably facilitated
overlay parser development. Also, the architecture
allows the use of large numbers of preference tests
without impacting parser speed. Finally, the treat-
ment of coordination exploits the lookaheads af-
forded by the shallow parser to license or bar alter-
native appositive readings.
Section 2 below discusses symbolic preference
systems in general, and section 3 provides an over-
view of RH parser structure. Section 4 describes
the organization of the RH preference system and
the simplified scoring mechanism. Section 5 dis-
cusses the training approach and Section 6 pro-
vides some experimental results. Section 7 sum-
marizes, and indicates directions for further work.
</bodyText>
<page confidence="0.989963">
83
</page>
<note confidence="0.9585255">
Proceedings of the 10th Conference on Parsing Technologies, pages 83–92,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9899785">
Figure 1. Output Parse Tree for &amp;quot;Rumsfeld micromanaged daily briefings and rode roughshod
over people.&amp;quot; * indicates head. Mouseover shows head features for &amp;quot;micromanaged&amp;quot;.
</figureCaption>
<sectionHeader confidence="0.778078" genericHeader="method">
2 Background: Symbolic Preference
</sectionHeader>
<subsectionHeader confidence="0.749297">
2.1 Principles
</subsectionHeader>
<bodyText confidence="0.997473615384615">
Preference-based parsing balances necessarily
permissive syntactic rules by preference rules that
promote more likely interpretations. One of the
earliest works in the area is by Wilks (1975),
which presented a view of preference as based on
semantic templates. Throughout the 1980&apos;s there
was a considerable amount of work devoted to
finding general principles, often cognitively ori-
ented, for preference rules, and then to devise
mechanisms for using them in practical systems.
Hobbs and Bear (1990) provide a useful summary
of the evolved principles. Slightly restated, these
principles are:
</bodyText>
<listItem confidence="0.982247">
1. Prefer attachments in the &amp;quot;most restrictive
context&amp;quot;.
2. If that doesn&apos;t uniquely determine the result,
attach low and parallel, and finally
3. Adjust the above based on considerations of
punctuation
</listItem>
<bodyText confidence="0.998861125">
Principle 1 suggests that the preference for a
constituent in a construction should depend on the
extent to which the constituent meets a narrow set
of expectations. Most of the examples given by
Hobbs and Bear use either (a) sub-categorization
information, e.g., preferring the attachment of a
prepositional phrase to a head that expects that par-
ticular preposition, or (b) limited semantic infor-
mation, for example, preferring the attachment of a
time expression to an event noun.
Principle 2 implies that in the absence of coor-
dination, attachment should be low, and in the
presence of coordination, parallel constituents
should be preferred. Principle 3 relates primarily
to the effect of commas in modifying attachment
preferences.
</bodyText>
<subsectionHeader confidence="0.997054">
2.2 Implementations
</subsectionHeader>
<bodyText confidence="0.995166615384615">
Abstractly, symbolic preference systems can be
thought of as regarding a set of possible parses as a
collection of spanning trees over a network of po-
tential relationships, with each edge having a nu-
meric value, and attempting to find the highest
scoring tree.1
However, for syntactic parsers, in contrast with
dependency parsers, it is convenient to associate
scores with constituents as they are built, for con-
sistency with the parser structure, and to permit
within-parse pruning. A basic model for a prefer-
ence system assigns preference scores to rules. For
a rule
</bodyText>
<equation confidence="0.8265202">
C- c1, c2, ..., cn
the preference score PS(CC) of a resultant con-
stituent CC is the sum:
PS(cc1) + PS(cc2) + +PS(ccn)
+ TRS (C, cc1, cc2, ..., ccn)
</equation>
<bodyText confidence="0.999964142857143">
where PS(cci) is the non-contexted score of con-
stituent cci, and the total relationship score TRS is a
value that assesses the relationships among the sib-
ling constituents of CC. The computation of TRS
depends on the parser approach. For a top-down
parser, TRS may be the sum of contexted relation-
ship scores CRS, for example:
</bodyText>
<equation confidence="0.989980333333333">
TRS = CRS (cc1|C) +CRS (cc2|C, cc1), +
CRS (cc3|C, cc1, cc2) + .....
+ CRS (cn |C, cc1,....ccn-1)
</equation>
<bodyText confidence="0.9911305">
where each CRS (cci|_ ) evaluates cci in the context
of the prior content of the constituent CC and the
category C..
Few publications specify details of how prefer-
ence scores are assigned and combined. For exam-
ple, Hobbs and Bear (1990) say only that &amp;quot;When a
</bodyText>
<footnote confidence="0.805329666666667">
1 The idea has also been used directly in stochastic pars-
ers that consider all possible attachments, for example,
by McDonald et al. (2005).
</footnote>
<page confidence="0.999001">
84
</page>
<bodyText confidence="0.999873571428572">
non-terminal node of a parse tree is constructed, it
is given an initial score which is the sum of the
scores of its child nodes. Various conditions are
checked during the construction of the node and, as
a result, a score of 20, 10, 3, -3, -10, or -20 may be
added to the initial score.&amp;quot;
McCord (1993), however, carefully describes
how the elements of TRS are computed in his slot
grammar system. Each element value is the sum of
the results of up to 8 optional, typed tests, relating
to structural, syntactic, and semantic conditions.
One of these tests, relating to coordination, is a
complex test involving 7 factors assessing parallel-
ism.
</bodyText>
<subsectionHeader confidence="0.998278">
2.3 Multi-Level Contexted Scoring
</subsectionHeader>
<bodyText confidence="0.999991166666667">
The scores assigned by symbolic preference sys-
tems to particular relationships or combinations
usually indicate not just whether they are preferred
or dispreferred, but to what degree. For example, a
score of 1 might indicate that a relationship is
good, and 2 that it is better.
Such multi-level scores create problems in tun-
ing parsers to remove undesirable interactions,
both in the grammar and the preference system.
Even for interactions foreseen in advance, one
must remember or find out the sizes of the prefer-
ences involved, to decide how to compensate.
Yamabana et al. (1993) give as an example a bot-
tom-up parser, where an S constituent with a tran-
sitive verb head but lacking an object is initially
given a strong negative preference, but when it is
discovered that the constituent actually functions
as a relative clause, the appropriate compensation
must be found. (Their solution uses a vector of
preference scores, with the vector positions corre-
sponding to specific types of preference features,
together with an accumulator. It allows the content
of vector elements to be erased based on subse-
quently discovered compensating features.)
For unforeseen interactions, for example when a
review of parser outputs finds that the best parse is
not given the highest preference score, multi-level
contexted scoring requires complex tracing of the
contribution of each score to the total, remember-
ing at each point what the score should be, to de-
termine the necessary adjustments.
A different sort of problem of multi-level scor-
ing stems from the unavoidable incompleteness of
information. For example, in Figure 1, the attach-
ment of an object to the &amp;quot;guessed&amp;quot; verb &amp;quot;micro-
managed&amp;quot; is dispreferred because the verb is not
identified as transitive. Here, the correct reading
survives because there are no higher scoring ones.
But in some situations, if such a dispreference
were given a large negative score, the parser could
be forced into very odd readings not compensated
for by other factors.
</bodyText>
<subsectionHeader confidence="0.987494">
2.4 Corpus-Based Preference
</subsectionHeader>
<bodyText confidence="0.9999418125">
In the early 1990&apos;s, the increasing availability and
use of corpora, together with a sense that multi-
level symbolic preference scores were based on ad-
hoc judgments, led to experiments and systems that
used empirical methods to obtain preference
weights. Examples of this work include a system
by Liu et al (1990), and experiments by Hindle and
Rooth (1993), and Resnik and Hearst (1993).2
These efforts had mixed success, suggesting that
while multi-level preference scores are problem-
atic, integrating some corpus data does not solve
the problems. In light of later developments, this
might be expected. Full-scale contemporary sto-
chastic parsers use a broad range of interacting fea-
tures to obtain their fine-grained results; frequen-
cies of particular relationships are just one aspect.
</bodyText>
<subsectionHeader confidence="0.936257">
2.5 OT-based Preference
</subsectionHeader>
<bodyText confidence="0.999352130434783">
A more recent approach to symbolic preference
adapts optimality theory to parser and generator
preference. Optimality Theory (OT) was origi-
nally developed to explain phonological rules
(Prince and Smolensky, 1993). In that use, poten-
tial rules are given one &amp;quot;optimality mark&amp;quot; for each
constraint they violate. The marks, all implicitly
negative, are ranked by level of severity. A best
rule R is one for which (a) the most severe level of
constraint violation L is &lt; the level violated by any
other rule, and (b) if other rules also violate level L
constraints, the number of such violations is &gt; the
number of violations by R.
As adapted for use in the XLE processor for
LFG (Frank et al. 1998) optimality marks are asso-
ciated with parser and generator outputs. Positive
marks are added, and also labeled inter-mark posi-
tions within the optimality mark ranking. The la-
beled positions influence processor behavior. For
generation, they are used to disprefer infelicitous
strings accepted in a parse direction. And for pars-
2 McCord (1993) also includes some corpus-based in-
formation, but to a very limited extent.
</bodyText>
<page confidence="0.998663">
85
</page>
<bodyText confidence="0.998173684210526">
ing they can be used to disprefer (actually ignore)
rarely-applicable rules, in order to reduce parse
time (Kaplan et al, 2004).
However, because the optimality marks are
global, a single dispreference can rule out an entire
parse. To partially overcome this limitation, a fur-
ther extension (see XLE Online Documentation)
allows direct comparisons of alternative readings
for the same input extent. A different optimality
mark can be set for each reading, and the use of
one such mark in the ranking can be conditioned
on the presence of another particular mark for the
same extent. For example, a conditional disprefer-
ence can be set for an adjunct reading if an argu-
ment reading also exists. The extension does not
address more global interactions, and is said (Forst
et al. 2005) to be used mostly as a pre-filter to limit
the readings disambiguated by a follow-on stochas-
tic process.
</bodyText>
<subsectionHeader confidence="0.984026">
2.6 A Slightly Different View
</subsectionHeader>
<bodyText confidence="0.999936722222223">
A slightly different view of preference–based pars-
ing is that the business of a preference system is to
work in tandem with a permissive syntactic gram-
mar, to manipulate outcomes.
The difference focuses on the pragmatic role of
preference in coercing the parser. In this light, the
principles of section 2.1 are guidelines for desired
outcomes, not bases for judging the goodness of a
relationship or setting preference values. Instead,
preference values should be set based on their ef-
fectiveness in isolating best parses. Also, in this
light, the utility of a preference system lies not
only in its contribution to accuracy, but also in its
software-engineering convenience. These consid-
erations led to the simpler, more practical scoring
system of the RH overlay parser, described in sec-
tion 4 below, in which contexted preference scores
CRS can have one of only 3 values, -1, 0, or +1.
</bodyText>
<sectionHeader confidence="0.983968" genericHeader="method">
3 Background: The RH Parser
</sectionHeader>
<bodyText confidence="0.995675666666667">
The RH parser consists of three major components,
outlined below: the shallow parser, a mediating
&amp;quot;locator&amp;quot; phase, and the overlay parser.
</bodyText>
<subsectionHeader confidence="0.999691">
3.1 Shallow Parser
</subsectionHeader>
<bodyText confidence="0.999004352941176">
The shallow parser used, XIP, was developed by
XRCE (Xerox Research Center Europe). It is
actually a full parser, whose per-sentence output
consists of a single tree of basic chunks, together
with identifications of (sometimes alternative)
typed dependences among the chunk heads (Ait-
Mokhtar et al. 2002, Gala 2004). But because the
XIP dependency analysis for English was not
mature at the time that work on RH began, and
because a classic parse tree annotated by syntactic
functions is more convenient for some
applications, we focused on the output chunks.
XIP is astonishingly fast, contributing very little
to parse times (about 20%). It consists of the XIP
processor, plus grammars for a number of
languages. The grammar for a particular language
consists of:
</bodyText>
<listItem confidence="0.937484777777778">
(a) a finite-state lexicon producing alternative
part-of-speech and morphological analyses for
each token, together with bit-expressed
subcategorization and control features, and
(some) semantic features,
(b) a substitutable tagger identifying the most
probable part of speech for each token, and
(c) sequentially applied rule sets that extend and
modify lexical information, disambiguate tags,
</listItem>
<bodyText confidence="0.960520833333333">
identify named entities and other multiwords,
and produce output chunks and inter-chunk
head dependences (the latter not used in the
hybrid).
Work on the hybrid parser has included large
scale extensions to the XIP English rule sets.
</bodyText>
<subsectionHeader confidence="0.999689">
3.2 Locator phase
</subsectionHeader>
<bodyText confidence="0.99993235">
The locator phase accumulates and analyses some
of the shallow parser results to expedite the
grammar and preference tests of the overlay parser.
For preference tests, for any input position, the
positions of important leftward and rightward
tokens are identified. These &amp;quot;important&amp;quot; tokens
include commas, and leftward phrase heads that
might serve as alternative attachment points.
Special attention is given to coordination, a
constant source of inefficiency and inaccuracy for
all parsers. To limit this problem, an input string is
divided into spans ending at coordinating conjunc-
tions, and the chunks following a span are exam-
ined to determine what kinds of coordination might
be present in the span. For example, if a chunk
following a span Sp is a noun phrase, and there are
no verbs in the input following that noun phrase,
only noun phrase coordination is considered within
Sp. Also, with heuristic exceptions, the locator
phase disallows searching for appositives within
</bodyText>
<page confidence="0.984574">
86
</page>
<bodyText confidence="0.992663">
long sequences of noun and prepositional phrases
ending with a coordinating conjunction.
</bodyText>
<subsectionHeader confidence="0.998381">
3.3 Overlay Parser
</subsectionHeader>
<bodyText confidence="0.999917">
The overlay parser uses a top-down grammar,
expressed as a collection of ATN-like grammar
networks. A recursive control mechanism traverses
the grammar networks depth-first to build
constituents. The labels on the grammar network
arcs represent specialized categories, and are
associated with tests that, if successful, either
return a chunk or reinvoke the control to attempt
to build a constituents for the category. The label-
specific tests include both context-free tests, and
tests taking into account the current context. For
details see (Newman, 2007).
If an invocation of the control is successful, it
returns an output network containing one or more
paths, with each path representing an alternative
sequence of immediate children of the constituent.
An example output network is shown in figure 2.
Each arc of the network references either a basic
chunk, or a final state of a subordinate output net-
work. Unlike the source grammar networks, the
output networks do not contain cycles or converg-
ing arcs, so states represent unique paths.
The states contain both (a) information about
material already encountered along the path, in-
cluding syntactic functions and head features, and
(b) a preference score for the path to that point.
Thus the figure 2 network represents two
alternative noun phrases, one represented by the
path containing OS0 and OS1, and one containing
OS0, OS1, and OS2. State OS2 contains the
preference score (+1), because attaching a locative
pp to a feature of the landscape is preferred.
</bodyText>
<table confidence="0.9655899">
From To Cat Synfun Reference
OSo OS1 NP HEAD NPChunk
(The park)
OS1 OS2 PP NMOD Final state of
PP net for
(in Paris)
States Score Final?
OS0 0 No
OS1 0 Yes
OS2 +1 Yes
</table>
<figureCaption confidence="0.997937">
Figure 2. Output network for &amp;quot;The park in Paris&amp;quot;
</figureCaption>
<bodyText confidence="0.999943363636364">
Before an output network is returned from an
invocation of the control mechanism, it is pruned
to remove lower-scoring paths, and cached.
Output from the overlay parser is a single tree
(Figure 1) derived from a highest scoring full path
(i.e. final state) of a topmost output network. If
there are several highest scoring paths, low attach
considerations select a &amp;quot;best&amp;quot; one. The preference
scores shown in Figure 1 in parentheses after the
category labels are the scores at the succeeding
states of the underlying output networks.
</bodyText>
<sectionHeader confidence="0.981846" genericHeader="method">
4 Preference System
</sectionHeader>
<bodyText confidence="0.9656985">
Any path in an output network has the form:
S0, Ref1, S1, Ref2, ..., Sn-1 , Refn, Sn
where Si is a state, and Refi labels an arc, and refer-
ences either a basic chunk, or a final state of an-
other output network. A state Si has total prefer-
ence score TPS(i) where:
</bodyText>
<equation confidence="0.762228666666667">
• TPS(0) = 0
• TPS(i), i&gt;0 =
TPS( i-1) + PS(Refi) +CRS(Refi)
</equation>
<listItem confidence="0.9570155">
• PS(Refi) is the non-contexted score of the
constituent referenced by Refi, that is, the
score at the referenced final state.
• CRS(Refi) is the contexted score for Refi, in
the context of the network category and the
path ending at the previous state i-1.
</listItem>
<bodyText confidence="0.999759714285714">
For example, if Refi refers to a noun phrase con-
sidered a second object within a path, and the syn-
tactic head along the path does not expect a second
object, CRS(Refi) might be (-1).
Each value CRS is limited to values in {-1, 0,
+1}. Therefore, no judgment is needed to decide
the degree to which a contexted reference is to be
dispreferred or preferred. Also, if the desired parse
result does not receive the highest overall score, it
is relatively easy to trace the reason. Pruning (see
below) can be disabled and all parses can be dis-
played, as in Figure 1, which shows the scores
TPS(i) in parentheses after the category labels for
each Refi (with zero scores not shown). Then, if
</bodyText>
<equation confidence="0.903938">
TPS(i) &gt; ( TPS(i-1) + PS(Refi))
</equation>
<bodyText confidence="0.9952055">
it is clear that the contexted reference is preferred.
If multi-level contexted scoring were used instead,
it would be necessary to determine whether the
reference was preferred to exactly the right degree.
</bodyText>
<page confidence="0.991772">
87
</page>
<table confidence="0.999328">
Test Block Length Indexed By
Type Independent?
Coordinate Y Parent syncat
Subcat Y No index
FN1 Y synfun
TAG1 Y syncat
FN2 N synfun
TAG2 N syncat
</table>
<tableCaption confidence="0.999928">
Table 1. Preference Test Block Types
</tableCaption>
<subsectionHeader confidence="0.971326">
4.1 Preference test organization
</subsectionHeader>
<bodyText confidence="0.999939673913043">
To compute the contexted score CRS for a refer-
ence, relevant tests are applied until either (a) a
score of -1 is obtained, which is used as CRS for
the reference, or (b) the tests are exhausted. In the
latter case, CRS is the higher of the values {0, +1}
returned by any test.
For purposes of efficiency, the preference tests
are divided into typed blocks, as shown in Table 1.
At most one block of each type can be applied to a
reference. Four of the blocks contain tests that are
independent of referenced constituent length. They
are applied at most once for a returned output net-
work and the results are assumed for all paths. The
other two blocks are length dependent.
Referring to Table 1, the length-independent co-
ordinate tests are applied only to non-first siblings
of coordinated constituents. The parent category
indicates the type of constituents being coordinated
and selects the appropriate test block. Tests in
these blocks focus on the semantic consistency of a
coordinated sibling with the first one.
Subcategorization tests are applied to preposi-
tional, particle, and clausal dependents of the cur-
rent head. These tests consist to a large extent of
bit-vector implemented operations, comparing the
expected dependent types of the head with lexical
features of the prospective dependent. The tests
are made somewhat more complex because of
various exceptions, such as (a) temporal and loca-
tive phrases, and (b) the presence of a nearer po-
tential head also expecting the dependent type.
The other test block types are selected and ac-
cessed either by the syntactic category or the syn-
tactic function of the reference, depending on the
focus of the test. The length-dependent tests in-
clude tests of noun-phrases within coordinations to
determine whether post modifiers should be ap-
plied to the individual phrase or to the coordination
as a whole.
The test blocks are expressed in procedural
code. This has allowed the parser to be developed
without advance prediction of the types of infor-
mation needed for the tests, and also has contrib-
uted some efficiency. The blocks, usually short
but occasionally long, generally consist of ordered
(if-then-else) subtests.
</bodyText>
<subsectionHeader confidence="0.987436">
4.2 Preference test scope
</subsectionHeader>
<bodyText confidence="0.999769235294118">
A contexted preference test can refer to material on
three levels of the developing parse tree: (a) the
syntactic category of the parent (available because
of the top-down parser direction) (b) information
about the current output network path, including
head features, already-encountered syntactic func-
tions, and a small collection of special-purpose
information, and (c) information about the refer-
enced constituent, specifically its head and a list of
the immediately contained syntactic functions. The
tests can also reference lookahead information fur-
nished by the locator phase. This material is suffi-
cient for most purposes. Limiting the kind of ref-
erenced information, particularly not permitting
access to sibling constituents or deep elements of
the referenced constituent, contributes to perform-
ance.
</bodyText>
<subsectionHeader confidence="0.998332">
4.3 Pruning
</subsectionHeader>
<bodyText confidence="0.9999745">
Before an output network is completed, it is pruned
to remove lower-scoring output network paths.
Any path with the same length as another but with
a lower score is pruned. Also, paths having other
lengths but considerably lower preference scores
than the best-scoring path are often pruned as well.
</bodyText>
<subsectionHeader confidence="0.999525">
4.4 Usage Example
</subsectionHeader>
<bodyText confidence="0.999979642857143">
To illustrate how the simple scores and modular
tests are used to detect and repair problems in the
preference system, Figure 1 shows, as noted be-
fore, that the attachment of an object to the guessed
verb &amp;quot;micromanaged&amp;quot; is dispreferred. In this case
the probable reason is the lack of a transitive fea-
ture for the verb. To check this, we would look at
the FN1 test block for OBJ and find that in fact the
test assigns (-1) in this case. The required modifi-
cation is best made by adding a transitive feature to
guessed verbs.
But there is another problem here: the attach-
ment of the pp &amp;quot;over people&amp;quot; is not given a positive
preference. Checking the FN1 test block for
</bodyText>
<page confidence="0.997563">
88
</page>
<bodyText confidence="0.999934666666667">
VMOD and the TAG1 test block for PP finds that
there is in fact no subtest that prefers combinations
of motion verbs and &amp;quot;over&amp;quot;. While this doesn&apos;t
cause trouble in the example, it could if there were
a prior object in the verb phrase. A subtest or sub-
categorization feature could be added.
</bodyText>
<sectionHeader confidence="0.958136" genericHeader="method">
5 Training the Preference System
</sectionHeader>
<bodyText confidence="0.999529142857143">
To obtain the preference system, an initial set of
tests is identified, based primarily on subcategori-
zation considerations, and then refined and ex-
tended based on manual &amp;quot;training&amp;quot; on large num-
bers of documents. Several problem situations
result in changes to the system, besides random
inspection of scores:
</bodyText>
<listItem confidence="0.688913">
(a) the best parse identified is not the correct one,
either because the correct parse is not the high-
est scoring one, or because another parse with
the same score was considered &amp;quot;best&amp;quot; because
of low-attach considerations.
(b) The best parse obtained is the correct one, but
there are many other parses with the same
score, suggesting a need for refinement, both
to improve performance and to avoid errors in
related circumstances when the correct parse
does not &amp;quot;float&amp;quot; to the top.
(c) No parse is returned for an input, because of
imposed space constraints, which indirectly
control the amount of time that can be spent to
obtain a parse.
</listItem>
<bodyText confidence="0.994428272727273">
In some cases the above problems can be solved
by adjusting the base grammar, or by extending
lexical information to obtain the appropriate pref-
erences. For example, the preference scoring prob-
lems of Figure 1 can be corrected by adding sub-
categorization information, as described above.
In other cases, one or more modifications to the
preference system are made, adding positive tests
to better distinguish best parses, adding negative
tests to disprefer incorrect parses, and/or refining
existing tests to narrow or expand applicability.
Positive tests often just give credit to expected
structures not previously considered to require rec-
ognition beyond acceptance by the grammar.
Negative tests fall into many classes, such as:
(a) Tests for &amp;quot;ungrammatical&amp;quot; phenomena that
should not be ruled out entirely by the gram-
mar. These include lack of agreement, lack of
expected punctuation, and presence of unex-
pected punctuation (such as a comma between
a subject and a verb when there is no comma
within the subject).
</bodyText>
<listItem confidence="0.919773">
(b) Tests for probably incomplete constituents,
based on the chunk types that follow them.
(c) Tests for unexpected arguments, except in
some circumstances. For example, &amp;quot;benefac-
tive&amp;quot; indirect objects (&amp;quot;John baked Mary a
cake&amp;quot;) are dispreferred if they are not in ap-
propriate semantic classes.
</listItem>
<bodyText confidence="0.998867411764706">
Also, a large, complex collection of positive and
negative tests, based on syntactic and semantic fac-
tors, are used to distinguish among coordinated and
appositive readings, and among alternative attach-
ments of appositives.
If the addition or modification of preference
tests does not solve a particular problem, then
some more basic changes can be made, such as the
introduction of new semantic classes. And, in rare
cases, new features are added to output network
states in order to make properties of non-head con-
stituents encountered along a path available for
testing both further along the path and in the de-
velopment of higher-level constituents. An exam-
ple is the person and number of syntactic subjects,
allowing contexted preference tests for finite verb
phrases to check for subject consistency.
</bodyText>
<subsectionHeader confidence="0.989694">
5.1 Relationship to &amp;quot;supervised&amp;quot; training
</subsectionHeader>
<bodyText confidence="0.999962913043478">
To illustrate the relationship between the above
symbolic training method for preference scoring
and corpus-based methods, perhaps the easiest way
is to compare it to an adaptation (Collins and
Roark, 2004) of the perceptron training method to
the problem of obtaining a best parse (either di-
rectly, or for parse reranking), because the two
methods are analogous in a number of ways.
The basic adapted perceptron training assumes a
generator function producing parses for inputs.
Each such parse is associated with a vector of fea-
ture values that express the number of times the
feature appears in the input or parse. The features
used are those identified by Roark (2001) for a top-
down stochastic parser.
The training method obtains a weight vector W
(initially 0) for the feature values, by iterating mul-
tiple times over pairs &lt;xi, yi&gt; where xi is a training
input, and yi is the correct parse for xi. For each
pair, the best current parse zi for xi produced by the
generator, with feature value vector V(zi), is se-
lected based on the current value of (W · V(zi)).
Then if zi :� yi, W is incremented by V(yi), and dec-
</bodyText>
<page confidence="0.999505">
89
</page>
<bodyText confidence="0.999941294117647">
remented by V(zi). After training, the weights in W
are divided by the number of training steps (# in-
puts * # iterations).
The method is analogous to the RH manual
training process for preference in a number of
ways. First, the features used were developed for
suitability to a top-down parser, for example taking
into account superordinate categories at several
levels, some lexical information associated with
non-head, left-side siblings of a node, and some
right-hand lookahead. Although only one su-
perordinate category is routinely used in RH pref-
erence tests, in order to allow caching of output
networks for a category, the preference system al-
lows for and occasionally uses the promotion of
non-head features of nested constituents to provide
similar capability.
Also, the feature weights obtained by the per-
ceptron training method can be seen to focus on
patterns that actually matter in distinguishing cor-
rect from incorrect parses, as does RH preference
training. Intuitively, the difference is that while
symbolic training for RH explicitly pinpoints pat-
terns that distinguish among parses, the perceptron
training method accomplishes something similar
by postulating some more general features as nega-
tive or positive based on particular examples, but
allowing the iterations over a large training set to
filter out potentially indicative patterns that do not
actually serve as such.
These analogies highlight the fact that prefer-
ence system training, whether symbolic or corpus-
based, is ultimately an empirical engineering exer-
cise.
</bodyText>
<sectionHeader confidence="0.94253" genericHeader="method">
6 Some Experimental Results
</sectionHeader>
<bodyText confidence="0.999214947368421">
Tables 2, 3, and 4 summarize some recent results
as obtained by testing on Wall Street Journal sec-
tion 23 of the Penn Treebank (Marcus et al. 1994).
The RH results were obtained by about 8 weeks of
manual training on the genre.
Table 2 compares speed and coverage for RH
and Collins Model3 (Collins, 1999) run on the
same CPU. The table also extrapolates the results
to two other parsers, based on reported compari-
sons with Collins. One extrapolation is to a very
fast stochastic parser by Sagae and Lavie (2005).
The comparison indicates that the RH parser speed
is close to that of the best contemporary parsers.
The second extrapolation is to the LFG XLE
parser (Kaplan et al. 2004) for English, consisting
of a highly developed symbolic parser and gram-
mar, an OT-based preference component, and a
stochastic back end to select among remaining al-
ternative parser outputs. Two sets of values are
given for XLE, one obtained using the full English
grammar, and one obtained using a reduced gram-
mar ignoring less-frequently applicable rules. The
extrapolation indicates that the coverage of RH is
quite good for a symbolic parser with limited train-
ing on an idiom.
While the most important factor in RH parser
speed is the enormous speed of the shallow parser,
the preference and pruning approach of the overlay
parser make contributions to both speed and cover-
age. This can be seen in Table 2 by the difference
between RH parser results with and without prun-
ing. Pruning increases coverage because without it
more parses exceed imposed resource limits.
Table 3 compares accuracy. The values for
Collins and Sagae/Lavie are based on comparison
with treebank data for the entire section 23. How-
ever, because RH does not produce treebank-style
tags, the RH values are based only on a random
</bodyText>
<table confidence="0.999602714285714">
Time No full parse
Sagae/Lavie ~ 4 min 1.1%
RH Prune 5 min 14 sec 10.8%
RH NoPrune 7 min 5 sec 13.9 %
Collins m3 16 min .6%
XLE reduced ~24 minutes unknown
XLE full ~80 minutes ~21%
</table>
<tableCaption confidence="0.996454">
Table 2. Speeds and Extrapolated speeds
</tableCaption>
<table confidence="0.999932333333333">
Fully F-score Avg cross
accurate bkts
Sagae/Lavie unknwn 86% unknwn
Collins Lbl 33.6% 88.2% 1.05
CollinsNoLbl 35.4% 89.4 % 1.05
RH NoLbl 46% 86 % .59
</table>
<tableCaption confidence="0.94831">
Table 3. Accuracy Comparison
</tableCaption>
<table confidence="0.999475666666667">
Average Median
RH Base 137.10 11
RH Pref 5.04 2
</table>
<tableCaption confidence="0.999097">
Table 4. Highest Scoring Parses per Input
</tableCaption>
<page confidence="0.995944">
90
</page>
<bodyText confidence="0.999557958333333">
100-sentence sample from section 23, and com-
pared using a different unlabeled bracketing stan-
dard. For details see Newman (2007). For non-
parsed sentences the chunks are bracketed. Accu-
racy is not extrapolated to XLE because available
measurements give f-scores (all &lt;_ 80%) for de-
pendency relations rather than for bracketed con-
stituents.
As a partial indication of the role and effective-
ness of the RH preference system, if non-parsed
sentences are ignored, the percentage of fully accu-
rate bracketings shown in Table 3 rises to ap-
proximately 46/89 = 51.6% (it is actually larger
because coverage is higher on the 100-sentence
sample). As further indication, Table 4 compares,
for section 23, the average and median number of
parses per sentence obtained by the base grammar
alone (RH Base), and the base grammar plus the
preference system (RH Pref).3 The table demon-
strates that the preference system is a crucial parser
component. Also, the median of 2 parses per sen-
tence obtained using the preference system ex-
plains why the fallback low-attach strategy is suc-
cessful in many cases.
</bodyText>
<sectionHeader confidence="0.978185" genericHeader="conclusions">
7 Summary and Directions
</sectionHeader>
<bodyText confidence="0.9998411">
The primary contribution of this work is in demon-
strating the feasibility of a vastly simplified sym-
bolic preference scoring method. The preference
scores assigned are neither &amp;quot;principle-based&amp;quot;, nor
&amp;quot;ad-hoc&amp;quot;, but explicitly engineered to facilitate the
management of undesirable interactions in the
grammar and in the preference system itself. Re-
stricting individual contexted scores to {-1, 0, +1}
addresses the problems of multi-level contexted
scoring discussed in Section 2, as follows:
</bodyText>
<listItem confidence="0.9944017">
• No abstract judgment is required to assign a
value to a preference or dispreference.
• Information deficiencies contribute only
small dispreferences, so they can often be
overcome by preferences.
• Compensating for interactions that are fore-
seen does not require searching the rules to
find necessary compensating values.
• For unforeseen interactions discovered when
reviewing parser results, the simplified pref-
</listItem>
<footnote confidence="0.660436666666667">
3 The values are somewhat inflated because they include
duplicate parses, which have not yet been entirely
eliminated.
</footnote>
<bodyText confidence="0.999965185185185">
erence scores facilitate finding the sources of
the problems and potential methods of solv-
ing them.
This approach to symbolic preference has facili-
tated development and maintenance of the RH
parser, and has enabled the production of results
with a speed and accuracy comparable to the best
stochastic parsers, even with limited training on an
idiom.
An interesting question is why this very simple
approach does not seem to have been used previ-
ously. Part of the answer may lie in the lack of
explicit recognition that symbolic preference scor-
ing is ultimately an engineering problem, and is
only indirectly based on cognitive principles or
approximations to frequencies of particular rela-
tionships.
Ongoing development of the RH preference sys-
tem includes continuing refinement based on
&amp;quot;manual&amp;quot; training, and continuing expansion of the
set of semantic features used as the parser is ap-
plied to new domains. Additional development
will also include more encoding of, and attention
to, the expected semantic features of arguments.
Experiments are also planned to examine the accu-
racy/performance tradeoffs of using additional
context information in the preference tests.
</bodyText>
<sectionHeader confidence="0.999257" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999693857142857">
Salah Aït-Mokhtar, Jean-Pierre Chanod, Claude Roux.
2002. Robustness beyond shallowness: incremental
deep parsing, Natural Language Engineering 8:121-
144, Cambridge University Press.
Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef
van Genabith, and Andy Way. 2004. Long-Distance
Dependency Resolution in Automatically Acquired
Wide-Coverage PCFG-Based LFG Approximations,
In Proc of the 42nd Annual Meeting of the Associa-
tion for Computational Linguistics (ACL&apos;04), Barce-
lona
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Michael Collins and Brian Roark. 2004. Incremental
Parsing with the Perceptron Algorithm. In Proc of the
42nd Annual Meeting of the Association for Compu-
tational Linguistics (ACL&apos;04), Barcelona.
Martin Forst, Jonas Kuhn, and Christian Rohrer. 2005.
Corpus-based Learning of OT Constraint Rankings
for Large-scale LFG Grammars. In Proc of the
</reference>
<page confidence="0.982715">
91
</page>
<reference confidence="0.999736423913044">
LFG05 Conference, Bergen. Available at
http://cslipublications.stanford.edu/LFG/10/lfg05.pdf
Anette Frank., Tracy H. King, Jonas Kuhn, and John
Maxwell. 1998. Optimality theory style constraint
ranking in large-scale LFG grammars. In M. Butt and
T. H. King, Eds. Proc of the Third LFG Conference.
Available http://csli-publications.stanford.edu/LFG3/
Revised version in Peter Sells, ed. Formal and Theo-
retical Issues in Optimality Theoretic Syntax, CSLI
Publications, 2001.
Nuria Gala. 2004. Using a robust parser grammar to
automatically generate UNL graphs. In Proc Work-
shop on Robust Methods for Natural Language Data
at COLING&apos;04, Geneva
Donald Hindle and Mats Rooth. 1993. Structural Ambi-
guity and Lexical Relations. Computational Linguis-
tics, 19:1,103–120.
Jerry R. Hobbs and John Bear. 1990. Two Principles of
Parse Preference. In Proceedings of the 13th Interna-
tional Conference on Computational Linguistics
(COLING&apos;90), Helsinki, Finland, August 1990.
Jerry. R. Hobbs, Douglas E. Appelt, John Bear, Mabry
Tyson, and David Magerman. 1992. Robust process-
ing of real-world natural language texts. In Paul S.
Jacobs, ed., Text-Based Intelligent Systems: Current
Research and Practice in Information Extraction and
Retrieval. Lawrence Erlbaum, New Jersey, 1992.
Mark Johnson. 2002. A simple pattern-matching algo-
rithm for recovering empty nodes and their antece-
dents. Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics (ACL&apos;02),
Philadelphia, July 2002, pp. 136-143.
Ronald M. Kaplan, Stephan Riezler, Tracy H. King,
John T. Maxwell, Alex Vasserman. 2004. Speed and
accuracy in shallow and deep stochastic parsing. In
Proc HLT/NAACL&apos;04, Boston, MA.
Chao-Lin Liu, Jing-Shin Chang, and Keh-Yi Su. 1990.
The Semantic Score Approach to the Disambiguation
of PP Attachment Problem. In Proceedings of RO-
CLING-90, Taiwan
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of English: The Penn treebank. Computa-
tional Linguistics, 19(2) pp.313--330.
Michael C. McCord. 1993. Heuristics for Broad-
Coverage Natural Language Parsing. Proceedings of
the workshop on Human Language Technology 1993,
Princeton, NJ
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing
(EMNLP 2005), Vancouver.
Paula S. Newman. 2007. RH: A Retro-Hybrid Parser.
In Short Papers of Proceedings of NAACL/HLT
2007, Rochester NY
Alan Prince and Paul Smolensky (1993). Optimality
Theory: Constraint interaction in generative gram-
mar, Rutgers University Center for Cognitive Sci-
ence, New Brunswick, NJ. Report RuCCS-TR-2.
[Reprinted in John J McCarthy, ed., Optimality The-
ory in Phonology: A Book of Readings, Blackwell
(2003).]
Philip Resnik and Marti Hearst. 1993. Structural Ambi-
guity and Conceptual Relations, in Proc. of 1st
Workshop on Very Large Corpora, 1993.
Brian Roark. 2001. Probabilistic top-down parsing and
language modeling. In Computational Linguistics,
27(2), pages 249-276.
Kenji Sagae and Alon Lavie. 2005. A classifier-based
parser with linear run-time complexity. In Proc. 9th
Int&apos;l Workshop on Parsing Technologies. Vancouver
Kristina Toutanova, Christopher D. Manning, Dan
Flickinger, and Stephan Oepen. 2005. Stochastic
HPSG Parse Disambiguation using the Redwoods
Corpus. Research in Language and Computation
2005.
Yorick A. Wilks. 1975. An Intelligent Analyzer and
Understander of English. Communications of the
ACM 18(5), pp.264-274
William Woods. 1970. Transition network grammars for
natural language analysis. Communications of the
ACM 13(10), pp.591-606
XLE Online Documentation. 2006. Available at
http://www2.parc.com/isl/groups/nltt/xle/doc/xle.htm
l#SEC15
Kiyoshi Yamabana, Shin&apos;ichiro Kamei and Kazunori
Muraki. On Representation of Preference Scores. In
Proceedings of The Fifth International Conference
on Theoretical and Methodological Issues in Ma-
chine Translation (TMI-93), Kyoto, pp. 92-101
</reference>
<page confidence="0.995788">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.939049">
<title confidence="0.999875">Symbolic Preference Using Simple Scoring</title>
<author confidence="0.998487">S Paula</author>
<email confidence="0.98907">newmanp@acm.org</email>
<abstract confidence="0.997837434782609">Despite the popularity of stochastic parsers, symbolic parsing still has some advantages, but is not practical without an effective mechanism for selecting among alternative analyses. This paper describes the symbolic preference system of a hybrid parser that combines a shallow parser with an overlay parser that builds on the chunks. The hybrid currently equals or exceeds most stochastic parsers in speed and is approaching them in accuracy. The preference system is novel in using a simple, three-valued scoring method (-1, 0, or +1) for assigning preferences to constituents viewed in the context of their containing constituents. The approach addresses problems associated with earlier preference systems, and has considerably facilitated development. It is ultimately based on viewing preference scoring as an engineering mechanism, and only indirectly related to cognitive principles or corpus-based frequencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah Aït-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>Robustness beyond shallowness: incremental deep parsing, Natural Language Engineering 8:121-144,</title>
<date>2002</date>
<publisher>University Press.</publisher>
<location>Cambridge</location>
<marker>Aït-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>Salah Aït-Mokhtar, Jean-Pierre Chanod, Claude Roux. 2002. Robustness beyond shallowness: incremental deep parsing, Natural Language Engineering 8:121-144, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations,</title>
<date>2004</date>
<booktitle>In Proc of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04),</booktitle>
<location>Barcelona</location>
<marker>Cahill, Burke, O’Donovan, van Genabith, Way, 2004</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef van Genabith, and Andy Way. 2004. Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations, In Proc of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04), Barcelona</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="30742" citStr="Collins, 1999" startWordPosition="4988" endWordPosition="4989">llowing the iterations over a large training set to filter out potentially indicative patterns that do not actually serve as such. These analogies highlight the fact that preference system training, whether symbolic or corpusbased, is ultimately an empirical engineering exercise. 6 Some Experimental Results Tables 2, 3, and 4 summarize some recent results as obtained by testing on Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994). The RH results were obtained by about 8 weeks of manual training on the genre. Table 2 compares speed and coverage for RH and Collins Model3 (Collins, 1999) run on the same CPU. The table also extrapolates the results to two other parsers, based on reported comparisons with Collins. One extrapolation is to a very fast stochastic parser by Sagae and Lavie (2005). The comparison indicates that the RH parser speed is close to that of the best contemporary parsers. The second extrapolation is to the LFG XLE parser (Kaplan et al. 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. Two sets of values are given f</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental Parsing with the Perceptron Algorithm.</title>
<date>2004</date>
<booktitle>In Proc of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04),</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="27946" citStr="Collins and Roark, 2004" startWordPosition="4520" endWordPosition="4523">atures are added to output network states in order to make properties of non-head constituents encountered along a path available for testing both further along the path and in the development of higher-level constituents. An example is the person and number of syntactic subjects, allowing contexted preference tests for finite verb phrases to check for subject consistency. 5.1 Relationship to &amp;quot;supervised&amp;quot; training To illustrate the relationship between the above symbolic training method for preference scoring and corpus-based methods, perhaps the easiest way is to compare it to an adaptation (Collins and Roark, 2004) of the perceptron training method to the problem of obtaining a best parse (either directly, or for parse reranking), because the two methods are analogous in a number of ways. The basic adapted perceptron training assumes a generator function producing parses for inputs. Each such parse is associated with a vector of feature values that express the number of times the feature appears in the input or parse. The features used are those identified by Roark (2001) for a topdown stochastic parser. The training method obtains a weight vector W (initially 0) for the feature values, by iterating mul</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental Parsing with the Perceptron Algorithm. In Proc of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04), Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Forst</author>
<author>Jonas Kuhn</author>
<author>Christian Rohrer</author>
</authors>
<title>Corpus-based Learning of OT Constraint Rankings for Large-scale LFG Grammars.</title>
<date>2005</date>
<booktitle>In Proc of the LFG05 Conference,</booktitle>
<location>Bergen.</location>
<note>Available at http://cslipublications.stanford.edu/LFG/10/lfg05.pdf</note>
<contexts>
<context position="12554" citStr="Forst et al. 2005" startWordPosition="2001" endWordPosition="2004">ks are global, a single dispreference can rule out an entire parse. To partially overcome this limitation, a further extension (see XLE Online Documentation) allows direct comparisons of alternative readings for the same input extent. A different optimality mark can be set for each reading, and the use of one such mark in the ranking can be conditioned on the presence of another particular mark for the same extent. For example, a conditional dispreference can be set for an adjunct reading if an argument reading also exists. The extension does not address more global interactions, and is said (Forst et al. 2005) to be used mostly as a pre-filter to limit the readings disambiguated by a follow-on stochastic process. 2.6 A Slightly Different View A slightly different view of preference–based parsing is that the business of a preference system is to work in tandem with a permissive syntactic grammar, to manipulate outcomes. The difference focuses on the pragmatic role of preference in coercing the parser. In this light, the principles of section 2.1 are guidelines for desired outcomes, not bases for judging the goodness of a relationship or setting preference values. Instead, preference values should be</context>
</contexts>
<marker>Forst, Kuhn, Rohrer, 2005</marker>
<rawString>Martin Forst, Jonas Kuhn, and Christian Rohrer. 2005. Corpus-based Learning of OT Constraint Rankings for Large-scale LFG Grammars. In Proc of the LFG05 Conference, Bergen. Available at http://cslipublications.stanford.edu/LFG/10/lfg05.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Frank</author>
<author>Tracy H King</author>
<author>Jonas Kuhn</author>
<author>John Maxwell</author>
</authors>
<title>Optimality theory style constraint ranking in large-scale LFG grammars.</title>
<date>1998</date>
<booktitle>Proc of the Third LFG Conference. Available http://csli-publications.stanford.edu/LFG3/ Revised version in Peter Sells, ed. Formal and Theoretical Issues in Optimality Theoretic Syntax,</booktitle>
<editor>In M. Butt and T. H. King, Eds.</editor>
<publisher>CSLI Publications,</publisher>
<contexts>
<context position="11351" citStr="Frank et al. 1998" startWordPosition="1806" endWordPosition="1809">ser and generator preference. Optimality Theory (OT) was originally developed to explain phonological rules (Prince and Smolensky, 1993). In that use, potential rules are given one &amp;quot;optimality mark&amp;quot; for each constraint they violate. The marks, all implicitly negative, are ranked by level of severity. A best rule R is one for which (a) the most severe level of constraint violation L is &lt; the level violated by any other rule, and (b) if other rules also violate level L constraints, the number of such violations is &gt; the number of violations by R. As adapted for use in the XLE processor for LFG (Frank et al. 1998) optimality marks are associated with parser and generator outputs. Positive marks are added, and also labeled inter-mark positions within the optimality mark ranking. The labeled positions influence processor behavior. For generation, they are used to disprefer infelicitous strings accepted in a parse direction. And for pars2 McCord (1993) also includes some corpus-based information, but to a very limited extent. 85 ing they can be used to disprefer (actually ignore) rarely-applicable rules, in order to reduce parse time (Kaplan et al, 2004). However, because the optimality marks are global, </context>
</contexts>
<marker>Frank, King, Kuhn, Maxwell, 1998</marker>
<rawString>Anette Frank., Tracy H. King, Jonas Kuhn, and John Maxwell. 1998. Optimality theory style constraint ranking in large-scale LFG grammars. In M. Butt and T. H. King, Eds. Proc of the Third LFG Conference. Available http://csli-publications.stanford.edu/LFG3/ Revised version in Peter Sells, ed. Formal and Theoretical Issues in Optimality Theoretic Syntax, CSLI Publications, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuria Gala</author>
</authors>
<title>Using a robust parser grammar to automatically generate UNL graphs.</title>
<date>2004</date>
<booktitle>In Proc Workshop on Robust Methods for Natural Language Data at COLING&apos;04,</booktitle>
<location>Geneva</location>
<contexts>
<context position="14081" citStr="Gala 2004" startWordPosition="2251" endWordPosition="2252">ed in section 4 below, in which contexted preference scores CRS can have one of only 3 values, -1, 0, or +1. 3 Background: The RH Parser The RH parser consists of three major components, outlined below: the shallow parser, a mediating &amp;quot;locator&amp;quot; phase, and the overlay parser. 3.1 Shallow Parser The shallow parser used, XIP, was developed by XRCE (Xerox Research Center Europe). It is actually a full parser, whose per-sentence output consists of a single tree of basic chunks, together with identifications of (sometimes alternative) typed dependences among the chunk heads (AitMokhtar et al. 2002, Gala 2004). But because the XIP dependency analysis for English was not mature at the time that work on RH began, and because a classic parse tree annotated by syntactic functions is more convenient for some applications, we focused on the output chunks. XIP is astonishingly fast, contributing very little to parse times (about 20%). It consists of the XIP processor, plus grammars for a number of languages. The grammar for a particular language consists of: (a) a finite-state lexicon producing alternative part-of-speech and morphological analyses for each token, together with bit-expressed subcategorizat</context>
</contexts>
<marker>Gala, 2004</marker>
<rawString>Nuria Gala. 2004. Using a robust parser grammar to automatically generate UNL graphs. In Proc Workshop on Robust Methods for Natural Language Data at COLING&apos;04, Geneva</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
<author>Mats Rooth</author>
</authors>
<date>1993</date>
<booktitle>Structural Ambiguity and Lexical Relations. Computational Linguistics,</booktitle>
<pages>19--1</pages>
<contexts>
<context position="10199" citStr="Hindle and Rooth (1993)" startWordPosition="1619" endWordPosition="1622"> correct reading survives because there are no higher scoring ones. But in some situations, if such a dispreference were given a large negative score, the parser could be forced into very odd readings not compensated for by other factors. 2.4 Corpus-Based Preference In the early 1990&apos;s, the increasing availability and use of corpora, together with a sense that multilevel symbolic preference scores were based on adhoc judgments, led to experiments and systems that used empirical methods to obtain preference weights. Examples of this work include a system by Liu et al (1990), and experiments by Hindle and Rooth (1993), and Resnik and Hearst (1993).2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems. In light of later developments, this might be expected. Full-scale contemporary stochastic parsers use a broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect. 2.5 OT-based Preference A more recent approach to symbolic preference adapts optimality theory to parser and generator preference. Optimality Theory (OT) was originall</context>
</contexts>
<marker>Hindle, Rooth, 1993</marker>
<rawString>Donald Hindle and Mats Rooth. 1993. Structural Ambiguity and Lexical Relations. Computational Linguistics, 19:1,103–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>John Bear</author>
</authors>
<title>Two Principles of Parse Preference.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING&apos;90),</booktitle>
<location>Helsinki, Finland,</location>
<contexts>
<context position="4534" citStr="Hobbs and Bear (1990)" startWordPosition="686" endWordPosition="689">.&amp;quot; * indicates head. Mouseover shows head features for &amp;quot;micromanaged&amp;quot;. 2 Background: Symbolic Preference 2.1 Principles Preference-based parsing balances necessarily permissive syntactic rules by preference rules that promote more likely interpretations. One of the earliest works in the area is by Wilks (1975), which presented a view of preference as based on semantic templates. Throughout the 1980&apos;s there was a considerable amount of work devoted to finding general principles, often cognitively oriented, for preference rules, and then to devise mechanisms for using them in practical systems. Hobbs and Bear (1990) provide a useful summary of the evolved principles. Slightly restated, these principles are: 1. Prefer attachments in the &amp;quot;most restrictive context&amp;quot;. 2. If that doesn&apos;t uniquely determine the result, attach low and parallel, and finally 3. Adjust the above based on considerations of punctuation Principle 1 suggests that the preference for a constituent in a construction should depend on the extent to which the constituent meets a narrow set of expectations. Most of the examples given by Hobbs and Bear use either (a) sub-categorization information, e.g., preferring the attachment of a preposit</context>
<context position="6966" citStr="Hobbs and Bear (1990)" startWordPosition="1087" endWordPosition="1090"> of constituent cci, and the total relationship score TRS is a value that assesses the relationships among the sibling constituents of CC. The computation of TRS depends on the parser approach. For a top-down parser, TRS may be the sum of contexted relationship scores CRS, for example: TRS = CRS (cc1|C) +CRS (cc2|C, cc1), + CRS (cc3|C, cc1, cc2) + ..... + CRS (cn |C, cc1,....ccn-1) where each CRS (cci|_ ) evaluates cci in the context of the prior content of the constituent CC and the category C.. Few publications specify details of how preference scores are assigned and combined. For example, Hobbs and Bear (1990) say only that &amp;quot;When a 1 The idea has also been used directly in stochastic parsers that consider all possible attachments, for example, by McDonald et al. (2005). 84 non-terminal node of a parse tree is constructed, it is given an initial score which is the sum of the scores of its child nodes. Various conditions are checked during the construction of the node and, as a result, a score of 20, 10, 3, -3, -10, or -20 may be added to the initial score.&amp;quot; McCord (1993), however, carefully describes how the elements of TRS are computed in his slot grammar system. Each element value is the sum of th</context>
</contexts>
<marker>Hobbs, Bear, 1990</marker>
<rawString>Jerry R. Hobbs and John Bear. 1990. Two Principles of Parse Preference. In Proceedings of the 13th International Conference on Computational Linguistics (COLING&apos;90), Helsinki, Finland, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hobbs</author>
<author>Douglas E Appelt</author>
<author>John Bear</author>
<author>Mabry Tyson</author>
<author>David Magerman</author>
</authors>
<title>Robust processing of real-world natural language texts.</title>
<date>1992</date>
<booktitle>Text-Based Intelligent Systems: Current Research and Practice in Information Extraction and Retrieval. Lawrence Erlbaum,</booktitle>
<editor>In Paul S. Jacobs, ed.,</editor>
<location>New Jersey,</location>
<marker>Hobbs, Appelt, Bear, Tyson, Magerman, 1992</marker>
<rawString>Jerry. R. Hobbs, Douglas E. Appelt, John Bear, Mabry Tyson, and David Magerman. 1992. Robust processing of real-world natural language texts. In Paul S. Jacobs, ed., Text-Based Intelligent Systems: Current Research and Practice in Information Extraction and Retrieval. Lawrence Erlbaum, New Jersey, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>A simple pattern-matching algorithm for recovering empty nodes and their antecedents.</title>
<date>2002</date>
<booktitle>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL&apos;02),</booktitle>
<pages>136--143</pages>
<location>Philadelphia,</location>
<contexts>
<context position="2576" citStr="Johnson (2002)" startWordPosition="391" endWordPosition="392">ated by Woods (1970). RH delivers single &amp;quot;best&amp;quot; parses providing syntactic categories, syntactic functions, head features, and other information (Figure 1). The parenthesized numbers following the category labels in the figure are preference scores, and are explained further on. While the parses are not quite as detailed as those obtained using &amp;quot;deep&amp;quot; grammars, the missing information, mostly relating to long distance dependencies, can be added at far less cost in a post-parse phase that operates only on a single best parse. Methods for doing so, for stochastic parser output, are described by Johnson (2002) and Cahill et al (2004). The hybrid parser exceeds most stochastic parsers in speed, and approaches them in accuracy, even based on limited manual &amp;quot;training&amp;quot; on a particular idiom, so the preference system is a successful one (see Section 6), and continues to improve. The RH preference system builds on earlier methods. The major difference is a far simpler scoring system, which has considerably facilitated overlay parser development. Also, the architecture allows the use of large numbers of preference tests without impacting parser speed. Finally, the treatment of coordination exploits the lo</context>
</contexts>
<marker>Johnson, 2002</marker>
<rawString>Mark Johnson. 2002. A simple pattern-matching algorithm for recovering empty nodes and their antecedents. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL&apos;02), Philadelphia, July 2002, pp. 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Stephan Riezler</author>
<author>Tracy H King</author>
<author>John T Maxwell</author>
<author>Alex Vasserman</author>
</authors>
<title>Speed and accuracy in shallow and deep stochastic parsing.</title>
<date>2004</date>
<booktitle>In Proc HLT/NAACL&apos;04,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="11899" citStr="Kaplan et al, 2004" startWordPosition="1892" endWordPosition="1895"> R. As adapted for use in the XLE processor for LFG (Frank et al. 1998) optimality marks are associated with parser and generator outputs. Positive marks are added, and also labeled inter-mark positions within the optimality mark ranking. The labeled positions influence processor behavior. For generation, they are used to disprefer infelicitous strings accepted in a parse direction. And for pars2 McCord (1993) also includes some corpus-based information, but to a very limited extent. 85 ing they can be used to disprefer (actually ignore) rarely-applicable rules, in order to reduce parse time (Kaplan et al, 2004). However, because the optimality marks are global, a single dispreference can rule out an entire parse. To partially overcome this limitation, a further extension (see XLE Online Documentation) allows direct comparisons of alternative readings for the same input extent. A different optimality mark can be set for each reading, and the use of one such mark in the ranking can be conditioned on the presence of another particular mark for the same extent. For example, a conditional dispreference can be set for an adjunct reading if an argument reading also exists. The extension does not address mo</context>
<context position="31122" citStr="Kaplan et al. 2004" startWordPosition="5052" endWordPosition="5055">sting on Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994). The RH results were obtained by about 8 weeks of manual training on the genre. Table 2 compares speed and coverage for RH and Collins Model3 (Collins, 1999) run on the same CPU. The table also extrapolates the results to two other parsers, based on reported comparisons with Collins. One extrapolation is to a very fast stochastic parser by Sagae and Lavie (2005). The comparison indicates that the RH parser speed is close to that of the best contemporary parsers. The second extrapolation is to the LFG XLE parser (Kaplan et al. 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. Two sets of values are given for XLE, one obtained using the full English grammar, and one obtained using a reduced grammar ignoring less-frequently applicable rules. The extrapolation indicates that the coverage of RH is quite good for a symbolic parser with limited training on an idiom. While the most important factor in RH parser speed is the enormous speed of the shallow parser, the preference and pruni</context>
</contexts>
<marker>Kaplan, Riezler, King, Maxwell, Vasserman, 2004</marker>
<rawString>Ronald M. Kaplan, Stephan Riezler, Tracy H. King, John T. Maxwell, Alex Vasserman. 2004. Speed and accuracy in shallow and deep stochastic parsing. In Proc HLT/NAACL&apos;04, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao-Lin Liu</author>
<author>Jing-Shin Chang</author>
<author>Keh-Yi Su</author>
</authors>
<title>The Semantic Score Approach to the Disambiguation of PP Attachment Problem.</title>
<date>1990</date>
<booktitle>In Proceedings of ROCLING-90,</booktitle>
<location>Taiwan</location>
<contexts>
<context position="10155" citStr="Liu et al (1990)" startWordPosition="1612" endWordPosition="1615">t identified as transitive. Here, the correct reading survives because there are no higher scoring ones. But in some situations, if such a dispreference were given a large negative score, the parser could be forced into very odd readings not compensated for by other factors. 2.4 Corpus-Based Preference In the early 1990&apos;s, the increasing availability and use of corpora, together with a sense that multilevel symbolic preference scores were based on adhoc judgments, led to experiments and systems that used empirical methods to obtain preference weights. Examples of this work include a system by Liu et al (1990), and experiments by Hindle and Rooth (1993), and Resnik and Hearst (1993).2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems. In light of later developments, this might be expected. Full-scale contemporary stochastic parsers use a broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect. 2.5 OT-based Preference A more recent approach to symbolic preference adapts optimality theory to parser and generator pref</context>
</contexts>
<marker>Liu, Chang, Su, 1990</marker>
<rawString>Chao-Lin Liu, Jing-Shin Chang, and Keh-Yi Su. 1990. The Semantic Score Approach to the Disambiguation of PP Attachment Problem. In Proceedings of ROCLING-90, Taiwan</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="30584" citStr="Marcus et al. 1994" startWordPosition="4958" endWordPosition="4961">the perceptron training method accomplishes something similar by postulating some more general features as negative or positive based on particular examples, but allowing the iterations over a large training set to filter out potentially indicative patterns that do not actually serve as such. These analogies highlight the fact that preference system training, whether symbolic or corpusbased, is ultimately an empirical engineering exercise. 6 Some Experimental Results Tables 2, 3, and 4 summarize some recent results as obtained by testing on Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994). The RH results were obtained by about 8 weeks of manual training on the genre. Table 2 compares speed and coverage for RH and Collins Model3 (Collins, 1999) run on the same CPU. The table also extrapolates the results to two other parsers, based on reported comparisons with Collins. One extrapolation is to a very fast stochastic parser by Sagae and Lavie (2005). The comparison indicates that the RH parser speed is close to that of the best contemporary parsers. The second extrapolation is to the LFG XLE parser (Kaplan et al. 2004) for English, consisting of a highly developed symbolic parser</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn treebank. Computational Linguistics, 19(2) pp.313--330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
</authors>
<title>Heuristics for BroadCoverage Natural Language Parsing.</title>
<date>1993</date>
<booktitle>Proceedings of the workshop on Human Language Technology</booktitle>
<location>Princeton, NJ</location>
<contexts>
<context position="7435" citStr="McCord (1993)" startWordPosition="1177" endWordPosition="1178"> CC and the category C.. Few publications specify details of how preference scores are assigned and combined. For example, Hobbs and Bear (1990) say only that &amp;quot;When a 1 The idea has also been used directly in stochastic parsers that consider all possible attachments, for example, by McDonald et al. (2005). 84 non-terminal node of a parse tree is constructed, it is given an initial score which is the sum of the scores of its child nodes. Various conditions are checked during the construction of the node and, as a result, a score of 20, 10, 3, -3, -10, or -20 may be added to the initial score.&amp;quot; McCord (1993), however, carefully describes how the elements of TRS are computed in his slot grammar system. Each element value is the sum of the results of up to 8 optional, typed tests, relating to structural, syntactic, and semantic conditions. One of these tests, relating to coordination, is a complex test involving 7 factors assessing parallelism. 2.3 Multi-Level Contexted Scoring The scores assigned by symbolic preference systems to particular relationships or combinations usually indicate not just whether they are preferred or dispreferred, but to what degree. For example, a score of 1 might indicat</context>
<context position="11693" citStr="McCord (1993)" startWordPosition="1860" endWordPosition="1861">evere level of constraint violation L is &lt; the level violated by any other rule, and (b) if other rules also violate level L constraints, the number of such violations is &gt; the number of violations by R. As adapted for use in the XLE processor for LFG (Frank et al. 1998) optimality marks are associated with parser and generator outputs. Positive marks are added, and also labeled inter-mark positions within the optimality mark ranking. The labeled positions influence processor behavior. For generation, they are used to disprefer infelicitous strings accepted in a parse direction. And for pars2 McCord (1993) also includes some corpus-based information, but to a very limited extent. 85 ing they can be used to disprefer (actually ignore) rarely-applicable rules, in order to reduce parse time (Kaplan et al, 2004). However, because the optimality marks are global, a single dispreference can rule out an entire parse. To partially overcome this limitation, a further extension (see XLE Online Documentation) allows direct comparisons of alternative readings for the same input extent. A different optimality mark can be set for each reading, and the use of one such mark in the ranking can be conditioned on</context>
</contexts>
<marker>McCord, 1993</marker>
<rawString>Michael C. McCord. 1993. Heuristics for BroadCoverage Natural Language Parsing. Proceedings of the workshop on Human Language Technology 1993, Princeton, NJ</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing (EMNLP 2005),</booktitle>
<location>Vancouver.</location>
<marker>McDonald, Pereira, Ribarov, Hajic, </marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing (EMNLP 2005), Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula S Newman</author>
</authors>
<title>RH: A Retro-Hybrid Parser.</title>
<date>2007</date>
<booktitle>In Short Papers of Proceedings of NAACL/HLT 2007,</booktitle>
<location>Rochester NY</location>
<contexts>
<context position="1735" citStr="Newman, 2007" startWordPosition="256" endWordPosition="257">ctical without an effective mechanism for selecting among alternative analyses. Without it, accept/fail grammar rules must either be overly strong or admit very large numbers of parses. . Symbolic parsers have recently been augmented by stochastic post-processors for output disambiguation, which reduces their independence from corpora. Both the LFG XLE parser (Kaplan et.al. 2004), and the HPSG LinGO ERG parser (Toutanova et al. 2005) have such additions. This paper examines significant aspects of a purely symbolic alternative: the preference and pruning system of the RH (Retro-Hybrid) parser (Newman, 2007). The parser combines a preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks. The overlay parser is &amp;quot;retro&amp;quot; in that the grammar is related to ATNs (Augmented Transition Networks) originated by Woods (1970). RH delivers single &amp;quot;best&amp;quot; parses providing syntactic categories, syntactic functions, head features, and other information (Figure 1). The parenthesized numbers following the category labels in the figure are preference scores, and are explained further on. While the parses are not quite as detailed as those obtained using &amp;quot;deep&amp;quot; grammars, the missi</context>
<context position="16828" citStr="Newman, 2007" startWordPosition="2670" endWordPosition="2671">ing with a coordinating conjunction. 3.3 Overlay Parser The overlay parser uses a top-down grammar, expressed as a collection of ATN-like grammar networks. A recursive control mechanism traverses the grammar networks depth-first to build constituents. The labels on the grammar network arcs represent specialized categories, and are associated with tests that, if successful, either return a chunk or reinvoke the control to attempt to build a constituents for the category. The labelspecific tests include both context-free tests, and tests taking into account the current context. For details see (Newman, 2007). If an invocation of the control is successful, it returns an output network containing one or more paths, with each path representing an alternative sequence of immediate children of the constituent. An example output network is shown in figure 2. Each arc of the network references either a basic chunk, or a final state of a subordinate output network. Unlike the source grammar networks, the output networks do not contain cycles or converging arcs, so states represent unique paths. The states contain both (a) information about material already encountered along the path, including syntactic </context>
<context position="32848" citStr="Newman (2007)" startWordPosition="5350" endWordPosition="5351">ull parse Sagae/Lavie ~ 4 min 1.1% RH Prune 5 min 14 sec 10.8% RH NoPrune 7 min 5 sec 13.9 % Collins m3 16 min .6% XLE reduced ~24 minutes unknown XLE full ~80 minutes ~21% Table 2. Speeds and Extrapolated speeds Fully F-score Avg cross accurate bkts Sagae/Lavie unknwn 86% unknwn Collins Lbl 33.6% 88.2% 1.05 CollinsNoLbl 35.4% 89.4 % 1.05 RH NoLbl 46% 86 % .59 Table 3. Accuracy Comparison Average Median RH Base 137.10 11 RH Pref 5.04 2 Table 4. Highest Scoring Parses per Input 90 100-sentence sample from section 23, and compared using a different unlabeled bracketing standard. For details see Newman (2007). For nonparsed sentences the chunks are bracketed. Accuracy is not extrapolated to XLE because available measurements give f-scores (all &lt;_ 80%) for dependency relations rather than for bracketed constituents. As a partial indication of the role and effectiveness of the RH preference system, if non-parsed sentences are ignored, the percentage of fully accurate bracketings shown in Table 3 rises to approximately 46/89 = 51.6% (it is actually larger because coverage is higher on the 100-sentence sample). As further indication, Table 4 compares, for section 23, the average and median number of p</context>
</contexts>
<marker>Newman, 2007</marker>
<rawString>Paula S. Newman. 2007. RH: A Retro-Hybrid Parser. In Short Papers of Proceedings of NAACL/HLT 2007, Rochester NY</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality Theory: Constraint interaction in generative grammar,</title>
<date>1993</date>
<booktitle>Optimality Theory in Phonology: A Book of Readings,</booktitle>
<editor>John J McCarthy, ed.,</editor>
<institution>Rutgers University Center for Cognitive Science,</institution>
<location>New Brunswick, NJ.</location>
<note>Report RuCCS-TR-2. [Reprinted in</note>
<contexts>
<context position="10869" citStr="Prince and Smolensky, 1993" startWordPosition="1716" endWordPosition="1719">rts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems. In light of later developments, this might be expected. Full-scale contemporary stochastic parsers use a broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect. 2.5 OT-based Preference A more recent approach to symbolic preference adapts optimality theory to parser and generator preference. Optimality Theory (OT) was originally developed to explain phonological rules (Prince and Smolensky, 1993). In that use, potential rules are given one &amp;quot;optimality mark&amp;quot; for each constraint they violate. The marks, all implicitly negative, are ranked by level of severity. A best rule R is one for which (a) the most severe level of constraint violation L is &lt; the level violated by any other rule, and (b) if other rules also violate level L constraints, the number of such violations is &gt; the number of violations by R. As adapted for use in the XLE processor for LFG (Frank et al. 1998) optimality marks are associated with parser and generator outputs. Positive marks are added, and also labeled inter-m</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>Alan Prince and Paul Smolensky (1993). Optimality Theory: Constraint interaction in generative grammar, Rutgers University Center for Cognitive Science, New Brunswick, NJ. Report RuCCS-TR-2. [Reprinted in John J McCarthy, ed., Optimality Theory in Phonology: A Book of Readings, Blackwell (2003).]</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Marti Hearst</author>
</authors>
<title>Structural Ambiguity and Conceptual Relations,</title>
<date>1993</date>
<booktitle>in Proc. of 1st Workshop on Very Large Corpora,</booktitle>
<contexts>
<context position="10229" citStr="Resnik and Hearst (1993)" startWordPosition="1624" endWordPosition="1627">ause there are no higher scoring ones. But in some situations, if such a dispreference were given a large negative score, the parser could be forced into very odd readings not compensated for by other factors. 2.4 Corpus-Based Preference In the early 1990&apos;s, the increasing availability and use of corpora, together with a sense that multilevel symbolic preference scores were based on adhoc judgments, led to experiments and systems that used empirical methods to obtain preference weights. Examples of this work include a system by Liu et al (1990), and experiments by Hindle and Rooth (1993), and Resnik and Hearst (1993).2 These efforts had mixed success, suggesting that while multi-level preference scores are problematic, integrating some corpus data does not solve the problems. In light of later developments, this might be expected. Full-scale contemporary stochastic parsers use a broad range of interacting features to obtain their fine-grained results; frequencies of particular relationships are just one aspect. 2.5 OT-based Preference A more recent approach to symbolic preference adapts optimality theory to parser and generator preference. Optimality Theory (OT) was originally developed to explain phonolo</context>
</contexts>
<marker>Resnik, Hearst, 1993</marker>
<rawString>Philip Resnik and Marti Hearst. 1993. Structural Ambiguity and Conceptual Relations, in Proc. of 1st Workshop on Very Large Corpora, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
</authors>
<title>Probabilistic top-down parsing and language modeling.</title>
<date>2001</date>
<journal>In Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<pages>249--276</pages>
<contexts>
<context position="28412" citStr="Roark (2001)" startWordPosition="4601" endWordPosition="4602">aining method for preference scoring and corpus-based methods, perhaps the easiest way is to compare it to an adaptation (Collins and Roark, 2004) of the perceptron training method to the problem of obtaining a best parse (either directly, or for parse reranking), because the two methods are analogous in a number of ways. The basic adapted perceptron training assumes a generator function producing parses for inputs. Each such parse is associated with a vector of feature values that express the number of times the feature appears in the input or parse. The features used are those identified by Roark (2001) for a topdown stochastic parser. The training method obtains a weight vector W (initially 0) for the feature values, by iterating multiple times over pairs &lt;xi, yi&gt; where xi is a training input, and yi is the correct parse for xi. For each pair, the best current parse zi for xi produced by the generator, with feature value vector V(zi), is selected based on the current value of (W · V(zi)). Then if zi :� yi, W is incremented by V(yi), and dec89 remented by V(zi). After training, the weights in W are divided by the number of training steps (# inputs * # iterations). The method is analogous to </context>
</contexts>
<marker>Roark, 2001</marker>
<rawString>Brian Roark. 2001. Probabilistic top-down parsing and language modeling. In Computational Linguistics, 27(2), pages 249-276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>A classifier-based parser with linear run-time complexity.</title>
<date>2005</date>
<booktitle>In Proc. 9th Int&apos;l Workshop on Parsing Technologies.</booktitle>
<location>Vancouver</location>
<contexts>
<context position="30949" citStr="Sagae and Lavie (2005)" startWordPosition="5022" endWordPosition="5025">whether symbolic or corpusbased, is ultimately an empirical engineering exercise. 6 Some Experimental Results Tables 2, 3, and 4 summarize some recent results as obtained by testing on Wall Street Journal section 23 of the Penn Treebank (Marcus et al. 1994). The RH results were obtained by about 8 weeks of manual training on the genre. Table 2 compares speed and coverage for RH and Collins Model3 (Collins, 1999) run on the same CPU. The table also extrapolates the results to two other parsers, based on reported comparisons with Collins. One extrapolation is to a very fast stochastic parser by Sagae and Lavie (2005). The comparison indicates that the RH parser speed is close to that of the best contemporary parsers. The second extrapolation is to the LFG XLE parser (Kaplan et al. 2004) for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs. Two sets of values are given for XLE, one obtained using the full English grammar, and one obtained using a reduced grammar ignoring less-frequently applicable rules. The extrapolation indicates that the coverage of RH is quite good for </context>
</contexts>
<marker>Sagae, Lavie, 2005</marker>
<rawString>Kenji Sagae and Alon Lavie. 2005. A classifier-based parser with linear run-time complexity. In Proc. 9th Int&apos;l Workshop on Parsing Technologies. Vancouver</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<date>2005</date>
<booktitle>Stochastic HPSG Parse Disambiguation using the Redwoods Corpus. Research in Language and Computation</booktitle>
<contexts>
<context position="1559" citStr="Toutanova et al. 2005" startWordPosition="228" endWordPosition="232">ctly related to cognitive principles or corpus-based frequencies. 1 Introduction Despite the popularity of stochastic parsers, symbolic parsing still has some advantages, but is not practical without an effective mechanism for selecting among alternative analyses. Without it, accept/fail grammar rules must either be overly strong or admit very large numbers of parses. . Symbolic parsers have recently been augmented by stochastic post-processors for output disambiguation, which reduces their independence from corpora. Both the LFG XLE parser (Kaplan et.al. 2004), and the HPSG LinGO ERG parser (Toutanova et al. 2005) have such additions. This paper examines significant aspects of a purely symbolic alternative: the preference and pruning system of the RH (Retro-Hybrid) parser (Newman, 2007). The parser combines a preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks. The overlay parser is &amp;quot;retro&amp;quot; in that the grammar is related to ATNs (Augmented Transition Networks) originated by Woods (1970). RH delivers single &amp;quot;best&amp;quot; parses providing syntactic categories, syntactic functions, head features, and other information (Figure 1). The parenthesized numbers following the </context>
</contexts>
<marker>Toutanova, Manning, Flickinger, Oepen, 2005</marker>
<rawString>Kristina Toutanova, Christopher D. Manning, Dan Flickinger, and Stephan Oepen. 2005. Stochastic HPSG Parse Disambiguation using the Redwoods Corpus. Research in Language and Computation 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>An Intelligent Analyzer and Understander of English.</title>
<date>1975</date>
<journal>Communications of the ACM</journal>
<volume>18</volume>
<issue>5</issue>
<pages>264--274</pages>
<contexts>
<context position="4224" citStr="Wilks (1975)" startWordPosition="640" endWordPosition="641"> indicates directions for further work. 83 Proceedings of the 10th Conference on Parsing Technologies, pages 83–92, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Figure 1. Output Parse Tree for &amp;quot;Rumsfeld micromanaged daily briefings and rode roughshod over people.&amp;quot; * indicates head. Mouseover shows head features for &amp;quot;micromanaged&amp;quot;. 2 Background: Symbolic Preference 2.1 Principles Preference-based parsing balances necessarily permissive syntactic rules by preference rules that promote more likely interpretations. One of the earliest works in the area is by Wilks (1975), which presented a view of preference as based on semantic templates. Throughout the 1980&apos;s there was a considerable amount of work devoted to finding general principles, often cognitively oriented, for preference rules, and then to devise mechanisms for using them in practical systems. Hobbs and Bear (1990) provide a useful summary of the evolved principles. Slightly restated, these principles are: 1. Prefer attachments in the &amp;quot;most restrictive context&amp;quot;. 2. If that doesn&apos;t uniquely determine the result, attach low and parallel, and finally 3. Adjust the above based on considerations of punct</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Yorick A. Wilks. 1975. An Intelligent Analyzer and Understander of English. Communications of the ACM 18(5), pp.264-274</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Woods</author>
</authors>
<title>Transition network grammars for natural language analysis.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<volume>13</volume>
<issue>10</issue>
<pages>591--606</pages>
<contexts>
<context position="1982" citStr="Woods (1970)" startWordPosition="297" endWordPosition="298">post-processors for output disambiguation, which reduces their independence from corpora. Both the LFG XLE parser (Kaplan et.al. 2004), and the HPSG LinGO ERG parser (Toutanova et al. 2005) have such additions. This paper examines significant aspects of a purely symbolic alternative: the preference and pruning system of the RH (Retro-Hybrid) parser (Newman, 2007). The parser combines a preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks. The overlay parser is &amp;quot;retro&amp;quot; in that the grammar is related to ATNs (Augmented Transition Networks) originated by Woods (1970). RH delivers single &amp;quot;best&amp;quot; parses providing syntactic categories, syntactic functions, head features, and other information (Figure 1). The parenthesized numbers following the category labels in the figure are preference scores, and are explained further on. While the parses are not quite as detailed as those obtained using &amp;quot;deep&amp;quot; grammars, the missing information, mostly relating to long distance dependencies, can be added at far less cost in a post-parse phase that operates only on a single best parse. Methods for doing so, for stochastic parser output, are described by Johnson (2002) and C</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>William Woods. 1970. Transition network grammars for natural language analysis. Communications of the ACM 13(10), pp.591-606</rawString>
</citation>
<citation valid="true">
<authors>
<author>XLE Online Documentation</author>
</authors>
<date>2006</date>
<note>Available at http://www2.parc.com/isl/groups/nltt/xle/doc/xle.htm l#SEC15</note>
<marker>Documentation, 2006</marker>
<rawString>XLE Online Documentation. 2006. Available at http://www2.parc.com/isl/groups/nltt/xle/doc/xle.htm l#SEC15</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kiyoshi Yamabana</author>
</authors>
<title>Shin&apos;ichiro Kamei and Kazunori Muraki. On Representation of Preference Scores.</title>
<booktitle>In Proceedings of The Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-93), Kyoto,</booktitle>
<pages>92--101</pages>
<marker>Yamabana, </marker>
<rawString>Kiyoshi Yamabana, Shin&apos;ichiro Kamei and Kazunori Muraki. On Representation of Preference Scores. In Proceedings of The Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-93), Kyoto, pp. 92-101</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>