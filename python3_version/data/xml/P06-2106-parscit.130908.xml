<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.768066">
Infrastructure for standardization of Asian language resources
</title>
<author confidence="0.642225">
Tokunaga Takenobu
</author>
<affiliation confidence="0.525235">
Tokyo Inst. of Tech.
</affiliation>
<note confidence="0.814681">
Nicoletta Calzolari
ILC/CNR
</note>
<author confidence="0.56457">
Chu-Ren Huang
</author>
<affiliation confidence="0.250956">
Academia Sinica
</affiliation>
<note confidence="0.6495845">
Virach Sornlertlamvanich
TCL, NICT
Monica Monachini
ILC/CNR
</note>
<author confidence="0.539427">
Xia YingJu
</author>
<affiliation confidence="0.403041">
Fujitsu R&amp;D Center
</affiliation>
<note confidence="0.803956">
Thatsanee Charoenporn
TCL, NICT
Claudia Soria
ILC/CNR
</note>
<author confidence="0.78689">
Yu Hao
</author>
<affiliation confidence="0.566369">
Fujitsu R&amp;D Center
</affiliation>
<author confidence="0.823159">
Laurent Prevot Shirai Kiyoaki
</author>
<affiliation confidence="0.321621">
Academia Sinica JAIST
</affiliation>
<sectionHeader confidence="0.928736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999986181818182">
As an area of great linguistic and cul-
tural diversity, Asian language resources
have received much less attention than
their western counterparts. Creating a
common standard for Asian language re-
sources that is compatible with an interna-
tional standard has at least three strong ad-
vantages: to increase the competitive edge
of Asian countries, to bring Asian coun-
tries to closer to their western counter-
parts, and to bring more cohesion among
Asian countries. To achieve this goal, we
have launched a two year project to create
a common standard for Asian language re-
sources. The project is comprised of four
research items, (1) building a description
framework of lexical entries, (2) building
sample lexicons, (3) building an upper-
layer ontology and (4) evaluating the pro-
posed framework through an application.
This paper outlines the project in terms of
its aim and approach.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999218">
There is a long history of creating a standard
for western language resources. The human
language technology (HLT) society in Europe
has been particularly zealous for the standardiza-
tion, making a series of attempts such as EA-
GLES1, PAROLE/SIMPLE (Lenci et al., 2000),
ISLE/MILE (Calzolari et al., 2003) and LIRICS2.
These continuous efforts has been crystallized as
activities in ISO-TC37/SC4 which aims to make
an international standard for language resources.
</bodyText>
<footnote confidence="0.992761">
1http://www.ilc.cnr.it/Eagles96/home.html
2lirics.loria.fr/documents.html
</footnote>
<figureCaption confidence="0.999731">
Figure 1: Relations among research items
</figureCaption>
<bodyText confidence="0.999951928571429">
On the other hand, since Asia has great lin-
guistic and cultural diversity, Asian language re-
sources have received much less attention than
their western counterparts. Creating a common
standard for Asian language resources that is com-
patible with an international standard has at least
three strong advantages: to increase the competi-
tive edge of Asian countries, to bring Asian coun-
tries to closer to their western counterparts, and to
bring more cohesion among Asian countries.
To achieve this goal, we have launched a two
year project to create a common standard for
Asian language resources. The project is com-
prised of the following four research items.
</bodyText>
<listItem confidence="0.904717">
(1) building a description framework of lexical
entries
(2) building sample lexicons
(3) building an upper-layer ontology
(4) evaluating the proposed framework through
an application
</listItem>
<figureCaption confidence="0.4084075">
Figure 1 illustrates the relations among these re-
search items.
</figureCaption>
<bodyText confidence="0.9114255">
Our main aim is the research item (1), building
a description framework of lexical entries which
</bodyText>
<figure confidence="0.994817071428571">
(1) Description
framework of lexical
entries
reÞnement
evaluation
evaluation
(4) Evaluation
through application
(2) Sample lexicons
reÞnement
classiÞcation
(3) Upper layer
ontology
description
</figure>
<page confidence="0.963961">
827
</page>
<note confidence="0.7226465">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 827–834,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999384">
fits with as many Asian languages as possible, and
contributing to the ISO-TC37/SC4 activities. As
a starting point, we employ an existing descrip-
tion framework, the MILE framework (Bertagna
et al., 2004a), to describe several lexical entries of
several Asian languages. Through building sam-
ple lexicons (research item (2)), we will find prob-
lems of the existing framework, and extend it so
as to fit with Asian languages. In this extension,
we need to be careful in keeping consistency with
the existing framework. We start with Chinese,
Japanese and Thai as target Asian languages and
plan to expand the coverage of languages. The re-
search items (2) and (3) also comprise the similar
feedback loop. Through building sample lexicons,
we refine an upper-layer ontology. An application
built in the research item (4) is dedicated to evalu-
ating the proposed framework. We plan to build an
information retrieval system using a lexicon built
by extending the sample lexicon.
In what follows, section 2 briefly reviews the
MILE framework which is a basis of our de-
scription framework. Since the MILE framework
is originally designed for European languages, it
does not always fit with Asian languages. We ex-
emplify some of the problems in section 3 and sug-
gest some directions to solve them. We expect
that further problems will come into clear view
through building sample lexicons. Section 4 de-
scribes a criteria to choose lexical entries in sam-
ple lexicons. Section 5 describes an approach
to build an upper-layer ontology which can be
sharable among languages. Section 6 describes
an application through which we evaluate the pro-
posed framework.
</bodyText>
<sectionHeader confidence="0.936369" genericHeader="introduction">
2 The MILE framework for
</sectionHeader>
<subsectionHeader confidence="0.493395">
interoperability of lexicons
</subsectionHeader>
<bodyText confidence="0.999303285714285">
The ISLE (International Standards for Language
Engineering) Computational Lexicon Working
Group has consensually defined the MILE (Mul-
tilingual ISLE Lexical Entry) as a standardized
infrastructure to develop multilingual lexical re-
sources for HLT applications, with particular at-
tention to Machine Translation (MT) and Crosslin-
gual Information Retrieval (CLIR) application
systems.
The MILE is a general architecture devised
for the encoding of multilingual lexical informa-
tion, a meta-entry acting as a common representa-
tional layer for multilingual lexicons, by allowing
integration and interoperability between different
monolingual lexicons3.
This formal and standardized framework to en-
code MILE-conformant lexical entries is provided
to lexicon and application developers by the over-
all MILE Lexical Model (MLM). As concerns
the horizontal organization, the MLM consists of
two independent, but interlinked primary compo-
nents, the monolingual and the multilingual mod-
ules. The monolingual component, on the vertical
dimension, is organized over three different repre-
sentational layers which allow to describe differ-
ent dimensions of lexical entries, namely the mor-
phological, syntactic and semantic layers. More-
over, an intermediate module allows to define
mechanisms of linkage and mapping between the
syntactic and semantic layers. Within each layer, a
basic linguistic information unit is identified; basic
units are separated but still interlinked each other
across the different layers.
Within each of the MLM layers, different types
of lexical object are distinguished :
</bodyText>
<listItem confidence="0.99919284">
• the MILE Lexical Classes (MLC) represent
the main building blocks which formalize
the basic lexical notions. They can be seen
as a set of structural elements organized in
a layered fashion: they constitute an on-
tology of lexical objects as an abstraction
over different lexical models and architec-
tures. These elements are the backbone of
the structural model. In the MLM a defini-
tion of the classes is provided together with
their attributes and the way they relate to each
other. Classes represent notions like Inflec-
tionalParadigm, SyntacticFunction, Syntac-
ticPhrase, Predicate, Argument,
• the MILE Data Categories (MDC) which
constitute the attributes and values to adorn
the structural classes and allow concrete en-
tries to be instantiated. MDC can belong to
a shared repository or be user-defined. “NP”
and “VP” are data category instances of the
class SyntacticPhrase, whereas and “subj”
and “obj” are data category instances of the
class SyntacticFunction.
• lexical operations, which are special lexical
entities allowing the user to define multilin-
</listItem>
<footnote confidence="0.984579666666667">
3MILE is based on the experience derived from exist-
ing computational lexicons (e.g. LE-PAROLE, SIMPLE, Eu-
roWordNet, etc.).
</footnote>
<page confidence="0.996578">
828
</page>
<bodyText confidence="0.999108782608696">
gual conditions and perform operations on
lexical entries.
Originally, in order to meet expectations placed
upon lexicons as critical resources for content pro-
cessing in the Semantic Web, the MILE syntactic
and semantic lexical objects have been formalized
in RDF(S), thus providing a web-based means to
implement the MILE architecture and allowing for
encoding individual lexical entries as instances of
the model (Ide et al., 2003; Bertagna et al., 2004b).
In the framework of our project, by situating our
work in the context of W3C standards and relying
on standardized technologies underlying this com-
munity, the original RDF schema for ISLE lexi-
cal entries has been made compliant to OWL. The
whole data model has been formalized in OWL by
using Prot´eg´e 3.2 beta and has been extended to
cover the morphological component as well (see
Figure 2). Prot´eg´e 3.2 beta has been also used as
a tool to instantiate the lexical entries of our sam-
ple monolingual lexicons, thus ensuring adherence
to the model, encoding coherence and inter- and
intra-lexicon consistency.
</bodyText>
<sectionHeader confidence="0.3933125" genericHeader="method">
3 Existing problems with the MILE
framework for Asian languages
</sectionHeader>
<bodyText confidence="0.999868444444445">
In this section, we will explain some problematic
phenomena of Asian languages and discuss pos-
sible extensions of the MILE framework to solve
them.
Inflection The MILE provides the powerful
framework to describe the information about in-
flection. InflectedForm class is devoted to de-
scribe inflected forms of a word, while Inflec-
tionalParadigm to define general inflection rules.
However, there is no inflection in several Asian
languages, such as Chinese and Thai. For these
languages, we do not use the Inflected Form and
Inflectional Paradigm.
Classifier Many Asian languages, such as
Japanese, Chinese, Thai and Korean, do not dis-
tinguish singularity and plurality of nouns, but use
classifiers to denote the number of objects. The
followings are examples of classifiers of Japanese.
</bodyText>
<listItem confidence="0.9993775">
• inu ni hiki · · · two dogs
(dog) (two) (CL)
• hon go satsu · · · five books
(book) (five) (CL)
</listItem>
<bodyText confidence="0.999791428571429">
“CL” stands for a classifier. They always follow
cardinal numbers in Japanese. Note that differ-
ent classifiers are used for different nouns. In the
above examples, classifier “hiki” is used to count
noun “inu (dog)”, while “satsu” for “hon (book)”.
The classifier is determined based on the semantic
type of the noun.
In the Thai language, classifiers are used in var-
ious situations (Sornlertlamvanich et al., 1994).
The classifier plays an important role in construc-
tion with noun to express ordinal, pronoun, for in-
stance. The classifier phrase is syntactically gener-
ated according to a specific pattern. Here are some
usages of classifiers and their syntactic patterns.
</bodyText>
<listItem confidence="0.879713076923077">
• Enumeration
(Noun/Verb)-(cardinal number)-(CL)
e.g. nakrian 3 khon · · · three students
(student) (CL)
• Ordinal
(Noun)-(CL)-/thi:/-(cardinal number)
e.g. kaew bai thi: 4 ··· the 4th glass
(glass) (CL) (4th)
• Determination
(Noun)-(CL)-(Determiner)
e.g. kruangkhidlek kruang nii
(calculator) (CL) (this)
· · · this calculator
</listItem>
<bodyText confidence="0.998370318181818">
Classifiers could be dealt as a class of the part-
of-speech. However, since classifiers depend on
the semantic type of nouns, we need to refer to
semantic features in the morphological layer, and
vice versa. Some mechanism to link between fea-
tures beyond layers needs to be introduced into the
current MILE framework.
Orthographic variants Many Chinese words
have orthographic variants. For instance, the con-
cept of rising can be represented by either char-
acter variants of sheng1: )+ or 4. However,
the free variants become non-free in certain com-
pound forms. For instance, only )+ allowed for �
)+ ‘liter’, and only 4 is allowed for 4V ‘to sub-
lime’. The interaction of lemmas and orthographic
variations is not yet represented in MILE.
Reduplication as a derivational process In
some Asian languages, reduplication of words de-
rives another word, and the derived word often has
a different part-of-speech. Here are some exam-
ples of reduplication in Chinese. Man4 &apos;rO ‘to be
slow’ is a state verb, while a reduplicated form
</bodyText>
<page confidence="0.988256">
829
</page>
<figure confidence="0.999867127659574">
Lexical Entry SyntacticUnit
1..*
Lemmatized Form
Form
0..*
Stem
Operation
0..* 0..*
Calculator
0..*
Argument
Inßectional
Paradigm
Combiner
0..*
0..1 0..*
0..*
Mrophfeat
Inßected Form
Morph
DataCats
&lt;LemmatizedForm rdf:ID=&amp;quot;LFstar&amp;quot;&gt;
&lt;hasInflectedForm&gt;
&lt;InflectedForm rdf:ID=&amp;quot;stars&amp;quot;&gt;
&lt;hasMorphoFeat&gt;
&lt;MorphoFeat rdf:ID=&amp;quot;pl&amp;quot;&gt;
&lt;number rdf:datatype=&amp;quot;http://www.w3c.org/
2001/ XMLSchema#string&amp;quot;&gt;
plural
&lt;/number&gt;
&lt;/MorphoFeat&gt;
&lt;/hasMorphoFeat&gt;
&lt;/InflectedForm&gt;
&lt;/hasInflectedForm&gt;
&lt;hasInflectedForm&gt;
&lt;InflectedForm rdf:ID=&amp;quot;star&amp;quot;&gt;
&lt;hasMorphoFeat&gt;
&lt;MorphoFeat rdf:ID=&amp;quot;sg&amp;quot;&gt;
&lt;number rdf:datatype=&amp;quot;http://www.w3c.org/
2001/ XMLSchema#string&amp;quot;&gt;
singular
&lt;/number&gt;
&lt;/MorphoFeat&gt;
&lt;/hasMorphoFeat&gt;
&lt;/InflectedForm&gt;
&lt;/hasInflectedForm&gt;
&lt;/LemmatiedForm&gt;
</figure>
<figureCaption confidence="0.999975">
Figure 2: Formalization of the morphological layer and excerpt of a sample RDF instantiation
</figureCaption>
<bodyText confidence="0.999663230769231">
man4-man4 慢慢 is an adverb. Another example
of reduplication involves verbal aspect. Kan4 看
‘to look’ is an activity verb, while the reduplica-
tive form kan4-kan4 看看, refers to the tentative
aspect, introducing either stage-like sub-division
or the event or tentativeness of the action of the
agent. This morphological process is not provided
for in the current MILE standard.
There are also various usages of reduplication in
Thai. Some words reduplicate themselves to add a
specific aspect to the original meaning. The redu-
plication can be grouped into 3 types according to
the tonal sound change of the original word.
</bodyText>
<listItem confidence="0.964564166666667">
• Word reduplication without sound change
e.g. /dek-dek/ · · · (N) children, (ADV) child-
ishly, (ADJ) childish
/sa:w-sa:w/ · · · (N) women
• Word reduplication with high tone on the first
word
e.g. /dam4-dam/ · · · (ADJ) extremely black
/bo:i4-bo:i/ · · · (ADV) really often
• Triple word reduplication with high tone on
the second word
e.g. /dern-dern4-dern/ ·· (V) intensively walk
/norn-norn4-norn/··(V) intensively sleep
</listItem>
<bodyText confidence="0.999040470588235">
In fact, only the reduplication of the same sound
is accepted in the written text, and a special sym-
bol, namely /mai-yamok/ is attached to the origi-
nal word to represent the reduplication. The redu-
plication occurs in many parts-of-speech, such as
noun, verb, adverb, classifier, adjective, preposi-
tion. Furthermore, various aspects can be added
to the original meaning of the word by reduplica-
tion, such as pluralization, emphasis, generaliza-
tion, and so on. These aspects should be instanti-
ated as features.
Change of parts-of-speech by afÞxes Af-
fixes change parts-of-speech of words in
Thai (Charoenporn et al., 1997). There are
three prefixes changing the part-of-speech of the
original word, namely /ka:n/, /khwa:m/, /ya:ng/.
They are used in the following cases.
</bodyText>
<listItem confidence="0.962116">
• Nominalization
</listItem>
<bodyText confidence="0.743035">
/ka:n/ is used to prefix an action verb and
/khwa:m/ is used to prefix a state verb
in nominalization such as /ka:n-tham-nga:n/
(working), /khwa:m-suk/ (happiness).
</bodyText>
<listItem confidence="0.958609">
• Adverbialization
</listItem>
<bodyText confidence="0.999854538461538">
An adverb can be derived by using /ya:ng/ to
prefix a state verb such as /ya:ng-di:/ (well).
Note that these prefixes are also words, and form
multi-word expressions with the original word.
This phenomenon is similar to derivation which
is not handled in the current MILE framework.
Derivation is traditionally considered as a different
phenomenon from inflection, and current MILE
focuses on inflection. The MILE framework is al-
ready being extended to treat such linguistic phe-
nomenon, since it is important to European lan-
guages as well. It would be handled in either the
morphological layer or syntactic layer.
</bodyText>
<page confidence="0.980207">
830
</page>
<bodyText confidence="0.999735866666667">
Function Type Function types of predicates
(verbs, adjectives etc.) might be handled in a
partially different way for Japanese. In the syn-
tactic layer of the MILE framework, Function-
Type class is prepared to denote subcategorization
frames of predicates, and they have function types
such as “subj” and “obj”. For example, the verb
“eat” has two FunctionType data categories of
“subj” and “obj”. Function types basically stand
for positions of case filler nouns. In Japanese,
cases are usually marked by postpositions and case
filler positions themselves do not provide much in-
formation on case marking. For example, both of
the following sentences mean the same, “She eats
a pizza.”
</bodyText>
<listItem confidence="0.9991355">
• kanojo ga piza wo taberu
(she) (NOM) (pizza) (ACC) (eat)
• piza wo kanojo ga taberu
(pizza) (ACC) (she) (NOM) (eat)
</listItem>
<bodyText confidence="0.999624266666667">
“Ga” and “wo” are postpositions which mark
nominative and accusative cases respectively.
Note that two case filler nouns “she” and “pizza”
can be exchanged. That is, the number of slots is
important, but their order is not.
For Japanese, we might use the set of post-
positions as values of FunctionType instead of
conventional function types such as “subj” and
“obj”. It might be an user defined data category or
language dependent data category. Furthermore,
it is preferable to prepare the mapping between
Japanese postpositions and conventional function
types. This is interesting because it seems more
a terminological difference, but the model can be
applied also to Japanese.
</bodyText>
<sectionHeader confidence="0.989341" genericHeader="method">
4 Building sample lexicons
</sectionHeader>
<subsectionHeader confidence="0.999873">
4.1 Swadesh list and basic lexicon
</subsectionHeader>
<bodyText confidence="0.99998265">
The issue involved in defining a basic lexicon for a
given language is more complicated than one may
think (Zhang et al., 2004). The naive approach of
simply taking the most frequent words in a lan-
guage is flawed in many ways. First, all frequency
counts are corpus-based and hence inherit the bias
of corpus sampling. For instance, since it is eas-
ier to sample written formal texts, words used pre-
dominantly in informal contexts are usually under-
represented. Second, frequency of content words
is topic-dependent and may vary from corpus to
corpus. Last, and most crucially, frequency of a
word does not correlate to its conceptual necessity,
which should be an important, if not only, criteria
for core lexicon. The definition of a cross-lingual
basic lexicon is even more complicated. The first
issue involves determination of cross-lingual lexi-
cal equivalencies. That is, how to determine that
word a (and not a’) in language A really is word b
in language B. The second issue involves the deter-
mination of what is a basic word in a multilingual
context. In this case, not even the frequency of-
fers an easy answer since lexical frequency may
vary greatly among different languages. The third
issue involves lexical gaps. That is, if there is a
word that meets all criteria of being a basic word
in language A, yet it does not exist in language D
(though it may exist in languages B, and C). Is this
word still qualified to be included in the multilin-
gual basic lexicon?
It is clear not all the above issues can be un-
equivocally solved with the time frame of our
project. Fortunately, there is an empirical core lex-
icon that we can adopt as a starting point. The
Swadesh list was proposed by the historical lin-
guist Morris Swadesh (Swadesh, 1952), and has
been widely used by field and historical linguists
for languages over the world. The Swadesh list
was first proposed as lexico-statistical metrics.
That is, these are words that can be reliably ex-
pected to occur in all historical languages and can
be used as the metrics for quantifying language
variations and language distance. The Swadesh
list is also widely used by field linguists when
they encounter a new language, since almost all
of these terms can be expected to occur in any
language. Note that the Swadesh list consists of
terms that embody human direct experience, with
culture-specific terms avoided. Swadesh started
with a 215 items list, before cutting back to 200
items and then to 100 items. A standard list of
207 items is arrived at by unifying the 200 items
list and the 100 items list. We take the 207 terms
from the Swadesh list as the core of our basic lex-
icon. Inclusion of the Swadesh list also gives us
the possibility of covering many Asian languages
in which we do not have the resources to make a
full and fully annotated lexicon. For some of these
languages, a Swadesh lexicon for reference is pro-
vided by a collaborator.
</bodyText>
<subsectionHeader confidence="0.99516">
4.2 Aligning multilingual lexical entries
</subsectionHeader>
<bodyText confidence="0.9993455">
Since our goal is to build a multilingual sample
lexicon, it is required to align words in several
</bodyText>
<page confidence="0.995816">
831
</page>
<bodyText confidence="0.940740111111111">
Asian languages. In this subsection, we propose
a simple method to align words in different lan-
guages. The basic idea for multilingual alignment
is an intermediary by English. That is, first we
prepare word pairs between English and other lan-
guages, then combine them together to make cor-
respondence among words in several languages.
The multilingual alignment method currently we
consider is as follows:
1. Preparing the set of frequent words of each
language
Suppose that {Jwi}, {Cwi}, {Twi} is the
set of frequent words of Japanese, Chinese
and Thai, respectively. Now we try to con-
struct a multilingual lexicon for these three
languages, however, our multilingual align-
ment method can be easily extended to han-
dle more languages.
</bodyText>
<sectionHeader confidence="0.663776" genericHeader="method">
2. Obtaining English translations
</sectionHeader>
<bodyText confidence="0.9976206">
A word Xwi is translated into a set of En-
glish words EXwij by referring to the bilin-
gual dictionary, where X denotes one of our
languages, J, C or T. We can obtain map-
pings as in (1).
</bodyText>
<equation confidence="0.9672776">
Jw1 : EJw11, EJw12, · · ·
Jw2 : EJw21, EJw22, · · ·
...
Cw1 : ECw11, ECw12, · · ·
Cw2 : ECw21, ECw22, · · ·
.
..
Tw1 : ETw11, ETw12, · · ·
Tw2 : ETw21, ETw22, · · ·
...
</equation>
<bodyText confidence="0.998057333333333">
Notice that this procedure is automatically
done and ambiguities would be left at this
stage.
</bodyText>
<sectionHeader confidence="0.48006" genericHeader="method">
3. Generating new mapping
</sectionHeader>
<bodyText confidence="0.999816833333333">
From mappings in (1), a new mapping is gen-
erated by inverting the key. That is, in the
new mapping, a key is an English word Ewi
and a correspondence for each key is sets
of translations XEwij for 3 languages, as
shown in (2):
</bodyText>
<equation confidence="0.999785333333333">
Ew1 : (JEw11, JEw12, · · ·)
(CEw11, CEw12, · · ·)
(TEw11,TEw12, · · ·)
Ew2 : (JEw21, JEw22, · · ·)
(CEw21, CEw22, · · ·)
(TEw21,TEw22, · · ·)
</equation>
<bodyText confidence="0.8394302">
...
Notice that at this stage, correspondence be-
tween different languages is very loose, since
they are aligned on the basis of sharing only
a single English word.
</bodyText>
<listItem confidence="0.593178">
4. Refinement of alignment
</listItem>
<bodyText confidence="0.997633833333333">
Groups of English words are constructed by
referring to the WordNet synset information.
For example, suppose that Ewi and Ewj be-
long to the same synset Sk. We will make a
new alignment by making an intersection of
{XEwi} and {XEwj} as shown in (3).
</bodyText>
<equation confidence="0.96659225">
Ewi : (JEwi1, ··) (CEwi1, ··) (TEwi1, ··) (3)
Ewj : (JEwj1, ··)(CEwj1, ··)(TEwj1, ··)
4 intersection
Sk : (JEw&apos; k1, ··)(CEw&apos; k1, ··)(TEw&apos; k1, ··)
</equation>
<bodyText confidence="0.999989617647059">
In (3), the key is a synset Sk, which is sup-
posed to be a conjunction of Ewi and Ewj,
and the counterpart is the intersection of set
of translations for each language. This oper-
ation would reduce the number of words of
each language. That means, we can expect
that the correspondence among words of dif-
ferent languages becomes more precise. This
new word alignment based on a synset is a
final result.
To evaluate the performance of this method,
we conducted a preliminary experiment using the
Swadesh list. Given the Swadesh list of Chi-
nese, Italian, Japanese and Thai as a gold stan-
dard, we tried to replicate these lists from the En-
glish Swadesh list and bilingual dictionaries be-
tween English and these languages. In this experi-
ment, we did not perform the refinement step with
WordNet. From 207 words in the Swadesh list,
we dropped 4 words (“at”, “in”, “with” and “and”)
due to their too many ambiguities in translation.
As a result, we obtained 181 word groups
aligned across 5 languages (Chinese, English, Ital-
ian, Japanese and Thai) for 203 words. An
aligned word group was judged “correct” when the
words of each language include only words in the
Swadesh list of that language. It was judged “par-
tially correct” when the words of a language also
include the words which are not in the Swadesh
list. Based on the correct instances, we obtain
0.497 for precision and 0.443 for recall. These fig-
ures go up to 0.912 for precision and 0.813 for re-
call when based on the partially correct instances.
This is quite a promising result.
</bodyText>
<page confidence="0.996119">
832
</page>
<sectionHeader confidence="0.964493" genericHeader="method">
5 Upper-layer ontology
</sectionHeader>
<bodyText confidence="0.99997718">
The empirical success of the Swadesh list poses
an interesting question that has not been explored
before. That is, does the Swadesh list instantiates a
shared, fundamental human conceptual structure?
And if there is such as a structure, can we discover
it?
In the project these fundamental issues are as-
sociated with our quest for cross-lingual interop-
erability. We must make sure that the items of
the basic lexicon are given the same interpreta-
tion. One measure taken to ensure this consists in
constructing an upper-ontology based on the ba-
sic lexicon. Our preliminary work of mapping the
Swadesh list items to SUMO (Suggested Upper
Merged Ontology) (Niles and Pease, 2001) has al-
ready been completed. We are in the process of
mapping the list to DOLCE (Descriptive Ontology
for Linguistic and Cognitive Engineering) (Ma-
solo et al., 2003). After the initial mapping, we
carry on the work to restructure the mapped nodes
to form a genuine conceptual ontology based on
the language universal basic lexical items. How-
ever one important observation that we have made
so far is that the success of the Swadesh list is
partly due to its underspecification and to the lib-
erty it gives to compilers of the list in a new lan-
guage. If this idea of underspecification is essen-
tial for basic lexicon for human languages, then we
must resolve this apparent dilemma of specifying
them in a formal ontology that requires fully spec-
ified categories. For the time being, genuine ambi-
guities resulted in the introduction of each disam-
biguated sense in the ontology. We are currently
investigating another solution that allows the in-
clusion of underspecified elements in the ontology
without threatening its coherence. More specifi-
cally we introduce a underspecified relation in the
structure for linking the underspecified meaning
to the different specified meaning. The specified
meanings are included in the taxonomic hierarchy
in a traditional manner, while a hierarchy of un-
derspecified meanings can be derived thanks to the
new relation. An underspecified node only inherits
from the most specific common mother of its fully
specified terms. Such distinction avoids the clas-
sical misuse of the subsumption relation for rep-
resenting multiple meanings. This method does
not reflect a dubious collapse of the linguistic and
conceptual levels but the treatment of such under-
specifications as truly conceptual. Moreover we
</bodyText>
<figureCaption confidence="0.999708">
Figure 3: The system architecture
</figureCaption>
<bodyText confidence="0.999928875">
hope this proposal will provide a knowledge rep-
resentation framework for the multilingual align-
ment method presented in the previous section.
Finally, our ontology will not only play the role
of a structured interlingual index. It will also serve
as a common conceptual base for lexical expan-
sion, as well as for comparative studies of the lex-
ical differences of different languages.
</bodyText>
<sectionHeader confidence="0.985941" genericHeader="evaluation">
6 Evaluation through an application
</sectionHeader>
<bodyText confidence="0.9999693">
To evaluate the proposed framework, we are build-
ing an information retrieval system. Figure 3
shows the system architecture.
A user can input a topic to retrieve the docu-
ments related to that topic. A topic can consist
of keywords, website URL’s and documents which
describe the topic. From the topic information, the
system builds a user interest model. The system
then uses a search engine and a crawler to search
for information related to this topic in WWW and
stores the results in the local database. Generally,
the search results include many noises. To filter
out these noises, we build a query from the user
interest model and then use this query to retrieve
documents in the local database. Those documents
similar to the query are considered as more related
to the topic and the user’s interest, and are returned
to the user. When the user obtains these retrieval
results, he can evaluate these documents and give
the feedback to the system, which is used for the
further refinement of the user interest model.
Language resources can contribute to improv-
ing the system performance in various ways.
Query expansion is a well-known technique which
expands user’s query terms into a set of similar and
related terms by referring to ontologies. Our sys-
tem is based on the vector space model (VSM) and
traditional query expansion can be applicable us-
ing the ontology.
There has been less research on using lexical in-
</bodyText>
<figure confidence="0.998261666666667">
Feedback
Topic
User interest
model
Retrieval
results
Query
Search Crawler
engine
Internet
Local
DB
</figure>
<page confidence="0.997634">
833
</page>
<bodyText confidence="0.999989722222222">
formation for information retrieval systems. One
possibility we are considering is query expansion
by using predicate-argument structures of terms.
Suppose a user inputs two keywords, “hockey”
and “ticket” as a query. The conventional query
expansion technique expands these keywords to
a set of similar words based on an ontology. By
referring to predicate-argument structures in the
lexicon, we can derive actions and events as well
which take these words as arguments. In the above
example, by referring to the predicate-argument
structure of “buy” or “sell”, and knowing that
these verbs can take “ticket” in their object role,
we can add “buy” and “sell” to the user’s query.
This new type of expansion requires rich lexical
information such as predicate argument structures,
and the information retrieval system would be a
good touchstone of the lexical information.
</bodyText>
<sectionHeader confidence="0.989635" genericHeader="conclusions">
7 Concluding remarks
</sectionHeader>
<bodyText confidence="0.999986">
This paper outlined a new project for creating a
common standard for Asian language resources
in cooperation with other initiatives. We start
with three Asian languages, Chinese, Japanese
and Thai, on top of the existing framework which
was designed mainly for European languages.
We plan to distribute our draft to HLT soci-
eties of other Asian languages, requesting for
their feedback through various networks, such
as the Asian language resource committee net-
work under Asian Federation of Natural Language
Processing (AFNLP)4, and Asian Language Re-
source Network project5. We believe our ef-
forts contribute to international activities like ISO-
TC37/SC46 (Francopoulo et al., 2006) and to the
revision of the ISO Data Category Registry (ISO
12620), making it possible to come close to the
ideal international standard of language resources.
</bodyText>
<sectionHeader confidence="0.953183" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.975191">
This research was carried out through financial
support provided under the NEDO International
Joint Research Grant Program (NEDO Grant).
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980590666666667">
F. Bertagna, A. Lenci, M. Monachini, and N. Calzo-
lari. 2004a. Content interoperability of lexical re-
sources, open issues and “MILE” perspectives. In
</reference>
<footnote confidence="0.998203666666667">
4http://www.afnlp.org/
5http://www.language-resource.net/
6http://www.tc37sc4.org/
</footnote>
<reference confidence="0.997814631578948">
Proceedings of the 4th International Conference on
Language Resources and Evaluation (LREC2004),
pages 131–134.
F. Bertagna, A. Lenci, M. Monachini, and N. Calzo-
lari. 2004b. The MILE lexical classes: Data cat-
egories for content interoperability among lexicons.
In A Registry of Linguistic Data Categories within
an Integrated Language Resources Repository Area
– LREC2004 Satellite Workshop, page 8.
N. Calzolari, F. Bertagna, A. Lenci, and M. Mona-
chini. 2003. Standards and best practice for mul-
tilingual computational lexicons. MILE (the mul-
tilingual ISLE lexical entry). ISLE Deliverable
D2.2&amp;3.2.
T. Charoenporn, V. Sornlertlamvanich, and H. Isahara.
1997. Building a large Thai text corpus — part-
of-speech tagged corpus: ORCHID—. In Proceed-
ings of the Natural Language Processing PaciÞc Rim
Symposium.
G. Francopoulo, G. Monte, N. Calzolari, M. Mona-
chini, N. Bel, M. Pet, and C. Soria. 2006. Lex-
ical markup framework (LMF). In Proceedings of
LREC2006 (forthcoming).
N. Ide, A. Lenci, and N. Calzolari. 2003. RDF in-
stantiation of ISLE/MILE lexical entries. In Pro-
ceedings of the ACL 2003 Workshop on Linguistic
Annotation: Getting the Model Right, pages 25–34.
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola,
M. Monachini, A. Ogonowsky, I. Peters, W. Peters,
N. Ruimy, M. Villegas, and A. Zampolli. 2000.
SIMPLE: A general framework for the development
of multilingual lexicons. International Journal of
Lexicography, Special Issue, Dictionaries, Thesauri
and Lexical-Semantic Relations, XIII(4):249–263.
C. Masolo, A. Borgo, S.; Gangemi, N. Guarino, and
A. Oltramari. 2003. Wonderweb deliverable d18
–ontology library (final)–. Technical report, Labo-
ratory for Applied Ontology, ISTC-CNR.
I. Niles and A Pease. 2001. Towards a standard upper
ontology. In Proceedings of the 2nd International
Conference on Formal Ontology in Information Sys-
tems (FOIS-2001).
V. Sornlertlamvanich, W. Pantachat, and S. Mek-
navin. 1994. Classifier assignment by corpus-
based approach. In Proceedings of the 15th Inter-
national Conference on Computational Linguistics
(COLING-94), pages 556–561.
M. Swadesh. 1952. Lexico-statistical dating of pre-
historic ethnic contacts: With special reference to
north American Indians and Eskimos. In Proceed-
ings of the American Philo-sophical Society, vol-
ume 96, pages 452–463.
H. Zhang, C. Huang, and S. Yu. 2004. Distributional
consistency: A general method for defining a core
lexicon. In Proceedings of the 4th International
Conference on Language Resources and Evaluation
(LREC2004), pages 1119–1222.
</reference>
<page confidence="0.998708">
834
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000675">
<title confidence="0.999471">Infrastructure for standardization of Asian language resources</title>
<author confidence="0.990332">Tokunaga Takenobu</author>
<affiliation confidence="0.90947">Tokyo Inst. of Tech.</affiliation>
<author confidence="0.654574">Nicoletta Calzolari</author>
<affiliation confidence="0.406899">ILC/CNR</affiliation>
<author confidence="0.845497">Chu-Ren Huang</author>
<affiliation confidence="0.5596765">Academia Sinica Virach Sornlertlamvanich</affiliation>
<address confidence="0.259471">TCL, NICT</address>
<author confidence="0.992774">Monica Monachini</author>
<affiliation confidence="0.792246">ILC/CNR</affiliation>
<author confidence="0.73682">Xia YingJu</author>
<affiliation confidence="0.763682">Fujitsu R&amp;D Center</affiliation>
<title confidence="0.4483465">Thatsanee Charoenporn TCL, NICT</title>
<author confidence="0.733605">Claudia Soria</author>
<affiliation confidence="0.447381">ILC/CNR</affiliation>
<author confidence="0.975311">Yu Hao</author>
<affiliation confidence="0.674989">Fujitsu R&amp;D Center</affiliation>
<author confidence="0.954545">Laurent Prevot Shirai Kiyoaki</author>
<affiliation confidence="0.563054">Academia Sinica JAIST</affiliation>
<abstract confidence="0.970527565217391">As an area of great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upperlayer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Bertagna</author>
<author>A Lenci</author>
<author>M Monachini</author>
<author>N Calzolari</author>
</authors>
<title>Content interoperability of lexical resources, open issues and “MILE” perspectives.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC2004),</booktitle>
<pages>131--134</pages>
<contexts>
<context position="3417" citStr="Bertagna et al., 2004" startWordPosition="504" endWordPosition="507">h item (1), building a description framework of lexical entries which (1) Description framework of lexical entries reÞnement evaluation evaluation (4) Evaluation through application (2) Sample lexicons reÞnement classiÞcation (3) Upper layer ontology description 827 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 827–834, Sydney, July 2006. c�2006 Association for Computational Linguistics fits with as many Asian languages as possible, and contributing to the ISO-TC37/SC4 activities. As a starting point, we employ an existing description framework, the MILE framework (Bertagna et al., 2004a), to describe several lexical entries of several Asian languages. Through building sample lexicons (research item (2)), we will find problems of the existing framework, and extend it so as to fit with Asian languages. In this extension, we need to be careful in keeping consistency with the existing framework. We start with Chinese, Japanese and Thai as target Asian languages and plan to expand the coverage of languages. The research items (2) and (3) also comprise the similar feedback loop. Through building sample lexicons, we refine an upper-layer ontology. An application built in the resea</context>
<context position="8139" citStr="Bertagna et al., 2004" startWordPosition="1228" endWordPosition="1231">es allowing the user to define multilin3MILE is based on the experience derived from existing computational lexicons (e.g. LE-PAROLE, SIMPLE, EuroWordNet, etc.). 828 gual conditions and perform operations on lexical entries. Originally, in order to meet expectations placed upon lexicons as critical resources for content processing in the Semantic Web, the MILE syntactic and semantic lexical objects have been formalized in RDF(S), thus providing a web-based means to implement the MILE architecture and allowing for encoding individual lexical entries as instances of the model (Ide et al., 2003; Bertagna et al., 2004b). In the framework of our project, by situating our work in the context of W3C standards and relying on standardized technologies underlying this community, the original RDF schema for ISLE lexical entries has been made compliant to OWL. The whole data model has been formalized in OWL by using Prot´eg´e 3.2 beta and has been extended to cover the morphological component as well (see Figure 2). Prot´eg´e 3.2 beta has been also used as a tool to instantiate the lexical entries of our sample monolingual lexicons, thus ensuring adherence to the model, encoding coherence and inter- and intra-lexi</context>
</contexts>
<marker>Bertagna, Lenci, Monachini, Calzolari, 2004</marker>
<rawString>F. Bertagna, A. Lenci, M. Monachini, and N. Calzolari. 2004a. Content interoperability of lexical resources, open issues and “MILE” perspectives. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC2004), pages 131–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bertagna</author>
<author>A Lenci</author>
<author>M Monachini</author>
<author>N Calzolari</author>
</authors>
<title>The MILE lexical classes: Data categories for content interoperability among lexicons.</title>
<date>2004</date>
<booktitle>In A Registry of Linguistic Data Categories within an Integrated Language Resources Repository Area – LREC2004 Satellite Workshop,</booktitle>
<pages>8</pages>
<contexts>
<context position="3417" citStr="Bertagna et al., 2004" startWordPosition="504" endWordPosition="507">h item (1), building a description framework of lexical entries which (1) Description framework of lexical entries reÞnement evaluation evaluation (4) Evaluation through application (2) Sample lexicons reÞnement classiÞcation (3) Upper layer ontology description 827 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 827–834, Sydney, July 2006. c�2006 Association for Computational Linguistics fits with as many Asian languages as possible, and contributing to the ISO-TC37/SC4 activities. As a starting point, we employ an existing description framework, the MILE framework (Bertagna et al., 2004a), to describe several lexical entries of several Asian languages. Through building sample lexicons (research item (2)), we will find problems of the existing framework, and extend it so as to fit with Asian languages. In this extension, we need to be careful in keeping consistency with the existing framework. We start with Chinese, Japanese and Thai as target Asian languages and plan to expand the coverage of languages. The research items (2) and (3) also comprise the similar feedback loop. Through building sample lexicons, we refine an upper-layer ontology. An application built in the resea</context>
<context position="8139" citStr="Bertagna et al., 2004" startWordPosition="1228" endWordPosition="1231">es allowing the user to define multilin3MILE is based on the experience derived from existing computational lexicons (e.g. LE-PAROLE, SIMPLE, EuroWordNet, etc.). 828 gual conditions and perform operations on lexical entries. Originally, in order to meet expectations placed upon lexicons as critical resources for content processing in the Semantic Web, the MILE syntactic and semantic lexical objects have been formalized in RDF(S), thus providing a web-based means to implement the MILE architecture and allowing for encoding individual lexical entries as instances of the model (Ide et al., 2003; Bertagna et al., 2004b). In the framework of our project, by situating our work in the context of W3C standards and relying on standardized technologies underlying this community, the original RDF schema for ISLE lexical entries has been made compliant to OWL. The whole data model has been formalized in OWL by using Prot´eg´e 3.2 beta and has been extended to cover the morphological component as well (see Figure 2). Prot´eg´e 3.2 beta has been also used as a tool to instantiate the lexical entries of our sample monolingual lexicons, thus ensuring adherence to the model, encoding coherence and inter- and intra-lexi</context>
</contexts>
<marker>Bertagna, Lenci, Monachini, Calzolari, 2004</marker>
<rawString>F. Bertagna, A. Lenci, M. Monachini, and N. Calzolari. 2004b. The MILE lexical classes: Data categories for content interoperability among lexicons. In A Registry of Linguistic Data Categories within an Integrated Language Resources Repository Area – LREC2004 Satellite Workshop, page 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Calzolari</author>
<author>F Bertagna</author>
<author>A Lenci</author>
<author>M Monachini</author>
</authors>
<title>Standards and best practice for multilingual computational lexicons.</title>
<date>2003</date>
<booktitle>MILE (the multilingual ISLE lexical entry). ISLE Deliverable D2.2&amp;3.2.</booktitle>
<contexts>
<context position="1589" citStr="Calzolari et al., 2003" startWordPosition="241" endWordPosition="244"> The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upperlayer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach. 1 Introduction There is a long history of creating a standard for western language resources. The human language technology (HLT) society in Europe has been particularly zealous for the standardization, making a series of attempts such as EAGLES1, PAROLE/SIMPLE (Lenci et al., 2000), ISLE/MILE (Calzolari et al., 2003) and LIRICS2. These continuous efforts has been crystallized as activities in ISO-TC37/SC4 which aims to make an international standard for language resources. 1http://www.ilc.cnr.it/Eagles96/home.html 2lirics.loria.fr/documents.html Figure 1: Relations among research items On the other hand, since Asia has great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase th</context>
</contexts>
<marker>Calzolari, Bertagna, Lenci, Monachini, 2003</marker>
<rawString>N. Calzolari, F. Bertagna, A. Lenci, and M. Monachini. 2003. Standards and best practice for multilingual computational lexicons. MILE (the multilingual ISLE lexical entry). ISLE Deliverable D2.2&amp;3.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Charoenporn</author>
<author>V Sornlertlamvanich</author>
<author>H Isahara</author>
</authors>
<title>Building a large Thai text corpus — partof-speech tagged corpus: ORCHID—.</title>
<date>1997</date>
<booktitle>In Proceedings of the Natural Language Processing PaciÞc Rim Symposium.</booktitle>
<contexts>
<context position="14222" citStr="Charoenporn et al., 1997" startWordPosition="2155" endWordPosition="2158">sleep In fact, only the reduplication of the same sound is accepted in the written text, and a special symbol, namely /mai-yamok/ is attached to the original word to represent the reduplication. The reduplication occurs in many parts-of-speech, such as noun, verb, adverb, classifier, adjective, preposition. Furthermore, various aspects can be added to the original meaning of the word by reduplication, such as pluralization, emphasis, generalization, and so on. These aspects should be instantiated as features. Change of parts-of-speech by afÞxes Affixes change parts-of-speech of words in Thai (Charoenporn et al., 1997). There are three prefixes changing the part-of-speech of the original word, namely /ka:n/, /khwa:m/, /ya:ng/. They are used in the following cases. • Nominalization /ka:n/ is used to prefix an action verb and /khwa:m/ is used to prefix a state verb in nominalization such as /ka:n-tham-nga:n/ (working), /khwa:m-suk/ (happiness). • Adverbialization An adverb can be derived by using /ya:ng/ to prefix a state verb such as /ya:ng-di:/ (well). Note that these prefixes are also words, and form multi-word expressions with the original word. This phenomenon is similar to derivation which is not handle</context>
</contexts>
<marker>Charoenporn, Sornlertlamvanich, Isahara, 1997</marker>
<rawString>T. Charoenporn, V. Sornlertlamvanich, and H. Isahara. 1997. Building a large Thai text corpus — partof-speech tagged corpus: ORCHID—. In Proceedings of the Natural Language Processing PaciÞc Rim Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Francopoulo</author>
<author>G Monte</author>
<author>N Calzolari</author>
<author>M Monachini</author>
<author>N Bel</author>
<author>M Pet</author>
<author>C Soria</author>
</authors>
<title>Lexical markup framework (LMF).</title>
<date>2006</date>
<booktitle>In Proceedings of LREC2006 (forthcoming).</booktitle>
<marker>Francopoulo, Monte, Calzolari, Monachini, Bel, Pet, Soria, 2006</marker>
<rawString>G. Francopoulo, G. Monte, N. Calzolari, M. Monachini, N. Bel, M. Pet, and C. Soria. 2006. Lexical markup framework (LMF). In Proceedings of LREC2006 (forthcoming).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>A Lenci</author>
<author>N Calzolari</author>
</authors>
<title>RDF instantiation of ISLE/MILE lexical entries.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Linguistic Annotation: Getting the Model Right,</booktitle>
<pages>25--34</pages>
<contexts>
<context position="8116" citStr="Ide et al., 2003" startWordPosition="1224" endWordPosition="1227">ial lexical entities allowing the user to define multilin3MILE is based on the experience derived from existing computational lexicons (e.g. LE-PAROLE, SIMPLE, EuroWordNet, etc.). 828 gual conditions and perform operations on lexical entries. Originally, in order to meet expectations placed upon lexicons as critical resources for content processing in the Semantic Web, the MILE syntactic and semantic lexical objects have been formalized in RDF(S), thus providing a web-based means to implement the MILE architecture and allowing for encoding individual lexical entries as instances of the model (Ide et al., 2003; Bertagna et al., 2004b). In the framework of our project, by situating our work in the context of W3C standards and relying on standardized technologies underlying this community, the original RDF schema for ISLE lexical entries has been made compliant to OWL. The whole data model has been formalized in OWL by using Prot´eg´e 3.2 beta and has been extended to cover the morphological component as well (see Figure 2). Prot´eg´e 3.2 beta has been also used as a tool to instantiate the lexical entries of our sample monolingual lexicons, thus ensuring adherence to the model, encoding coherence an</context>
</contexts>
<marker>Ide, Lenci, Calzolari, 2003</marker>
<rawString>N. Ide, A. Lenci, and N. Calzolari. 2003. RDF instantiation of ISLE/MILE lexical entries. In Proceedings of the ACL 2003 Workshop on Linguistic Annotation: Getting the Model Right, pages 25–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lenci</author>
<author>N Bel</author>
<author>F Busa</author>
<author>N Calzolari</author>
<author>E Gola</author>
<author>M Monachini</author>
<author>A Ogonowsky</author>
<author>I Peters</author>
<author>W Peters</author>
<author>N Ruimy</author>
<author>M Villegas</author>
<author>A Zampolli</author>
</authors>
<date>2000</date>
<contexts>
<context position="1553" citStr="Lenci et al., 2000" startWordPosition="236" endWordPosition="239">rd for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upperlayer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach. 1 Introduction There is a long history of creating a standard for western language resources. The human language technology (HLT) society in Europe has been particularly zealous for the standardization, making a series of attempts such as EAGLES1, PAROLE/SIMPLE (Lenci et al., 2000), ISLE/MILE (Calzolari et al., 2003) and LIRICS2. These continuous efforts has been crystallized as activities in ISO-TC37/SC4 which aims to make an international standard for language resources. 1http://www.ilc.cnr.it/Eagles96/home.html 2lirics.loria.fr/documents.html Figure 1: Relations among research items On the other hand, since Asia has great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least thr</context>
</contexts>
<marker>Lenci, Bel, Busa, Calzolari, Gola, Monachini, Ogonowsky, Peters, Peters, Ruimy, Villegas, Zampolli, 2000</marker>
<rawString>A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola, M. Monachini, A. Ogonowsky, I. Peters, W. Peters, N. Ruimy, M. Villegas, and A. Zampolli. 2000.</rawString>
</citation>
<citation valid="false">
<title>SIMPLE: A general framework for the development of multilingual lexicons.</title>
<journal>International Journal of Lexicography, Special Issue, Dictionaries, Thesauri and Lexical-Semantic Relations,</journal>
<pages>4--249</pages>
<marker></marker>
<rawString>SIMPLE: A general framework for the development of multilingual lexicons. International Journal of Lexicography, Special Issue, Dictionaries, Thesauri and Lexical-Semantic Relations, XIII(4):249–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Masolo</author>
<author>A Borgo</author>
<author>S Gangemi</author>
<author>N Guarino</author>
<author>A Oltramari</author>
</authors>
<title>Wonderweb deliverable d18 –ontology library (final)–.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>Laboratory for Applied Ontology, ISTC-CNR.</institution>
<contexts>
<context position="24396" citStr="Masolo et al., 2003" startWordPosition="3911" endWordPosition="3915">as a structure, can we discover it? In the project these fundamental issues are associated with our quest for cross-lingual interoperability. We must make sure that the items of the basic lexicon are given the same interpretation. One measure taken to ensure this consists in constructing an upper-ontology based on the basic lexicon. Our preliminary work of mapping the Swadesh list items to SUMO (Suggested Upper Merged Ontology) (Niles and Pease, 2001) has already been completed. We are in the process of mapping the list to DOLCE (Descriptive Ontology for Linguistic and Cognitive Engineering) (Masolo et al., 2003). After the initial mapping, we carry on the work to restructure the mapped nodes to form a genuine conceptual ontology based on the language universal basic lexical items. However one important observation that we have made so far is that the success of the Swadesh list is partly due to its underspecification and to the liberty it gives to compilers of the list in a new language. If this idea of underspecification is essential for basic lexicon for human languages, then we must resolve this apparent dilemma of specifying them in a formal ontology that requires fully specified categories. For </context>
</contexts>
<marker>Masolo, Borgo, Gangemi, Guarino, Oltramari, 2003</marker>
<rawString>C. Masolo, A. Borgo, S.; Gangemi, N. Guarino, and A. Oltramari. 2003. Wonderweb deliverable d18 –ontology library (final)–. Technical report, Laboratory for Applied Ontology, ISTC-CNR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Towards a standard upper ontology.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001).</booktitle>
<contexts>
<context position="24231" citStr="Niles and Pease, 2001" startWordPosition="3884" endWordPosition="3887">resting question that has not been explored before. That is, does the Swadesh list instantiates a shared, fundamental human conceptual structure? And if there is such as a structure, can we discover it? In the project these fundamental issues are associated with our quest for cross-lingual interoperability. We must make sure that the items of the basic lexicon are given the same interpretation. One measure taken to ensure this consists in constructing an upper-ontology based on the basic lexicon. Our preliminary work of mapping the Swadesh list items to SUMO (Suggested Upper Merged Ontology) (Niles and Pease, 2001) has already been completed. We are in the process of mapping the list to DOLCE (Descriptive Ontology for Linguistic and Cognitive Engineering) (Masolo et al., 2003). After the initial mapping, we carry on the work to restructure the mapped nodes to form a genuine conceptual ontology based on the language universal basic lexical items. However one important observation that we have made so far is that the success of the Swadesh list is partly due to its underspecification and to the liberty it gives to compilers of the list in a new language. If this idea of underspecification is essential for</context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>I. Niles and A Pease. 2001. Towards a standard upper ontology. In Proceedings of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sornlertlamvanich</author>
<author>W Pantachat</author>
<author>S Meknavin</author>
</authors>
<title>Classifier assignment by corpusbased approach.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94),</booktitle>
<pages>556--561</pages>
<contexts>
<context position="10119" citStr="Sornlertlamvanich et al., 1994" startWordPosition="1553" endWordPosition="1556">of nouns, but use classifiers to denote the number of objects. The followings are examples of classifiers of Japanese. • inu ni hiki · · · two dogs (dog) (two) (CL) • hon go satsu · · · five books (book) (five) (CL) “CL” stands for a classifier. They always follow cardinal numbers in Japanese. Note that different classifiers are used for different nouns. In the above examples, classifier “hiki” is used to count noun “inu (dog)”, while “satsu” for “hon (book)”. The classifier is determined based on the semantic type of the noun. In the Thai language, classifiers are used in various situations (Sornlertlamvanich et al., 1994). The classifier plays an important role in construction with noun to express ordinal, pronoun, for instance. The classifier phrase is syntactically generated according to a specific pattern. Here are some usages of classifiers and their syntactic patterns. • Enumeration (Noun/Verb)-(cardinal number)-(CL) e.g. nakrian 3 khon · · · three students (student) (CL) • Ordinal (Noun)-(CL)-/thi:/-(cardinal number) e.g. kaew bai thi: 4 ··· the 4th glass (glass) (CL) (4th) • Determination (Noun)-(CL)-(Determiner) e.g. kruangkhidlek kruang nii (calculator) (CL) (this) · · · this calculator Classifiers co</context>
</contexts>
<marker>Sornlertlamvanich, Pantachat, Meknavin, 1994</marker>
<rawString>V. Sornlertlamvanich, W. Pantachat, and S. Meknavin. 1994. Classifier assignment by corpusbased approach. In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94), pages 556–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Swadesh</author>
</authors>
<title>Lexico-statistical dating of prehistoric ethnic contacts: With special reference to north American Indians and Eskimos.</title>
<date>1952</date>
<booktitle>In Proceedings of the American Philo-sophical Society,</booktitle>
<volume>96</volume>
<pages>452--463</pages>
<contexts>
<context position="18484" citStr="Swadesh, 1952" startWordPosition="2863" endWordPosition="2864">quency may vary greatly among different languages. The third issue involves lexical gaps. That is, if there is a word that meets all criteria of being a basic word in language A, yet it does not exist in language D (though it may exist in languages B, and C). Is this word still qualified to be included in the multilingual basic lexicon? It is clear not all the above issues can be unequivocally solved with the time frame of our project. Fortunately, there is an empirical core lexicon that we can adopt as a starting point. The Swadesh list was proposed by the historical linguist Morris Swadesh (Swadesh, 1952), and has been widely used by field and historical linguists for languages over the world. The Swadesh list was first proposed as lexico-statistical metrics. That is, these are words that can be reliably expected to occur in all historical languages and can be used as the metrics for quantifying language variations and language distance. The Swadesh list is also widely used by field linguists when they encounter a new language, since almost all of these terms can be expected to occur in any language. Note that the Swadesh list consists of terms that embody human direct experience, with culture</context>
</contexts>
<marker>Swadesh, 1952</marker>
<rawString>M. Swadesh. 1952. Lexico-statistical dating of prehistoric ethnic contacts: With special reference to north American Indians and Eskimos. In Proceedings of the American Philo-sophical Society, volume 96, pages 452–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>C Huang</author>
<author>S Yu</author>
</authors>
<title>Distributional consistency: A general method for defining a core lexicon.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC2004),</booktitle>
<pages>1119--1222</pages>
<contexts>
<context position="16862" citStr="Zhang et al., 2004" startWordPosition="2578" endWordPosition="2581">the set of postpositions as values of FunctionType instead of conventional function types such as “subj” and “obj”. It might be an user defined data category or language dependent data category. Furthermore, it is preferable to prepare the mapping between Japanese postpositions and conventional function types. This is interesting because it seems more a terminological difference, but the model can be applied also to Japanese. 4 Building sample lexicons 4.1 Swadesh list and basic lexicon The issue involved in defining a basic lexicon for a given language is more complicated than one may think (Zhang et al., 2004). The naive approach of simply taking the most frequent words in a language is flawed in many ways. First, all frequency counts are corpus-based and hence inherit the bias of corpus sampling. For instance, since it is easier to sample written formal texts, words used predominantly in informal contexts are usually underrepresented. Second, frequency of content words is topic-dependent and may vary from corpus to corpus. Last, and most crucially, frequency of a word does not correlate to its conceptual necessity, which should be an important, if not only, criteria for core lexicon. The definitio</context>
</contexts>
<marker>Zhang, Huang, Yu, 2004</marker>
<rawString>H. Zhang, C. Huang, and S. Yu. 2004. Distributional consistency: A general method for defining a core lexicon. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC2004), pages 1119–1222.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>