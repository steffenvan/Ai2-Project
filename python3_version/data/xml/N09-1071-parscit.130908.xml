<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000638">
<title confidence="0.997796">
A Finite-State Turn-Taking Model for Spoken Dialog Systems
</title>
<author confidence="0.988865">
Antoine Raux∗
</author>
<affiliation confidence="0.97968">
Honda Research Institute
</affiliation>
<address confidence="0.960669">
800 California Street
Mountain View, CA 94041, USA
</address>
<email confidence="0.998679">
araux@hra.com
</email>
<author confidence="0.988539">
Maxine Eskenazi
</author>
<affiliation confidence="0.874344333333333">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.999143">
max@cs.cmu.edu
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999864833333333">
This paper introduces the Finite-State Turn-
Taking Machine (FSTTM), a new model to
control the turn-taking behavior of conversa-
tional agents. Based on a non-deterministic
finite-state machine, the FSTTM uses a cost
matrix and decision theoretic principles to se-
lect a turn-taking action at any time. We show
how the model can be applied to the problem
of end-of-turn detection. Evaluation results on
a deployed spoken dialog system show that the
FSTTM provides significantly higher respon-
siveness than previous approaches.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999739722222222">
Turn-taking, the process by which participants in a
conversation alternate speech and silence, is an es-
sential component of spoken interaction. In order to
lead productive conversations, people need not only
know what to say but also when to say it. Decades
of research on Conversation Analysis and psycholin-
guistics (Duncan, 1972; Sacks et al., 1974; Ore-
str¨om, 1983; Schegloff, 2000; Wesseling and van
Son, 2005) have shown that human turn-taking be-
havior relies on a wide range of rules and signals
at many different levels of language, from prosody
to syntax, semantics, and discourse structure. In
contrast, turn-taking in spoken dialog systems is of-
ten reduced to ad hoc rules only based on very low
level features. This simplistic approach leads to in-
efficient, unnatural, and possibly confusing behavior
(Porzel and Baudis, 2004; Ward et al., 2005).
∗ This research was conducted when the first author was a
student at the Language Technologies Institute.
Recently, more complex models of turn-taking
have been proposed (Cassell et al., 2001; Thorisson,
2002; Kronild, 2006). Yet, these models still rely
extensively on hand-coded expert knowledge and
do not lend themselves to data-driven optimization.
Furthermore, to our knowledge, no such model has
been deployed in a widely used system outside of the
laboratory. In this paper, we propose a flexible, prac-
tical model of turn-taking behavior that builds upon
previous work on finite-state models of the conver-
sational floor. Because of its simplicity and gener-
ality, this model can be applied to many turn-taking
phenomena. At the same time, being grounded in
decision theory, it lends itself well to data-driven op-
timization. We illustrate our approach by applying
the model to a specific turn-taking task: end-of-turn
detection.
</bodyText>
<sectionHeader confidence="0.9957545" genericHeader="introduction">
2 Conversational Floor as a Finite-State
Machine
</sectionHeader>
<subsectionHeader confidence="0.982873">
2.1 6-state finite state models of turn-taking
</subsectionHeader>
<bodyText confidence="0.999985333333333">
In the 1960’s and early 1970’s, several researchers
proposed models to explain the rhythmic turn-taking
patterns in human conversation. In particular, Jaffe
and Feldstein (1970) studied the mean duration of
pauses, switching pauses (when a different speaker
takes the floor), simultaneous speech, and (single-
speaker) vocalizations in recorded dyadic conversa-
tions. Based on their observation that these dura-
tions follow exponential distributions, they proposed
first-order Markov models to capture the alterna-
tion of speech and silence in dialog. Their initial
model had four states: only participant A is speak-
</bodyText>
<page confidence="0.985143">
629
</page>
<note confidence="0.927402">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 629–637,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9580985">
Figure 1: Our six-state model of turn-taking, inspired by
Jaffe and Feldstein (1970) and Brady (1969). See section
</figureCaption>
<subsectionHeader confidence="0.827301">
3.1 for a description of the states.
</subsectionHeader>
<bodyText confidence="0.999984428571428">
ing; only participant B is speaking; both participants
are speaking; and neither participant is speaking.
However, such a model fails to distinguish switch-
ing pauses from A to B from switching pauses from
B to A. Based on this observation, they extend their
model to a six-state model which they found to bet-
ter fit their data than the four-state model. Around
the same time, Brady (1969) developed a very sim-
ilar six-state model. He trained the parameters on a
recorded conversation and compared the generated
conversations to the original real one along several
dimensions (pause and speech segment durations,
overlaps, etc), finding that his model generally pro-
duced a good fit of the data.
</bodyText>
<subsectionHeader confidence="0.997788">
2.2 Finite-State Models for Control
</subsectionHeader>
<bodyText confidence="0.999925068965517">
While Jaffe, Feldstein and Brady were primarily
concerned with the analysis of human-human con-
versations, more recently, several researchers have
proposed finite-state machines to control conversa-
tional agents. For instance, Cassell et al. (2001)
model the conversational state of an embodied real
estate agent as a 5-state machine. Two states indi-
cate whether a user is present or not, whereas the
other three indicate who holds the floor between the
user and the agent, or whether the floor is open.
Floor conflicts are not captured by this machine and
are presumably resolved through simple rules (e.g.
when the user speaks, the agent yields the floor).
Kronild (2006) proposes a much more complex
model, based on Harel statecharts, which are an ex-
tension of finite-state machines for modeling and vi-
sualizing abstract control (Harel, 1987).
Thorisson’s Ymir architecture (Thorisson, 2002)
is an attempt to model the cognitive processes in-
volved in conversation. It features dialog states, cap-
turing, for example, who has the floor, and rules that
govern the transition from one state to another based
on ”boolean conditions of perceptual features”.
All these models are deterministic. At any point
in time, the agent knows who owns the floor and uses
fixed rules to take appropriate actions. These ap-
proaches assume 1) that the system can obtain per-
fectly reliable information on the state of the world,
and 2) that the state itself is unambiguous.
</bodyText>
<sectionHeader confidence="0.97478" genericHeader="method">
3 The Finite-State Turn-Taking Machine
</sectionHeader>
<subsectionHeader confidence="0.999107">
3.1 Extending the 6-state model for control
</subsectionHeader>
<bodyText confidence="0.999935928571429">
Our model, the Finite-State Turn-Taking Machine
(FSTTM), uses the same six states as Jaffe and
Feldstein: USER and SYSTEM represent states
where one and only one of the participants claims
the floor, FREES and FREEU states where no
participant claims the floor (following, resp., a
SYSTEM and USER state), and BOTHS and
BOTHU states where both participants claim the
floor (following, resp. a SYSTEM and USER
state). However, we apply this model to the control
of a conversational agent, with a goal similar to that
of Cassel, Thorisson, and Kronild. One important
distinction is that we define the states in terms of the
participants’ intentions and obligations (in the sense
of Traum and Allen (1994)) rather than the surface
level observation of speech vs silence. For example,
the state is USER when the user has the obligation
to speak (to respond to a system question) or the in-
tention to speak, while at the same time, the system
does not hold the floor. This does not necessarily
mean that the user is speaking, for example at pauses
during a user utterance.
As can be seen in Figure 1, not all transitions are
valid. First, there is no direct transition between any
of the intermediate states (the two FREE states and
two BOTH states). The assumption is that to go
from any of these state to another, the model will
first go to either SYSTEM or USER. This is an
</bodyText>
<page confidence="0.995555">
630
</page>
<bodyText confidence="0.999988218750001">
approximation as there might be cases where, for
example, both the system and user start speaking
at the exact same time, going from a FREE state
to a BOTH state. However these cases are rare
enough that they can be approximated using a tran-
sition through either SYSTEM or USER. Sec-
ond, because intermediate states are conditioned on
who had the floor previously, not all valid transitions
are bidirectional. For example, there is no transi-
tion from SYSTEM to BOTHU. We associate
pairs of user/system actions to each transition. The
four possible actions are Grab the floor, Release the
floor, Wait while not claiming the floor, and Keep
the floor. For example, transition from SYSTEM
to FREES corresponds to the user waiting silently
and the system releasing the floor at the end of a
prompt, noted (R, W) (we always note the system
action first and user action second).
This representation allows us to formalize a wide
variety of turn-taking phenomena in a unified frame-
work. Specifically, there are 4 types of 2-step transi-
tions from a single-floor-holder state (SYSTEM or
USER) to another (or the same) single-floor-holder
state, which represent typical turn-taking phenom-
ena:
Turn transitions with gap are the most common
way the floor goes from one participant to the
other. For example, at the end of a user utter-
ance, once the user finishes speaking, the floor
becomes free, after which the system starts re-
sponding, thus grabbing the floor. The resulting
state sequence is:
</bodyText>
<equation confidence="0.82531">
SYSTEM (R,W ) (W,G)
→ FREES → USER
</equation>
<bodyText confidence="0.965433">
Conversely, the transition with gap following a
system prompt corresponds to:
</bodyText>
<equation confidence="0.6977575">
USER (R,W ) (W,G
→ FREES → USER
</equation>
<bodyText confidence="0.999448">
Turn transitions with overlap happen when a par-
ticipant grabs the floor while it still belongs to
the other. For example, when a user barges in
on a system prompt, both participants hold the
floor. Then, the system recognizes the barge-
in attempt and relinquishes the floor, which be-
comes user’s.
</bodyText>
<equation confidence="0.3923245">
SYSTEM (K,G) (R,K
→ BOTHS → USER
</equation>
<bodyText confidence="0.9981706">
And conversely, when the system interrupts the
user mid-utterance (which in dialog systems is
more often the result of an intentional cut-in,
rather than intentional interruption), the state
sequence is:
</bodyText>
<equation confidence="0.8433695">
USER (G,K) (K,R)
→ BOTHU → SY STEM
</equation>
<bodyText confidence="0.995972333333333">
Failed interruptions happen when a participant
barges in on the other and then withdraws be-
fore the original floor holder releases the floor.
For example, when the system interrupts the
user (often by mistake) but detects it and in-
terrupts itself:
</bodyText>
<equation confidence="0.793201">
USER (G,K) (R,K
→ BOTHU → USER
</equation>
<bodyText confidence="0.976774">
The converse is usually the result of the system
failing to react fast enough to a user barge-in:
</bodyText>
<equation confidence="0.7642">
SYSTEM (K,G) (K,R)
→ BOTHS → SY STEM
</equation>
<bodyText confidence="0.999675933333334">
Note that backchannels seem to fit in this cat-
egory too. However, since backchannels, by
definition, do not represent an attempt to grab
the floor, they are not captured by the model
as it is (for example, the floor should remain
SYSTEM when a user backchannels a sys-
tem utterance).
Time outs start like transitions with gap but the in-
tended next speaker (e.g. the user after a system
prompt) does not take the floor and the original
floor holder grabs it back. For instance, after a
system prompt, if the floor remains free for a
certain amount of time, the system attempts to
re-establish the communication with the user,
as follows:
</bodyText>
<equation confidence="0.884386">
SYSTEM (R,W ) (G,W
→ F REES → SYSTEM
</equation>
<bodyText confidence="0.9981285">
The opposite also happens when the system is
to slow to respond to the user:
</bodyText>
<equation confidence="0.4190445">
USER (W,R) (W,G
→ FREEU → USER
</equation>
<bodyText confidence="0.998868666666667">
While all the transitions above were described
as deterministic, the actual state of the model is
not fully observable. Specifically, while the system
</bodyText>
<page confidence="0.993736">
631
</page>
<bodyText confidence="0.999912444444444">
knows whether its claiming the floor or not, it can
only believe with some degree of uncertainty that
the user does so. The system’s knowledge of its own
claim to the floor splits the state space into two dis-
joint subsets. When the system claims the floor, the
state can be SYSTEM, BOTHS, or BOTHU).
When the system does not claim the floor, the state
can be USER, FREEU, or FREES). In either
case, the system needs to recognize the user’s in-
tention (i.e. whether the user claims to the floor or
not) to maintain a probability distribution over the
three states. Since the distinction between the two
BOTH states (resp. the two FREE states) is based
on past history that can be known with a high level
of certainty, the uncertainty in state distribution is
fully characterized by the probability that the user is
claiming the floor, which will have to be estimated
from observations, as we will see below.
</bodyText>
<subsectionHeader confidence="0.999717">
3.2 Cost of Turn-Taking Actions
</subsectionHeader>
<bodyText confidence="0.99961185">
The problem we are facing is that of choosing the
best system action given the system’s belief about
the current state of the model. That is achieved by
applying the probabilistic decision theory principle
of selecting the action with lowest expected cost.
The actions available to the system are the four de-
scribed above (G,R,K,W), although not all actions
are available in all states. In fact, as can be seen in
Table 1, there are always only two actions available
in each state, depending on whether the system is
claiming the floor or not.
Each action in each state has a particular cost.
While there are many possible ways of defining
these costs, we propose a simple cost structure that
derives from the principles laid out in Sacks et al.
(1974):
3. The cost of an action that maintains a gap or
overlap is either a constant or an increasing
function of the total time spent in that state
The resulting cost matrix is shown in Table 1, where
</bodyText>
<listItem confidence="0.997155777777778">
• CS is the cost of interrupting a system prompt
before its end when the user is not claiming the
floor (false interruption)
• CO(τ) is the cost of remaining in an overlap
that is already τ ms long
• CU is the cost of grabbing the floor when the
user is holding it (cut-in)
• CG(τ) is the cost of remaining in a gap that is
already τ ms long
</listItem>
<bodyText confidence="0.999894">
This cost structure makes a number of simplifying
assumptions and there are many other possible cost
matrices. For example, the cost of interrupting the
user might vary depending on what has already been
said in the utterance, so does the cost of interrupt-
ing a system prompt. A more principled approach
to setting the costs would be to estimate from per-
ceptual experiments or user studies what the impact
of remaining in gap or overlap is compared to that
of a cut-in or false interruption. However, as a first
approximation, the proposed cost structure offers a
simple way to take into account some of the con-
straints of interaction.
</bodyText>
<subsectionHeader confidence="0.997266">
3.3 Decision Theoretic Action Selection
</subsectionHeader>
<bodyText confidence="0.99997625">
Given the state space and the cost matrix given
above, the optimal decision at any point in time is
the one that yields the lowest expected cost, where
the expected cost of action A is:
</bodyText>
<equation confidence="0.9426605">
C(A) = � P(s = S|O) · C(A, S)
S∈Σ
</equation>
<bodyText confidence="0.99656875">
Participants in a conversation attempt to
minimize gaps and overlaps.
From this general principle, we derive three rules to
drive the design of a cost matrix:
</bodyText>
<listItem confidence="0.9423766">
1. The cost of an action that resolves either a gap
or an overlap is zero
2. The cost of an action that creates unwanted gap
or overlap is equal to a constant parameter (po-
tentially different for each action/state pair)
</listItem>
<bodyText confidence="0.959089272727273">
where E is the set of states, O are the observable
features of the world, and C(A, S) is the cost of ac-
tion A in state S, from the cost matrix in Table 1.
In addition to the cost matrix’ four constants, which
we will consider as parameters of the model, it is
thus necessary to estimate P(s = S|O), which as
seen above amounts to estimate the probability that
the user is claiming the floor. Key to applying the
FSTTM to a practical turn-taking problem is thus
the construction of accurate estimates of the proba-
bilities P(s = S|O).
</bodyText>
<page confidence="0.973959">
632
</page>
<table confidence="0.999958555555556">
Action K R W G
��������
State
SYSTEM 0 CS - -
BOTHS CO(T) 0 - -
BOTHU CO(T) 0 - -
USER - - 0 CU
FREEU - - CG(T) 0
FREES - - CG(T) 0
</table>
<tableCaption confidence="0.9924825">
Table 1: Cost of system actions in each state (K: keep the floor, R: release the floor, W: wait without the floor, G:
grab the floor, T: time spent in current state, -: action unavailable).
</tableCaption>
<sectionHeader confidence="0.798354" genericHeader="method">
4 Endpointing with the FSTTM
</sectionHeader>
<subsectionHeader confidence="0.931988">
4.1 Problem formalization
</subsectionHeader>
<bodyText confidence="0.99917525">
In our FSTTM formalism, endpointing is the prob-
lem of selecting between the Wait and the Grab ac-
tions during a user utterance. We make the simplify-
ing assumption that, once a user utterance has been
detected, the only states with non-zero probability
are USER and FREEU. While this does not cap-
ture cases where the system erroneously detects user
speech (because there is, for example, background
noise), it represents a working first approximation
of the problem.
The main issue is to estimate the probability
P(s = FREEU|Ot) (hereafter abbreviated as
P(F|Ot), P(s = USER|Ot) being abbreviated as
P(U|Ot)) where Ot represents all observable fea-
tures at time t. Given that probability, the expected
cost of grabbing the floor is:
</bodyText>
<equation confidence="0.95496425">
C(G|Ot) = P(U|Ot) · CU + P(F|Ot) · 0
= (1 − P(F|Ot)) · CU
Similarly, the expected cost of waiting is:
C(W |Ot) = P(F |Ot) · CG(T)
</equation>
<bodyText confidence="0.999865">
The system endpoints whenever the expected cost
of grabbing the floor becomes higher than that of
waiting.
We consider two separate cases for computing
both P(F|Ot) and CG(T): when a pause has been
detected by the voice activity detector (VAD), and
when no pause has been detected (yet). In the fol-
lowing sections, we provide details on the approxi-
mations and estimation methods for these two cases.
</bodyText>
<subsectionHeader confidence="0.997975">
4.2 At pauses
</subsectionHeader>
<bodyText confidence="0.999943470588235">
If a pause has been detected by the VAD, we set
the cost of waiting in the FREEU state to be pro-
portional to the duration of the pause so far. If the
user has released the floor, the duration of the current
pause corresponds to the time spent in the FREEU
state, i.e. T in the cost matrix of Table 1. In this case,
we set CG(T) = CpG · T as a simple application of
rule 3 from section 3.2.
We decompose the observations at time t, Ot, into
observations available at the start of the pause (O),
and observations made during the pause. With only
audio information available, the only information
available during the pause is its duration so far, i.e.
T. Specifically, we know that d ≥ T, where d is the
total duration of the pause (with d = ∞ at the end
of a turn1). Consequently, P(F|Ot) can be rewritten
using Bayes rule as
</bodyText>
<equation confidence="0.9984562">
P(d ≥ T|O, F) · P(F|O)
P(F|Ot) =
P(d ≥ T|O)
P(F|O)
P(d ≥ T|O)
</equation>
<bodyText confidence="0.9985946">
where P(F|O) is the probability that the user re-
leased the floor without any knowledge of the dura-
tion of the pause, and P(d ≥ T|O) is the probability
that the pause will last at least T ms. We further de-
compose P(d ≥ T|O) into
</bodyText>
<equation confidence="0.628896">
P(d ≥ T|O) = P(d ≥ T, U|O) + P(d ≥ T, F|O)
</equation>
<bodyText confidence="0.977453">
1Note that this is an approximation since the user could start
speaking again after releasing the floor to reestablish the chan-
nel (e.g. by saying ”Hello?”). However, in the vast majority of
cases, the time after which the user resumes speaking is signifi-
cantly longer than the time the system takes to endpoint.
</bodyText>
<page confidence="0.961876">
633
</page>
<equation confidence="0.99311425">
= P(d ≥ τ|O, U) · P(U|O) +
P(d ≥ τ|O, F) · P(F|O)
= P(d ≥ τ|O, U) · (1 − P(F|O))
+P(F|O)
</equation>
<bodyText confidence="0.981880181818182">
Consequently, P(F|Ot) is a function of P(F|O)
and P(d ≥ τ|O, U). We estimate P(F|O) by step-
wise logistic regression on a training set of pauses
labeled for finality (whether the pause is turn-final or
turn-internal), using a wide range of features avail-
able from various components of the dialog system.
Based on the well established observation that pause
durations follow an exponential distribution (Jaffe
and Feldstein, 1970; Lennes and Anttila, 2002; Raux
et al., 2008), P(d ≥ τ|O, U) is a function of mean
pause duration, computed on the training set.
</bodyText>
<subsectionHeader confidence="0.997447">
4.3 In speech
</subsectionHeader>
<bodyText confidence="0.999990529411765">
In some cases, it is not necessary to wait for the VAD
to detect a pause to know with high confidence that
the user has released the floor. For example, after a
simple yes/no question, if the user says ”YES”, they
are very likely to have released the floor, regardless
of how long they remain silent afterwards. In order
to exploit this fact and improve the responsiveness
of the system in these highly predictable cases, we
use a separate model to compute the expected costs
of waiting and grabbing the floor before any pause is
detected by the VAD (specifically, whenever the du-
ration of the current pause is between 0 and 200 ms).
In this case, we set the cost of waiting to a constant
CsG. We train a logistic regression model to estimate
P(F|Ot) each time a new partial hypothesis is pro-
duced by the ASR during a user utterance. We use
the same set of features as above.
</bodyText>
<sectionHeader confidence="0.999176" genericHeader="method">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999818">
5.1 Corpus and Features
</subsectionHeader>
<bodyText confidence="0.9999574375">
We evaluated the effectiveness of the FSTTM on
an actual deployed spoken dialog system. The sys-
tem provides bus schedule information for a mid-
size North American city. It is actually used by the
general public and therefore constantly operates and
collects data. In order to train the various proba-
bility estimation models and evaluate the approach
in batch, we first collected a corpus of 586 dialogs
between May 4, and May 14, 2008 (the ”2008 cor-
pus”).
All of the features we used can be automatically
extracted at runtime, and most of them were readily
available in the system. They include dialog state in-
formation, turn-taking features, such as whether the
current user utterance is a barge-in, and semantic
information derived from the dialog state and par-
tial recognition hypotheses provided by the speech
recognizer. Dialog state is abstracted to three high-
level states, which correspond to the type of system
prompt directly preceding the user utterance: Open
question (”What can I do for you?”); Closed ques-
tion (e.g. ”Where do you want to go?”); and Confir-
mation (e.g. ”Going to the airport. Is this correct?”).
To capture lexical cues correlated with the end of
turns, we created a new feature called the boundary
LM score. To compute it, we used previously col-
lected data to train dialog-state-dependent statistical
language models to estimate the probability that the
hypothesis is complete. Boundary LM score is de-
fined as the ratio of the log likelihood of the hypoth-
esis being complete by that of the hypothesis being
incomplete.
</bodyText>
<subsectionHeader confidence="0.997691">
5.2 Estimating P(F|Ot)
</subsectionHeader>
<bodyText confidence="0.999922181818182">
We trained two logistic regression models using
stepwise regression and 10-fold cross-validation for
evaluation. The first model, whose performance
is given in Table 2, estimates P(F|O) at pauses.
The model is unable to improve classification accu-
racy over the majority baseline for each state, how-
ever, the statistically significant improvement in av-
erage log likelihood indicates that the probability
estimates are improved by using the features. The
most informative feature in all three states was the
boundary LM score introduced in section 5.1. Other
selected features included the average number of
words per user utterance so far and whether the cur-
rent utterance is a barge-in (for the Open and Closed
question states), as well as whether the partial hy-
pothesis contained a confirmation marker such as
”YES” or ”SURE” (for the Confirmation state).
The second model performs the same regression,
this time on all partial hypotheses received during
speech segments. As seen in the ”S” columns in Ta-
ble 2, classification error was significantly reduced
and the gain in average log likelihood were larger
</bodyText>
<page confidence="0.996839">
634
</page>
<table confidence="0.999865">
Open question Closed question Confirmation
P S P S P S
Majority Baseline 38% 20% 25% 32% 12% 36%
Classification Error 35% 17% 26% 22% 12% 17%
Baseline log likelihood -0.66 -0.50 -0.56 -0.63 -0.36 -0.65
Log likelihood -0.61 -0.40 -0.50 -0.49 -0.30 -0.40
</table>
<tableCaption confidence="0.999456">
Table 2: Performance of state-specific logistic regression for estimating P(FJO) at pauses (P) and in speech (S).
</tableCaption>
<figure confidence="0.826205">
(a) In-pause evaluation on the 2007 corpus. (a) Anytime evaluation on the 2008 corpus.
</figure>
<figureCaption confidence="0.997318">
Figure 2: Batch evaluation of FSTTM endpointing.
</figureCaption>
<bodyText confidence="0.998021166666667">
than at pauses, particularly for the ”Closed ques-
tion” and ”Confirmation” states. Again, boundary
LM score was the most informative feature. The
duration of the pause at the end of the partial hy-
pothesis (between 0 and 200 ms) also proved well
correlated with finality.
</bodyText>
<subsectionHeader confidence="0.99862">
5.3 Batch Evaluation of the FSTTM
</subsectionHeader>
<bodyText confidence="0.999995678571429">
We performed two batch evaluations of the FSTTM.
The first one aims at comparing in-pause-FSTTM
with a fixed-threshold baseline as well as previous
data-driven endpointing methods proposed in Ferrer
et al. (2003) (reimplemented by us) and Raux et al.
(2008). This evaluation was done on the corpus used
in Raux et al. (2008) (the ”2007 corpus”). As seen
in Figure 2 (a), the FSTTM outperforms all other ap-
proaches (albeit only slightly compared to Ferrer et
al.), improving over the fixed threshold baseline by
up to 29.5%.
Second, we compared the anytime-FSTTM with
in-pause-FSTTM and a fixed-threshold baseline (for
reference) on the more recent 2008 corpus (since the
2007 corpus did not contain all necessary features
for anytime-FSTTM). We set CG = 1 and set CG
to either 0, leading to an endpointer that never end-
points during speech (in-pause-FSTTM), or 1000
(anytime-FSTTM). In both cases, we vary CU to
compute the latency / cut-in rate trade-off curve.
The results are shown in Figure 2 (b). Anytime-
FSTTM endpointing is consistently better than in-
pause-FSTTM. For example, at a cut-in rate of 5%,
anytime-FSTTM yields latencies that are on average
17% shorter than in-pause-FSTTM, and 40% shorter
than the baseline. Additionally, we found that, in
anytime-FSTTM, 30 to 40% of the turns are end-
pointed before the pause is detected by the VAD.
</bodyText>
<subsectionHeader confidence="0.98035">
5.4 Live Evaluation
</subsectionHeader>
<bodyText confidence="0.999293833333334">
To confirm the results of the batch evaluation, we
implemented our FSTTM model in the deployed
system a let it run for ten days using either FSTTM
or a fixed threshold for endpointing, resulting in
a corpus of 171 FSTTM and 148 control dialogs.
For FSTTM, we set CG = 1, CG = 500, and
CU = 5000. In the batch evaluation, these values
correspond to a cut-in rate of 6.3% and an average
latency of 320 ms. For the control condition, we
set the fixed endpointing threshold to 555 ms, which
also corresponded to about 6.3% cut-ins.
Figure 3 shows the average latency and cut-in rate
</bodyText>
<page confidence="0.99135">
635
</page>
<figure confidence="0.999186">
(a) Latency (b) Cut-in rates
</figure>
<figureCaption confidence="0.999677">
Figure 3: Live evaluation results. All confidence intervals for latency (not shown on the figure) fall within +/ − 4ms.
</figureCaption>
<bodyText confidence="0.9354725">
for both conditions. The FSTTM improves over the
baseline on all metrics, reducing average latency by
193 ms (p &lt; 0.05), cut-in rate by 1.5% (although
this result is not statistically significant).
</bodyText>
<sectionHeader confidence="0.999826" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999980166666667">
Both batch and live evaluation results confirm the
effectiveness of the FSTTM approach in improv-
ing system responsiveness. This approach signif-
icantly reduced endpointing latency over previous
approaches. Boundary LM score got the highest
weight in the regression, indicating that in a domain
such as telephone-based information access, lexical
cues are very informative for endpointing. The fact
that boundary LMs can be computed without any hu-
man transcription effort (since they are trained on
ASR output) makes them all the more appealing.
Essentially, the FSTTM provides a simple, unified
model of turn-taking that lends itself to data-driven
optimization. While we discussed specific cost
structures and probability estimation techniques, the
framework’s flexibility opens it to other choices at
many levels. By formalizing the overall turn-taking
process in a probabilistic, decision-theoretic frame-
work, the FSTTM extends and generalizes previous
classification-based approaches to endpointing such
as those proposed by Sato et al. (2002), Ferrer et
al. (2003), Takeuchi et al. (2004), and our previous
work (Raux et al., 2008).
Possible extensions of the approach include data-
driven cost matrices to relax some of the assump-
tions introduced in section 3.2, as well as more com-
plex state structures to handle, for example, multi-
party conversations.
Finally, we plan to investigate more principled ap-
proaches, such as Partially Observable Markov De-
cision Processes or Dynamic Bayesian Networks, to
model the different sources of uncertainty (detection
errors and inherent ambiguity) and track the state
distribution over time. Raux (2009) provides more
details on all aspects of the approach and its possi-
ble extensions.
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999865">
In this paper, motivated by existing finite-state mod-
els of turn-taking in dyadic conversations, we pro-
pose the Finite-State Turn-Taking Machine, an ap-
proach to turn-taking that relies on three core ele-
ments: a non-deterministic finite-state machine that
captures the conversational floor; a cost matrix that
models the impact of different system actions in dif-
ferent states; and a decision-theoretic action selec-
tion mechanism. We describe the application of the
FSTTM to the key turn-taking phenomenon of end-
of-turn detection. Evaluation both offline and by
applying the FSTTM to a deployed spoken dialog
system system showed that it performs significantly
better than a fixed-threshold baseline.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999828571428571">
This work is supported by the US National Science
Foundation under grant number 0208835. Any opin-
ions, findings, and conclusions or recommendations
expressed in this material are those of the authors
and do not necessarily reflect the views of the NSF.
We would like to thank Alan Black for his many
comments and advice.
</bodyText>
<page confidence="0.99872">
636
</page>
<sectionHeader confidence="0.99589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999766029411764">
P. T. Brady. 1969. A model for generating on-off speech
patterns in two-way conversation. The Bell System
Technical Journal, 48:2445–2472.
J. Cassell, T. Bickmore, L. Campbell, H. Vilhjalmsson,
and H. Yan. 2001. More than just a pretty face: con-
versational protocols and the affordances of embodi-
ment. Knowledge-Based Systems, 14:55–64.
S. Duncan. 1972. Some signals and rules for taking
speaking turns in conversations. Journal of Person-
ality and Social Psychology, 23(2):283–292.
L. Ferrer, E. Shriberg, and A. Stolcke. 2003. A prosody-
based approach to end-of-utterance detection that does
not require speech recognition. In ICASSP, Hong
Kong.
D. Harel. 1987. Statecharts: A visual formalism for
complex systems. Science of Computer Programming,
8:231–274.
J. Jaffe and S. Feldstein. 1970. Rhythms of Dialogue.
Academic Press.
F. Kronild. 2006. Turn taking for artificial conversational
agents. In Cooperative Information Agents X, Edin-
burgh, UK.
Mietta Lennes and Hanna Anttila. 2002. Prosodic fea-
tures associated with the distribution of turns in finnish
informal dialogues. In Petri Korhonen, editor, The
Phonetics Symposium 2002, volume Report 67, pages
149–158. Laboratory of Acoustics and Audio Signal
Processing, Helsinki University of Technology.
B. Orestr¨om. 1983. Turn-Taking in English Conversa-
tion. CWK Gleerup, Lund.
R. Porzel and M. Baudis. 2004. The tao of chi:
Towards effective human-computer interaction. In
HLT/NAACL 2004, Boston, MA.
A. Raux, , and M. Eskenazi. 2008. Optimizing endpoint-
ing thresholds using dialogue features in a spoken dia-
logue system. In Proc. SIGdial 2008, Columbus, OH,
USA.
A. Raux. 2009. Flexible Turn-Taking for Spoken Dialog
Systems. Ph.D. thesis, Carnegie Mellon University.
H. Sacks, E. A. Schegloff, and G. Jefferson. 1974.
A simplest systematics for the organization of turn-
taking for conversation. Language, 50(4):696–735.
R. Sato, R. Higashinaka, M. Tamoto, M. Nakano, and
K. Aikawa. 2002. Learning decision trees to deter-
mine turn-taking by spoken dialogue systems. In IC-
SLP 2002, Denver, CO.
E.A. Schegloff. 2000. Overlapping talk and the orga-
nization of turn-taking for conversation. Language in
Society, 29:1–63.
M. Takeuchi, N. Kitaoka, and S. Nakagawa. 2004.
Timing detection for realtime dialog systems using
prosodic and linguistic information. In Proc. Speech
Prosody 04, Nara, Japan.
K. R. Thorisson, 2002. Multimodality in Language and
Speech Systems, chapter Natural Turn-Taking Needs
No Manual: Computational Theory and Model, From
Perception to Action, pages 173–207. Kluwer Aca-
demic Publishers.
D. R. Traum and J. F. Allen. 1994. Discourse obligations
in dialogue. In Proc. ACL-94, pages 1–8.
N. Ward, A. Rivera, K. Ward, and D. Novick. 2005. Root
causes of lost time and user stress in a simple dialog
system. In Interspeech 2005, Lisbon, Portugal.
W. Wesseling and R.J.J.H. van Son. 2005. Timing of
experimentally elicited minimal responses as quanti-
tative evidence for the use of intonation in projecting
TRPs. In Interspeech 2005, pages 3389–3392, Lisbon,
Portugal.
</reference>
<page confidence="0.997824">
637
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.237476">
<title confidence="0.995325">A Finite-State Turn-Taking Model for Spoken Dialog Systems</title>
<affiliation confidence="0.965335">Honda Research</affiliation>
<address confidence="0.998711">800 California Mountain View, CA 94041,</address>
<email confidence="0.998715">araux@hra.com</email>
<title confidence="0.3800955">Maxine Language Technologies</title>
<affiliation confidence="0.970794">Carnegie Mellon</affiliation>
<address confidence="0.850441">Pittsburgh, PA 15213,</address>
<email confidence="0.998555">max@cs.cmu.edu</email>
<abstract confidence="0.999038923076923">This paper introduces the Finite-State Turn- Taking Machine (FSTTM), a new model to control the turn-taking behavior of conversational agents. Based on a non-deterministic finite-state machine, the FSTTM uses a cost matrix and decision theoretic principles to select a turn-taking action at any time. We show how the model can be applied to the problem of end-of-turn detection. Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P T Brady</author>
</authors>
<title>A model for generating on-off speech patterns in two-way conversation.</title>
<date>1969</date>
<booktitle>The Bell System Technical Journal,</booktitle>
<pages>48--2445</pages>
<contexts>
<context position="3622" citStr="Brady (1969)" startWordPosition="545" endWordPosition="546"> and (singlespeaker) vocalizations in recorded dyadic conversations. Based on their observation that these durations follow exponential distributions, they proposed first-order Markov models to capture the alternation of speech and silence in dialog. Their initial model had four states: only participant A is speak629 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 629–637, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Figure 1: Our six-state model of turn-taking, inspired by Jaffe and Feldstein (1970) and Brady (1969). See section 3.1 for a description of the states. ing; only participant B is speaking; both participants are speaking; and neither participant is speaking. However, such a model fails to distinguish switching pauses from A to B from switching pauses from B to A. Based on this observation, they extend their model to a six-state model which they found to better fit their data than the four-state model. Around the same time, Brady (1969) developed a very similar six-state model. He trained the parameters on a recorded conversation and compared the generated conversations to the original real one</context>
</contexts>
<marker>Brady, 1969</marker>
<rawString>P. T. Brady. 1969. A model for generating on-off speech patterns in two-way conversation. The Bell System Technical Journal, 48:2445–2472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>T Bickmore</author>
<author>L Campbell</author>
<author>H Vilhjalmsson</author>
<author>H Yan</author>
</authors>
<title>More than just a pretty face: conversational protocols and the affordances of embodiment. Knowledge-Based Systems,</title>
<date>2001</date>
<pages>14--55</pages>
<contexts>
<context position="1874" citStr="Cassell et al., 2001" startWordPosition="282" endWordPosition="285">t human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work on finite-state models of the conversational floor. Because of its simplicity and generality, this model can be applied to many turn-taking phenomena. At the same time, being grounded in decision theory, it lends i</context>
<context position="4649" citStr="Cassell et al. (2001)" startWordPosition="706" endWordPosition="709">round the same time, Brady (1969) developed a very similar six-state model. He trained the parameters on a recorded conversation and compared the generated conversations to the original real one along several dimensions (pause and speech segment durations, overlaps, etc), finding that his model generally produced a good fit of the data. 2.2 Finite-State Models for Control While Jaffe, Feldstein and Brady were primarily concerned with the analysis of human-human conversations, more recently, several researchers have proposed finite-state machines to control conversational agents. For instance, Cassell et al. (2001) model the conversational state of an embodied real estate agent as a 5-state machine. Two states indicate whether a user is present or not, whereas the other three indicate who holds the floor between the user and the agent, or whether the floor is open. Floor conflicts are not captured by this machine and are presumably resolved through simple rules (e.g. when the user speaks, the agent yields the floor). Kronild (2006) proposes a much more complex model, based on Harel statecharts, which are an extension of finite-state machines for modeling and visualizing abstract control (Harel, 1987). T</context>
</contexts>
<marker>Cassell, Bickmore, Campbell, Vilhjalmsson, Yan, 2001</marker>
<rawString>J. Cassell, T. Bickmore, L. Campbell, H. Vilhjalmsson, and H. Yan. 2001. More than just a pretty face: conversational protocols and the affordances of embodiment. Knowledge-Based Systems, 14:55–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Duncan</author>
</authors>
<title>Some signals and rules for taking speaking turns in conversations.</title>
<date>1972</date>
<journal>Journal of Personality and Social Psychology,</journal>
<volume>23</volume>
<issue>2</issue>
<contexts>
<context position="1155" citStr="Duncan, 1972" startWordPosition="168" endWordPosition="169">to select a turn-taking action at any time. We show how the model can be applied to the problem of end-of-turn detection. Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches. 1 Introduction Turn-taking, the process by which participants in a conversation alternate speech and silence, is an essential component of spoken interaction. In order to lead productive conversations, people need not only know what to say but also when to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the</context>
</contexts>
<marker>Duncan, 1972</marker>
<rawString>S. Duncan. 1972. Some signals and rules for taking speaking turns in conversations. Journal of Personality and Social Psychology, 23(2):283–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ferrer</author>
<author>E Shriberg</author>
<author>A Stolcke</author>
</authors>
<title>A prosodybased approach to end-of-utterance detection that does not require speech recognition.</title>
<date>2003</date>
<booktitle>In ICASSP, Hong Kong.</booktitle>
<contexts>
<context position="23305" citStr="Ferrer et al. (2003)" startWordPosition="3978" endWordPosition="3981">007 corpus. (a) Anytime evaluation on the 2008 corpus. Figure 2: Batch evaluation of FSTTM endpointing. than at pauses, particularly for the ”Closed question” and ”Confirmation” states. Again, boundary LM score was the most informative feature. The duration of the pause at the end of the partial hypothesis (between 0 and 200 ms) also proved well correlated with finality. 5.3 Batch Evaluation of the FSTTM We performed two batch evaluations of the FSTTM. The first one aims at comparing in-pause-FSTTM with a fixed-threshold baseline as well as previous data-driven endpointing methods proposed in Ferrer et al. (2003) (reimplemented by us) and Raux et al. (2008). This evaluation was done on the corpus used in Raux et al. (2008) (the ”2007 corpus”). As seen in Figure 2 (a), the FSTTM outperforms all other approaches (albeit only slightly compared to Ferrer et al.), improving over the fixed threshold baseline by up to 29.5%. Second, we compared the anytime-FSTTM with in-pause-FSTTM and a fixed-threshold baseline (for reference) on the more recent 2008 corpus (since the 2007 corpus did not contain all necessary features for anytime-FSTTM). We set CG = 1 and set CG to either 0, leading to an endpointer that ne</context>
<context position="26476" citStr="Ferrer et al. (2003)" startWordPosition="4493" endWordPosition="4496"> transcription effort (since they are trained on ASR output) makes them all the more appealing. Essentially, the FSTTM provides a simple, unified model of turn-taking that lends itself to data-driven optimization. While we discussed specific cost structures and probability estimation techniques, the framework’s flexibility opens it to other choices at many levels. By formalizing the overall turn-taking process in a probabilistic, decision-theoretic framework, the FSTTM extends and generalizes previous classification-based approaches to endpointing such as those proposed by Sato et al. (2002), Ferrer et al. (2003), Takeuchi et al. (2004), and our previous work (Raux et al., 2008). Possible extensions of the approach include datadriven cost matrices to relax some of the assumptions introduced in section 3.2, as well as more complex state structures to handle, for example, multiparty conversations. Finally, we plan to investigate more principled approaches, such as Partially Observable Markov Decision Processes or Dynamic Bayesian Networks, to model the different sources of uncertainty (detection errors and inherent ambiguity) and track the state distribution over time. Raux (2009) provides more details </context>
</contexts>
<marker>Ferrer, Shriberg, Stolcke, 2003</marker>
<rawString>L. Ferrer, E. Shriberg, and A. Stolcke. 2003. A prosodybased approach to end-of-utterance detection that does not require speech recognition. In ICASSP, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Harel</author>
</authors>
<title>Statecharts: A visual formalism for complex systems.</title>
<date>1987</date>
<journal>Science of Computer Programming,</journal>
<pages>8--231</pages>
<contexts>
<context position="5246" citStr="Harel, 1987" startWordPosition="808" endWordPosition="809">l et al. (2001) model the conversational state of an embodied real estate agent as a 5-state machine. Two states indicate whether a user is present or not, whereas the other three indicate who holds the floor between the user and the agent, or whether the floor is open. Floor conflicts are not captured by this machine and are presumably resolved through simple rules (e.g. when the user speaks, the agent yields the floor). Kronild (2006) proposes a much more complex model, based on Harel statecharts, which are an extension of finite-state machines for modeling and visualizing abstract control (Harel, 1987). Thorisson’s Ymir architecture (Thorisson, 2002) is an attempt to model the cognitive processes involved in conversation. It features dialog states, capturing, for example, who has the floor, and rules that govern the transition from one state to another based on ”boolean conditions of perceptual features”. All these models are deterministic. At any point in time, the agent knows who owns the floor and uses fixed rules to take appropriate actions. These approaches assume 1) that the system can obtain perfectly reliable information on the state of the world, and 2) that the state itself is una</context>
</contexts>
<marker>Harel, 1987</marker>
<rawString>D. Harel. 1987. Statecharts: A visual formalism for complex systems. Science of Computer Programming, 8:231–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jaffe</author>
<author>S Feldstein</author>
</authors>
<title>Rhythms of Dialogue.</title>
<date>1970</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2891" citStr="Jaffe and Feldstein (1970)" startWordPosition="436" endWordPosition="439">nite-state models of the conversational floor. Because of its simplicity and generality, this model can be applied to many turn-taking phenomena. At the same time, being grounded in decision theory, it lends itself well to data-driven optimization. We illustrate our approach by applying the model to a specific turn-taking task: end-of-turn detection. 2 Conversational Floor as a Finite-State Machine 2.1 6-state finite state models of turn-taking In the 1960’s and early 1970’s, several researchers proposed models to explain the rhythmic turn-taking patterns in human conversation. In particular, Jaffe and Feldstein (1970) studied the mean duration of pauses, switching pauses (when a different speaker takes the floor), simultaneous speech, and (singlespeaker) vocalizations in recorded dyadic conversations. Based on their observation that these durations follow exponential distributions, they proposed first-order Markov models to capture the alternation of speech and silence in dialog. Their initial model had four states: only participant A is speak629 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 629–637, Boulder, Colorado, June 2009. c�2009 Association </context>
<context position="18545" citStr="Jaffe and Feldstein, 1970" startWordPosition="3183" endWordPosition="3186">ter which the user resumes speaking is significantly longer than the time the system takes to endpoint. 633 = P(d ≥ τ|O, U) · P(U|O) + P(d ≥ τ|O, F) · P(F|O) = P(d ≥ τ|O, U) · (1 − P(F|O)) +P(F|O) Consequently, P(F|Ot) is a function of P(F|O) and P(d ≥ τ|O, U). We estimate P(F|O) by stepwise logistic regression on a training set of pauses labeled for finality (whether the pause is turn-final or turn-internal), using a wide range of features available from various components of the dialog system. Based on the well established observation that pause durations follow an exponential distribution (Jaffe and Feldstein, 1970; Lennes and Anttila, 2002; Raux et al., 2008), P(d ≥ τ|O, U) is a function of mean pause duration, computed on the training set. 4.3 In speech In some cases, it is not necessary to wait for the VAD to detect a pause to know with high confidence that the user has released the floor. For example, after a simple yes/no question, if the user says ”YES”, they are very likely to have released the floor, regardless of how long they remain silent afterwards. In order to exploit this fact and improve the responsiveness of the system in these highly predictable cases, we use a separate model to compute</context>
</contexts>
<marker>Jaffe, Feldstein, 1970</marker>
<rawString>J. Jaffe and S. Feldstein. 1970. Rhythms of Dialogue. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Kronild</author>
</authors>
<title>Turn taking for artificial conversational agents.</title>
<date>2006</date>
<booktitle>In Cooperative Information Agents X,</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="1907" citStr="Kronild, 2006" startWordPosition="288" endWordPosition="289">a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work on finite-state models of the conversational floor. Because of its simplicity and generality, this model can be applied to many turn-taking phenomena. At the same time, being grounded in decision theory, it lends itself well to data-driven optimiz</context>
<context position="5074" citStr="Kronild (2006)" startWordPosition="781" endWordPosition="782"> with the analysis of human-human conversations, more recently, several researchers have proposed finite-state machines to control conversational agents. For instance, Cassell et al. (2001) model the conversational state of an embodied real estate agent as a 5-state machine. Two states indicate whether a user is present or not, whereas the other three indicate who holds the floor between the user and the agent, or whether the floor is open. Floor conflicts are not captured by this machine and are presumably resolved through simple rules (e.g. when the user speaks, the agent yields the floor). Kronild (2006) proposes a much more complex model, based on Harel statecharts, which are an extension of finite-state machines for modeling and visualizing abstract control (Harel, 1987). Thorisson’s Ymir architecture (Thorisson, 2002) is an attempt to model the cognitive processes involved in conversation. It features dialog states, capturing, for example, who has the floor, and rules that govern the transition from one state to another based on ”boolean conditions of perceptual features”. All these models are deterministic. At any point in time, the agent knows who owns the floor and uses fixed rules to t</context>
</contexts>
<marker>Kronild, 2006</marker>
<rawString>F. Kronild. 2006. Turn taking for artificial conversational agents. In Cooperative Information Agents X, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mietta Lennes</author>
<author>Hanna Anttila</author>
</authors>
<title>Prosodic features associated with the distribution of turns in finnish informal dialogues.</title>
<date>2002</date>
<booktitle>The Phonetics Symposium 2002, volume Report 67,</booktitle>
<pages>149--158</pages>
<editor>In Petri Korhonen, editor,</editor>
<institution>Helsinki University of Technology.</institution>
<contexts>
<context position="18571" citStr="Lennes and Anttila, 2002" startWordPosition="3187" endWordPosition="3190">speaking is significantly longer than the time the system takes to endpoint. 633 = P(d ≥ τ|O, U) · P(U|O) + P(d ≥ τ|O, F) · P(F|O) = P(d ≥ τ|O, U) · (1 − P(F|O)) +P(F|O) Consequently, P(F|Ot) is a function of P(F|O) and P(d ≥ τ|O, U). We estimate P(F|O) by stepwise logistic regression on a training set of pauses labeled for finality (whether the pause is turn-final or turn-internal), using a wide range of features available from various components of the dialog system. Based on the well established observation that pause durations follow an exponential distribution (Jaffe and Feldstein, 1970; Lennes and Anttila, 2002; Raux et al., 2008), P(d ≥ τ|O, U) is a function of mean pause duration, computed on the training set. 4.3 In speech In some cases, it is not necessary to wait for the VAD to detect a pause to know with high confidence that the user has released the floor. For example, after a simple yes/no question, if the user says ”YES”, they are very likely to have released the floor, regardless of how long they remain silent afterwards. In order to exploit this fact and improve the responsiveness of the system in these highly predictable cases, we use a separate model to compute the expected costs of wai</context>
</contexts>
<marker>Lennes, Anttila, 2002</marker>
<rawString>Mietta Lennes and Hanna Anttila. 2002. Prosodic features associated with the distribution of turns in finnish informal dialogues. In Petri Korhonen, editor, The Phonetics Symposium 2002, volume Report 67, pages 149–158. Laboratory of Acoustics and Audio Signal Processing, Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Orestr¨om</author>
</authors>
<date>1983</date>
<booktitle>Turn-Taking in English Conversation. CWK Gleerup,</booktitle>
<location>Lund.</location>
<marker>Orestr¨om, 1983</marker>
<rawString>B. Orestr¨om. 1983. Turn-Taking in English Conversation. CWK Gleerup, Lund.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Porzel</author>
<author>M Baudis</author>
</authors>
<title>The tao of chi: Towards effective human-computer interaction.</title>
<date>2004</date>
<booktitle>In HLT/NAACL 2004,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="1661" citStr="Porzel and Baudis, 2004" startWordPosition="248" endWordPosition="251">what to say but also when to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work o</context>
</contexts>
<marker>Porzel, Baudis, 2004</marker>
<rawString>R. Porzel and M. Baudis. 2004. The tao of chi: Towards effective human-computer interaction. In HLT/NAACL 2004, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Eskenazi</author>
</authors>
<title>Optimizing endpointing thresholds using dialogue features in a spoken dialogue system.</title>
<date>2008</date>
<booktitle>In Proc. SIGdial 2008,</booktitle>
<location>Columbus, OH, USA.</location>
<marker>Eskenazi, 2008</marker>
<rawString>A. Raux, , and M. Eskenazi. 2008. Optimizing endpointing thresholds using dialogue features in a spoken dialogue system. In Proc. SIGdial 2008, Columbus, OH, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Raux</author>
</authors>
<title>Flexible Turn-Taking for Spoken Dialog Systems.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="27053" citStr="Raux (2009)" startWordPosition="4585" endWordPosition="4586">t al. (2002), Ferrer et al. (2003), Takeuchi et al. (2004), and our previous work (Raux et al., 2008). Possible extensions of the approach include datadriven cost matrices to relax some of the assumptions introduced in section 3.2, as well as more complex state structures to handle, for example, multiparty conversations. Finally, we plan to investigate more principled approaches, such as Partially Observable Markov Decision Processes or Dynamic Bayesian Networks, to model the different sources of uncertainty (detection errors and inherent ambiguity) and track the state distribution over time. Raux (2009) provides more details on all aspects of the approach and its possible extensions. 7 Conclusion In this paper, motivated by existing finite-state models of turn-taking in dyadic conversations, we propose the Finite-State Turn-Taking Machine, an approach to turn-taking that relies on three core elements: a non-deterministic finite-state machine that captures the conversational floor; a cost matrix that models the impact of different system actions in different states; and a decision-theoretic action selection mechanism. We describe the application of the FSTTM to the key turn-taking phenomenon </context>
</contexts>
<marker>Raux, 2009</marker>
<rawString>A. Raux. 2009. Flexible Turn-Taking for Spoken Dialog Systems. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sacks</author>
<author>E A Schegloff</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turntaking for conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<volume>50</volume>
<issue>4</issue>
<contexts>
<context position="1175" citStr="Sacks et al., 1974" startWordPosition="170" endWordPosition="173">rn-taking action at any time. We show how the model can be applied to the problem of end-of-turn detection. Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches. 1 Introduction Turn-taking, the process by which participants in a conversation alternate speech and silence, is an essential component of spoken interaction. In order to lead productive conversations, people need not only know what to say but also when to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologi</context>
<context position="12551" citStr="Sacks et al. (1974)" startWordPosition="2067" endWordPosition="2070">That is achieved by applying the probabilistic decision theory principle of selecting the action with lowest expected cost. The actions available to the system are the four described above (G,R,K,W), although not all actions are available in all states. In fact, as can be seen in Table 1, there are always only two actions available in each state, depending on whether the system is claiming the floor or not. Each action in each state has a particular cost. While there are many possible ways of defining these costs, we propose a simple cost structure that derives from the principles laid out in Sacks et al. (1974): 3. The cost of an action that maintains a gap or overlap is either a constant or an increasing function of the total time spent in that state The resulting cost matrix is shown in Table 1, where • CS is the cost of interrupting a system prompt before its end when the user is not claiming the floor (false interruption) • CO(τ) is the cost of remaining in an overlap that is already τ ms long • CU is the cost of grabbing the floor when the user is holding it (cut-in) • CG(τ) is the cost of remaining in a gap that is already τ ms long This cost structure makes a number of simplifying assumptions</context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>H. Sacks, E. A. Schegloff, and G. Jefferson. 1974. A simplest systematics for the organization of turntaking for conversation. Language, 50(4):696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sato</author>
<author>R Higashinaka</author>
<author>M Tamoto</author>
<author>M Nakano</author>
<author>K Aikawa</author>
</authors>
<title>Learning decision trees to determine turn-taking by spoken dialogue systems.</title>
<date>2002</date>
<booktitle>In ICSLP 2002,</booktitle>
<location>Denver, CO.</location>
<contexts>
<context position="26454" citStr="Sato et al. (2002)" startWordPosition="4489" endWordPosition="4492">ed without any human transcription effort (since they are trained on ASR output) makes them all the more appealing. Essentially, the FSTTM provides a simple, unified model of turn-taking that lends itself to data-driven optimization. While we discussed specific cost structures and probability estimation techniques, the framework’s flexibility opens it to other choices at many levels. By formalizing the overall turn-taking process in a probabilistic, decision-theoretic framework, the FSTTM extends and generalizes previous classification-based approaches to endpointing such as those proposed by Sato et al. (2002), Ferrer et al. (2003), Takeuchi et al. (2004), and our previous work (Raux et al., 2008). Possible extensions of the approach include datadriven cost matrices to relax some of the assumptions introduced in section 3.2, as well as more complex state structures to handle, for example, multiparty conversations. Finally, we plan to investigate more principled approaches, such as Partially Observable Markov Decision Processes or Dynamic Bayesian Networks, to model the different sources of uncertainty (detection errors and inherent ambiguity) and track the state distribution over time. Raux (2009) </context>
</contexts>
<marker>Sato, Higashinaka, Tamoto, Nakano, Aikawa, 2002</marker>
<rawString>R. Sato, R. Higashinaka, M. Tamoto, M. Nakano, and K. Aikawa. 2002. Learning decision trees to determine turn-taking by spoken dialogue systems. In ICSLP 2002, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Schegloff</author>
</authors>
<title>Overlapping talk and the organization of turn-taking for conversation. Language in Society,</title>
<date>2000</date>
<pages>29--1</pages>
<contexts>
<context position="1209" citStr="Schegloff, 2000" startWordPosition="177" endWordPosition="178"> how the model can be applied to the problem of end-of-turn detection. Evaluation results on a deployed spoken dialog system show that the FSTTM provides significantly higher responsiveness than previous approaches. 1 Introduction Turn-taking, the process by which participants in a conversation alternate speech and silence, is an essential component of spoken interaction. In order to lead productive conversations, people need not only know what to say but also when to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more compl</context>
</contexts>
<marker>Schegloff, 2000</marker>
<rawString>E.A. Schegloff. 2000. Overlapping talk and the organization of turn-taking for conversation. Language in Society, 29:1–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Takeuchi</author>
<author>N Kitaoka</author>
<author>S Nakagawa</author>
</authors>
<title>Timing detection for realtime dialog systems using prosodic and linguistic information.</title>
<date>2004</date>
<booktitle>In Proc. Speech Prosody 04,</booktitle>
<location>Nara, Japan.</location>
<contexts>
<context position="26500" citStr="Takeuchi et al. (2004)" startWordPosition="4497" endWordPosition="4500">(since they are trained on ASR output) makes them all the more appealing. Essentially, the FSTTM provides a simple, unified model of turn-taking that lends itself to data-driven optimization. While we discussed specific cost structures and probability estimation techniques, the framework’s flexibility opens it to other choices at many levels. By formalizing the overall turn-taking process in a probabilistic, decision-theoretic framework, the FSTTM extends and generalizes previous classification-based approaches to endpointing such as those proposed by Sato et al. (2002), Ferrer et al. (2003), Takeuchi et al. (2004), and our previous work (Raux et al., 2008). Possible extensions of the approach include datadriven cost matrices to relax some of the assumptions introduced in section 3.2, as well as more complex state structures to handle, for example, multiparty conversations. Finally, we plan to investigate more principled approaches, such as Partially Observable Markov Decision Processes or Dynamic Bayesian Networks, to model the different sources of uncertainty (detection errors and inherent ambiguity) and track the state distribution over time. Raux (2009) provides more details on all aspects of the ap</context>
</contexts>
<marker>Takeuchi, Kitaoka, Nakagawa, 2004</marker>
<rawString>M. Takeuchi, N. Kitaoka, and S. Nakagawa. 2004. Timing detection for realtime dialog systems using prosodic and linguistic information. In Proc. Speech Prosody 04, Nara, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Thorisson</author>
</authors>
<title>Multimodality in Language and Speech Systems, chapter Natural Turn-Taking Needs No Manual: Computational Theory and Model, From Perception to Action,</title>
<date>2002</date>
<pages>173--207</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1891" citStr="Thorisson, 2002" startWordPosition="286" endWordPosition="287">havior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work on finite-state models of the conversational floor. Because of its simplicity and generality, this model can be applied to many turn-taking phenomena. At the same time, being grounded in decision theory, it lends itself well to dat</context>
<context position="5295" citStr="Thorisson, 2002" startWordPosition="813" endWordPosition="814">e of an embodied real estate agent as a 5-state machine. Two states indicate whether a user is present or not, whereas the other three indicate who holds the floor between the user and the agent, or whether the floor is open. Floor conflicts are not captured by this machine and are presumably resolved through simple rules (e.g. when the user speaks, the agent yields the floor). Kronild (2006) proposes a much more complex model, based on Harel statecharts, which are an extension of finite-state machines for modeling and visualizing abstract control (Harel, 1987). Thorisson’s Ymir architecture (Thorisson, 2002) is an attempt to model the cognitive processes involved in conversation. It features dialog states, capturing, for example, who has the floor, and rules that govern the transition from one state to another based on ”boolean conditions of perceptual features”. All these models are deterministic. At any point in time, the agent knows who owns the floor and uses fixed rules to take appropriate actions. These approaches assume 1) that the system can obtain perfectly reliable information on the state of the world, and 2) that the state itself is unambiguous. 3 The Finite-State Turn-Taking Machine </context>
</contexts>
<marker>Thorisson, 2002</marker>
<rawString>K. R. Thorisson, 2002. Multimodality in Language and Speech Systems, chapter Natural Turn-Taking Needs No Manual: Computational Theory and Model, From Perception to Action, pages 173–207. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
<author>J F Allen</author>
</authors>
<title>Discourse obligations in dialogue.</title>
<date>1994</date>
<booktitle>In Proc. ACL-94,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="6641" citStr="Traum and Allen (1994)" startWordPosition="1033" endWordPosition="1036">s as Jaffe and Feldstein: USER and SYSTEM represent states where one and only one of the participants claims the floor, FREES and FREEU states where no participant claims the floor (following, resp., a SYSTEM and USER state), and BOTHS and BOTHU states where both participants claim the floor (following, resp. a SYSTEM and USER state). However, we apply this model to the control of a conversational agent, with a goal similar to that of Cassel, Thorisson, and Kronild. One important distinction is that we define the states in terms of the participants’ intentions and obligations (in the sense of Traum and Allen (1994)) rather than the surface level observation of speech vs silence. For example, the state is USER when the user has the obligation to speak (to respond to a system question) or the intention to speak, while at the same time, the system does not hold the floor. This does not necessarily mean that the user is speaking, for example at pauses during a user utterance. As can be seen in Figure 1, not all transitions are valid. First, there is no direct transition between any of the intermediate states (the two FREE states and two BOTH states). The assumption is that to go from any of these state to a</context>
</contexts>
<marker>Traum, Allen, 1994</marker>
<rawString>D. R. Traum and J. F. Allen. 1994. Discourse obligations in dialogue. In Proc. ACL-94, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ward</author>
<author>A Rivera</author>
<author>K Ward</author>
<author>D Novick</author>
</authors>
<title>Root causes of lost time and user stress in a simple dialog system.</title>
<date>2005</date>
<booktitle>In Interspeech</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="1681" citStr="Ward et al., 2005" startWordPosition="252" endWordPosition="255"> to say it. Decades of research on Conversation Analysis and psycholinguistics (Duncan, 1972; Sacks et al., 1974; Orestr¨om, 1983; Schegloff, 2000; Wesseling and van Son, 2005) have shown that human turn-taking behavior relies on a wide range of rules and signals at many different levels of language, from prosody to syntax, semantics, and discourse structure. In contrast, turn-taking in spoken dialog systems is often reduced to ad hoc rules only based on very low level features. This simplistic approach leads to inefficient, unnatural, and possibly confusing behavior (Porzel and Baudis, 2004; Ward et al., 2005). ∗ This research was conducted when the first author was a student at the Language Technologies Institute. Recently, more complex models of turn-taking have been proposed (Cassell et al., 2001; Thorisson, 2002; Kronild, 2006). Yet, these models still rely extensively on hand-coded expert knowledge and do not lend themselves to data-driven optimization. Furthermore, to our knowledge, no such model has been deployed in a widely used system outside of the laboratory. In this paper, we propose a flexible, practical model of turn-taking behavior that builds upon previous work on finite-state model</context>
</contexts>
<marker>Ward, Rivera, Ward, Novick, 2005</marker>
<rawString>N. Ward, A. Rivera, K. Ward, and D. Novick. 2005. Root causes of lost time and user stress in a simple dialog system. In Interspeech 2005, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wesseling</author>
<author>R J J H van Son</author>
</authors>
<title>Timing of experimentally elicited minimal responses as quantitative evidence for the use of intonation in projecting TRPs. In Interspeech</title>
<date>2005</date>
<pages>3389--3392</pages>
<location>Lisbon, Portugal.</location>
<marker>Wesseling, van Son, 2005</marker>
<rawString>W. Wesseling and R.J.J.H. van Son. 2005. Timing of experimentally elicited minimal responses as quantitative evidence for the use of intonation in projecting TRPs. In Interspeech 2005, pages 3389–3392, Lisbon, Portugal.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>