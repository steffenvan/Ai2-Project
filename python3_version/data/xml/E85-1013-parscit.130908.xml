<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9845002">
Right Attachment and Preference Semantics.
Yorick Wilks
Computing Research Laboratory
New Mexico State University
Las Cruces, NM 88003, USA.
</title>
<sectionHeader confidence="0.883187" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999817307692308">
The paper claims that the right attachment rules for phrases
originally suggested by Frazier and Fodor are wrong, and that none
of the subsequent patchings of the rules by syntactic methods have
improved the situation. For each rule there are perfectly straightfor-
ward and indefinitely large classes of simple counter-examples. We
then examine suggestions by Ford et al., Schubert and Hirst which
are quasi-semantic in nature and which we consider ingenious but
unsatisfactory. We point towards a straightforward solution within
the framework of preference semantics, set out in detail elsewhere,
and argue that the principal issue is not the type and nature of infor-
mation required to get appropriate phrase attachments, but the issue
of where to store the information and with what processes to apply
it.
</bodyText>
<sectionHeader confidence="0.87965" genericHeader="keywords">
SYNTACTIC APPROACHES
</sectionHeader>
<bodyText confidence="0.998911">
Recent discussion of the issue of how and where to attach
right-hand phrases (and more generally, clauses) in sentence analysis
was started by the claims of Frazier and Fodor (1979). They offered
two rules :
</bodyText>
<listItem confidence="0.671149">
(i) Right Association
</listItem>
<bodyText confidence="0.7697815">
which is that phrases on the right should be attached as low as possi-
ble on a syntax tree, thus
</bodyText>
<sectionHeader confidence="0.953633" genericHeader="introduction">
JOHN BOUGHT THE BOOK THAT I HAD BEEN TRYING
TO OBTAIN (FOR SUSAN)
</sectionHeader>
<bodyText confidence="0.990988">
which attaches to OBTAIN not to BOUGHT.
But this rule fails for
</bodyText>
<sectionHeader confidence="0.551914" genericHeader="method">
JOHN BOUGHT THE BOOK (FOR SUSAN)
</sectionHeader>
<bodyText confidence="0.9997695">
which requires attachment to BOUGHT not BOOK.
A second principle was then added :
</bodyText>
<sectionHeader confidence="0.778383" genericHeader="method">
(ii) Minimal Attachment
</sectionHeader>
<bodyText confidence="0.980411666666667">
which is that a phrase must be attached higher in a tree if doing that
minimizes the number of nodes in the tree (and this rule is to take
precedence over (i)).
</bodyText>
<figure confidence="0.775626571428571">
So, in :
VP
V V
NP PP
carried NP PP for Mary
/
groceries for Mary
</figure>
<sectionHeader confidence="0.703212" genericHeader="method">
JOHN CARRIED THE GROCERIES (FOR MARY)
</sectionHeader>
<bodyText confidence="0.99724">
attaching FOR MARY to the top of the tree, rather than to the NP,
will create a tree with one less node. Shieber (1983) has an alterna-
tive analysis of this phenomenon, based on a clear parsing model,
which produces the same effect as rule (ii) by preferring longer reduc-
tions in the parsing table; i.e., in the present case, preferring VP &lt;—
V NP PP to NP &lt;— NP PP.
But there are still problems with (i) and (ii) taken together, as
is seen in:
</bodyText>
<sectionHeader confidence="0.619018" genericHeader="method">
SHE WANTED THE DRESS (ON THAT RACK)
</sectionHeader>
<bodyText confidence="0.9935205">
rather than attaching (ON THAT RACK) to WANTED, as (ii) would
cause.
</bodyText>
<sectionHeader confidence="0.9611175" genericHeader="method">
SEMANTIC APPROACHES
(i) Lexical Preference
</sectionHeader>
<bodyText confidence="0.934403941176471">
At this point Ford et al. (1981) suggested the use of lexical
preference, which is conventional case information associated with
individual verbs, so as to select for attachment PPs which match
that case information. This is semantic information in the broad
sense in which that term has traditionally been used in Al. Lexical
preference allows rules (i) and (ii) above to be overridden if a verb&apos;s
coding expresses a strong preference for a certain structure. The
effect of that rule differs from system to system: within Shieber&apos;s
parsing model (1983) that rule means in effect that a verb like
WANT will prefer to have only a single NP to its right. The parser
then performs the longest reduction it can with the strongest leftmost
stack element. So, if POSITION, say, prefers two entities to its right,
Shieber will obtain :
THE WOMAN WANTED THE DRESS (ON THE RACK)
THE WOMAN POSITIONED THE DRESS (ON THE RACK).
as part of
and
</bodyText>
<page confidence="0.987491">
89
</page>
<figure confidence="0.7590796">
(AT A WEDDING) case, informants continue to attach to MET,
seemingly discounting both the syntactic indication and the informa-
tion vacuity of MARRIED ATA WEDDING.
•
JOHN WAS NAMED (AFTER HIS TWIN SISTER)
</figure>
<bodyText confidence="0.967564">
But this iterative patching with more rules does not work,
because to every example, under every rule (i, ii and lexical prefer-
ence), there are clear and simple counter-examples. Thus, there is :
</bodyText>
<listItem confidence="0.644667583333333">
JOE TOOK THE BOOK THAT I BOUGHT (FOR SUSAN)
which comes under (i) and there is
• JOE BROUGHT THE BOOK THAT I LOVED (FOR SUSAN)
which Shieber&apos;s parser must get wrong and not in a way that (ii)
could rescue. Under (ii) itself, there is
JOE LOST THE TICK) PARIS)
which Shieber&apos;s conflict reduction rule must get wrong. For Shieber&apos;s
version of lexical preference there will be problems with :
THE WOMAN WANT 1---:7-SI:t.&apos;ORES HER
DAUGHTER)
which the rules he gives for WANT must get wrong.
(ii) Schubert
</listItem>
<bodyText confidence="0.98671954">
Schubert (1984) presents some of the above counter-examples in
an attack on syntactically based methods. He proposes a syntactico-
semantic network system of what he calls preference trade-offs. He is
driven to this, he says, because he rejects any system based wholly
on lexically-based semantic preferences (which is part of what we
here will call preference semantics, see below, and which would sub-
sume the simpler versions of lexical preference). He does this on the
grounds that there are clear cases where &amp;quot;syntactic preferences pre-
vail over much more coherent alternatives&amp;quot; (Schubert, 1984, p.248),
where by &amp;quot;coherent&amp;quot; • he means interpretations imposed by
semantics/pragmatics. His examples are :
MARY SAW THE MAN WHO HAD LIVED WITH HER
WHELE ON MATERNITY LEAVE)
(where full lines show the &amp;quot;natural&amp;quot; pragmatic interpretations, and
dotted ones the interpretations that Schubert says are imposed willy-
filly by the syntax). Our informants disagree with Schubert : they
attach as the syntax suggests to LIVE, but still insist that the leave
is Mary&apos;s (i.e. so interpreting the last clause that it contains an
elided (WHILE) SHE WAS (ON....). If that is so the example does
not split off semantics from syntax in the way Schubert wants,
because the issue is who is on leave and not when something was
done. In such circumstances the example presents no special prob-
lems.
JOHN MET A TALL SUM AUBUN HAIRED GIRL FROM
MONTREAL THAT HE MARRIED (AT A DANCE)
Here our informants attach the phrase resolutely to MET as com-
monsense dictates (i.e. they ignore or are able to discount the built-in
distance effect of the very long NP). A more difficult and interesting
case arises if the last phrase is (AT A WEDDING), since the example
then seems to fall withing the exclusion of an &amp;quot;attachment unless it
yields zero information&amp;quot; rule deployed within preference semantics
(Wilks, 1973), which is probably, in its turn, a close relative of
Grice&apos;s (1975) maxim concerned with information quantity. In the
Here our informants saw genuine ambiguity and did not seem
to mind much whether attachment or lexicalization of NAMED
AFTER was preferred. Again, information vacuity tells against the
syntactic attachment (the example is on the model of :
HE WAS NAMED AFTER HIS FATHER
Wilks 1973, which was used to make a closely related point),
but normal gendering of names tells against the lexicalization of the
verb to NAME+AFTER.
Our conclusion from Schubert&apos;s examples is the reverse of his
own : these are not simple examples but very complex ones, involving
distance and (in two cases) information quantity phenomena. In none
of the cases do they support the straightforward primacy of syntax
that his case against a generalized &amp;quot;lexical preference hypothesis&amp;quot;
(i.e. one without rules (i) and (ii) as default cases, as in Ford et al.&apos;s
lexical preference) would require. We shall therefore consider that
hypothesis, under the name preference semantics, to be still under
consideration.
</bodyText>
<figure confidence="0.667172">
(iii) Hirst
</figure>
<figureCaption confidence="0.878156833333333">
Hirst (1984) aims to produce a conflation of the approaches of
Ford et al., described above, and a principle of Crain and Steedman
(1984) called The Principle of Parsimony, which is to make an
attachment that corresponds to leaving the minimum number of
presuppositions unsatisfied. The example usually given is that of a
&amp;quot;garden path&amp;quot; sentence like :
</figureCaption>
<bodyText confidence="0.9772292">
THE HORSE RACED PAST THE BARN FELL
where the natural (initial) preference for the garden path interpreta-
tion is to be explained by the fact that, on that interpretation, only
the existence of an entity corresponding to THE HORSE is to be
presupposed, and that means less presuppositions to which nothing is
the memory structure corresponds than is needed to opt for the
existence of some THE HORSE RACED PAST THE BARN. One
difficulty here is what it is for something to exist in memory: Crain
and Steedman themselves note that readers do not garden path with
sentences like :
</bodyText>
<sectionHeader confidence="0.994533" genericHeader="method">
CARS RACED AT MONTE CARLO FETCH HIGH PRICES
AS COLLECTOR&apos;S ITEMS
</sectionHeader>
<bodyText confidence="0.999282">
but that is not because readers know of any particular cars raced at
Monte Carlo. Hirst accepts from (Winograd 1972) a general Principle
of Referential Success (i.e. to actual existent entities), but the general
unsatisfactoriness of restricting a system to actual entities has long
been known, for so much of our discourse is about possible and vir-
tual ontologies (for a full discussion of this aspect of Winograd, see
Ritchie 1978).
The strength of Hirst&apos;s approach is his attempt to reduce the
presuppositional metric of CraM and Steedman to criteria manipul-
able by basic semantic/lexical codings, and particularly the contrast
of definite and indefinite articles. But the general determination of
categories like definite and indefinite is so shaky (and only indirectly
related to &amp;quot;the&amp;quot; and &amp;quot;a&amp;quot; in English), and cannot possibly bear the
weight that he puts on it as the solid basis of a theory of phrase
attachment.
</bodyText>
<page confidence="0.992401">
90
</page>
<sectionHeader confidence="0.575825" genericHeader="method">
A FIRST TRIAL ATTACHMENT RULE
</sectionHeader>
<bodyText confidence="0.741093">
The examples discussed are correctly attached by the following
</bodyText>
<equation confidence="0.657885">
rule :
</equation>
<bodyText confidence="0.939852307692308">
Rule A : moving leftwards from the right hand end of a sentence,
assign the attachment of an entity X (word or phrase) to the first
entity to the left of X that has a preference that X satisfies; this
entails that any entity X can only satisfy the preference of one
entity. Assume also a push down stack for inserting such entities as
X into until they satisfy some preference. Assume also some distance
limit (to be empirically determined) and a DEFAULT rule such that,
if any X satisfies no preferences, it is attached locally, i.e. immedi-
ately to its left.
Rule A gets right all the classes of examples discussed (with
one exception, see below): e.g
JOHN BROUGHT THE BOOK THAT I LOVED (FOR
MARY)
</bodyText>
<sectionHeader confidence="0.902964" genericHeader="method">
JOHN TOOK THE BOOK THAT I BOUGHT (FOR MARY)
</sectionHeader>
<bodyText confidence="0.9869578">
JOHN WANT D THE DRESS (ON THE RACK )(FOR
MARY)
where the last requires use of the push-down stack. The phenomenon
treated here is assumed to be much more general than just phrases,
as in:
</bodyText>
<equation confidence="0.53047">
PATE DE CANARD TRUFFg
</equation>
<bodyText confidence="0.990398">
(i.e. a truffled pate of duck, not a pate of trufiled ducks!) where we
envisage a preference (POSS STUFF);,---i.e. prefers to be predicated
of substances — as part of [TRUFFE]. French gender is of no use
here, since all the concepts are masculine.
This rule would of course have to be modified for many special
factors, e.g. pronouns, because of:
SHE WANTED {THE /DTRN(0 THE SHELF)
A more substantial drawback to this substitution of a single
semantics- based rule for all the earlier syntactic complexity is that
placing the preferences essentially in the verbs (as did the systems
discussed earlier that used lexical preference) and having little more
than semantic type information on nouns (except in cases like
[TICKET] that also prefers associated cases) but, most importantly,
having no semantic preferences associated with prepositions that
introduce phrases, we shall only succeed with rule A by means of a
semantic subterfuge for a large and simple class of cases, namely:
</bodyText>
<sectionHeader confidence="0.596007" genericHeader="method">
JOHN LOVED HER (FOR HER BEAUTY)
or
JOHN SHOT THE GIRL (IN THE PARK)
</sectionHeader>
<bodyText confidence="0.98625175">
Given the &amp;quot;low default&amp;quot; component of rule A, these can only
be correctly attached if there is a very general case component in the
verbs, e.g. some statement of location in all &amp;quot;active types&amp;quot; of verbs
(to be described by the primitive type heads in their codings) like
SHOOT i.e. (location *pla), which expresses the fact that acts of this
type are necessarily located. (location *pla) is then the preference
that (IN THE PARK) satisfies, thus preventing a low default.
So, Hirst invites counter-examples to his Principle of Referen-
tial Success (1984, p.149) adapted from Winograd: &amp;quot;a non-generic NP
presupposes that the thing it describes exists an indefinite NP
presupposes only the plausibility of what it describes.&amp;quot; But this is
just not so in either case :
</bodyText>
<figure confidence="0.965961">
THE PERPETUAL MOTION MACHINE IS THE BANE OF
LIFE IN A PATENT OFFICE
A MAN I JUST MET LENT ME FIVE POUNDS
</figure>
<figureCaption confidence="0.881743375">
The machine is perfectly definite but the perpetual motion machine
does not exist and is not presupposed by the speaker. We conclude
that these notions are not yet in a state to be the basis of a theory of
PP attachment. Moreover, even though beliefs about the world must
play a role in attachment in certain cases, there is, as yet, no reason
to believe that beliefs and presuppositions can provide the material
for a basic attachment mechanism.
(iv) Preference Semantics
</figureCaption>
<bodyText confidence="0.93518995">
Preference Semantics has claimed that appropriate structurings
can be obtained using essentially semantic information, given also a
rule of preferring the most densely connected representations that
can be constructed from such semantic information (Wilks 1975, Fass
&amp; Wilks 1983).
Let us consider such a position initially expressed as semantic
dictionary information attaching to the verb; this is essentially the
position of the systems discussed above, as well as of case grammar.
and the semantics- based parsing systems (e.g. Riesbeck 1975) that
have been based on it. When discussing implementation in the last
section we shall argue (as in Wilks 1978) that semantic material that
is to be the base of a parsing process cannot be thought of as simply
attaching to a verb (rather than to nouns and all other word senses)
In what follows we shall assume case predicates in the diction-
ary entries of verbs, nouns etc. that express part of the meaning of
the concept and determine its semantic relations. We shall write as
[OBTAIN] the abbreviation of the semantic dictionary entry for
OBTAIN, and assume that the following concepts contain at least
the case entries shown (as case predicates and the types of argument
fillers) :
</bodyText>
<figure confidence="0.848085857142857">
[OBTAIN) (recipient hum) recipient case, human.
[BUY] (recipient hum) recipient case, human.
[POSITION] (location *pia) location case, place.
[BRING] (recipient human)recipient case, human.
[TICKET] (direction *pla) direction case, place.
[WANT] (object *physob) object case, physical object.
(recipient hum) recipient case, human.
</figure>
<bodyText confidence="0.9746831">
The issue here is whether these are plausible preferential meaning
constituents: e.g. that to obtain something is to obtain it for a reci-
pient;
to position something is to do it in association with a place; a ticket
(in this sense i.e. &amp;quot;billet&amp;quot; rather than &amp;quot;ticket&amp;quot; in French) is a ticket
to somewhere, and so on. They do not entail restrictions, but only
preferences. Hence, &amp;quot;John brought his dog a bone&amp;quot; in no way violates
the coding [BRING]. We shall refer to these case constituents within
semantic representations as semantic preferences of the corresponding
head concept.
</bodyText>
<page confidence="0.997355">
91
</page>
<bodyText confidence="0.9987986">
Again, verbs like LOVE would need a (REASON ANY) com-
ponent in their coding, expressing the notion that such states (as
opposed to actions, both defined ir terms of the main semantic primi-
tives of verbs) are dependent on some reason, which could be any-
thing.
But the clearest defect of Rule A (and, by implication, of all
the verb- centered approaches discussed earlier in the paper) is that
verbs in fact confront not cases, but PPs fronted by ambiguous
prepositions, and it is only by taking account of their preferences
that a general solution can be found.
</bodyText>
<sectionHeader confidence="0.925388" genericHeader="conclusions">
PREPOSITION SEMANTICS: PREPLATES
</sectionHeader>
<bodyText confidence="0.999989634615385">
In fact rule A was intentionally naive: it was designed to
demonstrate (as against Shubert&apos;s claims in particular) the wide cov-
erage of the data of a single semantics-based rule, even if that
required additional, hard to motivate, semantic information to be
given for action and states. It was stated in a verb-based lexical
preference mode simply to achieve contrast with the other systems
discussed.
For some years, it has been a principle of preference semantics
(e.g. Wilks 1973, 1975) that attachment relations of phrases, clauses
etc. are to be determined by comparing the preferences emanating
from all the entities involved in an attachment: they are all, as it
were, to be considered as objects seeking other preferred classes of
neighbors, and the best fit, within and between each order of struc-
tures built up, is to be found by comparing the preferences and
finding a best mutual fit. This point was made in (Wilks 1976) by
contrasting preference semantics with the simple verb-based requests
of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that
account had to be taken of both the preferences of verbs (and nouns),
and of the preferences cued from the prepositions themselves.
Those preferences were variously called paraplates (Wilks
1975), preplates (Boguraev 1979) and they were, for each preposition
sense, an ordered set of predication preferences restricted by action
or noun type. (Wilks 1975) contains examples of ordered paraplate
stacks and their functioning, but in what follows we shall stick to the
preplate notation of (Huang 19846).
We have implemented in CASSEX (see Wilks, Huang and Fass,
1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot;
and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more
generally those of any entity which is a candidate for the root of the
attachment, as opposed to what is attached) and of what-is-attached
first (i.e. prepositional phrases). We can also control for the applica-
tion of a more redundant form of rule where we attach preferably on
the conjunction of satisfactions of the preferences of the root and the
attached (e.g. for such a rule, satisfaction would require both that the
verb preferred a prepositional phrase of such a class, and that the
prepositional phrase preferred a verb of such a class).
In (Wilks, Huang &amp; Fass 1985) we describe the algorithm that
best fits the data and alternates between the use of semantic infor-
mation attached to verbs and nouns (i.e. the roots for attachments as
in Rule A) and that of prepositions; it does this by seeking the best
mutual fit between them, and without any fall back to default syn-
tactic rules like (i) and (ii).
This strategy, implemented within Huang&apos;s (1984a, 19846)
CASSEX program, correctly parses all of the example sentences in
this paper. CASSEX, which is written in Prolog on the Essex GEC.
63, uses a definite clause grammar (DCG) to recognize syntactic con-
stituents and Preference Semantics to provide their semantic
interpretation. Its content is described in detail in (Wilks, Huang &amp;
Fass 1985) and it consists in allowing the preferences of both the
clause verbs and the prepositions themselves to operate on each other
and compete in a perspicuous and determinate manner, without
recourse to syntactic preferences or weightings.
</bodyText>
<sectionHeader confidence="0.996304" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999762627450981">
Boguraev, B.K. (1979) &amp;quot;Automatic Resolution of Linguistic Ambigui-
ties.&amp;quot; Technical Report No.11, University of Cambridge Com-
puter Laboratory, Cambridge.
Crain, S. &amp; Steedman, M. (1984) &amp;quot;On Not Being Led Up The Garden
Path : The Use of Context by the Psychological Parser.&amp;quot; In
D.R. Dowty, L.J. Karttunen &amp; A.M. Zwicky (Eds.), Syntactic
Theory and How People Parse Sentences, Cambridge
University Press.
Fass, D.C. &amp; Wilks, Y.A. (1983) &amp;quot;Preference Semantics, Ill-
Formedness and Metaphor,&amp;quot; American Journal of Compu-
tational Linguistics, 9, pp. 178-187.
Ford, M., Bresnan, J. &amp; Kaplan, R. (1981) &amp;quot;A Competence-Based
Theory of Syntactic Closure.&amp;quot; In J. Bresnan (Ed.), The Men-
tal Representation of Grammatical Relations, Cambridge,
MA : MIT Press.
Frazier, L. &amp; Fodor, J. (1979) &amp;quot;The Sausage Machine: A New Two-
Stage Parsing Model.&amp;quot; Cognition, 6, pp.191-325.
Grice, H. P. (1975) &amp;quot;Logic &amp; Conversation.&amp;quot; In P. Cole &amp; J. Morgan
(Eds.), Syntax and Semantics 3 : Speech Acts, Academie
Press, pp. 41-58.
Hirst, G. (1983) &amp;quot;Semantic Interpretation against Ambiguity.&amp;quot;
Technical Report CS-83-25, Dept. of Computer Science, Brown
University.
Hirst, G. (1984) &amp;quot;A Semantic Process for Syntactic Disambigua-
tion.&amp;quot; Proc. of AAAI-84, Austin, Texas, pp. 148-152.
Huang, X-M. (1984a) &amp;quot;The Generation of Chinese Sentences from the
Semantic Representations of English Sentences.&amp;quot; Proc. of
International Conference on Machine Translation,
Cranfield, England.
Huang, X-M. (1984b) &amp;quot;A Computational Treatment of Gapping,
Right Node Raising &amp; Reduced Conjunction.&amp;quot; Proc. of
COLING-84, Stanford, CA., pp. 243-246.
Riesbeck, C. (1975) &amp;quot;Conceptual Analysis.&amp;quot; In R. C. Schank (Ed.),
Conceptual Information Processing, .Amsterdam : North
Holland.
Ritchie, G. (1978) Computational Grammar. Hassocks : Harves-
ter.
Shieber, S.M. (1983) &amp;quot;Sentence Disambiguation by a Shift-Reduced
Parsing Technique.&amp;quot; Proc. of IJCAI-83, Kahlsruhe, W. Ger-
many, pp. 699-703.
Shubert, L.K. (1984) &amp;quot;On Parsing Preferences.&amp;quot; Proc. of
COLING-84, Stanford, CA., pp. 247-250.
Wilks, Y.A. (1973) &amp;quot;Understanding without Proofs.&amp;quot; Proc. of
IJCAI-73, Stanford, CA.
Wilks, Y.A. (1975) &amp;quot;A Preferential Pattern-Seeking Semantics for
Natural Language Inference.&amp;quot; Artificial Intelligence, 6, pp.
53-74.
Wilks, Y.A. (1976) &amp;quot;Processing Case.&amp;quot; American Journal of
Computational Linguistics, 56.
Winograd, T. (1972) Understanding Natural Language. New
York : Academic Press.
</reference>
<page confidence="0.996018">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.9494">Right Attachment and Preference Semantics.</title>
<author confidence="0.922257">Yorick Wilks</author>
<affiliation confidence="0.999762">Computing Research Laboratory New Mexico State University</affiliation>
<address confidence="0.999639">Las Cruces, NM 88003, USA.</address>
<abstract confidence="0.989084">The paper claims that the right attachment rules for phrases originally suggested by Frazier and Fodor are wrong, and that none of the subsequent patchings of the rules by syntactic methods have improved the situation. For each rule there are perfectly straightforward and indefinitely large classes of simple counter-examples. We then examine suggestions by Ford et al., Schubert and Hirst which are quasi-semantic in nature and which we consider ingenious but unsatisfactory. We point towards a straightforward solution within the framework of preference semantics, set out in detail elsewhere, and argue that the principal issue is not the type and nature of information required to get appropriate phrase attachments, but the issue of where to store the information and with what processes to apply it. SYNTACTIC APPROACHES Recent discussion of the issue of how and where to attach right-hand phrases (and more generally, clauses) in sentence analysis was started by the claims of Frazier and Fodor (1979). They offered two rules : (i) Right Association which is that phrases on the right should be attached as low as possible on a syntax tree, thus JOHN BOUGHT THE BOOK THAT I HAD BEEN TRYING TO OBTAIN (FOR SUSAN) which attaches to OBTAIN not to BOUGHT. But this rule fails for JOHN BOUGHT THE BOOK (FOR SUSAN) which requires attachment to BOUGHT not BOOK. A second principle was then added : (ii) Minimal Attachment which is that a phrase must be attached higher in a tree if doing that minimizes the number of nodes in the tree (and this rule is to take (i)).</abstract>
<title confidence="0.706784">So, in : VP NP PP PP for Mary / groceries for Mary</title>
<author confidence="0.444876">JOHN CARRIED THE GROCERIES</author>
<abstract confidence="0.988619586666667">attaching FOR MARY to the top of the tree, rather than to the NP, will create a tree with one less node. Shieber (1983) has an alternative analysis of this phenomenon, based on a clear parsing model, which produces the same effect as rule (ii) by preferring longer reductions in the parsing table; i.e., in the present case, preferring VP &lt;— V NP PP to NP &lt;— NP PP. But there are still problems with (i) and (ii) taken together, as is seen in: SHE WANTED THE DRESS (ON THAT RACK) rather than attaching (ON THAT RACK) to WANTED, as (ii) would cause. SEMANTIC APPROACHES (i) Lexical Preference At this point Ford et al. (1981) suggested the use of lexical preference, which is conventional case information associated with individual verbs, so as to select for attachment PPs which match that case information. This is semantic information in the broad sense in which that term has traditionally been used in Al. Lexical preference allows rules (i) and (ii) above to be overridden if a verb&apos;s coding expresses a strong preference for a certain structure. The effect of that rule differs from system to system: within Shieber&apos;s parsing model (1983) that rule means in effect that a verb like WANT will prefer to have only a single NP to its right. The parser then performs the longest reduction it can with the strongest leftmost stack element. So, if POSITION, say, prefers two entities to its right, Shieber will obtain : THE WOMAN WANTED THE DRESS (ON THE RACK) THE WOMAN POSITIONED THE DRESS (ON THE RACK). as part of and 89 (AT A WEDDING) case, informants continue to attach to MET, discounting both the syntactic indication and the informa- MARRIED ATA WEDDING. • JOHN WAS NAMED (AFTER HIS TWIN SISTER) But this iterative patching with more rules does not work, because to every example, under every rule (i, ii and lexical preference), there are clear and simple counter-examples. Thus, there is : JOE TOOK THE BOOK THAT I BOUGHT (FOR SUSAN) which comes under (i) and there is • JOE BROUGHT THE BOOK THAT I LOVED (FOR SUSAN) which Shieber&apos;s parser must get wrong and not in a way that (ii) could rescue. Under (ii) itself, there is JOE LOST THE TICK) PARIS) which Shieber&apos;s conflict reduction rule must get wrong. For Shieber&apos;s version of lexical preference there will be problems with : WOMAN WANT HER DAUGHTER) which the rules he gives for WANT must get wrong. (ii) Schubert Schubert (1984) presents some of the above counter-examples in an attack on syntactically based methods. He proposes a syntacticosemantic network system of what he calls preference trade-offs. He is driven to this, he says, because he rejects any system based wholly on lexically-based semantic preferences (which is part of what we here will call preference semantics, see below, and which would subsume the simpler versions of lexical preference). He does this on the grounds that there are clear cases where &amp;quot;syntactic preferences prevail over much more coherent alternatives&amp;quot; (Schubert, 1984, p.248), where by &amp;quot;coherent&amp;quot; • he means interpretations imposed by semantics/pragmatics. His examples are : MARY SAW THE MAN WHO HAD LIVED WITH HER WHELE ON MATERNITY LEAVE) (where full lines show the &amp;quot;natural&amp;quot; pragmatic interpretations, and dotted ones the interpretations that Schubert says are imposed willyfilly by the syntax). Our informants disagree with Schubert : they attach as the syntax suggests to LIVE, but still insist that the leave is Mary&apos;s (i.e. so interpreting the last clause that it contains an elided (WHILE) SHE WAS (ON....). If that is so the example does not split off semantics from syntax in the way Schubert wants, because the issue is who is on leave and not when something was done. In such circumstances the example presents no special problems. JOHN MET A TALL SUM AUBUN HAIRED GIRL FROM THAT HE MARRIED DANCE) Here our informants attach the phrase resolutely to MET as commonsense dictates (i.e. they ignore or are able to discount the built-in distance effect of the very long NP). A more difficult and interesting case arises if the last phrase is (AT A WEDDING), since the example then seems to fall withing the exclusion of an &amp;quot;attachment unless it yields zero information&amp;quot; rule deployed within preference semantics (Wilks, 1973), which is probably, in its turn, a close relative of Grice&apos;s (1975) maxim concerned with information quantity. In the Here our informants saw genuine ambiguity and did not seem to mind much whether attachment or lexicalization of NAMED AFTER was preferred. Again, information vacuity tells against the syntactic attachment (the example is on the model of : HE WAS NAMED AFTER HIS FATHER Wilks 1973, which was used to make a closely related point), but normal gendering of names tells against the lexicalization of the verb to NAME+AFTER. Our conclusion from Schubert&apos;s examples is the reverse of his own : these are not simple examples but very complex ones, involving distance and (in two cases) information quantity phenomena. In none of the cases do they support the straightforward primacy of syntax that his case against a generalized &amp;quot;lexical preference hypothesis&amp;quot; (i.e. one without rules (i) and (ii) as default cases, as in Ford et al.&apos;s lexical preference) would require. We shall therefore consider that hypothesis, under the name preference semantics, to be still under consideration. (iii) Hirst Hirst (1984) aims to produce a conflation of the approaches of Ford et al., described above, and a principle of Crain and Steedman (1984) called The Principle of Parsimony, which is to make an attachment that corresponds to leaving the minimum number of presuppositions unsatisfied. The example usually given is that of a &amp;quot;garden path&amp;quot; sentence like : THE HORSE RACED PAST THE BARN FELL where the natural (initial) preference for the garden path interpretation is to be explained by the fact that, on that interpretation, only the existence of an entity corresponding to THE HORSE is to be presupposed, and that means less presuppositions to which nothing is the memory structure corresponds than is needed to opt for the existence of some THE HORSE RACED PAST THE BARN. One difficulty here is what it is for something to exist in memory: Crain and Steedman themselves note that readers do not garden path with sentences like : CARS RACED AT MONTE CARLO FETCH HIGH PRICES AS COLLECTOR&apos;S ITEMS but that is not because readers know of any particular cars raced at Monte Carlo. Hirst accepts from (Winograd 1972) a general Principle of Referential Success (i.e. to actual existent entities), but the general unsatisfactoriness of restricting a system to actual entities has long been known, for so much of our discourse is about possible and virtual ontologies (for a full discussion of this aspect of Winograd, see Ritchie 1978). The strength of Hirst&apos;s approach is his attempt to reduce the presuppositional metric of CraM and Steedman to criteria manipulable by basic semantic/lexical codings, and particularly the contrast of definite and indefinite articles. But the general determination of categories like definite and indefinite is so shaky (and only indirectly related to &amp;quot;the&amp;quot; and &amp;quot;a&amp;quot; in English), and cannot possibly bear the weight that he puts on it as the solid basis of a theory of phrase attachment. 90 A FIRST TRIAL ATTACHMENT RULE examples discussed are correctly attached by the rule : A : leftwards from the right hand end of a sentence, assign the attachment of an entity X (word or phrase) to the first entity to the left of X that has a preference that X satisfies; this entails that any entity X can only satisfy the preference of one entity. Assume also a push down stack for inserting such entities as X into until they satisfy some preference. Assume also some distance limit (to be empirically determined) and a DEFAULT rule such that, if any X satisfies no preferences, it is attached locally, i.e. immediately to its left. Rule A gets right all the classes of examples discussed (with one exception, see below): e.g</abstract>
<author confidence="0.6512585">JOHN BROUGHT THE BOOK THAT I LOVED JOHN TOOK THE BOOK THAT I BOUGHT JOHN WANT D THE DRESS</author>
<abstract confidence="0.973799638888889">MARY) where the last requires use of the push-down stack. The phenomenon treated here is assumed to be much more general than just phrases, as in: PATE DE CANARD TRUFFg (i.e. a truffled pate of duck, not a pate of trufiled ducks!) where we a preference (POSS prefers to be predicated of substances — as part of [TRUFFE]. French gender is of no use here, since all the concepts are masculine. This rule would of course have to be modified for many special factors, e.g. pronouns, because of: WANTED THE SHELF) A more substantial drawback to this substitution of a single semanticsbased rule for all the earlier syntactic complexity is that placing the preferences essentially in the verbs (as did the systems discussed earlier that used lexical preference) and having little more than semantic type information on nouns (except in cases like [TICKET] that also prefers associated cases) but, most importantly, having no semantic preferences associated with prepositions that introduce phrases, we shall only succeed with rule A by means of a semantic subterfuge for a large and simple class of cases, namely: JOHN LOVED HER (FOR HER BEAUTY) or JOHN SHOT THE GIRL (IN THE PARK) Given the &amp;quot;low default&amp;quot; component of rule A, these can only correctly attached there is a very general case component in the verbs, e.g. some statement of location in all &amp;quot;active types&amp;quot; of verbs (to be described by the primitive type heads in their codings) like SHOOT i.e. (location *pla), which expresses the fact that acts of this type are necessarily located. (location *pla) is then the preference THE PARK) satisfies, thus preventing a low default. So, Hirst invites counter-examples to his Principle of Referen- (1984, p.149) adapted from Winograd: &amp;quot;a NP presupposes that the thing it describes exists an indefinite NP presupposes only the plausibility of what it describes.&amp;quot; But this is just not so in either case :</abstract>
<title confidence="0.828524333333333">THE PERPETUAL MOTION MACHINE IS THE BANE OF LIFE IN A PATENT OFFICE A MAN I JUST MET LENT ME FIVE POUNDS</title>
<abstract confidence="0.995495623853211">The machine is perfectly definite but the perpetual motion machine does not exist and is not presupposed by the speaker. We conclude that these notions are not yet in a state to be the basis of a theory of PP attachment. Moreover, even though beliefs about the world must play a role in attachment in certain cases, there is, as yet, no reason to believe that beliefs and presuppositions can provide the material for a basic attachment mechanism. (iv) Preference Semantics Preference Semantics has claimed that appropriate structurings can be obtained using essentially semantic information, given also a rule of preferring the most densely connected representations that can be constructed from such semantic information (Wilks 1975, Fass &amp; Wilks 1983). Let us consider such a position initially expressed as semantic dictionary information attaching to the verb; this is essentially the position of the systems discussed above, as well as of case grammar. and the semanticsbased parsing systems (e.g. Riesbeck 1975) that have been based on it. When discussing implementation in the last section we shall argue (as in Wilks 1978) that semantic material that is to be the base of a parsing process cannot be thought of as simply attaching to a verb (rather than to nouns and all other word senses) In what follows we shall assume case predicates in the dictionary entries of verbs, nouns etc. that express part of the meaning of the concept and determine its semantic relations. We shall write as [OBTAIN] the abbreviation of the semantic dictionary entry for OBTAIN, and assume that the following concepts contain at least the case entries shown (as case predicates and the types of argument fillers) : [OBTAIN) (recipient hum) recipient case, human. [BUY] (recipient hum) recipient case, human. [POSITION] (location *pia) location case, place. [BRING] (recipient human)recipient case, human. [TICKET] (direction *pla) direction case, place. [WANT] (object *physob) object case, physical object. (recipient hum) recipient case, human. The issue here is whether these are plausible preferential meaning constituents: e.g. that to obtain something is to obtain it for a recipient; to position something is to do it in association with a place; a ticket (in this sense i.e. &amp;quot;billet&amp;quot; rather than &amp;quot;ticket&amp;quot; in French) is a ticket to somewhere, and so on. They do not entail restrictions, but only preferences. Hence, &amp;quot;John brought his dog a bone&amp;quot; in no way violates the coding [BRING]. We shall refer to these case constituents within semantic representations as semantic preferences of the corresponding head concept. 91 Again, verbs like LOVE would need a (REASON ANY) component in their coding, expressing the notion that such states (as opposed to actions, both defined ir terms of the main semantic primitives of verbs) are dependent on some reason, which could be anything. But the clearest defect of Rule A (and, by implication, of all the verbcentered approaches discussed earlier in the paper) is that verbs in fact confront not cases, but PPs fronted by ambiguous prepositions, and it is only by taking account of their preferences that a general solution can be found. PREPOSITION SEMANTICS: PREPLATES In fact rule A was intentionally naive: it was designed to demonstrate (as against Shubert&apos;s claims in particular) the wide coverage of the data of a single semantics-based rule, even if that required additional, hard to motivate, semantic information to be given for action and states. It was stated in a verb-based lexical preference mode simply to achieve contrast with the other systems discussed. For some years, it has been a principle of preference semantics (e.g. Wilks 1973, 1975) that attachment relations of phrases, clauses etc. are to be determined by comparing the preferences emanating from all the entities involved in an attachment: they are all, as it were, to be considered as objects seeking other preferred classes of neighbors, and the best fit, within and between each order of structures built up, is to be found by comparing the preferences and finding a best mutual fit. This point was made in (Wilks 1976) by contrasting preference semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the preplate notation of (Huang 19846). We have implemented in CASSEX (see Wilks, Huang and Fass, 1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot; and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more generally those of any entity which is a candidate for the root of the attachment, as opposed to what is attached) and of what-is-attached first (i.e. prepositional phrases). We can also control for the application of a more redundant form of rule where we attach preferably on the conjunction of satisfactions of the preferences of the root and the attached (e.g. for such a rule, satisfaction would require both that the verb preferred a prepositional phrase of such a class, and that the prepositional phrase preferred a verb of such a class). In (Wilks, Huang &amp; Fass 1985) we describe the algorithm that best fits the data and alternates between the use of semantic information attached to verbs and nouns (i.e. the roots for attachments as in Rule A) and that of prepositions; it does this by seeking the best mutual fit between them, and without any fall back to default syntactic rules like (i) and (ii). This strategy, implemented within Huang&apos;s (1984a, 19846) CASSEX program, correctly parses all of the example sentences in this paper. CASSEX, which is written in Prolog on the Essex GEC. 63, uses a definite clause grammar (DCG) to recognize syntactic constituents and Preference Semantics to provide their semantic interpretation. Its content is described in detail in (Wilks, Huang &amp; Fass 1985) and it consists in allowing the preferences of both the clause verbs and the prepositions themselves to operate on each other and compete in a perspicuous and determinate manner, without recourse to syntactic preferences or weightings.</abstract>
<note confidence="0.722259">REFERENCES Boguraev, B.K. (1979) &amp;quot;Automatic Resolution of Linguistic Ambiguities.&amp;quot; Technical Report No.11, University of Cambridge Computer Laboratory, Cambridge.</note>
<author confidence="0.309263">S Crain</author>
<author confidence="0.309263">M On Not Being Led Up The Garden Steedman</author>
<affiliation confidence="0.739806">Path : The Use of Context by the Psychological Parser.&amp;quot; In Dowty, &amp; A.M. Zwicky (Eds.), and How People Parse Sentences, University Press.</affiliation>
<address confidence="0.944996">Fass, D.C. &amp; Wilks, Y.A. (1983) &amp;quot;Preference Semantics, Ill-</address>
<affiliation confidence="0.781471">and Metaphor,&amp;quot; Journal of Compu-</affiliation>
<note confidence="0.732957">Linguistics, pp. Ford, M., Bresnan, J. &amp; Kaplan, R. (1981) &amp;quot;A Competence-Based of Syntactic Closure.&amp;quot; In J. Bresnan (Ed.), Men- Representation of Grammatical Relations, MA : MIT Press. Frazier, L. &amp; Fodor, J. (1979) &amp;quot;The Sausage Machine: A New Two- Parsing Model.&amp;quot; pp.191-325.</note>
<author confidence="0.827183">H P Logic Grice</author>
<author confidence="0.827183">Conversation In P Cole</author>
<author confidence="0.827183">J Morgan</author>
<affiliation confidence="0.802601">and Semantics 3 : Speech Acts,</affiliation>
<address confidence="0.6892">Hirst, G. (1983) &amp;quot;Semantic Interpretation against Ambiguity.&amp;quot;</address>
<note confidence="0.909874166666667">Technical Report CS-83-25, Dept. of Computer Science, Brown University. Hirst, G. (1984) &amp;quot;A Semantic Process for Syntactic Disambiguaof Texas, pp. 148-152. Huang, X-M. (1984a) &amp;quot;The Generation of Chinese Sentences from the Representations of English Sentences.&amp;quot; of</note>
<affiliation confidence="0.747123">International Conference on Machine Translation,</affiliation>
<address confidence="0.853219">Cranfield, England.</address>
<note confidence="0.974623545454546">Huang, X-M. (1984b) &amp;quot;A Computational Treatment of Gapping, Node Raising &amp; Reduced Conjunction.&amp;quot; of CA., pp. 243-246. Riesbeck, C. (1975) &amp;quot;Conceptual Analysis.&amp;quot; In R. C. Schank (Ed.), Information Processing, .Amsterdam North Holland. G. (1978) Grammar. : Harvester. Shieber, S.M. (1983) &amp;quot;Sentence Disambiguation by a Shift-Reduced Technique.&amp;quot; of W. Germany, pp. 699-703. L.K. (1984) &amp;quot;On Parsing Preferences.&amp;quot; of CA., pp. 247-250. Y.A. (1973) &amp;quot;Understanding without Proofs.&amp;quot; of CA. Wilks, Y.A. (1975) &amp;quot;A Preferential Pattern-Seeking Semantics for Language Inference.&amp;quot; Intelligence, pp. 53-74. Y.A. (1976) &amp;quot;Processing Case.&amp;quot; Journal of Linguistics, T. (1972) Natural Language. York : Academic Press.</note>
<intro confidence="0.469443">92</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
</authors>
<title>Automatic Resolution of Linguistic Ambiguities.&amp;quot;</title>
<date>1979</date>
<tech>Technical Report No.11,</tech>
<institution>University of Cambridge Computer Laboratory,</institution>
<location>Cambridge.</location>
<contexts>
<context position="16639" citStr="Boguraev 1979" startWordPosition="2780" endWordPosition="2781">, to be considered as objects seeking other preferred classes of neighbors, and the best fit, within and between each order of structures built up, is to be found by comparing the preferences and finding a best mutual fit. This point was made in (Wilks 1976) by contrasting preference semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the preplate notation of (Huang 19846). We have implemented in CASSEX (see Wilks, Huang and Fass, 1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot; and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more generally those of any entity which is a candidate for the root of the attachment, as opposed to what is attached) and of</context>
</contexts>
<marker>Boguraev, 1979</marker>
<rawString>Boguraev, B.K. (1979) &amp;quot;Automatic Resolution of Linguistic Ambiguities.&amp;quot; Technical Report No.11, University of Cambridge Computer Laboratory, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>M Steedman</author>
</authors>
<title>On Not Being Led Up The Garden Path : The Use of Context by the Psychological Parser.&amp;quot;</title>
<date>1984</date>
<booktitle>In D.R. Dowty, L.J. Karttunen &amp; A.M. Zwicky (Eds.), Syntactic Theory and How People Parse Sentences,</booktitle>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7389" citStr="Crain and Steedman (1984)" startWordPosition="1242" endWordPosition="1245">imple examples but very complex ones, involving distance and (in two cases) information quantity phenomena. In none of the cases do they support the straightforward primacy of syntax that his case against a generalized &amp;quot;lexical preference hypothesis&amp;quot; (i.e. one without rules (i) and (ii) as default cases, as in Ford et al.&apos;s lexical preference) would require. We shall therefore consider that hypothesis, under the name preference semantics, to be still under consideration. (iii) Hirst Hirst (1984) aims to produce a conflation of the approaches of Ford et al., described above, and a principle of Crain and Steedman (1984) called The Principle of Parsimony, which is to make an attachment that corresponds to leaving the minimum number of presuppositions unsatisfied. The example usually given is that of a &amp;quot;garden path&amp;quot; sentence like : THE HORSE RACED PAST THE BARN FELL where the natural (initial) preference for the garden path interpretation is to be explained by the fact that, on that interpretation, only the existence of an entity corresponding to THE HORSE is to be presupposed, and that means less presuppositions to which nothing is the memory structure corresponds than is needed to opt for the existence of so</context>
</contexts>
<marker>Crain, Steedman, 1984</marker>
<rawString>Crain, S. &amp; Steedman, M. (1984) &amp;quot;On Not Being Led Up The Garden Path : The Use of Context by the Psychological Parser.&amp;quot; In D.R. Dowty, L.J. Karttunen &amp; A.M. Zwicky (Eds.), Syntactic Theory and How People Parse Sentences, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Fass</author>
<author>Y A Wilks</author>
</authors>
<title>Preference Semantics, IllFormedness and Metaphor,&amp;quot;</title>
<date>1983</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>9</volume>
<pages>178--187</pages>
<contexts>
<context position="12892" citStr="Fass &amp; Wilks 1983" startWordPosition="2170" endWordPosition="2173">at these notions are not yet in a state to be the basis of a theory of PP attachment. Moreover, even though beliefs about the world must play a role in attachment in certain cases, there is, as yet, no reason to believe that beliefs and presuppositions can provide the material for a basic attachment mechanism. (iv) Preference Semantics Preference Semantics has claimed that appropriate structurings can be obtained using essentially semantic information, given also a rule of preferring the most densely connected representations that can be constructed from such semantic information (Wilks 1975, Fass &amp; Wilks 1983). Let us consider such a position initially expressed as semantic dictionary information attaching to the verb; this is essentially the position of the systems discussed above, as well as of case grammar. and the semantics- based parsing systems (e.g. Riesbeck 1975) that have been based on it. When discussing implementation in the last section we shall argue (as in Wilks 1978) that semantic material that is to be the base of a parsing process cannot be thought of as simply attaching to a verb (rather than to nouns and all other word senses) In what follows we shall assume case predicates in th</context>
</contexts>
<marker>Fass, Wilks, 1983</marker>
<rawString>Fass, D.C. &amp; Wilks, Y.A. (1983) &amp;quot;Preference Semantics, IllFormedness and Metaphor,&amp;quot; American Journal of Computational Linguistics, 9, pp. 178-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ford</author>
<author>J Bresnan</author>
<author>R Kaplan</author>
</authors>
<title>A Competence-Based Theory of Syntactic Closure.&amp;quot; In</title>
<date>1981</date>
<editor>J. Bresnan (Ed.),</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA :</location>
<contexts>
<context position="2462" citStr="Ford et al. (1981)" startWordPosition="423" endWordPosition="426">ing FOR MARY to the top of the tree, rather than to the NP, will create a tree with one less node. Shieber (1983) has an alternative analysis of this phenomenon, based on a clear parsing model, which produces the same effect as rule (ii) by preferring longer reductions in the parsing table; i.e., in the present case, preferring VP &lt;— V NP PP to NP &lt;— NP PP. But there are still problems with (i) and (ii) taken together, as is seen in: SHE WANTED THE DRESS (ON THAT RACK) rather than attaching (ON THAT RACK) to WANTED, as (ii) would cause. SEMANTIC APPROACHES (i) Lexical Preference At this point Ford et al. (1981) suggested the use of lexical preference, which is conventional case information associated with individual verbs, so as to select for attachment PPs which match that case information. This is semantic information in the broad sense in which that term has traditionally been used in Al. Lexical preference allows rules (i) and (ii) above to be overridden if a verb&apos;s coding expresses a strong preference for a certain structure. The effect of that rule differs from system to system: within Shieber&apos;s parsing model (1983) that rule means in effect that a verb like WANT will prefer to have only a sin</context>
</contexts>
<marker>Ford, Bresnan, Kaplan, 1981</marker>
<rawString>Ford, M., Bresnan, J. &amp; Kaplan, R. (1981) &amp;quot;A Competence-Based Theory of Syntactic Closure.&amp;quot; In J. Bresnan (Ed.), The Mental Representation of Grammatical Relations, Cambridge, MA : MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
<author>J Fodor</author>
</authors>
<title>The Sausage Machine: A New TwoStage Parsing Model.&amp;quot;</title>
<date>1979</date>
<journal>Cognition,</journal>
<volume>6</volume>
<pages>191--325</pages>
<contexts>
<context position="1159" citStr="Frazier and Fodor (1979)" startWordPosition="175" endWordPosition="178">Hirst which are quasi-semantic in nature and which we consider ingenious but unsatisfactory. We point towards a straightforward solution within the framework of preference semantics, set out in detail elsewhere, and argue that the principal issue is not the type and nature of information required to get appropriate phrase attachments, but the issue of where to store the information and with what processes to apply it. SYNTACTIC APPROACHES Recent discussion of the issue of how and where to attach right-hand phrases (and more generally, clauses) in sentence analysis was started by the claims of Frazier and Fodor (1979). They offered two rules : (i) Right Association which is that phrases on the right should be attached as low as possible on a syntax tree, thus JOHN BOUGHT THE BOOK THAT I HAD BEEN TRYING TO OBTAIN (FOR SUSAN) which attaches to OBTAIN not to BOUGHT. But this rule fails for JOHN BOUGHT THE BOOK (FOR SUSAN) which requires attachment to BOUGHT not BOOK. A second principle was then added : (ii) Minimal Attachment which is that a phrase must be attached higher in a tree if doing that minimizes the number of nodes in the tree (and this rule is to take precedence over (i)). So, in : VP V V NP PP car</context>
</contexts>
<marker>Frazier, Fodor, 1979</marker>
<rawString>Frazier, L. &amp; Fodor, J. (1979) &amp;quot;The Sausage Machine: A New TwoStage Parsing Model.&amp;quot; Cognition, 6, pp.191-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic &amp; Conversation.&amp;quot; In</title>
<date>1975</date>
<pages>41--58</pages>
<publisher>Academie Press,</publisher>
<marker>Grice, 1975</marker>
<rawString>Grice, H. P. (1975) &amp;quot;Logic &amp; Conversation.&amp;quot; In P. Cole &amp; J. Morgan (Eds.), Syntax and Semantics 3 : Speech Acts, Academie Press, pp. 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
</authors>
<title>Semantic Interpretation against Ambiguity.&amp;quot;</title>
<date>1983</date>
<tech>Technical Report CS-83-25,</tech>
<institution>Dept. of Computer Science, Brown University.</institution>
<marker>Hirst, 1983</marker>
<rawString>Hirst, G. (1983) &amp;quot;Semantic Interpretation against Ambiguity.&amp;quot; Technical Report CS-83-25, Dept. of Computer Science, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
</authors>
<title>A Semantic Process for Syntactic Disambiguation.&amp;quot;</title>
<date>1984</date>
<booktitle>Proc. of AAAI-84,</booktitle>
<pages>148--152</pages>
<location>Austin, Texas,</location>
<contexts>
<context position="7264" citStr="Hirst (1984)" startWordPosition="1222" endWordPosition="1223">n of the verb to NAME+AFTER. Our conclusion from Schubert&apos;s examples is the reverse of his own : these are not simple examples but very complex ones, involving distance and (in two cases) information quantity phenomena. In none of the cases do they support the straightforward primacy of syntax that his case against a generalized &amp;quot;lexical preference hypothesis&amp;quot; (i.e. one without rules (i) and (ii) as default cases, as in Ford et al.&apos;s lexical preference) would require. We shall therefore consider that hypothesis, under the name preference semantics, to be still under consideration. (iii) Hirst Hirst (1984) aims to produce a conflation of the approaches of Ford et al., described above, and a principle of Crain and Steedman (1984) called The Principle of Parsimony, which is to make an attachment that corresponds to leaving the minimum number of presuppositions unsatisfied. The example usually given is that of a &amp;quot;garden path&amp;quot; sentence like : THE HORSE RACED PAST THE BARN FELL where the natural (initial) preference for the garden path interpretation is to be explained by the fact that, on that interpretation, only the existence of an entity corresponding to THE HORSE is to be presupposed, and that </context>
</contexts>
<marker>Hirst, 1984</marker>
<rawString>Hirst, G. (1984) &amp;quot;A Semantic Process for Syntactic Disambiguation.&amp;quot; Proc. of AAAI-84, Austin, Texas, pp. 148-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X-M Huang</author>
</authors>
<title>The Generation of Chinese Sentences from the Semantic Representations of English Sentences.&amp;quot;</title>
<date>1984</date>
<booktitle>Proc. of International Conference on Machine Translation,</booktitle>
<location>Cranfield, England.</location>
<contexts>
<context position="16916" citStr="Huang 1984" startWordPosition="2824" endWordPosition="2825">nce semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the preplate notation of (Huang 19846). We have implemented in CASSEX (see Wilks, Huang and Fass, 1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot; and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more generally those of any entity which is a candidate for the root of the attachment, as opposed to what is attached) and of what-is-attached first (i.e. prepositional phrases). We can also control for the application of a more redundant form of rule where we attach preferably on the conjunction of satisfactions of the preferences of the root and the attached (e.g. for such a rule, satisfaction wou</context>
</contexts>
<marker>Huang, 1984</marker>
<rawString>Huang, X-M. (1984a) &amp;quot;The Generation of Chinese Sentences from the Semantic Representations of English Sentences.&amp;quot; Proc. of International Conference on Machine Translation, Cranfield, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X-M Huang</author>
</authors>
<title>A Computational Treatment of Gapping, Right Node Raising &amp; Reduced Conjunction.&amp;quot;</title>
<date>1984</date>
<booktitle>Proc. of COLING-84,</booktitle>
<pages>243--246</pages>
<location>Stanford, CA.,</location>
<contexts>
<context position="16916" citStr="Huang 1984" startWordPosition="2824" endWordPosition="2825">nce semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the preplate notation of (Huang 19846). We have implemented in CASSEX (see Wilks, Huang and Fass, 1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot; and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more generally those of any entity which is a candidate for the root of the attachment, as opposed to what is attached) and of what-is-attached first (i.e. prepositional phrases). We can also control for the application of a more redundant form of rule where we attach preferably on the conjunction of satisfactions of the preferences of the root and the attached (e.g. for such a rule, satisfaction wou</context>
</contexts>
<marker>Huang, 1984</marker>
<rawString>Huang, X-M. (1984b) &amp;quot;A Computational Treatment of Gapping, Right Node Raising &amp; Reduced Conjunction.&amp;quot; Proc. of COLING-84, Stanford, CA., pp. 243-246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Riesbeck</author>
</authors>
<title>Conceptual Analysis.&amp;quot; In</title>
<date>1975</date>
<booktitle>Conceptual Information Processing,</booktitle>
<publisher>North Holland.</publisher>
<location>Amsterdam :</location>
<contexts>
<context position="13158" citStr="Riesbeck 1975" startWordPosition="2213" endWordPosition="2214">aterial for a basic attachment mechanism. (iv) Preference Semantics Preference Semantics has claimed that appropriate structurings can be obtained using essentially semantic information, given also a rule of preferring the most densely connected representations that can be constructed from such semantic information (Wilks 1975, Fass &amp; Wilks 1983). Let us consider such a position initially expressed as semantic dictionary information attaching to the verb; this is essentially the position of the systems discussed above, as well as of case grammar. and the semantics- based parsing systems (e.g. Riesbeck 1975) that have been based on it. When discussing implementation in the last section we shall argue (as in Wilks 1978) that semantic material that is to be the base of a parsing process cannot be thought of as simply attaching to a verb (rather than to nouns and all other word senses) In what follows we shall assume case predicates in the dictionary entries of verbs, nouns etc. that express part of the meaning of the concept and determine its semantic relations. We shall write as [OBTAIN] the abbreviation of the semantic dictionary entry for OBTAIN, and assume that the following concepts contain at</context>
</contexts>
<marker>Riesbeck, 1975</marker>
<rawString>Riesbeck, C. (1975) &amp;quot;Conceptual Analysis.&amp;quot; In R. C. Schank (Ed.), Conceptual Information Processing, .Amsterdam : North Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
</authors>
<title>Computational Grammar. Hassocks :</title>
<date>1978</date>
<publisher>Harvester.</publisher>
<contexts>
<context position="8678" citStr="Ritchie 1978" startWordPosition="1460" endWordPosition="1461">thing to exist in memory: Crain and Steedman themselves note that readers do not garden path with sentences like : CARS RACED AT MONTE CARLO FETCH HIGH PRICES AS COLLECTOR&apos;S ITEMS but that is not because readers know of any particular cars raced at Monte Carlo. Hirst accepts from (Winograd 1972) a general Principle of Referential Success (i.e. to actual existent entities), but the general unsatisfactoriness of restricting a system to actual entities has long been known, for so much of our discourse is about possible and virtual ontologies (for a full discussion of this aspect of Winograd, see Ritchie 1978). The strength of Hirst&apos;s approach is his attempt to reduce the presuppositional metric of CraM and Steedman to criteria manipulable by basic semantic/lexical codings, and particularly the contrast of definite and indefinite articles. But the general determination of categories like definite and indefinite is so shaky (and only indirectly related to &amp;quot;the&amp;quot; and &amp;quot;a&amp;quot; in English), and cannot possibly bear the weight that he puts on it as the solid basis of a theory of phrase attachment. 90 A FIRST TRIAL ATTACHMENT RULE The examples discussed are correctly attached by the following rule : Rule A : m</context>
</contexts>
<marker>Ritchie, 1978</marker>
<rawString>Ritchie, G. (1978) Computational Grammar. Hassocks : Harvester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Sentence Disambiguation by a Shift-Reduced Parsing Technique.&amp;quot;</title>
<date>1983</date>
<booktitle>Proc. of IJCAI-83, Kahlsruhe,</booktitle>
<pages>699--703</pages>
<location>W.</location>
<contexts>
<context position="1957" citStr="Shieber (1983)" startWordPosition="332" endWordPosition="333">YING TO OBTAIN (FOR SUSAN) which attaches to OBTAIN not to BOUGHT. But this rule fails for JOHN BOUGHT THE BOOK (FOR SUSAN) which requires attachment to BOUGHT not BOOK. A second principle was then added : (ii) Minimal Attachment which is that a phrase must be attached higher in a tree if doing that minimizes the number of nodes in the tree (and this rule is to take precedence over (i)). So, in : VP V V NP PP carried NP PP for Mary / groceries for Mary JOHN CARRIED THE GROCERIES (FOR MARY) attaching FOR MARY to the top of the tree, rather than to the NP, will create a tree with one less node. Shieber (1983) has an alternative analysis of this phenomenon, based on a clear parsing model, which produces the same effect as rule (ii) by preferring longer reductions in the parsing table; i.e., in the present case, preferring VP &lt;— V NP PP to NP &lt;— NP PP. But there are still problems with (i) and (ii) taken together, as is seen in: SHE WANTED THE DRESS (ON THAT RACK) rather than attaching (ON THAT RACK) to WANTED, as (ii) would cause. SEMANTIC APPROACHES (i) Lexical Preference At this point Ford et al. (1981) suggested the use of lexical preference, which is conventional case information associated wit</context>
</contexts>
<marker>Shieber, 1983</marker>
<rawString>Shieber, S.M. (1983) &amp;quot;Sentence Disambiguation by a Shift-Reduced Parsing Technique.&amp;quot; Proc. of IJCAI-83, Kahlsruhe, W. Germany, pp. 699-703.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L K Shubert</author>
</authors>
<title>On Parsing Preferences.&amp;quot;</title>
<date>1984</date>
<booktitle>Proc. of COLING-84,</booktitle>
<pages>247--250</pages>
<location>Stanford, CA.,</location>
<marker>Shubert, 1984</marker>
<rawString>Shubert, L.K. (1984) &amp;quot;On Parsing Preferences.&amp;quot; Proc. of COLING-84, Stanford, CA., pp. 247-250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
</authors>
<title>Understanding without Proofs.&amp;quot;</title>
<date>1973</date>
<booktitle>Proc. of IJCAI-73,</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="6142" citStr="Wilks, 1973" startWordPosition="1043" endWordPosition="1044">s on leave and not when something was done. In such circumstances the example presents no special problems. JOHN MET A TALL SUM AUBUN HAIRED GIRL FROM MONTREAL THAT HE MARRIED (AT A DANCE) Here our informants attach the phrase resolutely to MET as commonsense dictates (i.e. they ignore or are able to discount the built-in distance effect of the very long NP). A more difficult and interesting case arises if the last phrase is (AT A WEDDING), since the example then seems to fall withing the exclusion of an &amp;quot;attachment unless it yields zero information&amp;quot; rule deployed within preference semantics (Wilks, 1973), which is probably, in its turn, a close relative of Grice&apos;s (1975) maxim concerned with information quantity. In the Here our informants saw genuine ambiguity and did not seem to mind much whether attachment or lexicalization of NAMED AFTER was preferred. Again, information vacuity tells against the syntactic attachment (the example is on the model of : HE WAS NAMED AFTER HIS FATHER Wilks 1973, which was used to make a closely related point), but normal gendering of names tells against the lexicalization of the verb to NAME+AFTER. Our conclusion from Schubert&apos;s examples is the reverse of his</context>
<context position="15833" citStr="Wilks 1973" startWordPosition="2651" endWordPosition="2652">s, and it is only by taking account of their preferences that a general solution can be found. PREPOSITION SEMANTICS: PREPLATES In fact rule A was intentionally naive: it was designed to demonstrate (as against Shubert&apos;s claims in particular) the wide coverage of the data of a single semantics-based rule, even if that required additional, hard to motivate, semantic information to be given for action and states. It was stated in a verb-based lexical preference mode simply to achieve contrast with the other systems discussed. For some years, it has been a principle of preference semantics (e.g. Wilks 1973, 1975) that attachment relations of phrases, clauses etc. are to be determined by comparing the preferences emanating from all the entities involved in an attachment: they are all, as it were, to be considered as objects seeking other preferred classes of neighbors, and the best fit, within and between each order of structures built up, is to be found by comparing the preferences and finding a best mutual fit. This point was made in (Wilks 1976) by contrasting preference semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to b</context>
</contexts>
<marker>Wilks, 1973</marker>
<rawString>Wilks, Y.A. (1973) &amp;quot;Understanding without Proofs.&amp;quot; Proc. of IJCAI-73, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
</authors>
<title>A Preferential Pattern-Seeking Semantics for Natural Language Inference.&amp;quot;</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<volume>6</volume>
<pages>53--74</pages>
<contexts>
<context position="12872" citStr="Wilks 1975" startWordPosition="2168" endWordPosition="2169"> conclude that these notions are not yet in a state to be the basis of a theory of PP attachment. Moreover, even though beliefs about the world must play a role in attachment in certain cases, there is, as yet, no reason to believe that beliefs and presuppositions can provide the material for a basic attachment mechanism. (iv) Preference Semantics Preference Semantics has claimed that appropriate structurings can be obtained using essentially semantic information, given also a rule of preferring the most densely connected representations that can be constructed from such semantic information (Wilks 1975, Fass &amp; Wilks 1983). Let us consider such a position initially expressed as semantic dictionary information attaching to the verb; this is essentially the position of the systems discussed above, as well as of case grammar. and the semantics- based parsing systems (e.g. Riesbeck 1975) that have been based on it. When discussing implementation in the last section we shall argue (as in Wilks 1978) that semantic material that is to be the base of a parsing process cannot be thought of as simply attaching to a verb (rather than to nouns and all other word senses) In what follows we shall assume c</context>
<context position="16612" citStr="Wilks 1975" startWordPosition="2777" endWordPosition="2778">they are all, as it were, to be considered as objects seeking other preferred classes of neighbors, and the best fit, within and between each order of structures built up, is to be found by comparing the preferences and finding a best mutual fit. This point was made in (Wilks 1976) by contrasting preference semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the preplate notation of (Huang 19846). We have implemented in CASSEX (see Wilks, Huang and Fass, 1985) a range of alternatives to Rule A : controlling both for &amp;quot;low&amp;quot; and &amp;quot;high&amp;quot; default; for examination of verb preferences first (or more generally those of any entity which is a candidate for the root of the attachment, as opposed </context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Wilks, Y.A. (1975) &amp;quot;A Preferential Pattern-Seeking Semantics for Natural Language Inference.&amp;quot; Artificial Intelligence, 6, pp. 53-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y A Wilks</author>
</authors>
<title>Processing Case.&amp;quot;</title>
<date>1976</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>56</volume>
<contexts>
<context position="16283" citStr="Wilks 1976" startWordPosition="2728" endWordPosition="2729">cal preference mode simply to achieve contrast with the other systems discussed. For some years, it has been a principle of preference semantics (e.g. Wilks 1973, 1975) that attachment relations of phrases, clauses etc. are to be determined by comparing the preferences emanating from all the entities involved in an attachment: they are all, as it were, to be considered as objects seeking other preferred classes of neighbors, and the best fit, within and between each order of structures built up, is to be found by comparing the preferences and finding a best mutual fit. This point was made in (Wilks 1976) by contrasting preference semantics with the simple verb-based requests of Riesbeck&apos;s (1975) MARGIE parser. It was argued there that account had to be taken of both the preferences of verbs (and nouns), and of the preferences cued from the prepositions themselves. Those preferences were variously called paraplates (Wilks 1975), preplates (Boguraev 1979) and they were, for each preposition sense, an ordered set of predication preferences restricted by action or noun type. (Wilks 1975) contains examples of ordered paraplate stacks and their functioning, but in what follows we shall stick to the</context>
</contexts>
<marker>Wilks, 1976</marker>
<rawString>Wilks, Y.A. (1976) &amp;quot;Processing Case.&amp;quot; American Journal of Computational Linguistics, 56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language.</title>
<date>1972</date>
<publisher>Academic Press.</publisher>
<location>New York :</location>
<contexts>
<context position="8361" citStr="Winograd 1972" startWordPosition="1409" endWordPosition="1410">t, on that interpretation, only the existence of an entity corresponding to THE HORSE is to be presupposed, and that means less presuppositions to which nothing is the memory structure corresponds than is needed to opt for the existence of some THE HORSE RACED PAST THE BARN. One difficulty here is what it is for something to exist in memory: Crain and Steedman themselves note that readers do not garden path with sentences like : CARS RACED AT MONTE CARLO FETCH HIGH PRICES AS COLLECTOR&apos;S ITEMS but that is not because readers know of any particular cars raced at Monte Carlo. Hirst accepts from (Winograd 1972) a general Principle of Referential Success (i.e. to actual existent entities), but the general unsatisfactoriness of restricting a system to actual entities has long been known, for so much of our discourse is about possible and virtual ontologies (for a full discussion of this aspect of Winograd, see Ritchie 1978). The strength of Hirst&apos;s approach is his attempt to reduce the presuppositional metric of CraM and Steedman to criteria manipulable by basic semantic/lexical codings, and particularly the contrast of definite and indefinite articles. But the general determination of categories like</context>
</contexts>
<marker>Winograd, 1972</marker>
<rawString>Winograd, T. (1972) Understanding Natural Language. New York : Academic Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>