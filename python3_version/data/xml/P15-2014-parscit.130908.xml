<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001881">
<title confidence="0.9958515">
Using prosodic annotations to improve coreference resolution
of spoken text
</title>
<author confidence="0.991448">
Ina R¨osiger and Arndt Riester
</author>
<affiliation confidence="0.9966">
Institute for Natural Language Processing
University of Stuttgart, Germany
</affiliation>
<address confidence="0.935054">
Pfaffenwaldring 5b, 70569 Stuttgart
</address>
<email confidence="0.997705">
roesigiaIarndt@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.993862" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999974090909091">
This paper is the first to examine the effect
of prosodic features on coreference resolu-
tion in spoken discourse. We test features
from different prosodic levels and investi-
gate which strategies can be applied. Our
results on the basis of manual prosodic la-
belling show that the presence of an accent
is a helpful feature in a machine-learning
setting. Including prosodic boundaries and
determining whether the accent is the nu-
clear accent further increases results.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999335456521739">
Noun phrase coreference resolution is the task of
determining which noun phrases (NPs) in a text
or dialogue refer to the same discourse entities
(Ng, 2010). Coreference resolution has been ex-
tensively addressed in NLP research, e.g. in the
CoNLL shared task 2012 (Pradhan et al., 2012)
or in the SemEval shared task 2010 (Recasens et
al., 2010). Amoia et al. (2012) have shown that
there are differences between written and spoken
text wrt coreference resolution and that the per-
formance typically drops when systems that have
been developed for written text are applied on spo-
ken text. There has been considerable work on
coreference resolution in written text, but com-
paratively little work on spoken text, with a few
exceptions of systems for pronoun resolution in
transcripts of spoken text e.g. Strube and M¨uller
(2003), Tetreault and Allen (2004). However,
so far, prosodic information has not been taken
into account. The interaction between prosodic
prominence and coreference has been investigated
in several experimental and theoretical analyses
(Terken and Hirschberg, 1994; Schwarzschild,
1999; Cruttenden, 2006); for German (Baumann
and Riester, 2013; Baumann and Roth, 2014; Bau-
mann et al., 2015).
There is a tendency for coreferent items, i.e. en-
tities that have already been introduced into the
discourse, to be deaccented, as the speaker as-
sumes the entity to be salient in the listener’s dis-
course model. We can exploit this by including
prominence features in the coreference resolver.
Our prosodic features mainly aim at definite
descriptions, where it is difficult for the resolver
to decide whether the potential anaphor is actu-
ally anaphoric or not. In these cases, accentua-
tion is an important means to distinguish between
given entities (often deaccented) and other cate-
gories (i.e. bridging anaphors, see below) that are
typically accented, particularly for entities whose
heads have a different lexeme than their potential
antecedent. Pronouns are not the case of inter-
est here, as they are (almost) always anaphoric.
To make the intuitions clearer, Example (1), taken
from Umbach (2002), shows the difference promi-
nence can make:
</bodyText>
<listItem confidence="0.996734666666667">
(1) John has an old cottage.1
a. Last year he reconstructed the SHED.
b. Last year he reconSTRUCted the shed.
</listItem>
<bodyText confidence="0.999914571428571">
Due to the pitch accent on shed in (1a), it is quite
obvious that the shed and the cottage refer to dif-
ferent entities; they exemplify a bridging relation,
where the shed is a part of the cottage. In (1b),
however, the shed is deaccented, which has the ef-
fect that the shed and the cottage corefer.
We present a pilot study on German spoken
text that uses manual prominence marking to show
the principled usefulness of prosodic features for
coreference resolution. In the long run and for
application-based settings, of course, we do not
want to rely on manual annotations. This work is
investigating the potential of prominence informa-
tion and is meant to motivate the use of automatic
</bodyText>
<footnote confidence="0.9821655">
1Anaphors are typed in boldface, their antecedents are un-
derlined. Accented syllables are capitalised.
</footnote>
<page confidence="0.946317">
83
</page>
<bodyText confidence="0.899357230769231">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 83–88,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
prosodic features. Our study deals with German
data, but the prosodic properties are comparable
to other West Germanic languages, like English or
Dutch. To the best of our knowledge, this is the
first work on coreference resolution in spoken text
that tests the theoretical claims regarding the inter-
action between coreference and prominence in a
general, state-of-the-art coreference resolver, and
shows that prosodic features improve coreference
resolution.
</bodyText>
<sectionHeader confidence="0.9446195" genericHeader="method">
2 Prosodic features for coreference
resolution
</sectionHeader>
<bodyText confidence="0.999949469387755">
The prosodic information used for the purpose of
our research results from manual annotations that
follow the GToBI(S) guidelines by Mayer (1995),
which stand in the tradition of autosegmental-
metrical phonology, cf. Pierrehumbert (1980),
Gussenhoven (1984), F´ery (1993), Ladd (2008),
Beckman et al. (2005). We mainly make use of
pitch accents and prosodic phrasing. The an-
notations distinguish intonation phrases, termi-
nated by a major boundary (%), and intermediate
phrases, closed by a minor boundary (-), as shown
in Examples (2) and (3).
The available pitch accent and boundary an-
notations allow us to automatically derive a sec-
ondary layer of prosodic information which rep-
resents a mapping of the pitch accents onto a
prominence scale in which the nuclear (i.e. final)
accents of an intonation phrase (n2) rank as the
most prominent, followed by the nuclear accents
of intermediate phrases (n1) and prenuclear (i.e.
non-final) accents which are perceptually the least
prominent. To put it simply, the nuclear accent
is the most prominent accent in a prosodic phrase
while prenuclear accents are less prominent.
While we expect the difference between the
presence or absence of pitch accents to influence
the classification of short NPs like in Example
(1), we do not expect complex NPs to be fully
deaccented. For complex NPs, we nevertheless
hope that the prosodic structure of coreferential
NPs will turn out to significantly differ from the
structure of discourse-new NPs such as to yield
a measurable effect. Examples (2) and (3) show
the prosodic realisation of two expressions with
different information status. In Example (2), the
complex NP the text about the aims and future
of the EU refers back to the Berlin Declaration,
whereas in Example (3), the complex NP assault
with lethal consequences and reckless homicide is
not anaphoric. The share of prenuclear accents
is higher in the anaphoric case, which indicates
lower overall prominence. The features described
in Section 2.1 only take into account the absence
or type of the pitch accent; those in Section 2.2
additionally employ prosodic phrasing. To get a
better picture of the effect of these features, we im-
plement, for each feature, one version for all noun
phrases and a second version only for short noun
phrases (&lt;=4 words).
</bodyText>
<subsectionHeader confidence="0.9252885">
2.1 Prosodic features ignorant of phrase
boundaries
</subsectionHeader>
<bodyText confidence="0.998807666666667">
Pitch accent type corresponds to the following
pitch accent types that are present in the GToBI(S)
based annotations.
</bodyText>
<figure confidence="0.975464142857143">
Fall H*L
Rise L*H
Downstep fall !H*L
High target H*
Low target L*
Early peak HH*L
Late peak L*HL
</figure>
<bodyText confidence="0.997661571428571">
For complex NPs, the crucial label is the last la-
bel in the mention. For short NPs, this usually
matches the label on the syntactic head.
Pitch accent presence focuses on the presence
of a pitch accent, disregarding its type. If one ac-
cent is present in the markable, the boolean feature
gets assigned the value true, and false otherwise.
</bodyText>
<subsectionHeader confidence="0.8942055">
2.2 Prosodic features including phrase
boundary information
</subsectionHeader>
<bodyText confidence="0.999991882352941">
The following set of features takes into account the
degree of prominence of pitch accents as presented
at the beginning of Section 2, which at the same
time encodes information about prosodic phras-
ing.
Nuclear accent type looks at the different de-
grees of accent prominence. The markable gets
assigned the type n2, n1, pn if the last accent in
the phrase matches one of the types (and none if it
is deaccented).
Nuclear accent presence is a Boolean feature
comparable to pitch accent presence. It gets as-
signed the value true if there is some kind of ac-
cent present in the markable. To be able to judge
the helpfulness of the distinction between the cat-
egories that are introduced above, we experiment
with two different versions:
</bodyText>
<page confidence="0.982422">
84
</page>
<listItem confidence="0.89423475">
(2) Anaphoric complex NP (DIRNDL sentences 9/10):
9: Im Mittelpunkt steht eine von der Ratspr¨asidentin, Bundeskanzlerin Merkel, vorbereitete “Berliner Erkl¨arung”.
10: Die Pr¨asidenten [... ] wollen [den TEXT ¨uber die ZIEle und ZUkunft der EU] unterzeichnen.
the presidents [... ] want [the text about the aims and future the EU] sign
</listItem>
<equation confidence="0.7573735">
(( L*H L*H-) ( H*L H*L H*L -)%)
pn n1 pn pn
</equation>
<bodyText confidence="0.947845">
Central is the ’Berlin Declaration’ that was prepared by the president of the Council of the EU, Chancellor Merkel.
The presidents want to sign [the text about the aims and future of the EU.]
</bodyText>
<table confidence="0.65019275">
(3) Non-anaphoric complex NP (DIRNDL sentences 2527/2528):
2527: Der Prozess um den Tod eines Asylbewerbers aus Sierra Leone in Polizeigewahrsam ist [... ] er¨offnet worden.
2528: [Wegen K ¨ORperverletzung mit TOdesfolge und fahrl¨assiger T ¨Otung] M ¨USsen ...
[Due assault with lethal consequence, and reckless homicide] must
(( H*L L*H -) ( H*L -)%)
pn n1 n2
The trial about the death of an asylum seeker from Sierra Leone during police custody has started.
Charges include [assault with lethal consequence, and reckless homicide], ...
</table>
<listItem confidence="0.940368">
1. Only n2 accents get assigned true
2. n2 and n1 accents get assigned true
</listItem>
<bodyText confidence="0.9991823125">
Note that a version where all accents get assigned
true, i.e. pn and n1 and n2, is not included as this
equals the feature Pitch accent presence.
Nuclear bag of accents treats accents like a
bag-of-words approach treats words: if one accent
type is present once (or multiple times), the accent
type is considered present. This means we get a
number of different combinations (23 = 8 in total)
of accent types that are present in the markable,
e.g. pn and n1 but no n2 for Example (2), and pn,
n1 and n2 for Example (3).
Nuclear: first and last includes linear informa-
tion while avoiding an explosion of combinations.
It only looks at the (degree of the) first pitch ac-
cent present in the markable and combines it with
the last accent.
</bodyText>
<sectionHeader confidence="0.99853" genericHeader="method">
3 Experimental setup
</sectionHeader>
<bodyText confidence="0.999981111111111">
We perform our experiments using the IMS Hot-
Coref system (Bj¨orkelund and Kuhn, 2014), a
state-of-the-art coreference resolution system for
English. As German is not a language that is fea-
tured in the standard resolver, we first had to adapt
it. These adaptations include gender and number
agreement, lemma-based (sub)string match and
a feature that addresses German compounds, to
name only a few.2
</bodyText>
<footnote confidence="0.977096666666667">
2To download the German coreference system, visit:
www.ims.uni-stuttgart.de/forschung/
ressourcen/werkzeuge/HOTCorefDe.html
</footnote>
<bodyText confidence="0.999352705882353">
For our experiments on prosodic features, we
use the DIRNDL corpus3 (ca. 50.000 tokens, 3221
sentences), a radio news corpus annotated with
both manual coreference and manual prosody la-
bels (Eckart et al., 2012; Bj¨orkelund et al., 2014)4.
We adopt the official train, test and development
split. We decided to remove abstract anaphors
(e.g. anaphors that refer to events or facts), which
are not resolved by the system. In all experi-
ments, we only use predicted annotations and no
gold mention boundary (GB) information as we
aim at real end-to-end coreference resolution. On
DIRNDL, our system achieves a CoNLL score of
47.93, which will serve as a baseline in our ex-
periments. To put the baseline in context, we also
report performance on the German reference cor-
pus T¨uBa-D/Z5 (Naumann, 2006), which consists
</bodyText>
<equation confidence="0.361847">
3http://www.ims.uni-stuttgart.de/
forschung/ressourcen/korpora/dirndl.html
</equation>
<bodyText confidence="0.941871833333333">
4In this work, we have focused on improvements within
the clearly defined field of coreference resolution, using
prosodic features. As one of the reviewers pointed out, the
DIRNDL corpus additionally features manual two-level in-
formation status annotations according to the RefLex scheme
(Baumann and Riester, 2012), which additionally distin-
guishes bridging anaphors, deictic expressions, and more.
Recent work on smaller datasets of read text has shown that
there is a meaningful correspondence between information
status classes and degrees of prosodic prominence, with re-
gard to both pitch accent type and position (Baumann and
Riester, 2013; Baumann et al., 2015). Moreover, informa-
tion status classification has been identified as a task closely
related to coreference resolution (Cahill and Riester, 2012;
Rahman and Ng, 2012). Integrating these approaches is a
promising, though rather complex task, which we reserve for
future work. It might, furthermore, require more detailed
prosodic analyses than are currently available in DIRNDL.
</bodyText>
<footnote confidence="0.96374">
5http://www.sfs.uni-tuebingen.de/de/
ascl/ressourcen/corpora/tueba-dz.html
</footnote>
<page confidence="0.998848">
85
</page>
<table confidence="0.999507">
System CoNLL CoNLL
(+singl.) (-singl.)
IMS HotCoref DE (open) 60.35 48.61
CorZu (open) 60.27 45.82
BART (open) 57.72 39.07
SUCRE (closed) 51.23 36,32
TANL-1 (closed) 38.48 14.17
</table>
<tableCaption confidence="0.94815">
Table 1: SemEval Shared Task 2010 post-task
evaluation for track regular (on T¨uBa 8), includ-
ing and excluding singletons
Table 2: IMS HotCoref performance on T¨uBa 9
(no singletons), using regular preprocessing
</tableCaption>
<bodyText confidence="0.9996101">
of newspaper text. In a post-task SemEval 2010
evaluation6 our system achieves a CoNLL score
of 60.35 in the open, regular track7 (cf. Table 1).
On the newest dataset available (T¨uBa-D/Z v9),
our resolver currently achieves a CoNLL score
of 51.61.8 Table 2 compares the performance of
our system against CorZu (Klenner and Tuggener,
2011; Tuggener and Klenner, 2014), a rule-based
state-of-the-art system for German9(on the newest
T¨uBa dataset).
</bodyText>
<sectionHeader confidence="0.989118" genericHeader="evaluation">
4 Experiments using prosodic features
</sectionHeader>
<bodyText confidence="0.999926714285714">
Table 3 shows the effect of the respective features
which are not informed about intonation bound-
aries (Table 3a) and those that are (Table 3b). Fea-
tures that achieved a significant improvement over
the baseline are marked in boldface.10
The best-performing feature in Table 3a is the
presence of a pitch accent in short NPs. It can be
seen that this feature has a negative effect when be-
ing applied on all NPs. Presumably, this is because
the system is misled to classify a higher number of
complex anaphoric expressions as non-anaphoric,
due to the presence of pitch accents. This confirms
our conjecture that long NPs will always contain
some kind of accent and we cannot distinguish nu-
</bodyText>
<footnote confidence="0.992413090909091">
6http://stel.ub.edu/semeval2010-coref/
7Using the official CoNLL scorer v8.01, including single-
tons as they are part of T¨uBa 8
8Using the official CoNLL scorer v8.01, not including
singletons as T¨uBa 9 does not contain them.
9CorZu performance: Don Tuggener,
personal communication. We did not use CorZu for our ex-
periments as the integration of prosodic information in a rule-
based system is non-trivial.
10We compute significance using the Wilcoxon signed rank
test (Siegel and Castellan, 1988) at the 0.01 level.
</footnote>
<table confidence="0.988755277777778">
(a) No boundary information
Baseline 47.93
+ Feature applied to ... ... short ... all
NPs only NPs
PitchAccentType 45.31 46.23
PitchAccentPresence 48.30 46.57
(b) Including boundary information
Baseline 47.93
+ Feature applied to ... ... short ... all
NPs only NPs
NuclearType 47.17 46.79
(n1 vs. n2 vs. pn vs. none)
NuclearType 48.55 45.24
(n1/n2 vs. pn vs. none)
NuclearPresence (n2) 46.69 48.88
NuclearPresence (n1/n2) 48.76 47.47
NuclearBagOfAccents 46.09 48.45
NuclearFirst+Last 46.41 46.74
</table>
<tableCaption confidence="0.869812666666667">
Table 3: CoNLL metric scores on DIRNDL for
different prosodic features (no singletons, signifi-
cant results in boldface)
</tableCaption>
<bodyText confidence="0.999472032258064">
clear from prenuclear accents. Features based on
GToBI(S) accent type did not result in any im-
provements.
Table 3b presents the performance of the fea-
tures that are phonologically more informed. Dis-
tinguishing between prenuclear and nuclear ac-
cents (NuclearType) is a feature that works best
for short NPs where there is only one accent, while
having a negative effect on all NPs. Nuclear pres-
ence, however, works well for both versions (not
distinguishing between n1 or n2 works for short
NPs while n2 accents only works best for all NPs).
This feature achieves the overall best performance
for both short NPs (48.76) and all NPs (48.88).
The NuclearBagOfAccents feature works quite
well, too: this is a feature designed for NPs that
have more than one accent and so it works best for
complex NPs. Combining the features did not lead
to any improvements.
Overall, it becomes clear that one has to be very
careful in terms of how the prosodic information is
used. In general, the presence of an accent works
better than the distinction between certain accent
types, and including intonation boundary informa-
tion also contributes to the system’s performance.
When including this information, we can observe
that when we look at the presence of a pitch accent
(the best-performing feature), the distinction be-
tween prenuclear and nuclear is an important one:
not distinguishing between prenuclear and nuclear
deteriorates results. The results also seem to sug-
</bodyText>
<figure confidence="0.746052">
System CoNLL
IMS HOTCoref DE (no GB matching) 51.61
CorZu (no GB matching) 53.07
</figure>
<page confidence="0.99318">
86
</page>
<bodyText confidence="0.999967181818182">
gest that simpler features (like the presence or ab-
sence of a certain type of pitch accent) work best
for simple (i.e. short) phrases. For longer mark-
ables this effect turns into the negative. This prob-
ably means that simple features cannot do justice
to the complex prosody of longer NPs, which gets
blurred. The obvious solution is to define more
complex features that approximate the rhythmic
pattern (or even the prosodic contour) found on
longer phrases, which however will require more
data and, ideally, automatic prosodic annotation.
</bodyText>
<sectionHeader confidence="0.993515" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999982928571429">
We have tested a set of features that include dif-
ferent levels of prosodic information and investi-
gated which strategies can be successfully applied
for coreference resolution. Our results on the basis
of manual prosodic labelling show that including
prosody improves performance. While informa-
tion on pitch accent types does not seem benefi-
cial, the presence of an accent is a helpful feature
in a machine-learning setting. Including prosodic
boundaries and determining whether the accent is
the nuclear accent further increases results. We in-
terpret this as a promising result, which motivates
further research on the integration of coreference
resolution and spoken language.
</bodyText>
<sectionHeader confidence="0.994948" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999964875">
We would like to thank Anders Bj¨orkelund for his
valuable comments on an earlier version of this
paper, as well as Kerstin Eckart for her help with
the preparation of DIRNDL data. This work was
funded by the German Science Foundation (DFG),
Sonderforschungsbereich 732 Incremental Speci-
fication in Context, Project A6, at the University
of Stuttgart.
</bodyText>
<sectionHeader confidence="0.998007" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99822628358209">
Marilisa Amoia, Kerstin Kunz, and Ekaterina
Lapshinova-Koltunski. 2012. Coreference in
spoken vs. written texts: a corpus-based analysis. In
Proceedings of LREC, Istanbul.
Stefan Baumann and Arndt Riester. 2012. Referen-
tial and Lexical Givenness: semantic, prosodic and
cognitive aspects. In Gorka Elordieta and Pilar Pri-
eto, editors, Prosody and Meaning, pages 119–162.
Mouton de Gruyter, Berlin.
Stefan Baumann and Arndt Riester. 2013. Corefer-
ence, Lexical Givenness and Prosody in German.
Lingua, 136:16–37.
Stefan Baumann and Anna Roth. 2014. Prominence
and coreference – On the perceptual relevance of F0
movement, duration and intensity. In Proceedings
of Speech Prosody, pages 227–231, Dublin.
Stefan Baumann, Christine R¨ohr, and Martine Grice.
2015. Prosodische (De-)Kodierung des Informa-
tionsstatus im Deutschen. Zeitschrift f¨ur Sprachwis-
senschaft, 34(1):1–42.
Mary Beckman, Julia Hirschberg, and Stefanie
Shattuck-Hufnagel. 2005. The original ToBI
system and the evolution of the ToBI framework.
In Sun-Ah Jun, editor, Prosodic Typology – The
Phonology of Intonation and Phrasing, pages 9–54.
Oxford University Press.
Anders Bj¨orkelund and Jonas Kuhn. 2014. Learn-
ing structured perceptrons for coreference resolution
with latent antecedents and non-local features. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 47–57, Baltimore.
Anders Bj¨orkelund, Kerstin Eckart, Arndt Riester,
Nadja Schauffler, and Katrin Schweitzer. 2014. The
extended DIRNDL corpus as a resource for auto-
matic coreference and bridging resolution. In Pro-
ceedings of LREC, pages 3222–3228, Reykjav´ık.
Aoife Cahill and Arndt Riester. 2012. Automatically
Acquiring Fine-Grained Information Status Distinc-
tions. In Proceedings of the 13th Annual SIGdial
Meeting on Discourse and Dialog, pages 232–236,
Seoul.
Alan Cruttenden. 2006. The de-accenting of given
information: a cognitive universal? In Giuliano
Bernini and Marcia Schwartz, editors, Pragmatic
Organization of Discourse in the Languages of Eu-
rope, pages 311–355. De Gruyter, Berlin.
Kerstin Eckart, Arndt Riester, and Katrin Schweitzer.
2012. A Discourse Information Radio News
Database for Linguistic Analysis. In Sebas-
tian Nordhoff Christian Chiarcos and Sebastian
Hellmann, editors, Linked Data in Linguistics: Rep-
resenting and Connecting Language Data and Lan-
guage Metadata, pages 65–76. Springer.
Caroline F´ery. 1993. German Intonational Patterns.
Niemeyer, T¨ubingen.
Carlos Gussenhoven. 1984. On the Grammar and Se-
mantics of Sentence Accents. Foris, Dordrecht.
Manfred Klenner and Don Tuggener. 2011. An in-
cremental entity-mention model for coreference res-
olution with restrictive antecedent accessibility. In
Proceedings of RANLP, pages 178–185, Hissar, Bul-
garia.
D. Robert Ladd. 2008. Intonational Phonology (2nd
ed.). Cambridge University Press.
J¨org Mayer. 1995. Transcription of German Intona-
tion. The Stuttgart System. University of Stuttgart.
</reference>
<page confidence="0.987811">
87
</page>
<reference confidence="0.999791865384615">
Karin Naumann. 2006. Manual for the annotation
of in-document referential relations. University of
T¨ubingen.
Vincent Ng. 2010. Supervised noun phrase corefer-
ence research: The first fifteen years. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 1396–1411.
Janet Pierrehumbert. 1980. The Phonology and Pho-
netics of English Intonation. Ph.D. thesis, Mas-
sachusetts Institute of Technology.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll-
2012 shared task: Modeling multilingual unre-
stricted coreference in ontonotes. In Joint Confer-
ence on EMNLP and CoNLL-Shared Task, pages 1–
40. Association for Computational Linguistics.
Altaf Rahman and Vincent Ng. 2012. Learning the
fine-grained information status of discourse entities.
In Proceedings of the 13th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics, pages 798–807. Association for Com-
putational Linguistics.
Marta Recasens, Llufs M`arquez, Emili Sapena,
M. Ant`onia Martf, Mariona Taul´e, V´eronique Hoste,
Massimo Poesio, and Yannick Versley. 2010.
Semeval-2010 task 1: Coreference resolution in
multiple languages. In Proceedings of the 5th In-
ternational Workshop on Semantic Evaluation, Se-
mEval ’10, pages 1–8, Stroudsburg, PA, USA.
Roger Schwarzschild. 1999. GIVENness, AvoidF, and
Other Constraints on the Placement of Accent. Nat-
ural Language Semantics, 7(2):141–177.
Michael Strube and Christoph M¨uller. 2003. A ma-
chine learning approach to pronoun resolution in
spoken dialogue. In Proceedings of the 41st Annual
Meeting on Association for Computational Linguis-
tics, pages 168–175.
Jacques Terken and Julia Hirschberg. 1994. Deaccen-
tuation of words representing ’given’ information:
Effects of persistence of grammatical function and
surface position. Language and Speech, 37(2):125–
145.
Joel Tetreault and James Allen. 2004. Dialogue struc-
ture and pronoun resolution. In Proceedings of the
5th Discourse Anaphora and Anaphor Resolution
Colloquium, S. Miguel, Portugal.
Don Tuggener and Manfred Klenner. 2014. A hybrid
entity-mention pronoun resolution model for ger-
man using markov logic networks. In Proceedings
of KONVENS 2014, pages 21–29.
Carla Umbach. 2002. (De)accenting definite descrip-
tions. Theoretical Linguistics, 2/3:251–280.
</reference>
<page confidence="0.999409">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.782155">
<title confidence="0.9275445">Using prosodic annotations to improve coreference of spoken text</title>
<author confidence="0.922244">Ina R¨osiger</author>
<author confidence="0.922244">Arndt</author>
<affiliation confidence="0.9997755">Institute for Natural Language University of Stuttgart,</affiliation>
<address confidence="0.955417">Pfaffenwaldring 5b, 70569</address>
<abstract confidence="0.997245583333333">This paper is the first to examine the effect of prosodic features on coreference resolution in spoken discourse. We test features from different prosodic levels and investigate which strategies can be applied. Our results on the basis of manual prosodic labelling show that the presence of an accent is a helpful feature in a machine-learning setting. Including prosodic boundaries and determining whether the accent is the nuclear accent further increases results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marilisa Amoia</author>
<author>Kerstin Kunz</author>
<author>Ekaterina Lapshinova-Koltunski</author>
</authors>
<title>Coreference in spoken vs. written texts: a corpus-based analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="1111" citStr="Amoia et al. (2012)" startWordPosition="165" endWordPosition="168"> basis of manual prosodic labelling show that the presence of an accent is a helpful feature in a machine-learning setting. Including prosodic boundaries and determining whether the accent is the nuclear accent further increases results. 1 Introduction Noun phrase coreference resolution is the task of determining which noun phrases (NPs) in a text or dialogue refer to the same discourse entities (Ng, 2010). Coreference resolution has been extensively addressed in NLP research, e.g. in the CoNLL shared task 2012 (Pradhan et al., 2012) or in the SemEval shared task 2010 (Recasens et al., 2010). Amoia et al. (2012) have shown that there are differences between written and spoken text wrt coreference resolution and that the performance typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic promin</context>
</contexts>
<marker>Amoia, Kunz, Lapshinova-Koltunski, 2012</marker>
<rawString>Marilisa Amoia, Kerstin Kunz, and Ekaterina Lapshinova-Koltunski. 2012. Coreference in spoken vs. written texts: a corpus-based analysis. In Proceedings of LREC, Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Baumann</author>
<author>Arndt Riester</author>
</authors>
<title>Referential and Lexical Givenness: semantic, prosodic and cognitive aspects.</title>
<date>2012</date>
<booktitle>In Gorka Elordieta and Pilar Prieto, editors, Prosody and Meaning,</booktitle>
<pages>119--162</pages>
<location>Berlin.</location>
<contexts>
<context position="11965" citStr="Baumann and Riester, 2012" startWordPosition="1904" endWordPosition="1907">DIRNDL, our system achieves a CoNLL score of 47.93, which will serve as a baseline in our experiments. To put the baseline in context, we also report performance on the German reference corpus T¨uBa-D/Z5 (Naumann, 2006), which consists 3http://www.ims.uni-stuttgart.de/ forschung/ressourcen/korpora/dirndl.html 4In this work, we have focused on improvements within the clearly defined field of coreference resolution, using prosodic features. As one of the reviewers pointed out, the DIRNDL corpus additionally features manual two-level information status annotations according to the RefLex scheme (Baumann and Riester, 2012), which additionally distinguishes bridging anaphors, deictic expressions, and more. Recent work on smaller datasets of read text has shown that there is a meaningful correspondence between information status classes and degrees of prosodic prominence, with regard to both pitch accent type and position (Baumann and Riester, 2013; Baumann et al., 2015). Moreover, information status classification has been identified as a task closely related to coreference resolution (Cahill and Riester, 2012; Rahman and Ng, 2012). Integrating these approaches is a promising, though rather complex task, which w</context>
</contexts>
<marker>Baumann, Riester, 2012</marker>
<rawString>Stefan Baumann and Arndt Riester. 2012. Referential and Lexical Givenness: semantic, prosodic and cognitive aspects. In Gorka Elordieta and Pilar Prieto, editors, Prosody and Meaning, pages 119–162. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Baumann</author>
<author>Arndt Riester</author>
</authors>
<date>2013</date>
<booktitle>Coreference, Lexical Givenness and Prosody in German. Lingua,</booktitle>
<pages>136--16</pages>
<contexts>
<context position="1910" citStr="Baumann and Riester, 2013" startWordPosition="284" endWordPosition="287">ed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by including prominence features in the coreference resolver. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these cases, accentuation is an important means to distinguish between given entities (</context>
<context position="12295" citStr="Baumann and Riester, 2013" startWordPosition="1953" endWordPosition="1956">ve focused on improvements within the clearly defined field of coreference resolution, using prosodic features. As one of the reviewers pointed out, the DIRNDL corpus additionally features manual two-level information status annotations according to the RefLex scheme (Baumann and Riester, 2012), which additionally distinguishes bridging anaphors, deictic expressions, and more. Recent work on smaller datasets of read text has shown that there is a meaningful correspondence between information status classes and degrees of prosodic prominence, with regard to both pitch accent type and position (Baumann and Riester, 2013; Baumann et al., 2015). Moreover, information status classification has been identified as a task closely related to coreference resolution (Cahill and Riester, 2012; Rahman and Ng, 2012). Integrating these approaches is a promising, though rather complex task, which we reserve for future work. It might, furthermore, require more detailed prosodic analyses than are currently available in DIRNDL. 5http://www.sfs.uni-tuebingen.de/de/ ascl/ressourcen/corpora/tueba-dz.html 85 System CoNLL CoNLL (+singl.) (-singl.) IMS HotCoref DE (open) 60.35 48.61 CorZu (open) 60.27 45.82 BART (open) 57.72 39.07</context>
</contexts>
<marker>Baumann, Riester, 2013</marker>
<rawString>Stefan Baumann and Arndt Riester. 2013. Coreference, Lexical Givenness and Prosody in German. Lingua, 136:16–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Baumann</author>
<author>Anna Roth</author>
</authors>
<title>Prominence and coreference – On the perceptual relevance of F0 movement, duration and intensity.</title>
<date>2014</date>
<booktitle>In Proceedings of Speech Prosody,</booktitle>
<pages>227--231</pages>
<location>Dublin.</location>
<contexts>
<context position="1934" citStr="Baumann and Roth, 2014" startWordPosition="288" endWordPosition="291">lied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by including prominence features in the coreference resolver. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these cases, accentuation is an important means to distinguish between given entities (often deaccented) and ot</context>
</contexts>
<marker>Baumann, Roth, 2014</marker>
<rawString>Stefan Baumann and Anna Roth. 2014. Prominence and coreference – On the perceptual relevance of F0 movement, duration and intensity. In Proceedings of Speech Prosody, pages 227–231, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Baumann</author>
<author>Christine R¨ohr</author>
<author>Martine Grice</author>
</authors>
<date>2015</date>
<booktitle>Prosodische (De-)Kodierung des Informationsstatus im Deutschen. Zeitschrift f¨ur Sprachwissenschaft,</booktitle>
<pages>34--1</pages>
<marker>Baumann, R¨ohr, Grice, 2015</marker>
<rawString>Stefan Baumann, Christine R¨ohr, and Martine Grice. 2015. Prosodische (De-)Kodierung des Informationsstatus im Deutschen. Zeitschrift f¨ur Sprachwissenschaft, 34(1):1–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Beckman</author>
<author>Julia Hirschberg</author>
<author>Stefanie Shattuck-Hufnagel</author>
</authors>
<title>The original ToBI system and the evolution of the ToBI framework.</title>
<date>2005</date>
<booktitle>In Sun-Ah Jun, editor, Prosodic Typology – The Phonology of Intonation and Phrasing,</booktitle>
<pages>9--54</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="4895" citStr="Beckman et al. (2005)" startWordPosition="752" endWordPosition="755">he first work on coreference resolution in spoken text that tests the theoretical claims regarding the interaction between coreference and prominence in a general, state-of-the-art coreference resolver, and shows that prosodic features improve coreference resolution. 2 Prosodic features for coreference resolution The prosodic information used for the purpose of our research results from manual annotations that follow the GToBI(S) guidelines by Mayer (1995), which stand in the tradition of autosegmentalmetrical phonology, cf. Pierrehumbert (1980), Gussenhoven (1984), F´ery (1993), Ladd (2008), Beckman et al. (2005). We mainly make use of pitch accents and prosodic phrasing. The annotations distinguish intonation phrases, terminated by a major boundary (%), and intermediate phrases, closed by a minor boundary (-), as shown in Examples (2) and (3). The available pitch accent and boundary annotations allow us to automatically derive a secondary layer of prosodic information which represents a mapping of the pitch accents onto a prominence scale in which the nuclear (i.e. final) accents of an intonation phrase (n2) rank as the most prominent, followed by the nuclear accents of intermediate phrases (n1) and </context>
</contexts>
<marker>Beckman, Hirschberg, Shattuck-Hufnagel, 2005</marker>
<rawString>Mary Beckman, Julia Hirschberg, and Stefanie Shattuck-Hufnagel. 2005. The original ToBI system and the evolution of the ToBI framework. In Sun-Ah Jun, editor, Prosodic Typology – The Phonology of Intonation and Phrasing, pages 9–54. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Jonas Kuhn</author>
</authors>
<title>Learning structured perceptrons for coreference resolution with latent antecedents and non-local features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>47--57</pages>
<location>Baltimore.</location>
<marker>Bj¨orkelund, Kuhn, 2014</marker>
<rawString>Anders Bj¨orkelund and Jonas Kuhn. 2014. Learning structured perceptrons for coreference resolution with latent antecedents and non-local features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 47–57, Baltimore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Kerstin Eckart</author>
<author>Arndt Riester</author>
<author>Nadja Schauffler</author>
<author>Katrin Schweitzer</author>
</authors>
<title>The extended DIRNDL corpus as a resource for automatic coreference and bridging resolution.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>3222--3228</pages>
<marker>Bj¨orkelund, Eckart, Riester, Schauffler, Schweitzer, 2014</marker>
<rawString>Anders Bj¨orkelund, Kerstin Eckart, Arndt Riester, Nadja Schauffler, and Katrin Schweitzer. 2014. The extended DIRNDL corpus as a resource for automatic coreference and bridging resolution. In Proceedings of LREC, pages 3222–3228, Reykjav´ık.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Arndt Riester</author>
</authors>
<title>Automatically Acquiring Fine-Grained Information Status Distinctions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual SIGdial Meeting on Discourse and Dialog,</booktitle>
<pages>232--236</pages>
<contexts>
<context position="12461" citStr="Cahill and Riester, 2012" startWordPosition="1977" endWordPosition="1980">additionally features manual two-level information status annotations according to the RefLex scheme (Baumann and Riester, 2012), which additionally distinguishes bridging anaphors, deictic expressions, and more. Recent work on smaller datasets of read text has shown that there is a meaningful correspondence between information status classes and degrees of prosodic prominence, with regard to both pitch accent type and position (Baumann and Riester, 2013; Baumann et al., 2015). Moreover, information status classification has been identified as a task closely related to coreference resolution (Cahill and Riester, 2012; Rahman and Ng, 2012). Integrating these approaches is a promising, though rather complex task, which we reserve for future work. It might, furthermore, require more detailed prosodic analyses than are currently available in DIRNDL. 5http://www.sfs.uni-tuebingen.de/de/ ascl/ressourcen/corpora/tueba-dz.html 85 System CoNLL CoNLL (+singl.) (-singl.) IMS HotCoref DE (open) 60.35 48.61 CorZu (open) 60.27 45.82 BART (open) 57.72 39.07 SUCRE (closed) 51.23 36,32 TANL-1 (closed) 38.48 14.17 Table 1: SemEval Shared Task 2010 post-task evaluation for track regular (on T¨uBa 8), including and excluding</context>
</contexts>
<marker>Cahill, Riester, 2012</marker>
<rawString>Aoife Cahill and Arndt Riester. 2012. Automatically Acquiring Fine-Grained Information Status Distinctions. In Proceedings of the 13th Annual SIGdial Meeting on Discourse and Dialog, pages 232–236, Seoul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Cruttenden</author>
</authors>
<title>The de-accenting of given information: a cognitive universal?</title>
<date>2006</date>
<booktitle>In Giuliano Bernini and Marcia Schwartz, editors, Pragmatic Organization of Discourse in the Languages of Europe,</booktitle>
<pages>311--355</pages>
<location>Berlin.</location>
<contexts>
<context position="1871" citStr="Cruttenden, 2006" startWordPosition="280" endWordPosition="281"> systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by including prominence features in the coreference resolver. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these cases, accentuation is an important means </context>
</contexts>
<marker>Cruttenden, 2006</marker>
<rawString>Alan Cruttenden. 2006. The de-accenting of given information: a cognitive universal? In Giuliano Bernini and Marcia Schwartz, editors, Pragmatic Organization of Discourse in the Languages of Europe, pages 311–355. De Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kerstin Eckart</author>
<author>Arndt Riester</author>
<author>Katrin Schweitzer</author>
</authors>
<title>A Discourse Information Radio News Database for Linguistic Analysis. In</title>
<date>2012</date>
<booktitle>Linked Data in Linguistics: Representing and Connecting Language Data and Language Metadata,</booktitle>
<pages>65--76</pages>
<editor>Sebastian Nordhoff Christian Chiarcos and Sebastian Hellmann, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="10972" citStr="Eckart et al., 2012" startWordPosition="1757" endWordPosition="1760">nce resolution system for English. As German is not a language that is featured in the standard resolver, we first had to adapt it. These adaptations include gender and number agreement, lemma-based (sub)string match and a feature that addresses German compounds, to name only a few.2 2To download the German coreference system, visit: www.ims.uni-stuttgart.de/forschung/ ressourcen/werkzeuge/HOTCorefDe.html For our experiments on prosodic features, we use the DIRNDL corpus3 (ca. 50.000 tokens, 3221 sentences), a radio news corpus annotated with both manual coreference and manual prosody labels (Eckart et al., 2012; Bj¨orkelund et al., 2014)4. We adopt the official train, test and development split. We decided to remove abstract anaphors (e.g. anaphors that refer to events or facts), which are not resolved by the system. In all experiments, we only use predicted annotations and no gold mention boundary (GB) information as we aim at real end-to-end coreference resolution. On DIRNDL, our system achieves a CoNLL score of 47.93, which will serve as a baseline in our experiments. To put the baseline in context, we also report performance on the German reference corpus T¨uBa-D/Z5 (Naumann, 2006), which consis</context>
</contexts>
<marker>Eckart, Riester, Schweitzer, 2012</marker>
<rawString>Kerstin Eckart, Arndt Riester, and Katrin Schweitzer. 2012. A Discourse Information Radio News Database for Linguistic Analysis. In Sebastian Nordhoff Christian Chiarcos and Sebastian Hellmann, editors, Linked Data in Linguistics: Representing and Connecting Language Data and Language Metadata, pages 65–76. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline F´ery</author>
</authors>
<title>German Intonational Patterns.</title>
<date>1993</date>
<location>Niemeyer, T¨ubingen.</location>
<marker>F´ery, 1993</marker>
<rawString>Caroline F´ery. 1993. German Intonational Patterns. Niemeyer, T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Gussenhoven</author>
</authors>
<title>On the Grammar and Semantics of Sentence Accents.</title>
<date>1984</date>
<location>Foris, Dordrecht.</location>
<contexts>
<context position="4845" citStr="Gussenhoven (1984)" startWordPosition="746" endWordPosition="747"> Dutch. To the best of our knowledge, this is the first work on coreference resolution in spoken text that tests the theoretical claims regarding the interaction between coreference and prominence in a general, state-of-the-art coreference resolver, and shows that prosodic features improve coreference resolution. 2 Prosodic features for coreference resolution The prosodic information used for the purpose of our research results from manual annotations that follow the GToBI(S) guidelines by Mayer (1995), which stand in the tradition of autosegmentalmetrical phonology, cf. Pierrehumbert (1980), Gussenhoven (1984), F´ery (1993), Ladd (2008), Beckman et al. (2005). We mainly make use of pitch accents and prosodic phrasing. The annotations distinguish intonation phrases, terminated by a major boundary (%), and intermediate phrases, closed by a minor boundary (-), as shown in Examples (2) and (3). The available pitch accent and boundary annotations allow us to automatically derive a secondary layer of prosodic information which represents a mapping of the pitch accents onto a prominence scale in which the nuclear (i.e. final) accents of an intonation phrase (n2) rank as the most prominent, followed by the</context>
</contexts>
<marker>Gussenhoven, 1984</marker>
<rawString>Carlos Gussenhoven. 1984. On the Grammar and Semantics of Sentence Accents. Foris, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Klenner</author>
<author>Don Tuggener</author>
</authors>
<title>An incremental entity-mention model for coreference resolution with restrictive antecedent accessibility.</title>
<date>2011</date>
<booktitle>In Proceedings of RANLP,</booktitle>
<pages>178--185</pages>
<location>Hissar, Bulgaria.</location>
<contexts>
<context position="13501" citStr="Klenner and Tuggener, 2011" startWordPosition="2128" endWordPosition="2131">T (open) 57.72 39.07 SUCRE (closed) 51.23 36,32 TANL-1 (closed) 38.48 14.17 Table 1: SemEval Shared Task 2010 post-task evaluation for track regular (on T¨uBa 8), including and excluding singletons Table 2: IMS HotCoref performance on T¨uBa 9 (no singletons), using regular preprocessing of newspaper text. In a post-task SemEval 2010 evaluation6 our system achieves a CoNLL score of 60.35 in the open, regular track7 (cf. Table 1). On the newest dataset available (T¨uBa-D/Z v9), our resolver currently achieves a CoNLL score of 51.61.8 Table 2 compares the performance of our system against CorZu (Klenner and Tuggener, 2011; Tuggener and Klenner, 2014), a rule-based state-of-the-art system for German9(on the newest T¨uBa dataset). 4 Experiments using prosodic features Table 3 shows the effect of the respective features which are not informed about intonation boundaries (Table 3a) and those that are (Table 3b). Features that achieved a significant improvement over the baseline are marked in boldface.10 The best-performing feature in Table 3a is the presence of a pitch accent in short NPs. It can be seen that this feature has a negative effect when being applied on all NPs. Presumably, this is because the system i</context>
</contexts>
<marker>Klenner, Tuggener, 2011</marker>
<rawString>Manfred Klenner and Don Tuggener. 2011. An incremental entity-mention model for coreference resolution with restrictive antecedent accessibility. In Proceedings of RANLP, pages 178–185, Hissar, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Robert Ladd</author>
</authors>
<date>2008</date>
<booktitle>Intonational Phonology (2nd ed.).</booktitle>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4872" citStr="Ladd (2008)" startWordPosition="750" endWordPosition="751">ge, this is the first work on coreference resolution in spoken text that tests the theoretical claims regarding the interaction between coreference and prominence in a general, state-of-the-art coreference resolver, and shows that prosodic features improve coreference resolution. 2 Prosodic features for coreference resolution The prosodic information used for the purpose of our research results from manual annotations that follow the GToBI(S) guidelines by Mayer (1995), which stand in the tradition of autosegmentalmetrical phonology, cf. Pierrehumbert (1980), Gussenhoven (1984), F´ery (1993), Ladd (2008), Beckman et al. (2005). We mainly make use of pitch accents and prosodic phrasing. The annotations distinguish intonation phrases, terminated by a major boundary (%), and intermediate phrases, closed by a minor boundary (-), as shown in Examples (2) and (3). The available pitch accent and boundary annotations allow us to automatically derive a secondary layer of prosodic information which represents a mapping of the pitch accents onto a prominence scale in which the nuclear (i.e. final) accents of an intonation phrase (n2) rank as the most prominent, followed by the nuclear accents of interme</context>
</contexts>
<marker>Ladd, 2008</marker>
<rawString>D. Robert Ladd. 2008. Intonational Phonology (2nd ed.). Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Mayer</author>
</authors>
<title>Transcription of German Intonation. The Stuttgart System.</title>
<date>1995</date>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="4734" citStr="Mayer (1995)" startWordPosition="732" endWordPosition="733">German data, but the prosodic properties are comparable to other West Germanic languages, like English or Dutch. To the best of our knowledge, this is the first work on coreference resolution in spoken text that tests the theoretical claims regarding the interaction between coreference and prominence in a general, state-of-the-art coreference resolver, and shows that prosodic features improve coreference resolution. 2 Prosodic features for coreference resolution The prosodic information used for the purpose of our research results from manual annotations that follow the GToBI(S) guidelines by Mayer (1995), which stand in the tradition of autosegmentalmetrical phonology, cf. Pierrehumbert (1980), Gussenhoven (1984), F´ery (1993), Ladd (2008), Beckman et al. (2005). We mainly make use of pitch accents and prosodic phrasing. The annotations distinguish intonation phrases, terminated by a major boundary (%), and intermediate phrases, closed by a minor boundary (-), as shown in Examples (2) and (3). The available pitch accent and boundary annotations allow us to automatically derive a secondary layer of prosodic information which represents a mapping of the pitch accents onto a prominence scale in </context>
</contexts>
<marker>Mayer, 1995</marker>
<rawString>J¨org Mayer. 1995. Transcription of German Intonation. The Stuttgart System. University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Naumann</author>
</authors>
<title>Manual for the annotation of in-document referential relations.</title>
<date>2006</date>
<institution>University of T¨ubingen.</institution>
<contexts>
<context position="11558" citStr="Naumann, 2006" startWordPosition="1856" endWordPosition="1857"> labels (Eckart et al., 2012; Bj¨orkelund et al., 2014)4. We adopt the official train, test and development split. We decided to remove abstract anaphors (e.g. anaphors that refer to events or facts), which are not resolved by the system. In all experiments, we only use predicted annotations and no gold mention boundary (GB) information as we aim at real end-to-end coreference resolution. On DIRNDL, our system achieves a CoNLL score of 47.93, which will serve as a baseline in our experiments. To put the baseline in context, we also report performance on the German reference corpus T¨uBa-D/Z5 (Naumann, 2006), which consists 3http://www.ims.uni-stuttgart.de/ forschung/ressourcen/korpora/dirndl.html 4In this work, we have focused on improvements within the clearly defined field of coreference resolution, using prosodic features. As one of the reviewers pointed out, the DIRNDL corpus additionally features manual two-level information status annotations according to the RefLex scheme (Baumann and Riester, 2012), which additionally distinguishes bridging anaphors, deictic expressions, and more. Recent work on smaller datasets of read text has shown that there is a meaningful correspondence between inf</context>
</contexts>
<marker>Naumann, 2006</marker>
<rawString>Karin Naumann. 2006. Manual for the annotation of in-document referential relations. University of T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1396--1411</pages>
<contexts>
<context position="901" citStr="Ng, 2010" startWordPosition="131" endWordPosition="132">amine the effect of prosodic features on coreference resolution in spoken discourse. We test features from different prosodic levels and investigate which strategies can be applied. Our results on the basis of manual prosodic labelling show that the presence of an accent is a helpful feature in a machine-learning setting. Including prosodic boundaries and determining whether the accent is the nuclear accent further increases results. 1 Introduction Noun phrase coreference resolution is the task of determining which noun phrases (NPs) in a text or dialogue refer to the same discourse entities (Ng, 2010). Coreference resolution has been extensively addressed in NLP research, e.g. in the CoNLL shared task 2012 (Pradhan et al., 2012) or in the SemEval shared task 2010 (Recasens et al., 2010). Amoia et al. (2012) have shown that there are differences between written and spoken text wrt coreference resolution and that the performance typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun r</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Vincent Ng. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1396–1411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Pierrehumbert</author>
</authors>
<title>The Phonology and Phonetics of English Intonation.</title>
<date>1980</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="4825" citStr="Pierrehumbert (1980)" startWordPosition="744" endWordPosition="745">uages, like English or Dutch. To the best of our knowledge, this is the first work on coreference resolution in spoken text that tests the theoretical claims regarding the interaction between coreference and prominence in a general, state-of-the-art coreference resolver, and shows that prosodic features improve coreference resolution. 2 Prosodic features for coreference resolution The prosodic information used for the purpose of our research results from manual annotations that follow the GToBI(S) guidelines by Mayer (1995), which stand in the tradition of autosegmentalmetrical phonology, cf. Pierrehumbert (1980), Gussenhoven (1984), F´ery (1993), Ladd (2008), Beckman et al. (2005). We mainly make use of pitch accents and prosodic phrasing. The annotations distinguish intonation phrases, terminated by a major boundary (%), and intermediate phrases, closed by a minor boundary (-), as shown in Examples (2) and (3). The available pitch accent and boundary annotations allow us to automatically derive a secondary layer of prosodic information which represents a mapping of the pitch accents onto a prominence scale in which the nuclear (i.e. final) accents of an intonation phrase (n2) rank as the most promin</context>
</contexts>
<marker>Pierrehumbert, 1980</marker>
<rawString>Janet Pierrehumbert. 1980. The Phonology and Phonetics of English Intonation. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes.</title>
<date>2012</date>
<booktitle>In Joint Conference on EMNLP and CoNLL-Shared Task,</booktitle>
<pages>pages</pages>
<contexts>
<context position="1031" citStr="Pradhan et al., 2012" startWordPosition="150" endWordPosition="153">rosodic levels and investigate which strategies can be applied. Our results on the basis of manual prosodic labelling show that the presence of an accent is a helpful feature in a machine-learning setting. Including prosodic boundaries and determining whether the accent is the nuclear accent further increases results. 1 Introduction Noun phrase coreference resolution is the task of determining which noun phrases (NPs) in a text or dialogue refer to the same discourse entities (Ng, 2010). Coreference resolution has been extensively addressed in NLP research, e.g. in the CoNLL shared task 2012 (Pradhan et al., 2012) or in the SemEval shared task 2010 (Recasens et al., 2010). Amoia et al. (2012) have shown that there are differences between written and spoken text wrt coreference resolution and that the performance typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic info</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP and CoNLL-Shared Task, pages 1– 40. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Learning the fine-grained information status of discourse entities.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>798--807</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12483" citStr="Rahman and Ng, 2012" startWordPosition="1981" endWordPosition="1984">al two-level information status annotations according to the RefLex scheme (Baumann and Riester, 2012), which additionally distinguishes bridging anaphors, deictic expressions, and more. Recent work on smaller datasets of read text has shown that there is a meaningful correspondence between information status classes and degrees of prosodic prominence, with regard to both pitch accent type and position (Baumann and Riester, 2013; Baumann et al., 2015). Moreover, information status classification has been identified as a task closely related to coreference resolution (Cahill and Riester, 2012; Rahman and Ng, 2012). Integrating these approaches is a promising, though rather complex task, which we reserve for future work. It might, furthermore, require more detailed prosodic analyses than are currently available in DIRNDL. 5http://www.sfs.uni-tuebingen.de/de/ ascl/ressourcen/corpora/tueba-dz.html 85 System CoNLL CoNLL (+singl.) (-singl.) IMS HotCoref DE (open) 60.35 48.61 CorZu (open) 60.27 45.82 BART (open) 57.72 39.07 SUCRE (closed) 51.23 36,32 TANL-1 (closed) 38.48 14.17 Table 1: SemEval Shared Task 2010 post-task evaluation for track regular (on T¨uBa 8), including and excluding singletons Table 2: I</context>
</contexts>
<marker>Rahman, Ng, 2012</marker>
<rawString>Altaf Rahman and Vincent Ng. 2012. Learning the fine-grained information status of discourse entities. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 798–807. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Llufs M`arquez</author>
<author>Emili Sapena</author>
<author>M Ant`onia Martf</author>
<author>Mariona Taul´e</author>
<author>V´eronique Hoste</author>
<author>Massimo Poesio</author>
<author>Yannick Versley</author>
</authors>
<title>Semeval-2010 task 1: Coreference resolution in multiple languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval ’10,</booktitle>
<pages>1--8</pages>
<location>Stroudsburg, PA, USA.</location>
<marker>Recasens, M`arquez, Sapena, Martf, Taul´e, Hoste, Poesio, Versley, 2010</marker>
<rawString>Marta Recasens, Llufs M`arquez, Emili Sapena, M. Ant`onia Martf, Mariona Taul´e, V´eronique Hoste, Massimo Poesio, and Yannick Versley. 2010. Semeval-2010 task 1: Coreference resolution in multiple languages. In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval ’10, pages 1–8, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schwarzschild</author>
</authors>
<title>GIVENness, AvoidF, and Other Constraints on the Placement of Accent.</title>
<date>1999</date>
<journal>Natural Language Semantics,</journal>
<volume>7</volume>
<issue>2</issue>
<contexts>
<context position="1852" citStr="Schwarzschild, 1999" startWordPosition="278" endWordPosition="279"> typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by including prominence features in the coreference resolver. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these cases, accentuation is </context>
</contexts>
<marker>Schwarzschild, 1999</marker>
<rawString>Roger Schwarzschild. 1999. GIVENness, AvoidF, and Other Constraints on the Placement of Accent. Natural Language Semantics, 7(2):141–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Christoph M¨uller</author>
</authors>
<title>A machine learning approach to pronoun resolution in spoken dialogue.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>168--175</pages>
<marker>Strube, M¨uller, 2003</marker>
<rawString>Michael Strube and Christoph M¨uller. 2003. A machine learning approach to pronoun resolution in spoken dialogue. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 168–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Terken</author>
<author>Julia Hirschberg</author>
</authors>
<title>Deaccentuation of words representing ’given’ information: Effects of persistence of grammatical function and surface position. Language and Speech,</title>
<date>1994</date>
<volume>37</volume>
<issue>2</issue>
<pages>145</pages>
<contexts>
<context position="1831" citStr="Terken and Hirschberg, 1994" startWordPosition="274" endWordPosition="277">tion and that the performance typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by including prominence features in the coreference resolver. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these ca</context>
</contexts>
<marker>Terken, Hirschberg, 1994</marker>
<rawString>Jacques Terken and Julia Hirschberg. 1994. Deaccentuation of words representing ’given’ information: Effects of persistence of grammatical function and surface position. Language and Speech, 37(2):125– 145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>James Allen</author>
</authors>
<title>Dialogue structure and pronoun resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th Discourse Anaphora and Anaphor</booktitle>
<contexts>
<context position="1599" citStr="Tetreault and Allen (2004)" startWordPosition="243" endWordPosition="246"> e.g. in the CoNLL shared task 2012 (Pradhan et al., 2012) or in the SemEval shared task 2010 (Recasens et al., 2010). Amoia et al. (2012) have shown that there are differences between written and spoken text wrt coreference resolution and that the performance typically drops when systems that have been developed for written text are applied on spoken text. There has been considerable work on coreference resolution in written text, but comparatively little work on spoken text, with a few exceptions of systems for pronoun resolution in transcripts of spoken text e.g. Strube and M¨uller (2003), Tetreault and Allen (2004). However, so far, prosodic information has not been taken into account. The interaction between prosodic prominence and coreference has been investigated in several experimental and theoretical analyses (Terken and Hirschberg, 1994; Schwarzschild, 1999; Cruttenden, 2006); for German (Baumann and Riester, 2013; Baumann and Roth, 2014; Baumann et al., 2015). There is a tendency for coreferent items, i.e. entities that have already been introduced into the discourse, to be deaccented, as the speaker assumes the entity to be salient in the listener’s discourse model. We can exploit this by includ</context>
</contexts>
<marker>Tetreault, Allen, 2004</marker>
<rawString>Joel Tetreault and James Allen. 2004. Dialogue structure and pronoun resolution. In Proceedings of the 5th Discourse Anaphora and Anaphor Resolution Colloquium, S. Miguel, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don Tuggener</author>
<author>Manfred Klenner</author>
</authors>
<title>A hybrid entity-mention pronoun resolution model for german using markov logic networks.</title>
<date>2014</date>
<booktitle>In Proceedings of KONVENS 2014,</booktitle>
<pages>21--29</pages>
<contexts>
<context position="13530" citStr="Tuggener and Klenner, 2014" startWordPosition="2132" endWordPosition="2135">closed) 51.23 36,32 TANL-1 (closed) 38.48 14.17 Table 1: SemEval Shared Task 2010 post-task evaluation for track regular (on T¨uBa 8), including and excluding singletons Table 2: IMS HotCoref performance on T¨uBa 9 (no singletons), using regular preprocessing of newspaper text. In a post-task SemEval 2010 evaluation6 our system achieves a CoNLL score of 60.35 in the open, regular track7 (cf. Table 1). On the newest dataset available (T¨uBa-D/Z v9), our resolver currently achieves a CoNLL score of 51.61.8 Table 2 compares the performance of our system against CorZu (Klenner and Tuggener, 2011; Tuggener and Klenner, 2014), a rule-based state-of-the-art system for German9(on the newest T¨uBa dataset). 4 Experiments using prosodic features Table 3 shows the effect of the respective features which are not informed about intonation boundaries (Table 3a) and those that are (Table 3b). Features that achieved a significant improvement over the baseline are marked in boldface.10 The best-performing feature in Table 3a is the presence of a pitch accent in short NPs. It can be seen that this feature has a negative effect when being applied on all NPs. Presumably, this is because the system is misled to classify a higher</context>
</contexts>
<marker>Tuggener, Klenner, 2014</marker>
<rawString>Don Tuggener and Manfred Klenner. 2014. A hybrid entity-mention pronoun resolution model for german using markov logic networks. In Proceedings of KONVENS 2014, pages 21–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carla Umbach</author>
</authors>
<title>(De)accenting definite descriptions. Theoretical Linguistics,</title>
<date>2002</date>
<pages>2--3</pages>
<contexts>
<context position="2861" citStr="Umbach (2002)" startWordPosition="439" endWordPosition="440">er. Our prosodic features mainly aim at definite descriptions, where it is difficult for the resolver to decide whether the potential anaphor is actually anaphoric or not. In these cases, accentuation is an important means to distinguish between given entities (often deaccented) and other categories (i.e. bridging anaphors, see below) that are typically accented, particularly for entities whose heads have a different lexeme than their potential antecedent. Pronouns are not the case of interest here, as they are (almost) always anaphoric. To make the intuitions clearer, Example (1), taken from Umbach (2002), shows the difference prominence can make: (1) John has an old cottage.1 a. Last year he reconstructed the SHED. b. Last year he reconSTRUCted the shed. Due to the pitch accent on shed in (1a), it is quite obvious that the shed and the cottage refer to different entities; they exemplify a bridging relation, where the shed is a part of the cottage. In (1b), however, the shed is deaccented, which has the effect that the shed and the cottage corefer. We present a pilot study on German spoken text that uses manual prominence marking to show the principled usefulness of prosodic features for coref</context>
</contexts>
<marker>Umbach, 2002</marker>
<rawString>Carla Umbach. 2002. (De)accenting definite descriptions. Theoretical Linguistics, 2/3:251–280.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>