<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000860">
<title confidence="0.99559">
Global Inference for Bridging Anaphora Resolution
</title>
<author confidence="0.999635">
Yufang Hou&apos;, Katja Markert2, Michael Strube&apos;
</author>
<affiliation confidence="0.993039">
&apos; Heidelberg Institute for Theoretical Studies gGmbH, Heidelberg, Germany
(yufang.hou|michael.strube)@h-its.org
2School of Computing, University of Leeds, UK
</affiliation>
<email confidence="0.996884">
scskm@leeds.ac.uk
</email>
<sectionHeader confidence="0.995615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.963554375">
We present the first work on antecedent se-
lection for bridging resolution without restric-
tions on anaphor or relation types. Our model
integrates global constraints on top of a rich
local feature set in the framework of Markov
logic networks. The global model improves
over the local one and both strongly outper-
form a reimplementation of prior work.
</bodyText>
<sectionHeader confidence="0.99866" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998300764705882">
Identity coreference is a relatively well understood
and well-studied instance of entity coherence. How-
ever, entity coherence can rely on more complex,
lexico-semantic, frame or encyclopedic relations
than identity. Anaphora linking distinct entities or
events this way are called bridging or associative
anaphora and have been widely discussed in the lin-
guistic literature (Clark, 1975; Prince, 1981; Gundel
et al., 1993).1 In Example 1, the phrases the win-
dows, the carpets and walls can be felicitously used
because they are semantically related via a part-of
relation to their antecedent the Polish center.2
(1) ... as much as possible of the Polish center will
be made from aluminum, steel and glass recycled
from Warsaw’s abundant rubble. ... The windows
will open. The carpets won’t be glued down and
walls will be coated with non-toxic finishes.
</bodyText>
<footnote confidence="0.6668495">
1Poesio and Vieira (1998) include cases where antecedent
and anaphor are coreferent but do not share the same head noun.
We restrict bridging to non-coreferential cases. We also exclude
comparative anaphora (Modjeska et al., 2003)
2Examples are from OntoNotes (Weischedel et al., 2011).
Bridging anaphora are typed in boldface; antecedents in italics.
</footnote>
<bodyText confidence="0.99985494117647">
Bridging is frequent amounting to between 5%
(Gardent and Manu´elian, 2005) and 20% (Caselli
and Prodanof, 2006) of definite descriptions (both
studies limited to NPs starting with the or non-
English equivalents). Bridging resolution is needed
to fill gaps in entity grids based on coreference only
(Barzilay and Lapata, 2008). Example 1 does not ex-
hibit any coreferential entity coherence. Coherence
can only be established when the bridging anaphora
are resolved. Bridging resolution may also be im-
portant for textual entailment (Mirkin et al., 2010).
Bridging resolution can be divided into two tasks,
recognizing that a bridging anaphor is present and
finding the correct antecedent among a list of candi-
dates. These two tasks have frequently been handled
in a pipeline with most research concentrating on an-
tecedent selection only. We also handle only the task
of antecedent selection.
Previous work on antecedent selection for bridg-
ing anaphora is restricted. It makes strong untested
assumptions about bridging anaphora types or rela-
tions, limiting it to definite NPs (Poesio and Vieira,
1998; Poesio et al., 2004; Lassalle and Denis, 2011)
or to part-of relations between anaphor and an-
tecedent (Poesio et al., 2004; Markert et al., 2003;
Lassalle and Denis, 2011). We break new ground
by considering all relations and anaphora/antecedent
types and show that the variety of bridging anaphora
is much higher than reported previously.
Following work on coreference resolution, we ap-
ply a local pairwise model (Soon et al., 2001) for an-
tecedent selection. We then develop novel semantic,
syntactic and salience features for this task, show-
ing strong improvements over one of the best known
</bodyText>
<page confidence="0.95149">
907
</page>
<note confidence="0.481608">
Proceedings of NAACL-HLT 2013, pages 907–917,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.997173875">
prior models (Poesio et al., 2004).
However, this local model classifies each
anaphor-antecedent candidate pair in isolation.
Thus, it neglects that bridging anaphora referring to
a single antecedent often occur in clusters (see Ex-
ample 1). It also neglects that once an entity is an
antecedent for a bridging anaphor it is more likely to
be used again as antecedent. In addition, such local
models construct the list of possible antecedent can-
didates normally relying on a window size constraint
to restrict the set of candidates: is the window too
small, we miss too many correct antecedents; is it
too large, we include so many incorrect antecedents
as to lead to severe data imbalance in learning.
To remedy these flaws we change to a global
Markov logic model that allows us to:
</bodyText>
<listItem confidence="0.993931625">
• model constraints that certain anaphora are
likely to share the same antecedent;
• model the global semantic connectivity of a
salient potential antecedent to all anaphora in a
text;
• consider the union of potential antecedents for
all anaphora instead of a static window-sized
constraint.
</listItem>
<bodyText confidence="0.998878666666667">
We show that this global model with the same lo-
cal features but enhanced with global constraints im-
proves significantly over the local model.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999796964912281">
Prior corpus-linguistic studies on bridging are be-
set by three main problems. First, reliability is not
measured or low (Fraurud, 1990; Poesio, 2003; Gar-
dent and Manu´elian, 2005; Riester et al., 2010).3
Second, annotated corpora are small (Poesio et al.,
2004; Korzen and Buch-Kromann, 2011). Third,
they are often based on strong untested assumptions
about bridging anaphora types, antecedent types or
relations, such as limiting it to definite NP anaphora
(Poesio and Vieira, 1998; Poesio et al., 2004; Gar-
dent and Manu´elian, 2005; Caselli and Prodanof,
2006; Riester et al., 2010; Lassalle and Denis,
2011), to NP antecedents (all prior work) or to part-
3Although the overall information status scheme in Riester
et al. (2010) achieved high agreement, their confusion matrix
shows that the anaphoric bridging category (BRI) is frequently
confused with other categories so that the two annotators agreed
on only less than a third of bridging anaphors.
of relations between anaphor and antecedent (Mark-
ert et al., 2003; Poesio et al., 2004). In our own
work (Markert et al., 2012) we established a corpus
that circumvents these problems, i.e. human bridg-
ing recognition was reliable, it contains a medium
number of bridging cases that allows generalisable
statistics and we did not limit bridging anaphora or
antecedents according to their syntactic type or re-
lations between them. However, we only discussed
human agreement on bridging recognition in Mark-
ert et al. (2012), disregarding antecedent annotation.
We also did not discuss the different types of bridg-
ing in the corpus. We will remedy this in Section 3.
Automatic work on bridging distinguishes be-
tween recognition (Vieira and Poesio, 2000; Rah-
man and Ng, 2012; Cahill and Riester, 2012; Mark-
ert et al., 2012) and antecedent selection. Work on
antecedent selection suffers from focusing on sub-
problems, e.g. only part-of bridging (Poesio et al.,
2004; Markert et al., 2003) or definite NP anaphora
(Lassalle and Denis, 2011). Most relevant for us is
Lassalle and Denis (2011) who restrict anaphora to
definite descriptions but have no other restrictions
on relations or antecedent NPs (in a French corpus)
with an accuracy of 23%. Also the evaluation set-
up is sometimes not clear: The high results in Poe-
sio et al. (2004) cannot be used for comparison as
they test unrealistically: they distinguish only be-
tween the correct antecedent and one or three false
candidates (baseline of 50% for the former). They
also restrict the phenomenon to part-of relations.
There is a partial overlap between bridging and
implicit noun roles (Ruppenhofer et al., 2010).
However, work on implicit noun roles is mostly
focused on few predicates (e.g. Gerber and Chai
(2012)). We consider all bridging anaphors in run-
ning text. The closest work to ours interpreting im-
plicit role filling as anaphora resolution is Silberer
and Frank (2012).
</bodyText>
<sectionHeader confidence="0.995958" genericHeader="method">
3 Corpus for Bridging: An Overview
</sectionHeader>
<bodyText confidence="0.999942166666667">
We use the dataset we created in Markert et al.
(2012) with almost 11,000 NPs annotated for infor-
mation status including 663 bridging NPs and their
antecedents in 50 texts taken from the WSJ portion
of the OntoNotes corpus (Weischedel et al., 2011).
Bridging anaphora can be any noun phrase. They
</bodyText>
<page confidence="0.996942">
908
</page>
<bodyText confidence="0.999778153846154">
are not limited to definite NPs as in previous work.
In contrast to Nissim et al. (2004), antecedents are
annotated and can be noun phrases, verb phrases or
even clauses. Our bridging annotation is also not
limited with regards to semantic relations between
anaphor and antecedent.
In Markert et al. (2012) we achieved high agree-
ment for the overall information status annotation
scheme between three annotators (r. between 75 and
80, dependent on annotator pairs) as well as for all
subcategories, including bridging (r. over 60 for all
annotator pairings, over 70 for two expert annota-
tors). Here, we add the following new results:
</bodyText>
<listItem confidence="0.941701833333333">
• Agreement for selecting bridging antecedents
was around 80% for all annotator pairings.
• Surprisingly, only 255 of the 663 (38%) bridg-
ing anaphors are definite NPs, which calls into
question the strategy of prior approaches to limit
themselves to these types of bridging.
• NPs are the most frequent antecedents by far
with only 42 of 663 (6%) bridging anaphora hav-
ing a non-NP antecedent (mostly verb phrases).
• Bridging is a relatively local phenomenon with
71% of NP antecedents occurring in the same or
up to 2 sentences prior to the anaphor. However,
farther away antecedents are common when the
antecedent is the global focus of a document.
• The semantic relations between anaphor and an-
tecedent are extremely diverse with only 92 of
663 (14%) anaphors having a part-of/attribute-
of antecedent (see Example 1) and only 45 (7%)
anaphors standing in a set relationship to the an-
tecedent (see Example 2). This contrasts with
Gardent and Manu´elian’s (2005) finding that
52% of bridging cases had meronymic relations.
We find many different types of relations in our
corpus, including encyclopedic relations such as
restaurant — the waiter as well as, frequently,
relational person nouns as bridging anaphors
such as friend, husband, president.
• There are only a few cases of bridging where
surface cues may indicate the antecedent. First,
some bridging anaphors are modified by a small
number of adjectives that have more than one
role filler, with the bridging relation often being
temporal or spatial sequence between two enti-
ties of the same semantic type as in Example 3
(see also Lassalle and Denis (2011) for a dis-
cussion of such cases). Second, some anaphors
are compounds where the nominal premodifier
matches the antecedent head as in Example 4.
(2) Still employees do occasionally try to smuggle
out a gem or two. One man wrapped several dia-
monds in the knot of his tie. Another poked a hole
in the heel of his shoe. None made it past the body
searches...
(3) His truck is parked across the field ... The
farmer at the next truck shouts ...
(4) ... it doesn’t make the equipment needed to
produce those chips. And IBM worries that the
Japanese will take over that equipment market.
</listItem>
<sectionHeader confidence="0.987955" genericHeader="method">
4 Models for Bridging Resolution
</sectionHeader>
<subsectionHeader confidence="0.989393">
4.1 Pairwise mention-entity model
</subsectionHeader>
<bodyText confidence="0.988167555555555">
The pairwise model is widely used in coreference
resolution (Soon et al., 2001). We adapt it for bridg-
ing resolution4: Given an anaphor mention m and
the set of antecedent candidate entities E,,t which
appear before m, we create a pairwise instance
(m, e) for every e E E,,t. A binary decision whether
m is bridged to e is made for each instance (m, e)
separately. A post-processing step to choose one an-
tecedent is necessary (closest first or best first are
common strategies). This model causes three prob-
lems for bridging resolution: First, the ratio between
positive and negative instances is 1 to 17 even if only
antecedent candidates from the current and the im-
mediately preceding two sentences are considered.
The ratio will be even worse with a larger win-
dow size. Therefore, usually a fixed window size is
used restricting the set of candidates. This, however,
causes a second problem: antecedents which are be-
yond the window cannot be found. In our data, only
81% of NP antecedents appear within the previous 5
sentences, and only 71% of NP antecedents appear
within the previous 2 sentences. The third problem
is a shortcoming of the pairwise model itself: deci-
sions are made for each instance separately, ignoring
4Different from coreference, we treat an anaphor as a men-
tion and an antecedent as an entity. The anaphor is the first
mention of the corresponding entity in the document.
</bodyText>
<page confidence="0.993481">
909
</page>
<bodyText confidence="0.989974">
relations between instances. We resolve these prob-
lems by employing a global model based on Markov
logic networks.
</bodyText>
<subsectionHeader confidence="0.997122">
4.2 Markov Logic Networks
</subsectionHeader>
<bodyText confidence="0.999967465116279">
Bridging can be considered a document global phe-
nomenon, where globally salient entities are pre-
ferred as antecedents and two or more anaphors hav-
ing the same antecedent should be related or similar.
Motivated by this observation, we explore Markov
logic networks (Domingos and Lowd, 2009, MLNs)
to model bridging resolution on the global discourse
level.
MLNs are a powerful representation for joint
inference with uncertainty. An MLN consists
of a set of pairs (Fi, wi), where Fi is a formula
in first-order logic and wi is its associated real
numbered weight. It can be viewed as a template for
constructing Markov networks. Given different sets
of constants, an MLN will produce different ground
Markov networks which may vary in size but have
the same structure and parameters. For a ground
Markov network, the probability distribution over
possible worlds x is given by
polarity of the weights is indicated by the leading
+ or −. The weight value (except for hard con-
straints) is learned from training data. For some for-
mulas the final weight consists of a learned weight
w multiplied by a score d (e.g. inverse distance be-
tween antecedent and anaphor). In these cases the
final weight for a formula in a ground Markov net-
work does not just depend on the respective formula,
but also on the specific constants. We indicate such
combined weights by the term w · d.
We tackle the previously mentioned problems of
the pairwise model: (1) We construct hard con-
straints to specify that each anaphor has at most
one antecedent entity (Table 1: f1) and that the an-
tecedent must precede the anaphor (f2). This elim-
inates the need for the post-processing step in the
pairwise model. (2) We select the antecedent en-
tity for each anaphor from the antecedent candidate
entities pool E which alleviates the missing true
antecedent problem in the pairwise model. Based
on (1) and (2), MLNs allow us to express relations
between anaphor-anaphor and anaphor-antecedent
pairs ((m,n) or (m,e)) on the global discourse level
improving accuracy by performing joint inference.
</bodyText>
<equation confidence="0.912812">
P(X = x) =2expl� Iwini(x) (1) 5 Features
\Z 5.1 Local features
</equation>
<bodyText confidence="0.999944894736842">
where ni(x) is the number of true groundings of Fi
in x. The normalization factor Z is the partition
function.
MLNs have been applied to many NLP tasks and
achieved good performance by leveraging rich re-
lations among objects (Poon and Domingos, 2008;
Meza-Ruiz and Riedel, 2009; Fahrni and Strube,
2012, inter alia). We use thebeast5 to learn weights
for the formulas and to perform inference. thebeast
employs cutting plane inference (Riedel, 2008) to
improve the accuracy and efficiency of MAP infer-
ence for Markov logic.
With MLNs, we model bridging resolution glob-
ally on the discourse level: given the set M of all
anaphors and sets of local antecedent candidates Em
for each anaphor m ∈ M, we select antecedents for
all anaphors from E = UmCM Em at the same time.
Table 1 shows the hidden predicates and formulas
used. Each formula is associated with a weight. The
</bodyText>
<footnote confidence="0.8646">
5http://code.google.com/p/thebeast
</footnote>
<subsubsectionHeader confidence="0.928406">
5.1.1 Poesio et al.’s feature set
</subsubsectionHeader>
<bodyText confidence="0.9999637">
Table 2 shows the feature set proposed by Poesio et
al. (2004) for part-of bridging. Google distance is
the inverse value of Google hit counts for the ofPat-
tern query (e.g. the windows of the center). Word-
Net distance is the inverse value of the shortest path
length between an anaphor and an antecedent candi-
date among all synset combinations. These features
are supposed to capture the meronymy relation be-
tween anaphor and antecedent. The other ones mea-
sure the salience of the antecedent candidate.
</bodyText>
<table confidence="0.967421333333333">
Group Feature Value
lexical Google distance numeric
WordNet distance numeric
salience utterance distance numeric
local first mention boolean
global first mention boolean
</table>
<tableCaption confidence="0.999255">
Table 2: Poesio et al.’s feature set
</tableCaption>
<page confidence="0.984403">
910
</page>
<bodyText confidence="0.786433">
Hidden predicates
</bodyText>
<equation confidence="0.979903710526316">
p1 isBridging(m, e)
p2 hasSameAntecedent(m, n)
Formulas
Hard constraints
f1 ∀m ∈ M : |e ∈ E : isBridging(m, e) |≤ 1
f2 ∀m ∈ M∀e ∈ E : hasPairDistance(e, m, d) ∧ d &lt; 0 → ¬isBridging(m, e)
f3 ∀m, n ∈ M : m =6 n ∧ hasSameAntecedent(m, n)
→ hasSameAntecedent(n, m)
f4 ∀m, n, l ∈ M : m =6 n ∧ m =6 l ∧ n =6 l ∧ hasSameAntecedent(m, n)
∧ hasSameAntecedent(n, l) → hasSameAntecedent(m, l)
f5 ∀m, n ∈ M∀e ∈ E : m =6 n ∧ hasSameAntecedent(m, n) ∧ isBridging(m, e)
→ isBridging(n, e)
f6 ∀m, n ∈ M∀e ∈ E : m =6 n ∧ isBridging(m, e) ∧ isBridging(n, e)
→ hasSameAntecedent(m, n)
Discourse level formulas
f7 + (w) ∀m ∈ M∀e ∈ E : predictedGlobalAnte(e) ∧ hasPairDistance(e, m, d)
∧ d &gt; 0 → isBridging(m, e)
f8 + (w) ∀m, n ∈ M conjunction(m, n) → hasSameAntecedent(m, n)
f9 + (w) ∀m, n ∈ M sameHead(m, n) → hasSameAntecedent(m, n)
f10 + (w) ∀m, n ∈ M similarTo(m, n) → hasSameAntecedent(m, n)
f11 + (w) ∀m ∈ M∀e ∈ E : hasSemanticClass(m, &amp;quot;rolePerson&amp;quot;)
∧ hasSemanticClass(e, &amp;quot;org|gpe&amp;quot;) ∧ hasPairDistance(e, m, d) ∧ d &gt; 0
→ isBridging(m, e)
f12 + (w · d) ∀m ∈ M∀e ∈ E : hasSemanticClass(m, &amp;quot;relativePerson&amp;quot;)
∧ hasSemanticClass(e, &amp;quot;otherPerson&amp;quot;) ∧ hasPairDistanceInverse(e, m, d)
→ isBridging(m, e)
f13 + (w · d) ∀m ∈ M∀e ∈ E : hasSemanticClass(m, ”date”)
∧ hasSemanticClass(e, ”date”) ∧ hasPairDistanceInverse(e,m, d)
→ isBridging(m, e)
Local formulas
f14 + (w) ∀m ∈ M ∀e ∈ Em : isTopRelativeRankPrepPattern(m, e) → isBridging(m, e)
f15 + (w) ∀m ∈ M ∀e ∈ Em : isTopRelativeRankVerbPattern(m, e) → isBridging(m, e)
f16 + (w · d) ∀m ∈ M ∀e ∈ Em : isPartOf (m, e) ∧ hasPairDistanceInverse(e, m, d)
→ isBridging(m, e)
f17 + (w) ∀m ∈ M ∀e ∈ Em : isTopRelativeRankDocSpan (m, e) → isBridging(m, e)
f18 − (w) ∀m ∈ M ∀e ∈ Em : isSameHead(m, e) → isBridging(m, e)
f19 + (w) ∀m ∈ M ∀e ∈ Em : isPremodOverlap(m, e) → isBridging(m, e)
f20 − (w) ∀m ∈ M ∀e ∈ Em : isCoArgument(m, e) → isBridging(m, e)
</equation>
<tableCaption confidence="0.997994666666667">
Table 1: Hidden predicates and formulas used for bridging resolution (m, n, l represent mentions, M the set of bridging
anaphora mentions in the whole document, e the antecedent candidate entity, E,,,, the set of local antecedent candidate
entities for m, and E = U ..E:M E,,,, )
</tableCaption>
<page confidence="0.988314">
911
</page>
<subsubsectionHeader confidence="0.903329">
5.1.2 Other features
</subsubsectionHeader>
<bodyText confidence="0.9986692">
Since Poesio et al. (2004) deal exclusively with
meronymy bridging, we have to extend the fea-
ture set to capture more diverse relations between
anaphor and antecedent. All numeric features in Ta-
ble 3 are normalized among all antecedent candi-
dates of one anaphor. For anaphor mi and its an-
tecedent candidates Emi (eij E Emi), the numeric
score for pair {mi, eik} is Sik. Then the value
NormSik for this pair is normalized (set to values
between 0 and 1) as below:
</bodyText>
<equation confidence="0.750525333333333">
NormS Sik − mini Si, 2
ak = ( )
maxj Sij − minj Sij
</equation>
<bodyText confidence="0.961053333333333">
A second variant of numeric features tells whether
the score of an anaphor-antecedent candidate pair is
the highest among all pairs for this anaphor.
</bodyText>
<table confidence="0.999600444444444">
Group Feature Value
semantic feat1 preposition pattern numeric
feat2 verb pattern numeric
feats WordNet partOf boolean
feat� semantic class nominal
salience feats document span numeric
surface feats isSameHead boolean
feat7 isPremodOverlap boolean
syntactic feats isCoArgument boolean
</table>
<tableCaption confidence="0.99952">
Table 3: Local features we developed
</tableCaption>
<bodyText confidence="0.998773368421053">
Preposition pattern (feat1). The ofPattern pro-
posed by Poesio et al. (2004) is useful for part-of
and attribute-of relations but cannot cover all bridg-
ing relations (such as sanctions against a country).
We extend the ofPattern to a generalised preposition
pattern by using the Gigaword (Parker et al., 2011)
and the Tipster (Harman and Liberman, 1993) cor-
pora (both automatically POS tagged and NP chun-
ked for improving query match precision).
First, we extract the three most highly associ-
ated prepositions for each anaphor. Then for each
anaphor-antecedent candidate pair, we use their head
words to create the query ”anaphor preposition an-
tecedent”. To improve recall, we take lowercase,
uppercase, singular and plural forms of the head
word into account, and replace proper names by
fine-grained named entity types (using a gazetteer).
All raw hit counts are converted into the Dunning
Root Loglikelihood association measure,6 then nor-
malized using Formula 2 within all antecedent can-
didates of one anaphor.
Verb pattern (feat2). A set-membership rela-
tion between anaphor and antecedent is often hard
to capture by the preposition pattern because the
anaphor often has no common noun head (see Ex-
ample 2 in Section 3). Hence, we measure the com-
patibility of the antecedent candidates with the verb
the anaphor depends on.
First, we hypothesise that anaphors whose lexi-
cal head is a pronoun or a number are potential set
bridging cases and then extract the verb the anaphor
depends on. In example 2, for the set anaphor An-
other, poked is the verb. Then for each antecedent
candidate, subject-verb or verb-object queries are
applied to the Web 1T 5-gram corpus (Brants and
Franz, 2006). In this case, employees poked and di-
amonds poked are example queries. The hit counts
are transformed into PMI and all pairs for one
anaphor are normalized as described in Formula 2.
WordNet partOf relation (feat3). To capture
part-of bridging, we extract whether the anaphor is
part of the antecedent candidate in WordNet. To im-
prove recall, we use hyponym information of the
antecedent. If an antecedent e is a hypernym of x
and an anaphor m is a meronym of x, then m is a
meronym of e.
Semantic class (feat4). The anaphor and the an-
tecedent candidate are assigned one of 16 coarse-
grained semantic classes, e.g. location, organiza-
tion, GPE, roleperson, relativePerson, otherPerson7,
product, language, NORP (nationalities, religious
or political groups) and several classes for numbers
(such as date, money or percent).
Salience feature (feat5). Salient entities are pre-
ferred as antecedents. We capture salience super-
ficially by computing the ”antecedent document
span” of an antecedent candidate. We compute the
</bodyText>
<footnote confidence="0.891889714285714">
6http://tdunning.blogspot.de/2008/03/
surprise-and-coincidence.html
7We use WordNet to extract lists for rolePerson (persons like
president or teacher playing a role in an organization) and rela-
tivePerson (persons like father or son indicating that they have
a relation with another person). Persons not in these two lists
are counted as otherPerson.
</footnote>
<page confidence="0.995501">
912
</page>
<bodyText confidence="0.999933272727273">
span of text (measured in sentences) in which the
antecedent candidate entity is mentioned. This is di-
vided by the number of sentences in the whole doc-
ument. This score is normalized using Formula 2 for
all antecedent candidates of one anaphor.
Surface features (feat6-feat7). isSameHead
(feat6) checks whether antecedent candidates have
the same head as the anaphor: this is rarely the
case in bridging anaphora (except in some cases
of set bridging and spatial/temporal sequence, see
Example 3) and can therefore be used to exclude
antecedent candidates. isPremodOverlap (feat7)
determines the antecedent for compound noun
anaphors whose head is prenominally modified by
the antecedent head (see Example 4).
Syntactic feature (feat8) The isCoArgument fea-
ture is based on the intuition that the subject can-
not be the bridging antecedent of the object in
the same clause. This feature excludes (some)
close antecedent candidates. In Example 4, the an-
tecedent candidate the Japanese isCoArgument with
the anaphor that equipment market.
</bodyText>
<subsectionHeader confidence="0.996161">
5.2 Global features for MLNs
</subsectionHeader>
<bodyText confidence="0.999959357142857">
f1-f13 in Table 1 are discourse level constraints.
All antecedent candidates come from the antecedent
candidates pool E in the whole document.
Global salience (Table 1: f3-f10). The salience
feature in the pairwise model only measures the
salience for candidates within the local window.
However, globally salient antecedents are preferred
even if they are far away from the anaphor. We
model this from two perspectives:
f7 models the preference for globally salient an-
tecedents, which we derive for each document. For
m ∈ M and e ∈ E, let score(m, e) be the prepo-
sition pattern score for pair (m,e). Calculate pattern
semantic salience score esal for each e ∈ E as
</bodyText>
<equation confidence="0.9913355">
�esal = score(m, e) (3)
mEM
</equation>
<bodyText confidence="0.995673184210526">
If e appears in the title and also has the highest
pattern semantic salience score esal among all e in
E, then e is the predicted globally salient antecedent
for this document. Note that global salience here is
based on semantic connectivity to all anaphors in the
document and that not every document has a glob-
ally salient antecedent.
f3-f6 and f8-f10 model that similar or related
anaphors in one document are likely to have the
same antecedent. To make the ground Markov net-
work more sparse for more efficient inference, we
add the hidden predicate (p2) and hard constraints
(f3-f6) specifying relations among similar/related
anaphors m, n and l (reflexivity and transitivity).
Formulas f8-f10 explore three different ways (syn-
tactic and semantic) to compute the similarity be-
tween two anaphors. In f10, we use SVMl�ght (simi-
larity scores from WordNet plus sentence distance as
features) to predict whether two anaphors not shar-
ing the same head are similar or not.
Frequent bridging relations (Table 1: f11-f13).
Three common bridging relations are restricted by
semantic class of anaphor and antecedent (see also
Section 3). It is worth noting that in formula f11
(modeling that a role person mention like presi-
dent or chairman prefers organization or GPE an-
tecedents), we do not penalize the antecedents far
away from the anaphor. In formula f12 (modeling
that a relativePerson mention such as mother or hus-
band prefers close person antecedents) and f13, we
prefer close antecedents by including the distance
between antecedent and anaphor into the weights.
MLN formulation of local features (Table 1: f14-
f20). Corresponding to features of the pairwise
model (Table 3) – we exclude only semantic class
as this is modelled globally via features f11-f13.
These local features are only used for an anaphor m
and its local antecedent candidate e from Em.
</bodyText>
<sectionHeader confidence="0.997056" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.981487">
6.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.9999932">
We perform experiments on our gold standard cor-
pus via 10-fold cross-validation on documents. We
use gold standard mentions, true coreference infor-
mation, and the OntoNotes named entity and syntac-
tic annotation layers for feature extraction.
</bodyText>
<subsectionHeader confidence="0.998915">
6.2 Improved baseline
</subsectionHeader>
<bodyText confidence="0.9970125">
We reimplement the algorithm from Poesio et al.
(2004) as baseline. Since they did not explain
</bodyText>
<page confidence="0.997782">
913
</page>
<bodyText confidence="0.9999824">
whether they used the mention-mention or mention-
entity model, we assume they treated antecedents as
entities and use a 2 and 5 sentence window for can-
didates8. Since the GoogleAPI is not available any
more, we use the Web 1T 5-gram corpus (Brants and
Franz, 2006) to extract the Google distance feature.
We improve it by taking all information about en-
tities via coreference into account as well as by re-
placing proper names. All other features (Table 2
in Section 5.1.1) are extracted as Poesio et al. did.
A Naive Bayes classifier with standard settings in
WEKA (Witten and Frank, 2005) is used. In order
to evaluate their model in the more realistic setting
of our experiment, we apply the best first strategy to
select the antecedent for each anaphor.
</bodyText>
<subsectionHeader confidence="0.99821">
6.3 Pairwise models
</subsectionHeader>
<bodyText confidence="0.99955747826087">
Pairwise model I: We use the preposition pattern
feature (feat1) plus Poesio et al.’s salience features
(Table 2). We use a 2 sentence window as it per-
formed on a par with the 5 sentence window in the
baseline. We replace Naive Bayes with SVM&amp;quot;ght
because it can deal better with imbalanced data9.
Pairwise model II: Based on Pairwise model I.
Local features feat2-feat8 from Table 2 are added.
Pairwise model III: Based on Pairwise model II.
We apply a more advanced antecedent candidate se-
lection strategy, which allows to include 77% of NP
antecedents compared to 71% in Pairwise model II.
For each anaphor, we add the top k salient enti-
ties measured through the length of the coreference
chains (k is set to 10%) as additional antecedent can-
didates. For potential set anaphors (as automatically
determined by pronoun or number heads), singu-
lar antecedent candidates are filtered out. We com-
piled a small set of adjectives (using FrameNet and
thesauri) that indicate spatial or temporal sequences
(see Example 3). For anaphors modified by such ad-
jectives we consider only antecedent candidates that
have the same semantic class as the anaphor.
</bodyText>
<footnote confidence="0.9737395">
8They use a 5 sentence window, because all antecedents in
their corpus are within the previous 5 sentences.
9The SVMlight parameter is set according to the ratio be-
tween positive and negative instances in the training set.
</footnote>
<subsectionHeader confidence="0.980931">
6.4 MLN models
</subsectionHeader>
<bodyText confidence="0.998336833333333">
MLN model I: MLN system using local formu-
las f1-f2 and f14-f20. The same strategy as in
Pairwise model III is used to select local antecedent
candidates En for each anaphor m.
MLN model II: Based on MLN model I, all for-
mulas in Table 1 are used.
</bodyText>
<sectionHeader confidence="0.575448" genericHeader="evaluation">
6.5 Results
</sectionHeader>
<tableCaption confidence="0.553127333333333">
Table 4 shows the comparison of our models to base-
lines. Significance tests are conducted using McNe-
mar’s test on overall accuracy at the level of 1%.
</tableCaption>
<table confidence="0.998301875">
acc
improved baseline 2 sent. + NB 18.85
5 sent. + NB 18.40
pairwise model pairwise model I 29.11
pairwise model II 33.94
pairwise model III 36.35
MLN model MLN model I 35.60
MLN model II 41.32
</table>
<tableCaption confidence="0.994102">
Table 4: Results for MLN models compared to pairwise
models and baselines.
</tableCaption>
<bodyText confidence="0.999408">
MLN model II, which is inspired by the linguis-
tic observation that globally salient entities are pre-
ferred as antecedents, performs significantly better
than all other systems. The gains come from three
aspects. First, by selecting the antecedent for each
anaphor from the antecedent candidate pool E in the
whole document 91% of NP antecedents are acces-
sible compared to 77% in pairwise model III. Sec-
ond, we leverage semantics and salience by using
local formulas and discourse level formulas. Lo-
cal formulas are used to capture semantic relations
for bridging pairs as well as surface and syntactic
constraints. Global formulas resolve several bridg-
ing anaphors together, often to a globally salient an-
tecedent beyond the local window. Third, the model
allows us to express specific relations among bridg-
ing anaphors and their antecedents (f11-f13).
However, our pairwise model I already outper-
forms improved baselines by about 10%, which sug-
gests that our preposition pattern feature can capture
more diverse semantic relations. The continuous im-
provements shown in pairwise model II and pair-
wise model III verify the contribution of our other
</bodyText>
<page confidence="0.995989">
914
</page>
<bodyText confidence="0.9994874">
features and advanced antecedent candidate selec-
tion strategy. pairwise model III would become too
complex if we tried to integrate discourse level for-
mulas f7, f11-f13 into antecedent candidate selec-
tion. MLN model II solves this task elegantly.
</bodyText>
<subsectionHeader confidence="0.984481">
6.6 Discussion and error analysis
</subsectionHeader>
<bodyText confidence="0.998906666666667">
We analyse our best model (MLN model II) and
compare it to the best local one (pairwise model III).
Anaphors with long distance antecedents are
harder to resolve. Table 5 shows the compari-
son of correctly resolved anaphors with regard to
anaphor-antecedent distance. We can see that the
global model is equal or better to the local model
for all anaphor types but that the difference is espe-
cially large for anaphora with antecedents that are
3 or more sentences away due to the use of global
salience and accessibility of possible antecedents
beyond a fixed window-size.
</bodyText>
<table confidence="0.97159775">
# pairs MLN II pairwise III
sent. distance 175 48.57 45.14
0 260
90
158
1 34.62 35
2 47.78 43.33
≥3 35.44 16.46
</table>
<tableCaption confidence="0.9103085">
Table 5: Comparison of the percentage of correctly re-
solved anaphors with regard to anaphor-antecedent dis-
tance. Significance tests are conducted using McNemar’s
test at the level of 1%.
</tableCaption>
<bodyText confidence="0.99998515">
We now distinguish between ”sibling anaphors”
(anaphors that share an antecedent with other bridg-
ing anaphors) and ”non-siblings” (anaphors that do
not share an antecedent with any other anaphor).
The performance of our MLN model II is 54%
on sibling anaphors but only 24% on non-sibling
anaphors. This shows that our use of global salience
and links between related anaphors does indeed help
to capture the behaviour of sibling anaphors.
However, our global model is good at predicting
the right antecedent for sibling anaphors where the
antecedent is globally salient but not as good for sib-
ling anaphors where the (shared) antecedent is a lo-
cally salient subtopic. Thus, in the future we need
to model equivalent constraints for local salience
of antecedents, taking into account topic segmen-
tation/shifts to improve over the 54% for sibling
anaphors.
The semantic knowledge we employ is still in-
sufficient. Typical cases where we have problems
are: (i) cases with very context-specific bridging re-
lations. For example, in one text about the stealing
of Sago Palms in California we found the thieves
as a bridging anaphor with the antecedent palms,
which is not a very usual semantic link. (ii) more
frequently, we have cases where several good an-
tecedents from a semantic perspective can be found.
For example, two laws are discussed and a later
anaphor the veto could be the veto of either bills.
Integration of the wider context apart from the two
NPs is necessary in these cases. This includes the se-
mantics of modification, whereas we currently con-
sider only head noun knowledge. An example is that
the anaphor the local council would preferably be
interpreted as the council of a village instead of the
council of a state due to the occurrence of local.
Finally, 6% of the anaphors in our corpus have a
non-NP antecedent. These cases are not correctly
resolved in our current model as we only extract NP
phrases as potential candidate antecedents.
</bodyText>
<sectionHeader confidence="0.999209" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.998322454545455">
We provide the first reasonably sized and reliably
annotated English corpus for bridging resolution. It
covers a diverse set of relations between anaphor and
antecedent as well as all anaphor/antecedent types.
We developed novel semantic, syntactic and salience
features based on linguistic intuition. Inspired by
the observation that salient entities are preferred as
antecedents, we implemented a global model for an-
tecedent selection within the framework of Markov
logic networks. We show that our global model sig-
nificantly outperforms other local models and base-
lines. This work is – to our knowledge – the first
bridging resolution algorithm that tackles the unre-
stricted phenomenon in a real setting.
Acknowledgements. Yufang Hou is funded by a PhD
scholarship from the Research Training Group Coher-
ence in Language Processing at Heidelberg University.
Katja Markert receives a Fellowship for Experienced Re-
searchers by the Alexander-von-Humboldt Foundation.
We thank HITS gGmbH for hosting Katja Markert and
funding the annotation. We thank our colleague Angela
Fahrni for advice on using Markov logic networks.
</bodyText>
<page confidence="0.997614">
915
</page>
<sectionHeader confidence="0.990079" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999853018867925">
Regina Barzilay and Mirella Lapata. 2008. Modeling
local coherence: An entity-based approach. Computa-
tional Linguistics, 34(1):1–34.
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram
version 1. LDC2006T13, Philadelphia, Penn.: Lin-
guistic Data Consortium.
Aoife Cahill and Arndt Riester. 2012. Automatically ac-
quiring fine-grained information status distinctions in
German. In Proceedings of the SIGdial 2012 Confer-
ence: The 13th Annual Meeting of the Special Interest
Group on Discourse and Dialogue, Seoul, Korea, 5–6
July 2012, pages 232–236.
Tommaso Caselli and Irina Prodanof. 2006. Annotat-
ing bridging anaphors in Italian: In search of reliabil-
ity. In Proceedings ofthe 5th International Conference
on Language Resources and Evaluation, Genoa, Italy,
22–28 May 2006.
Herbert H. Clark. 1975. Bridging. In Proceedings of the
Conference on Theoretical Issues in Natural Language
Processing, Cambridge, Mass., June 1975, pages 169–
174.
Pedro Domingos and Daniel Lowd. 2009. Markov
Logic: An Interface Layer for Artificial Intelligence.
Morgan Claypool Publishers.
Angela Fahrni and Michael Strube. 2012. Jointly
disambiguating and clustering concepts and entities
with Markov logic. In Proceedings of the 24th In-
ternational Conference on Computational Linguistics,
Mumbai, India, 8–15 December 2012, pages 815–832.
Kari Fraurud. 1990. Definiteness and the processing of
noun phrases in natural discourse. Journal of Seman-
tics, 7:395–433.
Claire Gardent and H´el`ene Manu´elian. 2005. Cr´eation
d’un corpus annot´e pour le traitement des descrip-
tions d´efinies. Traitement Automatique des Langues,
46(1):115–140.
Matthew Gerber and Joyce Chai. 2012. Semantic role
labeling of implicit arguments for nominal predicates.
Computational Linguistics, 38(4):756–798.
Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski.
1993. Cognitive status and the form of referring ex-
pressions in discourse. Language, 69:274–307.
Donna Harman and Mark Liberman. 1993. TIPSTER
Complete. LDC93T3A, Philadelphia, Penn.: Linguis-
tic Data Consortium.
Iorn Korzen and Matthias Buch-Kromann. 2011.
Anaphoric relations in the Copenhagen dependency
treebanks. In S. Dipper and H. Zinsmeister, edi-
tors, Corpus-based Investigations of Pragmatic and
Discourse Phenomena, volume 3 of Bochumer Lin-
guistische Arbeitsberichte, pages 83–98. University of
Bochum, Bochum, Germany.
Emmanuel Lassalle and Pascal Denis. 2011. Leverag-
ing different meronym discovery methods for bridging
resolution in French. In Proceedings of the 8th Dis-
course Anaphora and Anaphor Resolution Colloquium
(DAARC 2011), Faro, Algarve, Portugal, 6–7 October
2011, pages 35–46.
Katja Markert, Malvina Nissim, and Natalia N. Mod-
jeska. 2003. Using the web for nominal anaphora
resolution. In Proceedings of the EACL Workshop on
the Computational Treatment ofAnaphora. Budapest,
Hungary, 14 April 2003, pages 39–46.
Katja Markert, Yufang Hou, and Michael Strube. 2012.
Collective classification for fine-grained information
status. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics, Jeju Is-
land, Korea, 8–14 July 2012, pages 795–804.
Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly
identifying predicates, arguments and senses using
Markov logic. In Proceedings of Human Language
Technologies 2009: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, Boulder, Col., 31 May – 5 June
2009, pages 155–163.
Shachar Mirkin, Ido Dagan, and Sebastian Pad´o. 2010.
Assessing the role of discourse references in entail-
ment inference. In Proceedings of the 48th Annual
Meeting ofthe Association for Computational Linguis-
tics, Uppsala, Sweden, 11–16 July 2010, pages 1209–
1219.
Natalia M. Modjeska, Katja Markert, and Malvina Nis-
sim. 2003. Using the web in machine learning for
other-anaphora resolution. In Proceedings of the 2003
Conference on Empirical Methods in Natural Lan-
guage Processing, Sapporo, Japan, 11–12 July 2003,
pages 176–183.
Malvina Nissim, Shipara Dingare, Jean Carletta, and
Mark Steedman. 2004. An annotation scheme for in-
formation status in dialogue. In Proceedings of the 4th
International Conference on Language Resources and
Evaluation, Lisbon, Portugal, 26–28 May 2004, pages
1023–1026.
Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword Fifth Edi-
tion. LDC2011T07.
Massimo Poesio and Renata Vieira. 1998. A corpus-
based investigation of definite description use. Com-
putational Linguistics, 24(2):183–216.
Massimo Poesio, Rahul Mehta, Axel Maroudas, and
Janet Hitzeman. 2004. Learning to resolve bridging
references. In Proceedings of the 42nd Annual Meet-
ing of the Association for Computational Linguistics,
Barcelona, Spain, 21–26 July 2004, pages 143–150.
Massimo Poesio. 2003. Associate descriptions and
salience: A preliminary investigation. In Proceedings
</reference>
<page confidence="0.985486">
916
</page>
<reference confidence="0.999200534482759">
of the EACL Workshop on the Computational Treat-
ment ofAnaphora. Budapest, Hungary, 14 April 2003,
pages 31–38.
Hoifung Poon and Pedro Domingos. 2008. Joint un-
supervised coreference resolution with Markov Logic.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, Waikiki,
Honolulu, Hawaii, 25–27 October 2008, pages 650–
659.
Ellen F. Prince. 1981. Towards a taxonomy of given-new
information. In P. Cole, editor, Radical Pragmatics,
pages 223–255. Academic Press, New York, N.Y.
Altaf Rahman and Vincent Ng. 2012. Learning the fine-
grained information status of discourse entities. In
Proceedings of the 13th Conference of the European
Chapter ofthe Association for Computational Linguis-
tics, Avignon, France, 23–27 April 2012, pages 798–
807.
Sebastian Riedel. 2008. Improving the accuracy and ef-
ficiency of MAP inference for Markov logic. In Pro-
ceedings of the 24th Conference on Uncertainty in Ar-
tificial Intelligence, Helsinki, Finland, 9–12 July 2008,
pages 468–475.
Arndt Riester, David Lorenz, and Nina Seemann. 2010.
A recursive annotation scheme for referential informa-
tion status. In Proceedings of the 7th International
Conference on Language Resources and Evaluation,
La Valetta, Malta, 17–23 May 2010, pages 717–722.
Josef Ruppenhofer, Caroline Sporleder, Roser Morante,
Collin Baker, and Martha Palmer. 2010. SemEval-
2010 Task 10: Linking events and their participants
in discourse. In Proceedings of the 5th International
Workshop on Semantic Evaluations (SemEval-2), Up-
psala, Sweden, 15–16 July 2010, pages 45–50.
Carina Silberer and Anette Frank. 2012. Casting
implicit role linking as an anaphora resolution task.
In Proceedings of STARSEM 2012: The First Joint
Conference on Lexical and Computational Semantics,
Montr´eal, Qu´ebec, Canada, 7–8 June 2012, pages 1–
10.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A machine learning approach to corefer-
ence resolution of noun phrases. Computational Lin-
guistics, 27(4):521–544.
Renata Vieira and Massimo Poesio. 2000. An
empirically-based system for processing definite de-
scriptions. Computational Linguistics, 26(4):539–
593.
Ralph Weischedel, Martha Palmer, Mitchell Marcus, Ed-
uard Hovy, Sameer Pradhan, Lance Ramshaw, Ni-
anwen Xue, Ann Taylor, Jeff Kaufman, Michelle
Franchini, Mohammed El-Bachouti, Robert Belvin,
and Ann Houston. 2011. OntoNotes release 4.0.
LDC2011T03, Philadelphia, Penn.: Linguistic Data
Consortium.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Prac-
tical Machine Learning Tools and Techniques. Mor-
gan Kaufmann, San Francisco, Cal., 2nd edition.
</reference>
<page confidence="0.997255">
917
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959664">
<title confidence="0.999754">Global Inference for Bridging Anaphora Resolution</title>
<author confidence="0.997129">Katja Michael</author>
<affiliation confidence="0.9920685">Institute for Theoretical Studies gGmbH, Heidelberg, of Computing, University of Leeds,</affiliation>
<email confidence="0.99864">scskm@leeds.ac.uk</email>
<abstract confidence="0.997684888888889">We present the first work on antecedent selection for bridging resolution without restrictions on anaphor or relation types. Our model integrates global constraints on top of a rich local feature set in the framework of Markov logic networks. The global model improves over the local one and both strongly outperform a reimplementation of prior work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="2177" citStr="Barzilay and Lapata, 2008" startWordPosition="323" endWordPosition="326">edent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases. We also exclude comparative anaphora (Modjeska et al., 2003) 2Examples are from OntoNotes (Weischedel et al., 2011). Bridging anaphora are typed in boldface; antecedents in italics. Bridging is frequent amounting to between 5% (Gardent and Manu´elian, 2005) and 20% (Caselli and Prodanof, 2006) of definite descriptions (both studies limited to NPs starting with the or nonEnglish equivalents). Bridging resolution is needed to fill gaps in entity grids based on coreference only (Barzilay and Lapata, 2008). Example 1 does not exhibit any coreferential entity coherence. Coherence can only be established when the bridging anaphora are resolved. Bridging resolution may also be important for textual entailment (Mirkin et al., 2010). Bridging resolution can be divided into two tasks, recognizing that a bridging anaphor is present and finding the correct antecedent among a list of candidates. These two tasks have frequently been handled in a pipeline with most research concentrating on antecedent selection only. We also handle only the task of antecedent selection. Previous work on antecedent selecti</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1t 5-gram version 1. LDC2006T13,</title>
<date>2006</date>
<institution>Linguistic Data Consortium.</institution>
<location>Philadelphia, Penn.:</location>
<contexts>
<context position="21227" citStr="Brants and Franz, 2006" startWordPosition="3522" endWordPosition="3525">een anaphor and antecedent is often hard to capture by the preposition pattern because the anaphor often has no common noun head (see Example 2 in Section 3). Hence, we measure the compatibility of the antecedent candidates with the verb the anaphor depends on. First, we hypothesise that anaphors whose lexical head is a pronoun or a number are potential set bridging cases and then extract the verb the anaphor depends on. In example 2, for the set anaphor Another, poked is the verb. Then for each antecedent candidate, subject-verb or verb-object queries are applied to the Web 1T 5-gram corpus (Brants and Franz, 2006). In this case, employees poked and diamonds poked are example queries. The hit counts are transformed into PMI and all pairs for one anaphor are normalized as described in Formula 2. WordNet partOf relation (feat3). To capture part-of bridging, we extract whether the anaphor is part of the antecedent candidate in WordNet. To improve recall, we use hyponym information of the antecedent. If an antecedent e is a hypernym of x and an anaphor m is a meronym of x, then m is a meronym of e. Semantic class (feat4). The anaphor and the antecedent candidate are assigned one of 16 coarsegrained semantic</context>
<context position="26892" citStr="Brants and Franz, 2006" startWordPosition="4431" endWordPosition="4434">perform experiments on our gold standard corpus via 10-fold cross-validation on documents. We use gold standard mentions, true coreference information, and the OntoNotes named entity and syntactic annotation layers for feature extraction. 6.2 Improved baseline We reimplement the algorithm from Poesio et al. (2004) as baseline. Since they did not explain 913 whether they used the mention-mention or mentionentity model, we assume they treated antecedents as entities and use a 2 and 5 sentence window for candidates8. Since the GoogleAPI is not available any more, we use the Web 1T 5-gram corpus (Brants and Franz, 2006) to extract the Google distance feature. We improve it by taking all information about entities via coreference into account as well as by replacing proper names. All other features (Table 2 in Section 5.1.1) are extracted as Poesio et al. did. A Naive Bayes classifier with standard settings in WEKA (Witten and Frank, 2005) is used. In order to evaluate their model in the more realistic setting of our experiment, we apply the best first strategy to select the antecedent for each anaphor. 6.3 Pairwise models Pairwise model I: We use the preposition pattern feature (feat1) plus Poesio et al.’s s</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram version 1. LDC2006T13, Philadelphia, Penn.: Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Arndt Riester</author>
</authors>
<title>Automatically acquiring fine-grained information status distinctions in German.</title>
<date>2012</date>
<booktitle>In Proceedings of the SIGdial 2012 Conference: The 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, Seoul, Korea, 5–6</booktitle>
<pages>232--236</pages>
<contexts>
<context position="6663" citStr="Cahill and Riester, 2012" startWordPosition="1040" endWordPosition="1043">ese problems, i.e. human bridging recognition was reliable, it contains a medium number of bridging cases that allows generalisable statistics and we did not limit bridging anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vieira and Poesio, 2000; Rahman and Ng, 2012; Cahill and Riester, 2012; Markert et al., 2012) and antecedent selection. Work on antecedent selection suffers from focusing on subproblems, e.g. only part-of bridging (Poesio et al., 2004; Markert et al., 2003) or definite NP anaphora (Lassalle and Denis, 2011). Most relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they</context>
</contexts>
<marker>Cahill, Riester, 2012</marker>
<rawString>Aoife Cahill and Arndt Riester. 2012. Automatically acquiring fine-grained information status distinctions in German. In Proceedings of the SIGdial 2012 Conference: The 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, Seoul, Korea, 5–6 July 2012, pages 232–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommaso Caselli</author>
<author>Irina Prodanof</author>
</authors>
<title>Annotating bridging anaphors in Italian: In search of reliability.</title>
<date>2006</date>
<booktitle>In Proceedings ofthe 5th International Conference on Language Resources and Evaluation,</booktitle>
<location>Genoa, Italy,</location>
<contexts>
<context position="1964" citStr="Caselli and Prodanof, 2006" startWordPosition="290" endWordPosition="293">eel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases. We also exclude comparative anaphora (Modjeska et al., 2003) 2Examples are from OntoNotes (Weischedel et al., 2011). Bridging anaphora are typed in boldface; antecedents in italics. Bridging is frequent amounting to between 5% (Gardent and Manu´elian, 2005) and 20% (Caselli and Prodanof, 2006) of definite descriptions (both studies limited to NPs starting with the or nonEnglish equivalents). Bridging resolution is needed to fill gaps in entity grids based on coreference only (Barzilay and Lapata, 2008). Example 1 does not exhibit any coreferential entity coherence. Coherence can only be established when the bridging anaphora are resolved. Bridging resolution may also be important for textual entailment (Mirkin et al., 2010). Bridging resolution can be divided into two tasks, recognizing that a bridging anaphor is present and finding the correct antecedent among a list of candidates</context>
<context position="5475" citStr="Caselli and Prodanof, 2006" startWordPosition="849" endWordPosition="852">nts improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two annotators agreed on only less than a third of bridging anaphors. of relations between anaphor and antecedent (Markert et al., 2003; Poesio et al., 2004). In our own work (Markert et al., 2012) we established a corpus that circumvents these problems, i.e. human bridging re</context>
</contexts>
<marker>Caselli, Prodanof, 2006</marker>
<rawString>Tommaso Caselli and Irina Prodanof. 2006. Annotating bridging anaphors in Italian: In search of reliability. In Proceedings ofthe 5th International Conference on Language Resources and Evaluation, Genoa, Italy, 22–28 May 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<date>1975</date>
<booktitle>Bridging. In Proceedings of the Conference on Theoretical Issues in Natural Language Processing,</booktitle>
<pages>169--174</pages>
<location>Cambridge, Mass.,</location>
<contexts>
<context position="1032" citStr="Clark, 1975" startWordPosition="144" endWordPosition="145">ates global constraints on top of a rich local feature set in the framework of Markov logic networks. The global model improves over the local one and both strongly outperform a reimplementation of prior work. 1 Introduction Identity coreference is a relatively well understood and well-studied instance of entity coherence. However, entity coherence can rely on more complex, lexico-semantic, frame or encyclopedic relations than identity. Anaphora linking distinct entities or events this way are called bridging or associative anaphora and have been widely discussed in the linguistic literature (Clark, 1975; Prince, 1981; Gundel et al., 1993).1 In Example 1, the phrases the windows, the carpets and walls can be felicitously used because they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict</context>
</contexts>
<marker>Clark, 1975</marker>
<rawString>Herbert H. Clark. 1975. Bridging. In Proceedings of the Conference on Theoretical Issues in Natural Language Processing, Cambridge, Mass., June 1975, pages 169– 174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro Domingos</author>
<author>Daniel Lowd</author>
</authors>
<title>Markov Logic: An Interface Layer for Artificial Intelligence.</title>
<date>2009</date>
<publisher>Morgan Claypool Publishers.</publisher>
<contexts>
<context position="12868" citStr="Domingos and Lowd, 2009" startWordPosition="2080" endWordPosition="2083">arately, ignoring 4Different from coreference, we treat an anaphor as a mention and an antecedent as an entity. The anaphor is the first mention of the corresponding entity in the document. 909 relations between instances. We resolve these problems by employing a global model based on Markov logic networks. 4.2 Markov Logic Networks Bridging can be considered a document global phenomenon, where globally salient entities are preferred as antecedents and two or more anaphors having the same antecedent should be related or similar. Motivated by this observation, we explore Markov logic networks (Domingos and Lowd, 2009, MLNs) to model bridging resolution on the global discourse level. MLNs are a powerful representation for joint inference with uncertainty. An MLN consists of a set of pairs (Fi, wi), where Fi is a formula in first-order logic and wi is its associated real numbered weight. It can be viewed as a template for constructing Markov networks. Given different sets of constants, an MLN will produce different ground Markov networks which may vary in size but have the same structure and parameters. For a ground Markov network, the probability distribution over possible worlds x is given by polarity of </context>
</contexts>
<marker>Domingos, Lowd, 2009</marker>
<rawString>Pedro Domingos and Daniel Lowd. 2009. Markov Logic: An Interface Layer for Artificial Intelligence. Morgan Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Michael Strube</author>
</authors>
<title>Jointly disambiguating and clustering concepts and entities with Markov logic.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics,</booktitle>
<pages>815--832</pages>
<location>Mumbai,</location>
<contexts>
<context position="15007" citStr="Fahrni and Strube, 2012" startWordPosition="2442" endWordPosition="2445">ing true antecedent problem in the pairwise model. Based on (1) and (2), MLNs allow us to express relations between anaphor-anaphor and anaphor-antecedent pairs ((m,n) or (m,e)) on the global discourse level improving accuracy by performing joint inference. P(X = x) =2expl� Iwini(x) (1) 5 Features \Z 5.1 Local features where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. MLNs have been applied to many NLP tasks and achieved good performance by leveraging rich relations among objects (Poon and Domingos, 2008; Meza-Ruiz and Riedel, 2009; Fahrni and Strube, 2012, inter alia). We use thebeast5 to learn weights for the formulas and to perform inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP inference for Markov logic. With MLNs, we model bridging resolution globally on the discourse level: given the set M of all anaphors and sets of local antecedent candidates Em for each anaphor m ∈ M, we select antecedents for all anaphors from E = UmCM Em at the same time. Table 1 shows the hidden predicates and formulas used. Each formula is associated with a weight. The 5http://code.google.com/p/thebe</context>
</contexts>
<marker>Fahrni, Strube, 2012</marker>
<rawString>Angela Fahrni and Michael Strube. 2012. Jointly disambiguating and clustering concepts and entities with Markov logic. In Proceedings of the 24th International Conference on Computational Linguistics, Mumbai, India, 8–15 December 2012, pages 815–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kari Fraurud</author>
</authors>
<title>Definiteness and the processing of noun phrases in natural discourse.</title>
<date>1990</date>
<journal>Journal of Semantics,</journal>
<pages>7--395</pages>
<contexts>
<context position="5047" citStr="Fraurud, 1990" startWordPosition="785" endWordPosition="786">gic model that allows us to: • model constraints that certain anaphora are likely to share the same antecedent; • model the global semantic connectivity of a salient potential antecedent to all anaphora in a text; • consider the union of potential antecedents for all anaphora instead of a static window-sized constraint. We show that this global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) ach</context>
</contexts>
<marker>Fraurud, 1990</marker>
<rawString>Kari Fraurud. 1990. Definiteness and the processing of noun phrases in natural discourse. Journal of Semantics, 7:395–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>H´el`ene Manu´elian</author>
</authors>
<title>Cr´eation d’un corpus annot´e pour le traitement des descriptions d´efinies.</title>
<date>2005</date>
<booktitle>Traitement Automatique des Langues,</booktitle>
<volume>46</volume>
<issue>1</issue>
<marker>Gardent, Manu´elian, 2005</marker>
<rawString>Claire Gardent and H´el`ene Manu´elian. 2005. Cr´eation d’un corpus annot´e pour le traitement des descriptions d´efinies. Traitement Automatique des Langues, 46(1):115–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Gerber</author>
<author>Joyce Chai</author>
</authors>
<title>Semantic role labeling of implicit arguments for nominal predicates.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>4</issue>
<contexts>
<context position="7633" citStr="Gerber and Chai (2012)" startWordPosition="1199" endWordPosition="1202"> other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they distinguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of relations. There is a partial overlap between bridging and implicit noun roles (Ruppenhofer et al., 2010). However, work on implicit noun roles is mostly focused on few predicates (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. They 908 are not limited to definite NPs as in previous work. In contrast to Nissim et al. (2004), anteced</context>
</contexts>
<marker>Gerber, Chai, 2012</marker>
<rawString>Matthew Gerber and Joyce Chai. 2012. Semantic role labeling of implicit arguments for nominal predicates. Computational Linguistics, 38(4):756–798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeanette K Gundel</author>
<author>Nancy Hedberg</author>
<author>Ron Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse.</title>
<date>1993</date>
<journal>Language,</journal>
<pages>69--274</pages>
<contexts>
<context position="1068" citStr="Gundel et al., 1993" startWordPosition="148" endWordPosition="151">top of a rich local feature set in the framework of Markov logic networks. The global model improves over the local one and both strongly outperform a reimplementation of prior work. 1 Introduction Identity coreference is a relatively well understood and well-studied instance of entity coherence. However, entity coherence can rely on more complex, lexico-semantic, frame or encyclopedic relations than identity. Anaphora linking distinct entities or events this way are called bridging or associative anaphora and have been widely discussed in the linguistic literature (Clark, 1975; Prince, 1981; Gundel et al., 1993).1 In Example 1, the phrases the windows, the carpets and walls can be felicitously used because they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, 69:274–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna Harman</author>
<author>Mark Liberman</author>
</authors>
<date>1993</date>
<booktitle>TIPSTER Complete. LDC93T3A,</booktitle>
<institution>Linguistic Data Consortium.</institution>
<location>Philadelphia, Penn.:</location>
<contexts>
<context position="19891" citStr="Harman and Liberman, 1993" startWordPosition="3303" endWordPosition="3306">attern numeric feat2 verb pattern numeric feats WordNet partOf boolean feat� semantic class nominal salience feats document span numeric surface feats isSameHead boolean feat7 isPremodOverlap boolean syntactic feats isCoArgument boolean Table 3: Local features we developed Preposition pattern (feat1). The ofPattern proposed by Poesio et al. (2004) is useful for part-of and attribute-of relations but cannot cover all bridging relations (such as sanctions against a country). We extend the ofPattern to a generalised preposition pattern by using the Gigaword (Parker et al., 2011) and the Tipster (Harman and Liberman, 1993) corpora (both automatically POS tagged and NP chunked for improving query match precision). First, we extract the three most highly associated prepositions for each anaphor. Then for each anaphor-antecedent candidate pair, we use their head words to create the query ”anaphor preposition antecedent”. To improve recall, we take lowercase, uppercase, singular and plural forms of the head word into account, and replace proper names by fine-grained named entity types (using a gazetteer). All raw hit counts are converted into the Dunning Root Loglikelihood association measure,6 then normalized usin</context>
</contexts>
<marker>Harman, Liberman, 1993</marker>
<rawString>Donna Harman and Mark Liberman. 1993. TIPSTER Complete. LDC93T3A, Philadelphia, Penn.: Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iorn Korzen</author>
<author>Matthias Buch-Kromann</author>
</authors>
<title>Anaphoric relations in the Copenhagen dependency treebanks.</title>
<date>2011</date>
<booktitle>Corpus-based Investigations of Pragmatic and Discourse Phenomena,</booktitle>
<volume>3</volume>
<pages>83--98</pages>
<editor>In S. Dipper and H. Zinsmeister, editors,</editor>
<institution>University of Bochum,</institution>
<location>Bochum, Germany.</location>
<contexts>
<context position="5205" citStr="Korzen and Buch-Kromann, 2011" startWordPosition="807" endWordPosition="810">onnectivity of a salient potential antecedent to all anaphora in a text; • consider the union of potential antecedents for all anaphora instead of a static window-sized constraint. We show that this global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two ann</context>
</contexts>
<marker>Korzen, Buch-Kromann, 2011</marker>
<rawString>Iorn Korzen and Matthias Buch-Kromann. 2011. Anaphoric relations in the Copenhagen dependency treebanks. In S. Dipper and H. Zinsmeister, editors, Corpus-based Investigations of Pragmatic and Discourse Phenomena, volume 3 of Bochumer Linguistische Arbeitsberichte, pages 83–98. University of Bochum, Bochum, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Lassalle</author>
<author>Pascal Denis</author>
</authors>
<title>Leveraging different meronym discovery methods for bridging resolution in French.</title>
<date>2011</date>
<booktitle>In Proceedings of the 8th Discourse Anaphora and Anaphor Resolution Colloquium (DAARC 2011),</booktitle>
<pages>35--46</pages>
<location>Faro, Algarve,</location>
<contexts>
<context position="2998" citStr="Lassalle and Denis, 2011" startWordPosition="452" endWordPosition="455">tailment (Mirkin et al., 2010). Bridging resolution can be divided into two tasks, recognizing that a bridging anaphor is present and finding the correct antecedent among a list of candidates. These two tasks have frequently been handled in a pipeline with most research concentrating on antecedent selection only. We also handle only the task of antecedent selection. Previous work on antecedent selection for bridging anaphora is restricted. It makes strong untested assumptions about bridging anaphora types or relations, limiting it to definite NPs (Poesio and Vieira, 1998; Poesio et al., 2004; Lassalle and Denis, 2011) or to part-of relations between anaphor and antecedent (Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011). We break new ground by considering all relations and anaphora/antecedent types and show that the variety of bridging anaphora is much higher than reported previously. Following work on coreference resolution, we apply a local pairwise model (Soon et al., 2001) for antecedent selection. We then develop novel semantic, syntactic and salience features for this task, showing strong improvements over one of the best known 907 Proceedings of NAACL-HLT 2013, pages 907–917, At</context>
<context position="5524" citStr="Lassalle and Denis, 2011" startWordPosition="857" endWordPosition="860"> Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two annotators agreed on only less than a third of bridging anaphors. of relations between anaphor and antecedent (Markert et al., 2003; Poesio et al., 2004). In our own work (Markert et al., 2012) we established a corpus that circumvents these problems, i.e. human bridging recognition was reliable, it contains a medium numb</context>
<context position="6901" citStr="Lassalle and Denis, 2011" startWordPosition="1078" endWordPosition="1081">ations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vieira and Poesio, 2000; Rahman and Ng, 2012; Cahill and Riester, 2012; Markert et al., 2012) and antecedent selection. Work on antecedent selection suffers from focusing on subproblems, e.g. only part-of bridging (Poesio et al., 2004; Markert et al., 2003) or definite NP anaphora (Lassalle and Denis, 2011). Most relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they distinguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of relations. There is a partial overlap between bridging and implicit noun rol</context>
<context position="10388" citStr="Lassalle and Denis (2011)" startWordPosition="1656" endWordPosition="1659">cases had meronymic relations. We find many different types of relations in our corpus, including encyclopedic relations such as restaurant — the waiter as well as, frequently, relational person nouns as bridging anaphors such as friend, husband, president. • There are only a few cases of bridging where surface cues may indicate the antecedent. First, some bridging anaphors are modified by a small number of adjectives that have more than one role filler, with the bridging relation often being temporal or spatial sequence between two entities of the same semantic type as in Example 3 (see also Lassalle and Denis (2011) for a discussion of such cases). Second, some anaphors are compounds where the nominal premodifier matches the antecedent head as in Example 4. (2) Still employees do occasionally try to smuggle out a gem or two. One man wrapped several diamonds in the knot of his tie. Another poked a hole in the heel of his shoe. None made it past the body searches... (3) His truck is parked across the field ... The farmer at the next truck shouts ... (4) ... it doesn’t make the equipment needed to produce those chips. And IBM worries that the Japanese will take over that equipment market. 4 Models for Bridg</context>
</contexts>
<marker>Lassalle, Denis, 2011</marker>
<rawString>Emmanuel Lassalle and Pascal Denis. 2011. Leveraging different meronym discovery methods for bridging resolution in French. In Proceedings of the 8th Discourse Anaphora and Anaphor Resolution Colloquium (DAARC 2011), Faro, Algarve, Portugal, 6–7 October 2011, pages 35–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
<author>Natalia N Modjeska</author>
</authors>
<title>Using the web for nominal anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL Workshop on the Computational Treatment ofAnaphora.</booktitle>
<pages>39--46</pages>
<location>Budapest,</location>
<contexts>
<context position="3096" citStr="Markert et al., 2003" startWordPosition="469" endWordPosition="472">ridging anaphor is present and finding the correct antecedent among a list of candidates. These two tasks have frequently been handled in a pipeline with most research concentrating on antecedent selection only. We also handle only the task of antecedent selection. Previous work on antecedent selection for bridging anaphora is restricted. It makes strong untested assumptions about bridging anaphora types or relations, limiting it to definite NPs (Poesio and Vieira, 1998; Poesio et al., 2004; Lassalle and Denis, 2011) or to part-of relations between anaphor and antecedent (Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011). We break new ground by considering all relations and anaphora/antecedent types and show that the variety of bridging anaphora is much higher than reported previously. Following work on coreference resolution, we apply a local pairwise model (Soon et al., 2001) for antecedent selection. We then develop novel semantic, syntactic and salience features for this task, showing strong improvements over one of the best known 907 Proceedings of NAACL-HLT 2013, pages 907–917, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics prior models (Poe</context>
<context position="5933" citStr="Markert et al., 2003" startWordPosition="921" endWordPosition="925"> or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two annotators agreed on only less than a third of bridging anaphors. of relations between anaphor and antecedent (Markert et al., 2003; Poesio et al., 2004). In our own work (Markert et al., 2012) we established a corpus that circumvents these problems, i.e. human bridging recognition was reliable, it contains a medium number of bridging cases that allows generalisable statistics and we did not limit bridging anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Au</context>
</contexts>
<marker>Markert, Nissim, Modjeska, 2003</marker>
<rawString>Katja Markert, Malvina Nissim, and Natalia N. Modjeska. 2003. Using the web for nominal anaphora resolution. In Proceedings of the EACL Workshop on the Computational Treatment ofAnaphora. Budapest, Hungary, 14 April 2003, pages 39–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Yufang Hou</author>
<author>Michael Strube</author>
</authors>
<title>Collective classification for fine-grained information status.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju Island, Korea, 8–14</booktitle>
<pages>795--804</pages>
<contexts>
<context position="5995" citStr="Markert et al., 2012" startWordPosition="934" endWordPosition="937">oesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two annotators agreed on only less than a third of bridging anaphors. of relations between anaphor and antecedent (Markert et al., 2003; Poesio et al., 2004). In our own work (Markert et al., 2012) we established a corpus that circumvents these problems, i.e. human bridging recognition was reliable, it contains a medium number of bridging cases that allows generalisable statistics and we did not limit bridging anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vi</context>
<context position="7889" citStr="Markert et al. (2012)" startWordPosition="1243" endWordPosition="1246">inguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of relations. There is a partial overlap between bridging and implicit noun roles (Ruppenhofer et al., 2010). However, work on implicit noun roles is mostly focused on few predicates (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. They 908 are not limited to definite NPs as in previous work. In contrast to Nissim et al. (2004), antecedents are annotated and can be noun phrases, verb phrases or even clauses. Our bridging annotation is also not limited with regards to semantic relations between anaphor and antecedent. In Markert et al. (2012) we achieved high agreement for the overall inf</context>
</contexts>
<marker>Markert, Hou, Strube, 2012</marker>
<rawString>Katja Markert, Yufang Hou, and Michael Strube. 2012. Collective classification for fine-grained information status. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Jeju Island, Korea, 8–14 July 2012, pages 795–804.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Jointly identifying predicates, arguments and senses using Markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5</booktitle>
<pages>155--163</pages>
<contexts>
<context position="14982" citStr="Meza-Ruiz and Riedel, 2009" startWordPosition="2438" endWordPosition="2441"> E which alleviates the missing true antecedent problem in the pairwise model. Based on (1) and (2), MLNs allow us to express relations between anaphor-anaphor and anaphor-antecedent pairs ((m,n) or (m,e)) on the global discourse level improving accuracy by performing joint inference. P(X = x) =2expl� Iwini(x) (1) 5 Features \Z 5.1 Local features where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. MLNs have been applied to many NLP tasks and achieved good performance by leveraging rich relations among objects (Poon and Domingos, 2008; Meza-Ruiz and Riedel, 2009; Fahrni and Strube, 2012, inter alia). We use thebeast5 to learn weights for the formulas and to perform inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP inference for Markov logic. With MLNs, we model bridging resolution globally on the discourse level: given the set M of all anaphors and sets of local antecedent candidates Em for each anaphor m ∈ M, we select antecedents for all anaphors from E = UmCM Em at the same time. Table 1 shows the hidden predicates and formulas used. Each formula is associated with a weight. The 5http:</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly identifying predicates, arguments and senses using Markov logic. In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5 June 2009, pages 155–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shachar Mirkin</author>
<author>Ido Dagan</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Assessing the role of discourse references in entailment inference.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics,</booktitle>
<pages>1209--1219</pages>
<location>Uppsala,</location>
<marker>Mirkin, Dagan, Pad´o, 2010</marker>
<rawString>Shachar Mirkin, Ido Dagan, and Sebastian Pad´o. 2010. Assessing the role of discourse references in entailment inference. In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics, Uppsala, Sweden, 11–16 July 2010, pages 1209– 1219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia M Modjeska</author>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Using the web in machine learning for other-anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>176--183</pages>
<location>Sapporo,</location>
<contexts>
<context position="1730" citStr="Modjeska et al., 2003" startWordPosition="256" endWordPosition="259">, the carpets and walls can be felicitously used because they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases. We also exclude comparative anaphora (Modjeska et al., 2003) 2Examples are from OntoNotes (Weischedel et al., 2011). Bridging anaphora are typed in boldface; antecedents in italics. Bridging is frequent amounting to between 5% (Gardent and Manu´elian, 2005) and 20% (Caselli and Prodanof, 2006) of definite descriptions (both studies limited to NPs starting with the or nonEnglish equivalents). Bridging resolution is needed to fill gaps in entity grids based on coreference only (Barzilay and Lapata, 2008). Example 1 does not exhibit any coreferential entity coherence. Coherence can only be established when the bridging anaphora are resolved. Bridging reso</context>
</contexts>
<marker>Modjeska, Markert, Nissim, 2003</marker>
<rawString>Natalia M. Modjeska, Katja Markert, and Malvina Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, Sapporo, Japan, 11–12 July 2003, pages 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malvina Nissim</author>
<author>Shipara Dingare</author>
<author>Jean Carletta</author>
<author>Mark Steedman</author>
</authors>
<title>An annotation scheme for information status in dialogue.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>1023--1026</pages>
<location>Lisbon,</location>
<contexts>
<context position="8224" citStr="Nissim et al. (2004)" startWordPosition="1301" endWordPosition="1304"> (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. They 908 are not limited to definite NPs as in previous work. In contrast to Nissim et al. (2004), antecedents are annotated and can be noun phrases, verb phrases or even clauses. Our bridging annotation is also not limited with regards to semantic relations between anaphor and antecedent. In Markert et al. (2012) we achieved high agreement for the overall information status annotation scheme between three annotators (r. between 75 and 80, dependent on annotator pairs) as well as for all subcategories, including bridging (r. over 60 for all annotator pairings, over 70 for two expert annotators). Here, we add the following new results: • Agreement for selecting bridging antecedents was aro</context>
</contexts>
<marker>Nissim, Dingare, Carletta, Steedman, 2004</marker>
<rawString>Malvina Nissim, Shipara Dingare, Jean Carletta, and Mark Steedman. 2004. An annotation scheme for information status in dialogue. In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal, 26–28 May 2004, pages 1023–1026.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<title>English Gigaword Fifth Edition.</title>
<date>2011</date>
<contexts>
<context position="19847" citStr="Parker et al., 2011" startWordPosition="3296" endWordPosition="3299">ure Value semantic feat1 preposition pattern numeric feat2 verb pattern numeric feats WordNet partOf boolean feat� semantic class nominal salience feats document span numeric surface feats isSameHead boolean feat7 isPremodOverlap boolean syntactic feats isCoArgument boolean Table 3: Local features we developed Preposition pattern (feat1). The ofPattern proposed by Poesio et al. (2004) is useful for part-of and attribute-of relations but cannot cover all bridging relations (such as sanctions against a country). We extend the ofPattern to a generalised preposition pattern by using the Gigaword (Parker et al., 2011) and the Tipster (Harman and Liberman, 1993) corpora (both automatically POS tagged and NP chunked for improving query match precision). First, we extract the three most highly associated prepositions for each anaphor. Then for each anaphor-antecedent candidate pair, we use their head words to create the query ”anaphor preposition antecedent”. To improve recall, we take lowercase, uppercase, singular and plural forms of the head word into account, and replace proper names by fine-grained named entity types (using a gazetteer). All raw hit counts are converted into the Dunning Root Loglikelihoo</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edition. LDC2011T07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Renata Vieira</author>
</authors>
<title>A corpusbased investigation of definite description use.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="1525" citStr="Poesio and Vieira (1998)" startWordPosition="225" endWordPosition="228">vents this way are called bridging or associative anaphora and have been widely discussed in the linguistic literature (Clark, 1975; Prince, 1981; Gundel et al., 1993).1 In Example 1, the phrases the windows, the carpets and walls can be felicitously used because they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases. We also exclude comparative anaphora (Modjeska et al., 2003) 2Examples are from OntoNotes (Weischedel et al., 2011). Bridging anaphora are typed in boldface; antecedents in italics. Bridging is frequent amounting to between 5% (Gardent and Manu´elian, 2005) and 20% (Caselli and Prodanof, 2006) of definite descriptions (both studies limited to NPs starting with the or nonEnglish equivalents). Bridging resolution is needed to fill gaps in entity grids b</context>
<context position="2950" citStr="Poesio and Vieira, 1998" startWordPosition="444" endWordPosition="447">esolution may also be important for textual entailment (Mirkin et al., 2010). Bridging resolution can be divided into two tasks, recognizing that a bridging anaphor is present and finding the correct antecedent among a list of candidates. These two tasks have frequently been handled in a pipeline with most research concentrating on antecedent selection only. We also handle only the task of antecedent selection. Previous work on antecedent selection for bridging anaphora is restricted. It makes strong untested assumptions about bridging anaphora types or relations, limiting it to definite NPs (Poesio and Vieira, 1998; Poesio et al., 2004; Lassalle and Denis, 2011) or to part-of relations between anaphor and antecedent (Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011). We break new ground by considering all relations and anaphora/antecedent types and show that the variety of bridging anaphora is much higher than reported previously. Following work on coreference resolution, we apply a local pairwise model (Soon et al., 2001) for antecedent selection. We then develop novel semantic, syntactic and salience features for this task, showing strong improvements over one of the best known 907 </context>
<context position="5396" citStr="Poesio and Vieira, 1998" startWordPosition="836" endWordPosition="839"> global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with other categories so that the two annotators agreed on only less than a third of bridging anaphors. of relations between anaphor and antecedent (Markert et al., 2003; Poesio et al., 2004). In our own work (Markert et al., 2012) </context>
</contexts>
<marker>Poesio, Vieira, 1998</marker>
<rawString>Massimo Poesio and Renata Vieira. 1998. A corpusbased investigation of definite description use. Computational Linguistics, 24(2):183–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Rahul Mehta</author>
<author>Axel Maroudas</author>
<author>Janet Hitzeman</author>
</authors>
<title>Learning to resolve bridging references.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>143--150</pages>
<location>Barcelona,</location>
<contexts>
<context position="2971" citStr="Poesio et al., 2004" startWordPosition="448" endWordPosition="451">ortant for textual entailment (Mirkin et al., 2010). Bridging resolution can be divided into two tasks, recognizing that a bridging anaphor is present and finding the correct antecedent among a list of candidates. These two tasks have frequently been handled in a pipeline with most research concentrating on antecedent selection only. We also handle only the task of antecedent selection. Previous work on antecedent selection for bridging anaphora is restricted. It makes strong untested assumptions about bridging anaphora types or relations, limiting it to definite NPs (Poesio and Vieira, 1998; Poesio et al., 2004; Lassalle and Denis, 2011) or to part-of relations between anaphor and antecedent (Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011). We break new ground by considering all relations and anaphora/antecedent types and show that the variety of bridging anaphora is much higher than reported previously. Following work on coreference resolution, we apply a local pairwise model (Soon et al., 2001) for antecedent selection. We then develop novel semantic, syntactic and salience features for this task, showing strong improvements over one of the best known 907 Proceedings of NAACL-</context>
<context position="5173" citStr="Poesio et al., 2004" startWordPosition="803" endWordPosition="806">the global semantic connectivity of a salient potential antecedent to all anaphora in a text; • consider the union of potential antecedents for all anaphora instead of a static window-sized constraint. We show that this global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphoric bridging category (BRI) is frequently confused with othe</context>
<context position="6827" citStr="Poesio et al., 2004" startWordPosition="1066" endWordPosition="1069">ing anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vieira and Poesio, 2000; Rahman and Ng, 2012; Cahill and Riester, 2012; Markert et al., 2012) and antecedent selection. Work on antecedent selection suffers from focusing on subproblems, e.g. only part-of bridging (Poesio et al., 2004; Markert et al., 2003) or definite NP anaphora (Lassalle and Denis, 2011). Most relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they distinguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of re</context>
<context position="15707" citStr="Poesio et al. (2004)" startWordPosition="2560" endWordPosition="2563"> inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP inference for Markov logic. With MLNs, we model bridging resolution globally on the discourse level: given the set M of all anaphors and sets of local antecedent candidates Em for each anaphor m ∈ M, we select antecedents for all anaphors from E = UmCM Em at the same time. Table 1 shows the hidden predicates and formulas used. Each formula is associated with a weight. The 5http://code.google.com/p/thebeast 5.1.1 Poesio et al.’s feature set Table 2 shows the feature set proposed by Poesio et al. (2004) for part-of bridging. Google distance is the inverse value of Google hit counts for the ofPattern query (e.g. the windows of the center). WordNet distance is the inverse value of the shortest path length between an anaphor and an antecedent candidate among all synset combinations. These features are supposed to capture the meronymy relation between anaphor and antecedent. The other ones measure the salience of the antecedent candidate. Group Feature Value lexical Google distance numeric WordNet distance numeric salience utterance distance numeric local first mention boolean global first menti</context>
<context position="18578" citStr="Poesio et al. (2004)" startWordPosition="3088" endWordPosition="3091">Bridging(m, e) f17 + (w) ∀m ∈ M ∀e ∈ Em : isTopRelativeRankDocSpan (m, e) → isBridging(m, e) f18 − (w) ∀m ∈ M ∀e ∈ Em : isSameHead(m, e) → isBridging(m, e) f19 + (w) ∀m ∈ M ∀e ∈ Em : isPremodOverlap(m, e) → isBridging(m, e) f20 − (w) ∀m ∈ M ∀e ∈ Em : isCoArgument(m, e) → isBridging(m, e) Table 1: Hidden predicates and formulas used for bridging resolution (m, n, l represent mentions, M the set of bridging anaphora mentions in the whole document, e the antecedent candidate entity, E,,,, the set of local antecedent candidate entities for m, and E = U ..E:M E,,,, ) 911 5.1.2 Other features Since Poesio et al. (2004) deal exclusively with meronymy bridging, we have to extend the feature set to capture more diverse relations between anaphor and antecedent. All numeric features in Table 3 are normalized among all antecedent candidates of one anaphor. For anaphor mi and its antecedent candidates Emi (eij E Emi), the numeric score for pair {mi, eik} is Sik. Then the value NormSik for this pair is normalized (set to values between 0 and 1) as below: NormS Sik − mini Si, 2 ak = ( ) maxj Sij − minj Sij A second variant of numeric features tells whether the score of an anaphor-antecedent candidate pair is the hig</context>
<context position="26584" citStr="Poesio et al. (2004)" startWordPosition="4377" endWordPosition="4380">: f14- f20). Corresponding to features of the pairwise model (Table 3) – we exclude only semantic class as this is modelled globally via features f11-f13. These local features are only used for an anaphor m and its local antecedent candidate e from Em. 6 Experiments and Results 6.1 Experimental setup We perform experiments on our gold standard corpus via 10-fold cross-validation on documents. We use gold standard mentions, true coreference information, and the OntoNotes named entity and syntactic annotation layers for feature extraction. 6.2 Improved baseline We reimplement the algorithm from Poesio et al. (2004) as baseline. Since they did not explain 913 whether they used the mention-mention or mentionentity model, we assume they treated antecedents as entities and use a 2 and 5 sentence window for candidates8. Since the GoogleAPI is not available any more, we use the Web 1T 5-gram corpus (Brants and Franz, 2006) to extract the Google distance feature. We improve it by taking all information about entities via coreference into account as well as by replacing proper names. All other features (Table 2 in Section 5.1.1) are extracted as Poesio et al. did. A Naive Bayes classifier with standard settings</context>
</contexts>
<marker>Poesio, Mehta, Maroudas, Hitzeman, 2004</marker>
<rawString>Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet Hitzeman. 2004. Learning to resolve bridging references. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, Barcelona, Spain, 21–26 July 2004, pages 143–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
</authors>
<title>Associate descriptions and salience: A preliminary investigation.</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL Workshop on the Computational Treatment ofAnaphora.</booktitle>
<pages>31--38</pages>
<location>Budapest,</location>
<contexts>
<context position="5061" citStr="Poesio, 2003" startWordPosition="787" endWordPosition="788">allows us to: • model constraints that certain anaphora are likely to share the same antecedent; • model the global semantic connectivity of a salient potential antecedent to all anaphora in a text; • consider the union of potential antecedents for all anaphora instead of a static window-sized constraint. We show that this global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agr</context>
</contexts>
<marker>Poesio, 2003</marker>
<rawString>Massimo Poesio. 2003. Associate descriptions and salience: A preliminary investigation. In Proceedings of the EACL Workshop on the Computational Treatment ofAnaphora. Budapest, Hungary, 14 April 2003, pages 31–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov Logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>650--659</pages>
<location>Waikiki, Honolulu, Hawaii,</location>
<contexts>
<context position="14954" citStr="Poon and Domingos, 2008" startWordPosition="2434" endWordPosition="2437">t candidate entities pool E which alleviates the missing true antecedent problem in the pairwise model. Based on (1) and (2), MLNs allow us to express relations between anaphor-anaphor and anaphor-antecedent pairs ((m,n) or (m,e)) on the global discourse level improving accuracy by performing joint inference. P(X = x) =2expl� Iwini(x) (1) 5 Features \Z 5.1 Local features where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. MLNs have been applied to many NLP tasks and achieved good performance by leveraging rich relations among objects (Poon and Domingos, 2008; Meza-Ruiz and Riedel, 2009; Fahrni and Strube, 2012, inter alia). We use thebeast5 to learn weights for the formulas and to perform inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP inference for Markov logic. With MLNs, we model bridging resolution globally on the discourse level: given the set M of all anaphors and sets of local antecedent candidates Em for each anaphor m ∈ M, we select antecedents for all anaphors from E = UmCM Em at the same time. Table 1 shows the hidden predicates and formulas used. Each formula is associat</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Waikiki, Honolulu, Hawaii, 25–27 October 2008, pages 650– 659.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Towards a taxonomy of given-new information.</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>223--255</pages>
<editor>In P. Cole, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York, N.Y.</location>
<contexts>
<context position="1046" citStr="Prince, 1981" startWordPosition="146" endWordPosition="147">onstraints on top of a rich local feature set in the framework of Markov logic networks. The global model improves over the local one and both strongly outperform a reimplementation of prior work. 1 Introduction Identity coreference is a relatively well understood and well-studied instance of entity coherence. However, entity coherence can rely on more complex, lexico-semantic, frame or encyclopedic relations than identity. Anaphora linking distinct entities or events this way are called bridging or associative anaphora and have been widely discussed in the linguistic literature (Clark, 1975; Prince, 1981; Gundel et al., 1993).1 In Example 1, the phrases the windows, the carpets and walls can be felicitously used because they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to n</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Ellen F. Prince. 1981. Towards a taxonomy of given-new information. In P. Cole, editor, Radical Pragmatics, pages 223–255. Academic Press, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Learning the finegrained information status of discourse entities.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter ofthe Association for Computational Linguistics,</booktitle>
<pages>798--807</pages>
<location>Avignon,</location>
<contexts>
<context position="6637" citStr="Rahman and Ng, 2012" startWordPosition="1035" endWordPosition="1039">s that circumvents these problems, i.e. human bridging recognition was reliable, it contains a medium number of bridging cases that allows generalisable statistics and we did not limit bridging anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vieira and Poesio, 2000; Rahman and Ng, 2012; Cahill and Riester, 2012; Markert et al., 2012) and antecedent selection. Work on antecedent selection suffers from focusing on subproblems, e.g. only part-of bridging (Poesio et al., 2004; Markert et al., 2003) or definite NP anaphora (Lassalle and Denis, 2011). Most relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they </context>
</contexts>
<marker>Rahman, Ng, 2012</marker>
<rawString>Altaf Rahman and Vincent Ng. 2012. Learning the finegrained information status of discourse entities. In Proceedings of the 13th Conference of the European Chapter ofthe Association for Computational Linguistics, Avignon, France, 23–27 April 2012, pages 798– 807.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
</authors>
<title>Improving the accuracy and efficiency of MAP inference for Markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>468--475</pages>
<location>Helsinki,</location>
<contexts>
<context position="15154" citStr="Riedel, 2008" startWordPosition="2466" endWordPosition="2467">irs ((m,n) or (m,e)) on the global discourse level improving accuracy by performing joint inference. P(X = x) =2expl� Iwini(x) (1) 5 Features \Z 5.1 Local features where ni(x) is the number of true groundings of Fi in x. The normalization factor Z is the partition function. MLNs have been applied to many NLP tasks and achieved good performance by leveraging rich relations among objects (Poon and Domingos, 2008; Meza-Ruiz and Riedel, 2009; Fahrni and Strube, 2012, inter alia). We use thebeast5 to learn weights for the formulas and to perform inference. thebeast employs cutting plane inference (Riedel, 2008) to improve the accuracy and efficiency of MAP inference for Markov logic. With MLNs, we model bridging resolution globally on the discourse level: given the set M of all anaphors and sets of local antecedent candidates Em for each anaphor m ∈ M, we select antecedents for all anaphors from E = UmCM Em at the same time. Table 1 shows the hidden predicates and formulas used. Each formula is associated with a weight. The 5http://code.google.com/p/thebeast 5.1.1 Poesio et al.’s feature set Table 2 shows the feature set proposed by Poesio et al. (2004) for part-of bridging. Google distance is the i</context>
</contexts>
<marker>Riedel, 2008</marker>
<rawString>Sebastian Riedel. 2008. Improving the accuracy and efficiency of MAP inference for Markov logic. In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, Helsinki, Finland, 9–12 July 2008, pages 468–475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arndt Riester</author>
<author>David Lorenz</author>
<author>Nina Seemann</author>
</authors>
<title>A recursive annotation scheme for referential information status.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation,</booktitle>
<pages>717--722</pages>
<location>La Valetta, Malta, 17–23</location>
<contexts>
<context position="5114" citStr="Riester et al., 2010" startWordPosition="794" endWordPosition="797">in anaphora are likely to share the same antecedent; • model the global semantic connectivity of a salient potential antecedent to all anaphora in a text; • consider the union of potential antecedents for all anaphora instead of a static window-sized constraint. We show that this global model with the same local features but enhanced with global constraints improves significantly over the local model. 2 Related Work Prior corpus-linguistic studies on bridging are beset by three main problems. First, reliability is not measured or low (Fraurud, 1990; Poesio, 2003; Gardent and Manu´elian, 2005; Riester et al., 2010).3 Second, annotated corpora are small (Poesio et al., 2004; Korzen and Buch-Kromann, 2011). Third, they are often based on strong untested assumptions about bridging anaphora types, antecedent types or relations, such as limiting it to definite NP anaphora (Poesio and Vieira, 1998; Poesio et al., 2004; Gardent and Manu´elian, 2005; Caselli and Prodanof, 2006; Riester et al., 2010; Lassalle and Denis, 2011), to NP antecedents (all prior work) or to part3Although the overall information status scheme in Riester et al. (2010) achieved high agreement, their confusion matrix shows that the anaphor</context>
</contexts>
<marker>Riester, Lorenz, Seemann, 2010</marker>
<rawString>Arndt Riester, David Lorenz, and Nina Seemann. 2010. A recursive annotation scheme for referential information status. In Proceedings of the 7th International Conference on Language Resources and Evaluation, La Valetta, Malta, 17–23 May 2010, pages 717–722.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Caroline Sporleder</author>
<author>Roser Morante</author>
<author>Collin Baker</author>
<author>Martha Palmer</author>
</authors>
<title>SemEval2010 Task 10: Linking events and their participants in discourse.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2),</booktitle>
<pages>45--50</pages>
<location>Uppsala,</location>
<contexts>
<context position="7530" citStr="Ruppenhofer et al., 2010" startWordPosition="1182" endWordPosition="1185">st relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they distinguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of relations. There is a partial overlap between bridging and implicit noun roles (Ruppenhofer et al., 2010). However, work on implicit noun roles is mostly focused on few predicates (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. The</context>
</contexts>
<marker>Ruppenhofer, Sporleder, Morante, Baker, Palmer, 2010</marker>
<rawString>Josef Ruppenhofer, Caroline Sporleder, Roser Morante, Collin Baker, and Martha Palmer. 2010. SemEval2010 Task 10: Linking events and their participants in discourse. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2), Uppsala, Sweden, 15–16 July 2010, pages 45–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carina Silberer</author>
<author>Anette Frank</author>
</authors>
<title>Casting implicit role linking as an anaphora resolution task.</title>
<date>2012</date>
<booktitle>In Proceedings of STARSEM 2012: The First Joint Conference on Lexical and Computational Semantics,</booktitle>
<pages>1--10</pages>
<location>Montr´eal, Qu´ebec,</location>
<contexts>
<context position="7798" citStr="Silberer and Frank (2012)" startWordPosition="1226" endWordPosition="1229">s in Poesio et al. (2004) cannot be used for comparison as they test unrealistically: they distinguish only between the correct antecedent and one or three false candidates (baseline of 50% for the former). They also restrict the phenomenon to part-of relations. There is a partial overlap between bridging and implicit noun roles (Ruppenhofer et al., 2010). However, work on implicit noun roles is mostly focused on few predicates (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. They 908 are not limited to definite NPs as in previous work. In contrast to Nissim et al. (2004), antecedents are annotated and can be noun phrases, verb phrases or even clauses. Our bridging annotation is also not limited with regards to semantic relations between anap</context>
</contexts>
<marker>Silberer, Frank, 2012</marker>
<rawString>Carina Silberer and Anette Frank. 2012. Casting implicit role linking as an anaphora resolution task. In Proceedings of STARSEM 2012: The First Joint Conference on Lexical and Computational Semantics, Montr´eal, Qu´ebec, Canada, 7–8 June 2012, pages 1– 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="3385" citStr="Soon et al., 2001" startWordPosition="514" endWordPosition="517">nt selection for bridging anaphora is restricted. It makes strong untested assumptions about bridging anaphora types or relations, limiting it to definite NPs (Poesio and Vieira, 1998; Poesio et al., 2004; Lassalle and Denis, 2011) or to part-of relations between anaphor and antecedent (Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011). We break new ground by considering all relations and anaphora/antecedent types and show that the variety of bridging anaphora is much higher than reported previously. Following work on coreference resolution, we apply a local pairwise model (Soon et al., 2001) for antecedent selection. We then develop novel semantic, syntactic and salience features for this task, showing strong improvements over one of the best known 907 Proceedings of NAACL-HLT 2013, pages 907–917, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics prior models (Poesio et al., 2004). However, this local model classifies each anaphor-antecedent candidate pair in isolation. Thus, it neglects that bridging anaphora referring to a single antecedent often occur in clusters (see Example 1). It also neglects that once an entity is an antecedent for a bridg</context>
<context position="11116" citStr="Soon et al., 2001" startWordPosition="1785" endWordPosition="1788">e antecedent head as in Example 4. (2) Still employees do occasionally try to smuggle out a gem or two. One man wrapped several diamonds in the knot of his tie. Another poked a hole in the heel of his shoe. None made it past the body searches... (3) His truck is parked across the field ... The farmer at the next truck shouts ... (4) ... it doesn’t make the equipment needed to produce those chips. And IBM worries that the Japanese will take over that equipment market. 4 Models for Bridging Resolution 4.1 Pairwise mention-entity model The pairwise model is widely used in coreference resolution (Soon et al., 2001). We adapt it for bridging resolution4: Given an anaphor mention m and the set of antecedent candidate entities E,,t which appear before m, we create a pairwise instance (m, e) for every e E E,,t. A binary decision whether m is bridged to e is made for each instance (m, e) separately. A post-processing step to choose one antecedent is necessary (closest first or best first are common strategies). This model causes three problems for bridging resolution: First, the ratio between positive and negative instances is 1 to 17 even if only antecedent candidates from the current and the immediately pr</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>An empirically-based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<pages>593</pages>
<contexts>
<context position="6616" citStr="Vieira and Poesio, 2000" startWordPosition="1031" endWordPosition="1034">2) we established a corpus that circumvents these problems, i.e. human bridging recognition was reliable, it contains a medium number of bridging cases that allows generalisable statistics and we did not limit bridging anaphora or antecedents according to their syntactic type or relations between them. However, we only discussed human agreement on bridging recognition in Markert et al. (2012), disregarding antecedent annotation. We also did not discuss the different types of bridging in the corpus. We will remedy this in Section 3. Automatic work on bridging distinguishes between recognition (Vieira and Poesio, 2000; Rahman and Ng, 2012; Cahill and Riester, 2012; Markert et al., 2012) and antecedent selection. Work on antecedent selection suffers from focusing on subproblems, e.g. only part-of bridging (Poesio et al., 2004; Markert et al., 2003) or definite NP anaphora (Lassalle and Denis, 2011). Most relevant for us is Lassalle and Denis (2011) who restrict anaphora to definite descriptions but have no other restrictions on relations or antecedent NPs (in a French corpus) with an accuracy of 23%. Also the evaluation setup is sometimes not clear: The high results in Poesio et al. (2004) cannot be used fo</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. An empirically-based system for processing definite descriptions. Computational Linguistics, 26(4):539– 593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Martha Palmer</author>
<author>Mitchell Marcus</author>
<author>Eduard Hovy</author>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
</authors>
<date>2011</date>
<booktitle>OntoNotes release 4.0. LDC2011T03,</booktitle>
<institution>Linguistic Data Consortium.</institution>
<location>Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston.</location>
<contexts>
<context position="1785" citStr="Weischedel et al., 2011" startWordPosition="264" endWordPosition="267">use they are semantically related via a part-of relation to their antecedent the Polish center.2 (1) ... as much as possible of the Polish center will be made from aluminum, steel and glass recycled from Warsaw’s abundant rubble. ... The windows will open. The carpets won’t be glued down and walls will be coated with non-toxic finishes. 1Poesio and Vieira (1998) include cases where antecedent and anaphor are coreferent but do not share the same head noun. We restrict bridging to non-coreferential cases. We also exclude comparative anaphora (Modjeska et al., 2003) 2Examples are from OntoNotes (Weischedel et al., 2011). Bridging anaphora are typed in boldface; antecedents in italics. Bridging is frequent amounting to between 5% (Gardent and Manu´elian, 2005) and 20% (Caselli and Prodanof, 2006) of definite descriptions (both studies limited to NPs starting with the or nonEnglish equivalents). Bridging resolution is needed to fill gaps in entity grids based on coreference only (Barzilay and Lapata, 2008). Example 1 does not exhibit any coreferential entity coherence. Coherence can only be established when the bridging anaphora are resolved. Bridging resolution may also be important for textual entailment (Mi</context>
<context position="8083" citStr="Weischedel et al., 2011" startWordPosition="1275" endWordPosition="1278">lap between bridging and implicit noun roles (Ruppenhofer et al., 2010). However, work on implicit noun roles is mostly focused on few predicates (e.g. Gerber and Chai (2012)). We consider all bridging anaphors in running text. The closest work to ours interpreting implicit role filling as anaphora resolution is Silberer and Frank (2012). 3 Corpus for Bridging: An Overview We use the dataset we created in Markert et al. (2012) with almost 11,000 NPs annotated for information status including 663 bridging NPs and their antecedents in 50 texts taken from the WSJ portion of the OntoNotes corpus (Weischedel et al., 2011). Bridging anaphora can be any noun phrase. They 908 are not limited to definite NPs as in previous work. In contrast to Nissim et al. (2004), antecedents are annotated and can be noun phrases, verb phrases or even clauses. Our bridging annotation is also not limited with regards to semantic relations between anaphor and antecedent. In Markert et al. (2012) we achieved high agreement for the overall information status annotation scheme between three annotators (r. between 75 and 80, dependent on annotator pairs) as well as for all subcategories, including bridging (r. over 60 for all annotator</context>
</contexts>
<marker>Weischedel, Palmer, Marcus, Hovy, Pradhan, Ramshaw, 2011</marker>
<rawString>Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston. 2011. OntoNotes release 4.0. LDC2011T03, Philadelphia, Penn.: Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<title>edition.</title>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, Cal.,</location>
<contexts>
<context position="27217" citStr="Witten and Frank, 2005" startWordPosition="4487" endWordPosition="4490">ne. Since they did not explain 913 whether they used the mention-mention or mentionentity model, we assume they treated antecedents as entities and use a 2 and 5 sentence window for candidates8. Since the GoogleAPI is not available any more, we use the Web 1T 5-gram corpus (Brants and Franz, 2006) to extract the Google distance feature. We improve it by taking all information about entities via coreference into account as well as by replacing proper names. All other features (Table 2 in Section 5.1.1) are extracted as Poesio et al. did. A Naive Bayes classifier with standard settings in WEKA (Witten and Frank, 2005) is used. In order to evaluate their model in the more realistic setting of our experiment, we apply the best first strategy to select the antecedent for each anaphor. 6.3 Pairwise models Pairwise model I: We use the preposition pattern feature (feat1) plus Poesio et al.’s salience features (Table 2). We use a 2 sentence window as it performed on a par with the 5 sentence window in the baseline. We replace Naive Bayes with SVM&amp;quot;ght because it can deal better with imbalanced data9. Pairwise model II: Based on Pairwise model I. Local features feat2-feat8 from Table 2 are added. Pairwise model III</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques. Morgan Kaufmann, San Francisco, Cal., 2nd edition.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>