<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.996504">
Learning Translation Boundaries for Phrase-Based Decoding
</title>
<author confidence="0.986809">
Deyi Xiong, Min Zhang, Haizhou Li
</author>
<affiliation confidence="0.871534333333333">
Human Language Technology
Institute for Infocomm Research
1 Fusionopolis Way, #21-01 Connexis, Singapore 138632.
</affiliation>
<email confidence="0.994585">
{dyxiong, mzhang, hli}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999180142857143">
Constrained decoding is of great importance
not only for speed but also for translation qual-
ity. Previous efforts explore soft syntactic con-
straints which are based on constituent bound-
aries deduced from parse trees of the source
language. We present a new framework to es-
tablish soft constraints based on a more nat-
ural alternative: translation boundary rather
than constituent boundary. We propose sim-
ple classifiers to learn translation boundaries
for any source sentences. The classifiers are
trained directly on word-aligned corpus with-
out using any additional resources. We report
the accuracy of our translation boundary clas-
sifiers. We show that using constraints based
on translation boundaries predicted by our
classifiers achieves significant improvements
over the baseline on large-scale Chinese-to-
English translation experiments. The new
constraints also significantly outperform con-
stituent boundary based syntactic constrains.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972173913043">
It has been known that phrase-based decoding
(phrase segmentation/translation/reordering (Chi-
ang, 2005)) should be constrained to some extent not
only for transferring the NP-hard problem (Knight,
1999) into a tractable one in practice but also for im-
proving translation quality. For example, Xiong et
al. (2008) find that translation quality can be signif-
icantly improved by either prohibiting reorderings
around punctuation or restricting reorderings within
a 15-word window.
Recently, more linguistically motivated con-
straints are introduced to improve phrase-based de-
coding. (Cherry, 2008) and (Marton and Resnik,
2008) introduce syntactic constraints into the stan-
dard phrase-based decoding (Koehn et al., 2003) and
hierarchical phrase-based decoding (Chiang, 2005)
respectively by using a counting feature which ac-
cumulates whenever hypotheses violate syntactic
boundaries of source-side parse trees. (Xiong et al.,
2009) further presents a bracketing model to include
thousands of context-sensitive syntactic constraints.
All of these approaches achieve their improvements
by guiding the phrase-based decoder to prefer trans-
lations which respect source-side parse trees.
One major problem with such constituent bound-
ary based constraints is that syntactic structures of
the source language do not necessarily reflect trans-
lation structures where the source and target lan-
guage correspond to each other. In this paper,
we investigate building classifiers that directly ad-
dress the problem of translation boundary, rather
than extracting constituent boundary from source-
side parsers built for a different purpose. A trans-
lation boundary is a position in the source sequence
which begins or ends a translation zone 1 spanning
multiple source words. In a translation zone, the
source phrase is translated as a unit. Reorderings
which cross translation zones are not desirable.
Inspired by (Roark and Hollingshead, 2008)
which introduces classifiers to decide if a word can
begin/end a multi-word constituent, we build two
discriminative classifiers to tag each word in the
source sequence with a binary class label. The first
classifier decides if a word can begin a multi-source-
word translation zone; the second classifier decides
if a word can end a multi-source-word translation
</bodyText>
<footnote confidence="0.669565">
&apos;We will give a formal definition of translation zone in Sec-
tion 2.
</footnote>
<page confidence="0.955609">
136
</page>
<note confidence="0.755258">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 136–144,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.916569272727273">
zone. Given a partial translation covering source se-
quence (i, j) with start word ci and end word cj 2,
this translation can be penalized if the first classifier
decides that the start word ci can not be a beginning
translation boundary or the second classifier decides
that the end word cj can not be an ending translation
boundary. In such a way, we can guide the decoder
to boost hypotheses that respect translation bound-
aries and therefore the common translation structure
shared by the source and target language, rather than
the syntactic structure of the source language.
We report the accuracy of such classifiers by com-
paring their outputs with “gold” translation bound-
aries obtained from reference translations on the de-
velopment set. We integrate translation boundary
based constraints into phrase-based decoding and
display that they improve translation quality signif-
icantly in large-scale experiments. Furthermore, we
confirm that they also significantly outperform con-
stituent boundary based syntactic constraints.
2 Beginning and Ending Translation Zones
To better understand the particular task that we ad-
dress in this paper, we study the distribution of
classes of translation boundaries in real-world data.
First, we introduce some notations. Given a source
sentence c1...cn, we will say that a word ci (1 &lt; i &lt;
n) is in the class By if there is a translation zone T
spanning ci...cj for some j &gt; i; and ci E Bn oth-
erwise. Similarly, we will say that a word cj is in
the class Ey if there is a translation zone spanning
ci...cj for some j &gt; i; and cj E En otherwise.
Here, a translation zone T is a pair of aligned
source phrase and target phrase
</bodyText>
<equation confidence="0.831649">
T = (cj i , e� �)
where T must be consistent with the word alignment
M
b(u,v)EM,i&lt;u&lt;jHp&lt;v&lt;q
</equation>
<bodyText confidence="0.997707">
By this, we require that no words inside the source
phrase cji are aligned to words outside the target
phrase eP and that no words outside the source
phrase are aligned to words inside the target phrase.
</bodyText>
<footnote confidence="0.9908865">
2In this paper, we use c to denote the source language and e
the target language.
</footnote>
<table confidence="0.998913">
Item Count (M) P (%)
Sentences 3.8
Words 96.9
Words E By 22.7 23.4
Words E Ey 41.0 42.3
Words E� By and E� Ey 33.2 34.3
</table>
<tableCaption confidence="0.921849666666667">
Table 1: Statistics on word classes from our bilingual
training data. All numbers are calculated on the source
side. P means the percentage.
</tableCaption>
<bodyText confidence="0.998488722222222">
This means, in other words, that the source phrase
cji is mapped as a unit onto the target phrase eP.
When defining the By and Ey class, we also re-
quire that the source phrase cji in the translation zone
must contain multiple words (j &gt; i). Our interest
is the question of whether a sequence of consecu-
tive source words can be translated as a unit (i.e.
whether there is a translation zone covering these
source words). For a single-word source phrase, if
it can be translated separately, it is always translated
as a unit in the context of phrase-based decoding.
Therefore this question does not exist.
Note that the first word ci and the last word cn
are unambiguous in terms of whether they begin or
end a translation zone. The first word ci must begin
a translation zone spanning the whole source sen-
tence. The last word cn must end a translation zone
spanning the whole source sentence. Therefore, our
classifiers only need to predict the other n−2 words
for a source sentence of length n.
Table 1 shows statistics of word classes from our
training data which contain nearly 100M words in
approximately 4M sentences. Among these words,
only 22.7M words can begin a translation zone
which covers multiple source words. 41M words
can end a translation zone spanning multiple source
words, which accounts for more than 42% in all
words. We still have more than 33M words, ac-
counting for 34.3%, which neither begin nor end
a multi-source-word translation zone. Apparently,
translations that begin/end on words E By/E Ey are
preferable to those which begin/end on other words.
Yet another interesting study is to compare trans-
lation boundaries with constituent boundaries de-
duced from source-side parse trees. In doing so,
we can know further how well constituent boundary
</bodyText>
<page confidence="0.992825">
137
</page>
<table confidence="0.370199333333333">
Classification Task Avg. Accuracy (%)
By/Bn
Ey/En
</table>
<tableCaption confidence="0.98403875">
Table 2: Average classification accuracy on the develop-
ment set when we treat constituent boundary deducer (ac-
cording to source-side parse trees) as a translation bound-
ary classifier.
</tableCaption>
<bodyText confidence="0.999977264705882">
based syntactic constraints can improve translation
quality. We pair the source sentences of our devel-
opment set with each of the reference translations
and include the created sentence pairs in our bilin-
gual training corpus. Then we obtain word align-
ments on the new corpus (see Section 5.1 for the de-
tails of learning word alignments). From the word
alignments we obtain translation boundaries (see de-
tails in the next section). We parse the source sen-
tences of our development set and obtain constituent
boundaries from parse trees.
To make a clear comparison with our transla-
tion boundary classifiers (see Section 3.3), we treat
constituent boundaries deduced from source-side
parse trees as output from beginning/ending bound-
ary classifiers: the constituent beginning boundary
corresponds to By; the constituent ending boundary
corresponds to Ey. We have four reference transla-
tions for each source sentence. Therefore we have
four translation boundary sets, each of which is pro-
duced from word alignments between source sen-
tences and one reference translation set. Each of
the four translation boundary sets will be used as a
gold standard. We calculate classification accuracy
for our constituent boundary deducer on each gold
standard and average them finally.
Table 2 shows the accuracy results. The average
accuracies on the four gold standard sets are very
low, especially for the By/Bn classification task. In
section 3.3, we will show that our translation bound-
ary classifiers achieve higher accuracy than that of
constituent boundary deducer. This suggests that
pure constituent boundary based constraints are not
the best choice to constrain phrase-based decoding.
</bodyText>
<sectionHeader confidence="0.913456" genericHeader="method">
3 Learning Translation Boundaries
</sectionHeader>
<bodyText confidence="0.99993575">
In this section, we investigate building classifiers
to predict translation boundaries. First, we elabo-
rate the acquisition of training instances from word
alignments. Second, we build two classifiers with
simple features on the obtained training instances.
Finally, we evaluate our classifiers on the develop-
ment set using the “gold” translation boundaries ob-
tained from reference translations.
</bodyText>
<subsectionHeader confidence="0.999612">
3.1 Obtaining Translation Boundaries from
Word Alignments
</subsectionHeader>
<bodyText confidence="0.999425871794872">
We can easily obtain constituent boundaries from
parse trees. Similarly, if we have a tree covering
both source and target sentence, we can easily get
translation boundaries from this tree. Fortunately,
we can build such a tree directly from word align-
ments. We use (Zhang et al., 2008)’s shift-reduce al-
gorithm (SRA) to decompose word alignments into
hierarchical trees.
Given an arbitrary word-level alignment as an in-
put, SRA is able to output a tree representation of the
word alignment (a.k.a decomposition tree). Each
node of the tree is a translation zone as we defined
in the Section 2. Therefore the first word on the
source side of each multi-source-word node is a be-
ginning translation boundary (∈ By); the last word
on the source side of each multi-source-word node
is an ending translation boundary (∈ Ey).
Figure 1a shows an example of many-to-many
alignment, where the source language is Chinese
and the target language is English. Each word is
indexed with their occurring position from left to
right. Figure 1b is the tree representation of the word
alignment after hierarchical analysis using SRA. We
use Qi, j], [i, q]) to denote a tree node, where i, j
and p, q are the beginning and ending index in the
source and target language, respectively. By check-
ing nodes which cover multiple source words, we
can easily decide that the source words {ht-A, Ht,
Q�&amp;} are in the class By and any other words are
in the class Bn if we want to train a By/Bn classi-
fier with class labels {By, Bn}. Similarly, the source
words {&amp;, MT, 4, XA} are in the class Ey and
any other words are in the class En when we train a
Ey/En classifier with class labels {Ey, En}.
By using SRA on each word-aligned bilingual
sentence, as described above, we can tag each source
word with two sets of class labels: {By, Bn} and
{Ey, En}. The tagged source sentences will be used
to train our two translation boundary classifiers.
</bodyText>
<page confidence="0.718439">
46.9
52.2
138
</page>
<equation confidence="0.389939">
a) b) ([1, 7], [1, 9])
1 2 3 4 5 6 7
ii &amp; AIr a [Mtw �%k
TL
</equation>
<bodyText confidence="0.659941">
The last five flights all failed due to accident
</bodyText>
<equation confidence="0.95507075">
1 2 3 4 5 6 7 8 9
([1, 5], [1, 5])
s
([1, 4], [1, 4]) ([5, 5], [5, 5])
([1, 3], [1, 3]) ([4, 4], [4, 4])
([1, 1], [1, 2]) ([2, 3], [3, 3])
([6, 7], [6, 9])
([6, 6], [7, 9]) ([7, 7], [6, 6])
</equation>
<figureCaption confidence="0.994581">
Figure 1: An example of many-to-many word alignment and its tree representation produced by (Zhang et al., 2008)’s
shift-reduce algorithm.
</figureCaption>
<subsectionHeader confidence="0.99964">
3.2 Building Translation Boundary Classifiers
</subsectionHeader>
<bodyText confidence="0.999517">
We build two discriminative classifiers based on
Maximum Entropy Markov Models (MEMM) (Mc-
Callum et al., 2000). One classifier is to predict the
word class ( E {By, BnJ for each source word. The
other is to predict the word class ( E {Ey, EnJ.
These two classifiers are separately trained using
training instances obtained from our word-aligned
training data as demonstrated in the last section.
We use features from surrounding words, includ-
ing 2 before and 2 after the current word position
(c_2, c_1, c+1, c+2). We also use class features to
train models with Markov order 1 (including class
feature (c_1), and Markov order 2 (including class
features (c_1, (c_).
</bodyText>
<subsectionHeader confidence="0.98182">
3.3 Evaluating Translation Boundary
Classifiers
</subsectionHeader>
<bodyText confidence="0.999695181818182">
How well can we perform these binary classifica-
tion tasks using the classifiers described above? Can
we obtain better translation boundary predictions
than extracting constituent boundary from source-
side parse trees? To investigate these questions, we
evaluate our MEMM based classifiers. We trained
them on our 100M-word word-aligned corpus. We
ran the two trained classifiers on the development
set separately to obtain the By/Bn words and Ey/En
words. Then we built our four gold standards using
four reference translation sets as described in Sec-
</bodyText>
<table confidence="0.5222815">
Avg. Accuracy (%)
Classification Task MEMM 1 MEMM 2
71.7 70.2
59.2 58.8
</table>
<tableCaption confidence="0.935706">
Table 3: Average classification accuracy on the develop-
ment set for our MEMM based translation boundary clas-
sifiers with various Markov orders.
</tableCaption>
<bodyText confidence="0.98261225">
tion 2. The average classification accuracy results
are shown in Table 3.
Comparing Table 3 with Table 2, we find that our
MEMM based classifiers significantly outperform
constituent boundary deducer in predicting transla-
tion boundaries, especially in the By/Bn classifi-
cation task, where our MEMM based By/Bn clas-
sifier (Markov order 1) achieves a relative increase
of 52.9% in accuracy over the constituent bound-
ary deducer. In the Ey/En classification task, our
classifiers also perform much better than constituent
boundary deducer.
Then are our MEMM based translation boundary
classifiers good enough? The accuracies are still low
although they are higher than those of constituent
boundary deducer. One reason why we have low
accuracies is that our gold standard based evalua-
tion is not established on real gold standards. In
other words, we don’t have gold standards in terms
of translation boundary since different translations
</bodyText>
<figure confidence="0.732849">
By/Bn
Ey/En
139
LDC ID
Description
Classification Task
Avg. Accuracy (%)
By/Bn
Ey/En
</figure>
<tableCaption confidence="0.951255">
Table 4: Average classification accuracy on the develop-
ment set when treating each reference translation set as a
boundary classifier.
</tableCaption>
<figure confidence="0.98864925">
LDC2004E12
LDC2004T08
LDC2005T10
LDC2003E14
LDC2002E18
LDC2005T06
LDC2003E07
United Nations
Hong Kong News
Sinorama Magazine
FBIS
Xinhua News V1 beta
Chinese News Translation
Chinese Treebank
80.6
75.7
</figure>
<bodyText confidence="0.99917105882353">
generate very different translation boundaries. We
can measure these differences in reference transla-
tions using the same evaluation metric (classification
accuracy). We treat each reference translation set
as a translation boundary classifier while the other
three reference translation sets as gold standards.
We calculate the classification accuracy for the cur-
rent reference translation set and finally average all
four accuracies. Table 4 presents the results.
Comparing Table 4 with Table 3, we can see that
the accuracy of our translation boundary classifica-
tion approach is not that low when considering vast
divergences of reference translations. The question
now becomes, how can classifier output be used to
constrain phrase-based decoding, and what is the
impact on the system performance of using such
constraints.
</bodyText>
<sectionHeader confidence="0.9785375" genericHeader="method">
4 Integrating Translation Boundaries into
Decoding
</sectionHeader>
<bodyText confidence="0.995856631578947">
By running the two trained classifiers on the source
sentence separately, we obtain two classified word
sets: By/Bn words, and Ey/En words. We can pro-
hibit any translations or reorderings spanning ci...cj
(j &gt; i) where ci V By according to the first classi-
fier or cj V Ey according to the second classifier. In
such a way, we integrate translation boundaries into
phrase-based decoding as hard constraints, which,
however, is at the risk of producing no translation
covering the whole source sentence.
Alternatively, we introduce soft constraints based
on translation boundary that our classifiers pre-
dict, similar to constituent boundary based soft con-
straints in (Cherry, 2008) and (Marton and Resnik,
2008). We add a new feature to the decoder’s log-
linear model: translation boundary violation count-
ing feature. This counting feature accumulates
whenever hypotheses have a partial translation span-
ning ci...cj (j &gt; i) where ci V By or cj V Ey. The
</bodyText>
<tableCaption confidence="0.728403">
LDC2004T07 Multiple Translation Chinese
Table 5: Training corpora.
</tableCaption>
<bodyText confidence="0.9986891">
weight av of this feature is tuned via minimal error
rate training (MERT) (Och, 2003) with other feature
weights.
Unlike hard constraints, which simply prevent
any hypotheses from violating translation bound-
aries, soft constraints allow violations of translation
boundaries but with a penalty of exp(−avCv) where
Cv is the violation count. By using soft constraints,
we can enable the model to prefer hypotheses which
are consistent with translation boundaries.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<bodyText confidence="0.999971888888889">
Our baseline system is a phrase-based system us-
ing BTGs (Wu, 1997), which includes a content-
dependent reordering model discriminatively trained
using reordering examples (Xiong et al., 2006). We
carried out various experiments to evaluate the im-
pact of integrating translation boundary based soft
constraints into decoding on the system performance
on the Chinese-to-English translation task of the
NIST MT-05 using large scale training data.
</bodyText>
<subsectionHeader confidence="0.967247">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999559416666667">
Our training corpora are listed in Table 5. The
whole corpora consist of 96.9M Chinese words and
109.5M English words in 3.8M sentence pairs. We
ran GIZA++ (Och and Ney, 2000) on the par-
allel corpora in both directions and then applied
the “grow-diag-final” refinement rule (Koehn et al.,
2005) to obtain many-to-many word alignments.
From the word-aligned corpora, we extracted bilin-
gual phrases and trained our translation model.
We used all corpora in Table 5 except for the
United Nations corpus to train our MaxEnt based
reordering model (Xiong et al., 2006), which con-
</bodyText>
<page confidence="0.993073">
140
</page>
<bodyText confidence="0.999981965517242">
sist of 33.3M Chinese words and 35.8M English
words. We built a four-gram language model us-
ing the SRILM toolkit (Stolcke, 2002), which was
trained on Xinhua section of the English Gigaword
corpus (181.1M words).
To train our translation boundary classifiers, we
extract training instances from the whole word-
aligned corpora, from which we obtain 96.9M train-
ing instances for the By/B,,, and Ey/E,,, classifier.
We ran the off-the-shelf MaxEnt toolkit (Zhang,
2004) to tune classifier feature weights with Gaus-
sian prior set to 1 to avoid overfitting.
We used the NIST MT-03 evaluation test data as
our development set (919 sentences in total, 27.1
words per sentence). The NIST MT-05 test set in-
cludes 1082 sentences with an average of 27.4 words
per sentence. Both the reference corpus for the NIST
MT-03 set and the reference corpus for the NIST
MT-05 set contain 4 translations per source sen-
tence. To compare with constituent boundary based
constraints, we parsed source sentences of both the
development and test sets using a Chinese parser
(Xiong et al., 2005) which was trained on the Penn
Chinese Treebank with an Fi-score of 79.4%.
Our evaluation metric is case-insensitive BLEU-4
(Papineni et al., 2002) using the shortest reference
sentence length for the brevity penalty. Statistical
significance in BLEU score differences was tested
by paired bootstrap re-sampling (Koehn, 2004).
</bodyText>
<subsectionHeader confidence="0.98912">
5.2 Using Translation Boundaries from
Reference Translations
</subsectionHeader>
<bodyText confidence="0.991042">
The most direct way to investigate the impact on the
system performance of using translation boundaries
is to integrate “right” translation boundaries into de-
coding which are directly obtained from reference
translations. For both the development set and test
set, we have four reference translation sets, which
are named ref1, ref2, ref3 and ref4, respectively.
For the development set, we used translation bound-
aries obtained from ref1. Based on these boundaries,
we built our translation boundary violation counting
feature and tuned its feature weight with other fea-
tures using MERT. When we obtained the best fea-
ture weights As, we evaluated on the test set using
translation boundaries produced from ref1, ref2, ref3
and ref4 of the test set respectively.
Table 6 shows the results. We clearly see that us-
</bodyText>
<table confidence="0.9582445">
System BLEU-4 (%)
Base 33.05
Ref1 33.99*
Ref2 34.17*
Ref3 33.93*
Ref4 34.21*
</table>
<tableCaption confidence="0.977569">
Table 6: Results of using translation boundaries obtained
from reference translations. *: significantly better than
</tableCaption>
<bodyText confidence="0.980165153846154">
baseline (p &lt; 0.01).
ing “right” translation boundaries to build soft con-
straints significantly improve the performance mea-
sured by BLEU score. The best result comes from
ref4, which achieves an absolute increase of 1.16
BLEU points over the baseline. We believe that the
best result here only indicates the lower bound of
potential improvement when using right translation
boundaries. If we have consistent translation bound-
aries on the development and test set (for example,
we have the same 4 translators build reference trans-
lations for both the development and test set), the
performance improvement will be higher.
</bodyText>
<subsectionHeader confidence="0.9984775">
5.3 Using Automatically Learned Translation
Boundaries
</subsectionHeader>
<bodyText confidence="0.999976227272727">
The success of using translation boundaries from
reference translations inspires us to pursue trans-
lation boundaries predicted by our MEMM based
classifiers. We ran our MEMM1 (Markov order 1)
and MEMM2 (Markov order 2) By/B,,, and Ey/E,,,
classifiers on both the development and test set.
Based on translation boundaries output by MEMM1
and MEMM2 classifiers, we built our translation
boundary violation feature and tuned it on the de-
velopment set. The evaluation results on the test set
are shown in Table 7.
From Table 7 we observe that using soft con-
straints based on translation boundaries from both
our MEMM 1 and MEMM 2 significantly outper-
form the baseline. Impressively, when using outputs
from MEMM 2, we achieve an absolute improve-
ment of almost 1 BLEU point over the baseline. This
result is also very close to the best result of using
translation boundaries from reference translations.
To compare with constituent boundary based syn-
tactic constraints, we also carried out experiments
using two kinds of such constraints. One is the
</bodyText>
<page confidence="0.993836">
141
</page>
<table confidence="0.998796142857143">
System BLEU-4 (%)
Base 33.05
Condeducer 33.18
XP+ 33.58*
BestRef 34.21*+
MEMM 1 33.70*
MEMM 2 34.04*+
</table>
<tableCaption confidence="0.903346142857143">
Table 7: Results of using automatically learned trans-
lation boundaries. Condeducer means using pure con-
stituent boundary based soft constraint. XP+ is another
constituent boundary based soft constraint but with dis-
tinction among special constituent types (Marton and
Resnik, 2008). BestRef is the best result using reference
translation boundaries in Table 6. MEMM 1 and MEMM
</tableCaption>
<bodyText confidence="0.984469875">
2 are our MEMM based translation boundary classifiers
with Markov order 1 and 2. *: significantly better than
baseline (p &lt; 0.01). +: significantly better than XP+
(p &lt; 0.01).
Condeducer which uses pure constituent bound-
ary based syntactic constraint: any partial transla-
tions which cross any constituent boundaries will
be penalized. The other is the XP+ from (Marton
and Resnik, 2008) which only penalizes hypotheses
which violate the boundaries of a constituent with
a label from {NP, VP, CP, IP, PP, ADVP, QP, LCP,
DNP}. The XP+ is the best syntactic constraint
among all constraints that Marton and Resnik (2008)
use for Chinese-to-English translation.
Still in Table 7, we find that both syntactic con-
straint Condeducer and XP+ are better than the base-
line. But only XP+ is able to obtain significant im-
provement. Both our MEMM 1 and MEMM 2 out-
perform Condeducer. MEMM 2 achieves significant
improvement over XP+ by approximately 0.5 BLEU
points. This comparison suggests that translation
boundary is a better option than constituent bound-
ary when we build constraints to restrict phrase-
based decoding.
</bodyText>
<subsectionHeader confidence="0.995102">
5.4 One Classifier vs. Two Classifiers
</subsectionHeader>
<bodyText confidence="0.99981">
Revisiting the classification task in this paper, we
can also consider it as a sequence labeling task
where the first source word of a translation zone
is labeled “B”, the last source word of the trans-
lation zone is labeled “E”, and other words are la-
beled “O”. To complete such a sequence labeling
task, we built only one classifier which is still based
on MEMM (with Markov order 2) with the same
features as described in Section 3.2. We built soft
constraints based on the outputs of this classifier and
evaluated them on the test set. The case-insensitive
BLEU score is 33.62, which is lower than the per-
formance of using two separate classifiers (34.04).
We calculated the accuracy for class “B” by map-
ping “B” to By and “E” and “O” to B,,,. The result is
67.9%. Similarly, we obtained the accuracy of class
“E”, which is as low as 48.6%. These two accura-
cies are much lower than those of using two separate
classifiers, especially the accuracy of “E”. This sug-
gests that the By and Ey are not interrelated tightly.
It is better to learn them separately with two classi-
fiers.
Another advantage of using two separate classi-
fiers is that we can explore more constraints. A word
Ck can be possibly labeled as By by the first classifier
and Ey by the second classifier. Therefore we can
build soft constraints on span (CZ, Ck) (CZ E By, Ck E
Ey) and span (Ck, Cj) (Ck E By, Cj E Ey). This is
impossible if we use only one classifier since each
word can have only one class label. We can build
only one constraint on span (CZ, Ck) or span (Ck, Cj).
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9999157">
Various approaches incorporate constraints into
phrase-based decoding in a soft or hard manner. Our
introduction has already briefly mentioned (Cherry,
2008) and (Marton and Resnik, 2008), which utilize
source-side parse tree boundary violation counting
feature to build soft constraints for phrase-based de-
coding, and (Xiong et al., 2009), which calculates a
score to indicate to what extent a source phrase can
be translated as a unit using a bracketing model with
richer syntactic features. More previously, (Chi-
ang, 2005) rewards hypotheses whenever they ex-
actly match constituent boundaries of parse trees on
the source side.
In addition, hard linguistic constraints are also ex-
plored. (Wu and Ng, 1995) employs syntactic brack-
eting information to constrain search in order to im-
prove speed and accuracy. (Collins et al., 2005) and
(Wang et al., 2007) use hard syntactic constraints to
perform reorderings according to source-side parse
trees. (Xiong et al., 2008) prohibit any swappings
</bodyText>
<page confidence="0.993829">
142
</page>
<bodyText confidence="0.998988457142857">
which violate punctuation based constraints.
Non-linguistic constraints are also widely used
in phrase-based decoding. The IBM and ITG con-
straints (Zens et al., 2004) are used to restrict re-
orderings in practical phrase-based systems.
(Berger et al., 1996) introduces the concept of rift
into a machine translation system, which is similar
to our definition of translation boundary. They also
use a maximum entropy model to predict whether a
source position is a rift based on features only from
source sentences. Our work differs from (Berger et
al., 1996) in three major respects.
1) We distinguish a segment boundary into two
categories: beginning and ending boundary due
to their different distributions (see Table 1).
However, Berger et al. ignore this difference.
2) We train two classifiers to predict beginning
and ending boundary respectively while Berger
et al. build only one classifier. Our experiments
show that two separate classifiers outperform
one classifier.
3) The last difference is how segment bound-
aries are integrated into a machine transla-
tion system. Berger et al. use predicted
rifts to divide a long source sentence into a
series of smaller segments, which are then
translated sequentially in order to increase de-
coding speed (Brown et al., 1992; Berger
et al., 1996). This can be considered as a
hard integration, which may undermine trans-
lation accuracy given wrongly predicted rifts.
We integrate predicted translation boundaries
into phrase-based decoding in a soft manner,
which improves translation accuracy in terms
of BLEU score.
</bodyText>
<sectionHeader confidence="0.991252" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9998284">
In this paper, we have presented a simple approach
to learn translation boundaries on source sentences.
The learned translation boundaries are used to con-
strain phrase-based decoding in a soft manner. The
whole approach has several properties.
</bodyText>
<listItem confidence="0.998046571428571">
• First, it is based on a simple classification task
that can achieve considerably high accuracy
when taking translation divergences into ac-
count using simple models and features.
• Second, the classifier output can be straightfor-
wardly used to constrain phrase-based decoder.
• Finally, we have empirically shown that, to
</listItem>
<bodyText confidence="0.98709725">
build soft constraints for phrase-based decod-
ing, translation boundary predicted by our clas-
sifier is a better choice than constituent bound-
ary deduced from source-side parse tree.
Future work in this direction will involve trying
different methods to define more informative trans-
lation boundaries, such as a boundary to begin/end
a swapping. We would also like to investigate new
methods to incorporate automatically learned trans-
lation boundaries more efficiently into decoding in
an attempt to further improve search in both speed
and accuracy.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999900545454546">
Adam L. Berger, Stephen A. Della Pietra and Vincent J.
Della Pietra. 1996. A Maximum Entropy Approach
to Natural Language Processing. Computational Lin-
guistics, 22(1):39-71.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, Robert L. Mercer, and Surya Mohanty.
1992. Dividing and Conquering Long Sentences in a
Translation System. In Proceedings of the workshop
on Speech and Natural Language, Human Language
Technology.
Colin Cherry. 2008. Cohesive Phrase-based Decoding
for Statistical Machine Translation. In Proceedings of
ACL.
David Chiang. 2005. A Hierarchical Phrase-based
Model for Statistical Machine Translation. In Pro-
ceedings of ACL, pages 263–270.
Michael Collins, Philipp Koehn and Ivona Kucerova.
2005. Clause Restructuring for Statistical Machine
Translation. In Proceedings ofACL.
Kevin Knight. 1999. Decoding Complexity in Word Re-
placement Translation Models. In Computational Lin-
guistics, 25(4):607 – 615.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-based Translation. In Pro-
ceedings of HLT-NAACL.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of
EMNLP.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne and
David Talbot. 2005. Edinburgh System Description
for the 2005 IWSLT Speech Translation Evaluation.
In Proceedings of IWSLT.
</reference>
<page confidence="0.989759">
143
</page>
<reference confidence="0.998877984126984">
Yuval Marton and Philip Resnik. 2008. Soft Syntactic
Constraints for Hierarchical Phrase-Based Translation.
In Proceedings ofACL.
Andrew McCallum, Dayne Freitag and Fernando Pereira
2000. Maximum Entropy Markov Models for Infor-
mation Extraction and Segmentation. In Proceedings
of the Seventeenth International Conference on Ma-
chine Learning 2000.
Franz Josef Och and Hermann Ney. 2000. Improved
Statistical Alignment Models. In Proceedings of ACL
2000.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings of
ACL 2003.
Kishore Papineni, Salim Roukos, Todd Ward and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatically
Evaluation of Machine Translation. In Proceedings of
ACL 2002.
Brian Roark and Kristy Hollingshead. 2008. Classifying
Chart Cells for Quadratic Complexity Context-Free In-
ference. In Proceedings of COLING 2008.
Andreas Stolcke. 2002. SRILM - an Extensible Lan-
guage Modeling Toolkit. In Proceedings of Interna-
tional Conference on Spoken Language Processing,
volume 2, pages 901-904.
Chao Wang, Michael Collins and Philipp Koehn 2007.
Chinese Syntactic Reordering for Statistical Machine
Translation. In Proceedings of EMNLP.
Dekai Wu and Cindy Ng. 1995. Using Brackets to Im-
prove Search for Statistical Machine Translation In
Proceedings of PACLIC-IO, Pacific Asia Conference
on Language, Information and Computation.
Dekai Wu. 1997. Stochastic Inversion Transduction
Grammars and Bilingual Parsing of Parallel Corpora.
Computational Linguistics, 23(3):377-403.
Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin,
Yueliang Qian. 2005. Parsing the Penn Chinese Tree-
bank with Semantic Knowledge. In Proceedings of
IJCNLP, Jeju Island, Korea.
Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maxi-
mum Entropy Based Phrase Reordering Model for Sta-
tistical Machine Translation. In Proceedings of ACL-
COLING 2006.
Deyi Xiong, Min Zhang, Ai Ti Aw, Haitao Mi, Qun Liu
and Shouxun Lin. 2008. Refinements in BTG-based
Statistical Machine Translation. In Proceedings of
IJCNLP 2008.
Deyi Xiong, Min Zhang, Ai Ti Aw, and Haizhou Li.
2009. A Syntax-Driven Bracketing Model for Phrase-
Based Translation. In Proceedings of ACL-IJCNLP
2009.
Richard Zens, Hermann Ney, Taro Watanabe and Eiichiro
Sumita 2004. Reordering Constraints for Phrase-
Based Statistical Machine Translation. In Proceedings
of COLING.
Hao Zhang, Daniel Gildea, and David Chiang. 2008.
Extracting Synchronous Grammars Rules from Word-
Level Alignments in Linear Time. In Proceeding of
COLING 2008.
Le Zhang. 2004. Maximum Entropy Model-
ing Tooklkit for Python and C++. Available at
http://homepages.inf.ed.ac.uk/s0450736
/maxent toolkit.html.
</reference>
<page confidence="0.998258">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479591">
<title confidence="0.999984">Learning Translation Boundaries for Phrase-Based Decoding</title>
<author confidence="0.801392">Deyi Xiong</author>
<author confidence="0.801392">Min Zhang</author>
<author confidence="0.801392">Haizhou Human Language</author>
<affiliation confidence="0.942057">Institute for Infocomm</affiliation>
<address confidence="0.784413">1 Fusionopolis Way, #21-01 Connexis, Singapore</address>
<email confidence="0.98842">mzhang,</email>
<abstract confidence="0.997499409090909">Constrained decoding is of great importance not only for speed but also for translation quality. Previous efforts explore soft syntactic constraints which are based on constituent boundaries deduced from parse trees of the source language. We present a new framework to establish soft constraints based on a more natural alternative: translation boundary rather than constituent boundary. We propose simple classifiers to learn translation boundaries for any source sentences. The classifiers are trained directly on word-aligned corpus without using any additional resources. We report the accuracy of our translation boundary classifiers. We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-to- English translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="27547" citStr="Berger et al., 1996" startWordPosition="4420" endWordPosition="4423"> addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings 142 which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whether a source position is a rift based on features only from source sentences. Our work differs from (Berger et al., 1996) in three major respects. 1) We distinguish a segment boundary into two categories: beginning and ending boundary due to their different distributions (see Table 1). However, Berger et al. ignore this difference. 2) We train two classifiers to predict beginning and ending boundary respectively whil</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra and Vincent J. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
<author>Surya Mohanty</author>
</authors>
<title>Dividing and Conquering Long Sentences in a Translation System.</title>
<date>1992</date>
<booktitle>In Proceedings of the workshop on Speech and Natural Language, Human Language Technology.</booktitle>
<contexts>
<context position="28563" citStr="Brown et al., 1992" startWordPosition="4583" endWordPosition="4586"> ending boundary due to their different distributions (see Table 1). However, Berger et al. ignore this difference. 2) We train two classifiers to predict beginning and ending boundary respectively while Berger et al. build only one classifier. Our experiments show that two separate classifiers outperform one classifier. 3) The last difference is how segment boundaries are integrated into a machine translation system. Berger et al. use predicted rifts to divide a long source sentence into a series of smaller segments, which are then translated sequentially in order to increase decoding speed (Brown et al., 1992; Berger et al., 1996). This can be considered as a hard integration, which may undermine translation accuracy given wrongly predicted rifts. We integrate predicted translation boundaries into phrase-based decoding in a soft manner, which improves translation accuracy in terms of BLEU score. 7 Conclusion and Future Work In this paper, we have presented a simple approach to learn translation boundaries on source sentences. The learned translation boundaries are used to constrain phrase-based decoding in a soft manner. The whole approach has several properties. • First, it is based on a simple c</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, Mohanty, 1992</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, Robert L. Mercer, and Surya Mohanty. 1992. Dividing and Conquering Long Sentences in a Translation System. In Proceedings of the workshop on Speech and Natural Language, Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
</authors>
<title>Cohesive Phrase-based Decoding for Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1805" citStr="Cherry, 2008" startWordPosition="248" endWordPosition="249">ins. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major probl</context>
<context position="17062" citStr="Cherry, 2008" startWordPosition="2729" endWordPosition="2730">rately, we obtain two classified word sets: By/Bn words, and Ey/En words. We can prohibit any translations or reorderings spanning ci...cj (j &gt; i) where ci V By according to the first classifier or cj V Ey according to the second classifier. In such a way, we integrate translation boundaries into phrase-based decoding as hard constraints, which, however, is at the risk of producing no translation covering the whole source sentence. Alternatively, we introduce soft constraints based on translation boundary that our classifiers predict, similar to constituent boundary based soft constraints in (Cherry, 2008) and (Marton and Resnik, 2008). We add a new feature to the decoder’s loglinear model: translation boundary violation counting feature. This counting feature accumulates whenever hypotheses have a partial translation spanning ci...cj (j &gt; i) where ci V By or cj V Ey. The LDC2004T07 Multiple Translation Chinese Table 5: Training corpora. weight av of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translatio</context>
<context position="26451" citStr="Cherry, 2008" startWordPosition="4252" endWordPosition="4253">two separate classifiers is that we can explore more constraints. A word Ck can be possibly labeled as By by the first classifier and Ey by the second classifier. Therefore we can build soft constraints on span (CZ, Ck) (CZ E By, Ck E Ey) and span (Ck, Cj) (Ck E By, Cj E Ey). This is impossible if we use only one classifier since each word can have only one class label. We can build only one constraint on span (CZ, Ck) or span (Ck, Cj). 6 Related Work Various approaches incorporate constraints into phrase-based decoding in a soft or hard manner. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to cons</context>
</contexts>
<marker>Cherry, 2008</marker>
<rawString>Colin Cherry. 2008. Cohesive Phrase-based Decoding for Statistical Machine Translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="1315" citStr="Chiang, 2005" startWordPosition="176" endWordPosition="178">ies for any source sentences. The classifiers are trained directly on word-aligned corpus without using any additional resources. We report the accuracy of our translation boundary classifiers. We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-toEnglish translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn </context>
<context position="26819" citStr="Chiang, 2005" startWordPosition="4309" endWordPosition="4311">bel. We can build only one constraint on span (CZ, Ck) or span (Ck, Cj). 6 Related Work Various approaches incorporate constraints into phrase-based decoding in a soft or hard manner. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings 142 which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM a</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A Hierarchical Phrase-based Model for Statistical Machine Translation. In Proceedings of ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause Restructuring for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="27126" citStr="Collins et al., 2005" startWordPosition="4357" endWordPosition="4360">ide parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings 142 which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whe</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Philipp Koehn and Ivona Kucerova. 2005. Clause Restructuring for Statistical Machine Translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Decoding Complexity in Word Replacement Translation Models.</title>
<date>1999</date>
<booktitle>In Computational Linguistics, 25(4):607 –</booktitle>
<pages>615</pages>
<contexts>
<context position="1414" citStr="Knight, 1999" startWordPosition="192" endWordPosition="193">sing any additional resources. We report the accuracy of our translation boundary classifiers. We show that using constraints based on translation boundaries predicted by our classifiers achieves significant improvements over the baseline on large-scale Chinese-toEnglish translation experiments. The new constraints also significantly outperform constituent boundary based syntactic constrains. 1 Introduction It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a countin</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>Kevin Knight. 1999. Decoding Complexity in Word Replacement Translation Models. In Computational Linguistics, 25(4):607 – 615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="1928" citStr="Koehn et al., 2003" startWordPosition="264" endWordPosition="267"> 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent boundary based constraints is that syntactic structures of the source language do not necessarily </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical Phrase-based Translation. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="20312" citStr="Koehn, 2004" startWordPosition="3242" endWordPosition="3243"> corpus for the NIST MT-03 set and the reference corpus for the NIST MT-05 set contain 4 translations per source sentence. To compare with constituent boundary based constraints, we parsed source sentences of both the development and test sets using a Chinese parser (Xiong et al., 2005) which was trained on the Penn Chinese Treebank with an Fi-score of 79.4%. Our evaluation metric is case-insensitive BLEU-4 (Papineni et al., 2002) using the shortest reference sentence length for the brevity penalty. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 5.2 Using Translation Boundaries from Reference Translations The most direct way to investigate the impact on the system performance of using translation boundaries is to integrate “right” translation boundaries into decoding which are directly obtained from reference translations. For both the development set and test set, we have four reference translation sets, which are named ref1, ref2, ref3 and ref4, respectively. For the development set, we used translation boundaries obtained from ref1. Based on these boundaries, we built our translation boundary violation counting feature and tuned </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Alexandra Birch Mayne</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>IWSLT Speech Translation Evaluation.</title>
<date>2005</date>
<booktitle>Edinburgh System Description for the</booktitle>
<contexts>
<context position="18636" citStr="Koehn et al., 2005" startWordPosition="2971" endWordPosition="2974">ed using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora in both directions and then applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to obtain many-to-many word alignments. From the word-aligned corpora, we extracted bilingual phrases and trained our translation model. We used all corpora in Table 5 except for the United Nations corpus to train our MaxEnt based reordering model (Xiong et al., 2006), which con140 sist of 33.3M Chinese words and 35.8M English words. We built a four-gram language model using the SRILM toolkit (Stolcke, 2002), which was trained on Xinhua section of the English Gigaword corpus (181.1M words). To train our translation boundary classifiers, we extract training instances from the whole wordaligned</context>
</contexts>
<marker>Koehn, Axelrod, Mayne, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne and David Talbot. 2005. Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation. In Proceedings of IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Soft Syntactic Constraints for Hierarchical Phrase-Based Translation.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="1835" citStr="Marton and Resnik, 2008" startWordPosition="251" endWordPosition="254"> It has been known that phrase-based decoding (phrase segmentation/translation/reordering (Chiang, 2005)) should be constrained to some extent not only for transferring the NP-hard problem (Knight, 1999) into a tractable one in practice but also for improving translation quality. For example, Xiong et al. (2008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent bound</context>
<context position="17092" citStr="Marton and Resnik, 2008" startWordPosition="2732" endWordPosition="2735">wo classified word sets: By/Bn words, and Ey/En words. We can prohibit any translations or reorderings spanning ci...cj (j &gt; i) where ci V By according to the first classifier or cj V Ey according to the second classifier. In such a way, we integrate translation boundaries into phrase-based decoding as hard constraints, which, however, is at the risk of producing no translation covering the whole source sentence. Alternatively, we introduce soft constraints based on translation boundary that our classifiers predict, similar to constituent boundary based soft constraints in (Cherry, 2008) and (Marton and Resnik, 2008). We add a new feature to the decoder’s loglinear model: translation boundary violation counting feature. This counting feature accumulates whenever hypotheses have a partial translation spanning ci...cj (j &gt; i) where ci V By or cj V Ey. The LDC2004T07 Multiple Translation Chinese Table 5: Training corpora. weight av of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalt</context>
<context position="23486" citStr="Marton and Resnik, 2008" startWordPosition="3737" endWordPosition="3740"> very close to the best result of using translation boundaries from reference translations. To compare with constituent boundary based syntactic constraints, we also carried out experiments using two kinds of such constraints. One is the 141 System BLEU-4 (%) Base 33.05 Condeducer 33.18 XP+ 33.58* BestRef 34.21*+ MEMM 1 33.70* MEMM 2 34.04*+ Table 7: Results of using automatically learned translation boundaries. Condeducer means using pure constituent boundary based soft constraint. XP+ is another constituent boundary based soft constraint but with distinction among special constituent types (Marton and Resnik, 2008). BestRef is the best result using reference translation boundaries in Table 6. MEMM 1 and MEMM 2 are our MEMM based translation boundary classifiers with Markov order 1 and 2. *: significantly better than baseline (p &lt; 0.01). +: significantly better than XP+ (p &lt; 0.01). Condeducer which uses pure constituent boundary based syntactic constraint: any partial translations which cross any constituent boundaries will be penalized. The other is the XP+ from (Marton and Resnik, 2008) which only penalizes hypotheses which violate the boundaries of a constituent with a label from {NP, VP, CP, IP, PP, </context>
<context position="26481" citStr="Marton and Resnik, 2008" startWordPosition="4255" endWordPosition="4258">fiers is that we can explore more constraints. A word Ck can be possibly labeled as By by the first classifier and Ey by the second classifier. Therefore we can build soft constraints on span (CZ, Ck) (CZ E By, Ck E Ey) and span (Ck, Cj) (Ck E By, Cj E Ey). This is impossible if we use only one classifier since each word can have only one class label. We can build only one constraint on span (CZ, Ck) or span (Ck, Cj). 6 Related Work Various approaches incorporate constraints into phrase-based decoding in a soft or hard manner. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to impro</context>
</contexts>
<marker>Marton, Resnik, 2008</marker>
<rawString>Yuval Marton and Philip Resnik. 2008. Soft Syntactic Constraints for Hierarchical Phrase-Based Translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>Dayne Freitag and Fernando Pereira 2000. Maximum Entropy Markov Models for Information Extraction and Segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning</booktitle>
<marker>McCallum, 2000</marker>
<rawString>Andrew McCallum, Dayne Freitag and Fernando Pereira 2000. Maximum Entropy Markov Models for Information Extraction and Segmentation. In Proceedings of the Seventeenth International Conference on Machine Learning 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="18517" citStr="Och and Ney, 2000" startWordPosition="2952" endWordPosition="2955">a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora in both directions and then applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to obtain many-to-many word alignments. From the word-aligned corpora, we extracted bilingual phrases and trained our translation model. We used all corpora in Table 5 except for the United Nations corpus to train our MaxEnt based reordering model (Xiong et al., 2006), which con140 sist of 33.3M Chinese words and 35.8M English words. We built a four-gram language model using the SRILM toolkit (Stolcke, 2002), which was trained on Xinhua section of the English Gigaword corpus </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In Proceedings of ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="17486" citStr="Och, 2003" startWordPosition="2799" endWordPosition="2800">entence. Alternatively, we introduce soft constraints based on translation boundary that our classifiers predict, similar to constituent boundary based soft constraints in (Cherry, 2008) and (Marton and Resnik, 2008). We add a new feature to the decoder’s loglinear model: translation boundary violation counting feature. This counting feature accumulates whenever hypotheses have a partial translation spanning ci...cj (j &gt; i) where ci V By or cj V Ey. The LDC2004T07 Multiple Translation Chinese Table 5: Training corpora. weight av of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−avCv) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out var</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatically Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="20134" citStr="Papineni et al., 2002" startWordPosition="3216" endWordPosition="3219">ata as our development set (919 sentences in total, 27.1 words per sentence). The NIST MT-05 test set includes 1082 sentences with an average of 27.4 words per sentence. Both the reference corpus for the NIST MT-03 set and the reference corpus for the NIST MT-05 set contain 4 translations per source sentence. To compare with constituent boundary based constraints, we parsed source sentences of both the development and test sets using a Chinese parser (Xiong et al., 2005) which was trained on the Penn Chinese Treebank with an Fi-score of 79.4%. Our evaluation metric is case-insensitive BLEU-4 (Papineni et al., 2002) using the shortest reference sentence length for the brevity penalty. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 5.2 Using Translation Boundaries from Reference Translations The most direct way to investigate the impact on the system performance of using translation boundaries is to integrate “right” translation boundaries into decoding which are directly obtained from reference translations. For both the development set and test set, we have four reference translation sets, which are named ref1, ref2, ref3 and ref4, respective</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward and WeiJing Zhu. 2002. BLEU: a Method for Automatically Evaluation of Machine Translation. In Proceedings of ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Kristy Hollingshead</author>
</authors>
<title>Classifying Chart Cells for Quadratic Complexity Context-Free Inference.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="3134" citStr="Roark and Hollingshead, 2008" startWordPosition="440" endWordPosition="443">age do not necessarily reflect translation structures where the source and target language correspond to each other. In this paper, we investigate building classifiers that directly address the problem of translation boundary, rather than extracting constituent boundary from sourceside parsers built for a different purpose. A translation boundary is a position in the source sequence which begins or ends a translation zone 1 spanning multiple source words. In a translation zone, the source phrase is translated as a unit. Reorderings which cross translation zones are not desirable. Inspired by (Roark and Hollingshead, 2008) which introduces classifiers to decide if a word can begin/end a multi-word constituent, we build two discriminative classifiers to tag each word in the source sequence with a binary class label. The first classifier decides if a word can begin a multi-sourceword translation zone; the second classifier decides if a word can end a multi-source-word translation &apos;We will give a formal definition of translation zone in Section 2. 136 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 136–144, Los Angeles, California, June 2010. c�2010 Associati</context>
</contexts>
<marker>Roark, Hollingshead, 2008</marker>
<rawString>Brian Roark and Kristy Hollingshead. 2008. Classifying Chart Cells for Quadratic Complexity Context-Free Inference. In Proceedings of COLING 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit. In</title>
<date>2002</date>
<booktitle>Proceedings of International Conference on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="19048" citStr="Stolcke, 2002" startWordPosition="3041" endWordPosition="3042"> and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora in both directions and then applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to obtain many-to-many word alignments. From the word-aligned corpora, we extracted bilingual phrases and trained our translation model. We used all corpora in Table 5 except for the United Nations corpus to train our MaxEnt based reordering model (Xiong et al., 2006), which con140 sist of 33.3M Chinese words and 35.8M English words. We built a four-gram language model using the SRILM toolkit (Stolcke, 2002), which was trained on Xinhua section of the English Gigaword corpus (181.1M words). To train our translation boundary classifiers, we extract training instances from the whole wordaligned corpora, from which we obtain 96.9M training instances for the By/B,,, and Ey/E,,, classifier. We ran the off-the-shelf MaxEnt toolkit (Zhang, 2004) to tune classifier feature weights with Gaussian prior set to 1 to avoid overfitting. We used the NIST MT-03 evaluation test data as our development set (919 sentences in total, 27.1 words per sentence). The NIST MT-05 test set includes 1082 sentences with an av</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of International Conference on Spoken Language Processing, volume 2, pages 901-904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Wang</author>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
</authors>
<title>Chinese Syntactic Reordering for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="27150" citStr="Wang et al., 2007" startWordPosition="4362" endWordPosition="4365">lation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings 142 which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translation system, which is similar to our definition of translation boundary. They also use a maximum entropy model to predict whether a source position i</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Chao Wang, Michael Collins and Philipp Koehn 2007. Chinese Syntactic Reordering for Statistical Machine Translation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Cindy Ng</author>
</authors>
<title>Using Brackets to Improve Search for Statistical Machine Translation In</title>
<date>1995</date>
<booktitle>Proceedings of PACLIC-IO, Pacific Asia Conference on Language, Information and Computation.</booktitle>
<contexts>
<context position="27002" citStr="Wu and Ng, 1995" startWordPosition="4337" endWordPosition="4340">er. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side parse trees. (Xiong et al., 2008) prohibit any swappings 142 which violate punctuation based constraints. Non-linguistic constraints are also widely used in phrase-based decoding. The IBM and ITG constraints (Zens et al., 2004) are used to restrict reorderings in practical phrase-based systems. (Berger et al., 1996) introduces the concept of rift into a machine translat</context>
</contexts>
<marker>Wu, Ng, 1995</marker>
<rawString>Dekai Wu and Cindy Ng. 1995. Using Brackets to Improve Search for Statistical Machine Translation In Proceedings of PACLIC-IO, Pacific Asia Conference on Language, Information and Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--3</pages>
<contexts>
<context position="17942" citStr="Wu, 1997" startWordPosition="2867" endWordPosition="2868"> LDC2004T07 Multiple Translation Chinese Table 5: Training corpora. weight av of this feature is tuned via minimal error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−avCv) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora. Computational Linguistics, 23(3):377-403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Shuanglong Li</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
<author>Yueliang Qian</author>
</authors>
<title>Parsing the Penn Chinese Treebank with Semantic Knowledge.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP, Jeju Island,</booktitle>
<contexts>
<context position="19987" citStr="Xiong et al., 2005" startWordPosition="3193" endWordPosition="3196">kit (Zhang, 2004) to tune classifier feature weights with Gaussian prior set to 1 to avoid overfitting. We used the NIST MT-03 evaluation test data as our development set (919 sentences in total, 27.1 words per sentence). The NIST MT-05 test set includes 1082 sentences with an average of 27.4 words per sentence. Both the reference corpus for the NIST MT-03 set and the reference corpus for the NIST MT-05 set contain 4 translations per source sentence. To compare with constituent boundary based constraints, we parsed source sentences of both the development and test sets using a Chinese parser (Xiong et al., 2005) which was trained on the Penn Chinese Treebank with an Fi-score of 79.4%. Our evaluation metric is case-insensitive BLEU-4 (Papineni et al., 2002) using the shortest reference sentence length for the brevity penalty. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 5.2 Using Translation Boundaries from Reference Translations The most direct way to investigate the impact on the system performance of using translation boundaries is to integrate “right” translation boundaries into decoding which are directly obtained from reference tran</context>
</contexts>
<marker>Xiong, Li, Liu, Lin, Qian, 2005</marker>
<rawString>Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin, Yueliang Qian. 2005. Parsing the Penn Chinese Treebank with Semantic Knowledge. In Proceedings of IJCNLP, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of ACLCOLING</booktitle>
<contexts>
<context position="18066" citStr="Xiong et al., 2006" startWordPosition="2881" endWordPosition="2884"> error rate training (MERT) (Och, 2003) with other feature weights. Unlike hard constraints, which simply prevent any hypotheses from violating translation boundaries, soft constraints allow violations of translation boundaries but with a penalty of exp(−avCv) where Cv is the violation count. By using soft constraints, we can enable the model to prefer hypotheses which are consistent with translation boundaries. 5 Experiment Our baseline system is a phrase-based system using BTGs (Wu, 1997), which includes a contentdependent reordering model discriminatively trained using reordering examples (Xiong et al., 2006). We carried out various experiments to evaluate the impact of integrating translation boundary based soft constraints into decoding on the system performance on the Chinese-to-English translation task of the NIST MT-05 using large scale training data. 5.1 Experimental Setup Our training corpora are listed in Table 5. The whole corpora consist of 96.9M Chinese words and 109.5M English words in 3.8M sentence pairs. We ran GIZA++ (Och and Ney, 2000) on the parallel corpora in both directions and then applied the “grow-diag-final” refinement rule (Koehn et al., 2005) to obtain many-to-many word a</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation. In Proceedings of ACLCOLING 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
</authors>
<title>Ai Ti Aw, Haitao Mi, Qun Liu and Shouxun Lin.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP</booktitle>
<marker>Xiong, Zhang, 2008</marker>
<rawString>Deyi Xiong, Min Zhang, Ai Ti Aw, Haitao Mi, Qun Liu and Shouxun Lin. 2008. Refinements in BTG-based Statistical Machine Translation. In Proceedings of IJCNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Ai Ti Aw</author>
<author>Haizhou Li</author>
</authors>
<title>A Syntax-Driven Bracketing Model for PhraseBased Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP</booktitle>
<contexts>
<context position="2139" citStr="Xiong et al., 2009" startWordPosition="292" endWordPosition="295">008) find that translation quality can be significantly improved by either prohibiting reorderings around punctuation or restricting reorderings within a 15-word window. Recently, more linguistically motivated constraints are introduced to improve phrase-based decoding. (Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al., 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees. (Xiong et al., 2009) further presents a bracketing model to include thousands of context-sensitive syntactic constraints. All of these approaches achieve their improvements by guiding the phrase-based decoder to prefer translations which respect source-side parse trees. One major problem with such constituent boundary based constraints is that syntactic structures of the source language do not necessarily reflect translation structures where the source and target language correspond to each other. In this paper, we investigate building classifiers that directly address the problem of translation boundary, rather </context>
<context position="26633" citStr="Xiong et al., 2009" startWordPosition="4277" endWordPosition="4280">can build soft constraints on span (CZ, Ck) (CZ E By, Ck E Ey) and span (Ck, Cj) (Ck E By, Cj E Ey). This is impossible if we use only one classifier since each word can have only one class label. We can build only one constraint on span (CZ, Ck) or span (Ck, Cj). 6 Related Work Various approaches incorporate constraints into phrase-based decoding in a soft or hard manner. Our introduction has already briefly mentioned (Cherry, 2008) and (Marton and Resnik, 2008), which utilize source-side parse tree boundary violation counting feature to build soft constraints for phrase-based decoding, and (Xiong et al., 2009), which calculates a score to indicate to what extent a source phrase can be translated as a unit using a bracketing model with richer syntactic features. More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side. In addition, hard linguistic constraints are also explored. (Wu and Ng, 1995) employs syntactic bracketing information to constrain search in order to improve speed and accuracy. (Collins et al., 2005) and (Wang et al., 2007) use hard syntactic constraints to perform reorderings according to source-side par</context>
</contexts>
<marker>Xiong, Zhang, Aw, Li, 2009</marker>
<rawString>Deyi Xiong, Min Zhang, Ai Ti Aw, and Haizhou Li. 2009. A Syntax-Driven Bracketing Model for PhraseBased Translation. In Proceedings of ACL-IJCNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Taro Watanabe and Eiichiro Sumita</title>
<date>2004</date>
<booktitle>In Proceedings of COLING.</booktitle>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens, Hermann Ney, Taro Watanabe and Eiichiro Sumita 2004. Reordering Constraints for PhraseBased Statistical Machine Translation. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
<author>David Chiang</author>
</authors>
<title>Extracting Synchronous Grammars Rules from WordLevel Alignments in Linear Time.</title>
<date>2008</date>
<booktitle>In Proceeding of COLING</booktitle>
<contexts>
<context position="10537" citStr="Zhang et al., 2008" startWordPosition="1656" endWordPosition="1659">on of training instances from word alignments. Second, we build two classifiers with simple features on the obtained training instances. Finally, we evaluate our classifiers on the development set using the “gold” translation boundaries obtained from reference translations. 3.1 Obtaining Translation Boundaries from Word Alignments We can easily obtain constituent boundaries from parse trees. Similarly, if we have a tree covering both source and target sentence, we can easily get translation boundaries from this tree. Fortunately, we can build such a tree directly from word alignments. We use (Zhang et al., 2008)’s shift-reduce algorithm (SRA) to decompose word alignments into hierarchical trees. Given an arbitrary word-level alignment as an input, SRA is able to output a tree representation of the word alignment (a.k.a decomposition tree). Each node of the tree is a translation zone as we defined in the Section 2. Therefore the first word on the source side of each multi-source-word node is a beginning translation boundary (∈ By); the last word on the source side of each multi-source-word node is an ending translation boundary (∈ Ey). Figure 1a shows an example of many-to-many alignment, where the so</context>
<context position="12593" citStr="Zhang et al., 2008" startWordPosition="2045" endWordPosition="2048">as described above, we can tag each source word with two sets of class labels: {By, Bn} and {Ey, En}. The tagged source sentences will be used to train our two translation boundary classifiers. 46.9 52.2 138 a) b) ([1, 7], [1, 9]) 1 2 3 4 5 6 7 ii &amp; AIr a [Mtw �%k TL The last five flights all failed due to accident 1 2 3 4 5 6 7 8 9 ([1, 5], [1, 5]) s ([1, 4], [1, 4]) ([5, 5], [5, 5]) ([1, 3], [1, 3]) ([4, 4], [4, 4]) ([1, 1], [1, 2]) ([2, 3], [3, 3]) ([6, 7], [6, 9]) ([6, 6], [7, 9]) ([7, 7], [6, 6]) Figure 1: An example of many-to-many word alignment and its tree representation produced by (Zhang et al., 2008)’s shift-reduce algorithm. 3.2 Building Translation Boundary Classifiers We build two discriminative classifiers based on Maximum Entropy Markov Models (MEMM) (McCallum et al., 2000). One classifier is to predict the word class ( E {By, BnJ for each source word. The other is to predict the word class ( E {Ey, EnJ. These two classifiers are separately trained using training instances obtained from our word-aligned training data as demonstrated in the last section. We use features from surrounding words, including 2 before and 2 after the current word position (c_2, c_1, c+1, c+2). We also use c</context>
</contexts>
<marker>Zhang, Gildea, Chiang, 2008</marker>
<rawString>Hao Zhang, Daniel Gildea, and David Chiang. 2008. Extracting Synchronous Grammars Rules from WordLevel Alignments in Linear Time. In Proceeding of COLING 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Zhang</author>
</authors>
<date>2004</date>
<booktitle>Maximum Entropy Modeling Tooklkit for Python and C++. Available at http://homepages.inf.ed.ac.uk/s0450736</booktitle>
<marker>Le Zhang, 2004</marker>
<rawString>Le Zhang. 2004. Maximum Entropy Modeling Tooklkit for Python and C++. Available at http://homepages.inf.ed.ac.uk/s0450736</rawString>
</citation>
<citation valid="false">
<note>maxent toolkit.html.</note>
<marker></marker>
<rawString>/maxent toolkit.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>