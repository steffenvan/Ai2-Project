<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002874">
<title confidence="0.995575">
Peking: Building Semantic Dependency Graphs with a Hybrid Parser
</title>
<author confidence="0.993696">
Yantao Du, Fan Zhang, Xun Zhang, Weiwei Sun∗ and Xiaojun Wan
</author>
<affiliation confidence="0.982505">
Institute of Computer Science and Technology, Peking University
</affiliation>
<note confidence="0.621796">
The MOE Key Laboratory of Computational Linguistics, Peking University
</note>
<email confidence="0.9881255">
{duyantao,zhangxunah,ws,wanxiaojun}@pku.edu.cn
zhangf717@gmail.com
</email>
<sectionHeader confidence="0.99364" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992446833333334">
This paper is a description of our system
for SemEval-2015 Task 18: Broad-Coverage
Semantic Dependency Parsing. We imple-
ment a hybrid parser which benefits from both
transition-based and graph-based parsing ap-
proaches. In particular, the tree approximation
method is explored to take advantage of well-
studied tree parsing techniques. Evaluation on
multilingual data sets demonstrates that con-
siderably good semantic analysis can be au-
tomatically built by applying state-of-the-art
data-driven parsing techniques.
</bodyText>
<sectionHeader confidence="0.99898" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993208888888889">
Dependency grammar is a long-standing tradition
that determines syntacto-semantic structures on the
basis of word-to-word connections. It names a
family of approaches to linguistic analysis that all
share a commitment to typed relations between or-
dered pairs of words. Partially due to the power-
ful expressiveness of bi-lexical dependency struc-
tures, the corresponding parsing problem has been
widely studied especially in the last decade. The
majority of these studies, however, only focus on
tree-structured representations. Beyond tree-shaped
structures, SemEval-2014 Task 8 (Oepen et al.,
2014) seeked to stimulate the dependency parsing
community to move towards more general graph
processing. Quite a number of teams all over the
world participated in this shared task, which sug-
gests a growing community interest in parsing into
graph-shaped dependency representations.
∗Email correspondence.
SemEval-2015 Task 18 is a subsequent task of
SemEval-2014 Task 8. Following several well-
established syntactic theories, this task proposes us-
ing graphs to represent semantics and provides high-
quality annotations for three typologically different
languages. We have developed a system, dubbed
DZSW14 (Du et al., 2014) for the task last year.
The system employed a hybrid architecture which
benefits from both transition-based and graph-based
parsing approaches. Evaluation on multiple English
data sets provided by SemEval-2014 indicated that
DZSW14 is able to obtain high-quality parsing re-
sults. Following the key idea to employ hetero-
geneous models to enhance hybrid parsing, we ex-
tend DZSW14 by developing more tree approxima-
tion models, namely the weighted tree approxima-
tion models. Evaluation on multilingual data sets
provided by this year’s task confirms the effective-
ness of the techniques we have studied.
In this paper, we first give an introduction of the
architecture of the baseline system DZSW14. Then
we demonstrate the weighted tree approximation
models. Finally we show the experiment results on
SemEval-2015 Task 18. The tree approximation sys-
tem can be downloaded at http://www.icst.
pku.edu.cn/lcwm/grass.
</bodyText>
<sectionHeader confidence="0.91491" genericHeader="method">
2 Baseline System: DZSW14
</sectionHeader>
<bodyText confidence="0.998814">
Our system is based on the system we constructed
for SemEval-2014 Task 8. In this section we present
a brief overview of its architecture. Refer to (Du et
al., 2014) for more information.
Inspired by the research on discriminative de-
pendency tree parsing, DZSW14 employed a hy-
brid parsing architecture. DZSW14 explored two
</bodyText>
<page confidence="0.964161">
927
</page>
<bodyText confidence="0.8823525">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 927–931,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
kinds of heterogeneous approaches: transition-based
and tree approximation approaches. The transition-
based model use transitions on configurations to
obtain graph parses, while the tree approximation
model transform graphs into trees for training and
test. To further combine the complementary predic-
tion power, DZWS14 applied a voting-based ensem-
ble method.
</bodyText>
<subsectionHeader confidence="0.797572">
2.1 Transition-Based Models
</subsectionHeader>
<bodyText confidence="0.999980466666667">
Transition-based models consist of transitions and
configurations that can be manipulated by the tran-
sitions. The configurations generally encode the in-
formation of the current parsing state, especially in-
cluding partial parsing results, and the transitions
can be applied to a configuration, turning it into a
new one. When the system reaches any acceptable
configuration, a coherent semantic graph is also suc-
cessfully built. The key to the success of building
transition-based parsers is to train good classifiers
to approximate transition oracles. DZSW14 imple-
ments 5 different transition systems for graph pars-
ing. Experiments from last year’s evaluation suggest
that this method can be applied to build considerably
good parsers for more general linguistic graphs.
</bodyText>
<subsectionHeader confidence="0.996452">
2.2 Tree Approximation Models
</subsectionHeader>
<bodyText confidence="0.999995384615385">
The core of tree approximation is transformations
between graphs and trees. At the training time,
we convert the dependency graphs from the training
data into dependency trees, and train second-order
arc-factored models1 (Bohnet, 2010). At the test
phase, we parse sentences using this tree parser, and
convert the output trees back into semantic graphs.
In DZSW14, We develop several different methods
to convert a semantic graph into a tree. The main
idea is to apply graph traversal algorithms to con-
vert a directed graph to a directed tree. During the
traversal, we may lose or modify some dependency
relations in order to make a tree.
</bodyText>
<subsectionHeader confidence="0.99476">
2.3 Experience from DZSW14
</subsectionHeader>
<bodyText confidence="0.994203">
From a lot of experiments on DZSW14, we learned
several lessons as follows.
</bodyText>
<footnote confidence="0.73459">
1The mate parser (code.google.com/p/
mate-tools/) is used.
</footnote>
<listItem confidence="0.981786">
• Overall, the tree approximation models per-
form better than the transition-based models.
• The outputs of the different models exhibit sig-
nificant diversity.
• The model ensemble is quite effective, result-
ing in a boost in performance.
</listItem>
<bodyText confidence="0.999326">
This motivates us to explore more heterogeneous
tree approximation models for this year’s evaluation.
</bodyText>
<sectionHeader confidence="0.980717" genericHeader="method">
3 Weighted Tree Approximation Models
</sectionHeader>
<bodyText confidence="0.999898571428571">
In our system for SemEval-2015, we develop more
tree approximation models for model ensemble. We
call the graph-to-tree conversions in DZSW14 un-
weighted conversions since every edge in the graph
are treated equally. In this section, we demonstrate
weighted conversions which assign weights for dif-
ferent edges.
</bodyText>
<subsectionHeader confidence="0.98167">
3.1 Weighted Conversion
</subsectionHeader>
<bodyText confidence="0.987944555555556">
Given a graph G = (V, E), the edge selection in
the unweighted conversion is locally decided by its
current traversal state. In the weighted conversion,
we take the importance of different edges into ac-
count and try to globally improve the integrity with
respect to the losing edges. For example, in the
top of Figure 1, the undirected edges (Ward, was),
(Ward, relieved), (was, relieved) form a cycle. Only
two edges can be kept by the converted tree T. It
allows us to decide which edges to keep according
to the sum of the weights of them.
Let x →t y denote edges in the tree, and x →g y
edges in the graph. We assign each possible edge
x →t y a heuristic value W(x, y), and intend to ob-
tain a tree with maximum weight . More formally,
the result Tmax = (V, Emax
t ) contains the maximum
sum of values of edges:
</bodyText>
<equation confidence="0.651124">
1: Tmax = arg max W(x, y)
T=(V,Et) (x,y)∈Et
</equation>
<subsectionHeader confidence="0.987819">
3.2 Weight
</subsectionHeader>
<bodyText confidence="0.9924855">
We define weight W(x, y) as follows, where I is the
indicator function:
</bodyText>
<listItem confidence="0.9388725">
• W(x, y) = A(x, y) + B(x, y) + C(x, y): The
weight is separate into 3 parts.
</listItem>
<page confidence="0.950442">
928
</page>
<figure confidence="0.598051">
noun ARG1 verb ARG1 verb ARG2
adj ARG1
root
</figure>
<listItem confidence="0.937036">
• A(x, y) = IxIyEEVyIxEE(x, y) x a: a is the
weight for the existing edge on graph ignoring
direction.
• B(x, y) = IxIyEE(x, y) x b: b is the weight
for the directed edge in the graph.
• C(x, y) = n − |x − y|: This is to value the im-
portance of edges where n is the length of sen-
tence. We consider edges linking closer words
more important because they are generally eas-
ier to be predicted.
• a » b » n or a &gt; b x n &gt; n x n: First
the transformed tree should contain the original
edges in G as many as possible. Then we need
to consider the quantity of edges with correct
direction in G. And the distance between nodes
in the sentence is in the last place.
</listItem>
<subsectionHeader confidence="0.996301">
3.3 Decoding
</subsectionHeader>
<bodyText confidence="0.999955571428571">
After the edges are weighted, the core decoding task
for graph transformation can be solved by maximum
spanning tree (MST) algorithms, where the search
space T consists of all projective and non-projective
dependency trees. To transform a graph to a pro-
jective tree, we use Eisner’s algorithm, and for non-
projective, we use Chu-Liu-Edmonds algorithm.
</bodyText>
<subsectionHeader confidence="0.998401">
3.4 Adding Labels
</subsectionHeader>
<bodyText confidence="0.995592">
Now we get the MST Tmax(V, Emax
</bodyText>
<equation confidence="0.834305090909091">
t ). For each
(x, y) E Emax
t , we assign a new label to (x, y) as
follows,
Case 1: x —*g y, add the original label in G(V, E)
to the new edge x —*t y;
Case 2: y —*g x, add the original label with symbol
R˜ to x —*t y;
Case 3: x —*g y n y —*g x, add label as Case 1;
Case 4: x --I+g y n y --/+ x, add label None to the
edge x —*t y.
</equation>
<bodyText confidence="0.999848285714286">
To improve the coverage of original edges, a vari-
ant model with modified labels in trees to help en-
code more edges in graphs.Suppose that x —* y is a
lost edge which is not on the new dependency tree
but is on the original dependency graph. The statis-
tic shows the structure of a majority of lost edges are
in one of three different types:
</bodyText>
<figure confidence="0.9374065">
Mrs Ward was relieved
root
Mrs Ward was relieved
Mrs Ward was relieved
</figure>
<figureCaption confidence="0.999597">
Figure 1: One dependency graph and two possible depen-
dency trees after converting.
</figureCaption>
<listItem confidence="0.992614666666667">
1. The nodes are siblings.
2. One is the grandparent of the other.
3. One is the great-grandparent of the other.
</listItem>
<bodyText confidence="0.9998555">
The conversions can be enhanced by adding more
symbols to labels to indicate lost edges if they are
of the three types above. The method is to append
semicolon (;) and exclamation mark (!) to some de-
gree and then add new label with information of lost
edge directly. If x —*g y is not in the converted tree
and its structure is of one of aforementioned types,
we change the label connecting node y and its parent
node with assumption that y is not higher than x in
the dependency tree.
</bodyText>
<listItem confidence="0.998060933333333">
• x is great-grandparent node of y: New label is
the label of x —*g y following the symbol ‘g’.
• x is grandparent node of y: New label is the
label of x —*g y following the symbol ‘f’.
• x and y are siblings: Let z be the two nodes’
parent. We sort all the z’s children by the or-
der of position in the sentence And we use an
integer P to indicate the position. If the two
siblings are on the same side of z, P will be
the distance of the two siblings’ positions in
the sorted children sequence and extra symbol
will be ‘y’. If the two siblings are on the dif-
ferent sides of z, extra symbol will be ‘n’ and
P will be x’s rank in the same side’s nodes in
the sorted children sequence. New label is the
</listItem>
<figure confidence="0.9982028">
... verb ARG1;!bn1adj ARG1 ...
adj ARG1;!fverb ARG1
root
...
...
</figure>
<page confidence="0.994919">
929
</page>
<bodyText confidence="0.998150666666667">
symbol ‘b’ with extra symbol followed and the
label of x →g y.
If node y is higher than x in the dependency tree, we
would add symbol R˜ to indicate the additional edge
is reversed. Figure 1 is an example of a converted
tree.
</bodyText>
<sectionHeader confidence="0.926945" genericHeader="method">
4 Model Ensemble
</sectionHeader>
<bodyText confidence="0.999982578947368">
We select 9 tree approximation models from
DZSW14, and propose 4 new weighted models
({projective, non-projective} x {original, label-
modification-variant}). Together with the transition
models, we have to combine the outputs of them into
one. We use a simple voter to combine the outputs
just like in DZSW14. For each pair of words of a
sentence, we count the number of the models that
give positive predictions. If the number is greater
than a threshold, we put this arc to the final graph,
and label the arc with the most common label of
what the models give.
Furthermore, we find that the performance of the
tree approximation models are better than the tran-
sition based models, so we assign weights for indi-
vidual models too. Then instead of just counting,
we sum the weights of the models that give positive
predictions. The tree approximation models are as-
signed higher weights.
</bodyText>
<sectionHeader confidence="0.97691" genericHeader="method">
5 Sense Labeling
</sectionHeader>
<bodyText confidence="0.999916833333333">
In this task, two representations DM and PSD of En-
glish require to label the words additional sense la-
bel. We develop a sequence labeler for this require-
ment. The sequence labeler is based on a second-
order linear-chain global linear model and utilize the
perceptron algorithm for parameter estimation. To
accelerate processing, we apply a Viterbi decoder
but constrain it with beam search. In particular, the
number of cells in the dynamic programming table
for each word is bounded by a fixed beam size. This
decoder can be also viewed as a beam decoder with
state-merging.
The representation DM can be labeled directly.
However due to the large amount of different senses
in representation PSD, it is difficult to label senses
without preprocessing. We finally decide to filter out
the rare senses that have a frequency lower than 10,
substituting “unknown” for them.
</bodyText>
<table confidence="0.998959">
Algorithm DMen PASen PSDen PAScs PSDcz
PROJ 4.24 6.31 8.89 9.36 3.56
NON-PROJ 2.31 6.16 8.42 9.04 2.81
PROJ� 2.30 1.85 2.73 3.26 2.21
NON-PROJ� 0.60 1.62 2.33 3.07 1.55
</table>
<tableCaption confidence="0.997159">
Table 1: Edge loss of conversion algorithms (%).
</tableCaption>
<table confidence="0.9998767">
Domain Format LP LR LF LM
id DMen 0.9093 0.8732 0.8909 0.2702
PASen 0.9290 0.8967 0.9126 0.3028
PSDen 0.7860 0.7293 0.7566 0.0872
PAScs 0.8191 0.7434 0.7794 0.1144
PSDcz 0.8475 0.8215 0.8343 0.2809
ood DMen 0.8429 0.7953 0.8184 0.2499
PASen 0.8947 0.8510 0.8723 0.3012
PSDen 0.7736 0.6961 0.7328 0.1790
PAScs 0.6941 0.6002 0.6437 0.1146
</table>
<tableCaption confidence="0.990958">
Table 2: Final results of the ensembled model.
</tableCaption>
<sectionHeader confidence="0.999451" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999958">
We participated in the closed track. The tree approx-
imation algorithms may cause some edge loss, and
the statistics for the weighted conversions are shown
in Table 1. We can see that all the algorithms cause
edge loss, and edge loss of the variants is much
lower. In addition, non-projective tree conversions
cause less loss compared to projective tree conver-
sions. Edge loss may result in a lower recall and
higher precision, but we can tune the final results
during model ensemble.
The final results given by the organizers are
shown in Table 2. Here we only give the labeled
score.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999963166666667">
Based on our previous system DZSW14, we devel-
oped a hybrid system for SemEval-2015 Task 18.
Our new system extends DZSW14 by providing sev-
eral more tree approximation models. The final re-
sult shows that our system as well as our new models
are effective.
</bodyText>
<sectionHeader confidence="0.983495" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.950212333333333">
The work was supported by NSFC (61300064,
61170166 and 61331011) and National High-Tech
R&amp;D Program (2012AA011101).
</bodyText>
<page confidence="0.994899">
930
</page>
<sectionHeader confidence="0.995852" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99921125">
Bernd Bohnet. 2010. Top accuracy and fast dependency
parsing is not a contradiction. In Proceedings of the
23rd International Conference on Computational Lin-
guistics (Coling 2010), pages 89–97, Beijing, China,
August. Coling 2010 Organizing Committee.
Yantao Du, Fan Zhang, Weiwei Sun, and Xiaojun Wan.
2014. Peking: Profiling syntactic tree parsing tech-
niques for semantic graph parsing. In Proceedings of
the 8th International Workshop on Semantic Evalua-
tion (SemEval 2014).
Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 Task
8: Broad-coverage semantic dependency parsing. In
Proceedings of the 8th International Workshop on Se-
mantic Evaluation, Dublin, Ireland.
</reference>
<page confidence="0.99817">
931
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.736440">
<title confidence="0.919243">Peking: Building Semantic Dependency Graphs with a Hybrid Parser</title>
<author confidence="0.851682">Fan Zhang Du</author>
<author confidence="0.851682">Xun Zhang</author>
<author confidence="0.851682">Weiwei</author>
<affiliation confidence="0.983476">Institute of Computer Science and Technology, Peking</affiliation>
<address confidence="0.881862">The MOE Key Laboratory of Computational Linguistics, Peking</address>
<email confidence="0.998692">zhangf717@gmail.com</email>
<abstract confidence="0.999402461538461">This paper is a description of our system for SemEval-2015 Task 18: Broad-Coverage Semantic Dependency Parsing. We implement a hybrid parser which benefits from both transition-based and graph-based parsing approaches. In particular, the tree approximation method is explored to take advantage of wellstudied tree parsing techniques. Evaluation on multilingual data sets demonstrates that considerably good semantic analysis can be automatically built by applying state-of-the-art data-driven parsing techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>89--97</pages>
<location>Beijing, China,</location>
<contexts>
<context position="4951" citStr="Bohnet, 2010" startWordPosition="709" endWordPosition="710">ilt. The key to the success of building transition-based parsers is to train good classifiers to approximate transition oracles. DZSW14 implements 5 different transition systems for graph parsing. Experiments from last year’s evaluation suggest that this method can be applied to build considerably good parsers for more general linguistic graphs. 2.2 Tree Approximation Models The core of tree approximation is transformations between graphs and trees. At the training time, we convert the dependency graphs from the training data into dependency trees, and train second-order arc-factored models1 (Bohnet, 2010). At the test phase, we parse sentences using this tree parser, and convert the output trees back into semantic graphs. In DZSW14, We develop several different methods to convert a semantic graph into a tree. The main idea is to apply graph traversal algorithms to convert a directed graph to a directed tree. During the traversal, we may lose or modify some dependency relations in order to make a tree. 2.3 Experience from DZSW14 From a lot of experiments on DZSW14, we learned several lessons as follows. 1The mate parser (code.google.com/p/ mate-tools/) is used. • Overall, the tree approximation</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 89–97, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yantao Du</author>
<author>Fan Zhang</author>
<author>Weiwei Sun</author>
<author>Xiaojun Wan</author>
</authors>
<title>Peking: Profiling syntactic tree parsing techniques for semantic graph parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="2081" citStr="Du et al., 2014" startWordPosition="285" endWordPosition="288">eeked to stimulate the dependency parsing community to move towards more general graph processing. Quite a number of teams all over the world participated in this shared task, which suggests a growing community interest in parsing into graph-shaped dependency representations. ∗Email correspondence. SemEval-2015 Task 18 is a subsequent task of SemEval-2014 Task 8. Following several wellestablished syntactic theories, this task proposes using graphs to represent semantics and provides highquality annotations for three typologically different languages. We have developed a system, dubbed DZSW14 (Du et al., 2014) for the task last year. The system employed a hybrid architecture which benefits from both transition-based and graph-based parsing approaches. Evaluation on multiple English data sets provided by SemEval-2014 indicated that DZSW14 is able to obtain high-quality parsing results. Following the key idea to employ heterogeneous models to enhance hybrid parsing, we extend DZSW14 by developing more tree approximation models, namely the weighted tree approximation models. Evaluation on multilingual data sets provided by this year’s task confirms the effectiveness of the techniques we have studied. </context>
</contexts>
<marker>Du, Zhang, Sun, Wan, 2014</marker>
<rawString>Yantao Du, Fan Zhang, Weiwei Sun, and Xiaojun Wan. 2014. Peking: Profiling syntactic tree parsing techniques for semantic graph parsing. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Marco Kuhlmann</author>
<author>Yusuke Miyao</author>
<author>Daniel Zeman</author>
<author>Dan Flickinger</author>
<author>Jan Hajiˇc</author>
<author>Angelina Ivanova</author>
<author>Yi Zhang</author>
</authors>
<title>Task 8: Broad-coverage semantic dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation,</booktitle>
<location>Dublin, Ireland.</location>
<note>SemEval</note>
<marker>Oepen, Kuhlmann, Miyao, Zeman, Flickinger, Hajiˇc, Ivanova, Zhang, 2014</marker>
<rawString>Stephan Oepen, Marco Kuhlmann, Yusuke Miyao, Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina Ivanova, and Yi Zhang. 2014. SemEval 2014 Task 8: Broad-coverage semantic dependency parsing. In Proceedings of the 8th International Workshop on Semantic Evaluation, Dublin, Ireland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>