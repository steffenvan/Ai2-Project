<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008906">
<title confidence="0.943692">
Literal and Metaphorical Sense Identification
through Concrete and Abstract Context
</title>
<note confidence="0.855577">
Peter D. Turney Yair Neuman Dan Assaf Yohai Cohen
Inst. for Info. Tech. Dept. of Education Dept. of Education Gilasio Coding
NRC Canada Ben-Gurion Univ. Ben-Gurion Univ. Tel-Aviv, Israel
Ottawa, Canada Beer-Sheva, Israel Beer-Sheva, Israel yohai@gilasio.com
</note>
<email confidence="0.969082">
peter.turney@nrc-cnrc.gc.ca yneuman@bgu.ac.il dan.assaf4@googlemail.com
</email>
<sectionHeader confidence="0.995237" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997308">
Metaphor is ubiquitous in text, even in highly
technical text. Correct inference about tex-
tual entailment requires computers to distin-
guish the literal and metaphorical senses of
a word. Past work has treated this problem
as a classical word sense disambiguation task.
In this paper, we take a new approach, based
on research in cognitive linguistics that views
metaphor as a method for transferring knowl-
edge from a familiar, well-understood, or con-
crete domain to an unfamiliar, less understood,
or more abstract domain. This view leads to
the hypothesis that metaphorical word usage
is correlated with the degree of abstractness of
the word’s context. We introduce an algorithm
that uses this hypothesis to classify a word
sense in a given context as either literal (de-
notative) or metaphorical (connotative). We
evaluate this algorithm with a set of adjective-
noun phrases (e.g., in dark comedy, the adjec-
tive dark is used metaphorically; in dark hair,
it is used literally) and with the TroFi (Trope
Finder) Example Base of literal and nonliteral
usage for fifty verbs. We achieve state-of-the-
art performance on both datasets.
</bodyText>
<sectionHeader confidence="0.999335" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997436263157895">
Metaphor is a natural consequence of our ability
to reason by analogy (Gentner et al., 2001). It is
so common in our daily language that we rarely
notice it (Lakoff and Johnson, 1980). Identifying
metaphorical word usage is important for reasoning
about the implications of text.
Past work on the problem of distinguishing lit-
eral and metaphorical senses has approached it as
a classical word sense disambiguation (WSD) task
(Birke and Sarkar, 2006). Here, we take a differ-
ent approach to the problem. Lakoff and Johnson
(1980) argue that metaphor is a method for trans-
ferring knowledge from a concrete domain to an ab-
stract domain. Therefore we hypothesize that the de-
gree of abstractness in a word’s context is correlated
with the likelihood that the word is used metaphori-
cally. This hypothesis is the basis for our algorithm
for distinguishing literal and metaphorical senses.
Consider the following sentences:
</bodyText>
<listItem confidence="0.999150166666667">
L: He shot down my plane.
→ C1: He fired at my plane.
9 A1: He refuted my plane.
M: He shot down my argument.
9 C2: He fired at my argument.
→ A2: He refuted my argument.
</listItem>
<bodyText confidence="0.999972875">
The literal sense of shot down in L invokes knowl-
edge from the domain of war. The metaphorical us-
age of shot down in M transfers knowledge from
the concrete domain of war to the abstract domain
of debate (Lakoff and Johnson, 1980).
The entailments of L and M depend on the in-
tended senses of shot down. L entails the concrete
fired at in C1 (because, in order to literally shoot
something down, you must first fire at it) but not the
abstract refuted in A1 (except perhaps as a joke). On
the other hand, M entails refuted in A2 but not fired
at in C2 (except perhaps as a novel metaphor).
In semiotics, Danesi (2003) argues that metaphor
transfers associations from the source domain to the
target domain. The metaphorical usage of shot down
in M carries associations of violence and destruc-
</bodyText>
<page confidence="0.968922">
680
</page>
<note confidence="0.7352255">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 680–690,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.990415304347827">
tion that are not conveyed by A2. is labeled L (literal) or N (nonliteral), according to
To make correct inferences about textual entail- the sense of the verb that is invoked by the sentence.
ment, computers must be able to distinguish the lit- A subset of twenty-five of the fifty verbs was used
eral and metaphorical senses of a word. Since rec- by Birke and Sarkar (2006).
ognizing textual entailment (RTE) is a core problem In our second experiment, we duplicate the setup
for NLP, with applications in Question Answering, of Birke and Sarkar (2006) so that we can com-
Information Retrieval, Information Extraction, and pare our results with theirs. In particular, a sepa-
Text Summarization, it follows that distinguishing rate model is learned for each individual verb. We
literal and metaphorical senses is a problem for a achieve an average f-score of 63.9%, compared to
wide variety of NLP tasks. The ability to recognize Birke and Sarkar’s (2006) 64.9%.
metaphorical word usage is a core requirement in In the third experiment, we train the algorithm
the Intelligence Advanced Research Projects Activ- on the twenty-five new verbs that were not used by
ity (IARPA) Metaphor Program (Madrigal, 2011).1 Birke and Sarkar (2006) and then we test it on the
Our approach to the problem of distinguishing lit- old verbs. That is, the algorithm is tested with verbs
eral and metaphorical senses is based on an algo- that it has never seen before. The training verbs are
rithm for calculating the degree of abstractness of merged to build a single model, instead of building
words. For instance, plane in L is rated 0.36396 (rel- a separate model for each individual verb. In this
atively concrete), whereas argument in M is rated experiment, the average f-score is 68.1%.
0.64617 (relatively abstract), which suggests that the The next section presents our algorithm for calcu-
verb shot down is used literally in L, whereas it is lating the degree of abstractness of words. In Sec-
used metaphorically in M. Our abstractness rating tion 3, we review related work. The experiments are
algorithm is similar to Turney and Littman’s (2003) described in Section 4. We discuss the results of the
algorithm for rating words according to their seman- experiments in Section 5 and conclude in Section 6.
tic orientation.
To classify a word usage as literal or metaphori-
cal, based on the context, we use supervised learning
with logistic regression. The abstractness rating al-
gorithm is used to generate feature vectors from a
word’s context and training data is used to learn a
logistic regression model that relates degrees of ab-
stractness to the classes literal and metaphorical.
We evaluate our algorithm with three experi-
ments. The first experiment involves one hundred
adjective-noun phrases labeled denotative (literal) or
connotative (metaphorical or nonliteral) by five an-
notators, according to the sense of the adjective.2
For instance, deep snow is labeled denotative and
deep appreciation is labeled connotative. The algo-
rithm is able to predict the labels of the annotators
with an average accuracy of 79%.
The next two experiments use the TroFi (Trope
Finder) Example Base of literal and nonliteral usage
for fifty verbs.3 The fifty verbs occur in 3,737 sen-
tences from The 1987-89 Wall Street Journal (WSJ)
Corpus Release 1. In each sentence, the target verb
2 Abstractness and Concreteness
Concrete words refer to things, events, and proper-
ties that we can perceive directly with our senses,
such as trees, walking, and red.4 Abstract words re-
fer to ideas and concepts that are distant from im-
mediate perception, such as economics, calculating,
and disputable. In this section, we describe an algo-
rithm that can automatically calculate a numerical
rating of the degree of abstractness of a word on a
scale from 0 (highly concrete) to 1 (highly abstract).
For example, the algorithm rates purvey as 1, donut
as 0, and immodestly as 0.5.
The algorithm is a variation of Turney and
Littman’s (2003) algorithm that rates words accord-
ing to their semantic orientation. Positive seman-
tic orientation indicates praise (honest, intrepid)
and negative semantic orientation indicates criticism
(disturbing, superfluous). The algorithm calculates
the semantic orientation of a given word by com-
paring it to seven positive words and seven nega-
4The word red has an abstract political sense, but our ab-
stractness rating algorithm does not distinguish word senses.
The more frequent concrete sense of red dominates, resulting
in an abstractness rating of 0.24984 (highly concrete).
</bodyText>
<footnote confidence="0.87221725">
1See http://www.iarpa.gov/solicitations metaphor.html.
2The labeled phrases are available from Yair Neuman.
3Available at http://www.cs.sfu.ca/ anoop/students/jbirke/.
681
</footnote>
<bodyText confidence="0.99976452173913">
tive words that are used as paradigms of positive and
negative semantic orientation:
Positive paradigm words: good, nice, excellent,
positive, fortunate, correct, and superior.
Negative paradigm words: bad, nasty, poor, nega-
tive, unfortunate, wrong, and inferior.
Likewise, here we calculate the abstractness of
a given word by comparing it to twenty abstract
words and twenty concrete words that are used as
paradigms of abstractness and concreteness.
Turney and Littman (2003) experimented with
two measures of semantic similarity, pointwise mu-
tual information (PMI) (Church and Hanks, 1989)
and latent semantic analysis (LSA) (Landauer and
Dumais, 1997). These measures take a pair of words
as input and generate a numerical similarity rating as
output. The semantic orientation of a given word is
calculated as the sum of its similarity with the posi-
tive paradigm words minus the sum of its similarity
with the negative paradigm words. Likewise, here
we calculate the abstractness of a given word by the
sum of its similarity with twenty abstract paradigm
words minus the sum of its similarity with twenty
concrete paradigm words. We then use a linear nor-
malization to map the calculated abstractness value
to range from 0 to 1.
Our algorithm for calculating abstractness uses a
form of LSA to measure semantic similarity. This is
described in detail in Section 2.1. Although Turney
and Littman (2003) manually selected their fourteen
paradigm words, here we use a supervised learning
algorithm to choose our forty paradigm words, as
explained in Section 2.2.
The MRC Psycholinguistic Database Machine
Usable Dictionary (Coltheart, 1981) includes 4,295
words rated with degrees of abstractness by human
subjects in psycholinguistic experiments.5 The rat-
ings range from 158 (highly abstract) to 670 (highly
concrete). Table 1 gives some examples.
We used half of the 4,295 MRC words to train our
supervised learning algorithm and the other half to
validate the algorithm. On the testing set, the algo-
rithm attains a correlation of 0.81 with the dictionary
ratings. This indicates that the algorithm agrees well
with human judgements of the degrees of abstract-
ness of words.
</bodyText>
<footnote confidence="0.995764">
5Available at http://ota.oucs.ox.ac.uk/headers/1054.xml.
</footnote>
<table confidence="0.9996634">
Abstract Words Rating Concrete Words Rating
as 158 ape 654
of 180 grasshopper 660
apt 183 tomato 662
however 186 milk 670
</table>
<tableCaption confidence="0.901183">
Table 1: Examples of abstract and concrete words from
the MRC Dictionary (Coltheart, 1981).
</tableCaption>
<subsectionHeader confidence="0.998462">
2.1 Measuring Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.999248861111111">
The variation of LSA that we use here is similar
to Rapp’s (2003) work. We modeled our similarity
measure on Rapp’s due to the high score of 92.5%
that he achieved on a set of 80 multiple-choice syn-
onym questions from the Test of English as a For-
eign Language (TOEFL). The core idea is to repre-
sent words with vectors and calculate the similarity
of two words by the cosine of the angle between the
two corresponding vectors. The values of the ele-
ments in the vectors are derived from the frequencies
of the words in a large corpus of text. This general
approach is known as a Vector Space Model (VSM)
of semantics (Salton et al., 1975).
We began with a corpus of 5×1010 words (280 gi-
gabytes of plain text) gathered from university web-
sites by a webcrawler.6 We then indexed this cor-
pus with the Wumpus search engine (B¨uttcher and
Clarke, 2005).7 We selected our vocabulary from the
terms (words and phrases) in the WordNet lexicon.8
By querying Wumpus, we obtained the frequency of
each WordNet term in our corpus. We selected all
WordNet terms with a frequency of 100 or more in
our corpus. This resulted in a set of 114,501 terms.
Next we used Wumpus to search for up to 10,000
phrases per term, where a phrase consists of the
given term plus four words to the left of the term and
four words to the right of the term. These phrases
were used to build a word–context frequency matrix
F with 114,501 rows and 139,246 columns. A row
vector in F corresponds to a term in WordNet and
the columns in F correspond to contexts (the words
to the left and right of a given term in a given phrase)
in which the term appeared.
The columns in F are unigrams (single words)
in WordNet with a frequency of 100 or more in
the corpus. A given unigram is represented by two
</bodyText>
<footnote confidence="0.999988666666667">
6Collected by Charles Clarke at the University of Waterloo.
7Wumpus is available at http://www.wumpus-search.org/.
8WordNet is available at http://wordnet.princeton.edu/.
</footnote>
<page confidence="0.996454">
682
</page>
<bodyText confidence="0.999965416666667">
columns, one marked left and one marked right.
Suppose r is the term corresponding to the i-th row
in F and c is the term corresponding to the j-th col-
umn in F. Let c be marked left. Let fid be the cell
in the i-th row and j-th column of F. The numerical
value in the cell fid is the number of phrases found
by Wumpus in which the center term was r and c
was the unigram closest to r on the left side of r.
That is, fid is the frequency with which r was found
in the context c in our corpus.
A new matrix X, with the same number of rows
and columns as in F, was formed by calculating
the Positive Pointwise Mutual Information (PPMI)
of each cell in F (Turney and Pantel, 2010). The
function of PPMI is to emphasize cells in which
the frequency fid is statistically surprising, and
hence particularly informative. This matrix was then
smoothed with a truncated Singular Value Decom-
position (SVD), which decomposes X into the prod-
uct of three matrices UkEkVTk . Finally, the terms
were represented by the matrix UkEk, which has
114,501 rows (one for each term) and k columns
(one for each latent contextual factor). The semantic
similarity of two terms is given by the cosine of the
two corresponding rows in UkEk. For more detail,
see Turney and Pantel (2010).
There are two parameters in UkEk that need to
be set. The parameter k controls the number of la-
tent factors and the parameter p adjusts the weights
of the factors, by raising the corresponding singu-
lar values in Ek to the power p. The parameter k is
well-known in the literature on LSA, but p is less fa-
miliar. The use of p was suggested by Caron (2001).
Based on our past experience, we set k to 1000 and
p to 0.5. We did not explore any alternative settings
of these parameters for measuring abstractness.
</bodyText>
<subsectionHeader confidence="0.99964">
2.2 Measuring Abstractness
</subsectionHeader>
<bodyText confidence="0.999971410714286">
Now that we have UkEk, all we need in order
to measure abstractness is some paradigm words.
We used the MRC Psycholinguistic Database Ma-
chine Usable Dictionary (Coltheart, 1981) to guide
our search for paradigm words. We split the 4,295
MRC words into 2,148 for training (searching for
paradigm words) and 2,147 for testing (evaluation
of the final set of paradigm words). We began
with an empty set of paradigm words and added
words from the 114,501 rows of UkEk, one word
at a time, alternating between adding a word to the
concrete paradigm words and then adding a word
to the abstract paradigm words. At each step, we
added the paradigm word that resulted in the high-
est Pearson correlation with the ratings of the train-
ing words. This is a form of greedy forward search
without backtracking. We stopped the search after
forty paradigm words were found, in order to pre-
vent overfitting of the training data.
Table 2 shows the forty paradigm words and the
order in which they were selected. At each step, the
correlation increases on the training set, but even-
tually it must decrease on the testing set. After
forty steps, the training set Pearson correlation was
0.8600. At this point, we stopped the search for
paradigm words and calculated the testing set Pear-
son correlation, which was 0.8064. This shows a
small amount of overfitting of the training data. The
testing set Spearman correlation was 0.8216.
For another perspective on the performance of the
algorithm, we measured its accuracy on the testing
set, by creating a binary classification task from the
testing data. We calculated the median of the rat-
ings of the 2,147 words in the test set. Every word
with an abstractness above the median was assigned
to the class 1 and every word with an abstractness
below the median was assigned to the class 0. We
then used the algorithm to guess the rating of each
word in the test set, calculated the median guess, and
likewise assigned the guesses to classes 1 and 0. The
guesses were 84.65% accurate.
After generating the paradigm words with the
training set and evaluating them with the testing
set, we then used them to assign abstractness rat-
ings to every term in the matrix. The result of this
is that we now have a set of 114,501 terms (words
and phrases) with abstractness ratings ranging from
0 to 1.9 Based on the testing set performance, we
estimate these 114,501 ratings would have a Pearson
correlation of 0.81 with human ratings and an accu-
racy of 85% on binary (abstract or concrete) classi-
fication.
We chose to limit the search to forty paradigm
words based on our past experience with semantic
orientation (Turney and Littman, 2003). To validate
this choice, we allowed the algorithm to continue
</bodyText>
<footnote confidence="0.986429">
9The 114,501 rated terms are available from Peter Turney.
</footnote>
<page confidence="0.98752">
683
</page>
<table confidence="0.999952545454545">
Concrete Paradigm Words Abstract Paradigm Words
Order Word Correlation Order Word Correlation
1 donut 0.4447 2 sense 0.6165
3 antlers 0.6582 4 indulgent 0.6973
5 aquarium 0.7150 6 bedevil 0.7383
7 nursemaid 0.7476 8 improbable 0.7590
9 pyrethrum 0.7658 10 purvey 0.7762
11 swallowwort 0.7815 12 pigheadedness 0.7884
13 strongbox 0.7920 14 ranging 0.7973
15 sixth-former 0.8009 16 quietus 0.8067
17 restharrow 0.8089 18 regularisation 0.8123
19 recorder 0.8148 20 creditably 0.8188
21 sawmill 0.8212 22 arcella 0.8248
23 vulval 0.8270 24 nonproductive 0.8299
25 tenrecidae 0.8316 26 couth 0.8340
27 hairpiece 0.8363 28 repulsion 0.8400
29 sturnus 0.8414 30 palsgrave 0.8438
31 gadiformes 0.8451 32 goof-proof 0.8469
33 cobbler 0.8481 34 meshuga 0.8503
35 bullet 0.8521 36 dillydally 0.8538
37 dioxin 0.8550 38 reliance 0.8570
39 usa 0.8585 40 lumbus 0.8600
</table>
<tableCaption confidence="0.999626">
Table 2: The forty paradigm words and the Pearson correlation on the training set.
</tableCaption>
<bodyText confidence="0.999945413793103">
searching until one hundred paradigm words were
found. This resulted in a training set Pearson corre-
lation of 0.8963, but the testing set correlation was
only 0.8097, which shows a significant amount of
overfitting of the training data. Although the test-
ing set correlation is slightly higher with one hun-
dred paradigm words, we chose to base the follow-
ing experiments on the forty paradigm words, be-
cause the difference between 0.8064 and 0.8097 is
not significant, and the gap between the training and
testing correlation (0.8963 versus 0.8097) indicates
a problematic amount of overfitting. Furthermore,
the execution time of the algorithm increases as the
paradigm set increases.
We generated abstractness ratings for a large vo-
cabulary of 114,501 words in order to maximize the
variety of text genres and the range of applications
for which our list of abstractness ratings would be
useful. As a consequence of this large vocabulary,
many of the words in Table 2 are rare and obscure;
however, the measure of quality of the algorithm is
the correlation with the testing set (0.81), not the
familiarity of the words in the table. We include
the table here so that other researchers can exper-
iment with these paragidm words. The table may
give some insight into the internal functioning of the
algorithm, but the main output of the algorithm is
the list of 114,501 words with abstractness ratings,
not the list of paradigm words in Table 2.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="introduction">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999858571428571">
Here we discuss related work on metaphor and then
work on measuring abstractness. As far as we know,
our approach is the first in computational linguis-
tics to bring these two themes together, although
the connection is well-known in cognitive linguistics
(Lakoff and Johnson, 1980) and cognitive psychol-
ogy (Gentner et al., 2001).
</bodyText>
<subsectionHeader confidence="0.964644">
3.1 Metaphor
</subsectionHeader>
<bodyText confidence="0.99987225">
The most closely related work is Birke and Sarkar’s
(2006) research on distinguishing literal and nonlit-
eral usage of verbs. A later paper (Birke and Sarkar,
2007) provides more detail on their active learn-
ing system, briefly mentioned in the earlier paper.
Birke and Sarkar (2006; 2007) treat the problem as
a classical word sense disambiguation task (Navigli,
2009). A model is learned for each verb indepen-
</bodyText>
<page confidence="0.965479">
684
</page>
<bodyText confidence="0.98996603030303">
dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet
handle a new verb without additional training. hypernym hierarchy captures the general–specific
Hashimoto and Kawahara (2009) discuss work continuum, which might not be the same as the
on a similar problem, distinguishing idiomatic us- abstract–concrete continuum. It would be interest-
age from literal usage. They also approach this as ing to see how much correspondence there is be-
a classical word sense disambiguation task. Idioms tween Changizi’s measure of abstractness and the
are somewhat different from metaphors, in that the ratings in the MRC Psycholinguistic Database Ma-
meaning of an idiom (e.g., kick the bucket) is often chine Usable Dictionary (Coltheart, 1981). Also,
difficult to derive from the meanings of the compo- note that adjectives and adverbs are outside of Word-
nent words, unlike most metaphors. Net’s hypernym hierarchy, and thus cannot be rated
Nissim and Markert (2003) use supervised learn- by Changizi’s algorithm.
ing to distinguish metonymic usage from literal us- Xing et al. (2010) also use WordNet, but in a dif-
age. They take a classical WSD approach, learn- ferent way. They define the concreteness of a word
ing a separate model for each target word. As with sense (a WordNet synset) to be 1 if the given word
Birke and Sarkar (2006; 2007) and Hashimoto and sense is a hyponym of physical entity in the Word-
Kawahara (2009), the core idea is to learn to clas- Net hypernym hierarchy; otherwise the concreteness
sify word usage from similarity of context. Unlike is 0. We believe that, although physical entities are
these approaches, our algorithm generalizes beyond concrete, so are redness and walking, which are not
the specific semantic content of the context, paying hyponyms of physical entity. The category physical
attention only to the degrees of abstractness of the entity only partially captures concreteness.
context. 4 Experiments
Martin (1992) presents a knowledge-based ap- In the following experiments, we use the abstract-
proach to interpreting metaphors. This approach re- ness ratings of Section 2.2 to generate features for
quires complex hand-coded rules, which are specific supervised machine learning. The learning algo-
to a given domain (e.g., interpreting metaphorical rithm we apply is logistic regression (Le Cessie and
questions from computer users, such as, “How can Van Houwelingen, 1992), as implemented in Weka
I kill a process?”, in an online help system). The (Witten and Frank, 2005).10 In all experiments, we
knowledge base cannot handle words that are not used the Weka parameter settings R = 0.2 (for ro-
hand-coded in its rules and a new set of rules must bust ridge regression) and M = −1 (for unlimited
be constructed for each new application domain. iterations).
Dolan (1995) describes an algorithm for extract-
ing metaphors from a dictionary. Some suggestive
examples are given, but the algorithm is not evalu-
ated in any systematic way.
Mason (2004) takes a corpus-based approach to
metaphor. His algorithm is based on a statistical
approach to discovering the selectional restrictions
of verbs. It then uses these restrictions to discover
metaphorical mappings, such as, “Money flows like
a liquid.” Although the system can discover some
metaphorical mappings, it was not designed to dis-
tinguish literal and metaphorical usages of words.
3.2 Abstractness
Changizi (2008) uses the hypernym hierarchy in
WordNet to calculate the abstractness of a word.
A word near the top of the hierarchy is consid-
ered abstract and a word near the bottom is con-
685
4.1 Adjectives
For this experiment, we selected five adjectives,
dark, deep, hard, sweet, and warm. For each of
the five adjectives, we identified twenty word pairs
in which the first word is the adjective and the
second word is a noun. These pairs were identi-
fied through the Corpus of Contemporary American
English (COCA)11 (Davies, 2009) by seeking the
nouns that follow each adjective in the corpus and
sorting the candidate adjective-noun pairs by fre-
quency. We required a minimum pointwise mutual
information (PMI) of 3 between the adjective and
the noun. In some of the pairs, the adjective was
10Weka is available at http://www.cs.waikato.ac.nz/ml/weka/.
11Available at http://www.americancorpus.org/.
used in a denotative (literal) sense (dark hair) and in
others it was used in a connotative (nonliteral) sense
(dark humor). Table 3 gives some examples.
</bodyText>
<table confidence="0.8104044">
Adjective-Noun Pairs Noun Abstractness
dark glasses 0.26826
dark chocolate 0.28211
dark energy 0.66207
dark mood 0.61858
</table>
<tableCaption confidence="0.969225">
Table 3: Some examples of adjective-noun pairs and the
abstractness rating of the noun.
</tableCaption>
<bodyText confidence="0.999943181818181">
In this experiment, we used the abstractness rat-
ing of the noun (the context) to predict whether the
adjective (the target) was used in a metaphorical or
literal sense. Table 3 supports this idea, but it is easy
to find counterexamples. Although dark mood is
metaphorical, bad mood is literal. The difference is
that dark has an abstractness rating of 0.43356 (rel-
atively concrete), whereas bad has an abstractness
rating of 0.63326 (relatively abstract). Metaphor re-
sults when a concrete word is imported into an ab-
stract context (Lakoff and Johnson, 1980). Ideally,
we should be comparing the abstractness of the tar-
get to the abstractness of the context. However, in
our data, the target words are mostly concrete; thus
we can focus on the context and ignore the target.
We discuss this point further in Section 5.
Five judges, undergraduate students in psychol-
ogy, were asked to judge whether the use of the ad-
jective is a denotation or a connotation. The instruc-
tions were as follows:
Denotation is the most direct or specific
meaning of a word or expression while
connotation is the meaning suggested by
the word that goes beyond its literal mean-
ing. For instance, the meaning of bitter is
denotative in bitter lemon and connotative
in bitter relations. In each of the following
pairs, you will be asked to judge whether
(1) the meaning of the first word is denota-
tive or connotative and (2) to what extent
it is denotative or connotative on a scale
ranging from 1 to 4.
The judges were blind to the research hypothe-
sis. Each judge received a booklet with the items
organized by the groups of adjectives and presented
in a random order. Overall, each subject was asked
to evaluate one hundred pairs. Interjudge reliability
was high, with Cronbach’s Alpha equal to 0.95.
Our feature vectors for each pair contained only
one element, the abstractness rating of the noun in
the pair. We used logistic regression with ten-fold
cross-validation to predict each judge’s denotative
and connotative labels. The results are summarized
in Table 4. On average, we were able to predict a
</bodyText>
<table confidence="0.999085625">
judge’s labels with 79% accuracy.
Judge Accuracy Majority
1 0.730 0.590
2 0.810 0.570
3 0.840 0.560
4 0.790 0.510
5 0.780 0.520
Average 0.790 0.550
</table>
<tableCaption confidence="0.9936825">
Table 4: The accuracy of logistic regression at predicting
the labels of each judge.
</tableCaption>
<bodyText confidence="0.971251875">
Table 4 also shows the size of the majority class
(the most common label) for each judge. For all
of the judges, the accuracy was significantly greater
than the size of the majority class (Fisher Exact test,
95% confidence level). The results support our hy-
pothesis that the abstractness of the context is pre-
dictive of whether an adjective is used in a literal or
metaphorical sense.
</bodyText>
<subsectionHeader confidence="0.981478">
4.2 Known Verbs
</subsectionHeader>
<bodyText confidence="0.9996759375">
For this experiment, we used the TroFi (Trope
Finder) Example Base of literal and nonliteral usage
for fifty verbs.12 To compare our results with Birke
and Sarkar’s (2006) results, we use the same subset
of twenty-five of the fifty verbs. These twenty-five
verbs appear in 1,965 sentences, manually labeled
L (literal) or N (nonliteral), according to the sense
of the target verb. The verbs also appeared in some
sentences labeled U (unannotated), but we ignored
these sentences (although they could be useful for
semi-supervised learning).
The label nonliteral is intended to be a broad cat-
egory that includes metaphorical as a special case.
Other types of nonliteral usage include idiomatic
and metonymical, but it seems that most of the non-
literal cases in TroFi are in fact metaphorical, and
</bodyText>
<footnote confidence="0.989716">
12Available at http://www.cs.sfu.ca/ anoop/students/jbirke/.
</footnote>
<page confidence="0.997586">
686
</page>
<bodyText confidence="0.998641125">
hence our hypothesis about the correlation of ab-
stract context with metaphorical sense is appropriate
for classifying the TroFi sentences.
Two examples of sentences from TroFi follow.
Both contain the target verb absorb. The first sen-
tence is literal and the second is nonliteral.
L: An Energy Department spokesman says the sul-
fur dioxide might be simultaneously recover-
able through the use of powdered limestone,
which tends to absorb the sulfur.
N: He said that MMWEC will have to absorb only
$4 million in additional annual costs now paid
by the Vermont utilities.
To generate feature vectors for the sentences, we
first applied the OpenNLP part-of-speech tagger to
the sentences.13 We then looked for each word in
our list of 114,501 abstractness ratings (Section 2.2).
If the word was not found in the list, we applied the
Morpha morphological analyzer to identify the stem
of the word (e.g., the stem of managing is manage)
(Minnen et al., 2001).14 We then looked for the stem
in our list. If it was still not found, we skipped it.
For each sentence, we created a vector with five
features:
</bodyText>
<listItem confidence="0.998330875">
1. the average abstractness ratings of all nouns,
excluding proper nouns
2. the average abstractness ratings of all proper
nouns
3. the average abstractness ratings of all verbs, ex-
cluding the target verb
4. the average abstractness ratings of all adjectives
5. the average abstractness ratings of all adverbs
</listItem>
<bodyText confidence="0.998913555555555">
When there were no words for a given part of
speech, we set the average to a default value of 0.5.
Two examples of feature vectors follow, correspond-
ing to the two TroFi sentences above.
L: (0.3873, 0.5397, 0.6375, 0.2641, 0.5835)
N: (0.6120, 0.3726, 0.6699, 0.5612, 0.5000)
The intuition here is that the weight of each con-
text word, in predicting the class of the target verb,
may depend on the part of speech of the context
</bodyText>
<footnote confidence="0.977372666666667">
13Available at http://incubator.apache.org/opennlp/.
14Available at http://www.informatics.susx.ac.uk/research/
groups/nlp/carroll/morph.html.
</footnote>
<bodyText confidence="0.995380042553192">
word. We leave it to the logistic regression algo-
rithm to determine the appropriate weighting, based
on the training data. (See Table 7 in the next sec-
tion.)
Following Birke and Sarkar’s (2006) approach,
we treated each group of sentences for a given target
verb as a separate learning problem. For each verb,
we used ten-fold cross-validation to learn and test
logistic regression models. To measure the perfor-
mance of the models, we used three different scores,
macro-averaged accuracy and two forms of macro-
averaged f-score.
Birke and Sarkar (2006) explain their scoring as
follows:
Literal recall is defined as (correct literals
in literal cluster / total correct literals).
Literal precision is defined as (correct lit-
erals in literal cluster /size of literal clus-
ter). If there are no literals, literal recall
is 100%; literal precision is 100% if there
are no nonliterals in the literal cluster and
0% otherwise. The f-score is defined as
(2 · precision · recall) / (precision + re-
call). Nonliteral precision and recall are
defined similarly. Average precision is the
average of literal and nonliteral precision;
similarly for average recall. For overall
performance, we take the f-score of aver-
age precision and average recall.
The overall score is a macro-average, in which each
verb has equal weight, regardless of how many sen-
tences it appears in.
Every verb in TroFi has at least one literal usage
and one nonliteral usage, so there is no issue with
the definition of recall as 100% when there are no lit-
erals or no nonliterals. However, we believe that the
definition of precision as 100% when no sentence is
assigned to the literal or nonliteral cluster gives too
high a score to the trivial algorithm of always guess-
ing the majority class. The minority class will then
always have a precision of 100%. Therefore we use
a modified f-score in which the precision of a class
is 0% if the algorithm never guesses that class. We
refer to Birke and Sarkar’s (2006) score as f-score
(0/0 = 1) and to our own score as f-score (0/0 = 0).
Table 5 summarizes our results. Concrete-
Abstract refers to our own algorithm. Birke-Sarkar
</bodyText>
<page confidence="0.99624">
687
</page>
<bodyText confidence="0.9997645">
refers to the best result reported by Birke and Sarkar
(2006), using a form of active learning. Majority
Class is the simple strategy of always guessing the
majority class. Probability Matching is the strategy
of randomly guessing each class with a probability
equal to the size of the class.
</bodyText>
<table confidence="0.999391833333333">
Algorithm Accuracy F-score F-score
(0/0=0) (0/0=1)
Concrete-Abstract 0.734 0.631 0.639
Birke-Sarkar NA NA 0.649
Majority Class 0.697 0.408 0.629
Probability Matching 0.605 0.500 0.500
</table>
<tableCaption confidence="0.999949">
Table 5: The performance with known verbs.
</tableCaption>
<bodyText confidence="0.9999825">
We used a paired t-test to evaluate the statistical
significance of the results in Table 5. The num-
bers are in bold font when the performance of an
algorithm is significantly below the performance of
Concrete-Abstract. In no case is any score signifi-
cantly above the performance of Concrete-Abstract,
at the 95% confidence level. NA indicates scores that
were not calculated by Birke and Sarkar (2006).
</bodyText>
<subsectionHeader confidence="0.997376">
4.3 Unknown Verbs
</subsectionHeader>
<bodyText confidence="0.999948434782609">
For the final experiment, we again used the TroFi
Example Base, but with a different experimental
setup. Instead of ten-fold cross-validation, we used
the twenty-five verbs in Birke and Sarkar (2006) for
testing (we call these the old verbs) and the other
twenty-five verbs (the new verbs) for training. The
twenty-five old (testing) verbs appear in 1,965 sen-
tences and the twenty-five new (training) verbs ap-
pear in 1,772 sentences. For this experiment, we
no longer learn a separate logistic regression model
for each verb. All of the 1,772 training sentences
are used together to learn a single logistic regression
model, which is then evaluated on the testing sen-
tences.
Table 6 summarizes our results. Since the testing
set is exactly the same as in Section 4.2, we can com-
pare the performance directly with the performance
in the preceding section and with Birke and Sarkar’s
(2006) results.
Again, we used a paired t-test to evaluate the sta-
tistical significance of the results in Table 6. The
numbers are in bold font when the performance of
an algorithm is significantly below the performance
</bodyText>
<table confidence="0.999412666666667">
Algorithm Accuracy F-score F-score
(0/0=0) (0/0=1)
Concrete-Abstract 0.686 0.673 0.681
Birke-Sarkar NA NA 0.649
Majority Class 0.697 0.408 0.629
Probability Matching 0.605 0.500 0.500
</table>
<tableCaption confidence="0.999868">
Table 6: The performance with unknown verbs.
</tableCaption>
<bodyText confidence="0.995471727272727">
of Concrete-Abstract. In no case is any score signifi-
cantly above the performance of Concrete-Abstract,
at the 95% confidence level.
Table 7 shows the coefficients in the logistic re-
gression model that was learned on the training data.
The items numbered from 1 to 5 are the five features
described in Section 4.2. The sixth item is the con-
stant term in the regression equation. We see that the
abstractness of the nouns (excluding proper nouns)
has the largest weight in predicting whether the tar-
get verb is in class N.
</bodyText>
<sectionHeader confidence="0.960070285714286" genericHeader="method">
Feature Coefficient
1 AvgNounAbs 11.4117
2 AvgPropAbs 0.7250
3 AvgVerbAbs -0.5528
4 AvgAdjAbs 1.1478
5 AvgAdvAbs -0.2013
6 Intercept -5.9436
</sectionHeader>
<tableCaption confidence="0.989343">
Table 7: The logistic regression coefficients for class N.
</tableCaption>
<sectionHeader confidence="0.999112" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999973944444445">
It is a strength of our approach that it can classify
verbs that it has never seen before, as we see in Sec-
tion 4.3. The feature vectors in all three experiments
are based only on the context; the target adjective or
verb is not used in the vectors. This avoids the need
for gathering training data on every verb or adjective
for which we want to determine whether it is being
used metaphorically or literally, since the algorithm
is not sensitive to the specific target word.
On the other hand, the performance might im-
prove if the target word were included in the fea-
ture vectors. If metaphor is a method for transfer-
ring knowledge from concrete domains to abstract
domains, then it follows that highly abstract target
words will tend to be used literally in most con-
texts. For instance, the highly abstract verb epito-
mize (with an abstractness rating of 0.85861) is per-
haps almost always used in a literal sense. There-
</bodyText>
<page confidence="0.971229">
688
</page>
<bodyText confidence="0.990431326530612">
fore it would seem that the abstractness rating of the 1981) includes words rated for imagability. Our al-
target word could be a useful clue for determining gorithm for rating the abstractness of words (Sec-
whether the sense is literal or metaphorical. tion 2) could easily be trained with the MRC imaga-
We experimented with including the abstractness bility ratings instead of the abstractness ratings. In
rating of the target word as a feature, but the im- future work, it would be interesting to evaluate
pact on performance was not significant for either imagability ratings on the TroFi Example Base. It
the adjectives or the verbs. We hypothesize that this would also be worthwhile to see whether our algo-
may be due to the relatively narrow range in the ab- rithm can be adapted for image retrieval (Xing et al.,
stractness of the adjectives and verbs in our data. 2010) and image annotation (Deschacht and Moens,
The abstractness ratings of the adjectives vary from 2007).
0.43356 for dark to 0.56637 for hard. The abstract- 6 Conclusion
ness ratings of the fifty verbs range from 0.28756 for Metaphor is ubiquitous, yet recognizing textual
plant to 0.71628 for lend, but 80% of the verbs lie entailment is a challenge when words are used
in the range from 0.41879 for fly to 0.59912 for rest. metaphorically. An algorithm for distinguishing
It seems possible that the abstractness rating of the metaphorical and literal senses of a word will facil-
target word would be useful with a dataset in which itate correct textual inference, which will improve
the target’s abstractness varied substantially. the many NLP applications that depend on textual
In future work, we would like to gather data for inference.
target words with a wider range of abstractness. We We have introduced a new algorithm for measur-
expect that such data would show some benefit to in- ing the degree of abstractness of a word. Inspired by
cluding information on the abstractness of the target research in cognitive linguistics (Lakoff and John-
word in the feature vector. son, 1980), we hypothesize that the degree of ab-
We also expect that a hybrid of classical word stractness of the context in which a given word ap-
sense disambiguation, such as Birke and Sarkar’s pears is predictive of whether the word is used in
(2006) algorithm, with abstractness ratings would a metaphorical or literal sense. This hypothesis is
perform better than either approach alone. Abstract- supported by three experiments.
ness may provide a good rough estimate of whether A strength of this approach to the problem of dis-
a word usage is literal or metaphorical, but it seems tinguishing metaphorical and literal senses is that
likely that knowledge of the specific target word in it readily generalizes to new words, outside of the
question will be required for a highly precise answer. training data. We do not claim that abstractness is
This is another worthwhile topic for future research. a complete solution to the problem, but it may be a
Currently there is no algorithm that identifies valuable component in any practical system for pro-
what kind of concepts and relations are grafted from cessing metaphorical text.
the source domain to the target domain by metaphor- Acknowledgments
ical inference. The algorithm presented in this pa- Part of the work of Yair Neuman, Dan Assaf, and
per may be used within a constraints-based model Yohai Cohen has been supported by a grant from the
of metaphor (Neuman and Nave, 2009) to address Israel Ministry of Defense. Thanks to the EMNLP
this challenge. reviewers for their helpful comments.
Recently there has been some interest in visual- References
ness, picturability, and imagability, the degree to Julia Birke and Anoop Sarkar. 2006. A clustering ap-
which a word is associated with visual imagery (De- proach for the nearly unsupervised recognition of non-
schacht and Moens, 2007). Although Xing et al. literal language. In Proceedings of the 11th Confer-
(2010) use the term concreteness in their work, their ence of the European Chapter of the Association for
research is concerned with predicting the difficulty
of queries for image retrieval. It could be argued that
Xing et al. should be trying to capture imagability,
not concreteness.
The MRC Psycholinguistic Database (Coltheart,
689
</bodyText>
<reference confidence="0.999750230769231">
Computational Linguistics (EACL 2006), pages 329–
336.
Julia Birke and Anoop Sarkar. 2007. Active learning for
the identification of nonliteral language. In Proceed-
ings of the Workshop on Computational Approaches to
Figurative Language at HLT/NAACL-07, pages 21–28.
Stefan B¨uttcher and Charles Clarke. 2005. Efficiency vs.
effectiveness in terabyte-scale information retrieval.
In Proceedings of the 14th Text REtrieval Conference
(TREC 2005), Gaithersburg, MD.
John Caron. 2001. Experiments with LSA scor-
ing: Optimal rank and basis. In Proceedings of
the SIAM Computational Information Retrieval Work-
shop, pages 157–169, Raleigh, NC.
Mark Changizi. 2008. Economically organized hierar-
chies in WordNet and the Oxford English Dictionary.
Cognitive Systems Research, 9(3):214–228.
Kenneth Church and Patrick Hanks. 1989. Word associ-
ation norms, mutual information, and lexicography. In
Proceedings of the 27th Annual Conference of the As-
sociation of Computational Linguistics, pages 76–83,
Vancouver, British Columbia.
Max Coltheart. 1981. The MRC psycholinguistic
database. Quarterly Journal ofExperimental Psychol-
ogy, 33A(4):497–505.
Marcel Danesi. 2003. Metaphorical “networks” and ver-
bal communication: A semiotic perspective on human
discourse. Sign Systems Studies, 31:341–363.
Mark Davies. 2009. The 385+ million word Corpus of
Contemporary American English (1990–2008+): De-
sign, architecture, and linguistic insights. Interna-
tional Journal of Corpus Linguistics, 14(2):159–190.
Koen Deschacht and Marie-Francine Moens. 2007. Text
analysis for automatic image annotation. In Proceed-
ings of the 45th Annual Meeting of the Association of
Computational Linguistics, pages 1000–1007.
William B. Dolan. 1995. Metaphor as an emergent prop-
erty of machine-readable dictionaries. In Proceedings
of the AAAI 1995 Spring Symposium Series: Repre-
sentation and Acquisition of Lexical Knowledge: Pol-
ysemy, Ambiguity and Generativity, pages 27–32.
Dedre Gentner, Brian F. Bowdle, Phillip Wolff, and Con-
suelo Boronat. 2001. Metaphor is like analogy. In
D. Gentner, K. J. Holyoak, and B. N. Kokinov, editors,
The analogical mind: Perspectivesfrom Cognitive Sci-
ence, pages 199–253. MIT Press, Cambridge, MA.
Chikara Hashimoto and Daisuke Kawahara. 2009. Com-
pilation of an idiom example database for supervised
idiom identification. Language Resources and Evalu-
ation, 43(4):355–384.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University Of Chicago Press, Chicago, IL.
Thomas K. Landauer and Susan T. Dumais. 1997. A so-
lution to Plato’s problem: The latent semantic analysis
theory of the acquisition, induction, and representation
of knowledge. Psychological Review, 104(2):211–
240.
Saskia Le Cessie and J.C. Van Houwelingen. 1992.
Ridge estimators in logistic regression. Applied Statis-
tics, 41(1):191–201.
Alexis Madrigal. 2011. Why are spy researchers build-
ing a ‘Metaphor Program’? The Atlantic, May 25.
James H. Martin. 1992. Computer understanding of
conventional metaphoric language. Cognitive Science,
16(2):233–270.
Zachary Mason. 2004. CorMet: A computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of English. Natu-
ral Language Engineering, 7(3):207–223.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACM Computing Surveys, 41(2):1–69.
Yair Neuman and Ophir Nave. 2009. Metaphor-based
meaning excavation. Information Sciences, 179:2719–
2728.
Malvina Nissim and Katja Markert. 2003. Syntactic
features and word similarity for supervised metonymy
resolution. In Proceedings of the 41st Annual Meet-
ing of the Association for Computational Linguistics
(ACL-03), pages 56–63, Sapporo, Japan.
Reinhard Rapp. 2003. Word sense discovery based on
sense descriptor dissimilarity. In Proceedings of the
Ninth Machine Translation Summit, pages 315–322.
Gerard Salton, Anita Wong, and Chung-Shu Yang. 1975.
A vector space model for automatic indexing. Com-
munications of the ACM, 18(11):613–620.
Peter D. Turney and Michael L. Littman. 2003. Measur-
ing praise and criticism: Inference of semantic orien-
tation from association. ACM Transactions on Infor-
mation Systems, 21(4):315–346.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: Vector space models of semantics.
Journal of Artificial Intelligence Research, 37:141–
188.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Prac-
tical Machine Learning Tools and Techniques with
Java Implementations. Morgan Kaufmann, San Fran-
cisco.
Xing Xing, Yi Zhang, and Mei Han. 2010. Query dif-
ficulty prediction for contextual image retrieval. In
Advances in Information Retrieval, volume 5993 of
Lecture Notes in Computer Science, pages 581–585.
Springer.
</reference>
<page confidence="0.997574">
690
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.292186">
<title confidence="0.9962315">Literal and Metaphorical Sense through Concrete and Abstract Context</title>
<author confidence="0.998573">Peter D Turney Yair Neuman Dan Assaf Yohai Cohen</author>
<affiliation confidence="0.731432">Inst. for Info. Tech. Dept. of Education Dept. of Education Gilasio Coding NRC Canada Ben-Gurion Univ. Ben-Gurion Univ. Tel-Aviv, Israel</affiliation>
<address confidence="0.638739">Ottawa, Canada Beer-Sheva, Israel Beer-Sheva, Israel yohai@gilasio.com</address>
<email confidence="0.911934">peter.turney@nrc-cnrc.gc.cayneuman@bgu.ac.ildan.assaf4@googlemail.com</email>
<abstract confidence="0.999223692307692">Metaphor is ubiquitous in text, even in highly technical text. Correct inference about textual entailment requires computers to distinguish the literal and metaphorical senses of a word. Past work has treated this problem as a classical word sense disambiguation task. In this paper, we take a new approach, based on research in cognitive linguistics that views metaphor as a method for transferring knowledge from a familiar, well-understood, or concrete domain to an unfamiliar, less understood, or more abstract domain. This view leads to the hypothesis that metaphorical word usage is correlated with the degree of abstractness of the word’s context. We introduce an algorithm that uses this hypothesis to classify a word sense in a given context as either literal (denotative) or metaphorical (connotative). We evaluate this algorithm with a set of adjectivephrases (e.g., in the adjecused metaphorically; in it is used literally) and with the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs. We achieve state-of-theart performance on both datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<date>2006</date>
<pages>329--336</pages>
<institution>Computational Linguistics (EACL</institution>
<contexts>
<context position="4020" citStr="(2006)" startWordPosition="657" endWordPosition="657">ciations of violence and destruc680 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 680–690, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics tion that are not conveyed by A2. is labeled L (literal) or N (nonliteral), according to To make correct inferences about textual entail- the sense of the verb that is invoked by the sentence. ment, computers must be able to distinguish the lit- A subset of twenty-five of the fifty verbs was used eral and metaphorical senses of a word. Since rec- by Birke and Sarkar (2006). ognizing textual entailment (RTE) is a core problem In our second experiment, we duplicate the setup for NLP, with applications in Question Answering, of Birke and Sarkar (2006) so that we can comInformation Retrieval, Information Extraction, and pare our results with theirs. In particular, a sepaText Summarization, it follows that distinguishing rate model is learned for each individual verb. We literal and metaphorical senses is a problem for a achieve an average f-score of 63.9%, compared to wide variety of NLP tasks. The ability to recognize Birke and Sarkar’s (2006) 64.9%. metaphorical </context>
<context position="20183" citStr="(2006)" startWordPosition="3355" endWordPosition="3355">ight into the internal functioning of the algorithm, but the main output of the algorithm is the list of 114,501 words with abstractness ratings, not the list of paradigm words in Table 2. 3 Related Work Here we discuss related work on metaphor and then work on measuring abstractness. As far as we know, our approach is the first in computational linguistics to bring these two themes together, although the connection is well-known in cognitive linguistics (Lakoff and Johnson, 1980) and cognitive psychology (Gentner et al., 2001). 3.1 Metaphor The most closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb without additional training. hypernym hierarchy captures the general–specific Hashimoto and Kawahara (2009) discuss work contin</context>
<context position="21914" citStr="(2006; 2007)" startWordPosition="3635" endWordPosition="3636">art, 1981). Also, difficult to derive from the meanings of the compo- note that adjectives and adverbs are outside of Wordnent words, unlike most metaphors. Net’s hypernym hierarchy, and thus cannot be rated Nissim and Markert (2003) use supervised learn- by Changizi’s algorithm. ing to distinguish metonymic usage from literal us- Xing et al. (2010) also use WordNet, but in a difage. They take a classical WSD approach, learn- ferent way. They define the concreteness of a word ing a separate model for each target word. As with sense (a WordNet synset) to be 1 if the given word Birke and Sarkar (2006; 2007) and Hashimoto and sense is a hyponym of physical entity in the WordKawahara (2009), the core idea is to learn to clas- Net hypernym hierarchy; otherwise the concreteness sify word usage from similarity of context. Unlike is 0. We believe that, although physical entities are these approaches, our algorithm generalizes beyond concrete, so are redness and walking, which are not the specific semantic content of the context, paying hyponyms of physical entity. The category physical attention only to the degrees of abstractness of the entity only partially captures concreteness. context. 4 Experime</context>
<context position="28121" citStr="(2006)" startWordPosition="4649" endWordPosition="4649">dicting the labels of each judge. Table 4 also shows the size of the majority class (the most common label) for each judge. For all of the judges, the accuracy was significantly greater than the size of the majority class (Fisher Exact test, 95% confidence level). The results support our hypothesis that the abstractness of the context is predictive of whether an adjective is used in a literal or metaphorical sense. 4.2 Known Verbs For this experiment, we used the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs.12 To compare our results with Birke and Sarkar’s (2006) results, we use the same subset of twenty-five of the fifty verbs. These twenty-five verbs appear in 1,965 sentences, manually labeled L (literal) or N (nonliteral), according to the sense of the target verb. The verbs also appeared in some sentences labeled U (unannotated), but we ignored these sentences (although they could be useful for semi-supervised learning). The label nonliteral is intended to be a broad category that includes metaphorical as a special case. Other types of nonliteral usage include idiomatic and metonymical, but it seems that most of the nonliteral cases in TroFi are i</context>
<context position="30981" citStr="(2006)" startWordPosition="5107" endWordPosition="5107">he two TroFi sentences above. L: (0.3873, 0.5397, 0.6375, 0.2641, 0.5835) N: (0.6120, 0.3726, 0.6699, 0.5612, 0.5000) The intuition here is that the weight of each context word, in predicting the class of the target verb, may depend on the part of speech of the context 13Available at http://incubator.apache.org/opennlp/. 14Available at http://www.informatics.susx.ac.uk/research/ groups/nlp/carroll/morph.html. word. We leave it to the logistic regression algorithm to determine the appropriate weighting, based on the training data. (See Table 7 in the next section.) Following Birke and Sarkar’s (2006) approach, we treated each group of sentences for a given target verb as a separate learning problem. For each verb, we used ten-fold cross-validation to learn and test logistic regression models. To measure the performance of the models, we used three different scores, macro-averaged accuracy and two forms of macroaveraged f-score. Birke and Sarkar (2006) explain their scoring as follows: Literal recall is defined as (correct literals in literal cluster / total correct literals). Literal precision is defined as (correct literals in literal cluster /size of literal cluster). If there are no li</context>
<context position="32761" citStr="(2006)" startWordPosition="5408" endWordPosition="5408">rb in TroFi has at least one literal usage and one nonliteral usage, so there is no issue with the definition of recall as 100% when there are no literals or no nonliterals. However, we believe that the definition of precision as 100% when no sentence is assigned to the literal or nonliteral cluster gives too high a score to the trivial algorithm of always guessing the majority class. The minority class will then always have a precision of 100%. Therefore we use a modified f-score in which the precision of a class is 0% if the algorithm never guesses that class. We refer to Birke and Sarkar’s (2006) score as f-score (0/0 = 1) and to our own score as f-score (0/0 = 0). Table 5 summarizes our results. ConcreteAbstract refers to our own algorithm. Birke-Sarkar 687 refers to the best result reported by Birke and Sarkar (2006), using a form of active learning. Majority Class is the simple strategy of always guessing the majority class. Probability Matching is the strategy of randomly guessing each class with a probability equal to the size of the class. Algorithm Accuracy F-score F-score (0/0=0) (0/0=1) Concrete-Abstract 0.734 0.631 0.639 Birke-Sarkar NA NA 0.649 Majority Class 0.697 0.408 0.</context>
<context position="34067" citStr="(2006)" startWordPosition="5618" endWordPosition="5618">ed t-test to evaluate the statistical significance of the results in Table 5. The numbers are in bold font when the performance of an algorithm is significantly below the performance of Concrete-Abstract. In no case is any score significantly above the performance of Concrete-Abstract, at the 95% confidence level. NA indicates scores that were not calculated by Birke and Sarkar (2006). 4.3 Unknown Verbs For the final experiment, we again used the TroFi Example Base, but with a different experimental setup. Instead of ten-fold cross-validation, we used the twenty-five verbs in Birke and Sarkar (2006) for testing (we call these the old verbs) and the other twenty-five verbs (the new verbs) for training. The twenty-five old (testing) verbs appear in 1,965 sentences and the twenty-five new (training) verbs appear in 1,772 sentences. For this experiment, we no longer learn a separate logistic regression model for each verb. All of the 1,772 training sentences are used together to learn a single logistic regression model, which is then evaluated on the testing sentences. Table 6 summarizes our results. Since the testing set is exactly the same as in Section 4.2, we can compare the performance </context>
<context position="39159" citStr="(2006)" startWordPosition="6478" endWordPosition="6478">ata for inference. target words with a wider range of abstractness. We We have introduced a new algorithm for measurexpect that such data would show some benefit to in- ing the degree of abstractness of a word. Inspired by cluding information on the abstractness of the target research in cognitive linguistics (Lakoff and Johnword in the feature vector. son, 1980), we hypothesize that the degree of abWe also expect that a hybrid of classical word stractness of the context in which a given word apsense disambiguation, such as Birke and Sarkar’s pears is predictive of whether the word is used in (2006) algorithm, with abstractness ratings would a metaphorical or literal sense. This hypothesis is perform better than either approach alone. Abstract- supported by three experiments. ness may provide a good rough estimate of whether A strength of this approach to the problem of disa word usage is literal or metaphorical, but it seems tinguishing metaphorical and literal senses is that likely that knowledge of the specific target word in it readily generalizes to new words, outside of the question will be required for a highly precise answer. training data. We do not claim that abstractness is Th</context>
</contexts>
<marker>2006</marker>
<rawString>Computational Linguistics (EACL 2006), pages 329– 336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for the identification of nonliteral language.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language at HLT/NAACL-07,</booktitle>
<pages>21--28</pages>
<contexts>
<context position="20288" citStr="Birke and Sarkar, 2007" startWordPosition="3369" endWordPosition="3372">m is the list of 114,501 words with abstractness ratings, not the list of paradigm words in Table 2. 3 Related Work Here we discuss related work on metaphor and then work on measuring abstractness. As far as we know, our approach is the first in computational linguistics to bring these two themes together, although the connection is well-known in cognitive linguistics (Lakoff and Johnson, 1980) and cognitive psychology (Gentner et al., 2001). 3.1 Metaphor The most closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb without additional training. hypernym hierarchy captures the general–specific Hashimoto and Kawahara (2009) discuss work continuum, which might not be the same as the on a similar problem, distinguishing idiomatic us- abstract–concr</context>
</contexts>
<marker>Birke, Sarkar, 2007</marker>
<rawString>Julia Birke and Anoop Sarkar. 2007. Active learning for the identification of nonliteral language. In Proceedings of the Workshop on Computational Approaches to Figurative Language at HLT/NAACL-07, pages 21–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan B¨uttcher</author>
<author>Charles Clarke</author>
</authors>
<title>Efficiency vs. effectiveness in terabyte-scale information retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th Text REtrieval Conference (TREC</booktitle>
<location>Gaithersburg, MD.</location>
<marker>B¨uttcher, Clarke, 2005</marker>
<rawString>Stefan B¨uttcher and Charles Clarke. 2005. Efficiency vs. effectiveness in terabyte-scale information retrieval. In Proceedings of the 14th Text REtrieval Conference (TREC 2005), Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Caron</author>
</authors>
<title>Experiments with LSA scoring: Optimal rank and basis.</title>
<date>2001</date>
<booktitle>In Proceedings of the SIAM Computational Information Retrieval Workshop,</booktitle>
<pages>157--169</pages>
<location>Raleigh, NC.</location>
<contexts>
<context position="14417" citStr="Caron (2001)" startWordPosition="2387" endWordPosition="2388">e matrix UkEk, which has 114,501 rows (one for each term) and k columns (one for each latent contextual factor). The semantic similarity of two terms is given by the cosine of the two corresponding rows in UkEk. For more detail, see Turney and Pantel (2010). There are two parameters in UkEk that need to be set. The parameter k controls the number of latent factors and the parameter p adjusts the weights of the factors, by raising the corresponding singular values in Ek to the power p. The parameter k is well-known in the literature on LSA, but p is less familiar. The use of p was suggested by Caron (2001). Based on our past experience, we set k to 1000 and p to 0.5. We did not explore any alternative settings of these parameters for measuring abstractness. 2.2 Measuring Abstractness Now that we have UkEk, all we need in order to measure abstractness is some paradigm words. We used the MRC Psycholinguistic Database Machine Usable Dictionary (Coltheart, 1981) to guide our search for paradigm words. We split the 4,295 MRC words into 2,148 for training (searching for paradigm words) and 2,147 for testing (evaluation of the final set of paradigm words). We began with an empty set of paradigm words </context>
</contexts>
<marker>Caron, 2001</marker>
<rawString>John Caron. 2001. Experiments with LSA scoring: Optimal rank and basis. In Proceedings of the SIAM Computational Information Retrieval Workshop, pages 157–169, Raleigh, NC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Changizi</author>
</authors>
<title>Economically organized hierarchies</title>
<date>2008</date>
<booktitle>in WordNet and the Oxford English Dictionary. Cognitive Systems Research,</booktitle>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="23983" citStr="Changizi (2008)" startWordPosition="3958" endWordPosition="3959">ions). Dolan (1995) describes an algorithm for extracting metaphors from a dictionary. Some suggestive examples are given, but the algorithm is not evaluated in any systematic way. Mason (2004) takes a corpus-based approach to metaphor. His algorithm is based on a statistical approach to discovering the selectional restrictions of verbs. It then uses these restrictions to discover metaphorical mappings, such as, “Money flows like a liquid.” Although the system can discover some metaphorical mappings, it was not designed to distinguish literal and metaphorical usages of words. 3.2 Abstractness Changizi (2008) uses the hypernym hierarchy in WordNet to calculate the abstractness of a word. A word near the top of the hierarchy is considered abstract and a word near the bottom is con685 4.1 Adjectives For this experiment, we selected five adjectives, dark, deep, hard, sweet, and warm. For each of the five adjectives, we identified twenty word pairs in which the first word is the adjective and the second word is a noun. These pairs were identified through the Corpus of Contemporary American English (COCA)11 (Davies, 2009) by seeking the nouns that follow each adjective in the corpus and sorting the can</context>
</contexts>
<marker>Changizi, 2008</marker>
<rawString>Mark Changizi. 2008. Economically organized hierarchies in WordNet and the Oxford English Dictionary. Cognitive Systems Research, 9(3):214–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Conference of the Association of Computational Linguistics,</booktitle>
<pages>76--83</pages>
<location>Vancouver, British Columbia.</location>
<contexts>
<context position="8979" citStr="Church and Hanks, 1989" startWordPosition="1431" endWordPosition="1434">/ anoop/students/jbirke/. 681 tive words that are used as paradigms of positive and negative semantic orientation: Positive paradigm words: good, nice, excellent, positive, fortunate, correct, and superior. Negative paradigm words: bad, nasty, poor, negative, unfortunate, wrong, and inferior. Likewise, here we calculate the abstractness of a given word by comparing it to twenty abstract words and twenty concrete words that are used as paradigms of abstractness and concreteness. Turney and Littman (2003) experimented with two measures of semantic similarity, pointwise mutual information (PMI) (Church and Hanks, 1989) and latent semantic analysis (LSA) (Landauer and Dumais, 1997). These measures take a pair of words as input and generate a numerical similarity rating as output. The semantic orientation of a given word is calculated as the sum of its similarity with the positive paradigm words minus the sum of its similarity with the negative paradigm words. Likewise, here we calculate the abstractness of a given word by the sum of its similarity with twenty abstract paradigm words minus the sum of its similarity with twenty concrete paradigm words. We then use a linear normalization to map the calculated a</context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>Kenneth Church and Patrick Hanks. 1989. Word association norms, mutual information, and lexicography. In Proceedings of the 27th Annual Conference of the Association of Computational Linguistics, pages 76–83, Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>The MRC psycholinguistic database.</title>
<date>1981</date>
<journal>Quarterly Journal ofExperimental Psychology,</journal>
<pages>33--4</pages>
<contexts>
<context position="10027" citStr="Coltheart, 1981" startWordPosition="1602" endWordPosition="1603">rity with twenty abstract paradigm words minus the sum of its similarity with twenty concrete paradigm words. We then use a linear normalization to map the calculated abstractness value to range from 0 to 1. Our algorithm for calculating abstractness uses a form of LSA to measure semantic similarity. This is described in detail in Section 2.1. Although Turney and Littman (2003) manually selected their fourteen paradigm words, here we use a supervised learning algorithm to choose our forty paradigm words, as explained in Section 2.2. The MRC Psycholinguistic Database Machine Usable Dictionary (Coltheart, 1981) includes 4,295 words rated with degrees of abstractness by human subjects in psycholinguistic experiments.5 The ratings range from 158 (highly abstract) to 670 (highly concrete). Table 1 gives some examples. We used half of the 4,295 MRC words to train our supervised learning algorithm and the other half to validate the algorithm. On the testing set, the algorithm attains a correlation of 0.81 with the dictionary ratings. This indicates that the algorithm agrees well with human judgements of the degrees of abstractness of words. 5Available at http://ota.oucs.ox.ac.uk/headers/1054.xml. Abstrac</context>
<context position="14776" citStr="Coltheart, 1981" startWordPosition="2446" endWordPosition="2447">ent factors and the parameter p adjusts the weights of the factors, by raising the corresponding singular values in Ek to the power p. The parameter k is well-known in the literature on LSA, but p is less familiar. The use of p was suggested by Caron (2001). Based on our past experience, we set k to 1000 and p to 0.5. We did not explore any alternative settings of these parameters for measuring abstractness. 2.2 Measuring Abstractness Now that we have UkEk, all we need in order to measure abstractness is some paradigm words. We used the MRC Psycholinguistic Database Machine Usable Dictionary (Coltheart, 1981) to guide our search for paradigm words. We split the 4,295 MRC words into 2,148 for training (searching for paradigm words) and 2,147 for testing (evaluation of the final set of paradigm words). We began with an empty set of paradigm words and added words from the 114,501 rows of UkEk, one word at a time, alternating between adding a word to the concrete paradigm words and then adding a word to the abstract paradigm words. At each step, we added the paradigm word that resulted in the highest Pearson correlation with the ratings of the training words. This is a form of greedy forward search wi</context>
<context position="21312" citStr="Coltheart, 1981" startWordPosition="3531" endWordPosition="3532">erarchy captures the general–specific Hashimoto and Kawahara (2009) discuss work continuum, which might not be the same as the on a similar problem, distinguishing idiomatic us- abstract–concrete continuum. It would be interestage from literal usage. They also approach this as ing to see how much correspondence there is bea classical word sense disambiguation task. Idioms tween Changizi’s measure of abstractness and the are somewhat different from metaphors, in that the ratings in the MRC Psycholinguistic Database Mameaning of an idiom (e.g., kick the bucket) is often chine Usable Dictionary (Coltheart, 1981). Also, difficult to derive from the meanings of the compo- note that adjectives and adverbs are outside of Wordnent words, unlike most metaphors. Net’s hypernym hierarchy, and thus cannot be rated Nissim and Markert (2003) use supervised learn- by Changizi’s algorithm. ing to distinguish metonymic usage from literal us- Xing et al. (2010) also use WordNet, but in a difage. They take a classical WSD approach, learn- ferent way. They define the concreteness of a word ing a separate model for each target word. As with sense (a WordNet synset) to be 1 if the given word Birke and Sarkar (2006; 200</context>
</contexts>
<marker>Coltheart, 1981</marker>
<rawString>Max Coltheart. 1981. The MRC psycholinguistic database. Quarterly Journal ofExperimental Psychology, 33A(4):497–505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Danesi</author>
</authors>
<title>Metaphorical “networks” and verbal communication: A semiotic perspective on human discourse.</title>
<date>2003</date>
<booktitle>Sign Systems Studies,</booktitle>
<pages>31--341</pages>
<contexts>
<context position="3271" citStr="Danesi (2003)" startWordPosition="536" endWordPosition="537"> literal sense of shot down in L invokes knowledge from the domain of war. The metaphorical usage of shot down in M transfers knowledge from the concrete domain of war to the abstract domain of debate (Lakoff and Johnson, 1980). The entailments of L and M depend on the intended senses of shot down. L entails the concrete fired at in C1 (because, in order to literally shoot something down, you must first fire at it) but not the abstract refuted in A1 (except perhaps as a joke). On the other hand, M entails refuted in A2 but not fired at in C2 (except perhaps as a novel metaphor). In semiotics, Danesi (2003) argues that metaphor transfers associations from the source domain to the target domain. The metaphorical usage of shot down in M carries associations of violence and destruc680 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 680–690, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics tion that are not conveyed by A2. is labeled L (literal) or N (nonliteral), according to To make correct inferences about textual entail- the sense of the verb that is invoked by the sentence. ment, computers must be able to d</context>
</contexts>
<marker>Danesi, 2003</marker>
<rawString>Marcel Danesi. 2003. Metaphorical “networks” and verbal communication: A semiotic perspective on human discourse. Sign Systems Studies, 31:341–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Davies</author>
</authors>
<title>The 385+ million word Corpus of Contemporary American English (1990–2008+): Design, architecture, and linguistic insights.</title>
<date>2009</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="24501" citStr="Davies, 2009" startWordPosition="4048" endWordPosition="4049">igned to distinguish literal and metaphorical usages of words. 3.2 Abstractness Changizi (2008) uses the hypernym hierarchy in WordNet to calculate the abstractness of a word. A word near the top of the hierarchy is considered abstract and a word near the bottom is con685 4.1 Adjectives For this experiment, we selected five adjectives, dark, deep, hard, sweet, and warm. For each of the five adjectives, we identified twenty word pairs in which the first word is the adjective and the second word is a noun. These pairs were identified through the Corpus of Contemporary American English (COCA)11 (Davies, 2009) by seeking the nouns that follow each adjective in the corpus and sorting the candidate adjective-noun pairs by frequency. We required a minimum pointwise mutual information (PMI) of 3 between the adjective and the noun. In some of the pairs, the adjective was 10Weka is available at http://www.cs.waikato.ac.nz/ml/weka/. 11Available at http://www.americancorpus.org/. used in a denotative (literal) sense (dark hair) and in others it was used in a connotative (nonliteral) sense (dark humor). Table 3 gives some examples. Adjective-Noun Pairs Noun Abstractness dark glasses 0.26826 dark chocolate 0</context>
</contexts>
<marker>Davies, 2009</marker>
<rawString>Mark Davies. 2009. The 385+ million word Corpus of Contemporary American English (1990–2008+): Design, architecture, and linguistic insights. International Journal of Corpus Linguistics, 14(2):159–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Text analysis for automatic image annotation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>1000--1007</pages>
<marker>Deschacht, Moens, 2007</marker>
<rawString>Koen Deschacht and Marie-Francine Moens. 2007. Text analysis for automatic image annotation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1000–1007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William B Dolan</author>
</authors>
<title>Metaphor as an emergent property of machine-readable dictionaries.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI 1995 Spring Symposium Series: Representation and Acquisition of Lexical Knowledge: Polysemy, Ambiguity and Generativity,</booktitle>
<pages>27--32</pages>
<contexts>
<context position="23387" citStr="Dolan (1995)" startWordPosition="3868" endWordPosition="3869">ised machine learning. The learning algoto a given domain (e.g., interpreting metaphorical rithm we apply is logistic regression (Le Cessie and questions from computer users, such as, “How can Van Houwelingen, 1992), as implemented in Weka I kill a process?”, in an online help system). The (Witten and Frank, 2005).10 In all experiments, we knowledge base cannot handle words that are not used the Weka parameter settings R = 0.2 (for rohand-coded in its rules and a new set of rules must bust ridge regression) and M = −1 (for unlimited be constructed for each new application domain. iterations). Dolan (1995) describes an algorithm for extracting metaphors from a dictionary. Some suggestive examples are given, but the algorithm is not evaluated in any systematic way. Mason (2004) takes a corpus-based approach to metaphor. His algorithm is based on a statistical approach to discovering the selectional restrictions of verbs. It then uses these restrictions to discover metaphorical mappings, such as, “Money flows like a liquid.” Although the system can discover some metaphorical mappings, it was not designed to distinguish literal and metaphorical usages of words. 3.2 Abstractness Changizi (2008) use</context>
</contexts>
<marker>Dolan, 1995</marker>
<rawString>William B. Dolan. 1995. Metaphor as an emergent property of machine-readable dictionaries. In Proceedings of the AAAI 1995 Spring Symposium Series: Representation and Acquisition of Lexical Knowledge: Polysemy, Ambiguity and Generativity, pages 27–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dedre Gentner</author>
<author>Brian F Bowdle</author>
<author>Phillip Wolff</author>
<author>Consuelo Boronat</author>
</authors>
<title>Metaphor is like analogy.</title>
<date>2001</date>
<booktitle>The analogical mind: Perspectivesfrom Cognitive Science,</booktitle>
<pages>199--253</pages>
<editor>In D. Gentner, K. J. Holyoak, and B. N. Kokinov, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1661" citStr="Gentner et al., 2001" startWordPosition="246" endWordPosition="249">f abstractness of the word’s context. We introduce an algorithm that uses this hypothesis to classify a word sense in a given context as either literal (denotative) or metaphorical (connotative). We evaluate this algorithm with a set of adjectivenoun phrases (e.g., in dark comedy, the adjective dark is used metaphorically; in dark hair, it is used literally) and with the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs. We achieve state-of-theart performance on both datasets. 1 Introduction Metaphor is a natural consequence of our ability to reason by analogy (Gentner et al., 2001). It is so common in our daily language that we rarely notice it (Lakoff and Johnson, 1980). Identifying metaphorical word usage is important for reasoning about the implications of text. Past work on the problem of distinguishing literal and metaphorical senses has approached it as a classical word sense disambiguation (WSD) task (Birke and Sarkar, 2006). Here, we take a different approach to the problem. Lakoff and Johnson (1980) argue that metaphor is a method for transferring knowledge from a concrete domain to an abstract domain. Therefore we hypothesize that the degree of abstractness in</context>
<context position="20110" citStr="Gentner et al., 2001" startWordPosition="3340" endWordPosition="3343"> other researchers can experiment with these paragidm words. The table may give some insight into the internal functioning of the algorithm, but the main output of the algorithm is the list of 114,501 words with abstractness ratings, not the list of paradigm words in Table 2. 3 Related Work Here we discuss related work on metaphor and then work on measuring abstractness. As far as we know, our approach is the first in computational linguistics to bring these two themes together, although the connection is well-known in cognitive linguistics (Lakoff and Johnson, 1980) and cognitive psychology (Gentner et al., 2001). 3.1 Metaphor The most closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb without additional training. hypernym hierarchy captur</context>
</contexts>
<marker>Gentner, Bowdle, Wolff, Boronat, 2001</marker>
<rawString>Dedre Gentner, Brian F. Bowdle, Phillip Wolff, and Consuelo Boronat. 2001. Metaphor is like analogy. In D. Gentner, K. J. Holyoak, and B. N. Kokinov, editors, The analogical mind: Perspectivesfrom Cognitive Science, pages 199–253. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Daisuke Kawahara</author>
</authors>
<title>Compilation of an idiom example database for supervised idiom identification.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>4</issue>
<contexts>
<context position="20763" citStr="Hashimoto and Kawahara (2009)" startWordPosition="3443" endWordPosition="3446">closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb without additional training. hypernym hierarchy captures the general–specific Hashimoto and Kawahara (2009) discuss work continuum, which might not be the same as the on a similar problem, distinguishing idiomatic us- abstract–concrete continuum. It would be interestage from literal usage. They also approach this as ing to see how much correspondence there is bea classical word sense disambiguation task. Idioms tween Changizi’s measure of abstractness and the are somewhat different from metaphors, in that the ratings in the MRC Psycholinguistic Database Mameaning of an idiom (e.g., kick the bucket) is often chine Usable Dictionary (Coltheart, 1981). Also, difficult to derive from the meanings of th</context>
</contexts>
<marker>Hashimoto, Kawahara, 2009</marker>
<rawString>Chikara Hashimoto and Daisuke Kawahara. 2009. Compilation of an idiom example database for supervised idiom identification. Language Resources and Evaluation, 43(4):355–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University Of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="1752" citStr="Lakoff and Johnson, 1980" startWordPosition="263" endWordPosition="266">is to classify a word sense in a given context as either literal (denotative) or metaphorical (connotative). We evaluate this algorithm with a set of adjectivenoun phrases (e.g., in dark comedy, the adjective dark is used metaphorically; in dark hair, it is used literally) and with the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs. We achieve state-of-theart performance on both datasets. 1 Introduction Metaphor is a natural consequence of our ability to reason by analogy (Gentner et al., 2001). It is so common in our daily language that we rarely notice it (Lakoff and Johnson, 1980). Identifying metaphorical word usage is important for reasoning about the implications of text. Past work on the problem of distinguishing literal and metaphorical senses has approached it as a classical word sense disambiguation (WSD) task (Birke and Sarkar, 2006). Here, we take a different approach to the problem. Lakoff and Johnson (1980) argue that metaphor is a method for transferring knowledge from a concrete domain to an abstract domain. Therefore we hypothesize that the degree of abstractness in a word’s context is correlated with the likelihood that the word is used metaphorically. T</context>
<context position="20062" citStr="Lakoff and Johnson, 1980" startWordPosition="3332" endWordPosition="3335">ords in the table. We include the table here so that other researchers can experiment with these paragidm words. The table may give some insight into the internal functioning of the algorithm, but the main output of the algorithm is the list of 114,501 words with abstractness ratings, not the list of paradigm words in Table 2. 3 Related Work Here we discuss related work on metaphor and then work on measuring abstractness. As far as we know, our approach is the first in computational linguistics to bring these two themes together, although the connection is well-known in cognitive linguistics (Lakoff and Johnson, 1980) and cognitive psychology (Gentner et al., 2001). 3.1 Metaphor The most closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb withou</context>
<context position="25791" citStr="Lakoff and Johnson, 1980" startWordPosition="4246" endWordPosition="4249">es of adjective-noun pairs and the abstractness rating of the noun. In this experiment, we used the abstractness rating of the noun (the context) to predict whether the adjective (the target) was used in a metaphorical or literal sense. Table 3 supports this idea, but it is easy to find counterexamples. Although dark mood is metaphorical, bad mood is literal. The difference is that dark has an abstractness rating of 0.43356 (relatively concrete), whereas bad has an abstractness rating of 0.63326 (relatively abstract). Metaphor results when a concrete word is imported into an abstract context (Lakoff and Johnson, 1980). Ideally, we should be comparing the abstractness of the target to the abstractness of the context. However, in our data, the target words are mostly concrete; thus we can focus on the context and ignore the target. We discuss this point further in Section 5. Five judges, undergraduate students in psychology, were asked to judge whether the use of the adjective is a denotation or a connotation. The instructions were as follows: Denotation is the most direct or specific meaning of a word or expression while connotation is the meaning suggested by the word that goes beyond its literal meaning. </context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University Of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<pages>240</pages>
<contexts>
<context position="9042" citStr="Landauer and Dumais, 1997" startWordPosition="1440" endWordPosition="1443">radigms of positive and negative semantic orientation: Positive paradigm words: good, nice, excellent, positive, fortunate, correct, and superior. Negative paradigm words: bad, nasty, poor, negative, unfortunate, wrong, and inferior. Likewise, here we calculate the abstractness of a given word by comparing it to twenty abstract words and twenty concrete words that are used as paradigms of abstractness and concreteness. Turney and Littman (2003) experimented with two measures of semantic similarity, pointwise mutual information (PMI) (Church and Hanks, 1989) and latent semantic analysis (LSA) (Landauer and Dumais, 1997). These measures take a pair of words as input and generate a numerical similarity rating as output. The semantic orientation of a given word is calculated as the sum of its similarity with the positive paradigm words minus the sum of its similarity with the negative paradigm words. Likewise, here we calculate the abstractness of a given word by the sum of its similarity with twenty abstract paradigm words minus the sum of its similarity with twenty concrete paradigm words. We then use a linear normalization to map the calculated abstractness value to range from 0 to 1. Our algorithm for calcu</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K. Landauer and Susan T. Dumais. 1997. A solution to Plato’s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge. Psychological Review, 104(2):211– 240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saskia Le Cessie</author>
<author>J C Van Houwelingen</author>
</authors>
<title>Ridge estimators in logistic regression.</title>
<date>1992</date>
<journal>Applied Statistics,</journal>
<volume>41</volume>
<issue>1</issue>
<marker>Le Cessie, Van Houwelingen, 1992</marker>
<rawString>Saskia Le Cessie and J.C. Van Houwelingen. 1992. Ridge estimators in logistic regression. Applied Statistics, 41(1):191–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Madrigal</author>
</authors>
<title>Why are spy researchers building a ‘Metaphor Program’? The Atlantic,</title>
<date>2011</date>
<contexts>
<context position="4851" citStr="Madrigal, 2011" startWordPosition="787" endWordPosition="788">val, Information Extraction, and pare our results with theirs. In particular, a sepaText Summarization, it follows that distinguishing rate model is learned for each individual verb. We literal and metaphorical senses is a problem for a achieve an average f-score of 63.9%, compared to wide variety of NLP tasks. The ability to recognize Birke and Sarkar’s (2006) 64.9%. metaphorical word usage is a core requirement in In the third experiment, we train the algorithm the Intelligence Advanced Research Projects Activ- on the twenty-five new verbs that were not used by ity (IARPA) Metaphor Program (Madrigal, 2011).1 Birke and Sarkar (2006) and then we test it on the Our approach to the problem of distinguishing lit- old verbs. That is, the algorithm is tested with verbs eral and metaphorical senses is based on an algo- that it has never seen before. The training verbs are rithm for calculating the degree of abstractness of merged to build a single model, instead of building words. For instance, plane in L is rated 0.36396 (rel- a separate model for each individual verb. In this atively concrete), whereas argument in M is rated experiment, the average f-score is 68.1%. 0.64617 (relatively abstract), whi</context>
</contexts>
<marker>Madrigal, 2011</marker>
<rawString>Alexis Madrigal. 2011. Why are spy researchers building a ‘Metaphor Program’? The Atlantic, May 25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>Computer understanding of conventional metaphoric language.</title>
<date>1992</date>
<journal>Cognitive Science,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="22531" citStr="Martin (1992)" startWordPosition="3730" endWordPosition="3731"> Hashimoto and sense is a hyponym of physical entity in the WordKawahara (2009), the core idea is to learn to clas- Net hypernym hierarchy; otherwise the concreteness sify word usage from similarity of context. Unlike is 0. We believe that, although physical entities are these approaches, our algorithm generalizes beyond concrete, so are redness and walking, which are not the specific semantic content of the context, paying hyponyms of physical entity. The category physical attention only to the degrees of abstractness of the entity only partially captures concreteness. context. 4 Experiments Martin (1992) presents a knowledge-based ap- In the following experiments, we use the abstractproach to interpreting metaphors. This approach re- ness ratings of Section 2.2 to generate features for quires complex hand-coded rules, which are specific supervised machine learning. The learning algoto a given domain (e.g., interpreting metaphorical rithm we apply is logistic regression (Le Cessie and questions from computer users, such as, “How can Van Houwelingen, 1992), as implemented in Weka I kill a process?”, in an online help system). The (Witten and Frank, 2005).10 In all experiments, we knowledge base</context>
</contexts>
<marker>Martin, 1992</marker>
<rawString>James H. Martin. 1992. Computer understanding of conventional metaphoric language. Cognitive Science, 16(2):233–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary Mason</author>
</authors>
<title>CorMet: A computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="23561" citStr="Mason (2004)" startWordPosition="3896" endWordPosition="3897"> such as, “How can Van Houwelingen, 1992), as implemented in Weka I kill a process?”, in an online help system). The (Witten and Frank, 2005).10 In all experiments, we knowledge base cannot handle words that are not used the Weka parameter settings R = 0.2 (for rohand-coded in its rules and a new set of rules must bust ridge regression) and M = −1 (for unlimited be constructed for each new application domain. iterations). Dolan (1995) describes an algorithm for extracting metaphors from a dictionary. Some suggestive examples are given, but the algorithm is not evaluated in any systematic way. Mason (2004) takes a corpus-based approach to metaphor. His algorithm is based on a statistical approach to discovering the selectional restrictions of verbs. It then uses these restrictions to discover metaphorical mappings, such as, “Money flows like a liquid.” Although the system can discover some metaphorical mappings, it was not designed to distinguish literal and metaphorical usages of words. 3.2 Abstractness Changizi (2008) uses the hypernym hierarchy in WordNet to calculate the abstractness of a word. A word near the top of the hierarchy is considered abstract and a word near the bottom is con685 </context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary Mason. 2004. CorMet: A computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of English.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="29762" citStr="Minnen et al., 2001" startWordPosition="4910" endWordPosition="4913">dioxide might be simultaneously recoverable through the use of powdered limestone, which tends to absorb the sulfur. N: He said that MMWEC will have to absorb only $4 million in additional annual costs now paid by the Vermont utilities. To generate feature vectors for the sentences, we first applied the OpenNLP part-of-speech tagger to the sentences.13 We then looked for each word in our list of 114,501 abstractness ratings (Section 2.2). If the word was not found in the list, we applied the Morpha morphological analyzer to identify the stem of the word (e.g., the stem of managing is manage) (Minnen et al., 2001).14 We then looked for the stem in our list. If it was still not found, we skipped it. For each sentence, we created a vector with five features: 1. the average abstractness ratings of all nouns, excluding proper nouns 2. the average abstractness ratings of all proper nouns 3. the average abstractness ratings of all verbs, excluding the target verb 4. the average abstractness ratings of all adjectives 5. the average abstractness ratings of all adverbs When there were no words for a given part of speech, we set the average to a default value of 0.5. Two examples of feature vectors follow, corre</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of English. Natural Language Engineering, 7(3):207–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="20492" citStr="Navigli, 2009" startWordPosition="3403" endWordPosition="3404">ow, our approach is the first in computational linguistics to bring these two themes together, although the connection is well-known in cognitive linguistics (Lakoff and Johnson, 1980) and cognitive psychology (Gentner et al., 2001). 3.1 Metaphor The most closely related work is Birke and Sarkar’s (2006) research on distinguishing literal and nonliteral usage of verbs. A later paper (Birke and Sarkar, 2007) provides more detail on their active learning system, briefly mentioned in the earlier paper. Birke and Sarkar (2006; 2007) treat the problem as a classical word sense disambiguation task (Navigli, 2009). A model is learned for each verb indepen684 dently from the other verbs. This approach cannot sidered concrete. It seems to us that the WordNet handle a new verb without additional training. hypernym hierarchy captures the general–specific Hashimoto and Kawahara (2009) discuss work continuum, which might not be the same as the on a similar problem, distinguishing idiomatic us- abstract–concrete continuum. It would be interestage from literal usage. They also approach this as ing to see how much correspondence there is bea classical word sense disambiguation task. Idioms tween Changizi’s meas</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yair Neuman</author>
<author>Ophir Nave</author>
</authors>
<title>Metaphor-based meaning excavation.</title>
<date>2009</date>
<journal>Information Sciences,</journal>
<volume>179</volume>
<pages>2728</pages>
<contexts>
<context position="40344" citStr="Neuman and Nave, 2009" startWordPosition="6669" endWordPosition="6672"> do not claim that abstractness is This is another worthwhile topic for future research. a complete solution to the problem, but it may be a Currently there is no algorithm that identifies valuable component in any practical system for prowhat kind of concepts and relations are grafted from cessing metaphorical text. the source domain to the target domain by metaphor- Acknowledgments ical inference. The algorithm presented in this pa- Part of the work of Yair Neuman, Dan Assaf, and per may be used within a constraints-based model Yohai Cohen has been supported by a grant from the of metaphor (Neuman and Nave, 2009) to address Israel Ministry of Defense. Thanks to the EMNLP this challenge. reviewers for their helpful comments. Recently there has been some interest in visual- References ness, picturability, and imagability, the degree to Julia Birke and Anoop Sarkar. 2006. A clustering apwhich a word is associated with visual imagery (De- proach for the nearly unsupervised recognition of nonschacht and Moens, 2007). Although Xing et al. literal language. In Proceedings of the 11th Confer(2010) use the term concreteness in their work, their ence of the European Chapter of the Association for research is co</context>
</contexts>
<marker>Neuman, Nave, 2009</marker>
<rawString>Yair Neuman and Ophir Nave. 2009. Metaphor-based meaning excavation. Information Sciences, 179:2719– 2728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malvina Nissim</author>
<author>Katja Markert</author>
</authors>
<title>Syntactic features and word similarity for supervised metonymy resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-03),</booktitle>
<pages>56--63</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="21535" citStr="Nissim and Markert (2003)" startWordPosition="3565" endWordPosition="3568">d be interestage from literal usage. They also approach this as ing to see how much correspondence there is bea classical word sense disambiguation task. Idioms tween Changizi’s measure of abstractness and the are somewhat different from metaphors, in that the ratings in the MRC Psycholinguistic Database Mameaning of an idiom (e.g., kick the bucket) is often chine Usable Dictionary (Coltheart, 1981). Also, difficult to derive from the meanings of the compo- note that adjectives and adverbs are outside of Wordnent words, unlike most metaphors. Net’s hypernym hierarchy, and thus cannot be rated Nissim and Markert (2003) use supervised learn- by Changizi’s algorithm. ing to distinguish metonymic usage from literal us- Xing et al. (2010) also use WordNet, but in a difage. They take a classical WSD approach, learn- ferent way. They define the concreteness of a word ing a separate model for each target word. As with sense (a WordNet synset) to be 1 if the given word Birke and Sarkar (2006; 2007) and Hashimoto and sense is a hyponym of physical entity in the WordKawahara (2009), the core idea is to learn to clas- Net hypernym hierarchy; otherwise the concreteness sify word usage from similarity of context. Unlike</context>
</contexts>
<marker>Nissim, Markert, 2003</marker>
<rawString>Malvina Nissim and Katja Markert. 2003. Syntactic features and word similarity for supervised metonymy resolution. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-03), pages 56–63, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Word sense discovery based on sense descriptor dissimilarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the Ninth Machine Translation Summit,</booktitle>
<pages>315--322</pages>
<marker>Rapp, 2003</marker>
<rawString>Reinhard Rapp. 2003. Word sense discovery based on sense descriptor dissimilarity. In Proceedings of the Ninth Machine Translation Summit, pages 315–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Anita Wong</author>
<author>Chung-Shu Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="11504" citStr="Salton et al., 1975" startWordPosition="1849" endWordPosition="1852"> LSA that we use here is similar to Rapp’s (2003) work. We modeled our similarity measure on Rapp’s due to the high score of 92.5% that he achieved on a set of 80 multiple-choice synonym questions from the Test of English as a Foreign Language (TOEFL). The core idea is to represent words with vectors and calculate the similarity of two words by the cosine of the angle between the two corresponding vectors. The values of the elements in the vectors are derived from the frequencies of the words in a large corpus of text. This general approach is known as a Vector Space Model (VSM) of semantics (Salton et al., 1975). We began with a corpus of 5×1010 words (280 gigabytes of plain text) gathered from university websites by a webcrawler.6 We then indexed this corpus with the Wumpus search engine (B¨uttcher and Clarke, 2005).7 We selected our vocabulary from the terms (words and phrases) in the WordNet lexicon.8 By querying Wumpus, we obtained the frequency of each WordNet term in our corpus. We selected all WordNet terms with a frequency of 100 or more in our corpus. This resulted in a set of 114,501 terms. Next we used Wumpus to search for up to 10,000 phrases per term, where a phrase consists of the given</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Gerard Salton, Anita Wong, and Chung-Shu Yang. 1975. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="8864" citStr="Turney and Littman (2003)" startWordPosition="1415" endWordPosition="1418">/solicitations metaphor.html. 2The labeled phrases are available from Yair Neuman. 3Available at http://www.cs.sfu.ca/ anoop/students/jbirke/. 681 tive words that are used as paradigms of positive and negative semantic orientation: Positive paradigm words: good, nice, excellent, positive, fortunate, correct, and superior. Negative paradigm words: bad, nasty, poor, negative, unfortunate, wrong, and inferior. Likewise, here we calculate the abstractness of a given word by comparing it to twenty abstract words and twenty concrete words that are used as paradigms of abstractness and concreteness. Turney and Littman (2003) experimented with two measures of semantic similarity, pointwise mutual information (PMI) (Church and Hanks, 1989) and latent semantic analysis (LSA) (Landauer and Dumais, 1997). These measures take a pair of words as input and generate a numerical similarity rating as output. The semantic orientation of a given word is calculated as the sum of its similarity with the positive paradigm words minus the sum of its similarity with the negative paradigm words. Likewise, here we calculate the abstractness of a given word by the sum of its similarity with twenty abstract paradigm words minus the su</context>
<context position="17257" citStr="Turney and Littman, 2003" startWordPosition="2877" endWordPosition="2880">paradigm words with the training set and evaluating them with the testing set, we then used them to assign abstractness ratings to every term in the matrix. The result of this is that we now have a set of 114,501 terms (words and phrases) with abstractness ratings ranging from 0 to 1.9 Based on the testing set performance, we estimate these 114,501 ratings would have a Pearson correlation of 0.81 with human ratings and an accuracy of 85% on binary (abstract or concrete) classification. We chose to limit the search to forty paradigm words based on our past experience with semantic orientation (Turney and Littman, 2003). To validate this choice, we allowed the algorithm to continue 9The 114,501 rated terms are available from Peter Turney. 683 Concrete Paradigm Words Abstract Paradigm Words Order Word Correlation Order Word Correlation 1 donut 0.4447 2 sense 0.6165 3 antlers 0.6582 4 indulgent 0.6973 5 aquarium 0.7150 6 bedevil 0.7383 7 nursemaid 0.7476 8 improbable 0.7590 9 pyrethrum 0.7658 10 purvey 0.7762 11 swallowwort 0.7815 12 pigheadedness 0.7884 13 strongbox 0.7920 14 ranging 0.7973 15 sixth-former 0.8009 16 quietus 0.8067 17 restharrow 0.8089 18 regularisation 0.8123 19 recorder 0.8148 20 creditably </context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>37</volume>
<pages>188</pages>
<contexts>
<context position="13480" citStr="Turney and Pantel, 2010" startWordPosition="2219" endWordPosition="2222">se r is the term corresponding to the i-th row in F and c is the term corresponding to the j-th column in F. Let c be marked left. Let fid be the cell in the i-th row and j-th column of F. The numerical value in the cell fid is the number of phrases found by Wumpus in which the center term was r and c was the unigram closest to r on the left side of r. That is, fid is the frequency with which r was found in the context c in our corpus. A new matrix X, with the same number of rows and columns as in F, was formed by calculating the Positive Pointwise Mutual Information (PPMI) of each cell in F (Turney and Pantel, 2010). The function of PPMI is to emphasize cells in which the frequency fid is statistically surprising, and hence particularly informative. This matrix was then smoothed with a truncated Singular Value Decomposition (SVD), which decomposes X into the product of three matrices UkEkVTk . Finally, the terms were represented by the matrix UkEk, which has 114,501 rows (one for each term) and k columns (one for each latent contextual factor). The semantic similarity of two terms is given by the cosine of the two corresponding rows in UkEk. For more detail, see Turney and Pantel (2010). There are two pa</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141– 188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="23090" citStr="Witten and Frank, 2005" startWordPosition="3814" endWordPosition="3817">ally captures concreteness. context. 4 Experiments Martin (1992) presents a knowledge-based ap- In the following experiments, we use the abstractproach to interpreting metaphors. This approach re- ness ratings of Section 2.2 to generate features for quires complex hand-coded rules, which are specific supervised machine learning. The learning algoto a given domain (e.g., interpreting metaphorical rithm we apply is logistic regression (Le Cessie and questions from computer users, such as, “How can Van Houwelingen, 1992), as implemented in Weka I kill a process?”, in an online help system). The (Witten and Frank, 2005).10 In all experiments, we knowledge base cannot handle words that are not used the Weka parameter settings R = 0.2 (for rohand-coded in its rules and a new set of rules must bust ridge regression) and M = −1 (for unlimited be constructed for each new application domain. iterations). Dolan (1995) describes an algorithm for extracting metaphors from a dictionary. Some suggestive examples are given, but the algorithm is not evaluated in any systematic way. Mason (2004) takes a corpus-based approach to metaphor. His algorithm is based on a statistical approach to discovering the selectional restr</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Xing</author>
<author>Yi Zhang</author>
<author>Mei Han</author>
</authors>
<title>Query difficulty prediction for contextual image retrieval.</title>
<date>2010</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<volume>5993</volume>
<pages>581--585</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="21653" citStr="Xing et al. (2010)" startWordPosition="3583" endWordPosition="3586">d sense disambiguation task. Idioms tween Changizi’s measure of abstractness and the are somewhat different from metaphors, in that the ratings in the MRC Psycholinguistic Database Mameaning of an idiom (e.g., kick the bucket) is often chine Usable Dictionary (Coltheart, 1981). Also, difficult to derive from the meanings of the compo- note that adjectives and adverbs are outside of Wordnent words, unlike most metaphors. Net’s hypernym hierarchy, and thus cannot be rated Nissim and Markert (2003) use supervised learn- by Changizi’s algorithm. ing to distinguish metonymic usage from literal us- Xing et al. (2010) also use WordNet, but in a difage. They take a classical WSD approach, learn- ferent way. They define the concreteness of a word ing a separate model for each target word. As with sense (a WordNet synset) to be 1 if the given word Birke and Sarkar (2006; 2007) and Hashimoto and sense is a hyponym of physical entity in the WordKawahara (2009), the core idea is to learn to clas- Net hypernym hierarchy; otherwise the concreteness sify word usage from similarity of context. Unlike is 0. We believe that, although physical entities are these approaches, our algorithm generalizes beyond concrete, so</context>
</contexts>
<marker>Xing, Zhang, Han, 2010</marker>
<rawString>Xing Xing, Yi Zhang, and Mei Han. 2010. Query difficulty prediction for contextual image retrieval. In Advances in Information Retrieval, volume 5993 of Lecture Notes in Computer Science, pages 581–585. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>