<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000052">
<title confidence="0.894763">
Automatic Detection of Grammar Elements that Decrease Readability
</title>
<author confidence="0.987834">
Masatoshi Tsuchiya and Satoshi Sato
</author>
<affiliation confidence="0.9956935">
Department of Intelligence Science and Technology,
Graduate School of Informatics, Kyoto University
</affiliation>
<email confidence="0.995688">
tsuchiya@pine.kuee.kyoto-u.ac.jp, sato@i.kyoto-u.ac.jp
</email>
<sectionHeader confidence="0.998588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999948363636364">
This paper proposes an automatic method
of detecting grammar elements that de-
crease readability in a Japanese sentence.
The method consists of two components:
(1) the check list of the grammar elements
that should be detected; and (2) the de-
tector, which is a search program of the
grammar elements from a sentence. By
defining a readability level for every gram-
mar element, we can find which part of the
sentence is difficult to read.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988935483871">
We always prefer readable texts to unreadable texts.
The texts that transmit crucial information, such as
instructions of strong medicines, must be completely
readable. When texts are unreadable, we should
rewrite them to improve readability.
In English, measuring readability as reading age
is well studied (Johnson, 1978). The reading age
is the chronological age of a reader who could just
understand the text. The value is usually calculated
from the sentence length and the number of sylla-
bles. From this value, we find whether a text is read-
able or not for readers of a specific age; however, we
do not find which part we should rewrite to improve
readability when the text is unreadable.
The goal of our study is to present tools that help
rewriting work of improving readability in Japanese.
The first tool is to help detect the sentence frag-
ments (words and phrases) that should be rewrit-
ten; in other words, it is a checker of “hard-to-read”
words and phrases in a sentence. Such a checker can
be realized with two components: the check list and
its detector. The check list provides check items and
their readability levels. The detector is a program
that searches the check items in a sentence. From
the detected items and their readability levels, we
can identify which part of the sentence is difficult to
read.
We are currently working on three aspects con-
cerned with readability of Japanese: kanji charac-
ters, vocabulary, and grammar. In this paper, we re-
ports the readability checker for the grammar aspect.
</bodyText>
<sectionHeader confidence="0.914484" genericHeader="method">
2 The check list of grammar elements
</sectionHeader>
<bodyText confidence="0.99849175">
The first component of the readability checker is
the check list; in this list, we should define every
Japanese grammar element and its readability level.
A grammar element is a grammatical phenomenon
concerned with readability, and its readability level
indicates the familiarity of the grammar element.
In Japanese, grammar elements are classified into
four categories.
</bodyText>
<listItem confidence="0.996299636363636">
1. Conjugation: the form of a verb or an adjective
changes appropriately to the proceed word.
2. Functional word: postpositional particles work
as case makers; auxiliary verbs represent tense
and modality.
3. Sentential pattern: negation, passive form, and
question are represented as special sentence
patterns.
4. Functional phrase: there are idiomatic phrases
works functionally, like “not only ... but also
...” in English.
</listItem>
<bodyText confidence="0.999614157894737">
A grammar section exists in a part of the Japanese
Language Proficiency Test, which is used to measure
and certify the Japanese language ability of a person
who is a non-Japanese. There are four levels in this
test; Level 4 is the elementary level, and Level 1 is
the advanced level.
Test Content Specifications (TCS) (Foundation
and Association of International Education, 1994) is
intended to serve as a reference guide in question
compilation of the Japanese Language Proficiency
Test. This book describes the list of grammar ele-
ments, which can be tested at each level. These lists
fit our purpose: they can be used as the check list for
the readability checker.
TCS describes grammar elements in two ways. In
the first way, a grammar element is described as a
3-tuple: its name, its patterns, and its example sen-
tences. The following 3-tuple is an example of the
grammar element that belongs to Level 4.
</bodyText>
<tableCaption confidence="0.999502">
Table 1: The size of the check list
</tableCaption>
<table confidence="0.827724166666667">
Level # of rules
1 134
2 322
3 97
4 95
Total 648
</table>
<bodyText confidence="0.986304714285714">
to the Japanese Language Proficiency Test. An ex-
ample pair consists of an example sentence and an
instance of the grammar element. It is an implicit
description of the pattern detecting the grammar el-
ement. For example, the check item for ‘Adjective
(predicative, negative, polite)’ is shown as follows,
Level 4
</bodyText>
<figure confidence="0.673047444444445">
Name Adjective (predicative, negative, polite)
Test Pairs
kono heya ha hiroku nai desu.
daimeishi Sentence,
Name (Pronoun) (This room is not large.)
kore sore
Patterns (this), (that)
kore ha hon desu.
Examples (This is a book.),
</figure>
<figureCaption confidence="0.414808">
sore ha n¯oto desu.
</figureCaption>
<bodyText confidence="0.95191825">
(That is a note.)
Grammar elements of Level 3 and Level 4 are con-
jugations, functional words and sentential patterns
that are defined in this first way. In the second way,
a grammar element is described as a pair of its pat-
terns and its examples. The following pair is an ex-
ample of the grammar element that belongs to Level
2.
</bodyText>
<equation confidence="0.5605235">
ta tokoro
Patterns (when ...)
</equation>
<bodyText confidence="0.538291">
sensei no otaku he ukagatta tokoro
</bodyText>
<subsectionHeader confidence="0.468248">
Examples
</subsectionHeader>
<bodyText confidence="0.923999923076923">
(When visiting the teacher’s home)
Grammar elements of Level 1 and Level 2 are func-
tional phrases that are defined in this second way.
We decided to use this example-based definition
for the check list, because the check list should be in-
dependent from the implementation of the detector.
If the check list depends on detector’s implementa-
tion, the change of implementation requires change
of the check list.
Each item of the check list is defined as a 3-tuple:
(1) readability level, (2) name, and (3) a list of exam-
ple pairs. There are four readability levels according
hiroku nai desu
Instance,
(is not large)
The instance /hirokunaidesu/ consists
of three morphemes: (1) /hiroku/, the adjective
means ‘large’ in renyo form, (2) /nai/, the ad-
jective means ‘not’ in root form, and (3) /desu/,
the auxiliary verb ends a sentence politely. So, this
test pair represents implicitly that the grammar el-
ement can be detected by a pattern “Adjective(in
renyo form) + nai + desu”.
All example sentences are originated from TCS.
Some check items have several test pairs. Table 1
shows the size of the check list.
</bodyText>
<sectionHeader confidence="0.990563" genericHeader="method">
3 The grammar elements detector
</sectionHeader>
<bodyText confidence="0.9999684">
The check list must be converted into an explicit
rule set, because each item of the check list shows
no explicit description of its grammar element, only
shows one or more pairs of an example sentence and
an instance.
</bodyText>
<subsectionHeader confidence="0.990046">
3.1 The explicit rule set
</subsectionHeader>
<bodyText confidence="0.995966">
Four categories of grammar elements leads that each
rule of the explicit rule set may take three different
types.
</bodyText>
<listItem confidence="0.9948118">
• Type M: A rule detecting a sequence of mor-
phemes
• Type B: A rule detecting a bunsetsu.
• Type R: A rule detecting a modifier-modifee re-
lationship.
</listItem>
<bodyText confidence="0.987535866666667">
Type M is the basic type of them, because almost of
grammar elements can be detected by morphologi-
cal sequential patterns.
Conversion from a check item to a Type M rule
is almost automatic. This conversion process con-
sists of three steps. First, an example sentence of
the check item is analyzed morphologically and syn-
tactically. Second, a sentence fragment covered by
the target grammar element is extracted based on
signs and fixed strings included in the name of the
check item. Third, a part of a generated rule is re-
laxed based on part-of-speech tags. For example,
the check item of the grammar element whose name
is “Adjective (predicative, negative, polite)” is con-
verted to the following rule.
</bodyText>
<equation confidence="0.994565875">
np( 4, ’Adjective
(predicative,negative,polite)’,
Dm({ H1=&gt;’Adjective’,
K2=&gt;’Basic Renyou Form’ },
{ G=&gt;’ /nai/’,
H1=&gt;’Postfix’, K2=&gt;’Root Form’ },
{ G=&gt;’ /desu/’,
H1=&gt;’Auxiliary Verb’ }) );
</equation>
<bodyText confidence="0.999961769230769">
The function np() makes the declaration of the
rule, and the function Dm() describes a morphologi-
cal sequential pattern which matches the target. This
example means that this grammar element belongs
to Level 4, and can be detected by the pattern which
consists of three morphemes.
Type B rules are used to describe grammar ele-
ments such as conjugations including no functional
words. They are not generated automatically; they
are converted by hand from type M rules that are
generated automatically. For example, the rule de-
tecting the grammar element whose name is “Adjec-
tive in Root Form” is defined as follows.
</bodyText>
<equation confidence="0.841223">
np( 4, ’Adjective in Root Form’,
Db( { H1=&gt;’Adjective’,
K2=&gt;’Root Form’ } ) );
</equation>
<bodyText confidence="0.9992482">
The function Db() describes a pattern which
matches a bunsetsu which consists of specified mor-
phemes. This example means that this grammar el-
ement belongs to Level 3, and shows the detection
pattern of this grammar element.
</bodyText>
<figure confidence="0.349726">
Sentence + Grammar Elements
</figure>
<figureCaption confidence="0.999773">
Figure 1: System structure
</figureCaption>
<bodyText confidence="0.999844545454545">
Type R rules are used to describe grammar ele-
ments that include modifier-modifee relationships.
In the case of the grammar element whose name is
“Verb Modified by Adjective”, it includes a structure
that an adjective modifies a verb. It is impossible
to detect this grammar element by a morphological
continuous pattern, because any bunsetsus can be in-
serted between the adjective and the verb. For such a
grammar element, we introduce the function Dk()
that takes two arguments: the former is a modifier
and the latter is its modifee.
</bodyText>
<table confidence="0.22706525">
np( 4, ’Verb Modified by Adjective’,
Dk( Db({ H1=&gt;’Adjective’,
K2=&gt;’Basic Renyou Form’ }),
Dm({ H1=&gt;’Verb’ }) ) );
</table>
<subsectionHeader confidence="0.999482">
3.2 The architecture of the detector
</subsectionHeader>
<bodyText confidence="0.981634466666667">
The architecture of the detector is shown in Figure 1.
The detector uses a morphological analyzer, Juman,
and a syntactic analyzer, KNP (Kurohashi and Na-
gao, 1994). The rule set is converted into the format
that KNP can read and it is added to the standard rule
set of KNP. This addition enables KNP to detect can-
didates of grammar elements. The ‘Detection’ part
selects final results from these candidates based on
preference information given by the rule set.
Figure 2 shows grammar elements detected by our
chizu ha oroka, ryakuzu
detector from the sentence “
sae mo kubarare nakatta.
” which means “Neither a
map nor a rough map was not distributed.”
</bodyText>
<sectionHeader confidence="0.998641" genericHeader="conclusions">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999617">
We conducted two experiments, in order to check
the performance of our detector.
</bodyText>
<figure confidence="0.932304142857143">
Loaded
Detection
Syntactic Analysis
+Detection against
morphmes and
bunsetsues
Detection against
modifier-modifee
relationships
+ Lanking
Converted Automatically
+ Modified by Hand
Rule Set KNP Rule
Converted
Automatically
KNP
Sentence
Juman
Morphological
Analysis
Check List
</figure>
<table confidence="0.958780411764706">
Fragment Name Level
chizu - -
(a map) ha oroka 1
ha oroka (neither ...) 4
(neither) (comma) -
(,) - 2
ryakuzu sae 4
(a rough map) (even ...) 3
sae ! (huku postpositional particle means ‘nor’) 4
(even) reru 4
mo (passive verb phrase)
(nor) nai
kubarare (predicative adjective means ‘not’)
(distributed) (period)
nakatta
(was not)
(.)
</table>
<figureCaption confidence="0.989313">
Figure 2: Automatically detected grammar elements
</figureCaption>
<bodyText confidence="0.999942357142857">
The first test is a closed test, where we examine
whether grammar elements in example sentences of
TCS are detected correctly. TCS gives 840 example
sentences, and there are 802 sentences from which
their grammar elements are detected correctly. From
the rest 38 sentences, our detector failed to detect
the right grammar element. This result shows that
our program achieves the sufficient recall 95% in the
closed test. Almost of these errors are caused failure
of morphological analysis.
The second test is an open test, where we examine
whether grammar elements in example sentences of
the textbook, which is written for learners preparing
for the Japanese Language Proficiency Test (Tomo-
matsu et al., 1996), are detected correctly. The text-
book gives 1110 example sentences, and there are
680 sentences from which their grammar elements
are detected correctly. Wrong grammar elements
are detected from 71 sentences, and no grammar el-
ements are detected from the rest 359 sentences. So,
the recall of automatic detection of grammar ele-
ments is 61%, and the precision is 90%. The ma-
jor reason of these failures is strictness of several
rules; several rules that are generated from example
pairs automatically are overfitting to example pairs
so that they cannot detect variations in the textbook.
We think that relaxation of such rules will eliminate
these failures.
</bodyText>
<sectionHeader confidence="0.999277" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988965461538462">
The Japan Foundation and Japan Association of Interna-
tional Education. 1994. Japanese Language Profi-
ciency Test: Test content Specifications (Revised Edi-
tion). Bonjin-sha Co.
Keith Johnson. 1978. Readability. http://www.
timetabler.com/readable.pdf.
Sadao Kurohashi and Makoto Nagao. 1994. A syntactic
analysis method of long Japanese sentences based on
the detection of conjunctive structures. Computational
Linguistics, 20(4).
Etsuko Tomomatsu, Jun Miyamoto, and Masako Waguri.
1996. Donna-toki Dou-tsukau Nihongo Hyougen
Bunkei 500. ALC Co.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974137">
<title confidence="0.999868">Automatic Detection of Grammar Elements that Decrease Readability</title>
<author confidence="0.999941">Tsuchiya Sato</author>
<affiliation confidence="0.998891">Department of Intelligence Science and Technology, Graduate School of Informatics, Kyoto University</affiliation>
<abstract confidence="0.997595">This paper proposes an automatic method of detecting grammar elements that decrease readability in a Japanese sentence. The method consists of two components: (1) the check list of the grammar elements that should be detected; and (2) the detector, which is a search program of the grammar elements from a sentence. By defining a readability level for every grammar element, we can find which part of the sentence is difficult to read.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>The Japan Foundation and Japan Association of International Education.</title>
<date>1994</date>
<marker>1994</marker>
<rawString>The Japan Foundation and Japan Association of International Education. 1994. Japanese Language Proficiency Test: Test content Specifications (Revised Edition). Bonjin-sha Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Johnson</author>
</authors>
<date>1978</date>
<note>Readability. http://www. timetabler.com/readable.pdf.</note>
<contexts>
<context position="1040" citStr="Johnson, 1978" startWordPosition="150" endWordPosition="151">1) the check list of the grammar elements that should be detected; and (2) the detector, which is a search program of the grammar elements from a sentence. By defining a readability level for every grammar element, we can find which part of the sentence is difficult to read. 1 Introduction We always prefer readable texts to unreadable texts. The texts that transmit crucial information, such as instructions of strong medicines, must be completely readable. When texts are unreadable, we should rewrite them to improve readability. In English, measuring readability as reading age is well studied (Johnson, 1978). The reading age is the chronological age of a reader who could just understand the text. The value is usually calculated from the sentence length and the number of syllables. From this value, we find whether a text is readable or not for readers of a specific age; however, we do not find which part we should rewrite to improve readability when the text is unreadable. The goal of our study is to present tools that help rewriting work of improving readability in Japanese. The first tool is to help detect the sentence fragments (words and phrases) that should be rewritten; in other words, it is</context>
</contexts>
<marker>Johnson, 1978</marker>
<rawString>Keith Johnson. 1978. Readability. http://www. timetabler.com/readable.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="9401" citStr="Kurohashi and Nagao, 1994" startWordPosition="1553" endWordPosition="1557"> a verb. It is impossible to detect this grammar element by a morphological continuous pattern, because any bunsetsus can be inserted between the adjective and the verb. For such a grammar element, we introduce the function Dk() that takes two arguments: the former is a modifier and the latter is its modifee. np( 4, ’Verb Modified by Adjective’, Dk( Db({ H1=&gt;’Adjective’, K2=&gt;’Basic Renyou Form’ }), Dm({ H1=&gt;’Verb’ }) ) ); 3.2 The architecture of the detector The architecture of the detector is shown in Figure 1. The detector uses a morphological analyzer, Juman, and a syntactic analyzer, KNP (Kurohashi and Nagao, 1994). The rule set is converted into the format that KNP can read and it is added to the standard rule set of KNP. This addition enables KNP to detect candidates of grammar elements. The ‘Detection’ part selects final results from these candidates based on preference information given by the rule set. Figure 2 shows grammar elements detected by our chizu ha oroka, ryakuzu detector from the sentence “ sae mo kubarare nakatta. ” which means “Neither a map nor a rough map was not distributed.” 4 Experiment We conducted two experiments, in order to check the performance of our detector. Loaded Detecti</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures. Computational Linguistics, 20(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Etsuko Tomomatsu</author>
<author>Jun Miyamoto</author>
<author>Masako Waguri</author>
</authors>
<title>Donna-toki Dou-tsukau Nihongo Hyougen Bunkei 500.</title>
<date>1996</date>
<publisher>ALC Co.</publisher>
<contexts>
<context position="11356" citStr="Tomomatsu et al., 1996" startWordPosition="1867" endWordPosition="1871">entences of TCS are detected correctly. TCS gives 840 example sentences, and there are 802 sentences from which their grammar elements are detected correctly. From the rest 38 sentences, our detector failed to detect the right grammar element. This result shows that our program achieves the sufficient recall 95% in the closed test. Almost of these errors are caused failure of morphological analysis. The second test is an open test, where we examine whether grammar elements in example sentences of the textbook, which is written for learners preparing for the Japanese Language Proficiency Test (Tomomatsu et al., 1996), are detected correctly. The textbook gives 1110 example sentences, and there are 680 sentences from which their grammar elements are detected correctly. Wrong grammar elements are detected from 71 sentences, and no grammar elements are detected from the rest 359 sentences. So, the recall of automatic detection of grammar elements is 61%, and the precision is 90%. The major reason of these failures is strictness of several rules; several rules that are generated from example pairs automatically are overfitting to example pairs so that they cannot detect variations in the textbook. We think th</context>
</contexts>
<marker>Tomomatsu, Miyamoto, Waguri, 1996</marker>
<rawString>Etsuko Tomomatsu, Jun Miyamoto, and Masako Waguri. 1996. Donna-toki Dou-tsukau Nihongo Hyougen Bunkei 500. ALC Co.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>