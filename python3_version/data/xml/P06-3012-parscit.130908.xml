<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000107">
<title confidence="0.995794">
Focus to Emphasize Tone Structures for Prosodic Analysis in Spoken
Language Generation
</title>
<author confidence="0.994415">
Lalita Narupiyakul
</author>
<affiliation confidence="0.998218">
Faculty of Computer Science, Dalhousie University
6050 University Avenue, Halifax, Nova Scotia, Canada B3H 1W5
</affiliation>
<address confidence="0.761401">
Tel. +1-902-494-6441, Fax. +1-902-494-3962
</address>
<email confidence="0.995425">
lalita@cs.dal.ca
</email>
<sectionHeader confidence="0.993775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999990705882353">
We analyze the concept of focus in speech
and the relationship between focus and
speech acts for prosodic generation. We
determine how the speaker’s utterances are
influenced by speaker’s intention. The re-
lationship between speech acts and focus
information is used to define which parts
of the sentence serve as the focus parts.
We propose the Focus to Emphasize Tones
(FET) structure to analyze the focus com-
ponents. We also design the FET grammar
to analyze the intonation patterns and pro-
duce tone marks as a result of our anal-
ysis. We present a proof-of-the-concept
working example to validate our proposal.
More comprehensive evaluations are part
of our current work.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999995092592593">
A speaker’s utterance may convey different mean-
ing to a hearer. Such ambiguities can be resolved
by emphasizing accents in different positions. Fo-
cus information is needed to select correct posi-
tions for accent information. To determine fo-
cus information, a speaker’s intentions must be
revealed. We apply speech act theory to written
sentences, our input, to determine a speaker’s in-
tention. Subsequently our system will produce a
speaker utterance, the result of analysis.
Several research publications, such as (Steed-
man and Prevost, 1994) and (Klein, 2000), ex-
plore prosodic analysis for spoken language gen-
eration (SLG). Klein (2000) designs constraints
for prosodic structures in the HPSG framework.
His approach is based on an isomorphism of
syntactic and prosodic trees. This approach
is heavily syntax-driven and involves making
prosodic trees by manipulation of the syntactic
trees. This approach results in increased complex-
ity since the type hierarchy of phrases must cross-
classify prosodic phrases under syntactic phrases.
Haji-Abdolhosseini (2003) extended Klein’s ap-
proach. Rather than referring to syntax, Haji-
Abdolhosseini sets the information domain to in-
teract between the syntactic-semantic domain and
the prosodic domain. His work reduces the com-
plexity of type hierarchies and constraints which
are not related to the syntactic structure. He de-
signs the information structure and defines con-
straints for the HPSG framework. However his
work limits the number of tone selections because
he only defines two tone marks: rise-fall-rise and
fall to annotate a sentence.
Our work is inspired by Haji-Abdolhosseini’s
work. We design the focus structure for spo-
ken language generation. Based on the focus the-
ory (Von Heusinger, 1999), the focus part identi-
fies what part of the sentence can be marked with
the strong accent or emphasized by a high tone.
By analyzing speech acts, we can understand how
speech with prosody can convey distinct speaker
intentions to a hearer. In the next section, we
present an overview of our FET (Focus to Empha-
size Tone) system and its processes. We will ex-
plain how to analyze focus information, design the
FET structure, and find the relationships of focus
with speech acts to prosodic marks in section 3.
We implement our FET grammar for the Linguis-
tic Knowledge Base (LKB) system (Copestake,
2002), generate a set of focus words, explain the
FET environment, and show an example in sec-
tion 4. In the last section, we conclude the current
state of our work and the future work.
</bodyText>
<page confidence="0.994376">
67
</page>
<note confidence="0.823756">
Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 67–72,
Sydney, July 2006. c�2006 Association for Computational Linguistics
2 Overview of FET System for Prosodic
Analysis in SLG
</note>
<bodyText confidence="0.9988815">
Our system generates the prosodic structure de-
pending on the focus analysis. We use this
prosodic structure to modify synthetic speech for
SLG. Our FET structure is constrained by the
speaker’s intention. To define prosody, we ex-
plore the relationships of focus and speech acts
from various sentence types. The diagram of our
FET system is shown in figure 1 and we present
an overview of the FET system based on the LKB
system below.
</bodyText>
<figureCaption confidence="0.999645">
Figure 1: A diagram of the FET system
</figureCaption>
<bodyText confidence="0.99998328">
Our input is a sentence and its focus criterion
obtained from a user. In figure 1, the example sen-
tence is “Kim bought a flower” and the focus cri-
terion is G (see table 2). Our system is composed
of four main steps.
The first step is preprocessing. The LKB
system with the English Resource Grammar
(ERG) (Copestake, 2002) parses a sentence. The
LKB system analyzes the syntactic and semantic
structures and generates the Minimal Recursive
Semantic (MRS) (Copestake et al., 1995) repre-
sentation. This step occurs before invoking the
FET system.
In the second step, we scan the MRS struc-
ture and collect any components and their relations
among them obtained from the preprocessing step.
We select only required information, such as sen-
tence mood, from the MRS representation, assign
a speech act code referring to a main verb of a sen-
tence, and obtain from the MRS structure a set of
focus words. These focus words are an input for
the focus information analysis in the FET system.
The third step is the FET analysis. This step
generates the prosodic components inside the FET
structure. Using our FET grammar, we input the
focus words into the LKB system with the FET en-
vironment. This environment consists of the FET
type hierarchy, constraints, rules, and structures
including the focus and prosodic features. Since
the LKB system with FET environment can an-
alyze the focus relations corresponding to speech
acts and sentence moods, the system completes the
FET structure by generating a set of appropriate
prosodic structures containing prosodic marks as
a result.
The last step is the postprocessing process. We
extract words and their prosodic marks as Tone
and Break Index (ToBI) representations (Silver-
man et al., 1992) from the FET structure. The ex-
tracting system processes the FET structure, ex-
tracts only our required prosodic fields. These
fields are a set of words and their tone marks for a
sentence. We use the set of words with tone marks
to modify synthetic speech, which is generated by
speech synthesis. We use the PRAAT (Boersma
and Weenink, 2005) to modify the prosody of the
synthetic speech for a sentence. Our output is an
audio file of the sentence with modified prosody.
Modifying prosody follows the tone marks which
are analyzed by the FET system.
</bodyText>
<sectionHeader confidence="0.994484" genericHeader="method">
3 FET Analysis
</sectionHeader>
<bodyText confidence="0.999493571428572">
We describe our concept of the FET analysis (see
step 3, figure 1). We determine how the speaker’s
utterances are influenced by a speaker’s intention.
Focus information can be used to indicate how to
appropriately mark a part of a sentence to con-
vey the speaker’s intention. Focus can scope the
content in a sentence to which a speaker wants
the listener to pay attention. We also consider
speech acts which involve a speaker’s intention
and speaker’s utterance. We analyze the relation-
ships of focus parts with speech acts to tone marks.
We define the intonation patterns depending on
particular focus parts and speech acts. Our FET
analysis obtains syntactic and semantic contents
from the preprocessing process. We employ the
LKB system to parse a sentence. The LKB system
is an HPSG parser. A particular grammar, used
for LKB system, is called ERG containing more
than 10,000 lexemes. The LKB system generates
the semantic information which is represented by
MRS representation.
</bodyText>
<figure confidence="0.99732041025641">
Step 1
Step 2
Step 4
Step 3
FET structure
with prosodic
marks
Transforming MRS to Focus words
FET structure with prosodic marks
Input: “Kim bought a flower”
LKB system with ERG
MRS representation of
“Kim bought a flower”
LKB with FET Analysis
Focus Words
Focus Words
Extracting the
tone marks
III. Postprocessing
I. Prepocessing
II. FET System
Words +
Tone Marks
FET Envoronment
- FET typed hierarchy - FET structure
-FET constraints -FET rules
The relationship of focus with speech acts
to prosody
- Scan the MRS representation
- Keep any relations of each components
- Transform Structure
- Create a set focus words for a sentence
Speech
Synthesis &amp;
Prosodic
Modification
Modified Synthetic
Speech of
“Kim bought a flower”
</figure>
<page confidence="0.98156">
68
</page>
<subsectionHeader confidence="0.985371">
3.1 FET Constraints
</subsectionHeader>
<bodyText confidence="0.997025333333333">
Our FET analysis uses a constraint-based ap-
proach. We find what part (actor, act, actee or
their combinations) must be in the focus from the
the MRS structure. If the focus is marked at a
position in a sentence then the speaker wants the
hearer to recognize the content at that position in
the sentence. For example, the speaker utters the
sentence “Kim bought a flower” by emphasizing
at the different positions in the sentence as shown
table 1. Then we transform the MRS structures to
our FET content structure which is represented by
a set of focus words. This structure contains “ac-
tor” (a person or a thing that acts something in a
sentence), “act” (an activity in that sentence), and
“actee” (the response of the activity) parts.
</bodyText>
<tableCaption confidence="0.996009">
Table 1: The different focuses in the sentence
</tableCaption>
<bodyText confidence="0.991263470588235">
Focus Speaker wants to focus at ...
[KIM]F bought a flower. (Who bought a flower?)
Kim bought [a FLOWER]F . (What did Kim buy?)
Kim [BOUGHT a flower]F . (What did Kim do?)
Considering a focus part, our focus model will
acknowledge two focus types: w-focus, and s-
focus. The w-focus represents wide focus, which
covers a phrase or a word. The s-focus represents
single focus, which is placed on a word in the sen-
tence. We assign the actor and actee parts as single
or wide focus while the act part is only an s-focus.
Normally, the focus does not cover only the act
part. If the focus covers the act part, then the focus
must cover at least one of the related parts (actor
or actee). Therefore, we set the focus types fol-
lowing all situations that occur and call the focus
criteria. Eight focus criteria are shown in table 2.
</bodyText>
<tableCaption confidence="0.994096">
Table 2: The focus parts and the focus types
</tableCaption>
<table confidence="0.997663454545455">
No. Focus Parts Focus Types
A actor+act+actee {w-focus(actor),s-focus(act),w-
focus(actee)} or undefined
B actor+act {w-focus(actor),s-focus(act)}
C actor+actee {w-focus(actor),s-focus(actee)}
or {w-focus(actee),s-focus(actor)}
D actor w-focus(actor) or s-focus(actor)
E act+actee {s-focus(act),w-focus(actee)}
F act s-focus(act)
G actee w-focus(actee) or s-focus(actee)
H 0 undefined
</table>
<bodyText confidence="0.906904833333333">
We define constraints to select the focus types
following the different situations. We categorize
the conditions for focus types to five cases. These
conditions cover all possible situations. These sit-
uations define the focus based on the focus parts
for most simple sentences. We illustrate the at-
tribute value matrix (AVM) structure to represent
these situations in figure 2.
(a) An s-focus of the actor or actee parts. The
last node in the list of objects is defined as
the focus position to emphasize tone (FET-
obj), see figure 2(a).
</bodyText>
<listItem confidence="0.882413736842105">
(b) A w-focus at the actor or actee parts. The list
of objects is the FET-obj in the sentence as
shown in figure 2(b).
(c) A w-focus at actor or actee parts contain-
ing the multiple lists of objects. The lists are
merged together to be the FET-obj as shown
in figure 2(c).
(d) An s-focus at actor or actee parts containing
the multiple lists of objects. If the focus type
is an s-focus and there are m sets of lists of
objects (multiple lists of objects), then these
lists of objects can be split into the s-focus of
each list of objects, see figure 2(d).
(e) A focus on the act part. Two cases of defining
the focus types are shown in figure 2(e). The
first case, the s-focus marks the act part while
the w-focus marks the actee part. The second
case, the s-focus marks the act part and the
w-focus marks at the actor part.
</listItem>
<equation confidence="0.979842714285714">
make s −focus → focus− struc &amp; make _ w focus → focus struc &amp;
_ − −
⎡ Focus Type w focus
− − ⎤⎢ ⎥
focus−
, , ,
a
2an &gt;&gt;J
2
list
(b)
→ focus −struc &amp;
⎡ Focus Type w focus
− − ⎤
⎢ ⎥
list focus
− &lt;[a1,a 2,K, an] ,.. ,[m„m 2,K, mn]&gt; ⎥
⎣ ⎢FET obj
− &lt;a„a 2,K, an ,..., m„m2, K ,mn &gt;
(c)
split list
_
&amp; focus struc
− &amp;
⎤ focus
,a2,K,an&gt;...−focus &lt;m„m2,,
Km&gt;
�Flis&apos;t
⎦⎥
n
(d)
⎧ focus struc
− &amp; focus struc
− &amp; ⎫
⎪ ⎡ ⎪
⎡ act ⎤ actee ⎤
⎪ ⎪
⎢Focus Type
− s focus
− ⎥ ⎢ ⎥
Focus Type w focus
− −
⎨ ⎢ ⎥ ⎢ ⎥ ⎬
list− focus &lt;a1,a 2,..., an &gt;⎥,⎢list− focus &lt;b1,b2,...,bn &gt;
⎪⎪ ⎢ ⎥ ⎢ ⎥ ⎪⎪
⎩ ⎣FET obj
− &lt; &gt;
a ⎦ ⎣ FET obj
− &lt;b b b &gt;
n 1 2
, ,..., n ⎦ ⎭
⎧ focus struc
− &amp;focus struc
− &amp; ⎫⎪
⎤ ⎤ ⎪⎡
⎪ ⎢ ⎥ ⎪
w focus
− −⎢
Type
− s focus
− ⎥
⎨ ⎢ ⎥ ⎢ ⎥ ⎬
,
⎪ ⎢ list focus
− &lt; c c c list focus , ,..., ⎪
1 2
, ,..., &gt; ⎥ ⎢ − &lt; a a a &gt;
n 12 n ⎥⎪⎪ ⎢ ⎥ ⎢ ⎥ ⎪⎪
⎩
1
</equation>
<page confidence="0.23942">
2
</page>
<figure confidence="0.803505">
n
&lt;an
⎭
actor
Type
&lt;
c
c
(e)
</figure>
<figureCaption confidence="0.6214525">
Figure 2: The AVM structure of focus marking:
For actor or actee part, (a) s-focus (b) w-focus (c)
w-focus of the multiple lists (d) s-focus of the mul-
tiple lists and, (e) s-focus for act part
</figureCaption>
<subsectionHeader confidence="0.7517595">
3.2 The Relationships of Focus with Speech
Acts to Prosody
</subsectionHeader>
<bodyText confidence="0.9984725">
At step 3 of figure 1, we define the speech act
codes following Brennenstuhl (1981). To mark
</bodyText>
<figure confidence="0.997515873015873">
:→
makeact
s−focus
Focus−Type s−focus
,
⎡list
an
&lt; a„a2,...
focus
&gt;
FET obj
−
&lt; an
⎤
⎥
&gt; ⎥
⎦ ⎥
(a)
w focus
−
merg list
_
−
FET
obj
&lt;a
&lt;a
a
a
→
s focus
−
focus struc
−
⎡
⎢
⎢
⎣ ⎢
Focus−Type s−
list−focus &lt; a1
FET − obj
&lt;&gt;
an
−
FET
obj
−
−
cus
Type s
focus
&lt; m
&gt;
∨
act
Focus
Focus
−
FET
obj
−
FET
obj
</figure>
<page confidence="0.995561">
69
</page>
<bodyText confidence="0.999973657142857">
these codes, we consider the main verb (known
as the act part inside the FET content structure).
These codes define what the speech act cate-
gories can be in each sentence. A sentence can
be marked by more than one code according to
speech act classification (Ballmer and Brennen-
stuhl, 1981). We mark the speech act codes for 62
sentences from a part of the CMU communicator
dataset (2002). Considering the relationships be-
tween speech acts and focus parts, we found some
common patterns for marking tones in a sentence.
For example, the tone mark L-L%, analyzed as
low phrase tone (L-) to low boundary tone (L%), is
marked at the last word of a sentence for any affir-
mative sentence. The tone marks H- (high phrase
tone) and L- are marked at the last word before
conjunction (such as “and”, “or”, “but”, and so
on) or are marked at the last word of the current
phrase (following the next phrase). We know that
the tone mark H* (high accent tone) is used to em-
phasize a word or a group of words in a sentence.
If we want strong emphasis at a word or a group
of words then we use the tone mark L+H* (rising
accent tone) instead of H*. The groups of speech
acts, that we consider in this paper, include intend-
ing (EN0ab), want (DE8b), and victory (KA4a),
to explore tone patterns. We analyze the relation-
ships of speech acts and tone marks grouping by
focus parts as shown in figure 3. Since our ex-
ample sentence has focus at actee part, speech act
code is en0ab, and the sentence mood is affirma-
tive sentence (aff), we define the tone marks for a
set of words in the actee part as L+H* L-L%, fol-
lowing figure 3. The outcome of this process is the
FET structure including the prosodic structure.
</bodyText>
<table confidence="0.9993471">
Code Act Sent Condition
Type Type
EN0ab Actee Aff Actee_tone F ( [ L* v(L+H*)]+L-) n -1+([L*v(L+H*)]+L-L%)
Int Actee_tone FqH*v(L+H*)]+H-r-1+([H*v(L+H*)]+H-H%)
DE8b Actee Aff Actee_tone FH*+L-L%
Int Actee_toneF H*+H-H%
KA4a Actor Aff Actor_tone F H* v (L+H*)
Int Actor_tone F H* v (L+H*)
Actee Aff Actee_tone F([H*v(L+H*)]+L-)1 +L-L%
Int Actee_toneF ([H* v (L + H*)]+ H-r1 + H-H%
</table>
<figureCaption confidence="0.96531">
Figure 3: Tone constraints
</figureCaption>
<sectionHeader confidence="0.9701675" genericHeader="method">
4 An Example of FET Implementation
with LKB System
</sectionHeader>
<bodyText confidence="0.999861125">
In this section, we implement our system using the
LKB system with the FET environment. We ana-
lyze an example sentence “Kim bought a flower”
using the FET system. The system contains the
FET environment (see section 4.2) and constrains
focus and prosodic features based on FET analysis
in section 3. We introduce the FET type hierarchy
and describe the components of FET structure.
</bodyText>
<subsectionHeader confidence="0.9917355">
4.1 Interpreting the MRS representation for
Focus Words
</subsectionHeader>
<bodyText confidence="0.999996888888889">
In the preprocessing process, the LKB system with
ERG parses a sentence and generates the MRS
representation (see step 1, figure 1). By scan-
ning each object inside the MRS representation,
we keep all reference numbers, mapped with their
objects and record every connection that is related
to this object and this reference number. We ex-
tract only necessary information to generate a set
of focus words (see step 2, figure 1). These focus
words are generated to correspond to the LKB sys-
tem. For a sentence, we define a speech act code
referring to a main verb and obtain a focus crite-
rion from a user.
Each focus word, as shown in figure 4, is
marked by a focus part (focus-part). A focus
word structure (focus-word) contains the focus cri-
terion (fcgroup), speech act code (spcode), sen-
tence mood (stmood) and focus position (focus-
pos) in a focus part. In figure 4, the focus crite-
rion is defined as group G (see table 2) while the
speech acts code is en0ab (intending). The sen-
tence mood referring from MRS is affirmative sen-
tence and focus position is the last node (ls). We
will describe the focus-word and its components
in the next section. In figure 4, “Kim” is a actor
part while “bought” is an act part. The words “a”
and “flower” are the actee parts.
</bodyText>
<equation confidence="0.970447857142857">
Kim := focus-word &amp; bought := focus-word &amp;
[ ORTH &amp;quot;Kim&amp;quot;, [ ORTH &amp;quot;bought&amp;quot;,
HEAD actor-part &amp; HEAD act-part &amp; [ AGR1 ls-act_G-aff-en0ab ],
[ AGR1 ls-actor_G-aff-en0ab], SPR &lt; [HEAD actor-part &amp;
SPR &lt; &gt;, [ AGR1 ls-actor_G-aff-en0ab ] ] &gt;,
COMPS &lt; &gt; ]. COMPS &lt; focus-phrase &amp; [HEAD actee-part &amp;
[AGR1 ls-actee_G-aff-en0ab ]] &gt; ].
</equation>
<figureCaption confidence="0.997706">
Figure 4: A set of focus words
</figureCaption>
<subsectionHeader confidence="0.931561">
4.2 FET Tone Environment
</subsectionHeader>
<bodyText confidence="0.999980222222222">
In FTE system, we provide a set of focus words
to the LKB system with the FET environment (see
step 3, figure 1). This environment contains the
constraints, rules, type hierarchy, a set of features,
and their structures for the FET analysis. We
design the FET type hierarchy as shown in fig-
ure 5. We define three main groups of feature
structures: *focus-value*, *prosodic-value* and
feat-struc to control the focus constraints. *focus-
</bodyText>
<equation confidence="0.967903142857143">
flower := focus-word &amp;
[ ORTH &amp;quot;flower&amp;quot;,
HEAD actee-part &amp;
[AGR1 ls-actee_G-aff-en0ab ],
SPR &lt; [ HEAD actee-part &amp;
[AGR1 pv-actee_G-aff-en0ab ]] &gt;,
COMPS &lt; focus-phrase &amp; [HEAD actee-part &amp;
[AGR1 ls-actee_G-aff-en0ab ]]&gt; ].
a := focus-word &amp;
[ ORTH &amp;quot;a&amp;quot;,
HEAD actee-part &amp;
[AGR1 pv-actee_G-aff-en0ab ],
SPR &lt; &gt;,
COMPS &lt; &gt; ].
</equation>
<page confidence="0.98317">
70
</page>
<bodyText confidence="0.999791230769231">
value* represents the focus structures. It is com-
posed of five subfeature structures: focus crite-
rion, focus type (fctype), focus name (focus), fo-
cus position (focus-pos), and checking whether a
tone mark can be marked at a word (tone-mark).
*prosody-value* represents the prosodic structure.
Four prosodic subfeature structures are sentence
mood, speech act code, accent tone (accent-tone),
and boundary tone (bound-tone). feat-struc con-
tains the core FET structure that constrains the re-
lationships between focus and prosodic features.
The feat-struc structure is composed of six main
subfeature structures: (i) focus category structure
(focus-cat) is a set of constraints which are the
combinations of a focus part and a focus criterion
such as act g, actor g, actee g, and so on, (ii) fo-
cus part structure (focus-part) classifies act part
and non-act part as actor part or actee part, (iii)
focus structure (focus-struc) is a subfeature struc-
ture offocus-word and focus-phrase, (iv) checking
whether prosodic marks can be marked (prosody),
(v) prosodic mark (prosody-mark) structure maps
between types of prosodic mark and accent and
boundary tones: no-mark, hEm Sh-break, etc, (vi)
a set of prosodic marks (prosody-set) is a set of
combinations between accent and boundary tones.
</bodyText>
<figureCaption confidence="0.984594">
Figure 5: FET type hierarchy
</figureCaption>
<subsectionHeader confidence="0.907469">
4.2.1 Focus Structure
</subsectionHeader>
<bodyText confidence="0.999562884615385">
In figure 6(a), the focus-phrase inherits the
focus-struc with a feature ARGS. The ARGS rep-
resents a list of words in the sentence. The focus
rules parse the focus-phrase with their constraints
and define whether tone can be marked at a word
in each focus part. The focus-word inherits the
focus-struc with orthography of a word (ORTH)
as string. The focus-word, as shown in 6(b), repre-
sents the focus content structure and corresponds
to the LKB system. The focus-struc, as show in
figure 6(c), consists of HEAD, specifier (SPR) and
complement (COMPS) (Ivan et al., 2003). In-
side the focus-struc, HEAD refers to focus-part
which is shown in figure 6(d). SPR and COMP
are used to specify the components of previous
nodes and following nodes in a sentence. Each
focus-part contains focus and prosodic structures.
We classify focus following the possible focus-
cat for the FET structure. The focus-cat controls
the constraints for the actor, act and actee parts.
The focus-cat contains both the focus and prosodic
features as a set of subfeatures of the FET struc-
ture. This structure contains focus position, fo-
cus group, focus type, a set of prosody marks
and prosodic structure (prosody). The focus-cat
is shown in figure 6(e).
</bodyText>
<figure confidence="0.981319">
focus struc : =
−
(a) (b) (c)
focus
feat struc
− &amp;
FOCUS POS focus
− −
FCGROUP fcgroup
FCTYPE fctype
ADDTONE addtone
PROSODY prosody
(e)
</figure>
<figureCaption confidence="0.973949333333333">
Figure 6: Type feature structure of: (a) focus-
phrase (b) focus-word (c) focus-struc (d) focus-
part (e) focus-cat
</figureCaption>
<subsectionHeader confidence="0.593001">
4.2.2 Prosodic Structure
</subsectionHeader>
<bodyText confidence="0.999982444444444">
The prosodic structure consists of these subfea-
tures: sentence mood, speech act code, and a set of
prosodic mark structures. This structure controls
the prosodic marks following the FET constraints.
These constraints depend on the relationships of
focus with speech acts to intonation patterns. The
prosody structure is shown in figure 7(a). The
accent and boundary tones are mapped with the
prosody-mark which is illustrated in figure 7(b).
</bodyText>
<figure confidence="0.4331618">
⎡ACCENT TONE accent tone
− − ⎤
⎢⎣ BOUND TONE bound tone
− − ⎦⎥
(b)
</figure>
<figureCaption confidence="0.9004225">
Figure 7: Type feature structure of: (a) Prosodic
structure (b) Prosodic mark structure
</figureCaption>
<bodyText confidence="0.999471714285714">
For focus rules, we have two types of focus
rules that are head-complement and head-specifier
rules. These rules process the same as a simple
grammar rule which is explained in (Ivan et al.,
2003). Using these rules, the example sentence
“Kim bought a flower” is parsed and the result
is the complete FET structure including the focus
</bodyText>
<figure confidence="0.999304892857143">
&amp;
: =
focus word
−
: =
HEAD focus
&amp;
focus struc
−
�COMPS
SPR *
list
[ORTH string ]
feat struc
−
−
*
* ⎦
*list
focus phrase
−
focus struc
− &amp;
[* *]
ARGS list
: =
cat
focuspart : �
−
featstruc &amp;
−
IAGR1FOCUS focus
1 focus−cat]
(d)
pos
: =
prosody
&amp;
feat struc
−
STMOOD stmood
SPCODE spcode
mark
PROSODY MARK prosody
− 1
mark
PROSODY MARK prosody
− 2
(a)
−
mark
: =
prosody
&amp;
feat struc
−
</figure>
<page confidence="0.990654">
71
</page>
<bodyText confidence="0.9910495">
and prosodic information. The FET structure of
the word “Kim” is shown in figure 8.
</bodyText>
<figureCaption confidence="0.99648">
Figure 8: FET structure of the word “Kim”
</figureCaption>
<subsectionHeader confidence="0.988025">
4.3 Modifying Prosody for Synthetic Speech
</subsectionHeader>
<bodyText confidence="0.999693666666667">
In the postprocessing process (see step 4, figure 1),
we extract a set of words with tone marks from the
FET structure. An example of these words with
tone marks is shown in figure 9. Finally we trans-
fer this data to generate the synthesized speech by
the speech synthesis and modify prosody.
</bodyText>
<reference confidence="0.833483">
ORTH: Kim ORTH: a
Focus: actor-part Focus: actee-part
ACCENT_TONE1: NOACCENT ACCENT_TONE1: NOACCENT
BOUND_TONE1: NOBOUND BOUND_TONE1: NOBOUND
ORTH: bought ORTH: flower
Focus: act-part Focus: actee-part
ACCENT_TONE1: NOACCENT ACCENT_TONE1: L+H*
BOUND_TONE1: NOBOUND BOUND_TONE1: L-L%
</reference>
<figureCaption confidence="0.992611">
Figure 9: A set of words and their tone marks
</figureCaption>
<sectionHeader confidence="0.990788" genericHeader="method">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999992142857143">
We design the FET system based on the small
number of sentences from a part of the CMU com-
municator dataset (2002). These simple sentences
relate to traveling information. In this paper, we
use the MRS representation from the LKB system
to determine actor, act and actee parts. Since the
LKB has a limited grammar and produces multi-
ple parses, then we assume that our input sentence
can be parsed by the HPSG parser and only a cor-
rect output is provided to the LKB system with
the FET environment. We analyze the relation-
ships of focus with speech acts to tone marks. To
mark tone, we group the tone patterns by speech
acts and focus parts. We implement the FET sys-
tem using LKB and an example is illustrated in
section 4 in this paper. Using the LKB with the
FET grammar, the system can parse most simple
sentences from the CMU communicator dataset
and generate the complete FET structure including
prosodic marks for each sentence. We are evaluat-
ing the FET system with respect to three aspects:
appreciation of listeners to tone based on the tone
marks from the FET system, conveying the focus
content in a sentence to listeners and the correct-
ness of prosodic annotation. In the future, we will
finish the evaluations and analyze more relation-
ships of focus with speech acts to tones to support
the various sentences.
</bodyText>
<sectionHeader confidence="0.972426" genericHeader="conclusions">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.8266695">
This work is supported by NSERC, Canada, Royal
Golden Jubilee Ph.D. program, Thailand Research
Fund, Thailand, and King Mongkut’s University
of Technology Thonburi, Thailand.
</bodyText>
<sectionHeader confidence="0.98545" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999801714285715">
Mohammad Haji-Adolhosseini. 2003. A Constraint-
Based Approach to Information Structure and
Prosody Correspondence. Proc. of The HPSG-2003
Conf., In Stefan Muller (ed.), CSLI Pub., Michigan
State Univ., East Lansing, pp. 143-162.
Ewan Klein. 2000. Prosodic constituency in HPSG,
Grammatical Interfaces in HPSG. In Ronnie Cann,
and Philip Miller, ed., CSLI Pub., pp 169-200.
Copestake A. 2002. Implementing Typed Feature
Structure Grammars. CSLI Pub., Stanford, CA.
Copestake A., Flickinger D., Malouf R., Riehemann S.
and Sag I.A. 1995. Translation using Minimal Re-
cursion Semantics. Proc. of the The 6th Int’l Conf.
on Theoretical and Methodological Issues in Ma-
chine Translation (TMI-95), Belgium.
Silverman K., Beckman M. B., Pirelli J., Ostendorf
M., Wightman C., Price P., Pierrehumbert J., and
Hirschberg J. 1992. ToBI: A Standard for Label-
ing English Prosody. In Proc. of ICSLP’92, Banff,
Canada, pages. 867-870.
Steedman M. and Prevost, S. 1994. Specifying Into-
nation from Context for Speech Synthesis. Speech
Comm., 15, 1994, 139-153.
Von Heusinger K. 1999. Intonation and Information
Structure. The Representation of Focus in Phonol-
ogy and Semantics. Habilitationsschrift, University
Konstanz, pp. 125-155.
Paul Boersma and David Weenink 2005. Praat:
doing phonetics by computer. Inst. of Pho-
netic Sciences, Univ. of Amsterdam, Netherlands,
http://www.praat.org, Oct. 2005.
Ballmer T. and Brennenstuhl W. 1981. Speech Act
Classification. A study in the Lexical analysis of
English speech activity verbs. Springer Series in
Language and Comm., Vol.8. Springer Verlag, New
York, 1981.
CMU Communicator KAL limited domain. 2002.
Language Technologies Inst., Carnegie Mellon
Univ., www.festvox.org, Oct 2005.
Sag, Ivan A., Thomas Wasow, and Emily Bender.
2003. Syntactic Theory: A formal introduction.
CSLI Pub., Univ. of Chicago Press.
</reference>
<page confidence="0.998722">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.892477">
<title confidence="0.9922315">Focus to Emphasize Tone Structures for Prosodic Analysis in Spoken Language Generation</title>
<author confidence="0.930016">Lalita Narupiyakul</author>
<affiliation confidence="0.99964">Faculty of Computer Science, Dalhousie University</affiliation>
<address confidence="0.995651">6050 University Avenue, Halifax, Nova Scotia, Canada B3H 1W5</address>
<phone confidence="0.995017">Tel. +1-902-494-6441, Fax. +1-902-494-3962</phone>
<email confidence="0.998106">lalita@cs.dal.ca</email>
<abstract confidence="0.998784">We analyze the concept of focus in speech and the relationship between focus and speech acts for prosodic generation. We determine how the speaker’s utterances are influenced by speaker’s intention. The relationship between speech acts and focus information is used to define which parts of the sentence serve as the focus parts. We propose the Focus to Emphasize Tones (FET) structure to analyze the focus components. We also design the FET grammar to analyze the intonation patterns and produce tone marks as a result of our analysis. We present a proof-of-the-concept working example to validate our proposal. More comprehensive evaluations are part of our current work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>ORTH Kim</author>
</authors>
<title>ORTH: a Focus: actor-part Focus: actee-part</title>
<booktitle>ACCENT_TONE1: NOACCENT ACCENT_TONE1: NOACCENT BOUND_TONE1: NOBOUND BOUND_TONE1: NOBOUND</booktitle>
<marker>Kim, </marker>
<rawString>ORTH: Kim ORTH: a Focus: actor-part Focus: actee-part ACCENT_TONE1: NOACCENT ACCENT_TONE1: NOACCENT BOUND_TONE1: NOBOUND BOUND_TONE1: NOBOUND</rawString>
</citation>
<citation valid="false">
<authors>
<author>ORTH bought</author>
</authors>
<title>ORTH: flower Focus: act-part Focus: actee-part</title>
<booktitle>ACCENT_TONE1: NOACCENT ACCENT_TONE1: L+H* BOUND_TONE1: NOBOUND BOUND_TONE1: L-L%</booktitle>
<marker>bought, </marker>
<rawString>ORTH: bought ORTH: flower Focus: act-part Focus: actee-part ACCENT_TONE1: NOACCENT ACCENT_TONE1: L+H* BOUND_TONE1: NOBOUND BOUND_TONE1: L-L%</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Haji-Adolhosseini</author>
</authors>
<title>A ConstraintBased Approach to Information Structure and Prosody Correspondence.</title>
<date>2003</date>
<booktitle>Proc. of The HPSG-2003 Conf., In</booktitle>
<pages>143--162</pages>
<editor>Stefan Muller (ed.), CSLI Pub.,</editor>
<institution>Michigan State Univ., East Lansing,</institution>
<marker>Haji-Adolhosseini, 2003</marker>
<rawString>Mohammad Haji-Adolhosseini. 2003. A ConstraintBased Approach to Information Structure and Prosody Correspondence. Proc. of The HPSG-2003 Conf., In Stefan Muller (ed.), CSLI Pub., Michigan State Univ., East Lansing, pp. 143-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ewan Klein</author>
</authors>
<title>Prosodic constituency in HPSG, Grammatical Interfaces</title>
<date>2000</date>
<pages>169--200</pages>
<editor>in HPSG. In Ronnie Cann, and Philip Miller, ed., CSLI Pub.,</editor>
<contexts>
<context position="1535" citStr="Klein, 2000" startWordPosition="232" endWordPosition="233">ations are part of our current work. 1 Introduction A speaker’s utterance may convey different meaning to a hearer. Such ambiguities can be resolved by emphasizing accents in different positions. Focus information is needed to select correct positions for accent information. To determine focus information, a speaker’s intentions must be revealed. We apply speech act theory to written sentences, our input, to determine a speaker’s intention. Subsequently our system will produce a speaker utterance, the result of analysis. Several research publications, such as (Steedman and Prevost, 1994) and (Klein, 2000), explore prosodic analysis for spoken language generation (SLG). Klein (2000) designs constraints for prosodic structures in the HPSG framework. His approach is based on an isomorphism of syntactic and prosodic trees. This approach is heavily syntax-driven and involves making prosodic trees by manipulation of the syntactic trees. This approach results in increased complexity since the type hierarchy of phrases must crossclassify prosodic phrases under syntactic phrases. Haji-Abdolhosseini (2003) extended Klein’s approach. Rather than referring to syntax, HajiAbdolhosseini sets the information</context>
</contexts>
<marker>Klein, 2000</marker>
<rawString>Ewan Klein. 2000. Prosodic constituency in HPSG, Grammatical Interfaces in HPSG. In Ronnie Cann, and Philip Miller, ed., CSLI Pub., pp 169-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars. CSLI Pub.,</title>
<date>2002</date>
<location>Stanford, CA.</location>
<contexts>
<context position="3325" citStr="Copestake, 2002" startWordPosition="517" endWordPosition="518">usinger, 1999), the focus part identifies what part of the sentence can be marked with the strong accent or emphasized by a high tone. By analyzing speech acts, we can understand how speech with prosody can convey distinct speaker intentions to a hearer. In the next section, we present an overview of our FET (Focus to Emphasize Tone) system and its processes. We will explain how to analyze focus information, design the FET structure, and find the relationships of focus with speech acts to prosodic marks in section 3. We implement our FET grammar for the Linguistic Knowledge Base (LKB) system (Copestake, 2002), generate a set of focus words, explain the FET environment, and show an example in section 4. In the last section, we conclude the current state of our work and the future work. 67 Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 67–72, Sydney, July 2006. c�2006 Association for Computational Linguistics 2 Overview of FET System for Prosodic Analysis in SLG Our system generates the prosodic structure depending on the focus analysis. We use this prosodic structure to modify synthetic speech for SLG. Our FET structure is constrained by the speaker’s intention. To define proso</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake A. 2002. Implementing Typed Feature Structure Grammars. CSLI Pub., Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>R Malouf</author>
<author>S Riehemann</author>
<author>I A Sag</author>
</authors>
<title>Translation using Minimal Recursion Semantics.</title>
<date>1995</date>
<booktitle>Proc. of the The 6th Int’l Conf. on Theoretical and Methodological Issues in Machine Translation (TMI-95),</booktitle>
<location>Belgium.</location>
<contexts>
<context position="4655" citStr="Copestake et al., 1995" startWordPosition="743" endWordPosition="746">ET system is shown in figure 1 and we present an overview of the FET system based on the LKB system below. Figure 1: A diagram of the FET system Our input is a sentence and its focus criterion obtained from a user. In figure 1, the example sentence is “Kim bought a flower” and the focus criterion is G (see table 2). Our system is composed of four main steps. The first step is preprocessing. The LKB system with the English Resource Grammar (ERG) (Copestake, 2002) parses a sentence. The LKB system analyzes the syntactic and semantic structures and generates the Minimal Recursive Semantic (MRS) (Copestake et al., 1995) representation. This step occurs before invoking the FET system. In the second step, we scan the MRS structure and collect any components and their relations among them obtained from the preprocessing step. We select only required information, such as sentence mood, from the MRS representation, assign a speech act code referring to a main verb of a sentence, and obtain from the MRS structure a set of focus words. These focus words are an input for the focus information analysis in the FET system. The third step is the FET analysis. This step generates the prosodic components inside the FET st</context>
</contexts>
<marker>Copestake, Flickinger, Malouf, Riehemann, Sag, 1995</marker>
<rawString>Copestake A., Flickinger D., Malouf R., Riehemann S. and Sag I.A. 1995. Translation using Minimal Recursion Semantics. Proc. of the The 6th Int’l Conf. on Theoretical and Methodological Issues in Machine Translation (TMI-95), Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Silverman</author>
<author>M B Beckman</author>
<author>J Pirelli</author>
<author>M Ostendorf</author>
<author>C Wightman</author>
<author>P Price</author>
<author>J Pierrehumbert</author>
<author>J Hirschberg</author>
</authors>
<title>ToBI: A Standard for Labeling English Prosody.</title>
<date>1992</date>
<booktitle>In Proc. of ICSLP’92,</booktitle>
<pages>867--870</pages>
<location>Banff, Canada,</location>
<contexts>
<context position="5903" citStr="Silverman et al., 1992" startWordPosition="949" endWordPosition="953">ammar, we input the focus words into the LKB system with the FET environment. This environment consists of the FET type hierarchy, constraints, rules, and structures including the focus and prosodic features. Since the LKB system with FET environment can analyze the focus relations corresponding to speech acts and sentence moods, the system completes the FET structure by generating a set of appropriate prosodic structures containing prosodic marks as a result. The last step is the postprocessing process. We extract words and their prosodic marks as Tone and Break Index (ToBI) representations (Silverman et al., 1992) from the FET structure. The extracting system processes the FET structure, extracts only our required prosodic fields. These fields are a set of words and their tone marks for a sentence. We use the set of words with tone marks to modify synthetic speech, which is generated by speech synthesis. We use the PRAAT (Boersma and Weenink, 2005) to modify the prosody of the synthetic speech for a sentence. Our output is an audio file of the sentence with modified prosody. Modifying prosody follows the tone marks which are analyzed by the FET system. 3 FET Analysis We describe our concept of the FET </context>
</contexts>
<marker>Silverman, Beckman, Pirelli, Ostendorf, Wightman, Price, Pierrehumbert, Hirschberg, 1992</marker>
<rawString>Silverman K., Beckman M. B., Pirelli J., Ostendorf M., Wightman C., Price P., Pierrehumbert J., and Hirschberg J. 1992. ToBI: A Standard for Labeling English Prosody. In Proc. of ICSLP’92, Banff, Canada, pages. 867-870.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
<author>S Prevost</author>
</authors>
<title>Specifying Intonation from Context for Speech Synthesis.</title>
<date>1994</date>
<journal>Speech Comm.,</journal>
<volume>15</volume>
<pages>139--153</pages>
<contexts>
<context position="1517" citStr="Steedman and Prevost, 1994" startWordPosition="226" endWordPosition="230">roposal. More comprehensive evaluations are part of our current work. 1 Introduction A speaker’s utterance may convey different meaning to a hearer. Such ambiguities can be resolved by emphasizing accents in different positions. Focus information is needed to select correct positions for accent information. To determine focus information, a speaker’s intentions must be revealed. We apply speech act theory to written sentences, our input, to determine a speaker’s intention. Subsequently our system will produce a speaker utterance, the result of analysis. Several research publications, such as (Steedman and Prevost, 1994) and (Klein, 2000), explore prosodic analysis for spoken language generation (SLG). Klein (2000) designs constraints for prosodic structures in the HPSG framework. His approach is based on an isomorphism of syntactic and prosodic trees. This approach is heavily syntax-driven and involves making prosodic trees by manipulation of the syntactic trees. This approach results in increased complexity since the type hierarchy of phrases must crossclassify prosodic phrases under syntactic phrases. Haji-Abdolhosseini (2003) extended Klein’s approach. Rather than referring to syntax, HajiAbdolhosseini se</context>
</contexts>
<marker>Steedman, Prevost, 1994</marker>
<rawString>Steedman M. and Prevost, S. 1994. Specifying Intonation from Context for Speech Synthesis. Speech Comm., 15, 1994, 139-153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Von Heusinger</author>
</authors>
<title>Intonation and Information Structure. The Representation of Focus</title>
<date>1999</date>
<booktitle>in Phonology and Semantics. Habilitationsschrift,</booktitle>
<pages>125--155</pages>
<location>University Konstanz,</location>
<marker>Von Heusinger, 1999</marker>
<rawString>Von Heusinger K. 1999. Intonation and Information Structure. The Representation of Focus in Phonology and Semantics. Habilitationsschrift, University Konstanz, pp. 125-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
<author>David Weenink</author>
</authors>
<title>Praat: doing phonetics by computer.</title>
<date>2005</date>
<journal>Inst. of Phonetic Sciences, Univ. of</journal>
<location>Amsterdam, Netherlands, http://www.praat.org,</location>
<contexts>
<context position="6244" citStr="Boersma and Weenink, 2005" startWordPosition="1010" endWordPosition="1013">stem completes the FET structure by generating a set of appropriate prosodic structures containing prosodic marks as a result. The last step is the postprocessing process. We extract words and their prosodic marks as Tone and Break Index (ToBI) representations (Silverman et al., 1992) from the FET structure. The extracting system processes the FET structure, extracts only our required prosodic fields. These fields are a set of words and their tone marks for a sentence. We use the set of words with tone marks to modify synthetic speech, which is generated by speech synthesis. We use the PRAAT (Boersma and Weenink, 2005) to modify the prosody of the synthetic speech for a sentence. Our output is an audio file of the sentence with modified prosody. Modifying prosody follows the tone marks which are analyzed by the FET system. 3 FET Analysis We describe our concept of the FET analysis (see step 3, figure 1). We determine how the speaker’s utterances are influenced by a speaker’s intention. Focus information can be used to indicate how to appropriately mark a part of a sentence to convey the speaker’s intention. Focus can scope the content in a sentence to which a speaker wants the listener to pay attention. We </context>
</contexts>
<marker>Boersma, Weenink, 2005</marker>
<rawString>Paul Boersma and David Weenink 2005. Praat: doing phonetics by computer. Inst. of Phonetic Sciences, Univ. of Amsterdam, Netherlands, http://www.praat.org, Oct. 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ballmer</author>
<author>W Brennenstuhl</author>
</authors>
<title>Speech Act Classification. A study in the Lexical analysis of English speech activity verbs.</title>
<date>1981</date>
<booktitle>Series in Language and Comm., Vol.8.</booktitle>
<publisher>Springer</publisher>
<location>New York,</location>
<contexts>
<context position="13392" citStr="Ballmer and Brennenstuhl, 1981" startWordPosition="2368" endWordPosition="2372"> following Brennenstuhl (1981). To mark :→ makeact s−focus Focus−Type s−focus , ⎡list an &lt; a„a2,... focus &gt; FET obj − &lt; an ⎤ ⎥ &gt; ⎥ ⎦ ⎥ (a) w focus − merg list _ − FET obj &lt;a &lt;a a a → s focus − focus struc − ⎡ ⎢ ⎢ ⎣ ⎢ Focus−Type s− list−focus &lt; a1 FET − obj &lt;&gt; an − FET obj − − cus Type s focus &lt; m &gt; ∨ act Focus Focus − FET obj − FET obj 69 these codes, we consider the main verb (known as the act part inside the FET content structure). These codes define what the speech act categories can be in each sentence. A sentence can be marked by more than one code according to speech act classification (Ballmer and Brennenstuhl, 1981). We mark the speech act codes for 62 sentences from a part of the CMU communicator dataset (2002). Considering the relationships between speech acts and focus parts, we found some common patterns for marking tones in a sentence. For example, the tone mark L-L%, analyzed as low phrase tone (L-) to low boundary tone (L%), is marked at the last word of a sentence for any affirmative sentence. The tone marks H- (high phrase tone) and L- are marked at the last word before conjunction (such as “and”, “or”, “but”, and so on) or are marked at the last word of the current phrase (following the next ph</context>
</contexts>
<marker>Ballmer, Brennenstuhl, 1981</marker>
<rawString>Ballmer T. and Brennenstuhl W. 1981. Speech Act Classification. A study in the Lexical analysis of English speech activity verbs. Springer Series in Language and Comm., Vol.8. Springer Verlag, New York, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CMU Communicator</author>
</authors>
<title>KAL limited domain.</title>
<date>2002</date>
<location>Carnegie Mellon Univ., www.festvox.org,</location>
<marker>Communicator, 2002</marker>
<rawString>CMU Communicator KAL limited domain. 2002. Language Technologies Inst., Carnegie Mellon Univ., www.festvox.org, Oct 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Thomas Wasow</author>
<author>Emily Bender</author>
</authors>
<title>Syntactic Theory: A formal introduction. CSLI Pub., Univ.</title>
<date>2003</date>
<publisher>of Chicago Press.</publisher>
<marker>Sag, Wasow, Bender, 2003</marker>
<rawString>Sag, Ivan A., Thomas Wasow, and Emily Bender. 2003. Syntactic Theory: A formal introduction. CSLI Pub., Univ. of Chicago Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>