<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.176585">
<title confidence="0.837963">
Semeval 2007 Task 18: Arabic Semantic Labeling
</title>
<author confidence="0.99253">
Mona Diab Musa Alkhalifa Sabri Elkateb
</author>
<affiliation confidence="0.999924">
Columbia University University of Barcelona University of Manchester
</affiliation>
<email confidence="0.977979">
mdiab@cs.columbia.edu musa@thera-clic.com Sabri.Elkateb@manchester.ac.uk
</email>
<author confidence="0.994875">
Christiane Fellbaum Aous Mansouri Martha Palmer
</author>
<affiliation confidence="0.999881">
Princeton University University of Colorado, Boulder University of Colorado, Boulder
</affiliation>
<email confidence="0.998754">
fellbaum@clarity.princeton.edu aous.mansouri@colorado.edu martha.palmer@colorado.edu
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999727714285714">
In this paper, we present the details of the
Arabic Semantic Labeling task. We describe
some of the features of Arabic that are rele-
vant for the task. The task comprises two
subtasks: Arabic word sense disambiguation
and Arabic semantic role labeling. The task
focuses on modern standard Arabic.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935086956522">
Recent years have witnessed a surge in available re-
sources for the Arabic language.1 The computa-
tional linguistics community is just about starting
to exploit these resources toward several interesting
scientific and engineering goals. The Arabic lan-
guage is interesting from a computational linguistic
perspective. It is significantly different from English
hence creating a challenge for existing technology to
be easily portable to Arabic. The Arabic language is
inherently complex due to its rich morphology and
relative free word order. Moreover, with the exis-
tence of several interesting varieties, the spoken ver-
naculars, we are witnessing the emergence of written
dialectal Arabic everyday on the web, however there
are no set standards for these varieties.
We have seen many successful strides towards
functional systems for Arabic enabling technolo-
gies, but we are yet to read about large Arabic NLP
applications such as Machine Translation and Infor-
mation Extraction that are on par with performance
on the English language. The problem is not the ex-
istence of data, but rather the existence of data an-
notated with the relevant level of information that
</bodyText>
<footnote confidence="0.931735333333333">
1Author 1 is supported by DARPA contract Contract No.
HR0011-06-C-0023. Authors 2, 3 and 4 are supported by the
US Central Intelligence Service.
</footnote>
<bodyText confidence="0.999256428571429">
is useful for NLP. This task attempts a step towards
the goal of creating resources that could be useful
for such applications.
In this task, we presented practitioners in the field
with challenge of labeling Arabic text with seman-
tic labels. The labels constitute two levels of gran-
ularity: sense labels and semantic role labels. We
specifically chose data that overlapped such that we
would have the same data annotated for different
types of semantics, lexical and structural. The over-
all task of Arabic Semantic Labeling was subdivided
into 4 sub-tasks: Arabic word sense disambiguation
(AWSD), English to Arabic WSD task (EAWSD),
argument detection within the context of semantic
role labeling, and argument semantic role classifica-
tion.
Such a set of tasks would not have been feasible
without the existence of several crucial resources:
the Arabic Treebank (ATB) (Maamouri et al.,
2004), the Arabic WordNet (AWN) (Elkateb et
al., 2006), and the Pilot Arabic Propbank
(APB).2
This paper is laid out as follows: Section 2 will
describe some facts about the Arabic language; Sec-
tion 3 will present the overall description of the
tasks; Section 4 describes the word sense disam-
biguation task; Section 5 describes the semantic role
labeling task.
</bodyText>
<sectionHeader confidence="0.792712" genericHeader="method">
2 The Arabic Language
</sectionHeader>
<bodyText confidence="0.911273333333333">
In the context of our tasks, we only deal with MSA.3
Arabic is a Semitic language. It is known for its
templatic morphology where words are made up of
</bodyText>
<footnote confidence="0.995122">
2Funded by DARPA subcontract to BBN Inc. to University
of Colorado, LDC-UPenn and Columbia University.
3In this paper we use MSA and Arabic interchangeably.
</footnote>
<page confidence="0.994449">
93
</page>
<bodyText confidence="0.993115446808511">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 93–98,
Prague, June 2007. c�2007 Association for Computational Linguistics
roots and affixes. Clitics agglutinate to words. For
instance, the surface word wbHsnAthm4
‘and by their virtues[fem.]’, can be split into the con-
junction w ‘and’, preposition b ‘by’, the stem HsnAt
‘virtues [fem.]’, and possessive pronoun hm ‘their’.
Arabic is different from English from both the mor-
phological and syntactic perspectives which make it
a challenging language to the existing NLP technol-
ogy that is too tailored to the English language.
From the morphological standpoint, Arabic ex-
hibits rich morphology. Similar to English, Ara-
bic verbs are marked explicitly for tense, voice and
person, however in addition, Arabic marks verbs
with mood (subjunctive, indicative and jussive) in-
formation. For nominals (nouns, adjectives, proper
names), Arabic marks case (accusative, genitive and
nominative), number, gender and definiteness fea-
tures. Depending on the genre of the text at hand,
not all of those features are explicitly marked on nat-
urally occurring text.
Arabic writing is known for being underspecified
for short vowels. Some of the case, mood and voice
features are marked only using short vowels. Hence,
if the genre of the text were religious such as the
Quran or the Bible, or pedagogical such as children’s
books in Arabic, it would be fully specified for all
the short vowels to enhance readability and disam-
biguation.
From the syntactic standpoint, Arabic, different
from English, is considered a pro-drop language,
where the subject of a verb may be implicitly en-
coded in the verb morphology. Hence, we observe
sentences such as Akl AlbrtqAl ‘ate-[he]
the-oranges’, where the verb Akl encodes that the
subject is a 3rd person masculine singular. This sen-
tence is exactly equivalent to hw Akl Al-
brtqAl ‘he ate the-oranges’. In the Arabic Tree-
bank (ATB), we observe that 30% of all sentences
are pro-dropped for subject.
Also Arabic is different from English in that it ex-
hibits a larger degree of free word order. For ex-
ample, Arabic allows for subject-verb-object (SVO)
and verb-subject-object (VSO) argument orders, as
well as, OSV and OVS. In the ATB, we observe
an equal distribution of both VSO and SVO orders
</bodyText>
<footnote confidence="0.992607">
4We use the Buckwalter transliteration scheme to show ro-
manized Arabic (Buckwalter, 2002).
</footnote>
<bodyText confidence="0.999347142857143">
each equally 35% of the time. An example of an
SVO sentence is AlrjAl AklwA Al-
brtqAl ‘the-men ate-them the-oranges’, this is con-
trasted with Akl AlrjAl AlbrtqAl ‘ate
the-men the-oranges’.
Arabic exhibits more complex noun phrases than
English mainly to express possession. These con-
structions are known as idafa constructions. In these
complex structures an indefinite noun is followed
by a definite noun. For example, rjl Al-
byt ‘man the-house’ meaning ‘man of the house’.
Accordingly, MSA does not have a special preposi-
tional use to express possession in a manner similar
to English.
</bodyText>
<sectionHeader confidence="0.99682" genericHeader="method">
3 Overall Tasks Description
</sectionHeader>
<bodyText confidence="0.9999935">
Given the differences between English and Arabic,
we anticipate that the process of automatically tag-
ging text with semantic information might take more
than just applying an English semantic labeler to
Arabic. With this in mind, we decided to design a
set of tasks that target different types of semantic
annotations. We designed an all-words style word
sense disambiguation (WSD) task for all the nouns
and verbs in Arabic running text. Moreover, we de-
signed another task where the participants are asked
to detect and classify semantic role labels (SRL) for
a large portion of newswire text. The WSD texts
are chosen from the same set used for SRL. All the
data is from the Arabic Treebank III ver.
2 (ATB). The ATB consists of MSA newswire data
from Annhar newspaper, from the months of July
through November of 2002. The ATB is fully anno-
tated with morphological information as well syn-
tactic structural information. The released data for
the subtasks is unvowelized and romanized using
the Buckwalter transliteration scheme. The part of
speech (POS) tag set used in the released data for
both the WSD and the SRL sub-tasks is the reduced
tag set that is officially released with the ATB.
</bodyText>
<sectionHeader confidence="0.994481" genericHeader="method">
4 Task: WSD
</sectionHeader>
<bodyText confidence="0.9999636">
In the context of this task, word sense disambigua-
tion is the process by which words in context are
tagged with their specific meaning definitions from
a predefined lexical resource such as a dictionary or
taxonomy. The NLP field has gone through a very
</bodyText>
<page confidence="0.996534">
94
</page>
<bodyText confidence="0.999910845070423">
long tradition of algorithms designed for solving this
problem (Ide and Veronis, 1998). Most of the sys-
tems however target English since it is the language
with most resources. In fact a big push forward
dawned on English WSD with the wide release of
significant resources such as WordNet.
Arabic poses some interesting challenges for
WSD since it has an inherent complexity in its writ-
ing system. As mentioned earlier, written MSA is
underspecified for short vowels and diacritics. These
short vowels and diacritics convey both lexical and
inflectional information. For example, klyp could
mean three different things, ‘all’, ‘kidney’ and ‘col-
lege’. Due to the undiacritized, unvowelized writing
system, the three meanings are conflated. If diacrit-
ics are explicitly present, we would observe a bet-
ter distinction made between kly—p ‘all’ or ‘col-
lege’, and klyp ‘kidney’. Hence, full diacritiza-
tion may be viewed as a level of WSD. But crucially,
naturally occurring Arabic text conflates more words
due to the writing system.
To date, very little work has been published on
Arabic WSD. This is mainly attributed to the lack in
lexical resources for the Arabic language. But this
picture is about to change with the new release of an
Arabic WordNet (AWN).
Arabic WordNet Arabic WordNet (AWN) is a
lexical resource for modern standard Arabic. AWN
is based on the design and contents of Prince-
ton WordNet (PWN)(Fellbaum, 1998) and can be
mapped onto PWN as well as a number of other
wordnets, enabling translation on the lexical level to
and from dozens of other languages.
AWN focuses on the the Common Base Concepts
(Tufis, 2004), as well as extensions specific to Ara-
bic and Named Entities. The Base Concepts are
translated manually by authors 2 and 3 into Ara-
bic. Encoding is bi-directional: Arabic concepts
for all senses are determined in PWN and encoded
in AWN; when a new Arabic verb is added, exten-
sions are made from verbal entries, including verbal
derivations, nominalizations, verbal nouns, etc.
To date, the database comprises over 8,000
synsets with over 15,000 words; about 1,400 synsets
refer to Named Entities.
Task design With the release of the AWN, we
set out to design a sub-task on Arabic WSD. The
task had only trial and test data released in an
XML compliant format marking instance, sentence
and document boundaries. The relevant words are
marked with their gross part of speech and underly-
ing lemma and English gloss information.
The participants are required to annotate the cho-
sen instances with the synset information from
AWN. Many of the entries in AWN are directly
mapped to PWN 2.0 via the byte offset for the
synsets.
The two subtasks data comprised 1176 verb and
noun instances: 256 verbs and 920 nouns. The an-
notators were only able to annotate 888 instances for
both English and Arabic due to gaps in the AWN.
Hence, the final data set comprised 677 nouns and
211 verbs. The gold standard data is annotated au-
thors 2 and 3 of Arabic (the annotators who created
the AWN). There was always an overlap in the data
of around 300 instances. In the English Arabic WSD
task, participants are provided with a specific En-
glish word in translation to an Arabic instance. They
are also given the full English translation of the Ara-
bic document. Unfortunately, there were no partici-
pants in the task.
</bodyText>
<sectionHeader confidence="0.9945" genericHeader="method">
5 Task: Semantic Role Labeling (SRL)
</sectionHeader>
<bodyText confidence="0.999910619047619">
Shallow approaches to text processing have been
garnering a lot of attention recently. Specifically,
shallow approaches to semantic processing are mak-
ing large strides in the direction of efficiently and
effectively deriving tacit semantic information from
text. Semantic Role Labeling (SRL) is one such ap-
proach. With the advent of faster and powerful com-
puters, more effective machine learning algorithms,
and importantly, large data resources annotated with
relevant levels of semantic information FrameNet
(Baker et al., 1998) and ProbBank corpora (Palmer
et al., 2005), we are seeing a surge in efficient ap-
proaches to SRL (Carreras and M`arquez, 2005).
SRL is the process by which predicates and their
arguments are identified and their roles defined in a
sentence.
To date, most of the reported SRL systems are for
English. We do see some headway for other lan-
guages such as German and Chinese. The systems
for the other languages follow the successful mod-
els devised for English, (Gildea and Jurafsky, 2002;
</bodyText>
<page confidence="0.994789">
95
</page>
<bodyText confidence="0.995017233333334">
Xue and Palmer, 2004; Pradhan et al., 2003). How-
ever, no SRL systems exist for Arabic.
Challenges of Arabic for SRL Given the deep
difference between such languages, this method may
not be straightforward.
To clarify this point, let us consider Figure 1.
It illustrates a sample Arabic syntactic
tree with the relevant part of speech tags
and arguments defined. The sentence is
m$rwE AlAmm AlmtHdp frD mhlp nhAyp l AtAHp
AlfrSp AmAm qbrS. meaning ‘The United Nations’
project imposed a final grace period as an oppor-
tunity for Cyprus’. As we see in the figure, the
predicate is frD ‘imposed’ and it has two numbered
arguments: ARG0 is the subject of the sentence
which is m$rwE AlAmm AlmtHdp ‘United Nations
project’; ARG1, in the object position, namely,
mhlp nhAyp ‘final grace period’. The predicate has
an ARGM-PRP (purpose argument) in l AtAHp
AlfrSp AmAm qbrS ‘as an opportunity for Cyprus’.
As exemplified earlier in Section 2, there are sev-
eral crucial structural differences between English
and Arabic. These differences can make the SRL
task much harder to resolve than it is for English.
Pro-drop could cause a problem for Arabic SRL
systems that do not annotate traces.
Passivization is marked with a short vowel that
hardly ever appears on unvocalized text.
The structural word order could create problems.
For instance for a sentence such as ‘the
man reached—told the boy’, Alrjl ‘the man’ could
be an ARG0 for the VSO, or ARG1 for an VOS.
Or for the following structure Alwld
blg Alrjl ‘the boy reached the man’, Alwld ‘the boy’
could be an ARG0 if it were a SVO sentence, or
could be an ARG1 if it were an OVS sentence.
Idafa constructions may cause problems for argu-
ment boundary detection systems unless the under-
lying parser is sensitive to these constructions. For
example, in the sentence illustrated in Figure 1, the
NP m$rwE AlAmm AlmtHdp ‘the United Nations’
project’ is an idafa construction, so the scope of the
NP has to cover all three words and then assign the
ARG boundary to the correct NP.
Arabic Propbank Taking into consideration
the possible challenges, an Arabic Propbank
(APB) was created. APB comprises 200K words
from ATB 3 version 2 annotating the proposition
for each verb. The chosen verbs occur at least 12
times in the corpus covering 80% of the data. It
provides semantic role annotations for 454 verbal
predicates. The predicates are fully specified for
diacritization hence no two lexically variant verbs
are conflated. APB defines an overall 26 argument
types. We have excluded here 4 of these argument
types, three of which were absent from the training
data and ARGM-TER which marks ATB errors.
Once the verbs are chosen, the framers come up
with frames based on a combination of syntactic
and semantic behaviors expressed by the verb
and its core arguments. The framers use their
native intuition, look at a sample occurrence in the
data, and use external sources to aid them in the
frame-creating process. If the verb has more than
one sense, it is divided into more than one frame
depending on how it relates to its arguments. The
arguments themselves are chosen based not only
on what is deemed semantically necessary, but on
frequency of usage, as well. Figure 1 shows an
example predicate and its arguments annotated with
semantic role labels.
Task Design The Arabic SRL task is split into
an argument boundary detection task and an argu-
ment classification task. We released data for the
95 most frequent verbs. An important characteristic
of the data-set is the use of unvowelized Arabic in
the Buckwalter transliteration scheme. We released
the gold standard parses in the ATB as a source for
syntactic parses for the data. The data is annotated
with the reduced Bies POS tag set (in the LDC ATB
distribution). The data comprises a development
set of 886 sentences, a test set of 902 sentences,
and a training set of 8,402 sentences. The devel-
opment set comprises 1710 argument instances, the
test data comprises 1657 argument instances, and
training data comprises 21,194 argument instances.
For evaluation we use the official CoNLL evaluator
(Carreras and M`arquez, 2005). The evaluation soft-
ware produces accuracy, precision, recall and F,a–i
metrics.
</bodyText>
<page confidence="0.989005">
96
</page>
<figure confidence="0.999555037037037">
S
VBP[PREDICATE] NP[ARG1] PP[ARGM−PRP]
NN
NP
NP[ARG0]
VP
NNP
JJ
AlmtHdp
‘United’
AlAmm
‘Nations’
m$rwE
‘project’
IN
NP
PP
frD
‘imposed’
mhlp
‘grace-period’
nhA}yp
‘final’
NN
JJ
l
‘for’
</figure>
<figureCaption confidence="0.924292">
Figure 1: An example SRL annotated tree
</figureCaption>
<figure confidence="0.998946133333333">
IN
NP
NP
NN
NN
AtAHp
‘giving’
AlfrSp
‘the-opportunity’
NP
NNP
qbrS
‘Cyprus’
AmAm
‘before’
</figure>
<subsectionHeader confidence="0.936222">
5.1 Subtask : Argument Boundary Detection
</subsectionHeader>
<bodyText confidence="0.999930391304348">
In this task, the participating systems are ex-
pected to detect the boundaries of arguments as-
sociated with designated predicates. The systems
are expected to identify the arguments with the
correct level of scoping. For instance, in our
running example sentence, the argument bound-
aries for the verb frD ‘imposed’ are illus-
trated as follows: [m$rwE AlAmm AlmtHdp]ARG
[frD]LemmajaroD [mhlp nhA}yp]ARG [l AtAHp Al-
frSp AmAm qbrS]ARG. The three relevant argu-
ments are m$rwE AlAmm AlmtHdp ‘the United Na-
tions Project’, mhlp nhA}yp ‘final grace-period’, and
l AtAHp AlfrSp AmAm qbrS ‘as an opportunity for
Cyprus’.
Only one system (CUNIT) participated in the sub-
task. CUNIT is an SVM based discriminative clas-
sification system based on different degrees polyno-
mial kernels. The best CUNIT system (with degree
2 kernel) achieves an F13_1 argument boundary de-
tection score of 93.68% on the development data and
94.06% on the test data. We note that the results on
the test data are higher than on the development data
indicating that the test data is relatively easier.
</bodyText>
<subsectionHeader confidence="0.971041">
5.2 Subtask: Argument Classification
</subsectionHeader>
<bodyText confidence="0.9999866">
In this task, the participating systems are expected
to identify the class of the arguments detected in the
previous step of argument boundary detection. In
this sub task we have 22 argument types. Table 1
illustrates the different argument types and their dis-
tributions between the dev, train and test sets.
The most frequent arguments are ARG0, ARG1,
ARG2 and ARGM-TMP. This is similar to what we
see in the English Propbank. We note the additional
ARG types with the extension STR. These are for
stranded arguments. The tag STR is used when one
constituent cannot be selected and an argument has
two or more concatenated constituents. An exam-
ple of this type of ARG is
{stqr fy nyw ywrk fy brwklyn ‘he settled in New
York, in Brooklyn’. In this case, fy nyw ywrk ‘in
New York’ is labeled ARG1 and fy brwklyn ‘in
Brooklyn’ is labeled ARG1-STR.
Only one system (CUNIT) participated in the
SRL subtask. CUNIT is an SVM based discrimina-
tive classification system based on different degrees
polynomial kernels. The best CUNIT system (with
degree 2 kernel) achieves an overall F,3_1 score for
all arguments classification of 77.84% on the devel-
opment data and 81.43% on the test data. It is worth
noting that these results are run with the automatic
argument boundary detection as an initial step. In
both the test and the development results, the preci-
sion is significantly higher than the recall. For the
development set precision is 81.31% and the recall
</bodyText>
<page confidence="0.998371">
97
</page>
<table confidence="0.99986208">
#train #dev #test
ARG0 6,328 227 256
ARG0-STR 70 8 5
ARG1 7,858 702 699
ARG1-PRD 38 2 3
ARG1-STR 172 23 13
ARG2 1,843 191 180
ARG2-STR 32 5 4
ARG3 164 13 12
ARG4 15 0 4
ARGM 79 6 1
ARGM-ADV 994 103 115
ARGM-BNF 53 5 7
ARGM-CAU 89 12 11
ARGM-CND 38 6 3
ARGM-DIR 25 3 1
ARGM-DIS 56 8 5
ARGM-EXT 21 0 1
ARGM-LOC 711 82 61
ARGM-MNR 623 85 55
ARGM-NEG 529 76 39
ARGM-PRD 77 14 12
ARGM-PRP 343 42 27
ARGM-TMP 1,347 96 107
Total 21,194 1,710 1,657
</table>
<tableCaption confidence="0.990007">
Table 1: Distribution of training, development and test in-
stances on the different role types.
</tableCaption>
<bodyText confidence="0.999747166666667">
is 74.67%. For the test set, the precision is 84.71%
and the recall is 78.39%. We note that, similar to
the boundary detection sub-task, the results on the
test data are significantly higher than on the devel-
opment data which suggests that the test data is rel-
atively easier.
</bodyText>
<sectionHeader confidence="0.999578" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999927739130435">
In this paper, we presented a description of Task 18
on Arabic Semantic labeling. Our goal was to rally
interest in Arabic Semantic labeling. On the word
sense disambiguation front, we have successfully
created an all-words sense annotated set of Arabic
nouns and verbs in running text. The set is anno-
tated with both Arabic WordNet synset labels and
their corresponding English WordNet 2.0 synset la-
bels. Unfortunately, no systems participated in the
WSD sub-tasks, however, we have prepared the data
for future endeavors and hopefully this will motivate
researchers in NLP to start experimenting with Ara-
bic WSD.
On the task of Semantic Role Labeling, we have
created a test, training and development set that has
been successfully validated through being employed
for building the first Arabic SRL system. Hopefully,
this data will help propel research in Arabic SRL.
It is also worth noting that we currently have effec-
tively created a data set that is annotated for word
senses, lexical information such as full morpholog-
ical specifications, syntactic and semantic parses as
well as English glosses and translations.
</bodyText>
<sectionHeader confidence="0.999188" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999725609756097">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998.
The berkeley FrameNet project. In COLING-ACL ’98:
Proceedings of the Conference, held at the University of
Montr´eal, pages 86–90.
Tim Buckwalter. 2002. Buckwalter Arabic Morphological An-
alyzer Version 1.0. Linguistic Data Consortium, University
of Pennsylvania, 2002. LDC Catalog No.: LDC2002L49.
Xavier Carreras and Llu´is M`arquez. 2005. Introduction to the
CoNLL-2005 shared task: Semantic role labeling. In Pro-
ceedings of CoNLL-2005, Ann Arbor, Michigan.
S. Elkateb, H. Rodriguez, M. Alkhalifa, P. Vossen, A. Pease,
M. Bertran, W. Black, and C. Fellbaum. 2006. The arabic
wordnet project. In Proceedings of the Conference on Lex-
ical Resources in the European Community, Genoa, Italy,
May.
Christiane Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press. http://www.cogsci.princeton.edu/˜wn
[2000, September 7].
Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling
of semantic roles. Computational Linguistics, 28(3):245–
288.
Nancy Ide and Jean Veronis. 1998. Word sense disambigua-
tion: State of the art. In Computational Linguistics, num-
ber 24, pages 1–40.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wig dan
Mekki. 2004. The penn arabic treebank : Building a large-
scale annotated arabic corpus.
Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005. The
proposition bank: A corpus anotated with semantic roles. In
Computational Linguistics Journal, number 31:1.
Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H. Mar-
tin, and Daniel Jurafsky. 2003. Semantic role parsing:
Adding semantic structure to unstructured text. In Proceed-
ings ofICDM-2003, Melbourne, USA.
Dan Tufis. 2004. The balkanet project. In Special Issue of The
Romanian Journal of Information Science and Technology,
number 7, pages 1–248.
Nianwen Xue and Martha Palmer. 2004. Calibrating features
for semantic role labeling. In Dekang Lin and Dekai Wu, ed-
itors, Proceedings ofEMNLP2004, pages 88–94, Barcelona,
Spain, July. Association for Computational Linguistics.
</reference>
<page confidence="0.996236">
98
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.851290">
<title confidence="0.996533">Semeval 2007 Task 18: Arabic Semantic Labeling</title>
<author confidence="0.997653">Mona Diab Musa Alkhalifa Sabri Elkateb</author>
<affiliation confidence="0.999943">Columbia University University of Barcelona University of Manchester</affiliation>
<email confidence="0.91535">mdiab@cs.columbia.edumusa@thera-clic.comSabri.Elkateb@manchester.ac.uk</email>
<author confidence="0.993308">Christiane Fellbaum Aous Mansouri Martha Palmer</author>
<affiliation confidence="0.98457">Princeton University University of Colorado, Boulder University of Colorado, Boulder</affiliation>
<email confidence="0.999795">fellbaum@clarity.princeton.eduaous.mansouri@colorado.edumartha.palmer@colorado.edu</email>
<abstract confidence="0.994186625">In this paper, we present the details of the Arabic Semantic Labeling task. We describe some of the features of Arabic that are relevant for the task. The task comprises two subtasks: Arabic word sense disambiguation and Arabic semantic role labeling. The task focuses on modern standard Arabic.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In COLING-ACL ’98: Proceedings of the Conference, held at the University of Montr´eal,</booktitle>
<pages>86--90</pages>
<contexts>
<context position="12029" citStr="Baker et al., 1998" startWordPosition="1931" endWordPosition="1934">ortunately, there were no participants in the task. 5 Task: Semantic Role Labeling (SRL) Shallow approaches to text processing have been garnering a lot of attention recently. Specifically, shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; 95 Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley FrameNet project. In COLING-ACL ’98: Proceedings of the Conference, held at the University of Montr´eal, pages 86–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium,</title>
<date>2002</date>
<publisher>LDC Catalog</publisher>
<institution>University of Pennsylvania,</institution>
<location>No.:</location>
<contexts>
<context position="6057" citStr="Buckwalter, 2002" startWordPosition="938" endWordPosition="939">ncodes that the subject is a 3rd person masculine singular. This sentence is exactly equivalent to hw Akl AlbrtqAl ‘he ate the-oranges’. In the Arabic Treebank (ATB), we observe that 30% of all sentences are pro-dropped for subject. Also Arabic is different from English in that it exhibits a larger degree of free word order. For example, Arabic allows for subject-verb-object (SVO) and verb-subject-object (VSO) argument orders, as well as, OSV and OVS. In the ATB, we observe an equal distribution of both VSO and SVO orders 4We use the Buckwalter transliteration scheme to show romanized Arabic (Buckwalter, 2002). each equally 35% of the time. An example of an SVO sentence is AlrjAl AklwA AlbrtqAl ‘the-men ate-them the-oranges’, this is contrasted with Akl AlrjAl AlbrtqAl ‘ate the-men the-oranges’. Arabic exhibits more complex noun phrases than English mainly to express possession. These constructions are known as idafa constructions. In these complex structures an indefinite noun is followed by a definite noun. For example, rjl Albyt ‘man the-house’ meaning ‘man of the house’. Accordingly, MSA does not have a special prepositional use to express possession in a manner similar to English. 3 Overall Ta</context>
</contexts>
<marker>Buckwalter, 2002</marker>
<rawString>Tim Buckwalter. 2002. Buckwalter Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium, University of Pennsylvania, 2002. LDC Catalog No.: LDC2002L49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´is M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 shared task: Semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-2005,</booktitle>
<location>Ann Arbor, Michigan.</location>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Llu´is M`arquez. 2005. Introduction to the CoNLL-2005 shared task: Semantic role labeling. In Proceedings of CoNLL-2005, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Elkateb</author>
<author>H Rodriguez</author>
<author>M Alkhalifa</author>
<author>P Vossen</author>
<author>A Pease</author>
<author>M Bertran</author>
<author>W Black</author>
<author>C Fellbaum</author>
</authors>
<title>The arabic wordnet project.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Lexical Resources in the European Community,</booktitle>
<location>Genoa, Italy,</location>
<contexts>
<context position="3018" citStr="Elkateb et al., 2006" startWordPosition="446" endWordPosition="449">e labels. We specifically chose data that overlapped such that we would have the same data annotated for different types of semantics, lexical and structural. The overall task of Arabic Semantic Labeling was subdivided into 4 sub-tasks: Arabic word sense disambiguation (AWSD), English to Arabic WSD task (EAWSD), argument detection within the context of semantic role labeling, and argument semantic role classification. Such a set of tasks would not have been feasible without the existence of several crucial resources: the Arabic Treebank (ATB) (Maamouri et al., 2004), the Arabic WordNet (AWN) (Elkateb et al., 2006), and the Pilot Arabic Propbank (APB).2 This paper is laid out as follows: Section 2 will describe some facts about the Arabic language; Section 3 will present the overall description of the tasks; Section 4 describes the word sense disambiguation task; Section 5 describes the semantic role labeling task. 2 The Arabic Language In the context of our tasks, we only deal with MSA.3 Arabic is a Semitic language. It is known for its templatic morphology where words are made up of 2Funded by DARPA subcontract to BBN Inc. to University of Colorado, LDC-UPenn and Columbia University. 3In this paper we</context>
</contexts>
<marker>Elkateb, Rodriguez, Alkhalifa, Vossen, Pease, Bertran, Black, Fellbaum, 2006</marker>
<rawString>S. Elkateb, H. Rodriguez, M. Alkhalifa, P. Vossen, A. Pease, M. Bertran, W. Black, and C. Fellbaum. 2006. The arabic wordnet project. In Proceedings of the Conference on Lexical Resources in the European Community, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>http://www.cogsci.princeton.edu/˜wn</location>
<contexts>
<context position="9561" citStr="Fellbaum, 1998" startWordPosition="1519" endWordPosition="1520">tion made between kly—p ‘all’ or ‘college’, and klyp ‘kidney’. Hence, full diacritization may be viewed as a level of WSD. But crucially, naturally occurring Arabic text conflates more words due to the writing system. To date, very little work has been published on Arabic WSD. This is mainly attributed to the lack in lexical resources for the Arabic language. But this picture is about to change with the new release of an Arabic WordNet (AWN). Arabic WordNet Arabic WordNet (AWN) is a lexical resource for modern standard Arabic. AWN is based on the design and contents of Princeton WordNet (PWN)(Fellbaum, 1998) and can be mapped onto PWN as well as a number of other wordnets, enabling translation on the lexical level to and from dozens of other languages. AWN focuses on the the Common Base Concepts (Tufis, 2004), as well as extensions specific to Arabic and Named Entities. The Base Concepts are translated manually by authors 2 and 3 into Arabic. Encoding is bi-directional: Arabic concepts for all senses are determined in PWN and encoded in AWN; when a new Arabic verb is added, extensions are made from verbal entries, including verbal derivations, nominalizations, verbal nouns, etc. To date, the data</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press. http://www.cogsci.princeton.edu/˜wn [2000, September 7].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>288</pages>
<contexts>
<context position="12513" citStr="Gildea and Jurafsky, 2002" startWordPosition="2015" endWordPosition="2018">arning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; 95 Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward. To clarify this point, let us consider Figure 1. It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined. The sentence is m$rwE AlAmm AlmtHdp frD mhlp nhAyp l AtAHp AlfrSp AmAm qbrS. meaning ‘The United Nations’ project imposed a final grace period as an opportunity for Cyprus’. As we see in the figure, the predicate is frD ‘imposed’ and</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245– 288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean Veronis</author>
</authors>
<title>Word sense disambiguation: State of the art.</title>
<date>1998</date>
<booktitle>In Computational Linguistics, number 24,</booktitle>
<pages>1--40</pages>
<contexts>
<context position="8222" citStr="Ide and Veronis, 1998" startWordPosition="1298" endWordPosition="1301">eleased data for the subtasks is unvowelized and romanized using the Buckwalter transliteration scheme. The part of speech (POS) tag set used in the released data for both the WSD and the SRL sub-tasks is the reduced tag set that is officially released with the ATB. 4 Task: WSD In the context of this task, word sense disambiguation is the process by which words in context are tagged with their specific meaning definitions from a predefined lexical resource such as a dictionary or taxonomy. The NLP field has gone through a very 94 long tradition of algorithms designed for solving this problem (Ide and Veronis, 1998). Most of the systems however target English since it is the language with most resources. In fact a big push forward dawned on English WSD with the wide release of significant resources such as WordNet. Arabic poses some interesting challenges for WSD since it has an inherent complexity in its writing system. As mentioned earlier, written MSA is underspecified for short vowels and diacritics. These short vowels and diacritics convey both lexical and inflectional information. For example, klyp could mean three different things, ‘all’, ‘kidney’ and ‘college’. Due to the undiacritized, unvoweliz</context>
</contexts>
<marker>Ide, Veronis, 1998</marker>
<rawString>Nancy Ide and Jean Veronis. 1998. Word sense disambiguation: State of the art. In Computational Linguistics, number 24, pages 1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wig dan Mekki</author>
</authors>
<title>The penn arabic treebank : Building a largescale annotated arabic corpus.</title>
<date>2004</date>
<contexts>
<context position="2969" citStr="Maamouri et al., 2004" startWordPosition="438" endWordPosition="441">vels of granularity: sense labels and semantic role labels. We specifically chose data that overlapped such that we would have the same data annotated for different types of semantics, lexical and structural. The overall task of Arabic Semantic Labeling was subdivided into 4 sub-tasks: Arabic word sense disambiguation (AWSD), English to Arabic WSD task (EAWSD), argument detection within the context of semantic role labeling, and argument semantic role classification. Such a set of tasks would not have been feasible without the existence of several crucial resources: the Arabic Treebank (ATB) (Maamouri et al., 2004), the Arabic WordNet (AWN) (Elkateb et al., 2006), and the Pilot Arabic Propbank (APB).2 This paper is laid out as follows: Section 2 will describe some facts about the Arabic language; Section 3 will present the overall description of the tasks; Section 4 describes the word sense disambiguation task; Section 5 describes the semantic role labeling task. 2 The Arabic Language In the context of our tasks, we only deal with MSA.3 Arabic is a Semitic language. It is known for its templatic morphology where words are made up of 2Funded by DARPA subcontract to BBN Inc. to University of Colorado, LDC</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wig dan Mekki. 2004. The penn arabic treebank : Building a largescale annotated arabic corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Dan Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: A corpus anotated with semantic roles.</title>
<date>2005</date>
<journal>In Computational Linguistics Journal, number</journal>
<pages>31--1</pages>
<contexts>
<context position="12072" citStr="Palmer et al., 2005" startWordPosition="1938" endWordPosition="1941">the task. 5 Task: Semantic Role Labeling (SRL) Shallow approaches to text processing have been garnering a lot of attention recently. Specifically, shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; 95 Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005. The proposition bank: A corpus anotated with semantic roles. In Computational Linguistics Journal, number 31:1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Semantic role parsing: Adding semantic structure to unstructured text.</title>
<date>2003</date>
<booktitle>In Proceedings ofICDM-2003,</booktitle>
<location>Melbourne, USA.</location>
<contexts>
<context position="12561" citStr="Pradhan et al., 2003" startWordPosition="2024" endWordPosition="2027">rces annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; 95 Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward. To clarify this point, let us consider Figure 1. It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined. The sentence is m$rwE AlAmm AlmtHdp frD mhlp nhAyp l AtAHp AlfrSp AmAm qbrS. meaning ‘The United Nations’ project imposed a final grace period as an opportunity for Cyprus’. As we see in the figure, the predicate is frD ‘imposed’ and it has two numbered arguments: ARG0 is the subj</context>
</contexts>
<marker>Pradhan, Hacioglu, Ward, Martin, Jurafsky, 2003</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2003. Semantic role parsing: Adding semantic structure to unstructured text. In Proceedings ofICDM-2003, Melbourne, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufis</author>
</authors>
<title>The balkanet project.</title>
<date>2004</date>
<journal>In Special Issue of The Romanian Journal of Information Science and Technology,</journal>
<volume>7</volume>
<pages>1--248</pages>
<contexts>
<context position="9766" citStr="Tufis, 2004" startWordPosition="1556" endWordPosition="1557">g system. To date, very little work has been published on Arabic WSD. This is mainly attributed to the lack in lexical resources for the Arabic language. But this picture is about to change with the new release of an Arabic WordNet (AWN). Arabic WordNet Arabic WordNet (AWN) is a lexical resource for modern standard Arabic. AWN is based on the design and contents of Princeton WordNet (PWN)(Fellbaum, 1998) and can be mapped onto PWN as well as a number of other wordnets, enabling translation on the lexical level to and from dozens of other languages. AWN focuses on the the Common Base Concepts (Tufis, 2004), as well as extensions specific to Arabic and Named Entities. The Base Concepts are translated manually by authors 2 and 3 into Arabic. Encoding is bi-directional: Arabic concepts for all senses are determined in PWN and encoded in AWN; when a new Arabic verb is added, extensions are made from verbal entries, including verbal derivations, nominalizations, verbal nouns, etc. To date, the database comprises over 8,000 synsets with over 15,000 words; about 1,400 synsets refer to Named Entities. Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The task had o</context>
</contexts>
<marker>Tufis, 2004</marker>
<rawString>Dan Tufis. 2004. The balkanet project. In Special Issue of The Romanian Journal of Information Science and Technology, number 7, pages 1–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings ofEMNLP2004,</booktitle>
<pages>88--94</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="12538" citStr="Xue and Palmer, 2004" startWordPosition="2020" endWordPosition="2023">ntly, large data resources annotated with relevant levels of semantic information FrameNet (Baker et al., 1998) and ProbBank corpora (Palmer et al., 2005), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence. To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, (Gildea and Jurafsky, 2002; 95 Xue and Palmer, 2004; Pradhan et al., 2003). However, no SRL systems exist for Arabic. Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward. To clarify this point, let us consider Figure 1. It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined. The sentence is m$rwE AlAmm AlmtHdp frD mhlp nhAyp l AtAHp AlfrSp AmAm qbrS. meaning ‘The United Nations’ project imposed a final grace period as an opportunity for Cyprus’. As we see in the figure, the predicate is frD ‘imposed’ and it has two numbered argu</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating features for semantic role labeling. In Dekang Lin and Dekai Wu, editors, Proceedings ofEMNLP2004, pages 88–94, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>