<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005069">
<title confidence="0.988761">
Alignment-Based Discriminative String Similarity
</title>
<author confidence="0.99716">
Shane Bergsma and Grzegorz Kondrak
</author>
<affiliation confidence="0.997966">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.638303">
Edmonton, Alberta, Canada, T6G 2E8
</address>
<email confidence="0.999117">
{bergsma,kondrak}@cs.ualberta.ca
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971368421053">
A character-based measure of similarity is
an important component of many natu-
ral language processing systems, including
approaches to transliteration, coreference,
word alignment, spelling correction, and the
identification of cognates in related vocabu-
laries. We propose an alignment-based dis-
criminative framework for string similarity.
We gather features from substring pairs con-
sistent with a character-based alignment of
the two strings. This approach achieves
exceptional performance; on nine separate
cognate identification experiments using six
language pairs, we more than double the pre-
cision of traditional orthographic measures
like Longest Common Subsequence Ratio
and Dice’s Coefficient. We also show strong
improvements over other recent discrimina-
tive and heuristic similarity functions.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999764681818182">
String similarity is often used as a means of quan-
tifying the likelihood that two pairs of strings have
the same underlying meaning, based purely on the
character composition of the two words. Strube et
al. (2002) use Edit Distance as a feature for de-
termining if two words are coreferent. Taskar et
al. (2005) use French-English common letter se-
quences as a feature for discriminative word align-
ment in bilingual texts. Brill and Moore (2000) learn
misspelled-word to correctly-spelled-word similari-
ties for spelling correction. In each of these exam-
ples, a similarity measure can make use of the recur-
rent substring pairings that reliably occur between
words having the same meaning.
Across natural languages, these recurrent sub-
string correspondences are found in word pairs
known as cognates: words with a common form
and meaning across languages. Cognates arise ei-
ther from words in a common ancestor language
(e.g. light/Licht, night/Nacht in English/German)
or from foreign word borrowings (e.g. trampo-
line/toranporin in English/Japanese). Knowledge of
cognates is useful for a number of applications, in-
cluding sentence alignment (Melamed, 1999) and
learning translation lexicons (Mann and Yarowsky,
2001; Koehn and Knight, 2002).
We propose an alignment-based, discriminative
approach to string similarity and evaluate this ap-
proach on cognate identification. Section 2 de-
scribes previous approaches and their limitations. In
Section 3, we explain our technique for automati-
cally creating a cognate-identification training set. A
novel aspect of this set is the inclusion of competitive
counter-examples for learning. Section 4 shows how
discriminative features are created from a character-
based, minimum-edit-distance alignment of a pair
of strings. In Section 5, we describe our bitext and
dictionary-based experiments on six language pairs,
including three based on non-Roman alphabets. In
Section 6, we show significant improvements over
traditional approaches, as well as significant gains
over more recent techniques by Ristad and Yiani-
los (1998), Tiedemann (1999), Kondrak (2005), and
Klementiev and Roth (2006).
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.995759">
String similarity is a fundamental concept in a va-
riety of fields and hence a range of techniques
</bodyText>
<page confidence="0.993144">
656
</page>
<note confidence="0.9255255">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999887681159421">
have been developed. We focus on approaches
that have been applied to words, i.e., uninterrupted
sequences of characters found in natural language
text. The most well-known measure of the simi-
larity of two strings is the Edit Distance or Lev-
enshtein Distance (Levenshtein, 1966): the number
of insertions, deletions and substitutions required to
transform one string into another. In our experi-
ments, we use Normalized Edit Distance (NED):
Edit Distance divided by the length of the longer
word. Other popular measures include Dice’s Coef-
ficient (DICE) (Adamson and Boreham, 1974), and
the length-normalized measures Longest Common
Subsequence Ratio (LCSR) (Melamed, 1999), and
Longest Common Prefix Ratio (PREFIX) (Kondrak,
2005). These baseline approaches have the impor-
tant advantage of not requiring training data. We
can also include in the non-learning category Kon-
drak (2005)’s Longest Common Subsequence For-
mula (LCSF), a probabilistic measure designed to
mitigate LCSR’s preference for shorter words.
Although simple to use, the untrained measures
cannot adapt to the specific spelling differences be-
tween a pair of languages. Researchers have there-
fore investigated adaptive measures that are learned
from a set of known cognate pairs. Ristad and Yiani-
los (1998) developed a stochastic transducer version
of Edit Distance learned from unaligned string pairs.
Mann and Yarowsky (2001) saw little improvement
over Edit Distance when applying this transducer to
cognates, even when filtering the transducer’s proba-
bilities into different weight classes to better approx-
imate Edit Distance. Tiedemann (1999) used various
measures to learn the recurrent spelling changes be-
tween English and Swedish, and used these changes
to re-weight LCSR to identify more cognates, with
modest performance improvements. Mulloni and
Pekar (2006) developed a similar technique to im-
prove NED for English/German.
Essentially, all these techniques improve on the
baseline approaches by using a set of positive (true)
cognate pairs to re-weight the costs of edit op-
erations or the score of sequence matches. Ide-
ally, we would prefer a more flexible approach that
can learn positive or negative weights on substring
pairings in order to better identify related strings.
One system that can potentially provide this flexi-
bility is a discriminative string-similarity approach
to named-entity transliteration by Klementiev and
Roth (2006). Although not compared to other simi-
larity measures in the original paper, we show that
this discriminative technique can strongly outper-
form traditional methods on cognate identification.
Unlike many recent generative systems, the Kle-
mentiev and Roth approach does not exploit the
known positions in the strings where the characters
match. For example, Brill and Moore (2000) com-
bine a character-based alignment with the Expec-
tation Maximization (EM) algorithm to develop an
improved probabilistic error model for spelling cor-
rection. Rappoport and Levent-Levi (2006) apply
this approach to learn substring correspondences for
cognates. Zelenko and Aone (2006) recently showed
a Klementiev and Roth (2006)-style discriminative
approach to be superior to alignment-based genera-
tive techniques for name transliteration. Our work
successfully uses the alignment-based methodology
of the generative approaches to enhance the feature
set for discriminative string similarity.
</bodyText>
<sectionHeader confidence="0.984637" genericHeader="method">
3 The Cognate Identification Task
</sectionHeader>
<bodyText confidence="0.996577041666667">
Given two string lists, E and F, the task of cog-
nate identification is to find all pairs of strings (e, f)
that are cognate. In other similarity-driven applica-
tions, E and F could be misspelled and correctly
spelled words, or the orthographic and the phonetic
representation of words, etc. The task remains to
link strings with common meaning in E and F us-
ing only the string similarity measure.
We can facilitate the application of string simi-
larity to cognates by using a definition of cognation
not dependent on etymological analysis. For ex-
ample, Mann and Yarowsky (2001) define a word
pair (e, f) to be cognate if they are a translation
pair (same meaning) and their Edit Distance is less
than three (same form). We adopt an improved
definition (suggested by Melamed (1999) for the
French-English Canadian Hansards) that does not
over-propose shorter word pairs: (e, f) are cog-
nate if they are translations and their LCSR &gt;
0.58. Note that this cutoff is somewhat conser-
vative: the English/German cognates light/Licht
(LCSR=0.8) are included, but not the cognates
eight/acht (LCSR=0.4).
If two words must have LCSR &gt; 0.58 to be cog-
</bodyText>
<page confidence="0.997205">
657
</page>
<table confidence="0.70967075">
Foreign Language F Words f E F Cognates Ef+ False Friends Ef_
Japanese (Rˆomaji) napukin napkin nanking, pumpkin, snacking, sneaking
French abondamment abundantly abandonment, abatement, ... wonderment
German prozyklische procyclical polished, prophylactic, prophylaxis
</table>
<tableCaption confidence="0.997669">
Table 1: Foreign-English cognates and false friend training examples.
</tableCaption>
<bodyText confidence="0.999802448275862">
nate, then for a given word f E F, we need only
consider as possible cognates the subset of words in
E having an LCSR with f larger than 0.58, a set we
call Ef. The portion of Ef with the same meaning
as f, Ef+, are cognates, while the part with differ-
ent meanings, Ef_, are not cognates. The words
Ef_ with similar spelling but different meaning are
sometimes called false friends. The cognate identi-
fication task is, for every word f E F, and a list of
similarly spelled words Ef, to distinguish the cog-
nate subset Ef+ from the false friend set Ef_.
To create training data for our learning ap-
proaches, and to generate a high-quality labelled test
set, we need to annotate some of the (f, ef E Ef)
word pairs for whether or not the words share a
common meaning. In Section 5, we explain our
two high-precision automatic annotation methods:
checking if each pair of words (a) were aligned in
a word-aligned bitext, or (b) were listed as transla-
tion pairs in a bilingual dictionary.
Table 1 provides some labelled examples with
non-empty cognate and false friend lists. Note that
despite these examples, this is not a ranking task:
even in highly related languages, most words in F
have empty Ef+ lists, and many have empty Ef_
as well. Thus one natural formulation for cognate
identification is a pairwise (and symmetric) cogna-
tion classification that looks at each pair (f, ef) sep-
arately and individually makes a decision:
</bodyText>
<equation confidence="0.997304">
+(napukin,napkin)
– (napukin,nanking)
– (napukin,pumpkin)
</equation>
<bodyText confidence="0.99999125">
In this formulation, the benefits of a discrimina-
tive approach are clear: it must find substrings that
distinguish cognate pairs from word pairs with oth-
erwise similar form. Klementiev and Roth (2006),
although using a discriminative approach, do not
provide their infinite-attribute perceptron with com-
petitive counter-examples. They instead use translit-
erations as positives and randomly-paired English
and Russian words as negative examples. In the fol-
lowing section, we also improve on Klementiev and
Roth (2006) by using a character-based string align-
ment to focus the features for discrimination.
</bodyText>
<sectionHeader confidence="0.999563" genericHeader="method">
4 Features for Discriminative Similarity
</sectionHeader>
<bodyText confidence="0.973341416666667">
Discriminative learning works by providing a train-
ing set of labelled examples, each represented as a
set of features, to a module that learns a classifier. In
the previous section we showed how labelled word
pairs can be collected. We now address methods of
representing these word pairs as sets of features use-
ful for determining cognation.
Consider the Rˆomaji Japanese/English cognates:
(sutoresu,stress). The LCSR is 0.625. Note that the
LCSR of sutoresu with the English false friend sto-
ries is higher: 0.75. LCSR alone is too weak a fea-
ture to pick out cognates. We need to look at the
actual character substrings.
Klementiev and Roth (2006) generate features for
a pair of words by splitting both words into all pos-
sible substrings of up to size two:
sutoresu { s, u, t, o, r, e, s, u, su, ut, to, ... su }
stress { s, t, r, e, s, s, st, tr, re, es, ss }
Then, a feature vector is built from all substring pairs
from the two words such that the difference in posi-
tions of the substrings is within one:
{s-s, s-t, s-st, su-s, su-t, su-st, su-tr... r-s, r-s, r-es...}
This feature vector provides the feature representa-
tion used in supervised machine learning.
This example also highlights the limitations of the
Klementiev and Roth approach. The learner can pro-
vide weight to features like s-s or s-st at the begin-
ning of the word, but because of the gradual accu-
mulation of positional differences, the learner never
sees the tor-tr and es-es correspondences that really
help indicate the words are cognate.
Our solution is to use the minimum-edit-distance
alignment of the two strings as the basis for fea-
ture extraction, rather than the positional correspon-
dences. We also include beginning-of-word (ˆ) and
end-of-word ($) markers (referred to as boundary
</bodyText>
<page confidence="0.953039">
658
</page>
<bodyText confidence="0.994373810126582">
markers) to highlight correspondences at those po- proaches in our experiments. Also, there is no rea-
sitions. The pair (sutoresu, stress) can be aligned: son not to include the scores of baseline approaches
like NED, LCSR, PREFIX or DICE as features in
the representation as well. Features like the lengths
of the two words and the difference in lengths of the
words have also proved to be useful in preliminary
experiments. Semantic features like frequency simi-
larity or contextual similarity might also be included
to help determine cognation between words that are
not present in a translation lexicon or bitext.
5 Experiments
Section 3 introduced two high-precision methods for
generating labelled cognate pairs: using the word
alignments from a bilingual corpus or using the en-
tries in a translation lexicon. We investigate both of
these methods in our experiments. In each case, we
generate sets of labelled word pairs for training, test-
ing, and development. The proportion of positive ex-
amples in the bitext-labelled test sets range between
1.4% and 1.8%, while ranging between 1.0% and
1.6% for the dictionary data.2
For the discriminative methods, we use a popu-
lar Support Vector Machine (SVM) learning pack-
age called SVM&amp;quot;ght (Joachims, 1999). SVMs are
maximum-margin classifiers that achieve good per-
formance on a range of tasks. In each case, we
learn a linear kernel on the training set pairs and
tune the parameter that trades-off training error and
margin on the development set. We apply our classi-
fier to the test set and score the pairs by their pos-
itive distance from the SVM classification hyper-
plane (also done by Bilenko and Mooney (2003)
with their token-based SVM similarity measure).
We also score the test sets using traditional ortho-
graphic similarity measures PREFIX, DICE, LCSR,
and NED, an average of these four, and Kondrak
(2005)’s LCSF. We also use the log of the edit prob-
ability from the stochastic decoder of Ristad and
Yianilos (1998) (normalized by the length of the
longer word) and Tiedemann (1999)’s highest per-
forming system (Approach #3). Both use only the
positive examples in our training set. Our evaluation
metric is 11-pt average precision on the score-sorted
pair lists (also used by Kondrak and Sherif (2006)).
For the feature representation, we only extract sub-
string pairs that are consistent with this alignment.1
That is, the letters in our pairs can only be aligned to
each other and not to letters outside the pairing:
{ ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...}
We define phrase pairs to be the pairs of substrings
consistent with the alignment. A similar use of the
term “phrase” exists in machine translation, where
phrases are often pairs of word sequences consistent
with word-based alignments (Koehn et al., 2003).
By limiting the substrings to only those pairs
that are consistent with the alignment, we gener-
ate fewer, more-informative features. Using more
precise features allows a larger maximum substring
size L than is feasible with the positional approach.
Larger substrings allow us to capture important re-
curring deletions like the “u” in sut-st.
Tiedemann (1999) and others have shown the im-
portance of using the mismatching portions of cog-
nate pairs to learn the recurrent spelling changes be-
tween two languages. In order to capture mismatch-
ing segments longer than our maximum substring
size will allow, we include special features in our
representation called mismatches. Mismatches are
phrases that span the entire sequence of unaligned
characters between two pairs of aligned end char-
acters (similar to the “rules” extracted by Mulloni
and Pekar (2006)). In the above example, su$-ss$
is a mismatch with “s” and “$” as the aligned end
characters. Two sets of features are taken from each
mismatch, one that includes the beginning/ending
aligned characters as context and one that does not.
For example, for the endings of the French/English
pair (´economique,economic), we include both the
substring pairs ique$:ic$ and que:c as features.
</bodyText>
<table confidence="0.789870636363636">
One consideration is whether substring features
should be binary presence/absence, or the count of
the feature in the pair normalized by the length of
the longer word. We investigate both of these ap-
1If the words are from different alphabets, we can get the
alignment by mapping the letters to their closest Roman equiv-
alent, or by using the EM algorithm to learn the edits (Ristad
and Yianilos, 1998).
2The cognate data sets used in our experiments are available
at http://www.cs.ualberta.ca/˜bergsma/Cognates/
659
</table>
<subsectionHeader confidence="0.987803">
5.1 Bitext Experiments
</subsectionHeader>
<bodyText confidence="0.999952380952381">
For the bitext-based annotation, we use publicly-
available word alignments from the Europarl corpus,
automatically generated by GIZA++ for French-
English (Fr), Spanish-English (Es) and German-
English (De) (Koehn and Monz, 2006). Initial clean-
ing of these noisy word pairs is necessary. We thus
remove all pairs with numbers, punctuation, a capi-
talized English word, and all words that occur fewer
than ten times. We also remove many incorrectly
aligned words by filtering pairs where the pairwise
Mutual Information between the words is less than
7.5. This processing leaves vocabulary sizes of 39K
for French, 31K for Spanish, and 60K for German.
Our labelled set is then generated from pairs
with LCSR  0.58 (using the cutoff from Melamed
(1999)). Each labelled set entry is a triple of a) the
foreign word f, b) the cognates Ef+ and c) the false
friends Ef_. For each language pair, we randomly
take 20K triples for training, 5K for development
and 5K for testing. Each triple is converted to a set
of pairwise examples for learning and classification.
</bodyText>
<subsectionHeader confidence="0.997851">
5.2 Dictionary Experiments
</subsectionHeader>
<bodyText confidence="0.999985777777778">
For the dictionary-based cognate identification, we
use French, Spanish, German, Greek (Gr), Japanese
(Jp), and Russian (Rs) to English translation pairs
from the Freelang program.3 The latter three pairs
were chosen so that we can evaluate on more distant
languages that use non-Roman alphabets (although
the Rˆomaji Japanese is Romanized by definition).
We take 10K labelled-set triples for training, 2K for
testing and 2K for development.
The baseline approaches and our definition of
cognation require comparison in a common alpha-
bet. Thus we use a simple context-free mapping to
convert every Russian and Greek character in the
word pairs to their nearest Roman equivalent. We
then label a translation pair as cognate if the LCSR
between the words’ Romanized representations is
greater than 0.58. We also operate all of our com-
parison systems on these Romanized pairs.
</bodyText>
<sectionHeader confidence="0.999958" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9986205">
We were interested in whether our working defini-
tion of cognation (translations and LCSR  0.58)
</bodyText>
<footnote confidence="0.814091">
3http://www.freelang.net/dictionary/
</footnote>
<figureCaption confidence="0.989995">
Figure 1: LCSR histogram and polynomial trendline
of French-English dictionary pairs.
</figureCaption>
<table confidence="0.999513">
System Prec
Klementiev-Roth (KR) L2 58.6
KR L2 (normalized, boundary markers) 62.9
phrases L2 61.0
phrases L3 65.1
phrases L3 + mismatches 65.6
phrases L3 + mismatches + NED 65.8
</table>
<tableCaption confidence="0.977876">
Table 2: Bitext French-English development set cog-
</tableCaption>
<bodyText confidence="0.992017583333333">
nate identification 11-pt average precision (%).
reflects true etymological relatedness. We looked at
the LCSR histogram for translation pairs in one of
our translation dictionaries (Figure 1). The trendline
suggests a bimodal distribution, with two distinct
distributions of translation pairs making up the dic-
tionary: incidental letter agreement gives low LCSR
for the larger, non-cognate portion and high LCSR
characterizes the likely cognates. A threshold of
0.58 captures most of the cognate distribution while
excluding non-cognate pairs. This hypothesis was
confirmed by checking the LCSR values of a list
of known French-English cognates (randomly col-
lected from a dictionary for another project): 87.4%
were above 0.58. We also checked cognation on
100 randomly-sampled, positively-labelled French-
English pairs (i.e. translated or aligned and having
LCSR  0.58) from both the dictionary and bitext
data. 100% of the dictionary pairs and 93% of the
bitext pairs were cognate.
Next, we investigate various configurations of the
discriminative systems on one of our cognate iden-
tification development sets (Table 2). The origi-
nal Klementiev and Roth (2006) (KR) system can
</bodyText>
<page confidence="0.993929">
660
</page>
<table confidence="0.999784833333333">
Bitext Dictionary
System Fr Es De Fr Es De Gr Jp Rs
PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8
DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6
LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6
NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4
PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9
Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5
Ristad &amp; Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8
Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8
Klementiev &amp; Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4
Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9
</table>
<tableCaption confidence="0.999792">
Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%).
</tableCaption>
<bodyText confidence="0.984486047619048">
be improved by normalizing the feature count by
the longer string length and including the bound-
ary markers. This is therefore done with all the
alignment-based approaches. Also, because of the
way its features are constructed, the KR system
is limited to a maximum substring length of two
(L&lt;2). A maximum length of three (L&lt;3) in the KR
framework produces millions of features and pro-
hibitive training times, while L&lt;3 is computation-
ally feasible in the phrasal case, and increases pre-
cision by 4.1% over the phrases L&lt;2 system.4 In-
cluding mismatches results in another small boost in
performance (0.5%), while using an Edit Distance
feature again increases performance by a slight mar-
gin (0.2%). This ranking of configurations is consis-
tent across all the bitext-based development sets; we
therefore take the configuration of the highest scor-
ing system as our Alignment-Based Discriminative
system for the remainder of this paper.
We next compare the Alignment-Based Discrim-
inative scorer to the various other implemented ap-
proaches across the three bitext and six dictionary-
based cognate identification test sets (Table 3). The
table highlights the top system among both the
non-adaptive and adaptive similarity scorers.5 In
4Preliminary experiments using even longer phrases (be-
yond L&lt;_3) currently produce a computationally prohibitive
number of features for SVM learning. Deploying current fea-
ture selection techniques might enable the use of even more ex-
pressive and powerful feature sets with longer phrase lengths.
5Using the training data and the SVM to weight the com-
ponents of the PREFIX+DICE+LCSR+NED scorer resulted in
negligible improvements over the simple average on our devel-
opment data.
each language pair, the alignment-based discrimi-
native approach outperforms all other approaches,
but the KR system also shows strong gains over
non-adaptive techniques and their re-weighted ex-
tensions. This is in contrast to previous compar-
isons which have only demonstrated minor improve-
ments with adaptive over traditional similarity mea-
sures (Kondrak and Sherif, 2006).
We consistently found that the original KR perfor-
mance could be surpassed by a system that normal-
izes the KR feature count and adds boundary mark-
ers. Across all the test sets, this modification results
in a 6% average gain in performance over baseline
KR, but is still on average 5% below the Alignment-
Based Discriminative technique, with a statistically
significantly difference on each of the nine sets.6
Figure 2 shows the relationship between train-
ing data size and performance in our bitext-based
French-English data. Note again that the Tiedemann
and Ristad &amp; Yanilos systems only use the positive
examples in the training data. Our alignment-based
similarity function outperforms all the other systems
across nearly the entire range of training data. Note
also that the discriminative learning curves show no
signs of slowing down: performance grows logarith-
mically from 1K to 846K word pairs.
For insight into the power of our discrimina-
tive approach, we provide some of our classifiers’
highest and lowest-weighted features (Table 4).
</bodyText>
<footnote confidence="0.94322925">
6Following Evert (2004), significance was computed using
Fisher’s exact test (at p = 0.05) to compare the n-best word pairs
from the scored test sets, where n was taken as the number of
positive pairs in the set.
</footnote>
<page confidence="0.992585">
661
</page>
<figure confidence="0.949991">
1000 10000 100000 1e+06
Number of training pairs
</figure>
<figureCaption confidence="0.8270005">
Figure 2: Bitext French-English cognate identifica-
tion learning curve.
</figureCaption>
<table confidence="0.99972525">
Lang. Feat. Wt. Example
Fr (Bitext) ´ees-ed +8.0 v´erifi´ees:verified
Jp (Dict.) ru-l +5.9 penaruti:penalty
De (Bitext) k-c +5.5 kreativ:creative
Rs (Dict.) irov- +4.9 motivirovat:motivate
Gr (Dict.) f-ph +4.1 symfonia:symphony
Gr (Dict.) kos-c +3.3 anarchikos:anarchic
Gr (Dict.) os$-y$ -2.5 anarchikos:anarchy
Jp (Dict.) ou-ou -2.6 handoutai:handout
Es (Dict.) -un -3.1 balance:unbalance
Fr (Dict.) er$-er$ -5.0 former:former
Es (Bitext) mos-s -5.1 toleramos:tolerates
</table>
<tableCaption confidence="0.865043333333333">
Table 4: Example features and weights for var-
ious Alignment-Based Discriminative classifiers
(Foreign-English, negative pairs in italics).
</tableCaption>
<bodyText confidence="0.999761533333334">
Note the expected correspondences between foreign
spellings and English (k-c, f-ph), but also features
that leverage derivational and inflectional morphol-
ogy. For example, Greek-English pairs with the
adjective-ending correspondence kos-c, e.g. anar-
chikos:anarchic, are favoured, but pairs with the ad-
jective ending in Greek and noun ending in English,
os$-y$, are penalized; indeed, by our definition, an-
archikos:anarchy is not cognate. In a bitext, the
feature ´ees-ed captures that feminine-plural inflec-
tion of past tense verbs in French corresponds to
regular past tense in English. On the other hand,
words ending in the Spanish first person plural verb
suffix -amos are rarely translated to English words
ending with the suffix -s, causing mos-s to be pe-
</bodyText>
<table confidence="0.994515857142857">
Gr-En (Dict.) Es-En (Bitext)
alkali:alkali agenda:agenda
makaroni:macaroni natural:natural
adrenalini:adrenaline m´argenes:margins
flamingko:flamingo hormonal:hormonal
spasmodikos:spasmodic rad´on:radon
amvrosia:ambrosia higi´enico:hygienic
</table>
<tableCaption confidence="0.955386">
Table 5: Highest scored pairs by Alignment-Based
Discriminative classifier (negative pairs in italics).
</tableCaption>
<bodyText confidence="0.999518821428572">
nalized. The ability to leverage negative features,
learned from appropriate counter examples, is a key
innovation of our discriminative framework.
Table 5 gives the top pairs scored by our system
on two of the sets. Notice that unlike traditional sim-
ilarity measures that always score identical words
higher than all other pairs, by virtue of our feature
weighting, our discriminative classifier prefers some
pairs with very characteristic spelling changes.
We performed error analysis by looking at all the
pairs our system scored quite confidently (highly
positive or highly negative similarity), but which
were labelled oppositely. Highly-scored false pos-
itives arose equally from 1) actual cognates not
linked as translations in the data, 2) related words
with diverged meanings, e.g. the error in Table 5:
makaroni in Greek actually means spaghetti in En-
glish, and 3) the same word stem, a different part
of speech (e.g. the Greek/English adjective/noun
synonymos:synonym). Meanwhile, inspection of the
highly-confident false negatives revealed some (of-
ten erroneously-aligned in the bitext) positive pairs
with incidental letter match (e.g. the French/English
recettes:proceeds) that we would not actually deem
to be cognate. Thus the errors that our system makes
are often either linguistically interesting or point out
mistakes in our automatically-labelled bitext and (to
a lesser extent) dictionary data.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999765">
This is the first research to apply discriminative
string similarity to the task of cognate identification.
We have introduced and successfully applied an
alignment-based framework for discriminative sim-
ilarity that consistently demonstrates improved per-
formance in both bitext and dictionary-based cog-
</bodyText>
<figure confidence="0.999511923076923">
NED
Tiedemann
Ristad-Yanilos
Klementiev-Roth
Alignment-Based Discrim.
11-pt Average Precision 0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
</figure>
<page confidence="0.983537">
662
</page>
<bodyText confidence="0.999961192307692">
nate identification on six language pairs. Our im-
proved approach can be applied in any of the di-
verse applications where traditional similarity mea-
sures like Edit Distance and LCSR are prevalent. We
have also made available our cognate identification
data sets, which will be of interest to general string
similarity researchers.
Furthermore, we have provided a natural frame-
work for future cognate identification research. Pho-
netic, semantic, or syntactic features could be in-
cluded within our discriminative infrastructure to aid
in the identification of cognates in text. In particu-
lar, we plan to investigate approaches that do not re-
quire the bilingual dictionaries or bitexts to generate
training data. For example, researchers have auto-
matically developed translation lexicons by seeing
if words from each language have similar frequen-
cies, contexts (Koehn and Knight, 2002), bursti-
ness, inverse document frequencies, and date dis-
tributions (Schafer and Yarowsky, 2002). Semantic
and string similarity might be learned jointly with a
co-training or bootstrapping approach (Klementiev
and Roth, 2006). We may also compare alignment-
based discriminative string similarity with a more
complex discriminative model that learns the align-
ments as latent structure (McCallum et al., 2005).
</bodyText>
<sectionHeader confidence="0.99825" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.98235525">
We gratefully acknowledge support from the Natu-
ral Sciences and Engineering Research Council of
Canada, the Alberta Ingenuity Fund, and the Alberta
Informatics Circle of Research Excellence.
</bodyText>
<sectionHeader confidence="0.997321" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995438212121212">
George W. Adamson and Jillian Boreham. 1974. The use of
an association measure based on character structure to iden-
tify semantically related pairs of words and document titles.
Information Storage and Retrieval, 10:253–260.
Mikhail Bilenko and Raymond J. Mooney. 2003. Adaptive du-
plicate detection using learnable string similarity measures.
In KDD, pages 39–48.
Eric Brill and Robert Moore. 2000. An improved error model
for noisy channel spelling correction. In ACL. 286–293.
Stefan Evert. 2004. Significance tests for the evaluation of
ranking methods. In COLING, pages 945–951.
Thorsten Joachims. 1999. Making large-scale Support Vector
Machine learning practical. In Advances in Kernel Methods:
Support Vector Machines, pages 169–184. MIT-Press.
Alexandre Klementiev and Dan Roth. 2006. Named entity
transliteration and discovery from multilingual comparable
corpora. In HLT-NAACL, pages 82–88.
Philipp Koehn and Kevin Knight. 2002. Learning a transla-
tion lexicon from monolingual corpora. In ACL Workshop
on Unsupervised Lexical Acquistion.
Philipp Koehn and Christof Monz. 2006. Manual and auto-
matic evaluation of machine translation between European
languages. In NAACL Workshop on Statistical Machine
Translation, pages 102–121.
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In HLT-NAACL, pages
127–133.
Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation of
several phonetic similarity algorithms on the task of cog-
nate identification. In COLING-ACL Workshop on Linguis-
tic Distances, pages 37–44.
Grzegorz Kondrak. 2005. Cognates and word alignment in
bitexts. In MT Summit X, pages 305–312.
Vladimir I. Levenshtein. 1966. Binary codes capable of cor-
recting deletions, insertions, and reversals. Soviet Physics
Doklady, 10(8):707–710.
Gideon S. Mann and David Yarowsky. 2001. Multipath trans-
lation lexicon induction via bridge languages. In NAACL,
pages 151–158.
Andrew McCallum, Kedar Bellare, and Fernando Pereira.
2005. A conditional random field for discriminatively-
trained finite-state string edit distance. In UAI. 388–395.
I. Dan Melamed. 1999. Bitext maps and alignment via pattern
recognition. Computational Linguistics, 25(1):107–130.
Andrea Mulloni and Viktor Pekar. 2006. Automatic detec-
tion of orthographic cues for cognate recognition. In LREC,
pages 2387–2390.
Ari Rappoport and Tsahi Levent-Levi. 2006. Induction of
cross-language affix and letter sequence correspondence. In
EACL Workshop on Cross-Language Knowledge Induction.
Eric Sven Ristad and Peter N. Yianilos. 1998. Learning string-
edit distance. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 20(5):522–532.
Charles Schafer and David Yarowsky. 2002. Inducing transla-
tion lexicons via diverse similarity measures and bridge lan-
guages. In CoNLL, pages 207–216.
Michael Strube, Stefan Rapp, and Christoph M¨uller. 2002. The
influence of minimum edit distance on reference resolution.
In EMNLP, pages 312–319.
Ben Taskar, Simon Lacoste-Julien, and Dan Klein. 2005. A
discriminative matching approach to word alignment. In
HLT-EMNLP, pages 73–80.
J¨org Tiedemann. 1999. Automatic construction of weighted
string similarity measures. In EMNLP-VLC, pages 213–219.
Dmitry Zelenko and Chinatsu Aone. 2006. Discriminative
methods for transliteration. In EMNLP, pages 612–617.
</reference>
<page confidence="0.998896">
663
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.942280">
<title confidence="0.998245">Alignment-Based Discriminative String Similarity</title>
<author confidence="0.999963">Shane Bergsma</author>
<author confidence="0.999963">Grzegorz Kondrak</author>
<affiliation confidence="0.9999765">Department of Computing Science University of Alberta</affiliation>
<address confidence="0.994321">Edmonton, Alberta, Canada, T6G 2E8</address>
<abstract confidence="0.997454">A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identification of cognates in related vocabu- We propose an alignment-based disfor string similarity. We gather features from substring pairs consistent with a character-based alignment of the two strings. This approach achieves exceptional performance; on nine separate cognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice’s Coefficient. We also show strong improvements over other recent discriminative and heuristic similarity functions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George W Adamson</author>
<author>Jillian Boreham</author>
</authors>
<title>The use of an association measure based on character structure to identify semantically related pairs of words and document titles. Information Storage and Retrieval,</title>
<date>1974</date>
<pages>10--253</pages>
<contexts>
<context position="4048" citStr="Adamson and Boreham, 1974" startWordPosition="584" endWordPosition="587">007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levenshtein Distance (Levenshtein, 1966): the number of insertions, deletions and substitutions required to transform one string into another. In our experiments, we use Normalized Edit Distance (NED): Edit Distance divided by the length of the longer word. Other popular measures include Dice’s Coefficient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005). These baseline approaches have the important advantage of not requiring training data. We can also include in the non-learning category Kondrak (2005)’s Longest Common Subsequence Formula (LCSF), a probabilistic measure designed to mitigate LCSR’s preference for shorter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adap</context>
</contexts>
<marker>Adamson, Boreham, 1974</marker>
<rawString>George W. Adamson and Jillian Boreham. 1974. The use of an association measure based on character structure to identify semantically related pairs of words and document titles. Information Storage and Retrieval, 10:253–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bilenko</author>
<author>Raymond J Mooney</author>
</authors>
<title>Adaptive duplicate detection using learnable string similarity measures.</title>
<date>2003</date>
<booktitle>In KDD,</booktitle>
<pages>39--48</pages>
<contexts>
<context position="13931" citStr="Bilenko and Mooney (2003)" startWordPosition="2168" endWordPosition="2171">range between 1.4% and 1.8%, while ranging between 1.0% and 1.6% for the dictionary data.2 For the discriminative methods, we use a popular Support Vector Machine (SVM) learning package called SVM&amp;quot;ght (Joachims, 1999). SVMs are maximum-margin classifiers that achieve good performance on a range of tasks. In each case, we learn a linear kernel on the training set pairs and tune the parameter that trades-off training error and margin on the development set. We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondrak (2005)’s LCSF. We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)).</context>
</contexts>
<marker>Bilenko, Mooney, 2003</marker>
<rawString>Mikhail Bilenko and Raymond J. Mooney. 2003. Adaptive duplicate detection using learnable string similarity measures. In KDD, pages 39–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In ACL.</booktitle>
<pages>286--293</pages>
<contexts>
<context position="1478" citStr="Brill and Moore (2000)" startWordPosition="205" endWordPosition="208">like Longest Common Subsequence Ratio and Dice’s Coefficient. We also show strong improvements over other recent discriminative and heuristic similarity functions. 1 Introduction String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similarities for spelling correction. In each of these examples, a similarity measure can make use of the recurrent substring pairings that reliably occur between words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanes</context>
<context position="6265" citStr="Brill and Moore (2000)" startWordPosition="914" endWordPosition="917">tive weights on substring pairings in order to better identify related strings. One system that can potentially provide this flexibility is a discriminative string-similarity approach to named-entity transliteration by Klementiev and Roth (2006). Although not compared to other similarity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates. Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration. Our work successfully uses the alignment-based methodology of the generative approaches to enhance the feature set for discriminative string similarity. 3 Th</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert Moore. 2000. An improved error model for noisy channel spelling correction. In ACL. 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>Significance tests for the evaluation of ranking methods.</title>
<date>2004</date>
<booktitle>In COLING,</booktitle>
<pages>945--951</pages>
<contexts>
<context position="24355" citStr="Evert (2004)" startWordPosition="3815" endWordPosition="3816"> data size and performance in our bitext-based French-English data. Note again that the Tiedemann and Ristad &amp; Yanilos systems only use the positive examples in the training data. Our alignment-based similarity function outperforms all the other systems across nearly the entire range of training data. Note also that the discriminative learning curves show no signs of slowing down: performance grows logarithmically from 1K to 846K word pairs. For insight into the power of our discriminative approach, we provide some of our classifiers’ highest and lowest-weighted features (Table 4). 6Following Evert (2004), significance was computed using Fisher’s exact test (at p = 0.05) to compare the n-best word pairs from the scored test sets, where n was taken as the number of positive pairs in the set. 661 1000 10000 100000 1e+06 Number of training pairs Figure 2: Bitext French-English cognate identification learning curve. Lang. Feat. Wt. Example Fr (Bitext) ´ees-ed +8.0 v´erifi´ees:verified Jp (Dict.) ru-l +5.9 penaruti:penalty De (Bitext) k-c +5.5 kreativ:creative Rs (Dict.) irov- +4.9 motivirovat:motivate Gr (Dict.) f-ph +4.1 symfonia:symphony Gr (Dict.) kos-c +3.3 anarchikos:anarchic Gr (Dict.) os$-y</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. Significance tests for the evaluation of ranking methods. In COLING, pages 945–951.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale Support Vector Machine learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods: Support Vector Machines,</booktitle>
<pages>169--184</pages>
<contexts>
<context position="13523" citStr="Joachims, 1999" startWordPosition="2098" endWordPosition="2099">n 3 introduced two high-precision methods for generating labelled cognate pairs: using the word alignments from a bilingual corpus or using the entries in a translation lexicon. We investigate both of these methods in our experiments. In each case, we generate sets of labelled word pairs for training, testing, and development. The proportion of positive examples in the bitext-labelled test sets range between 1.4% and 1.8%, while ranging between 1.0% and 1.6% for the dictionary data.2 For the discriminative methods, we use a popular Support Vector Machine (SVM) learning package called SVM&amp;quot;ght (Joachims, 1999). SVMs are maximum-margin classifiers that achieve good performance on a range of tasks. In each case, we learn a linear kernel on the training set pairs and tune the parameter that trades-off training error and margin on the development set. We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondr</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale Support Vector Machine learning practical. In Advances in Kernel Methods: Support Vector Machines, pages 169–184. MIT-Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>82--88</pages>
<contexts>
<context position="3162" citStr="Klementiev and Roth (2006)" startWordPosition="448" endWordPosition="451">ognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). 2 Related Work String similarity is a fundamental concept in a variety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levenshtein Distance (Levenshtein, 1966): the number of </context>
<context position="5888" citStr="Klementiev and Roth (2006)" startWordPosition="857" endWordPosition="860">ce improvements. Mulloni and Pekar (2006) developed a similar technique to improve NED for English/German. Essentially, all these techniques improve on the baseline approaches by using a set of positive (true) cognate pairs to re-weight the costs of edit operations or the score of sequence matches. Ideally, we would prefer a more flexible approach that can learn positive or negative weights on substring pairings in order to better identify related strings. One system that can potentially provide this flexibility is a discriminative string-similarity approach to named-entity transliteration by Klementiev and Roth (2006). Although not compared to other similarity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn s</context>
<context position="10059" citStr="Klementiev and Roth (2006)" startWordPosition="1527" endWordPosition="1530">iend lists. Note that despite these examples, this is not a ranking task: even in highly related languages, most words in F have empty Ef+ lists, and many have empty Ef_ as well. Thus one natural formulation for cognate identification is a pairwise (and symmetric) cognation classification that looks at each pair (f, ef) separately and individually makes a decision: +(napukin,napkin) – (napukin,nanking) – (napukin,pumpkin) In this formulation, the benefits of a discriminative approach are clear: it must find substrings that distinguish cognate pairs from word pairs with otherwise similar form. Klementiev and Roth (2006), although using a discriminative approach, do not provide their infinite-attribute perceptron with competitive counter-examples. They instead use transliterations as positives and randomly-paired English and Russian words as negative examples. In the following section, we also improve on Klementiev and Roth (2006) by using a character-based string alignment to focus the features for discrimination. 4 Features for Discriminative Similarity Discriminative learning works by providing a training set of labelled examples, each represented as a set of features, to a module that learns a classifier.</context>
<context position="20425" citStr="Klementiev and Roth (2006)" startWordPosition="3187" endWordPosition="3190"> pairs. This hypothesis was confirmed by checking the LCSR values of a list of known French-English cognates (randomly collected from a dictionary for another project): 87.4% were above 0.58. We also checked cognation on 100 randomly-sampled, positively-labelled FrenchEnglish pairs (i.e. translated or aligned and having LCSR  0.58) from both the dictionary and bitext data. 100% of the dictionary pairs and 93% of the bitext pairs were cognate. Next, we investigate various configurations of the discriminative systems on one of our cognate identification development sets (Table 2). The original Klementiev and Roth (2006) (KR) system can 660 Bitext Dictionary System Fr Es De Fr Es De Gr Jp Rs PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8 DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6 LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6 NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4 PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9 Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5 Ristad &amp; Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8 Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8 Klementiev &amp; Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.</context>
<context position="20986" citStr="Klementiev &amp; Roth (2006)" startWordPosition="3293" endWordPosition="3296">lopment sets (Table 2). The original Klementiev and Roth (2006) (KR) system can 660 Bitext Dictionary System Fr Es De Fr Es De Gr Jp Rs PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8 DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6 LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6 NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4 PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9 Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5 Ristad &amp; Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8 Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8 Klementiev &amp; Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4 Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9 Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%). be improved by normalizing the feature count by the longer string length and including the boundary markers. This is therefore done with all the alignment-based approaches. Also, because of the way its features are constructed, the KR system is limited to a maximum substring length of two (L&lt;2). A maximum length of three (L&lt;3) in the KR framework produces millions of features </context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Named entity transliteration and discovery from multilingual comparable corpora. In HLT-NAACL, pages 82–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In ACL Workshop on Unsupervised Lexical Acquistion.</booktitle>
<contexts>
<context position="2272" citStr="Koehn and Knight, 2002" startWordPosition="320" endWordPosition="323">ing pairings that reliably occur between words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six </context>
<context position="29125" citStr="Koehn and Knight, 2002" startWordPosition="4493" endWordPosition="4496">ts, which will be of interest to general string similarity researchers. Furthermore, we have provided a natural framework for future cognate identification research. Phonetic, semantic, or syntactic features could be included within our discriminative infrastructure to aid in the identification of cognates in text. In particular, we plan to investigate approaches that do not require the bilingual dictionaries or bitexts to generate training data. For example, researchers have automatically developed translation lexicons by seeing if words from each language have similar frequencies, contexts (Koehn and Knight, 2002), burstiness, inverse document frequencies, and date distributions (Schafer and Yarowsky, 2002). Semantic and string similarity might be learned jointly with a co-training or bootstrapping approach (Klementiev and Roth, 2006). We may also compare alignmentbased discriminative string similarity with a more complex discriminative model that learns the alignments as latent structure (McCallum et al., 2005). Acknowledgments We gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada, the Alberta Ingenuity Fund, and the Alberta Informatics Circle of Resear</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In ACL Workshop on Unsupervised Lexical Acquistion.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Manual and automatic evaluation of machine translation between European languages.</title>
<date>2006</date>
<booktitle>In NAACL Workshop on Statistical Machine Translation,</booktitle>
<pages>102--121</pages>
<contexts>
<context position="17066" citStr="Koehn and Monz, 2006" startWordPosition="2664" endWordPosition="2667">ength of the longer word. We investigate both of these ap1If the words are from different alphabets, we can get the alignment by mapping the letters to their closest Roman equivalent, or by using the EM algorithm to learn the edits (Ristad and Yianilos, 1998). 2The cognate data sets used in our experiments are available at http://www.cs.ualberta.ca/˜bergsma/Cognates/ 659 5.1 Bitext Experiments For the bitext-based annotation, we use publiclyavailable word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) (Koehn and Monz, 2006). Initial cleaning of these noisy word pairs is necessary. We thus remove all pairs with numbers, punctuation, a capitalized English word, and all words that occur fewer than ten times. We also remove many incorrectly aligned words by filtering pairs where the pairwise Mutual Information between the words is less than 7.5. This processing leaves vocabulary sizes of 39K for French, 31K for Spanish, and 60K for German. Our labelled set is then generated from pairs with LCSR  0.58 (using the cutoff from Melamed (1999)). Each labelled set entry is a triple of a) the foreign word f, b) the cognate</context>
</contexts>
<marker>Koehn, Monz, 2006</marker>
<rawString>Philipp Koehn and Christof Monz. 2006. Manual and automatic evaluation of machine translation between European languages. In NAACL Workshop on Statistical Machine Translation, pages 102–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="15062" citStr="Koehn et al., 2003" startWordPosition="2352" endWordPosition="2355">erage precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). For the feature representation, we only extract substring pairs that are consistent with this alignment.1 That is, the letters in our pairs can only be aligned to each other and not to letters outside the pairing: { ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...} We define phrase pairs to be the pairs of substrings consistent with the alignment. A similar use of the term “phrase” exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al., 2003). By limiting the substrings to only those pairs that are consistent with the alignment, we generate fewer, more-informative features. Using more precise features allows a larger maximum substring size L than is feasible with the positional approach. Larger substrings allow us to capture important recurring deletions like the “u” in sut-st. Tiedemann (1999) and others have shown the importance of using the mismatching portions of cognate pairs to learn the recurrent spelling changes between two languages. In order to capture mismatching segments longer than our maximum substring size will allo</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In HLT-NAACL, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Evaluation of several phonetic similarity algorithms on the task of cognate identification.</title>
<date>2006</date>
<booktitle>In COLING-ACL Workshop on Linguistic Distances,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="14529" citStr="Kondrak and Sherif (2006)" startWordPosition="2265" endWordPosition="2268">y Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondrak (2005)’s LCSF. We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). For the feature representation, we only extract substring pairs that are consistent with this alignment.1 That is, the letters in our pairs can only be aligned to each other and not to letters outside the pairing: { ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...} We define phrase pairs to be the pairs of substrings consistent with the alignment. A similar use of the term “phrase” exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al., 2003). By limiting the substrings to only those pairs that are consisten</context>
<context position="23286" citStr="Kondrak and Sherif, 2006" startWordPosition="3644" endWordPosition="3647"> more expressive and powerful feature sets with longer phrase lengths. 5Using the training data and the SVM to weight the components of the PREFIX+DICE+LCSR+NED scorer resulted in negligible improvements over the simple average on our development data. each language pair, the alignment-based discriminative approach outperforms all other approaches, but the KR system also shows strong gains over non-adaptive techniques and their re-weighted extensions. This is in contrast to previous comparisons which have only demonstrated minor improvements with adaptive over traditional similarity measures (Kondrak and Sherif, 2006). We consistently found that the original KR performance could be surpassed by a system that normalizes the KR feature count and adds boundary markers. Across all the test sets, this modification results in a 6% average gain in performance over baseline KR, but is still on average 5% below the AlignmentBased Discriminative technique, with a statistically significantly difference on each of the nine sets.6 Figure 2 shows the relationship between training data size and performance in our bitext-based French-English data. Note again that the Tiedemann and Ristad &amp; Yanilos systems only use the pos</context>
</contexts>
<marker>Kondrak, Sherif, 2006</marker>
<rawString>Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation of several phonetic similarity algorithms on the task of cognate identification. In COLING-ACL Workshop on Linguistic Distances, pages 37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Cognates and word alignment in bitexts.</title>
<date>2005</date>
<booktitle>In MT Summit X,</booktitle>
<pages>305--312</pages>
<contexts>
<context position="3130" citStr="Kondrak (2005)" startWordPosition="445" endWordPosition="446">tically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). 2 Related Work String similarity is a fundamental concept in a variety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levenshtein Distance (Le</context>
<context position="4350" citStr="Kondrak (2005)" startWordPosition="628" endWordPosition="630">ein, 1966): the number of insertions, deletions and substitutions required to transform one string into another. In our experiments, we use Normalized Edit Distance (NED): Edit Distance divided by the length of the longer word. Other popular measures include Dice’s Coefficient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005). These baseline approaches have the important advantage of not requiring training data. We can also include in the non-learning category Kondrak (2005)’s Longest Common Subsequence Formula (LCSF), a probabilistic measure designed to mitigate LCSR’s preference for shorter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adaptive measures that are learned from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, eve</context>
<context position="14132" citStr="Kondrak (2005)" startWordPosition="2201" endWordPosition="2202">1999). SVMs are maximum-margin classifiers that achieve good performance on a range of tasks. In each case, we learn a linear kernel on the training set pairs and tune the parameter that trades-off training error and margin on the development set. We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondrak (2005)’s LCSF. We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). For the feature representation, we only extract substring pairs that are consistent with this alignment.1 That is, the letters in our pairs can only be aligned to each other and not to letters outside</context>
<context position="20779" citStr="Kondrak (2005)" startWordPosition="3257" endWordPosition="3258">text data. 100% of the dictionary pairs and 93% of the bitext pairs were cognate. Next, we investigate various configurations of the discriminative systems on one of our cognate identification development sets (Table 2). The original Klementiev and Roth (2006) (KR) system can 660 Bitext Dictionary System Fr Es De Fr Es De Gr Jp Rs PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8 DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6 LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6 NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4 PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9 Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5 Ristad &amp; Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8 Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8 Klementiev &amp; Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4 Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9 Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%). be improved by normalizing the feature count by the longer string length and including the boundary markers. This is therefore done with all the alignment-based approaches.</context>
</contexts>
<marker>Kondrak, 2005</marker>
<rawString>Grzegorz Kondrak. 2005. Cognates and word alignment in bitexts. In MT Summit X, pages 305–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="3746" citStr="Levenshtein, 1966" startWordPosition="540" endWordPosition="541">5), and Klementiev and Roth (2006). 2 Related Work String similarity is a fundamental concept in a variety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levenshtein Distance (Levenshtein, 1966): the number of insertions, deletions and substitutions required to transform one string into another. In our experiments, we use Normalized Edit Distance (NED): Edit Distance divided by the length of the longer word. Other popular measures include Dice’s Coefficient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005). These baseline approaches have the important advantage of not requiring training data. We can also include in the non-learning category Kondrak (2</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(8):707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>David Yarowsky</author>
</authors>
<title>Multipath translation lexicon induction via bridge languages. In</title>
<date>2001</date>
<booktitle>NAACL,</booktitle>
<pages>151--158</pages>
<contexts>
<context position="2247" citStr="Mann and Yarowsky, 2001" startWordPosition="316" endWordPosition="319">e of the recurrent substring pairings that reliably occur between words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-</context>
<context position="4861" citStr="Mann and Yarowsky (2001)" startWordPosition="703" endWordPosition="706">portant advantage of not requiring training data. We can also include in the non-learning category Kondrak (2005)’s Longest Common Subsequence Formula (LCSF), a probabilistic measure designed to mitigate LCSR’s preference for shorter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adaptive measures that are learned from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer’s probabilities into different weight classes to better approximate Edit Distance. Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements. Mulloni and Pekar (2006) developed a similar technique to improve NED for English/German. Essentially, all these techniques improve on the baseline approaches by using a set of posit</context>
<context position="7470" citStr="Mann and Yarowsky (2001)" startWordPosition="1098" endWordPosition="1101">ng similarity. 3 The Cognate Identification Task Given two string lists, E and F, the task of cognate identification is to find all pairs of strings (e, f) that are cognate. In other similarity-driven applications, E and F could be misspelled and correctly spelled words, or the orthographic and the phonetic representation of words, etc. The task remains to link strings with common meaning in E and F using only the string similarity measure. We can facilitate the application of string similarity to cognates by using a definition of cognation not dependent on etymological analysis. For example, Mann and Yarowsky (2001) define a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form). We adopt an improved definition (suggested by Melamed (1999) for the French-English Canadian Hansards) that does not over-propose shorter word pairs: (e, f) are cognate if they are translations and their LCSR &gt; 0.58. Note that this cutoff is somewhat conservative: the English/German cognates light/Licht (LCSR=0.8) are included, but not the cognates eight/acht (LCSR=0.4). If two words must have LCSR &gt; 0.58 to be cog657 Foreign Language F Words f E F Cogn</context>
</contexts>
<marker>Mann, Yarowsky, 2001</marker>
<rawString>Gideon S. Mann and David Yarowsky. 2001. Multipath translation lexicon induction via bridge languages. In NAACL, pages 151–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Kedar Bellare</author>
<author>Fernando Pereira</author>
</authors>
<title>A conditional random field for discriminativelytrained finite-state string edit distance.</title>
<date>2005</date>
<booktitle>In UAI.</booktitle>
<pages>388--395</pages>
<marker>McCallum, Bellare, Pereira, 2005</marker>
<rawString>Andrew McCallum, Kedar Bellare, and Fernando Pereira. 2005. A conditional random field for discriminativelytrained finite-state string edit distance. In UAI. 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Bitext maps and alignment via pattern recognition.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="2188" citStr="Melamed, 1999" startWordPosition="310" endWordPosition="311">f these examples, a similarity measure can make use of the recurrent substring pairings that reliably occur between words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of st</context>
<context position="4140" citStr="Melamed, 1999" startWordPosition="597" endWordPosition="598"> applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levenshtein Distance (Levenshtein, 1966): the number of insertions, deletions and substitutions required to transform one string into another. In our experiments, we use Normalized Edit Distance (NED): Edit Distance divided by the length of the longer word. Other popular measures include Dice’s Coefficient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005). These baseline approaches have the important advantage of not requiring training data. We can also include in the non-learning category Kondrak (2005)’s Longest Common Subsequence Formula (LCSF), a probabilistic measure designed to mitigate LCSR’s preference for shorter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adaptive measures that are learned from a set of known cognate pairs. Ristad and Yianilos (1998)</context>
<context position="7673" citStr="Melamed (1999)" startWordPosition="1136" endWordPosition="1137">, E and F could be misspelled and correctly spelled words, or the orthographic and the phonetic representation of words, etc. The task remains to link strings with common meaning in E and F using only the string similarity measure. We can facilitate the application of string similarity to cognates by using a definition of cognation not dependent on etymological analysis. For example, Mann and Yarowsky (2001) define a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form). We adopt an improved definition (suggested by Melamed (1999) for the French-English Canadian Hansards) that does not over-propose shorter word pairs: (e, f) are cognate if they are translations and their LCSR &gt; 0.58. Note that this cutoff is somewhat conservative: the English/German cognates light/Licht (LCSR=0.8) are included, but not the cognates eight/acht (LCSR=0.4). If two words must have LCSR &gt; 0.58 to be cog657 Foreign Language F Words f E F Cognates Ef+ False Friends Ef_ Japanese (Rˆomaji) napukin napkin nanking, pumpkin, snacking, sneaking French abondamment abundantly abandonment, abatement, ... wonderment German prozyklische procyclical poli</context>
<context position="17587" citStr="Melamed (1999)" startWordPosition="2754" endWordPosition="2755">++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) (Koehn and Monz, 2006). Initial cleaning of these noisy word pairs is necessary. We thus remove all pairs with numbers, punctuation, a capitalized English word, and all words that occur fewer than ten times. We also remove many incorrectly aligned words by filtering pairs where the pairwise Mutual Information between the words is less than 7.5. This processing leaves vocabulary sizes of 39K for French, 31K for Spanish, and 60K for German. Our labelled set is then generated from pairs with LCSR  0.58 (using the cutoff from Melamed (1999)). Each labelled set entry is a triple of a) the foreign word f, b) the cognates Ef+ and c) the false friends Ef_. For each language pair, we randomly take 20K triples for training, 5K for development and 5K for testing. Each triple is converted to a set of pairwise examples for learning and classification. 5.2 Dictionary Experiments For the dictionary-based cognate identification, we use French, Spanish, German, Greek (Gr), Japanese (Jp), and Russian (Rs) to English translation pairs from the Freelang program.3 The latter three pairs were chosen so that we can evaluate on more distant languag</context>
</contexts>
<marker>Melamed, 1999</marker>
<rawString>I. Dan Melamed. 1999. Bitext maps and alignment via pattern recognition. Computational Linguistics, 25(1):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Mulloni</author>
<author>Viktor Pekar</author>
</authors>
<title>Automatic detection of orthographic cues for cognate recognition. In</title>
<date>2006</date>
<booktitle>LREC,</booktitle>
<pages>2387--2390</pages>
<contexts>
<context position="5303" citStr="Mulloni and Pekar (2006)" startWordPosition="767" endWordPosition="770">from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer’s probabilities into different weight classes to better approximate Edit Distance. Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements. Mulloni and Pekar (2006) developed a similar technique to improve NED for English/German. Essentially, all these techniques improve on the baseline approaches by using a set of positive (true) cognate pairs to re-weight the costs of edit operations or the score of sequence matches. Ideally, we would prefer a more flexible approach that can learn positive or negative weights on substring pairings in order to better identify related strings. One system that can potentially provide this flexibility is a discriminative string-similarity approach to named-entity transliteration by Klementiev and Roth (2006). Although not </context>
<context position="15916" citStr="Mulloni and Pekar (2006)" startWordPosition="2486" endWordPosition="2489">positional approach. Larger substrings allow us to capture important recurring deletions like the “u” in sut-st. Tiedemann (1999) and others have shown the importance of using the mismatching portions of cognate pairs to learn the recurrent spelling changes between two languages. In order to capture mismatching segments longer than our maximum substring size will allow, we include special features in our representation called mismatches. Mismatches are phrases that span the entire sequence of unaligned characters between two pairs of aligned end characters (similar to the “rules” extracted by Mulloni and Pekar (2006)). In the above example, su$-ss$ is a mismatch with “s” and “$” as the aligned end characters. Two sets of features are taken from each mismatch, one that includes the beginning/ending aligned characters as context and one that does not. For example, for the endings of the French/English pair (´economique,economic), we include both the substring pairs ique$:ic$ and que:c as features. One consideration is whether substring features should be binary presence/absence, or the count of the feature in the pair normalized by the length of the longer word. We investigate both of these ap1If the words </context>
</contexts>
<marker>Mulloni, Pekar, 2006</marker>
<rawString>Andrea Mulloni and Viktor Pekar. 2006. Automatic detection of orthographic cues for cognate recognition. In LREC, pages 2387–2390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ari Rappoport</author>
<author>Tsahi Levent-Levi</author>
</authors>
<title>Induction of cross-language affix and letter sequence correspondence.</title>
<date>2006</date>
<booktitle>In EACL Workshop on Cross-Language Knowledge Induction.</booktitle>
<contexts>
<context position="6457" citStr="Rappoport and Levent-Levi (2006)" startWordPosition="941" endWordPosition="944">h to named-entity transliteration by Klementiev and Roth (2006). Although not compared to other similarity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates. Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration. Our work successfully uses the alignment-based methodology of the generative approaches to enhance the feature set for discriminative string similarity. 3 The Cognate Identification Task Given two string lists, E and F, the task of cognate identification is to find all pairs of strings (e, f) that are cognate. In other similarity-driven applicatio</context>
</contexts>
<marker>Rappoport, Levent-Levi, 2006</marker>
<rawString>Ari Rappoport and Tsahi Levent-Levi. 2006. Induction of cross-language affix and letter sequence correspondence. In EACL Workshop on Cross-Language Knowledge Induction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Sven Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<title>Learning stringedit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="3096" citStr="Ristad and Yianilos (1998)" startWordPosition="438" endWordPosition="442">Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). 2 Related Work String similarity is a fundamental concept in a variety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Di</context>
<context position="4740" citStr="Ristad and Yianilos (1998)" startWordPosition="685" endWordPosition="689">tio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005). These baseline approaches have the important advantage of not requiring training data. We can also include in the non-learning category Kondrak (2005)’s Longest Common Subsequence Formula (LCSF), a probabilistic measure designed to mitigate LCSR’s preference for shorter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adaptive measures that are learned from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer’s probabilities into different weight classes to better approximate Edit Distance. Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements. Mulloni and Pekar (2006) developed a similar technique to imp</context>
<context position="14242" citStr="Ristad and Yianilos (1998)" startWordPosition="2219" endWordPosition="2222">ach case, we learn a linear kernel on the training set pairs and tune the parameter that trades-off training error and margin on the development set. We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondrak (2005)’s LCSF. We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). For the feature representation, we only extract substring pairs that are consistent with this alignment.1 That is, the letters in our pairs can only be aligned to each other and not to letters outside the pairing: { ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...} We define phrase pairs to be the pai</context>
<context position="16704" citStr="Ristad and Yianilos, 1998" startWordPosition="2616" endWordPosition="2619">s the beginning/ending aligned characters as context and one that does not. For example, for the endings of the French/English pair (´economique,economic), we include both the substring pairs ique$:ic$ and que:c as features. One consideration is whether substring features should be binary presence/absence, or the count of the feature in the pair normalized by the length of the longer word. We investigate both of these ap1If the words are from different alphabets, we can get the alignment by mapping the letters to their closest Roman equivalent, or by using the EM algorithm to learn the edits (Ristad and Yianilos, 1998). 2The cognate data sets used in our experiments are available at http://www.cs.ualberta.ca/˜bergsma/Cognates/ 659 5.1 Bitext Experiments For the bitext-based annotation, we use publiclyavailable word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) (Koehn and Monz, 2006). Initial cleaning of these noisy word pairs is necessary. We thus remove all pairs with numbers, punctuation, a capitalized English word, and all words that occur fewer than ten times. We also remove many incorrectly aligned words by fil</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric Sven Ristad and Peter N. Yianilos. 1998. Learning stringedit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages. In CoNLL,</title>
<date>2002</date>
<pages>207--216</pages>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>Charles Schafer and David Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. In CoNLL, pages 207–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Stefan Rapp</author>
<author>Christoph M¨uller</author>
</authors>
<title>The influence of minimum edit distance on reference resolution.</title>
<date>2002</date>
<booktitle>In EMNLP,</booktitle>
<pages>312--319</pages>
<marker>Strube, Rapp, M¨uller, 2002</marker>
<rawString>Michael Strube, Stefan Rapp, and Christoph M¨uller. 2002. The influence of minimum edit distance on reference resolution. In EMNLP, pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
</authors>
<title>A discriminative matching approach to word alignment.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="1345" citStr="Taskar et al. (2005)" startWordPosition="184" endWordPosition="187">ognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice’s Coefficient. We also show strong improvements over other recent discriminative and heuristic similarity functions. 1 Introduction String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similarities for spelling correction. In each of these examples, a similarity measure can make use of the recurrent substring pairings that reliably occur between words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor lang</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien, and Dan Klein. 2005. A discriminative matching approach to word alignment. In HLT-EMNLP, pages 73–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Automatic construction of weighted string similarity measures.</title>
<date>1999</date>
<booktitle>In EMNLP-VLC,</booktitle>
<pages>213--219</pages>
<contexts>
<context position="3114" citStr="Tiedemann (1999)" startWordPosition="443" endWordPosition="444">chnique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). 2 Related Work String similarity is a fundamental concept in a variety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e., uninterrupted sequences of characters found in natural language text. The most well-known measure of the similarity of two strings is the Edit Distance or Levensht</context>
<context position="5081" citStr="Tiedemann (1999)" startWordPosition="736" endWordPosition="737">orter words. Although simple to use, the untrained measures cannot adapt to the specific spelling differences between a pair of languages. Researchers have therefore investigated adaptive measures that are learned from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer’s probabilities into different weight classes to better approximate Edit Distance. Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements. Mulloni and Pekar (2006) developed a similar technique to improve NED for English/German. Essentially, all these techniques improve on the baseline approaches by using a set of positive (true) cognate pairs to re-weight the costs of edit operations or the score of sequence matches. Ideally, we would prefer a more flexible approach that can learn positive or negative weights on substring pairings in </context>
<context position="14309" citStr="Tiedemann (1999)" startWordPosition="2232" endWordPosition="2233">ameter that trades-off training error and margin on the development set. We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by Bilenko and Mooney (2003) with their token-based SVM similarity measure). We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and Kondrak (2005)’s LCSF. We also use the log of the edit probability from the stochastic decoder of Ristad and Yianilos (1998) (normalized by the length of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). For the feature representation, we only extract substring pairs that are consistent with this alignment.1 That is, the letters in our pairs can only be aligned to each other and not to letters outside the pairing: { ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...} We define phrase pairs to be the pairs of substrings consistent with the alignment. A similar use of th</context>
<context position="20916" citStr="Tiedemann (1999)" startWordPosition="3282" endWordPosition="3283">scriminative systems on one of our cognate identification development sets (Table 2). The original Klementiev and Roth (2006) (KR) system can 660 Bitext Dictionary System Fr Es De Fr Es De Gr Jp Rs PREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8 DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6 LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6 NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4 PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9 Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5 Ristad &amp; Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8 Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8 Klementiev &amp; Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4 Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9 Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%). be improved by normalizing the feature count by the longer string length and including the boundary markers. This is therefore done with all the alignment-based approaches. Also, because of the way its features are constructed, the KR system is limited to a maximum substring length of two (L&lt;2). A maximum le</context>
</contexts>
<marker>Tiedemann, 1999</marker>
<rawString>J¨org Tiedemann. 1999. Automatic construction of weighted string similarity measures. In EMNLP-VLC, pages 213–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
</authors>
<title>Discriminative methods for transliteration.</title>
<date>2006</date>
<booktitle>In EMNLP,</booktitle>
<pages>612--617</pages>
<contexts>
<context position="6550" citStr="Zelenko and Aone (2006)" startWordPosition="954" endWordPosition="957">rity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates. Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration. Our work successfully uses the alignment-based methodology of the generative approaches to enhance the feature set for discriminative string similarity. 3 The Cognate Identification Task Given two string lists, E and F, the task of cognate identification is to find all pairs of strings (e, f) that are cognate. In other similarity-driven applications, E and F could be misspelled and correctly spelled words, or the orthographic and the phon</context>
</contexts>
<marker>Zelenko, Aone, 2006</marker>
<rawString>Dmitry Zelenko and Chinatsu Aone. 2006. Discriminative methods for transliteration. In EMNLP, pages 612–617.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>