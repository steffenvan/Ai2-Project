<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000750">
<title confidence="0.9918675">
The Role of Centering Theory&apos;s Rough-Shift in the Teaching
and Evaluation of Writing Skills
</title>
<author confidence="0.999208">
Eleni Miltsakaki Karen Kukich
</author>
<affiliation confidence="0.853912">
University of Pennsylvania Educatinal Testing Service
Philadelphia, PA 19104 USA Princeton, NJ 08541 USA
</affiliation>
<email confidence="0.997674">
elenimi@unagi.cis.upenn.edu kkukich@ets.org
</email>
<sectionHeader confidence="0.980261" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998096533333333">
Existing software systems for automated essay scor-
ing can provide NLP researchers with opportunities
to test certain theoretical hypotheses, including some
derived from Centering Theory. In this study we em-
ploy ETS&apos;s e-rater essay scoring system to examine
whether local discourse coherence, as defined by a
measure of Rough-Shift transitions, might be a sig-
nificant contributor to the evaluation of essays. Our
positive results indicate that Rough-Shifts do indeed
capture a source of incoherence, one that has not been
closely examined in the Centering literature. These re-
sults not only justify Rough-Shifts as a valid transition
type, but they also support the original formulation of
Centering as a measure of discourse continuity even in
pronominal-free text.
</bodyText>
<sectionHeader confidence="0.996304" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998401">
The task of evaluating student&apos;s writ-
ing ability has traditionally been a labor-
intensive human endeavor. However, sev-
eral different software systems, e.g., PEG
Page and Peterson (1995), Intelligent Essay
Assessor i and e-rater �, are now being used
to perform this task fully automatically. Fur-
thermore, by at least one measure, these soft-
ware systems evaluate student essays with the
same degree of accuracy as human experts.
That is, computer-generated scores tend to
match human expert scores as frequently as
two human scores match each other (Burstein
et al., 1998).
Essay scoring systems such as these can
provide NLP researchers with opportunities
to test certain theoretical hypotheses and to
explore a variety of practical issues in compu-
tational linguistics. In this study, we employ
the e-rater essay scoring system to test a hy-
</bodyText>
<footnote confidence="0.9966855">
1http://lsa.colorado.edu.
2http://www.ets.org/research/erater.html
</footnote>
<bodyText confidence="0.991866521739131">
pothesis related to Centering Theory (Joshi
and Weinstein, 1981; Grosz et al., 1983, in-
ter alia). We focus on Centering Theory&apos;s
Rough-Shift transition which is the least well
studied among the four transition types. In
particular, we examine whether the discourse
coherence found in an essay, as defined by a
measure of relative proportion of Rough-Shift
transitions, might be a significant contributor
to the accuracy of computer-generated essay
scores. Our positive finding validates the role
of the Rough-Shift transition and suggests a
route for exploring Centering Theory&apos;s prac-
tical applicability to writing evaluation and
instruction.
2 The e-rater essay scoring system
One goal of automatic essay scoring systems
such as e-rater is to represent the criteria that
human experts use to evaluate essays. The
writing features that e-rater evaluates were
specifically chosen to reflect scoring criteria
for the essay portion of the Graduate Manage-
ment Admissions Test (GMAT). These cri-
teria are articulated in GMAT test prepara-
tion materials at http://www.gmat.org. In
e-rater, syntactic variety is represented by
features that quantify occurrences of clause
types. Logical organization and clear transi-
tions are represented by features that quan-
tify cue words in certain syntactic construc-
tions. The existence of main and supporting
points is represented by features that detect
where new points begin and where they are
developed. E-rater also includes features that
quantify the appropriateness of the vocabu-
lary content of an essay.
One feature of writing valued by writing
experts that is not explicitly represented in
the current version of e-rater is local coher-
ence. Centering Theory provides an algo-
rithm for computing local coherence in writ-
ten discourse. Our study investigates the ap-
plicability of Centering Theory&apos;s local coher-
ence measure to essay evaluation by determin-
ing the effect of adding this new feature to
e-rater&apos;s existing array of features.
</bodyText>
<sectionHeader confidence="0.9626" genericHeader="method">
3 Overview of Centering
</sectionHeader>
<bodyText confidence="0.999540916666667">
A synthesis of two different lines of work
(Joshi and Kuhn, 1979; Joshi and Weinstein,
1981) and (Sidner, 1979; Grosz, 1977; Grosz
and Sidner, 1986) yielded the formulation
of Centering Theory as a model for moni-
toring local focus in discourse. The Cen-
tering model was designed to account for
those aspects of processing that are respon-
sible for the difference in the perceived co-
herence of discourses such as those demon-
strated in (1) and (2) below (examples from
Hudson-D&apos;Zmura (1988)).
</bodyText>
<listItem confidence="0.995816333333333">
(1) a. John went to his favorite music store to
buy a piano.
b. He had frequented the store for many
years.
c. He was excited that he could finally buy a
piano.
d. He arrived just as the store was closing for
the day.
(2) a. John went to his favorite music store to
buy a piano.
b. It was a store John had frequented for
many years.
c. He was excited that he could finally buy a
piano.
d. It was closing just as John arrived.
</listItem>
<bodyText confidence="0.925960777777778">
Discourse (1) is intuitively more coherent
than discourse (2). This difference may be
seen to arise from the different degrees of con-
tinuity in what the discourse is about. Dis-
course (1) centers a single individual (John)
whereas discourse (2) seems to focus in and
out on different entities (John, store, John,
store). Centering is designed to capture these
fluctuations in continuity.
</bodyText>
<sectionHeader confidence="0.967758" genericHeader="method">
4 The Centering model
</sectionHeader>
<bodyText confidence="0.99957">
In this section, we present the basic def-
initions and common assumptions in Cen-
tering as discussed in the literature (e.g.,
Walker et al. (1998)). We present the as-
sumptions and modifications we made for this
study in Section 6.1.
</bodyText>
<subsectionHeader confidence="0.999141">
4.1 Discourse segments and entities
</subsectionHeader>
<bodyText confidence="0.999837433333333">
Discourse consists of a sequence of textual
segments and each segment consists of a se-
quence of utterances. In Centering The-
ory, utterances are designated by Ui — Un.
Each utterance Ui evokes a set of dis-
course entities, the FORWARD-LOOKING
CENTERS, designated by Cf(Ui). The
members of the Cf set are ranked accord-
ing to discourse salience. (Ranking is de-
scribed in Section 4.4.)The highest-ranked
member of the Cf set is the PREFERRED
CENTER, Cp. A BACKWARD-LOOKING
CENTER, Cb,is also identified for utterance
Ui. The highest ranked entity in the pre-
vious utterance, Cf(Ui_1 ), that is realized
in the current utterance, Ui, is its des-
ignated BACKWARD-LOOKING CENTER,
Cb. The BACKWARD-LOOKING CEN-
TER is a special member of the Cf set because
it represents the discourse entity that Ui is
about, what in the literature is often called
the &apos;topic&apos; (Reinhart, 1981; Horn, 1986).
The Cp for a given utterance may be iden-
tical with its Cb, but not necessarily so. It
is precisely this distinction between looking
back in the discourse with the Cb and pro-
jecting preferences for interpretations in the
subsequent discourse with the Cp that pro-
vides the key element in computing local co-
herence in discourse.
</bodyText>
<subsectionHeader confidence="0.999103">
4.2 Centering transitions
</subsectionHeader>
<bodyText confidence="0.951673916666667">
Four types of transitions, reflecting four de-
grees of coherence, are defined in Centering.
They are shown in transition ordering rule
(1). The rules for computing the transitions
are shown in Table 1.
(1) Transition ordering rule: Continue
is preferred to Retain, which is preferred to
Smooth-Shift, which is preferred to Rough-
Shift.
Centering defines one more rule, the Pro-
noun rule which we will discuss in detail in
Section 5.
</bodyText>
<table confidence="0.963812666666667">
Cb(Ui)=Cb(Ui-1) Cb(Ui)7�Cb(Ui-1)
Cb(Ui)=Cp Continue Smooth-Shift
Cb(Ui)oCp Retain Rough-Shift
</table>
<tableCaption confidence="0.999024">
Table 1: Table of transitions
</tableCaption>
<subsectionHeader confidence="0.928794">
4.3 Utterance
</subsectionHeader>
<bodyText confidence="0.999391181818182">
In early formulations of Centering Theory,
the &apos;utterance&apos; was not defined explicitly. In
subsequent work (Kameyama, 1998), the ut-
terance was defined as, roughly, the tensed
clause with relative clauses and clausal com-
plements as exceptions. Based on crosslin-
guistic studies, Miltsakaki (1999) defined the
utterance as the traditional &apos;sentence&apos;, i.e.,
the main clause and its accompanying subor-
dinate and adjunct clauses constitute a single
utterance.
</bodyText>
<subsectionHeader confidence="0.99855">
4.4 Cf ranking
</subsectionHeader>
<bodyText confidence="0.9978377">
As mentioned earlier, the PREFERRED
CENTER of an utterance is defined as the
highest ranked member of the Cf set. The
ranking of the Cf members is determined
by the salience status of the entities in the
utterance and may vary crosslinguistically.
Kameyama (1985) and Brennan et al. (1987)
proposed that the Cf ranking for English is
determined by grammatical function as fol-
lows:
</bodyText>
<listItem confidence="0.784108666666667">
(2) Rule for ranking of
forward-looking centers: SUBJ&gt;IND.
OBJ&gt;OBJ&gt;OTHERS
</listItem>
<bodyText confidence="0.9639533">
Later crosslinguistic studies based on em-
pirical work (Di Eugenio, 1998; Turan, 1995;
Kameyama, 1985) determined the following
detailed ranking, with QIS standing for quan-
tified indefinite subjects (people, everyone
etc) and PRO-ARB (we, you) for arbitrary
plural pronominals.
(3)Revised rule for the ranking of
forward-looking centers: SUBJ&gt;IND.
OBJ&gt;OBJ&gt;OTHERS&gt;QIS, PRO-ARB.
</bodyText>
<subsubsectionHeader confidence="0.962286">
4.4.1 Complex NPs
</subsubsectionHeader>
<bodyText confidence="0.988314272727273">
In the case of complex NPs, which have
the property of evoking multiple discourse en-
tities (e.g. his mother, software industry),
the working hypothesis commonly assumed
(e.g. Walker and Prince (1995)) is ordering
from left to right.3
5 The role of Rough-Shift
transitions
As mentioned briefly earlier, the Centering
model includes one more rule, the Pronoun
Rule given in (4).
</bodyText>
<listItem confidence="0.901068">
(4) Pronoun Rule: If some element of
Cf(Ui-1) is realized as a pronoun in Ui, then
so is the Cb(Ui).
</listItem>
<bodyText confidence="0.999903135135135">
The Pronoun Rule reflects the intuition
that pronominals are felicitously used to re-
fer to discourse-salient entities. As a result,
Cbs are often pronominalized, or even deleted
(if the grammar allows it). Rule (4) then
predicts that if there is only one pronoun in
an utterance, this pronoun must realize the
Cb. The Pronoun Rule and the distribution
of forms (definite/indefinite NPs and pronom-
inals) over transition types plays a significant
role in the development of anaphora resolu-
tion algorithms in NLP. Note that the utility
of the Pronoun Rule and the Centering transi-
tions in anaphora resolution algorithms relies
heavily on the assumption that the texts un-
der consideration are maximally coherent. In
maximally coherent texts, however, Rough-
Shifts transitions are rare, and even in less
than maximally coherent texts they occur
infrequently. For this reason the distinc-
tion between Smooth-Shifts and Rough-Shifts
was collapsed in previous work (Di Eugenio,
1998; Hurewitz, 1998, inter alia). The status
of Rough-Shift transitions in the Centering
model was therefore unclear, receiving only
negative evidence: Rough-Shifts are valid be-
cause they are found to be rare in coherent
discourse.
In this study we gain insights pertaining
to the nature of the Rough-Shifts precisely
because we are forced to drop the coherence
assumption. Our data consist of student es-
says whose degree of coherence is under eval-
uation and therefore cannot be assumed. Us-
ing students&apos; paragraph marking as segment
boundaries, we &apos;centered&apos; 100 GMAT essays.
The average length of these essays was about
</bodyText>
<footnote confidence="0.75452">
3But see also Di Eugenio (1998) for the treatment
of complex NPs in Italian.
</footnote>
<table confidence="0.993004333333333">
Def. Phr. Indef. Phr. Prons
Rough-Shifts 75 120 16
Total 195 16
</table>
<tableCaption confidence="0.998043">
Table 2: Distribution of forms over Rough-Shifts
</tableCaption>
<bodyText confidence="0.9999606">
250 words. In the next section we show
that Rough-Shift transitions provide a reli-
able measure of incoherence, correlating well
with scores provided by writing experts.
One of the crucial insights was that, in
our data, the incoherence detected by the
Rough-Shift measure is not due to violations
of the Pronominal Rule or infelicitous use of
pronominal forms in general. In Table 2,
we report the results of the distribution of
forms over Rough-Shift transitions. Out of
the 211 Rough-Shift transitions, found in the
set of 100 essays, in 195 occasions the Cp
was a nominal phrase, either definite or indef-
inite. Pronominals occurred in only 16 cases
of which 6 cases instantiated the pronominals
&apos;we&apos; or &apos;you&apos; in their generic sense. Table 2
strongly indicates that student essays were
not incoherent in terms of the processing load
imposed on the reader to resolve anaphoric
references. Instead, the incoherence in the es-
says was due to discontinuities in students&apos;
essays caused by their introducing too many
undeveloped topics within what should be a
conceptually uniform segment, i.e. their para-
graphs. This is, in fact, what Rough-Shift
picked up.
These results not only justify Rough-Shifts
as a valid transition type but they also sup-
port the original formulation of Centering as
a measure of discourse continuity even when
anaphora resoluion is not an issue. It seems
that Rough-Shifts are capturing a source of
incoherence that has been overlooked in the
Centering literature. The processing load in
the Rough-Shift cases reported here is not
increased by the effort required to resolve
anaphoric reference but instead by the effort
required to find the relevant topic connections
in a discourse bombarded with a rapid suc-
cession of multiple entities. That is, Rough-
Shifts are the result of absent or extremely
short-lived Cbs. We interpret the Rough-
Shift transitions in this context as a reflection
of the incoherence perceived by the reader
when s/he is unable to identify the topic (fo-
cus) structure of the discourse. This is a
significant insight which opens up new av-
enues for practical applications of the Cen-
tering model.
</bodyText>
<sectionHeader confidence="0.950369" genericHeader="method">
6 The e-rater Centering study
</sectionHeader>
<bodyText confidence="0.999724138888889">
In an earlier preliminary study, we applied the
Centering algorithm manually to a sample of
36 GMAT essays to explore the hypothesis
that the Centering model provides a reason-
able measure of coherence (or lack of) reflect-
ing the evaluation performed by human raters
with respect to the corresponding require-
ments described in the instructions for human
raters. We observed that essays with higher
scores tended to have significantly lower per-
centages of ROUGH-SHIFTs than essays with
lower scores. As expected, the distribution of
the other types of transitions was not signif-
icant. In general, CONTINUEs, RETAINs,
and SMOOTH-SHIFTs do not yield incoher-
ent discourses (in fact, an essay with only
CONTINUE transitions might sound rather
boring!).
In this study we test the hypothesis that
a predictor variable derived from Centering
can significantly improve the performance of
e-rater. Since we are in fact proposing Cen-
tering&apos;s ROUGH-SHIFTs as a predictor vari-
able, our model, strictly speaking, measures
incoherence.
The corpus for our study came from a
pool of essays written by students taking the
GMAT test. We randomly selected a total
of 100 essays, covering the full range of the
scoring scale, where 1 is lowest and 6 is high-
est (see appendix). We applied the Center-
ing algorithm to all 100 essays, calculated the
percentage of ROUGH-SHIFTs in each essay
and then ran multiple regression to evaluate
the contribution of the proposed variable to
the e-rater&apos;s performance.
</bodyText>
<subsectionHeader confidence="0.670057">
6.1 Centering assumptions and
</subsectionHeader>
<bodyText confidence="0.983586892857143">
modifications
Utterance. Following Miltsakaki (1999), we
assume that the each utterance consists of one
main clause and all its subordinate and ad-
junct clauses.
Cf ranking. We assumed the Cf ranking
given in (3).
A modification we made involved the sta-
tus of the pronominal I. 4We observed that
in low-scored essays the first person pronom-
inal I was used extensively, normally present-
ing personal narratives. However, personal
narratives were unsuited to this essay writing
task and were assigned lower scores by ex-
pert readers. The extensive use of I in the
subject position produced an unwanted effect
of high coherence. We prescriptively decided
to penalize the use of I&apos;s in order to better
reflect the coherence demands made by the
particular writing task. The way to penal-
ize was to omit I&apos;s. As a result, coherence
was measured with respect to the treatment
of the remaining entities in the I-containing
utterances. This gave us the desired result of
being able to distinguish those I-containing
utterances which made coherent transitions
with respect to the entities they were talking
about and those that did not.
</bodyText>
<table confidence="0.999710388888889">
Lack of Fit DF Sum of Mean F-
Source 71 Squares Square Ratio
Lack of Fit 24 53.55 0.75 1.30
Pure Error 95 13.83 0.57 Prob&gt;F
Total Error 67.38 0.23
Max RSq
0.94
Parameter Esti- Std t- Prob&gt;
Estimates mate Error Ratio iti
Term
Intercept 1.46 0.37 3.92 0.0002
E-RATER 0.80 0.06 11.91 &lt;.0001
ROUGH -0.013 0.0041 -3.32 0.0013
Effect Test DF Sum of F- Prob&gt;
Source Squares Ratio F
Nparm
E-RATER 1 1 100.56 141.77 &lt;.0001
ROUGH 1 1 7.81 11.01 0.0013
</table>
<tableCaption confidence="0.803743">
Table 3: Regression
Segments. Segment boundaries are ex-
</tableCaption>
<footnote confidence="0.7838368">
4In fact, a similar modification has been proposed
by Hurewitz (1998) and Walker (1998) observed that
the use of I in sentences such as &apos;I believe that...&apos;, &apos;I
think that...&apos; do not affect the focus structure of the
text.
</footnote>
<bodyText confidence="0.999879090909091">
tremely hard to identify in an accurate and
principled way. Furthermore, existing algo-
rithms (Morris and Hirst, 1991; Youmans,
1991; Hearst, 1994; Kozima, 1993; Reynar,
1994; Passonneau and Litman, 1997; Passon-
neau, 1998) rely heavily on the assumption of
textual coherence. In our case, textual coher-
ence cannot be assumed. Given that text or-
ganization is also part of the evaluation of the
essays, we decided to use the students&apos; para-
graph breaks to locate segment boundaries.
</bodyText>
<subsectionHeader confidence="0.990582">
6.2 Implementation
</subsectionHeader>
<bodyText confidence="0.999847291666667">
For this study, we decided to manually tag
coreferring expressions despite the availabil-
ity of coreference algorithms. We made this
decision because a poor performance of the
coreference algorithm would give us distorted
results and we would not be able to test our
hypothesis. For the same reason, we manu-
ally tagged the Preferred centers as Cp. We
only needed to mark all the other entities as
OTHER. This information was adequate for
the computation of the Cb and all of the tran-
sitions.
Discourse segmentation and the implemen-
tation of the Centering algorithm for the com-
putation of the transitions were automated.
Segments boundaries were marked at para-
graph breaks and the transitions were calcu-
lated according to the instructions given in
Table 1. As output, the system computed
the percentage of Rough-Shifts for each es-
say. The percentage of Rough-Shifts was cal-
culated as the number of Rough-Shifts over
the total number of identified transitions in
the essay.
</bodyText>
<sectionHeader confidence="0.958016" genericHeader="method">
7 Study results
</sectionHeader>
<bodyText confidence="0.999945215686275">
In the appendix, we give the percentages of
Rough-Shifts (ROUGH) for each of the actual
student essays (100) on which we tested the
ROUGH variable in the regression discussed
below. The HUMAN (HUM) column con-
tains the essay scores given by human raters
and the EARTER (E-R) column contains the
corresponding score assigned by the e-rater.
Comparing HUMAN and ROUGH, we ob-
serve that essays with scores from the higher
end of the scale tend to have lower percent-
ages of Rough-Shifts than the ones from the
lower end. To evaluate that this observa-
tion can be utilized to improve the e-rater&apos;s
performance, we regressed X=E-RATER and
X=ROUGH (the predictors) by Y=HUMAN.
The results of the regression are shown in Ta-
ble 3. The &apos;Estimate&apos; cell contains the coef-
ficients assigned for each variable. The coef-
ficient for ROUGH is negative, thus penaliz-
ing occurrences of Rough-Shifts in the essays.
The t-test (&apos;t-ratio&apos; in Table 3) for ROUGH
has a highly significant p-value (p&lt;0.0013) for
these 100 essays suggesting that the added
variable ROUGH can contribute to the ac-
curacy of the model. The magnitude of the
contribution indicated by this regression is
approximately 0.5 point, a reasonalby siz-
able effect given the scoring scale (1-6). Ad-
ditional work is needed to precisely quan-
tify the contribution of ROUGH. That would
involve incorporating the ROUGH variable
into the building of a new e-rater model and
comapring the results of the new model to the
original e-rater model.
As a preliminary test of the predictability
of the model, we jacknifed the data. We per-
formed 100 tests with ERATER as the sole
variable leaving out one essay each time and
recorded the prediction of the model for that
essay. We repeated the procedure using both
variables. The predicted values for ERATER
alone and ERATER+ROUGH are shown in
columns PrH/E and PrH/E+R respectively
in Table 4. In comparing the predictions, we
observe that, indeed, 57 % of the predicted
values shown in the PrH/E+R column are
better approximations of the HUMAN scores,
especially in the cases where the ERATER&apos;s
score is discrepant by 2 points from the HU-
MAN score.
</bodyText>
<sectionHeader confidence="0.993095" genericHeader="method">
8 Discussion
</sectionHeader>
<bodyText confidence="0.99998459375">
Our positive finding, namely that Centering
Theory&apos;s measure of relative proportion of
Rough-Shift transitions is indeed a signifi-
cant contributor to the accuracy of computer-
generated essay scores, has several practical
and theoretical implications. Clearly, it in-
dicates that adding a local coherence feature
to e-rater could significantly improve e-rater&apos;s
scoring accuracy. Note, however, that over-
all scores and coherence scores need not be
strongly correlated. Indeed, our data contain
several examples of essays with high coher-
ence scores but low overall scores and vice
versa.
We briefly reviewed these cases with several
ETS writing assessment experts to gain their
insights into the value of pursuing this work
further. In an effort to maximize the use of
their time with us, we carefully selected three
pairs of essays to elicit specific information.
One pair included two high-scoring (6) essays,
one with a high coherence score and the other
with a low coherence score. Another pair in-
cluded two essays with low coherence scores
but differing overall scores (a 5 and a 6). A
final pair was carefully chosen to include one
essay with an overall score of 3 that made
several main points but did not develop them
fully or coherently, and another essay with an
overall score of 4 that made only one main
point but did develop it fully and coherently.
After briefly describing the Rough-Shift co-
herence measure and without revealing either
the overall scores or the coherence scores of
the essay pairs, we asked our experts for their
comments on the overall scores and coherence
of the essays. In all cases, our experts pre-
cisely identified the scores the essays had been
given. In the first case, they agreed with the
high Centering coherence measure, but one
expert disagreed with the low Centering co-
herence measure. For that essay, one expert
noted that &amp;quot;coherence comes and goes&amp;quot; while
another found coherence in a &amp;quot;chronological
organization of examples&amp;quot; (a notion beyond
the domain of Centering Theory). In the sec-
ond case, our experts&apos; judgments confirmed
the Rough-Shift coherence measure. In the
third case, our experts specifically identified
both the coherence and the development as-
pects as determinants of the essays&apos; scores. In
general, our experts felt that the development
of an automated coherence measure would be
a useful instructional aid.
The advantage of the Rough-Shift metric
over other quantified components of the e-
rater is that it can be appropriately translated
into instructive feedback for the student. In
an interactive tutorial system, segments con-
taining Rough-Shift transitions can be high-
lighted and supplementary instructional com-
ments will guide the student into revising the
relevant section paying attention to topic dis-
continuities.
</bodyText>
<sectionHeader confidence="0.987324" genericHeader="discussions">
9 Future work
</sectionHeader>
<bodyText confidence="0.999960583333333">
Our study prescribes a route for several fu-
ture research projects. Some, such as the
need to improve on fully automated tech-
niques for noun phrase/discourse entity iden-
tification and coreference resolution, are es-
sential for converting this measure of local co-
herence to a fully automated procedure. Oth-
ers, not explicitly discussed here, such as the
status of discourse deictic expressions, nom-
inalization resolution, and global coherence
studies are fair game for basic, theoretical re-
search.
</bodyText>
<sectionHeader confidence="0.954486" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9993357">
We would like to thank Jill Burstein who provided us
with the essay set and human and e-rater scores used
in this study; Mary Fowles, Peter Cooper, and Seth
Weiner who provided us with the valuable insights
of their writing assessment expertise; Henry Brown
who kindly discussed some statistical issues with us;
Ramin Hemat who provided perl code for automati-
cally computing Centering transitions and the Rough-
Shift measure for each essay. We are grateful to Ar-
avind Joshi and Alistair Knott for useful discussions.
</bodyText>
<sectionHeader confidence="0.9919" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.97572741">
S. Brennan, M. Walker-Friedman, and C. Pollard.
1987. A Centering approach to pronouns. In Pro-
ceedings of the 25th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 155-162.
Stanford, Calif.
J. Burstein, K. Kukich, S. Wolff, M. Chodorow,
L. Braden-Harder, M.D. Harris, and C. Lu. 1998.
Automated essay scoring using a hybrid feature
identification technique. In Annual Meeting of the
Association for Computational Linguistics, Mon-
treal, Canada, August.
B. Di Eugenio. 1998. Centering in Italian. In Center-
ing Theory in Discourse, pages 115-137. Clarendon
Press, Oxford.
B. Grosz and C. Sidner. 1986. Attentions, intentions
and the structure of discourse. Computational Lin-
guistics, 12:175-204.
B. Grosz, A. Joshi, and S. Weinstein. 1983. Provid-
ing a unified account of definite noun phrases in
discourse. In Annual Meeting of the Association
for Computational Linguistics, pages 44-50.
B. Grosz. 1977. The representation and use of focus
in language underastanding. Technical Report No.
151, Menlo Park, Calif., SRI International.
M. Hearst. 1994. Multiparagraph segmentation of
expository text. In Proc. of the 32nd ACL.
L. Horn. 1986. Presupposition, theme and variations.
In Chicago Linguistics Society, volume 22, pages
168-192.
S. Hudson-D&apos;Zmura. 1988. The Structure of Dis-
course and Anaphor Resolution: The Discourse
Center and the Roles of Nouns and Pronouns.
Ph.D. thesis, University of Rochester.
F. Hurewitz. 1998. A quantitative look at discourse
coherence. In M. Walker, A. Joshi, and E. Prince,
editors, Centering Theory in Discourse, chapter 14.
Clarendon Press, Oxford.
A. Joshi and S. Kuhn. 1979. Centered logic: The
role of entity centered sentence representation in
natural language inferencing. In 6th International
Joint Conference on Artificial Intelligence, pages
435-439.
A. Joshi and S. Weinstein. 1981. Control of infer-
ence: Role of some aspects of discourse structure:
Centering. In 7th International Joint Conference
on Artificial Intelligence, pages 385-387.
M. Kameyama. 1985. Zero Anaphora: The Case of
Japanese. Ph.D. thesis, Stanford University.
M. Kameyama. 1998. Intrasentential Centering: A
case study. In M. Walker, A. Joshi, and E. Prince,
editors, Centering Theory in Discourse, pages 89-
112. Clarendon Press: Oxford.
H. Kozima. 1993. Text segmentation based on sim-
ilarity between words. In Proc. of the 31st ACL
�tudent Session), pages 286-288.
E. iltsakaki. 1999. Locating topics in text process-
ing. In Proceedings of Computational Linguistics in
the Netherlands (CLIN&apos;99).
J. Morris and G. Hirst. 1991. Lexical cohesion com-
puted by thesaural relations as an indicator of the
structure of the text. Computational Linguistics,
17:21-28.
E. B. Page and N. Peterson. 1995. The computer
moves into essay grading: Updating the ancient
test. Phi Delta Kappan, March:561-565.
R. Passonneau and D. Litman. 1997. Discourse seg-
mentation by human and automated means. Com-
putational Linguistics, 23(1):103-139.
R. Passonneau. 1998. Interaction of discourse struc-
ture with explicitness of discourse anaphoric noun
phrases. In M. Walker, A. Joshi, and E. Prince,
editors, Centering Theory in Discourse, pages 327-
358. Clarendon Press: Oxford.
T. Reinhart. 1981. Pragmatics and linguistics: An
analysis of sentence topics. Philosophica, 27:53-94.
J. Reynar. 1994. An automatic method of finding
topic boundaaries. In Proc. of 32nd ACL (Studen
Session), pages 331-333.
C. Sidner. 1979. Toward a computational theory of
definite anaphora comprehension in English. Tech-
nical Report No. AI-TR-537, Cambridge, Mass.
MIT Press.
U. Turan. 1995. Null vs. Overt Subjects in Turk-
ish Discourse: A Centering Analysis. Ph.D. thesis,
University of Pennsylvania.
M. Walker and E. Prince. 1995. A bilateral approach
to givenness: A hearer-status algorithm and a Cen-
tering algorithm. In T. Fretheim and J. Gundel,
editors, Reference and Referent Accessibility. Ams-
terdam: John Benjamins.
M. Walker, A. Joshi, and E. Prince (eds). 1998. Cen-
tering Theory in Discourse. Clarendon Press: Ox-
ford.
M. Walker. 1998. Centering : Anaphora resolution
and discourse structure. In M. Walker, A. Joshi,
and E. Prince, editors, Centering Theory in Dis-
course, pages 401-35. Clarendon Press: Oxford.
G. Youmans. 1991. A new tool for discourse ana-
lyis: The vocabulary-management profile. Lan-
guage, 67:763-789.
</reference>
<figure confidence="0.99373806097561">
HUM E-R ROUGH PrH/E PrH/E+R
6 5 15 5.05 5.26
6 6 22 5.9921 5.9928
6 6 15 5.99 6.09
6 6 22 5.9921 5.9928
6 6 24 5.99 5.96
6 4 22 4.13 4.35
6 4 13 4.13 4.46
6 6 28 5.99 5.90
6 5 30 5.0577 5.0594
6 4 30 4.13 4.24
6 4 0 4.13 4.62
6 5 20 5.05 5.19
6 6 21 5.99 6.00
6 6 50 5.99 5.58
6 6 25 5.99 5.94
6 5 21 5.05 5.18
6 6 6 5.99 6.22
6 5 35 5.05 4.98
6 5 25 5.05 5.12
6 5 30 5.057 5.059
5 4 15 4.14 4.46
5 5 7 5.07 5.40
5 4 5 4.14 4.60
5 5 38 5.07 4.96
5 4 40 4.14 4.12
5 5 45 5.07 4.86
5 6 27 6.02 5.95
5 4 30 4.28 4.14
5 5 21 5.07 5.20
5 5 16 5.07 5.27
5 5 20 5.07 5.22
5 6 32 6.02 5.88
5 4 40 4.143 4.148
5 4 10 4.14 4.53
5 4 23 4.14 4.35
5 5 20 5.07 5.22
5 6 25 6.02 5.98
5 4 25 4.14 4.33
5 5 50 5.07 4.79
5 6 10 6.02 6.20
4 3 11 3.22 3.71
4 5 45 5.09 4.88
4 4 46 4.15 4.04
4 3 50 3.22 3.17
4 3 36 3.22 3.37
4 3 33 3.22 3.41
4 5 42 5.09 4.92
4 3 50 3.22 3.17
4 4 36 4.15 4.18
4 4 40 4.15 4.13
HUM E-R ROUGH PrH/E PrH/E+R
4 3 11 3.22 3.71
4 3 75 3.22 2.79
4 4 38 4.15 4.16
4 3 62 3.22 3.00
4 4 12 4.15 4.53
4 4 40 4.15 4.13
4 5 48 5.09 4.84
4 3 9 3.22 3.74
4 3 81 3.22 2.69
4 3 100 3.22 2.34
3 3 55 3.24 3.11
3 4 30 4.16 4.28
3 4 81 4.16 3.59
3 4 42 4.16 4.11
3 3 50 3.24 3.18
3 3 66 3.24 2.96
3 3 42 3.24 3.30
3 2 40 2.30 2.50
3 3 75 3.24 2.83
3 3 40 3.24 3.33
3 3 78 3.24 2.78
3 3 62 3.24 3.02
3 2 55 2.30 2.29
3 2 30 2.30 2.64
3 3 ? 3.29 ?
3 5 45 5.11 4.91
3 3 80 3.24 2.75
3 2 37 2.30 2.54
3 3 75 3.24 2.83
3 2 50 2.30 2.36
</figure>
<table confidence="0.9628577">
2 2 67 2.32 2.14
2 2 67 2.32 2.14
2 4 78 4.17 3.68
2 3 67 3.25 2.97
2 3 41 3.25 3.33
2 2 ? 2.32 ?
2 1 67 1.37 1.30
2 2 20 2.32 2.84
2 2 42 2.32 2.50
2 2 50 2.32 2.39
1 2 50 2.35 2.41
1 2 0 2.35 3.29
1 1 67 1.42 1.35
1 3 71 3.26 2.95
1 3 57 3.26 3.12
1 0 100 0.44 -0.03
1 1 85 1.42 1.09
1 1 67 1.42 1.35
1 2 57 2.35 2.31
1 1 0 1.42 2.48
</table>
<tableCaption confidence="0.5862882">
Table 4: Table with the human scores (HUM), the e-rater scores (E-R), the Rough-Shift measure (ROUGH),
the (jacknifed) predicted values using e-rater as the only variable (PrH/E) and the (jacknifed) predicted values
using the e-rater and the added variable Rough-Shift (PrH/E+R). The ROUGH measure is the percentage of
Rough-Shifts over the total number of identified transitions. The question mark appears where no transitions
were identified.
</tableCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912041">
<title confidence="0.9993355">The Role of Centering Theory&apos;s Rough-Shift in the Teaching and Evaluation of Writing Skills</title>
<author confidence="0.999679">Eleni Miltsakaki Karen Kukich</author>
<affiliation confidence="0.999823">University of Pennsylvania Educatinal Testing Service</affiliation>
<address confidence="0.952058">Philadelphia, PA 19104 USA Princeton, NJ 08541 USA</address>
<email confidence="0.997325">elenimi@unagi.cis.upenn.edukkukich@ets.org</email>
<abstract confidence="0.99717925">Existing software systems for automated essay scoring can provide NLP researchers with opportunities to test certain theoretical hypotheses, including some derived from Centering Theory. In this study we em- ETS&apos;s scoring system to examine whether local discourse coherence, as defined by a measure of Rough-Shift transitions, might be a significant contributor to the evaluation of essays. Our positive results indicate that Rough-Shifts do indeed capture a source of incoherence, one that has not been closely examined in the Centering literature. These results not only justify Rough-Shifts as a valid transition type, but they also support the original formulation of Centering as a measure of discourse continuity even in pronominal-free text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Brennan</author>
<author>M Walker-Friedman</author>
<author>C Pollard</author>
</authors>
<title>A Centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>155--162</pages>
<location>Stanford, Calif.</location>
<contexts>
<context position="8108" citStr="Brennan et al. (1987)" startWordPosition="1282" endWordPosition="1285">e was defined as, roughly, the tensed clause with relative clauses and clausal complements as exceptions. Based on crosslinguistic studies, Miltsakaki (1999) defined the utterance as the traditional &apos;sentence&apos;, i.e., the main clause and its accompanying subordinate and adjunct clauses constitute a single utterance. 4.4 Cf ranking As mentioned earlier, the PREFERRED CENTER of an utterance is defined as the highest ranked member of the Cf set. The ranking of the Cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically. Kameyama (1985) and Brennan et al. (1987) proposed that the Cf ranking for English is determined by grammatical function as follows: (2) Rule for ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS Later crosslinguistic studies based on empirical work (Di Eugenio, 1998; Turan, 1995; Kameyama, 1985) determined the following detailed ranking, with QIS standing for quantified indefinite subjects (people, everyone etc) and PRO-ARB (we, you) for arbitrary plural pronominals. (3)Revised rule for the ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS&gt;QIS, PRO-ARB. 4.4.1 Complex NPs In the case of complex NPs, which have t</context>
</contexts>
<marker>Brennan, Walker-Friedman, Pollard, 1987</marker>
<rawString>S. Brennan, M. Walker-Friedman, and C. Pollard. 1987. A Centering approach to pronouns. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, pages 155-162. Stanford, Calif.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Burstein</author>
<author>K Kukich</author>
<author>S Wolff</author>
<author>M Chodorow</author>
<author>L Braden-Harder</author>
<author>Harris</author>
<author>C Lu</author>
</authors>
<title>Automated essay scoring using a hybrid feature identification technique.</title>
<date>1998</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="1631" citStr="Burstein et al., 1998" startWordPosition="240" endWordPosition="243">inuity even in pronominal-free text. 1 Introduction The task of evaluating student&apos;s writing ability has traditionally been a laborintensive human endeavor. However, several different software systems, e.g., PEG Page and Peterson (1995), Intelligent Essay Assessor i and e-rater �, are now being used to perform this task fully automatically. Furthermore, by at least one measure, these software systems evaluate student essays with the same degree of accuracy as human experts. That is, computer-generated scores tend to match human expert scores as frequently as two human scores match each other (Burstein et al., 1998). Essay scoring systems such as these can provide NLP researchers with opportunities to test certain theoretical hypotheses and to explore a variety of practical issues in computational linguistics. In this study, we employ the e-rater essay scoring system to test a hy1http://lsa.colorado.edu. 2http://www.ets.org/research/erater.html pothesis related to Centering Theory (Joshi and Weinstein, 1981; Grosz et al., 1983, inter alia). We focus on Centering Theory&apos;s Rough-Shift transition which is the least well studied among the four transition types. In particular, we examine whether the discourse</context>
</contexts>
<marker>Burstein, Kukich, Wolff, Chodorow, Braden-Harder, Harris, Lu, 1998</marker>
<rawString>J. Burstein, K. Kukich, S. Wolff, M. Chodorow, L. Braden-Harder, M.D. Harris, and C. Lu. 1998. Automated essay scoring using a hybrid feature identification technique. In Annual Meeting of the Association for Computational Linguistics, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Di Eugenio</author>
</authors>
<title>Centering in Italian.</title>
<date>1998</date>
<booktitle>In Centering Theory in Discourse,</booktitle>
<pages>115--137</pages>
<publisher>Clarendon Press,</publisher>
<location>Oxford.</location>
<marker>Di Eugenio, 1998</marker>
<rawString>B. Di Eugenio. 1998. Centering in Italian. In Centering Theory in Discourse, pages 115-137. Clarendon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attentions, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--175</pages>
<contexts>
<context position="4110" citStr="Grosz and Sidner, 1986" startWordPosition="616" endWordPosition="619">content of an essay. One feature of writing valued by writing experts that is not explicitly represented in the current version of e-rater is local coherence. Centering Theory provides an algorithm for computing local coherence in written discourse. Our study investigates the applicability of Centering Theory&apos;s local coherence measure to essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived just as the store was closing for the day. (2) a. John went to his favorite music st</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>A Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Providing a unified account of definite noun phrases in discourse.</title>
<date>1983</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>44--50</pages>
<contexts>
<context position="2050" citStr="Grosz et al., 1983" startWordPosition="298" endWordPosition="301">says with the same degree of accuracy as human experts. That is, computer-generated scores tend to match human expert scores as frequently as two human scores match each other (Burstein et al., 1998). Essay scoring systems such as these can provide NLP researchers with opportunities to test certain theoretical hypotheses and to explore a variety of practical issues in computational linguistics. In this study, we employ the e-rater essay scoring system to test a hy1http://lsa.colorado.edu. 2http://www.ets.org/research/erater.html pothesis related to Centering Theory (Joshi and Weinstein, 1981; Grosz et al., 1983, inter alia). We focus on Centering Theory&apos;s Rough-Shift transition which is the least well studied among the four transition types. In particular, we examine whether the discourse coherence found in an essay, as defined by a measure of relative proportion of Rough-Shift transitions, might be a significant contributor to the accuracy of computer-generated essay scores. Our positive finding validates the role of the Rough-Shift transition and suggests a route for exploring Centering Theory&apos;s practical applicability to writing evaluation and instruction. 2 The e-rater essay scoring system One g</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1983</marker>
<rawString>B. Grosz, A. Joshi, and S. Weinstein. 1983. Providing a unified account of definite noun phrases in discourse. In Annual Meeting of the Association for Computational Linguistics, pages 44-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
</authors>
<title>The representation and use of focus in language underastanding.</title>
<date>1977</date>
<tech>Technical Report No. 151,</tech>
<publisher>International.</publisher>
<location>Menlo Park, Calif., SRI</location>
<contexts>
<context position="4085" citStr="Grosz, 1977" startWordPosition="614" endWordPosition="615">e vocabulary content of an essay. One feature of writing valued by writing experts that is not explicitly represented in the current version of e-rater is local coherence. Centering Theory provides an algorithm for computing local coherence in written discourse. Our study investigates the applicability of Centering Theory&apos;s local coherence measure to essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived just as the store was closing for the day. (2) a. John went</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>B. Grosz. 1977. The representation and use of focus in language underastanding. Technical Report No. 151, Menlo Park, Calif., SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Multiparagraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proc. of the 32nd ACL.</booktitle>
<contexts>
<context position="16593" citStr="Hearst, 1994" startWordPosition="2657" endWordPosition="2658">0002 E-RATER 0.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and we would not b</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>M. Hearst. 1994. Multiparagraph segmentation of expository text. In Proc. of the 32nd ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Horn</author>
</authors>
<title>Presupposition, theme and variations.</title>
<date>1986</date>
<booktitle>In Chicago Linguistics Society,</booktitle>
<volume>22</volume>
<pages>168--192</pages>
<contexts>
<context position="6429" citStr="Horn, 1986" startWordPosition="1020" endWordPosition="1021">f(Ui). The members of the Cf set are ranked according to discourse salience. (Ranking is described in Section 4.4.)The highest-ranked member of the Cf set is the PREFERRED CENTER, Cp. A BACKWARD-LOOKING CENTER, Cb,is also identified for utterance Ui. The highest ranked entity in the previous utterance, Cf(Ui_1 ), that is realized in the current utterance, Ui, is its designated BACKWARD-LOOKING CENTER, Cb. The BACKWARD-LOOKING CENTER is a special member of the Cf set because it represents the discourse entity that Ui is about, what in the literature is often called the &apos;topic&apos; (Reinhart, 1981; Horn, 1986). The Cp for a given utterance may be identical with its Cb, but not necessarily so. It is precisely this distinction between looking back in the discourse with the Cb and projecting preferences for interpretations in the subsequent discourse with the Cp that provides the key element in computing local coherence in discourse. 4.2 Centering transitions Four types of transitions, reflecting four degrees of coherence, are defined in Centering. They are shown in transition ordering rule (1). The rules for computing the transitions are shown in Table 1. (1) Transition ordering rule: Continue is pre</context>
</contexts>
<marker>Horn, 1986</marker>
<rawString>L. Horn. 1986. Presupposition, theme and variations. In Chicago Linguistics Society, volume 22, pages 168-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hudson-D&apos;Zmura</author>
</authors>
<title>The Structure of Discourse and Anaphor Resolution: The Discourse Center and the Roles of Nouns and Pronouns.</title>
<date>1988</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Rochester.</institution>
<contexts>
<context position="4448" citStr="Hudson-D&apos;Zmura (1988)" startWordPosition="675" endWordPosition="676">essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived just as the store was closing for the day. (2) a. John went to his favorite music store to buy a piano. b. It was a store John had frequented for many years. c. He was excited that he could finally buy a piano. d. It was closing just as John arrived. Discourse (1) is intuitively more coherent than discourse (2). This difference may be seen to arise from the different degrees of continuity in what the discourse is about</context>
</contexts>
<marker>Hudson-D&apos;Zmura, 1988</marker>
<rawString>S. Hudson-D&apos;Zmura. 1988. The Structure of Discourse and Anaphor Resolution: The Discourse Center and the Roles of Nouns and Pronouns. Ph.D. thesis, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Hurewitz</author>
</authors>
<title>A quantitative look at discourse coherence.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse, chapter 14.</booktitle>
<editor>In M. Walker, A. Joshi, and E. Prince, editors,</editor>
<publisher>Clarendon Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="10134" citStr="Hurewitz, 1998" startWordPosition="1595" endWordPosition="1596">efinite NPs and pronominals) over transition types plays a significant role in the development of anaphora resolution algorithms in NLP. Note that the utility of the Pronoun Rule and the Centering transitions in anaphora resolution algorithms relies heavily on the assumption that the texts under consideration are maximally coherent. In maximally coherent texts, however, RoughShifts transitions are rare, and even in less than maximally coherent texts they occur infrequently. For this reason the distinction between Smooth-Shifts and Rough-Shifts was collapsed in previous work (Di Eugenio, 1998; Hurewitz, 1998, inter alia). The status of Rough-Shift transitions in the Centering model was therefore unclear, receiving only negative evidence: Rough-Shifts are valid because they are found to be rare in coherent discourse. In this study we gain insights pertaining to the nature of the Rough-Shifts precisely because we are forced to drop the coherence assumption. Our data consist of student essays whose degree of coherence is under evaluation and therefore cannot be assumed. Using students&apos; paragraph marking as segment boundaries, we &apos;centered&apos; 100 GMAT essays. The average length of these essays was abou</context>
<context position="16295" citStr="Hurewitz (1998)" startWordPosition="2607" endWordPosition="2608">es they were talking about and those that did not. Lack of Fit DF Sum of Mean FSource 71 Squares Square Ratio Lack of Fit 24 53.55 0.75 1.30 Pure Error 95 13.83 0.57 Prob&gt;F Total Error 67.38 0.23 Max RSq 0.94 Parameter Esti- Std t- Prob&gt; Estimates mate Error Ratio iti Term Intercept 1.46 0.37 3.92 0.0002 E-RATER 0.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph break</context>
</contexts>
<marker>Hurewitz, 1998</marker>
<rawString>F. Hurewitz. 1998. A quantitative look at discourse coherence. In M. Walker, A. Joshi, and E. Prince, editors, Centering Theory in Discourse, chapter 14. Clarendon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>S Kuhn</author>
</authors>
<title>Centered logic: The role of entity centered sentence representation in natural language inferencing.</title>
<date>1979</date>
<booktitle>In 6th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>435--439</pages>
<contexts>
<context position="4026" citStr="Joshi and Kuhn, 1979" startWordPosition="603" endWordPosition="606">rater also includes features that quantify the appropriateness of the vocabulary content of an essay. One feature of writing valued by writing experts that is not explicitly represented in the current version of e-rater is local coherence. Centering Theory provides an algorithm for computing local coherence in written discourse. Our study investigates the applicability of Centering Theory&apos;s local coherence measure to essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived </context>
</contexts>
<marker>Joshi, Kuhn, 1979</marker>
<rawString>A. Joshi and S. Kuhn. 1979. Centered logic: The role of entity centered sentence representation in natural language inferencing. In 6th International Joint Conference on Artificial Intelligence, pages 435-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Control of inference: Role of some aspects of discourse structure: Centering.</title>
<date>1981</date>
<booktitle>In 7th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>385--387</pages>
<contexts>
<context position="2030" citStr="Joshi and Weinstein, 1981" startWordPosition="294" endWordPosition="297">systems evaluate student essays with the same degree of accuracy as human experts. That is, computer-generated scores tend to match human expert scores as frequently as two human scores match each other (Burstein et al., 1998). Essay scoring systems such as these can provide NLP researchers with opportunities to test certain theoretical hypotheses and to explore a variety of practical issues in computational linguistics. In this study, we employ the e-rater essay scoring system to test a hy1http://lsa.colorado.edu. 2http://www.ets.org/research/erater.html pothesis related to Centering Theory (Joshi and Weinstein, 1981; Grosz et al., 1983, inter alia). We focus on Centering Theory&apos;s Rough-Shift transition which is the least well studied among the four transition types. In particular, we examine whether the discourse coherence found in an essay, as defined by a measure of relative proportion of Rough-Shift transitions, might be a significant contributor to the accuracy of computer-generated essay scores. Our positive finding validates the role of the Rough-Shift transition and suggests a route for exploring Centering Theory&apos;s practical applicability to writing evaluation and instruction. 2 The e-rater essay </context>
<context position="4054" citStr="Joshi and Weinstein, 1981" startWordPosition="607" endWordPosition="610">atures that quantify the appropriateness of the vocabulary content of an essay. One feature of writing valued by writing experts that is not explicitly represented in the current version of e-rater is local coherence. Centering Theory provides an algorithm for computing local coherence in written discourse. Our study investigates the applicability of Centering Theory&apos;s local coherence measure to essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived just as the store was closin</context>
</contexts>
<marker>Joshi, Weinstein, 1981</marker>
<rawString>A. Joshi and S. Weinstein. 1981. Control of inference: Role of some aspects of discourse structure: Centering. In 7th International Joint Conference on Artificial Intelligence, pages 385-387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>Zero Anaphora: The Case of Japanese.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="8082" citStr="Kameyama (1985)" startWordPosition="1279" endWordPosition="1280"> 1998), the utterance was defined as, roughly, the tensed clause with relative clauses and clausal complements as exceptions. Based on crosslinguistic studies, Miltsakaki (1999) defined the utterance as the traditional &apos;sentence&apos;, i.e., the main clause and its accompanying subordinate and adjunct clauses constitute a single utterance. 4.4 Cf ranking As mentioned earlier, the PREFERRED CENTER of an utterance is defined as the highest ranked member of the Cf set. The ranking of the Cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically. Kameyama (1985) and Brennan et al. (1987) proposed that the Cf ranking for English is determined by grammatical function as follows: (2) Rule for ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS Later crosslinguistic studies based on empirical work (Di Eugenio, 1998; Turan, 1995; Kameyama, 1985) determined the following detailed ranking, with QIS standing for quantified indefinite subjects (people, everyone etc) and PRO-ARB (we, you) for arbitrary plural pronominals. (3)Revised rule for the ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS&gt;QIS, PRO-ARB. 4.4.1 Complex NPs In the case of</context>
</contexts>
<marker>Kameyama, 1985</marker>
<rawString>M. Kameyama. 1985. Zero Anaphora: The Case of Japanese. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>Intrasentential Centering: A case study.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>89--112</pages>
<editor>In M. Walker, A. Joshi, and E. Prince, editors,</editor>
<publisher>Clarendon Press: Oxford.</publisher>
<contexts>
<context position="7473" citStr="Kameyama, 1998" startWordPosition="1183" endWordPosition="1184">d in Centering. They are shown in transition ordering rule (1). The rules for computing the transitions are shown in Table 1. (1) Transition ordering rule: Continue is preferred to Retain, which is preferred to Smooth-Shift, which is preferred to RoughShift. Centering defines one more rule, the Pronoun rule which we will discuss in detail in Section 5. Cb(Ui)=Cb(Ui-1) Cb(Ui)7�Cb(Ui-1) Cb(Ui)=Cp Continue Smooth-Shift Cb(Ui)oCp Retain Rough-Shift Table 1: Table of transitions 4.3 Utterance In early formulations of Centering Theory, the &apos;utterance&apos; was not defined explicitly. In subsequent work (Kameyama, 1998), the utterance was defined as, roughly, the tensed clause with relative clauses and clausal complements as exceptions. Based on crosslinguistic studies, Miltsakaki (1999) defined the utterance as the traditional &apos;sentence&apos;, i.e., the main clause and its accompanying subordinate and adjunct clauses constitute a single utterance. 4.4 Cf ranking As mentioned earlier, the PREFERRED CENTER of an utterance is defined as the highest ranked member of the Cf set. The ranking of the Cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically. Kameya</context>
</contexts>
<marker>Kameyama, 1998</marker>
<rawString>M. Kameyama. 1998. Intrasentential Centering: A case study. In M. Walker, A. Joshi, and E. Prince, editors, Centering Theory in Discourse, pages 89-112. Clarendon Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kozima</author>
</authors>
<title>Text segmentation based on similarity between words.</title>
<date>1993</date>
<booktitle>In Proc. of the 31st ACL �tudent Session),</booktitle>
<pages>286--288</pages>
<contexts>
<context position="16607" citStr="Kozima, 1993" startWordPosition="2659" endWordPosition="2660">.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and we would not be able to test</context>
</contexts>
<marker>Kozima, 1993</marker>
<rawString>H. Kozima. 1993. Text segmentation based on similarity between words. In Proc. of the 31st ACL �tudent Session), pages 286-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E iltsakaki</author>
</authors>
<title>Locating topics in text processing.</title>
<date>1999</date>
<booktitle>In Proceedings of Computational Linguistics in the Netherlands (CLIN&apos;99).</booktitle>
<contexts>
<context position="7644" citStr="iltsakaki (1999)" startWordPosition="1209" endWordPosition="1210">eferred to Retain, which is preferred to Smooth-Shift, which is preferred to RoughShift. Centering defines one more rule, the Pronoun rule which we will discuss in detail in Section 5. Cb(Ui)=Cb(Ui-1) Cb(Ui)7�Cb(Ui-1) Cb(Ui)=Cp Continue Smooth-Shift Cb(Ui)oCp Retain Rough-Shift Table 1: Table of transitions 4.3 Utterance In early formulations of Centering Theory, the &apos;utterance&apos; was not defined explicitly. In subsequent work (Kameyama, 1998), the utterance was defined as, roughly, the tensed clause with relative clauses and clausal complements as exceptions. Based on crosslinguistic studies, Miltsakaki (1999) defined the utterance as the traditional &apos;sentence&apos;, i.e., the main clause and its accompanying subordinate and adjunct clauses constitute a single utterance. 4.4 Cf ranking As mentioned earlier, the PREFERRED CENTER of an utterance is defined as the highest ranked member of the Cf set. The ranking of the Cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically. Kameyama (1985) and Brennan et al. (1987) proposed that the Cf ranking for English is determined by grammatical function as follows: (2) Rule for ranking of forward-looking cent</context>
<context position="14660" citStr="iltsakaki (1999)" startWordPosition="2326" endWordPosition="2327">predictor variable, our model, strictly speaking, measures incoherence. The corpus for our study came from a pool of essays written by students taking the GMAT test. We randomly selected a total of 100 essays, covering the full range of the scoring scale, where 1 is lowest and 6 is highest (see appendix). We applied the Centering algorithm to all 100 essays, calculated the percentage of ROUGH-SHIFTs in each essay and then ran multiple regression to evaluate the contribution of the proposed variable to the e-rater&apos;s performance. 6.1 Centering assumptions and modifications Utterance. Following Miltsakaki (1999), we assume that the each utterance consists of one main clause and all its subordinate and adjunct clauses. Cf ranking. We assumed the Cf ranking given in (3). A modification we made involved the status of the pronominal I. 4We observed that in low-scored essays the first person pronominal I was used extensively, normally presenting personal narratives. However, personal narratives were unsuited to this essay writing task and were assigned lower scores by expert readers. The extensive use of I in the subject position produced an unwanted effect of high coherence. We prescriptively decided to </context>
</contexts>
<marker>iltsakaki, 1999</marker>
<rawString>E. iltsakaki. 1999. Locating topics in text processing. In Proceedings of Computational Linguistics in the Netherlands (CLIN&apos;99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Morris</author>
<author>G Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of the text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<pages>17--21</pages>
<contexts>
<context position="16564" citStr="Morris and Hirst, 1991" startWordPosition="2651" endWordPosition="2654">io iti Term Intercept 1.46 0.37 3.92 0.0002 E-RATER 0.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distort</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>J. Morris and G. Hirst. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of the text. Computational Linguistics, 17:21-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E B Page</author>
<author>N Peterson</author>
</authors>
<title>The computer moves into essay grading: Updating the ancient test.</title>
<date>1995</date>
<pages>561--565</pages>
<institution>Phi Delta Kappan,</institution>
<contexts>
<context position="1245" citStr="Page and Peterson (1995)" startWordPosition="177" endWordPosition="180">s, might be a significant contributor to the evaluation of essays. Our positive results indicate that Rough-Shifts do indeed capture a source of incoherence, one that has not been closely examined in the Centering literature. These results not only justify Rough-Shifts as a valid transition type, but they also support the original formulation of Centering as a measure of discourse continuity even in pronominal-free text. 1 Introduction The task of evaluating student&apos;s writing ability has traditionally been a laborintensive human endeavor. However, several different software systems, e.g., PEG Page and Peterson (1995), Intelligent Essay Assessor i and e-rater �, are now being used to perform this task fully automatically. Furthermore, by at least one measure, these software systems evaluate student essays with the same degree of accuracy as human experts. That is, computer-generated scores tend to match human expert scores as frequently as two human scores match each other (Burstein et al., 1998). Essay scoring systems such as these can provide NLP researchers with opportunities to test certain theoretical hypotheses and to explore a variety of practical issues in computational linguistics. In this study, </context>
</contexts>
<marker>Page, Peterson, 1995</marker>
<rawString>E. B. Page and N. Peterson. 1995. The computer moves into essay grading: Updating the ancient test. Phi Delta Kappan, March:561-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Passonneau</author>
<author>D Litman</author>
</authors>
<title>Discourse segmentation by human and automated means.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--1</pages>
<contexts>
<context position="16650" citStr="Passonneau and Litman, 1997" startWordPosition="2663" endWordPosition="2666">-0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and we would not be able to test our hypothesis. For the same reason, we ma</context>
</contexts>
<marker>Passonneau, Litman, 1997</marker>
<rawString>R. Passonneau and D. Litman. 1997. Discourse segmentation by human and automated means. Computational Linguistics, 23(1):103-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Passonneau</author>
</authors>
<title>Interaction of discourse structure with explicitness of discourse anaphoric noun phrases.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>327--358</pages>
<editor>In M. Walker, A. Joshi, and E. Prince, editors,</editor>
<publisher>Clarendon Press: Oxford.</publisher>
<contexts>
<context position="16669" citStr="Passonneau, 1998" startWordPosition="2667" endWordPosition="2669">fect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and we would not be able to test our hypothesis. For the same reason, we manually tagged the P</context>
</contexts>
<marker>Passonneau, 1998</marker>
<rawString>R. Passonneau. 1998. Interaction of discourse structure with explicitness of discourse anaphoric noun phrases. In M. Walker, A. Joshi, and E. Prince, editors, Centering Theory in Discourse, pages 327-358. Clarendon Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Reinhart</author>
</authors>
<title>Pragmatics and linguistics: An analysis of sentence topics.</title>
<date>1981</date>
<journal>Philosophica,</journal>
<pages>27--53</pages>
<contexts>
<context position="6416" citStr="Reinhart, 1981" startWordPosition="1018" endWordPosition="1019"> designated by Cf(Ui). The members of the Cf set are ranked according to discourse salience. (Ranking is described in Section 4.4.)The highest-ranked member of the Cf set is the PREFERRED CENTER, Cp. A BACKWARD-LOOKING CENTER, Cb,is also identified for utterance Ui. The highest ranked entity in the previous utterance, Cf(Ui_1 ), that is realized in the current utterance, Ui, is its designated BACKWARD-LOOKING CENTER, Cb. The BACKWARD-LOOKING CENTER is a special member of the Cf set because it represents the discourse entity that Ui is about, what in the literature is often called the &apos;topic&apos; (Reinhart, 1981; Horn, 1986). The Cp for a given utterance may be identical with its Cb, but not necessarily so. It is precisely this distinction between looking back in the discourse with the Cb and projecting preferences for interpretations in the subsequent discourse with the Cp that provides the key element in computing local coherence in discourse. 4.2 Centering transitions Four types of transitions, reflecting four degrees of coherence, are defined in Centering. They are shown in transition ordering rule (1). The rules for computing the transitions are shown in Table 1. (1) Transition ordering rule: Co</context>
</contexts>
<marker>Reinhart, 1981</marker>
<rawString>T. Reinhart. 1981. Pragmatics and linguistics: An analysis of sentence topics. Philosophica, 27:53-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reynar</author>
</authors>
<title>An automatic method of finding topic boundaaries.</title>
<date>1994</date>
<booktitle>In Proc. of 32nd ACL (Studen Session),</booktitle>
<pages>331--333</pages>
<contexts>
<context position="16621" citStr="Reynar, 1994" startWordPosition="2661" endWordPosition="2662"> &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and we would not be able to test our hypothesi</context>
</contexts>
<marker>Reynar, 1994</marker>
<rawString>J. Reynar. 1994. An automatic method of finding topic boundaaries. In Proc. of 32nd ACL (Studen Session), pages 331-333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sidner</author>
</authors>
<title>Toward a computational theory of definite anaphora comprehension in English.</title>
<date>1979</date>
<tech>Technical Report No. AI-TR-537,</tech>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="4072" citStr="Sidner, 1979" startWordPosition="612" endWordPosition="613">iateness of the vocabulary content of an essay. One feature of writing valued by writing experts that is not explicitly represented in the current version of e-rater is local coherence. Centering Theory provides an algorithm for computing local coherence in written discourse. Our study investigates the applicability of Centering Theory&apos;s local coherence measure to essay evaluation by determining the effect of adding this new feature to e-rater&apos;s existing array of features. 3 Overview of Centering A synthesis of two different lines of work (Joshi and Kuhn, 1979; Joshi and Weinstein, 1981) and (Sidner, 1979; Grosz, 1977; Grosz and Sidner, 1986) yielded the formulation of Centering Theory as a model for monitoring local focus in discourse. The Centering model was designed to account for those aspects of processing that are responsible for the difference in the perceived coherence of discourses such as those demonstrated in (1) and (2) below (examples from Hudson-D&apos;Zmura (1988)). (1) a. John went to his favorite music store to buy a piano. b. He had frequented the store for many years. c. He was excited that he could finally buy a piano. d. He arrived just as the store was closing for the day. (2)</context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>C. Sidner. 1979. Toward a computational theory of definite anaphora comprehension in English. Technical Report No. AI-TR-537, Cambridge, Mass. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Turan</author>
</authors>
<title>Null vs. Overt Subjects in Turkish Discourse: A Centering Analysis.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="8358" citStr="Turan, 1995" startWordPosition="1321" endWordPosition="1322">inate and adjunct clauses constitute a single utterance. 4.4 Cf ranking As mentioned earlier, the PREFERRED CENTER of an utterance is defined as the highest ranked member of the Cf set. The ranking of the Cf members is determined by the salience status of the entities in the utterance and may vary crosslinguistically. Kameyama (1985) and Brennan et al. (1987) proposed that the Cf ranking for English is determined by grammatical function as follows: (2) Rule for ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS Later crosslinguistic studies based on empirical work (Di Eugenio, 1998; Turan, 1995; Kameyama, 1985) determined the following detailed ranking, with QIS standing for quantified indefinite subjects (people, everyone etc) and PRO-ARB (we, you) for arbitrary plural pronominals. (3)Revised rule for the ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS&gt;QIS, PRO-ARB. 4.4.1 Complex NPs In the case of complex NPs, which have the property of evoking multiple discourse entities (e.g. his mother, software industry), the working hypothesis commonly assumed (e.g. Walker and Prince (1995)) is ordering from left to right.3 5 The role of Rough-Shift transitions As mentioned brief</context>
</contexts>
<marker>Turan, 1995</marker>
<rawString>U. Turan. 1995. Null vs. Overt Subjects in Turkish Discourse: A Centering Analysis. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>E Prince</author>
</authors>
<title>A bilateral approach to givenness: A hearer-status algorithm and a Centering algorithm.</title>
<date>1995</date>
<booktitle>Reference and Referent Accessibility.</booktitle>
<editor>In T. Fretheim and J. Gundel, editors,</editor>
<location>Amsterdam: John Benjamins.</location>
<contexts>
<context position="8867" citStr="Walker and Prince (1995)" startWordPosition="1390" endWordPosition="1393">ters: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS Later crosslinguistic studies based on empirical work (Di Eugenio, 1998; Turan, 1995; Kameyama, 1985) determined the following detailed ranking, with QIS standing for quantified indefinite subjects (people, everyone etc) and PRO-ARB (we, you) for arbitrary plural pronominals. (3)Revised rule for the ranking of forward-looking centers: SUBJ&gt;IND. OBJ&gt;OBJ&gt;OTHERS&gt;QIS, PRO-ARB. 4.4.1 Complex NPs In the case of complex NPs, which have the property of evoking multiple discourse entities (e.g. his mother, software industry), the working hypothesis commonly assumed (e.g. Walker and Prince (1995)) is ordering from left to right.3 5 The role of Rough-Shift transitions As mentioned briefly earlier, the Centering model includes one more rule, the Pronoun Rule given in (4). (4) Pronoun Rule: If some element of Cf(Ui-1) is realized as a pronoun in Ui, then so is the Cb(Ui). The Pronoun Rule reflects the intuition that pronominals are felicitously used to refer to discourse-salient entities. As a result, Cbs are often pronominalized, or even deleted (if the grammar allows it). Rule (4) then predicts that if there is only one pronoun in an utterance, this pronoun must realize the Cb. The Pro</context>
</contexts>
<marker>Walker, Prince, 1995</marker>
<rawString>M. Walker and E. Prince. 1995. A bilateral approach to givenness: A hearer-status algorithm and a Centering algorithm. In T. Fretheim and J. Gundel, editors, Reference and Referent Accessibility. Amsterdam: John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>A Joshi</author>
<author>E Prince</author>
</authors>
<title>Centering Theory in Discourse.</title>
<date>1998</date>
<publisher>Clarendon Press: Oxford.</publisher>
<contexts>
<context position="5430" citStr="Walker et al. (1998)" startWordPosition="852" endWordPosition="855">could finally buy a piano. d. It was closing just as John arrived. Discourse (1) is intuitively more coherent than discourse (2). This difference may be seen to arise from the different degrees of continuity in what the discourse is about. Discourse (1) centers a single individual (John) whereas discourse (2) seems to focus in and out on different entities (John, store, John, store). Centering is designed to capture these fluctuations in continuity. 4 The Centering model In this section, we present the basic definitions and common assumptions in Centering as discussed in the literature (e.g., Walker et al. (1998)). We present the assumptions and modifications we made for this study in Section 6.1. 4.1 Discourse segments and entities Discourse consists of a sequence of textual segments and each segment consists of a sequence of utterances. In Centering Theory, utterances are designated by Ui — Un. Each utterance Ui evokes a set of discourse entities, the FORWARD-LOOKING CENTERS, designated by Cf(Ui). The members of the Cf set are ranked according to discourse salience. (Ranking is described in Section 4.4.)The highest-ranked member of the Cf set is the PREFERRED CENTER, Cp. A BACKWARD-LOOKING CENTER, C</context>
</contexts>
<marker>Walker, Joshi, Prince, 1998</marker>
<rawString>M. Walker, A. Joshi, and E. Prince (eds). 1998. Centering Theory in Discourse. Clarendon Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
</authors>
<title>Centering : Anaphora resolution and discourse structure.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>401--35</pages>
<editor>In M. Walker, A. Joshi, and E. Prince, editors,</editor>
<publisher>Clarendon Press: Oxford.</publisher>
<contexts>
<context position="16313" citStr="Walker (1998)" startWordPosition="2610" endWordPosition="2611"> about and those that did not. Lack of Fit DF Sum of Mean FSource 71 Squares Square Ratio Lack of Fit 24 53.55 0.75 1.30 Pure Error 95 13.83 0.57 Prob&gt;F Total Error 67.38 0.23 Max RSq 0.94 Parameter Esti- Std t- Prob&gt; Estimates mate Error Ratio iti Term Intercept 1.46 0.37 3.92 0.0002 E-RATER 0.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segmen</context>
</contexts>
<marker>Walker, 1998</marker>
<rawString>M. Walker. 1998. Centering : Anaphora resolution and discourse structure. In M. Walker, A. Joshi, and E. Prince, editors, Centering Theory in Discourse, pages 401-35. Clarendon Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Youmans</author>
</authors>
<title>A new tool for discourse analyis: The vocabulary-management profile.</title>
<date>1991</date>
<journal>Language,</journal>
<pages>67--763</pages>
<contexts>
<context position="16579" citStr="Youmans, 1991" startWordPosition="2655" endWordPosition="2656">46 0.37 3.92 0.0002 E-RATER 0.80 0.06 11.91 &lt;.0001 ROUGH -0.013 0.0041 -3.32 0.0013 Effect Test DF Sum of F- Prob&gt; Source Squares Ratio F Nparm E-RATER 1 1 100.56 141.77 &lt;.0001 ROUGH 1 1 7.81 11.01 0.0013 Table 3: Regression Segments. Segment boundaries are ex4In fact, a similar modification has been proposed by Hurewitz (1998) and Walker (1998) observed that the use of I in sentences such as &apos;I believe that...&apos;, &apos;I think that...&apos; do not affect the focus structure of the text. tremely hard to identify in an accurate and principled way. Furthermore, existing algorithms (Morris and Hirst, 1991; Youmans, 1991; Hearst, 1994; Kozima, 1993; Reynar, 1994; Passonneau and Litman, 1997; Passonneau, 1998) rely heavily on the assumption of textual coherence. In our case, textual coherence cannot be assumed. Given that text organization is also part of the evaluation of the essays, we decided to use the students&apos; paragraph breaks to locate segment boundaries. 6.2 Implementation For this study, we decided to manually tag coreferring expressions despite the availability of coreference algorithms. We made this decision because a poor performance of the coreference algorithm would give us distorted results and </context>
</contexts>
<marker>Youmans, 1991</marker>
<rawString>G. Youmans. 1991. A new tool for discourse analyis: The vocabulary-management profile. Language, 67:763-789.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>