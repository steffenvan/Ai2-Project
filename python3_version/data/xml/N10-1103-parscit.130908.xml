<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061149">
<title confidence="0.997424">
Integrating Joint n-gram Features
into a Discriminative Training Framework
</title>
<author confidence="0.992386">
Sittichai Jiampojamarn† and Colin Cherry$ and Grzegorz Kondrak†
</author>
<affiliation confidence="0.994631">
†Department of Computing Science National Research Council Canada
University of Alberta 1200 Montreal Road
</affiliation>
<address confidence="0.862335">
Edmonton, AB, T6G 2E8, Canada Ottawa, ON, K1A 0R6, Canada
</address>
<email confidence="0.993223">
{sj,kondrak}@cs.ualberta.ca Colin.Cherry@nrc-cnrc.gc.ca
</email>
<sectionHeader confidence="0.995538" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999904363636364">
Phonetic string transduction problems, such
as letter-to-phoneme conversion and name
transliteration, have recently received much
attention in the NLP community. In the past
few years, two methods have come to dom-
inate as solutions to supervised string trans-
duction: generative joint n-gram models, and
discriminative sequence models. Both ap-
proaches benefit from their ability to consider
large, flexible spans of source context when
making transduction decisions. However, they
encode this context in different ways, provid-
ing their respective models with different in-
formation. To combine the strengths of these
two systems, we include joint n-gram fea-
tures inside a state-of-the-art discriminative
sequence model. We evaluate our approach
on several letter-to-phoneme and translitera-
tion data sets. Our results indicate an improve-
ment in overall performance with respect to
both the joint n-gram approach and traditional
feature sets for discriminative models.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.953367022222222">
Phonetic string transduction transforms a source
string into a target representation according to its
pronunciation. Two important examples of this task
are letter-to-phoneme conversion and name translit-
eration. In general, the problem is challenging be-
cause source orthography does not unambiguously
specify the target representation. When consider-
ing letter-to-phoneme, ambiguities and exceptions
in the pronunciation of orthography complicate con-
version. Transliteration suffers from the same ambi-
guities, but the transformation is further complicated
by restrictions in the target orthography that may not
exist in the source.
Joint n-gram models (Bisani and Ney, 2002;
Chen, 2003; Bisani and Ney, 2008) have been
widely applied to string transduction problems (Li et
al., 2004; Demberg et al., 2007; Jansche and Sproat,
2009). The power of the approach lies in building
a language model over the operations used in the
conversion from source to target. Crucially, this al-
lows the inclusion of source context in the generative
story. Smoothing techniques play an important role
in joint n-gram models, greatly affecting their per-
formance. Although joint n-gram models are capa-
ble of capturing context information in both source
and target, they cannot selectively use only source
or target information, nor can they consider arbitrary
sequences within their context window, as they are
limited by their back-off schedule.
Discriminative sequence models have also been
shown to perform extremely well on string transduc-
tion problems. These begin with a Hidden Markov
Model architecture, augmented with substring op-
erations and discriminative training. The primary
strength of these systems is their ability to include
rich indicator features representing long sequences
of source context. We will assume a specific in-
stance of discriminative sequence modeling, DI-
RECTL (Jiampojamarn et al., 2009), which achieved
the best results on several language pairs in the
NEWS Machine Transliteration Shared Task (Li et
al., 2009). The same system matches or exceeds the
performance of the joint n-gram approach on letter-
to-phoneme conversion (Jiampojamarn et al., 2008).
Its features are optimized by an online, margin-
</bodyText>
<page confidence="0.958371">
697
</page>
<subsubsectionHeader confidence="0.574735">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700,
</subsubsectionHeader>
<subsectionHeader confidence="0.27511">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.9996625">
based learning algorithm, specifically, the Margin
Infused Relaxed Algorithm, MIRA (Crammer and
Singer, 2003).
In this paper, we propose an approach that com-
bines these two different paradigms by formulating
the joint n-gram model as a new set of features in the
discriminative model. This leverages an advantage
of discriminative training, in that it can easily and
effectively incorporate arbitrary features. We eval-
uate our approach on several letter-to-phoneme and
transliteration data sets. Our results demonstrate an
improvement in overall performance with respect to
both the generative joint n-gram approach and the
original DIRECTL system.
</bodyText>
<sectionHeader confidence="0.957629" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999980615384615">
String transduction transforms an input string x into
the desired output string y. The input and output are
different representations of the same entity; for ex-
ample, the spelling and the pronunciation of a word,
or the orthographic forms of a word in two different
writing scripts.
One approach to string transduction is to view
it as a tagging problem where the input charac-
ters are tagged with the output characters. How-
ever, since sounds are often represented by multi-
character units, the relationship between the input
and output characters is often complex. This pre-
vents the straightforward application of standard
tagging techniques, but can be addressed by sub-
string decoders or semi-Markov models.
Because the relationship between x and y is hid-
den, alignments between the input and output char-
acters (or substrings) are often provided in a pre-
processing step. These are usually generated in an
unsupervised fashion using a variant of the EM al-
gorithm. Our system employs the many-to-many
alignment described in (Jiampojamarn et al., 2007).
We trained our system on these aligned examples by
using the online discriminative training of (Jiampo-
jamarn et al., 2009). At each step, the parameter
update is provided by MIRA.
</bodyText>
<sectionHeader confidence="0.999244" genericHeader="method">
3 Features
</sectionHeader>
<bodyText confidence="0.919194333333333">
Jiampojamarn et al. (2009) describe a set of indica-
tor feature templates that include (1) context features
(2) transition features and (3) linear-chain features.
</bodyText>
<table confidence="0.998717045454546">
context xi−c yi
. . .
xi+c yi
xi−cxi−c+1 yi
. . .
xi+c−1xi+c yi
xi−c ... xi+c yi
transition yi−1 yi
linear-chain xi−c yi−1 yi
. . .
xi+c yi−1 yi
xi−cxi−c+1 yi−1 yi
. . .
xi+c−1xi+c yi−1 yi
xi−c ... xi+c, yi−1 yi
joint n-gram xi+1−nyi+1−nxiyi
. . .
xi−1yi−1xiyi
xi+1−nyi+1−nxi+2−nyi+2−nxiyi
. . .
xi−2yi−2xi−1yi−1xiyi
xi+1−nyi+1−n ... xi−1yi−1xiyi
</table>
<tableCaption confidence="0.999238">
Table 1: Feature template
</tableCaption>
<bodyText confidence="0.986646318181818">
Table 1 summarizes these features and introduces
the new set ofjoint n-gram features.
The context features represent the source side ev-
idence that surrounds an input substring xi as it gen-
erates the target output yi. These features include
all possible n-grams that fit inside a source-side con-
text windows of size C, each conjoined with yi. The
transition features enforce the cohesion of the gen-
erated output with target-side bigrams. The linear-
chain features conjoin context and transition fea-
tures.
The set of feature templates described above
has been demonstrated to achieve excellent perfor-
mance. The context features express rich informa-
tion on the source side, but no feature template al-
lows target context beyond yi_1, yi. Target and
source context are considered jointly, but only in a
very limited fashion, as provided by the linear chain
features. Jiampojamarn et al. (2008) report that con-
text features contribute the most to system perfor-
mance. They also report that increasing the Markov
order in the transition features from bigram to tri-
</bodyText>
<page confidence="0.992521">
698
</page>
<figureCaption confidence="0.999791">
Figure 1: System accuracy as a function of the beam size Figure 2: System accuracy as a function of n-gram size
</figureCaption>
<bodyText confidence="0.999973173913044">
gram results in no significant improvement. Intu-
itively, the joint information of both source and tar-
get sides is important in string transduction prob-
lems. By integrating the joint n-gram features into
the online discriminative training framework, we en-
able the system to not only enjoy rich context fea-
tures and long-range dependency linear-chain fea-
tures, but we also take advantage of joint informa-
tion between source and target substring pairs, as
encoded by the joint n-gram template shown in the
bottom of Table 1.
An alternative method to incorporate a joint n-
gram feature would compute the generative joint n-
gram scores, and supply them as a real-valued fea-
ture to the model. As all of the other features in
the DIRECTL framework are indicators, the training
algorithm may have trouble scaling an informative
real-valued feature. Therefore, we represent these
joint n-gram features as binary features that indi-
cate whether the model has seen particular strings
of joint evidence in the previous n − 1 operations
when generating yi from xi. In this case, the sys-
tem learns a distinct weight for each substring of the
joint n-gram.
In order to accommodate higher-order joint n-
grams, we replace the exact search algorithm of Ji-
ampojamarn et al. (2008) with a beam search. Dur-
ing our development experiments, we observed no
significant decrease in accuracy after introducing
this approximation. Figure 1 shows the system per-
formance in terms of the word accuracy as a function
of the beam size on a development set. The perfor-
mance starts to converge quickly and shows no fur-
ther improvement for values grater than 20. In the
remaining experiments we set the beam size to 50.
We also performed development experiments
with a version of the system that includes only joint
n-gram indicators. Figure 2 shows the word ac-
curacy with different values of n. The accuracy
reaches its maximum for n = 4, and actually falls
off for larger values of n. This anomaly is likely
caused by the model using its expanded expressive
power to memorize sequences of operations, overfit-
ting to its training data. Such overfitting is less likely
to happen in the generative joint n-gram model,
which smooths high-order estimates very carefully.
</bodyText>
<sectionHeader confidence="0.994075" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999996708333334">
We evaluate our new approach on two string trans-
duction applications: (1) letter-to-phoneme conver-
sion and (2) name transliteration. For the letter-to-
phoneme conversion, we employ the English Celex,
NETtalk, OALD, CMUdict, and the French Brulex
data sets. In order to perform direct comparison with
the joint n-gram approach, we follow exactly the
same data splits as Bisani and Ney (2008). The train-
ing sizes range from 19K to 106K words. For the
transliteration task, we use three data sets provided
by the NEWS 2009 Machine Transliteration Shared
Task (Li et al., 2009): English-Russian (EnRu),
English-Chinese (EnCh), and English-Hindi (EnHi).
The training sizes range from 10K to 30K words.
We set n = 6 for the joint n-gram features; other pa-
rameters are set on the respective development sets.
Tables 2 and 3 show the performance of our new
system in comparison with the joint n-gram ap-
proach and DIRECTL. The results in the rightmost
column of Table 2 are taken directly from (Bisani
and Ney, 2008), where they were evaluated on the
same data splits. The results in the rightmost col-
umn of Table 3 are from (Jansche and Sproat, 2009),
which was the best performing system based on joint
</bodyText>
<page confidence="0.99716">
699
</page>
<table confidence="0.999749166666667">
Data set this work DIRECTL joint n-gram
Celex 89.23 88.54 88.58
CMUdict 76.41 75.41 75.47
OALD 85.54 82.43 82.51
NETtalk 73.52 70.18 69.00
Brulex 95.21 95.03 93.75
</table>
<tableCaption confidence="0.799367">
Table 2: Letter-to-phoneme conversion accuracy
</tableCaption>
<table confidence="0.99934125">
Data set this work DIRECTL joint n-gram
EnRu 61.80 61.30 59.70
EnCh 74.17 73.34 64.60
EnHi 50.30 49.80 41.50
</table>
<tableCaption confidence="0.999558">
Table 3: Name transliteration accuracy
</tableCaption>
<bodyText confidence="0.999767826086956">
n-grams at NEWS 2009. We report all results in
terms of the word accuracy, which awards the sys-
tem only for complete matches between system out-
puts and the references.
Our full system outperforms both DIRECTL and
the joint n-gram approach in all data sets. This
shows the utility of adding joint n-gram features to
the DIRECTL system, and confirms an advantage of
discriminative approaches: strong competitors can
simply be folded into the model.
Comparing across tables, one can see that the gap
between the generative joint n-gram and the DI-
RECTL methods is much larger for the transliter-
ation tasks. This could be because joint n-grams
are a poor fit for transliteration, or the gap could
stem from differences between the joint n-gram im-
plementations used for the two tasks. Looking at
the improvements to DIRECTL from joint n-gram
features, we see further evidence that joint n-grams
are better suited to letter-to-phoneme than they are
to transliteration: letter-to-phoneme improvements
range from relative error reductions of 3.6 to 17.3,
while in transliteration, the largest reduction is 3.1.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999989909090909">
We have presented a new set ofjoint n-gram features
for the DIRECTL discriminative sequence model.
The resulting system combines two successful ap-
proaches for string transduction — DIRECTL and
the joint n-gram model. Joint n-gram indicator fea-
tures are efficiently trained using a large margin
method. We have shown that the resulting system
consistently outperforms both DIRECTL and strong
joint n-gram implementations in letter-to-phoneme
conversion and name transliteration, establishing a
new state-of-the-art for these tasks.
</bodyText>
<sectionHeader confidence="0.990408" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.942877666666667">
This research was supported by the Alberta Ingenu-
ity Fund and the Natural Sciences and Engineering
Research Council of Canada.
</bodyText>
<sectionHeader confidence="0.998877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999917102564102">
Maximilian Bisani and Hermann Ney. 2002. Investi-
gations on joint-multigram models for grapheme-to-
phoneme conversion. In Proc. ICSLP, pages 105–108.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.
Stanley F. Chen. 2003. Conditional and joint mod-
els for grapheme-to-phoneme conversion. In Proc.
Eurospeech-2003.
Koby Crammer and Yoram Singer. 2003. Ultraconserva-
tive online algorithms for multiclass problems. Jour-
nal ofMachine Learning Research, 3:951–991.
Vera Demberg, Helmut Schmid, and Gregor M¨ohler.
2007. Phonological constraints and morphological
preprocessing for grapheme-to-phoneme conversion.
In Proc. ACL, pages 96–103.
Martin Jansche and Richard Sproat. 2009. Named entity
transcription with pair n-gram models. In Proc. ACL-
IJCNLP Named Entities Workshop, pages 32–35.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and Hidden Markov Models to letter-to-phoneme con-
version. In Proc. HLT-NAACL, pages 372–379.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Proc.
ACL, pages 905–913.
Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,
Kenneth Dwyer, and Grzegorz Kondrak. 2009. Di-
recTL: a language independent approach to translitera-
tion. In Proc. ACL-IJCNLP Named Entities Workshop,
pages 28–31.
Haizhou Li, Min Zhang, and Jian Su. 2004. A joint
source channel model for machine transliteration. In
Proc. ACL, pages 159–166.
Haizhou Li, A Kumaran, Vladimir Pervouchine, and Min
Zhang. 2009. Report of NEWS 2009 machine translit-
eration shared task. In Proc. ACL-IJCNLP Named En-
tities Workshop, pages 1–18.
</reference>
<page confidence="0.996412">
700
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.227678">
<title confidence="0.8237815">Joint into a Discriminative Training Framework</title>
<author confidence="0.286477">of Computing Science Research Council Canada</author>
<affiliation confidence="0.82375">University of Alberta 1200 Montreal Road</affiliation>
<address confidence="0.941528">Edmonton, AB, T6G 2E8, Canada Ottawa, ON, K1A 0R6,</address>
<email confidence="0.874084">Colin.Cherry@nrc-cnrc.gc.ca</email>
<abstract confidence="0.999688086956522">Phonetic string transduction problems, such as letter-to-phoneme conversion and name transliteration, have recently received much attention in the NLP community. In the past few years, two methods have come to dominate as solutions to supervised string transgenerative joint models, and discriminative sequence models. Both approaches benefit from their ability to consider large, flexible spans of source context when making transduction decisions. However, they encode this context in different ways, providing their respective models with different information. To combine the strengths of these systems, we include joint features inside a state-of-the-art discriminative sequence model. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results indicate an improvement in overall performance with respect to the joint approach and traditional feature sets for discriminative models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Investigations on joint-multigram models for grapheme-tophoneme conversion.</title>
<date>2002</date>
<booktitle>In Proc. ICSLP,</booktitle>
<pages>105--108</pages>
<contexts>
<context position="2021" citStr="Bisani and Ney, 2002" startWordPosition="274" endWordPosition="277">ing into a target representation according to its pronunciation. Two important examples of this task are letter-to-phoneme conversion and name transliteration. In general, the problem is challenging because source orthography does not unambiguously specify the target representation. When considering letter-to-phoneme, ambiguities and exceptions in the pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated by restrictions in the target orthography that may not exist in the source. Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use </context>
</contexts>
<marker>Bisani, Ney, 2002</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2002. Investigations on joint-multigram models for grapheme-tophoneme conversion. In Proc. ICSLP, pages 105–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="2056" citStr="Bisani and Ney, 2008" startWordPosition="280" endWordPosition="283">ccording to its pronunciation. Two important examples of this task are letter-to-phoneme conversion and name transliteration. In general, the problem is challenging because source orthography does not unambiguously specify the target representation. When considering letter-to-phoneme, ambiguities and exceptions in the pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated by restrictions in the target orthography that may not exist in the source. Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, </context>
<context position="10018" citStr="Bisani and Ney (2008)" startWordPosition="1557" endWordPosition="1560">wer to memorize sequences of operations, overfitting to its training data. Such overfitting is less likely to happen in the generative joint n-gram model, which smooths high-order estimates very carefully. 4 Experiments and Results We evaluate our new approach on two string transduction applications: (1) letter-to-phoneme conversion and (2) name transliteration. For the letter-tophoneme conversion, we employ the English Celex, NETtalk, OALD, CMUdict, and the French Brulex data sets. In order to perform direct comparison with the joint n-gram approach, we follow exactly the same data splits as Bisani and Ney (2008). The training sizes range from 19K to 106K words. For the transliteration task, we use three data sets provided by the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009): English-Russian (EnRu), English-Chinese (EnCh), and English-Hindi (EnHi). The training sizes range from 10K to 30K words. We set n = 6 for the joint n-gram features; other parameters are set on the respective development sets. Tables 2 and 3 show the performance of our new system in comparison with the joint n-gram approach and DIRECTL. The results in the rightmost column of Table 2 are taken directly from (Bisa</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Conditional and joint models for grapheme-to-phoneme conversion.</title>
<date>2003</date>
<booktitle>In Proc. Eurospeech-2003.</booktitle>
<contexts>
<context position="2033" citStr="Chen, 2003" startWordPosition="278" endWordPosition="279">esentation according to its pronunciation. Two important examples of this task are letter-to-phoneme conversion and name transliteration. In general, the problem is challenging because source orthography does not unambiguously specify the target representation. When considering letter-to-phoneme, ambiguities and exceptions in the pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated by restrictions in the target orthography that may not exist in the source. Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source </context>
</contexts>
<marker>Chen, 2003</marker>
<rawString>Stanley F. Chen. 2003. Conditional and joint models for grapheme-to-phoneme conversion. In Proc. Eurospeech-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="3873" citStr="Crammer and Singer, 2003" startWordPosition="553" endWordPosition="556">, which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA (Crammer and Singer, 2003). In this paper, we propose an approach that combines these two different paradigms by formulating the joint n-gram model as a new set of features in the discriminative model. This leverages an advantage of discriminative training, in that it can easily and effectively incorporate arbitrary features. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results demonstrate an improvement in overall performance with respect to both the generative joint n-gram approach and the original DIRECTL system. 2 Background String transduction transforms an input string </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal ofMachine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Demberg</author>
<author>Helmut Schmid</author>
<author>Gregor M¨ohler</author>
</authors>
<title>Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>96--103</pages>
<marker>Demberg, Schmid, M¨ohler, 2007</marker>
<rawString>Vera Demberg, Helmut Schmid, and Gregor M¨ohler. 2007. Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion. In Proc. ACL, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Jansche</author>
<author>Richard Sproat</author>
</authors>
<title>Named entity transcription with pair n-gram models.</title>
<date>2009</date>
<booktitle>In Proc. ACLIJCNLP Named Entities Workshop,</booktitle>
<pages>32--35</pages>
<contexts>
<context position="2179" citStr="Jansche and Sproat, 2009" startWordPosition="300" endWordPosition="303">ation. In general, the problem is challenging because source orthography does not unambiguously specify the target representation. When considering letter-to-phoneme, ambiguities and exceptions in the pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated by restrictions in the target orthography that may not exist in the source. Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, nor can they consider arbitrary sequences within their context window, as they are limited by their back-off schedule. Disc</context>
<context position="10770" citStr="Jansche and Sproat, 2009" startWordPosition="1688" endWordPosition="1691">09 Machine Transliteration Shared Task (Li et al., 2009): English-Russian (EnRu), English-Chinese (EnCh), and English-Hindi (EnHi). The training sizes range from 10K to 30K words. We set n = 6 for the joint n-gram features; other parameters are set on the respective development sets. Tables 2 and 3 show the performance of our new system in comparison with the joint n-gram approach and DIRECTL. The results in the rightmost column of Table 2 are taken directly from (Bisani and Ney, 2008), where they were evaluated on the same data splits. The results in the rightmost column of Table 3 are from (Jansche and Sproat, 2009), which was the best performing system based on joint 699 Data set this work DIRECTL joint n-gram Celex 89.23 88.54 88.58 CMUdict 76.41 75.41 75.47 OALD 85.54 82.43 82.51 NETtalk 73.52 70.18 69.00 Brulex 95.21 95.03 93.75 Table 2: Letter-to-phoneme conversion accuracy Data set this work DIRECTL joint n-gram EnRu 61.80 61.30 59.70 EnCh 74.17 73.34 64.60 EnHi 50.30 49.80 41.50 Table 3: Name transliteration accuracy n-grams at NEWS 2009. We report all results in terms of the word accuracy, which awards the system only for complete matches between system outputs and the references. Our full system</context>
</contexts>
<marker>Jansche, Sproat, 2009</marker>
<rawString>Martin Jansche and Richard Sproat. 2009. Named entity transcription with pair n-gram models. In Proc. ACLIJCNLP Named Entities Workshop, pages 32–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and Hidden Markov Models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. HLT-NAACL,</booktitle>
<pages>372--379</pages>
<contexts>
<context position="5475" citStr="Jiampojamarn et al., 2007" startWordPosition="806" endWordPosition="809">ever, since sounds are often represented by multicharacter units, the relationship between the input and output characters is often complex. This prevents the straightforward application of standard tagging techniques, but can be addressed by substring decoders or semi-Markov models. Because the relationship between x and y is hidden, alignments between the input and output characters (or substrings) are often provided in a preprocessing step. These are usually generated in an unsupervised fashion using a variant of the EM algorithm. Our system employs the many-to-many alignment described in (Jiampojamarn et al., 2007). We trained our system on these aligned examples by using the online discriminative training of (Jiampojamarn et al., 2009). At each step, the parameter update is provided by MIRA. 3 Features Jiampojamarn et al. (2009) describe a set of indicator feature templates that include (1) context features (2) transition features and (3) linear-chain features. context xi−c yi . . . xi+c yi xi−cxi−c+1 yi . . . xi+c−1xi+c yi xi−c ... xi+c yi transition yi−1 yi linear-chain xi−c yi−1 yi . . . xi+c yi−1 yi xi−cxi−c+1 yi−1 yi . . . xi+c−1xi+c yi−1 yi xi−c ... xi+c, yi−1 yi joint n-gram xi+1−nyi+1−nxiyi . .</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and Hidden Markov Models to letter-to-phoneme conversion. In Proc. HLT-NAACL, pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>905--913</pages>
<contexts>
<context position="3513" citStr="Jiampojamarn et al., 2008" startWordPosition="503" endWordPosition="506">hese begin with a Hidden Markov Model architecture, augmented with substring operations and discriminative training. The primary strength of these systems is their ability to include rich indicator features representing long sequences of source context. We will assume a specific instance of discriminative sequence modeling, DIRECTL (Jiampojamarn et al., 2009), which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA (Crammer and Singer, 2003). In this paper, we propose an approach that combines these two different paradigms by formulating the joint n-gram model as a new set of features in the discriminative model. This leverages an advantage of discriminative training, in that </context>
<context position="7090" citStr="Jiampojamarn et al. (2008)" startWordPosition="1070" endWordPosition="1073">that fit inside a source-side context windows of size C, each conjoined with yi. The transition features enforce the cohesion of the generated output with target-side bigrams. The linearchain features conjoin context and transition features. The set of feature templates described above has been demonstrated to achieve excellent performance. The context features express rich information on the source side, but no feature template allows target context beyond yi_1, yi. Target and source context are considered jointly, but only in a very limited fashion, as provided by the linear chain features. Jiampojamarn et al. (2008) report that context features contribute the most to system performance. They also report that increasing the Markov order in the transition features from bigram to tri698 Figure 1: System accuracy as a function of the beam size Figure 2: System accuracy as a function of n-gram size gram results in no significant improvement. Intuitively, the joint information of both source and target sides is important in string transduction problems. By integrating the joint n-gram features into the online discriminative training framework, we enable the system to not only enjoy rich context features and lo</context>
<context position="8631" citStr="Jiampojamarn et al. (2008)" startWordPosition="1328" endWordPosition="1332">nd supply them as a real-valued feature to the model. As all of the other features in the DIRECTL framework are indicators, the training algorithm may have trouble scaling an informative real-valued feature. Therefore, we represent these joint n-gram features as binary features that indicate whether the model has seen particular strings of joint evidence in the previous n − 1 operations when generating yi from xi. In this case, the system learns a distinct weight for each substring of the joint n-gram. In order to accommodate higher-order joint ngrams, we replace the exact search algorithm of Jiampojamarn et al. (2008) with a beam search. During our development experiments, we observed no significant decrease in accuracy after introducing this approximation. Figure 1 shows the system performance in terms of the word accuracy as a function of the beam size on a development set. The performance starts to converge quickly and shows no further improvement for values grater than 20. In the remaining experiments we set the beam size to 50. We also performed development experiments with a version of the system that includes only joint n-gram indicators. Figure 2 shows the word accuracy with different values of n. </context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proc. ACL, pages 905–913.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Aditya Bhargava</author>
<author>Qing Dou</author>
<author>Kenneth Dwyer</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>DirecTL: a language independent approach to transliteration.</title>
<date>2009</date>
<booktitle>In Proc. ACL-IJCNLP Named Entities Workshop,</booktitle>
<pages>28--31</pages>
<contexts>
<context position="3248" citStr="Jiampojamarn et al., 2009" startWordPosition="462" endWordPosition="465">nly source or target information, nor can they consider arbitrary sequences within their context window, as they are limited by their back-off schedule. Discriminative sequence models have also been shown to perform extremely well on string transduction problems. These begin with a Hidden Markov Model architecture, augmented with substring operations and discriminative training. The primary strength of these systems is their ability to include rich indicator features representing long sequences of source context. We will assume a specific instance of discriminative sequence modeling, DIRECTL (Jiampojamarn et al., 2009), which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA (</context>
<context position="5599" citStr="Jiampojamarn et al., 2009" startWordPosition="825" endWordPosition="829">s often complex. This prevents the straightforward application of standard tagging techniques, but can be addressed by substring decoders or semi-Markov models. Because the relationship between x and y is hidden, alignments between the input and output characters (or substrings) are often provided in a preprocessing step. These are usually generated in an unsupervised fashion using a variant of the EM algorithm. Our system employs the many-to-many alignment described in (Jiampojamarn et al., 2007). We trained our system on these aligned examples by using the online discriminative training of (Jiampojamarn et al., 2009). At each step, the parameter update is provided by MIRA. 3 Features Jiampojamarn et al. (2009) describe a set of indicator feature templates that include (1) context features (2) transition features and (3) linear-chain features. context xi−c yi . . . xi+c yi xi−cxi−c+1 yi . . . xi+c−1xi+c yi xi−c ... xi+c yi transition yi−1 yi linear-chain xi−c yi−1 yi . . . xi+c yi−1 yi xi−cxi−c+1 yi−1 yi . . . xi+c−1xi+c yi−1 yi xi−c ... xi+c, yi−1 yi joint n-gram xi+1−nyi+1−nxiyi . . . xi−1yi−1xiyi xi+1−nyi+1−nxi+2−nyi+2−nxiyi . . . xi−2yi−2xi−1yi−1xiyi xi+1−nyi+1−n ... xi−1yi−1xiyi Table 1: Feature templ</context>
</contexts>
<marker>Jiampojamarn, Bhargava, Dou, Dwyer, Kondrak, 2009</marker>
<rawString>Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou, Kenneth Dwyer, and Grzegorz Kondrak. 2009. DirecTL: a language independent approach to transliteration. In Proc. ACL-IJCNLP Named Entities Workshop, pages 28–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Min Zhang</author>
<author>Jian Su</author>
</authors>
<title>A joint source channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>159--166</pages>
<contexts>
<context position="2130" citStr="Li et al., 2004" startWordPosition="292" endWordPosition="295">-phoneme conversion and name transliteration. In general, the problem is challenging because source orthography does not unambiguously specify the target representation. When considering letter-to-phoneme, ambiguities and exceptions in the pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated by restrictions in the target orthography that may not exist in the source. Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, nor can they consider arbitrary sequences within their context window, as </context>
</contexts>
<marker>Li, Zhang, Su, 2004</marker>
<rawString>Haizhou Li, Min Zhang, and Jian Su. 2004. A joint source channel model for machine transliteration. In Proc. ACL, pages 159–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Vladimir Pervouchine</author>
<author>Min Zhang</author>
</authors>
<title>machine transliteration shared task.</title>
<date>2009</date>
<journal>Report of NEWS</journal>
<booktitle>In Proc. ACL-IJCNLP Named Entities Workshop,</booktitle>
<pages>1--18</pages>
<contexts>
<context position="3373" citStr="Li et al., 2009" startWordPosition="482" endWordPosition="485">ack-off schedule. Discriminative sequence models have also been shown to perform extremely well on string transduction problems. These begin with a Hidden Markov Model architecture, augmented with substring operations and discriminative training. The primary strength of these systems is their ability to include rich indicator features representing long sequences of source context. We will assume a specific instance of discriminative sequence modeling, DIRECTL (Jiampojamarn et al., 2009), which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA (Crammer and Singer, 2003). In this paper, we propose an approach that combines these two different paradigms by formulating t</context>
<context position="10201" citStr="Li et al., 2009" startWordPosition="1589" endWordPosition="1592">s very carefully. 4 Experiments and Results We evaluate our new approach on two string transduction applications: (1) letter-to-phoneme conversion and (2) name transliteration. For the letter-tophoneme conversion, we employ the English Celex, NETtalk, OALD, CMUdict, and the French Brulex data sets. In order to perform direct comparison with the joint n-gram approach, we follow exactly the same data splits as Bisani and Ney (2008). The training sizes range from 19K to 106K words. For the transliteration task, we use three data sets provided by the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009): English-Russian (EnRu), English-Chinese (EnCh), and English-Hindi (EnHi). The training sizes range from 10K to 30K words. We set n = 6 for the joint n-gram features; other parameters are set on the respective development sets. Tables 2 and 3 show the performance of our new system in comparison with the joint n-gram approach and DIRECTL. The results in the rightmost column of Table 2 are taken directly from (Bisani and Ney, 2008), where they were evaluated on the same data splits. The results in the rightmost column of Table 3 are from (Jansche and Sproat, 2009), which was the best performing</context>
</contexts>
<marker>Li, Kumaran, Pervouchine, Zhang, 2009</marker>
<rawString>Haizhou Li, A Kumaran, Vladimir Pervouchine, and Min Zhang. 2009. Report of NEWS 2009 machine transliteration shared task. In Proc. ACL-IJCNLP Named Entities Workshop, pages 1–18.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>