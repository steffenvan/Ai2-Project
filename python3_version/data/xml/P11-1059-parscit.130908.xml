<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002955">
<title confidence="0.971594">
Semantic Representation of Negation Using Focus Detection
</title>
<author confidence="0.995287">
Eduardo Blanco and Dan Moldovan
</author>
<affiliation confidence="0.9944825">
Human Language Technology Research Institute
The University of Texas at Dallas
</affiliation>
<address confidence="0.843379">
Richardson, TX 75080 USA
</address>
<email confidence="0.999559">
{eduardo,moldovan}@hlt.utdallas.edu
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999233333333333">
Negation is present in all human languages
and it is used to reverse the polarity of part
of statements that are otherwise affirmative by
default. A negated statement often carries pos-
itive implicit meaning, but to pinpoint the pos-
itive part from the negative part is rather dif-
ficult. This paper aims at thoroughly repre-
senting the semantics of negation by revealing
implicit positive meaning. The proposed rep-
resentation relies on focus of negation detec-
tion. For this, new annotation over PropBank
and a learning algorithm are proposed.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999822830188679">
Understanding the meaning of text is a long term
goal in the natural language processing commu-
nity. Whereas philosophers and linguists have pro-
posed several theories, along with models to rep-
resent the meaning of text, the field of computa-
tional linguistics is still far from doing this automati-
cally. The ambiguity of language, the need to detect
implicit knowledge, and the demand for common-
sense knowledge and reasoning are a few of the dif-
ficulties to overcome. Substantial progress has been
made, though, especially on detection of semantic
relations, ontologies and reasoning methods.
Negation is present in all languages and it is al-
ways the case that statements are affirmative by
default. Negation is marked and it typically sig-
nals something unusual or an exception. It may
be present in all units of language, e.g., words
(incredible), clauses (He doesn’t have friends).
Negation and its correlates (truth values, lying,
irony, false or contradictory statements) are exclu-
sive characteristics of humans (Horn, 1989; Horn
and Kato, 2000).
Negation is fairly well-understood in grammars;
the valid ways to express a negation are documented.
However, there has not been extensive research on
detecting it, and more importantly, on representing
the semantics of negation. Negation has been largely
ignored within the area of semantic relations.
At first glance, one would think that interpreting
negation could be reduced to finding negative key-
words, detect their scope using syntactic analysis
and reverse its polarity. Actually, it is more com-
plex. Negation plays a remarkable role in text un-
derstanding and it poses considerable challenges.
Detecting the scope of negation in itself is chal-
lenging: All vegetarians do not eat meat means that
vegetarians do not eat meat and yet All that glitters
is not gold means that it is not the case that all that
glitters is gold (so out of all things that glitter, some
are gold and some are not). In the former example,
the universal quantifier all has scope over the nega-
tion; in the latter, the negation has scope over all.
In logic, two negatives always cancel each other
out. On the other hand, in language this is only theo-
retically the case: she is not unhappy does not mean
that she is happy; it means that she is notfully un-
happy, but she is not happy either.
Some negated statements carry a positive implicit
meaning. For example, cows do not eat meat implies
that cows eat something other than meat. Otherwise,
the speaker would have stated cows do not eat. A
clearer example is the correct and yet puzzling state-
ment tables do not eat meat. This sentence sounds
</bodyText>
<page confidence="0.973362">
581
</page>
<note confidence="0.9795565">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 581–589,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.998751111111111">
unnatural because of the underlying positive state-
ment (i.e., tables eat something other than meat).
Negation can express less than or in between
when used in a scalar context. For example, John
does not have three children probably means that he
has either one or two children. Contrasts may use
negation to disagree about a statement and not to
negate it, e.g., That place is not big, it is massive
defines the place as massive, and therefore, big.
</bodyText>
<sectionHeader confidence="0.99978" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999938823529412">
Negation has been widely studied outside of com-
putational linguistics. In logic, negation is usu-
ally the simplest unary operator and it reverses the
truth value. The seminal work by Horn (1989)
presents the main thoughts in philosophy and psy-
chology. Linguists have found negation a complex
phenomenon; Huddleston and Pullum (2002) ded-
icate over 60 pages to it. Negation interacts with
quantifiers and anaphora (Hintikka, 2002), and in-
fluences reasoning (Dowty, 1994; S´anchez Valencia,
1991). Zeijlstra (2007) analyzes the position and
form of negative elements and negative concords.
Rooth (1985) presented a theory of focus in his
dissertation and posterior publications (e.g., Rooth
(1992)). In this paper, we follow the insights on
scope and focus of negation by Huddleston and Pul-
lum (2002) rather than Rooth’s (1985).
Within natural language processing, negation
has drawn attention mainly in sentiment analysis
(Wilson et al., 2009; Wiegand et al., 2010) and
the biomedical domain. Recently, the Negation
and Speculation in NLP Workshop (Morante and
Sporleder, 2010) and the CoNLL-2010 Shared Task
(Farkas et al., 2010) targeted negation mostly on
those subfields. Morante and Daelemans (2009) and
¨Ozg¨ur and Radev (2009) propose scope detectors
using the BioScope corpus. Councill et al. (2010)
present a supervised scope detector using their own
annotation. Some NLP applications deal indirectly
with negation, e.g., machine translation (van Mun-
ster, 1988), text classification (Rose et al., 2003) and
recognizing entailments (Bos and Markert, 2005).
Regarding corpora, the BioScope corpus anno-
tates negation marks and linguistic scopes exclu-
sively on biomedical texts. It does not annotate fo-
cus and it purposely ignores negations such as (talk-
ing about the reaction of certain elements) in NK3.3
cells is not always identical (Vincze et al., 2008),
which carry the kind of positive meaning this work
aims at extracting (in NK3.3 cells is often identi-
cal). PropBank (Palmer et al., 2005) only indicates
the verb to which a negation mark attaches; it does
not provide any information about the scope or fo-
cus. FrameNet (Baker et al., 1998) does not con-
sider negation and FactBank (Sauriand Pustejovsky,
2009) only annotates degrees of factuality for events.
None of the above references aim at detecting or
annotating the focus of negation in natural language.
Neither do they aim at carefully representing the
meaning of negated statements nor extracting im-
plicit positive meaning from them.
</bodyText>
<sectionHeader confidence="0.993824" genericHeader="method">
3 Negation in Natural Language
</sectionHeader>
<bodyText confidence="0.9995778">
Simply put, negation is a process that turns a state-
ment into its opposite. Unlike affirmative state-
ments, negation is marked by words (e.g., not, no,
never) or affixes (e.g., -n’t, un-). Negation can inter-
act with other words in special ways. For example,
negated clauses use different connective adjuncts
that positive clauses do: neither, nor instead of ei-
ther, or. The so-called negatively-oriented polarity-
sensitive items (Huddleston and Pullum, 2002) in-
clude, among many others, words starting with any-
(anybody, anyone, anywhere, etc.), the modal aux-
iliaries dare and need and the grammatical units at
all, much and till. Negation in verbs usually requires
an auxiliary; if none is present, the auxiliary do is in-
serted (I read the paper vs. I didn’t read the paper).
</bodyText>
<subsectionHeader confidence="0.999978">
3.1 Meaning of Negated Statements
</subsectionHeader>
<bodyText confidence="0.978726923076923">
State-of-the-art semantic role labelers (e.g., the ones
trained over PropBank) do not completely repre-
sent the meaning of negated statements. Given
John didn’t build a house to impress Mary, they en-
code AGENT(John, build), THEME(a house, build),
PURPOSE(to impress Mary, build), NEGATION(n’t,
build). This representation corresponds to the inter-
pretation it is not the case that John built a house
to impress Mary, ignoring that it is implicitly stated
that John did build a house.
Several examples are shown Table 1. For all state-
ments s, current role labelers would only encode it
is not the case that s. However, examples (1–7)
</bodyText>
<page confidence="0.996717">
582
</page>
<table confidence="0.998275294117647">
Statement Interpretation
1 John didn’t build a house to ims. John built a house for other purpose.
2 with me. I have a watch, but it is not with me.
I don’t have a watch ���
3 flooding. We have an evacuation plan for something else (e.g., fire).
for �������
We don’t have an evacuation plan���
4 They didn’t release the UFO files until 2008. They released the UFO files in 2008.
5 John doesn’t know exactly how they met. John knows how they met, but not exactly.
6 driving. His new job has requirements, but it does not require driving.
His new job doesn’t require �����
7 yet. His new job requires driving in the future.
His new job doesn’t require driving ��
8 require anything. His new job has no requirements.
His new job doesn’t������
9 inspire confidence. A panic on Wall Streen discourages confidence.
A panic on Wall Street doesn’t exactly �����
</table>
<tableCaption confidence="0.980844">
Table 1: Examples of negated statements and their interpretations considering underlying positive meaning. A wavy
underline indicates the focus of negation (Section 3.3); examples (8, 9) do not carry any positive meaning.
</tableCaption>
<bodyText confidence="0.999812818181818">
carry positive meaning underneath the direct mean-
ing. Regarding (4), encoding that the UFO files
were released in 2008 is crucial to fully interpret
the statement. (6–8) show that different verb argu-
ments modify the interpretation and even signal the
existence of positive meaning. Examples (5, 9) fur-
ther illustrate the difficulty of the task; they are very
similar (both have AGENT, THEME and MANNER)
and their interpretation is altogether different. Note
that (8, 9) do not carry any positive meaning; even
though their interpretations do not contain a verbal
negation, the meaning remains negative. Some ex-
amples could be interpreted differently depending
on the context (Section 4.2.1).
This paper aims at thoroughly representing the se-
mantics of negation by revealing implicit positive
meaning. The main contributions are: (1) interpre-
tation of negation using focus detection; (2) focus of
negation annotation over all PropBank negated sen-
tences1; (3) feature set to detect the focus of nega-
tion; and (4) model to semantically represent nega-
tion and reveal its underlying positive meaning.
</bodyText>
<subsectionHeader confidence="0.999629">
3.2 Negation Types
</subsectionHeader>
<bodyText confidence="0.9946945">
Huddleston and Pullum (2002) distinguish four con-
trasts for negation:
</bodyText>
<listItem confidence="0.959113947368421">
• Verbal if the marker of negation is grammati-
cally associated with the verb (I did not see any-
thing at all); non-verbal if it is associated with a
dependent of the verb (I saw nothing at all).
• Analytic if the sole function of the negated
mark is to mark negation (Bill did not go);
synthetic if it has some other function as well
([Nobody]AGENT went to the meeting).
1Annotation will be available on the author’s website
• Clausal if the negation yields a negative clause
(She didn’t have a large income); subclausal oth-
erwise (She had a not inconsiderable income).
• Ordinary if it indicates that something is not the
case, e.g., (1) She didn’t have lunch with my
old man: he couldn’t make it; metalinguistic if
it does not dispute the truth but rather reformu-
lates a statement, e.g., (2) She didn’t have lunch
with your ‘old man’: she had lunch with your fa-
ther. Note that in (1) the lunch never took place,
</listItem>
<bodyText confidence="0.868762333333333">
whereas in (2) a lunch did take place.
In this paper, we focus on verbal, analytic, clausal,
and both metalinguistic and ordinary negation.
</bodyText>
<subsectionHeader confidence="0.997756">
3.3 Scope and Focus
</subsectionHeader>
<bodyText confidence="0.99888435">
Negation has both scope and focus and they are ex-
tremely important to capture its semantics. Scope is
the part of the meaning that is negated. Focus is that
part of the scope that is most prominently or explic-
itly negated (Huddleston and Pullum, 2002).
Both concepts are tightly connected. Scope corre-
sponds to all elements any of whose individual fal-
sity would make the negated statement true. Focus
is the element of the scope that is intended to be in-
terpreted as false to make the overall negative true.
Consider (1) Cows don’t eat meat and its positive
counterpart (2) Cows eat meat. The truth conditions
of (2) are: (a) somebody eats something; (b) cows
are the ones who eat; and (c) meat is what is eaten.
In order for (2) to be true, (a–c) have to be true.
And the falsity of any of them is sufficient to make
(1) true. In other words, (1) would be true if nobody
eats, cows don’t eat or meat is not eaten. Therefore,
all three statements (a–c) are inside the scope of (1).
The focus is more difficult to identify, especially
</bodyText>
<page confidence="0.996796">
583
</page>
<table confidence="0.9981318">
1 AGENT(the cow, didn’t eat) THEME(grass, didn’t eat) INSTRUMENT(with a fork, didn’t eat)
2 NOT[AGENT(the cow, ate) THEME(grass, ate) INSTRUMENT(with a fork, ate)]
3 NOT[AGENT(the cow, ate)] THEME(grass, ate) INSTRUMENT(with a fork, ate)
4 AGENT(the cow, ate) NOT[THEME(grass, ate)] INSTRUMENT(with a fork, ate)
5 AGENT(the cow, ate) THEME(grass, ate) NOT[INSTRUMENT(with a fork, ate)]
</table>
<tableCaption confidence="0.999434">
Table 2: Possible semantic representations for The cow didn’t eat grass with a fork.
</tableCaption>
<bodyText confidence="0.9998307">
without knowing stress or intonation. Text under-
standing is needed and context plays an important
role. The most probable focus for (1) is meat, which
corresponds to the interpretation cows eat something
else than meat. Another possible focus is cows,
which yields someone eats meat, but not cows.
Both scope and focus are primarily semantic,
highly ambiguous and context-dependent. More ex-
amples can be found in Tables 1 and 3 and (Huddle-
ston and Pullum, 2002, Chap. 9).
</bodyText>
<sectionHeader confidence="0.915429" genericHeader="method">
4 Approach to Semantic Representation of
Negation
</sectionHeader>
<bodyText confidence="0.99991425">
Negation does not stand on its own. To be useful, it
should be added as part of another existing knowl-
edge representation. In this Section, we outline how
to incorporate negation into semantic relations.
</bodyText>
<subsectionHeader confidence="0.997218">
4.1 Semantic Relations
</subsectionHeader>
<bodyText confidence="0.993877256410257">
Semantic relations capture connections between
concepts and label them according to their nature.
It is out of the scope of this paper to define them
in depth, establish a set to consider or discuss their
detection. Instead, we use generic semantic roles.
Given s: The cow didn’t eat grass with a fork,
typical semantic roles encode AGENT(the cow, eat),
THEME(grass, eat), INSTRUMENT(with a fork, eat)
and NEGATION(n’t, eat). This representation only
differs on the last relation from the positive counter-
part. Its interpretation is it is not the case that s.
Several options arise to thoroughly represent s.
First, we find it useful to consider the seman-
tic representation of the affirmative counterpart:
AGENT(the cow, ate), THEME(grass, ate), and IN-
STRUMENT(with a fork, ate). Second, we believe
detecting the focus of negation is useful. Even
though it is open to discussion, the focus corre-
sponds to INSTRUMENT(with a fork, ate) Thus, the
negated statement should be interpreted as the cow
ate grass, but it did not do so using a fork.
Table 2 depicts five different possible semantic
representations. Option (1) does not incorporate any
explicit representation of negation. It attaches the
negated mark and auxiliary to eat; the negation is
part of the relation arguments. This option fails
to detect any underlying positive meaning and cor-
responds to the interpretation the cow did not eat,
grass was not eaten and a fork was not used to eat.
Options (2–5) embody negation into the represen-
tation with the pseudo-relation NOT. NOT takes as its
argument an instantiated relation or set of relations
and indicates that they do not hold.
Option (2) includes all the scope as the argument
of NOT and corresponds to the interpretation it is not
the case that the cow ate grass with a fork. Like typi-
cal semantic roles, option (2) does not reveal the im-
plicit positive meaning carried by statement s. Op-
tions (3–5) encode different interpretations:
</bodyText>
<listItem confidence="0.9932756">
• (3) negates the AGENT; it corresponds to the cow
didn’t eat, but grass was eaten with a fork.
• (4) applies NOT to the THEME; it corresponds to
the cow ate something with a fork, but not grass.
• (5) denies the INSTRUMENT, encoding the mean-
</listItem>
<bodyText confidence="0.847953285714286">
ing the cow ate grass, but it did not use a fork.
Option (5) is preferred since it captures the best
implicit positive meaning. It corresponds to the se-
mantic representation of the affirmative counterpart
after applying the pseudo-relation NOT over the fo-
cus of the negation. This fact justifies and motivates
the detection of the focus of negation.
</bodyText>
<subsectionHeader confidence="0.997489">
4.2 Annotating the Focus of Negation
</subsectionHeader>
<bodyText confidence="0.999941375">
Due to the lack of corpora containing annotation for
focus of negation, new annotation is needed. An ob-
vious option is to add it to any text collection. How-
ever, building on top of publicly available resources
is a better approach: they are known by the commu-
nity, they contain useful information for detecting
the focus of negation and tools have already been
developed to predict their annotation.
</bodyText>
<page confidence="0.987341">
584
</page>
<table confidence="0.999936058823529">
Statement V A0 A1 A2 A4 TMP MNR ADV LOC PNC EXT DIS MOD
1 Even if [that deal]A1 isn’t [revived]V, NBC hopes to find another.
– Even if that deal is suppressed, NBC hopes to find another one. ⋆ - + - - - - - - - - -
2 Heinz]A1, she says.
[He]A0 [simply]MDIS [ca]MMODn’t [stomach]V [���the taste of�����
– He simply can stomach any ketchup but Heinz’s. + + + +
⋆
3 year]MTMP.
[A decision]A1 isn’t [expected]V [until some time next ����
– A decision is expected at some time next year. + - + - - ⋆ - - - - - -
4 [... ] it told the SEC [it]A0 [could]MMODn’t [provide]V [financial statements]A1 [by the end of its first
without������������ unreasonable burden ��or expense]MMNR”.
extension]MTMP “[�������
– It could provide them by that time with a huge overhead. + + + - - + +
⋆
5 [For example]MDIS, [P&amp;G]A0 [up until now]MTMP hasn’t [sold]V [coffee]A1 [��to airlines]A2 and does only limited
business with hotels and large restaurant chains.
– Up until now, P&amp;G has sold coffee, but not to airlines. + + + ⋆ - +
+
6 [Decent life ]A1 [wo]MMODn’t be [restored][unless thereclaims the streets from then]MADV .
... V government�������� gags
– It will be restored if the government reclaims the streets from the gangs. + - + - - - - ⋆ - - - - +
7 few money���������managers]A0 aren’t [buying]V [it]A1.
But [quite a ���
– Very little managers are buying it. + ⋆ + - - - - - - - - -
8 [When]MTMP [she]A0 isn’t [performing]V [for an audience]MPNC, she prepares for a song by removing the wad of
gum from her mouth, and indicates that she’s finished by sticking the gum back in.
– She prepares in that way when she is performing, but not for an audience. + + - - - + - - - ⋆-- -
9 below����� $185 million]A4 [after the dividends are issued]MTMP.
[The company’s net worth]A1 [can]MMODnot [fall]V [������
– It can fall after the dividends are issued, but not below $185 million. + - + - ⋆ +
+
10 Mario Gabelli, an expert at spotting takeover candidates, says that [takeovers]A1 aren’t [������totally]MEXT [gone]V.
– Mario Gabelli says that takeovers are partially gone. + - + ⋆ - -
</table>
<tableCaption confidence="0.977998">
Table 3: Negated statements from PropBank and their interpretation considering underlying positive meaning. Focus
is underlined; ‘+’ indicates that the role is present, ‘-’ that it is not and ‘⋆’ that it corresponds to the focus of negation.
</tableCaption>
<bodyText confidence="0.999886111111111">
We decided to work over PropBank. Unlike other
resources (e.g., FrameNet), gold syntactic trees are
available. Compared to the BioScope corpus, Prop-
Bank provides semantic annotation and is not lim-
ited to the biomedical domain. On top of that, there
has been active research on predicting PropBank
roles for years. The additional annotation can be
readily used by any system trained with PropBank,
quickly incorporating interpretation of negation.
</bodyText>
<subsectionHeader confidence="0.674021">
4.2.1 Annotation Guidelines
</subsectionHeader>
<bodyText confidence="0.997428">
The focus of a negation involving verb v is resolved
as:
</bodyText>
<listItem confidence="0.998648">
• If it cannot be inferred that an action v oc-
curred, focus is role MNEG.
• Otherwise, focus is the role that is most promi-
nently negated.
</listItem>
<bodyText confidence="0.99927796">
All decisions are made considering as context the
previous and next sentence. The mark -NOT is used
to indicate the focus. Consider the following state-
ment (file wsj 2282, sentence 16).
[While profitable]MADV1,2, [it]A11,A02 “was[n’t]MNEG1
[growing]v1 and was[n’t]MNEG2 [providing]v2 [a sat-
isfactory return on invested capital]A12,” he says.
The previous sentence is Applied, then a closely
held company, was stagnating under the manage-
ment of its controlling family. Regarding the first
verb (growing), one cannot infer that anything was
growing, so focus is MNEG. For the second verb
(providing), it is implicitly stated that the company
was providing a not satisfactory return on invest-
ment, therefore, focus is A1.
The guidelines assume that the focus corresponds
to a single role or the verb. In cases where more than
one role could be selected, the most likely focus is
chosen; context and text understanding are key. We
define the most likely focus as the one that yields the
most meaningful implicit information.
For example, in (Table 3, example 2) [HeJA0
could be chosen as focus, yielding someone can
stomach the taste of Heinz, but not him. However,
given the previous sentence ([... J her husband is
</bodyText>
<page confidence="0.992533">
585
</page>
<figure confidence="0.999466588235294">
it
MADV
was
A1
n’t
MNEG-NOT��
MADV
growing
A0
and was
n’t
MNEG
providing
��
A1-NOT
a satisfacory return ...
While profitable
</figure>
<figureCaption confidence="0.999995">
Figure 1: Example of focus annotation (marked with -NOT). Its interpretation is explained in Section 4.2.2.
</figureCaption>
<bodyText confidence="0.999615714285714">
adamant about eating only Hunt’s ketchup), it is
clear that the best option is A1. Example (5) has a
similar ambiguity between A0 and A2, example (9)
between MTMP and A4, etc. The role that yields the
most useful positive implicit information given the
context is always chosen as focus.
Table 3 provides several examples having as their
focus different roles. Example (1) does not carry
any positive meaning, the focus is V. In (2–10) the
verb must be interpreted as affirmative, as well as
all roles except the one marked with ‘⋆’ (i.e., the
focus). For each example, we provide PropBank an-
notation (top), the new annotation (i.e., the focus,
bottom right) and its interpretation (bottom left).
</bodyText>
<subsectionHeader confidence="0.86736">
4.2.2 Interpretation of -NOT
</subsectionHeader>
<bodyText confidence="0.991788">
The mark -NOT is interpreted as follows:
</bodyText>
<listItem confidence="0.9720505">
• If MNEG-NOT(x, y), then verb y must be
negated; the statement does not carry positive
meaning.
• If any other role is marked with -NOT, ROLE-
NOT(x, y) must be interpreted as it is not the
case that x is ROLE of y.
</listItem>
<bodyText confidence="0.99991775">
Unmarked roles are interpreted positive; they cor-
respond to implicit positive meaning. Role labels
(A0, MTMP, etc.) maintain the same meaning from
PropBank (Palmer et al., 2005). MNEG can be ig-
nored since it is overwritten by -NOT.
The new annotation for the example (Figure 1)
must be interpreted as: While profitable, it (the com-
pany) was not growing and was providing a not sat-
isfactory return on investment. Paraphrasing, While
profitable, it was shrinking or idle and was providing
an unsatisfactory return on investment. We discover
an entailment and an implicature respectively.
</bodyText>
<subsectionHeader confidence="0.992014">
4.3 Annotation Process
</subsectionHeader>
<bodyText confidence="0.9997256">
We annotated the 3,993 verbal negations signaled
with MNEG in PropBank. Before annotation began,
all semantic information was removed by mapping
all role labels to ARG. This step is necessary to en-
sure that focus selection is not biased by the seman-
</bodyText>
<table confidence="0.9996720625">
Role #Inst. Focus
# – %
A1 2,930 1,194 – 40.75
MNEG 3,196 1,109 – 34.70
MTMP 609 246 – 40.39
MMNR 250 190 – 76.00
A2 501 179 – 35.73
MADV 466 94 – 20.17
A0 2,163 73 – 3.37
MLOC 114 22 – 19.30
MEXT 25 22 – 88.00
A4 26 22 – 84.62
A3 48 18 – 37.50
MDIR 35 13 – 37.14
MPNC 87 9 – 10.34
MDIS 287 6 – 2.09
</table>
<tableCaption confidence="0.993873">
Table 4: Roles, total instantiations and counts corre-
sponding to focus over training and held-out instances.
</tableCaption>
<bodyText confidence="0.998908">
tic labels provided by PropBank.
As annotation tool, we use Jubilee (Choi et al.,
2010). For each instance, annotators decide the fo-
cus given the full syntactic tree, as well as the previ-
ous and next sentence. A post-processing step incor-
porates focus annotation to the original PropBank by
adding -NOT to the corresponding role.
In a first round, 50% of instances were annotated
twice. Inter-annotator agreement was 0.72. After
careful examination of the disagreements, they were
resolved and annotators were given clearer instruc-
tions. The main point of conflict was selecting a fo-
cus that yields valid implicit meaning, but not the
most valuable (Section 4.2.1). Due to space con-
straints, we cannot elaborate more on this issue. The
remaining instances were annotated once. Table 4
depicts counts for each role.
</bodyText>
<sectionHeader confidence="0.949326" genericHeader="method">
5 Learning Algorithm
</sectionHeader>
<bodyText confidence="0.99772825">
We propose a supervised learning approach. Each
sentence from PropBank containing a verbal nega-
tion becomes an instance. The decision to be made
is to choose the role that corresponds to the focus.
</bodyText>
<page confidence="0.995622">
586
</page>
<table confidence="0.99955552173913">
No. Feature Values Explanation
1 role-present {y, n} is role present?
2 role-f-pos {DT, NNP, ... } First POS tag of role
3 role-f-word {This, to, overseas,... } First word of role
4 role-length N number fo words in role
5 role-posit N position within the set of roles
6 A1-top {NP, SBAR, PP, ...} syntactic node of A1
7 A1-postag {y, n} does A1 contain the tag postag?
8 A1-keyword {y, n} does A1 cotain the word keyword?
9 first-role {A1, MLOC, ... } label of the first role
10 last-role {A1, MLOC, ... } label of the last role
11 verb-word {appear, describe,... } main verb
12 verb-postag {VBN, VBZ, ... } POS tag main verb
13 VP-words {were-n’t, be-quickly,... } sequence of words of VP until verb
14 VP-postags {VBP-RB-RB-VBG, VBN-VBG, ...} sequence of POS tags of VP until verb
15 VP-has-CC {y, n} does the VP contain a CC?
16 VP-has-RB {y, n} does the VP contain a RB?
17 predicate {rule-out, come-up,... } predicate
18 them-role-A0 {preparer, assigner, ... } thematic role for A0
19 them-role-A1 {effort, container, ... } thematic role for A1
20 them-role-A2 {audience, loaner,... } thematic role for A2
21 them-role-A3 {intensifier, collateral, ... } thematic role for A3
22 them-role-A4 {beneficiary, end point,... } thematic role for A4
</table>
<tableCaption confidence="0.99972">
Table 5: Full set of features. Features (1–5) are extracted for all roles, (7, 8) for all POS tags and keywords detected.
</tableCaption>
<bodyText confidence="0.999867625">
The 3,993 annotated instances are divided into
training (70%), held-out (10%) and test (20%). The
held-out portion is used to tune the feature set and
results are reported for the test split only, i.e., us-
ing unseen instances. Because PropBank adds se-
mantic role annotation on top of the Penn TreeBank,
we have available syntactic annotation and semantic
role labels for all instances.
</bodyText>
<subsectionHeader confidence="0.996528">
5.1 Baselines
</subsectionHeader>
<bodyText confidence="0.997843">
We implemented four baselines to measure the diffi-
culty of the task:
</bodyText>
<listItem confidence="0.9984445">
• A1: select A1, if not present then MNEG.
• FIRST: select first role.
• LAST: select last role.
• BASIC: same than FOC-DET but only using fea-
tures last role and flags indicating the presence
of roles.
</listItem>
<subsectionHeader confidence="0.99989">
5.2 Selecting Features
</subsectionHeader>
<bodyText confidence="0.999939333333333">
The BASIC baseline obtains a respectable accuracy
of 61.38 (Table 6). Most errors correspond to in-
stances having as focus the two most likely foci: A1
and MNEG (Table 4). We improve BASIC with an
extended feature set which targets especially A1 and
the verb (Table 5).
Features (1–5) are extracted for each role and
capture their presence, first POS tag and word,
length and position within the roles present for
that instance. Features (6–8) further characterize
A1. A1-postag is extracted for the following
POS tags: DT, JJ, PRP, CD, RB, VB and WP;
A1-keyword for the following words: any, any-
body, anymore, anyone, anything, anytime, any-
where, certain, enough, full, many, much, other,
some, specifics, too and until. These lists of POS
tags and keywords were extracted after manual ex-
amination of training examples and aim at signaling
whether this role correspond to the focus. Examples
of A1 corresponding to the focus and including one
of the POS tags or keywords are:
</bodyText>
<listItem confidence="0.9664322">
• [Apparently]MADV, [the respondents]A0 do n’t
think [����that���an���������� economic slowdown would harm
������ the major investment markets veryfts much]A1
(i.e., the responders think it would harm the in-
vestements little).
</listItem>
<page confidence="0.965691">
587
</page>
<figure confidence="0.71203">
• [The oil company]A0 does n’t anticipate
[����������
anykeyword additional ��������charges]A1 (i.e., the
������������
company anticipates no additional charges).
</figure>
<listItem confidence="0.923322">
• [Money managers and other bond buyers]A0
haven’t [shown]V [muchkeyword ��������
interest��in����the
Refcorp�������� ������bonds]A1 (i.e., they have shown little
interest in the bonds).
• He concedes H&amp;R Block is well-entrenched
and a great company, but says “[it]A1 doesn’t
[grow]V[����fast�������������� enoughkeyword ����for��us]A1” (i.e., it
is growing too slow for us).
• [We]A0 don’t [see]V [�a���������� domestic source����for
</listItem>
<bodyText confidence="0.969675681818182">
somekeyword requirements ]A1,
������������ ���of����our�������� HDTV�������������
and that’s a source of concern [... ] (i.e., we see
a domestic source for some other of our HDTV
requirements)
Features (11–16) correspond to the main verb.
VP-words (VP-postag) captures the full se-
quence of words (POS tags) from the beginning of
the VP until the main verb. Features (15–16) check
for POS tags as the presence of certain tags usually
signal that the verb is not the focus of negation (e.g.,
[Thus]MDIS, he asserts, [Lloyd’s]A0 [[ca]MMODn’t
[react]v [quicklyRB]MMNR [to competition]A1]VP).
Features (17–22) tackle the predicate, which in-
cludes the main verb and may include other words
(typically prepositions). We consider the words in
the predicate, as well as the specific thematic roles
for each numbered argument. This is useful since
PropBank uses different numbered arguments for
the same thematic role depending on the frame (e.g.,
A3 is used as PURPOSE in authorize.01 and as IN-
STRUMENT in avert.01).
</bodyText>
<sectionHeader confidence="0.998958" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.997980583333333">
As a learning algorithm, we use bagging with C4.5
decision trees. This combination is fast to train and
test, and typically provides good performance. More
features than the ones depicted were tried, but we
only report the final set. For example, the parent
node for all roles was considered and discarded. We
name the model considering all features and trained
using bagging with C4.5 trees FOC-DET.
Results over the test split are depicted in Table 6.
Simply choosing A1 as the focus yields an accuracy
of 42.11. A better baseline is to always pick the last
role (58.39 accuracy). Feeding the learning algo-
</bodyText>
<table confidence="0.939490166666667">
System Accuracy
A1 42.11
FIRST 7.00
LAST 58.39
BASIC 61.38
FOC-DET 65.50
</table>
<tableCaption confidence="0.99959">
Table 6: Accuracies over test split.
</tableCaption>
<bodyText confidence="0.997512636363636">
rithm exclusively the label corresponding to the last
role and flags indicating the presence of roles yields
61.38 accuracy (BASIC baseline).
Having an agreement of 0.72, there is still room
for improvement. The full set of features yields
65.50 accuracy. The difference in accuracy between
BASIC and FOC-DET (4.12) is statistically significant
(Z-value = 1.71). We test the significance of the dif-
ference in performance between two systems i and j
on a set of ins instances with the Z-score test, where
z = abs(erσri,errj), errk is the error made using set k
</bodyText>
<equation confidence="0.905373">
erri (nserri) + errs (nserr� )
</equation>
<bodyText confidence="0.8223695">
and Qd — /
.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999877875">
In this paper, we present a novel way to semantically
represent negation using focus detection. Implicit
positive meaning is identified, giving a thorough in-
terpretation of negated statements.
Due to the lack of corpora annotating the focus of
negation, we have added this information to all the
negations marked with MNEG in PropBank. A set
of features is depicted and a supervised model pro-
posed. The task is highly ambiguous and semantic
features have proven helpful.
A verbal negation is interpreted by considering all
roles positive except the one corresponding to the
focus. This has proven useful as shown in several
examples. In some cases, though, it is not easy to
obtain the meaning of a negated role.
Consider (Table 3, example 5) P&amp;G hasn’t sold
coffee��to�������� airlines. The proposed representation en-
codes P&amp;G has sold coffee, but not to airlines. How-
ever, it is not said that the buyers are likely to have
been other kinds of companies. Even without fully
identifying the buyer, we believe it is of utmost im-
portance to detect that P&amp;G has sold coffee. Empir-
ical data (Table 4) shows that over 65% of negations
in PropBank carry implicit positive meaning.
</bodyText>
<page confidence="0.997218">
588
</page>
<sectionHeader confidence="0.989726" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999704432989691">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of the 17th international conference on Computa-
tional Linguistics, Montreal, Canada.
Johan Bos and Katja Markert. 2005. Recognising Tex-
tual Entailment with Logical Inference. In Proceed-
ings ofHuman Language Technology Conference and
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 628–635, Vancouver, British
Columbia, Canada.
Jinho D. Choi, Claire Bonial, and Martha Palmer. 2010.
Propbank Instance Annotation Guidelines Using a
Dedicated Editor, Jubilee. In Proceedings of the Sev-
enth conference on International Language Resources
and Evaluation (LREC’10), Valletta, Malta.
Isaac Councill, Ryan McDonald, and Leonid Velikovich.
2010. What’s great and what’s not: learning to clas-
sify the scope of negation for improved sentiment anal-
ysis. In Proceedings of the Workshop on Negation and
Speculation in Natural Language Processing, pages
51–59, Uppsala, Sweden.
David Dowty. 1994. The Role of Negative Polarity
and Concord Marking in Natural Language Reason-
ing. In Proceedings of Semantics and Linguistics The-
ory (SALT) 4, pages 114–144.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their
Scope in Natural Language Text. In Proceedings of
the Fourteenth Conference on Computational Natural
Language Learning, pages 1–12, Uppsala, Sweden.
Jaakko Hintikka. 2002. Negation in Logic and in Natural
Language. Linguistics and Philosophy, 25(5/6).
Laurence R. Horn and Yasuhiko Kato, editors. 2000.
Negation and Polarity - Syntactic and Semantic Per-
spectives (Oxford Linguistics). Oxford University
Press, USA.
Laurence R. Horn. 1989. A Natural History ofNegation.
University Of Chicago Press.
Rodney D. Huddleston and Geoffrey K. Pullum. 2002.
The Cambridge Grammar of the English Language.
Cambridge University Press.
Roser Morante and Walter Daelemans. 2009. Learning
the Scope of Hedge Cues in Biomedical Texts. In Pro-
ceedings of the BioNLP 2009 Workshop, pages 28–36,
Boulder, Colorado.
Roser Morante and Caroline Sporleder, editors. 2010.
Proceedings of the Workshop on Negation and Specu-
lation in Natural Language Processing. University of
Antwerp, Uppsala, Sweden.
Arzucan
¨Ozg¨ur
ing Speculations and their Scopes in Scientific Text.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1398–1407, Singapore.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71–106.
Mats Rooth. 1985. Association with Focus. Ph.D. thesis,
Univeristy of Massachusetts, Amherst.
Mats Rooth. 1992. A Theory of Focus Interpretation.
Natural Language Semantics, 1:75–116.
Carolyn P. Rose, Antonio Roque, Dumisizwe Bhembe,
and Kurt Vanlehn. 2003. A Hybrid Text Classification
Approach for Analysis of Student Essays. In In Build-
ing EducationalApplications Using Natural Language
Processing, pages 68–75.
Victor S´anchez Valencia. 1991. Studies on Natural Logic
and Categorial Grammar. Ph.D. thesis, University of
Amsterdam.
Roser Sauriand James Pustejovsky. 2009. FactBank:
a corpus annotated with event factuality. Language
Resources and Evaluation, 43(3):227–268.
Elly van Munster. 1988. The treatment of Scope and
Negation in Rosetta. In Proceedings of the 12th In-
ternational Conference on Computational Linguistics,
Budapest, Hungary.
Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-
orgy Mora, and Janos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9(Suppl 11):S9+.
Michael Wiegand, Alexandra Balahur, Benjamin Roth,
Dietrich Klakow, and Andr´es Montoyo. 2010. A sur-
vey on the role of negation in sentiment analysis. In
Proceedings of the Workshop on Negation and Specu-
lation in Natural Language Processing, pages 60–68,
Uppsala, Sweden, July.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing Contextual Polarity: An Explo-
ration of Features for Phrase-Level Sentiment Analy-
sis. Computational Linguistics, 35(3):399–433.
H. Zeijlstra. 2007. Negation in Natural Language: On
the Form and Meaning of Negative Elements. Lan-
guage and Linguistics Compass, 1(5):498–518.
</reference>
<footnote confidence="0.812582">
R.
and Dragomir
</footnote>
<note confidence="0.57355">
Radev. 2009. Detect-
</note>
<page confidence="0.996874">
589
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.706404">
<title confidence="0.998294">Semantic Representation of Negation Using Focus Detection</title>
<author confidence="0.815646">Blanco</author>
<affiliation confidence="0.935772">Human Language Technology Research The University of Texas at</affiliation>
<address confidence="0.958538">Richardson, TX 75080 USA</address>
<abstract confidence="0.999546692307692">Negation is present in all human languages and it is used to reverse the polarity of part of statements that are otherwise affirmative by default. A negated statement often carries positive implicit meaning, but to pinpoint the positive part from the negative part is rather difficult. This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning. The proposed representation relies on focus of negation detection. For this, new annotation over PropBank and a learning algorithm are proposed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational Linguistics,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="6228" citStr="Baker et al., 1998" startWordPosition="995" endWordPosition="998">ments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the scope or focus. FrameNet (Baker et al., 1998) does not consider negation and FactBank (Sauriand Pustejovsky, 2009) only annotates degrees of factuality for events. None of the above references aim at detecting or annotating the focus of negation in natural language. Neither do they aim at carefully representing the meaning of negated statements nor extracting implicit positive meaning from them. 3 Negation in Natural Language Simply put, negation is a process that turns a statement into its opposite. Unlike affirmative statements, negation is marked by words (e.g., not, no, never) or affixes (e.g., -n’t, un-). Negation can interact with </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 17th international conference on Computational Linguistics, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising Textual Entailment with Logical Inference.</title>
<date>2005</date>
<booktitle>In Proceedings ofHuman Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>628--635</pages>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="5638" citStr="Bos and Markert, 2005" startWordPosition="895" endWordPosition="898">9; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the scope or focus. FrameNet (Baker et al., 1998) does not </context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising Textual Entailment with Logical Inference. In Proceedings ofHuman Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 628–635, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
<author>Claire Bonial</author>
<author>Martha Palmer</author>
</authors>
<title>Propbank Instance Annotation Guidelines Using a Dedicated Editor, Jubilee.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="23398" citStr="Choi et al., 2010" startWordPosition="3933" endWordPosition="3936">emoved by mapping all role labels to ARG. This step is necessary to ensure that focus selection is not biased by the semanRole #Inst. Focus # – % A1 2,930 1,194 – 40.75 MNEG 3,196 1,109 – 34.70 MTMP 609 246 – 40.39 MMNR 250 190 – 76.00 A2 501 179 – 35.73 MADV 466 94 – 20.17 A0 2,163 73 – 3.37 MLOC 114 22 – 19.30 MEXT 25 22 – 88.00 A4 26 22 – 84.62 A3 48 18 – 37.50 MDIR 35 13 – 37.14 MPNC 87 9 – 10.34 MDIS 287 6 – 2.09 Table 4: Roles, total instantiations and counts corresponding to focus over training and held-out instances. tic labels provided by PropBank. As annotation tool, we use Jubilee (Choi et al., 2010). For each instance, annotators decide the focus given the full syntactic tree, as well as the previous and next sentence. A post-processing step incorporates focus annotation to the original PropBank by adding -NOT to the corresponding role. In a first round, 50% of instances were annotated twice. Inter-annotator agreement was 0.72. After careful examination of the disagreements, they were resolved and annotators were given clearer instructions. The main point of conflict was selecting a focus that yields valid implicit meaning, but not the most valuable (Section 4.2.1). Due to space constrai</context>
</contexts>
<marker>Choi, Bonial, Palmer, 2010</marker>
<rawString>Jinho D. Choi, Claire Bonial, and Martha Palmer. 2010. Propbank Instance Annotation Guidelines Using a Dedicated Editor, Jubilee. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac Councill</author>
<author>Ryan McDonald</author>
<author>Leonid Velikovich</author>
</authors>
<title>What’s great and what’s not: learning to classify the scope of negation for improved sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>51--59</pages>
<location>Uppsala,</location>
<contexts>
<context position="5382" citStr="Councill et al. (2010)" startWordPosition="859" endWordPosition="862">ooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning t</context>
</contexts>
<marker>Councill, McDonald, Velikovich, 2010</marker>
<rawString>Isaac Councill, Ryan McDonald, and Leonid Velikovich. 2010. What’s great and what’s not: learning to classify the scope of negation for improved sentiment analysis. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 51–59, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>The Role of Negative Polarity and Concord Marking in Natural Language Reasoning.</title>
<date>1994</date>
<booktitle>In Proceedings of Semantics and Linguistics Theory (SALT)</booktitle>
<volume>4</volume>
<pages>114--144</pages>
<contexts>
<context position="4544" citStr="Dowty, 1994" startWordPosition="735" endWordPosition="736">ut a statement and not to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporlede</context>
</contexts>
<marker>Dowty, 1994</marker>
<rawString>David Dowty. 1994. The Role of Negative Polarity and Concord Marking in Natural Language Reasoning. In Proceedings of Semantics and Linguistics Theory (SALT) 4, pages 114–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>1--12</pages>
<location>Uppsala,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1–12, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaakko Hintikka</author>
</authors>
<date>2002</date>
<booktitle>Negation in Logic and in Natural Language. Linguistics and Philosophy,</booktitle>
<pages>25--5</pages>
<contexts>
<context position="4505" citStr="Hintikka, 2002" startWordPosition="729" endWordPosition="730"> Contrasts may use negation to disagree about a statement and not to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculatio</context>
</contexts>
<marker>Hintikka, 2002</marker>
<rawString>Jaakko Hintikka. 2002. Negation in Logic and in Natural Language. Linguistics and Philosophy, 25(5/6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence R Horn</author>
<author>Yasuhiko Kato</author>
<author>editors</author>
</authors>
<date>2000</date>
<booktitle>Negation and Polarity - Syntactic and Semantic Perspectives (Oxford Linguistics).</booktitle>
<publisher>Oxford University Press, USA.</publisher>
<marker>Horn, Kato, editors, 2000</marker>
<rawString>Laurence R. Horn and Yasuhiko Kato, editors. 2000. Negation and Polarity - Syntactic and Semantic Perspectives (Oxford Linguistics). Oxford University Press, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence R Horn</author>
</authors>
<title>A Natural History ofNegation.</title>
<date>1989</date>
<publisher>University Of Chicago Press.</publisher>
<contexts>
<context position="1819" citStr="Horn, 1989" startWordPosition="280" endWordPosition="281">asoning are a few of the difficulties to overcome. Substantial progress has been made, though, especially on detection of semantic relations, ontologies and reasoning methods. Negation is present in all languages and it is always the case that statements are affirmative by default. Negation is marked and it typically signals something unusual or an exception. It may be present in all units of language, e.g., words (incredible), clauses (He doesn’t have friends). Negation and its correlates (truth values, lying, irony, false or contradictory statements) are exclusive characteristics of humans (Horn, 1989; Horn and Kato, 2000). Negation is fairly well-understood in grammars; the valid ways to express a negation are documented. However, there has not been extensive research on detecting it, and more importantly, on representing the semantics of negation. Negation has been largely ignored within the area of semantic relations. At first glance, one would think that interpreting negation could be reduced to finding negative keywords, detect their scope using syntactic analysis and reverse its polarity. Actually, it is more complex. Negation plays a remarkable role in text understanding and it pose</context>
<context position="4271" citStr="Horn (1989)" startWordPosition="694" endWordPosition="695">tement (i.e., tables eat something other than meat). Negation can express less than or in between when used in a scalar context. For example, John does not have three children probably means that he has either one or two children. Contrasts may use negation to disagree about a statement and not to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (20</context>
</contexts>
<marker>Horn, 1989</marker>
<rawString>Laurence R. Horn. 1989. A Natural History ofNegation. University Of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodney D Huddleston</author>
<author>Geoffrey K Pullum</author>
</authors>
<title>The Cambridge Grammar of the English Language.</title>
<date>2002</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4409" citStr="Huddleston and Pullum (2002)" startWordPosition="712" endWordPosition="715">ontext. For example, John does not have three children probably means that he has either one or two children. Contrasts may use negation to disagree about a statement and not to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et a</context>
<context position="7069" citStr="Huddleston and Pullum, 2002" startWordPosition="1125" endWordPosition="1128">anguage. Neither do they aim at carefully representing the meaning of negated statements nor extracting implicit positive meaning from them. 3 Negation in Natural Language Simply put, negation is a process that turns a statement into its opposite. Unlike affirmative statements, negation is marked by words (e.g., not, no, never) or affixes (e.g., -n’t, un-). Negation can interact with other words in special ways. For example, negated clauses use different connective adjuncts that positive clauses do: neither, nor instead of either, or. The so-called negatively-oriented polaritysensitive items (Huddleston and Pullum, 2002) include, among many others, words starting with any(anybody, anyone, anywhere, etc.), the modal auxiliaries dare and need and the grammatical units at all, much and till. Negation in verbs usually requires an auxiliary; if none is present, the auxiliary do is inserted (I read the paper vs. I didn’t read the paper). 3.1 Meaning of Negated Statements State-of-the-art semantic role labelers (e.g., the ones trained over PropBank) do not completely represent the meaning of negated statements. Given John didn’t build a house to impress Mary, they encode AGENT(John, build), THEME(a house, build), PU</context>
<context position="10275" citStr="Huddleston and Pullum (2002)" startWordPosition="1654" endWordPosition="1657">h their interpretations do not contain a verbal negation, the meaning remains negative. Some examples could be interpreted differently depending on the context (Section 4.2.1). This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning. The main contributions are: (1) interpretation of negation using focus detection; (2) focus of negation annotation over all PropBank negated sentences1; (3) feature set to detect the focus of negation; and (4) model to semantically represent negation and reveal its underlying positive meaning. 3.2 Negation Types Huddleston and Pullum (2002) distinguish four contrasts for negation: • Verbal if the marker of negation is grammatically associated with the verb (I did not see anything at all); non-verbal if it is associated with a dependent of the verb (I saw nothing at all). • Analytic if the sole function of the negated mark is to mark negation (Bill did not go); synthetic if it has some other function as well ([Nobody]AGENT went to the meeting). 1Annotation will be available on the author’s website • Clausal if the negation yields a negative clause (She didn’t have a large income); subclausal otherwise (She had a not inconsiderabl</context>
<context position="11641" citStr="Huddleston and Pullum, 2002" startWordPosition="1899" endWordPosition="1902">; metalinguistic if it does not dispute the truth but rather reformulates a statement, e.g., (2) She didn’t have lunch with your ‘old man’: she had lunch with your father. Note that in (1) the lunch never took place, whereas in (2) a lunch did take place. In this paper, we focus on verbal, analytic, clausal, and both metalinguistic and ordinary negation. 3.3 Scope and Focus Negation has both scope and focus and they are extremely important to capture its semantics. Scope is the part of the meaning that is negated. Focus is that part of the scope that is most prominently or explicitly negated (Huddleston and Pullum, 2002). Both concepts are tightly connected. Scope corresponds to all elements any of whose individual falsity would make the negated statement true. Focus is the element of the scope that is intended to be interpreted as false to make the overall negative true. Consider (1) Cows don’t eat meat and its positive counterpart (2) Cows eat meat. The truth conditions of (2) are: (a) somebody eats something; (b) cows are the ones who eat; and (c) meat is what is eaten. In order for (2) to be true, (a–c) have to be true. And the falsity of any of them is sufficient to make (1) true. In other words, (1) wou</context>
<context position="13359" citStr="Huddleston and Pullum, 2002" startWordPosition="2187" endWordPosition="2191">k, ate) 5 AGENT(the cow, ate) THEME(grass, ate) NOT[INSTRUMENT(with a fork, ate)] Table 2: Possible semantic representations for The cow didn’t eat grass with a fork. without knowing stress or intonation. Text understanding is needed and context plays an important role. The most probable focus for (1) is meat, which corresponds to the interpretation cows eat something else than meat. Another possible focus is cows, which yields someone eats meat, but not cows. Both scope and focus are primarily semantic, highly ambiguous and context-dependent. More examples can be found in Tables 1 and 3 and (Huddleston and Pullum, 2002, Chap. 9). 4 Approach to Semantic Representation of Negation Negation does not stand on its own. To be useful, it should be added as part of another existing knowledge representation. In this Section, we outline how to incorporate negation into semantic relations. 4.1 Semantic Relations Semantic relations capture connections between concepts and label them according to their nature. It is out of the scope of this paper to define them in depth, establish a set to consider or discuss their detection. Instead, we use generic semantic roles. Given s: The cow didn’t eat grass with a fork, typical </context>
</contexts>
<marker>Huddleston, Pullum, 2002</marker>
<rawString>Rodney D. Huddleston and Geoffrey K. Pullum. 2002. The Cambridge Grammar of the English Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the Scope of Hedge Cues in Biomedical Texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>28--36</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="5279" citStr="Morante and Daelemans (2009)" startWordPosition="843" endWordPosition="846">ve concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) i</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the Scope of Hedge Cues in Biomedical Texts. In Proceedings of the BioNLP 2009 Workshop, pages 28–36, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Caroline Sporleder</author>
<author>editors</author>
</authors>
<date>2010</date>
<booktitle>Proceedings of the Workshop on Negation and Speculation in Natural Language Processing. University of Antwerp, Uppsala, Sweden. ing Speculations and their Scopes in Scientific Text. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1398--1407</pages>
<marker>Morante, Sporleder, editors, 2010</marker>
<rawString>Roser Morante and Caroline Sporleder, editors. 2010. Proceedings of the Workshop on Negation and Speculation in Natural Language Processing. University of Antwerp, Uppsala, Sweden. ing Speculations and their Scopes in Scientific Text. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1398–1407, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="6077" citStr="Palmer et al., 2005" startWordPosition="968" endWordPosition="971">pplications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the scope or focus. FrameNet (Baker et al., 1998) does not consider negation and FactBank (Sauriand Pustejovsky, 2009) only annotates degrees of factuality for events. None of the above references aim at detecting or annotating the focus of negation in natural language. Neither do they aim at carefully representing the meaning of negated statements nor extracting implicit positive meaning from them. 3 Negation in Natural Language Simply put, negation is a process that turns a statement into it</context>
<context position="22221" citStr="Palmer et al., 2005" startWordPosition="3715" endWordPosition="3718"> the focus). For each example, we provide PropBank annotation (top), the new annotation (i.e., the focus, bottom right) and its interpretation (bottom left). 4.2.2 Interpretation of -NOT The mark -NOT is interpreted as follows: • If MNEG-NOT(x, y), then verb y must be negated; the statement does not carry positive meaning. • If any other role is marked with -NOT, ROLENOT(x, y) must be interpreted as it is not the case that x is ROLE of y. Unmarked roles are interpreted positive; they correspond to implicit positive meaning. Role labels (A0, MTMP, etc.) maintain the same meaning from PropBank (Palmer et al., 2005). MNEG can be ignored since it is overwritten by -NOT. The new annotation for the example (Figure 1) must be interpreted as: While profitable, it (the company) was not growing and was providing a not satisfactory return on investment. Paraphrasing, While profitable, it was shrinking or idle and was providing an unsatisfactory return on investment. We discover an entailment and an implicature respectively. 4.3 Annotation Process We annotated the 3,993 verbal negations signaled with MNEG in PropBank. Before annotation began, all semantic information was removed by mapping all role labels to ARG.</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
</authors>
<title>Association with Focus.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<pages>1--75</pages>
<institution>Univeristy of Massachusetts,</institution>
<location>Amherst. Mats Rooth.</location>
<contexts>
<context position="4676" citStr="Rooth (1985)" startWordPosition="753" endWordPosition="754"> Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (20</context>
</contexts>
<marker>Rooth, 1985</marker>
<rawString>Mats Rooth. 1985. Association with Focus. Ph.D. thesis, Univeristy of Massachusetts, Amherst. Mats Rooth. 1992. A Theory of Focus Interpretation. Natural Language Semantics, 1:75–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn P Rose</author>
<author>Antonio Roque</author>
<author>Dumisizwe Bhembe</author>
<author>Kurt Vanlehn</author>
</authors>
<title>A Hybrid Text Classification Approach for Analysis of Student Essays. In</title>
<date>2003</date>
<booktitle>In Building EducationalApplications Using Natural Language Processing,</booktitle>
<pages>68--75</pages>
<contexts>
<context position="5586" citStr="Rose et al., 2003" startWordPosition="888" endWordPosition="891">mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the sco</context>
</contexts>
<marker>Rose, Roque, Bhembe, Vanlehn, 2003</marker>
<rawString>Carolyn P. Rose, Antonio Roque, Dumisizwe Bhembe, and Kurt Vanlehn. 2003. A Hybrid Text Classification Approach for Analysis of Student Essays. In In Building EducationalApplications Using Natural Language Processing, pages 68–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor S´anchez Valencia</author>
</authors>
<date>1991</date>
<booktitle>Studies on Natural Logic and Categorial Grammar. Ph.D. thesis,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="4570" citStr="Valencia, 1991" startWordPosition="738" endWordPosition="739"> to negate it, e.g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-201</context>
</contexts>
<marker>Valencia, 1991</marker>
<rawString>Victor S´anchez Valencia. 1991. Studies on Natural Logic and Categorial Grammar. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Sauriand James Pustejovsky</author>
</authors>
<title>FactBank: a corpus annotated with event factuality.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>3</issue>
<contexts>
<context position="6297" citStr="Pustejovsky, 2009" startWordPosition="1007" endWordPosition="1008">annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the scope or focus. FrameNet (Baker et al., 1998) does not consider negation and FactBank (Sauriand Pustejovsky, 2009) only annotates degrees of factuality for events. None of the above references aim at detecting or annotating the focus of negation in natural language. Neither do they aim at carefully representing the meaning of negated statements nor extracting implicit positive meaning from them. 3 Negation in Natural Language Simply put, negation is a process that turns a statement into its opposite. Unlike affirmative statements, negation is marked by words (e.g., not, no, never) or affixes (e.g., -n’t, un-). Negation can interact with other words in special ways. For example, negated clauses use differe</context>
</contexts>
<marker>Pustejovsky, 2009</marker>
<rawString>Roser Sauriand James Pustejovsky. 2009. FactBank: a corpus annotated with event factuality. Language Resources and Evaluation, 43(3):227–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elly van Munster</author>
</authors>
<title>The treatment of Scope and Negation in Rosetta.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<location>Budapest, Hungary.</location>
<marker>van Munster, 1988</marker>
<rawString>Elly van Munster. 1988. The treatment of Scope and Negation in Rosetta. In Proceedings of the 12th International Conference on Computational Linguistics, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gyorgy Szarvas</author>
<author>Richard Farkas</author>
<author>Gyorgy Mora</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<contexts>
<context position="5938" citStr="Vincze et al., 2008" startWordPosition="944" endWordPosition="947">cope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). Regarding corpora, the BioScope corpus annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely ignores negations such as (talking about the reaction of certain elements) in NK3.3 cells is not always identical (Vincze et al., 2008), which carry the kind of positive meaning this work aims at extracting (in NK3.3 cells is often identical). PropBank (Palmer et al., 2005) only indicates the verb to which a negation mark attaches; it does not provide any information about the scope or focus. FrameNet (Baker et al., 1998) does not consider negation and FactBank (Sauriand Pustejovsky, 2009) only annotates degrees of factuality for events. None of the above references aim at detecting or annotating the focus of negation in natural language. Neither do they aim at carefully representing the meaning of negated statements nor extr</context>
</contexts>
<marker>Vincze, Szarvas, Farkas, Mora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gyorgy Mora, and Janos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9+.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wiegand</author>
<author>Alexandra Balahur</author>
<author>Benjamin Roth</author>
<author>Dietrich Klakow</author>
<author>Andr´es Montoyo</author>
</authors>
<title>A survey on the role of negation in sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>60--68</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="5040" citStr="Wiegand et al., 2010" startWordPosition="808" endWordPosition="811">over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (Bos and Markert, 2005). </context>
</contexts>
<marker>Wiegand, Balahur, Roth, Klakow, Montoyo, 2010</marker>
<rawString>Michael Wiegand, Alexandra Balahur, Benjamin Roth, Dietrich Klakow, and Andr´es Montoyo. 2010. A survey on the role of negation in sentiment analysis. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 60–68, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="5017" citStr="Wilson et al., 2009" startWordPosition="804" endWordPosition="807">llum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Farkas et al., 2010) targeted negation mostly on those subfields. Morante and Daelemans (2009) and ¨Ozg¨ur and Radev (2009) propose scope detectors using the BioScope corpus. Councill et al. (2010) present a supervised scope detector using their own annotation. Some NLP applications deal indirectly with negation, e.g., machine translation (van Munster, 1988), text classification (Rose et al., 2003) and recognizing entailments (B</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2009. Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis. Computational Linguistics, 35(3):399–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zeijlstra</author>
</authors>
<title>Negation in Natural Language: On the Form and Meaning of Negative Elements.</title>
<date>2007</date>
<journal>Language and Linguistics Compass,</journal>
<volume>1</volume>
<issue>5</issue>
<contexts>
<context position="4588" citStr="Zeijlstra (2007)" startWordPosition="740" endWordPosition="741">g., That place is not big, it is massive defines the place as massive, and therefore, big. 2 Related Work Negation has been widely studied outside of computational linguistics. In logic, negation is usually the simplest unary operator and it reverses the truth value. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Linguists have found negation a complex phenomenon; Huddleston and Pullum (2002) dedicate over 60 pages to it. Negation interacts with quantifiers and anaphora (Hintikka, 2002), and influences reasoning (Dowty, 1994; S´anchez Valencia, 1991). Zeijlstra (2007) analyzes the position and form of negative elements and negative concords. Rooth (1985) presented a theory of focus in his dissertation and posterior publications (e.g., Rooth (1992)). In this paper, we follow the insights on scope and focus of negation by Huddleston and Pullum (2002) rather than Rooth’s (1985). Within natural language processing, negation has drawn attention mainly in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, the Negation and Speculation in NLP Workshop (Morante and Sporleder, 2010) and the CoNLL-2010 Shared Task (Far</context>
</contexts>
<marker>Zeijlstra, 2007</marker>
<rawString>H. Zeijlstra. 2007. Negation in Natural Language: On the Form and Meaning of Negative Elements. Language and Linguistics Compass, 1(5):498–518.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>