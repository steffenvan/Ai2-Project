<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000265">
<title confidence="0.9593005">
Briefly Noted
Information Extraction: A Multi-
disciplinary Approach to an Emerging
Information Technology
</title>
<author confidence="0.693941">
Maria Teresa Pazienza (editor)
</author>
<affiliation confidence="0.887016">
(University of Rome, Tor Vergata)
</affiliation>
<address confidence="0.569797">
Berlin: Springer-Verlag (Lecture notes in
</address>
<bodyText confidence="0.981526657142857">
computer science, volume 1299), 1997,
ix+213 pp; paperbound, ISBN
3-540-63438-X, $43.00
This book is a diverse collection of ten pre-
sentations given at an International Summer
School on Information Extraction in Rome,
1997. The goal of information extraction (IE)
is selective, task-driven interpretation of text
narrative in order to fill out templates with
information about a particular scenario. I was
disappointed to find that only five of the ar-
ticles were actually about IE research. The
other half of the articles addressed issues pe-
ripheral to IE, such as information retrieval
(IR) and text classification.
The first two articles are by Yorick Wilks
and by Ralph Grishman, who are prominent
IE researchers in the UK and the US, respec-
tively. Each gives a high-level discussion of
IE, its successes and limitations. Wilks makes
the observation that IE&apos;s strength comes from
its modular architecture. Individual modules
such as part-of-speech tagging or morphol-
ogy analysis can be constructed and opti-
mized independently and reused in a variety
of applications. He sees the primary limita-
tion of IE to be the template representation
that restricts the type of information that can
be extracted.
Grishman describes the typical archi-
tecture of IE systems whose modules in-
clude lexical analysis, name recognition,
shallow syntactic parsing, task-specific pat-
tern matching, coreference analysis, event
merging, and finally template generation. He
identifies the main challenges to IE as the
cost of adapting a system to a new domain or
scenario and a ceiling on performance, which
is closely related to the issue of knowledge
acquisition and difficulty handling complex
syntactic structures.
Three other articles deal with more spe-
cialized topics within IE. Robert Gaizauskas,
Kevin Humphreys, Saliha Azzam, and Yorick
Wilks describe a system for multilingual
IE with some language-independent mod-
ules that are indexed by language-specific
lexicons. Roberto Basili and Maria Teresa
Pazienza discuss corpus-driven lexical ac-
quisition, in particular for the &amp;quot;foreground&amp;quot;
lexicon of words that support a particu-
lar IE task. Branimir Boguraev and Christo-
pher Kennedy present work in technical-
term recognition and how this can be a step
towards document summarization.
The remaining articles concern IR, text
classification, or heterogeneous database
techniques, and are only tangentially related
to IE. Gregory Grefenstette presents an NLP-
based strategy for suggesting additional IR
query terms to a user. Alan Smeaton gives a
tutorial on uses of NLP in IR. Nicola Guar-
ino discusses formal ontologies and how
these can enhance IR with semantic match-
ing. Filippo Neri and Lorenza Saitta give
a tutorial on machine learning that briefly
touches on text classification. Sophie Cluet
describes database techniques for querying
semi-structured Web pages.—Stephen Soder-
land, Children&apos;s Hospital, Seattle
</bodyText>
<subsectionHeader confidence="0.9145345">
Observing Interaction: An Introduction
to Sequential Analysis (second edition)
</subsectionHeader>
<bodyText confidence="0.978397666666667">
Roger Bakeman and John M. Gottman
(Georgia State University and University of
Washington)
Cambridge, England: Cambridge University
Press, 1997, 207 pp; hardbound, ISBN
0-521-45008-X, £50.00, $69.95; paperbound,
ISBN 0-521-57427-7, £17.95, $24.95
The current trend for &amp;quot;empirical methods&amp;quot;
in computational linguistics (see, for exam-
ple, the special issue of Computational Lin-
guistics, 23(1), March 1997) has led many re-
searchers to mark up dialogue and text cor-
pora subjectively for linguistic phenomena
such as discourse structure and coreference.
This has led to some methodological confu-
sion, especially since as a field computational
linguistics has not used these techniques be-
fore. However, the idea of &amp;quot;coding&amp;quot; is not
new; within psychology there is a long tra-
dition of systematically observing behavior
so that statistical analysis can be performed.
Even something akin to dialogue-move clas-
sification for group discussion was devel-
oped in the 1950s (Bales 1950) and has been
used in various guises ever since. Bakeman
and Gottman&apos;s Observing Interaction: An In-
troduction to Sequential Analysis, recently out
</bodyText>
<page confidence="0.990677">
659
</page>
<note confidence="0.423582">
Computational Linguistics Volume 24, Number 4
</note>
<bodyText confidence="0.999694717948718">
in a second edition, is an excellent manual
for observational analysis techniques. It con-
tains advice about developing coding sys-
tems, testing agreement among coders, and
analyzing the results. Although many differ-
ent kinds of behaviors are included (notably
the state of children&apos;s play and sounds made
by baby chicks before they hatch), many of
the examples are based on Gottman&apos;s work
on marital conversations, and so relate fairly
closely to research in this community
This manual is not a perfect fit for com-
putational linguists because in psychology
coding is designed to answer a specific re-
search question and so it is fairly simple.
The authors remind the reader that cod-
ing schemes should be tailored for the re-
search question under study and not bor-
rowed. This makes for much better hypoth-
esis testing—and we would do well to re-
member that—but it will grate with people
developing coding schemes in order to train
language engines, since there the consider-
ations are rather different. Psychologists do
not often use more than one or two flat-
structured behavioral codings at a time, so
there is not much advice about relating dif-
ferent codes or comparing the distribution
of codes in data collected under two differ-
ent conditions. To save effort, coding of lin-
guistic behavior is often performed directly
from videotape rather than resorting to tran-
scripts, and so there are fewer representa-
tional issues involved. Often results are ex-
pressed simply in terms of differences in
code counts, although the point of this book
and the companion volume describing soft-
ware tools (Bakeman and Quera 1992) is to
convince observational analysts that it&apos;s pos-
sible to perform much more sophisticated
analyses that describe patterns in how behav-
iors are sequenced. The book also assumes
knowledge of very basic inferential statis-
tics but describes transitional probabilities at
great length, which is exactly the wrong way
round for most of us.
Despite these difficulties, I highly rec-
ommend this book to all researchers setting
out on coding exercises. The coding advice
given is always insightful, often lively, and
addresses many of the concerns that em-
pirical researchers are discussing behind the
scenes. Even if there were a manual tailored
for our community I still think there would
be merit in reading this one. Coding-based
research is much more mature in psychol-
ogy than in computational linguistics, and al-
though for practical reasons we may not wish
to emulate the studies described, just think-
ing about the issues involved is likely to im-
prove our work. In addition, the methods for
sequential analysis, plus a distinction Bake-
man and Gottman make between microcod-
ing and macrocoding, which codes for se-
quences of events, are potentially quite use-
ful for informing systems that need good pre-
dictions of behavior, like dialogue engines.
One word of warning, though: although the
coding advice has not changed very much
between the editions, in the chapters about
analysis the second edition corrects a basic
statistical mistake and adds a whole new and
much better technique based on log-linear
modeling. Glance through the library&apos;s first
edition if you will, but if you want to use
the analytical methods, you will have to or-
der the new one.—Jean Carletta, University of
Edinburgh
</bodyText>
<sectionHeader confidence="0.971639" genericHeader="abstract">
References
</sectionHeader>
<bodyText confidence="0.685616875">
Bakeman, Roger, and Vincenc Quera. 1992.
Analyzing Interaction: Sequential Analysis
with SDIS and GSEQ. Cambridge
University Press.
Bales, Robert Freed. 1950. Interaction Process
Analysis: A Method for the Study of Small
Groups. Addison-Wesley Press, Cambridge,
MA.
</bodyText>
<sectionHeader confidence="0.6969425" genericHeader="categories and subject descriptors">
Representation and Processing of Spa-
tial Expressions
</sectionHeader>
<bodyText confidence="0.9918509375">
Patrick Olivier and Klaus-Peter Gapp
(editors)
(University of Wales, Aberystwyth and
Universitat des Saarlandes)
Mahwah, NJ: Lawrence Erlbaum Associates,
1998, viiii-287 pp; hardbound, ISBN
0-8058-2285-2, $79.95 (special prepaid price,
$49.95)
This book presents 16 new papers on the lin-
guistic expression of spatial relations. This
general topic has attracted a good deal of at-
tention recently. It raises fundamental ques-
tions about the linking of word to world, and
can be profitably approached from the per-
spectives of several disciplines. The chapters
of this book reflect the multidisciplinary na-
</bodyText>
<page confidence="0.992571">
660
</page>
<bodyText confidence="0.993375345238096">
Briefly Noted
ture of the subject matter, presenting both
computational and psycholinguistic studies
of this topic. In this review, I briefly discuss
a selection of the chapters, some from each
of these two disciplines.
The computational chapters provide an
overview of some of the challenges that arise
in the processing of spatial expressions, and
the techniques employed to address them.
A central issue addressed by these chapters
is that of appropriate knowledge represen-
tation. Fuhr, Socher, Scheering, and Sagerer
present a clear and reasonable-seeming ap-
proach in which the space surrounding a ref-
erence object is subdivided into fairly fine re-
gions, and the applicability of a spatial term
is a function of the region or regions into
which the located object falls. In an inter-
esting variation on this region-based theme,
Edwards and Moulin present a system that
uses Voronof diagrams to recognize and clas-
sify spatial relations among objects. In con-
trast to these region-based and essentially ge-
ometric approaches, Di Tomaso, Lombardo,
and Lesmo argue convincingly for the use of
semantic networks of detailed world knowl-
edge in the processing of some spatial ex-
pressions, and present a system based on
this principle. Blocher and Stopp address
a different problem, that of producing an
appropriate spatial utterance given limited
time to do so. They present an anytime-
algorithm for this purpose, which returns de-
scriptions of increasing accuracy given in-
creasing amounts of processing time. And
the chapter by Voss, Dorr, and Sencan dis-
cusses the problem of machine translation
of spatial expressions from English to Turk-
ish. These two languages differ as to when
a spatial verb particle obligatorily accom-
panies a verb. In Voss, Dorr, and Sencan&apos;s
interlingua-based system, this problem is ad-
dressed through semantic markings in the
lexicon.
The psycholinguistic chapters provide a
useful overview of some recent empirical
work bearing on the processing of spatial
language. In the most linguistically oriented
of these chapters, Herskovits argues that the
role of schematization in spatial language is
more subtle than has so far been appreci-
ated. Other chapters report on experimen-
tal work. Spivey-Knowlton, Tanenhaus, Eber-
hard, and Sedivy demonstrate compellingly
that visuospatial context can influence the
on-line processing of spatial language—and
thus, that syntactic processing is not informa-
tionally encapsulated. The chapter by Bryant
provides useful coverage of some recent ex-
perimental work on the relative psychologi-
cal salience of the different body axes in spa-
tial cognition and language. Schober&apos;s chap-
ter demonstrates that a speaker&apos;s spatial ut-
terances often give evidence of an under-
standing of the addressee&apos;s viewpoint, which
might or might not be the same as that of the
speaker. And Coventry&apos;s chapter presents ex-
perimental evidence implicating functional,
rather than purely geometric, knowledge in
spatial language.
While the book treats both computational
and psycholinguistic work, it does not in
general bring these two streams of inquiry
into very close contact with one another.
(An exception is Di Tomaso, Lombardo, and
Lesmo&apos;s and Coventry&apos;s shared emphasis on
detailed knowledge of object function, as
a critical element of spatial language.) The
reader will also find that the chapters are of
uneven quality. However, some are excellent,
and will be useful to those wishing to learn
about current research in spatial language.
—Terry Regier, University of Chicago
</bodyText>
<sectionHeader confidence="0.712085" genericHeader="method">
Computing Natural Language
</sectionHeader>
<reference confidence="0.466990590909091">
Atocha Aliseda, Rob van Glabbeek, and
Dag WesterstAhl (editors)
(Stanford University and University of Stock-
holm)
Stanford: CSLI Publications (CSLI lecture
notes, number 81) (distributed by
Cambridge University Press), 1998,
x+158 pp; hardbound, ISBN 1-57586-101-1,
$59.95; paperbound, ISBN 1-57586-100-3,
$22.95
The volume is an &amp;quot;outgrowth&amp;quot; of the Fourth
CSLI Workshop on Logic, Language, and
Computation (Stanford, 2-4 June 1995). The
contents of the volume are as follows:
&amp;quot;Indexicals, contexts and unarticulated con-
stituents&amp;quot; by John Perry.
&amp;quot;Formalizing context (Expanded notes)&amp;quot; by
John McCarthy and Saga Buvde.
&amp;quot;Changing contexts and shifting assertions&amp;quot;
by Johan van Benthem.
&amp;quot;Discourse preferences in dynamic logic&amp;quot; by
Jan Jaspars and Megumi Kameyama.
</reference>
<page confidence="0.958564">
661
</page>
<note confidence="0.352264">
Computational Linguistics Volume 24, Number 4
</note>
<reference confidence="0.988160333333333">
&amp;quot;Polarity predicates and monotonidty&amp;quot; by
Victor Sanchez Valencia.
&amp;quot;HPSG as type theory&amp;quot; by M. Andrew
Moshier.
&amp;quot;Machine learning of physics word prob-
lems: A preliminary report&amp;quot; by Patrick
Suppes, Michael Bottner, and Lin Liang.
Phonological Representations:
Their Names, Forms and Powers
John Coleman
(Oxford University)
Cambridge University Press (Cambridge
studies in linguistics, volume 85), 1998,
xvii+345 pp; hardbound, ISBN
0-521-47208-3, $74.95
</reference>
<bodyText confidence="0.99201575">
&amp;quot;Rewriting rules, derivations, and underly-
ing representations are enduring character-
istics of generative phonology. In this book,
John Coleman argues that they are unneces-
sary. The expressive resources of context-free
unification grammars are sufficient to char-
acterize phonological structures and alterna-
tions.
&amp;quot;According to this view, all phonolog-
ical forms and constraints are partial de-
scriptions of surface representations. This
framework, now called Declarative Phonol-
ogy, is based on a detailed examination
of the formalisms of feature theory syl-
lable theory, and the leading varieties of
non-linear phonology. Dr. Coleman illus-
trates this with two extensive analyses of the
phonological structure of words in English
and Japanese. As Declarative Phonology is
surface-based and highly restrictive, it is con-
sistent with findings in cognitive psychology
and amenable to straightforward computa-
tional implementation.&amp;quot;—From the publisher&apos;s
announcement
</bodyText>
<page confidence="0.994932">
662
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.078505">
<title confidence="0.941383">Briefly Noted Information Extraction: A Multidisciplinary Approach to an Emerging Information Technology</title>
<author confidence="0.90082">Maria Teresa Pazienza</author>
<affiliation confidence="0.899024">(University of Rome, Tor Vergata)</affiliation>
<abstract confidence="0.958324185714286">Berlin: Springer-Verlag (Lecture notes in computer science, volume 1299), 1997, ix+213 pp; paperbound, ISBN 3-540-63438-X, $43.00 This book is a diverse collection of ten presentations given at an International Summer School on Information Extraction in Rome, 1997. The goal of information extraction (IE) is selective, task-driven interpretation of text narrative in order to fill out templates with information about a particular scenario. I was disappointed to find that only five of the articles were actually about IE research. The other half of the articles addressed issues peripheral to IE, such as information retrieval (IR) and text classification. The first two articles are by Yorick Wilks and by Ralph Grishman, who are prominent IE researchers in the UK and the US, respectively. Each gives a high-level discussion of IE, its successes and limitations. Wilks makes the observation that IE&apos;s strength comes from its modular architecture. Individual modules such as part-of-speech tagging or morphology analysis can be constructed and optimized independently and reused in a variety of applications. He sees the primary limitation of IE to be the template representation that restricts the type of information that can be extracted. Grishman describes the typical architecture of IE systems whose modules include lexical analysis, name recognition, shallow syntactic parsing, task-specific pattern matching, coreference analysis, event merging, and finally template generation. He identifies the main challenges to IE as the cost of adapting a system to a new domain or scenario and a ceiling on performance, which is closely related to the issue of knowledge acquisition and difficulty handling complex syntactic structures. Three other articles deal with more specialized topics within IE. Robert Gaizauskas, Kevin Humphreys, Saliha Azzam, and Yorick Wilks describe a system for multilingual IE with some language-independent modules that are indexed by language-specific lexicons. Roberto Basili and Maria Teresa Pazienza discuss corpus-driven lexical acquisition, in particular for the &amp;quot;foreground&amp;quot; lexicon of words that support a particular IE task. Branimir Boguraev and Christopher Kennedy present work in technicalterm recognition and how this can be a step towards document summarization. The remaining articles concern IR, text classification, or heterogeneous database techniques, and are only tangentially related to IE. Gregory Grefenstette presents an NLPbased strategy for suggesting additional IR query terms to a user. Alan Smeaton gives a tutorial on uses of NLP in IR. Nicola Guarino discusses formal ontologies and how these can enhance IR with semantic matching. Filippo Neri and Lorenza Saitta give a tutorial on machine learning that briefly touches on text classification. Sophie Cluet describes database techniques for querying Web pages.—Stephen Soder-</abstract>
<address confidence="0.538451">land, Children&apos;s Hospital, Seattle</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<editor>Atocha Aliseda, Rob van Glabbeek, and Dag WesterstAhl (editors)</editor>
<institution>(Stanford University and University of Stockholm)</institution>
<marker></marker>
<rawString>Atocha Aliseda, Rob van Glabbeek, and Dag WesterstAhl (editors) (Stanford University and University of Stockholm)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanford CSLI</author>
</authors>
<title>Publications (CSLI lecture notes, number 81) (distributed by Cambridge</title>
<date>1998</date>
<journal>ISBN</journal>
<pages>1--57586</pages>
<publisher>University Press),</publisher>
<note>x+158 pp; hardbound, ISBN 1-57586-101-1, $59.95; paperbound,</note>
<marker>CSLI, 1998</marker>
<rawString>Stanford: CSLI Publications (CSLI lecture notes, number 81) (distributed by Cambridge University Press), 1998, x+158 pp; hardbound, ISBN 1-57586-101-1, $59.95; paperbound, ISBN 1-57586-100-3, $22.95</rawString>
</citation>
<citation valid="false">
<title>The volume is an &amp;quot;outgrowth&amp;quot; of the Fourth CSLI Workshop on Logic, Language, and Computation</title>
<date>1995</date>
<marker>1995</marker>
<rawString>The volume is an &amp;quot;outgrowth&amp;quot; of the Fourth CSLI Workshop on Logic, Language, and Computation (Stanford, 2-4 June 1995). The contents of the volume are as follows: &amp;quot;Indexicals, contexts and unarticulated constituents&amp;quot; by John Perry. &amp;quot;Formalizing context (Expanded notes)&amp;quot; by John McCarthy and Saga Buvde. &amp;quot;Changing contexts and shifting assertions&amp;quot; by Johan van Benthem. &amp;quot;Discourse preferences in dynamic logic&amp;quot; by Jan Jaspars and Megumi Kameyama.</rawString>
</citation>
<citation valid="false">
<title>Polarity predicates and monotonidty&amp;quot; by Victor Sanchez Valencia.</title>
<marker></marker>
<rawString>&amp;quot;Polarity predicates and monotonidty&amp;quot; by Victor Sanchez Valencia.</rawString>
</citation>
<citation valid="false">
<title>HPSG as type theory&amp;quot; by M. Andrew Moshier.</title>
<marker></marker>
<rawString>&amp;quot;HPSG as type theory&amp;quot; by M. Andrew Moshier.</rawString>
</citation>
<citation valid="false">
<title>Machine learning of physics word problems: A preliminary report&amp;quot; by Patrick Suppes, Michael Bottner, and Lin Liang. Phonological Representations: Their Names, Forms and Powers</title>
<marker></marker>
<rawString>&amp;quot;Machine learning of physics word problems: A preliminary report&amp;quot; by Patrick Suppes, Michael Bottner, and Lin Liang. Phonological Representations: Their Names, Forms and Powers</rawString>
</citation>
<citation valid="true">
<title>Press (Cambridge studies in linguistics,</title>
<date>1998</date>
<journal>ISBN</journal>
<volume>85</volume>
<pages>0--521</pages>
<institution>John Coleman (Oxford University) Cambridge University</institution>
<marker>1998</marker>
<rawString>John Coleman (Oxford University) Cambridge University Press (Cambridge studies in linguistics, volume 85), 1998, xvii+345 pp; hardbound, ISBN 0-521-47208-3, $74.95</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>