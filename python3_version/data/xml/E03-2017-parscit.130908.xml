<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017906">
<title confidence="0.925944">
Question Answering Using Web News as Knowledge Base
</title>
<author confidence="0.982869">
Zhiping Zheng
</author>
<affiliation confidence="0.948887">
Computational Linguistics Department
Saarland University
</affiliation>
<note confidence="0.791527">
D-66041 Saarbriicken, Germany
zheng@coli .uni—sb. de
</note>
<sectionHeader confidence="0.976205" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998612571428572">
AnswerBus News Engine&apos; is a question
answering system using the contents of
CNN Web site2 as its knowledge base.
Comparing to other question answering
systems including its previous versions, it
has a totally independent crawling and
indexing system and a fully functioning
search engine. Because of its dynamic
and continuous indexing, it is possible to
answer questions on just-happened facts.
Again, it reaches high correct answer
rate. In this demonstration we will present
the living system as well as its new
technical features.
</bodyText>
<keyword confidence="0.679695">
Keywords: question answering, QA specific
indexing, search engine
</keyword>
<sectionHeader confidence="0.99934" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998705">
AnswerBus3 ([2,3]) is originally designed as a
Web-based open-domain question answering
(QA) system. It successfully uses natural
language processing and information retrieval
techniques and reaches very high correct answer
rate. Although it is not designed for TREC, it still
correctly answers over 70% of TREC-8 questions
with Web resources. Because we use commercial
search engines as the search tools for the system,
we don&apos;t know if special indexing system and
other possible techniques will work better for the
QA tasks.
In the new experiment, we used the contents of
CNN Web site and developed a QA system
</bodyText>
<footnote confidence="0.991371666666667">
http://www.coli.uni-sb.de/—zheng/answerbus/news/
2 http://www.cnn.com/
http://www.answerbus.com/
</footnote>
<bodyText confidence="0.994521333333333">
called AnswerBus News Engine to automatically
answer news related questions. We chose CNN
Web site as the knowledge base because it has a
good archive of news stories since 1996 and the
CNN Web site seems having good reputation on
timely updating. The goal of this experiment is to
use most techniques used in AnswerBus QA
system together with some new techniques, such
as QA specific indexing described in [2,3] but
not fully implemented in original AnswerBus
system, and build a QA system to answer time
sensitive questions in the real world.
Before building the AnswerBus News Engine,
we did another experiment4 ([7]) using part of
DUC conference corpus as local archive. The
result was exciting. The experimental QA system
correctly answered 80% questions designed
specially for the local archive.
</bodyText>
<sectionHeader confidence="0.96105" genericHeader="method">
2 New Features
</sectionHeader>
<bodyText confidence="0.992956666666667">
AnswerBus News Engine has many new features
not used in other QA systems including its
previous versions.
</bodyText>
<subsectionHeader confidence="0.997885">
2.1 Sentence Level Indexing
</subsectionHeader>
<bodyText confidence="0.999604333333333">
QA systems usually use some search tools to
retrieve documents. These search tools include
some commercial search engines like Google,
Alta Vista. Some other systems tried local search
engines for local data, for example, local Web
contents or TREC corpus. We partially deployed
the techniques used in Seven Tones Search
Engine5 ([6,5]) for the search task, since it has a
high indexing speed and it is possible to timely
update the indexed database pa rt by part.
Comparing to other QA systems, AnswerBus
News Engine not only uses a specialized search
</bodyText>
<footnote confidence="0.998531">
4 http://www.coli.uni-sb.de/—zheng/answerbus/local/
5 http://www.seventones.com/
</footnote>
<page confidence="0.996523">
251
</page>
<bodyText confidence="0.9998406">
engine for QA task, but also crawls and indexes
CNN Web site automatically. Also, the special
index system is different from other search
engine index system in some aspects, for
example, sentence level indexing ([4]), temporal
indexing and partially updating.
As the results of the new techniques,
AnswerBus News Engine is now able to answer
some time sensitive questions about the some
factual issues just happened half an hour ago.
</bodyText>
<subsectionHeader confidence="0.991331">
2.2 Embedded Search Engine
</subsectionHeader>
<bodyText confidence="0.999988111111111">
It is normal that some times a QA system cannot
find any answer from the working knowledge
base for a question. This doesn&apos;t mean there is no
answer for the question. In this case, AnswerBus
redirects the question to the embedded search
engine so users will get a bunch of documents
instead of answers. Very likely, if there is an
answer to the question, the user can dig it out
from the documents given by the search engine.
</bodyText>
<subsectionHeader confidence="0.995325">
2.3 Scalability
</subsectionHeader>
<bodyText confidence="0.999989375">
The current size of indexed data has been over
700K Web pages from CNN Web site and some
of its sub sites. We believe that it has been the
largest size of knowledge base for QA tasks at
current time. And the designed size can be much
bigger than the size we have already reached.
This makes it possible for the future system to
index the whole Web and answer questions.
</bodyText>
<subsectionHeader confidence="0.993209">
2.4 Speed and System Load
</subsectionHeader>
<bodyText confidence="0.999884888888889">
Because of the local indexing, AnswerBus is now
able to find the possible answers for a user
question in 2-4 seconds. This makes the system
fast enough to process more documents to mine
the answers.
This also decreases the system load than its
previous systems and the system can answer
more questions at the same time than its previous
versions with same resource.
</bodyText>
<sectionHeader confidence="0.991495" genericHeader="method">
3 Web Interface
</sectionHeader>
<bodyText confidence="0.998124769230769">
The system has a Web interface as its previous
versions. As in Figure 1, the system lists up to ten
possible answers to a specific user question. Each
of these answers has a dynamic link back to a
specific CNN Web page containing the answer
sentence. The navigation bar at the end provides
an easy way to try user question with other online
systems.
Figure 2 is a screen shot when the system
could not find the proper answer and the
redirected the user question to embedded search
engine. This page only shows 20 items returned
by the search engine.
</bodyText>
<sectionHeader confidence="0.998885" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999976190476191">
Evaluation of question answering techniques has
been a very difficult task. It gets more difficult to
evaluate this system because we don&apos;t have any
baseline or comparable systems. And also
because of the dynamic content, it is difficult to
design a question set to do the evaluation like
TREC.
However, the techniques used in this system
and in its previous local archive version [7] are
almost same. The evaluation data should be able
to technically level the performance of the
system.
We refer to the milestones described in [1]
and designed a set of 50 questions, which
covered all 16 Arthur Graesser s questions
categories and three other question categories
that ranged from easy to very difficult. The test
result is very encouraging and the accuracy is
72% in top 1 and 80% in top 5 (Table 1).
We also compared our search engine results
with the search result from the LookSmart search
</bodyText>
<listItem confidence="0.713311">
• 6
</listItem>
<bodyText confidence="0.980853666666667">
engine used by CNN Web site, and the result
from the Google site search&apos;. We conclude that
our system outperforms these systems.
Question-sentence matching formula used in
original AnswerBus system was proved effective
in Web-based QA system. However, in the new
QA system, it is not working as good as in
original AnswerBus QA system. The possible
reasons include: 1) The text in CNN Web site is
much more formal and the style is much more
unique; 2) Fewer redundant information can be
found in CNN Web site.
Restricted to the contents of CNN Web site,
the system seems working better for news or
politics related questions.
</bodyText>
<footnote confidence="0.998316">
6 http://cnn.looksmart.com/r_search
7 http://www.google.com/search?q=site:cnn.com
</footnote>
<page confidence="0.993662">
252
</page>
<sectionHeader confidence="0.941161" genericHeader="conclusions">
5 Conclusion [4]
</sectionHeader>
<bodyText confidence="0.996873333333333">
Based on our experiment on our new QA system,
we found that QA specific indexing and
searching are quite feasible. Most techniques
used in original AnswerBus System can be [5]
scalable to large size knowledge base and still
gets high accuracy.
</bodyText>
<sectionHeader confidence="0.98648" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.735868545454545">
[1] John Burger et al. Issues, Tasks and Program [6]
Structures to Roadmap Research in Question &amp;
Answering (Q&amp;A). NIST: hap:11mm-
n lpir.n ist. go v/project s/duc/papers/qa. Roadmap-
paper_v2.doc 2001
[2] Zhiping Zheng. AnswerBus Question Answering [7]
System. Human Language Technology
Conference (HLT 2002). San Diego, CA. March
24-27, 2002.
[31 Zhiping Zheng. Developing a Web-based
Question Answering System. The Eleventh
World Wide Conference (WWW 2002).
Zhiping Zheng. Rule-based Sentence
Segmentation for HTML/TEXT Documents. The
Thirteenth meeting of Computational Linguistics
in the Netherlands (CLIN 2002). Groningen,
Netherlands. November 29 2002.
Zhiping Zheng. Seven Tones: Search for
Linguistics and Languages. The 2nd Meeting of
the North American Chapter of Association for
Computational Linguistics (NAA CL 2001).
Pittsburgh, PA. June 2-7, 2001.
Zhiping Zheng and Gregor Erbach. Specialized
search in linguistics and languages.
XI International Conference on Computing (CIC
2002). Mexico City, Mexico. November 25-29,
2002.
Zhiping Zheng, Huiyan Huang and Sven
Schmeier. Deploying Web-based Question
Answering System to Local Archive. Fifth
International Conference on TEXT, SPEECH
and DIALOGUE (TSD 2002). Brno, Czech
Republic. September 9-12, 2002.
</reference>
<tableCaption confidence="0.854755">
Honolulu, HI. May 7-11,2002.
Table 1. Evaluation on AnswerBus Local Archive
</tableCaption>
<table confidence="0.9985746">
Question Type Number Topl Top5 Wrong
I. Verification 3 1 1 1
2. Comparison 2 0 1 1
3. Disjunctive 2 2 0 0
4. Concept Completion 6 5 0 1
5. Definition 6 5 0 1
6. Example 3 3 0 0
7. Interpretation 3 2 1 0
8. Feature Specification 5 5 0 0
9. Quantification 6 4 0 2
10. Causal antecedent 3 2 0 1
11. Cause Consequence 0 0 0 0
12. Goal orientation 1 1 0 0
13. Enablement 0 0 0 0
14. Instrumental/Procedural 1 1 0 0
15. Expectational 1 1 0 0
16. Judgmental 3 1 0 0
17. Assertion 3 1 1 1
18. Request/Directive 0 0 0 0
19. Nils question 2 0 0 2
</table>
<page confidence="0.959449">
253
</page>
<figure confidence="0.940676916666667">
Fri
Amowitata
Itic the orhgtr, of the Democrattc• party&apos; s scot?
Question:
What is the origin of the Democratic Party&apos;s mascot?
Possible answers:
1. While there is no precise date for the beginning of the Democratic party,.its origin can be traced to the late 1700s when
Thomas Jefferson&apos;s Democratic-Republican party organized opposition to the Federalist Party.
2. The 1828 presidential campaign is also the origin of the Democratic party&apos;s mascot-- the donkey.
3. The 1828 campaign was also the origin of the Democratic Party&apos;s mascot-- the donkey.
Try your question on other engines:
Alta Vista I AnswerBus I Ask Jeeves I Excite I Google I HotBot I Lycos 1Northern Light I Start I Yahoo
</figure>
<figureCaption confidence="0.9999885">
Figure 1. Screen Shot of AnswerBus News Engine (1)
Figure 2. Screen Shot of AnswerBus News Engine (2)
</figureCaption>
<figure confidence="0.998623166666667">
coli.uri-sh.de/,theng/answerhus/news/answer.cgl
111,, mehh hearts does oct,ph. hav, Askil
Question:
How many hearts does an octopus have?
Possible answers:
I found no answer for your question.
You may find the answers in following web pages:
1. News for you -- Giant octopus, Raggedy Ann, mighty thumbs
News for you -- Giant octopus, Raggedy Ann, mighty thumbs
2. Octopus seen reaching into China
Octopus seen reaching into China
3. Giant octopus caught off NZ
Giant octopus caught off NZ
4. Transcripts
Called octopus cards, these smart cards emit a signal that talks to an electronic reader.
It-bp CPT GontrkanarRirrs0:03/11/1_ea 00 1,11
Help
Z11- What s Relal cf
</figure>
<page confidence="0.984088">
254
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.315370">
<title confidence="0.994539">Question Answering Using Web News as Knowledge Base</title>
<author confidence="0.98751">Zhiping Zheng</author>
<affiliation confidence="0.998321">Computational Linguistics Department Saarland University</affiliation>
<address confidence="0.999151">D-66041 Saarbriicken, Germany</address>
<email confidence="0.952238">zheng@coli.uni—sb.de</email>
<abstract confidence="0.9821571875">AnswerBus News Engine&apos; is a question answering system using the contents of Web as its knowledge base. Comparing to other question answering systems including its previous versions, it has a totally independent crawling and indexing system and a fully functioning search engine. Because of its dynamic and continuous indexing, it is possible to answer questions on just-happened facts. Again, it reaches high correct answer rate. In this demonstration we will present the living system as well as its new technical features. answering, QA specific</abstract>
<intro confidence="0.517757">indexing, search engine</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Burger</author>
</authors>
<title>Tasks and Program [6] Structures to Roadmap Research in Question &amp; Answering (Q&amp;A). NIST: hap:11mmn lpir.n ist. go v/project s/duc/papers/qa.</title>
<date>2001</date>
<booktitle>Roadmappaper_v2.doc</booktitle>
<marker>Burger, 2001</marker>
<rawString>[1] John Burger et al. Issues, Tasks and Program [6] Structures to Roadmap Research in Question &amp; Answering (Q&amp;A). NIST: hap:11mmn lpir.n ist. go v/project s/duc/papers/qa. Roadmappaper_v2.doc 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiping Zheng</author>
</authors>
<title>AnswerBus Question Answering [7] System. Human</title>
<date>2002</date>
<booktitle>Language Technology Conference (HLT 2002).</booktitle>
<location>San Diego, CA.</location>
<marker>Zheng, 2002</marker>
<rawString>[2] Zhiping Zheng. AnswerBus Question Answering [7] System. Human Language Technology Conference (HLT 2002). San Diego, CA. March 24-27, 2002.</rawString>
</citation>
<citation valid="true">
<title>Developing a Web-based Question Answering System. The Eleventh World Wide Conference (WWW</title>
<date>2002</date>
<marker>2002</marker>
<rawString>[31 Zhiping Zheng. Developing a Web-based Question Answering System. The Eleventh World Wide Conference (WWW 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiping Zheng</author>
</authors>
<title>Rule-based Sentence Segmentation for HTML/TEXT Documents. The Thirteenth meeting of</title>
<date>2002</date>
<booktitle>Computational Linguistics in the Netherlands (CLIN 2002).</booktitle>
<location>Groningen, Netherlands.</location>
<marker>Zheng, 2002</marker>
<rawString>Zhiping Zheng. Rule-based Sentence Segmentation for HTML/TEXT Documents. The Thirteenth meeting of Computational Linguistics in the Netherlands (CLIN 2002). Groningen, Netherlands. November 29 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiping Zheng</author>
</authors>
<title>Seven Tones: Search for Linguistics and Languages.</title>
<date>2001</date>
<booktitle>The 2nd Meeting of the North American Chapter of Association for Computational Linguistics (NAA CL</booktitle>
<location>Pittsburgh, PA.</location>
<marker>Zheng, 2001</marker>
<rawString>Zhiping Zheng. Seven Tones: Search for Linguistics and Languages. The 2nd Meeting of the North American Chapter of Association for Computational Linguistics (NAA CL 2001). Pittsburgh, PA. June 2-7, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiping Zheng</author>
<author>Gregor Erbach</author>
</authors>
<title>Specialized search in linguistics and languages.</title>
<date>2002</date>
<booktitle>XI International Conference on Computing (CIC 2002). Mexico City,</booktitle>
<location>Mexico.</location>
<marker>Zheng, Erbach, 2002</marker>
<rawString>Zhiping Zheng and Gregor Erbach. Specialized search in linguistics and languages. XI International Conference on Computing (CIC 2002). Mexico City, Mexico. November 25-29, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiping Zheng</author>
<author>Huiyan Huang</author>
<author>Sven Schmeier</author>
</authors>
<title>Deploying Web-based Question Answering System to Local Archive.</title>
<date>2002</date>
<booktitle>Fifth International Conference on TEXT, SPEECH and DIALOGUE (TSD 2002).</booktitle>
<location>Brno, Czech Republic.</location>
<marker>Zheng, Huang, Schmeier, 2002</marker>
<rawString>Zhiping Zheng, Huiyan Huang and Sven Schmeier. Deploying Web-based Question Answering System to Local Archive. Fifth International Conference on TEXT, SPEECH and DIALOGUE (TSD 2002). Brno, Czech Republic. September 9-12, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>