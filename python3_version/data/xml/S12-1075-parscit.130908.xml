<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001526">
<title confidence="0.999426">
PolyUCOMP: Combining Semantic Vectors with Skip bigrams for
Semantic Textual Similarity
</title>
<author confidence="0.969307">
Jian Xu Qin Lu Zhengzhong Liu
</author>
<affiliation confidence="0.9293775">
The Hong Kong Polytechnic University
Department of Computing
</affiliation>
<address confidence="0.492258">
Hung Hom, Kowloon, Hong Kong
</address>
<email confidence="0.907316">
{csjxu, csluqin, hector.liu}@comp.polyu.edu.hk
</email>
<sectionHeader confidence="0.982232" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999250666666667">
This paper presents the work of the Hong
Kong Polytechnic University (PolyUCOMP)
team which has participated in the Semantic
Textual Similarity task of SemEval-2012. The
PolyUCOMP system combines semantic vec-
tors with skip bigrams to determine sentence
similarity. The semantic vector is used to
compute similarities between sentence pairs
using the lexical database WordNet and the
Wikipedia corpus. The use of skip bigram is
to introduce the order of words in measuring
sentence similarity.
</bodyText>
<sectionHeader confidence="0.99508" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99979896">
Sentence similarity computation plays an im-
portant role in text summarization, classification,
question answering and social network applica-
tions (Lin and Pantel, 2001; Erkan and Radev,
2004; Ko et al., 2004; Ou et al., 2011). The
SemEval 2012 competition includes a task targeted
at Semantic Textual Similarity (STS) between sen-
tence pairs (Eneko et al., 2012). Given a set of sen-
tence pairs, participants are required to assign to
each sentence pair a similarity score.
Because a sentence has only a limited amount of
content words, it is not easy to determine sentence
similarities because of the sparseness issue.
Hatzivassiloglou et al. (1999) proposed to use lin-
guistic features as indicators of text similarity to
address the problem of sparse representation of
sentences. Mihalcea et al. (2006) measured sen-
tence similarity using component words in sen-
tences. Li et al. (2006) proposed to incorporate the
semantic vector and word order to calculate sen-
tence similarity.
In our approach to the STS task, semantic vector
is used and the semantic relatedness between
words is derived from two sources: WordNet and
Wikipedia. Because WordNet is limited in its cov-
erage, Wikipedia is used as a candidate for deter-
mining word similarity.
Word order, however, is not considered in se-
mantic vector. As semantic information are coded
in sentences according to its order of writing, and
in our systems, content words may not be adjacent
to each other, we proposed to use skip bigrams to
represent the structure of sentences. Skip bigrams,
generally speaking, are pairs of words in a sen-
tence order with arbitrary gap (Lin and Och,
2004a). Different from the previous skip bigram
statistics which compare sentence similarities
through overlapping skip bigrams (Lin and Och,
2004a), the skip bigrams we used are weighted by
a decaying factor of the skipping gap in a sentence,
giving higher scores to closer occurrences of skip
bigrams. It is reasonable to assume that similar
sentences should have more overlapping skip bi-
grams, and the gaps in their shared skip bigrams
should also be similar.
The rest of this paper is organized as followed.
Section 2 describes sentence similarity using se-
mantic vectors and the order-sensitive skip bigrams.
Section 3 gives the performance evaluation. Sec-
tion 4 is the conclusion.
</bodyText>
<sectionHeader confidence="0.604059" genericHeader="method">
2 Similarity between Sentences
</sectionHeader>
<bodyText confidence="0.999804142857143">
Words are used to represent a sentence in the
vector space model. Semantic vectors are con-
structed for sentence representations with each en-
try corresponding to a word. Since the semantic
vector does not consider word order, we further
proposed to use skip bigrams to represent sentence
structure. Moreover, these skip bigrams are
</bodyText>
<page confidence="0.562384">
524
</page>
<note confidence="0.937488">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 524–528,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<footnote confidence="0.511416">
weighted by a decaying factor based on the so
called skip distance in the sentence.
</footnote>
<subsectionHeader confidence="0.990101">
2.1 Sentence similarity using Semantic
Vector
</subsectionHeader>
<bodyText confidence="0.996332">
Given a sentence pair, S1 and S2, for example,
</bodyText>
<listItem confidence="0.4291385">
S1: Chairman Michael Powell and FCC colleagues at
the Wednesday hearing.
S2: FCC chief Michael Powell presides over hearing
Monday.
</listItem>
<bodyText confidence="0.99162996">
The term set of the vector space is first formed
by taking only the content words in both sentences,
T={chairman, chief, colleagues, fcc, hearing, michael,
monday, powell, presides, wednesday }
Each entry of the semantic vector corresponds to
a word in the joint word set (Li et al., 2006). Then,
the vector for each sentence is formed in two steps:
For a word both in the term set T and in the sen-
tence, the value for this word entry is set to 1. If a
word is not in the sentence, the most similar word
in the sentence will then be identified, and the cor-
responding path similarity value will be assigned
to this entry. Let T be the term set with a sorted list
of content words, T=(t1, t2,..., tn). Without loss of
generality, let a sentence S=(w1 w2...wm) where wj
is a content word and wj is a word in T. Let the
vector space of the sentence S be VSs = (v1, v2, ...,
vn). Then the value of vi is assigned as follows,
where the similarity function SIM(ti, wj) is calcu-
lated according to the path measure (Pedersen et
al., 2004) using the WordNet, formally defined as,
where dist(ti, wj) is the shortest path from ti, to
wj by counting nodes in the WordNet taxonomy.
Based on this, the semantic vectors for the two ex-
ample sentences will be,
</bodyText>
<equation confidence="0.9785365">
SVS1 = (1, 0.25, 1, 1, 1, 1, 0.33, 1, 0, 1) and
SVS2 = (0.25, 1, 0, 1, 1, 1, 1, 1, 1, 0.33)
</equation>
<bodyText confidence="0.999876210526316">
Based on the two semantic vectors, the cosine
metric is used to measure sentence similarity. In
the WordNet, the entry chairman in the joint set is
most similar to the word chief in sentence S2. In
practice, however, this entry might be closer to the
word presides than to the word chief. Therefore,
we try to obtain the semantic relatedness using the
Wikipedia for sentence T and find that the entry
chairman is closest to the word presides. The Wik-
ipedia-based word relatedness utilizes the hyper-
link structure (Milne &amp; Witten, 2008). It first
identifies the candidate articles, a and b, that dis-
cuss ti and wj respectively in this case and then
compute relatedness between these articles,
where A and B are sets of articles that link to a
and b. W is the set of all articles in the Wikipedia.
Finally, two articles that represent ti and wj are se-
lected and their relatedness score is assigned to
SIM(ti, wj).
</bodyText>
<subsectionHeader confidence="0.997412">
2.2 Sentence Similarity by Skip bigrams
</subsectionHeader>
<bodyText confidence="0.9999455">
Skip bigrams are pairs of words in a sentence
order with arbitrary gaps. They contain the order-
sensitive information between two words. The skip
bigrams of a sentence are extracted as features
which will be stacked in a vector space. Each skip
bigram is weighted by a decaying factor with its
skip distances in the sentence. To illustrate this,
consider the following sentences S and T:
</bodyText>
<equation confidence="0.960486">
S = w1 w2 w1 w3 w4 and T = w2 w1 w4 w5 w4
</equation>
<bodyText confidence="0.997849">
where w denotes a word. It can be used more
than once in a sentence. Each sentence above has a
C(5, 2) 1 = 10 skip bigrams.
The sentence S has the following skip bigrams:
</bodyText>
<equation confidence="0.98032925">
“ ” “ ” “ ” “ ” “ ”
w1w2 , w1w1 , w1w3 , w1w4 , w2w1 ,
“ ” “ ” “ ” “ ” “ ”
w2w3 , w2w4 , w1w3 , w1w4 , w3w4
The sentence T has the following skip bigrams:
“w2w1”, “w2w4”, “w2w5”, “w2w4”, “w1w4”,
“ ” “ ” “ ” “ ” “ ”
w1w5 , w1w4 , w4w5 , w4w4 , w5w4
</equation>
<bodyText confidence="0.9998312">
In the sentence S, we have two repeated skip bi-
grams “w1w4” and “w1w3”. In the sentence T, we
have “w2w4” and “w1w4” repeated twice. In this
case, the weight of the recurring skip bigrams will
be increased. Hereafter, vectors for S and T will be
</bodyText>
<equation confidence="0.777036666666667">
1 Combination: C(5,2)=5!/(2!*3!)=10.
SIM(ti, wj) 
dist(ti, wj
)
1
525
</equation>
<bodyText confidence="0.83519">
formulated with each entry corresponding to a dis-
tinctive skip bigram.
</bodyText>
<equation confidence="0.995015">
VS = (“w1w2”, “w1w1”, “w1w3”, “w1w4”, “w2w1,
“w2w3”, “w2w4”, “w3w4”)’
VT = (“w2w1”, “w2w4”, “w2w5”, “w1w4”, “w1w5”,
“ ” “ ” “ ”
w4w5, w4w4 w5w4
</equation>
<bodyText confidence="0.996865263157895">
Now, the question remains how to weight the
skip bigrams. GivenΣ as a finite word set, let
S=w1w2...w|S |be a sentence, wi∈Σand 1≤i≤|S|.
A skip bigram of S, denoted by u, is defined by an
index set I=(i1, i2) of S (1≤i1&lt;i2≤|S |and u=S[I]).
The skip distance of S[I] , denoted by du (I), is the
skip distance of the first word and the second word
of u, calculated by i2-i1+1. For example, if S is the
sentence of w1w2w1w3w4 and u = w1w4, then there
are two index sets, I1=[3,5] and I2=[1,5] such that
u=S[3,5] and u=S[1,5], and the skip distances of
S[3,5] and S[1,5] are 3 and 5. The weight of a skip
bigram u for a sentence S with all its possible oc-
currences, denoted by 0. (S) , is defined as:
where λ is the decay factor which penalizes the
longer skip distance of a skip bigram. By doing so,
for the sentence S, the complete word set is Σ={w1,
w2, w3,w4}. The weights for the skip bigrams are
listed in Table 1:
</bodyText>
<table confidence="0.9836344">
u u OU(S)
W1 W2 z W2 W1 A2
Wiwi /� 3 W2 W3 V
W1 W3 A4 +A2 W2W4 A4
W1 W4 X + X W3 W4 Az
</table>
<tableCaption confidence="0.999802">
Table 1: Skip bigrams and their Weights in S
</tableCaption>
<bodyText confidence="0.998154333333333">
In Table 1, if λ is set to 0.25, the weight of the
skip bigram w1w2 in S is 0.252=0.0625, and w1w3 is
0.254 +0.252=0.064. Similarly, the skip bigrams
and weights in the sentence T can be obtained.
With the skip bigram-based vectors, cosine metric
is then used to compute similarity between S and T.
</bodyText>
<sectionHeader confidence="0.999231" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999950826086957">
In the STS task, three training datasets are avail-
able: MSR-Paraphrase, MSR-Video and
SMTeuroparl (Eneko et al., 2012). The number of
sentence pairs for three dataset is 750, 750 and 734.
In the following experiments, Let SWN, SWIKI and
SSKIP denote similarity measures of the vector space
representation using WordNet, Wikipedia and skip
bigrams, respectively. The three similarity
measures are linearly combined as SCOMB:
where α and β are weight factors for SWN and
SWIKI in the range [0,1]. If α is set to 1, only the
WordNet-based similarity measure is used; if α is 0,
the Wikipedia and skip bigram measures are used.
Because each dataset has a different representa-
tion for sentences, the parameter configurations for
them are different. For the word similarity using
the lexical resource WordNet, the path measure is
used in experiments. To get word relatedness from
the English Wikipedia, the Wikipedia Miner tool2
is used. When computing sentence similarity based
on the skip bigrams, the decaying factor (DF) must
be specified beforehand. Hence, parameter config-
urations for the three datasets are listed in Table 2:
</bodyText>
<tableCaption confidence="0.952337">
Table 2: Parameter Configurations
</tableCaption>
<bodyText confidence="0.999720117647059">
In the testing phase, five testing dataset are pro-
vided. In addition to three test datasets drawn from
the publicly available datasets used in the training
phase, two surprise datasets are given. They are
SMTnews and OnWN (Eneko et al., 2012).
SMTnews has 399 pairs of sentences and OnWN
contains 750 sentence pairs. The parameter config-
urations for these two surprise datasets are the
same as those for the dataset MSR-Paraphrase.
The official scoring is based on Pearson correla-
tion. If the system gives the similarity scores close
to the reference answers, the system will attain a
high correlation value. Besides, three other evalua-
tion metrics (ALL, ALLnrm, Mean) based on the
Pearson correlation are used (Eneko et al., 2012).
Among the 89 submitted systems, the results of
our system are given in Table 3:
</bodyText>
<table confidence="0.9194875">
Run ALL Rank ALLnrm RankNrm Mean RankMean
PolyUCOMP 0.6528 31 0.7642 59 0.5492 51
</table>
<tableCaption confidence="0.999527">
Table 3: Performance using Different Metrics
</tableCaption>
<footnote confidence="0.885207">
2 http://wikipedia-miner.cms.waikato.ac.nz/
</footnote>
<page confidence="0.849214">
526
</page>
<bodyText confidence="0.996484266666667">
Using the ALL metric, our system ranks 31, but
for ALLnrm and Mean metrics, our system ranking
is decreased to 59 and 51. In terms of ALL metric,
our system achieves a medium performance, im-
plying that our system correlates well with human
assessments. In terms of ALLnrm and Mean met-
rics, our system performance degrades a lot, imply-
ing that our system is not well correlated with the
reference answer when each dataset is normalized
into the aggregated dataset using the least square
error or the weighted mean across the datasets.
To see how well each of the individual vector
space models performed on the evaluation sets, we
experiment on the five datasets using vectors based
on WordNet, Wikipedia (Wiki), SkipBigram and
</bodyText>
<tableCaption confidence="0.882185666666667">
PolyuCOMP (a combination of the three vectors).
Table 4 gives detailed results of each dataset.
Table 4: Pearson Correlation for each Dataset
</tableCaption>
<bodyText confidence="0.991588048780488">
Table 4 shows that after combining three vector
representations, each dataset obtains the best per-
formance. The WordNet-based approach gives a
better performance than Wikipedia-based approach
in MSRvid dataset. The two approaches, however,
give similar performance in other four datasets.
This is because the sentences in the MSRvid da-
taset are too short with limited amount of content
words. It is difficult to capture the meaning of a
sentence without distinguishing words in consecu-
tive positions. This is why the order-sensitive
SkipBigram approach gives better performance
than the other two approaches. For example,
A woman is playing a game with a man.
A man is playing piano.
Using the semantic vectors, we will get high
similarity scores, but the two sentences are dissimi-
lar. If the skip bigram approach is used, the simi-
larity score between sentences will be 0, which
correlates with human judgment. In parameter con-
figurations for the MSRvid dataset, higher weight
(1-0.123-0.01=0.867) is also given to skip bigrams.
It is interesting to note that the decaying factor for
this dataset is 1.4 and is not in the range from 0 to
1 inclusive. This is because higher decaying factor
helps to capture semantic meaning between words
that span afar. For example,
A man is playing a flute.
A man is playing a bamboo flute.
In this sentence pair, the second sentence is en-
tailed by the first one. The similarity can be cap-
tured by assigned larger decay factor to weigh the
skip bigram “playing flute” in two sentences.
Hence, if the value of the decay factor is greater
than 1, the two sentences will become much more
similar. After careful investigation, these two sen-
tences are similar to a large extent. In this sense, a
higher decaying factor would help capture the
meaning between sentence pairs. This is quite dif-
ferent from the other four datasets which focus on
shared skip bigrams with smaller decaying factor.
</bodyText>
<sectionHeader confidence="0.996481" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999974555555555">
In the Semantic Textual Similarity task of
SemEval-2012, we proposed to combine the se-
mantic vector with the order-sensitive skip bigrams
to capture the meaning between sentences. First, a
semantic vector is derived from either the
WordNet or Wikipedia. The WordNet simulates
the common human knowledge about word con-
cepts. However, WordNet is limited in its word
coverage. To remedy this, Wikipedia is used to
obtain the semantic relatedness between words.
Second, the proposed approach also considers the
impact of word order in sentence similarity by us-
ing skip bigrams. Finally, the overall sentence sim-
ilarity is defined as a linear combination of the
three similarity metrics. However, our system is
limited in its approaches. In future work, we would
like to apply machine learning approach in deter-
mining sentence similarity.
</bodyText>
<page confidence="0.724697">
527
</page>
<sectionHeader confidence="0.983026" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999543578947369">
David Milne , Ian H. Witten. 2008. An Effective, Low-
cost Measure of Semantic Relatedness Obtained from
Wikipedia Links. In Proceedings of the first AAAI
Workshop on Wikipedia and Artificial Intelligence
(WIKIAI&apos;08), Chicago, I.L
Dekang Lin and Patrick Pantel. 2001. Discovery of In-
ference Rules for Question Answering. Natural Lan-
guage Engineering, 7(4):343-360.
Eneko Agirre, Daniel Cer, Mona Diab and Aitor Gonza-
lez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on
Semantic Textual Similarity. In Proceedings of the
6th International Workshop on Semantic Evaluation
(SemEval 2012), in conjunction with the First Joint
Conference on Lexical and Computational Semantics
(*SEM 2012).
Gunes Erkan and Dragomir R. Radev. 2004. Lexrank:
Graph-based Lexical Centrality as Salience in Text
Summarization. Journal of Artificial Intelligence Re-
search, 22: 457–479.
Lin, Chin-Yew and Franz Josef Och. 2004a. Automatic
Evaluation of Machine Translation Quality Using
Longest Common Subsequence and Skip bigram Sta-
tistics. In Proceedings of the 42nd Annual Meeting of
the Association for Computational Linguistics (ACL
2004), Barcelona, Spain.
Ou Jin, Nathan Nan Liu, Yong Yu and Qiang Yang.
2011. Transferring Topical Knowledge from Auxilia-
ry Long Text for Short Text Understanding. In: Pro-
ceedings of the 20th ACM Conference on
Information and Knowledge Management (ACM
CIKM 2011). Glasgow, UK.
Rada Mihalcea and Courtney Corley. 2006. Corpus-
based and Knowledge-based Measures of Text Se-
mantic Similarity. In Proceeding of the Twenty-First
National Conference on Artificial Intelligence and
the Eighteenth Innovative Applications of Artificial
Intelligence Conference.
Ted Pedersen, Siddharth Patwardhan and Jason
Michelizzi. 2004. WordNet::Similarity—Measuring
the Relatedness of Concepts. In Proceedings of the
19th National Conference on Artificial Intelligence
(AAAI, San Jose, CA), pages 144–152.
Vasileios Hatzivassiloglou, Judith L. Klavans , Eleazar
Eskin. 1999. Detecting Text Similarity over Short
Passages: Exploring Linguistic Feature Combinations
via Machine Learning. In Proceeding of Empirical
Methods in natural language processing and Very
Large Corpora.
Youngjoong Ko, Jinwoo Park, and Jungyun Seo. 2004.
Improving Text Categorization using the Importance
of Sentences. Information Processingand Manage-
ment, 40(1): 65–79.
Yuhua Li, David Mclean, Zuhair B, James D. O&apos;shea
and Keeley Crockett. 2006. Sentence Similarity
Based on Semantic Nets and Corpus Statistics. IEEE
Transactions on Knowledge and Data Engineering,
18(8), 1138–1149.
</reference>
<page confidence="0.909988">
528
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.495617">
<title confidence="0.9832455">PolyUCOMP: Combining Semantic Vectors with Skip bigrams Semantic Textual Similarity</title>
<author confidence="0.9850425">Jian Xu Qin Lu Zhengzhong Liu The Hong Kong Polytechnic</author>
<affiliation confidence="0.964267">Department of</affiliation>
<author confidence="0.594425">Hung Hom</author>
<author confidence="0.594425">Hong Kowloon</author>
<email confidence="0.95698">csluqin,</email>
<abstract confidence="0.995284769230769">This paper presents the work of the Hong Kong Polytechnic University (PolyUCOMP) team which has participated in the Semantic Textual Similarity task of SemEval-2012. The PolyUCOMP system combines semantic vectors with skip bigrams to determine sentence similarity. The semantic vector is used to compute similarities between sentence pairs using the lexical database WordNet and the Wikipedia corpus. The use of skip bigram is to introduce the order of words in measuring sentence similarity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
</authors>
<title>An Effective, Lowcost Measure of Semantic Relatedness Obtained from Wikipedia Links.</title>
<date>2008</date>
<booktitle>In Proceedings of the first AAAI Workshop on Wikipedia and Artificial Intelligence (WIKIAI&apos;08),</booktitle>
<location>Chicago, I.L</location>
<contexts>
<context position="5801" citStr="Witten, 2008" startWordPosition="963" endWordPosition="964">5, 1, 1, 1, 1, 0.33, 1, 0, 1) and SVS2 = (0.25, 1, 0, 1, 1, 1, 1, 1, 1, 0.33) Based on the two semantic vectors, the cosine metric is used to measure sentence similarity. In the WordNet, the entry chairman in the joint set is most similar to the word chief in sentence S2. In practice, however, this entry might be closer to the word presides than to the word chief. Therefore, we try to obtain the semantic relatedness using the Wikipedia for sentence T and find that the entry chairman is closest to the word presides. The Wikipedia-based word relatedness utilizes the hyperlink structure (Milne &amp; Witten, 2008). It first identifies the candidate articles, a and b, that discuss ti and wj respectively in this case and then compute relatedness between these articles, where A and B are sets of articles that link to a and b. W is the set of all articles in the Wikipedia. Finally, two articles that represent ti and wj are selected and their relatedness score is assigned to SIM(ti, wj). 2.2 Sentence Similarity by Skip bigrams Skip bigrams are pairs of words in a sentence order with arbitrary gaps. They contain the ordersensitive information between two words. The skip bigrams of a sentence are extracted as</context>
</contexts>
<marker>Witten, 2008</marker>
<rawString>David Milne , Ian H. Witten. 2008. An Effective, Lowcost Measure of Semantic Relatedness Obtained from Wikipedia Links. In Proceedings of the first AAAI Workshop on Wikipedia and Artificial Intelligence (WIKIAI&apos;08), Chicago, I.L</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<pages>7--4</pages>
<contexts>
<context position="939" citStr="Lin and Pantel, 2001" startWordPosition="129" endWordPosition="132">ic University (PolyUCOMP) team which has participated in the Semantic Textual Similarity task of SemEval-2012. The PolyUCOMP system combines semantic vectors with skip bigrams to determine sentence similarity. The semantic vector is used to compute similarities between sentence pairs using the lexical database WordNet and the Wikipedia corpus. The use of skip bigram is to introduce the order of words in measuring sentence similarity. 1 Introduction Sentence similarity computation plays an important role in text summarization, classification, question answering and social network applications (Lin and Pantel, 2001; Erkan and Radev, 2004; Ko et al., 2004; Ou et al., 2011). The SemEval 2012 competition includes a task targeted at Semantic Textual Similarity (STS) between sentence pairs (Eneko et al., 2012). Given a set of sentence pairs, participants are required to assign to each sentence pair a similarity score. Because a sentence has only a limited amount of content words, it is not easy to determine sentence similarities because of the sparseness issue. Hatzivassiloglou et al. (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation o</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for Question Answering. Natural Language Engineering, 7(4):343-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab and Aitor Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>Lexrank: Graph-based Lexical Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>22</volume>
<pages>457--479</pages>
<contexts>
<context position="962" citStr="Erkan and Radev, 2004" startWordPosition="133" endWordPosition="136">MP) team which has participated in the Semantic Textual Similarity task of SemEval-2012. The PolyUCOMP system combines semantic vectors with skip bigrams to determine sentence similarity. The semantic vector is used to compute similarities between sentence pairs using the lexical database WordNet and the Wikipedia corpus. The use of skip bigram is to introduce the order of words in measuring sentence similarity. 1 Introduction Sentence similarity computation plays an important role in text summarization, classification, question answering and social network applications (Lin and Pantel, 2001; Erkan and Radev, 2004; Ko et al., 2004; Ou et al., 2011). The SemEval 2012 competition includes a task targeted at Semantic Textual Similarity (STS) between sentence pairs (Eneko et al., 2012). Given a set of sentence pairs, participants are required to assign to each sentence pair a similarity score. Because a sentence has only a limited amount of content words, it is not easy to determine sentence similarities because of the sparseness issue. Hatzivassiloglou et al. (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. Mihalcea e</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Gunes Erkan and Dragomir R. Radev. 2004. Lexrank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22: 457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Franz Josef Och</author>
</authors>
<title>Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip bigram Statistics.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2405" citStr="Lin and Och, 2004" startWordPosition="373" endWordPosition="376">tic vector is used and the semantic relatedness between words is derived from two sources: WordNet and Wikipedia. Because WordNet is limited in its coverage, Wikipedia is used as a candidate for determining word similarity. Word order, however, is not considered in semantic vector. As semantic information are coded in sentences according to its order of writing, and in our systems, content words may not be adjacent to each other, we proposed to use skip bigrams to represent the structure of sentences. Skip bigrams, generally speaking, are pairs of words in a sentence order with arbitrary gap (Lin and Och, 2004a). Different from the previous skip bigram statistics which compare sentence similarities through overlapping skip bigrams (Lin and Och, 2004a), the skip bigrams we used are weighted by a decaying factor of the skipping gap in a sentence, giving higher scores to closer occurrences of skip bigrams. It is reasonable to assume that similar sentences should have more overlapping skip bigrams, and the gaps in their shared skip bigrams should also be similar. The rest of this paper is organized as followed. Section 2 describes sentence similarity using semantic vectors and the order-sensitive skip </context>
</contexts>
<marker>Lin, Och, 2004</marker>
<rawString>Lin, Chin-Yew and Franz Josef Och. 2004a. Automatic Evaluation of Machine Translation Quality Using Longest Common Subsequence and Skip bigram Statistics. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ou Jin</author>
<author>Nathan Nan Liu</author>
<author>Yong Yu</author>
<author>Qiang Yang</author>
</authors>
<title>Transferring Topical Knowledge from Auxiliary Long Text for Short Text Understanding. In:</title>
<date>2011</date>
<booktitle>Proceedings of the 20th ACM Conference on Information and Knowledge Management (ACM CIKM 2011).</booktitle>
<location>Glasgow, UK.</location>
<marker>Jin, Liu, Yu, Yang, 2011</marker>
<rawString>Ou Jin, Nathan Nan Liu, Yong Yu and Qiang Yang. 2011. Transferring Topical Knowledge from Auxiliary Long Text for Short Text Understanding. In: Proceedings of the 20th ACM Conference on Information and Knowledge Management (ACM CIKM 2011). Glasgow, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
</authors>
<title>Corpusbased and Knowledge-based Measures of Text Semantic Similarity.</title>
<date>2006</date>
<booktitle>In Proceeding of the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference.</booktitle>
<marker>Mihalcea, Corley, 2006</marker>
<rawString>Rada Mihalcea and Courtney Corley. 2006. Corpusbased and Knowledge-based Measures of Text Semantic Similarity. In Proceeding of the Twenty-First National Conference on Artificial Intelligence and the Eighteenth Innovative Applications of Artificial Intelligence Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity—Measuring the Relatedness of Concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 19th National Conference on Artificial Intelligence (AAAI,</booktitle>
<pages>144--152</pages>
<location>San Jose, CA),</location>
<contexts>
<context position="4960" citStr="Pedersen et al., 2004" startWordPosition="806" endWordPosition="809">e value for this word entry is set to 1. If a word is not in the sentence, the most similar word in the sentence will then be identified, and the corresponding path similarity value will be assigned to this entry. Let T be the term set with a sorted list of content words, T=(t1, t2,..., tn). Without loss of generality, let a sentence S=(w1 w2...wm) where wj is a content word and wj is a word in T. Let the vector space of the sentence S be VSs = (v1, v2, ..., vn). Then the value of vi is assigned as follows, where the similarity function SIM(ti, wj) is calculated according to the path measure (Pedersen et al., 2004) using the WordNet, formally defined as, where dist(ti, wj) is the shortest path from ti, to wj by counting nodes in the WordNet taxonomy. Based on this, the semantic vectors for the two example sentences will be, SVS1 = (1, 0.25, 1, 1, 1, 1, 0.33, 1, 0, 1) and SVS2 = (0.25, 1, 0, 1, 1, 1, 1, 1, 1, 0.33) Based on the two semantic vectors, the cosine metric is used to measure sentence similarity. In the WordNet, the entry chairman in the joint set is most similar to the word chief in sentence S2. In practice, however, this entry might be closer to the word presides than to the word chief. There</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan and Jason Michelizzi. 2004. WordNet::Similarity—Measuring the Relatedness of Concepts. In Proceedings of the 19th National Conference on Artificial Intelligence (AAAI, San Jose, CA), pages 144–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Judith L Klavans</author>
</authors>
<title>Detecting Text Similarity over Short Passages: Exploring Linguistic Feature Combinations via Machine Learning.</title>
<date>1999</date>
<booktitle>In Proceeding of Empirical Methods in natural language processing and Very Large Corpora.</booktitle>
<marker>Hatzivassiloglou, Klavans, 1999</marker>
<rawString>Vasileios Hatzivassiloglou, Judith L. Klavans , Eleazar Eskin. 1999. Detecting Text Similarity over Short Passages: Exploring Linguistic Feature Combinations via Machine Learning. In Proceeding of Empirical Methods in natural language processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngjoong Ko</author>
<author>Jinwoo Park</author>
<author>Jungyun Seo</author>
</authors>
<title>Improving Text Categorization using the Importance of Sentences.</title>
<date>2004</date>
<journal>Information Processingand Management,</journal>
<volume>40</volume>
<issue>1</issue>
<pages>65--79</pages>
<contexts>
<context position="979" citStr="Ko et al., 2004" startWordPosition="137" endWordPosition="140">icipated in the Semantic Textual Similarity task of SemEval-2012. The PolyUCOMP system combines semantic vectors with skip bigrams to determine sentence similarity. The semantic vector is used to compute similarities between sentence pairs using the lexical database WordNet and the Wikipedia corpus. The use of skip bigram is to introduce the order of words in measuring sentence similarity. 1 Introduction Sentence similarity computation plays an important role in text summarization, classification, question answering and social network applications (Lin and Pantel, 2001; Erkan and Radev, 2004; Ko et al., 2004; Ou et al., 2011). The SemEval 2012 competition includes a task targeted at Semantic Textual Similarity (STS) between sentence pairs (Eneko et al., 2012). Given a set of sentence pairs, participants are required to assign to each sentence pair a similarity score. Because a sentence has only a limited amount of content words, it is not easy to determine sentence similarities because of the sparseness issue. Hatzivassiloglou et al. (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. Mihalcea et al. (2006) meas</context>
</contexts>
<marker>Ko, Park, Seo, 2004</marker>
<rawString>Youngjoong Ko, Jinwoo Park, and Jungyun Seo. 2004. Improving Text Categorization using the Importance of Sentences. Information Processingand Management, 40(1): 65–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuhua Li</author>
<author>David Mclean</author>
<author>B Zuhair</author>
<author>James D O&apos;shea</author>
<author>Keeley Crockett</author>
</authors>
<title>Sentence Similarity Based on Semantic Nets and Corpus Statistics.</title>
<date>2006</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>18</volume>
<issue>8</issue>
<pages>1138--1149</pages>
<contexts>
<context position="1656" citStr="Li et al. (2006)" startWordPosition="247" endWordPosition="250">ask targeted at Semantic Textual Similarity (STS) between sentence pairs (Eneko et al., 2012). Given a set of sentence pairs, participants are required to assign to each sentence pair a similarity score. Because a sentence has only a limited amount of content words, it is not easy to determine sentence similarities because of the sparseness issue. Hatzivassiloglou et al. (1999) proposed to use linguistic features as indicators of text similarity to address the problem of sparse representation of sentences. Mihalcea et al. (2006) measured sentence similarity using component words in sentences. Li et al. (2006) proposed to incorporate the semantic vector and word order to calculate sentence similarity. In our approach to the STS task, semantic vector is used and the semantic relatedness between words is derived from two sources: WordNet and Wikipedia. Because WordNet is limited in its coverage, Wikipedia is used as a candidate for determining word similarity. Word order, however, is not considered in semantic vector. As semantic information are coded in sentences according to its order of writing, and in our systems, content words may not be adjacent to each other, we proposed to use skip bigrams to</context>
<context position="4220" citStr="Li et al., 2006" startWordPosition="659" endWordPosition="662">ional Linguistics weighted by a decaying factor based on the so called skip distance in the sentence. 2.1 Sentence similarity using Semantic Vector Given a sentence pair, S1 and S2, for example, S1: Chairman Michael Powell and FCC colleagues at the Wednesday hearing. S2: FCC chief Michael Powell presides over hearing Monday. The term set of the vector space is first formed by taking only the content words in both sentences, T={chairman, chief, colleagues, fcc, hearing, michael, monday, powell, presides, wednesday } Each entry of the semantic vector corresponds to a word in the joint word set (Li et al., 2006). Then, the vector for each sentence is formed in two steps: For a word both in the term set T and in the sentence, the value for this word entry is set to 1. If a word is not in the sentence, the most similar word in the sentence will then be identified, and the corresponding path similarity value will be assigned to this entry. Let T be the term set with a sorted list of content words, T=(t1, t2,..., tn). Without loss of generality, let a sentence S=(w1 w2...wm) where wj is a content word and wj is a word in T. Let the vector space of the sentence S be VSs = (v1, v2, ..., vn). Then the value</context>
</contexts>
<marker>Li, Mclean, Zuhair, O&apos;shea, Crockett, 2006</marker>
<rawString>Yuhua Li, David Mclean, Zuhair B, James D. O&apos;shea and Keeley Crockett. 2006. Sentence Similarity Based on Semantic Nets and Corpus Statistics. IEEE Transactions on Knowledge and Data Engineering, 18(8), 1138–1149.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>