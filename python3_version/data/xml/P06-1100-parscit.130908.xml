<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.981161">
Ontologizing Semantic Relations
</title>
<author confidence="0.828713">
Marco Pennacchiotti
</author>
<affiliation confidence="0.8345235">
ART Group - DISP
University of Rome “Tor Vergata”
</affiliation>
<address confidence="0.882999">
Viale del Politecnico 1
Rome, Italy
</address>
<email confidence="0.993462">
pennacchiotti@info.uniroma2.it
</email>
<sectionHeader confidence="0.99727" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999865416666667">
Many algorithms have been developed
to harvest lexical semantic resources,
however few have linked the mined
knowledge into formal knowledge re-
positories. In this paper, we propose two
algorithms for automatically ontologiz-
ing (attaching) semantic relations into
WordNet. We present an empirical
evaluation on the task of attaching part-
of and causation relations, showing an
improvement on F-score over a baseline
model.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99884152">
NLP researchers have developed many algo-
rithms for mining knowledge from text and the
Web, including facts (Etzioni et al. 2005), se-
mantic lexicons (Riloff and Shepherd 1997),
concept lists (Lin and Pantel 2002), and word
similarity lists (Hindle 1990). Many recent ef-
forts have also focused on extracting binary se-
mantic relations between entities, such as
entailments (Szpektor et al. 2004), is-a (Ravi-
chandran and Hovy 2002), part-of (Girju et al.
2003), and other relations.
The output of most of these systems is flat lists
of lexical semantic knowledge such as “Italy is-a
country” and “orange similar-to blue”. However,
using this knowledge beyond simple keyword
matching, for example in inferences, requires it
to be linked into formal semantic repositories
such as ontologies or term banks like WordNet
(Fellbaum 1998).
Pantel (2005) defined the task of ontologizing
a lexical semantic resource as linking its terms to
the concepts in a WordNet-like hierarchy. For
example, “orange similar-to blue” ontologizes in
WordNet to “orange#2 similar-to blue#1” and
“orange#2 similar-to blue#2”. In his framework,
</bodyText>
<author confidence="0.818354">
Patrick Pantel
</author>
<affiliation confidence="0.9909345">
Information Sciences Institute
University of Southern California
</affiliation>
<address confidence="0.765897">
4676 Admiralty Way
Marina del Rey, CA90292
</address>
<email confidence="0.991847">
pantel@isi.edu
</email>
<bodyText confidence="0.99980895">
Pantel proposed a method of inducing ontologi-
cal co-occurrence vectors 1 which are subse-
quently used to ontologize unknown terms into
WordNet with 74% accuracy.
In this paper, we take the next step and explore
two algorithms for ontologizing binary semantic
relations into WordNet and we present empirical
results on the task of attaching part-of and causa-
tion relations. Formally, given an instance
(x, r, y) of a binary relation r between terms x
and y, the ontologizing task is to identify the
WordNet senses of x and y where r holds. For
example, the instance (proton, PART-OF, element)
ontologizes into WordNet as (proton#1, PART-OF,
element#2).
The first algorithm that we explore, called the
anchoring approach, was suggested as a promis-
ing avenue of future work in (Pantel 2005). This
bottom up algorithm is based on the intuition that
x can be disambiguated by retrieving the set of
terms that occur in the same relation r with y and
then finding the senses of x that are most similar
to this set. The assumption is that terms occur-
ring in the same relation will tend to have similar
meaning. In this paper, we propose a measure of
similarity to capture this intuition.
In contrast to anchoring, our second algorithm,
called the clustering approach, takes a top-down
view. Given a relation r, suppose that we are
given every conceptual instance of r, i.e., in-
stances of r in the upper ontology like (parti-
cles#1, PART-OF, substances#1). An instance
(x, r, y) can then be ontologized easily by finding
the senses of x and y that are subsumed by ances-
tors linked by a conceptual instance of r. For ex-
ample, the instance (proton, PART-OF, element)
ontologizes to (proton#1, PART-OF, element#2)
since proton#1 is subsumed by particles and
element#2 is subsumed by substances. The prob-
lem then is to automatically infer the set of con-
</bodyText>
<footnote confidence="0.873825">
1 The ontological co-occurrence vector of a concept con-
sists of all lexical co-occurrences with the concept in a
corpus.
</footnote>
<page confidence="0.970808">
793
</page>
<note confidence="0.5423605">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 793–800,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999793444444444">
ceptual instances. In this paper, we develop a
clustering algorithm for generalizing a set of re-
lation instances to conceptual instances by look-
ing up the WordNet hypernymy hierarchy for
common ancestors, as specific as possible, that
subsume as many instances as possible. An in-
stance is then attached to its senses that are sub-
sumed by the highest scoring conceptual
instances.
</bodyText>
<sectionHeader confidence="0.998517" genericHeader="introduction">
2 Relevant Work
</sectionHeader>
<bodyText confidence="0.999689607142857">
Several researchers have worked on ontologizing
semantic resources. Most recently, Pantel (2005)
developed a method to propagate lexical co-
occurrence vectors to WordNet synsets, forming
ontological co-occurrence vectors. Adopting an
extension of the distributional hypothesis (Harris
1985), the co-occurrence vectors are used to
compute the similarity between synset/synset and
between lexical term/synset. An unknown term is
then attached to the WordNet synset whose co-
occurrence vector is most similar to the term’s
co-occurrence vector. Though the author sug-
gests a method for attaching more complex lexi-
cal structures like binary semantic relations, the
paper focused only on attaching terms.
Basili (2000) proposed an unsupervised
method to infer semantic classes (WordNet syn-
sets) for terms in domain-specific verb relations.
These relations, such as (x, EXPAND, y) are first
automatically learnt from a corpus. The semantic
classes of x and y are then inferred using concep-
tual density (Agirre and Rigau 1996), a Word-
Net-based measure applied to all instantiation of
x and y in the corpus. Semantic classes represent
possible common generalizations of the verb ar-
guments. At the end of the process, a set of syn-
tactic-semantic patterns are available for each
verb, such as:
</bodyText>
<equation confidence="0.993308">
(social_group#1, expand, act#2)
(instrumentality#2, expand, act#2)
</equation>
<bodyText confidence="0.999543515151515">
The method is successful on specific relations
with few instances (such as domain verb rela-
tions) while its value on generic and frequent
relations, such as part-of, was untested.
Girju et al. (2003) presented a highly super-
vised machine learning algorithm to infer seman-
tic constraints on part-of relations, such as
(object#1, PART-OF, social_event#1). These con-
straints are then used as selectional restrictions in
harvesting part-of instances from ambiguous
lexical patterns, like “X of Y”. The approach
shows high performance in terms of precision
and recall, but, as the authors acknowledge, it
requires large human effort during the training
phase.
Others have also made significant additions to
WordNet. For example, in eXtended WordNet
(Harabagiu et al. 1999), the glosses in WordNet
are enriched by disambiguating the nouns, verbs,
adverbs, and adjectives with synsets. Another
work has enriched WordNet synsets with topi-
cally related words extracted from the Web
(Agirre et al. 2001). Finally, the general task of
word sense disambiguation (Gale et al. 1991) is
relevant since there the task is to ontologize each
term in a passage into a WordNet-like sense in-
ventory. If we had a large collection of sense-
tagged text, then our mining algorithms could
directly discover WordNet attachment points at
harvest time. However, since there is little high
precision sense-tagged corpora, methods are re-
quired to ontologize semantic resources without
fully disambiguating text.
</bodyText>
<sectionHeader confidence="0.983609" genericHeader="method">
3 Ontologizing Semantic Relations
</sectionHeader>
<bodyText confidence="0.999536">
Given an instance (x, r, y) of a binary relation r
between terms x and y, the ontologizing task is to
identify the senses of x and y where r holds. In
this paper, we focus on WordNet 2.0 senses,
though any similar term bank would apply.
Let Sx and Sy be the sets of all WordNet senses
of x and y. A sense pair, sxy, is defined as any
pair of senses of x and y: sxy={sx, sy} where sxESx
and syESy. The set of all sense pairs Sxy consists
of all permutations between senses in Sx and Sy.
In order to attach a relation instance (x, r, y)
into WordNet, one must:
</bodyText>
<listItem confidence="0.99791875">
• Disambiguate x and y, that is, find the subsets
S&apos;xcSx and S&apos;ycSy for which the relation r holds;
and
• Instantiate the relation in WordNet, using the
</listItem>
<bodyText confidence="0.577956333333333">
synsets corresponding to all correct permuta-
tions between the senses in S&apos;x and S&apos;y. We de-
note this set of attachment points as S&apos;xy.
If Sx or Sy is empty, no attachments are produced.
For example, the instance (study, PART-OF, re-
port) is ontologized into WordNet through the
senses S&apos;x={survey#1, study#2} and
S’y={report#1}. The final attachment points S&apos;xy
are:
</bodyText>
<equation confidence="0.9734805">
(survey#1, PART-OF, report#1)
(study#1, PART-OF, report#1)
</equation>
<bodyText confidence="0.9980592">
Unlike common algorithms for word sense
disambiguation, here it is important to take into
consideration the semantic dependency between
the two terms x and y. For example, an entity that
is part-of a study has to be some kind of informa-
</bodyText>
<page confidence="0.996705">
794
</page>
<bodyText confidence="0.999855">
tion. This knowledge about mutual selectional
preference (the preferred semantic class that fills
a certain relation role, as x or y) can be exploited
to ontologize the instance.
In the following sections, we propose two al-
gorithms for ontologizing binary semantic rela-
tions.
</bodyText>
<subsectionHeader confidence="0.999849">
3.1 Method 1: Anchor Approach
</subsectionHeader>
<bodyText confidence="0.999963333333333">
Given an instance (x, r, y), this approach fixes the
term y, called the anchor, and then disambiguates
x by looking at all other terms that occur in the
relation r with y. Based on the principle of distri-
butional similarity (Harris 1985), the algorithm
assumes that the words that occur in the same
relation r with y will be more similar to the cor-
rect sense(s) of x than the incorrect ones. After
disambiguating x, the process is then inverted
with x as the anchor to disambiguate y.
In the first step, y is fixed and the algorithm
retrieves the set of all other terms X&apos; that occur in
an instance (x&apos;, r, y), x&apos; E X&apos;2. For example, given
the instance (reflections, PART-OF, book), and a
resource containing the following relations:
</bodyText>
<construct confidence="0.998187">
(false allegations, PART-OF, book)
(stories, PART-OF, book)
(expert analysis, PART-OF, book)
(conclusions, PART-OF, book)
</construct>
<bodyText confidence="0.999394933333333">
the resulting set X&apos; would be: {allegations, sto-
ries, analysis, conclusions}.
All possible permutations, Sxx&apos;, between the
senses of x and the senses of each term in X&apos;,
called Sx&apos;, are computed. For each sense pair
{sx, sx&apos;} E Sxx&apos;, a similarity score r(sx, sx&apos;) is calcu-
lated using WordNet:
where the distance d(sx, sx&apos;) is the length of the
shortest path connecting the two synsets in the
hypernymy hierarchy of WordNet, and f(sx&apos;) is
the number of times sense sx&apos; occurs in any of the
instances of X&apos;. Note that if no connection be-
tween two synsets exists, then r(sx, sx&apos;) = 0.
The overall sense score for each sense sx of x
is calculated as:
</bodyText>
<equation confidence="0.85040475">
r(sx ) = E r sx sx
( , &apos;
s x S x
&apos; �
</equation>
<bodyText confidence="0.980882363636363">
Finally, the algorithm inverts the process by
setting x as the anchor and computes r(sy) for
2 For semantic relations between complex terms, like (ex-
pert analysis, PART-OF, book), only the head noun of terms
are recorded, like “analysis”. As a future work, we plan to
use the whole term if it is present in WordNet.
each sense of y. All possible permutations of
senses are computed and scored by averaging
r(sx) and r(sy). Permutations scoring higher than a
threshold ti1 are selected as the attachment points
in WordNet. We experimentally set ti1 = 0.02.
</bodyText>
<subsectionHeader confidence="0.999719">
3.2 Method 2: Clustering Approach
</subsectionHeader>
<bodyText confidence="0.971335111111111">
The main idea of the clustering approach is to
leverage the lexical behaviors of the two terms in
an instance as a whole. The assumption is that
the general meaning of the relation is derived
from the combination of the two terms.
The algorithm is divided in two main phases.
In the first phase, semantic clusters are built us-
ing the WordNet senses of all instances. A se-
mantic cluster is defined by the set of instances
that have a common semantic generalization. We
denote the conceptual instance of the semantic
cluster as the pair of WordNet synsets that repre-
sents this generalization. For example the follow-
ing two part-of instances:
(second section, PART-OF, Los Angeles-area news)
(Sandag study, PART-OF, report)
are in a common cluster represented by the fol-
lowing conceptual instance:
</bodyText>
<equation confidence="0.76118">
[writing#2, PART-OF, message#2]
</equation>
<bodyText confidence="0.99100675">
since writing#2 is a hypernym of both section
and study, and message#2 is a hypernym of news
and report3.
In the second phase, the algorithm attaches an
instance into WordNet by using WordNet dis-
tance metrics and frequency scores to select the
best cluster for each instance. A good cluster is
one that:
</bodyText>
<listItem confidence="0.99869">
• achieves a good trade-off between generality
and specificity; and
• disambiguates among the senses of x and y us-
</listItem>
<bodyText confidence="0.993911">
ing the other instances’ senses as support.
For example, given the instance (second section,
PART-OF, Los Angeles-area news) and the follow-
ing conceptual instances:
</bodyText>
<equation confidence="0.6284658">
[writing#2, PART-OF, message#2]
[object#], PART-OF, message#2]
[writing#2, PART-OF, communication#2]
[social_group#], PART-OF, broadcast#2]
[organization#, PART-OF, message#2]
</equation>
<bodyText confidence="0.9983358">
the first conceptual instance should be scored
highest since it is both not too generic nor too
specific and is supported by the instance (Sandag
study, PART-OF, report), i.e., the conceptual in-
stance subsumes both instances. The second and
</bodyText>
<page confidence="0.621786">
3 Again, here, we use the syntactic head of each term for
</page>
<bodyText confidence="0.9224955">
generalization since we assume that it drives the meaning
of the term itself.
</bodyText>
<equation confidence="0.745145125">
r(sx,sx&apos;) = 1 x f (sx&apos;
d�
(sx, sx
)
)
1
)
&apos;
</equation>
<page confidence="0.98468">
795
</page>
<bodyText confidence="0.998988125">
the third conceptual instances should be scored
lower since they are too generic, while the last
two should be scored lower since the sense for
section and news are not supported by other in-
stances. The system then outputs, for each in-
stance, the set of sense pairs that are subsumed
by the highest scoring conceptual instance. In the
previous example:
</bodyText>
<equation confidence="0.993742333333333">
(section#1, PART-OF, news#1)
(section#1, PART-OF, news#2)
(section#1, PART-OF, news#3)
</equation>
<bodyText confidence="0.99948475">
are selected, as they are subsumed by [writing#2,
PART-OF, message#2]. These sense pairs are then
retained as attachment points into WordNet.
Below, we describe each phase in more detail.
</bodyText>
<subsectionHeader confidence="0.253753">
Phase 1: Cluster Building
</subsectionHeader>
<bodyText confidence="0.997279210526316">
Given an instance (x, r, y), all sense pair permu-
tations sxy={sx, sy} are retrieved from WordNet.
A set of candidate conceptual instances, Cxy, is
formed for each instance from the permutation of
each WordNet ancestor of sx and sy, following the
hypernymy link, up to degree ti2.
Each candidate conceptual instance,
c={cx, cy}, is scored by its degree of generaliza-
tion as follows:
where ni is the number of hypernymy links
needed to go from si to ci, for i E {x, y}. r(c)
ranges from [0, 1] and is highest when little gen-
eralization is needed.
For example, the instance (Sandag study,
PART-OF, report) produces 70 sense pairs since
study has 10 senses and report has 7 senses. As-
suming ti2=1, the instance sense (survey#1, PART-
OF, report#1) has the following set of candidate
conceptual instances:
</bodyText>
<table confidence="0.5728788">
Cxy nx ny r(c)
(survey#1, PART-OF,report#1) 0 0 1
(survey#1, PART-OF,document#1) 0 1 0.5
(examination#1, PART-OF,report#1) 1 0 0.5
(examination#1, PART-OF,document#1) 1 1 0.25
</table>
<bodyText confidence="0.998964">
Finally, each candidate conceptual instance c
forms a cluster of all instances (x, r, y) that have
some sense pair sx and sy as hyponyms of c. Note
also that candidate conceptual instances may be
subsumed by other candidate conceptual in-
stances. Let Gc refer to the set of all candidate
conceptual instances subsumed by candidate
conceptual instance c.
Intuitively, better candidate conceptual in-
stances are those that subsume both many in-
stances and other candidate conceptual instances,
but at the same time that have the least distance
from subsumed instances. We capture this intui-
tion with the following score of c:
</bodyText>
<equation confidence="0.99143">
E r(g)
g G
� c x log I x log Gc
</equation>
<bodyText confidence="0.99955875">
where Ic is the set of instances subsumed by c.
We experimented with different variations of this
score and found that it is important to put more
weight on the distance between subsumed con-
ceptual instances than the actual number of sub-
sumed instances. Without the log terms, the
highest scoring conceptual instances are too ge-
neric (i.e., they are too high up in the ontology).
</bodyText>
<subsubsectionHeader confidence="0.263213">
Phase 2: Attachment Points Selection
</subsubsectionHeader>
<bodyText confidence="0.999950277777778">
In this phase, we utilize the conceptual instances
of the previous phase to attach each instance
(x, r, y) into WordNet.
At the end of Phase 1, an instance can be clus-
tered in different conceptual instances. In order
to select an attachment, the algorithm selects the
sense pair of x and y that is subsumed by the
highest scoring candidate conceptual instance. It
and all other sense pairs that are subsumed by
this conceptual instance are then retained as the
final attachment points.
As a side effect, a final set of conceptual in-
stances is obtained by deleting from each candi-
date those instances that are subsumed by a
higher scoring conceptual instance. Remaining
conceptual instances are then re-scored using
score(c). The final set of conceptual instances
thus contains unambiguous sense pairs.
</bodyText>
<sectionHeader confidence="0.998316" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999375">
In this section we provide an empirical evalua-
tion of our two algorithms.
</bodyText>
<subsectionHeader confidence="0.96823">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999734">
Researchers have developed many algorithms for
harvesting semantic relations from corpora and
the Web. For the purposes of this paper, we may
choose any one of them and manually validate its
mined relations. We choose Espresso4, a general-
purpose, broad, and accurate corpus harvesting
algorithm requiring minimal supervision. Adopt-
</bodyText>
<footnote confidence="0.8250415">
4 Reference suppressed – the paper introducing Espresso
has also been submitted to COLING/ACL 2006.
</footnote>
<equation confidence="0.90496">
1
nx + x +
1) ( n y
r(c)
(
)
1
score(c) =
Gc
</equation>
<page confidence="0.994691">
796
</page>
<table confidence="0.99965875">
SYSTEM PRECISION RECALL F-SCORE
BL 54.0% 31.3% 39.6%
AN 40.7% 47.3% 43.8%
CL 57.4% 49.6% 53.2%
</table>
<tableCaption confidence="0.817491">
Table 1. System precision, recall and F-score on
the part-of relation.
</tableCaption>
<bodyText confidence="0.89535075">
ing a bootstrapping approach, Espresso takes as
input a few seed instances of a particular relation
and iteratively learns surface patterns to extract
more instances.
</bodyText>
<subsectionHeader confidence="0.913565">
Test Sets
</subsectionHeader>
<bodyText confidence="0.9998975625">
We experiment with two relations: part-of and
causation. The causation relation occurs when an
entity produces an effect or is responsible for
events or results, for example (virus, CAUSE, in-
fluenza) and (burning fuel, CAUSE, pollution). We
manually built five seed relation instances for
both relations and apply Espresso to a dataset
consisting of a sample of articles from the
Aquaint (TREC-9) newswire text collection. The
sample consists of 55.7 million words extracted
from the Los Angeles Times data files. Espresso
extracted 1,468 part-of instances and 1,129 cau-
sation instances. We manually validated the out-
put and randomly selected 200 correct relation
instances of each relation for ontologizing into
WordNet 2.0.
</bodyText>
<subsectionHeader confidence="0.792484">
Gold Standard
</subsectionHeader>
<bodyText confidence="0.999943181818182">
We manually built a gold standard of all correct
attachments of the test sets in WordNet. For each
relation instance (x, r, y), two human annotators
selected from all sense permutations of x and y
the correct attachment points in WordNet. For
example, for (synthetic material, PART-OF, filter),
the judges selected the following attachment
points: (synthetic material#1, PART-OF, filter#1)
and (synthetic material#1, PART-OF, filter#2). The
kappa statistic (Siegel and Castellan Jr. 1988) on
the two relations together was Κ = 0.73.
</bodyText>
<subsectionHeader confidence="0.512734">
Systems
</subsectionHeader>
<bodyText confidence="0.990773">
The following three systems are evaluated:
</bodyText>
<listItem confidence="0.991500571428572">
• BL: the baseline system that attaches each rela-
tion instance to the first (most common)
WordNet sense of both terms;
• AN: the anchor approach described in Section
3.1.
• CL: the clustering approach described in Sec-
tion 3.2.
</listItem>
<table confidence="0.99952925">
SYSTEM PRECISION RECALL F-SCORE
BL 45.0% 25.0% 32.1%
AN 41.7% 32.4% 36.5%
CL 40.0% 32.6% 35.9%
</table>
<tableCaption confidence="0.9585075">
Table 2. System precision, recall and F-score on
the causation relation.
</tableCaption>
<subsectionHeader confidence="0.997601">
4.2 Precision, Recall and F-score
</subsectionHeader>
<bodyText confidence="0.99997325">
For both the part-of and causation relations, we
apply the three systems described above and
compare their attachment performance using pre-
cision, recall, and F-score. Using the manually
built gold standard, the precision of a system on a
given relation instance is measured as the per-
centage of correct attachments and recall is
measured as the percentage of correct attach-
ments retrieved by the system. Overall system
precision and recall are then computed by aver-
aging the precision and recall of each relation
instance.
Table 1 and Table 2 report the results on the
part-of and causation relations. We experimen-
tally set the CL generalization parameter τ2 to 5
and the τ1 parameter for AN to 0.02.
</bodyText>
<subsectionHeader confidence="0.978281">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.9999498">
For both relations, CL and AN outperform the
baseline in overall F-score. For part-of, Table 1
shows that CL outperforms BL by 13.6% in F-
score and AN by 9.4%. For causation, Table 2
shows that AN outperforms BL by 4.4% on F-
score and CL by 0.6%.
The good results of the CL method on the
part-of relation suggest that instances of this rela-
tion are particularly amenable to be clustered.
The generality of the part-of relation in fact al-
lows the creation of fairly natural clusters, corre-
sponding to different sub-types of part-of, as
those proposed in (Winston 1983). The causation
relation, however, being more difficult to define
at a semantic level (Girju 2003), is less easy to
cluster and thus to disambiguate.
Both CL and AN have better recall than BL,
but precision results vary with CL beating BL
only on the part-of relation. Overall, the system
performances suggest that ontologizing semantic
relations into WordNet is in general not easy.
The better results of CL and AN with respect
to BL suggest that the use of comparative seman-
tic analysis among corpus instances is a good
way to carry out disambiguation. Yet, the BL
</bodyText>
<page confidence="0.992435">
797
</page>
<bodyText confidence="0.9999655">
method shows surprisingly good results. This
indicates that also a simple method based on
word sense usage in language can be valuable.
An interesting avenue of future work is to better
combine these two different views in a single
system.
The low recall results for CL are mostly at-
tributed to the fact that in Phase 2 only the best
scoring cluster is retained for each instance. This
means that instances with multiple senses that do
not have a common generalization are not cap-
tured. For example the part-of instance (wings,
PART-OF, chicken) should cluster both in
[body_part#1, PART-OF, animal#1] and
[body_part#1, PART-OF, food#2], but only the
best scoring one is retained.
</bodyText>
<sectionHeader confidence="0.995362" genericHeader="method">
5 Conceptual Instances: Other Uses
</sectionHeader>
<bodyText confidence="0.999848090909091">
Our clustering approach from Section 3.2 is en-
abled by learning conceptual instances – relations
between mid-level ontological concepts. Beyond
the ontologizing task, conceptual instances may
be useful for several other tasks. In this section,
we discuss some of these opportunities and pre-
sent small qualitative evaluations.
Conceptual instances represent common se-
mantic generalizations of a particular relation.
For example, below are two possible conceptual
instances for the part-of relation:
</bodyText>
<equation confidence="0.743297">
[person#1, PART-OF, organization#1]
[act#1, PART-OF, plan#1]
</equation>
<bodyText confidence="0.997218333333333">
The first conceptual instance in the example sub-
sumes all the part-of instances in which one or
more persons are part of an organization, such as:
</bodyText>
<construct confidence="0.88888375">
(president Brown, PART-OF, executive council)
(representatives, PART-OF, organization)
(students, PART-OF, orchestra)
(players, PART-OF, Metro League)
</construct>
<bodyText confidence="0.999874">
Below, we present three possible ways of ex-
ploiting these conceptual instances.
</bodyText>
<subsectionHeader confidence="0.912862">
Support to Relation Extraction Tools
</subsectionHeader>
<bodyText confidence="0.982300807692308">
Conceptual instances may be used to support re-
lation extraction algorithms such as Espresso.
Most minimally supervised harvesting algo-
rithm do not exploit generic patterns, i.e. those
patterns with high recall but low precision, since
they cannot separate correct and incorrect rela-
tion instances. For example, the pattern “X of Y”
extracts many correct relation instances like
“wheel of the car” but also many incorrect ones
like “house of representatives”.
Girju et al. (2003) described a highly super-
vised algorithm for learning semantic constraints
on generic patterns, leading to a very significant
increase in system recall without deteriorating
precision. Conceptual instances can be used to
automatically learn such semantic constraints by
acting as a filter for generic patterns, retaining
only those instances that are subsumed by high
scoring conceptual instances. Effectively, con-
ceptual instances are used as selectional restric-
tions for the relation. For example, our system
discards the following incorrect instances:
(week, CAUSE, coalition)
(demeanor, CAUSE, vacuum)
as they are both part of the very low scoring con-
ceptual instance [abstraction#6, CAUSE, state#1].
</bodyText>
<subsectionHeader confidence="0.909695">
Ontology Learning from Text
</subsectionHeader>
<bodyText confidence="0.99998795">
Each conceptual instance can be viewed as a
formal specification of the relation at hand. For
example, Winston (1983) manually identified six
sub-types of the part-of relation: member-
collection, component-integral object, portion-
mass, stuff-object, feature-activity and place-
area. Such classifications are useful in applica-
tions and tasks where a semantically rich organi-
zation of knowledge is required. Conceptual
instances can be viewed as an automatic deriva-
tion of such a classification based on corpus us-
age. Moreover, conceptual instances can be used
to improve the ontology learning process itself.
For example, our clustering approach can be
seen as an inductive step producing conceptual
instances that are then used in a deductive step to
learn new instances. An algorithm could iterate
between the induction/deduction cycle until no
new relation instances and conceptual instances
can be inferred.
</bodyText>
<subsectionHeader confidence="0.947323">
Word Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.954496714285714">
Word Sense Disambiguation (WSD) systems can
exploit the selectional restrictions identified by
conceptual instances to disambiguate ambiguous
terms occurring in particular contexts. For exam-
ple, given the sentence:
“the board is composed by members of different countries”
and a harvesting algorithm that extracts the part-
of relation (members, PART-OF, board), the sys-
tem could infer the correct senses for board and
members by looking at their closest conceptual
instance. In our system, we would infer the at-
tachment (member#1, PART-OF, board#1) since it
is part of the highest scoring conceptual instance
[person#1, PART-OF, organization#1].
</bodyText>
<page confidence="0.991043">
798
</page>
<table confidence="0.9988395">
CONCEPTUAL INSTANCE SCORE # INSTANCES INSTANCES
[multitude#3, PART-OF, group#1] 2.04 10 (ordinary people, PART-OF, Democratic Revolutionary Party)
(unlicensed people, PART-OF, underground economy)
(young people, PART-OF, commission)
(air mass, PART-OF, cold front)
[person#1, PART-OF, organization#1] 1.71 43 (foreign ministers, PART-OF, council)
(students, PART-OF, orchestra)
(socialists, PART-OF, Iraqi National Joint Action Committee)
(players, PART-OF, Metro League)
[act#2, PART-OF, plan#1] 1.60 16 (major concessions, PART-OF, new plan)
(attacks, PART-OF, coordinated terrorist plan)
(visit, PART-OF, exchange program)
(survey, PART-OF, project)
[communication#2, PART-OF, book#1] 1.14 10 (hints, PART-OF, booklet)
(soup recipes, PART-OF, book)
(information, PART-OF, instruction manual)
(extensive expert analysis, PART-OF, book)
[compound#2, PART-OF, waste#1] 0.57 3 (salts, PART-OF, powdery white waste)
(lime, PART-OF, powdery white waste)
(resin, PART-OF, waste)
</table>
<tableCaption confidence="0.986028">
Table 3. Sample of the highest scoring conceptual instances learned for the part-of relation. For each
conceptual instance, we report the score(c), the number of instances, and some example instances.
</tableCaption>
<subsectionHeader confidence="0.9542">
5.1 Qualitative Evaluation
</subsectionHeader>
<bodyText confidence="0.982316591836735">
Table 3 and Table 4 list samples of the highest
ranking conceptual instances obtained by our
system for the part-of and causation relations.
Below we provide a small evaluation to verify:
• the correctness of the conceptual instances.
Incorrect conceptual instances such as [attrib-
ute#2, CAUSE, state#4], discovered by our sys-
tem, can impede WSD and extraction tools
where precise selectional restrictions are
needed; and
• the accuracy of the conceptual instances.
Sometimes, an instance is incorrectly attached
to a correct conceptual instance. For example,
the instance (air mass, PART-OF, cold front) is
incorrectly clustered in [group#1, PART-OF,
multitude#3] since mass and front both have a
sense that is descendant of group#1 and multi-
tude#3. However, these are not the correct
senses of mass and front for which the part-of
relation holds.
For evaluating correctness, we manually ver-
ify how many correct conceptual instances are
produced by Phase 2 of the clustering approach
described in Section 3.2. The claim is that a cor-
rect conceptual instance is one for which the re-
lation holds for all possible subsumed senses. For
example, the conceptual instance [group#1,
PART-OF, multitude#3] is correct, as the relation
holds for every semantic subsumption of the two
senses. An example of an incorrect conceptual
instance is [state#4, CAUSE, abstraction#6] since
it subsumes the incorrect instance (audience,
CAUSE, new context). A manual evaluation of the
highest scoring 200 conceptual instances, gener-
ated on our test sets described in Section 4.1,
showed 82% correctness for the part-of relation
and 86% for causation.
For estimating the overall clustering accuracy,
we evaluated the number of correctly clustered
instances in each conceptual instance. For exam-
ple, the instance (business people, PART-OF,
committee) is correctly clustered in [multitude#3,
PART-OF, group#1] and the instance (law, PART-
OF, constitutional pitfalls) is incorrectly clustered
in [group#1, PART-OF, artifact#1]. We estimated
the overall accuracy by manually judging the
instances attached to 10 randomly sampled con-
ceptual instances. The accuracy for part-of is
84% and for causation it is 76.6%.
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999673571428571">
In this paper, we proposed two algorithms for
automatically ontologizing binary semantic rela-
tions into WordNet: an anchoring approach and
a clustering approach. Experiments on the part-
of and causation relations showed promising re-
sults. Both algorithms outperformed the baseline
on F-score. Our best results were on the part-of
relation where the clustering approach achieved
13.6% higher F-score than the baseline.
The induction of conceptual instances has
opened the way for many avenues of future
work. We intend to pursue the ideas presented in
Section 5 for using conceptual instances to:
i) support knowledge acquisition tools by learn-
ing semantic constraints on extracting patterns;
ii) support ontology learning from text; and iii)
improve word sense disambiguation through se-
lectional restrictions. Also, we will try different
similarity score functions for both the clustering
and the anchor approaches, as those surveyed in
Corley and Mihalcea (2005).
</bodyText>
<page confidence="0.997161">
799
</page>
<table confidence="0.998417235294118">
CONCEPTUAL INSTANCE SCORE # INSTANCES INSTANCES
[change#3, CAUSE, state#4] 1.49 17 (separation, CAUSE, anxiety)
(demotion, CAUSE, roster vacancy)
(budget cuts, CAUSE, enrollment declines)
(reduced flow, CAUSE, vacuum)
[act#2, CAUSE, state#3] 0.81 20 (oil drilling, CAUSE, air pollution)
(workplace exposure, CAUSE, genetic injury)
(industrial emissions, CAUSE, air pollution)
(long recovery, CAUSE, great stress)
[person#], CAUSE, act#2] 0.64 12 (homeowners, CAUSE, water waste)
(needlelike puncture, CAUSE, physician)
(group member, CAUSE, controversy)
(children, CAUSE, property damage)
[organism#], CAUSE, disease#]] 0.03 4 (parasites, CAUSE, pneumonia)
(virus, CAUSE, influenza)
(chemical agents, CAUSE, pneumonia)
(genetic mutation, CAUSE, Dwarfism)
</table>
<tableCaption confidence="0.8894785">
Table 4. Sample of the highest scoring conceptual instances learned for the causation relation. For
each conceptual instance, we report score(c) , the number of instances, and some example instances.
</tableCaption>
<bodyText confidence="0.999699818181818">
The algorithms described in this paper may be
applied to ontologize many lexical resources of
semantic relations, no matter the harvesting algo-
rithm used to mine them. In doing so, we have
the potential to quickly enrich our ontologies,
like WordNet, thus reducing the knowledge ac-
quisition bottleneck. It is our hope that we will be
able to leverage these enriched resources, albeit
with some noisy additions, to improve perform-
ance on knowledge-rich problems such as ques-
tion answering and textual entailment.
</bodyText>
<sectionHeader confidence="0.999082" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999852833333334">
Agirre, E. and Rigau, G. 1996. Word sense
disambiguation using conceptual density. In
Proceedings of COLING-96. pp. 16-22. Copenhagen,
Danmark.
Agirre, E.; Ansa, O.; Martinez, D.; and Hovy, E. 2001.
Enriching WordNet concepts with topic signatures. In
Proceedings of NAACL Workshop on WordNet and
Other Lexical Resources: Applications, Extensions
and Customizations. Pittsburgh, PA.
Basili, R.; Pazienza, M.T.; and Vindigni, M. 2000.
Corpus-driven learning of event recognition rules. In
Proceedings of Workshop on Machine Learning and
Information Extraction (ECAI-00).
Corley, C. and Mihalcea, R. 2005. Measuring the
Semantic Similarity of Texts. In Proceedings of the
ACL Workshop on Empirical Modelling of Semantic
Equivalence and Entailment. Ann Arbor, MI.
Etzioni, O.; Cafarella, M.J.; Downey, D.; Popescu, A.-
M.; Shaked, T.; Soderland, S.; Weld, D.S.; and Yates,
A. 2005. Unsupervised named-entity extraction from
the Web: An experimental study. Artificial
Intelligence, 165(1): 91-134.
Fellbaum, C. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
Gale, W.; Church, K.; and Yarowsky, D. 1992. A
method for disambiguating word senses in a large
corpus. Computers and Humanities, 26:415-439.
Girju, R.; Badulescu, A.; and Moldovan, D. 2003.
Learning semantic constraints for the automatic
discovery of part-whole relations. In Proceedings of
HLT/NAACL-03. pp. 80-87. Edmonton, Canada.
Girju, R. 2003. Automatic Detection of Causal Relations
for Question Answering. In Proceedings of ACL
Workshop on Multilingual Summarization and
Question Answering. Sapporo, Japan.
Harabagiu, S.; Miller, G.; and Moldovan, D. 1999.
WordNet 2 - A Morphologically and Semantically
Enhanced Resource. In Proceedings of SIGLEX-99.
pp.1-8. University of Maryland.
Harris, Z. 1985. Distributional structure. In: Katz, J. J.
(ed.) The Philosophy of Linguistics. New York:
Oxford University Press. pp. 26–47.
Hindle, D. 1990. Noun classification from predicate-
argument structures. In Proceedings of ACL-90. pp.
268–275. Pittsburgh, PA.
Lin, D. and Pantel, P. 2002. Concept discovery from text.
In Proceedings of COLING-02. pp. 577-583. Taipei,
Taiwan.
Pantel, P. 2005. Inducing Ontological Co-occurrence
Vectors. In Proceedings of ACL-05. pp. 125-132. Ann
Arbor, MI.
Ravichandran, D. and Hovy, E.H. 2002. Learning surface
text patterns for a question answering system. In
Proceedings of ACL-2002. pp. 41-47. Philadelphia,
PA.
Riloff, E. and Shepherd, J. 1997. A corpus-based
approach for building semantic lexicons. In
Proceedings of EMNLP-97.
Siegel, S. and Castellan Jr., N. J. 1988. Nonparametric
Statistics for the Behavioral Sciences. McGraw-Hill.
Szpektor, I.; Tanev, H.; Dagan, I.; and Coppola, B. 2004.
Scaling web-based acquisition of entailment relations.
In Proceedings of EMNLP-04. Barcelona, Spain.
Winston, M.; Chaffin, R.; and Hermann, D. 1987. A
taxonomy of part-whole relations. Cognitive Science,
11:417–444.
</reference>
<page confidence="0.996987">
800
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.835533">
<title confidence="0.999955">Ontologizing Semantic Relations</title>
<author confidence="0.999963">Marco Pennacchiotti</author>
<affiliation confidence="0.9852835">ART Group - DISP University of Rome “Tor Vergata”</affiliation>
<address confidence="0.9504615">Viale del Politecnico 1 Rome, Italy</address>
<email confidence="0.988603">pennacchiotti@info.uniroma2.it</email>
<abstract confidence="0.996595307692308">Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical on the task of attaching partshowing an on over a baseline model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>G Rigau</author>
</authors>
<title>Word sense disambiguation using conceptual density.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING-96.</booktitle>
<pages>16--22</pages>
<location>Copenhagen, Danmark.</location>
<contexts>
<context position="5439" citStr="Agirre and Rigau 1996" startWordPosition="845" endWordPosition="848">term/synset. An unknown term is then attached to the WordNet synset whose cooccurrence vector is most similar to the term’s co-occurrence vector. Though the author suggests a method for attaching more complex lexical structures like binary semantic relations, the paper focused only on attaching terms. Basili (2000) proposed an unsupervised method to infer semantic classes (WordNet synsets) for terms in domain-specific verb relations. These relations, such as (x, EXPAND, y) are first automatically learnt from a corpus. The semantic classes of x and y are then inferred using conceptual density (Agirre and Rigau 1996), a WordNet-based measure applied to all instantiation of x and y in the corpus. Semantic classes represent possible common generalizations of the verb arguments. At the end of the process, a set of syntactic-semantic patterns are available for each verb, such as: (social_group#1, expand, act#2) (instrumentality#2, expand, act#2) The method is successful on specific relations with few instances (such as domain verb relations) while its value on generic and frequent relations, such as part-of, was untested. Girju et al. (2003) presented a highly supervised machine learning algorithm to infer se</context>
</contexts>
<marker>Agirre, Rigau, 1996</marker>
<rawString>Agirre, E. and Rigau, G. 1996. Word sense disambiguation using conceptual density. In Proceedings of COLING-96. pp. 16-22. Copenhagen, Danmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Ansa</author>
<author>D Martinez</author>
<author>E Hovy</author>
</authors>
<title>Enriching WordNet concepts with topic signatures.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="6764" citStr="Agirre et al. 2001" startWordPosition="1048" endWordPosition="1051">e then used as selectional restrictions in harvesting part-of instances from ambiguous lexical patterns, like “X of Y”. The approach shows high performance in terms of precision and recall, but, as the authors acknowledge, it requires large human effort during the training phase. Others have also made significant additions to WordNet. For example, in eXtended WordNet (Harabagiu et al. 1999), the glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets. Another work has enriched WordNet synsets with topically related words extracted from the Web (Agirre et al. 2001). Finally, the general task of word sense disambiguation (Gale et al. 1991) is relevant since there the task is to ontologize each term in a passage into a WordNet-like sense inventory. If we had a large collection of sensetagged text, then our mining algorithms could directly discover WordNet attachment points at harvest time. However, since there is little high precision sense-tagged corpora, methods are required to ontologize semantic resources without fully disambiguating text. 3 Ontologizing Semantic Relations Given an instance (x, r, y) of a binary relation r between terms x and y, the o</context>
</contexts>
<marker>Agirre, Ansa, Martinez, Hovy, 2001</marker>
<rawString>Agirre, E.; Ansa, O.; Martinez, D.; and Hovy, E. 2001. Enriching WordNet concepts with topic signatures. In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>M Vindigni</author>
</authors>
<title>Corpus-driven learning of event recognition rules.</title>
<date>2000</date>
<booktitle>In Proceedings of Workshop on Machine Learning and Information Extraction (ECAI-00).</booktitle>
<marker>Basili, Pazienza, Vindigni, 2000</marker>
<rawString>Basili, R.; Pazienza, M.T.; and Vindigni, M. 2000. Corpus-driven learning of event recognition rules. In Proceedings of Workshop on Machine Learning and Information Extraction (ECAI-00).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Corley</author>
<author>R Mihalcea</author>
</authors>
<title>Measuring the Semantic Similarity of Texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Empirical Modelling of Semantic Equivalence and Entailment.</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="30009" citStr="Corley and Mihalcea (2005)" startWordPosition="4747" endWordPosition="4750">n where the clustering approach achieved 13.6% higher F-score than the baseline. The induction of conceptual instances has opened the way for many avenues of future work. We intend to pursue the ideas presented in Section 5 for using conceptual instances to: i) support knowledge acquisition tools by learning semantic constraints on extracting patterns; ii) support ontology learning from text; and iii) improve word sense disambiguation through selectional restrictions. Also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in Corley and Mihalcea (2005). 799 CONCEPTUAL INSTANCE SCORE # INSTANCES INSTANCES [change#3, CAUSE, state#4] 1.49 17 (separation, CAUSE, anxiety) (demotion, CAUSE, roster vacancy) (budget cuts, CAUSE, enrollment declines) (reduced flow, CAUSE, vacuum) [act#2, CAUSE, state#3] 0.81 20 (oil drilling, CAUSE, air pollution) (workplace exposure, CAUSE, genetic injury) (industrial emissions, CAUSE, air pollution) (long recovery, CAUSE, great stress) [person#], CAUSE, act#2] 0.64 12 (homeowners, CAUSE, water waste) (needlelike puncture, CAUSE, physician) (group member, CAUSE, controversy) (children, CAUSE, property damage) [orga</context>
</contexts>
<marker>Corley, Mihalcea, 2005</marker>
<rawString>Corley, C. and Mihalcea, R. 2005. Measuring the Semantic Similarity of Texts. In Proceedings of the ACL Workshop on Empirical Modelling of Semantic Equivalence and Entailment. Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M J Cafarella</author>
<author>D Downey</author>
<author>A-M Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D S Weld</author>
<author>A Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the Web: An experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<pages>91--134</pages>
<contexts>
<context position="742" citStr="Etzioni et al. 2005" startWordPosition="103" endWordPosition="106">o 1 Rome, Italy pennacchiotti@info.uniroma2.it Abstract Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be lin</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Etzioni, O.; Cafarella, M.J.; Downey, D.; Popescu, A.-M.; Shaked, T.; Soderland, S.; Weld, D.S.; and Yates, A. 2005. Unsupervised named-entity extraction from the Web: An experimental study. Artificial Intelligence, 165(1): 91-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1441" citStr="Fellbaum 1998" startWordPosition="214" endWordPosition="215">and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy. For example, “orange similar-to blue” ontologizes in WordNet to “orange#2 similar-to blue#1” and “orange#2 similar-to blue#2”. In his framework, Patrick Pantel Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA90292 pantel@isi.edu Pantel proposed a method of inducing ontological co-occurrence vectors 1 which are subsequently used to ontologize unknown terms into WordNet with 74% accuracy. In this paper</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus. Computers and Humanities,</title>
<date>1992</date>
<pages>26--415</pages>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, W.; Church, K.; and Yarowsky, D. 1992. A method for disambiguating word senses in a large corpus. Computers and Humanities, 26:415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Girju</author>
<author>A Badulescu</author>
<author>D Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/NAACL-03.</booktitle>
<pages>80--87</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1070" citStr="Girju et al. 2003" startWordPosition="155" endWordPosition="158"> present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy. For example, “orange similar-to blue” ontologizes in WordNet to “orange#2 similar-to b</context>
<context position="5970" citStr="Girju et al. (2003)" startWordPosition="929" endWordPosition="932">ic classes of x and y are then inferred using conceptual density (Agirre and Rigau 1996), a WordNet-based measure applied to all instantiation of x and y in the corpus. Semantic classes represent possible common generalizations of the verb arguments. At the end of the process, a set of syntactic-semantic patterns are available for each verb, such as: (social_group#1, expand, act#2) (instrumentality#2, expand, act#2) The method is successful on specific relations with few instances (such as domain verb relations) while its value on generic and frequent relations, such as part-of, was untested. Girju et al. (2003) presented a highly supervised machine learning algorithm to infer semantic constraints on part-of relations, such as (object#1, PART-OF, social_event#1). These constraints are then used as selectional restrictions in harvesting part-of instances from ambiguous lexical patterns, like “X of Y”. The approach shows high performance in terms of precision and recall, but, as the authors acknowledge, it requires large human effort during the training phase. Others have also made significant additions to WordNet. For example, in eXtended WordNet (Harabagiu et al. 1999), the glosses in WordNet are enr</context>
<context position="23326" citStr="Girju et al. (2003)" startWordPosition="3784" endWordPosition="3787"> PART-OF, Metro League) Below, we present three possible ways of exploiting these conceptual instances. Support to Relation Extraction Tools Conceptual instances may be used to support relation extraction algorithms such as Espresso. Most minimally supervised harvesting algorithm do not exploit generic patterns, i.e. those patterns with high recall but low precision, since they cannot separate correct and incorrect relation instances. For example, the pattern “X of Y” extracts many correct relation instances like “wheel of the car” but also many incorrect ones like “house of representatives”. Girju et al. (2003) described a highly supervised algorithm for learning semantic constraints on generic patterns, leading to a very significant increase in system recall without deteriorating precision. Conceptual instances can be used to automatically learn such semantic constraints by acting as a filter for generic patterns, retaining only those instances that are subsumed by high scoring conceptual instances. Effectively, conceptual instances are used as selectional restrictions for the relation. For example, our system discards the following incorrect instances: (week, CAUSE, coalition) (demeanor, CAUSE, va</context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Girju, R.; Badulescu, A.; and Moldovan, D. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proceedings of HLT/NAACL-03. pp. 80-87. Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Girju</author>
</authors>
<title>Automatic Detection of Causal Relations for Question Answering.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL Workshop on Multilingual Summarization and Question Answering.</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="20685" citStr="Girju 2003" startWordPosition="3379" endWordPosition="3380">e in overall F-score. For part-of, Table 1 shows that CL outperforms BL by 13.6% in Fscore and AN by 9.4%. For causation, Table 2 shows that AN outperforms BL by 4.4% on Fscore and CL by 0.6%. The good results of the CL method on the part-of relation suggest that instances of this relation are particularly amenable to be clustered. The generality of the part-of relation in fact allows the creation of fairly natural clusters, corresponding to different sub-types of part-of, as those proposed in (Winston 1983). The causation relation, however, being more difficult to define at a semantic level (Girju 2003), is less easy to cluster and thus to disambiguate. Both CL and AN have better recall than BL, but precision results vary with CL beating BL only on the part-of relation. Overall, the system performances suggest that ontologizing semantic relations into WordNet is in general not easy. The better results of CL and AN with respect to BL suggest that the use of comparative semantic analysis among corpus instances is a good way to carry out disambiguation. Yet, the BL 797 method shows surprisingly good results. This indicates that also a simple method based on word sense usage in language can be v</context>
</contexts>
<marker>Girju, 2003</marker>
<rawString>Girju, R. 2003. Automatic Detection of Causal Relations for Question Answering. In Proceedings of ACL Workshop on Multilingual Summarization and Question Answering. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>G Miller</author>
<author>D Moldovan</author>
</authors>
<title>WordNet 2 - A Morphologically and Semantically Enhanced Resource.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGLEX-99.</booktitle>
<pages>1--8</pages>
<institution>University of Maryland.</institution>
<contexts>
<context position="6538" citStr="Harabagiu et al. 1999" startWordPosition="1013" endWordPosition="1016">ns, such as part-of, was untested. Girju et al. (2003) presented a highly supervised machine learning algorithm to infer semantic constraints on part-of relations, such as (object#1, PART-OF, social_event#1). These constraints are then used as selectional restrictions in harvesting part-of instances from ambiguous lexical patterns, like “X of Y”. The approach shows high performance in terms of precision and recall, but, as the authors acknowledge, it requires large human effort during the training phase. Others have also made significant additions to WordNet. For example, in eXtended WordNet (Harabagiu et al. 1999), the glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets. Another work has enriched WordNet synsets with topically related words extracted from the Web (Agirre et al. 2001). Finally, the general task of word sense disambiguation (Gale et al. 1991) is relevant since there the task is to ontologize each term in a passage into a WordNet-like sense inventory. If we had a large collection of sensetagged text, then our mining algorithms could directly discover WordNet attachment points at harvest time. However, since there is little high precisio</context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>Harabagiu, S.; Miller, G.; and Moldovan, D. 1999. WordNet 2 - A Morphologically and Semantically Enhanced Resource. In Proceedings of SIGLEX-99. pp.1-8. University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1985</date>
<booktitle>The Philosophy of Linguistics.</booktitle>
<pages>26--47</pages>
<editor>In: Katz, J. J. (ed.)</editor>
<publisher>University Press.</publisher>
<location>New York: Oxford</location>
<contexts>
<context position="4712" citStr="Harris 1985" startWordPosition="734" endWordPosition="735">eneralizing a set of relation instances to conceptual instances by looking up the WordNet hypernymy hierarchy for common ancestors, as specific as possible, that subsume as many instances as possible. An instance is then attached to its senses that are subsumed by the highest scoring conceptual instances. 2 Relevant Work Several researchers have worked on ontologizing semantic resources. Most recently, Pantel (2005) developed a method to propagate lexical cooccurrence vectors to WordNet synsets, forming ontological co-occurrence vectors. Adopting an extension of the distributional hypothesis (Harris 1985), the co-occurrence vectors are used to compute the similarity between synset/synset and between lexical term/synset. An unknown term is then attached to the WordNet synset whose cooccurrence vector is most similar to the term’s co-occurrence vector. Though the author suggests a method for attaching more complex lexical structures like binary semantic relations, the paper focused only on attaching terms. Basili (2000) proposed an unsupervised method to infer semantic classes (WordNet synsets) for terms in domain-specific verb relations. These relations, such as (x, EXPAND, y) are first automat</context>
<context position="9204" citStr="Harris 1985" startWordPosition="1470" endWordPosition="1471"> an entity that is part-of a study has to be some kind of informa794 tion. This knowledge about mutual selectional preference (the preferred semantic class that fills a certain relation role, as x or y) can be exploited to ontologize the instance. In the following sections, we propose two algorithms for ontologizing binary semantic relations. 3.1 Method 1: Anchor Approach Given an instance (x, r, y), this approach fixes the term y, called the anchor, and then disambiguates x by looking at all other terms that occur in the relation r with y. Based on the principle of distributional similarity (Harris 1985), the algorithm assumes that the words that occur in the same relation r with y will be more similar to the correct sense(s) of x than the incorrect ones. After disambiguating x, the process is then inverted with x as the anchor to disambiguate y. In the first step, y is fixed and the algorithm retrieves the set of all other terms X&apos; that occur in an instance (x&apos;, r, y), x&apos; E X&apos;2. For example, given the instance (reflections, PART-OF, book), and a resource containing the following relations: (false allegations, PART-OF, book) (stories, PART-OF, book) (expert analysis, PART-OF, book) (conclusio</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Harris, Z. 1985. Distributional structure. In: Katz, J. J. (ed.) The Philosophy of Linguistics. New York: Oxford University Press. pp. 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Noun classification from predicateargument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of ACL-90.</booktitle>
<pages>268--275</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="866" citStr="Hindle 1990" startWordPosition="124" endWordPosition="125">owever few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined t</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, D. 1990. Noun classification from predicateargument structures. In Proceedings of ACL-90. pp. 268–275. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-02.</booktitle>
<pages>577--583</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="825" citStr="Lin and Pantel 2002" startWordPosition="116" endWordPosition="119">eveloped to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Lin, D. and Pantel, P. 2002. Concept discovery from text. In Proceedings of COLING-02. pp. 577-583. Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
</authors>
<title>Inducing Ontological Co-occurrence Vectors.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05.</booktitle>
<pages>125--132</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="1456" citStr="Pantel (2005)" startWordPosition="216" endWordPosition="217">ity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy. For example, “orange similar-to blue” ontologizes in WordNet to “orange#2 similar-to blue#1” and “orange#2 similar-to blue#2”. In his framework, Patrick Pantel Information Sciences Institute University of Southern California 4676 Admiralty Way Marina del Rey, CA90292 pantel@isi.edu Pantel proposed a method of inducing ontological co-occurrence vectors 1 which are subsequently used to ontologize unknown terms into WordNet with 74% accuracy. In this paper, we take the n</context>
<context position="4519" citStr="Pantel (2005)" startWordPosition="709" endWordPosition="710">s and 44th Annual Meeting of the ACL, pages 793–800, Sydney, July 2006. c�2006 Association for Computational Linguistics ceptual instances. In this paper, we develop a clustering algorithm for generalizing a set of relation instances to conceptual instances by looking up the WordNet hypernymy hierarchy for common ancestors, as specific as possible, that subsume as many instances as possible. An instance is then attached to its senses that are subsumed by the highest scoring conceptual instances. 2 Relevant Work Several researchers have worked on ontologizing semantic resources. Most recently, Pantel (2005) developed a method to propagate lexical cooccurrence vectors to WordNet synsets, forming ontological co-occurrence vectors. Adopting an extension of the distributional hypothesis (Harris 1985), the co-occurrence vectors are used to compute the similarity between synset/synset and between lexical term/synset. An unknown term is then attached to the WordNet synset whose cooccurrence vector is most similar to the term’s co-occurrence vector. Though the author suggests a method for attaching more complex lexical structures like binary semantic relations, the paper focused only on attaching terms.</context>
</contexts>
<marker>Pantel, 2005</marker>
<rawString>Pantel, P. 2005. Inducing Ontological Co-occurrence Vectors. In Proceedings of ACL-05. pp. 125-132. Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ravichandran</author>
<author>E H Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-2002.</booktitle>
<pages>41--47</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1041" citStr="Ravichandran and Hovy 2002" startWordPosition="149" endWordPosition="153">g) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy. For example, “orange similar-to blue” ontologizes in Word</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Ravichandran, D. and Hovy, E.H. 2002. Learning surface text patterns for a question answering system. In Proceedings of ACL-2002. pp. 41-47. Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Shepherd</author>
</authors>
<title>A corpus-based approach for building semantic lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of EMNLP-97.</booktitle>
<contexts>
<context position="788" citStr="Riloff and Shepherd 1997" startWordPosition="110" endWordPosition="113">a2.it Abstract Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as </context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Riloff, E. and Shepherd, J. 1997. A corpus-based approach for building semantic lexicons. In Proceedings of EMNLP-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>Castellan Jr</author>
<author>N J</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGraw-Hill.</publisher>
<marker>Siegel, Jr, J, 1988</marker>
<rawString>Siegel, S. and Castellan Jr., N. J. 1988. Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Szpektor</author>
<author>H Tanev</author>
<author>I Dagan</author>
<author>B Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP-04.</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1006" citStr="Szpektor et al. 2004" startWordPosition="144" endWordPosition="147">ically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching partof and causation relations, showing an improvement on F-score over a baseline model. 1 Introduction NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al. 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990). Many recent efforts have also focused on extracting binary semantic relations between entities, such as entailments (Szpektor et al. 2004), is-a (Ravichandran and Hovy 2002), part-of (Girju et al. 2003), and other relations. The output of most of these systems is flat lists of lexical semantic knowledge such as “Italy is-a country” and “orange similar-to blue”. However, using this knowledge beyond simple keyword matching, for example in inferences, requires it to be linked into formal semantic repositories such as ontologies or term banks like WordNet (Fellbaum 1998). Pantel (2005) defined the task of ontologizing a lexical semantic resource as linking its terms to the concepts in a WordNet-like hierarchy. For example, “orange s</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Szpektor, I.; Tanev, H.; Dagan, I.; and Coppola, B. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of EMNLP-04. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Winston</author>
<author>R Chaffin</author>
<author>D Hermann</author>
</authors>
<title>A taxonomy of part-whole relations.</title>
<date>1987</date>
<journal>Cognitive Science,</journal>
<pages>11--417</pages>
<marker>Winston, Chaffin, Hermann, 1987</marker>
<rawString>Winston, M.; Chaffin, R.; and Hermann, D. 1987. A taxonomy of part-whole relations. Cognitive Science, 11:417–444.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>