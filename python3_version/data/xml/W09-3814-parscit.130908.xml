<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002519">
<title confidence="0.99823">
Evaluating Contribution of Deep Syntactic Information
to Shallow Semantic Analysis
</title>
<author confidence="0.986224">
Sumire Uematsu Jun’ichi Tsujii
</author>
<affiliation confidence="0.9931385">
Graduate School of Information Science and Technology
The University of Tokyo
</affiliation>
<email confidence="0.999129">
{uematsu,tsujii}@is.s.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999438">
This paper presents shallow semantic pars-
ing based only on HPSG parses. An
HPSG-FrameNet map was constructed
from a semantically annotated corpus, and
semantic parsing was performed by map-
ping HPSG dependencies to FrameNet re-
lations. The semantic parsing was evalu-
ated in a Senseval-3 task; the results sug-
gested that there is a high contribution of
syntactic information to semantic analysis.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978424242424">
This paper presents semantic parsing based only
on HPSG parses, and examines the contribution of
the syntactic information to semantic analysis.
In computational linguistics, many researchers
have studied the relationship between syntax and
semantics. Its quantitative analysis was formal-
ized as semantic parsing, or semantic role label-
ing, and has attracted the attention of researchers.
Recently, an improvement in the accuracy and
robustness of “deep parsers” has enabled us to di-
rectly map deep syntactic dependencies to seman-
tic relations. Deep parsers are based on linguisti-
cally expressive grammars; e.g. HPSG, LFG, etc,
and less affected by syntactic alternations such as
passivization. Their results are therefore expected
to closely relate to semantic annotations. For ex-
ample, the sentences in figure 1 share the same
set of semantic roles, and the roles have one-to-
one relations to deep syntactic dependencies in the
sentences. However, the results of the deep parsers
are represented in complex structures, shown in
figure 3, and cannot be straightforwardly com-
pared to semantic annotations.
In order to directly map the deep dependencies
to semantic relations, we adapted the corpus anal-
ysis method of (Frank and Semeck´y, 2004) for
the semantic parsing using HPSG parses. We per-
formed the semantic parsing by mapping paths in
HPSG parses to semantic predicate-argument re-
lations. The analysis of the HPSG paths for the
predicate-argument pairs, and the preliminary re-
sult of the semantic parsing indicate the contribu-
tion of syntactic analysis to semantic parsing.
</bodyText>
<sectionHeader confidence="0.999937" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99892">
Besides (Frank and Semeck´y, 2004)’s work, as
mentioned above, there have been several studies
on the relationship between deep syntax and se-
mantic parsing. Although the studies did not focus
on direct mappings between deep syntax and shal-
low semantics, they suggested a strong relation-
ship between the two. (Miyao and Tsujii, 2004)
evaluated the accuracy of an HPSG parser against
PropBank semantic annotations, and showed that
the HPSG dependants correlated with semantic ar-
guments of the PropBank, particularly with “core”
arguments. In (Gildea and Hockenmaier, 2003)
and (Zhang et al., 2008), features from deep parses
were used for semantic parsing, together with fea-
tures from CFG or dependency parses. The deep
features were reported to contribute to a perfor-
mance gain.
</bodyText>
<sectionHeader confidence="0.975513" genericHeader="method">
3 Syntactic and Semantic Parsing
</sectionHeader>
<bodyText confidence="0.990193615384615">
Some semantic relations are easily identified by
using syntactic parsing while others are more diffi-
cult. This section presents easy and difficult cases
in syntax-semantics map construction.
Trivial when using syntactic analysis: Syn-
tactic parsing, including CFG analysis, detects
semantic similarity of sentences sharing similar
phrase structures. For the example sentences a)
and b) in figure 1, the parsing provides similar
phrase structures, and therefore gives the same
syntactic dependency to occurrences of each role.
Trivial when using deep analysis: Deep pars-
ing reveals the semantic similarity of sentences
</bodyText>
<page confidence="0.996829">
85
</page>
<note confidence="0.3615915">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 85–88,
Paris, October 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.9621485">
a) ..., ICommunicator praise themEvaluee for being 99 percent perfectReason. e) ItEvaluee received high praise, ...
b) ..., but heCommunicator praised the Irish premierEvaluee for making a ``sensible’’ speechReason. f) AliceWearer ’s dress
c) The childEvaluee is praised for having a dry bedReason and ... g) Versace’s dress
d) ..., SheCommunicator was supposed, therefore, to praise himEvaluee and then ...
</figure>
<figureCaption confidence="0.950076">
Figure 2: Example phrases
</figureCaption>
<figure confidence="0.578918">
..., HeEl has been particularly p
</figure>
<figureCaption confidence="0.986281">
Figure 1: Sentences with a set of semantic roles for the predicate praise.
</figureCaption>
<figure confidence="0.741544">
e) ItEvaluee received high praise, ... for section 3.
</figure>
<figureCaption confidence="0.999077">
Figure 3: An HPSG parse for The girl likes Mary.
</figureCaption>
<bodyText confidence="0.995522272727273">
containing complex syntactic phenomena, which
is not easily detected by CFG analysis. The sen-
tences c) and d) in figure 1 contain passivization
and object raising, while deep parsing provides
one dependency for each role in the figure.
Not trivial even when using deep analysis:
Some semantic arguments are not direct syntactic
dependants of their predicates - especially of noun
predicates. In sentence e) in figure 2, the Evaluee
phrase depends on the predicate praise, through
the support verb receive. The deep analysis would
be advantageous in capturing such dependencies,
because it provides receive with direct links to the
phrases of the role and the predicate.
Problematic when using only syntactic analy-
sis: Sometimes, the semantic role of a phrase is
strongly dependent on the type of the mentioned
entity, rather than on the syntactic dependency. In
phrases f) and g) in figure 2, the phrases Alice and
Versace, have the same syntactic relation to the
predicate dress. However, the Wearer role is given
only to the former phrase.
</bodyText>
<sectionHeader confidence="0.992043" genericHeader="method">
4 A Wide-Coverage HPSG Parser
</sectionHeader>
<bodyText confidence="0.962552875">
We employed a wide-coverage HPSG parser for
semantic parsing, and used deep syntactic depen-
dencies encoded in a Predicate Argument Struc-
ture (PAS) in each parse node.
In our experiments, the parser results were con-
sidered as graphs, as illustrated by figures 3 and 4,
to extract HPSG dependencies conveniently. The
The girl likes Mary.
</bodyText>
<figureCaption confidence="0.998852">
Figure 4: A simplified representation of figure 3.
</figureCaption>
<bodyText confidence="0.999954333333333">
graph is obtained by ignoring most of the linguis-
tic information in the original parse nodes, and
by adding edges directing to the PAS dependants.
The PAS information is represented in the graph,
by the terminal nodes’ PAS types, e.g. verb arg12,
etc., and by the added edges. Note that the inter-
pretation of the edge labels depends on the PAS
type. If the PAS type is verb arg12, the ARG2 de-
pendant is the object of the transitive verb or its
equivalence (the subject of the passive, etc.). If
the PAS type is prep arg12, then the dependant is
the NP governed by the preposition node.
</bodyText>
<sectionHeader confidence="0.969545" genericHeader="method">
5 Semantic Parsing Based on FrameNet
</sectionHeader>
<bodyText confidence="0.9999804">
We employed FrameNet (FN) as a semantic cor-
pus. Furthermore, we evaluated our semantic pars-
ing on the SRL task data of Senseval-3 (Litkowski,
2004), which consists of FN annotations.
In FN, semantic frames are defined, and each
frame is associated with predicates that evoke the
frame. For instance, the verb and noun praise are
predicates of the Judgment communication frame,
and they share the same set of semantic roles.
The Senseval-3 data is a standard for evaluation
of semantic parsing. The task is defined as identi-
fying phrases and their semantic roles for a given
sentence, predicate, and frame. The data includes
null instantiations of rolesl, which are “conceptu-
ally salient”, but do not appear in the text.
</bodyText>
<sectionHeader confidence="0.998571" genericHeader="method">
6 Methods
</sectionHeader>
<bodyText confidence="0.9969916">
The semantic parsing using an HPSG-FN map
consisted of the processes shown in figure 5.
&apos;An example of a null instantiation is the Communicator
role in the sentence, “All in all the conference was acclaimed
as a considerable success.”
</bodyText>
<figure confidence="0.999685170731707">
likes
Mary
HEAD: 3
CAT
SUBJ: &lt; &gt;
VAL
SYNSEM|LOCAL COMP:&lt; &gt;
CONT|HOOK:
l 6
Head‐Subject schema
Head‐Specifier schema
CAT
1 LOCAL
CONT|HOOK:
HEAD
VAL
SUBJ: &lt; &gt;
noun
CASE: nom
AGR: 3sg
4
&gt;
HEAD: 3
CAT SUBJ: &lt; 1 &gt;
VAL
SYNSEM|LOCAL COMP:&lt; &gt;
CONT|HOOK: 6
Head‐Complement schema
HEAD: det
CAT
VAL |SPEC: &lt; 8 &gt;
7
SYNSEM: LOCAL CONT|HOOK det_arg1
PRED: ÒtheÓ
ARG1: 4
The
8
LOCAL CAT
girl
CONT|HOOK
HEAD
VAL
SUBJ: &lt; &gt;
COMP:&lt; &gt;
SPR: &lt; 7 &gt;
noun
CASE: nom
AGR: 3sg
noun_arg0
4 PRED: “girl”
verb
VFORM: fin
HEAD 3 AUX: none
CAT SUBJ: &lt; 1 &gt;
VAL
SYNSEM|LOCAL COMP:&lt; 2 &gt;
verb_arg12
CONT|HOOK 6 PRED: “like”
4
ARG2: 5
SYNSEM:
2
LOCAL
CAT
CONT|HOOK
HEAD
VAL
noun
CASE: acc
AGR: 3sg
5
&lt; &gt;
&lt; &gt;
noun_arg0
PRED: “Mary”
det_arg1
ARG1
noun_arg0
ARG1
verb_arg12
ARG2
noun_arg0
</figure>
<page confidence="0.717425">
86
</page>
<figureCaption confidence="0.993608">
Figure 5: Processes in the map construction and evaluation.
Figure 6: an HPSG path for a
semantic relation.
</figureCaption>
<figure confidence="0.999803127659575">
Semantic parsing (Map evaluation)
Map construction
Training data
Test data
Semantic annotations
Predicate annotations
Raw sentences
Raw sentences
HPSG
parsing
HPSG
parsing
HPSG parses
HPSG parses
Phrase
projection
Phrase
projection
HPSG parses with
semantically
marked nodes
HPSG parses with
nodes marked as
predicates
HPSG dependency
extraction
Role node
prediction
Map instances
HPSG dependency between
predicate1 and role1
HPSG dependency between
predicate1 and role2
Role prediction rules
HPSG parses with
semantically
marked nodes
Feature filter
It recieved high praise, É
Evaluee role
noun_arg0
ARG1
verb_arg12
ARG2
adj_arg1
ARG1
noun_arg0
</figure>
<figureCaption confidence="0.927324666666667">
Predicate base: The base form of the semantic
predicate word. (praise in the case of figure 6).
Predicate type: The PAS type of the HPSG
</figureCaption>
<bodyText confidence="0.868062214285714">
terminal node for the predicate - see section 4.
(noun arg0 in figure 6).
Intermediate word base: The base form of the
intermediate word, corresponding to a terminal
passed by the path, and satisfying pre-defined
conditions. The word may be a support verb.
- see figure 6. (receive in figure 6).
Intermediate word type: The PAS type of the
intermediate word. (verb arg12 in figure 6).
Dependency label sequence: The labels of
the path’s edges. We omitted labels presenting
head-child relations, for identifying a phrase with
another phrase sharing the same head word.
(Reverse of ARG2, ARG1 in figure 6).
</bodyText>
<tableCaption confidence="0.990796">
Table 1: Features used to represent a HPSG path.
</tableCaption>
<equation confidence="0.6315112">
√ √ √ √ √
Same √ √ √ √
AllInter √ √ √ √
AllPred √ √ √
AllPred-AllInter
</equation>
<tableCaption confidence="0.89674">
Table 2: Syntactic features for role prediction.
</tableCaption>
<bodyText confidence="0.999773592592593">
Phrase projection: Because we used FN anno-
tations, which are independent of any syntactic
framework, role phrases needed to be projected
to appropriate HPSG nodes. We projected the
phrases based on maximal projection, which was
generally employed, with heads defined in the
HPSG.
HPSG dependency extraction: As an HPSG
dependency for a predicate-argument pair, we
used the shortest path between the predicate node
and the argument node in the HPSG parse. The
path was then represented by pre-defined fea-
tures, listed in table 1. The search for the short-
est path was done in the simplified graph of the
HPSG parse (see figure 4), with the edges denot-
ing deep dependencies, and head-child relations.
An instance of the HPSG-FN map consisted of the
path’s features, the FNframe, and the role label.
Role node prediction: The role prediction was
based on simple rules with scores. The rules were
obtained by filtering features of the map instances.
Table 2 shows the feature filters. The score of a
rule was the number of map instances matching
the rule’s features. In the test, for each node of a
HPSG parse, the role label with the highest score
was selected as the result, where the score of a la-
bel was that of the rule providing the label.
</bodyText>
<sectionHeader confidence="0.999799" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.999707666666667">
For the experiments, we employed a wide cover-
age HPSG parser, Enju version 2.3.12, and the data
for the Semantic Role Labeling task of Senseval-3.
</bodyText>
<subsectionHeader confidence="0.999828">
7.1 Analysis of Map Instances
</subsectionHeader>
<bodyText confidence="0.999627357142857">
We extracted 41,193 HPSG-FN map instances
from the training set, the training data apart from
the development set. The instances amounted to
97.7 % (41,193 / 42,163) of all the non-null in-
stantiated roles in the set, and HPSG paths were
short for many instances. Paths to syntactic ar-
guments were almost directly mapped to semantic
roles, while roles for other phrases were more am-
biguous.
The length distribution of HPSG paths: 64 %
(26410 / 41193) of the obtained HPSG paths were
length-one, and 8 % (3390 / 41193) were length-
two, due to the effect of direct links provided by
HPSG parsing. The length of a path was defined
</bodyText>
<footnote confidence="0.909759">
2http://www-tsujii.is.s.u-tokyo.ac.jp/enju/
</footnote>
<figureCaption confidence="0.570788">
Filter Pred. Inter. Dep.
</figureCaption>
<bodyText confidence="0.986334">
base type base type label
</bodyText>
<page confidence="0.996806">
87
</page>
<table confidence="0.966857142857143">
Pred. Freq. Feature representation Interpretation
Verb 3792 verb arg12/–/–/ARG2 The object of the transitive predicate
3191 verb arg12/–/–/ARG1 The subject of the transitive predicate
Noun 7468 noun arg0/–/–/– NP headed by the predicate
1161 noun arg0/of/prep arg12/Rev-ARG1 The PP headed by “of”, attaching to the predicate
Adj 1595 adj arg1/–/–/ARG1 The modifiee of the predicate
274 verb arg12/–/–/ARG2 The modifiee of the predicate treated as a verb
</table>
<tableCaption confidence="0.999313">
Table 3: Most frequent syntactic paths extracted for predicates of each POS.
</tableCaption>
<bodyText confidence="0.999979785714286">
as the number of the labels in the Dep. label seq.
of the path. Most of the one-length paths were
paths directing to syntactic arguments, and to PPs
attaching to the predicates. The two-length paths
included paths using support verbs (see figure 6).
Most frequent HPSG dependencies: The most
frequent paths are shown in table 3; syntactic de-
pendencies are presented and counted as taples of
Pred. type, Inter. base, Inter. type, and Dep.
label seq. The interpretation column describes
the syntactic dependencies for the taples. Note
that the column denotes normalized dependencies,
in which object indicates objects of active voice
verbs, subjects of passive-voiced verbs, etc.
</bodyText>
<subsectionHeader confidence="0.998574">
7.2 Performance of Semantic Parsing
</subsectionHeader>
<bodyText confidence="0.999991538461538">
Finally, semantic parsing was evaluated on the test
data. Table 4 shows the overall performance. The
scores were measured by the Senseval-3 official
script, in the restrictive setting, and can be directly
compared to other systems’ scores. Since our pre-
liminary system of semantic parsing ignored null
instantiations of roles, it lost around 0.10 point
of the recalls. We believe that such instantia-
tions may be separately treated. Although the sys-
tem was based on only the syntactic information,
and was very naive, the system’s performance was
promising, and showed the high contribution of
syntactic dependencies for semantic parsing.
</bodyText>
<sectionHeader confidence="0.999168" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9999601">
This paper presents semantic parsing based on
only HPSG parses, and investigates the contribu-
tion of syntactic information to semantic parsing.
We constructed an HPSG-FN map by finding
the HPSG paths that corresponded to semantic re-
lations, and used it as role prediction rules in se-
mantic parsing. The semantic parsing was evalu-
ated on the SRL task data of Senseval-3. Although
the preliminary system used only the syntactic in-
formation, the performance was promising, and
</bodyText>
<table confidence="0.998893571428572">
Rule set Prec. Overlap Recall
Same 0.799 0.783 0.518
AllInter 0.599 0.586 0.589
AllPred 0.472 0.462 0.709
AllPred-AllInter 0.344 0.335 0.712
Senseval-3 best 0.899 0.882 0.772
Senseval-3 4th best 0.802 0.784 0.654
</table>
<tableCaption confidence="0.999843">
Table 4: Semantic parsing result on the test data.
</tableCaption>
<bodyText confidence="0.99990075">
indicated that syntactic dependencies may make
significant contribution to semantic analysis.
This paper also suggests a limit of the seman-
tic analysis based purely on syntax. A next step
for accurate HPSG-FN mapping could be analy-
sis of the interaction between the HPSG-FN map
and other information, such as named entity types
which were shown to be effective in many studies.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999573">
This work was partially supported by Grant-in-Aid
for Specially Promoted Research (MEXT, Japan)
and Special Coordination Funds for Promoting
Science and Technology (MEXT, Japan).
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999587866666667">
Anette Frank and Jiˇr´ı Semeck´y. 2004. Corpus-based
induction of an LFG syntax-semantics interface for
frame semantic processing. In Proc. of International
Workshop on Linguistically Interpreted Corpora.
Daniel Gildea and Julia Hockenmaier. 2003. Identi-
fying semantic roles using combinatory categorial
grammar. In Proc. of EMNLP.
Ken Litkowski. 2004. Senseval-3 task: Automatic la-
beling of semantic roles. In Proc. of Senseval-3.
Yusuke Miyao and Jun’ichi Tsujii. 2004. Deep lin-
guistic analysis for the accurate identification of
predicate-argument relations. In Proc. of Coling.
Yi Zhang, Rui Wang, and Hans Uszkoreit. 2008. Hy-
brid learning of dependency structures from hetero-
geneous linguistic resources. In Proc. of CoNLL.
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.772966">
<title confidence="0.9444375">Evaluating Contribution of Deep Syntactic to Shallow Semantic Analysis</title>
<author confidence="0.829231">Sumire Uematsu Jun’ichi</author>
<affiliation confidence="0.9818235">Graduate School of Information Science and The University of</affiliation>
<abstract confidence="0.999626272727273">This paper presents shallow semantic parsing based only on HPSG parses. An HPSG-FrameNet map was constructed from a semantically annotated corpus, and semantic parsing was performed by mapping HPSG dependencies to FrameNet relations. The semantic parsing was evaluated in a Senseval-3 task; the results suggested that there is a high contribution of syntactic information to semantic analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anette Frank</author>
<author>Jiˇr´ı Semeck´y</author>
</authors>
<title>Corpus-based induction of an LFG syntax-semantics interface for frame semantic processing.</title>
<date>2004</date>
<booktitle>In Proc. of International Workshop on Linguistically Interpreted Corpora.</booktitle>
<marker>Frank, Semeck´y, 2004</marker>
<rawString>Anette Frank and Jiˇr´ı Semeck´y. 2004. Corpus-based induction of an LFG syntax-semantics interface for frame semantic processing. In Proc. of International Workshop on Linguistically Interpreted Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Identifying semantic roles using combinatory categorial grammar.</title>
<date>2003</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="2811" citStr="Gildea and Hockenmaier, 2003" startWordPosition="420" endWordPosition="423"> of syntactic analysis to semantic parsing. 2 Related Work Besides (Frank and Semeck´y, 2004)’s work, as mentioned above, there have been several studies on the relationship between deep syntax and semantic parsing. Although the studies did not focus on direct mappings between deep syntax and shallow semantics, they suggested a strong relationship between the two. (Miyao and Tsujii, 2004) evaluated the accuracy of an HPSG parser against PropBank semantic annotations, and showed that the HPSG dependants correlated with semantic arguments of the PropBank, particularly with “core” arguments. In (Gildea and Hockenmaier, 2003) and (Zhang et al., 2008), features from deep parses were used for semantic parsing, together with features from CFG or dependency parses. The deep features were reported to contribute to a performance gain. 3 Syntactic and Semantic Parsing Some semantic relations are easily identified by using syntactic parsing while others are more difficult. This section presents easy and difficult cases in syntax-semantics map construction. Trivial when using syntactic analysis: Syntactic parsing, including CFG analysis, detects semantic similarity of sentences sharing similar phrase structures. For the ex</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Daniel Gildea and Julia Hockenmaier. 2003. Identifying semantic roles using combinatory categorial grammar. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Litkowski</author>
</authors>
<title>Senseval-3 task: Automatic labeling of semantic roles.</title>
<date>2004</date>
<booktitle>In Proc. of Senseval-3.</booktitle>
<contexts>
<context position="6711" citStr="Litkowski, 2004" startWordPosition="1049" endWordPosition="1050"> information is represented in the graph, by the terminal nodes’ PAS types, e.g. verb arg12, etc., and by the added edges. Note that the interpretation of the edge labels depends on the PAS type. If the PAS type is verb arg12, the ARG2 dependant is the object of the transitive verb or its equivalence (the subject of the passive, etc.). If the PAS type is prep arg12, then the dependant is the NP governed by the preposition node. 5 Semantic Parsing Based on FrameNet We employed FrameNet (FN) as a semantic corpus. Furthermore, we evaluated our semantic parsing on the SRL task data of Senseval-3 (Litkowski, 2004), which consists of FN annotations. In FN, semantic frames are defined, and each frame is associated with predicates that evoke the frame. For instance, the verb and noun praise are predicates of the Judgment communication frame, and they share the same set of semantic roles. The Senseval-3 data is a standard for evaluation of semantic parsing. The task is defined as identifying phrases and their semantic roles for a given sentence, predicate, and frame. The data includes null instantiations of rolesl, which are “conceptually salient”, but do not appear in the text. 6 Methods The semantic pars</context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>Ken Litkowski. 2004. Senseval-3 task: Automatic labeling of semantic roles. In Proc. of Senseval-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Deep linguistic analysis for the accurate identification of predicate-argument relations.</title>
<date>2004</date>
<booktitle>In Proc. of Coling.</booktitle>
<contexts>
<context position="2573" citStr="Miyao and Tsujii, 2004" startWordPosition="386" endWordPosition="389">semantic parsing by mapping paths in HPSG parses to semantic predicate-argument relations. The analysis of the HPSG paths for the predicate-argument pairs, and the preliminary result of the semantic parsing indicate the contribution of syntactic analysis to semantic parsing. 2 Related Work Besides (Frank and Semeck´y, 2004)’s work, as mentioned above, there have been several studies on the relationship between deep syntax and semantic parsing. Although the studies did not focus on direct mappings between deep syntax and shallow semantics, they suggested a strong relationship between the two. (Miyao and Tsujii, 2004) evaluated the accuracy of an HPSG parser against PropBank semantic annotations, and showed that the HPSG dependants correlated with semantic arguments of the PropBank, particularly with “core” arguments. In (Gildea and Hockenmaier, 2003) and (Zhang et al., 2008), features from deep parses were used for semantic parsing, together with features from CFG or dependency parses. The deep features were reported to contribute to a performance gain. 3 Syntactic and Semantic Parsing Some semantic relations are easily identified by using syntactic parsing while others are more difficult. This section pr</context>
</contexts>
<marker>Miyao, Tsujii, 2004</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2004. Deep linguistic analysis for the accurate identification of predicate-argument relations. In Proc. of Coling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Rui Wang</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Hybrid learning of dependency structures from heterogeneous linguistic resources.</title>
<date>2008</date>
<booktitle>In Proc. of CoNLL.</booktitle>
<contexts>
<context position="2836" citStr="Zhang et al., 2008" startWordPosition="425" endWordPosition="428">parsing. 2 Related Work Besides (Frank and Semeck´y, 2004)’s work, as mentioned above, there have been several studies on the relationship between deep syntax and semantic parsing. Although the studies did not focus on direct mappings between deep syntax and shallow semantics, they suggested a strong relationship between the two. (Miyao and Tsujii, 2004) evaluated the accuracy of an HPSG parser against PropBank semantic annotations, and showed that the HPSG dependants correlated with semantic arguments of the PropBank, particularly with “core” arguments. In (Gildea and Hockenmaier, 2003) and (Zhang et al., 2008), features from deep parses were used for semantic parsing, together with features from CFG or dependency parses. The deep features were reported to contribute to a performance gain. 3 Syntactic and Semantic Parsing Some semantic relations are easily identified by using syntactic parsing while others are more difficult. This section presents easy and difficult cases in syntax-semantics map construction. Trivial when using syntactic analysis: Syntactic parsing, including CFG analysis, detects semantic similarity of sentences sharing similar phrase structures. For the example sentences a) and b)</context>
</contexts>
<marker>Zhang, Wang, Uszkoreit, 2008</marker>
<rawString>Yi Zhang, Rui Wang, and Hans Uszkoreit. 2008. Hybrid learning of dependency structures from heterogeneous linguistic resources. In Proc. of CoNLL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>