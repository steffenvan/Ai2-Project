<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000024">
<title confidence="0.985479">
Aspectual Type and Temporal Relation Classification
</title>
<author confidence="0.99331">
Francisco Costa Ant´onio Branco
</author>
<affiliation confidence="0.968013">
Universidade de Lisboa Universidade de Lisboa
</affiliation>
<email confidence="0.993682">
fcosta@di.fc.ul.pt Antonio.Branco@di.fc.ul.pt
</email>
<sectionHeader confidence="0.994" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99629065">
In this paper we investigate the relevance of
aspectual type for the problem of temporal
information processing, i.e. the problems
of the recent TempEval challenges.
For a large list of verbs, we obtain sev-
eral indicators about their lexical aspect by
querying the web for expressions where
these verbs occur in contexts associated
with specific aspectual types.
We then proceed to extend existing solu-
tions for the problem of temporal informa-
tion processing with the information ex-
tracted this way. The improved perfor-
mance of the resulting models shows that
(i) aspectual type can be data-mined with
unsupervised methods with a level of noise
that does not prevent this information from
being useful and that (ii) temporal informa-
tion processing can profit from information
about aspectual type.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978176470589">
Extracting the temporal information present in a
text is relevant to many natural language process-
ing applications, including question-answering,
information extraction, and even document sum-
marization, as summaries may be more readable
if they follow a chronological order.
Recent evaluation campaigns have focused on
the extraction of temporal information from writ-
ten text. TempEval (Verhagen et al., 2007), in
2007, and more recently TempEval-2 (Verhagen
et al., 2010), in 2010, were concerned with this
problem. Additionally, they provided data that
can be used to develop and evaluate systems that
can automatically temporally tag natural language
text. These data are annotated according to the
TimeML (Pustejovsky et al., 2003) scheme.
Figure 1 shows a small and slightly simpli-
fied fragment of the data from TempEval, with
TimeML annotations. There, event terms, such
as the term referring to the event of releasing the
tapes, are annotated using EVENT tags. States
(such as the situations denoted by verbs like want
or love) are also considered events. Temporal ex-
pressions, such as today, are enclosed in TIMEX3
tags. The attribute value of time expressions
holds a normalized representation of the date or
time they refer to (e.g. the word today denotes the
date 1998-01-14 in this example). The TLINK
elements at the end describe temporal relations
between events and temporal expressions. For in-
stance, the event of the plane going down is anno-
tated as temporally preceding the date denoted by
the temporal expression today.
The major tasks of these two TempEval evalu-
ation challenges were about guessing the type of
temporal relations, i.e. the value of the relType
attribute of the TLINK elements in Figure 1, all
other annotations being given. Temporal relation
classification is also the most interesting problem
in temporal information processing. The other
relevant tasks (identifying and normalizing tem-
poral expressions and events) have a longer re-
search history and show better evaluation results.
TempEval was organized in three tasks
(TempEval-2 has four additional ones, that are not
relevant to this work): task A was concerned with
classifying temporal relations holding between an
event and a time mentioned in the same sentence
(although they could be syntactically unrelated, as
the temporal relation represented by the TLINK
with the lid with the value l1 in Figure 1); task
</bodyText>
<page confidence="0.973997">
266
</page>
<note confidence="0.9930665">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 266–275,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.759064">
&lt;s&gt;In Washington &lt;TIMEX3 tid=&amp;quot;t53&amp;quot; type=&amp;quot;DATE&amp;quot;
value=&amp;quot;1998-01-14&amp;quot;&gt;today&lt;/TIMEX3&gt;, the Federal
Aviation Administration &lt;EVENT eid=&amp;quot;e1&amp;quot;
class=&amp;quot;OCCURRENCE&amp;quot; stem=&amp;quot;release&amp;quot;
aspect=&amp;quot;NONE&amp;quot; tense=&amp;quot;PAST&amp;quot; polarity=&amp;quot;POS&amp;quot;
pos=&amp;quot;VERB&amp;quot;&gt;released&lt;/EVENT&gt; air traffic control tapes from
&lt;TIMEX3 tid=&amp;quot;t54&amp;quot; type=&amp;quot;TIME&amp;quot;
value=&amp;quot;1998-XX-XXTNI&amp;quot;&gt;thenight&lt;/TIMEX3&gt; the TWA
Flight eight hundred &lt;EVENT eid=&amp;quot;e2&amp;quot;
class=&amp;quot;OCCURRENCE&amp;quot; stem=&amp;quot;go&amp;quot; aspect=&amp;quot;NONE&amp;quot;
tense=&amp;quot;PAST&amp;quot; polarity=&amp;quot;POS&amp;quot;
pos=&amp;quot;VERB&amp;quot;&gt;went&lt;/EVENT&gt; down.&lt;/s&gt;
&lt;TLINK lid=&amp;quot;l1&amp;quot; relType=&amp;quot;BEFORE&amp;quot; eventID=&amp;quot;e2&amp;quot;
relatedToTime=&amp;quot;t53&amp;quot;/&gt;
&lt;TLINK lid=&amp;quot;l2&amp;quot; relType=&amp;quot;OVERLAP&amp;quot;
eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t54&amp;quot;/&gt;
</figure>
<figureCaption confidence="0.90683">
Figure 1: Sample of the data annotated for TempEval,
corresponding to the fragment: In Washington today,
the Federal Aviation Administration released air traf-
fic control tapes from the night the TWA Flight eight
hundred went down.
</figureCaption>
<figure confidence="0.4735175">
Task
A B C
</figure>
<table confidence="0.921972333333333">
Best system 0.62 0.80 0.55
Average of all participants 0.56 0.74 0.51
Majority class baseline 0.57 0.56 0.47
</table>
<tableCaption confidence="0.9133805">
Table 1: Results for English in TempEval (F-measure),
from Verhagen et al. (2009)
</tableCaption>
<bodyText confidence="0.999699235294118">
B focused on the temporal relation between events
and the document’s creation time, which is also
annotated in TimeML (not shown in that Figure);
and task C was about classifying the temporal re-
lation between the main events of two consecu-
tive sentences. The possible values for the type
of temporal relation are BEFORE, AFTER and
OVERLAP.1
Table 1 shows the results of the first TempEval
evaluation. The results of TempEval-2 are fairly
similar (Verhagen et al., 2010), but the data used
are similar but not identical.
The best system in TempEval for tasks A and B
(Pus¸cas¸u, 2007) combined statistical and knowl-
edge based methods to propagate temporal con-
straints along parse trees coming from a syntac-
tic parser. The best system for task C (Min et
</bodyText>
<footnote confidence="0.8054948">
1There are the additional disjunctive values
BEFORE-OR-OVERLAP, OVERLAP-OR-AFTER and
VAGUE, employed when the annotators could not make a
more specific decision, but these affect a small number of
instances.
</footnote>
<bodyText confidence="0.995445888888889">
al., 2007) also combined rule-based and machine
learning approaches. It employed sophisticated
NLP to compute some of the features used; more
specifically it used syntactic features.
Our goal with this work is to evaluate the im-
pact of information about aspectual type on these
tasks. The TimeML annotations include an at-
tribute class for EVENTs that encodes some as-
pectual information, distinguishing between sta-
tive (annotated with the value STATE) and non-
stative events (value OCCURRENCE). This at-
tribute is relevant to the classification problem at
hand, i.e. it is a useful feature for machine learned
classifiers for the TempEval tasks (although this
class attribute encodes other kinds of informa-
tion as well). However, aspectual distinctions can
be more fine-grained than a mere binary distinc-
tion, and so far no system has explored this sort of
information to help improve the solutions to tem-
poral relation classification.
In this paper we work with Portuguese, but in
principle there is no reason to believe that our
findings would not apply to other languages that
display similar aspectual phenomena, such as En-
glish. Some of the details, such as the material
in Section 4.2, are however language specific and
would need adaptation.
</bodyText>
<sectionHeader confidence="0.933626" genericHeader="method">
2 Aspectual Type
</sectionHeader>
<bodyText confidence="0.9999465">
Distinctions of aspectual type (also referred to as
situation type, lexical aspect or Aktionsart) of the
sort of Vendler (1967) and Dowty (1979) are ex-
pected to improve the existing solutions to the
problem of temporal relation classification. The
major aspectual distinctions are between (i) states
(e.g. to hate beer, to know the answer, to own a
car, to stink), (ii) processes, also called activities
(to work, to eat ice cream, to grow, to play the
piano), (iii) culminated processes, also called ac-
complishments (to paint a picture, to burn down,
to deliver a sermon) and (iv) culminations, also
called achievements (to explode, to win the game,
to find the key). States and processes are atelic
situations in that they do not make salient a spe-
cific instant in time. Culminated processes and
culminations are telic situations: they have an in-
trinsic, instantaneous endpoint, called the culmi-
nation (e.g. in the case of to paint a picture, it is
the moment when the picture is ready; in the case
of to explode, it is the moment of the explosion).
There are several reasons to think aspectual
</bodyText>
<page confidence="0.99342">
267
</page>
<bodyText confidence="0.991862">
type is relevant to temporal information pro-
cessing. First, these distinctions are related to
how long events last: culminations are punctual,
whereas states can be very prolonged in time.
States are thus more likely to temporally overlap
other temporal entities than culminations, for in-
stance.
Second, there are grammatical consequences
on how events are anchored in time. Consider
the following examples, from Ritchie (1979) and
Moens and Steedman (1988):
</bodyText>
<listItem confidence="0.970943">
(1) When they built the 59th Street bridge,
they used the best materials.
(2) When they built that bridge, I was still a
young lad.
</listItem>
<bodyText confidence="0.999264791666667">
The situation of building the bridge is a cul-
minated processed, composed by the process of
actively building a bridge followed by the culmi-
nation of the bridge being finished. In sentence
(1), the event described in the main clause (that of
using the best materials) is a process, but in sen-
tence (2) it is a state (the state of being a young
lad). Even though the two clauses in each sen-
tence are connected by when, the temporal rela-
tions holding between the events of each clause
are different. On the one hand, in sentence (1)
the event of using the best materials (a process)
overlaps with the process of actively building the
bridge and precedes the culmination of finishing
the bridge. On the other hand, in sentence (2)
the event of being a young lad (which is a state)
overlaps with both the process of actively build-
ing the bridge and the culmination of the bridge
being built. This difference is arguably caused by
the different aspectual types of the main events of
each sentence.
As another example, states overlap with tem-
poral location adverbials, as in (3), while culmi-
nations are included in them, as in (4).
</bodyText>
<listItem confidence="0.98775">
(3) He was happy last Monday.
(4) He reached the top of Mount Everest last
Monday.
</listItem>
<bodyText confidence="0.999606034482759">
In other cases, differences in aspectual type can
disambiguate ambiguous linguistic material. For
instance, the preposition in is ambiguous as it can
be used to locate events in the future but also to
measure the duration of culminated processes; it
is thus ambiguous with culminated processes, as
in he will read the book in three days but not with
other aspectual types, as in he will be living there
in three days.
A factor related to aspectual class, that is not
trivial to account for, is the phenomenon of as-
pectual shift, or aspectual coercion (Moens and
Steedman, 1988; de Swart, 1998; de Swart, 2000).
Many linguistic contexts pose constraints on as-
pectual type. This does not mean, however, that
clashes of aspectual type cause ungrammatical-
ity. What often happens is that phrases associated
with an incompatible aspectual type get their type
changed in order to be of the required type, caus-
ing a change in meaning.
For instance, the progressive construction com-
bines with processes. When it combines with e.g.
a culminated process, the culmination is stripped
off from this culminated process, which is thus
converted into a process. The result is that a sen-
tence like (5) does not say that the bridge was fin-
ished (the event has no culmination), whereas one
such as (6) does say this (the event has a culmina-
tion).
</bodyText>
<listItem confidence="0.8083155">
(5) They were building that bridge.
(6) They built that bridge.
</listItem>
<bodyText confidence="0.999842375">
Aspectual type is not a property of just words,
but phrases as well. For example, while the
progressive construction just mentioned combines
with processes, the resulting phrase behaves as a
state (cf. the sentence When they built the 59th
Street bridge, they were using the best materi-
als and what was mentioned above about when
clauses).
</bodyText>
<sectionHeader confidence="0.995861" genericHeader="method">
3 Strategy
</sectionHeader>
<bodyText confidence="0.999994785714286">
Aspectual type is hard to annotate. This is partly
because of what was just mentioned: it is not a
property of just words, but rather phrases, and
different phrases with the same head word can
have different aspectual types; however anno-
tation schemes like TimeML annotate the head
word as denoting events, not full phrases or
clauses.
For this reason, our strategy is to obtain aspec-
tual type information from unannotated data. Be-
cause these data are gradient—an event-denoting
word can be associated with different aspectual
types, depending on word sense—we do not aim
to extract categorical information, but rather nu-
</bodyText>
<page confidence="0.984758">
268
</page>
<bodyText confidence="0.99997144">
meric values for each event term that reflect as-
sociations to aspectual types. These may be seen
as values that are indicative of the frequencies in
which an event term denotes a state, or a process,
etc.
In order to extract these indicators, we resort to
a methodology sometimes referred to as Google
Hits: large amounts of queries are sent to a web
search engine (not necessarily Google), and the
number of search results (the number of web
pages that match the query) is recorded and taken
as a measure of the frequency of the queried ex-
pression.
This methodology is not perfect, since multiple
occurrences of the queried expression in the same
web page are not reflected in the hit count, and
in many cases the hit counts reported by search
engines are just estimates and might not be very
accurate. Additionally, uncarefully formulated
queries can match expressions that are syntacti-
cally and semantically very different from what
was intended. In any case, it has the advantages
of being based on a very large amount of data and
not requiring any manual annotation, which can
introduce errors.
</bodyText>
<subsectionHeader confidence="0.99806">
3.1 The Web as a Very Large Corpus
</subsectionHeader>
<bodyText confidence="0.99999">
Hearst (1992) is one of the earliest studies where
specific textual patterns are used to extract lexico-
semantic information from very large corpora.
The author’s goal was to extract hyponymy rela-
tions. With the same goal, Kozareva et al. (2008)
apply similar textual patterns to the web.
The web has been used as a corpus by many
other authors with the purpose of extracting syn-
tactic or semantic properties of words or re-
lations between them, e.g. Ravichandran and
Hovy (2002), Etzioni et al. (2004), etc. Some
of this work is specially relevant to the problem
of temporal information processing. VerbOcean
(Chklovski and Pantel, 2004) is a database of
web mined relations between verbs. Among other
kinds of relations, it includes typical precedence
relations, e.g. sleeping happens before waking up.
This type of information has in fact been used by
some of the participating systems of TempEval-2
(Ha et al., 2010), with good results.
More generally, there is a large body of work
focusing on lexical acquisition from corpora. Just
as an example, Mayol et al. (2005) learn subcate-
gorization frames of verbs from large amounts of
data. Relevant to our work is that of Siegel and
McKeown (2000). The authors guess the aspec-
tual type of verbs by searching for specific pat-
terns in a one million word corpus that has been
syntactically parsed. They extract several linguis-
tic indicators and combine them with machine
learning algorithms. The indicators that they ex-
tract are naturally different from ours, since they
have access to syntactic structure and we do not,
but our data are based on a much larger corpus.
</bodyText>
<subsectionHeader confidence="0.9979625">
3.2 Textual Patterns as Indicators of
Aspectual Type
</subsectionHeader>
<bodyText confidence="0.999813769230769">
Because of aspectual shift phenomena (see Sec-
tion 2), full syntactic parsing is necessary in order
to determine the aspectual type of a natural lan-
guage expression. However, this can be approxi-
mated by frequencies: it is natural to expect that
e.g. stative verbs occur more frequently in stative
contexts than non-stative verbs, even if there may
be errors in determining these contexts if syntactic
parsing is not a possibility.
If one uses Google Hits, syntactic information
is not accessible. In return for its impreciseness,
Google Hits have the advantage of being based on
very large amounts of data.
</bodyText>
<sectionHeader confidence="0.958195" genericHeader="method">
4 Scope and Approach
</sectionHeader>
<bodyText confidence="0.999972">
In this study we focus exclusively on verbs, but
events can be denoted by words belonging to
other parts-of-speech. This limitation is linked to
the fact that the textual patterns that are used to
search for specific aspectual contexts are sensitive
to part-of-speech (i.e. what may work for a verb
may not work equally well for a noun).
In order to assess whether aspectual type in-
formation is relevant to the problem of temporal
relation classification, our approach is to check
whether incorporating that kind of information
into existing solutions for this problem can im-
prove their performance. TimeML annotated
data, such as those used for TempEval, can be
used to train machine learned classifiers. These
can then be augmented with attributes encoding
aspectual type information and their performance
compared to the original classifiers.
Additionally, we work with Portuguese data.
This is because our work is part of an effort to
implement a temporal processing system for Por-
tuguese. We briefly describe the data next.
</bodyText>
<page confidence="0.992584">
269
</page>
<table confidence="0.982472933333333">
&lt;s&gt;Em Washington, &lt;TIMEX3 tid=&amp;quot;t53&amp;quot; type=&amp;quot;DATE&amp;quot;
value=&amp;quot;1998-01-14&amp;quot;&gt;hoje&lt;/TIMEX3&gt;, a Federal Aviation
Administration &lt;EVENT eid=&amp;quot;e1&amp;quot; class=&amp;quot;OCCURRENCE&amp;quot;
stem=&amp;quot;publicar&amp;quot; aspect=&amp;quot;NONE&amp;quot; tense=&amp;quot;PPI&amp;quot;
polarity=&amp;quot;POS&amp;quot; pos=&amp;quot;VERB&amp;quot;&gt;publicou&lt;/EVENT&gt;
gravac¸˜oes do controlo de tr´afego a´ereo da &lt;TIMEX3
tid=&amp;quot;t54&amp;quot; type=&amp;quot;TIME&amp;quot;
value=&amp;quot;1998-XX-XXTNI&amp;quot;&gt;noite&lt;/TIMEX3&gt; emqueovoo
TWA800 &lt;EVENT eid=&amp;quot;e2&amp;quot; class=&amp;quot;OCCURRENCE&amp;quot;
stem=&amp;quot;cair&amp;quot; aspect=&amp;quot;NONE&amp;quot; tense=&amp;quot;PPI&amp;quot;
polarity=&amp;quot;POS&amp;quot; pos=&amp;quot;VERB&amp;quot;&gt;caiu&lt;/EVENT&gt;.&lt;/s&gt;
&lt;TLINK lid=&amp;quot;l1&amp;quot; relType=&amp;quot;BEFORE&amp;quot; eventID=&amp;quot;e2&amp;quot;
relatedToTime=&amp;quot;t53&amp;quot;/&gt;
&lt;TLINK lid=&amp;quot;l2&amp;quot; relType=&amp;quot;OVERLAP&amp;quot;
eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t54&amp;quot;/&gt;
</table>
<bodyText confidence="0.988620384615385">
tool (Branco et al., 2009) to generate the specific
verb forms that are used in the queries. They are
mostly third person singular forms of several dif-
ferent tenses.
The indicators that we used are ratios of Google
Hits. They compare two queries.
Several indicators were tested. We provide ex-
amples with the verb fazer “do” for the queries
being compared by each indicator. The name of
each indicator reflects the aspectual type being
tested, i.e. states should present high values for
State Indicators 1 and 2, processes should show
high values for Process Indicators 1–4, etc.
</bodyText>
<figureCaption confidence="0.8757244">
Figure 2: Sample of the Portuguese data adapted from
the TempEval data, corresponding to the fragment: Em
Washington, hoje, a Federal Aviation Administration
publicou gravac¸˜oes do controlo de tr´afego a´ereo da
noite em que o voo TWA800 caiu.
</figureCaption>
<subsectionHeader confidence="0.932693">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999965857142857">
Our experiments used TimeBankPT (Costa and
Branco, 2010; Costa and Branco, 2012; Costa, to
appear). This corpus is an adaptation of the orig-
inal TempEval data to Portuguese, obtained by
translating it and then adapting the annotations.
Figure 2 shows the Portuguese equivalent to the
sample presented above in Figure 1. The two cor-
pora are quite similar, but there is of course the
language difference. TimeBankPT contains a few
corrections to the data (mostly the temporal rela-
tions), but these corrections only changed around
1.2% of the total number of annotated temporal
relations (Costa and Branco, 2012). Although we
did not test our results on English data, we specu-
late that our results carry over to other languages.
Just like the original English corpus for
TempEval, it is divided in a training part and a
testing part. The numbers (sentences, words, an-
notated events, time expressions and temporal re-
lations) are fairly similar for the two corpora (the
English one and the Portuguese one).
</bodyText>
<subsectionHeader confidence="0.993982">
4.2 Extracting the Aspectual Indicators
</subsectionHeader>
<bodyText confidence="0.991121285714286">
We extracted the 4,000 most common verbs from
a 180 million word corpus of Portuguese news-
paper text, CETEMP´ublico. Because this corpus
is not annotated, we used a part-of-speech tag-
ger and morphological analyzer (Barreto et al.,
2006; Silva, 2007) to detect verbs and to obtain
their dictionary form. We then used an inflection
</bodyText>
<listItem confidence="0.588573">
• State Indicator 1 (Indicator S1) is about im-
perfective and perfective past forms of verbs.
It compares the number of hits a for an im-
perfective form fazia “did” to the number of
</listItem>
<bodyText confidence="0.891471285714286">
hits b for a perfective form fez “did”: a
a+b.
Assuming the imperfective past constrains
the entire clause to be a state, and the perfec-
tive past constrains it to be telic, the higher
this value the more frequently the verb ap-
pears in stative clauses in a past tense.2
</bodyText>
<listItem confidence="0.905629333333334">
• State Indicator 2 (Indicator S2) is about the
co-occurrence with acaba de “has just fin-
ished”. It compares the number of hits a
for acaba de fazer “has just finished doing”
to the number of hits b for fazer “to do”:
bIn Portuguese, this construction does
a+b.
not seem to be felicitous with states.
• Process Indicator 1 (Indicator P1) is about
past progressive forms and simple past forms
(both imperfective). It compares the num-
ber of hits a for fazia “did” to the number of
</listItem>
<bodyText confidence="0.901481285714286">
hits b for estava a fazer “was doing”: b
a+b.
Assuming the progressive construction is a
function from processes to states (see Sec-
tion 2), the higher this value, the more likely
the verb can occur with the interpretation of
a process.
</bodyText>
<footnote confidence="0.917182777777778">
2We expect this frequency to be indicative of states be-
cause states can appear in the imperfective past tense with
their interpretation unchanged, whereas non-stative events
have their interpretation shifted to a stative one in that con-
text (e.g. they get a habitual reading). In order to refer to an
event occurring in the past with an on-going interpretation,
non-stative verbs require the progressive construction to be
used in Portuguese, whereas states do not. Therefore, states
should occur more freely in the simple imperfective past.
</footnote>
<page confidence="0.979156">
270
</page>
<listItem confidence="0.853613">
• Process Indicator 2 (Indicator P2) is about
</listItem>
<bodyText confidence="0.817204">
past progressive forms vs. simple past forms
(perfective). It compares the number of hits
a for fez “did” to the number of hits b for
esteve a fazer “was doing”: b
a+b. Similarly
to the previous indicator, this one tests the
frequency of a verb appearing in a context
typical of processes.
</bodyText>
<listItem confidence="0.952368">
• Process Indicator 3 (Indicator P3) is about
</listItem>
<bodyText confidence="0.979821076923077">
the occurrence of for Adverbials. It com-
pares the number of hits a for fez “did” to
the number of hits b for fez durante muito
tempo “did for a long time”: b
a+b. This
number is also intended to be an indica-
tion of how frequent a verb can be used
with the interpretation of a process. Note
that Portuguese allows modifiers to occur
freely between a verb and its complements,
so this test should work for transitive verbs
(or any other subcategorization frame involv-
ing complements), not just intransitive ones.
</bodyText>
<listItem confidence="0.933255">
• Process Indicator 4 (Indicator P4) is about
</listItem>
<bodyText confidence="0.974410222222222">
the co-occurrence of a verb with parar de “to
stop”. It compares the number of hits a for
parou de fazer “stopped doing” to the num-
ber of hits b for fazer “to do”: a
a+b. Just like
the English verbs stop and finish are sensitive
to the aspectual type of their complement, so
is the Portuguese verb parar, which selects
for processes.
</bodyText>
<listItem confidence="0.895191">
• Atelicity Indicator 1 (Indicator A1) is about
</listItem>
<bodyText confidence="0.996832">
comparing in and for adverbials. It compares
the number of hits a for fez num instante “did
in an instant” to the number of hits b for fez
durante muito tempo “did for a long time”:
bProcesses can be modified by for ad-
a+b.
verbials, whereas culminated processes are
modified by in adverbials. This indicator
tests the occurrence of a verb in contexts that
require these aspectual types.
</bodyText>
<listItem confidence="0.887063">
• Atelicity Indicator 2 (Indicator A2) is about
</listItem>
<bodyText confidence="0.906381795454545">
comparing for Adverbials with suddenly. It
compares the number of hits a for fez de re-
pente “did suddenly” to the number of hits
b for fez durante muito tempo “did for a
long time”: b
a+b. De repente “suddenly”
seems to modify culminations, so this indi-
cator compares process readings with culmi-
nation readings.
• Culmination Indicator1 (Indicator C1) is
about differentiating culminations and cul-
minated processes. It compares the number
of hits a for fez de repente “did suddenly” to
the number of hits b for fez num instante “did
in an instant”: a
a+b.
For each of the 4,000 verbs, the necessary
queries required by these indicators were gener-
ated and then sent to a search engine. The queries
were enclosed in quotes, so as to guarantee ex-
act matches. The number of hits was recorded for
each query.
We had some problems with outliers for a few
rather infrequent verbs. These could show very
extreme values for some indicators. In order
to minimize their impact, for each indicator we
homogenized the 100 highest values that were
found. More specifically, for each indicator, each
one of the highest 100 values was replaced by the
100th highest value. The bottom 100 values were
similarly changed. This way the top 99 values and
the bottom 99 values are replaced by the 100th
highest value and the 100th lowest value respec-
tively.
Each indicator ranges between 0 and 1 in the-
ory. In practice, we seldom find values close to the
extremes, as this would imply that some queries
would have close to 0 hits, which does not occur
very often (after all, we intentionally used queries
for which we would expect large hit counts, as
these are more likely to be representative of true
language use). For this reason, each indicator is
scaled so that its minimum (actual) value is 0 and
its maximum (actual) value is 1.
</bodyText>
<sectionHeader confidence="0.998123" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999892285714286">
As mentioned before, in order to assess the use-
fulness of these aspectual indicators for the tasks
of temporal relation classification, we checked
whether they can improve machine learned clas-
sifiers trained for this problem. We next describe
the classifiers that were used as the bases for com-
parison.
</bodyText>
<subsectionHeader confidence="0.948669">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9998352">
In order to obtain bases for comparison, we
trained machine learned classifiers on the Por-
tuguese corpus TimeBankPT, that is adapted from
the TempEval data (see Section 4.1). We took
inspiration in the work of Hepple et al. (2007).
</bodyText>
<page confidence="0.993756">
271
</page>
<bodyText confidence="0.999985078431373">
This was one of the participating systems of
TempEval. It used machine learning algorithms
implemented in Weka (Witten and Frank, 1999).
For our experiments, we used Weka’s implemen-
tation of the C4.5 algorithm, trees.J48 (Quin-
lan, 1993), the RIPPER algorithm as implemented
by Weka’s rules.JRip (Cohen, 1995), a near-
est neighbors classifier, lazy.KStar (Cleary
and Trigg, 1995), a Naive Bayes classifier, namely
Weka’s bayes.NaiveBayes (John and Lang-
ley, 1995), and a support vector classifier, Weka’s
functions.SMO (Platt, 1998) . We chose these
algorithms as they are representative of a wide
range of machine learning approaches.
Recall that the tasks of TempEval are to guess
the type of temporal relations. Each train or test
instance thus corresponds to a temporal relation,
i.e. a TLINK element in the TimeML annota-
tions (see Figures 1 and 2). The classification
problem is to determine the value of the attribute
relType of TimeML TLINK elements. These
temporal relations relate an event (referred by the
eventID attribute of TLINK elements) to an-
other temporal entity, that can be a time (pointed
to by the relatedToTime attribute), in the case
of tasks A and B, or, in the case of task C, an-
other event (given by the relatedToEvent at-
tribute).
As for the features that were employed, we also
took inspiration in the approach of Hepple et al.
(2007). These authors used as classifier attributes
two types of features. The first group of features
corresponds to TimeML attributes: for instance
the value of the aspect attribute of EVENT el-
ements, for the events involved in the temporal
relation to be classified. The second group of fea-
tures corresponds to simple features that can be
computed with string manipulation and do not re-
quire any kind of natural language processing.
Table 2 shows the features that were tried and
employed.
The event features correspond to attributes
of EVENT elements, with the exception of
the event-string feature, which takes as
value the character data inside the correspond-
ing TimeML EVENT element. In a simi-
lar spirit, the timex3 features are taken from
the attributes of TIMEX3 elements with the
same name. The tlink-relType feature
is the class attribute and corresponds to the
relType attribute of the TimeML TLINK el-
</bodyText>
<equation confidence="0.94840475">
Task
Attribute A B C
event-aspect x ✓ ✓
event-polarity ✓ ✓ ✓
event-POS x x ✓
event-stem x ✓ x
event-string ✓ x x
event-class ✓ x ✓
event-tense ✓ ✓ ✓
order-event-first ✓ N/A N/A
order-event-between ✓ N/A N/A
order-timex3-between x N/A N/A
order-adjacent ✓ N/A N/A
timex3-mod ✓ x N/A
timex3-type x x N/A
tlink-relType ✓ ✓ ✓
</equation>
<tableCaption confidence="0.990686">
Table 2: Feature combinations used in the classifiers
used as comparison bases. Features inspired by the
ones used by Hepple et al. (2007) in TempEval.
</tableCaption>
<bodyText confidence="0.999581285714286">
ement that represents the temporal relation to
be classified. The order features are the at-
tributes computed from the document’s textual
content. The feature order-event-first
encodes whether the event terms precedes in
the text the time expression it is related to by
the temporal relation to classify. The clas-
sifier attribute order-event-between de-
scribes whether any other event is mentioned
in the text between the two expressions for
the entities that are in the temporal relation,
and similarly order-timex3-between is
about whether there is an intervening tempo-
ral expression. Finally, order-adjacent is
true iff both order-timex3-between and
order-event-between are false (even if
other linguistic material occurs between the ex-
pressions denoting the two entities in the temporal
relation).
In order to arrive at the final set of features
(marked with a check mark in Table 2), we per-
formed exhaustive search on all possible combi-
nations of these features for each task, using the
Naive Bayes algorithm. They were compared us-
ing 10-fold cross-validation on the training data.
The feature combinations shown in Table 2 are
the optimal combinations arrived at in this way.
These are the classifiers that we used for the
</bodyText>
<page confidence="0.991406">
272
</page>
<bodyText confidence="0.999985260869565">
comparison with the aspectual type indicators.
We chose this straightforward approach because it
forms a basis for comparison that is easily repro-
ducible: the algorithm implementations that were
used are part of freely available software, and the
features that were employed are easily computed
from the annotated data, with no need to run any
natural language processing tools whatsoever.
As mentioned before in Section 4.1, the data
used are organized in a training set and an evalu-
ation set. The training part is around 60K words
long, the test data containing around 9K words.
When tested on held-out data, these classifiers
present the scores shown in italics in Table 3.
These results are fairly similar to the scores that
the system of Hepple et al. (2007) obtained in
TempEval with English data: 0.59 for task A, 0.73
for task B, and 0.54 for task C. They are also not
very far from the best results of TempEval. As
such they represent interesting bases for compar-
ison, as improving their performance is likely to
be relevant to the best systems that have been de-
veloped for temporal information processing.
</bodyText>
<subsectionHeader confidence="0.977544">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999703269230769">
After obtaining the bases for comparison de-
scribed above, we proceeded to check whether the
aspectual type indicators described in Section 4.2
can improve these results.
For each aspectual indicator, we implemented
a classifier feature that encodes its value for the
event term in the temporal relation (if it is not a
verb, this value is missing). In the case of task C,
two features are added for each indicator, one for
each event term.
We extended each of these classifiers with one
of these features at a time (two in the case of task
C), and checked whether it improved the results
on the test data. So for instance, in order to test
Indicator S1, we extended each of these classifiers
with a feature that encodes the value that this indi-
cator presents for the term that denotes the event
present in the temporal relation to be classified.
In the case of task C, two classifier features are
added, one for each event term, and both for the
same Indicator S1. For instance, for the (train-
ing) instance corresponding to the TLINK in Fig-
ure 2 with the lid attribute that has the value l1,
the classifier feature for Indicator S1 has the value
that was computed for the verb cair “go down”,
since this is the stem of the word that denotes
</bodyText>
<table confidence="0.999428166666667">
Classifier Task
A B C
trees.J48 0.57 0.77 0.53
With best indicator 0.55
rules.JRip 0.60 0.76 0.51
With best indicator 0.61 0.54
lazy.KStar 0.54 0.70 0.52
With best indicator 0.73 0.53
bayes.NaiveBayes 0.50 0.76 0.53
With best indicator 0.53 0.54
functions.SMO 0.55 0.79 0.54
With best indicator 0.56 0.55
</table>
<tableCaption confidence="0.998071">
Table 3: Evaluation on held-out test data of classi-
fiers trained on full train data. Values for the classi-
fiers used as comparison bases are in italics. Boldface
highlights improvements resulting from incorporating
aspectual indicators as classifier features, and missing
values represent no improvement.
</tableCaption>
<bodyText confidence="0.999944214285714">
the event that is the first argument of this temporal
relation. After adding each of these features, we
retrained the classifiers on the training data and
tested them on the held-out test data. In order to
keep the evaluation manageable, we did not test
combinations of multiple indicators.
Table 3 shows the overall results. For task
A, the best indicators were P4 (with JRip), A1
(NaiveBayes) and S1 (SMO). For task B the
best one was P4 (KStar). For task C, the best
indicators were P3 (J48), A1 and P3 (JRip),
C1 (KStar), A1 (NaiveBayes) and P2 (SMO).
Each of the indicators S2, P1 and A2 either does
not improve the results or does so but not as much
as another, better indicator for the same task and
algorithm.
It seems clear from Table 3 that some tasks ben-
efit from these indicators more than others. In
particular, task C shows consistent improvements
whereas task B is hardly affected. Since task C
is about relations involving two events, the classi-
fiers may be picking up the sort of linguistic gen-
eralizations mentioned in Section 2 about when
clauses.
J48 and JRip produce human-readable mod-
els. We checked how these classifiers are taking
advantage of the aspectual indicators. For task C,
the induced models are generally associating high
</bodyText>
<page confidence="0.993798">
273
</page>
<bodyText confidence="0.999975421052632">
values of the indicators A1 and P3 with overlap
relations and low values of these indicators with
other types of relations. This is expected. On the
one end, high values for these indicators are asso-
ciated with atelicity (i.e. the endpoint of the cor-
responding event is not presented). On the other
hand, both indicators are based on queries con-
taining the phrase durante muito tempo “for a long
time”, which, in addition to picking up events that
can be modified by for adverbials, more specifi-
cally pick up events that happen for a long time
and are thus likely to overlap other events.
For task A, JRip also associates high values of
the indicator P4—which constitute evidence that
the corresponding events are processes (which are
atelic)—with overlap relations. This is a specially
interesting result, considering that the queries on
which this indicator is based reflect a purely as-
pectual constraint.
</bodyText>
<sectionHeader confidence="0.993764" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999983315789474">
In this paper, we evaluated the relevance of infor-
mation about aspectual type for temporal process-
ing tasks.
Temporal information processing has received
substantial attention recently with the two
TempEval challenges in 2007 and 2010. The most
interesting problem of temporal information pro-
cessing, that of temporal relation classification, is
still affected by high error rates.
Even though a very substantial part of the se-
mantics literature on tense and aspect focuses on
aspectual type, solutions to the problem of auto-
matic temporal relation classification have not in-
corporated this sort of semantic information. In
part this is expected, as aspectual type is very in-
terconnected with syntax (cf. the discussion about
aspectual coercion in Section 2), and the phe-
nomenon of aspect shift can make it hard to com-
pute even when syntactic information is available.
Our contribution with this paper is to incor-
porate this sort of information in existing ma-
chine learned classifiers that tackle this problem.
Even though these classifiers do not have access to
syntactic information, aspectual type information
seemed to be useful in improving the performance
of these models. We hypothesize that combin-
ing aspectual type information with information
about syntactic structure can further improve the
problems of temporal information processing, but
we leave that research to future work.
An interesting question that we hope will be ad-
dressed by future work is how these results extend
to other languages. We cannot provide an answer
to this question, as we do not have the data. How-
ever, this experiment can be replicated for any lan-
guage that has (i) TimeML annotated data, (ii) a
reasonable size of documents on the Web and a
search engine capable of separating them from the
documents in other languages and (iii) an aspec-
tual system similar enough that the question be-
ing addressed in this paper makes sense (and use-
ful patterns for queries can be constructed, even
if not entirely identical to the ones that we used).
The second criterion is met by many, many lan-
guages. The third one also seems to affect many
languages, as the existing literature on aspectual
phenomena indicates that these phenomena are
quite widespread. The second criterion is, at the
moment, the hardest to fulfill as not many lan-
guages have data with rich annotations about time
(i.e. including events and temporal relations). We
speculate that our results can extend to English,
although a different set of query patterns may
have to be used in order to extract the aspectual
indicators that are employed. We believe this be-
cause the two languages largely overlap when it
comes to aspectual phenomena.
</bodyText>
<sectionHeader confidence="0.998573" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999391666666666">
Florbela Barreto, Ant´onio Branco, Eduardo Ferreira,
Am´alia Mendes, Maria Fernanda Nascimento, Fil-
ipe Nunes, and Jo˜ao Silva. 2006. Open resources
and tools for the shallow processing of Portuguese:
the TagShare project. In Proceedings of LREC
2006.
Ant´onio Branco, Francisco Costa, Eduardo Ferreira,
Pedro Martins, Filipe Nunes, Jo˜ao Silva, and Sara
Silveira. 2009. LX-Center: a center of online lin-
guistic services. In Proceedings of the Demo Ses-
sion, ACL-IJCNLP2009, Singapore.
Timothy Chklovski and Patrick Pantel. 2004. Verb-
Ocean: Mining the Web for fine-grained semantic
verb relations. In In Proceedings of EMNLP-2004,
Barcelona, Spain.
John G. Cleary and Leonard E. Trigg. 1995. K*: An
instance-based learner using an entropic distance
measure. In 12th International Conference on Ma-
chine Learning, pages 108–114.
William W. Cohen. 1995. Fast effective rule induc-
tion. In Proceedings of the Twelfth International
Conference on Machine Learning, pages 115–123.
Francisco Costa and Ant´onio Branco. 2010. Tempo-
ral information processing of a new language: Fast
</reference>
<page confidence="0.975876">
274
</page>
<reference confidence="0.999875535714286">
porting with minimal resources. In Proceedings of
ACL 2010.
Francisco Costa and Ant´onio Branco. 2012. Time-
BankPT: A TimeML annotated corpus of Por-
tuguese. In Proceedings ofLREC2012.
Francisco Costa. to appear. Processing Temporal In-
formation in Unstructured Documents. Ph.D. the-
sis, Universidade de Lisboa, Lisbon.
Henri¨ette de Swart. 1998. Aspect shift and coercion.
Natural Language and Linguistic Theory, 16:347–
385.
Henri¨ette de Swart. 2000. Tense, aspect and coer-
cion in a cross-linguistic perspective. In Proceed-
ings of the Berkeley Formal Grammar conference,
Stanford. CSLI Publications.
David R. Dowty. 1979. Word Meaning and Montague
Grammar: the Semantics of Verbs and Times in
Generative Semantics and Montague’s PTQ. Rei-
del, Dordrecht.
Oren Etzioni, Michael Cafarella, Doug Downey, Stan-
ley Kok, Ana-Maria Popescu, Tal Shaked, , Stephen
Soderland, Daniel S. Weld, and Alexander Yates.
2004. Web-scale information extraction in Know-
ItAll. In Proceedings of the 13th International Con-
ference on World Wide Web.
Eun Young Ha, Alok Baikadi, Carlyle Licata, and
James C. Lester. 2010. NCSU: Modeling temporal
relations with Markov logic and lexical ontology. In
Proceedings of SemEval 2010.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th Conference on Computational Linguistics,
volume 2, pages 539–545, Nantes, France.
Mark Hepple, Andrea Setzer, and Rob Gaizauskas.
2007. USFD: Preliminary exploration of fea-
tures and classifiers for the TempEval-2007 tasks.
In Proceedings of SemEval-2007, pages 484–487,
Prague, Czech Republic. Association for Computa-
tional Linguistics.
George H. John and Pat Langley. 1995. Estimating
continuous distributions in Bayesian classifiers. In
Eleventh Conference on Uncertainty in Artificial In-
telligence, pages 338–345, San Mateo.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008. Semantic class learning from the web with
hyponym pattern linkage graphs. In Proceedings of
ACL-08: HLT, pages 1048–1056, Columbus, Ohio.
Association for Computational Linguistics.
Laia Mayol, Gemma Boleda, and Toni Badia. 2005.
Automatic acquisition of syntactic verb classes with
basic resources. Language Resources and Evalua-
tion, 39(4):295–312.
Congmin Min, Munirathnam Srikanth, and Abraham
Fowler. 2007. LCC-TE: A hybrid approach to
temporal relation identification in news text. pages
219–222.
Marc Moens and Mark Steedman. 1988. Temporal
ontology and temporal reference. Computational
Linguistics, 14(2):15–28.
John Platt. 1998. Fast training of support vec-
tor machines using sequential minimal optimiza-
tion. In Bernhard Sch¨olkopf, Chris Burges, and
Alexander J. Smola, editors, Advances in Kernel
Methods—Support Vector Learning.
Georgiana Pus¸cas¸u. 2007. WVALI: Temporal rela-
tion identification by syntactico-semantic analysis.
In Proceedings of SemEval-2007, pages 484–487,
Prague, Czech Republic. Association for Computa-
tional Linguistics.
James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, and Gra-
ham Katz. 2003. TimeML: Robust specification of
event and temporal expressions in text. In IWCS-
5, Fifth International Workshop on Computational
Semantics.
John Ross Quinlan. 1993. C4.5: Programs for Ma-
chine Learning. Morgan Kaufmann, San Mateo,
CA.
Deepak Ravichandran and Eduard Hovy. 2002.
Learning surface text patterns for a question an-
swering system. In Proceedings ofACL 2002.
Graeme D. Ritchie. 1979. Temporal clauses in En-
glish. Theoretical Linguistics, 6:87–115.
Eric V. Siegel and Kathleen McKeown. 2000.
Learning methods to combine linguistic indica-
tors: Improving aspectual classification and reveal-
ing linguistic insights. Computational Linguistics,
24(4):595–627.
Jo˜ao Ricardo Silva. 2007. Shallow processing
of Portuguese: From sentence chunking to nomi-
nal lemmatization. Master’s thesis, Faculdade de
Ciˆencias da Universidade de Lisboa, Lisbon, Portu-
gal.
Zeno Vendler. 1967. Verbs and times. Linguistics in
Philosophy, pages 97–121.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, and James Pustejovsky. 2007.
SemEval-2007 Task 15: TempEval temporal re-
lation identification. In Proceedings of SemEval-
2007.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The TempEval challenge: iden-
tifying temporal relations in text. Language Re-
sources and Evaluation.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 task 13:
TempEval-2. In Proceedings of SemEval-2010.
Ian H. Witten and Eibe Frank. 1999. Data Mining:
Practical Machine Learning Tools and Techniques
with Java Implementations. Morgan Kaufmann,
San Francisco.
</reference>
<page confidence="0.99844">
275
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.651792">
<title confidence="0.999852">Aspectual Type and Temporal Relation Classification</title>
<author confidence="0.999966">Francisco Costa Ant´onio Branco</author>
<affiliation confidence="0.992101">Universidade de Lisboa Universidade de Lisboa</affiliation>
<email confidence="0.669274">fcosta@di.fc.ul.ptAntonio.Branco@di.fc.ul.pt</email>
<abstract confidence="0.999003571428572">In this paper we investigate the relevance of aspectual type for the problem of temporal information processing, i.e. the problems of the recent TempEval challenges. For a large list of verbs, we obtain several indicators about their lexical aspect by querying the web for expressions where these verbs occur in contexts associated with specific aspectual types. We then proceed to extend existing solutions for the problem of temporal information processing with the information extracted this way. The improved performance of the resulting models shows that (i) aspectual type can be data-mined with unsupervised methods with a level of noise that does not prevent this information from being useful and that (ii) temporal information processing can profit from information about aspectual type.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Florbela Barreto</author>
<author>Ant´onio Branco</author>
<author>Eduardo Ferreira</author>
<author>Am´alia Mendes</author>
<author>Maria Fernanda Nascimento</author>
<author>Filipe Nunes</author>
<author>Jo˜ao Silva</author>
</authors>
<title>Open resources and tools for the shallow processing of Portuguese: the TagShare project.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="19362" citStr="Barreto et al., 2006" startWordPosition="3066" endWordPosition="3069">h data, we speculate that our results carry over to other languages. Just like the original English corpus for TempEval, it is divided in a training part and a testing part. The numbers (sentences, words, annotated events, time expressions and temporal relations) are fairly similar for the two corpora (the English one and the Portuguese one). 4.2 Extracting the Aspectual Indicators We extracted the 4,000 most common verbs from a 180 million word corpus of Portuguese newspaper text, CETEMP´ublico. Because this corpus is not annotated, we used a part-of-speech tagger and morphological analyzer (Barreto et al., 2006; Silva, 2007) to detect verbs and to obtain their dictionary form. We then used an inflection • State Indicator 1 (Indicator S1) is about imperfective and perfective past forms of verbs. It compares the number of hits a for an imperfective form fazia “did” to the number of hits b for a perfective form fez “did”: a a+b. Assuming the imperfective past constrains the entire clause to be a state, and the perfective past constrains it to be telic, the higher this value the more frequently the verb appears in stative clauses in a past tense.2 • State Indicator 2 (Indicator S2) is about the co-occur</context>
</contexts>
<marker>Barreto, Branco, Ferreira, Mendes, Nascimento, Nunes, Silva, 2006</marker>
<rawString>Florbela Barreto, Ant´onio Branco, Eduardo Ferreira, Am´alia Mendes, Maria Fernanda Nascimento, Filipe Nunes, and Jo˜ao Silva. 2006. Open resources and tools for the shallow processing of Portuguese: the TagShare project. In Proceedings of LREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ant´onio Branco</author>
<author>Francisco Costa</author>
<author>Eduardo Ferreira</author>
<author>Pedro Martins</author>
<author>Filipe Nunes</author>
<author>Jo˜ao Silva</author>
<author>Sara Silveira</author>
</authors>
<title>LX-Center: a center of online linguistic services.</title>
<date>2009</date>
<booktitle>In Proceedings of the Demo Session, ACL-IJCNLP2009,</booktitle>
<contexts>
<context position="17278" citStr="Branco et al., 2009" startWordPosition="2726" endWordPosition="2729">tid=&amp;quot;t53&amp;quot; type=&amp;quot;DATE&amp;quot; value=&amp;quot;1998-01-14&amp;quot;&gt;hoje&lt;/TIMEX3&gt;, a Federal Aviation Administration &lt;EVENT eid=&amp;quot;e1&amp;quot; class=&amp;quot;OCCURRENCE&amp;quot; stem=&amp;quot;publicar&amp;quot; aspect=&amp;quot;NONE&amp;quot; tense=&amp;quot;PPI&amp;quot; polarity=&amp;quot;POS&amp;quot; pos=&amp;quot;VERB&amp;quot;&gt;publicou&lt;/EVENT&gt; gravac¸˜oes do controlo de tr´afego a´ereo da &lt;TIMEX3 tid=&amp;quot;t54&amp;quot; type=&amp;quot;TIME&amp;quot; value=&amp;quot;1998-XX-XXTNI&amp;quot;&gt;noite&lt;/TIMEX3&gt; emqueovoo TWA800 &lt;EVENT eid=&amp;quot;e2&amp;quot; class=&amp;quot;OCCURRENCE&amp;quot; stem=&amp;quot;cair&amp;quot; aspect=&amp;quot;NONE&amp;quot; tense=&amp;quot;PPI&amp;quot; polarity=&amp;quot;POS&amp;quot; pos=&amp;quot;VERB&amp;quot;&gt;caiu&lt;/EVENT&gt;.&lt;/s&gt; &lt;TLINK lid=&amp;quot;l1&amp;quot; relType=&amp;quot;BEFORE&amp;quot; eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t53&amp;quot;/&gt; &lt;TLINK lid=&amp;quot;l2&amp;quot; relType=&amp;quot;OVERLAP&amp;quot; eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t54&amp;quot;/&gt; tool (Branco et al., 2009) to generate the specific verb forms that are used in the queries. They are mostly third person singular forms of several different tenses. The indicators that we used are ratios of Google Hits. They compare two queries. Several indicators were tested. We provide examples with the verb fazer “do” for the queries being compared by each indicator. The name of each indicator reflects the aspectual type being tested, i.e. states should present high values for State Indicators 1 and 2, processes should show high values for Process Indicators 1–4, etc. Figure 2: Sample of the Portuguese data adapted</context>
</contexts>
<marker>Branco, Costa, Ferreira, Martins, Nunes, Silva, Silveira, 2009</marker>
<rawString>Ant´onio Branco, Francisco Costa, Eduardo Ferreira, Pedro Martins, Filipe Nunes, Jo˜ao Silva, and Sara Silveira. 2009. LX-Center: a center of online linguistic services. In Proceedings of the Demo Session, ACL-IJCNLP2009, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>VerbOcean: Mining the Web for fine-grained semantic verb relations. In</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP-2004,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="13940" citStr="Chklovski and Pantel, 2004" startWordPosition="2230" endWordPosition="2233">992) is one of the earliest studies where specific textual patterns are used to extract lexicosemantic information from very large corpora. The author’s goal was to extract hyponymy relations. With the same goal, Kozareva et al. (2008) apply similar textual patterns to the web. The web has been used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn subcategorization frames of verbs from large amounts of data. Relevant to our work is that of Siegel and McKeown (2000). The authors guess the aspectual type o</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. VerbOcean: Mining the Web for fine-grained semantic verb relations. In In Proceedings of EMNLP-2004, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John G Cleary</author>
<author>Leonard E Trigg</author>
</authors>
<title>K*: An instance-based learner using an entropic distance measure.</title>
<date>1995</date>
<booktitle>In 12th International Conference on Machine Learning,</booktitle>
<pages>108--114</pages>
<contexts>
<context position="25689" citStr="Cleary and Trigg, 1995" startWordPosition="4166" endWordPosition="4169">tal Setup In order to obtain bases for comparison, we trained machine learned classifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test instance thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Figures 1 and 2). The classification problem is to determine the value of the attribute relType of TimeML TLINK elements. These temporal relatio</context>
</contexts>
<marker>Cleary, Trigg, 1995</marker>
<rawString>John G. Cleary and Leonard E. Trigg. 1995. K*: An instance-based learner using an entropic distance measure. In 12th International Conference on Machine Learning, pages 108–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Proceedings of the Twelfth International Conference on Machine Learning,</booktitle>
<pages>115--123</pages>
<contexts>
<context position="25620" citStr="Cohen, 1995" startWordPosition="4158" endWordPosition="4159"> that were used as the bases for comparison. 5.1 Experimental Setup In order to obtain bases for comparison, we trained machine learned classifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test instance thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Figures 1 and 2). The classification problem is to determine the value of t</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>William W. Cohen. 1995. Fast effective rule induction. In Proceedings of the Twelfth International Conference on Machine Learning, pages 115–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Costa</author>
<author>Ant´onio Branco</author>
</authors>
<title>Temporal information processing of a new language: Fast porting with minimal resources.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="18140" citStr="Costa and Branco, 2010" startWordPosition="2866" endWordPosition="2869">were tested. We provide examples with the verb fazer “do” for the queries being compared by each indicator. The name of each indicator reflects the aspectual type being tested, i.e. states should present high values for State Indicators 1 and 2, processes should show high values for Process Indicators 1–4, etc. Figure 2: Sample of the Portuguese data adapted from the TempEval data, corresponding to the fragment: Em Washington, hoje, a Federal Aviation Administration publicou gravac¸˜oes do controlo de tr´afego a´ereo da noite em que o voo TWA800 caiu. 4.1 Data Our experiments used TimeBankPT (Costa and Branco, 2010; Costa and Branco, 2012; Costa, to appear). This corpus is an adaptation of the original TempEval data to Portuguese, obtained by translating it and then adapting the annotations. Figure 2 shows the Portuguese equivalent to the sample presented above in Figure 1. The two corpora are quite similar, but there is of course the language difference. TimeBankPT contains a few corrections to the data (mostly the temporal relations), but these corrections only changed around 1.2% of the total number of annotated temporal relations (Costa and Branco, 2012). Although we did not test our results on Engl</context>
</contexts>
<marker>Costa, Branco, 2010</marker>
<rawString>Francisco Costa and Ant´onio Branco. 2010. Temporal information processing of a new language: Fast porting with minimal resources. In Proceedings of ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Costa</author>
<author>Ant´onio Branco</author>
</authors>
<title>TimeBankPT: A TimeML annotated corpus of Portuguese.</title>
<date>2012</date>
<booktitle>In Proceedings ofLREC2012.</booktitle>
<contexts>
<context position="18164" citStr="Costa and Branco, 2012" startWordPosition="2870" endWordPosition="2873">examples with the verb fazer “do” for the queries being compared by each indicator. The name of each indicator reflects the aspectual type being tested, i.e. states should present high values for State Indicators 1 and 2, processes should show high values for Process Indicators 1–4, etc. Figure 2: Sample of the Portuguese data adapted from the TempEval data, corresponding to the fragment: Em Washington, hoje, a Federal Aviation Administration publicou gravac¸˜oes do controlo de tr´afego a´ereo da noite em que o voo TWA800 caiu. 4.1 Data Our experiments used TimeBankPT (Costa and Branco, 2010; Costa and Branco, 2012; Costa, to appear). This corpus is an adaptation of the original TempEval data to Portuguese, obtained by translating it and then adapting the annotations. Figure 2 shows the Portuguese equivalent to the sample presented above in Figure 1. The two corpora are quite similar, but there is of course the language difference. TimeBankPT contains a few corrections to the data (mostly the temporal relations), but these corrections only changed around 1.2% of the total number of annotated temporal relations (Costa and Branco, 2012). Although we did not test our results on English data, we speculate t</context>
</contexts>
<marker>Costa, Branco, 2012</marker>
<rawString>Francisco Costa and Ant´onio Branco. 2012. TimeBankPT: A TimeML annotated corpus of Portuguese. In Proceedings ofLREC2012.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Francisco Costa</author>
</authors>
<title>to appear. Processing Temporal Information in Unstructured Documents.</title>
<tech>Ph.D. thesis,</tech>
<institution>Universidade de Lisboa,</institution>
<location>Lisbon.</location>
<marker>Costa, </marker>
<rawString>Francisco Costa. to appear. Processing Temporal Information in Unstructured Documents. Ph.D. thesis, Universidade de Lisboa, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henri¨ette de Swart</author>
</authors>
<title>Aspect shift and coercion. Natural Language and Linguistic Theory,</title>
<date>1998</date>
<pages>16--347</pages>
<marker>de Swart, 1998</marker>
<rawString>Henri¨ette de Swart. 1998. Aspect shift and coercion. Natural Language and Linguistic Theory, 16:347– 385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henri¨ette de Swart</author>
</authors>
<title>Tense, aspect and coercion in a cross-linguistic perspective.</title>
<date>2000</date>
<booktitle>In Proceedings of the Berkeley Formal Grammar conference,</booktitle>
<publisher>CSLI Publications.</publisher>
<location>Stanford.</location>
<marker>de Swart, 2000</marker>
<rawString>Henri¨ette de Swart. 2000. Tense, aspect and coercion in a cross-linguistic perspective. In Proceedings of the Berkeley Formal Grammar conference, Stanford. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>Word Meaning and Montague Grammar: the Semantics of Verbs and Times in Generative Semantics and Montague’s PTQ.</title>
<date>1979</date>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="7045" citStr="Dowty (1979)" startWordPosition="1058" endWordPosition="1059">istinction, and so far no system has explored this sort of information to help improve the solutions to temporal relation classification. In this paper we work with Portuguese, but in principle there is no reason to believe that our findings would not apply to other languages that display similar aspectual phenomena, such as English. Some of the details, such as the material in Section 4.2, are however language specific and would need adaptation. 2 Aspectual Type Distinctions of aspectual type (also referred to as situation type, lexical aspect or Aktionsart) of the sort of Vendler (1967) and Dowty (1979) are expected to improve the existing solutions to the problem of temporal relation classification. The major aspectual distinctions are between (i) states (e.g. to hate beer, to know the answer, to own a car, to stink), (ii) processes, also called activities (to work, to eat ice cream, to grow, to play the piano), (iii) culminated processes, also called accomplishments (to paint a picture, to burn down, to deliver a sermon) and (iv) culminations, also called achievements (to explode, to win the game, to find the key). States and processes are atelic situations in that they do not make salient</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>David R. Dowty. 1979. Word Meaning and Montague Grammar: the Semantics of Verbs and Times in Generative Semantics and Montague’s PTQ. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>Stanley Kok</author>
<author>Ana-Maria Popescu</author>
<author>Tal Shaked</author>
</authors>
<title>Web-scale information extraction in KnowItAll.</title>
<date>2004</date>
<booktitle>In Proceedings of the 13th International Conference on World Wide Web.</booktitle>
<contexts>
<context position="13804" citStr="Etzioni et al. (2004)" startWordPosition="2210" endWordPosition="2213">e amount of data and not requiring any manual annotation, which can introduce errors. 3.1 The Web as a Very Large Corpus Hearst (1992) is one of the earliest studies where specific textual patterns are used to extract lexicosemantic information from very large corpora. The author’s goal was to extract hyponymy relations. With the same goal, Kozareva et al. (2008) apply similar textual patterns to the web. The web has been used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn subcategorization frame</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Kok, Popescu, Shaked, 2004</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, Stanley Kok, Ana-Maria Popescu, Tal Shaked, , Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2004. Web-scale information extraction in KnowItAll. In Proceedings of the 13th International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eun Young Ha</author>
<author>Alok Baikadi</author>
<author>Carlyle Licata</author>
<author>James C Lester</author>
</authors>
<title>NCSU: Modeling temporal relations with Markov logic and lexical ontology.</title>
<date>2010</date>
<booktitle>In Proceedings of SemEval</booktitle>
<contexts>
<context position="14222" citStr="Ha et al., 2010" startWordPosition="2276" endWordPosition="2279">en used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn subcategorization frames of verbs from large amounts of data. Relevant to our work is that of Siegel and McKeown (2000). The authors guess the aspectual type of verbs by searching for specific patterns in a one million word corpus that has been syntactically parsed. They extract several linguistic indicators and combine them with machine learning algorithms. The indicators that they extract are naturally different from ours, since they h</context>
</contexts>
<marker>Ha, Baikadi, Licata, Lester, 2010</marker>
<rawString>Eun Young Ha, Alok Baikadi, Carlyle Licata, and James C. Lester. 2010. NCSU: Modeling temporal relations with Markov logic and lexical ontology. In Proceedings of SemEval 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="13317" citStr="Hearst (1992)" startWordPosition="2129" endWordPosition="2130">ed expression. This methodology is not perfect, since multiple occurrences of the queried expression in the same web page are not reflected in the hit count, and in many cases the hit counts reported by search engines are just estimates and might not be very accurate. Additionally, uncarefully formulated queries can match expressions that are syntactically and semantically very different from what was intended. In any case, it has the advantages of being based on a very large amount of data and not requiring any manual annotation, which can introduce errors. 3.1 The Web as a Very Large Corpus Hearst (1992) is one of the earliest studies where specific textual patterns are used to extract lexicosemantic information from very large corpora. The author’s goal was to extract hyponymy relations. With the same goal, Kozareva et al. (2008) apply similar textual patterns to the web. The web has been used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chkl</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th Conference on Computational Linguistics, volume 2, pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
<author>Andrea Setzer</author>
<author>Rob Gaizauskas</author>
</authors>
<title>USFD: Preliminary exploration of features and classifiers for the TempEval-2007 tasks.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval-2007,</booktitle>
<pages>484--487</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="25306" citStr="Hepple et al. (2007)" startWordPosition="4108" endWordPosition="4111">l) value is 0 and its maximum (actual) value is 1. 5 Evaluation As mentioned before, in order to assess the usefulness of these aspectual indicators for the tasks of temporal relation classification, we checked whether they can improve machine learned classifiers trained for this problem. We next describe the classifiers that were used as the bases for comparison. 5.1 Experimental Setup In order to obtain bases for comparison, we trained machine learned classifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide</context>
<context position="26670" citStr="Hepple et al. (2007)" startWordPosition="4332" endWordPosition="4335">e thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Figures 1 and 2). The classification problem is to determine the value of the attribute relType of TimeML TLINK elements. These temporal relations relate an event (referred by the eventID attribute of TLINK elements) to another temporal entity, that can be a time (pointed to by the relatedToTime attribute), in the case of tasks A and B, or, in the case of task C, another event (given by the relatedToEvent attribute). As for the features that were employed, we also took inspiration in the approach of Hepple et al. (2007). These authors used as classifier attributes two types of features. The first group of features corresponds to TimeML attributes: for instance the value of the aspect attribute of EVENT elements, for the events involved in the temporal relation to be classified. The second group of features corresponds to simple features that can be computed with string manipulation and do not require any kind of natural language processing. Table 2 shows the features that were tried and employed. The event features correspond to attributes of EVENT elements, with the exception of the event-string feature, wh</context>
<context position="28037" citStr="Hepple et al. (2007)" startWordPosition="4564" endWordPosition="4567">tributes of TIMEX3 elements with the same name. The tlink-relType feature is the class attribute and corresponds to the relType attribute of the TimeML TLINK elTask Attribute A B C event-aspect x ✓ ✓ event-polarity ✓ ✓ ✓ event-POS x x ✓ event-stem x ✓ x event-string ✓ x x event-class ✓ x ✓ event-tense ✓ ✓ ✓ order-event-first ✓ N/A N/A order-event-between ✓ N/A N/A order-timex3-between x N/A N/A order-adjacent ✓ N/A N/A timex3-mod ✓ x N/A timex3-type x x N/A tlink-relType ✓ ✓ ✓ Table 2: Feature combinations used in the classifiers used as comparison bases. Features inspired by the ones used by Hepple et al. (2007) in TempEval. ement that represents the temporal relation to be classified. The order features are the attributes computed from the document’s textual content. The feature order-event-first encodes whether the event terms precedes in the text the time expression it is related to by the temporal relation to classify. The classifier attribute order-event-between describes whether any other event is mentioned in the text between the two expressions for the entities that are in the temporal relation, and similarly order-timex3-between is about whether there is an intervening temporal expression. F</context>
<context position="30045" citStr="Hepple et al. (2007)" startWordPosition="4886" endWordPosition="4889">producible: the algorithm implementations that were used are part of freely available software, and the features that were employed are easily computed from the annotated data, with no need to run any natural language processing tools whatsoever. As mentioned before in Section 4.1, the data used are organized in a training set and an evaluation set. The training part is around 60K words long, the test data containing around 9K words. When tested on held-out data, these classifiers present the scores shown in italics in Table 3. These results are fairly similar to the scores that the system of Hepple et al. (2007) obtained in TempEval with English data: 0.59 for task A, 0.73 for task B, and 0.54 for task C. They are also not very far from the best results of TempEval. As such they represent interesting bases for comparison, as improving their performance is likely to be relevant to the best systems that have been developed for temporal information processing. 5.2 Results and Discussion After obtaining the bases for comparison described above, we proceeded to check whether the aspectual type indicators described in Section 4.2 can improve these results. For each aspectual indicator, we implemented a cla</context>
</contexts>
<marker>Hepple, Setzer, Gaizauskas, 2007</marker>
<rawString>Mark Hepple, Andrea Setzer, and Rob Gaizauskas. 2007. USFD: Preliminary exploration of features and classifiers for the TempEval-2007 tasks. In Proceedings of SemEval-2007, pages 484–487, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George H John</author>
<author>Pat Langley</author>
</authors>
<title>Estimating continuous distributions in Bayesian classifiers.</title>
<date>1995</date>
<booktitle>In Eleventh Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>338--345</pages>
<location>San Mateo.</location>
<contexts>
<context position="25772" citStr="John and Langley, 1995" startWordPosition="4177" endWordPosition="4181">ifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test instance thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Figures 1 and 2). The classification problem is to determine the value of the attribute relType of TimeML TLINK elements. These temporal relations relate an event (referred by the eventID attribute of TLINK elements) to another</context>
</contexts>
<marker>John, Langley, 1995</marker>
<rawString>George H. John and Pat Langley. 1995. Estimating continuous distributions in Bayesian classifiers. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 338–345, San Mateo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1048--1056</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<contexts>
<context position="13548" citStr="Kozareva et al. (2008)" startWordPosition="2165" endWordPosition="2168">just estimates and might not be very accurate. Additionally, uncarefully formulated queries can match expressions that are syntactically and semantically very different from what was intended. In any case, it has the advantages of being based on a very large amount of data and not requiring any manual annotation, which can introduce errors. 3.1 The Web as a Very Large Corpus Hearst (1992) is one of the earliest studies where specific textual patterns are used to extract lexicosemantic information from very large corpora. The author’s goal was to extract hyponymy relations. With the same goal, Kozareva et al. (2008) apply similar textual patterns to the web. The web has been used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the web with hyponym pattern linkage graphs. In Proceedings of ACL-08: HLT, pages 1048–1056, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laia Mayol</author>
<author>Gemma Boleda</author>
<author>Toni Badia</author>
</authors>
<title>Automatic acquisition of syntactic verb classes with basic resources.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<issue>4</issue>
<contexts>
<context position="14374" citStr="Mayol et al. (2005)" startWordPosition="2302" endWordPosition="2305">vichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn subcategorization frames of verbs from large amounts of data. Relevant to our work is that of Siegel and McKeown (2000). The authors guess the aspectual type of verbs by searching for specific patterns in a one million word corpus that has been syntactically parsed. They extract several linguistic indicators and combine them with machine learning algorithms. The indicators that they extract are naturally different from ours, since they have access to syntactic structure and we do not, but our data are based on a much larger corpus. 3.2 Textual Patterns as Indicators of Aspectual Type Be</context>
</contexts>
<marker>Mayol, Boleda, Badia, 2005</marker>
<rawString>Laia Mayol, Gemma Boleda, and Toni Badia. 2005. Automatic acquisition of syntactic verb classes with basic resources. Language Resources and Evaluation, 39(4):295–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Congmin Min</author>
<author>Munirathnam Srikanth</author>
<author>Abraham Fowler</author>
</authors>
<title>LCC-TE: A hybrid approach to temporal relation identification in news text.</title>
<date>2007</date>
<pages>219--222</pages>
<marker>Min, Srikanth, Fowler, 2007</marker>
<rawString>Congmin Min, Munirathnam Srikanth, and Abraham Fowler. 2007. LCC-TE: A hybrid approach to temporal relation identification in news text. pages 219–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
<author>Mark Steedman</author>
</authors>
<title>Temporal ontology and temporal reference.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="8459" citStr="Moens and Steedman (1988)" startWordPosition="1289" endWordPosition="1292"> a picture, it is the moment when the picture is ready; in the case of to explode, it is the moment of the explosion). There are several reasons to think aspectual 267 type is relevant to temporal information processing. First, these distinctions are related to how long events last: culminations are punctual, whereas states can be very prolonged in time. States are thus more likely to temporally overlap other temporal entities than culminations, for instance. Second, there are grammatical consequences on how events are anchored in time. Consider the following examples, from Ritchie (1979) and Moens and Steedman (1988): (1) When they built the 59th Street bridge, they used the best materials. (2) When they built that bridge, I was still a young lad. The situation of building the bridge is a culminated processed, composed by the process of actively building a bridge followed by the culmination of the bridge being finished. In sentence (1), the event described in the main clause (that of using the best materials) is a process, but in sentence (2) it is a state (the state of being a young lad). Even though the two clauses in each sentence are connected by when, the temporal relations holding between the events</context>
<context position="10377" citStr="Moens and Steedman, 1988" startWordPosition="1630" endWordPosition="1633">e reached the top of Mount Everest last Monday. In other cases, differences in aspectual type can disambiguate ambiguous linguistic material. For instance, the preposition in is ambiguous as it can be used to locate events in the future but also to measure the duration of culminated processes; it is thus ambiguous with culminated processes, as in he will read the book in three days but not with other aspectual types, as in he will be living there in three days. A factor related to aspectual class, that is not trivial to account for, is the phenomenon of aspectual shift, or aspectual coercion (Moens and Steedman, 1988; de Swart, 1998; de Swart, 2000). Many linguistic contexts pose constraints on aspectual type. This does not mean, however, that clashes of aspectual type cause ungrammaticality. What often happens is that phrases associated with an incompatible aspectual type get their type changed in order to be of the required type, causing a change in meaning. For instance, the progressive construction combines with processes. When it combines with e.g. a culminated process, the culmination is stripped off from this culminated process, which is thus converted into a process. The result is that a sentence </context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>Marc Moens and Mark Steedman. 1988. Temporal ontology and temporal reference. Computational Linguistics, 14(2):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Platt</author>
</authors>
<title>Fast training of support vector machines using sequential minimal optimization.</title>
<date>1998</date>
<booktitle>Advances in Kernel Methods—Support Vector Learning.</booktitle>
<editor>In Bernhard Sch¨olkopf, Chris Burges, and Alexander J. Smola, editors,</editor>
<contexts>
<context position="25841" citStr="Platt, 1998" startWordPosition="4189" endWordPosition="4190">ta (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test instance thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Figures 1 and 2). The classification problem is to determine the value of the attribute relType of TimeML TLINK elements. These temporal relations relate an event (referred by the eventID attribute of TLINK elements) to another temporal entity, that can be a time (pointed to by the relatedToTime</context>
</contexts>
<marker>Platt, 1998</marker>
<rawString>John Platt. 1998. Fast training of support vector machines using sequential minimal optimization. In Bernhard Sch¨olkopf, Chris Burges, and Alexander J. Smola, editors, Advances in Kernel Methods—Support Vector Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Pus¸cas¸u</author>
</authors>
<title>WVALI: Temporal relation identification by syntactico-semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval-2007,</booktitle>
<pages>484--487</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<marker>Pus¸cas¸u, 2007</marker>
<rawString>Georgiana Pus¸cas¸u. 2007. WVALI: Temporal relation identification by syntactico-semantic analysis. In Proceedings of SemEval-2007, pages 484–487, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>TimeML: Robust specification of event and temporal expressions in text.</title>
<date>2003</date>
<booktitle>In IWCS5, Fifth International Workshop on Computational Semantics.</booktitle>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003. TimeML: Robust specification of event and temporal expressions in text. In IWCS5, Fifth International Workshop on Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="25548" citStr="Quinlan, 1993" startWordPosition="4147" endWordPosition="4149">ned classifiers trained for this problem. We next describe the classifiers that were used as the bases for comparison. 5.1 Experimental Setup In order to obtain bases for comparison, we trained machine learned classifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test instance thus corresponds to a temporal relation, i.e. a TLINK element in the TimeML annotations (see Fig</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="13781" citStr="Ravichandran and Hovy (2002)" startWordPosition="2206" endWordPosition="2209"> of being based on a very large amount of data and not requiring any manual annotation, which can introduce errors. 3.1 The Web as a Very Large Corpus Hearst (1992) is one of the earliest studies where specific textual patterns are used to extract lexicosemantic information from very large corpora. The author’s goal was to extract hyponymy relations. With the same goal, Kozareva et al. (2008) apply similar textual patterns to the web. The web has been used as a corpus by many other authors with the purpose of extracting syntactic or semantic properties of words or relations between them, e.g. Ravichandran and Hovy (2002), Etzioni et al. (2004), etc. Some of this work is specially relevant to the problem of temporal information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn </context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings ofACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme D Ritchie</author>
</authors>
<date>1979</date>
<booktitle>Temporal clauses in English. Theoretical Linguistics,</booktitle>
<pages>6--87</pages>
<contexts>
<context position="8429" citStr="Ritchie (1979)" startWordPosition="1286" endWordPosition="1287">he case of to paint a picture, it is the moment when the picture is ready; in the case of to explode, it is the moment of the explosion). There are several reasons to think aspectual 267 type is relevant to temporal information processing. First, these distinctions are related to how long events last: culminations are punctual, whereas states can be very prolonged in time. States are thus more likely to temporally overlap other temporal entities than culminations, for instance. Second, there are grammatical consequences on how events are anchored in time. Consider the following examples, from Ritchie (1979) and Moens and Steedman (1988): (1) When they built the 59th Street bridge, they used the best materials. (2) When they built that bridge, I was still a young lad. The situation of building the bridge is a culminated processed, composed by the process of actively building a bridge followed by the culmination of the bridge being finished. In sentence (1), the event described in the main clause (that of using the best materials) is a process, but in sentence (2) it is a state (the state of being a young lad). Even though the two clauses in each sentence are connected by when, the temporal relati</context>
</contexts>
<marker>Ritchie, 1979</marker>
<rawString>Graeme D. Ritchie. 1979. Temporal clauses in English. Theoretical Linguistics, 6:87–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
<author>Kathleen McKeown</author>
</authors>
<title>Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="14500" citStr="Siegel and McKeown (2000)" startWordPosition="2324" endWordPosition="2327">al information processing. VerbOcean (Chklovski and Pantel, 2004) is a database of web mined relations between verbs. Among other kinds of relations, it includes typical precedence relations, e.g. sleeping happens before waking up. This type of information has in fact been used by some of the participating systems of TempEval-2 (Ha et al., 2010), with good results. More generally, there is a large body of work focusing on lexical acquisition from corpora. Just as an example, Mayol et al. (2005) learn subcategorization frames of verbs from large amounts of data. Relevant to our work is that of Siegel and McKeown (2000). The authors guess the aspectual type of verbs by searching for specific patterns in a one million word corpus that has been syntactically parsed. They extract several linguistic indicators and combine them with machine learning algorithms. The indicators that they extract are naturally different from ours, since they have access to syntactic structure and we do not, but our data are based on a much larger corpus. 3.2 Textual Patterns as Indicators of Aspectual Type Because of aspectual shift phenomena (see Section 2), full syntactic parsing is necessary in order to determine the aspectual ty</context>
</contexts>
<marker>Siegel, McKeown, 2000</marker>
<rawString>Eric V. Siegel and Kathleen McKeown. 2000. Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights. Computational Linguistics, 24(4):595–627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Ricardo Silva</author>
</authors>
<title>Shallow processing of Portuguese: From sentence chunking to nominal lemmatization.</title>
<date>2007</date>
<booktitle>Master’s thesis, Faculdade de Ciˆencias da Universidade de</booktitle>
<location>Lisboa, Lisbon, Portugal.</location>
<contexts>
<context position="19376" citStr="Silva, 2007" startWordPosition="3070" endWordPosition="3071">hat our results carry over to other languages. Just like the original English corpus for TempEval, it is divided in a training part and a testing part. The numbers (sentences, words, annotated events, time expressions and temporal relations) are fairly similar for the two corpora (the English one and the Portuguese one). 4.2 Extracting the Aspectual Indicators We extracted the 4,000 most common verbs from a 180 million word corpus of Portuguese newspaper text, CETEMP´ublico. Because this corpus is not annotated, we used a part-of-speech tagger and morphological analyzer (Barreto et al., 2006; Silva, 2007) to detect verbs and to obtain their dictionary form. We then used an inflection • State Indicator 1 (Indicator S1) is about imperfective and perfective past forms of verbs. It compares the number of hits a for an imperfective form fazia “did” to the number of hits b for a perfective form fez “did”: a a+b. Assuming the imperfective past constrains the entire clause to be a state, and the perfective past constrains it to be telic, the higher this value the more frequently the verb appears in stative clauses in a past tense.2 • State Indicator 2 (Indicator S2) is about the co-occurrence with aca</context>
</contexts>
<marker>Silva, 2007</marker>
<rawString>Jo˜ao Ricardo Silva. 2007. Shallow processing of Portuguese: From sentence chunking to nominal lemmatization. Master’s thesis, Faculdade de Ciˆencias da Universidade de Lisboa, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Verbs and times. Linguistics in Philosophy,</title>
<date>1967</date>
<pages>97--121</pages>
<contexts>
<context position="7028" citStr="Vendler (1967)" startWordPosition="1055" endWordPosition="1056">han a mere binary distinction, and so far no system has explored this sort of information to help improve the solutions to temporal relation classification. In this paper we work with Portuguese, but in principle there is no reason to believe that our findings would not apply to other languages that display similar aspectual phenomena, such as English. Some of the details, such as the material in Section 4.2, are however language specific and would need adaptation. 2 Aspectual Type Distinctions of aspectual type (also referred to as situation type, lexical aspect or Aktionsart) of the sort of Vendler (1967) and Dowty (1979) are expected to improve the existing solutions to the problem of temporal relation classification. The major aspectual distinctions are between (i) states (e.g. to hate beer, to know the answer, to own a car, to stink), (ii) processes, also called activities (to work, to eat ice cream, to grow, to play the piano), (iii) culminated processes, also called accomplishments (to paint a picture, to burn down, to deliver a sermon) and (iv) culminations, also called achievements (to explode, to win the game, to find the key). States and processes are atelic situations in that they do</context>
</contexts>
<marker>Vendler, 1967</marker>
<rawString>Zeno Vendler. 1967. Verbs and times. Linguistics in Philosophy, pages 97–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 Task 15: TempEval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval2007.</booktitle>
<contexts>
<context position="1407" citStr="Verhagen et al., 2007" startWordPosition="202" endWordPosition="205">h unsupervised methods with a level of noise that does not prevent this information from being useful and that (ii) temporal information processing can profit from information about aspectual type. 1 Introduction Extracting the temporal information present in a text is relevant to many natural language processing applications, including question-answering, information extraction, and even document summarization, as summaries may be more readable if they follow a chronological order. Recent evaluation campaigns have focused on the extraction of temporal information from written text. TempEval (Verhagen et al., 2007), in 2007, and more recently TempEval-2 (Verhagen et al., 2010), in 2010, were concerned with this problem. Additionally, they provided data that can be used to develop and evaluate systems that can automatically temporally tag natural language text. These data are annotated according to the TimeML (Pustejovsky et al., 2003) scheme. Figure 1 shows a small and slightly simplified fragment of the data from TempEval, with TimeML annotations. There, event terms, such as the term referring to the event of releasing the tapes, are annotated using EVENT tags. States (such as the situations denoted by</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, and James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval temporal relation identification. In Proceedings of SemEval2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Jessica Moszkowicz</author>
<author>James Pustejovsky</author>
</authors>
<title>The TempEval challenge: identifying temporal relations in text. Language Resources and Evaluation.</title>
<date>2009</date>
<contexts>
<context position="4677" citStr="Verhagen et al. (2009)" startWordPosition="673" endWordPosition="676">ST&amp;quot; polarity=&amp;quot;POS&amp;quot; pos=&amp;quot;VERB&amp;quot;&gt;went&lt;/EVENT&gt; down.&lt;/s&gt; &lt;TLINK lid=&amp;quot;l1&amp;quot; relType=&amp;quot;BEFORE&amp;quot; eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t53&amp;quot;/&gt; &lt;TLINK lid=&amp;quot;l2&amp;quot; relType=&amp;quot;OVERLAP&amp;quot; eventID=&amp;quot;e2&amp;quot; relatedToTime=&amp;quot;t54&amp;quot;/&gt; Figure 1: Sample of the data annotated for TempEval, corresponding to the fragment: In Washington today, the Federal Aviation Administration released air traffic control tapes from the night the TWA Flight eight hundred went down. Task A B C Best system 0.62 0.80 0.55 Average of all participants 0.56 0.74 0.51 Majority class baseline 0.57 0.56 0.47 Table 1: Results for English in TempEval (F-measure), from Verhagen et al. (2009) B focused on the temporal relation between events and the document’s creation time, which is also annotated in TimeML (not shown in that Figure); and task C was about classifying the temporal relation between the main events of two consecutive sentences. The possible values for the type of temporal relation are BEFORE, AFTER and OVERLAP.1 Table 1 shows the results of the first TempEval evaluation. The results of TempEval-2 are fairly similar (Verhagen et al., 2010), but the data used are similar but not identical. The best system in TempEval for tasks A and B (Pus¸cas¸u, 2007) combined statis</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Jessica Moszkowicz, and James Pustejovsky. 2009. The TempEval challenge: identifying temporal relations in text. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 task 13: TempEval-2. In Proceedings of SemEval-2010.</booktitle>
<contexts>
<context position="1470" citStr="Verhagen et al., 2010" startWordPosition="212" endWordPosition="215">ent this information from being useful and that (ii) temporal information processing can profit from information about aspectual type. 1 Introduction Extracting the temporal information present in a text is relevant to many natural language processing applications, including question-answering, information extraction, and even document summarization, as summaries may be more readable if they follow a chronological order. Recent evaluation campaigns have focused on the extraction of temporal information from written text. TempEval (Verhagen et al., 2007), in 2007, and more recently TempEval-2 (Verhagen et al., 2010), in 2010, were concerned with this problem. Additionally, they provided data that can be used to develop and evaluate systems that can automatically temporally tag natural language text. These data are annotated according to the TimeML (Pustejovsky et al., 2003) scheme. Figure 1 shows a small and slightly simplified fragment of the data from TempEval, with TimeML annotations. There, event terms, such as the term referring to the event of releasing the tapes, are annotated using EVENT tags. States (such as the situations denoted by verbs like want or love) are also considered events. Temporal </context>
<context position="5147" citStr="Verhagen et al., 2010" startWordPosition="751" endWordPosition="754">all participants 0.56 0.74 0.51 Majority class baseline 0.57 0.56 0.47 Table 1: Results for English in TempEval (F-measure), from Verhagen et al. (2009) B focused on the temporal relation between events and the document’s creation time, which is also annotated in TimeML (not shown in that Figure); and task C was about classifying the temporal relation between the main events of two consecutive sentences. The possible values for the type of temporal relation are BEFORE, AFTER and OVERLAP.1 Table 1 shows the results of the first TempEval evaluation. The results of TempEval-2 are fairly similar (Verhagen et al., 2010), but the data used are similar but not identical. The best system in TempEval for tasks A and B (Pus¸cas¸u, 2007) combined statistical and knowledge based methods to propagate temporal constraints along parse trees coming from a syntactic parser. The best system for task C (Min et 1There are the additional disjunctive values BEFORE-OR-OVERLAP, OVERLAP-OR-AFTER and VAGUE, employed when the annotators could not make a more specific decision, but these affect a small number of instances. al., 2007) also combined rule-based and machine learning approaches. It employed sophisticated NLP to compute</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 task 13: TempEval-2. In Proceedings of SemEval-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="25447" citStr="Witten and Frank, 1999" startWordPosition="4130" endWordPosition="4133">indicators for the tasks of temporal relation classification, we checked whether they can improve machine learned classifiers trained for this problem. We next describe the classifiers that were used as the bases for comparison. 5.1 Experimental Setup In order to obtain bases for comparison, we trained machine learned classifiers on the Portuguese corpus TimeBankPT, that is adapted from the TempEval data (see Section 4.1). We took inspiration in the work of Hepple et al. (2007). 271 This was one of the participating systems of TempEval. It used machine learning algorithms implemented in Weka (Witten and Frank, 1999). For our experiments, we used Weka’s implementation of the C4.5 algorithm, trees.J48 (Quinlan, 1993), the RIPPER algorithm as implemented by Weka’s rules.JRip (Cohen, 1995), a nearest neighbors classifier, lazy.KStar (Cleary and Trigg, 1995), a Naive Bayes classifier, namely Weka’s bayes.NaiveBayes (John and Langley, 1995), and a support vector classifier, Weka’s functions.SMO (Platt, 1998) . We chose these algorithms as they are representative of a wide range of machine learning approaches. Recall that the tasks of TempEval are to guess the type of temporal relations. Each train or test inst</context>
</contexts>
<marker>Witten, Frank, 1999</marker>
<rawString>Ian H. Witten and Eibe Frank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Francisco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>