<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003991">
<title confidence="0.998155">
Arabic Named Entity Recognition:
Using Features Extracted from Noisy Data
</title>
<author confidence="0.384994">
Yassine Benajibas Imed Zitouni2 Mona Diabs Paolo Rosso3
</author>
<affiliation confidence="0.355785">
s Center for Computational Learning Systems, Columbia University
</affiliation>
<address confidence="0.43087">
2 IBM T.J. Watson Research Center, Yorktown Heights
3 Natural Language Engineering Lab. - ELiRF, Universidad Polit´ecnica de Valencia
</address>
<email confidence="0.929048">
{ybenajiba,mdiab}@ccls.columbia.edu, izitouni@us.ibm.com, prosso@dsic.upv.es
</email>
<sectionHeader confidence="0.993775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999829">
Building an accurate Named Entity
Recognition (NER) system for languages
with complex morphology is a challeng-
ing task. In this paper, we present research
that explores the feature space using both
gold and bootstrapped noisy features to
build an improved highly accurate Arabic
NER system. We bootstrap noisy features
by projection from an Arabic-English par-
allel corpus that is automatically tagged
with a baseline NER system. The feature
space covers lexical, morphological, and
syntactic features. The proposed approach
yields an improvement of up to 1.64
F-measure (absolute).
</bodyText>
<sectionHeader confidence="0.998741" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9984243">
Named Entity Recognition (NER) has earned an
important place in Natural Language Processing
(NLP) as an enabling process for other tasks.
When explicitly taken into account, research
shows that it helps such applications achieve bet-
ter performance levels (Babych and Hartley, 2003;
Thompson and Dozier, 1997). NER is defined as
the computational identification and classification
of Named Entities (NEs) in running text. For in-
stance, consider the following text:
</bodyText>
<subsubsectionHeader confidence="0.683835">
Barack Obama is visiting the Middle East.
</subsubsectionHeader>
<bodyText confidence="0.999913133333333">
A NER system should be able to identify Barack
Obama and Middle East as NEs and classify them
as Person (PER) and Geo-Political Entity (GPE),
respectively. The class-set used to tag NEs may
vary according to user needs. In this research,
we adopt the Automatic Content Extraction (ACE)
2007 nomenclature1.
According to (Nadeau and Sekine, 2007), opti-
mization of the feature set is the key component in
enhancing the performance of a global NER sys-
tem. In this paper we investigate the possibil-
ity of building a high performance Arabic NER
system by using a large space of available feature
sets that go beyond the explored shallow feature
sets used to date in the literature for Arabic NER.
</bodyText>
<footnote confidence="0.922814">
1http://www.nist.gov/speech/tests/ace/index.htm
</footnote>
<bodyText confidence="0.999203833333333">
Given current state-of-the-art syntactic processing
of Arabic text and the relative small size of man-
ually annotated Arabic NER data, we set out to
explore a main concrete research goal: to fully ex-
ploit the level of advancement in Arabic lexical
and syntactic processing to explore deeper linguis-
tic features for the NER task. Realizing that the
gold data available for NER is quite limited in size
especially given the diverse genres in the set, we
devise a method to bootstrap additional instances
for the new features of interest from noisily NER
tagged Arabic data.
</bodyText>
<sectionHeader confidence="0.966708" genericHeader="method">
2 Our Approach
</sectionHeader>
<bodyText confidence="0.763246705882353">
We use our state-of-the-art NER system described
in (Benajiba et al., 2008) as our baseline sys-
tem (BASE) since it yields, to our knowledge, the
best performance for Arabic NER . BASE em-
ploys Support Vector Machines (SVMs) and Con-
ditional Random Fields (CRFs) as Machine Learn-
ing (ML) approaches. BASE uses lexical, syn-
tactic and morphological features extracted using
highly accurate automatic Arabic POS-taggers.
BASE employs a multi-classifier approach where
each classifier is tagging a NE class separately.
The feature selection is performed by using an in-
cremental approach selecting the top n features
(the features are ranked according to their individ-
ual impact) at each iteration and keeping the set
that yields the best results. In case of conflict - a
word is classified with more than one class/tag si-
multaneously - the global NER system selects the
output of the classifier with the highest precision.
The following is the feature set used in (Bena-
jiba et al., 2008) and accordingly in the BASE sys-
tem. 1. Context: a −/ + 1 token window; 2. Lex-
ical: character n − grams where n ranges from
1− 3; 3. Gazetteers: automatically harvested and
manually cleaned Person NE class (PER), Geopo-
litical Entity NE class (GPE), and Organization
NE class (ORG) lexica; 4. POS-tag and Base
Phrase Chunk (BPC): automatically tagged us-
ing AMIRA (Diab et al., 2007) which yields F-
measures for both tasks in the high 90’s; 5. Mor-
phological features: automatically tagged using
the Morphological Analysis and Disambiguation
for Arabic (MADA) tool to extract information
about gender, number, person, definiteness and as-
</bodyText>
<page confidence="0.924579">
281
</page>
<note confidence="0.45184">
Proceedings of the ACL 2010 Conference Short Papers, pages 281–285,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.8758405">
pect for each word (Habash and Rambow, 2005);
6. Capitalization: derived as a side effect from
</listItem>
<bodyText confidence="0.991572">
running MADA. MADA chooses a specific mor-
phological analysis given the context of a given
word. As part of the morphological information
available in the underlying lexicon that MADA ex-
ploits. As part of the information present, the un-
derlying lexicon has an English gloss associated
with each entry. More often than not, if the word
is a NE in Arabic then the gloss will also be a NE
in English and hence capitalized.
We devise an extended Arabic NER system (EX-
TENDED) that uses the same architecture as
BASE but employs additional features to those in
BASE. EXTENDED defines new additional syn-
tagmatic features.
We specifically investigate the space of the sur-
rounding context for the NEs. We explore gener-
alizations over the kinds of words that occur with
NEs and the syntactic relations NEs engage in. We
use an off-the-shelf Arabic syntactic parser. State-
of-the-art for Arabic syntactic parsing for the most
common genre (with the most training data) of
Arabic data, newswire, is in the low 80%s. Hence,
we acknowledge that some of the derived syntactic
features will be noisy.
Similar to all supervised ML problems, it is de-
sirable to have sufficient training data for the rele-
vant phenomena. The size of the manually anno-
tated gold data typically used for training Arabic
NER systems poses a significant challenge for ro-
bustly exploring deeper syntactic and lexical fea-
tures. Accordingly, we bootstrap more NE tagged
data via projection over Arabic-English parallel
data. The role of this data is simply to give us more
instances of the newly defined features (namely
the syntagmatic features) in the EXTENDED sys-
tem as well as more instances for the Gazetteers
and Context features defined in BASE. It is worth
noting that we do not use the bootstrapped NE
tagged data directly as training data with the gold
data.
</bodyText>
<subsectionHeader confidence="0.993973">
2.1 Syntagmatic Features
</subsectionHeader>
<bodyText confidence="0.998426333333333">
For deriving our deeper linguistic features, we
parse the Arabic sentences that contain an NE. For
each of the NEs, we extract a number of features
described as follows:
- Syntactic head-word (SHW): The idea here
is to look for a broader relevant context.
Whereas the feature lexical n-gram context fea-
ture used in BASE, and hence here for EX-
TENDED, considers the linearly adjacent neigh-
boring words of a NE, SHW uses a parse tree
to look at farther, yet related, words. For
instance, in the Arabic phrase “SrH Ams An
</bodyText>
<figureCaption confidence="0.890881">
Figure 1: Example for the head word and syntactic
environment feature
</figureCaption>
<bodyText confidence="0.999664148148148">
bArAk AwbAma ytrAs”, which means “de-
clared yesterday that Barack Obama governs
...”, glossed “SrH/declared Ams/yesterday An/that
bArAk/Barack AwbAmA/Obama ytrAs/governs
...”, is parsed in Figure 1. According to the phrase
structure parse, the first parent sub-tree headword
of the NE “bArAk AwbAmA” is the verb ‘ytrAs’
(governs), the second one is ‘An’ (that) and the
third one is the verb ‘SrH’ (declared). This exam-
ple illustrates that the word “Ams” is ignored for
this feature set since it is not a syntactic head. This
is a lexicalized feature.
- Syntactic Environment (SE): This follows in the
same spirit as SHW, but expands the idea in that
it looks at the parent non-terminal instead of the
parent head word, hence it is not a lexicalized fea-
ture. The goal being to use a more abstract repre-
sentation level of the context in which a NE ap-
pears. For instance, for the same example pre-
sented in Figure 1, the first, second, and third non-
terminal parents of the NE “bArAk AwbAmA” are
‘S’, ‘SBAR’ and ‘VP’, respectively.
In our experiments we use the Bikel implementa-
tion (Bikel, 2004) of the Collins parser (Collins,
1999) which is freely available on the web2. It is a
head-driven CFG-style parser trained to parse En-
glish, Arabic, and Chinese.
</bodyText>
<subsectionHeader confidence="0.999761">
2.2 Bootstrapping Noisy Arabic NER Data
</subsectionHeader>
<bodyText confidence="0.9999546">
Extracting the syntagmatic features from the
training data yields relatively small number of
instances. Hence the need for additional tagged
data. The new Arabic NER tagged data is derived
via projection exploiting parallel Arabic English
data. The process depends on the availability
of two key components: a large Arabic English
parallel corpus that is sentence and word aligned,
and a robust high performing English NER
system. The process is as follows. We NE tag the
</bodyText>
<footnote confidence="0.9849565">
2http://www.cis.upenn.edu/—dbikel/software.html#stat-
parser
</footnote>
<page confidence="0.992244">
282
</page>
<bodyText confidence="0.999753916666667">
English side of the parallel corpus. We project
the automatically tagged NER tags from the
English side to the Arabic side of the parallel
corpus. In our case, we have access to a large
manually aligned parallel corpus, therefore the
NER projection is direct. However, the English
side of the parallel corpus is not NER tagged,
hence we use an off-the-shelf competitive robust
automatic English NER system which has a
published performance of 92% (Zitouni and
Florian, 2009). The result of these two processes
is a large Arabic NER, albeit noisy, tagged data
set. As mentioned earlier this data is used only
for deriving additional instances for training
for the syntagmatic features and for the context
and gazetteer features.3 Given this additional
source of data, we changed the lexical features
extracted from the BASE to the EXTENDED. We
added two other lexical features: CBG and NGC,
described as follows: - Class Based Gazetteers
(CBG): This feature focuses on the surface form
of the NEs. We group the NEs encountered on the
Arabic side of the parallel corpus by class as they
are found in different dictionaries. The difference
between this feature and that in BASE is that the
Gazetteers are not restricted to Wikipedia sources.
- N-gram context (NGC): Here we disregard
the surface form of the NE, instead we focus on its
lexical context. For each n, where n varies from 1
to 3, we compile a list of the −n, +n, and −/ + n
words surrounding the NE. Similar to the CBG
feature, these lists are also separated by NE class.
It is worth highlighting that the NCG feature is
different from the Context feature in BASE in
that the window size is different +/ − 1 − 3 for
EXTENDED versus +/ − 1 for BASE.
</bodyText>
<sectionHeader confidence="0.999555" genericHeader="method">
3 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.999675">
3.1 Gold Data for training and evaluation
</subsectionHeader>
<bodyText confidence="0.999962461538462">
We use the standard sets of ACE 2003, ACE
2004 and ACE 2005.4 The ACE data is annotated
for many tasks: Entity Detection and Tracking
(EDT), Relation Detection and Recognition
(RDR), Event Detection and Recognition (EDR).
All the data sets comprise Broadcast News
(BN) and Newswire (NW) genres. ACE 2004
includes an additional NW data set from the
Arabic TreeBank (ATB). ACE 2005 includes
a different genre of Weblogs (WL). The NE
classes adopted in the annotation of the ACE
2003 data are: Person (PER), Geo Political Entity
(GPE), Organization (ORG) and Facility (FAC).
</bodyText>
<footnote confidence="0.998076666666667">
3Therefore, we did not do the full feature extraction for
the other features described in BASE for this data.
4http://www.nist.gov/speech/tests/ace/
</footnote>
<bodyText confidence="0.991418">
Additionally for the ACE 2004 and 2005 data, two
NE classes are added to the ACE 2003 tag-set:
Vehicles (e.g. Rotterdam Ship) and Weapons (e.g.
Kalashnikof). We use the same split for train, de-
velopment, and test used in (Benajiba et al., 2008).
</bodyText>
<subsectionHeader confidence="0.999512">
3.2 Parallel Data
</subsectionHeader>
<bodyText confidence="0.9992465">
Most of the hand-aligned Arabic-English parallel
data used in our experiments is from the Language
Data Consortium (LDC).5. Another set of the par-
allel data is annotated in-house by professional an-
notators. The corpus has texts of five different gen-
res, namely: newswire, news groups, broadcast
news, broadcast conversation and weblogs corre-
sponding to the data genres in the ACE gold data.
The Arabic side of the parallel corpus contains
941,282 tokens. After projecting the NE tags from
the English side to the Arabic side of the paral-
lel corpus, we obtain a total of 57,290 Arabic NE
instances. Table 1 shows the number of NEs for
each class.
</bodyText>
<table confidence="0.9782545">
Class Number of NEs Class Number of NEs
FAC 998 PER 17,964
LOC 27,651 VEH 85
ORG 10,572 WEA 20
</table>
<tableCaption confidence="0.871629">
Table 1: Number of NEs per class in the Arabic
side of the parallel corpus
</tableCaption>
<subsectionHeader confidence="0.995307">
3.3 Individual Feature Impact
</subsectionHeader>
<bodyText confidence="0.999974947368421">
Across the board, all the features yield improved
performance. The highest obtained result is ob-
served where the first non-terminal parent is used
as a feature, a Syntactic Environment (SE) fea-
ture, yielding an improvement of up to 4 points
over the baseline. We experiment with different
sizes for the SE, i.e. taking the first parent versus
adding neighboring non-terminal parents. We note
that even though we observe an overall increase
in performance, considering both the {first, sec-
ond} or the {first, second, and third} non-terminal
parents decreases performance by 0.5 and 1.5 F-
measure points, respectively, compared to consid-
ering the first parent information alone. The head
word features, SHW, show a higher positive im-
pact than the lexical context feature, NGC. Finally,
the Gazetteer feature, CBG, impact is comparable
to the obtained improvement of the lexical context
feature.
</bodyText>
<subsectionHeader confidence="0.975255">
3.4 Feature Combination Experiments
</subsectionHeader>
<bodyText confidence="0.9994858">
Table 2 illustrates the final results. It shows for
each data set and each genre the F-measure ob-
tained using the best feature set and ML approach.
It shows results for both the dev and test data us-
ing the optimal number of features selected from
</bodyText>
<footnote confidence="0.96089">
5All the LDC data are publicly available
</footnote>
<page confidence="0.992576">
283
</page>
<table confidence="0.980733571428572">
ACE 2003 ACE 2004 ACE 2005
BN NW BN NW ATB BN NW WL
FreqBaseline 73.74 67.61 62.17 51.67 62.94 70.18 57.17 27.66
dev All-Synt. 83.41 79.11 76.90 72.90 74.82 81.42 76.07 54.49
All 83.93 79.72 78.54 72.80 74.97 81.82 75.92 55.65
test All-Synt. 83.50 78.90 76.70 72.40 73.50 81.31 75.30 57.30
All 84.32 79.4 78.12 72.13 74.54 81.73 75.67 58.11
</table>
<tableCaption confidence="0.998238">
Table 2: Final Results obtained with selected features contrasted against all features combined
</tableCaption>
<bodyText confidence="0.9999345">
the all the features except the syntagmatic ones
(All-Synt.) contrasted against the system in-
cluding the semantic features, i.e. All the features,
per class All. The baseline results, FreqBaseline,
assigns a test token the most frequent tag observed
for it in the gold training data, if a test token is
not observed in the training data, it is assigned the
most frequent tag which is the O tag.
</bodyText>
<sectionHeader confidence="0.999876" genericHeader="method">
4 Results Discussion
</sectionHeader>
<bodyText confidence="0.999900269230769">
Individual feature impact results show that the
syntagmatic features are helpful for most of the
data sets. The highest improvements are obtained
for the 2003 BN and 2005 WL data-sets. The im-
provement varies significantly from one data-set
to another because it highly depends on the num-
ber of NEs which the model has not been able to
capture using the contextual, lexical, syntactic and
morphological features.
Impact of the features extracted from the paral-
lel corpus per class: The syntagmatic features
have varied in their influence on the different NE
classes. Generally, the LOC and PER classes ben-
efitted more from the head word features, SHW),
than the other classes. On the other hand for the
syntactic environment feature (SE), the PER class
seemed not to benefit much from the presence of
this feature. Weblogs: Our results show that the
random contexts in which the NEs tend to ap-
pear in the WL documents stand against obtain-
ing a significant improvement. Consequently, the
features which use a more global context (syntac-
tic environment, SE, and head word, SHW, fea-
tures) have helped obtain better results than the
ones which we have obtained using local context
namely CBG and NGC.
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999940275862069">
Projecting explicit linguistic tags from another
language via parallel corpora has been widely used
in the NLP tasks and has proved to contribute sig-
nificantly to achieving better performance. Dif-
ferent research works report positive results when
using this technique to enhance WSD (Diab and
Resnik, 2002; Ng et al., 2003). In the latter two
works, they augment training data from parallel
data for training supervised systems. In (Diab,
2004), the author uses projections from English
into Arabic to bootstrap a sense tagging system
for Arabic as well as a seed Arabic WordNet
through projection. In (Hwa et al., 2002), the
authors report promising results of inducing Chi-
nese dependency trees from English. The ob-
tained model outperformed the baseline. More re-
cently, in (Chen and Ji, 2009), the authors report
their comparative study between monolingual and
cross-lingual bootstrapping. Finally, in Mention
Detection (MD), a task which includes NER and
adds the identification and classification of nom-
inal and pronominal mentions, (Zitouni and Flo-
rian, 2008) show the impact of using a MT sys-
tem to enhance the performance of an Arabic MD
model. The authors report an improvement of up
to 1.6F when the baseline system uses lexical fea-
tures only. Unlike the work we present here, their
approach requires the availability of an accurate
MT system which is a more expensive process.
</bodyText>
<sectionHeader confidence="0.996447" genericHeader="conclusions">
6 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.999563769230769">
In this paper we investigate the possibility of
building a high performance Arabic NER system
by using lexical, syntactic and morphological fea-
tures and augmenting the model with deeper lexi-
cal features and more syntagmatic features. These
extra features are extracted from noisy data ob-
tained via projection from an Arabic-English par-
allel corpus. Our results show that we achieve a
significantly high performance for almost all the
data-sets. The greatest impact of the syntagmatic
features (1.64 points of F-measure) is obtained for
the ACE 2004, BN genre. Also, the WL genre
yields an improvement of 1.16 F1 points absolute.
</bodyText>
<sectionHeader confidence="0.998268" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9405715">
This work has been partially funded by DARPA GALE
project. The research of the last author was funded
by MICINN research project TEXT-ENTERPRISE 2.0
TIN2009-13391-C04-03 (Plan I+D+i).
</bodyText>
<page confidence="0.996576">
284
</page>
<sectionHeader confidence="0.990329" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999926862068966">
B. Babych and A. Hartley. 2003. Improving Machine
Translation Quality with Automatic Named Entity
Recognition. In Proc. of EACL-EAMT.
Y. Benajiba, M. Diab, and P. Rosso. 2008. Ara-
bic named entity recognition using optimized feature
sets. In Proceedings of EMNLP’08, pages 284–293.
Daniel M. Bikel. 2004. On the parameter space
of generative lexicalized statistical parsing models.
University of Pennsylvania, Philadelphia, PA, USA.
Supervisor-Marcus, Mitchell P.
Z. Chen and H. Ji. 2009. Can one language bootstrap
the other: A case study of event extraction. In Pro-
ceedings of NAACL’09.
M. Collins. 1999. Head-Driven Statistical Models for
Nat- ural Language Parsing. University of Pennsyl-
vania, Philadelphia, PA, USA.
Mona Diab and Philip Resnik. 2002. An unsuper-
vised method for word sense tagging using parallel
corpora. In Proceedings of 40th Annual Meeting
of the Association for Computational Linguistics,
pages 255–262, Philadelphia, Pennsylvania, USA,
July. Association for Computational Linguistics.
M. Diab, K. Hacioglu, and D. Jurafsky, 2007. Arabic
Computational Morphology: Knowledge-based and
Empirical Methods, chapter 9. Springer.
Mona Diab. 2004. Bootstrapping a wordnet taxonomy
for arabic. In Proceedings of First Arabic Language
Technology Conference (NEMLAR), Cairo Egypt,.
N. Habash and O. Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morpholog-
ical Disambiguation in One Fell Swoop. In Proc.
of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL’05), pages 573–
580, Ann Arbor, Michigan, June. Association for
Computational Linguistics.
R. Hwa, P. Resnik, and A. Weinberg. 2002. Break-
ing the resource bottleneck for multilingual parsing.
In In Proceedings of the Workshop on Linguistic
Knowledge Acquisition and Representation: Boot-
strapping Annotated Language Data.
D. Nadeau and S. Sekine. 2007. A Survey of Named
Entity Recognition and Classification. Linguisticae
Investigationes, 30(7).
H.-T. Ng, B. Wang, and Y.-S. Chan. 2003. Exploit-
ing parallel texts for word sense disambiguation: An
empirical study. In ACL’03, pages 455–462, Sap-
poro, Japan.
P. Thompson and C. Dozier. 1997. Name Searching
and Information Retrieval. In In Proc. of Second
Conference on Empirical Methods in Natural Lan-
guage Processing, Providence, Rhode Island.
I. Zitouni and R. Florian. 2008. Mention detection
crossing the language barrier. In Proceedings of
EMNLP’08, Honolulu, Hawaii, October.
Imed Zitouni and Radu Florian. 2009. Cross language
information propagation for arabic mention detec-
tion. Journal of ACM Transactions on Asian Lan-
guage Information Processing, December.
</reference>
<page confidence="0.998526">
285
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.285949">
<title confidence="0.995428">Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</title>
<author confidence="0.94526">Imed Mona Paolo</author>
<affiliation confidence="0.999661">sCenter for Computational Learning Systems, Columbia University</affiliation>
<address confidence="0.705714">2IBM T.J. Watson Research Center, Yorktown Heights 3Natural Language Engineering Lab. - ELiRF, Universidad Polit´ecnica de Valencia</address>
<email confidence="0.912787">izitouni@us.ibm.com,prosso@dsic.upv.es</email>
<abstract confidence="0.97042">Building an accurate Named Entity Recognition (NER) system for languages with complex morphology is a challenging task. In this paper, we present research that explores the feature space using both gold and bootstrapped noisy features to build an improved highly accurate Arabic NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Babych</author>
<author>A Hartley</author>
</authors>
<title>Improving Machine Translation Quality with Automatic Named Entity Recognition.</title>
<date>2003</date>
<booktitle>In Proc. of EACL-EAMT.</booktitle>
<contexts>
<context position="1292" citStr="Babych and Hartley, 2003" startWordPosition="176" endWordPosition="179">ed highly accurate Arabic NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute). 1 Introduction Named Entity Recognition (NER) has earned an important place in Natural Language Processing (NLP) as an enabling process for other tasks. When explicitly taken into account, research shows that it helps such applications achieve better performance levels (Babych and Hartley, 2003; Thompson and Dozier, 1997). NER is defined as the computational identification and classification of Named Entities (NEs) in running text. For instance, consider the following text: Barack Obama is visiting the Middle East. A NER system should be able to identify Barack Obama and Middle East as NEs and classify them as Person (PER) and Geo-Political Entity (GPE), respectively. The class-set used to tag NEs may vary according to user needs. In this research, we adopt the Automatic Content Extraction (ACE) 2007 nomenclature1. According to (Nadeau and Sekine, 2007), optimization of the feature </context>
</contexts>
<marker>Babych, Hartley, 2003</marker>
<rawString>B. Babych and A. Hartley. 2003. Improving Machine Translation Quality with Automatic Named Entity Recognition. In Proc. of EACL-EAMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Benajiba</author>
<author>M Diab</author>
<author>P Rosso</author>
</authors>
<title>Arabic named entity recognition using optimized feature sets.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP’08,</booktitle>
<pages>284--293</pages>
<contexts>
<context position="2918" citStr="Benajiba et al., 2008" startWordPosition="439" endWordPosition="442">c processing of Arabic text and the relative small size of manually annotated Arabic NER data, we set out to explore a main concrete research goal: to fully exploit the level of advancement in Arabic lexical and syntactic processing to explore deeper linguistic features for the NER task. Realizing that the gold data available for NER is quite limited in size especially given the diverse genres in the set, we devise a method to bootstrap additional instances for the new features of interest from noisily NER tagged Arabic data. 2 Our Approach We use our state-of-the-art NER system described in (Benajiba et al., 2008) as our baseline system (BASE) since it yields, to our knowledge, the best performance for Arabic NER . BASE employs Support Vector Machines (SVMs) and Conditional Random Fields (CRFs) as Machine Learning (ML) approaches. BASE uses lexical, syntactic and morphological features extracted using highly accurate automatic Arabic POS-taggers. BASE employs a multi-classifier approach where each classifier is tagging a NE class separately. The feature selection is performed by using an incremental approach selecting the top n features (the features are ranked according to their individual impact) at </context>
<context position="11711" citStr="Benajiba et al., 2008" startWordPosition="1909" endWordPosition="1912"> the Arabic TreeBank (ATB). ACE 2005 includes a different genre of Weblogs (WL). The NE classes adopted in the annotation of the ACE 2003 data are: Person (PER), Geo Political Entity (GPE), Organization (ORG) and Facility (FAC). 3Therefore, we did not do the full feature extraction for the other features described in BASE for this data. 4http://www.nist.gov/speech/tests/ace/ Additionally for the ACE 2004 and 2005 data, two NE classes are added to the ACE 2003 tag-set: Vehicles (e.g. Rotterdam Ship) and Weapons (e.g. Kalashnikof). We use the same split for train, development, and test used in (Benajiba et al., 2008). 3.2 Parallel Data Most of the hand-aligned Arabic-English parallel data used in our experiments is from the Language Data Consortium (LDC).5. Another set of the parallel data is annotated in-house by professional annotators. The corpus has texts of five different genres, namely: newswire, news groups, broadcast news, broadcast conversation and weblogs corresponding to the data genres in the ACE gold data. The Arabic side of the parallel corpus contains 941,282 tokens. After projecting the NE tags from the English side to the Arabic side of the parallel corpus, we obtain a total of 57,290 Ara</context>
</contexts>
<marker>Benajiba, Diab, Rosso, 2008</marker>
<rawString>Y. Benajiba, M. Diab, and P. Rosso. 2008. Arabic named entity recognition using optimized feature sets. In Proceedings of EMNLP’08, pages 284–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>On the parameter space of generative lexicalized statistical parsing models.</title>
<date>2004</date>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA. Supervisor-Marcus, Mitchell P.</location>
<contexts>
<context position="8232" citStr="Bikel, 2004" startWordPosition="1332" endWordPosition="1333">re set since it is not a syntactic head. This is a lexicalized feature. - Syntactic Environment (SE): This follows in the same spirit as SHW, but expands the idea in that it looks at the parent non-terminal instead of the parent head word, hence it is not a lexicalized feature. The goal being to use a more abstract representation level of the context in which a NE appears. For instance, for the same example presented in Figure 1, the first, second, and third nonterminal parents of the NE “bArAk AwbAmA” are ‘S’, ‘SBAR’ and ‘VP’, respectively. In our experiments we use the Bikel implementation (Bikel, 2004) of the Collins parser (Collins, 1999) which is freely available on the web2. It is a head-driven CFG-style parser trained to parse English, Arabic, and Chinese. 2.2 Bootstrapping Noisy Arabic NER Data Extracting the syntagmatic features from the training data yields relatively small number of instances. Hence the need for additional tagged data. The new Arabic NER tagged data is derived via projection exploiting parallel Arabic English data. The process depends on the availability of two key components: a large Arabic English parallel corpus that is sentence and word aligned, and a robust hig</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel M. Bikel. 2004. On the parameter space of generative lexicalized statistical parsing models. University of Pennsylvania, Philadelphia, PA, USA. Supervisor-Marcus, Mitchell P.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Chen</author>
<author>H Ji</author>
</authors>
<title>Can one language bootstrap the other: A case study of event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL’09.</booktitle>
<contexts>
<context position="16654" citStr="Chen and Ji, 2009" startWordPosition="2734" endWordPosition="2737">tter performance. Different research works report positive results when using this technique to enhance WSD (Diab and Resnik, 2002; Ng et al., 2003). In the latter two works, they augment training data from parallel data for training supervised systems. In (Diab, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Mention Detection (MD), a task which includes NER and adds the identification and classification of nominal and pronominal mentions, (Zitouni and Florian, 2008) show the impact of using a MT system to enhance the performance of an Arabic MD model. The authors report an improvement of up to 1.6F when the baseline system uses lexical features only. Unlike the work we present here, their approach requires the availability of an accurate MT system which is a more expensive process. 6 Concl</context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Z. Chen and H. Ji. 2009. Can one language bootstrap the other: A case study of event extraction. In Proceedings of NAACL’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Nat- ural Language Parsing.</title>
<date>1999</date>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="8270" citStr="Collins, 1999" startWordPosition="1338" endWordPosition="1339">ead. This is a lexicalized feature. - Syntactic Environment (SE): This follows in the same spirit as SHW, but expands the idea in that it looks at the parent non-terminal instead of the parent head word, hence it is not a lexicalized feature. The goal being to use a more abstract representation level of the context in which a NE appears. For instance, for the same example presented in Figure 1, the first, second, and third nonterminal parents of the NE “bArAk AwbAmA” are ‘S’, ‘SBAR’ and ‘VP’, respectively. In our experiments we use the Bikel implementation (Bikel, 2004) of the Collins parser (Collins, 1999) which is freely available on the web2. It is a head-driven CFG-style parser trained to parse English, Arabic, and Chinese. 2.2 Bootstrapping Noisy Arabic NER Data Extracting the syntagmatic features from the training data yields relatively small number of instances. Hence the need for additional tagged data. The new Arabic NER tagged data is derived via projection exploiting parallel Arabic English data. The process depends on the availability of two key components: a large Arabic English parallel corpus that is sentence and word aligned, and a robust high performing English NER system. The p</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>M. Collins. 1999. Head-Driven Statistical Models for Nat- ural Language Parsing. University of Pennsylvania, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Philip Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>255--262</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="16166" citStr="Diab and Resnik, 2002" startWordPosition="2653" endWordPosition="2656">r in the WL documents stand against obtaining a significant improvement. Consequently, the features which use a more global context (syntactic environment, SE, and head word, SHW, features) have helped obtain better results than the ones which we have obtained using local context namely CBG and NGC. 5 Related Work Projecting explicit linguistic tags from another language via parallel corpora has been widely used in the NLP tasks and has proved to contribute significantly to achieving better performance. Different research works report positive results when using this technique to enhance WSD (Diab and Resnik, 2002; Ng et al., 2003). In the latter two works, they augment training data from parallel data for training supervised systems. In (Diab, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Me</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>Mona Diab and Philip Resnik. 2002. An unsupervised method for word sense tagging using parallel corpora. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 255–262, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>K Hacioglu</author>
<author>D Jurafsky</author>
</authors>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods, chapter 9.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="4204" citStr="Diab et al., 2007" startWordPosition="655" endWordPosition="658">case of conflict - a word is classified with more than one class/tag simultaneously - the global NER system selects the output of the classifier with the highest precision. The following is the feature set used in (Benajiba et al., 2008) and accordingly in the BASE system. 1. Context: a −/ + 1 token window; 2. Lexical: character n − grams where n ranges from 1− 3; 3. Gazetteers: automatically harvested and manually cleaned Person NE class (PER), Geopolitical Entity NE class (GPE), and Organization NE class (ORG) lexica; 4. POS-tag and Base Phrase Chunk (BPC): automatically tagged using AMIRA (Diab et al., 2007) which yields Fmeasures for both tasks in the high 90’s; 5. Morphological features: automatically tagged using the Morphological Analysis and Disambiguation for Arabic (MADA) tool to extract information about gender, number, person, definiteness and as281 Proceedings of the ACL 2010 Conference Short Papers, pages 281–285, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pect for each word (Habash and Rambow, 2005); 6. Capitalization: derived as a side effect from running MADA. MADA chooses a specific morphological analysis given the context of a given word. As</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2007</marker>
<rawString>M. Diab, K. Hacioglu, and D. Jurafsky, 2007. Arabic Computational Morphology: Knowledge-based and Empirical Methods, chapter 9. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Bootstrapping a wordnet taxonomy for arabic.</title>
<date>2004</date>
<booktitle>In Proceedings of First Arabic Language Technology Conference (NEMLAR),</booktitle>
<location>Cairo</location>
<contexts>
<context position="16305" citStr="Diab, 2004" startWordPosition="2678" endWordPosition="2679">nment, SE, and head word, SHW, features) have helped obtain better results than the ones which we have obtained using local context namely CBG and NGC. 5 Related Work Projecting explicit linguistic tags from another language via parallel corpora has been widely used in the NLP tasks and has proved to contribute significantly to achieving better performance. Different research works report positive results when using this technique to enhance WSD (Diab and Resnik, 2002; Ng et al., 2003). In the latter two works, they augment training data from parallel data for training supervised systems. In (Diab, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Mention Detection (MD), a task which includes NER and adds the identification and classification of nominal and pronominal mentions, (Zitouni</context>
</contexts>
<marker>Diab, 2004</marker>
<rawString>Mona Diab. 2004. Bootstrapping a wordnet taxonomy for arabic. In Proceedings of First Arabic Language Technology Conference (NEMLAR), Cairo Egypt,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4655" citStr="Habash and Rambow, 2005" startWordPosition="721" endWordPosition="724">ER), Geopolitical Entity NE class (GPE), and Organization NE class (ORG) lexica; 4. POS-tag and Base Phrase Chunk (BPC): automatically tagged using AMIRA (Diab et al., 2007) which yields Fmeasures for both tasks in the high 90’s; 5. Morphological features: automatically tagged using the Morphological Analysis and Disambiguation for Arabic (MADA) tool to extract information about gender, number, person, definiteness and as281 Proceedings of the ACL 2010 Conference Short Papers, pages 281–285, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pect for each word (Habash and Rambow, 2005); 6. Capitalization: derived as a side effect from running MADA. MADA chooses a specific morphological analysis given the context of a given word. As part of the morphological information available in the underlying lexicon that MADA exploits. As part of the information present, the underlying lexicon has an English gloss associated with each entry. More often than not, if the word is a NE in Arabic then the gloss will also be a NE in English and hence capitalized. We devise an extended Arabic NER system (EXTENDED) that uses the same architecture as BASE but employs additional features to thos</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>N. Habash and O. Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573– 580, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
</authors>
<title>Breaking the resource bottleneck for multilingual parsing. In</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</booktitle>
<contexts>
<context position="16481" citStr="Hwa et al., 2002" startWordPosition="2706" endWordPosition="2709">jecting explicit linguistic tags from another language via parallel corpora has been widely used in the NLP tasks and has proved to contribute significantly to achieving better performance. Different research works report positive results when using this technique to enhance WSD (Diab and Resnik, 2002; Ng et al., 2003). In the latter two works, they augment training data from parallel data for training supervised systems. In (Diab, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Mention Detection (MD), a task which includes NER and adds the identification and classification of nominal and pronominal mentions, (Zitouni and Florian, 2008) show the impact of using a MT system to enhance the performance of an Arabic MD model. The authors report an improvement of up to 1.6F when the baseline sys</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, 2002</marker>
<rawString>R. Hwa, P. Resnik, and A. Weinberg. 2002. Breaking the resource bottleneck for multilingual parsing. In In Proceedings of the Workshop on Linguistic Knowledge Acquisition and Representation: Bootstrapping Annotated Language Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nadeau</author>
<author>S Sekine</author>
</authors>
<title>A Survey of Named Entity Recognition and Classification. Linguisticae Investigationes,</title>
<date>2007</date>
<volume>30</volume>
<issue>7</issue>
<contexts>
<context position="1862" citStr="Nadeau and Sekine, 2007" startWordPosition="266" endWordPosition="269">ve better performance levels (Babych and Hartley, 2003; Thompson and Dozier, 1997). NER is defined as the computational identification and classification of Named Entities (NEs) in running text. For instance, consider the following text: Barack Obama is visiting the Middle East. A NER system should be able to identify Barack Obama and Middle East as NEs and classify them as Person (PER) and Geo-Political Entity (GPE), respectively. The class-set used to tag NEs may vary according to user needs. In this research, we adopt the Automatic Content Extraction (ACE) 2007 nomenclature1. According to (Nadeau and Sekine, 2007), optimization of the feature set is the key component in enhancing the performance of a global NER system. In this paper we investigate the possibility of building a high performance Arabic NER system by using a large space of available feature sets that go beyond the explored shallow feature sets used to date in the literature for Arabic NER. 1http://www.nist.gov/speech/tests/ace/index.htm Given current state-of-the-art syntactic processing of Arabic text and the relative small size of manually annotated Arabic NER data, we set out to explore a main concrete research goal: to fully exploit t</context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>D. Nadeau and S. Sekine. 2007. A Survey of Named Entity Recognition and Classification. Linguisticae Investigationes, 30(7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-T Ng</author>
<author>B Wang</author>
<author>Y-S Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In ACL’03,</booktitle>
<pages>455--462</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="16184" citStr="Ng et al., 2003" startWordPosition="2657" endWordPosition="2660">tand against obtaining a significant improvement. Consequently, the features which use a more global context (syntactic environment, SE, and head word, SHW, features) have helped obtain better results than the ones which we have obtained using local context namely CBG and NGC. 5 Related Work Projecting explicit linguistic tags from another language via parallel corpora has been widely used in the NLP tasks and has proved to contribute significantly to achieving better performance. Different research works report positive results when using this technique to enhance WSD (Diab and Resnik, 2002; Ng et al., 2003). In the latter two works, they augment training data from parallel data for training supervised systems. In (Diab, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Mention Detection (M</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>H.-T. Ng, B. Wang, and Y.-S. Chan. 2003. Exploiting parallel texts for word sense disambiguation: An empirical study. In ACL’03, pages 455–462, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Thompson</author>
<author>C Dozier</author>
</authors>
<title>Name Searching and Information Retrieval. In</title>
<date>1997</date>
<booktitle>In Proc. of Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Providence, Rhode Island.</location>
<contexts>
<context position="1320" citStr="Thompson and Dozier, 1997" startWordPosition="180" endWordPosition="183">NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute). 1 Introduction Named Entity Recognition (NER) has earned an important place in Natural Language Processing (NLP) as an enabling process for other tasks. When explicitly taken into account, research shows that it helps such applications achieve better performance levels (Babych and Hartley, 2003; Thompson and Dozier, 1997). NER is defined as the computational identification and classification of Named Entities (NEs) in running text. For instance, consider the following text: Barack Obama is visiting the Middle East. A NER system should be able to identify Barack Obama and Middle East as NEs and classify them as Person (PER) and Geo-Political Entity (GPE), respectively. The class-set used to tag NEs may vary according to user needs. In this research, we adopt the Automatic Content Extraction (ACE) 2007 nomenclature1. According to (Nadeau and Sekine, 2007), optimization of the feature set is the key component in </context>
</contexts>
<marker>Thompson, Dozier, 1997</marker>
<rawString>P. Thompson and C. Dozier. 1997. Name Searching and Information Retrieval. In In Proc. of Second Conference on Empirical Methods in Natural Language Processing, Providence, Rhode Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zitouni</author>
<author>R Florian</author>
</authors>
<title>Mention detection crossing the language barrier.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP’08,</booktitle>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="16924" citStr="Zitouni and Florian, 2008" startWordPosition="2771" endWordPosition="2775">, 2004), the author uses projections from English into Arabic to bootstrap a sense tagging system for Arabic as well as a seed Arabic WordNet through projection. In (Hwa et al., 2002), the authors report promising results of inducing Chinese dependency trees from English. The obtained model outperformed the baseline. More recently, in (Chen and Ji, 2009), the authors report their comparative study between monolingual and cross-lingual bootstrapping. Finally, in Mention Detection (MD), a task which includes NER and adds the identification and classification of nominal and pronominal mentions, (Zitouni and Florian, 2008) show the impact of using a MT system to enhance the performance of an Arabic MD model. The authors report an improvement of up to 1.6F when the baseline system uses lexical features only. Unlike the work we present here, their approach requires the availability of an accurate MT system which is a more expensive process. 6 Conclusion and Future Directions In this paper we investigate the possibility of building a high performance Arabic NER system by using lexical, syntactic and morphological features and augmenting the model with deeper lexical features and more syntagmatic features. These ex</context>
</contexts>
<marker>Zitouni, Florian, 2008</marker>
<rawString>I. Zitouni and R. Florian. 2008. Mention detection crossing the language barrier. In Proceedings of EMNLP’08, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Radu Florian</author>
</authors>
<title>Cross language information propagation for arabic mention detection.</title>
<date>2009</date>
<journal>Journal of ACM Transactions on Asian Language Information Processing,</journal>
<contexts>
<context position="9443" citStr="Zitouni and Florian, 2009" startWordPosition="1519" endWordPosition="1522">nd a robust high performing English NER system. The process is as follows. We NE tag the 2http://www.cis.upenn.edu/—dbikel/software.html#statparser 282 English side of the parallel corpus. We project the automatically tagged NER tags from the English side to the Arabic side of the parallel corpus. In our case, we have access to a large manually aligned parallel corpus, therefore the NER projection is direct. However, the English side of the parallel corpus is not NER tagged, hence we use an off-the-shelf competitive robust automatic English NER system which has a published performance of 92% (Zitouni and Florian, 2009). The result of these two processes is a large Arabic NER, albeit noisy, tagged data set. As mentioned earlier this data is used only for deriving additional instances for training for the syntagmatic features and for the context and gazetteer features.3 Given this additional source of data, we changed the lexical features extracted from the BASE to the EXTENDED. We added two other lexical features: CBG and NGC, described as follows: - Class Based Gazetteers (CBG): This feature focuses on the surface form of the NEs. We group the NEs encountered on the Arabic side of the parallel corpus by cla</context>
</contexts>
<marker>Zitouni, Florian, 2009</marker>
<rawString>Imed Zitouni and Radu Florian. 2009. Cross language information propagation for arabic mention detection. Journal of ACM Transactions on Asian Language Information Processing, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>