<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002434">
<title confidence="0.9846655">
Modeling Letter-to-Phoneme Conversion as a Phrase Based Statistical
Machine Translation Problem with Minimum Error Rate Training
</title>
<author confidence="0.892178">
Taraka Rama, Anil Kumar Singh, Sudheer Kolachina
</author>
<affiliation confidence="0.9129">
Language Technologies Research Centre,
IIIT, Hyderabad, India.
</affiliation>
<email confidence="0.891101">
{taraka@students,anil@research,sudheer.kpg08@research}.iiit.ac.in
</email>
<sectionHeader confidence="0.984836" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999761266666667">
Letter-to-phoneme conversion plays an impor-
tant role in several applications. It can be a dif-
ficult task because the mapping from letters to
phonemes can be many-to-many. We present a
language independent letter-to-phoneme con-
version approach which is based on the pop-
ular phrase based Statistical Machine Trans-
lation techniques. The results of our ex-
periments clearly demonstrate that such tech-
niques can be used effectively for letter-to-
phoneme conversion. Our results show an
overall improvement of 5.8% over the base-
line and are comparable to the state of the art.
We also propose a measure to estimate the dif-
ficulty level of L2P task for a language.
</bodyText>
<sectionHeader confidence="0.99548" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99979504">
Letter-to-phoneme (L2P) conversion can be defined
as the task of predicting the pronunciation of a
word given its orthographic form (Bartlett et al.,
2008).The pronunciation is usually represented as
a sequence of phonemes. Letter-to-phoneme con-
version systems play a very important role in spell
checkers (Toutanova and Moore, 2002), speech syn-
thesis systems (Schroeter et al., 2002) and translit-
eration (Sherif and Kondrak, 2007). Letter-to-
phoneme conversion systems may also be effec-
tively used for cognate identification and translitera-
tion. The existing cognate identification systems use
the orthographic form of a word as the input. But we
know that the correspondence between written and
spoken forms of words can be quite irregular as is
the case in English. Even in other languages with
supposedly regular spellings, this irregularity exists
owing to linguistic phenomena like borrowing and
language variation. Letter-to-phoneme conversion
systems can facilitate the task of cognate identifica-
tion by providing a language independent transcrip-
tion for any word.
Until a few years ago, letter-to-phoneme conver-
sion was performed considering only one-one cor-
respondences (Black et al., 1998; Damper et al.,
2004). Recent work uses many-to-many correspon-
dences (Jiampojamarn et al., 2007) and reports sig-
nificantly higher accuracy for Dutch, German and
French. The current state of the art systems give as
much as 90% (Jiampojamarn et al., 2008) accuracy
for languages like Dutch, German and French. How-
ever, accuracy of this level is yet to be achieved for
English.
Rule-based approaches to the problem of letter-
to-phoneme conversion although appealing, are im-
practical as the number of rules for a particular lan-
guage can be very high (Kominek and Black, 2006).
Alternative approaches to this problem are based on
machine learning and make use of resources such as
pronunciation dictionaries. In this paper, we present
one such machine learning based approach wherein
we envisage this problem as a Statistical Machine
Translation (SMT) problem.
The outline of the paper is as follows. Section 2
presents a brief summary of the related work done
in L2P conversion. Section 3 describes our model
and the techniques devised for optimizing the per-
formance. Section 4 describes the letter-to-phoneme
alignment. The description of the results and exper-
iments and a new technique for estimating the diffi-
</bodyText>
<page confidence="0.986585">
90
</page>
<note confidence="0.8154555">
Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 90–95,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99942775">
culty level of L2P task have been given in Section 5.
Error analysis is presented in Section 6. Finally we
conclude with a summary and suggest directions for
future work.
</bodyText>
<sectionHeader confidence="0.998922" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999930421686747">
In the letter-to-phoneme conversion task, a single
letter can map to multiple phonemes [x → ks] and
multiple letters can generate a single phoneme. A
letter can also map to a null phoneme [e → W] and
vice-versa. These examples give a glimpse of why
the task is so complex and a single machine learning
technique may not be enough to solve the problem.
A overview of the literature supports this claim.
In older approaches, the alignment between the
letters and phonemes was taken to be one-to-
one (Black et al., 1998) and the phoneme was
predicted for every single letter. But recent
work (Bisani and Ney, 2002; Jiampojamarn et al.,
2007) shows that multiple letter-to-phoneme align-
ments perform better than single letter to phoneme
alignments. The problem can be either viewed as a
multi-class classifier problem or a structure predic-
tion problem. In structure prediction, the algorithm
takes the previous decisions as the features which
influence the current decision.
In the classifier approach, only the letter and its
context are taken as features. Then, either multiclass
decision trees (Daelemans and van den Bosch, 1997)
or instance based learning as in (van den Bosch and
Daelemans, 1998) is used to predict the class, which
in this case is a phoneme. Some of these meth-
ods (Black et al., 1998) are not completely automatic
and need an initial handcrafted seeding to begin the
classification.
Structure prediction is like a tagging problem
where HMMs (Taylor, 2005) are used to model
the problem. Taylor claims that except for a pre-
processing step, it is completely automatic. The
whole process is performed in a single step. The
results are poor, as reasoned in (Jiampojamarn et al.,
2008) due to the emission probabilities not being in-
formed by the previous letter’s emission probabil-
ities. Pronunciation by Analogy (PbA) is a data-
driven method (Marchand and Damper, 2000) for
letter-to-phoneme conversion which is used again
by Damper et al (2004). They simply use an
Expectation-Maximisation (EM) like algorithm for
aligning the letter-phoneme pairs in a speech dictio-
nary. They claim that by integrating the alignments
induced by the algorithm into the PbA system, they
were able to improve the accuracy of the pronunci-
ation significantly. We also use the many-to-many
alignment approach but in a different way and ob-
tained from a different source.
The recent work of Jiampojamarn et al (2007)
combines both of the above approaches in a very in-
teresting manner. It uses an EM like algorithm for
aligning the letters and phonemes. The algorithm al-
lows many-to-many alignments between letters and
phonemes. Then there is a letter chunking module
which uses instance-based training to train on the
alignments which have been obtained in the previ-
ous step. This module is used to guess the possible
letter chunks in every word. Then a local phoneme
predictor is used to guess the phonemes for every
letter in a word. The size of the letter chunk could
be either one or two. Only one candidate for every
word is allowed. The best phoneme sequence is ob-
tained by using Viterbi search.
An online model MIRA (Crammer and Singer,
2003) which updates parameters is used for the L2P
task by Jiampojamarn et al (2008). The authors
unify the steps of letter segmentation, phoneme pre-
diction and sequence modeling into a single mod-
ule. The phoneme prediction and sequence model-
ing are considered as tagging problems and a Per-
ceptron HMM (Collins, 2002) is used to model
it. The letter segmenter module is replaced by a
monotone phrasal decoder (Zens and Ney, 2004) to
search for the possible substrings in a word and out-
put the n-best list for updating MIRA. Bisani and
Ney (2002) take the joint multigrams of graphemes
and phonemes as features for alignment and lan-
guage modeling for phonetic transcription probabili-
ties. A hybrid approach similar to this is by (van den
Bosch and Canisius, 2006).
In the next section we model the problem as a Sta-
tistical Machine Translation (SMT) task.
</bodyText>
<sectionHeader confidence="0.953682" genericHeader="method">
3 Modeling the Problem
</sectionHeader>
<bodyText confidence="0.999427666666667">
Assume that given a word, represented as a se-
quence of letters l = lJ1 = l1...lj...lJ, needs to be tran-
scribed as a sequence of phonemes, represented as f
</bodyText>
<page confidence="0.993745">
91
</page>
<bodyText confidence="0.995412375">
= fI1 = f1...fi...fI. The problem of finding the best
phoneme sequence among the candidate translations
can be represented as:
fbest
f {Pr (f  |l)} (1)
We model the problem of letter to phoneme con-
version based on the noisy channel model. Refor-
mulating the above equation using Bayes Rule:
</bodyText>
<equation confidence="0.977074">
= arg max
fbest =arg
f) wri
maxp(l  |f)pLM (3)
f
p(l|
tten as
� �
�´fI 1 exp ΣM m=1λmhm( ´fI 1 ,l)
</equation>
<bodyText confidence="0.999599">
with the denominator, a normalization factor that
can be ignored in the maximization process.
The above modeling entails finding the suitable
model parameters or weights which reflect the prop-
erties of our task. We adopt the criterion followed
in (Och, 2003) for optimising the parameters of the
model. The details of the solution and proof for the
convergence are given in Och (2003). The models’
weights, used for the L2P task, are obtained from
this training.
</bodyText>
<equation confidence="0.90156625">
� �
exp ΣM m=1λmhm(f, l)
(6)
p(¯lK1  |¯fK1 ) = �K Φ(¯lk  |¯fk) (4) grapheme is treated as a single
</equation>
<bodyText confidence="0.962042315789474">
k=1 for the
GIZA++ input. The transcription probabilities can
then be easily learnt from the alignments induced
by GIZA++, using a scoring function (Koehn et al.,
2003). Figure 1 shows the alignments induced by
GIZA++ for the example words which are men-
tioned by Jiampojamarn et al (2007). In this fig-
ure, we only show the alignments fr
‘word’
om graphemes
to phonemes.
weights can be done in the following man-
ner.
The posterior probability Pr (f
can also be
directly modeled using alog-linear model. In
this model, we have a set of M feature functions
m = 1...M . For each feature function
there exists a weight or model parameter
</bodyText>
<figure confidence="0.9324165">
m =
1...M. Thus the posterior probabili
models’
|l)
hm(f, l),
λm,
ty becomes:
=arg max
f)
(f) (2)
This formulation allows for a phoneme n-gram
model
(f) and a transcription model
Given
a sequence of letters
the argmax function is a
search function to output the best phonemic se-
quence. During the decoding phase, the letter se-
quence
is segmented into a sequence of K letter
segments
Each segment
in
is transcribed
into a phoneme segment
Thus the best phoneme
sequence is generated from left to right in the form
of partial translations. By using an n-gram model
as the lan
fbest
p(l|
p
f
p
p(l|f).
l,
l
¯lK1
¯lk
¯lK1
¯fk.
pLM
guage model, we have the equations:
with
</figure>
<bodyText confidence="0.945309625">
From the above equation, the best phoneme se-
quence is obtained based on the product of the prob-
abilities of transcription model and the probabilities
of a language model and their respective weights.
The method for obtaining the transcription probabil-
ities is described briefly in the next section. Deter-
mining the best weights is necessary for obtaining
the right phoneme sequence. The estimation of the
</bodyText>
<sectionHeader confidence="0.997206" genericHeader="method">
4 Letter-to-Phoneme Alignment
</sectionHeader>
<bodyText confidence="0.977820166666667">
We used GIZA++ (Och and Ney, 2003), an open
source toolkit, for aligning the letters with the
phonemes in the training data sets. In the context
of SMT, say English-Spanish, the parallel corpus is
aligned bidirectionally to obtain the two alignments.
The IBM models give only one-to-one alignments
between words in a sentence pair. So, GIZA++ uses
some heuristics to refine the alignments (Och and
Ney, 2003).
In our input data, the source side consists of
grapheme (or letter) sequences and the target side
consists of phoneme sequences. Every letter or
</bodyText>
<figureCaption confidence="0.995521">
Figure 1: Example Alignments fr
</figureCaption>
<equation confidence="0.727822">
om GIZA++
Pr (f  |l) = pλM1 (f  |l) (5)
</equation>
<page confidence="0.97772">
92
</page>
<sectionHeader confidence="0.992853" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999669769230769">
We evaluated our models on the English CMUDict,
French Brulex, German Celex and Dutch Celex
speech dictionaries. These dictionaries are available
for download on the website of PROANALSYL1
Letter-to-Phoneme Conversion Challenge. Table 1
shows the number of words for each language. The
datasets available at the website were divided into
10 folds. In the process of preparing the datasets we
took one set for test, another for developing our pa-
rameters and the remaining 8 sets for training. We
report our results in word accuracy rate, based on
10-fold cross validation, with mean and standard de-
viation.
</bodyText>
<table confidence="0.9946542">
Language Datasets Number of Words
English CMUDict 112241
French Brulex 27473
German Celex 49421
Dutch Celex 116252
</table>
<tableCaption confidence="0.999747">
Table 1: Number of words in each Dataset
</tableCaption>
<bodyText confidence="0.999726">
We removed the one-to-one alignments from
the corpora and induced our own alignments us-
ing GIZA++. We used minimum error rate train-
ing (Och, 2003) and the A* beam search de-
coder implemented by Koehn (Koehn et al., 2003).
All the above tools are available as parts of the
MOSES (Koehn et al., 2007) toolkit.
</bodyText>
<subsectionHeader confidence="0.994324">
5.1 Exploring the Parameters
</subsectionHeader>
<bodyText confidence="0.9999864">
The parameters which have a major influence on the
performance of a phrase-based SMT model are the
alignment heuristics, the maximum phrase length
(MPR) and the order of the language model (Koehn
et al., 2003). In the context of letter to phoneme
conversion, phrase means a sequence of letters or
phonemes mapped to each other with some prob-
ability (i.e., the hypothesis) and stored in a phrase
table. The maximum phrase length corresponds to
the maximum number of letters or phonemes that a
hypothesis can contain. Higher phrase length corre-
sponds a larger phrase table during decoding.
We have conducted experiments to see which
combination gives the best output. We initially
trained the model with various parameters on the
</bodyText>
<footnote confidence="0.925561">
1http://www.pascal-network.org/Challenges/PRONALSYL/
</footnote>
<bodyText confidence="0.999767">
training data and tested for various values of the
above parameters. We varied the maximum phrase
length from 2 to 7. The language model was trained
using SRILM toolkit (Stolcke, 2002). We varied the
order of language model from 2 to 8. We also tra-
versed the alignment heuristics spectrum, from the
parsimonious intersect at one end of the spectrum
through grow, grow-diag, grow-diag-final, grow-
diag-final-and and srctotgt to the most lenient union
at the other end. Our intuitive guess was that the best
alignment heuristic would be union.
We observed that the best results were obtained
when the language model was trained on 6-gram and
the alignment heuristic was union. No significant
improvement was observed in the results when the
value of MPR was greater than 5. We have taken
care such that the alignments are always monotonic.
Note that the average length of the phoneme se-
quence was also 6. We adopted the above parameter
settings for performing training on the input data.
</bodyText>
<subsectionHeader confidence="0.997404">
5.2 System Comparison
</subsectionHeader>
<bodyText confidence="0.999959">
We adopt the results given in (2007) as our baseline.
We also compare our results with some other recent
techniques mentioned in the Related Work section.
Table 2 shows the results. As this table shows, our
approach yields the best results in the case of Ger-
man and Dutch. The word accuracy obtained for
the German Celex and Dutch Celex dataset using
our approach is higher than that of all the previous
approaches listed in the table. In the case of En-
glish and French, although the baseline is achieved
through our approach, the word accuracy falls short
of being the best. However, it must also be noted
that the dataset that we used for English is slightly
larger than those of the other systems shown in the
table.
We also observe that for an average phoneme
accuracy of 91.4%, the average word accuracy is
63.81%, which corroborates the claim by Black et
al (Black et al., 1998) that a 90% phoneme accuracy
corresponds to 60% word accuracy.
</bodyText>
<subsectionHeader confidence="0.998964">
5.3 Difficulty Level and Accuracy
</subsectionHeader>
<bodyText confidence="0.999258">
We also propose a new language-independent mea-
sure that we call ‘Weighted Symmetric Cross En-
tropy’ (WSCE) to estimate the difficulty level of the
L2P task for a particular language. The weighted
</bodyText>
<page confidence="0.995491">
93
</page>
<table confidence="0.9992022">
Language Dataset Baseline CART 1-1 Align 1-1 + CSIF 1-1 + HMM M-M Align M-M + HMM MeR+ A*
English CMUDict 58.3±0.49 57.8 60.3±0.53 62.9±0.45 62.1±0.53 65.1±0.60 65.6±0.72 63.81±0.47
German Celex 86.0±0.40 89.38 86.6±0.54 87.6±0.47 87.6±0.59 89.3±0.53 89.8±0.59 90.20±0.25
French Brulex 86.3±0.67 - 87.0±0.38 86.5±0.68 88.2±0.39 90.6±0.57 90.9±0.45 86.71±0.52
Dutch Celex 84.3± 0.34 - 86.6±0.36 87.5±0.32 87.6±0.34 91.1±0.27 91.4±0.24 91.63±0.24
</table>
<tableCaption confidence="0.8341815">
Table 2: System Comparison in terms of word accuracies. Baseline:Results from PRONALSYS website. CART: CART Decision
Tree System (Black et al., 1998). 1-1 Align, M-M align, HMM: one-one alignments, many-many alignments, HMM with local
prediction (Jiampojamarn et al., 2007). CSIF:Constraint Satisfaction Inference(CSIF) of(van den Bosch and Canisius, 2006).
MeR+A*:Our approach with minimum error rate training and A* search decoder. “-” refers to no reported results.
</tableCaption>
<bodyText confidence="0.57724">
SCE is defined as follows:
</bodyText>
<equation confidence="0.9663375">
�
dscewt = rt (pl log (qf) + qf log (pl)) (7)
</equation>
<bodyText confidence="0.999832764705882">
where p and q are the probabilities of occurrence
of letter (l) and phoneme (f) sequences, respec-
tively. Also, rt corresponds to the conditional prob-
ability p(f  |l). This transcription probability can
be obtained from the phrase tables generated during
training. The weighted entropy measure dscewt,for
each language, was normalised with the total num-
ber of such n-gram pairs being considered for com-
parison with other languages. We have fixed the
maximum order of l and f n-grams to be 6. Ta-
ble 3 shows the difficulty levels as calculated using
WSCE along with the accuracy for the languages
that we tested on. As is evident from this table,
there is a rough correlation between the difficulty
level and the accuracy obtained, which also seems
intuitively valid, given the nature of these languages
and their orthographies.
</bodyText>
<table confidence="0.9996236">
Language Datasets dscewt Accuracy
English CMUDict 0.30 63.81±0.47
French Brulex 0.41 86.71±0.52
Dutch Celex 0.45 91.63±0.24
German Celex 0.49 90.20±0.25
</table>
<tableCaption confidence="0.999531">
Table 3: dscewt values predict the accuracy rates.
</tableCaption>
<sectionHeader confidence="0.996159" genericHeader="method">
6 Error Analysis
</sectionHeader>
<bodyText confidence="0.999983133333333">
In this section we present a summary of the error
analysis for the output generated. We tried to ob-
serve if there exist any patterns in the words that
were transcribed incorrectly.
The majority of errors occurred in the case of
vowel transcription, and diphthong transcription in
particular. In the case of English, this can be at-
tributed to the phenomenon of lexical borrowing
from a variety of sources as a result of which the
number of sparse alignments is very high. The sys-
tem is also unable to learn allophonic variation of
certain kinds of consonantal phonemes, most no-
tably fricatives like /s/ and /z/. This problem is ex-
acerbated by the irregularity of allophonic variation
in the language itself.
</bodyText>
<sectionHeader confidence="0.989263" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999720818181818">
In this paper we have tried to address the problem
of letter-to-phoneme conversion by modeling it as
an SMT problem and we have used minimum error
rate training to obtain the suitable model parame-
ters, which according to our knowledge, is a novel
approach to L2P task. The results obtained are com-
parable to the state of the art system and our error
analysis shows that a lot of improvement is still pos-
sible.
Intuitively, the performance of the system can be
improved in at least two areas. First is the Minimum
Error Rate Training (MERT) and the second is the
decoding phase. Using phonetic feature based edit
distance or string similarity as the loss function in
the MERT implementation can improve results sig-
nificantly. In addition, incorporating more model
parameters and extensive testing of these parame-
ters might improve the results of the system. We
also plan to introduce a decoding scheme similar to
the substring based transducer (Sherif and Kondrak,
2007) to improve the usage of lower order language
models.
</bodyText>
<sectionHeader confidence="0.998037" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9934065">
This work was supported by ILMT grant
11(10)/2006-HCC(TDIL).
</bodyText>
<page confidence="0.998957">
94
</page>
<sectionHeader confidence="0.967181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708572916667">
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured SVMs
for letter-to-phoneme conversion. In Proceedings of
ACL-08: HLT, pages 568–576, Columbus, Ohio, June.
ACL.
Max Bisani and Hermann Ney. 2002. Investigations
on joint-multigram models for grapheme-to-phoneme
conversion. In International Conference on Spoken
Language Processing, pages 105–108, Denver, CO,
USA, September.
A.W. Black, K. Lenzo, and V. Pagel. 1998. Issues in
Building General Letter to Sound Rules. In The Third
ESCA/COCOSDA Workshop (ETRW) on Speech Syn-
thesis. ISCA.
M. Collins. 2002. Discriminative training methods for
hidden Markov models: theory and experiments with
perceptron algorithms. In Proceedings of the ACL-02
conference on EMNLP-Volume 10, pages 1–8. ACL,
Morristown, NJ, USA.
K. Crammer and Y. Singer. 2003. Ultraconservative on-
line algorithms for multiclass problems. The Journal
of Machine Learning Research, 3:951–991.
Walter M. P. Daelemans and Antal P. J. van den
Bosch. 1997. Language-Independent Data-0riented
Grapheme-to-Phoneme Conversion. Progress in
Speech Synthesis.
R.I. Damper, Y. Marchand, J.D. Marseters, and A. Bazin.
2004. Aligning Letters and Phonemes for Speech Syn-
thesis. In Fifth ISCA Workshop on Speech Synthesis.
ISCA.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme con-
version. In HLT 2007: The Conference of the NAACL;
Proceedings of the Main Conference, pages 372–379,
Rochester, New York, April. ACL.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discrimina-
tive training for letter-to-phoneme conversion. In Pro-
ceedings of ACL-08: HLT, pages 905–913, Columbus,
Ohio, June. ACL.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proceedings of the 2003
Conference of the NAACL:HLT-Volume 1, pages 48–
54. ACL Morristown, NJ, USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL,
volume 45, page 2.
J. Kominek and A.W. Black. 2006. Learning pronuncia-
tion dictionaries: language complexity and word selec-
tion strategies. In HLT-NAACL, pages 232–239. ACL,
Morristown, NJ, USA.
Y. Marchand and R.I. Damper. 2000. A Multistrat-
egy Approach to Improving Pronunciation by Anal-
ogy. Computational Linguistics, 26(2):195–219.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19–51.
F.J. Och. 2003. Minimum error rate training in statistical
machine translation. In Proceedings of the 41st An-
nual Meeting on ACL-Volume 1, pages 160–167. ACL,
Morristown, NJ, USA.
J. Schroeter, A. Conkie, A. Syrdal, M. Beutnagel,
M. Jilka, V. Strom, Y.J. Kim, H.G. Kang, and D. Kapi-
low. 2002. A Perspective on the Next Challenges for
TTS Research. In IEEE 2002 Workshop on Speech
Synthesis.
Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 944–951, Prague, Czech Republic,
June. Association for Computational Linguistics.
A. Stolcke. 2002. Srilm – an extensible language model-
ing toolkit.
P. Taylor. 2005. Hidden Markov Models for Grapheme
to Phoneme Conversion. In Ninth European Con-
ference on Speech Communication and Technology.
ISCA.
K. Toutanova and R.C. Moore. 2002. Pronunciation
modeling for improved spelling correction. In Pro-
ceedings of the 40th annual meeting of ACL, pages
144–151.
A. van den Bosch and S. Canisius. 2006. Improved
morpho-phonological sequence processing with con-
straint satisfaction inference. In Proceedings of the
Eighth Meeting of the ACL-SIGPHONatHLT-NAACL,
pages 41–49.
A. van den Bosch and W. Daelemans. 1998. Do not for-
get: Full memory in memory-based learning of word
pronunciation. proceedings of NeMLap3/CoNLL98,
pages 195–204.
R. Zens and H. Ney. 2004. Improvements in phrase-
based statistical machine translation. In HLT Conf. /
NAACL, pages 257–264, Boston, MA, May.
</reference>
<page confidence="0.999075">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.718782">
<title confidence="0.9995015">Modeling Letter-to-Phoneme Conversion as a Phrase Based Machine Translation Problem with Minimum Error Rate Training</title>
<author confidence="0.995186">Taraka Rama</author>
<author confidence="0.995186">Anil Kumar Singh</author>
<author confidence="0.995186">Sudheer</author>
<affiliation confidence="0.976064">Language Technologies Research</affiliation>
<address confidence="0.793248">IIIT, Hyderabad,</address>
<abstract confidence="0.994447">Letter-to-phoneme conversion plays an important role in several applications. It can be a difficult task because the mapping from letters to phonemes can be many-to-many. We present a language independent letter-to-phoneme conversion approach which is based on the popular phrase based Statistical Machine Translation techniques. The results of our experiments clearly demonstrate that such techniques can be used effectively for letter-tophoneme conversion. Our results show an overall improvement of 5.8% over the baseline and are comparable to the state of the art. We also propose a measure to estimate the difficulty level of L2P task for a language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
<author>Grzegorz Kondrak</author>
<author>Colin Cherry</author>
</authors>
<title>Automatic syllabification with structured SVMs for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>568--576</pages>
<publisher>ACL.</publisher>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1142" citStr="Bartlett et al., 2008" startWordPosition="162" endWordPosition="165"> letter-to-phoneme conversion approach which is based on the popular phrase based Statistical Machine Translation techniques. The results of our experiments clearly demonstrate that such techniques can be used effectively for letter-tophoneme conversion. Our results show an overall improvement of 5.8% over the baseline and are comparable to the state of the art. We also propose a measure to estimate the difficulty level of L2P task for a language. 1 Introduction Letter-to-phoneme (L2P) conversion can be defined as the task of predicting the pronunciation of a word given its orthographic form (Bartlett et al., 2008).The pronunciation is usually represented as a sequence of phonemes. Letter-to-phoneme conversion systems play a very important role in spell checkers (Toutanova and Moore, 2002), speech synthesis systems (Schroeter et al., 2002) and transliteration (Sherif and Kondrak, 2007). Letter-tophoneme conversion systems may also be effectively used for cognate identification and transliteration. The existing cognate identification systems use the orthographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case</context>
</contexts>
<marker>Bartlett, Kondrak, Cherry, 2008</marker>
<rawString>Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2008. Automatic syllabification with structured SVMs for letter-to-phoneme conversion. In Proceedings of ACL-08: HLT, pages 568–576, Columbus, Ohio, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Investigations on joint-multigram models for grapheme-to-phoneme conversion.</title>
<date>2002</date>
<booktitle>In International Conference on Spoken Language Processing,</booktitle>
<pages>105--108</pages>
<location>Denver, CO, USA,</location>
<contexts>
<context position="4363" citStr="Bisani and Ney, 2002" startWordPosition="674" endWordPosition="677">lated Work In the letter-to-phoneme conversion task, a single letter can map to multiple phonemes [x → ks] and multiple letters can generate a single phoneme. A letter can also map to a null phoneme [e → W] and vice-versa. These examples give a glimpse of why the task is so complex and a single machine learning technique may not be enough to solve the problem. A overview of the literature supports this claim. In older approaches, the alignment between the letters and phonemes was taken to be one-toone (Black et al., 1998) and the phoneme was predicted for every single letter. But recent work (Bisani and Ney, 2002; Jiampojamarn et al., 2007) shows that multiple letter-to-phoneme alignments perform better than single letter to phoneme alignments. The problem can be either viewed as a multi-class classifier problem or a structure prediction problem. In structure prediction, the algorithm takes the previous decisions as the features which influence the current decision. In the classifier approach, only the letter and its context are taken as features. Then, either multiclass decision trees (Daelemans and van den Bosch, 1997) or instance based learning as in (van den Bosch and Daelemans, 1998) is used to p</context>
<context position="7433" citStr="Bisani and Ney (2002)" startWordPosition="1184" endWordPosition="1187">obtained by using Viterbi search. An online model MIRA (Crammer and Singer, 2003) which updates parameters is used for the L2P task by Jiampojamarn et al (2008). The authors unify the steps of letter segmentation, phoneme prediction and sequence modeling into a single module. The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it. The letter segmenter module is replaced by a monotone phrasal decoder (Zens and Ney, 2004) to search for the possible substrings in a word and output the n-best list for updating MIRA. Bisani and Ney (2002) take the joint multigrams of graphemes and phonemes as features for alignment and language modeling for phonetic transcription probabilities. A hybrid approach similar to this is by (van den Bosch and Canisius, 2006). In the next section we model the problem as a Statistical Machine Translation (SMT) task. 3 Modeling the Problem Assume that given a word, represented as a sequence of letters l = lJ1 = l1...lj...lJ, needs to be transcribed as a sequence of phonemes, represented as f 91 = fI1 = f1...fi...fI. The problem of finding the best phoneme sequence among the candidate translations can be</context>
</contexts>
<marker>Bisani, Ney, 2002</marker>
<rawString>Max Bisani and Hermann Ney. 2002. Investigations on joint-multigram models for grapheme-to-phoneme conversion. In International Conference on Spoken Language Processing, pages 105–108, Denver, CO, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A W Black</author>
<author>K Lenzo</author>
<author>V Pagel</author>
</authors>
<title>Issues in Building General Letter to Sound Rules.</title>
<date>1998</date>
<booktitle>In The Third ESCA/COCOSDA Workshop (ETRW) on Speech Synthesis. ISCA.</booktitle>
<contexts>
<context position="2185" citStr="Black et al., 1998" startWordPosition="316" endWordPosition="319">n systems use the orthographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of cognate identification by providing a language independent transcription for any word. Until a few years ago, letter-to-phoneme conversion was performed considering only one-one correspondences (Black et al., 1998; Damper et al., 2004). Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports significantly higher accuracy for Dutch, German and French. The current state of the art systems give as much as 90% (Jiampojamarn et al., 2008) accuracy for languages like Dutch, German and French. However, accuracy of this level is yet to be achieved for English. Rule-based approaches to the problem of letterto-phoneme conversion although appealing, are impractical as the number of rules for a particular language can be very high (Kominek and Black, 2006). Alternative approaches to t</context>
<context position="4270" citStr="Black et al., 1998" startWordPosition="658" endWordPosition="661">n Section 6. Finally we conclude with a summary and suggest directions for future work. 2 Related Work In the letter-to-phoneme conversion task, a single letter can map to multiple phonemes [x → ks] and multiple letters can generate a single phoneme. A letter can also map to a null phoneme [e → W] and vice-versa. These examples give a glimpse of why the task is so complex and a single machine learning technique may not be enough to solve the problem. A overview of the literature supports this claim. In older approaches, the alignment between the letters and phonemes was taken to be one-toone (Black et al., 1998) and the phoneme was predicted for every single letter. But recent work (Bisani and Ney, 2002; Jiampojamarn et al., 2007) shows that multiple letter-to-phoneme alignments perform better than single letter to phoneme alignments. The problem can be either viewed as a multi-class classifier problem or a structure prediction problem. In structure prediction, the algorithm takes the previous decisions as the features which influence the current decision. In the classifier approach, only the letter and its context are taken as features. Then, either multiclass decision trees (Daelemans and van den B</context>
<context position="15015" citStr="Black et al., 1998" startWordPosition="2478" endWordPosition="2481"> Dutch. The word accuracy obtained for the German Celex and Dutch Celex dataset using our approach is higher than that of all the previous approaches listed in the table. In the case of English and French, although the baseline is achieved through our approach, the word accuracy falls short of being the best. However, it must also be noted that the dataset that we used for English is slightly larger than those of the other systems shown in the table. We also observe that for an average phoneme accuracy of 91.4%, the average word accuracy is 63.81%, which corroborates the claim by Black et al (Black et al., 1998) that a 90% phoneme accuracy corresponds to 60% word accuracy. 5.3 Difficulty Level and Accuracy We also propose a new language-independent measure that we call ‘Weighted Symmetric Cross Entropy’ (WSCE) to estimate the difficulty level of the L2P task for a particular language. The weighted 93 Language Dataset Baseline CART 1-1 Align 1-1 + CSIF 1-1 + HMM M-M Align M-M + HMM MeR+ A* English CMUDict 58.3±0.49 57.8 60.3±0.53 62.9±0.45 62.1±0.53 65.1±0.60 65.6±0.72 63.81±0.47 German Celex 86.0±0.40 89.38 86.6±0.54 87.6±0.47 87.6±0.59 89.3±0.53 89.8±0.59 90.20±0.25 French Brulex 86.3±0.67 - 87.0±0.</context>
</contexts>
<marker>Black, Lenzo, Pagel, 1998</marker>
<rawString>A.W. Black, K. Lenzo, and V. Pagel. 1998. Issues in Building General Letter to Sound Rules. In The Third ESCA/COCOSDA Workshop (ETRW) on Speech Synthesis. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on EMNLP-Volume 10,</booktitle>
<pages>1--8</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7205" citStr="Collins, 2002" startWordPosition="1144" endWordPosition="1145">Then a local phoneme predictor is used to guess the phonemes for every letter in a word. The size of the letter chunk could be either one or two. Only one candidate for every word is allowed. The best phoneme sequence is obtained by using Viterbi search. An online model MIRA (Crammer and Singer, 2003) which updates parameters is used for the L2P task by Jiampojamarn et al (2008). The authors unify the steps of letter segmentation, phoneme prediction and sequence modeling into a single module. The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it. The letter segmenter module is replaced by a monotone phrasal decoder (Zens and Ney, 2004) to search for the possible substrings in a word and output the n-best list for updating MIRA. Bisani and Ney (2002) take the joint multigrams of graphemes and phonemes as features for alignment and language modeling for phonetic transcription probabilities. A hybrid approach similar to this is by (van den Bosch and Canisius, 2006). In the next section we model the problem as a Statistical Machine Translation (SMT) task. 3 Modeling the Problem Assume that given a word, represented as</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on EMNLP-Volume 10, pages 1–8. ACL, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>Y Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="6893" citStr="Crammer and Singer, 2003" startWordPosition="1090" endWordPosition="1093">ng the letters and phonemes. The algorithm allows many-to-many alignments between letters and phonemes. Then there is a letter chunking module which uses instance-based training to train on the alignments which have been obtained in the previous step. This module is used to guess the possible letter chunks in every word. Then a local phoneme predictor is used to guess the phonemes for every letter in a word. The size of the letter chunk could be either one or two. Only one candidate for every word is allowed. The best phoneme sequence is obtained by using Viterbi search. An online model MIRA (Crammer and Singer, 2003) which updates parameters is used for the L2P task by Jiampojamarn et al (2008). The authors unify the steps of letter segmentation, phoneme prediction and sequence modeling into a single module. The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it. The letter segmenter module is replaced by a monotone phrasal decoder (Zens and Ney, 2004) to search for the possible substrings in a word and output the n-best list for updating MIRA. Bisani and Ney (2002) take the joint multigrams of graphemes and phonemes as feat</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>K. Crammer and Y. Singer. 2003. Ultraconservative online algorithms for multiclass problems. The Journal of Machine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter M P Daelemans</author>
<author>Antal P J van den Bosch</author>
</authors>
<title>Language-Independent Data-0riented Grapheme-to-Phoneme Conversion. Progress in Speech Synthesis.</title>
<date>1997</date>
<marker>Daelemans, van den Bosch, 1997</marker>
<rawString>Walter M. P. Daelemans and Antal P. J. van den Bosch. 1997. Language-Independent Data-0riented Grapheme-to-Phoneme Conversion. Progress in Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Damper</author>
<author>Y Marchand</author>
<author>J D Marseters</author>
<author>A Bazin</author>
</authors>
<title>Aligning Letters and Phonemes for Speech Synthesis.</title>
<date>2004</date>
<booktitle>In Fifth ISCA Workshop on Speech Synthesis. ISCA.</booktitle>
<contexts>
<context position="2207" citStr="Damper et al., 2004" startWordPosition="320" endWordPosition="323">thographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of cognate identification by providing a language independent transcription for any word. Until a few years ago, letter-to-phoneme conversion was performed considering only one-one correspondences (Black et al., 1998; Damper et al., 2004). Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports significantly higher accuracy for Dutch, German and French. The current state of the art systems give as much as 90% (Jiampojamarn et al., 2008) accuracy for languages like Dutch, German and French. However, accuracy of this level is yet to be achieved for English. Rule-based approaches to the problem of letterto-phoneme conversion although appealing, are impractical as the number of rules for a particular language can be very high (Kominek and Black, 2006). Alternative approaches to this problem are based </context>
<context position="5712" citStr="Damper et al (2004)" startWordPosition="890" endWordPosition="893">d an initial handcrafted seeding to begin the classification. Structure prediction is like a tagging problem where HMMs (Taylor, 2005) are used to model the problem. Taylor claims that except for a preprocessing step, it is completely automatic. The whole process is performed in a single step. The results are poor, as reasoned in (Jiampojamarn et al., 2008) due to the emission probabilities not being informed by the previous letter’s emission probabilities. Pronunciation by Analogy (PbA) is a datadriven method (Marchand and Damper, 2000) for letter-to-phoneme conversion which is used again by Damper et al (2004). They simply use an Expectation-Maximisation (EM) like algorithm for aligning the letter-phoneme pairs in a speech dictionary. They claim that by integrating the alignments induced by the algorithm into the PbA system, they were able to improve the accuracy of the pronunciation significantly. We also use the many-to-many alignment approach but in a different way and obtained from a different source. The recent work of Jiampojamarn et al (2007) combines both of the above approaches in a very interesting manner. It uses an EM like algorithm for aligning the letters and phonemes. The algorithm a</context>
</contexts>
<marker>Damper, Marchand, Marseters, Bazin, 2004</marker>
<rawString>R.I. Damper, Y. Marchand, J.D. Marseters, and A. Bazin. 2004. Aligning Letters and Phonemes for Speech Synthesis. In Fifth ISCA Workshop on Speech Synthesis. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In HLT 2007: The Conference of the NAACL; Proceedings of the Main Conference,</booktitle>
<pages>372--379</pages>
<publisher>ACL.</publisher>
<location>Rochester, New York,</location>
<contexts>
<context position="2282" citStr="Jiampojamarn et al., 2007" startWordPosition="330" endWordPosition="333">ndence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of cognate identification by providing a language independent transcription for any word. Until a few years ago, letter-to-phoneme conversion was performed considering only one-one correspondences (Black et al., 1998; Damper et al., 2004). Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports significantly higher accuracy for Dutch, German and French. The current state of the art systems give as much as 90% (Jiampojamarn et al., 2008) accuracy for languages like Dutch, German and French. However, accuracy of this level is yet to be achieved for English. Rule-based approaches to the problem of letterto-phoneme conversion although appealing, are impractical as the number of rules for a particular language can be very high (Kominek and Black, 2006). Alternative approaches to this problem are based on machine learning and make use of resources such as pronunciation diction</context>
<context position="4391" citStr="Jiampojamarn et al., 2007" startWordPosition="678" endWordPosition="681">er-to-phoneme conversion task, a single letter can map to multiple phonemes [x → ks] and multiple letters can generate a single phoneme. A letter can also map to a null phoneme [e → W] and vice-versa. These examples give a glimpse of why the task is so complex and a single machine learning technique may not be enough to solve the problem. A overview of the literature supports this claim. In older approaches, the alignment between the letters and phonemes was taken to be one-toone (Black et al., 1998) and the phoneme was predicted for every single letter. But recent work (Bisani and Ney, 2002; Jiampojamarn et al., 2007) shows that multiple letter-to-phoneme alignments perform better than single letter to phoneme alignments. The problem can be either viewed as a multi-class classifier problem or a structure prediction problem. In structure prediction, the algorithm takes the previous decisions as the features which influence the current decision. In the classifier approach, only the letter and its context are taken as features. Then, either multiclass decision trees (Daelemans and van den Bosch, 1997) or instance based learning as in (van den Bosch and Daelemans, 1998) is used to predict the class, which in t</context>
<context position="6160" citStr="Jiampojamarn et al (2007)" startWordPosition="962" endWordPosition="965">sion probabilities. Pronunciation by Analogy (PbA) is a datadriven method (Marchand and Damper, 2000) for letter-to-phoneme conversion which is used again by Damper et al (2004). They simply use an Expectation-Maximisation (EM) like algorithm for aligning the letter-phoneme pairs in a speech dictionary. They claim that by integrating the alignments induced by the algorithm into the PbA system, they were able to improve the accuracy of the pronunciation significantly. We also use the many-to-many alignment approach but in a different way and obtained from a different source. The recent work of Jiampojamarn et al (2007) combines both of the above approaches in a very interesting manner. It uses an EM like algorithm for aligning the letters and phonemes. The algorithm allows many-to-many alignments between letters and phonemes. Then there is a letter chunking module which uses instance-based training to train on the alignments which have been obtained in the previous step. This module is used to guess the possible letter chunks in every word. Then a local phoneme predictor is used to guess the phonemes for every letter in a word. The size of the letter chunk could be either one or two. Only one candidate for </context>
<context position="9158" citStr="Jiampojamarn et al (2007)" startWordPosition="1489" endWordPosition="1492">e criterion followed in (Och, 2003) for optimising the parameters of the model. The details of the solution and proof for the convergence are given in Och (2003). The models’ weights, used for the L2P task, are obtained from this training. � � exp ΣM m=1λmhm(f, l) (6) p(¯lK1 |¯fK1 ) = �K Φ(¯lk |¯fk) (4) grapheme is treated as a single k=1 for the GIZA++ input. The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003). Figure 1 shows the alignments induced by GIZA++ for the example words which are mentioned by Jiampojamarn et al (2007). In this figure, we only show the alignments fr ‘word’ om graphemes to phonemes. weights can be done in the following manner. The posterior probability Pr (f can also be directly modeled using alog-linear model. In this model, we have a set of M feature functions m = 1...M . For each feature function there exists a weight or model parameter m = 1...M. Thus the posterior probabili models’ |l) hm(f, l), λm, ty becomes: =arg max f) (f) (2) This formulation allows for a phoneme n-gram model (f) and a transcription model Given a sequence of letters the argmax function is a search function to outpu</context>
<context position="16028" citStr="Jiampojamarn et al., 2007" startWordPosition="2625" endWordPosition="2628">glish CMUDict 58.3±0.49 57.8 60.3±0.53 62.9±0.45 62.1±0.53 65.1±0.60 65.6±0.72 63.81±0.47 German Celex 86.0±0.40 89.38 86.6±0.54 87.6±0.47 87.6±0.59 89.3±0.53 89.8±0.59 90.20±0.25 French Brulex 86.3±0.67 - 87.0±0.38 86.5±0.68 88.2±0.39 90.6±0.57 90.9±0.45 86.71±0.52 Dutch Celex 84.3± 0.34 - 86.6±0.36 87.5±0.32 87.6±0.34 91.1±0.27 91.4±0.24 91.63±0.24 Table 2: System Comparison in terms of word accuracies. Baseline:Results from PRONALSYS website. CART: CART Decision Tree System (Black et al., 1998). 1-1 Align, M-M align, HMM: one-one alignments, many-many alignments, HMM with local prediction (Jiampojamarn et al., 2007). CSIF:Constraint Satisfaction Inference(CSIF) of(van den Bosch and Canisius, 2006). MeR+A*:Our approach with minimum error rate training and A* search decoder. “-” refers to no reported results. SCE is defined as follows: � dscewt = rt (pl log (qf) + qf log (pl)) (7) where p and q are the probabilities of occurrence of letter (l) and phoneme (f) sequences, respectively. Also, rt corresponds to the conditional probability p(f |l). This transcription probability can be obtained from the phrase tables generated during training. The weighted entropy measure dscewt,for each language, was normalise</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion. In HLT 2007: The Conference of the NAACL; Proceedings of the Main Conference, pages 372–379, Rochester, New York, April. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>905--913</pages>
<publisher>ACL.</publisher>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2439" citStr="Jiampojamarn et al., 2008" startWordPosition="357" endWordPosition="360"> this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of cognate identification by providing a language independent transcription for any word. Until a few years ago, letter-to-phoneme conversion was performed considering only one-one correspondences (Black et al., 1998; Damper et al., 2004). Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports significantly higher accuracy for Dutch, German and French. The current state of the art systems give as much as 90% (Jiampojamarn et al., 2008) accuracy for languages like Dutch, German and French. However, accuracy of this level is yet to be achieved for English. Rule-based approaches to the problem of letterto-phoneme conversion although appealing, are impractical as the number of rules for a particular language can be very high (Kominek and Black, 2006). Alternative approaches to this problem are based on machine learning and make use of resources such as pronunciation dictionaries. In this paper, we present one such machine learning based approach wherein we envisage this problem as a Statistical Machine Translation (SMT) problem</context>
<context position="5452" citStr="Jiampojamarn et al., 2008" startWordPosition="849" endWordPosition="852">lass decision trees (Daelemans and van den Bosch, 1997) or instance based learning as in (van den Bosch and Daelemans, 1998) is used to predict the class, which in this case is a phoneme. Some of these methods (Black et al., 1998) are not completely automatic and need an initial handcrafted seeding to begin the classification. Structure prediction is like a tagging problem where HMMs (Taylor, 2005) are used to model the problem. Taylor claims that except for a preprocessing step, it is completely automatic. The whole process is performed in a single step. The results are poor, as reasoned in (Jiampojamarn et al., 2008) due to the emission probabilities not being informed by the previous letter’s emission probabilities. Pronunciation by Analogy (PbA) is a datadriven method (Marchand and Damper, 2000) for letter-to-phoneme conversion which is used again by Damper et al (2004). They simply use an Expectation-Maximisation (EM) like algorithm for aligning the letter-phoneme pairs in a speech dictionary. They claim that by integrating the alignments induced by the algorithm into the PbA system, they were able to improve the accuracy of the pronunciation significantly. We also use the many-to-many alignment approa</context>
<context position="6972" citStr="Jiampojamarn et al (2008)" startWordPosition="1104" endWordPosition="1107">en letters and phonemes. Then there is a letter chunking module which uses instance-based training to train on the alignments which have been obtained in the previous step. This module is used to guess the possible letter chunks in every word. Then a local phoneme predictor is used to guess the phonemes for every letter in a word. The size of the letter chunk could be either one or two. Only one candidate for every word is allowed. The best phoneme sequence is obtained by using Viterbi search. An online model MIRA (Crammer and Singer, 2003) which updates parameters is used for the L2P task by Jiampojamarn et al (2008). The authors unify the steps of letter segmentation, phoneme prediction and sequence modeling into a single module. The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it. The letter segmenter module is replaced by a monotone phrasal decoder (Zens and Ney, 2004) to search for the possible substrings in a word and output the n-best list for updating MIRA. Bisani and Ney (2002) take the joint multigrams of graphemes and phonemes as features for alignment and language modeling for phonetic transcription probabiliti</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proceedings of ACL-08: HLT, pages 905–913, Columbus, Ohio, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the</booktitle>
<volume>1</volume>
<pages>48--54</pages>
<publisher>ACL</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9038" citStr="Koehn et al., 2003" startWordPosition="1468" endWordPosition="1471">ing entails finding the suitable model parameters or weights which reflect the properties of our task. We adopt the criterion followed in (Och, 2003) for optimising the parameters of the model. The details of the solution and proof for the convergence are given in Och (2003). The models’ weights, used for the L2P task, are obtained from this training. � � exp ΣM m=1λmhm(f, l) (6) p(¯lK1 |¯fK1 ) = �K Φ(¯lk |¯fk) (4) grapheme is treated as a single k=1 for the GIZA++ input. The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003). Figure 1 shows the alignments induced by GIZA++ for the example words which are mentioned by Jiampojamarn et al (2007). In this figure, we only show the alignments fr ‘word’ om graphemes to phonemes. weights can be done in the following manner. The posterior probability Pr (f can also be directly modeled using alog-linear model. In this model, we have a set of M feature functions m = 1...M . For each feature function there exists a weight or model parameter m = 1...M. Thus the posterior probabili models’ |l) hm(f, l), λm, ty becomes: =arg max f) (f) (2) This formulation allows for a phoneme </context>
<context position="12226" citStr="Koehn et al., 2003" startWordPosition="2012" endWordPosition="2015"> of preparing the datasets we took one set for test, another for developing our parameters and the remaining 8 sets for training. We report our results in word accuracy rate, based on 10-fold cross validation, with mean and standard deviation. Language Datasets Number of Words English CMUDict 112241 French Brulex 27473 German Celex 49421 Dutch Celex 116252 Table 1: Number of words in each Dataset We removed the one-to-one alignments from the corpora and induced our own alignments using GIZA++. We used minimum error rate training (Och, 2003) and the A* beam search decoder implemented by Koehn (Koehn et al., 2003). All the above tools are available as parts of the MOSES (Koehn et al., 2007) toolkit. 5.1 Exploring the Parameters The parameters which have a major influence on the performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003). In the context of letter to phoneme conversion, phrase means a sequence of letters or phonemes mapped to each other with some probability (i.e., the hypothesis) and stored in a phrase table. The maximum phrase length corresponds to the maximum number of letters or phoneme</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Conference of the NAACL:HLT-Volume 1, pages 48– 54. ACL Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In ACL,</booktitle>
<volume>45</volume>
<pages>2</pages>
<contexts>
<context position="12304" citStr="Koehn et al., 2007" startWordPosition="2027" endWordPosition="2030">r parameters and the remaining 8 sets for training. We report our results in word accuracy rate, based on 10-fold cross validation, with mean and standard deviation. Language Datasets Number of Words English CMUDict 112241 French Brulex 27473 German Celex 49421 Dutch Celex 116252 Table 1: Number of words in each Dataset We removed the one-to-one alignments from the corpora and induced our own alignments using GIZA++. We used minimum error rate training (Och, 2003) and the A* beam search decoder implemented by Koehn (Koehn et al., 2003). All the above tools are available as parts of the MOSES (Koehn et al., 2007) toolkit. 5.1 Exploring the Parameters The parameters which have a major influence on the performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003). In the context of letter to phoneme conversion, phrase means a sequence of letters or phonemes mapped to each other with some probability (i.e., the hypothesis) and stored in a phrase table. The maximum phrase length corresponds to the maximum number of letters or phonemes that a hypothesis can contain. Higher phrase length corresponds a larger phr</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, et al. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL, volume 45, page 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kominek</author>
<author>A W Black</author>
</authors>
<title>Learning pronunciation dictionaries: language complexity and word selection strategies.</title>
<date>2006</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>232--239</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2756" citStr="Kominek and Black, 2006" startWordPosition="410" endWordPosition="413">ring only one-one correspondences (Black et al., 1998; Damper et al., 2004). Recent work uses many-to-many correspondences (Jiampojamarn et al., 2007) and reports significantly higher accuracy for Dutch, German and French. The current state of the art systems give as much as 90% (Jiampojamarn et al., 2008) accuracy for languages like Dutch, German and French. However, accuracy of this level is yet to be achieved for English. Rule-based approaches to the problem of letterto-phoneme conversion although appealing, are impractical as the number of rules for a particular language can be very high (Kominek and Black, 2006). Alternative approaches to this problem are based on machine learning and make use of resources such as pronunciation dictionaries. In this paper, we present one such machine learning based approach wherein we envisage this problem as a Statistical Machine Translation (SMT) problem. The outline of the paper is as follows. Section 2 presents a brief summary of the related work done in L2P conversion. Section 3 describes our model and the techniques devised for optimizing the performance. Section 4 describes the letter-to-phoneme alignment. The description of the results and experiments and a n</context>
</contexts>
<marker>Kominek, Black, 2006</marker>
<rawString>J. Kominek and A.W. Black. 2006. Learning pronunciation dictionaries: language complexity and word selection strategies. In HLT-NAACL, pages 232–239. ACL, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Marchand</author>
<author>R I Damper</author>
</authors>
<title>A Multistrategy Approach to Improving Pronunciation by Analogy.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="5636" citStr="Marchand and Damper, 2000" startWordPosition="878" endWordPosition="881">me. Some of these methods (Black et al., 1998) are not completely automatic and need an initial handcrafted seeding to begin the classification. Structure prediction is like a tagging problem where HMMs (Taylor, 2005) are used to model the problem. Taylor claims that except for a preprocessing step, it is completely automatic. The whole process is performed in a single step. The results are poor, as reasoned in (Jiampojamarn et al., 2008) due to the emission probabilities not being informed by the previous letter’s emission probabilities. Pronunciation by Analogy (PbA) is a datadriven method (Marchand and Damper, 2000) for letter-to-phoneme conversion which is used again by Damper et al (2004). They simply use an Expectation-Maximisation (EM) like algorithm for aligning the letter-phoneme pairs in a speech dictionary. They claim that by integrating the alignments induced by the algorithm into the PbA system, they were able to improve the accuracy of the pronunciation significantly. We also use the many-to-many alignment approach but in a different way and obtained from a different source. The recent work of Jiampojamarn et al (2007) combines both of the above approaches in a very interesting manner. It uses</context>
</contexts>
<marker>Marchand, Damper, 2000</marker>
<rawString>Y. Marchand and R.I. Damper. 2000. A Multistrategy Approach to Improving Pronunciation by Analogy. Computational Linguistics, 26(2):195–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="10638" citStr="Och and Ney, 2003" startWordPosition="1749" endWordPosition="1752">tial translations. By using an n-gram model as the lan fbest p(l| p f p p(l|f). l, l ¯lK1 ¯lk ¯lK1 ¯fk. pLM guage model, we have the equations: with From the above equation, the best phoneme sequence is obtained based on the product of the probabilities of transcription model and the probabilities of a language model and their respective weights. The method for obtaining the transcription probabilities is described briefly in the next section. Determining the best weights is necessary for obtaining the right phoneme sequence. The estimation of the 4 Letter-to-Phoneme Alignment We used GIZA++ (Och and Ney, 2003), an open source toolkit, for aligning the letters with the phonemes in the training data sets. In the context of SMT, say English-Spanish, the parallel corpus is aligned bidirectionally to obtain the two alignments. The IBM models give only one-to-one alignments between words in a sentence pair. So, GIZA++ uses some heuristics to refine the alignments (Och and Ney, 2003). In our input data, the source side consists of grapheme (or letter) sequences and the target side consists of phoneme sequences. Every letter or Figure 1: Example Alignments fr om GIZA++ Pr (f |l) = pλM1 (f |l) (5) 92 5 Eval</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on ACL-Volume 1,</booktitle>
<pages>160--167</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="8568" citStr="Och, 2003" startWordPosition="1387" endWordPosition="1388">f finding the best phoneme sequence among the candidate translations can be represented as: fbest f {Pr (f |l)} (1) We model the problem of letter to phoneme conversion based on the noisy channel model. Reformulating the above equation using Bayes Rule: = arg max fbest =arg f) wri maxp(l |f)pLM (3) f p(l| tten as � � �´fI 1 exp ΣM m=1λmhm( ´fI 1 ,l) with the denominator, a normalization factor that can be ignored in the maximization process. The above modeling entails finding the suitable model parameters or weights which reflect the properties of our task. We adopt the criterion followed in (Och, 2003) for optimising the parameters of the model. The details of the solution and proof for the convergence are given in Och (2003). The models’ weights, used for the L2P task, are obtained from this training. � � exp ΣM m=1λmhm(f, l) (6) p(¯lK1 |¯fK1 ) = �K Φ(¯lk |¯fk) (4) grapheme is treated as a single k=1 for the GIZA++ input. The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003). Figure 1 shows the alignments induced by GIZA++ for the example words which are mentioned by Jiampojamarn et al (2007). In this </context>
<context position="12153" citStr="Och, 2003" startWordPosition="2000" endWordPosition="2001">ilable at the website were divided into 10 folds. In the process of preparing the datasets we took one set for test, another for developing our parameters and the remaining 8 sets for training. We report our results in word accuracy rate, based on 10-fold cross validation, with mean and standard deviation. Language Datasets Number of Words English CMUDict 112241 French Brulex 27473 German Celex 49421 Dutch Celex 116252 Table 1: Number of words in each Dataset We removed the one-to-one alignments from the corpora and induced our own alignments using GIZA++. We used minimum error rate training (Och, 2003) and the A* beam search decoder implemented by Koehn (Koehn et al., 2003). All the above tools are available as parts of the MOSES (Koehn et al., 2007) toolkit. 5.1 Exploring the Parameters The parameters which have a major influence on the performance of a phrase-based SMT model are the alignment heuristics, the maximum phrase length (MPR) and the order of the language model (Koehn et al., 2003). In the context of letter to phoneme conversion, phrase means a sequence of letters or phonemes mapped to each other with some probability (i.e., the hypothesis) and stored in a phrase table. The maxi</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F.J. Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on ACL-Volume 1, pages 160–167. ACL, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schroeter</author>
<author>A Conkie</author>
<author>A Syrdal</author>
<author>M Beutnagel</author>
<author>M Jilka</author>
<author>V Strom</author>
<author>Y J Kim</author>
<author>H G Kang</author>
<author>D Kapilow</author>
</authors>
<title>A Perspective on the Next Challenges for TTS Research.</title>
<date>2002</date>
<booktitle>In IEEE 2002 Workshop on Speech Synthesis.</booktitle>
<contexts>
<context position="1371" citStr="Schroeter et al., 2002" startWordPosition="195" endWordPosition="198">tter-tophoneme conversion. Our results show an overall improvement of 5.8% over the baseline and are comparable to the state of the art. We also propose a measure to estimate the difficulty level of L2P task for a language. 1 Introduction Letter-to-phoneme (L2P) conversion can be defined as the task of predicting the pronunciation of a word given its orthographic form (Bartlett et al., 2008).The pronunciation is usually represented as a sequence of phonemes. Letter-to-phoneme conversion systems play a very important role in spell checkers (Toutanova and Moore, 2002), speech synthesis systems (Schroeter et al., 2002) and transliteration (Sherif and Kondrak, 2007). Letter-tophoneme conversion systems may also be effectively used for cognate identification and transliteration. The existing cognate identification systems use the orthographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of</context>
</contexts>
<marker>Schroeter, Conkie, Syrdal, Beutnagel, Jilka, Strom, Kim, Kang, Kapilow, 2002</marker>
<rawString>J. Schroeter, A. Conkie, A. Syrdal, M. Beutnagel, M. Jilka, V. Strom, Y.J. Kim, H.G. Kang, and D. Kapilow. 2002. A Perspective on the Next Challenges for TTS Research. In IEEE 2002 Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Substringbased transliteration.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>944--951</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1418" citStr="Sherif and Kondrak, 2007" startWordPosition="202" endWordPosition="205">n overall improvement of 5.8% over the baseline and are comparable to the state of the art. We also propose a measure to estimate the difficulty level of L2P task for a language. 1 Introduction Letter-to-phoneme (L2P) conversion can be defined as the task of predicting the pronunciation of a word given its orthographic form (Bartlett et al., 2008).The pronunciation is usually represented as a sequence of phonemes. Letter-to-phoneme conversion systems play a very important role in spell checkers (Toutanova and Moore, 2002), speech synthesis systems (Schroeter et al., 2002) and transliteration (Sherif and Kondrak, 2007). Letter-tophoneme conversion systems may also be effectively used for cognate identification and transliteration. The existing cognate identification systems use the orthographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-phoneme conversion systems can facilitate the task of cognate identification by providing a language</context>
</contexts>
<marker>Sherif, Kondrak, 2007</marker>
<rawString>Tarek Sherif and Grzegorz Kondrak. 2007. Substringbased transliteration. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 944–951, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm – an extensible language modeling toolkit.</title>
<date>2002</date>
<contexts>
<context position="13308" citStr="Stolcke, 2002" startWordPosition="2185" endWordPosition="2186">.e., the hypothesis) and stored in a phrase table. The maximum phrase length corresponds to the maximum number of letters or phonemes that a hypothesis can contain. Higher phrase length corresponds a larger phrase table during decoding. We have conducted experiments to see which combination gives the best output. We initially trained the model with various parameters on the 1http://www.pascal-network.org/Challenges/PRONALSYL/ training data and tested for various values of the above parameters. We varied the maximum phrase length from 2 to 7. The language model was trained using SRILM toolkit (Stolcke, 2002). We varied the order of language model from 2 to 8. We also traversed the alignment heuristics spectrum, from the parsimonious intersect at one end of the spectrum through grow, grow-diag, grow-diag-final, growdiag-final-and and srctotgt to the most lenient union at the other end. Our intuitive guess was that the best alignment heuristic would be union. We observed that the best results were obtained when the language model was trained on 6-gram and the alignment heuristic was union. No significant improvement was observed in the results when the value of MPR was greater than 5. We have taken</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm – an extensible language modeling toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
</authors>
<title>Hidden Markov Models for Grapheme to Phoneme Conversion. In</title>
<date>2005</date>
<booktitle>Ninth European Conference on Speech Communication and Technology. ISCA.</booktitle>
<contexts>
<context position="5227" citStr="Taylor, 2005" startWordPosition="812" endWordPosition="813"> prediction, the algorithm takes the previous decisions as the features which influence the current decision. In the classifier approach, only the letter and its context are taken as features. Then, either multiclass decision trees (Daelemans and van den Bosch, 1997) or instance based learning as in (van den Bosch and Daelemans, 1998) is used to predict the class, which in this case is a phoneme. Some of these methods (Black et al., 1998) are not completely automatic and need an initial handcrafted seeding to begin the classification. Structure prediction is like a tagging problem where HMMs (Taylor, 2005) are used to model the problem. Taylor claims that except for a preprocessing step, it is completely automatic. The whole process is performed in a single step. The results are poor, as reasoned in (Jiampojamarn et al., 2008) due to the emission probabilities not being informed by the previous letter’s emission probabilities. Pronunciation by Analogy (PbA) is a datadriven method (Marchand and Damper, 2000) for letter-to-phoneme conversion which is used again by Damper et al (2004). They simply use an Expectation-Maximisation (EM) like algorithm for aligning the letter-phoneme pairs in a speech</context>
</contexts>
<marker>Taylor, 2005</marker>
<rawString>P. Taylor. 2005. Hidden Markov Models for Grapheme to Phoneme Conversion. In Ninth European Conference on Speech Communication and Technology. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>R C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting of ACL,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="1320" citStr="Toutanova and Moore, 2002" startWordPosition="187" endWordPosition="190">te that such techniques can be used effectively for letter-tophoneme conversion. Our results show an overall improvement of 5.8% over the baseline and are comparable to the state of the art. We also propose a measure to estimate the difficulty level of L2P task for a language. 1 Introduction Letter-to-phoneme (L2P) conversion can be defined as the task of predicting the pronunciation of a word given its orthographic form (Bartlett et al., 2008).The pronunciation is usually represented as a sequence of phonemes. Letter-to-phoneme conversion systems play a very important role in spell checkers (Toutanova and Moore, 2002), speech synthesis systems (Schroeter et al., 2002) and transliteration (Sherif and Kondrak, 2007). Letter-tophoneme conversion systems may also be effectively used for cognate identification and transliteration. The existing cognate identification systems use the orthographic form of a word as the input. But we know that the correspondence between written and spoken forms of words can be quite irregular as is the case in English. Even in other languages with supposedly regular spellings, this irregularity exists owing to linguistic phenomena like borrowing and language variation. Letter-to-ph</context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>K. Toutanova and R.C. Moore. 2002. Pronunciation modeling for improved spelling correction. In Proceedings of the 40th annual meeting of ACL, pages 144–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A van den Bosch</author>
<author>S Canisius</author>
</authors>
<title>Improved morpho-phonological sequence processing with constraint satisfaction inference.</title>
<date>2006</date>
<booktitle>In Proceedings of the Eighth Meeting of the ACL-SIGPHONatHLT-NAACL,</booktitle>
<pages>41--49</pages>
<marker>van den Bosch, Canisius, 2006</marker>
<rawString>A. van den Bosch and S. Canisius. 2006. Improved morpho-phonological sequence processing with constraint satisfaction inference. In Proceedings of the Eighth Meeting of the ACL-SIGPHONatHLT-NAACL, pages 41–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A van den Bosch</author>
<author>W Daelemans</author>
</authors>
<title>Do not forget: Full memory in memory-based learning of word pronunciation. proceedings of NeMLap3/CoNLL98,</title>
<date>1998</date>
<pages>195--204</pages>
<marker>van den Bosch, Daelemans, 1998</marker>
<rawString>A. van den Bosch and W. Daelemans. 1998. Do not forget: Full memory in memory-based learning of word pronunciation. proceedings of NeMLap3/CoNLL98, pages 195–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Improvements in phrasebased statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT Conf. / NAACL,</booktitle>
<pages>257--264</pages>
<location>Boston, MA,</location>
<contexts>
<context position="7317" citStr="Zens and Ney, 2004" startWordPosition="1162" endWordPosition="1165">tter chunk could be either one or two. Only one candidate for every word is allowed. The best phoneme sequence is obtained by using Viterbi search. An online model MIRA (Crammer and Singer, 2003) which updates parameters is used for the L2P task by Jiampojamarn et al (2008). The authors unify the steps of letter segmentation, phoneme prediction and sequence modeling into a single module. The phoneme prediction and sequence modeling are considered as tagging problems and a Perceptron HMM (Collins, 2002) is used to model it. The letter segmenter module is replaced by a monotone phrasal decoder (Zens and Ney, 2004) to search for the possible substrings in a word and output the n-best list for updating MIRA. Bisani and Ney (2002) take the joint multigrams of graphemes and phonemes as features for alignment and language modeling for phonetic transcription probabilities. A hybrid approach similar to this is by (van den Bosch and Canisius, 2006). In the next section we model the problem as a Statistical Machine Translation (SMT) task. 3 Modeling the Problem Assume that given a word, represented as a sequence of letters l = lJ1 = l1...lj...lJ, needs to be transcribed as a sequence of phonemes, represented as</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>R. Zens and H. Ney. 2004. Improvements in phrasebased statistical machine translation. In HLT Conf. / NAACL, pages 257–264, Boston, MA, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>