<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014926">
<title confidence="0.783358">
Bayesian Network, a model for NLP?
Davy Weissenbacher
Laboratoire d’Informatique de Paris-Nord
Universite Paris-Nord
Villetaneuse, FRANCE
</title>
<email confidence="0.989767">
davy.weissenbacher@lipn.univ-paris13.fr
</email>
<sectionHeader confidence="0.995469" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999798888888889">
The NLP systems often have low perfor-
mances because they rely on unreliable
and heterogeneous knowledge. We show
on the task of non-anaphoric it identifi-
cation how to overcome these handicaps
with the Bayesian Network (BN) formal-
ism. The first results are very encourag-
ing compared with the state-of-the-art sys-
tems.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858189189189">
When a pronoun refers to a linguistic expression
previously introduced in the text, it is anaphoric.
In the sentence Nonexpression of the locus even
when it is present suggests that these chromo-
somes[...], the pronoun it refers to the referent
designated as ’the locus’. When it does not re-
fer to any referent, as in the sentence Thus, it is
not unexpected that this versatile cellular... the
pronoun is semantically empty or non-anaphoric.
Any anaphora resolution system starts by identi-
fying the pronoun occurrences and distinguishing
the anaphoric and non-anaphoric occurrences of it.
The first systems that tackled this classification
problem were based either on manually written
rules or on the automatic learning of relevant sur-
face clues. Whatever strategy is used, these sys-
tems see their performances limited by the quality
of knowledge they exploit, which is usually only
partially reliable and heterogeneous.
This article describes a new approach to go be-
yond the limits of traditional systems. This ap-
proach stands on the formalism, still little ex-
ploited for NLP, of Bayesian Network (BN). As
a probabilistic formalism, it offers a great expres-
sion capacity to integrate heterogeneous knowl-
edge in a single representation (Peshkin, 2003)
as well as an elegant mechanism to take into ac-
count an a priori estimation of their reliability in
the classification decision (Roth, 2002). In order
to validate our approach we carried out various ex-
periments on a corpus made up of abtsracts of ge-
nomic articles.
Section 2 presents the state of the art for the
automatic recognition of the non-anaphoric oc-
curences of it. Our BN-based approach is exposed
in section 3. The experiments are reported in sec-
tion 4, and results are discussed in section 5.
</bodyText>
<sectionHeader confidence="0.941408" genericHeader="method">
2 Identification of Non-anaphoric it
occurences
</sectionHeader>
<bodyText confidence="0.9999625">
The decisions made by NLP systems depend on
the available knowledge. However this informa-
tion is often weakly reliable and leads to erroneous
or incomplete results.
One of first pronoun classifier system is pre-
sented by (Paice, 1987). It relies on a set of logical
first order rules to distinguish the non-anaphoric
occurences of the pronoun it. Non-anaphoric se-
quences share remarkable forms (they start with an
it and end with a delimiter like to, that, whether...).
The rules expresses some constraints which vary
according to the delimiter. They concern the left
context of the pronoun (it should not be immedi-
ately preceded by certain words like before, from
to), the distance between the pronoun and the de-
limiter (it must be shorter than 25 words long), and
finally the lexical items occurring between the pro-
noun and the delimiter (the sequence must or must
not contain certain words belonging to specific
sets, such as words expressing modality over the
sentence content, e.g. certain, known, unclear...).
Tests performed by Paice show good results with
</bodyText>
<page confidence="0.9984">
195
</page>
<bodyText confidence="0.994002031746032">
91.4%Accuracy1 on a technical corpus. However
the performances are degraded if one applies them
to corpora of different natures: the number of false
positive increases.
In order to avoid this pitfall, (Lappin, 1994) pro-
poses some more constrained rules in the form of
finite state automata. Based on linguistic knowl-
edge the automata recognize specific sequences
like It is not/may be&lt;Modaladj&gt;; It is &lt;Cogv-
ed&gt; that &lt;Subject&gt; where &lt;Modaladj&gt; and
&lt;Cogv&gt; are modal adjective and cognitive verbs
classes known to introduce non-anaphoric it (e.g.
necessary, possible and recommend, think). This
system has a good precision (few false positive
cases), but has a low recall (many false negative
cases). Any sequence with a variation is ignored
by the automata and it is difficult to get exhaustive
adjective and verb semantic classes2. In the next
paragraphs we refer to Lappin rules’ as Highly
Constraint rules (HC rules) and Paice rules’ as
Lightly Constraint rules (LC rules).
(Evans, 2001) gives up the constraints brought
into play by these rules and proposes a machine
learning approach based on surface clues. The
training determines the relative weight of the vari-
ous corpus clues. Evans considers 35 syntactic and
contextual surface clues (e.g. pronoun position in
the sentence, lemma of the following verb) on a
manually annotated sample. The system classifies
the new it occurences by the k-nearest neighbor
method metric. The first tests achieve a satisfac-
tory score: 71.31%Acc on a general language cor-
pus. (Clement, 2004) carries out a similar test in
the genomic domain. He reduces the number of
Evans’s surface clues to the 21 most relevant ones
and classifies the new instances with a Support
Vector Machine(SVM). It obtains 92.71%Acc to
be compared with a 90.78%Acc score for the LC
rules on the same corpus. The difficulty, however,
comes from the fact that the information on which
1Accuraccy(Acc) is a classifi cation measure:
Acc= P+N+p+n where p is the number of anaphoric
pronoun occurences tagged as non-anaphoric, which we
call the false positive cases, n the number of non-anaphoric
pronoun ocurrences tagged as anaphoric, the false negative
cases. P and N are the numbers of correctly tagged
non-anaphoric and anaphoric pronoun occurences, the true
positive and negative cases respectively.
2For instance in the sentences It is well documented that
treatment of serum-grown... and It is generally accepted that
Bcl-2 exerts... the it occurences are not classified as non-
anaphorics because documented does not belong to the origi-
nal verb class &lt;Cogv&gt; and generally does not appear in the
previous automaton.
the systems are built is often diverse and hetero-
geneous. This system is based on atomic surface
clues only and does not make use of the linguistic
knowledge or the relational information that the
constraints of the previous systems encode. We ar-
gue that these three types of knowledge that are the
HC rules, the LC rules, and the surfaces clues are
all relevant and complementary for the task and
that they must be unified in a single representation.
</bodyText>
<sectionHeader confidence="0.873238" genericHeader="method">
3 A Bayesian Network Based System
</sectionHeader>
<figureCaption confidence="0.9955455">
Figure 1: A Bayesian Network for identification
ofnon-anaphoric it occurrences
</figureCaption>
<bodyText confidence="0.992341368421052">
Neither the surface clues nor the surface clues
are reliable indicators of the pronoun status. They
encode heterogeneous pieces of information and
consequently produce different false negative and
positive cases. The HC rules have a good precision
but tag only few pronouns. On the opposite, the
LC rules, which have a good recall, are not precise
enough to be exploited as such and the additional
surface clues must be checked. Our model com-
bines these clues and take their respective reliabil-
ity in to account. It obtains better results than those
obtained from each clue exploited separately.
The BN is a model designed to deal with dubi-
ous pieces of information. It is based on a qualita-
tive description of their dependancy relationships,
a directed acyclic graph, and a set of condition-
nal probablities, each node being represented as
a Random Variable (RV). Parametrizing the BN
associates an a priori probability distribution to
</bodyText>
<figure confidence="0.999588803921569">
Grammatical−Role
Subject
Object
Preposition
Other
Unknown−Words
One
Two
Three
More
Left−Context−Constraints
Match
Start−Sentence
Start−Abstract
Start
No−Start
Start
No−Start
No−match
Start−Proposition
Star
No−Start
Contain−Known−Nou
Contain
No−Contain
Non−anaphoric−It
Anaphoric−It
Pronoun
LCR−Automata
Match
No−match
HCR−Automata
Contain−Known−Adjective
Contain−Known−Verb
Match
No−match
Contain
No−Contain
Contain
No−Contain
To
That
Whether−if
Which−Who
Other
Sequence−Length
Inferior−three
three
...
Superior−eleven
Delimitor
</figure>
<page confidence="0.996507">
196
</page>
<bodyText confidence="0.999965825000001">
the graph. Exploiting the BN (inference stage)
consists in propagating new pieces of informa-
tion through the network edges and updating them
according to observations (a posteriori probabili-
ties).
We integrated all the clues exploted by of the
previous methods within the same BN. We use de-
pendancy relationships to express the fact that two
clues are combined. The BN is manually designed
(choice of the RV values and graph structure). On
the Figure1, the nodes associated with the HC
rules method are marked in grey, white is for
the LC rules method and black for the Clement’s
method3. The Pronoun node estimates the de-
cision probability for a given it occurence to be
non-anaphoric.
The parameterising stage establishes the a pri-
ori probability values for all possible RV by sim-
ple frequency counts in a training corpus. They
express the weight of each piece of information in
the decision, its a priori reliability in the classifi-
cation decision4. The inference stage exploits the
relationships for the propagation of the informa-
tion and the BN operates by information reinforce-
ment to label a pronoun. We applied all precedent
rules and checked surface clues on the sequence
containing the it occurrence and set observation
values to the correspondant RV probabilities. A
new probability is computed for the node’s vari-
able Pronoun: if it is superior or equal to 50%
the pronoun is labeled non-anaphoric, anaphoric
otherwise.
Let us consider the sentence extracted from our
corpus: It had previously been thought that ZE-
BRA’s capacity to disrupt EBV latency.... No HC
rule recognizes the sequence even by tolerating 3
unknown words 5, but a LC rule matches it with
4 words between the pronoun and the delimiter
that6. Among the surface clues, we checked that
the sequence is at the beginning of the sentence
</bodyText>
<footnote confidence="0.7722158">
3Only significant surface clues for our modelisation have
been added to the BN.
4Among the 2000 it occurences of our training cor-
pus (see next section), the HC rules recognized 649
of the 727 non-anaphoric pronouns and they have er-
roneously recognized as non-anaphoric 17 pronouns, so
we set the HCR-rules node probabilities as P(HCR-
rules=MatchIPronoun=Non-Anaphoric)=89.2% and P(HCR-
rules=MatchIPronoun=Anaphoric)=1.3% which expresses
the expected value for the false negative cases and the false
positive cases produced by the HC rules respectively.
5So we set P(HC-rules = No-match)=1 and P(Unknown-
Words = More)=1.
6We set P(LC-rules = Match)=1, P(Sequence-Length =
four)=1 and P(Delimitor = That)=1.
</footnote>
<tableCaption confidence="0.980951">
Table 1: Prediction Results (Accuracy/False Posi-
</tableCaption>
<table confidence="0.960379">
tive Cases/False Negatives Cases)
Method Results
Highly Constraint Rules 88.11% / 12.8 / 169.1
Lightly Constraint Rules 88.88% / 123.6 / 24.2
Support Vector Machine 92.71% / - / -
Naive Bayesian Classifier 92.58% / 74.1 / 19.5
Bayesan Network 95.91% / 21.0 / 38.2
</table>
<bodyText confidence="0.8348271">
(1) but that the sentence is not the first of the ab-
stract (2). The sentence also contains the adverb
previously (3) and the verb think (4), which words
belong to our semantic classes7. The a priori
probability for the pronoun to be non-anaphoric is
36.2%. After modifying the probabilities of the
nodes of the BN according to the corpus obser-
vations, the a posteriori probability computed for
this occurence is 99.9% and the system classifies
it as non-anaphoric.
</bodyText>
<sectionHeader confidence="0.993586" genericHeader="evaluation">
4 Experiments and Discussion
</sectionHeader>
<bodyText confidence="0.999487434782609">
Medline is a database specialized in genomic re-
search articles. We extracted from it 11966 ab-
stracts with keywords bacillus subtilis, transcrip-
tion factors, Human, blood cells, gene and fu-
sion. Among these abstracts, we isolated 3347
occurences of the pronoun it and two human an-
notators tagged it occurences as either anaphoric
or non-anaphoric8. After discussion, the two an-
notators achieved a total agreement.
We implemented the HC rules, LC rules and
surface clues using finite transducers and extracted
the pronoun syntactic role from the results of
the Link Parser analysis of the corpus (Aubin,
2005). As a working approximation, we automati-
caly generated the verb, adjective and noun classes
from the training corpus: among all it occurences
tagged as non-anaphoric, we selected the verbs,
adjectives and nouns occurring between the delim-
iter and the pronoun. We considered a third of the
corpus for training and the remaining for testing.
Our experiment was performed using 20-cross val-
idation.
Table1 summarizes the average results reached
</bodyText>
<footnote confidence="0.995598333333333">
7Others node values are set consequently.
8Corpus is available at http://www-lipn.univ-
paris13.fr/˜weissenbacher/
</footnote>
<page confidence="0.996406">
197
</page>
<bodyText confidence="0.999886238095238">
by the state-of-the-art methods described above9.
The BN system achieved a better classification
than other methods.
In order to neutralize and comparatively quan-
tify the contribution in the decision of the depen-
dancy relationships between the factors, we have
implemented a Naive Bayesian Classifier (NBC)
which exploits the same pieces of knowledge and
the same parameters as the BN but it does not
profit from reinforcement mechanism, which leads
to a rise in the number of false positive cases.
Our BN, which has a good precision, never-
theless tags as non-anaphoric some occurrences
which are not. The most recurrent error corre-
sponds to the sequences ending with a delimiter
to recognized by some LC rules. Although none
HC rule matches the sequence, its minimal length
and the fact that it contains particular adjectives
or verbs like assumed or shown, makes this con-
figuration caracteristic enough to tag the pronoun
as non-anaphoric. When the delimiter is that, this
classification is correct 10 but it is always incorrect
when the delimiter is to11. For the delimiter to, the
rules must be more carefully designed.
Three different factors explain the false nega-
tive cases. Firstly, some sequences were ignored
because the delimiter remained implicit12. Sec-
ondly, the presence of apposition clauses increases
the sequence length and decreases the confidence.
Dedicated algorithms taking advantage of a deeper
syntactic analysis could resolve these cases. The
last cause is the non-exhaustiveness of the verb,
adjective and noun classes. It should be possible
to enrich them automatically. In our experiments
we have noticed that if a LC rule matches a se-
quence in the first clause of the first sentence in the
abstract then the pronoun is non-anaphoric. We
could automatically extract from Medline a large
number of such sentences and extend our classes
by selecting the verbs, adjectives and nouns occur-
ing between the pronoun and the delimiter in these
sentences.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9902115">
Our system can of course be enhanced along the
previous axes. However, it is interesting to note
</bodyText>
<footnote confidence="0.877936333333333">
9We have completed the Clement’s SVM score for the
same biological corpus to compare its results with ours.
10Like in the sentence It is assumed that the SecY protein
of B. subtilis has multiple roles...
11Like in the sentence It is assumed to play a role in ...
12For example Thus, it appears T3SO4 has no intrinsic...
</footnote>
<bodyText confidence="0.999867">
that it achieves better results than the comparable
state-of-the art systems, although it relies on the
same set of rules and surface clues. This com-
parison confirms the fact that the BN model pro-
poses an interesting way to combine the various
clues, some of then being only partially reliable.
We are continuing our work and expect to confirm
the contribution of BN to NLP problems on a task
which is more complex than the classification of it
occurences: the resolution of anaphora.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99978225">
S. Aubin, A. Nazarenko and C. Nedellec. 2005.
Adapting a General Parser to a Sublanguage. Pro-
ceedings of the International Conference on Re-
cent Advances in Natural Language Processing
(RANLP’05), 1:89–93.
L. Clemente, K. Satou and K. Torisawa. 2004. Im-
proving the Identification of Non-anaphoric It Us-
ing Support Vector Machines. Actes d’International
Joint Workshop on Natural Language Processing in
Biomedicine and its Applications, 1:58–61.
I. Dagan and A. Itai. 1990. Automatic Processing
of Large Corpora for the Resolution of Anaphora
References. Proceedings of the 13th International
Conference on Computational Linguistics (COL-
ING’90), 3:1–3.
R. Evans. 2001. Applying Machine Learning Toward
an Automatic Classification of it. Literary and lin-
guistic computing, 16:45–57.
S. Lappin and H.J. Leass. 1994. An Algorithm for
Pronominal Anaphora Resolution. Computational
Linguistics, 20(4):535–561.
C.D. Paice and G.D. Husk. 1987. Towards the Auto-
matic Recognition ofAnaphoric Features in English
Text: the Impersonal Pronoun It. Computer Speech
and Language, 2:109–132.
L. Peshkin and A. Pfeffer 2003. Bayesian Information
Extraction Network. In Proc.18th Int. Joint Conf.
Artifical Intelligence, 421–426.
D. Roth and Y. Wen-tau. 2002. Probalistic Reasoning
for Entity and Relation Recognition. Proceedings of
the 19th International Conference on Computational
Linguistics (COLING’02), 1:1–7.
</reference>
<page confidence="0.997708">
198
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.816610">
<title confidence="0.99989">Bayesian Network, a model for NLP?</title>
<author confidence="0.999744">Davy Weissenbacher</author>
<affiliation confidence="0.9777885">Laboratoire d’Informatique de Paris-Nord Universite Paris-Nord</affiliation>
<address confidence="0.998563">Villetaneuse, FRANCE</address>
<email confidence="0.995571">davy.weissenbacher@lipn.univ-paris13.fr</email>
<abstract confidence="0.985585">The NLP systems often have low performances because they rely on unreliable and heterogeneous knowledge. We show the task of non-anaphoric identification how to overcome these handicaps with the Bayesian Network (BN) formalism. The first results are very encouraging compared with the state-of-the-art systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Aubin</author>
<author>A Nazarenko</author>
<author>C Nedellec</author>
</authors>
<title>Adapting a General Parser to a Sublanguage.</title>
<date>2005</date>
<booktitle>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP’05),</booktitle>
<pages>1--89</pages>
<marker>Aubin, Nazarenko, Nedellec, 2005</marker>
<rawString>S. Aubin, A. Nazarenko and C. Nedellec. 2005. Adapting a General Parser to a Sublanguage. Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP’05), 1:89–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Clemente</author>
<author>K Satou</author>
<author>K Torisawa</author>
</authors>
<title>Improving the Identification of Non-anaphoric It Using Support Vector Machines.</title>
<date>2004</date>
<booktitle>Actes d’International Joint Workshop on Natural Language Processing in Biomedicine and its Applications,</booktitle>
<pages>1--58</pages>
<marker>Clemente, Satou, Torisawa, 2004</marker>
<rawString>L. Clemente, K. Satou and K. Torisawa. 2004. Improving the Identification of Non-anaphoric It Using Support Vector Machines. Actes d’International Joint Workshop on Natural Language Processing in Biomedicine and its Applications, 1:58–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>A Itai</author>
</authors>
<title>Automatic Processing of Large Corpora for the Resolution of Anaphora References.</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics (COLING’90),</booktitle>
<pages>3--1</pages>
<marker>Dagan, Itai, 1990</marker>
<rawString>I. Dagan and A. Itai. 1990. Automatic Processing of Large Corpora for the Resolution of Anaphora References. Proceedings of the 13th International Conference on Computational Linguistics (COLING’90), 3:1–3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Evans</author>
</authors>
<title>Applying Machine Learning Toward an Automatic Classification of it. Literary and linguistic computing,</title>
<date>2001</date>
<pages>16--45</pages>
<contexts>
<context position="4378" citStr="Evans, 2001" startWordPosition="693" endWordPosition="694">t/may be&lt;Modaladj&gt;; It is &lt;Cogved&gt; that &lt;Subject&gt; where &lt;Modaladj&gt; and &lt;Cogv&gt; are modal adjective and cognitive verbs classes known to introduce non-anaphoric it (e.g. necessary, possible and recommend, think). This system has a good precision (few false positive cases), but has a low recall (many false negative cases). Any sequence with a variation is ignored by the automata and it is difficult to get exhaustive adjective and verb semantic classes2. In the next paragraphs we refer to Lappin rules’ as Highly Constraint rules (HC rules) and Paice rules’ as Lightly Constraint rules (LC rules). (Evans, 2001) gives up the constraints brought into play by these rules and proposes a machine learning approach based on surface clues. The training determines the relative weight of the various corpus clues. Evans considers 35 syntactic and contextual surface clues (e.g. pronoun position in the sentence, lemma of the following verb) on a manually annotated sample. The system classifies the new it occurences by the k-nearest neighbor method metric. The first tests achieve a satisfactory score: 71.31%Acc on a general language corpus. (Clement, 2004) carries out a similar test in the genomic domain. He redu</context>
</contexts>
<marker>Evans, 2001</marker>
<rawString>R. Evans. 2001. Applying Machine Learning Toward an Automatic Classification of it. Literary and linguistic computing, 16:45–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>H J Leass</author>
</authors>
<title>An Algorithm for Pronominal Anaphora Resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<marker>Lappin, Leass, 1994</marker>
<rawString>S. Lappin and H.J. Leass. 1994. An Algorithm for Pronominal Anaphora Resolution. Computational Linguistics, 20(4):535–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
<author>G D Husk</author>
</authors>
<title>Towards the Automatic Recognition ofAnaphoric Features</title>
<date>1987</date>
<booktitle>in English Text: the Impersonal Pronoun It. Computer Speech and Language,</booktitle>
<pages>2--109</pages>
<marker>Paice, Husk, 1987</marker>
<rawString>C.D. Paice and G.D. Husk. 1987. Towards the Automatic Recognition ofAnaphoric Features in English Text: the Impersonal Pronoun It. Computer Speech and Language, 2:109–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Peshkin</author>
<author>A Pfeffer</author>
</authors>
<title>Bayesian Information Extraction Network.</title>
<date>2003</date>
<booktitle>In Proc.18th Int. Joint Conf. Artifical Intelligence,</booktitle>
<pages>421--426</pages>
<marker>Peshkin, Pfeffer, 2003</marker>
<rawString>L. Peshkin and A. Pfeffer 2003. Bayesian Information Extraction Network. In Proc.18th Int. Joint Conf. Artifical Intelligence, 421–426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>Y Wen-tau</author>
</authors>
<title>Probalistic Reasoning for Entity and Relation Recognition.</title>
<date>2002</date>
<booktitle>Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>1--1</pages>
<marker>Roth, Wen-tau, 2002</marker>
<rawString>D. Roth and Y. Wen-tau. 2002. Probalistic Reasoning for Entity and Relation Recognition. Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), 1:1–7.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>