<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.998921">
Trainable Generation of Big-Five Personality Styles
through Data-driven Parameter Estimation
</title>
<author confidence="0.992881">
Franc¸ois Mairesse
</author>
<affiliation confidence="0.995599">
Cambridge University Engineering Department
</affiliation>
<address confidence="0.8638645">
Trumpington Street
Cambridge, CB2 1PZ, United Kingdom
</address>
<email confidence="0.995208">
farm2@eng.cam.ac.uk
</email>
<author confidence="0.982959">
Marilyn Walker
</author>
<affiliation confidence="0.9974545">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.96249">
Sheffield, S1 4DP, United Kingdom
</address>
<email confidence="0.998369">
lynwalker@gmail.com
</email>
<sectionHeader confidence="0.998589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999097181818182">
Previous work on statistical language gen-
eration has primarily focused on grammat-
icality and naturalness, scoring generation
possibilities according to a language model
or user feedback. More recent work has
investigated data-driven techniques for con-
trolling linguistic style without overgenera-
tion, by reproducing variation dimensions ex-
tracted from corpora. Another line of work
has produced handcrafted rule-based systems
to control specific stylistic dimensions, such
as politeness and personality. This paper
describes a novel approach that automati-
cally learns to produce recognisable varia-
tion along a meaningful stylistic dimension—
personality—without the computational cost
incurred by overgeneration techniques. We
present the first evaluation of a data-driven
generation method that projects multiple per-
sonality traits simultaneously and on a contin-
uous scale. We compare our performance to a
rule-based generator in the same domain.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953076923077">
Over the last 20 years, statistical language models
(SLMs) have been used successfully in many tasks
in natural language processing, and the data avail-
able for modeling has steadily grown (Lapata and
Keller, 2005). Langkilde and Knight (1998) first
applied SLMs to statistical natural language genera-
tion (SNLG), showing that high quality paraphrases
can be generated from an underspecified representa-
tion of meaning, by first applying a very undercon-
strained, rule-based overgeneration phase, whose
outputs are then ranked by an SLM scoring phase.
Since then, research in SNLG has explored a range
of models for both dialogue and text generation.
One line of work has primarily focused on gram-
maticality and naturalness, scoring the overgener-
ation phase with a SLM, and evaluating against
a gold-standard corpus, using string or tree-match
metrics (Langkilde-Geary, 2002; Bangalore and
Rambow, 2000; Chambers and Allen, 2004; Belz,
2005; Isard et al., 2006).
Another thread investigates SNLG scoring mod-
els trained using higher-level linguistic features
to replicate human judgments of utterance quality
(Rambow et al., 2001; Nakatsu and White, 2006;
Stent and Guo, 2005). The error of these scoring
models approaches the gold-standard human rank-
ing with a relatively small training set.
A third SNLG approach eliminates the overgen-
eration phase (Paiva and Evans, 2005). It applies
factor analysis to a corpus exhibiting stylistic vari-
ation, and then learns which generation parameters
to manipulate to correlate with factor measurements.
The generator was shown to reproduce intended fac-
tor levels across several factors, thus modelling the
stylistic variation as measured in the original corpus.
Our goal is a generation technique that can tar-
get multiple stylistic effects simultaneously and
over a continuous scale, controlling stylistic di-
mensions that are commonly understood and thus
meaningful to users and application developers.
Our intended applications are output utterances
for intelligent training or intervention systems,
video game characters, or virtual environment
avatars. In previous work, we presented PERSON-
AGE, a psychologically-informed rule-based genera-
tor based on the Big Five personality model, and we
showed that PERSONAGE can project extreme per-
sonality on the extraversion scale, i.e. both intro-
verted and extraverted personality types (Mairesse
and Walker, 2007). We used the Big Five model
to develop PERSONAGE for several reasons. First,
the Big Five has been shown in psychology to ex-
</bodyText>
<page confidence="0.985209">
165
</page>
<note confidence="0.5772577">
Proceedings of ACL-08: HLT, pages 165–173,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
Trait High Low
Extraversion warm, assertive, sociable, excitement seeking, active, shy, quiet, reserved, passive, solitary, moody
spontaneous, optimistic, talkative
Emotional stability calm, even-tempered, reliable, peaceful, confident neurotic, anxious, depressed, self-conscious
Agreeableness trustworthy, considerate, friendly, generous, helpful unfriendly, selfish, suspicious, uncooperative, ma-
licious
Conscientiousness competent, disciplined, dutiful, achievement striving disorganised, impulsive, unreliable, forgetful
Openness to experience creative, intellectual, curious, cultured, complex narrow-minded, conservative, ignorant, simple
</note>
<tableCaption confidence="0.999011">
Table 1: Example adjectives associated with extreme values of the Big Five trait scales.
</tableCaption>
<figure confidence="0.983741142857143">
1.00
2.00
3.00
4.00
5.00
6.00
7.00
</figure>
<bodyText confidence="0.994552090909091">
plain much of the variation in human perceptions of
personality differences. Second, we believe that the
adjectives used to develop the Big Five model pro-
vide an intuitive, meaningful definition of linguis-
tic style. Table 1 shows some of the trait adjec-
tives associated with the extremes of each Big Five
trait. Third, there are many studies linking person-
ality to linguistic variables (Pennebaker and King,
1999; Mehl et al., 2006, inter alia). See (Mairesse
and Walker, 2007) for more detail.
In this paper, we further test the utility of basing
stylistic variation on the Big Five personality model.
The Big Five traits are represented by scalar val-
ues that range from 1 to 7, with values normally
distributed among humans. While our previous
work targeted extreme values of individual traits,
here we show that we can target multiple person-
ality traits simultaneously and over the continuous
scales of the Big Five model. Section 2 describes
a novel parameter-estimation method that automat-
ically learns to produce recognisable variation for
all Big Five traits, without overgeneration, imple-
mented in a new SNLG called PERSONAGE-PE.
We show that PERSONAGE-PE generates targets for
multiple personality dimensions, using linear and
non-linear parameter estimation models to predict
generation parameters directly from the scalar tar-
gets. Section 3.2 shows that humans accurately per-
ceive the intended variation, and Section 3.3 com-
pares PERSONAGE-PE (trained) with PERSONAGE
(rule-based; Mairesse and Walker, 2007). We delay
a detailed discussion of related work to Section 4,
where we summarize and discuss future work.
</bodyText>
<sectionHeader confidence="0.990269" genericHeader="method">
2 Parameter Estimation Models
</sectionHeader>
<bodyText confidence="0.999464">
The data-driven parameter estimation method con-
sists of a development phase and a generation phase
(Section 3). The development phase:
</bodyText>
<listItem confidence="0.954008666666667">
1. Uses a base generator to produce multiple utter-
ances by randomly varying its parameters;
2. Collects human judgments rating the personality of
each utterance;
3. Trains statistical models to predict the parameters
from the personality judgments;
</listItem>
<figure confidence="0.9356756">
30
20
10
0
Agreeableness rating
</figure>
<figureCaption confidence="0.994509">
Figure 1: Distribution of average agreeableness ratings
from the 2 expert judges for 160 random utterances.
</figureCaption>
<bodyText confidence="0.505306">
4. Selects the best model for each parameter via cross-
validation.
</bodyText>
<subsectionHeader confidence="0.999822">
2.1 Base Generator
</subsectionHeader>
<bodyText confidence="0.977946458333333">
We make minimal assumptions about the input to
the generator to favor domain independence. The
input is a speech act, a potential content pool that
can be used to achieve that speech act, and five scalar
personality parameters (1...7), specifying values for
the continuous scalar dimensions of each trait in
the Big Five model. See Table 1. This requires a
base generator that generates multiple outputs ex-
pressing the same input content by varying linguis-
tic parameters related to the Big Five traits. We
start with the PERSONAGE generator (Mairesse and
Walker, 2007), which generates recommendations
and comparisons of restaurants. We extend PER-
SONAGE with new parameters for a total of 67 pa-
rameters in PERSONAGE-PE. See Table 2. These
parameters are derived from psychological studies
identifying linguistic markers of the Big Five traits
(Pennebaker and King, 1999; Mehl et al., 2006, in-
ter alia). As PERSONAGE’s input parameters are
domain-independent, most parameters range contin-
uously between 0 and 1, while pragmatic marker in-
sertion parameters are binary, except for the SUB-
JECT IMPLICITNESS, STUTTERING and PRONOMI-
Frequency
</bodyText>
<page confidence="0.992762">
166
</page>
<table confidence="0.999678888888889">
Parameters Description
Content parameters:
VERBOSITY Control the number of propositions in the utterance
RESTATEMENTS Paraphrase an existing proposition, e.g. ‘Chanpen Thai has great service, it has fantastic waiters’
REPETITIONS Repeat an existing proposition
CONTENT POLARITY Control the polarity of the propositions expressed, i.e. referring to negative or positive attributes
REPETITIONS POLARITY Control the polarity of the restated propositions
CONCESSIONS Emphasise one attribute over another, e.g. ‘even if Chanpen Thai has great food, it has bad service’
CONCESSIONS POLARITY Determine whether positive or negative attributes are emphasised
POLARISATION Control whether the expressed polarity is neutral or extreme
POSITIVE CONTENT FIRST Determine whether positive propositions—including the claim—are uttered first
Syntactic template selection parameters:
SELF-REFERENCES Control the number of first person pronouns
CLAIM COMPLEXITY Control the syntactic complexity (syntactic embedding)
CLAIM POLARITY Control the connotation of the claim, i.e. whether positive or negative affect is expressed
Aggregation operations:
PERIOD Leave two propositions in their own sentences, e.g. ‘Chanpen Thai has great service. It has nice decor.’
RELATIVE CLAUSE Aggregate propositions with a relative clause, e.g. ‘Chanpen Thai, which has great service, has nice decor’
WITH CUE WORD Aggregate propositions using with, e.g. ‘Chanpen Thai has great service, with nice decor’
CONJUNCTION Join two propositions using a conjunction, or a comma if more than two propositions
MERGE Merge the subject and verb of two propositions, e.g. ‘Chanpen Thai has great service and nice decor’
ALSO CUE WORD Join two propositions using also, e.g. ’Chanpen Thai has great service, also it has nice decor’
CONTRAST - CUE WORD Contrast two propositions using while, but, however, on the other hand, e.g. ’While Chanpen Thai has great
service, it has bad decor’, ’Chanpen Thai has great service, but it has bad decor’
JUSTIFY - CUE WORD Justify a proposition using because, since, so, e.g. ’Chanpen Thai is the best, because it has great service’
CONCEDE - CUE WORD Concede a proposition using although, even if, but/though, e.g. ‘Although Chanpen Thai has great service, it
has bad decor’, ‘Chanpen Thai has great service, but it has bad decor though’
MERGE WITH COMMA Restate a proposition by repeating only the object, e.g. ’Chanpen Thai has great service, nice waiters’
CONJ. WITH ELLIPSIS Restate a proposition after replacing its object by an ellipsis, e.g. ’Chanpen Thai has ..., it has great service’
Pragmatic markers:
SUBJECT IMPLICITNESS Make the restaurant implicit by moving the attribute to the subject, e.g. ‘the service is great’
NEGATION Negate a verb by replacing its modifier by its antonym, e.g. ‘Chanpen Thai doesn’t have bad service’
SOFTENER HEDGES Insert syntactic elements (sort of, kind of, somewhat, quite, around, rather, I think that, it seems that, it seems
to me that) to mitigate the strength of a proposition, e.g. ‘Chanpen Thai has kind of great service’ or ‘It seems
to me that Chanpen Thai has rather great service’
EMPHASIZER HEDGES Insert syntactic elements (really, basically, actually, just) to strengthen a proposition, e.g. ‘Chanpen Thai has
really great service’ or ‘Basically, Chanpen Thai just has great service’
ACKNOWLEDGMENTS Insert an initial back-channel (yeah, right, ok, I see, oh, well), e.g. ‘Well, Chanpen Thai has great service’
FILLED PAUSES Insert syntactic elements expressing hesitancy (like, I mean, err, mmhm, you know), e.g. ‘I mean, Chanpen
Thai has great service, you know’ or ‘Err... Chanpen Thai has, like, great service’
EXCLAMATION Insert an exclamation mark, e.g. ‘Chanpen Thai has great service!’
EXPLETIVES Insert a swear word, e.g. ‘the service is damn great’
NEAR-EXPLETIVES Insert a near-swear word, e.g. ‘the service is darn great’
COMPETENCE MITIGATION Express the speaker’s negative appraisal of the hearer’s request, e.g. ‘everybody knows that... ’
TAG QUESTION Insert a tag question, e.g. ‘the service is great, isn’t it?’
STUTTERING Duplicate the first letters of a restaurant’s name, e.g. ‘Ch-ch-anpen Thai is the best’
CONFIRMATION Begin the utterance with a confirmation of the restaurant’s name, e.g. ‘did you say Chanpen Thai?’
INITIAL REJECTION Begin the utterance with a mild rejection, e.g. ‘I’m not sure’
IN-GROUP MARKER Refer to the hearer as a member of the same social group, e.g. pal, mate and buddy
PRONOMINALIZATION Replace occurrences of the restaurant’s name by pronouns
Lexical choice parameters:
LEXICAL FREQUENCY Control the average frequency of use of each content word, according to BNC frequency counts
WORD LENGTH Control the average number of letters of each content word
VERB STRENGTH Control the strength of the selected verbs, e.g. ‘I would suggest’ vs. ‘I would recommend’
</table>
<tableCaption confidence="0.905437333333333">
Table 2: The 67 generation parameters whose target values are learned. Aggregation cue words, hedges, acknowl-
edgments and filled pauses are learned individually (as separate parameters), e.g. kind of is modeled differently than
somewhat in the SOFTENER HEDGES category. Parameters are detailed in previous work (Mairesse and Walker, 2007).
</tableCaption>
<sectionHeader confidence="0.541472" genericHeader="method">
NALIZATION parameters.
</sectionHeader>
<subsectionHeader confidence="0.970844">
2.2 Random Sample Generation and Expert
Judgments
</subsectionHeader>
<bodyText confidence="0.999965">
We generate a sample of 160 random utterances by
varying the parameters in Table 2 with a uniform dis-
tribution. This sample is intended to provide enough
training material for estimating all 67 parameters
for each personality dimension. Following Mairesse
and Walker (2007), two expert judges (not the au-
thors) familiar with the Big Five adjectives (Table 1)
evaluate the personality of each utterance using the
Ten-Item Personality Inventory (TIPI; Gosling et al.,
2003), and also judge the utterance’s naturalness.
Thus 11 judgments were made for each utterance for
a total of 1760 judgments. The TIPI outputs a rating
on a scale from 1 (low) to 7 (high) for each Big Five
trait. The expert judgments are approximately nor-
</bodyText>
<page confidence="0.988022">
167
</page>
<bodyText confidence="0.9876285">
mally distributed; Figure 1 shows the distribution for
agreeableness.
</bodyText>
<subsectionHeader confidence="0.983012">
2.3 Statistical Model Training
</subsectionHeader>
<bodyText confidence="0.999507479166666">
Training data is created for each generation
parameter—i.e. the output variable—to train statis-
tical models predicting the optimal parameter value
from the target personality scores. The models are
thus based on the simplifying assumption that the
generation parameters are independent. Any person-
ality trait whose correlation with a generation deci-
sion is below 0.1 is removed from the training data.
This has the effect of removing parameters that do
not correlate strongly with any trait, which are set to
a constant default value at generation time. Since
the input parameter values may not be satisfiable
depending on the input content, the actual genera-
tion decisions made for each utterance are recorded.
For example, the CONCESSIONS decision value is
the actual number of concessions produced in the
utterance. To ensure that the models’ output can
control the generator, the generation decision values
are normalized to match the input range (0...1) of
PERSONAGE-PE. Thus the dataset consists of 160
utterances and the corresponding generation deci-
sions, each associated with 5 personality ratings av-
eraged over both judges.
Parameter estimation models are trained to predict
either continuous (e.g. VERBOSITY) or binary (e.g.
EXCLAMATION) generation decisions. We compare
various learning algorithms using the Weka toolkit
(with default values unless specified; Witten and
Frank, 2005). Continuous parameters are modeled
with a linear regression model (LR), an M5’ model
tree (M5), and a model based on support vector ma-
chines with a linear kernel (SVM). As regression
models can extrapolate beyond the [0, 1] interval, the
output parameter values are truncated if needed—at
generation time—before being sent to the base gen-
erator. Binary parameters are modeled using clas-
sifiers that predict whether the parameter is enabled
or disabled. We test a Naive Bayes classifier (NB), a
j48 decision tree (J48), a nearest-neighbor classifier
using one neighbor (NN), a Java implementation of
the RIPPER rule-based learner (JRIP), the AdaBoost
boosting algorithm (ADA), and a support vector ma-
chines classifier with a linear kernel (SVM).
Figures 2, 3 and 4 show the models learned for
the EXCLAMATION (binary), STUTTERING (contin-
uous), and CONTENT POLARITY (continuous) pa-
rameters in Table 2. The models predict generation
parameters from input personality scores; note that
</bodyText>
<construct confidence="0.968448777777778">
Condition Class Weight
if extraversion &gt; 6.42 then 1 else 0 1.81
if extraversion &gt; 4.42 then 1 else 0 0.38
if extraversion &lt;= 6.58 then 1 else 0 0.22
if extraversion &gt; 4.71 then 1 else 0 0.28
if agreeableness &gt; 5.13 then 1 else 0 0.42
if extraversion &lt;= 6.58 then 1 else 0 0.14
if extraversion &gt; 4.79 then 1 else 0 0.19
if extraversion &lt;= 6.58 then 1 else 0 0.17
</construct>
<figureCaption confidence="0.944154166666667">
Figure 2: AdaBoost model predicting the EXCLAMATION
parameter. Given input trait values, the model outputs
the class yielding the largest sum of weights for the rules
returning that class. Class 0 = disabled, class 1 = enabled.
Figure 3: SVM model with a linear kernel predicting the
CONTENT POLARITY parameter.
</figureCaption>
<bodyText confidence="0.999974739130435">
sometimes the best performing model is non-linear.
Given input trait values, the AdaBoost model in Fig-
ure 2 outputs the class yielding the largest sum of
weights for the rules returning that class. For ex-
ample, the first rule of the EXCLAMATION model
shows that an extraversion score above 6.42 out of
7 would increase the weight of the enabled class by
1.81. The fifth rule indicates that a target agreeable-
ness above 5.13 would further increase the weight
by .42. The STUTTERING model tree in Figure 4
lets us calculate that a low emotional stability (1.0)
together with a neutral conscientiousness and open-
ness to experience (4.0) yield a parameter value of
.62 (see LM2), whereas a neutral emotional stabil-
ity decreases the value down to .17. Figure 4 also
shows how personality traits that do not affect the
parameter are removed, i.e. emotional stability, con-
scientiousness and openness to experience are the
traits that affect stuttering. The linear model in Fig-
ure 3 shows that agreeableness has a strong effect
on the CONTENT POLARITY parameter (.97 weight),
but emotional stability, conscientiousness and open-
ness to experience also have an effect.
</bodyText>
<subsectionHeader confidence="0.991805">
2.4 Model Selection
</subsectionHeader>
<bodyText confidence="0.998903333333333">
The final step of the development phase identifies
the best performing model(s) for each generation
parameter via cross-validation. For continuous pa-
</bodyText>
<table confidence="0.982670283018868">
(normalized) Content polarity =
0.054
- 0.102 * (normalized) emotional stability
+ 0.970 * (normalized) agreeableness
- 0.110 * (normalized) conscientiousness
+ 0.013 * (normalized) openness to
experience
168
Conscientiousness
&lt; 3.875 &gt; 3.875
Stuttering =
-0.0136 * emotional stability
+ 0.0098 * conscientiousness
+ 0.0063 * openness to experience
+ 0.0126
Emotional stability
&lt; 4.375 &gt; 4.375
Stuttering = Stuttering =
-0.1531 * emotional stability -0.0142 * emotional stability
+ 0.004 * conscientiousness + 0.004 * conscientiousness
+ 0.1122 * openness to experience + 0.0076 * openness to experience
+ 0.3129 + 0.0576
Figure 4: M5’ model tree predicting the STUTTERING parameter.
Continuous parameters LR M5 SVM
Content parameters:
VERBOSITY 0.24 0.26 0.21
RESTATEMENTS 0.14 0.14 0.04
REPETITIONS 0.13 0.13 0.08
CONTENT POLARITY 0.46 0.46 0.47
REPETITIONS POLARITY 0.02 0.15 0.06
CONCESSIONS 0.23 0.23 0.12
CONCESSIONS POLARITY -0.01 0.16 0.07
POLARISATION 0.20 0.21 0.20
Syntactic template selection:
CLAIM COMPLEXITY 0.10 0.33 0.26
CLAIM POLARITY 0.04 0.04 0.05
Aggregation operations:
INFER - WITH CUE WORD 0.03 0.03 0.01
INFER - ALSO CUE WORD 0.10 0.10 0.06
JUSTIFY - SINCE CUE WORD 0.03 0.07 0.05
JUSTIFY - SO CUE WORD 0.07 0.07 0.04
JUSTIFY - PERIOD 0.36 0.35 0.21
CONTRAST - PERIOD 0.27 0.26 0.26
RESTATE - MERGE WITH COMMA 0.18 0.18 0.09
CONCEDE - ALTHOUGH CUE WORD 0.08 0.08 0.05
CONCEDE - EVEN IF CUE WORD 0.05 0.05 0.03
Pragmatic markers:
SUBJECT IMPLICITNESS 0.13 0.13 0.04
STUTTERING INSERTION 0.16 0.23 0.17
PRONOMINALIZATION 0.22 0.20 0.17
Lexical choice parameters:
LEXICAL FREQUENCY 0.21 0.21 0.19
WORD LENGTH 0.18 0.18 0.15
</table>
<tableCaption confidence="0.811116166666667">
Table 3: Pearson’s correlation between parameter model
predictions and continuous parameter values, for differ-
ent regression models. Parameters that do not correlate
with any trait are omitted. Aggregation operations are as-
sociated with a rhetorical relation (e.g. INFER). Results
are averaged over a 10-fold cross-validation.
</tableCaption>
<bodyText confidence="0.97558">
rameters, Table 3 evaluates modeling accuracy by
comparing the correlations between the model’s pre-
dictions and the actual parameter values in the test
folds. Table 4 reports results for binary parameter
classifiers, by comparing the F-measures of the en-
abled class. Best performing models are identified
in bold; parameters that do not correlate with any
trait or that produce a poor modeling accuracy are
omitted.
The CONTENT POLARITY parameter is modeled
</bodyText>
<table confidence="0.999790444444444">
Binary parameters NB J48 NN ADA SVM
Pragmatic markers:
SOFTENER HEDGES
kind of 0.00 0.00 0.16 0.11 0.10
rather 0.00 0.00 0.02 0.01 0.01
quite 0.14 0.08 0.09 0.07 0.06
EMPHASIZER HEDGES 0.00 0.00 0.02 0.01 0.01
basically
ACKNOWLEDGMENTS 0.00 0.00 0.04 0.03 0.03
yeah
ok 0.13 0.07 0.06 0.05 0.05
FILLED PAUSES 0.32 0.20 0.24 0.22 0.19
err
EXCLAMATION 0.23 0.34 0.36 0.38 0.34
EXPLETIVES 0.27 0.18 0.24 0.17 0.15
IN-GROUP MARKER 0.40 0.31 0.31 0.24 0.21
TAG QUESTION 0.32 0.21 0.21 0.15 0.13
CONFIRMATION 0.00 0.00 0.07 0.04 0.04
</table>
<tableCaption confidence="0.8901748">
Table 4: F-measure of the enabled class for classifica-
tion models of binary parameters. Parameters that do
not correlate with any trait are omitted. Results are av-
eraged over a 10-fold cross-validation. JRIP models are
not shown as they never perform best.
</tableCaption>
<bodyText confidence="0.999972166666667">
the most accurately, with the SVM model in Fig-
ure 3 producing a correlation of .47 with the true pa-
rameter values. Models of the PERIOD aggregation
operation also perform well, with a linear regression
model yielding a correlation of .36 when realizing
a justification, and .27 when contrasting two propo-
sitions. CLAIM COMPLEXITY and VERBOSITY are
also modeled successfully, with correlations of .33
and .26 using a model tree. The model tree control-
ling the STUTTERING parameter illustrated in Fig-
ure 4 produces a correlation of .23. For binary pa-
rameters, Table 4 shows that the Naive Bayes classi-
fier is generally the most accurate, with F-measures
of .40 for the IN-GROUP MARKER parameter, and
.32 for both the insertion of filled pauses (err) and
tag questions. The AdaBoost algorithm best predicts
the EXCLAMATION parameter, with an F-measure of
.38 for the model in Figure 2.
</bodyText>
<page confidence="0.996693">
169
</page>
<table confidence="0.999509166666667">
# Traits End Rating Nat Output utterance
1.a Extraversion 4.42 4.79 Radio Perfecto’s price is 25 dollars but Les Routiers provides adequate food. I
Extraversion high 4.94 imagine they’re alright!
high
1.b Emotional stability high 5.35 5.04 Let’s see, Les Routiers and Radio Perfecto... You would probably appreciate them.
Conscientiousness high 5.21 Radio Perfecto is in the East Village with kind of acceptable food. Les Routiers is
located in Manhattan. Its price is 41 dollars.
2.a Extraversion low 3.65 3.21 Err... you would probably appreciate Trattoria Rustica, wouldn’t you? It’s in
Agreeableness low 4.02 Manhattan, also it’s an italian restaurant. It offers poor ambience, also it’s quite costly.
2.b Emotional stability low 4.13 4.50 Trattoria Rustica isn’t as bad as the others. Err... even if it’s costly, it offers kind of
Openness to low 3.85 adequate food, alright? It’s an italian place.
experience
</table>
<tableCaption confidence="0.900504666666667">
Table 5: Example outputs controlled by the parameter estimation models for a comparison (#1) and a recommendation
(#2), with the average judges’ ratings (Rating) and naturalness (Nat). Ratings are on a scale from 1 to 7, with 1 = very
low (e.g. neurotic or introvert) and 7 = very high on the dimension (e.g. emotionally stable or extraverted).
</tableCaption>
<sectionHeader confidence="0.993893" genericHeader="evaluation">
3 Evaluation Experiment
</sectionHeader>
<bodyText confidence="0.999334">
The generation phase of our parameter estimation
SNLG method consists of the following steps:
</bodyText>
<listItem confidence="0.99536725">
1. Use the best performing models to predict parame-
ter values from the desired personality scores;
2. Generate the output utterance using the predicted
parameter values.
</listItem>
<bodyText confidence="0.999389666666667">
We then evaluate the output utterances using naive
human judges to rate their perceived personality and
naturalness.
</bodyText>
<subsectionHeader confidence="0.997894">
3.1 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.916425068181818">
Given the best performing model for each genera-
tion parameter, we generate 5 utterances for each
of 5 recommendation and 5 comparison speech acts.
Each utterance targets an extreme value for two traits
(either 1 or 7 out of 7) and neutral values for the re-
maining three traits (4 out of 7). The goal is for each
utterance to project multiple traits on a continuous
scale. To generate a range of alternatives, a Gaus-
sian noise with a standard deviation of 10% of the
full scale is added to each target value.
Subjects were 24 native English speakers (12
male and 12 female graduate students from a range
of disciplines from both the U.K. and the U.S.). Sub-
jects evaluate the naturalness and personality of each
utterance using the TIPI (Gosling et al., 2003). To
limit the experiment’s duration, only the two traits
with extreme target values are evaluated for each
utterance. Subjects thus answered 5 questions for
50 utterances, two from the TIPI for each extreme
trait and one about naturalness (250 judgments in
total per subject). Subjects were not told that the
utterances were intended to manifest extreme trait
values. Table 5 shows several sample outputs and
the mean personality ratings from the human judges.
For example, utterance 1.a projects a high extraver-
sion through the insertion of an exclamation mark
based on the model in Figure 2, whereas utterance
2.a conveys introversion by beginning with the filled
pause err. The same utterance also projects a low
agreeableness by focusing on negative propositions,
through a low CONTENT POLARITY parameter value
as per the model in Figure 3. This evaluation ad-
dresses a number of open questions discussed below.
Q1: Is the personality projected by models trained on
ratings from a few expert judges recognised by a
larger sample of naive judges? (Section 3.2)
Q2: Can a combination of multiple traits within a single
utterance be detected by naive judges? (Section 3.2)
Q3: How does PERSONAGE-PE compare to PERSON-
AGE, a psychologically-informed rule-based gen-
erator for projecting extreme personality? (Sec-
tion 3.3)
Q4: Does the parameter estimation SNLG method pro-
duce natural utterances? (Section 3.4)
</bodyText>
<subsectionHeader confidence="0.997735">
3.2 Parameter Estimation Evaluation
</subsectionHeader>
<bodyText confidence="0.987421947368421">
Table 6 shows that extraversion is the dimension
modeled most accurately by the parameter estima-
tion models, producing a .45 correlation with the
subjects’ ratings (p &lt; .01). Emotional stability,
agreeableness, and openness to experience ratings
also correlate strongly with the target scores, with
correlations of .39, .36 and .17 respectively (p &lt;
.01). Additionally, Table 6 shows that the magni-
tude of the correlation increases when considering
the perception of a hypothetical average subject, i.e.
smoothing individual variation by averaging the rat-
ings over all 24 judges, producing a correlation ra,,g
up to .80 for extraversion. These correlations are
unexpectedly high; in corpus analyses, significant
correlations as low as .05 to .10 are typically ob-
served between personality and linguistic markers
(Pennebaker and King, 1999; Mehl et al., 2006).
Conscientiousness is the only dimension whose
ratings do not correlate with the target scores. The
</bodyText>
<page confidence="0.991719">
170
</page>
<bodyText confidence="0.998631">
comparison with rule-based results in Section 3.3
suggests that this is not because conscientiousness
cannot be exhibited in our domain or manifested in
a single utterance, so perhaps this arises from dif-
fering perceptions of conscientiousness between the
expert and naive judges.
</bodyText>
<table confidence="0.956132375">
Trait r rang e
Extraversion .45 • .80 • 1.89
Emotional stability .39 • .64 • 2.14
Agreeableness .36 • .68 • 2.38
Conscientiousness -.01 -.02 2.79
Openness to experience .17 • .41 • 2.51
• statistically significant correlation
p &lt; .05, • p = .07 (two-tailed)
</table>
<tableCaption confidence="0.885015">
Table 6: Pearson’s correlation coefficient r and mean ab-
solute error e between the target personality scores and
</tableCaption>
<bodyText confidence="0.9371857">
the 480 judges’ ratings (20 ratings per trait for 24 judges);
rang is the correlation between the personality scores and
the average judges’ ratings.
Table 6 shows that the mean absolute error varies
between 1.89 and 2.79 on a scale from 1 to 7. Such
large errors result from the decision to ask judges to
answer just the TIPI questions for the two traits that
were the extreme targets (See Section 3.1), because
the judges tend to use the whole scale, with approx-
imately normally distributed ratings. This means
that although the judges make distinctions leading to
high correlations, they do so on a compressed scale.
This explains the large correlations despite the mag-
nitude of the absolute error.
Table 7 shows results evaluating whether utter-
ances targeting the extremes of a trait are perceived
differently. The ratings differ significantly for all
traits but conscientiousness (p &lt; .001). Thus pa-
rameter estimation models can be used in applica-
tions that only require discrete binary variation.
</bodyText>
<table confidence="0.898415625">
Trait Low High
Extraversion 3.69 5.06 •
Emotional stability 3.75 4.75 •
Agreeableness 3.42 4.33 •
Conscientiousness 4.16 4.15
Openness to experience 3.71 4.06 •
• statistically significant difference
p &lt; .001 (two-tailed)
</table>
<tableCaption confidence="0.977976333333333">
Table 7: Average personality ratings for the utterances
generated with the low and high target values for each
trait on a scale from 1 to 7.
</tableCaption>
<bodyText confidence="0.999801692307692">
It is important to emphasize that generation pa-
rameters were predicted based on 5 target person-
ality values. Thus, the results show that individ-
ual traits are perceived even when utterances project
other traits as well, confirming that the Big Five the-
ory models independent dimensions and thus pro-
vides a useful and meaningful framework for mod-
eling variation in language. Additionally, although
we do not directly evaluate the perception of mid-
range values of personality target scores, the results
suggest that mid-range personality is modeled cor-
rectly because the neutral target scores do not affect
the perception of extreme traits.
</bodyText>
<subsectionHeader confidence="0.999853">
3.3 Comparison with Rule-Based Generation
</subsectionHeader>
<bodyText confidence="0.984848666666667">
PERSONAGE is a rule-based personality generator
based on handcrafted parameter settings derived
from psychological studies. Mairesse and Walker
(2007) show that this approach generates utterances
that are perceptibly different along the extraversion
dimension. Table 8 compares the mean ratings of
the utterances generated by PERSONAGE-PE with
ratings of 20 utterances generated by PERSONAGE
for each extreme of each Big Five scale (40 for ex-
traversion, resulting in 240 handcrafted utterances in
total). Table 8 shows that the handcrafted parame-
ter settings project a significantly more extreme per-
sonality for 6 traits out of 10. However, the learned
parameter models for neuroticism, disagreeableness,
unconscientiousness and openness to experience do
not perform significantly worse than the handcrafted
generator. These findings are promising as we dis-
cuss further in Section 4.
</bodyText>
<table confidence="0.999721714285714">
Method Rule-based Learned parameters
Trait Low High Low High
Extraversion 2.96 5.98 3.69 o 5.05 o
Emotional stability 3.29 5.96 3.75 4.75 o
Agreeableness 3.41 5.66 3.42 4.33 o
Conscientiousness 3.71 5.53 4.16 4.15 o
Openness to experience 2.89 4.21 3.71 o 4.06
</table>
<tableCaption confidence="0.958271125">
•,o significant increase or decrease of the variation range
over the average rule-based ratings (p &lt; .05, two-tailed)
Table 8: Pair-wise comparison between the ratings of
the utterances generated using PERSONAGE-PE with ex-
treme target values (Learned Parameters), and the ratings
for utterances generated with Mairesse and Walker’s rule-
based PERSONAGE generator, (Rule-based). Ratings are
averaged over all judges.
</tableCaption>
<subsectionHeader confidence="0.97332">
3.4 Naturalness Evaluation
</subsectionHeader>
<bodyText confidence="0.999967">
The naive judges also evaluated the naturalness of
the outputs of our trained models. Table 9 shows
that the average naturalness is 3.98 out of 7, which is
significantly lower (p &lt; .05) than the naturalness of
handcrafted and randomly generated utterances re-
ported by Mairesse and Walker (2007). It is possi-
ble that the differences arise from judgments of ut-
terances targeting multiple traits, or that the naive
</bodyText>
<page confidence="0.994951">
171
</page>
<table confidence="0.916072">
judges are more critical.
Trait Rule-based Random Learned
All 4.59 4.38 3.98
</table>
<tableCaption confidence="0.779555285714286">
Table 9: Average naturalness ratings for utterances gen-
erated using (1) PERSONAGE, the rule-based generator,
(2) the random utterances (expert judges) and (3) the out-
puts of PERSONAGE-PE using the parameter estimation
models (Learned, naive judges). The means differ sig-
nificantly at the p &lt; .05 level (two-tailed independent
sample t-test).
</tableCaption>
<sectionHeader confidence="0.998728" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999988395604396">
We present a new method for generating linguis-
tic variation projecting multiple personality traits
continuously, by combining and extending previous
research in statistical natural language generation
(Paiva and Evans, 2005; Rambow et al., 2001; Is-
ard et al., 2006; Mairesse and Walker, 2007). While
handcrafted rule-based approaches are limited to
variation along a small number of discrete points
(Hovy, 1988; Walker et al., 1997; Lester et al., 1997;
Power et al., 2003; Cassell and Bickmore, 2003; Pi-
wek, 2003; Mairesse and Walker, 2007; Rehm and
Andr´e, in press), we learn models that predict pa-
rameter values for any arbitrary value on the varia-
tion dimension scales. Additionally, our data-driven
approach can be applied to any dimension that is
meaningful to human judges, and it provides an ele-
gant way to project multiple dimensions simultane-
ously, by including the relevant dimensions as fea-
tures of the parameter models’ training data.
Isard et al. (2006) and Mairesse and Walker
(2007) also propose a personality generation
method, in which a data-driven personality model
selects the best utterance from a large candidate set.
Isard et al.’s technique has not been evaluated, while
Mairesse and Walker’s overgenerate and score ap-
proach is inefficient. Paiva and Evans’ technique
does not overgenerate (2005), but it requires a search
for the optimal generation decisions according to
the learned models. Our approach does not require
any search or overgeneration, as parameter estima-
tion models predict the generation decisions directly
from the target variation dimensions. This tech-
nique is therefore beneficial for real-time genera-
tion. Moreover the variation dimensions of Paiva
and Evans’ data-driven technique are extracted from
a corpus: there is thus no guarantee that they can
be easily interpreted by humans, and that they gen-
eralise to other corpora. Previous work has shown
that modeling the relation between personality and
language is far from trivial (Pennebaker and King,
1999; Argamon et al., 2005; Oberlander and Now-
son, 2006; Mairesse et al., 2007), suggesting that the
control of personality is a harder problem than the
control of data-driven variation dimensions.
We present the first human perceptual evaluation
of a data-driven stylistic variation method. In terms
of our research questions in Section 3.1, we show
that models trained on expert judges to project mul-
tiple traits in a single utterance generate utterances
whose personality is recognized by naive judges.
There is only one other similar evaluation of an
SNLG (Rambow et al., 2001). Our models perform
only slightly worse than a handcrafted rule-based
generator in the same domain. These findings are
promising as (1) parameter estimation models are
able to target any combination of traits over the full
range of the Big Five scales; (2) they do not benefit
from psychological knowledge, i.e. they are trained
on randomly generated utterances.
This work also has several limitations that should
be addressed in future work. Even though the
parameters of PERSONAGE-PE were suggested by
psychological studies (Mairesse and Walker, 2007),
some of them are not modeled successfully by our
approach, and thus omitted from Tables 3 and 4.
This could be due to the relatively small develop-
ment dataset size (160 utterances to optimize 67 pa-
rameters), or to the implementation of some param-
eters. The strong parameter-independence assump-
tion could also be responsible, but we are not aware
of any state of the art implementation for learn-
ing multiple dependent variables, and this approach
could further aggravate data sparsity issues.
In addition, it is unclear why PERSONAGE per-
forms better for projecting extreme personality
and produces more natural utterances, and why
PERSONAGE-PE fails to project conscientiousness
correctly. It might be possible to improve the pa-
rameter estimation models with a larger sample of
random utterances at development time, or with ad-
ditional extreme data generated using the rule-based
approach. Such hybrid models are likely to perform
better for extreme target scores, as they are trained
on more uniformly distributed ratings (e.g. com-
pared to the normal distribution in Figure 1). In ad-
dition, we have only shown that personality can be
expressed by information presentation speech-acts
in the restaurant domain; future work should assess
the extent to which the parameters derived from psy-
chological findings are culture, domain, and speech
act dependent.
</bodyText>
<page confidence="0.996977">
172
</page>
<sectionHeader confidence="0.998331" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99994109">
S. Argamon, S. Dhawle, M. Koppel, and J. Pennebaker.
Lexical predictors of personality type. In Proceedings
of the Joint Annual Meeting of the Interface and the
Classification Society of North America, 2005.
S. Bangalore and O. Rambow. Exploiting a probabilistic
hierarchical model for generation. In Proceedings of
the 18th International Conference on Computational
Linguistics (COLING), pages 42–48, 2000.
A. Belz. Corpus-driven generation of weather forecasts.
In Proceedings of the 3rd Corpus Linguistics Confer-
ence, 2005.
J. Cassell and T. Bickmore. Negotiated collusion: Mod-
eling social language and its relationship effects in in-
telligent agents. User Modeling and User-Adapted In-
teraction, 13:89–132, 2003.
N. Chambers and J. Allen. Stochastic language genera-
tion in a dialogue system: Toward a domain indepen-
dent generator. In Proceedings 5th SIGdial Workshop
on Discourse and Dialogue, 2004.
S. D. Gosling, P. J. Rentfrow, and W. B. Swann. A
very brief measure of the big five personality domains.
Journal of Research in Personality, 37:504–528, 2003.
E. Hovy. Generating Natural Language under Pragmatic
Constraints. Lawrence Erlbaum Associates, 1988.
A. Isard, C. Brockmann, and J. Oberlander. Individuality
and alignment in generated dialogues. In Proceedings
of the 4th International Natural Language Generation
Conference (INLG), pages 22–29, 2006.
I. Langkilde and K. Knight. Generation that exploits
corpus-based statistical knowledge. In Proceedings of
the 36th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 704–710, 1998.
I. Langkilde-Geary. An empirical verification of coverage
and correctness for a general-purpose sentence genera-
tor. In Proceedings of the 1st International Conference
on Natural Language Generation, 2002.
M. Lapata and F. Keller. Web-based models for natu-
ral language processing. ACM Transactions on Speech
and Language Processing, 2:1–31, 2005.
J. Lester, S. Converse, S. Kahler, S. Barlow, B. Stone,
and R. Bhogal. The persona effect: affective impact
of animated pedagogical agents. Proceedings of the
SIGCHI conference on Human factors in computing
systems, pages 359–366, 1997.
F. Mairesse and M. A. Walker. PERSONAGE: Personal-
ity generation for dialogue. In Proceedings of the 45th
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 496–503, 2007.
F. Mairesse, M. A. Walker, M. R. Mehl, and R. K. Moore.
Using linguistic cues for the automatic recognition of
personality in conversation and text. Journal of Artifi-
cial Intelligence Research (JAIR), 30:457–500, 2007.
M. R. Mehl, S. D. Gosling, and J. W. Pennebaker. Person-
ality in its natural habitat: Manifestations and implicit
folk theories of personality in daily life. Journal of
Personality and Social Psychology, 90:862–877, 2006.
C. Nakatsu and M. White. Learning to say it well:
Reranking realizations by predicted synthesis quality.
In Proceedings of the 44th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
1113–1120, 2006.
J. Oberlander and S. Nowson. Whose thumb is it any-
way? classifying author personality from weblog text.
In Proceedings of the 44th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), 2006.
D. S. Paiva and R. Evans. Empirically-based control of
natural language generation. In Proceedings of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 58–65, 2005.
J. W. Pennebaker and L. A. King. Linguistic styles: Lan-
guage use as an individual difference. Journal of Per-
sonality and Social Psychology, 77:1296–1312, 1999.
P. Piwek. A flexible pragmatics-driven language gener-
ator for animated agents. In Proceedings of Annual
Meeting of the European Chapter of the Association
for Computational Linguistics (EACL), 2003.
R. Power, D. Scott, and N. Bouayad-Agha. Generating
texts with style. In Proceedings of the 4th Interna-
tional Conference on Intelligent Text Processing and
Computational Linguistics, 2003.
O. Rambow, M. Rogati, and M. A. Walker. Evaluating a
trainable sentence planner for a spoken dialogue travel
system. In Proceedings of the 39th Annual Meeting of
the Association for Computational Linguistics (ACL),
2001.
M. Rehm and E. Andr´e. From annotated multi-
modal corpora to simulated human-like behaviors.
In I. Wachsmuth and G. Knoblich, editors, Model-
ing Communication with Robots and Virtual Humans.
Springer, Berlin, Heidelberg, in press.
A. Stent and H. Guo. A new data-driven approach
for multimedia presentation generation. In Proc. Eu-
roIMSA, 2005.
M. A. Walker, J. E. Cahn, and S. J. Whittaker. Improvis-
ing linguistic style: Social and affective bases for agent
personality. In Proceedings of the 1st Conference on
Autonomous Agents, pages 96–105, 1997.
I. H. Witten and E. Frank. Data Mining: Practical ma-
chine learning tools and techniques. Morgan Kauf-
mann, San Francisco, CA, 2005.
</reference>
<page confidence="0.999106">
173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.489777">
<title confidence="0.983631">Trainable Generation of Big-Five Personality Styles through Data-driven Parameter Estimation</title>
<author confidence="0.781712">Mairesse</author>
<affiliation confidence="0.816998">Cambridge University Engineering Department Trumpington Street</affiliation>
<address confidence="0.999507">Cambridge, CB2 1PZ, United Kingdom</address>
<email confidence="0.995577">farm2@eng.cam.ac.uk</email>
<author confidence="0.999863">Marilyn Walker</author>
<affiliation confidence="0.999891">Department of Computer Science University of Sheffield</affiliation>
<address confidence="0.997553">Sheffield, S1 4DP, United Kingdom</address>
<email confidence="0.999867">lynwalker@gmail.com</email>
<abstract confidence="0.999316478260869">Previous work on statistical language generation has primarily focused on grammaticality and naturalness, scoring generation possibilities according to a language model or user feedback. More recent work has investigated data-driven techniques for controlling linguistic style without overgeneration, by reproducing variation dimensions extracted from corpora. Another line of work produced handcrafted to control specific stylistic dimensions, such as politeness and personality. This paper describes a novel approach that automatically learns to produce recognisable variation along a meaningful stylistic dimension— personality—without the computational cost incurred by overgeneration techniques. We present the first evaluation of a data-driven generation method that projects multiple pertraits on a contin- We compare our performance to a rule-based generator in the same domain.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Argamon</author>
<author>S Dhawle</author>
<author>M Koppel</author>
<author>J Pennebaker</author>
</authors>
<title>Lexical predictors of personality type.</title>
<date>2005</date>
<booktitle>In Proceedings of the Joint Annual Meeting of the Interface and the Classification Society of</booktitle>
<publisher>North America,</publisher>
<contexts>
<context position="34744" citStr="Argamon et al., 2005" startWordPosition="5354" endWordPosition="5357">d models. Our approach does not require any search or overgeneration, as parameter estimation models predict the generation decisions directly from the target variation dimensions. This technique is therefore beneficial for real-time generation. Moreover the variation dimensions of Paiva and Evans’ data-driven technique are extracted from a corpus: there is thus no guarantee that they can be easily interpreted by humans, and that they generalise to other corpora. Previous work has shown that modeling the relation between personality and language is far from trivial (Pennebaker and King, 1999; Argamon et al., 2005; Oberlander and Nowson, 2006; Mairesse et al., 2007), suggesting that the control of personality is a harder problem than the control of data-driven variation dimensions. We present the first human perceptual evaluation of a data-driven stylistic variation method. In terms of our research questions in Section 3.1, we show that models trained on expert judges to project multiple traits in a single utterance generate utterances whose personality is recognized by naive judges. There is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform only slightly worse than</context>
</contexts>
<marker>Argamon, Dhawle, Koppel, Pennebaker, 2005</marker>
<rawString>S. Argamon, S. Dhawle, M. Koppel, and J. Pennebaker. Lexical predictors of personality type. In Proceedings of the Joint Annual Meeting of the Interface and the Classification Society of North America, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>42--48</pages>
<contexts>
<context position="2225" citStr="Bangalore and Rambow, 2000" startWordPosition="306" endWordPosition="309">cal natural language generation (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulat</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>S. Bangalore and O. Rambow. Exploiting a probabilistic hierarchical model for generation. In Proceedings of the 18th International Conference on Computational Linguistics (COLING), pages 42–48, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Belz</author>
</authors>
<title>Corpus-driven generation of weather forecasts.</title>
<date>2005</date>
<booktitle>In Proceedings of the 3rd Corpus Linguistics Conference,</booktitle>
<contexts>
<context position="2263" citStr="Belz, 2005" startWordPosition="314" endWordPosition="315">igh quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurement</context>
</contexts>
<marker>Belz, 2005</marker>
<rawString>A. Belz. Corpus-driven generation of weather forecasts. In Proceedings of the 3rd Corpus Linguistics Conference, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>T Bickmore</author>
</authors>
<title>Negotiated collusion: Modeling social language and its relationship effects in intelligent agents. User Modeling and User-Adapted Interaction,</title>
<date>2003</date>
<location>13:89–132,</location>
<contexts>
<context position="33215" citStr="Cassell and Bickmore, 2003" startWordPosition="5115" endWordPosition="5118">rned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality generation method, in which a data-driven personality model selects the b</context>
</contexts>
<marker>Cassell, Bickmore, 2003</marker>
<rawString>J. Cassell and T. Bickmore. Negotiated collusion: Modeling social language and its relationship effects in intelligent agents. User Modeling and User-Adapted Interaction, 13:89–132, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>J Allen</author>
</authors>
<title>Stochastic language generation in a dialogue system: Toward a domain independent generator.</title>
<date>2004</date>
<booktitle>In Proceedings 5th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<contexts>
<context position="2251" citStr="Chambers and Allen, 2004" startWordPosition="310" endWordPosition="313">ion (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor</context>
</contexts>
<marker>Chambers, Allen, 2004</marker>
<rawString>N. Chambers and J. Allen. Stochastic language generation in a dialogue system: Toward a domain independent generator. In Proceedings 5th SIGdial Workshop on Discourse and Dialogue, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Gosling</author>
<author>P J Rentfrow</author>
<author>W B Swann</author>
</authors>
<title>A very brief measure of the big five personality domains.</title>
<date>2003</date>
<journal>Journal of Research in Personality,</journal>
<volume>37</volume>
<contexts>
<context position="13889" citStr="Gosling et al., 2003" startWordPosition="2045" endWordPosition="2048">egory. Parameters are detailed in previous work (Mairesse and Walker, 2007). NALIZATION parameters. 2.2 Random Sample Generation and Expert Judgments We generate a sample of 160 random utterances by varying the parameters in Table 2 with a uniform distribution. This sample is intended to provide enough training material for estimating all 67 parameters for each personality dimension. Following Mairesse and Walker (2007), two expert judges (not the authors) familiar with the Big Five adjectives (Table 1) evaluate the personality of each utterance using the Ten-Item Personality Inventory (TIPI; Gosling et al., 2003), and also judge the utterance’s naturalness. Thus 11 judgments were made for each utterance for a total of 1760 judgments. The TIPI outputs a rating on a scale from 1 (low) to 7 (high) for each Big Five trait. The expert judgments are approximately nor167 mally distributed; Figure 1 shows the distribution for agreeableness. 2.3 Statistical Model Training Training data is created for each generation parameter—i.e. the output variable—to train statistical models predicting the optimal parameter value from the target personality scores. The models are thus based on the simplifying assumption tha</context>
<context position="25174" citStr="Gosling et al., 2003" startWordPosition="3862" endWordPosition="3865">eech acts. Each utterance targets an extreme value for two traits (either 1 or 7 out of 7) and neutral values for the remaining three traits (4 out of 7). The goal is for each utterance to project multiple traits on a continuous scale. To generate a range of alternatives, a Gaussian noise with a standard deviation of 10% of the full scale is added to each target value. Subjects were 24 native English speakers (12 male and 12 female graduate students from a range of disciplines from both the U.K. and the U.S.). Subjects evaluate the naturalness and personality of each utterance using the TIPI (Gosling et al., 2003). To limit the experiment’s duration, only the two traits with extreme target values are evaluated for each utterance. Subjects thus answered 5 questions for 50 utterances, two from the TIPI for each extreme trait and one about naturalness (250 judgments in total per subject). Subjects were not told that the utterances were intended to manifest extreme trait values. Table 5 shows several sample outputs and the mean personality ratings from the human judges. For example, utterance 1.a projects a high extraversion through the insertion of an exclamation mark based on the model in Figure 2, where</context>
</contexts>
<marker>Gosling, Rentfrow, Swann, 2003</marker>
<rawString>S. D. Gosling, P. J. Rentfrow, and W. B. Swann. A very brief measure of the big five personality domains. Journal of Research in Personality, 37:504–528, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum Associates,</title>
<date>1988</date>
<contexts>
<context position="33125" citStr="Hovy, 1988" startWordPosition="5101" endWordPosition="5102">(3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propo</context>
</contexts>
<marker>Hovy, 1988</marker>
<rawString>E. Hovy. Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum Associates, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Isard</author>
<author>C Brockmann</author>
<author>J Oberlander</author>
</authors>
<title>Individuality and alignment in generated dialogues.</title>
<date>2006</date>
<booktitle>In Proceedings of the 4th International Natural Language Generation Conference (INLG),</booktitle>
<pages>22--29</pages>
<contexts>
<context position="2284" citStr="Isard et al., 2006" startWordPosition="316" endWordPosition="319">paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements. The generator was </context>
<context position="32979" citStr="Isard et al., 2006" startWordPosition="5077" endWordPosition="5081">able 9: Average naturalness ratings for utterances generated using (1) PERSONAGE, the rule-based generator, (2) the random utterances (expert judges) and (3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by i</context>
</contexts>
<marker>Isard, Brockmann, Oberlander, 2006</marker>
<rawString>A. Isard, C. Brockmann, and J. Oberlander. Individuality and alignment in generated dialogues. In Proceedings of the 4th International Natural Language Generation Conference (INLG), pages 22–29, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
<author>K Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>704--710</pages>
<contexts>
<context position="1568" citStr="Langkilde and Knight (1998)" startWordPosition="207" endWordPosition="210"> recognisable variation along a meaningful stylistic dimension— personality—without the computational cost incurred by overgeneration techniques. We present the first evaluation of a data-driven generation method that projects multiple personality traits simultaneously and on a continuous scale. We compare our performance to a rule-based generator in the same domain. 1 Introduction Over the last 20 years, statistical language models (SLMs) have been used successfully in many tasks in natural language processing, and the data available for modeling has steadily grown (Lapata and Keller, 2005). Langkilde and Knight (1998) first applied SLMs to statistical natural language generation (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match m</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>I. Langkilde and K. Knight. Generation that exploits corpus-based statistical knowledge. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL), pages 704–710, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st International Conference on Natural Language Generation,</booktitle>
<contexts>
<context position="2197" citStr="Langkilde-Geary, 2002" startWordPosition="304" endWordPosition="305">pplied SLMs to statistical natural language generation (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which genera</context>
</contexts>
<marker>Langkilde-Geary, 2002</marker>
<rawString>I. Langkilde-Geary. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proceedings of the 1st International Conference on Natural Language Generation, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
<author>F Keller</author>
</authors>
<title>Web-based models for natural language processing.</title>
<date>2005</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>2</volume>
<contexts>
<context position="1539" citStr="Lapata and Keller, 2005" startWordPosition="203" endWordPosition="206">atically learns to produce recognisable variation along a meaningful stylistic dimension— personality—without the computational cost incurred by overgeneration techniques. We present the first evaluation of a data-driven generation method that projects multiple personality traits simultaneously and on a continuous scale. We compare our performance to a rule-based generator in the same domain. 1 Introduction Over the last 20 years, statistical language models (SLMs) have been used successfully in many tasks in natural language processing, and the data available for modeling has steadily grown (Lapata and Keller, 2005). Langkilde and Knight (1998) first applied SLMs to statistical natural language generation (SNLG), showing that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus,</context>
</contexts>
<marker>Lapata, Keller, 2005</marker>
<rawString>M. Lapata and F. Keller. Web-based models for natural language processing. ACM Transactions on Speech and Language Processing, 2:1–31, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lester</author>
<author>S Converse</author>
<author>S Kahler</author>
<author>S Barlow</author>
<author>B Stone</author>
<author>R Bhogal</author>
</authors>
<title>The persona effect: affective impact of animated pedagogical agents.</title>
<date>1997</date>
<booktitle>Proceedings of the SIGCHI conference on Human factors in computing systems,</booktitle>
<pages>359--366</pages>
<contexts>
<context position="33167" citStr="Lester et al., 1997" startWordPosition="5107" endWordPosition="5110">sing the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality generation method, in whi</context>
</contexts>
<marker>Lester, Converse, Kahler, Barlow, Stone, Bhogal, 1997</marker>
<rawString>J. Lester, S. Converse, S. Kahler, S. Barlow, B. Stone, and R. Bhogal. The persona effect: affective impact of animated pedagogical agents. Proceedings of the SIGCHI conference on Human factors in computing systems, pages 359–366, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M A Walker</author>
</authors>
<title>PERSONAGE: Personality generation for dialogue.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>496--503</pages>
<contexts>
<context position="3721" citStr="Mairesse and Walker, 2007" startWordPosition="525" endWordPosition="528">effects simultaneously and over a continuous scale, controlling stylistic dimensions that are commonly understood and thus meaningful to users and application developers. Our intended applications are output utterances for intelligent training or intervention systems, video game characters, or virtual environment avatars. In previous work, we presented PERSONAGE, a psychologically-informed rule-based generator based on the Big Five personality model, and we showed that PERSONAGE can project extreme personality on the extraversion scale, i.e. both introverted and extraverted personality types (Mairesse and Walker, 2007). We used the Big Five model to develop PERSONAGE for several reasons. First, the Big Five has been shown in psychology to ex165 Proceedings of ACL-08: HLT, pages 165–173, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics Trait High Low Extraversion warm, assertive, sociable, excitement seeking, active, shy, quiet, reserved, passive, solitary, moody spontaneous, optimistic, talkative Emotional stability calm, even-tempered, reliable, peaceful, confident neurotic, anxious, depressed, self-conscious Agreeableness trustworthy, considerate, friendly, generous, helpfu</context>
<context position="5221" citStr="Mairesse and Walker, 2007" startWordPosition="728" endWordPosition="731">vative, ignorant, simple Table 1: Example adjectives associated with extreme values of the Big Five trait scales. 1.00 2.00 3.00 4.00 5.00 6.00 7.00 plain much of the variation in human perceptions of personality differences. Second, we believe that the adjectives used to develop the Big Five model provide an intuitive, meaningful definition of linguistic style. Table 1 shows some of the trait adjectives associated with the extremes of each Big Five trait. Third, there are many studies linking personality to linguistic variables (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). See (Mairesse and Walker, 2007) for more detail. In this paper, we further test the utility of basing stylistic variation on the Big Five personality model. The Big Five traits are represented by scalar values that range from 1 to 7, with values normally distributed among humans. While our previous work targeted extreme values of individual traits, here we show that we can target multiple personality traits simultaneously and over the continuous scales of the Big Five model. Section 2 describes a novel parameter-estimation method that automatically learns to produce recognisable variation for all Big Five traits, without ov</context>
<context position="7576" citStr="Mairesse and Walker, 2007" startWordPosition="1093" endWordPosition="1096">or each parameter via crossvalidation. 2.1 Base Generator We make minimal assumptions about the input to the generator to favor domain independence. The input is a speech act, a potential content pool that can be used to achieve that speech act, and five scalar personality parameters (1...7), specifying values for the continuous scalar dimensions of each trait in the Big Five model. See Table 1. This requires a base generator that generates multiple outputs expressing the same input content by varying linguistic parameters related to the Big Five traits. We start with the PERSONAGE generator (Mairesse and Walker, 2007), which generates recommendations and comparisons of restaurants. We extend PERSONAGE with new parameters for a total of 67 parameters in PERSONAGE-PE. See Table 2. These parameters are derived from psychological studies identifying linguistic markers of the Big Five traits (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). As PERSONAGE’s input parameters are domain-independent, most parameters range continuously between 0 and 1, while pragmatic marker insertion parameters are binary, except for the SUBJECT IMPLICITNESS, STUTTERING and PRONOMIFrequency 166 Parameters Description Conte</context>
<context position="13343" citStr="Mairesse and Walker, 2007" startWordPosition="1962" endWordPosition="1965"> LEXICAL FREQUENCY Control the average frequency of use of each content word, according to BNC frequency counts WORD LENGTH Control the average number of letters of each content word VERB STRENGTH Control the strength of the selected verbs, e.g. ‘I would suggest’ vs. ‘I would recommend’ Table 2: The 67 generation parameters whose target values are learned. Aggregation cue words, hedges, acknowledgments and filled pauses are learned individually (as separate parameters), e.g. kind of is modeled differently than somewhat in the SOFTENER HEDGES category. Parameters are detailed in previous work (Mairesse and Walker, 2007). NALIZATION parameters. 2.2 Random Sample Generation and Expert Judgments We generate a sample of 160 random utterances by varying the parameters in Table 2 with a uniform distribution. This sample is intended to provide enough training material for estimating all 67 parameters for each personality dimension. Following Mairesse and Walker (2007), two expert judges (not the authors) familiar with the Big Five adjectives (Table 1) evaluate the personality of each utterance using the Ten-Item Personality Inventory (TIPI; Gosling et al., 2003), and also judge the utterance’s naturalness. Thus 11 </context>
<context position="30430" citStr="Mairesse and Walker (2007)" startWordPosition="4690" endWordPosition="4693">raits as well, confirming that the Big Five theory models independent dimensions and thus provides a useful and meaningful framework for modeling variation in language. Additionally, although we do not directly evaluate the perception of midrange values of personality target scores, the results suggest that mid-range personality is modeled correctly because the neutral target scores do not affect the perception of extreme traits. 3.3 Comparison with Rule-Based Generation PERSONAGE is a rule-based personality generator based on handcrafted parameter settings derived from psychological studies. Mairesse and Walker (2007) show that this approach generates utterances that are perceptibly different along the extraversion dimension. Table 8 compares the mean ratings of the utterances generated by PERSONAGE-PE with ratings of 20 utterances generated by PERSONAGE for each extreme of each Big Five scale (40 for extraversion, resulting in 240 handcrafted utterances in total). Table 8 shows that the handcrafted parameter settings project a significantly more extreme personality for 6 traits out of 10. However, the learned parameter models for neuroticism, disagreeableness, unconscientiousness and openness to experienc</context>
<context position="32161" citStr="Mairesse and Walker (2007)" startWordPosition="4953" endWordPosition="4956">tailed) Table 8: Pair-wise comparison between the ratings of the utterances generated using PERSONAGE-PE with extreme target values (Learned Parameters), and the ratings for utterances generated with Mairesse and Walker’s rulebased PERSONAGE generator, (Rule-based). Ratings are averaged over all judges. 3.4 Naturalness Evaluation The naive judges also evaluated the naturalness of the outputs of our trained models. Table 9 shows that the average naturalness is 3.98 out of 7, which is significantly lower (p &lt; .05) than the naturalness of handcrafted and randomly generated utterances reported by Mairesse and Walker (2007). It is possible that the differences arise from judgments of utterances targeting multiple traits, or that the naive 171 judges are more critical. Trait Rule-based Random Learned All 4.59 4.38 3.98 Table 9: Average naturalness ratings for utterances generated using (1) PERSONAGE, the rule-based generator, (2) the random utterances (expert judges) and (3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguis</context>
<context position="33714" citStr="Mairesse and Walker (2007)" startWordPosition="5197" endWordPosition="5200">number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality generation method, in which a data-driven personality model selects the best utterance from a large candidate set. Isard et al.’s technique has not been evaluated, while Mairesse and Walker’s overgenerate and score approach is inefficient. Paiva and Evans’ technique does not overgenerate (2005), but it requires a search for the optimal generation decisions according to the learned models. Our approach does not require any search or overgeneration, as parameter estimation models predict the generation decisions directly from the target variation dimensions. This tech</context>
<context position="35853" citStr="Mairesse and Walker, 2007" startWordPosition="5527" endWordPosition="5530">re is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform only slightly worse than a handcrafted rule-based generator in the same domain. These findings are promising as (1) parameter estimation models are able to target any combination of traits over the full range of the Big Five scales; (2) they do not benefit from psychological knowledge, i.e. they are trained on randomly generated utterances. This work also has several limitations that should be addressed in future work. Even though the parameters of PERSONAGE-PE were suggested by psychological studies (Mairesse and Walker, 2007), some of them are not modeled successfully by our approach, and thus omitted from Tables 3 and 4. This could be due to the relatively small development dataset size (160 utterances to optimize 67 parameters), or to the implementation of some parameters. The strong parameter-independence assumption could also be responsible, but we are not aware of any state of the art implementation for learning multiple dependent variables, and this approach could further aggravate data sparsity issues. In addition, it is unclear why PERSONAGE performs better for projecting extreme personality and produces m</context>
</contexts>
<marker>Mairesse, Walker, 2007</marker>
<rawString>F. Mairesse and M. A. Walker. PERSONAGE: Personality generation for dialogue. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), pages 496–503, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M A Walker</author>
<author>M R Mehl</author>
<author>R K Moore</author>
</authors>
<title>Using linguistic cues for the automatic recognition of personality in conversation and text.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<volume>30</volume>
<contexts>
<context position="34797" citStr="Mairesse et al., 2007" startWordPosition="5363" endWordPosition="5366">or overgeneration, as parameter estimation models predict the generation decisions directly from the target variation dimensions. This technique is therefore beneficial for real-time generation. Moreover the variation dimensions of Paiva and Evans’ data-driven technique are extracted from a corpus: there is thus no guarantee that they can be easily interpreted by humans, and that they generalise to other corpora. Previous work has shown that modeling the relation between personality and language is far from trivial (Pennebaker and King, 1999; Argamon et al., 2005; Oberlander and Nowson, 2006; Mairesse et al., 2007), suggesting that the control of personality is a harder problem than the control of data-driven variation dimensions. We present the first human perceptual evaluation of a data-driven stylistic variation method. In terms of our research questions in Section 3.1, we show that models trained on expert judges to project multiple traits in a single utterance generate utterances whose personality is recognized by naive judges. There is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform only slightly worse than a handcrafted rule-based generator in the same domai</context>
</contexts>
<marker>Mairesse, Walker, Mehl, Moore, 2007</marker>
<rawString>F. Mairesse, M. A. Walker, M. R. Mehl, and R. K. Moore. Using linguistic cues for the automatic recognition of personality in conversation and text. Journal of Artificial Intelligence Research (JAIR), 30:457–500, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Mehl</author>
<author>S D Gosling</author>
<author>J W Pennebaker</author>
</authors>
<title>Personality in its natural habitat: Manifestations and implicit folk theories of personality in daily life.</title>
<date>2006</date>
<journal>Journal of Personality and Social Psychology,</journal>
<volume>90</volume>
<contexts>
<context position="5175" citStr="Mehl et al., 2006" startWordPosition="721" endWordPosition="724">ltured, complex narrow-minded, conservative, ignorant, simple Table 1: Example adjectives associated with extreme values of the Big Five trait scales. 1.00 2.00 3.00 4.00 5.00 6.00 7.00 plain much of the variation in human perceptions of personality differences. Second, we believe that the adjectives used to develop the Big Five model provide an intuitive, meaningful definition of linguistic style. Table 1 shows some of the trait adjectives associated with the extremes of each Big Five trait. Third, there are many studies linking personality to linguistic variables (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). See (Mairesse and Walker, 2007) for more detail. In this paper, we further test the utility of basing stylistic variation on the Big Five personality model. The Big Five traits are represented by scalar values that range from 1 to 7, with values normally distributed among humans. While our previous work targeted extreme values of individual traits, here we show that we can target multiple personality traits simultaneously and over the continuous scales of the Big Five model. Section 2 describes a novel parameter-estimation method that automatically learns to produce recognisable</context>
<context position="7896" citStr="Mehl et al., 2006" startWordPosition="1142" endWordPosition="1145">s scalar dimensions of each trait in the Big Five model. See Table 1. This requires a base generator that generates multiple outputs expressing the same input content by varying linguistic parameters related to the Big Five traits. We start with the PERSONAGE generator (Mairesse and Walker, 2007), which generates recommendations and comparisons of restaurants. We extend PERSONAGE with new parameters for a total of 67 parameters in PERSONAGE-PE. See Table 2. These parameters are derived from psychological studies identifying linguistic markers of the Big Five traits (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). As PERSONAGE’s input parameters are domain-independent, most parameters range continuously between 0 and 1, while pragmatic marker insertion parameters are binary, except for the SUBJECT IMPLICITNESS, STUTTERING and PRONOMIFrequency 166 Parameters Description Content parameters: VERBOSITY Control the number of propositions in the utterance RESTATEMENTS Paraphrase an existing proposition, e.g. ‘Chanpen Thai has great service, it has fantastic waiters’ REPETITIONS Repeat an existing proposition CONTENT POLARITY Control the polarity of the propositions expressed, i.e. referring to </context>
<context position="27476" citStr="Mehl et al., 2006" startWordPosition="4218" endWordPosition="4221">tings also correlate strongly with the target scores, with correlations of .39, .36 and .17 respectively (p &lt; .01). Additionally, Table 6 shows that the magnitude of the correlation increases when considering the perception of a hypothetical average subject, i.e. smoothing individual variation by averaging the ratings over all 24 judges, producing a correlation ra,,g up to .80 for extraversion. These correlations are unexpectedly high; in corpus analyses, significant correlations as low as .05 to .10 are typically observed between personality and linguistic markers (Pennebaker and King, 1999; Mehl et al., 2006). Conscientiousness is the only dimension whose ratings do not correlate with the target scores. The 170 comparison with rule-based results in Section 3.3 suggests that this is not because conscientiousness cannot be exhibited in our domain or manifested in a single utterance, so perhaps this arises from differing perceptions of conscientiousness between the expert and naive judges. Trait r rang e Extraversion .45 • .80 • 1.89 Emotional stability .39 • .64 • 2.14 Agreeableness .36 • .68 • 2.38 Conscientiousness -.01 -.02 2.79 Openness to experience .17 • .41 • 2.51 • statistically significant </context>
</contexts>
<marker>Mehl, Gosling, Pennebaker, 2006</marker>
<rawString>M. R. Mehl, S. D. Gosling, and J. W. Pennebaker. Personality in its natural habitat: Manifestations and implicit folk theories of personality in daily life. Journal of Personality and Social Psychology, 90:862–877, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nakatsu</author>
<author>M White</author>
</authors>
<title>Learning to say it well: Reranking realizations by predicted synthesis quality.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1113--1120</pages>
<contexts>
<context position="2476" citStr="Nakatsu and White, 2006" startWordPosition="343" endWordPosition="346">an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements. The generator was shown to reproduce intended factor levels across several factors, thus modelling the stylistic variation as measured in the original corpus. Our goal is a generation technique that can target </context>
</contexts>
<marker>Nakatsu, White, 2006</marker>
<rawString>C. Nakatsu and M. White. Learning to say it well: Reranking realizations by predicted synthesis quality. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1113–1120, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Oberlander</author>
<author>S Nowson</author>
</authors>
<title>Whose thumb is it anyway? classifying author personality from weblog text.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="34773" citStr="Oberlander and Nowson, 2006" startWordPosition="5358" endWordPosition="5362"> does not require any search or overgeneration, as parameter estimation models predict the generation decisions directly from the target variation dimensions. This technique is therefore beneficial for real-time generation. Moreover the variation dimensions of Paiva and Evans’ data-driven technique are extracted from a corpus: there is thus no guarantee that they can be easily interpreted by humans, and that they generalise to other corpora. Previous work has shown that modeling the relation between personality and language is far from trivial (Pennebaker and King, 1999; Argamon et al., 2005; Oberlander and Nowson, 2006; Mairesse et al., 2007), suggesting that the control of personality is a harder problem than the control of data-driven variation dimensions. We present the first human perceptual evaluation of a data-driven stylistic variation method. In terms of our research questions in Section 3.1, we show that models trained on expert judges to project multiple traits in a single utterance generate utterances whose personality is recognized by naive judges. There is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform only slightly worse than a handcrafted rule-based gen</context>
</contexts>
<marker>Oberlander, Nowson, 2006</marker>
<rawString>J. Oberlander and S. Nowson. Whose thumb is it anyway? classifying author personality from weblog text. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Paiva</author>
<author>R Evans</author>
</authors>
<title>Empirically-based control of natural language generation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>58--65</pages>
<contexts>
<context position="2696" citStr="Paiva and Evans, 2005" startWordPosition="378" endWordPosition="381"> phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements. The generator was shown to reproduce intended factor levels across several factors, thus modelling the stylistic variation as measured in the original corpus. Our goal is a generation technique that can target multiple stylistic effects simultaneously and over a continuous scale, controlling stylistic dimensions that are commonly understood and thus meaningful to users and application developers. Our intended applications are </context>
<context position="32938" citStr="Paiva and Evans, 2005" startWordPosition="5069" endWordPosition="5072">le-based Random Learned All 4.59 4.38 3.98 Table 9: Average naturalness ratings for utterances generated using (1) PERSONAGE, the rule-based generator, (2) the random utterances (expert judges) and (3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project</context>
</contexts>
<marker>Paiva, Evans, 2005</marker>
<rawString>D. S. Paiva and R. Evans. Empirically-based control of natural language generation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 58–65, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Pennebaker</author>
<author>L A King</author>
</authors>
<title>Linguistic styles: Language use as an individual difference.</title>
<date>1999</date>
<journal>Journal of Personality and Social Psychology,</journal>
<volume>77</volume>
<contexts>
<context position="5156" citStr="Pennebaker and King, 1999" startWordPosition="717" endWordPosition="720">, intellectual, curious, cultured, complex narrow-minded, conservative, ignorant, simple Table 1: Example adjectives associated with extreme values of the Big Five trait scales. 1.00 2.00 3.00 4.00 5.00 6.00 7.00 plain much of the variation in human perceptions of personality differences. Second, we believe that the adjectives used to develop the Big Five model provide an intuitive, meaningful definition of linguistic style. Table 1 shows some of the trait adjectives associated with the extremes of each Big Five trait. Third, there are many studies linking personality to linguistic variables (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). See (Mairesse and Walker, 2007) for more detail. In this paper, we further test the utility of basing stylistic variation on the Big Five personality model. The Big Five traits are represented by scalar values that range from 1 to 7, with values normally distributed among humans. While our previous work targeted extreme values of individual traits, here we show that we can target multiple personality traits simultaneously and over the continuous scales of the Big Five model. Section 2 describes a novel parameter-estimation method that automatically learns to p</context>
<context position="7877" citStr="Pennebaker and King, 1999" startWordPosition="1138" endWordPosition="1141">ng values for the continuous scalar dimensions of each trait in the Big Five model. See Table 1. This requires a base generator that generates multiple outputs expressing the same input content by varying linguistic parameters related to the Big Five traits. We start with the PERSONAGE generator (Mairesse and Walker, 2007), which generates recommendations and comparisons of restaurants. We extend PERSONAGE with new parameters for a total of 67 parameters in PERSONAGE-PE. See Table 2. These parameters are derived from psychological studies identifying linguistic markers of the Big Five traits (Pennebaker and King, 1999; Mehl et al., 2006, inter alia). As PERSONAGE’s input parameters are domain-independent, most parameters range continuously between 0 and 1, while pragmatic marker insertion parameters are binary, except for the SUBJECT IMPLICITNESS, STUTTERING and PRONOMIFrequency 166 Parameters Description Content parameters: VERBOSITY Control the number of propositions in the utterance RESTATEMENTS Paraphrase an existing proposition, e.g. ‘Chanpen Thai has great service, it has fantastic waiters’ REPETITIONS Repeat an existing proposition CONTENT POLARITY Control the polarity of the propositions expressed,</context>
<context position="27456" citStr="Pennebaker and King, 1999" startWordPosition="4214" endWordPosition="4217">d openness to experience ratings also correlate strongly with the target scores, with correlations of .39, .36 and .17 respectively (p &lt; .01). Additionally, Table 6 shows that the magnitude of the correlation increases when considering the perception of a hypothetical average subject, i.e. smoothing individual variation by averaging the ratings over all 24 judges, producing a correlation ra,,g up to .80 for extraversion. These correlations are unexpectedly high; in corpus analyses, significant correlations as low as .05 to .10 are typically observed between personality and linguistic markers (Pennebaker and King, 1999; Mehl et al., 2006). Conscientiousness is the only dimension whose ratings do not correlate with the target scores. The 170 comparison with rule-based results in Section 3.3 suggests that this is not because conscientiousness cannot be exhibited in our domain or manifested in a single utterance, so perhaps this arises from differing perceptions of conscientiousness between the expert and naive judges. Trait r rang e Extraversion .45 • .80 • 1.89 Emotional stability .39 • .64 • 2.14 Agreeableness .36 • .68 • 2.38 Conscientiousness -.01 -.02 2.79 Openness to experience .17 • .41 • 2.51 • statis</context>
<context position="34722" citStr="Pennebaker and King, 1999" startWordPosition="5350" endWordPosition="5353">ons according to the learned models. Our approach does not require any search or overgeneration, as parameter estimation models predict the generation decisions directly from the target variation dimensions. This technique is therefore beneficial for real-time generation. Moreover the variation dimensions of Paiva and Evans’ data-driven technique are extracted from a corpus: there is thus no guarantee that they can be easily interpreted by humans, and that they generalise to other corpora. Previous work has shown that modeling the relation between personality and language is far from trivial (Pennebaker and King, 1999; Argamon et al., 2005; Oberlander and Nowson, 2006; Mairesse et al., 2007), suggesting that the control of personality is a harder problem than the control of data-driven variation dimensions. We present the first human perceptual evaluation of a data-driven stylistic variation method. In terms of our research questions in Section 3.1, we show that models trained on expert judges to project multiple traits in a single utterance generate utterances whose personality is recognized by naive judges. There is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform on</context>
</contexts>
<marker>Pennebaker, King, 1999</marker>
<rawString>J. W. Pennebaker and L. A. King. Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychology, 77:1296–1312, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Piwek</author>
</authors>
<title>A flexible pragmatics-driven language generator for animated agents.</title>
<date>2003</date>
<booktitle>In Proceedings of Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<contexts>
<context position="33228" citStr="Piwek, 2003" startWordPosition="5119" endWordPosition="5121">ns differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality generation method, in which a data-driven personality model selects the best utterance</context>
</contexts>
<marker>Piwek, 2003</marker>
<rawString>P. Piwek. A flexible pragmatics-driven language generator for animated agents. In Proceedings of Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL), 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Power</author>
<author>D Scott</author>
<author>N Bouayad-Agha</author>
</authors>
<title>Generating texts with style.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<contexts>
<context position="33187" citStr="Power et al., 2003" startWordPosition="5111" endWordPosition="5114">timation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality generation method, in which a data-driven per</context>
</contexts>
<marker>Power, Scott, Bouayad-Agha, 2003</marker>
<rawString>R. Power, D. Scott, and N. Bouayad-Agha. Generating texts with style. In Proceedings of the 4th International Conference on Intelligent Text Processing and Computational Linguistics, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Rambow</author>
<author>M Rogati</author>
<author>M A Walker</author>
</authors>
<title>Evaluating a trainable sentence planner for a spoken dialogue travel system.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="2451" citStr="Rambow et al., 2001" startWordPosition="339" endWordPosition="342">s are then ranked by an SLM scoring phase. Since then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements. The generator was shown to reproduce intended factor levels across several factors, thus modelling the stylistic variation as measured in the original corpus. Our goal is a generation t</context>
<context position="32959" citStr="Rambow et al., 2001" startWordPosition="5073" endWordPosition="5076"> All 4.59 4.38 3.98 Table 9: Average naturalness ratings for utterances generated using (1) PERSONAGE, the rule-based generator, (2) the random utterances (expert judges) and (3) the outputs of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions </context>
<context position="35299" citStr="Rambow et al., 2001" startWordPosition="5442" endWordPosition="5445">far from trivial (Pennebaker and King, 1999; Argamon et al., 2005; Oberlander and Nowson, 2006; Mairesse et al., 2007), suggesting that the control of personality is a harder problem than the control of data-driven variation dimensions. We present the first human perceptual evaluation of a data-driven stylistic variation method. In terms of our research questions in Section 3.1, we show that models trained on expert judges to project multiple traits in a single utterance generate utterances whose personality is recognized by naive judges. There is only one other similar evaluation of an SNLG (Rambow et al., 2001). Our models perform only slightly worse than a handcrafted rule-based generator in the same domain. These findings are promising as (1) parameter estimation models are able to target any combination of traits over the full range of the Big Five scales; (2) they do not benefit from psychological knowledge, i.e. they are trained on randomly generated utterances. This work also has several limitations that should be addressed in future work. Even though the parameters of PERSONAGE-PE were suggested by psychological studies (Mairesse and Walker, 2007), some of them are not modeled successfully by</context>
</contexts>
<marker>Rambow, Rogati, Walker, 2001</marker>
<rawString>O. Rambow, M. Rogati, and M. A. Walker. Evaluating a trainable sentence planner for a spoken dialogue travel system. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), 2001.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Rehm</author>
<author>E Andr´e</author>
</authors>
<title>From annotated multimodal corpora to simulated human-like behaviors.</title>
<booktitle>Modeling Communication with Robots and Virtual Humans.</booktitle>
<editor>In I. Wachsmuth and G. Knoblich, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg,</location>
<note>in press.</note>
<marker>Rehm, Andr´e, </marker>
<rawString>M. Rehm and E. Andr´e. From annotated multimodal corpora to simulated human-like behaviors. In I. Wachsmuth and G. Knoblich, editors, Modeling Communication with Robots and Virtual Humans. Springer, Berlin, Heidelberg, in press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
<author>H Guo</author>
</authors>
<title>A new data-driven approach for multimedia presentation generation.</title>
<date>2005</date>
<booktitle>In Proc. EuroIMSA,</booktitle>
<contexts>
<context position="2498" citStr="Stent and Guo, 2005" startWordPosition="347" endWordPosition="350">ce then, research in SNLG has explored a range of models for both dialogue and text generation. One line of work has primarily focused on grammaticality and naturalness, scoring the overgeneration phase with a SLM, and evaluating against a gold-standard corpus, using string or tree-match metrics (Langkilde-Geary, 2002; Bangalore and Rambow, 2000; Chambers and Allen, 2004; Belz, 2005; Isard et al., 2006). Another thread investigates SNLG scoring models trained using higher-level linguistic features to replicate human judgments of utterance quality (Rambow et al., 2001; Nakatsu and White, 2006; Stent and Guo, 2005). The error of these scoring models approaches the gold-standard human ranking with a relatively small training set. A third SNLG approach eliminates the overgeneration phase (Paiva and Evans, 2005). It applies factor analysis to a corpus exhibiting stylistic variation, and then learns which generation parameters to manipulate to correlate with factor measurements. The generator was shown to reproduce intended factor levels across several factors, thus modelling the stylistic variation as measured in the original corpus. Our goal is a generation technique that can target multiple stylistic eff</context>
</contexts>
<marker>Stent, Guo, 2005</marker>
<rawString>A. Stent and H. Guo. A new data-driven approach for multimedia presentation generation. In Proc. EuroIMSA, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>J E Cahn</author>
<author>S J Whittaker</author>
</authors>
<title>Improvising linguistic style: Social and affective bases for agent personality.</title>
<date>1997</date>
<booktitle>In Proceedings of the 1st Conference on Autonomous Agents,</booktitle>
<pages>96--105</pages>
<contexts>
<context position="33146" citStr="Walker et al., 1997" startWordPosition="5103" endWordPosition="5106">uts of PERSONAGE-PE using the parameter estimation models (Learned, naive judges). The means differ significantly at the p &lt; .05 level (two-tailed independent sample t-test). 4 Conclusion We present a new method for generating linguistic variation projecting multiple personality traits continuously, by combining and extending previous research in statistical natural language generation (Paiva and Evans, 2005; Rambow et al., 2001; Isard et al., 2006; Mairesse and Walker, 2007). While handcrafted rule-based approaches are limited to variation along a small number of discrete points (Hovy, 1988; Walker et al., 1997; Lester et al., 1997; Power et al., 2003; Cassell and Bickmore, 2003; Piwek, 2003; Mairesse and Walker, 2007; Rehm and Andr´e, in press), we learn models that predict parameter values for any arbitrary value on the variation dimension scales. Additionally, our data-driven approach can be applied to any dimension that is meaningful to human judges, and it provides an elegant way to project multiple dimensions simultaneously, by including the relevant dimensions as features of the parameter models’ training data. Isard et al. (2006) and Mairesse and Walker (2007) also propose a personality gene</context>
</contexts>
<marker>Walker, Cahn, Whittaker, 1997</marker>
<rawString>M. A. Walker, J. E. Cahn, and S. J. Whittaker. Improvising linguistic style: Social and affective bases for agent personality. In Proceedings of the 1st Conference on Autonomous Agents, pages 96–105, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA,</location>
<contexts>
<context position="15642" citStr="Witten and Frank, 2005" startWordPosition="2314" endWordPosition="2317">mber of concessions produced in the utterance. To ensure that the models’ output can control the generator, the generation decision values are normalized to match the input range (0...1) of PERSONAGE-PE. Thus the dataset consists of 160 utterances and the corresponding generation decisions, each associated with 5 personality ratings averaged over both judges. Parameter estimation models are trained to predict either continuous (e.g. VERBOSITY) or binary (e.g. EXCLAMATION) generation decisions. We compare various learning algorithms using the Weka toolkit (with default values unless specified; Witten and Frank, 2005). Continuous parameters are modeled with a linear regression model (LR), an M5’ model tree (M5), and a model based on support vector machines with a linear kernel (SVM). As regression models can extrapolate beyond the [0, 1] interval, the output parameter values are truncated if needed—at generation time—before being sent to the base generator. Binary parameters are modeled using classifiers that predict whether the parameter is enabled or disabled. We test a Naive Bayes classifier (NB), a j48 decision tree (J48), a nearest-neighbor classifier using one neighbor (NN), a Java implementation of </context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I. H. Witten and E. Frank. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann, San Francisco, CA, 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>