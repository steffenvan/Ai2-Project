<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001427">
<title confidence="0.993366">
Source-Language Entailment Modeling for Translating Unknown Terms
</title>
<author confidence="0.990038">
Shachar Mirkin§, Lucia Specia†, Nicola Cancedda†, Ido Dagan§, Marc Dymetman†, Idan Szpektor§
</author>
<affiliation confidence="0.9559195">
§ Computer Science Department, Bar-Ilan University
† Xerox Research Centre Europe
</affiliation>
<email confidence="0.9793135">
{mirkins,dagan,szpekti}@cs.biu.ac.il
{lucia.specia,nicola.cancedda,marc.dymetman}@xrce.xerox.com
</email>
<sectionHeader confidence="0.99736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905285714286">
This paper addresses the task of handling
unknown terms in SMT. We propose us-
ing source-language monolingual models
and resources to paraphrase the source text
prior to translation. We further present a
conceptual extension to prior work by al-
lowing translations of entailed texts rather
than paraphrases only. A method for
performing this process efficiently is pre-
sented and applied to some 2500 sentences
with unknown terms. Our experiments
show that the proposed approach substan-
tially increases the number of properly
translated texts.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999758238095238">
Machine Translation systems frequently encounter
terms they are not able to translate due to some
missing knowledge. For instance, a Statistical Ma-
chine Translation (SMT) system translating the
sentence “Cisco filed a lawsuit against Apple for
patent violation” may lack words like filed and
lawsuit in its phrase table. The problem is espe-
cially severe for languages for which parallel cor-
pora are scarce, or in the common scenario when
the SMT system is used to translate texts of a do-
main different from the one it was trained on.
A previously suggested solution (Callison-
Burch et al., 2006) is to learn paraphrases of
source terms from multilingual (parallel) corpora,
and expand the phrase table with these para-
phrases1. Such solutions could potentially yield a
paraphrased sentence like “Cisco sued Apple for
patent violation”, although their dependence on
bilingual resources limits their utility.
In this paper we propose an approach that con-
sists in directly replacing unknown source terms,
</bodyText>
<footnote confidence="0.826391">
1As common in the literature, we use the term para-
phrases to refer to texts of equivalent meaning, of any length
from single words (synonyms) up to complete sentences.
</footnote>
<bodyText confidence="0.999842146341463">
using source-language resources and models in or-
der to achieve two goals.
The first goal is coverage increase. The avail-
ability of bilingual corpora, from which para-
phrases can be learnt, is in many cases limited.
On the other hand, monolingual resources and
methods for extracting paraphrases from monolin-
gual corpora are more readily available. These
include manually constructed resources, such as
WordNet (Fellbaum, 1998), and automatic meth-
ods for paraphrases acquisition, such as DIRT (Lin
and Pantel, 2001). However, such resources have
not been applied yet to the problem of substitut-
ing unknown terms in SMT. We suggest that by
using such monolingual resources we could pro-
vide paraphrases for a larger number of texts with
unknown terms, thus increasing the overall cover-
age of the SMT system, i.e. the number of texts it
properly translates.
Even with larger paraphrase resources, we may
encounter texts in which not all unknown terms are
successfully handled through paraphrasing, which
often results in poor translations (see Section 2.1).
To further increase coverage, we therefore pro-
pose to generate and translate texts that convey a
somewhat more general meaning than the original
source text. For example, using such approach,
the following text could be generated: “Cisco ac-
cused Apple ofpatent violation”. Although less in-
formative than the original, a translation for such
texts may be useful. Such non-symmetric relation-
ships (as between filed a lawsuit and accused) are
difficult to learn from parallel corpora and there-
fore monolingual resources are more appropriate
for this purpose.
The second goal we wish to accomplish by
employing source-language resources is to rank
the alternative generated texts. This goal can be
achieved by using context-models on the source
language prior to translation. This has two advan-
tages. First, the ranking allows us to prune some
</bodyText>
<page confidence="0.967703">
791
</page>
<note confidence="0.9996115">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 791–799,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999787463414634">
candidates before supplying them to the transla-
tion engine, thus improving translation efficiency.
Second, the ranking may be combined with target
language information in order to choose the best
translation, thus improving translation quality.
We position the problem of generating alterna-
tive texts for translation within the Textual Entail-
ment (TE) framework (Giampiccolo et al., 2007).
TE provides a generic way for handling language
variability, identifying when the meaning of one
text is entailed by the other (i.e. the meaning of
the entailed text can be inferred from the mean-
ing of the entailing one). When the meanings of
two texts are equivalent (paraphrase), entailment
is mutual. Typically, a more general version of
a certain text is entailed by it. Hence, through TE
we can formalize the generation of both equivalent
and more general texts for the source text. When
possible, a paraphrase is used. Otherwise, an alter-
native text whose meaning is entailed by the orig-
inal source is generated and translated.
We assess our approach by applying an SMT
system to a text domain that is different from the
one used to train the system. We use WordNet
as a source language resource for entailment rela-
tionships and several common statistical context-
models for selecting the best generated texts to be
sent to translation. We show that the use of source
language resources, and in particular the extension
to non-symmetric textual entailment relationships,
is useful for substantially increasing the amount of
texts that are properly translated. This increase is
observed relative to both using paraphrases pro-
duced by the same resource (WordNet) and us-
ing paraphrases produced from multilingual paral-
lel corpora. We demonstrate that by using simple
context-models on the source, efficiency can be
improved, while translation quality is maintained.
We believe that with the use of more sophisticated
context-models further quality improvement can
be achieved.
</bodyText>
<sectionHeader confidence="0.998579" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.999356">
2.1 Unknown Terms
</subsectionHeader>
<bodyText confidence="0.999373826086956">
A very common problem faced by machine trans-
lation systems is the need to translate terms (words
or multi-word expressions) that are not found in
the system’s lexicon or phrase table. The reasons
for such unknown terms in SMT systems include
scarcity of training material and the application
of the system to text domains that differ from the
ones used for training.
In SMT, when unknown terms are found in the
source text, the systems usually omit or copy them
literally into the target. Though copying the source
words can be of some help to the reader if the
unknown word has a cognate in the target lan-
guage, this will not happen in the most general
scenario where, for instance, languages use dif-
ferent scripts. In addition, the presence of a sin-
gle unknown term often affects the translation of
wider portions of text, inducing errors in both lex-
ical selection and ordering. This phenomenon is
demonstrated in the following sentences, where
the translation of the English sentence (1) is ac-
ceptable only when the unknown word (in bold) is
replaced with a translatable paraphrase (3):
</bodyText>
<listItem confidence="0.9928205">
1. “... , despite bearing the heavy burden of the
unemployed 10% or more of the labor force.”
2. “... , malgr´e la lourde charge de compte le
10% ou plus de chˆomeurs labor la force .”
3. “... , malgr´e la lourde charge des chˆomeurs
de 10% ou plus de la force du travail.”
</listItem>
<bodyText confidence="0.999794210526316">
Several approaches have been proposed to deal
with unknown terms in SMT systems, rather than
omitting or copying the terms. For example, (Eck
et al., 2008) replace the unknown terms in the
source text by their definition in a monolingual
dictionary, which can be useful for gisting. To
translate across languages with different alpha-
bets approaches such as (Knight and Graehl, 1997;
Habash, 2008) use transliteration techniques to
tackle proper nouns and technical terms. For trans-
lation from highly inflected languages, certain ap-
proaches rely on some form of lexical approx-
imation or morphological analysis (Koehn and
Knight, 2003; Yang and Kirchhoff, 2006; Langlais
and Patry, 2007; Arora et al., 2008). Although
these strategies yield gain in coverage and transla-
tion quality, they only account for unknown terms
that should be transliterated or are variations of
known ones.
</bodyText>
<subsectionHeader confidence="0.999642">
2.2 Paraphrasing in MT
</subsectionHeader>
<bodyText confidence="0.999967">
A recent strategy to broadly deal with the prob-
lem of unknown terms is to paraphrase the source
text with terms whose translation is known to
the system, using paraphrases learnt from multi-
lingual corpora, typically involving at least one
“pivot” language different from the target lan-
guage of immediate interest (Callison-Burch et
</bodyText>
<page confidence="0.995311">
792
</page>
<bodyText confidence="0.997820592592593">
al., 2006; Cohn and Lapata, 2007; Zhao et al.,
2008; Callison-Burch, 2008; Guzm´an and Gar-
rido, 2008). The procedure to extract paraphrases
in these approaches is similar to standard phrase
extraction in SMT systems, and therefore a large
amount of additional parallel corpus is required.
Moreover, as discussed in Section 5, when un-
known texts are not from the same domain as the
SMT training corpus, it is likely that paraphrases
found through such methods will yield misleading
translations.
Bond et al. (2008) use grammars to paraphrase
the whole source sentence, covering aspects like
word order and minor lexical variations (tenses
etc.), but not content words. The paraphrases are
added to the source side of the corpus and the cor-
responding target sentences are duplicated. This,
however, may yield distorted probability estimates
in the phrase table, since these were not computed
from parallel data.
The main use of monolingual paraphrases in
MT to date has been for evaluation. For exam-
ple, (Kauchak and Barzilay, 2006) paraphrase ref-
erences to make them closer to the system transla-
tion in order to obtain more reliable results when
using automatic evaluation metrics like BLEU
(Papineni et al., 2002).
</bodyText>
<subsectionHeader confidence="0.999755">
2.3 Textual Entailment and Entailment Rules
</subsectionHeader>
<bodyText confidence="0.999918191489362">
Textual Entailment (TE) has recently become a
prominent paradigm for modeling semantic infer-
ence, capturing the needs of a broad range of
text understanding applications (Giampiccolo et
al., 2007). Yet, its application to SMT has been so
far limited to MT evaluation (Pado et al., 2009).
TE defines a directional relation between two
texts, where the meaning of the entailed text (hy-
pothesis, h) can be inferred from the meaning of
the entailing text, t. Under this paradigm, para-
phrases are a special case of the entailment rela-
tion, when the relation is symmetric (the texts en-
tail each other). Otherwise, we say that one text
directionally entails the other.
A common practice for proving (or generating)
h from t is to apply entailment rules to t. An
entailment rule, denoted LHS ==&gt;. RHS, specifies
an entailment relation between two text fragments
(the Left- and Right- Hand Sides), possibly with
variables (e.g. build X in Y ==&gt;. X is completed
in Y ). A paraphrasing rule is denoted with q.
When a rule is applied to a text, a new text is in-
ferred, where the matched LHS is replaced with the
RHS. For example, the rule skyscraper ==&gt;. building
is applied to “The world’s tallest skyscraper was
completed in Taiwan” to infer “The world’s tallest
building was completed in Taiwan”. In this work,
we employ lexical entailment rules, i.e. rules with-
out variables. Various resources for lexical rules
are available, and the prominent one is WordNet
(Fellbaum, 1998), which has been used in virtu-
ally all TE systems (Giampiccolo et al., 2007).
Typically, a rule application is valid only under
specific contexts. For example, mouse ==&gt;. rodent
should not be applied to “Use the mouse to mark
your answers”. Context-models can be exploited
to validate the application of a rule to a text. In
such models, an explicit Word Sense Disambigua-
tion (WSD) is not necessarily required; rather, an
implicit sense-match is sought after (Dagan et al.,
2006). Within the scope of our paper, rule ap-
plication is handled similarly to Lexical Substitu-
tion (McCarthy and Navigli, 2007), considering
the contextual relationship between the text and
the rule. However, in general, entailment rule ap-
plication addresses other aspects of context match-
ing as well (Szpektor et al., 2008).
</bodyText>
<sectionHeader confidence="0.7851105" genericHeader="method">
3 Textual Entailment for Statistical
Machine Translation
</sectionHeader>
<bodyText confidence="0.999945347826087">
Previous solutions for handling unknown terms in
a source text s augment the SMT system’s phrase
table based on multilingual corpora. This allows
indirectly paraphrasing s, when the SMT system
chooses to use a paraphrase included in the table
and produces a translation with the corresponding
target phrase for the unknown term.
We propose using monolingual paraphrasing
methods and resources for this task to obtain a
more extensive set of rules for paraphrasing the
source. These rules are then applied to s directly
to produce alternative versions of the source text
prior to the translation step. Moreover, further
coverage increase can be achieved by employing
directional entailment rules, when paraphrasing is
not possible, to generate more general texts for
translation.
Our approach, based on the textual entailment
framework, considers the newly generated texts as
entailed from the original one. Monolingual se-
mantic resources such as WordNet can provide en-
tailment rules required for both these symmetric
and asymmetric entailment relations.
</bodyText>
<page confidence="0.992634">
793
</page>
<bodyText confidence="0.7975295">
Input: A text t with one or more unknown terms;
a monolingual resource of entailment rules;
</bodyText>
<listItem confidence="0.8771705">
k - maximal number of source alternatives to produce
Output: A translation of either (in order of preference):
a paraphrase of t OR a text entailed by t OR t itself
1. For each unknown term - fetch entailment rules:
(a) Fetch rules for paraphrasing; disregard rules
whose RHS is not in the phrase table
(b) If the set of rules is empty: fetch directional en-
tailment rules; disregard rules whose RHS is not
in the phrase table
2. Apply a context-model to compute a score for each rule
application
3. Compute total source score for each entailed text as a
combination of individual rule scores
4. Generate and translate the top-k entailed texts
</listItem>
<figure confidence="0.7122125">
5. If k &gt; 1
(a) Apply target model to score the translation
(b) Compute final source-target score
6. Pick highest scoring translation
</figure>
<figureCaption confidence="0.9962555">
Figure 1: Scheme for handling unknown terms by using
monolingual resources through textual entailment
</figureCaption>
<bodyText confidence="0.999973104477612">
Through the process of applying entailment
rules to the source text, multiple alternatives of
entailed texts are generated. To rank the candi-
date texts we employ monolingual context-models
to provide scores for rule applications over the
source sentence. This can be used to (a) directly
select the text with the highest score, which can
then be translated, or (b) to select a subset of top
candidates to be translated, which will then be
ranked using the target language information as
well. This pruning reduces the load of the SMT
system, and allows for potential improvements in
translation quality by considering both source- and
target-language information.
The general scheme through which we achieve
these goals, which can be implemented using dif-
ferent context-models and scoring techniques, is
detailed in Figure 1. Details of our concrete im-
plementation are given in Section 4.
Preliminary analysis confirmed (as expected)
that readers prefer translations of paraphrases,
when available, over translations of directional en-
tailments. This consideration is therefore taken
into account in the proposed method.
The input is a text unit to be translated, such as a
sentence or paragraph, with one or more unknown
terms. For each unknown term we first fetch a
list of candidate rules for paraphrasing (e.g. syn-
onyms), where the unknown term is the LHS. For
example, if our unknown term is dodge, a possi-
ble candidate might be dodge &lt;---&gt; circumvent. We
inflect the RHS to keep the original morphologi-
cal information of the unknown term and filter out
rules where the inflected RHS does not appear in
the phrase table (step 1a in Figure 1).
When no applicable rules for paraphrasing are
available (1b), we fetch directional entailment
rules (e.g. hypernymy rules such as dodge =&gt;
avoid), and filter them in the same way as for para-
phrasing rules. To each set of rules for a given un-
known term we add the “identity-rule”, to allow
leaving the unknown term unchanged, the correct
choice in cases of proper names, for example.
Next, we apply a context-model to compute an
applicability score of each rule to the source text
(step 2). An entailed text’s total score is the com-
bination (e.g. product, see Section 4) of the scores
of the rules used to produce it (3). A set of the
top-k entailed texts is then generated and sent for
translation (4).
If more than one alternative is produced by the
source model (and k &gt; 1), a target model is ap-
plied on the selected set of translated texts (5a).
The combined source-target model score is a com-
bination of the scores of the source and target
models (5b). The final translation is selected to be
the one that yields the highest combined source-
target score (6). Note that setting k = 1 is equiva-
lent to using the source-language model alone.
Our algorithm validates the application of the
entailment rules at two stages – before and af-
ter translation, through context-models applied at
each end. As the experiments will show in Sec-
tion 4, a large number of possible combinations of
entailment rules is a common scenario, and there-
fore using the source context models to reduce this
number plays an important role.
</bodyText>
<sectionHeader confidence="0.998363" genericHeader="method">
4 Experimental Setting
</sectionHeader>
<bodyText confidence="0.999930727272727">
To assess our approach, we conducted a series of
experiments; in each experiment we applied the
scheme described in 3, changing only the mod-
els being used for scoring the generated and trans-
lated texts. The setting of these experiments is de-
scribed in what follows.
SMT data To produce sentences for our experi-
ments, we use Matrax (Simard et al., 2005), a stan-
dard phrase-based SMT system, with the excep-
tion that it allows gaps in phrases. We use approxi-
mately 1M sentence pairs from the English-French
</bodyText>
<page confidence="0.99113">
794
</page>
<bodyText confidence="0.999480657894737">
Europarl corpus for training, and then translate a
test set of 5,859 English sentences from the News
corpus into French. Both resources are taken
from the shared translation task in WMT-2008
(Callison-Burch et al., 2008). Hence, we compare
our method in a setting where the training and test
data are from different domains, a common sce-
nario in the practical use of MT systems.
Of the 5,859 translated sentences, 2,494 contain
unknown terms (considering only sequences with
alphabetic symbols), summing up to 4,255 occur-
rences of unknown terms. 39% of the 2,494 sen-
tences contain more than a single unknown term.
Entailment resource We use WordNet 3.0 as
a resource for entailment rules. Paraphrases are
generated using synonyms. Directionally entailed
texts are created using hypernyms, which typically
conform with entailment. We do not rely on sense
information in WordNet. Hence, any other seman-
tic resource for entailment rules can be utilized.
Each sentence is tagged using the OpenNLP
POS tagger2. Entailment rules are applied for un-
known terms tagged as nouns, verbs, adjectives
and adverbs. The use of relations from WordNet
results in 1,071 sentences with applicable rules
(with phrase table entries) for the unknown terms
when using synonyms, and 1,643 when using both
synonyms and hypernyms, accounting for 43%
and 66% of the test sentences, respectively.
The number of alternative sentences generated
for each source text varies from 1 to 960 when
paraphrasing rules were applied, and reaches very
large numbers, up to 89,700 at the “worst case”,
when all TE rules are employed, an average of 456
alternatives per sentence.
Scoring source texts We test our proposed
method using several context-models shown to
perform reasonably well in previous work:
</bodyText>
<listItem confidence="0.9941571">
• FREQ: The first model we use is a context-
independent baseline. A common useful
heuristic to pick an entailment rule is to se-
lect the candidate with the highest frequency
in the corpus (Mccarthy et al., 2004). In this
model, a rule’s score is the normalized num-
ber of occurrences of its RHS in the training
corpus, ignoring the context of the LHS.
• LSA: Latent Semantic Analysis (Deerwester
et al., 1990) is a well-known method for rep-
</listItem>
<footnote confidence="0.701739">
2http://opennlp.sourceforge.net
</footnote>
<bodyText confidence="0.989173714285714">
resenting the contextual usage of words based
on corpus statistics. We represented each
term by a normalized vector of the top 100
SVD dimensions, as described in (Gliozzo,
2005). This model measures the similarity
between the sentence words and the RHS in
the LSA space.
</bodyText>
<listItem confidence="0.95442075">
• NB: We implemented the unsupervised
Naive Bayes model described in (Glickman
et al., 2006) to estimate the probability that
the unknown term entails the RHS in the
given context. The estimation is based on
corpus co-occurrence statistics of the context
words with the RHS.
• LMS: This model generates the Language
</listItem>
<bodyText confidence="0.994339576923077">
Model probability of the RHS in the source.
We use 3-grams probabilities as produced by
the SRILM toolkit (Stolcke, 2002).
Finally, as a simple baseline, we generated a ran-
dom score for each rule application, RAND.
The score of each rule application by any of
the above models is normalized to the range (0,1].
To combine individual rule applications in a given
sentence, we use the product of their scores. The
monolingual data used for the models above is the
source side of the training parallel corpus.
Target-language scores On the target side we
used either a standard 3-gram language-model, de-
noted LMT, or the score assigned by the com-
plete SMT log-linear model, which includes the
language model as one of its components (SMT).
A pair of a source:target models comprises a
complete model for selecting the best translated
sentence, where the overall score is the product of
the scores of the two models.
We also applied several combinations of source
models, such as LSA combined with LMS, to take
advantage of their complementary strengths. Ad-
ditionally, we assessed our method with source-
only models, by setting the number of sentences to
be selected by the source model to one (k = 1).
</bodyText>
<sectionHeader confidence="0.999993" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.998424">
5.1 Manual Evaluation
</subsectionHeader>
<bodyText confidence="0.9999394">
To evaluate the translations produced using the
various source and target models and the different
rule-sets, we rely mostly on manual assessment,
since automatic MT evaluation metrics like BLEU
do not capture well the type of semantic variations
</bodyText>
<page confidence="0.9967">
795
</page>
<table confidence="0.998037222222222">
Model Precision (%) Coverage (%)
PARAPH. TE PARAPH. TE
1 –:SMT 75.8 73.1 32.5 48.1
2 NB:SMT 75.2 71.5 32.3 47.1
3 LSA:SMT 74.9 72.4 32.1 47.7
4 NB:– 74.7 71.1 32.1 46.8
5 LMS:LMT 73.8 70.2 31.7 46.3
6 FREQ:– 72.5 68.0 31.2 44.8
7 RAND 57.2 63.4 24.6 41.8
</table>
<tableCaption confidence="0.95658725">
Table 1: Translation acceptance when using only para-
phrases and when using all entailment rules. “:” indicates
which model is applied to the source (left side) and which to
the target language (right side).
</tableCaption>
<bodyText confidence="0.999943138888889">
generated in our experiments, particularly at the
sentence level.
In the manual evaluation, two native speakers
of the target language judged whether each trans-
lation preserves the meaning of its reference sen-
tence, marking it as acceptable or unacceptable.
From the sentences for which rules were applica-
ble, we randomly selected a sample of sentences
for each annotator, allowing for some overlap-
ping for agreement analysis. In total, the transla-
tions of 1,014 unique source sentences were man-
ually annotated, of which 453 were produced us-
ing only hypernyms (no paraphrases were appli-
cable). When a sentence was annotated by both
annotators, one annotation was picked randomly.
Inter-annotator agreement was measured by the
percentage of sentences the annotators agreed on,
as well as via the Kappa measure (Cohen, 1960).
For different models, the agreement rate varied
from 67% to 78% (72% overall), and the Kappa
value ranged from 0.34 to 0.55, which is compa-
rable to figures reported for other standard SMT
evaluation metrics (Callison-Burch et al., 2008).
Translation with TE For each model m, we
measured Precisionm, the percentage of accept-
able translations out of all sampled translations.
Precisionm was measured both when using only
paraphrases (PARAPH.) and when using all entail-
ment rules (TE). We also measured Coveragem,
the percentage of sentences with acceptable trans-
lations, Am, out of all sentences (2,494). As
our annotators evaluated only a sample of sen-
tences, Am is estimated as the model’s total num-
ber of sentences with applicable rules, Sm, mul-
tiplied by the model’s Precision (Sm was 1,071
for paraphrases and 1,643 for entailment rules):
</bodyText>
<equation confidence="0.517859">
Coveragem = S.-Precision.
</equation>
<page confidence="0.738686">
2,494 .
</page>
<tableCaption confidence="0.48663">
Table 1 presents the results of several source-
</tableCaption>
<bodyText confidence="0.999382901960784">
target combinations when using only paraphrases
and when also using directional entailment rules.
When all rules are used, a substantial improve-
ment in coverage is consistently obtained across
all models, reaching a relative increase of 50%
over paraphrases only, while just a slight decrease
in precision is observed (see Section 5.3 for some
error analysis). This confirms our hypothesis that
directional entailment rules can be very useful for
replacing unknown terms.
For the combination of source-target models,
the value of k is set depending on which rule-set
is used. Preliminary analysis showed that k = 5
is sufficient when only paraphrases are used and
k = 20 when directional entailment rules are also
considered.
We measured statistical significance between
different models for precision of the TE re-
sults according to the Wilcoxon signed ranks test
(Wilcoxon, 1945). Models 1-6 in Table 1 are sig-
nificantly better than the RAND baseline (p &lt;
0.03), and models 1-3 are significantly better than
model 6 (p &lt; 0.05). The difference between
–:SMT and NB:SMT or LSA:SMT is not statisti-
cally significant.
The results in Table 1 therefore suggest that
taking a source model into account preserves the
quality of translation. Furthermore, the quality is
maintained even when source models’ selections
are restricted to a rather small top-k ranks, at a
lower computational cost (for the models combin-
ing source and target, like NB:SMT or LSA:SMT).
This is particularly relevant for on-demand MT
systems, where time is an issue. For such systems,
using this source-language based pruning method-
ology will yield significant performance gains as
compared to target-only models.
We also evaluated the baseline strategy where
unknown terms are omitted from the translation,
resulting in 25% precision. Leaving unknown
words untranslated also yielded very poor transla-
tion quality in an analysis performed on a similar
dataset.
Comparison to related work We compared our
algorithm with an implementation of the algo-
rithm proposed by (Callison-Burch et al., 2006)
(see Section 2.2), henceforth CB, using the Span-
ish side of Europarl as the pivot language.
Out of the tested 2,494 sentences with unknown
terms, CB found paraphrases for 706 sentences
(28.3%), while with any of our models, including
</bodyText>
<page confidence="0.99529">
796
</page>
<table confidence="0.999577">
Model Precision (%) Coverage (%) Better (%)
NB:SMT (TE) 85.3 56.2 72.7
CB 85.3 24.2 12.7
</table>
<tableCaption confidence="0.999751">
Table 2: Comparison between our top model and the
</tableCaption>
<bodyText confidence="0.93213024137931">
method by Callison-Burch et al. (2006), showing the per-
centage of times translations were considered acceptable, the
model’s coverage and the percentage of times each model
scored better than the other (in the 14% remaining cases, both
models produced unacceptable translations).
NB:SMT, our algorithm found applicable entail-
ment rules for 1,643 sentences (66%).
The quality of the CB translations was manually
assessed for a sample of 150 sentences. Table 2
presents the precision and coverage on this sample
for both CB and NB:SMT, as well as the number
of times each model’s translation was preferred by
the annotators. While both models achieve equally
high precision scores on this sample, the NB:SMT
model’s translations were undoubtedly preferred
by the annotators, with a considerably higher cov-
erage.
With the CB method, given that many of the
phrases added to the phrase table are noisy, the
global quality of the sentences seem to have been
affected, explaining why the judges preferred the
NB:SMT translations. One reason for the lower
coverage of CB is the fact that paraphrases were
acquired from a corpus whose domain is differ-
ent from that of the test sentences. The entail-
ment rules in our models are not limited to para-
phrases and are derived from WordNet, which has
broader applicability. Hence, utilizing monolin-
gual resources has proven beneficial for the task.
</bodyText>
<subsectionHeader confidence="0.997087">
5.2 Automatic MT Evaluation
</subsectionHeader>
<bodyText confidence="0.9999305">
Although automatic MT evaluation metrics are
less appropriate for capturing the variations gen-
erated by our method, to ensure that there was no
degradation in the system-level scores according
to such metrics we also measured the models’ per-
formance using BLEU and METEOR (Agarwal
and Lavie, 2007). The version of METEOR we
used on the target language (French) considers the
stems of the words, instead of surface forms only,
but does not make use of WordNet synonyms.
We evaluated the performance of the top mod-
els of Table 1, as well as of a baseline SMT sys-
tem that left unknown terms untranslated, on the
sample of 1,014 manually annotated sentences. As
shown in Table 3, all models resulted in improve-
ment with respect to the original sentences (base-
</bodyText>
<table confidence="0.997399142857143">
Model BLEU (TE) METEOR (TE)
–:SMT 15.50 0.1325
NB:SMT 15.37 0.1316
LSA:SMT 15.51 0.1318
NB:– 15.37 0.1311
CB 15.33 0.1299
Baseline SMT 15.29 0.1294
</table>
<tableCaption confidence="0.99232325">
Table 3: Performance of the best models according to auto-
matic MT evaluation metrics at the corpus level. The baseline
refers to translation of the text without applying any entail-
ment rules.
</tableCaption>
<bodyText confidence="0.9961934">
line). The difference in METEOR scores is statis-
tically significant (p &lt; 0.05) for the three top mod-
els against the baseline. The generally low scores
may be attributed to the fact that training and test
sentences are from different domains.
</bodyText>
<subsectionHeader confidence="0.965458">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999944176470588">
The use of entailed texts produced using our ap-
proach clearly improves the quality of translations,
as compared to leaving unknown terms untrans-
lated or omitting them altogether. While it is clear
that textual entailment is useful for increasing cov-
erage in translation, further research is required to
identify the amount of information loss incurred
when non-symmetric entailment relations are be-
ing used, and thus to identify the cases where such
relations are detrimental to translation.
Consider, for example, the sentence: “Conven-
tional military models are geared to decapitate
something that, in this case, has no head.”. In this
sentence, the unknown term was replaced by kill,
which results in missing the point originally con-
veyed in the text. Accordingly, the produced trans-
lation does not preserve the meaning of the source,
and was considered unacceptable: “Les mod`eles
militaires visent a` faire quelque chose que, dans
ce cas, n’est pas responsable.”.
In other cases, the selected hypernyms were too
generic words, such as entity or attribute, which
also fail to preserve the sentence’s meaning. On
the other hand, when the unknown term was a
very specific word, hypernyms played an impor-
tant role. For example, “Bulgaria is the most
sought-after east European real estate target, with
its low-cost ski chalets and oceanfront homes”.
Here, chalets are replaced by houses or units (de-
pending on the model), providing a translation that
would be acceptable by most readers.
Other incorrect translations occurred when the
unknown term was part of a phrase, for exam-
ple, troughs replaced with depressions in peaks
</bodyText>
<page confidence="0.988928">
797
</page>
<bodyText confidence="0.999950043478261">
and troughs, a problem that also strongly affects
paraphrasing. In another case, movement was the
hypernym chosen to replace labor in labor move-
ment, yielding an awkward text for translation.
Many of the cases which involved ambiguity
were resolved by the applied context-models, and
can be further addressed, together with the above
mentioned problems, with better source-language
context models.
We suggest that other types of entailment rules
could be useful for the task beyond the straight-
forward generalization using hypernyms, which
was demonstrated in this work. This includes
other types of lexical entailment relations, such as
holonymy (e.g. Singapore ==&gt;. Southeast Asia) as
well as lexical syntactic rules (X cure Y ==&gt;. treat
Y with X). Even syntactic rules, such as clause re-
moval, can be recruited for the task: “Obama, the
44th president, declared Monday... ” ==&gt;. “Obama
declared Monday ... ”. When the system is un-
able to translate a term found in the embedded
clause, the translation of the less informative sen-
tence may still be acceptable by readers.
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999773571428572">
In this paper we propose a new entailment-based
approach for addressing the problem of unknown
terms in machine translation. Applying this ap-
proach with lexical entailment rules from Word-
Net, we show that using monolingual resources
and textual entailment relationships allows sub-
stantially increasing the quality of translations
produced by an SMT system. Our experiments
also show that it is possible to perform the process
efficiently by relying on source language context-
models as a filter prior to translation. This pipeline
maintains translation quality, as assessed by both
human annotators and standard automatic mea-
sures.
For future work we suggest generating entailed
texts with a more extensive set of rules, in particu-
lar lexical-syntactic ones. Combining rules from
monolingual and bilingual resources seems ap-
pealing as well. Developing better context-models
to be applied on the source is expected to further
improve our method’s performance. Specifically,
we suggest taking into account the prior likelihood
that a rule is correct as part of the model score.
Finally, some researchers have advocated re-
cently the use of shared structures such as parse
forests (Mi and Huang, 2008) or word lattices
(Dyer et al., 2008) in order to allow a compact rep-
resentation of alternative inputs to an SMT system.
This is an approach that we intend to explore in
future work, as a way to efficiently handle the dif-
ferent source language alternatives generated by
entailment rules. However, since most current MT
systems do not accept such type of inputs, we con-
sider the results on pruning by source-side context
models as broadly relevant.
</bodyText>
<sectionHeader confidence="0.998091" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999860875">
This work was supported in part by the ICT Pro-
gramme of the European Community, under the
PASCAL 2 Network of Excellence, ICT-216886
and The Israel Science Foundation (grant No.
1112/08). We wish to thank Roy Bar-Haim and
the anonymous reviewers of this paper for their
useful feedback. This publication only reflects the
authors’ views.
</bodyText>
<sectionHeader confidence="0.998839" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998770066666667">
Abhaya Agarwal and Alon Lavie. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
Proceedings of WMT-08.
Karunesh Arora, Michael Paul, and Eiichiro Sumita.
2008. Translation of Unknown Words in Phrase-
Based Statistical Machine Translation for Lan-
guages of Rich Morphology. In Proceedings of
SLTU.
Francis Bond, Eric Nichols, Darren Scott Appling, and
Michael Paul. 2008. Improving Statistical Machine
Translation by Paraphrasing the Training Data. In
Proceedings of IWSLT.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine Trans-
lation Using Paraphrases. In Proceedings of HLT-
NAACL.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2008.
Further Meta-Evaluation of Machine Translation. In
Proceedings of WMT.
Chris Callison-Burch. 2008. Syntactic Constraints
on Paraphrases Extracted from Parallel Corpora. In
Proceedings of EMNLP.
Jacob Cohen. 1960. A Coefficient of Agreement for
Nominal Scales. Educational and Psychological
Measurement, 20(1):37–46.
Trevor Cohn and Mirella Lapata. 2007. Machine
Translation by Triangulation: Making Effective Use
of Multi-Parallel Corpora. In Proceedings of ACL.
</reference>
<page confidence="0.97546">
798
</page>
<reference confidence="0.999849142857143">
Ido Dagan, Oren Glickman, Alfio Massimiliano
Gliozzo, Efrat Marmorshtein, and Carlo Strappar-
ava. 2006. Direct Word Sense Matching for Lexical
Substitution. In Proceedings of ACL.
Scott Deerwester, S.T. Dumais, G.W. Furnas, T.K. Lan-
dauer, and R.A. Harshman. 1990. Indexing by La-
tent Semantic Analysis. Journal of the American So-
ciety for Information Science, 41.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008. Generalizing Word Lattice Trans-
lation. In Proceedings of ACL-HLT.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2008.
Communicating Unknown Words in Machine Trans-
lation. In Proceedings of LREC.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and
Communication). The MIT Press.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The Third PASCAL Recog-
nising Textual Entailment Challenge. In Proceed-
ings of ACL-WTEP Workshop.
Oren Glickman, Ido Dagan, Mikaela Keller, Samy
Bengio, and Walter Daelemans. 2006. Investigat-
ing Lexical Substitution Scoring for Subtitle Gener-
ation. In Proceedings of CoNLL.
Alfio Massimiliano Gliozzo. 2005. Semantic Domains
in Computational Linguistics. Ph.D. thesis, Univer-
sity of Trento.
Francisco Guzm´an and Leonardo Garrido. 2008.
Translation Paraphrases in Phrase-Based Machine
Translation. In Proceedings of CICLing.
Nizar Habash. 2008. Four Techniques for Online
Handling of Out-of-Vocabulary Words in Arabic-
English Statistical Machine Translation. In Pro-
ceedings of ACL-HLT.
David Kauchak and Regina Barzilay. 2006. Paraphras-
ing for Automatic Evaluation. In Proceedings of
HLT-NAACL.
Kevin Knight and Jonathan Graehl. 1997. Machine
Transliteration. In Proceedings of ACL.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings
of EACL.
Philippe Langlais and Alexandre Patry. 2007. Trans-
lating Unknown Words by Analogical Learning. In
Proceedings of EMNLP-CoNLL.
Dekang Lin and Patrick Pantel. 2001. DIRT – Discov-
ery of Inference Rules from Text. In Proceedings of
SIGKDD.
Diana McCarthy and Roberto Navigli. 2007.
SemEval-2007 Task 10: English Lexical Substitu-
tion Task. In Proceedings of SemEval.
Diana Mccarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding Predominant Word Senses
in Untagged Text. In Proceedings of ACL.
Haitao Mi and Liang Huang. 2008. Forest-based
Translation Rule Extraction. In Proceedings of
EMNLP.
Sebastian Pado, Michel Galley, Daniel Jurafsky, and
Christopher D. Manning. 2009. Textual Entail-
ment Features for Machine Translation Evaluation.
In Proceedings of WMT.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
ofACL.
M. Simard, N. Cancedda, B. Cavestro, M. Dymet-
man, E. Gaussier, C. Goutte, and K. Yamada. 2005.
Translating with Non-contiguous Phrases. In Pro-
ceedings of HLT-EMNLP.
Andreas Stolcke. 2002. SRILM – An Extensible Lan-
guage Modeling Toolkit. In Proceedings of ICSLP.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob
Goldberger. 2008. Contextual Preferences. In Pro-
ceedings of ACL-HLT.
Frank Wilcoxon. 1945. Individual Comparisons by
Ranking Methods. Biometrics Bulletin, 1(6):80–83.
Mei Yang and Katrin Kirchhoff. 2006. Phrase-Based
Backoff Models for Machine Translation of Highly
Inflected Languages. In Proceedings of EACL.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008. Pivot Approach for Extracting Paraphrase
Patterns from Bilingual Corpora. In Proceedings of
ACL-HLT.
</reference>
<page confidence="0.99865">
799
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.824489">
<title confidence="0.999841">Source-Language Entailment Modeling for Translating Unknown Terms</title>
<author confidence="0.999983">Lucia Nicola Ido Marc Idan</author>
<affiliation confidence="0.999903">Science Department, Bar-Ilan University</affiliation>
<address confidence="0.848918">Research Centre Europe</address>
<email confidence="0.995284">mirkins@cs.biu.ac.il</email>
<email confidence="0.995284">dagan@cs.biu.ac.il</email>
<email confidence="0.995284">szpekti@cs.biu.ac.il</email>
<abstract confidence="0.998305333333333">This paper addresses the task of handling unknown terms in SMT. We propose using source-language monolingual models and resources to paraphrase the source text prior to translation. We further present a conceptual extension to prior work by altranslations of rather than paraphrases only. A method for performing this process efficiently is presented and applied to some 2500 sentences with unknown terms. Our experiments show that the proposed approach substantially increases the number of properly translated texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abhaya Agarwal</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of WMT-08.</booktitle>
<contexts>
<context position="28694" citStr="Agarwal and Lavie, 2007" startWordPosition="4654" endWordPosition="4657">phrases were acquired from a corpus whose domain is different from that of the test sentences. The entailment rules in our models are not limited to paraphrases and are derived from WordNet, which has broader applicability. Hence, utilizing monolingual resources has proven beneficial for the task. 5.2 Automatic MT Evaluation Although automatic MT evaluation metrics are less appropriate for capturing the variations generated by our method, to ensure that there was no degradation in the system-level scores according to such metrics we also measured the models’ performance using BLEU and METEOR (Agarwal and Lavie, 2007). The version of METEOR we used on the target language (French) considers the stems of the words, instead of surface forms only, but does not make use of WordNet synonyms. We evaluated the performance of the top models of Table 1, as well as of a baseline SMT system that left unknown terms untranslated, on the sample of 1,014 manually annotated sentences. As shown in Table 3, all models resulted in improvement with respect to the original sentences (baseModel BLEU (TE) METEOR (TE) –:SMT 15.50 0.1325 NB:SMT 15.37 0.1316 LSA:SMT 15.51 0.1318 NB:– 15.37 0.1311 CB 15.33 0.1299 Baseline SMT 15.29 0</context>
</contexts>
<marker>Agarwal, Lavie, 2007</marker>
<rawString>Abhaya Agarwal and Alon Lavie. 2007. METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments. In Proceedings of WMT-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karunesh Arora</author>
<author>Michael Paul</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Translation of Unknown Words in PhraseBased Statistical Machine Translation for Languages of Rich Morphology.</title>
<date>2008</date>
<booktitle>In Proceedings of SLTU.</booktitle>
<contexts>
<context position="8192" citStr="Arora et al., 2008" startWordPosition="1295" endWordPosition="1298">r than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burc</context>
</contexts>
<marker>Arora, Paul, Sumita, 2008</marker>
<rawString>Karunesh Arora, Michael Paul, and Eiichiro Sumita. 2008. Translation of Unknown Words in PhraseBased Statistical Machine Translation for Languages of Rich Morphology. In Proceedings of SLTU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
<author>Eric Nichols</author>
<author>Darren Scott Appling</author>
<author>Michael Paul</author>
</authors>
<title>Improving Statistical Machine Translation by Paraphrasing the Training Data.</title>
<date>2008</date>
<booktitle>In Proceedings of IWSLT.</booktitle>
<contexts>
<context position="9239" citStr="Bond et al. (2008)" startWordPosition="1463" endWordPosition="1466">ast one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but not content words. The paraphrases are added to the source side of the corpus and the corresponding target sentences are duplicated. This, however, may yield distorted probability estimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to ob</context>
</contexts>
<marker>Bond, Nichols, Appling, Paul, 2008</marker>
<rawString>Francis Bond, Eric Nichols, Darren Scott Appling, and Michael Paul. 2008. Improving Statistical Machine Translation by Paraphrasing the Training Data. In Proceedings of IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved Statistical Machine Translation Using Paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of HLTNAACL.</booktitle>
<contexts>
<context position="26608" citStr="Callison-Burch et al., 2006" startWordPosition="4315" endWordPosition="4318">NB:SMT or LSA:SMT). This is particularly relevant for on-demand MT systems, where time is an issue. For such systems, using this source-language based pruning methodology will yield significant performance gains as compared to target-only models. We also evaluated the baseline strategy where unknown terms are omitted from the translation, resulting in 25% precision. Leaving unknown words untranslated also yielded very poor translation quality in an analysis performed on a similar dataset. Comparison to related work We compared our algorithm with an implementation of the algorithm proposed by (Callison-Burch et al., 2006) (see Section 2.2), henceforth CB, using the Spanish side of Europarl as the pivot language. Out of the tested 2,494 sentences with unknown terms, CB found paraphrases for 706 sentences (28.3%), while with any of our models, including 796 Model Precision (%) Coverage (%) Better (%) NB:SMT (TE) 85.3 56.2 72.7 CB 85.3 24.2 12.7 Table 2: Comparison between our top model and the method by Callison-Burch et al. (2006), showing the percentage of times translations were considered acceptable, the model’s coverage and the percentage of times each model scored better than the other (in the 14% remainin</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved Statistical Machine Translation Using Paraphrases. In Proceedings of HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>Further Meta-Evaluation of Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of WMT.</booktitle>
<contexts>
<context position="18252" citStr="Callison-Burch et al., 2008" startWordPosition="2958" endWordPosition="2961">me described in 3, changing only the models being used for scoring the generated and translated texts. The setting of these experiments is described in what follows. SMT data To produce sentences for our experiments, we use Matrax (Simard et al., 2005), a standard phrase-based SMT system, with the exception that it allows gaps in phrases. We use approximately 1M sentence pairs from the English-French 794 Europarl corpus for training, and then translate a test set of 5,859 English sentences from the News corpus into French. Both resources are taken from the shared translation task in WMT-2008 (Callison-Burch et al., 2008). Hence, we compare our method in a setting where the training and test data are from different domains, a common scenario in the practical use of MT systems. Of the 5,859 translated sentences, 2,494 contain unknown terms (considering only sequences with alphabetic symbols), summing up to 4,255 occurrences of unknown terms. 39% of the 2,494 sentences contain more than a single unknown term. Entailment resource We use WordNet 3.0 as a resource for entailment rules. Paraphrases are generated using synonyms. Directionally entailed texts are created using hypernyms, which typically conform with en</context>
<context position="23859" citStr="Callison-Burch et al., 2008" startWordPosition="3882" endWordPosition="3885">tal, the translations of 1,014 unique source sentences were manually annotated, of which 453 were produced using only hypernyms (no paraphrases were applicable). When a sentence was annotated by both annotators, one annotation was picked randomly. Inter-annotator agreement was measured by the percentage of sentences the annotators agreed on, as well as via the Kappa measure (Cohen, 1960). For different models, the agreement rate varied from 67% to 78% (72% overall), and the Kappa value ranged from 0.34 to 0.55, which is comparable to figures reported for other standard SMT evaluation metrics (Callison-Burch et al., 2008). Translation with TE For each model m, we measured Precisionm, the percentage of acceptable translations out of all sampled translations. Precisionm was measured both when using only paraphrases (PARAPH.) and when using all entailment rules (TE). We also measured Coveragem, the percentage of sentences with acceptable translations, Am, out of all sentences (2,494). As our annotators evaluated only a sample of sentences, Am is estimated as the model’s total number of sentences with applicable rules, Sm, multiplied by the model’s Precision (Sm was 1,071 for paraphrases and 1,643 for entailment r</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2008</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2008. Further Meta-Evaluation of Machine Translation. In Proceedings of WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic Constraints on Paraphrases Extracted from Parallel Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="8799" citStr="Callison-Burch, 2008" startWordPosition="1394" endWordPosition="1395">et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but not content words. The p</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic Constraints on Paraphrases Extracted from Parallel Corpora. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A Coefficient of Agreement for Nominal Scales. Educational and Psychological Measurement,</title>
<date>1960</date>
<contexts>
<context position="23621" citStr="Cohen, 1960" startWordPosition="3845" endWordPosition="3846">ence, marking it as acceptable or unacceptable. From the sentences for which rules were applicable, we randomly selected a sample of sentences for each annotator, allowing for some overlapping for agreement analysis. In total, the translations of 1,014 unique source sentences were manually annotated, of which 453 were produced using only hypernyms (no paraphrases were applicable). When a sentence was annotated by both annotators, one annotation was picked randomly. Inter-annotator agreement was measured by the percentage of sentences the annotators agreed on, as well as via the Kappa measure (Cohen, 1960). For different models, the agreement rate varied from 67% to 78% (72% overall), and the Kappa value ranged from 0.34 to 0.55, which is comparable to figures reported for other standard SMT evaluation metrics (Callison-Burch et al., 2008). Translation with TE For each model m, we measured Precisionm, the percentage of acceptable translations out of all sampled translations. Precisionm was measured both when using only paraphrases (PARAPH.) and when using all entailment rules (TE). We also measured Coveragem, the percentage of sentences with acceptable translations, Am, out of all sentences (2,</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A Coefficient of Agreement for Nominal Scales. Educational and Psychological Measurement, 20(1):37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8758" citStr="Cohn and Lapata, 2007" startWordPosition="1386" endWordPosition="1389">ff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (t</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2007. Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Alfio Massimiliano Gliozzo</author>
<author>Efrat Marmorshtein</author>
<author>Carlo Strapparava</author>
</authors>
<title>Direct Word Sense Matching for Lexical Substitution.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="11932" citStr="Dagan et al., 2006" startWordPosition="1910" endWordPosition="1913">nt rules, i.e. rules without variables. Various resources for lexical rules are available, and the prominent one is WordNet (Fellbaum, 1998), which has been used in virtually all TE systems (Giampiccolo et al., 2007). Typically, a rule application is valid only under specific contexts. For example, mouse ==&gt;. rodent should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). 3 Textual Entailment for Statistical Machine Translation Previous solutions for handling unknown terms in a source text s augment the SMT system’s phrase table based on multilingual corpora. This allows indirectly paraphrasing s, when the SMT system chooses to use a paraphrase </context>
</contexts>
<marker>Dagan, Glickman, Gliozzo, Marmorshtein, Strapparava, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, Alfio Massimiliano Gliozzo, Efrat Marmorshtein, and Carlo Strapparava. 2006. Direct Word Sense Matching for Lexical Substitution. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R A Harshman</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<contexts>
<context position="20205" citStr="Deerwester et al., 1990" startWordPosition="3277" endWordPosition="3280">orst case”, when all TE rules are employed, an average of 456 alternatives per sentence. Scoring source texts We test our proposed method using several context-models shown to perform reasonably well in previous work: • FREQ: The first model we use is a contextindependent baseline. A common useful heuristic to pick an entailment rule is to select the candidate with the highest frequency in the corpus (Mccarthy et al., 2004). In this model, a rule’s score is the normalized number of occurrences of its RHS in the training corpus, ignoring the context of the LHS. • LSA: Latent Semantic Analysis (Deerwester et al., 1990) is a well-known method for rep2http://opennlp.sourceforge.net resenting the contextual usage of words based on corpus statistics. We represented each term by a normalized vector of the top 100 SVD dimensions, as described in (Gliozzo, 2005). This model measures the similarity between the sentence words and the RHS in the LSA space. • NB: We implemented the unsupervised Naive Bayes model described in (Glickman et al., 2006) to estimate the probability that the unknown term entails the RHS in the given context. The estimation is based on corpus co-occurrence statistics of the context words with</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer, and R.A. Harshman. 1990. Indexing by Latent Semantic Analysis. Journal of the American Society for Information Science, 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
<author>Smaranda Muresan</author>
<author>Philip Resnik</author>
</authors>
<title>Generalizing Word Lattice Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="33715" citStr="Dyer et al., 2008" startWordPosition="5462" endWordPosition="5465">matic measures. For future work we suggest generating entailed texts with a more extensive set of rules, in particular lexical-syntactic ones. Combining rules from monolingual and bilingual resources seems appealing as well. Developing better context-models to be applied on the source is expected to further improve our method’s performance. Specifically, we suggest taking into account the prior likelihood that a rule is correct as part of the model score. Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al., 2008) in order to allow a compact representation of alternative inputs to an SMT system. This is an approach that we intend to explore in future work, as a way to efficiently handle the different source language alternatives generated by entailment rules. However, since most current MT systems do not accept such type of inputs, we consider the results on pruning by source-side context models as broadly relevant. Acknowledgments This work was supported in part by the ICT Programme of the European Community, under the PASCAL 2 Network of Excellence, ICT-216886 and The Israel Science Foundation (grant</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008. Generalizing Word Lattice Translation. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Communicating Unknown Words in Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="7642" citStr="Eck et al., 2008" startWordPosition="1210" endWordPosition="1213">monstrated in the following sentences, where the translation of the English sentence (1) is acceptable only when the unknown word (in bold) is replaced with a translatable paraphrase (3): 1. “... , despite bearing the heavy burden of the unemployed 10% or more of the labor force.” 2. “... , malgr´e la lourde charge de compte le 10% ou plus de chˆomeurs labor la force .” 3. “... , malgr´e la lourde charge des chˆomeurs de 10% ou plus de la force du travail.” Several approaches have been proposed to deal with unknown terms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage</context>
</contexts>
<marker>Eck, Vogel, Waibel, 2008</marker>
<rawString>Matthias Eck, Stephan Vogel, and Alex Waibel. 2008. Communicating Unknown Words in Machine Translation. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The Third PASCAL Recognising Textual Entailment Challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-WTEP Workshop.</booktitle>
<contexts>
<context position="4511" citStr="Giampiccolo et al., 2007" startWordPosition="684" endWordPosition="687">nslation. This has two advantages. First, the ranking allows us to prune some 791 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 791–799, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP candidates before supplying them to the translation engine, thus improving translation efficiency. Second, the ranking may be combined with target language information in order to choose the best translation, thus improving translation quality. We position the problem of generating alternative texts for translation within the Textual Entailment (TE) framework (Giampiccolo et al., 2007). TE provides a generic way for handling language variability, identifying when the meaning of one text is entailed by the other (i.e. the meaning of the entailed text can be inferred from the meaning of the entailing one). When the meanings of two texts are equivalent (paraphrase), entailment is mutual. Typically, a more general version of a certain text is entailed by it. Hence, through TE we can formalize the generation of both equivalent and more general texts for the source text. When possible, a paraphrase is used. Otherwise, an alternative text whose meaning is entailed by the original </context>
<context position="10181" citStr="Giampiccolo et al., 2007" startWordPosition="1610" endWordPosition="1613">stimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 Textual Entailment and Entailment Rules Textual Entailment (TE) has recently become a prominent paradigm for modeling semantic inference, capturing the needs of a broad range of text understanding applications (Giampiccolo et al., 2007). Yet, its application to SMT has been so far limited to MT evaluation (Pado et al., 2009). TE defines a directional relation between two texts, where the meaning of the entailed text (hypothesis, h) can be inferred from the meaning of the entailing text, t. Under this paradigm, paraphrases are a special case of the entailment relation, when the relation is symmetric (the texts entail each other). Otherwise, we say that one text directionally entails the other. A common practice for proving (or generating) h from t is to apply entailment rules to t. An entailment rule, denoted LHS ==&gt;. RHS, sp</context>
<context position="11529" citStr="Giampiccolo et al., 2007" startWordPosition="1844" endWordPosition="1847">build X in Y ==&gt;. X is completed in Y ). A paraphrasing rule is denoted with q. When a rule is applied to a text, a new text is inferred, where the matched LHS is replaced with the RHS. For example, the rule skyscraper ==&gt;. building is applied to “The world’s tallest skyscraper was completed in Taiwan” to infer “The world’s tallest building was completed in Taiwan”. In this work, we employ lexical entailment rules, i.e. rules without variables. Various resources for lexical rules are available, and the prominent one is WordNet (Fellbaum, 1998), which has been used in virtually all TE systems (Giampiccolo et al., 2007). Typically, a rule application is valid only under specific contexts. For example, mouse ==&gt;. rodent should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. H</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The Third PASCAL Recognising Textual Entailment Challenge. In Proceedings of ACL-WTEP Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Glickman</author>
<author>Ido Dagan</author>
<author>Mikaela Keller</author>
<author>Samy Bengio</author>
<author>Walter Daelemans</author>
</authors>
<title>Investigating Lexical Substitution Scoring for Subtitle Generation.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="20632" citStr="Glickman et al., 2006" startWordPosition="3344" endWordPosition="3347">In this model, a rule’s score is the normalized number of occurrences of its RHS in the training corpus, ignoring the context of the LHS. • LSA: Latent Semantic Analysis (Deerwester et al., 1990) is a well-known method for rep2http://opennlp.sourceforge.net resenting the contextual usage of words based on corpus statistics. We represented each term by a normalized vector of the top 100 SVD dimensions, as described in (Gliozzo, 2005). This model measures the similarity between the sentence words and the RHS in the LSA space. • NB: We implemented the unsupervised Naive Bayes model described in (Glickman et al., 2006) to estimate the probability that the unknown term entails the RHS in the given context. The estimation is based on corpus co-occurrence statistics of the context words with the RHS. • LMS: This model generates the Language Model probability of the RHS in the source. We use 3-grams probabilities as produced by the SRILM toolkit (Stolcke, 2002). Finally, as a simple baseline, we generated a random score for each rule application, RAND. The score of each rule application by any of the above models is normalized to the range (0,1]. To combine individual rule applications in a given sentence, we u</context>
</contexts>
<marker>Glickman, Dagan, Keller, Bengio, Daelemans, 2006</marker>
<rawString>Oren Glickman, Ido Dagan, Mikaela Keller, Samy Bengio, and Walter Daelemans. 2006. Investigating Lexical Substitution Scoring for Subtitle Generation. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfio Massimiliano Gliozzo</author>
</authors>
<date>2005</date>
<booktitle>Semantic Domains in Computational Linguistics. Ph.D. thesis,</booktitle>
<institution>University of Trento.</institution>
<contexts>
<context position="20446" citStr="Gliozzo, 2005" startWordPosition="3315" endWordPosition="3316"> a contextindependent baseline. A common useful heuristic to pick an entailment rule is to select the candidate with the highest frequency in the corpus (Mccarthy et al., 2004). In this model, a rule’s score is the normalized number of occurrences of its RHS in the training corpus, ignoring the context of the LHS. • LSA: Latent Semantic Analysis (Deerwester et al., 1990) is a well-known method for rep2http://opennlp.sourceforge.net resenting the contextual usage of words based on corpus statistics. We represented each term by a normalized vector of the top 100 SVD dimensions, as described in (Gliozzo, 2005). This model measures the similarity between the sentence words and the RHS in the LSA space. • NB: We implemented the unsupervised Naive Bayes model described in (Glickman et al., 2006) to estimate the probability that the unknown term entails the RHS in the given context. The estimation is based on corpus co-occurrence statistics of the context words with the RHS. • LMS: This model generates the Language Model probability of the RHS in the source. We use 3-grams probabilities as produced by the SRILM toolkit (Stolcke, 2002). Finally, as a simple baseline, we generated a random score for each</context>
</contexts>
<marker>Gliozzo, 2005</marker>
<rawString>Alfio Massimiliano Gliozzo. 2005. Semantic Domains in Computational Linguistics. Ph.D. thesis, University of Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Guzm´an</author>
<author>Leonardo Garrido</author>
</authors>
<title>Translation Paraphrases in Phrase-Based Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of CICLing.</booktitle>
<marker>Guzm´an, Garrido, 2008</marker>
<rawString>Francisco Guzm´an and Leonardo Garrido. 2008. Translation Paraphrases in Phrase-Based Machine Translation. In Proceedings of CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Four Techniques for Online Handling of Out-of-Vocabulary Words in ArabicEnglish Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="7883" citStr="Habash, 2008" startWordPosition="1250" endWordPosition="1251">yed 10% or more of the labor force.” 2. “... , malgr´e la lourde charge de compte le 10% ou plus de chˆomeurs labor la force .” 3. “... , malgr´e la lourde charge des chˆomeurs de 10% ou plus de la force du travail.” Several approaches have been proposed to deal with unknown terms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the sour</context>
</contexts>
<marker>Habash, 2008</marker>
<rawString>Nizar Habash. 2008. Four Techniques for Online Handling of Out-of-Vocabulary Words in ArabicEnglish Statistical Machine Translation. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
<author>Regina Barzilay</author>
</authors>
<title>Paraphrasing for Automatic Evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="9756" citStr="Kauchak and Barzilay, 2006" startWordPosition="1545" endWordPosition="1548">t is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but not content words. The paraphrases are added to the source side of the corpus and the corresponding target sentences are duplicated. This, however, may yield distorted probability estimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 Textual Entailment and Entailment Rules Textual Entailment (TE) has recently become a prominent paradigm for modeling semantic inference, capturing the needs of a broad range of text understanding applications (Giampiccolo et al., 2007). Yet, its application to SMT has been so far limited to MT evaluation (Pado et al., 2009). TE defines a directional relation between two texts, where the meaning of the entai</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>David Kauchak and Regina Barzilay. 2006. Paraphrasing for Automatic Evaluation. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Machine Transliteration.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="7868" citStr="Knight and Graehl, 1997" startWordPosition="1246" endWordPosition="1249">avy burden of the unemployed 10% or more of the labor force.” 2. “... , malgr´e la lourde charge de compte le 10% ou plus de chˆomeurs labor la force .” 3. “... , malgr´e la lourde charge des chˆomeurs de 10% ou plus de la force du travail.” Several approaches have been proposed to deal with unknown terms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to para</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1997. Machine Transliteration. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical Methods for Compound Splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="8119" citStr="Koehn and Knight, 2003" startWordPosition="1283" endWordPosition="1286">proaches have been proposed to deal with unknown terms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch </context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical Methods for Compound Splitting. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>Alexandre Patry</author>
</authors>
<title>Translating Unknown Words by Analogical Learning.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="8171" citStr="Langlais and Patry, 2007" startWordPosition="1291" endWordPosition="1294">erms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al.</context>
</contexts>
<marker>Langlais, Patry, 2007</marker>
<rawString>Philippe Langlais and Alexandre Patry. 2007. Translating Unknown Words by Analogical Learning. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<date>2001</date>
<booktitle>DIRT – Discovery of Inference Rules from Text. In Proceedings of SIGKDD.</booktitle>
<contexts>
<context position="2584" citStr="Lin and Pantel, 2001" startWordPosition="381" endWordPosition="384"> refer to texts of equivalent meaning, of any length from single words (synonyms) up to complete sentences. using source-language resources and models in order to achieve two goals. The first goal is coverage increase. The availability of bilingual corpora, from which paraphrases can be learnt, is in many cases limited. On the other hand, monolingual resources and methods for extracting paraphrases from monolingual corpora are more readily available. These include manually constructed resources, such as WordNet (Fellbaum, 1998), and automatic methods for paraphrases acquisition, such as DIRT (Lin and Pantel, 2001). However, such resources have not been applied yet to the problem of substituting unknown terms in SMT. We suggest that by using such monolingual resources we could provide paraphrases for a larger number of texts with unknown terms, thus increasing the overall coverage of the SMT system, i.e. the number of texts it properly translates. Even with larger paraphrase resources, we may encounter texts in which not all unknown terms are successfully handled through paraphrasing, which often results in poor translations (see Section 2.1). To further increase coverage, we therefore propose to genera</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT – Discovery of Inference Rules from Text. In Proceedings of SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<date>2007</date>
<booktitle>SemEval-2007 Task 10: English Lexical Substitution Task. In Proceedings of SemEval.</booktitle>
<contexts>
<context position="12055" citStr="McCarthy and Navigli, 2007" startWordPosition="1930" endWordPosition="1933"> WordNet (Fellbaum, 1998), which has been used in virtually all TE systems (Giampiccolo et al., 2007). Typically, a rule application is valid only under specific contexts. For example, mouse ==&gt;. rodent should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). 3 Textual Entailment for Statistical Machine Translation Previous solutions for handling unknown terms in a source text s augment the SMT system’s phrase table based on multilingual corpora. This allows indirectly paraphrasing s, when the SMT system chooses to use a paraphrase included in the table and produces a translation with the corresponding target phrase for the unknown term. We propose usin</context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. SemEval-2007 Task 10: English Lexical Substitution Task. In Proceedings of SemEval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Mccarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding Predominant Word Senses in Untagged Text.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="20008" citStr="Mccarthy et al., 2004" startWordPosition="3242" endWordPosition="3245"> respectively. The number of alternative sentences generated for each source text varies from 1 to 960 when paraphrasing rules were applied, and reaches very large numbers, up to 89,700 at the “worst case”, when all TE rules are employed, an average of 456 alternatives per sentence. Scoring source texts We test our proposed method using several context-models shown to perform reasonably well in previous work: • FREQ: The first model we use is a contextindependent baseline. A common useful heuristic to pick an entailment rule is to select the candidate with the highest frequency in the corpus (Mccarthy et al., 2004). In this model, a rule’s score is the normalized number of occurrences of its RHS in the training corpus, ignoring the context of the LHS. • LSA: Latent Semantic Analysis (Deerwester et al., 1990) is a well-known method for rep2http://opennlp.sourceforge.net resenting the contextual usage of words based on corpus statistics. We represented each term by a normalized vector of the top 100 SVD dimensions, as described in (Gliozzo, 2005). This model measures the similarity between the sentence words and the RHS in the LSA space. • NB: We implemented the unsupervised Naive Bayes model described in</context>
</contexts>
<marker>Mccarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana Mccarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding Predominant Word Senses in Untagged Text. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
</authors>
<title>Forest-based Translation Rule Extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="33678" citStr="Mi and Huang, 2008" startWordPosition="5455" endWordPosition="5458">oth human annotators and standard automatic measures. For future work we suggest generating entailed texts with a more extensive set of rules, in particular lexical-syntactic ones. Combining rules from monolingual and bilingual resources seems appealing as well. Developing better context-models to be applied on the source is expected to further improve our method’s performance. Specifically, we suggest taking into account the prior likelihood that a rule is correct as part of the model score. Finally, some researchers have advocated recently the use of shared structures such as parse forests (Mi and Huang, 2008) or word lattices (Dyer et al., 2008) in order to allow a compact representation of alternative inputs to an SMT system. This is an approach that we intend to explore in future work, as a way to efficiently handle the different source language alternatives generated by entailment rules. However, since most current MT systems do not accept such type of inputs, we consider the results on pruning by source-side context models as broadly relevant. Acknowledgments This work was supported in part by the ICT Programme of the European Community, under the PASCAL 2 Network of Excellence, ICT-216886 and</context>
</contexts>
<marker>Mi, Huang, 2008</marker>
<rawString>Haitao Mi and Liang Huang. 2008. Forest-based Translation Rule Extraction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
<author>Michel Galley</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Textual Entailment Features for Machine Translation Evaluation.</title>
<date>2009</date>
<booktitle>In Proceedings of WMT.</booktitle>
<contexts>
<context position="10271" citStr="Pado et al., 2009" startWordPosition="1627" endWordPosition="1630">onolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 Textual Entailment and Entailment Rules Textual Entailment (TE) has recently become a prominent paradigm for modeling semantic inference, capturing the needs of a broad range of text understanding applications (Giampiccolo et al., 2007). Yet, its application to SMT has been so far limited to MT evaluation (Pado et al., 2009). TE defines a directional relation between two texts, where the meaning of the entailed text (hypothesis, h) can be inferred from the meaning of the entailing text, t. Under this paradigm, paraphrases are a special case of the entailment relation, when the relation is symmetric (the texts entail each other). Otherwise, we say that one text directionally entails the other. A common practice for proving (or generating) h from t is to apply entailment rules to t. An entailment rule, denoted LHS ==&gt;. RHS, specifies an entailment relation between two text fragments (the Left- and Right- Hand Sides</context>
</contexts>
<marker>Pado, Galley, Jurafsky, Manning, 2009</marker>
<rawString>Sebastian Pado, Michel Galley, Daniel Jurafsky, and Christopher D. Manning. 2009. Textual Entailment Features for Machine Translation Evaluation. In Proceedings of WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="9939" citStr="Papineni et al., 2002" startWordPosition="1575" endWordPosition="1578">ord order and minor lexical variations (tenses etc.), but not content words. The paraphrases are added to the source side of the corpus and the corresponding target sentences are duplicated. This, however, may yield distorted probability estimates in the phrase table, since these were not computed from parallel data. The main use of monolingual paraphrases in MT to date has been for evaluation. For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al., 2002). 2.3 Textual Entailment and Entailment Rules Textual Entailment (TE) has recently become a prominent paradigm for modeling semantic inference, capturing the needs of a broad range of text understanding applications (Giampiccolo et al., 2007). Yet, its application to SMT has been so far limited to MT evaluation (Pado et al., 2009). TE defines a directional relation between two texts, where the meaning of the entailed text (hypothesis, h) can be inferred from the meaning of the entailing text, t. Under this paradigm, paraphrases are a special case of the entailment relation, when the relation i</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>N Cancedda</author>
<author>B Cavestro</author>
<author>M Dymetman</author>
<author>E Gaussier</author>
<author>C Goutte</author>
<author>K Yamada</author>
</authors>
<title>Translating with Non-contiguous Phrases.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP.</booktitle>
<contexts>
<context position="17876" citStr="Simard et al., 2005" startWordPosition="2896" endWordPosition="2899">odels applied at each end. As the experiments will show in Section 4, a large number of possible combinations of entailment rules is a common scenario, and therefore using the source context models to reduce this number plays an important role. 4 Experimental Setting To assess our approach, we conducted a series of experiments; in each experiment we applied the scheme described in 3, changing only the models being used for scoring the generated and translated texts. The setting of these experiments is described in what follows. SMT data To produce sentences for our experiments, we use Matrax (Simard et al., 2005), a standard phrase-based SMT system, with the exception that it allows gaps in phrases. We use approximately 1M sentence pairs from the English-French 794 Europarl corpus for training, and then translate a test set of 5,859 English sentences from the News corpus into French. Both resources are taken from the shared translation task in WMT-2008 (Callison-Burch et al., 2008). Hence, we compare our method in a setting where the training and test data are from different domains, a common scenario in the practical use of MT systems. Of the 5,859 translated sentences, 2,494 contain unknown terms (c</context>
</contexts>
<marker>Simard, Cancedda, Cavestro, Dymetman, Gaussier, Goutte, Yamada, 2005</marker>
<rawString>M. Simard, N. Cancedda, B. Cavestro, M. Dymetman, E. Gaussier, C. Goutte, and K. Yamada. 2005. Translating with Non-contiguous Phrases. In Proceedings of HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<contexts>
<context position="20977" citStr="Stolcke, 2002" startWordPosition="3403" endWordPosition="3404"> a normalized vector of the top 100 SVD dimensions, as described in (Gliozzo, 2005). This model measures the similarity between the sentence words and the RHS in the LSA space. • NB: We implemented the unsupervised Naive Bayes model described in (Glickman et al., 2006) to estimate the probability that the unknown term entails the RHS in the given context. The estimation is based on corpus co-occurrence statistics of the context words with the RHS. • LMS: This model generates the Language Model probability of the RHS in the source. We use 3-grams probabilities as produced by the SRILM toolkit (Stolcke, 2002). Finally, as a simple baseline, we generated a random score for each rule application, RAND. The score of each rule application by any of the above models is normalized to the range (0,1]. To combine individual rule applications in a given sentence, we use the product of their scores. The monolingual data used for the models above is the source side of the training parallel corpus. Target-language scores On the target side we used either a standard 3-gram language-model, denoted LMT, or the score assigned by the complete SMT log-linear model, which includes the language model as one of its co</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Roy Bar-Haim</author>
<author>Jacob Goldberger</author>
</authors>
<title>Contextual Preferences.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="12252" citStr="Szpektor et al., 2008" startWordPosition="1960" endWordPosition="1963"> should not be applied to “Use the mouse to mark your answers”. Context-models can be exploited to validate the application of a rule to a text. In such models, an explicit Word Sense Disambiguation (WSD) is not necessarily required; rather, an implicit sense-match is sought after (Dagan et al., 2006). Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule. However, in general, entailment rule application addresses other aspects of context matching as well (Szpektor et al., 2008). 3 Textual Entailment for Statistical Machine Translation Previous solutions for handling unknown terms in a source text s augment the SMT system’s phrase table based on multilingual corpora. This allows indirectly paraphrasing s, when the SMT system chooses to use a paraphrase included in the table and produces a translation with the corresponding target phrase for the unknown term. We propose using monolingual paraphrasing methods and resources for this task to obtain a more extensive set of rules for paraphrasing the source. These rules are then applied to s directly to produce alternative</context>
</contexts>
<marker>Szpektor, Dagan, Bar-Haim, Goldberger, 2008</marker>
<rawString>Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Goldberger. 2008. Contextual Preferences. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wilcoxon</author>
</authors>
<title>Individual Comparisons by Ranking Methods.</title>
<date>1945</date>
<journal>Biometrics Bulletin,</journal>
<volume>1</volume>
<issue>6</issue>
<contexts>
<context position="25426" citStr="Wilcoxon, 1945" startWordPosition="4131" endWordPosition="4132">hile just a slight decrease in precision is observed (see Section 5.3 for some error analysis). This confirms our hypothesis that directional entailment rules can be very useful for replacing unknown terms. For the combination of source-target models, the value of k is set depending on which rule-set is used. Preliminary analysis showed that k = 5 is sufficient when only paraphrases are used and k = 20 when directional entailment rules are also considered. We measured statistical significance between different models for precision of the TE results according to the Wilcoxon signed ranks test (Wilcoxon, 1945). Models 1-6 in Table 1 are significantly better than the RAND baseline (p &lt; 0.03), and models 1-3 are significantly better than model 6 (p &lt; 0.05). The difference between –:SMT and NB:SMT or LSA:SMT is not statistically significant. The results in Table 1 therefore suggest that taking a source model into account preserves the quality of translation. Furthermore, the quality is maintained even when source models’ selections are restricted to a rather small top-k ranks, at a lower computational cost (for the models combining source and target, like NB:SMT or LSA:SMT). This is particularly relev</context>
</contexts>
<marker>Wilcoxon, 1945</marker>
<rawString>Frank Wilcoxon. 1945. Individual Comparisons by Ranking Methods. Biometrics Bulletin, 1(6):80–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mei Yang</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Phrase-Based Backoff Models for Machine Translation of Highly Inflected Languages.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="8145" citStr="Yang and Kirchhoff, 2006" startWordPosition="1287" endWordPosition="1290">sed to deal with unknown terms in SMT systems, rather than omitting or copying the terms. For example, (Eck et al., 2008) replace the unknown terms in the source text by their definition in a monolingual dictionary, which can be useful for gisting. To translate across languages with different alphabets approaches such as (Knight and Graehl, 1997; Habash, 2008) use transliteration techniques to tackle proper nouns and technical terms. For translation from highly inflected languages, certain approaches rely on some form of lexical approximation or morphological analysis (Koehn and Knight, 2003; Yang and Kirchhoff, 2006; Langlais and Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and</context>
</contexts>
<marker>Yang, Kirchhoff, 2006</marker>
<rawString>Mei Yang and Katrin Kirchhoff. 2006. Phrase-Based Backoff Models for Machine Translation of Highly Inflected Languages. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="8777" citStr="Zhao et al., 2008" startWordPosition="1390" endWordPosition="1393">Patry, 2007; Arora et al., 2008). Although these strategies yield gain in coverage and translation quality, they only account for unknown terms that should be transliterated or are variations of known ones. 2.2 Paraphrasing in MT A recent strategy to broadly deal with the problem of unknown terms is to paraphrase the source text with terms whose translation is known to the system, using paraphrases learnt from multilingual corpora, typically involving at least one “pivot” language different from the target language of immediate interest (Callison-Burch et 792 al., 2006; Cohn and Lapata, 2007; Zhao et al., 2008; Callison-Burch, 2008; Guzm´an and Garrido, 2008). The procedure to extract paraphrases in these approaches is similar to standard phrase extraction in SMT systems, and therefore a large amount of additional parallel corpus is required. Moreover, as discussed in Section 5, when unknown texts are not from the same domain as the SMT training corpus, it is likely that paraphrases found through such methods will yield misleading translations. Bond et al. (2008) use grammars to paraphrase the whole source sentence, covering aspects like word order and minor lexical variations (tenses etc.), but no</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008. Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora. In Proceedings of ACL-HLT.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>