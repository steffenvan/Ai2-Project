<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.865334">
Coreference or Not: A Twin Model for Coreference Resolution
</note>
<author confidence="0.561645">
Xiaoqiang Luo
</author>
<affiliation confidence="0.470732">
IBM T.J. Watson Research Center
</affiliation>
<address confidence="0.9298855">
1101 Kitchawan Road
Yorktown Heights, NY 10598, U.S.A.
</address>
<email confidence="0.998539">
{xiaoluo}@us.ibm.com
</email>
<sectionHeader confidence="0.998596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947941176471">
A twin-model is proposed for coreference res-
olution: a link component, modeling the coref-
erential relationship between an anaphor and
a candidate antecedent, and a creation com-
ponent modeling the possibility that a phrase
is not coreferential with any candidate an-
tecedent. The creation model depends on all
candidate antecedents and is often expensive
to compute; Therefore constraints are imposed
on feature forms so that features in the cre-
ation model can be efficiently computed from
feature values in the link model. The pro-
posed twin-model is tested on the data from
the 2005 Automatic Content Extraction (ACE)
task and the proposed model performs bet-
ter than a thresholding baseline without tuning
free parameter.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99849806122449">
Coreference resolution aims to find multiple mentions
of an entity (e.g., PERSON, ORGANIZATION) in a
document. In a typical machine learning-based coref-
erence resolution system (Soon et al., 2001; Ng and
Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a
statistical model is learned from training data and is
used to measure how likely an anaphor 1 is corefer-
ential to a candidate antecedent. A related, but often
overlooked, problem is that the anaphor may be non-
coreferential to any candidate, which arises from sce-
narios such as an identified anaphor is truly generic and
&apos;In this paper, “anaphor” includes all kinds of phrases to
be resolved, which can be named, nominal or pronominal
phrases.
there does not exist an antecedent in the discourse con-
text, or an anaphor is the first mention (relative to pro-
cessing order) in a coreference chain.
In (Soon et al., 2001; Ng and Cardie, 2002b),
the problem is treated by thresholding the scores re-
turned by the coreference model. That is, if the max-
imum coreference score is below a threshold, then the
anaphor is deemed non-referential to any candidate an-
tecedent. The threshold approach does not model non-
coreferential events directly, and is by no means the op-
timal approach to the problem. It also introduces a free
parameter which has to be set by trial-and-error. As an
improvement, Ng and Cardie (2002a) and Ng (2004)
train a separate model to classify an anaphor as either
anaphoric or non-anaphoric. The output of this clas-
sifier can be used either as a pre-filter (Ng and Cardie,
2002a) so that non-anaphoric anaphors will not be pre-
cessed in the coreference system, or as a set of features
in the coreference model (Ng, 2004). By rejecting any
anaphor classified as non-anaphoric in coreference res-
olution, the filtering approach is meant to handle non-
anaphoric phrases (i.e., no antecedent exists in the dis-
course under consideration), not the first mention in a
coreference chain.
In this paper, coreference is viewed as a process of
sequential operations on anaphor mentions: an anaphor
can either be linked with its antecedent if the antecedent
is available or present. If the anaphor, on the other
hand, is discourse new (relative to the process order),
then a new entity is created. Corresponding to the two
types of operations, a twin-model is proposed to re-
solve coreferential relationships in a document. The
first component is a statistical model measuring how
likely an anaphor is coreferential to a candidate an-
tecedent; The second one explicitly models the non-
</bodyText>
<page confidence="0.983144">
73
</page>
<note confidence="0.8892895">
Proceedings of NAACL HLT 2007, pages 73–80,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999818">
coreferential events. Both models are trained automat-
ically and are used simultaneously in the coreference
system. The twin-model coreference system is tested
on the 2005 ACE (Automatic Content Extraction, see
(NIST, 2005)) data and the best performance under
both ACE-Value and entity F-measure can be obtained
without tuning a free parameter.
The rest of the paper is organized as follows. The
twin-model is presented in Section 2. A maximum-
entropy implementation and features are then presented
in Section 3. The experimental results on the 2005
ACE data is presented in Section 4. The proposed twin-
model is compared with related work in Section 5 be-
fore the paper is concluded.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="method">
2 Coreference Model
</sectionHeader>
<bodyText confidence="0.9914549375">
A phrasal reference to an entity is called a mention. A
set of mentions referring to the same physical object is
said to belong to the same entity. For example, in the
following sentence:
(I) John said Mary was his sister.
there are four mentions: John, Mary, his, and
sister. John and his belong to the same entity
since they refer to the same person; So do Mary and
sister. Furthermore, John and Mary are named
mentions, sister is a nominal mention and his is a
pronominal mention.
In our coreference system, mentions are processed
sequentially, though not necessarily in chronological
order. For a document with n mentions {mi : 1  i 
n}, at any time t(t &gt; 1), mention m1 through mt_1
have been processed and each mention is placed in one
of Nt(Nt  (t−1)) entities: Et = {ej : 1  j  Nt}.
Index i in mi indicates the order in which it is pro-
cessed, not necessarily the order in which it appears in
a document. The basic step is to extend Et to Et+1
with mt.
Let us use the example in Figure 1 to illustrate how
this is done. Note that Figure 1 contains one possible
processing order for the four mentions in Example (I):
first name mentions are processed, followed by nom-
inal mentions, followed by pronominal mentions. At
time t = 1, there is no existing entity and the mention
m1=John is placed in an initial entity (entity is signi-
fied by a solid rectangle). At time t = 2, m2=Mary
is processed and a new entity containing Mary is cre-
ated. At time t = 3, the nominal mention m3=sister
is processed. At this point, the set of existing entities
</bodyText>
<equation confidence="0.9792395">
� }
E3 = {John}, {Mary} .
</equation>
<bodyText confidence="0.999082380952381">
m3 is linked with the existing entity {Mary}. At the
last step t = 4, the pronominal mention his is linked
with the entity {John}.
The above example illustrates how a sequence of
coreference steps lead to a particular coreference result.
Conversely, if the processing order is known and fixed,
every possible coreference result can be decomposed
and mapped to a unique sequence of such coreference
steps. Therefore, if we can score the set of coreference
sequences, we can score the set of coreference results
as well.
In general, when determining if a mention mt is
coreferential with any entity in Et, there are two types
of actions: one is that mt is coreferential with one of
the entities; The other is that mt is not coreferential
with any. It is important to distinguish the two cases
for the following reason: if mt is coreferential with an
entity ej, in most cases it is sufficient to determine the
relationship by examining mt and ej, and their local
context; But if mt is not coreferential with any existing
entities, we need to consider mt with all members in
Et. This observation leads us to propose the following
twin-model for coreference resolution.
The first model, P(L|ej, mt), is conditioned on an
entity ej and the current mention mt and measure how
likely they are coreferential. L is a binary variable, tak-
ing value 1 or 0, which represents positive and nega-
tive coreferential relationship, respectively. The second
model, on the other hand, P(C|Et, mt), is conditioned
on the past entities Et and the current mention mt. The
random variable C is also binary: when C is 1, it means
that a new entity {mt} will be created. In other words,
the second model measures the probability that mt is
not coreferential to any existing entity. To avoid con-
fusion in the subsequent presentation, the first model
will be written as Pl(·|ej, mt) and called link model;
The second model is written as Pc(·|Et, mt) and called
creation model.
For the time being, let’s assume that we have the link
and creation model at our disposal, and we will show
how they can be used to score coreference decisions.
Given a set of existing entities Et = {ej}N&apos;
</bodyText>
<equation confidence="0.6562205">
1 , formed
by mentions {mi}t_1
</equation>
<bodyText confidence="0.996609111111111">
i�1, and the current mention mt,
there are Nt + 1 possible actions: we can either link
mt with an existing entity ej (j = 1, 2, · · · , Nt), or
create a new entity containing mt. The link action be-
tween ej and mt can be scored by Pl(1|ej, mt) while
the creation action can be measured by Pc(1|Et, mt).
Each possible coreference outcome consists of n such
actions {at : t = 1, 2, · · · , n}, each of which can be
scored by either the link model Pl(·|ej, mt) or the cre-
</bodyText>
<page confidence="0.991058">
74
</page>
<figure confidence="0.999524818181818">
E1={}
m1
John
t=1 t=2 t=3 t=4
John
Mary
E2
m2
Mary
John
sister his
m3
E3
John
Mary
sister
m4
E4
Mary
sister
John
his
</figure>
<figureCaption confidence="0.903067333333333">
Figure 1: Coreference process for the four mentions in Example (I). Mentions in a document are processed se-
quentially: first name mentions, then nominal mentions, and then pronominal mentions. A dashed arrow signifies
that a new entity is created, while a solid arrow means that the current mention is linked with an existing entity.
</figureCaption>
<bodyText confidence="0.9954995">
ation model Pc(·|Et, mt). Denote the score for ac-
tion at by S(at|at−1
1 ), where dependency of at on
a1 through at−1 is emphasized. The coreference re-
sult corresponding to the action sequence is written as
En({ai}ni=1). When it is clear from context, we will
drop {ai}ni=1 and write En only.
With this notation, the score for a coreference out-
come En({ai}ni=1) is the product of individual scores
assigned to the corresponding action sequence {ai}ni=1,
and the best coreference result is the one with the high-
est score:
</bodyText>
<equation confidence="0.994479222222222">
En = arg max
En
S(at|at−1
1 ). (1)
Given n mentions, the number of all possible
entity outcomes is the Bell Number (Bell, 1934):
P� kn
B(n) = 1 k! . Exhaustive search is out of the
e k=0
</equation>
<bodyText confidence="0.9995448125">
question. Thus, we organize hypotheses into a Bell
Tree (Luo et al., 2004) and use a beam search with the
following pruning strategy: first, a maximum beam size
(typically 20) S is set, and we keep only the top S hy-
potheses; Second, a relative threshold r (we use 10−5)
is set to prune any hypothesis whose score divided by
the maximum score falls below the threshold.
To give an concrete example, we use the example
in Figure 1 again. The first step at t = 1 creates a
new entity and is therefore scored by Pc(1|{}, John);
the second step also creates an entity and is scored
by Pc(1|{John},Mary); the step t = 3, how-
ever, links sister with {Mary} and is scored by
Pl(1|{Mary}, sister); Similarly, the last step is
scored by Pl(1|{John},his). The score for this
coreference outcome is the product of the four num-
</bodyText>
<equation confidence="0.9340995">
bers:
n o
S( {John,his}, {Mary,sister} )
=Pc(1|{}, John)Pc(1|{John},Mary)·
Pl(1|{Mary}, sister)·
Pl(1|{John}, his). (2)
</equation>
<bodyText confidence="0.99936875">
Other coreference results for these four mentions can
be scored similarly. For example, if his at the last
step is linked with {Mary,sister}, the score would
be:
</bodyText>
<equation confidence="0.980259">
n o
S( {John},{Mary,sister,his} )
=Pc(1|{}, John)Pc(1|{John},Mary)·
Pl(1|{Mary}, sister)·
Pl(1|{Mary,sister}, his). (3)
</equation>
<bodyText confidence="0.999859611111111">
At testing time, (2) and (3), among other possible out-
comes, will be searched and compared, and the one
with the highest score will be output as the coreference
result.
Examples in (2) and (3) indicate that the link model
Pl(·|ej, mt) and creation model Pc(·|Et, mt) form an
integrated coreference system and are applied simul-
taneously at testing time. As will be shown in the next
section, features in the creation model Pc(·|Et, mt) can
be computed from their counterpart in the link model
Pl(·|ej, mt) under some mild constraints. So the two
models’ training procedures are tightly coupled. This
is different from (Ng and Cardie, 2002a; Ng, 2004)
where their anaphoricty models are trained indepen-
dently of the coreference model, and it is either used
as a pre-filter, or its output is used as features in the
coreference model. The creation model Pc(·|Et, mt)
proposed here bears similarity to the starting model
</bodyText>
<equation confidence="0.974416333333333">
S(En)
= arg max
{at}n1
n
Y
t=1
</equation>
<page confidence="0.978134">
75
</page>
<bodyText confidence="0.9995688">
in (Luo et al., 2004). But there is a crucial differ-
ence: the starting model in (Luo et al., 2004) is an
ad-hoc use of the link scores and is not learned auto-
matically, while Pc(·|Et, mt) is fully trained. Training
Pc(·|Et, mt) is covered in the next section.
</bodyText>
<sectionHeader confidence="0.993615" genericHeader="method">
3 Implementation
</sectionHeader>
<subsectionHeader confidence="0.999571">
3.1 Feature Structure
</subsectionHeader>
<bodyText confidence="0.9999745">
To implement the twin model, we adopt the log linear
or maximum entropy (MaxEnt) model (Berger et al.,
1996) for its flexibility of combining diverse sources of
information. The two models are of the form:
</bodyText>
<equation confidence="0.993691">
, (5)
Z(Et, mt)
</equation>
<bodyText confidence="0.90934821875">
where L and C are binary variables indicating either
mt is coreferential with ej, or mt is used to create a
new entity. Y (ej, mt) and Z(ej, mt) are normalization
factors to ensure that Pl(·|ej, mt) and Pc(·|Et, mt) are
probabilities; λk and νi are the weights for feature
gk(ej, mt, L) and hi(Et, mt, C), respectively. Once
the set of features functions are selected, algorithm
such as improved iterative scaling (Berger et al., 1996)
or sequential conditional generalized iterative scal-
ing (Goodman, 2002) can be used to find the optimal
parameter values of {λk} and {νi}.
Computing features {gk(ej, mt, ·)} for the link
model Pl(L|ej,mt) 2 is relatively straightforward:
given an entity ej and the current mention mt, we
just need to characterize things such as lexical similar-
ity, syntactic relationship, and/or semantic compatibil-
ity of the two. It is, however, very challenging to com-
pute the features {hi(Et, mt, ·)} for the creation model
Pc(·|Et, mt) since its conditioning includes a set of en-
tities Et, whose size grows as more and more mentions
are processed. The problem exists because the decision
of creating a new entity with mt has to be made after
examining all preceding entities. There is no reason-
able modeling assumption one can make to drop some
entities in the conditioning.
To overcome the difficulty, we impose the follow-
ing constraints on the features of the link and creation
2The link model is actually implemented as:
Pl(L|ej, mt) ,., max,,,, Ee� Pl(L|ej, m&apos;, mt). Some
features are computed on a pair of mentions (m&apos;, mt) while
some are computed at entity level. See (Luo and Zitouni,
2005) and (Daum´e III and Marcu, 2005).
</bodyText>
<equation confidence="0.930995">
model:
gk(ej, mt, L) =g(1)
k (ej, mt)g(2)
k (L) (6)
hi(Et, mt, C) =h1�1) ({gk1) (e, mt) : e  Et})·
h(2)
</equation>
<listItem confidence="0.677998666666667">
i (C), for some k. (7)
(6) states that a feature in the link model is separable
and can be written as a product of two functions: the
</listItem>
<equation confidence="0.902061625">
first one, g(1)
k (·, ·), is a binary function depending on
the conditioning part only; the second one, g(2)
k (·), is
an indicator function depending on the prediction part
L only. Like g(2)
k (·), h(2)
i (·) is also a binary indicator
function.
(7) implies that features in the creation model
are also separable; Moreover, the conditioning part
0) ({gk1) (e, mt) : e  Et}), also a binary function,
only depends on the function values of the set of link
features {g(1) k(e, mt) : e  Et} (for some k). In other
words, once {g(1)
k (e, mt) : e  Et} and C are known,
</equation>
<bodyText confidence="0.98193325">
we can compute hi(Et, mt, C) without actually com-
paring mt with any entity in Et. Using binary features
is a fairly mild constraint as non-binary features can be
replaced by a set of binary features through quantiza-
tion.
How fast h&amp;quot;�1) ({gk1)(e, mt) : e  Et}) can be com-
puted depends on how h(1)
i is defined. In most cases
– as will be shown in Section 3.2, it boils down test-
ing if any member in {g(1)
k (e, mt) : e  Et} is non-
zero; or counting how many non-zero members there
are in {g(1) k(e, mt) : e  Et}. Both are simple op-
erations that can be carried out quickly. Thus, the as-
sumption (7) makes it possible to compute efficiently
hi(Et, mt, C).
</bodyText>
<subsectionHeader confidence="0.985269">
3.2 Features in the Creation Model
</subsectionHeader>
<bodyText confidence="0.99999175">
We describe features used in our coreference system.
We will concentrate on features used in the creation
model since those in the link model can be found in
the literature (Soon et al., 2001; Ng and Cardie, 2002b;
Yang et al., 2003; Luo et al., 2004). In particular,
we show how features in the creation model can be
computed from a set of feature values from the link
model for a few example categories. Since g(2)
</bodyText>
<equation confidence="0.9915392">
k (·) and
h(2)
i (·) are simple indicator functions, we will focus on
gk (·, ·) and h(1)
(1) i (·).
</equation>
<subsectionHeader confidence="0.670895">
3.2.1 Lexical Features
</subsectionHeader>
<bodyText confidence="0.999893">
This set of features computes if two surface strings
(spellings of two mentions) match each other, and are
</bodyText>
<equation confidence="0.99159775">
Pl(L|ej,mt) =
� E �
exp k λkgk(ej, mt, L)
(4)
Y (ej, mt)
Pc(C|Et, mt) =
� E �
exp i νihi(Et, mt, C)
</equation>
<page confidence="0.838869">
76
</page>
<bodyText confidence="0.8254415">
applied to name and nominal mentions only. For the
link model, a lexical feature g(1)
</bodyText>
<equation confidence="0.673694">
k (ej, mt) is 1 if ej con-
</equation>
<bodyText confidence="0.9987658">
tains a mention matches mt, where a match can be ex-
act, partial, or one is an acronym of the other.
Since gk(ej, mt) is binary, one corresponding fea-
ture used in the creation model is the disjunction of the
values in the link model, or
</bodyText>
<equation confidence="0.999022666666667">
h(1)
i (Et, mt) = eEEt{g(1)
k (e, mt)}, (8)
</equation>
<bodyText confidence="0.9935506">
where  is a binary “or” operator. The intuition is that
if there is any mention in Et matching mt, then the
probability to create a new entity with mt should be
low; Conversely, if none of the mentions in Et matches
mt, then mt is likely to be the first mention of a new
entity.
Take t = 2 in Figure 1 as an example. There is
only one partially-established entity {John}, so E2 =
{John}, and m2 = Mary. The exact string match
feature g(1)
</bodyText>
<equation confidence="0.981779333333333">
em(·, ·) would be
g(1)
em({John}, Mary) = 0,
</equation>
<bodyText confidence="0.9232225">
and the corresponding string match feature in the cre-
ation model is
</bodyText>
<equation confidence="0.9375864">
h(1)
em({John}, Mary) = eEEt{g(1)
em(e, Mary)}
= 0.
Disjunction is not the only operation we can use.
Another possibility is counting how many times mt
matches mentions in Et, so (8) becomes:
{gk
(1)(e,mt)}],. (9)
eEEt
</equation>
<bodyText confidence="0.999664">
where Q[·� quantizes raw counts into bins.
</bodyText>
<subsectionHeader confidence="0.854252">
3.2.2 Attribute Features
</subsectionHeader>
<bodyText confidence="0.999996">
In the link model, features in this category compare
the properties of the current mention mt with that of an
entity ej. Properties of a mention or an entity, when-
ever applicable, include gender, number, entity type,
reflexivity of pronouns etc. Similar to what done in
the lexical feature, we again synthesize a feature in the
creation model by taking the disjunction of the corre-
sponding set of feature values in the link model, or
</bodyText>
<equation confidence="0.968144">
h(1)
i (Et, mt) = eEEt{g(1)
k (e, mt)},
where g(1)
k (e, mt) takes value 1 if entity e and mention
</equation>
<bodyText confidence="0.997569">
mt share the same property; Otherwise its value is 0.
The intuition is that if there is an entity having the same
property as the current mention, then the probability for
the current mention to be linked with the entity should
be higher than otherwise; Conversely, if none of the en-
tities in Et shares a property with the current mention,
the probability for the current mention to create a new
entity ought to be higher.
Consider the gender attribute at t = 4 in Fig-
</bodyText>
<equation confidence="0.970430428571429">
ure 1. Let g(1)
gender(·, ·) be the gender feature in the
link model, assume that we know the gender of John,
Mary and his. Then g(1)
gender({{John},his) is 1,
while g(1)
gender({Mary, sister}, his) is 0. There-
</equation>
<bodyText confidence="0.7997495">
fore, the gender feature for the creation model would
be
</bodyText>
<equation confidence="0.969983">
hge)e
dr(l{John},{Mary, sister}},his)
=0  1 = 1,
</equation>
<bodyText confidence="0.9956615">
which means that there is at least one mention which
has the same the gender of the current mention mt.
</bodyText>
<subsectionHeader confidence="0.800782">
3.2.3 Distance Feature
</subsectionHeader>
<bodyText confidence="0.946097875">
Distance feature needs special treatment: while it
makes sense to talk about the distance between a pair
of mentions, it is not immediately clear how to compute
the distance between a set of entities Et and a mention
mt. To this end, we compute the minimum distance be-
tween the entities and the current mention with respect
to a “fired” link feature, as follows.
For a particular feature g(1)
</bodyText>
<equation confidence="0.8144615">
k (·, ·) in the link model,
define the minimum distance to be
d(Et, mt; gk) = min{d(m, mt) : m  Et,
and gk(1) (m, mt) = 1}, (10)
</equation>
<bodyText confidence="0.999570727272727">
where d(m, mt) is the distance between mention mand
mt. The distance itself can be the number of tokens,
or the number of intervening mentions, or the number
of sentences. The minimum distance d(Et, mt; gk) is
quantized and represented as binary feature in the cre-
ation model. The idea here is to encode what is the
nearest place where a feature fires.
Again as an example, consider the gender attribute at
t = 4 in Figure 1. Assuming that d(m, mt) is the num-
ber of tokens. Since only John matches the gender of
his,
</bodyText>
<equation confidence="0.967594">
d(E4, m4; ggender) = 3.
</equation>
<bodyText confidence="0.99978125">
The number is then quantized and used as a binary fea-
ture to encode the information that “there is a mention
whose gender matches the current mention within in a
token distance range including 3.”
</bodyText>
<equation confidence="0.997863">
h(1)
i (Et, mt) = Q[
</equation>
<page confidence="0.839888">
77
</page>
<note confidence="0.466326">
Performance
</note>
<bodyText confidence="0.999777571428571">
In general, binary features in the link model which
measure the similarity between an entity and a mention
can be turned into features in the creation model in the
same manner as described in Section 3.2.1 and 3.2.2.
For example, syntactic features (Ng and Cardie, 2002b;
Luo and Zitouni, 2005) can be computed this way and
are used in our system.
</bodyText>
<sectionHeader confidence="0.999842" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999678">
4.1 Data and Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.9993729">
We report the experimental results on ACE 2005
data (NIST, 2005). The dataset consists of 599 doc-
uments from a rich and diversified sources, which in-
clude newswire articles, web logs, and Usenet posts,
transcription of broadcast news, broadcast conversa-
tions and telephone conversations. We reserve the last
16% documents of each source as the test set and use
the rest of the documents as the training set. Statistics
such as the number of documents, words, mentions and
entities of this data split is tabulated in Table 1.
</bodyText>
<table confidence="0.9992105">
DataSet #Docs #Words #Mentions #Entities
Training 499 253771 46646 16102
Test 100 45659 8178 2709
Total 599 299430 54824 18811
</table>
<tableCaption confidence="0.995236">
Table 1: Statistics of ACE 2005 data: number of docu-
</tableCaption>
<bodyText confidence="0.9606646875">
ments, words, mentions and entities in the training and
test set.
The link and creation model are trained at the same
time. Besides the basic feature categories described in
Section 3.2, we also compute composite features by
taking conjunctions of the basic features. Features are
selected by their counts with a threshold of 8.
ACE-Value is the official score reported in the ACE
task and will be used to report our coreference system’s
performance. Its detailed definition can be found in the
official evaluation document 3. Since ACE-Value is a
weighted metric measuring a coreference system’s rel-
ative value, and it is not sensitive to certain type of
errors (e.g., false-alarm entities if these entities con-
tain correct mentions), we also report results using un-
weighted entity F-measure.
</bodyText>
<subsectionHeader confidence="0.580561">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999085">
To compare the proposed twin model with simple
thresholding (Soon et al., 2001; Ng and Cardie, 2002b),
</bodyText>
<footnote confidence="0.99442">
3The official evaluation document can be found at:
www.nist.gov/speech/tests/ace/ace05/doc/
ace05-evalplan.v3.pdf.
</footnote>
<note confidence="0.551962">
Performances vs. Threshold
</note>
<figure confidence="0.982280928571429">
95
90
85
80
75
70
65
Baseline-EntF
Twin-EntF
Baseline-ACEVal
Twin-ACEVal
55
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Threshold
</figure>
<figureCaption confidence="0.998841">
Figure 2: Performance comparison between a thresh-
</figureCaption>
<bodyText confidence="0.90593025">
olding baseline and the twin-model: lines with square
points are the entity F-measure (x100) results; lines
with triangle points are ACE-Value (in %). Solid lines
are baseline while dashed lines are twin-model.
we first train our twin model. To simulate the thresh-
olding approach, a baseline coreference system is cre-
ated by replacing the creation model with a constant,
i.e.,
</bodyText>
<equation confidence="0.990809">
P,(1|Et, mt) = 0, (11)
</equation>
<bodyText confidence="0.99667">
where 0 is a number between 0 and 1. At testing time,
a new entity is created with score 0 when
</bodyText>
<equation confidence="0.684161">
Pi(1|ej, mt) &lt; 0, dej E Et.
</equation>
<bodyText confidence="0.99998819047619">
The decision rule simply implies that if the scores be-
tween the current mention mt and all candidate entities
ej E Et are below the threshold 0, a new entity will be
created.
Performance comparison between the baseline and
the twin-model is plotted in Figure 2. X-axis is the
threshold varying from 0.1 to 0.9 with a step size 0.1.
Two metrics are used to compare the results: two lines
with square data points are the entity F-measure results,
and two lines with triangle points are ACE-Value. Note
that performances for the twin-model are constant since
it does not use thresholding.
As shown in the graph, the twin-model (two dashed
lines) always outperforms the baseline (two solid
lines). A “bad” threshold impacts the entity F-measure
much more than ACE-Value, especially in the region
with high threshold value. Note that a large 0 will lead
to more false-alarm entities. The graph suggests that
ACE-Value is much less sensitive than the un-weighted
F-measure in measuring false-alarm errors. For exam-
ple, at 0 = 0.9, the baseline F-measure is 0.591 while
</bodyText>
<page confidence="0.961154">
60
78
</page>
<bodyText confidence="0.999970419354839">
the twin model F-measure is 0.848, a 43.5% difference;
On the other hand, the corresponding ACE-Values are
84.5% (baseline) vs. 88.4% (twin model), a mere 4.6%
relative difference. There are at least two reasons: first,
ACE-Value discounts importance of nominal and pro-
noun entities, so more nominal and pronoun entity er-
rors are not reflected in the metric; Second, ACE-Value
does not penalize false-alarm entities if they contain
correct mentions. The problem associated with ACE-
Value is the reason we include the entity F-measure re-
sults.
Another interesting observation is that an optimal
threshold for the entity F-measure is not necessarily op-
timal for ACE-Value, and vice versa: 0 = 0.3 is the
best threshold for the entity F-measure, while 0 = 0.5
is optimal for ACE-Value. This is highlighted in Ta-
ble 2, where row “B-opt-F” contains the best results op-
timizing the entity F-measure (at 0 = 0.3), row “B-opt-
AV” contains the best results optimizing ACE-Value (at
0 = 0.5), and the last line “Twin-model” contains the
results of the proposed twin-model. It is clear from
Table 2 that thresholding cannot be used to optimize
the entity F-measure and ACE-Value simultaneously.
A sub-optimal threshold could be detrimental to an un-
weighted metric such as the entity F-measure. The pro-
posed twin model eliminates the need for threshold-
ing, a benefit of using the principled creation model.
In practice, the optimal threshold is a free parameter
that has to be tuned every time when a task, dataset and
model changes. Thus the proposed twin model is more
portable when a task or dataset changes.
</bodyText>
<table confidence="0.9963585">
System F-measure ACE-Value
B-opt-F 84.7 87.5
B-opt-AV 81.1 88.0
Twin-model 84.8 88.4
</table>
<tableCaption confidence="0.79744175">
Table 2: Comparison between the thresholding base-
line and the twin model: optimal threshold depends on
performance metric. The proposed twin-model outper-
forms the baseline without tuning the free parameter.
</tableCaption>
<sectionHeader confidence="0.999972" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999951454545455">
Some earlier work (Lappin and Leass, 1994; Kennedy
and Boguraev, 1996) use heuristic to determine
whether a phrase is anaphoric or not. Bean and Riloff
(1999) extracts rules from non-anaphoric noun phrases
and noun phrases patterns, which are then applied to
test data to identify existential noun phrases. It is in-
tended as as pre-filtering step before a coreference res-
olution system is run. Ng and Cardie (2002a) trains a
separate anaphoricity classifier in addition to a corefer-
ence model. The anaphoricity classifier is applied as a
filter and only anaphoric mentions are later considered
by the coreference model. Ng (2004) studies what is
the best way to make use of anaphoricity information
and concludes that the constrained-based and globally-
optimized approach works the best. Poesio et al. (2004)
contains a good summary of recent research work on
discourse new or anaphoricity. Luo et al. (2004) uses
a start model to determine whether a mention is the
first one in a coreference chain, but it is computed ad
hoc without training. Nicolae and Nicolae (2006) con-
structs a graph where mentions are nodes and an edge
represents the likelihood two mentions are in an entity,
and then a graph-cut algorithm is employed to produce
final coreference results.
We take the view that determining whether an
anaphor is coreferential with any candidate antecedent
is part of the coreference process. But we do recog-
nize that the disparity between the two types of events:
while a coreferential relationship can be resolved by
examining the local context of the anaphor and its an-
tecedent, it is necessary to compare the anaphor with
all the preceding candidates before it can be declared
that it is not coreferential with any. Thus, a creation
component P,(·|Et, mt) is needed to model the second
type of events. A problem arising from the adoption of
the creation model is that it is very expensive to have
a conditional model depending on all preceding enti-
ties Et. To solve this problem, we adopt the MaxEnt
model and impose some reasonable constraints on the
feature functions, which makes it possible to synthe-
size features in the creation model from those of the
link model. The twin model components are intimately
trained and used simultaneously in our coreference sys-
tem.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999956916666667">
A twin-model is proposed for coreference resolution:
one link component computes how likely a mention is
coreferential with a candidate entity; the other compo-
nent, called creation model, computes the probability
that a mention is not coreferential with any candidate
entity. Log linear or MaxEnt approach is adopted for
building the two components. The twin components
are trained and used simultaneously in our coreference
system.
The creation model depends on all preceding enti-
ties and is often expensive to compute. We impose
some reasonable constraints on feature functions which
</bodyText>
<page confidence="0.993954">
79
</page>
<bodyText confidence="0.999919375">
makes it feasible to compute efficiently the features in
the creation model from a subset of link feature val-
ues. We test the proposed twin-model on the ACE 2005
data and the proposed model outperforms a threshold-
ing baseline. Moreover, it is observed that the optimal
threshold in the baseline depends on performance met-
ric, while the proposed model eliminates the need of
tuning the optimal threshold.
</bodyText>
<sectionHeader confidence="0.998935" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999968545454545">
This work was partially supported by the Defense Ad-
vanced Research Projects Agency under contract No.
HR0011-06-2-0001. The views and findings contained
in this material are those of the authors and do not
necessarily reflect the position or policy of the U.S.
government and no official endorsement should be in-
ferred.
I would like to thank Salim Roukos for helping to
improve the writing of the paper. Suggestions and com-
ments from three anonymous reviewers are also grate-
fully acknowledged.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999323449275362">
David L. Bean and Ellen Riloff. 1999. Corpus-based
identification of non-anaphoric noun phrases. In
Proc. ACL.
E.T. Bell. 1934. Exponential numbers. Amer. Math.
Monthly, pages 411–419.
Adam L. Berger, Stephen A. Della Pietra, and Vincent
J. Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistics, 22(1):39–71, March.
Hal Daum´e III and Daniel Marcu. 2005. A large-
scale exploration of effective global features for a
joint entity detection and tracking model. In Proc. of
HLT and EMNLP, pages 97–104, Vancouver, British
Columbia, Canada, October. Association for Com-
putational Linguistics.
Joshua Goodman. 2002. Sequential conditional gener-
alized iterative scaling. In Pro. of the 40th ACL.
Christopher Kennedy and Branimir Boguraev. 1996.
Anaphora for everyone: Pronominal anaphora reso-
lution without a parser. In Proceedings of COLING-
96 (16th International Conference on Computa-
tional Linguistics), Copenhagen,DK.
Shalom Lappin and Herbert J. Leass. 1994. An algo-
rithm for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4), December.
Xiaoqiang Luo and Imed Zitouni. 2005. Multi-
lingual coreference resolution with syntactic fea-
tures. In Proc. of Human Language Technology
(HLT)/Empirical Methods in Natural Language Pro-
cessing (EMNLP).
Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda
Kambhatla, and Salim Roukos. 2004. A mention-
synchronous coreference resolution algorithm based
on the bell tree. In Proc. ofACL.
Vincent Ng and Claire Cardie. 2002a. Identifying
anaphoric and non-anaphoric noun phrases to im-
prove coreference resolution. In Proceedings of
COLING.
Vincent Ng and Claire Cardie. 2002b. Improving ma-
chine learning approaches to coreference resolution.
In Proc. ofACL, pages 104–111.
Vincent Ng. 2004. Learning noun phrase anaphoric-
ity to improve conference resolution: Issues in rep-
resentation and optimization. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04), Main Volume, pages 151–158,
Barcelona, Spain, July.
Cristina Nicolae and Gabriel Nicolae. 2006. BEST-
CUT: A graph algorithm for coreference resolution.
In Proceedings of the 2006 Conference on Empiri-
cal Methods in Natural Language Processing, pages
275–283, Sydney, Australia, July. Association for
Computational Linguistics.
NIST. 2005. ACE 2005 evaluation.
www.nist.gov/speech/tests/ace/ace05/index.htm.
M. Poesio, O. Uryupina, R. Vieira, M. Alexandrov-
Kabadjov, and R. Goulart. 2004. Discourse-new de-
tectors for definite description resolution: A survey
and a preliminary proposal. In ACL 2004: Workshop
on Reference Resolution and its Applications, pages
47–54, Barcelona, Spain, July.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.
2001. A machine learning approach to coreference
resolution of noun phrases. Computational Linguis-
tics, 27(4):521–544.
Xiaofeng Yang, Guodong Zhou, Jian Su, and
Chew Lim Tan. 2003. Coreference resolution us-
ing competition learning approach. In Proc. of the
4181 ACL.
</reference>
<page confidence="0.998236">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.682178">
<title confidence="0.993503">Coreference or Not: A Twin Model for Coreference Resolution</title>
<author confidence="0.822075">Xiaoqiang</author>
<affiliation confidence="0.974939">IBM T.J. Watson Research</affiliation>
<address confidence="0.9048755">1101 Kitchawan Yorktown Heights, NY 10598,</address>
<abstract confidence="0.998757277777778">A twin-model is proposed for coreference resa modeling the coreferential relationship between an anaphor and candidate antecedent, and a component modeling the possibility that a phrase is not coreferential with any candidate antecedent. The creation model depends on all candidate antecedents and is often expensive to compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David L Bean</author>
<author>Ellen Riloff</author>
</authors>
<title>Corpus-based identification of non-anaphoric noun phrases.</title>
<date>1999</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="26222" citStr="Bean and Riloff (1999)" startWordPosition="4589" endWordPosition="4592">ameter that has to be tuned every time when a task, dataset and model changes. Thus the proposed twin model is more portable when a task or dataset changes. System F-measure ACE-Value B-opt-F 84.7 87.5 B-opt-AV 81.1 88.0 Twin-model 84.8 88.4 Table 2: Comparison between the thresholding baseline and the twin model: optimal threshold depends on performance metric. The proposed twin-model outperforms the baseline without tuning the free parameter. 5 Related Work Some earlier work (Lappin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimi</context>
</contexts>
<marker>Bean, Riloff, 1999</marker>
<rawString>David L. Bean and Ellen Riloff. 1999. Corpus-based identification of non-anaphoric noun phrases. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E T Bell</author>
</authors>
<title>Exponential numbers.</title>
<date>1934</date>
<journal>Amer. Math. Monthly,</journal>
<pages>411--419</pages>
<contexts>
<context position="9621" citStr="Bell, 1934" startWordPosition="1670" endWordPosition="1671"> score for action at by S(at|at−1 1 ), where dependency of at on a1 through at−1 is emphasized. The coreference result corresponding to the action sequence is written as En({ai}ni=1). When it is clear from context, we will drop {ai}ni=1 and write En only. With this notation, the score for a coreference outcome En({ai}ni=1) is the product of individual scores assigned to the corresponding action sequence {ai}ni=1, and the best coreference result is the one with the highest score: En = arg max En S(at|at−1 1 ). (1) Given n mentions, the number of all possible entity outcomes is the Bell Number (Bell, 1934): P� kn B(n) = 1 k! . Exhaustive search is out of the e k=0 question. Thus, we organize hypotheses into a Bell Tree (Luo et al., 2004) and use a beam search with the following pruning strategy: first, a maximum beam size (typically 20) S is set, and we keep only the top S hypotheses; Second, a relative threshold r (we use 10−5) is set to prune any hypothesis whose score divided by the maximum score falls below the threshold. To give an concrete example, we use the example in Figure 1 again. The first step at t = 1 creates a new entity and is therefore scored by Pc(1|{}, John); the second step </context>
</contexts>
<marker>Bell, 1934</marker>
<rawString>E.T. Bell. 1934. Exponential numbers. Amer. Math. Monthly, pages 411–419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="12254" citStr="Berger et al., 1996" startWordPosition="2120" endWordPosition="2123">t is either used as a pre-filter, or its output is used as features in the coreference model. The creation model Pc(·|Et, mt) proposed here bears similarity to the starting model S(En) = arg max {at}n1 n Y t=1 75 in (Luo et al., 2004). But there is a crucial difference: the starting model in (Luo et al., 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc(·|Et, mt) is fully trained. Training Pc(·|Et, mt) is covered in the next section. 3 Implementation 3.1 Feature Structure To implement the twin model, we adopt the log linear or maximum entropy (MaxEnt) model (Berger et al., 1996) for its flexibility of combining diverse sources of information. The two models are of the form: , (5) Z(Et, mt) where L and C are binary variables indicating either mt is coreferential with ej, or mt is used to create a new entity. Y (ej, mt) and Z(ej, mt) are normalization factors to ensure that Pl(·|ej, mt) and Pc(·|Et, mt) are probabilities; λk and νi are the weights for feature gk(ej, mt, L) and hi(Et, mt, C), respectively. Once the set of features functions are selected, algorithm such as improved iterative scaling (Berger et al., 1996) or sequential conditional generalized iterative sc</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A largescale exploration of effective global features for a joint entity detection and tracking model.</title>
<date>2005</date>
<booktitle>In Proc. of HLT and EMNLP,</booktitle>
<pages>97--104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2005. A largescale exploration of effective global features for a joint entity detection and tracking model. In Proc. of HLT and EMNLP, pages 97–104, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Sequential conditional generalized iterative scaling.</title>
<date>2002</date>
<booktitle>In Pro. of the 40th ACL.</booktitle>
<contexts>
<context position="12875" citStr="Goodman, 2002" startWordPosition="2227" endWordPosition="2228">s flexibility of combining diverse sources of information. The two models are of the form: , (5) Z(Et, mt) where L and C are binary variables indicating either mt is coreferential with ej, or mt is used to create a new entity. Y (ej, mt) and Z(ej, mt) are normalization factors to ensure that Pl(·|ej, mt) and Pc(·|Et, mt) are probabilities; λk and νi are the weights for feature gk(ej, mt, L) and hi(Et, mt, C), respectively. Once the set of features functions are selected, algorithm such as improved iterative scaling (Berger et al., 1996) or sequential conditional generalized iterative scaling (Goodman, 2002) can be used to find the optimal parameter values of {λk} and {νi}. Computing features {gk(ej, mt, ·)} for the link model Pl(L|ej,mt) 2 is relatively straightforward: given an entity ej and the current mention mt, we just need to characterize things such as lexical similarity, syntactic relationship, and/or semantic compatibility of the two. It is, however, very challenging to compute the features {hi(Et, mt, ·)} for the creation model Pc(·|Et, mt) since its conditioning includes a set of entities Et, whose size grows as more and more mentions are processed. The problem exists because the deci</context>
</contexts>
<marker>Goodman, 2002</marker>
<rawString>Joshua Goodman. 2002. Sequential conditional generalized iterative scaling. In Pro. of the 40th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Boguraev</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING96 (16th International Conference on Computational Linguistics), Copenhagen,DK.</booktitle>
<contexts>
<context position="26134" citStr="Kennedy and Boguraev, 1996" startWordPosition="4574" endWordPosition="4577">efit of using the principled creation model. In practice, the optimal threshold is a free parameter that has to be tuned every time when a task, dataset and model changes. Thus the proposed twin model is more portable when a task or dataset changes. System F-measure ACE-Value B-opt-F 84.7 87.5 B-opt-AV 81.1 88.0 Twin-model 84.8 88.4 Table 2: Comparison between the thresholding baseline and the twin model: optimal threshold depends on performance metric. The proposed twin-model outperforms the baseline without tuning the free parameter. 5 Related Work Some earlier work (Lappin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Christopher Kennedy and Branimir Boguraev. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of COLING96 (16th International Conference on Computational Linguistics), Copenhagen,DK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="26105" citStr="Lappin and Leass, 1994" startWordPosition="4570" endWordPosition="4573"> for thresholding, a benefit of using the principled creation model. In practice, the optimal threshold is a free parameter that has to be tuned every time when a task, dataset and model changes. Thus the proposed twin model is more portable when a task or dataset changes. System F-measure ACE-Value B-opt-F 84.7 87.5 B-opt-AV 81.1 88.0 Twin-model 84.8 88.4 Table 2: Comparison between the thresholding baseline and the twin model: optimal threshold depends on performance metric. The proposed twin-model outperforms the baseline without tuning the free parameter. 5 Related Work Some earlier work (Lappin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies wha</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert J. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4), December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Imed Zitouni</author>
</authors>
<title>Multilingual coreference resolution with syntactic features.</title>
<date>2005</date>
<booktitle>In Proc. of Human Language Technology (HLT)/Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="13989" citStr="Luo and Zitouni, 2005" startWordPosition="2415" endWordPosition="2418">f entities Et, whose size grows as more and more mentions are processed. The problem exists because the decision of creating a new entity with mt has to be made after examining all preceding entities. There is no reasonable modeling assumption one can make to drop some entities in the conditioning. To overcome the difficulty, we impose the following constraints on the features of the link and creation 2The link model is actually implemented as: Pl(L|ej, mt) ,., max,,,, Ee� Pl(L|ej, m&apos;, mt). Some features are computed on a pair of mentions (m&apos;, mt) while some are computed at entity level. See (Luo and Zitouni, 2005) and (Daum´e III and Marcu, 2005). model: gk(ej, mt, L) =g(1) k (ej, mt)g(2) k (L) (6) hi(Et, mt, C) =h1�1) ({gk1) (e, mt) : e  Et})· h(2) i (C), for some k. (7) (6) states that a feature in the link model is separable and can be written as a product of two functions: the first one, g(1) k (·, ·), is a binary function depending on the conditioning part only; the second one, g(2) k (·), is an indicator function depending on the prediction part L only. Like g(2) k (·), h(2) i (·) is also a binary indicator function. (7) implies that features in the creation model are also separable; Moreover, t</context>
<context position="20541" citStr="Luo and Zitouni, 2005" startWordPosition="3654" endWordPosition="3657">t) is the number of tokens. Since only John matches the gender of his, d(E4, m4; ggender) = 3. The number is then quantized and used as a binary feature to encode the information that “there is a mention whose gender matches the current mention within in a token distance range including 3.” h(1) i (Et, mt) = Q[ 77 Performance In general, binary features in the link model which measure the similarity between an entity and a mention can be turned into features in the creation model in the same manner as described in Section 3.2.1 and 3.2.2. For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system. 4 Experiments 4.1 Data and Evaluation Metric We report the experimental results on ACE 2005 data (NIST, 2005). The dataset consists of 599 documents from a rich and diversified sources, which include newswire articles, web logs, and Usenet posts, transcription of broadcast news, broadcast conversations and telephone conversations. We reserve the last 16% documents of each source as the test set and use the rest of the documents as the training set. Statistics such as the number of documents, words, mentions and entities of this data split i</context>
</contexts>
<marker>Luo, Zitouni, 2005</marker>
<rawString>Xiaoqiang Luo and Imed Zitouni. 2005. Multilingual coreference resolution with syntactic features. In Proc. of Human Language Technology (HLT)/Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Salim Roukos</author>
</authors>
<title>A mentionsynchronous coreference resolution algorithm based on the bell tree.</title>
<date>2004</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="1182" citStr="Luo et al., 2004" startWordPosition="179" endWordPosition="182"> constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter. 1 Introduction Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document. In a typical machine learning-based coreference resolution system (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent. A related, but often overlooked, problem is that the anaphor may be noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and &apos;In this paper, “anaphor” includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases. there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in a coreference chain. I</context>
<context position="9755" citStr="Luo et al., 2004" startWordPosition="1696" endWordPosition="1699">ding to the action sequence is written as En({ai}ni=1). When it is clear from context, we will drop {ai}ni=1 and write En only. With this notation, the score for a coreference outcome En({ai}ni=1) is the product of individual scores assigned to the corresponding action sequence {ai}ni=1, and the best coreference result is the one with the highest score: En = arg max En S(at|at−1 1 ). (1) Given n mentions, the number of all possible entity outcomes is the Bell Number (Bell, 1934): P� kn B(n) = 1 k! . Exhaustive search is out of the e k=0 question. Thus, we organize hypotheses into a Bell Tree (Luo et al., 2004) and use a beam search with the following pruning strategy: first, a maximum beam size (typically 20) S is set, and we keep only the top S hypotheses; Second, a relative threshold r (we use 10−5) is set to prune any hypothesis whose score divided by the maximum score falls below the threshold. To give an concrete example, we use the example in Figure 1 again. The first step at t = 1 creates a new entity and is therefore scored by Pc(1|{}, John); the second step also creates an entity and is scored by Pc(1|{John},Mary); the step t = 3, however, links sister with {Mary} and is scored by Pl(1|{Ma</context>
<context position="11868" citStr="Luo et al., 2004" startWordPosition="2052" endWordPosition="2055"> will be shown in the next section, features in the creation model Pc(·|Et, mt) can be computed from their counterpart in the link model Pl(·|ej, mt) under some mild constraints. So the two models’ training procedures are tightly coupled. This is different from (Ng and Cardie, 2002a; Ng, 2004) where their anaphoricty models are trained independently of the coreference model, and it is either used as a pre-filter, or its output is used as features in the coreference model. The creation model Pc(·|Et, mt) proposed here bears similarity to the starting model S(En) = arg max {at}n1 n Y t=1 75 in (Luo et al., 2004). But there is a crucial difference: the starting model in (Luo et al., 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc(·|Et, mt) is fully trained. Training Pc(·|Et, mt) is covered in the next section. 3 Implementation 3.1 Feature Structure To implement the twin model, we adopt the log linear or maximum entropy (MaxEnt) model (Berger et al., 1996) for its flexibility of combining diverse sources of information. The two models are of the form: , (5) Z(Et, mt) where L and C are binary variables indicating either mt is coreferential with ej, or mt is used to c</context>
<context position="15772" citStr="Luo et al., 2004" startWordPosition="2766" endWordPosition="2769"> – as will be shown in Section 3.2, it boils down testing if any member in {g(1) k (e, mt) : e  Et} is nonzero; or counting how many non-zero members there are in {g(1) k(e, mt) : e  Et}. Both are simple operations that can be carried out quickly. Thus, the assumption (7) makes it possible to compute efficiently hi(Et, mt, C). 3.2 Features in the Creation Model We describe features used in our coreference system. We will concentrate on features used in the creation model since those in the link model can be found in the literature (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004). In particular, we show how features in the creation model can be computed from a set of feature values from the link model for a few example categories. Since g(2) k (·) and h(2) i (·) are simple indicator functions, we will focus on gk (·, ·) and h(1) (1) i (·). 3.2.1 Lexical Features This set of features computes if two surface strings (spellings of two mentions) match each other, and are Pl(L|ej,mt) = � E � exp k λkgk(ej, mt, L) (4) Y (ej, mt) Pc(C|Et, mt) = � E � exp i νihi(Et, mt, C) 76 applied to name and nominal mentions only. For the link model, a lexical feature g(1) k (ej, mt) is 1</context>
<context position="26971" citStr="Luo et al. (2004)" startWordPosition="4709" endWordPosition="4712">al noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is computed ad hoc without training. Nicolae and Nicolae (2006) constructs a graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then a graph-cut algorithm is employed to produce final coreference results. We take the view that determining whether an anaphor is coreferential with any candidate antecedent is part of the coreference process. But we do recognize that the disparity between the two types of events: while a coreferential relationship </context>
</contexts>
<marker>Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004</marker>
<rawString>Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mentionsynchronous coreference resolution algorithm based on the bell tree. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="1143" citStr="Ng and Cardie, 2002" startWordPosition="171" endWordPosition="174"> is often expensive to compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter. 1 Introduction Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document. In a typical machine learning-based coreference resolution system (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent. A related, but often overlooked, problem is that the anaphor may be noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and &apos;In this paper, “anaphor” includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases. there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to proc</context>
<context position="2476" citStr="Ng and Cardie, 2002" startWordPosition="403" endWordPosition="406">sholding the scores returned by the coreference model. That is, if the maximum coreference score is below a threshold, then the anaphor is deemed non-referential to any candidate antecedent. The threshold approach does not model noncoreferential events directly, and is by no means the optimal approach to the problem. It also introduces a free parameter which has to be set by trial-and-error. As an improvement, Ng and Cardie (2002a) and Ng (2004) train a separate model to classify an anaphor as either anaphoric or non-anaphoric. The output of this classifier can be used either as a pre-filter (Ng and Cardie, 2002a) so that non-anaphoric anaphors will not be precessed in the coreference system, or as a set of features in the coreference model (Ng, 2004). By rejecting any anaphor classified as non-anaphoric in coreference resolution, the filtering approach is meant to handle nonanaphoric phrases (i.e., no antecedent exists in the discourse under consideration), not the first mention in a coreference chain. In this paper, coreference is viewed as a process of sequential operations on anaphor mentions: an anaphor can either be linked with its antecedent if the antecedent is available or present. If the an</context>
<context position="11533" citStr="Ng and Cardie, 2002" startWordPosition="1992" endWordPosition="1995">2) and (3), among other possible outcomes, will be searched and compared, and the one with the highest score will be output as the coreference result. Examples in (2) and (3) indicate that the link model Pl(·|ej, mt) and creation model Pc(·|Et, mt) form an integrated coreference system and are applied simultaneously at testing time. As will be shown in the next section, features in the creation model Pc(·|Et, mt) can be computed from their counterpart in the link model Pl(·|ej, mt) under some mild constraints. So the two models’ training procedures are tightly coupled. This is different from (Ng and Cardie, 2002a; Ng, 2004) where their anaphoricty models are trained independently of the coreference model, and it is either used as a pre-filter, or its output is used as features in the coreference model. The creation model Pc(·|Et, mt) proposed here bears similarity to the starting model S(En) = arg max {at}n1 n Y t=1 75 in (Luo et al., 2004). But there is a crucial difference: the starting model in (Luo et al., 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc(·|Et, mt) is fully trained. Training Pc(·|Et, mt) is covered in the next section. 3 Implementation 3.1 Featu</context>
<context position="15733" citStr="Ng and Cardie, 2002" startWordPosition="2758" endWordPosition="2761">s on how h(1) i is defined. In most cases – as will be shown in Section 3.2, it boils down testing if any member in {g(1) k (e, mt) : e  Et} is nonzero; or counting how many non-zero members there are in {g(1) k(e, mt) : e  Et}. Both are simple operations that can be carried out quickly. Thus, the assumption (7) makes it possible to compute efficiently hi(Et, mt, C). 3.2 Features in the Creation Model We describe features used in our coreference system. We will concentrate on features used in the creation model since those in the link model can be found in the literature (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004). In particular, we show how features in the creation model can be computed from a set of feature values from the link model for a few example categories. Since g(2) k (·) and h(2) i (·) are simple indicator functions, we will focus on gk (·, ·) and h(1) (1) i (·). 3.2.1 Lexical Features This set of features computes if two surface strings (spellings of two mentions) match each other, and are Pl(L|ej,mt) = � E � exp k λkgk(ej, mt, L) (4) Y (ej, mt) Pc(C|Et, mt) = � E � exp i νihi(Et, mt, C) 76 applied to name and nominal mentions only. For the link model,</context>
<context position="20516" citStr="Ng and Cardie, 2002" startWordPosition="3650" endWordPosition="3653">. Assuming that d(m, mt) is the number of tokens. Since only John matches the gender of his, d(E4, m4; ggender) = 3. The number is then quantized and used as a binary feature to encode the information that “there is a mention whose gender matches the current mention within in a token distance range including 3.” h(1) i (Et, mt) = Q[ 77 Performance In general, binary features in the link model which measure the similarity between an entity and a mention can be turned into features in the creation model in the same manner as described in Section 3.2.1 and 3.2.2. For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system. 4 Experiments 4.1 Data and Evaluation Metric We report the experimental results on ACE 2005 data (NIST, 2005). The dataset consists of 599 documents from a rich and diversified sources, which include newswire articles, web logs, and Usenet posts, transcription of broadcast news, broadcast conversations and telephone conversations. We reserve the last 16% documents of each source as the test set and use the rest of the documents as the training set. Statistics such as the number of documents, words, mentions and enti</context>
<context position="22249" citStr="Ng and Cardie, 2002" startWordPosition="3937" endWordPosition="3940">ted by their counts with a threshold of 8. ACE-Value is the official score reported in the ACE task and will be used to report our coreference system’s performance. Its detailed definition can be found in the official evaluation document 3. Since ACE-Value is a weighted metric measuring a coreference system’s relative value, and it is not sensitive to certain type of errors (e.g., false-alarm entities if these entities contain correct mentions), we also report results using unweighted entity F-measure. 4.2 Results To compare the proposed twin model with simple thresholding (Soon et al., 2001; Ng and Cardie, 2002b), 3The official evaluation document can be found at: www.nist.gov/speech/tests/ace/ace05/doc/ ace05-evalplan.v3.pdf. Performances vs. Threshold 95 90 85 80 75 70 65 Baseline-EntF Twin-EntF Baseline-ACEVal Twin-ACEVal 55 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Threshold Figure 2: Performance comparison between a thresholding baseline and the twin-model: lines with square points are the entity F-measure (x100) results; lines with triangle points are ACE-Value (in %). Solid lines are baseline while dashed lines are twin-model. we first train our twin model. To simulate the thresholding approach, a </context>
<context position="26477" citStr="Ng and Cardie (2002" startWordPosition="4631" endWordPosition="4634">son between the thresholding baseline and the twin model: optimal threshold depends on performance metric. The proposed twin-model outperforms the baseline without tuning the free parameter. 5 Related Work Some earlier work (Lappin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is comp</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002a. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proc. ofACL,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="1143" citStr="Ng and Cardie, 2002" startWordPosition="171" endWordPosition="174"> is often expensive to compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter. 1 Introduction Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document. In a typical machine learning-based coreference resolution system (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent. A related, but often overlooked, problem is that the anaphor may be noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and &apos;In this paper, “anaphor” includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases. there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to proc</context>
<context position="2476" citStr="Ng and Cardie, 2002" startWordPosition="403" endWordPosition="406">sholding the scores returned by the coreference model. That is, if the maximum coreference score is below a threshold, then the anaphor is deemed non-referential to any candidate antecedent. The threshold approach does not model noncoreferential events directly, and is by no means the optimal approach to the problem. It also introduces a free parameter which has to be set by trial-and-error. As an improvement, Ng and Cardie (2002a) and Ng (2004) train a separate model to classify an anaphor as either anaphoric or non-anaphoric. The output of this classifier can be used either as a pre-filter (Ng and Cardie, 2002a) so that non-anaphoric anaphors will not be precessed in the coreference system, or as a set of features in the coreference model (Ng, 2004). By rejecting any anaphor classified as non-anaphoric in coreference resolution, the filtering approach is meant to handle nonanaphoric phrases (i.e., no antecedent exists in the discourse under consideration), not the first mention in a coreference chain. In this paper, coreference is viewed as a process of sequential operations on anaphor mentions: an anaphor can either be linked with its antecedent if the antecedent is available or present. If the an</context>
<context position="11533" citStr="Ng and Cardie, 2002" startWordPosition="1992" endWordPosition="1995">2) and (3), among other possible outcomes, will be searched and compared, and the one with the highest score will be output as the coreference result. Examples in (2) and (3) indicate that the link model Pl(·|ej, mt) and creation model Pc(·|Et, mt) form an integrated coreference system and are applied simultaneously at testing time. As will be shown in the next section, features in the creation model Pc(·|Et, mt) can be computed from their counterpart in the link model Pl(·|ej, mt) under some mild constraints. So the two models’ training procedures are tightly coupled. This is different from (Ng and Cardie, 2002a; Ng, 2004) where their anaphoricty models are trained independently of the coreference model, and it is either used as a pre-filter, or its output is used as features in the coreference model. The creation model Pc(·|Et, mt) proposed here bears similarity to the starting model S(En) = arg max {at}n1 n Y t=1 75 in (Luo et al., 2004). But there is a crucial difference: the starting model in (Luo et al., 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc(·|Et, mt) is fully trained. Training Pc(·|Et, mt) is covered in the next section. 3 Implementation 3.1 Featu</context>
<context position="15733" citStr="Ng and Cardie, 2002" startWordPosition="2758" endWordPosition="2761">s on how h(1) i is defined. In most cases – as will be shown in Section 3.2, it boils down testing if any member in {g(1) k (e, mt) : e  Et} is nonzero; or counting how many non-zero members there are in {g(1) k(e, mt) : e  Et}. Both are simple operations that can be carried out quickly. Thus, the assumption (7) makes it possible to compute efficiently hi(Et, mt, C). 3.2 Features in the Creation Model We describe features used in our coreference system. We will concentrate on features used in the creation model since those in the link model can be found in the literature (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004). In particular, we show how features in the creation model can be computed from a set of feature values from the link model for a few example categories. Since g(2) k (·) and h(2) i (·) are simple indicator functions, we will focus on gk (·, ·) and h(1) (1) i (·). 3.2.1 Lexical Features This set of features computes if two surface strings (spellings of two mentions) match each other, and are Pl(L|ej,mt) = � E � exp k λkgk(ej, mt, L) (4) Y (ej, mt) Pc(C|Et, mt) = � E � exp i νihi(Et, mt, C) 76 applied to name and nominal mentions only. For the link model,</context>
<context position="20516" citStr="Ng and Cardie, 2002" startWordPosition="3650" endWordPosition="3653">. Assuming that d(m, mt) is the number of tokens. Since only John matches the gender of his, d(E4, m4; ggender) = 3. The number is then quantized and used as a binary feature to encode the information that “there is a mention whose gender matches the current mention within in a token distance range including 3.” h(1) i (Et, mt) = Q[ 77 Performance In general, binary features in the link model which measure the similarity between an entity and a mention can be turned into features in the creation model in the same manner as described in Section 3.2.1 and 3.2.2. For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system. 4 Experiments 4.1 Data and Evaluation Metric We report the experimental results on ACE 2005 data (NIST, 2005). The dataset consists of 599 documents from a rich and diversified sources, which include newswire articles, web logs, and Usenet posts, transcription of broadcast news, broadcast conversations and telephone conversations. We reserve the last 16% documents of each source as the test set and use the rest of the documents as the training set. Statistics such as the number of documents, words, mentions and enti</context>
<context position="22249" citStr="Ng and Cardie, 2002" startWordPosition="3937" endWordPosition="3940">ted by their counts with a threshold of 8. ACE-Value is the official score reported in the ACE task and will be used to report our coreference system’s performance. Its detailed definition can be found in the official evaluation document 3. Since ACE-Value is a weighted metric measuring a coreference system’s relative value, and it is not sensitive to certain type of errors (e.g., false-alarm entities if these entities contain correct mentions), we also report results using unweighted entity F-measure. 4.2 Results To compare the proposed twin model with simple thresholding (Soon et al., 2001; Ng and Cardie, 2002b), 3The official evaluation document can be found at: www.nist.gov/speech/tests/ace/ace05/doc/ ace05-evalplan.v3.pdf. Performances vs. Threshold 95 90 85 80 75 70 65 Baseline-EntF Twin-EntF Baseline-ACEVal Twin-ACEVal 55 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Threshold Figure 2: Performance comparison between a thresholding baseline and the twin-model: lines with square points are the entity F-measure (x100) results; lines with triangle points are ACE-Value (in %). Solid lines are baseline while dashed lines are twin-model. we first train our twin model. To simulate the thresholding approach, a </context>
<context position="26477" citStr="Ng and Cardie (2002" startWordPosition="4631" endWordPosition="4634">son between the thresholding baseline and the twin model: optimal threshold depends on performance metric. The proposed twin-model outperforms the baseline without tuning the free parameter. 5 Related Work Some earlier work (Lappin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is comp</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002b. Improving machine learning approaches to coreference resolution. In Proc. ofACL, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>151--158</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="2306" citStr="Ng (2004)" startWordPosition="375" endWordPosition="376">anaphor is the first mention (relative to processing order) in a coreference chain. In (Soon et al., 2001; Ng and Cardie, 2002b), the problem is treated by thresholding the scores returned by the coreference model. That is, if the maximum coreference score is below a threshold, then the anaphor is deemed non-referential to any candidate antecedent. The threshold approach does not model noncoreferential events directly, and is by no means the optimal approach to the problem. It also introduces a free parameter which has to be set by trial-and-error. As an improvement, Ng and Cardie (2002a) and Ng (2004) train a separate model to classify an anaphor as either anaphoric or non-anaphoric. The output of this classifier can be used either as a pre-filter (Ng and Cardie, 2002a) so that non-anaphoric anaphors will not be precessed in the coreference system, or as a set of features in the coreference model (Ng, 2004). By rejecting any anaphor classified as non-anaphoric in coreference resolution, the filtering approach is meant to handle nonanaphoric phrases (i.e., no antecedent exists in the discourse under consideration), not the first mention in a coreference chain. In this paper, coreference is </context>
<context position="11545" citStr="Ng, 2004" startWordPosition="1996" endWordPosition="1997">r possible outcomes, will be searched and compared, and the one with the highest score will be output as the coreference result. Examples in (2) and (3) indicate that the link model Pl(·|ej, mt) and creation model Pc(·|Et, mt) form an integrated coreference system and are applied simultaneously at testing time. As will be shown in the next section, features in the creation model Pc(·|Et, mt) can be computed from their counterpart in the link model Pl(·|ej, mt) under some mild constraints. So the two models’ training procedures are tightly coupled. This is different from (Ng and Cardie, 2002a; Ng, 2004) where their anaphoricty models are trained independently of the coreference model, and it is either used as a pre-filter, or its output is used as features in the coreference model. The creation model Pc(·|Et, mt) proposed here bears similarity to the starting model S(En) = arg max {at}n1 n Y t=1 75 in (Luo et al., 2004). But there is a crucial difference: the starting model in (Luo et al., 2004) is an ad-hoc use of the link scores and is not learned automatically, while Pc(·|Et, mt) is fully trained. Training Pc(·|Et, mt) is covered in the next section. 3 Implementation 3.1 Feature Structure</context>
<context position="26693" citStr="Ng (2004)" startWordPosition="4666" endWordPosition="4667">appin and Leass, 1994; Kennedy and Boguraev, 1996) use heuristic to determine whether a phrase is anaphoric or not. Bean and Riloff (1999) extracts rules from non-anaphoric noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is computed ad hoc without training. Nicolae and Nicolae (2006) constructs a graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then a graph-cut algorithm is employed to </context>
</contexts>
<marker>Ng, 2004</marker>
<rawString>Vincent Ng. 2004. Learning noun phrase anaphoricity to improve conference resolution: Issues in representation and optimization. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 151–158, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
</authors>
<title>BESTCUT: A graph algorithm for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>275--283</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="27133" citStr="Nicolae and Nicolae (2006)" startWordPosition="4738" endWordPosition="4741">ity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is computed ad hoc without training. Nicolae and Nicolae (2006) constructs a graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then a graph-cut algorithm is employed to produce final coreference results. We take the view that determining whether an anaphor is coreferential with any candidate antecedent is part of the coreference process. But we do recognize that the disparity between the two types of events: while a coreferential relationship can be resolved by examining the local context of the anaphor and its antecedent, it is necessary to compare the anaphor with all the preceding candidates before </context>
</contexts>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Cristina Nicolae and Gabriel Nicolae. 2006. BESTCUT: A graph algorithm for coreference resolution. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 275–283, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<date>2005</date>
<publisher>ACE</publisher>
<note>evaluation. www.nist.gov/speech/tests/ace/ace05/index.htm.</note>
<contexts>
<context position="3811" citStr="NIST, 2005" startWordPosition="615" endWordPosition="616">he two types of operations, a twin-model is proposed to resolve coreferential relationships in a document. The first component is a statistical model measuring how likely an anaphor is coreferential to a candidate antecedent; The second one explicitly models the non73 Proceedings of NAACL HLT 2007, pages 73–80, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics coreferential events. Both models are trained automatically and are used simultaneously in the coreference system. The twin-model coreference system is tested on the 2005 ACE (Automatic Content Extraction, see (NIST, 2005)) data and the best performance under both ACE-Value and entity F-measure can be obtained without tuning a free parameter. The rest of the paper is organized as follows. The twin-model is presented in Section 2. A maximumentropy implementation and features are then presented in Section 3. The experimental results on the 2005 ACE data is presented in Section 4. The proposed twinmodel is compared with related work in Section 5 before the paper is concluded. 2 Coreference Model A phrasal reference to an entity is called a mention. A set of mentions referring to the same physical object is said to</context>
<context position="20704" citStr="NIST, 2005" startWordPosition="3685" endWordPosition="3686">tion that “there is a mention whose gender matches the current mention within in a token distance range including 3.” h(1) i (Et, mt) = Q[ 77 Performance In general, binary features in the link model which measure the similarity between an entity and a mention can be turned into features in the creation model in the same manner as described in Section 3.2.1 and 3.2.2. For example, syntactic features (Ng and Cardie, 2002b; Luo and Zitouni, 2005) can be computed this way and are used in our system. 4 Experiments 4.1 Data and Evaluation Metric We report the experimental results on ACE 2005 data (NIST, 2005). The dataset consists of 599 documents from a rich and diversified sources, which include newswire articles, web logs, and Usenet posts, transcription of broadcast news, broadcast conversations and telephone conversations. We reserve the last 16% documents of each source as the test set and use the rest of the documents as the training set. Statistics such as the number of documents, words, mentions and entities of this data split is tabulated in Table 1. DataSet #Docs #Words #Mentions #Entities Training 499 253771 46646 16102 Test 100 45659 8178 2709 Total 599 299430 54824 18811 Table 1: Sta</context>
</contexts>
<marker>NIST, 2005</marker>
<rawString>NIST. 2005. ACE 2005 evaluation. www.nist.gov/speech/tests/ace/ace05/index.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>O Uryupina</author>
<author>R Vieira</author>
<author>M AlexandrovKabadjov</author>
<author>R Goulart</author>
</authors>
<title>Discourse-new detectors for definite description resolution: A survey and a preliminary proposal.</title>
<date>2004</date>
<booktitle>In ACL 2004: Workshop on Reference Resolution and its Applications,</booktitle>
<pages>47--54</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="26871" citStr="Poesio et al. (2004)" startWordPosition="4692" endWordPosition="4695">horic noun phrases and noun phrases patterns, which are then applied to test data to identify existential noun phrases. It is intended as as pre-filtering step before a coreference resolution system is run. Ng and Cardie (2002a) trains a separate anaphoricity classifier in addition to a coreference model. The anaphoricity classifier is applied as a filter and only anaphoric mentions are later considered by the coreference model. Ng (2004) studies what is the best way to make use of anaphoricity information and concludes that the constrained-based and globallyoptimized approach works the best. Poesio et al. (2004) contains a good summary of recent research work on discourse new or anaphoricity. Luo et al. (2004) uses a start model to determine whether a mention is the first one in a coreference chain, but it is computed ad hoc without training. Nicolae and Nicolae (2006) constructs a graph where mentions are nodes and an edge represents the likelihood two mentions are in an entity, and then a graph-cut algorithm is employed to produce final coreference results. We take the view that determining whether an anaphor is coreferential with any candidate antecedent is part of the coreference process. But we </context>
</contexts>
<marker>Poesio, Uryupina, Vieira, AlexandrovKabadjov, Goulart, 2004</marker>
<rawString>M. Poesio, O. Uryupina, R. Vieira, M. AlexandrovKabadjov, and R. Goulart. 2004. Discourse-new detectors for definite description resolution: A survey and a preliminary proposal. In ACL 2004: Workshop on Reference Resolution and its Applications, pages 47–54, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1122" citStr="Soon et al., 2001" startWordPosition="167" endWordPosition="170">ate antecedents and is often expensive to compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter. 1 Introduction Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document. In a typical machine learning-based coreference resolution system (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent. A related, but often overlooked, problem is that the anaphor may be noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and &apos;In this paper, “anaphor” includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases. there does not exist an antecedent in the discourse context, or an anaphor is the first ment</context>
<context position="15712" citStr="Soon et al., 2001" startWordPosition="2754" endWordPosition="2757"> be computed depends on how h(1) i is defined. In most cases – as will be shown in Section 3.2, it boils down testing if any member in {g(1) k (e, mt) : e  Et} is nonzero; or counting how many non-zero members there are in {g(1) k(e, mt) : e  Et}. Both are simple operations that can be carried out quickly. Thus, the assumption (7) makes it possible to compute efficiently hi(Et, mt, C). 3.2 Features in the Creation Model We describe features used in our coreference system. We will concentrate on features used in the creation model since those in the link model can be found in the literature (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004). In particular, we show how features in the creation model can be computed from a set of feature values from the link model for a few example categories. Since g(2) k (·) and h(2) i (·) are simple indicator functions, we will focus on gk (·, ·) and h(1) (1) i (·). 3.2.1 Lexical Features This set of features computes if two surface strings (spellings of two mentions) match each other, and are Pl(L|ej,mt) = � E � exp k λkgk(ej, mt, L) (4) Y (ej, mt) Pc(C|Et, mt) = � E � exp i νihi(Et, mt, C) 76 applied to name and nominal mentions only</context>
<context position="22228" citStr="Soon et al., 2001" startWordPosition="3933" endWordPosition="3936"> Features are selected by their counts with a threshold of 8. ACE-Value is the official score reported in the ACE task and will be used to report our coreference system’s performance. Its detailed definition can be found in the official evaluation document 3. Since ACE-Value is a weighted metric measuring a coreference system’s relative value, and it is not sensitive to certain type of errors (e.g., false-alarm entities if these entities contain correct mentions), we also report results using unweighted entity F-measure. 4.2 Results To compare the proposed twin model with simple thresholding (Soon et al., 2001; Ng and Cardie, 2002b), 3The official evaluation document can be found at: www.nist.gov/speech/tests/ace/ace05/doc/ ace05-evalplan.v3.pdf. Performances vs. Threshold 95 90 85 80 75 70 65 Baseline-EntF Twin-EntF Baseline-ACEVal Twin-ACEVal 55 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Threshold Figure 2: Performance comparison between a thresholding baseline and the twin-model: lines with square points are the entity F-measure (x100) results; lines with triangle points are ACE-Value (in %). Solid lines are baseline while dashed lines are twin-model. we first train our twin model. To simulate the thre</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Guodong Zhou</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Coreference resolution using competition learning approach.</title>
<date>2003</date>
<booktitle>In Proc. of the 4181 ACL.</booktitle>
<contexts>
<context position="1163" citStr="Yang et al., 2003" startWordPosition="175" endWordPosition="178"> compute; Therefore constraints are imposed on feature forms so that features in the creation model can be efficiently computed from feature values in the link model. The proposed twin-model is tested on the data from the 2005 Automatic Content Extraction (ACE) task and the proposed model performs better than a thresholding baseline without tuning free parameter. 1 Introduction Coreference resolution aims to find multiple mentions of an entity (e.g., PERSON, ORGANIZATION) in a document. In a typical machine learning-based coreference resolution system (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004), a statistical model is learned from training data and is used to measure how likely an anaphor 1 is coreferential to a candidate antecedent. A related, but often overlooked, problem is that the anaphor may be noncoreferential to any candidate, which arises from scenarios such as an identified anaphor is truly generic and &apos;In this paper, “anaphor” includes all kinds of phrases to be resolved, which can be named, nominal or pronominal phrases. there does not exist an antecedent in the discourse context, or an anaphor is the first mention (relative to processing order) in a c</context>
<context position="15753" citStr="Yang et al., 2003" startWordPosition="2762" endWordPosition="2765">ined. In most cases – as will be shown in Section 3.2, it boils down testing if any member in {g(1) k (e, mt) : e  Et} is nonzero; or counting how many non-zero members there are in {g(1) k(e, mt) : e  Et}. Both are simple operations that can be carried out quickly. Thus, the assumption (7) makes it possible to compute efficiently hi(Et, mt, C). 3.2 Features in the Creation Model We describe features used in our coreference system. We will concentrate on features used in the creation model since those in the link model can be found in the literature (Soon et al., 2001; Ng and Cardie, 2002b; Yang et al., 2003; Luo et al., 2004). In particular, we show how features in the creation model can be computed from a set of feature values from the link model for a few example categories. Since g(2) k (·) and h(2) i (·) are simple indicator functions, we will focus on gk (·, ·) and h(1) (1) i (·). 3.2.1 Lexical Features This set of features computes if two surface strings (spellings of two mentions) match each other, and are Pl(L|ej,mt) = � E � exp k λkgk(ej, mt, L) (4) Y (ej, mt) Pc(C|Et, mt) = � E � exp i νihi(Et, mt, C) 76 applied to name and nominal mentions only. For the link model, a lexical feature g</context>
</contexts>
<marker>Yang, Zhou, Su, Tan, 2003</marker>
<rawString>Xiaofeng Yang, Guodong Zhou, Jian Su, and Chew Lim Tan. 2003. Coreference resolution using competition learning approach. In Proc. of the 4181 ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>