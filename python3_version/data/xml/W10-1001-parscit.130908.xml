<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012444">
<title confidence="0.994553">
Readability Assessment for Text Simplification
</title>
<author confidence="0.999875">
Sandra Aluisio1, Lucia Specia2, Caroline Gasperin1 and Carolina Scarton1
</author>
<affiliation confidence="0.9956285">
1Center of Computational Linguistics (NILC) 2Research Group in Computational Linguistics
University of São Paulo University of Wolverhampton
</affiliation>
<address confidence="0.792839">
São Carlos - SP, Brazil Wolverhampton, UK
</address>
<email confidence="0.982916">
{sandra,cgasperin}@icmc.usp.br,
carol.scarton@gmail.com
</email>
<sectionHeader confidence="0.997128" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999893714285714">
We describe a readability assessment ap-
proach to support the process of text simplifi-
cation for poor literacy readers. Given an in-
put text, the goal is to predict its readability
level, which corresponds to the literacy level
that is expected from the target reader: rudi-
mentary, basic or advanced. We complement
features traditionally used for readability as-
sessment with a number of new features, and
experiment with alternative ways to model
this problem using machine learning methods,
namely classification, regression and ranking.
The best resulting model is embedded in an
authoring tool for Text Simplification.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999773888888889">
In Brazil, the National Indicator of Functional Lite-
racy (INAF) index has been computed annually
since 2001 to measure the levels of literacy of the
Brazilian population. The 2009 report presented a
worrying scenario: 7% of the individuals are illite-
rate; 21% are literate at the rudimentary level; 47%
are literate at the basic level; only 25% are literate
at the advanced level (INAF, 2009). These literacy
levels are defined as:
</bodyText>
<listItem confidence="0.98719">
(1) Illiterate: individuals who cannot perform
simple tasks such as reading words and phrases;
(2) Rudimentary: individuals who can find ex-
plicit information in short and familiar texts (such
as an advertisement or a short letter);
(3) Basic: individuals who are functionally lite-
rate, i.e., they can read and understand texts of av-
erage length, and find information even when it is
necessary to make some inference; and
(4) Advanced: fully literate individuals, who can
read longer texts, relating their parts, comparing
and interpreting information, distinguish fact from
opinion, make inferences and synthesize.
</listItem>
<page confidence="0.711571">
1
</page>
<email confidence="0.762981">
L.Specia@wlv.ac.uk
</email>
<bodyText confidence="0.999966081081081">
In order to promote digital inclusion and acces-
sibility for people with low levels of literacy, par-
ticularly to documents available on the web, it is
important to provide text in a simple and easy-to-
read way. This is a requirement of the Web Con-
tent Accessibility Guidelines 2.0’s principle of
comprehensibility and accessibility of Web con-
tent&apos;. It states that for texts which demand reading
skills more advanced than that of individuals with
lower secondary education, one should offer an al-
ternative version of the same content suitable for
those individuals. While readability formulas for
English have a long history – 200 formulas have
been reported from 1920 to 1980s (Dubay, 2004) –
the only tool available for Portuguese is an adapta-
tion of the Flesch Reading Ease index. It evaluates
the complexity of texts in a 4-level scale corres-
ponding to grade levels (Martins et al., 1996).
In the PorSimples project (Aluísio et al., 2008)
we develop text adaptation methods (via text sim-
plification and elaboration approaches) to improve
the comprehensibility of texts published on gov-
ernment websites or by renowned news agencies,
which are expected to be relevant to a large au-
dience with various literacy levels. The project
provides automatic simplification tools to aid (1)
poorly literate readers to understand online content
– a browser plug-in for automatically simplifying
websites – and (2) authors producing texts for this
audience – an authoring tool for guiding the crea-
tion of simplified versions of texts.
This paper focuses on a readability assessment
approach to assist the simplification process in the
authoring tool, SIMPLIFICA. The current version
of SIMPLIFICA offers simplification operations
addressing a number of lexical and syntactic phe-
nomena to make the text more readable. The au-
</bodyText>
<footnote confidence="0.954607">
1 http://www.w3.org/TR/WCAG20/
</footnote>
<note confidence="0.9926875">
Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 1–9,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999922461538462">
thor has the freedom to choose when and whether
to apply the available simplification operations, a
decision based on the level of complexity of the
current text and on the target reader.
A method for automatically identifying such
level of complexity is therefore of great value.
With our readability assessment tool, the author is
able to automatically check the complexi-
ty/readability level of the original text, as well as
modified versions of such text produced as he/she
applies simplification operations offered by
SIMPLIFICA, until the text reaches the expected
level, adequate for the target reader.
In this paper we present such readability as-
sessment tool, developed as part of the PorSimples
project, and discuss its application within the au-
thoring tool. Different from previous work, the tool
does not model text difficulty according to linear
grade levels (e.g., Heilman et al., 2008), but in-
stead maps the text into the three levels of literacy
defined by INAF: rudimentary, basic or advanced.
Moreover, it uses a more comprehensive set of fea-
tures, different learning techniques and targets a
new language and application, as we discuss in
Section 4. More specifically, we address the fol-
lowing research questions:
</bodyText>
<listItem confidence="0.986101166666667">
1. Given some training material, is it possible to
detect the complexity level of Portuguese texts,
which corresponds to the different literacy levels
defined by INAF?
2. What is the best way to model this problem
and which features are relevant?
</listItem>
<bodyText confidence="0.999781625">
We experiment with nominal, ordinal and interval-
based modeling techniques and exploit a number
of the cognitively motivated features proposed by
Coh-Metrix 2.0 (Graesser et al., 2004) and adapted
to Portuguese (called Coh-Metrix-PORT), along
with a set of new features, including syntactic fea-
tures to capture simplification operations and n-
gram language model features.
In the remainder of this paper, we first provide
some background information on the need for a
readability assessment tool within our text simpli-
fication system (Section 2) and discuss prior work
on readability assessment (Section 3), to then
present our features and modeling techniques (Sec-
tion 4) and the experiments performed to answer
our research questions (Section 5).
</bodyText>
<sectionHeader confidence="0.840369" genericHeader="method">
2. Text Simplification in PorSimples
</sectionHeader>
<bodyText confidence="0.999457822222222">
Text Simplification (TS) aims to maximize reading
comprehension of written texts through their sim-
plification. Simplification usually involves substi-
tuting complex by simpler words and breaking
down and changing the syntax of complex, long
sentences (Max, 2006; Siddharthan, 2003).
To meet the needs of people with different le-
vels of literacy, in the PorSimples project we pro-
pose two types of simplification: natural and
strong. The first type results in texts adequate for
people with a basic literacy level and the second,
rudimentary level. The difference between these
two is the degree of application of simplification
operations to complex sentences. In strong simpli-
fication, operations are applied to all complex syn-
tactic phenomena present in the text in order to
make it as simple as possible, while in natural sim-
plification these operations are applied selectively,
only when the resulting text remains “natural”.
One example of original text (a), along with its
natural (b) and strong (c) manual simplifications, is
given in Table 1.
The cinema theaters around the world were show-
ing a production by director Joe Dante in which a
shoal of piranhas escaped from a military laborato-
ry and attacked participants of an aquatic show.
(...) More than 20 people were bitten by palometas
(Serrasalmus spilopleura, a species of piranhas)
that live in the waters of the Sanchuri dam.
The cinema theaters around the world were show-
ing a production by director Joe Dante. In the pro-
duction a shoal of piranhas escaped from a military
laboratory and attacked participants of an aquatic
show. (...) More than 20 people were bitten by pa-
lometas that live in the waters of the Sanchuri dam.
Palometas are Serrasalmus spilopleura, a species
of piranhas.
The cinema theaters around the world were show-
ing a movie by director Joe Dante. In the movie a
shoal of piranhas escaped from a military laborato-
ry. The shoal of piranhas attacked participants of
an aquatic show. (...). Palometas have bitten more
than 20 people. Palometas live in the waters of the
Sanchuri dam. Palometas are Serrasalmus spilop-
leura, a species of piranhas.
</bodyText>
<tableCaption confidence="0.996527">
Table 1: Example of original and simplified texts
</tableCaption>
<bodyText confidence="0.9993965">
The association between these two types of simpli-
fication and the literacy levels was identified by
means of a corpus study. We have manually built a
corpus of simplified texts at both natural and
</bodyText>
<page confidence="0.988286">
2
</page>
<bodyText confidence="0.999503444444444">
strong levels and analyzed their linguistic struc-
tures according to the description of the two litera-
cy levels. We verified that strong simplified sen-
tences are more adequate for rudimentary level
readers, and natural ones for basic level readers.
This claim is supported by several studies which
relate capabilities and performance of the working
memory with reading levels (Siddharthan, 2003;
McNamara et al., 2002).
</bodyText>
<subsectionHeader confidence="0.997823">
2.1 The Rule-based Simplification System
</subsectionHeader>
<bodyText confidence="0.999989913043478">
The association between simplification operations
and the syntactic phenomena they address is im-
plemented within a rule-based syntactic simplifica-
tion system (Candido Jr. et al., 2009). This system
is able to identify complex syntactic phenomena in
a sentence and perform the appropriate operations
to simplify each phenomenon.
The simplification rules follow a manual for
syntactic simplification in Portuguese also devel-
oped in PorSimples. They cover syntactic con-
structions such as apposition, relative clauses,
coordination and subordination, which had already
been addressed by previous work on text simplifi-
cation (Siddharthan, 2003). Additionally, they ad-
dress the transformation of sentences from passive
into active voice, normalization of sentences into
the Subject-Verb-Object order, and simplification
of adverbial phrases. The simplification operations
available are: sentence splitting, changing particu-
lar discourse markers by simpler ones, transform-
ing passive into active voice, inverting the order of
clauses, converting to subject-verb-object order,
relocating long adverbial phrases.
</bodyText>
<subsectionHeader confidence="0.997072">
2.2 The SIMPLIFICA Tool
</subsectionHeader>
<bodyText confidence="0.999972301587302">
The rule-based simplification system is part of
SIMPLIFICA, an authoring tool for writers to
adapt original texts into simplified texts. Within
SIMPLIFICA, the author plays an active role in
generating natural or strong simplified texts by ac-
cepting or rejecting the simplifications offered by
the system on a sentence basis and post-editing
them if necessary.
Despite the ability to make such choices at the
sentence level, it is not straightforward for the au-
thor to judge the complexity level of the text as
whole in order to decide whether it is ready for a
certain audience. This is the main motivation for
the development of a readability assessment tool.
The readability assessment tool automatically
detects the level of complexity of a text at any
moment of the authoring process, and therefore
guides the author towards producing the adequate
simplification level according to the type of reader.
It classifies a text in one of three levels: rudimenta-
ry, basic or advanced.
Figure 1 shows the interface of SIMPLIFICA,
where the complexity level of the current text as
given by the readability assessment tool is shown
at the bottom, in red (in this case, “Nível Pleno”,
which corresponds to advanced). To update the
readability assessment of a text the author can
choose “Nível de Inteligibilidade” (readability lev-
el) at any moment.
The text shown in Figure 1 is composed of 13
sentences, 218 words. The lexical simplification
module (not shown in the Figure 1) finds 10 candi-
date words for simplification in this text, and the
syntactic simplification module selects 10 sen-
tences to be simplified (highlighted in gray).
When the author selects a highlighted sentence,
he/she is presented with all possible simplifications
proposed by the rule-based system for this sen-
tence. Figure 2 shows the options for the first sen-
tence in Figure 1. The first two options cover non-
finite clause and adverbial adjuncts, respectively,
while the third option covers both phenomena in
one single step. The original sentence is also given
as an option.
It is possible that certain suggestions of auto-
matic simplifications result in ungrammatical or
inadequate sentences (mainly due to parsing er-
rors). The author can choose not to use such sug-
gestions as well as manually edit the original or
automatically simplified versions. The impact of
the author’s choice on the overall readability level
of the text is not always clear to the author. The
goal of the readability assessment function is to
provide such information.
Simplified texts are usually longer than the
original ones, due to sentence splittings and
repetition of information to connect such
sentences. We acknowledge that low literacy
readers prefer short texts, but in this tool the
shortening of the text is a responsibility of the
author. Our focus is on the linguistic structure of
the texts; the length of the text actually is a feature
considered by our readability assessment system.
</bodyText>
<page confidence="0.995954">
3
</page>
<figureCaption confidence="0.9999965">
Figure 1: SIMPLIFICA interface
Figure 2. Simplification options available for the first sentence of the text presented in Figure 1
</figureCaption>
<sectionHeader confidence="0.961563" genericHeader="method">
3. Readability Assessment
</sectionHeader>
<bodyText confidence="0.999889934782609">
Recent work on readability assessment for the
English language focus on: (i) the feature set used
to capture the various aspects of readability, to
evaluate the contribution of lexical, syntactic, se-
mantic and discursive features; (ii) the audience of
the texts the readability measurement is intended
to; (iii) the genre effects on the calculation of text
difficult; (iv) the type of learning technique
which is more appropriate: those producing nomi-
nal, ordinal or interval scales of measurement, and
(v) providing an application for the automatic as-
sessment of reading difficulty.
Pitler and Nenkova (2008) propose a unified
framework composed of vocabulary, syntactic,
elements of lexical cohesion, entity coherence and
discourse relations to measure text quality, which
resembles the composition of rubrics in the area of
essay scoring (Burstein et al., 2003).
The following studies address readability as-
sessment for specific audiences: learners of Eng-
lish as second language (Schwarm and Ostendorf,
2005; Heilman et al., 2007), people with intellec-
tual disabilities (Feng et al., 2009), and people with
cognitive impairment caused by Alzheimer (Roark
at al, 2007).
Sheehan et al. (2007) focus on models for
literary and expository texts, given that traditional
metrics like Flesch-Kincaid Level score tend to
overpredict the difficulty of literary texts and
underpredict the difficulty of expository texts.
Heilman et al. (2008) investigate an appropriate
scale of measurement for reading difficulty –
nominal, ordinal, or interval – by comparing the
effectiveness of statistical models for each type of
data. Petersen and Ostendorf (2009) use
classification and regression techniques to predict a
readability score.
Miltsakali and Troutt (2007; 2008) propose an
automatic tool to evaluate reading difficulty of
Web texts in real time, addressing teenagers and
adults with low literacy levels. Using machine
learning, Glöckner et al. (2006) present a tool for
automatically rating the readability of German
texts using several linguistic information sources
and a global readability score similar to the Flesch
Reading Ease.
</bodyText>
<page confidence="0.995823">
4
</page>
<sectionHeader confidence="0.969066" genericHeader="method">
4. A Tool for Readability Assessment
</sectionHeader>
<bodyText confidence="0.999892416666667">
In this section we present our approach to readabil-
ity assessment. It differs from previous work in
the following aspects: (i) it uses a feature set with
cognitively-motivated metrics and a number of ad-
ditional features to provide a better explanation of
the complexity of a text; (ii) it targets a new audi-
ence: people with different literacy levels; (iii) it
investigates different statistical models for non-
linear data scales: the levels of literacy defined by
INAF, (iv) it focus on a new application: the use of
readability assessment for text simplification sys-
tems; and (v) it is aimed at Portuguese.
</bodyText>
<sectionHeader confidence="0.734884" genericHeader="method">
4.1 Features for Assessing Readability
</sectionHeader>
<bodyText confidence="0.9999639375">
Our feature set (Table 2) consists of 3 groups of
features. The first group contains cognitively-
motivated features (features 1-42), derived from
the Coh-Metrix-PORT tool (see Section 4.1.1).
The second group contains features that reflect the
incidence of particular syntactic constructions
which we target in our text simplification system
(features 43-49). The third group (the remaining
features in Table 2) contains features derived from
n-gram language models built considering uni-
grams, bigrams and trigrams probability and per-
plexity plus out-of-vocabulary rate scores. We later
refer to a set of basic features, which consist of
simple counts that do not require any linguistic tool
or external resources to be computed. This set cor-
responds to features 1-3 and 9-11.
</bodyText>
<subsectionHeader confidence="0.658924">
4.1.1 Coh-Metrix-Port
</subsectionHeader>
<bodyText confidence="0.9999585">
The Coh-Metrix tool was developed to compute
features potentially relevant to the comprehension
of English texts through a number of measures in-
formed by linguistics, psychology and cognitive
studies. The main aspects covered by the measures
are cohesion and coherence (Graesser et al., 2004).
Coh-Metrix 2.0, the free version of the tool, con-
tains 60 readability metrics. The Coh-Metrix-
PORT tool (Scarton et al., 2009) computes similar
metrics for texts in Brazilian Portuguese. The ma-
jor challenge to create such tool is the lack of some
of the necessary linguistic resources. The follow-
ing metrics are currently available in the tool (we
refer to Table 2 for details):
</bodyText>
<listItem confidence="0.902956666666667">
1. Readability metric: feature 12.
2. Words and textual information:
Basic counts: features 1 to 11.
1 Number of words
2 Number of sentences
3 Number of paragraphs
4 Number of verbs
5 Number of nouns
6 Number of adjectives
7 Number of adverbs
8 Number of pronouns
9 Average number of words per sentence
</listItem>
<table confidence="0.97995108">
10 Average number of sentences per paragraph
11 Average number of syllables per word
12 Flesch index for Portuguese
13 Incidence of content words
14 Incidence of functional words
15 Raw Frequency of content words
16 Minimal frequency of content words
17 Average number of verb hypernyms
18 Incidence of NPs
19 Number of NP modifiers
20 Number of words before the main verb
21 Number of high level constituents
22 Number of personal pronouns
23 Type-token ratio
24 Pronoun-NP ratio
25 Number of “e” (and)
26 Number of “ou” (or)
27 Number of “se” (if)
28 Number of negations
29 Number of logic operators
30 Number of connectives
31 Number of positive additive connectives
32 Number of negative additive connectives
33 Number of positive temporal connectives
34 Number of negative temporal connectives
35 Number of positive causal connectives
36 Number of negative causal connectives
37 Number of positive logic connectives
38 Number of negative logic connectives
39 Verb ambiguity ratio
40 Noun ambiguity ratio
41 Adverb ambiguity ratio
42 Adjective ambiguity ratio
43 Incidence of clauses
44 Incidence of adverbial phrases
45 Incidence of apposition
46 Incidence of passive voice
47 Incidence of relative clauses
48 Incidence of coordination
49 Incidence of subordination
50 Out-of-vocabulary words
51 LM probability of unigrams
52 LM perplexity of unigrams
53 LM perplexity of unigrams, without line break
54 LM probability of bigrams
55 LM perplexity of bigrams
56 LM perplexity of bigrams, without line break
57 LM probability of trigrams
58 LM perplexity of trigrams
59 LM perplexity of trigrams, without line break
</table>
<tableCaption confidence="0.999661">
Table 2. Feature set
</tableCaption>
<page confidence="0.994476">
5
</page>
<sectionHeader confidence="0.827399" genericHeader="method">
4. Logical operators: features 25 to 29.
</sectionHeader>
<bodyText confidence="0.999194875">
The following resources for Portuguese were used:
the MXPOST POS tagger (Ratnaparkhi, 1996), a
word frequency list compiled from a 700 million-
token corpus2, a tool to identify reduced noun
phrases (Oliveira et al., 2006), a list of connectives
classified as positives/negatives and according to
cohesion type (causal, temporal, additive or logi-
cal), a list of logical operators and WordNet.Br
(Dias-da-Silva et al., 2008).
In this paper we include seven new metrics to
Coh-Metrix-PORT: features 13, 14, 21, and 39 to
42. We used TEP3 (Dias-da-Silva et al., 2003) to
obtain the number of senses of words (and thus
their ambiguity level), and the Palavras parser
(Bick, 2000) to identify the higher level constitu-
ents. The remaining metrics were computed based
on the POS tags.
According to a report on the performance of
each Coh-Metrix-PORT metric (Scarton et al.,
2009), no individual feature provides sufficient in-
dication to measure text complexity, and therefore
the need to exploit their combination, and also to
combine them with the other types of features de-
scribed in this section.
</bodyText>
<subsubsectionHeader confidence="0.461748">
4.1.2 Language-model Features
</subsubsectionHeader>
<bodyText confidence="0.999943125">
Language model features were derived from a
large corpus composed of a sample of the Brazilian
newspaper Folha de São Paulo containing issues
from 12 months taken at random from 1994 to
2005. The corpus contains 96,868 texts and
26,425,483 tokens. SRILM (Stolcke, 2002), a
standard language modelling toolkit, was used to
produce the language model features.
</bodyText>
<subsectionHeader confidence="0.997975">
4.2 Learning Techniques
</subsectionHeader>
<bodyText confidence="0.999839">
Given that the boundaries of literacy level classes
are one of the subjects of our study, we exploit
three different types of models in order to check
</bodyText>
<footnote confidence="0.992494">
2 http://www2.lael.pucsp.br/corpora/bp/index.htm
3 http://www.nilc.icmc.usp.br/tep2/index.htm
</footnote>
<bodyText confidence="0.99896175">
which of them can better distinguish among the
three literacy levels. We therefore experiment with
three types of machine learning algorithms: a stan-
dard classifier, an ordinal (ranking) classifier and a
regressor. Each algorithm assumes different rela-
tions among the groups: the classifier assumes no
relation, the ordinal classifier assumes that the
groups are ordered, and the regressor assumes that
the groups are continuous.
As classifier we use the Support Vector Ma-
chines (SVM) implementation in the Weka4 toolkit
(SMO). As ordinal classifier we use a meta clas-
sifier in Weka which takes SMO as the base classi-
fication algorithm and performs pairwise classifi-
cations (OrdinalClassClassifier). For regression we
use the SVM regression implementation in Weka
(SMO-reg). We use the linear versions of the algo-
rithms for classification, ordinal classification and
regression, and also experiment with a radial basis
function (RBF) kernel for regression.
</bodyText>
<sectionHeader confidence="0.998919" genericHeader="evaluation">
5. Experiments
</sectionHeader>
<subsectionHeader confidence="0.912706">
5.1 Corpora
</subsectionHeader>
<bodyText confidence="0.999840954545455">
In order to train (and test) the different machine
learning algorithms to automatically identify the
readability level of the texts we make use of ma-
nually simplified corpora created in the PorSimples
project. Seven corpora covering our three literacy
levels (advanced, basic and rudimentary) and two
different genres were compiled. The first corpus is
composed of general news articles from the Brazil-
ian newspaper Zero Hora (ZH original). These ar-
ticles were manually simplified by a linguist, ex-
pert in text simplification, according to the two
levels of simplification: natural (ZH natural) and
strong (ZH strong). The remaining corpora are
composed of popular science articles from differ-
ent sources: (a) the Caderno Ciência section of the
Brazilian newspaper Folha de São Paulo, a main-
stream newspaper in Brazil (CC original) and a
manually simplified version of this corpus using
the natural (CC natural) and strong (CC strong)
levels; and (b) advanced level texts from a popular
science magazine called Ciência Hoje (CH). Table
3 shows a few statistics about these seven corpora.
</bodyText>
<subsectionHeader confidence="0.998348">
5.2 Feature Analysis
</subsectionHeader>
<bodyText confidence="0.9997165">
As a simple way to check the contribution of dif-
ferent features to our three literacy levels, we com-
</bodyText>
<footnote confidence="0.915126">
4 http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<table confidence="0.983655">
Frequencies: features 15 to 16.
Hypernymy: feature 17.
3. Syntactic information:
Constituents: features 18 to 20.
Pronouns: feature 22
Types and Tokens: features 23 to 24.
Connectives: features 30 to 38.
</table>
<page confidence="0.921276">
6
</page>
<table confidence="0.9998614">
Corpus Doc Sent Words Avg. words Avg.
per text (std. words p.
deviation) sentence
ZH original 104 2184 46190 444.1 (133.7) 21.1
ZH natural 104 3234 47296 454.7 (134.2) 14.6
ZH strong 104 3668 47938 460.9 (137.5) 13.0
CC original 50 882 20263 405.2 (175.6) 22.9
CC natural 50 975 19603 392.0 (176.0) 20.1
CC strong 50 1454 20518 410.3 (169.6) 14.1
CH 130 3624 95866 737.4 (226.1) 26.4
</table>
<tableCaption confidence="0.999733">
Table 3. Corpus statistics
</tableCaption>
<bodyText confidence="0.998264166666667">
puted the (absolute) Pearson correlation between
our features and the expected literacy level for the
two sets of corpora that contain versions of the
three classes of interest (original, natural and
strong). Table 4 lists the most highly correlated
features.
</bodyText>
<table confidence="0.985471909090909">
Feature Corr.
1 Words per sentence 0.693
2 Incidence of apposition 0.688
3 Incidence of clauses 0.614
4 Flesch index 0.580
5 Words before main verb 0.516
6 Sentences per paragraph 0.509
7 Incidence of relative clauses 0.417
8 Syllables per word 0.414
9 Number of positive additive connectives 0.397
10 Number of negative causal connectives 0.388
</table>
<tableCaption confidence="0.99986">
Table 4: Correlation between features and literacy levels
</tableCaption>
<bodyText confidence="0.999994857142857">
Among the top features are mostly basic and syn-
tactic features representing the number of apposi-
tive and relative clauses and clauses in general, and
also features from Coh-Metrix-PORT. This shows
that traditional cognitively-motivated features can
be complemented with more superficial features
for readability assessment.
</bodyText>
<subsectionHeader confidence="0.999893">
5.3 Predicting Complexity Levels
</subsectionHeader>
<bodyText confidence="0.9998856875">
As previously discussed, the goal is to predict the
complexity level of a text as original, naturally or
strongly simplified, which correspond to the three
literacy levels of INAF: rudimentary, basic and ad-
vanced level.
Tables 5-7 show the results of our experiments
using 10-fold cross-validation and standard classi-
fication (Table 5), ordinal classification (Table 6)
and regression (Table 7), in terms of F-measure
(F), Pearson correlation with true score (Corr.) and
mean absolute error (MAE). Results using our
complete feature set (All) and different subsets of
it are shown so that we can analyze the
performance of each group of features. We also
experiment with the Flesch index on its own as a
feature.
</bodyText>
<table confidence="0.999741315789474">
Features Class F Corr. MAE
All original 0.913 0.84 0.276
natural 0.483
strong 0.732
Language original 0.669 0.25 0.381
Model natural 0.025
strong 0.221
Basic original 0.846 0.76 0.302
natural 0.149
strong 0.707
Syntactic original 0.891 0.82 0.285
natural 0.32
strong 0.74
Coh- original 0.873 0.79 0.290
Metrix- natural 0.381
PORT strong 0.712
Flesch original 0.751 0.52 0.348
natural 0.152
strong 0.546
</table>
<tableCaption confidence="0.881994">
Table 5: Standard Classification
</tableCaption>
<table confidence="0.999621473684211">
Features Class F Corr. MAE
All original 0.904 0.83 0.163
natural 0.484
strong 0.731
Language original 0.634 0.49 0.344
Model natural 0.497
strong 0.05
Basic original 0.83 0.73 0.231
natural 0.334
strong 0.637
Syntactic original 0.891 0.81 0.180
natural 0.382
strong 0.714
Coh- original 0.878 0.8 0.183
Metrix- natural 0.432
PORT strong 0.709
Flesch original 0.746 0.56 0.310
natural 0.489
strong 0
</table>
<tableCaption confidence="0.993776">
Table 6: Ordinal classification
</tableCaption>
<bodyText confidence="0.9991958">
The results of the standard and ordinal classifica-
tion are comparable in terms of F-measure and cor-
relation, but the mean absolute error is lower for
the ordinal classification. This indicates that ordi-
nal classification is more adequate to handle our
classes, similarly to the results found in (Heilman
et al., 2008). Results also show that distinguishing
between natural and strong simplifications is a
harder problem than distinguishing between these
and original texts. This was expected, since these
two levels of simplification share many features.
However, the average performance achieved is
considered satisfactory.
Concerning the regression model (Table 7), the
RBF kernel reaches the best correlation scores
</bodyText>
<page confidence="0.997708">
7
</page>
<bodyText confidence="0.998214">
among all models. However, its mean error rates
are above the ones found for classification. A lin-
ear SVM (not shown here) achieves very poor re-
sults across all metrics.
</bodyText>
<table confidence="0.997033714285714">
Features Corr. MAE
All 0.8502 0.3478
Language Model 0.6245 0.5448
Basic 0.7266 0.4538
Syntactic 0.8063 0.3878
Coh-Metrix-PORT 0.8051 0.3895
Flesch 0.5772 0.5492
</table>
<tableCaption confidence="0.999967">
Table 7: Regression with RBF kernel
</tableCaption>
<bodyText confidence="0.999991391304348">
With respect to the different feature sets, we can
observe that the combination of all features consis-
tently yields better results according to all metrics
across all our models. The performances obtained
with the subsets of features vary considerably from
model to model, which shows that the combination
of features is more robust across different learning
techniques. Considering each feature set independ-
ently, the syntactic features, followed by Coh-
Metrix-PORT, achieve the best correlation scores,
while the language model features performed the
poorest.
These results show that it is possible to predict
with satisfactory accuracy the readability level of
texts according to our three classes of interest:
original, naturally simplified and strongly simpli-
fied texts. Given such results we embedded the
classification model (Table 5) as a tool for read-
ability assessment into our text simplification au-
thoring system. The linear classification is our
simplest model, has achieved the highest F-
measure and its correlation scores are comparable
to those of the other models.
</bodyText>
<sectionHeader confidence="0.998889" genericHeader="conclusions">
6. Conclusions
</sectionHeader>
<bodyText confidence="0.999983321428571">
We have experimented with different machine
learning algorithms and features in order to verify
whether it was possible to automatically distin-
guish among the three readability levels: original
texts aimed at advanced readers, naturally simpli-
fied texts aimed at people with basic literacy level,
and strongly simplified texts aimed at people with
rudimentary literacy level. All algorithms achieved
satisfactory performance with the combination of
all features and we embedded the simplest model
into our authoring tool.
As future work, we plan to investigate the con-
tribution of deeper cognitive features to this prob-
lem, more specifically, semantic, co-reference and
mental model dimensions metrics. Having this ca-
pacity for readability assessment is useful not only
to inform authors preparing simplified material
about the complexity of the current material, but
also to guide automatic simplification systems to
produce simplifications with the adequate level of
complexity according to the target user.
The authoring tool, as well as its text simplifica-
tion and readability assessment systems, can be
used not only for improving text accessibility, but
also for educational purposes: the author can pre-
pare texts that are adequate according to the level
of the reader and it will also allow them to improve
their reading skills.
</bodyText>
<sectionHeader confidence="0.999408" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998662447368421">
Sandra M. Aluísio, Lucia Specia, Thiago A. S. Pardo,
Erick G. Maziero, Renata P. M. Fortes (2008). To-
wards Brazilian Portuguese Automatic Text Simpli-
fication Systems. In the Proceedings of the 8th ACM
Symposium on Document Engineering, pp. 240-248.
Eckhard Bick (2000). The Parsing System &amp;quot;Palavras&amp;quot;:
Automatic Grammatical Analysis of Portuguese in a
Constraint Grammar Framework. PhD Thesis. Uni-
versity of Århus, Denmark.
Jill Burstein, Martin Chodorow and Claudia Leacock
(2003). CriterionSM Online Essay Evaluation: An
Application for Automated Evaluation of Student
Essays. In the Proceedings of the Fifteenth Annual
Conference on Innovative Applications of Artificial
Intelligence, Acapulco, Mexico.
Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin,
Thiago A. S. Pardo, Lucia Specia, and Sandra M.
Aluisio (2009). Supporting the Adaptation of Texts
for Poor Literacy Readers: a Text Simplification
Editor for Brazilian Portuguese. In NAACL-HLT
Workshop on Innovative Use of NLP for Building
Educational Applications, pages 34–42, Boulder’.
Helena de M. Caseli, Tiago de F. Pereira, Lúcia Specia,
Thiago A. S. Pardo, Caroline Gasperin and Sandra
Maria Aluísio (2009). Building a Brazilian Portu-
guese Parallel Corpus of Original and Simplified
Texts. In the Proceedings of CICLing.
Max Coltheart (1981). The MRC psycholinguistic data-
base. In Quartely Jounal of Experimental Psycholo-
gy, 33A, pages 497-505.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer e Richard Harshman (1990).
Indexing By Latent Semantic Analysis. In Journal of
the American Society For Information Science, V.
41, pages 391-407.
Bento C. Dias-da-Silva and Helio R. Moraes (2003). A
construção de um thesaurus eletrônico para o portu-
guês do Brasil. In ALFA- Revista de Lingüística, V.
</reference>
<page confidence="0.990409">
8
</page>
<reference confidence="0.999234527777778">
47, N. 2, pages 101-115.
Bento C Dias-da-Silva, Ariani Di Felippo and Maria das
Graças V. Nunes (2008). The automatic mapping of
Princeton WordNet lexical conceptual relations onto
the Brazilian Portuguese WordNet database. In Pro-
ceedings of the 6th LREC, Marrakech, Morocco.
William H. DuBay (2004). The principles of readability.
Costa Mesa, CA: Impact Information: http://www.i
mpact-information.com/impactinfo/readability02.pdf
Christiane Fellbaum (1998). WordNet: An electronic
lexical database. Cambridge, MA: MIT Press.
Lijun Feng, Noémie Elhadad and Matt Huenerfauth
(2009). Cognitively Motivated Features for Reada-
bility Assessment. In the Proceedings of EACL
2009, pages 229-237.
Ingo Glöckner, Sven Hartrumpf, Hermann Helbig, Jo-
hannes Leveling and Rainer Osswald (2006b). An
architecture for rating and controlling text readabili-
ty. In Proceedings of KONVENS 2006, pages 32-35.
Konstanz, Germany.
Arthur C. Graesser, Danielle S. McNamara, Max M.
Louwerse and Zhiqiang Cai (2004). Coh-Metrix:
Analysis of text on cohesion and language. In Beha-
vioral Research Methods, Instruments, and Comput-
ers, V. 36, pages 193-202.
Ronald K. Hambleton, H. Swaminathan and H. Jane
Rogers (1991). Fundamentals of item response
theory. Newbury Park, CA: Sage Press.
Michael Heilman, Kevyn Collins-Thompson, Jamie
Callan and Max Eskenazi (2007). Combining lexical
and grammatical features to improve readability
measures for first and second language texts. In the
Proceedings of NAACL HLT 2007, pages 460-467.
Michael Heilman, Kevyn Collins-Thompson and Max-
ine Eskenazi (2008). An Analysis of Statistical
Models and Features for Reading Difficulty Predic-
tion. In Proceedings of the 3rd Workshop on Innova-
tive Use of NLP for Building Educational Applica-
tions, pages 71-79.
INAF (2009). Instituto P. Montenegro and Ação Educa-
tiva. INAF Brasil - Indicador de Alfabetismo Funcio-
nal - 2009. Available online at http://www. ibope.
com.br/ipm/relatorios/relatorio_inaf_2009.pdf
Teresa B. F. Martins, Claudete M. Ghiraldelo, Maria
das Graças V. Nunes e Osvaldo N. de Oliveira Jr.
(1996). Readability formulas applied to textbooks in
brazilian portuguese. ICMC Technical Report, N.
28, 11p.
Aurélien Max (2006). Writing for Language-impaired
Readers. In Proceedings of CICLing, pages 567-570.
Danielle McNamara, Max Louwerse, and Art Graesser,
2002. Coh-Metrix: Automated cohesion and coher-
ence scores to predict text readability and facilitate
comprehension. Grant proposal. http://cohmetrix.
memphis.edu/cohmetrixpr/publications.html
Eleni Miltsakaki and Audrey Troutt (2007). Read-X:
Automatic Evaluation of Reading Difficulty of Web
Text. In the Proceedings of E-Learn 2007, Quebec,
Canada.
Eleni Miltsakaki and Audrey Troutt (2008). Real Time
Web Text Classification and Analysis of Reading
Difficulty. In the Proceedings of the 3rd Workshop
on Innovative Use of NLP for Building Educational
Applications, Columbus, OH.
Cláudia Oliveira, Maria C. Freitas, Violeta Quental, Cí-
cero N. dos Santos, Renato P. L. and Lucas Souza
(2006). A Set of NP-extraction rules for Portuguese:
defining and learning. In 7th Workshop on Computa-
tional Processing of Written and Spoken Portuguese,
Itatiaia, Brazil.
Sarah E. Petersen and Mari Ostendorf (2009). A ma-
chine learning approach to reading level assess-
ment. Computer Speech and Language 23, 89-106.
Emily Pitler and Ani Nenkova (2008). Revisiting reada-
bility: A unified framework for predicting text quali-
ty. In Proceedings of EMNLP, 2008.
Adwait Ratnaparkhi (1996). A Maximum Entropy Part-
of-Speech Tagger. In Proceedings of the First Em-
pirical Methods in Natural Language Processing
Conference, pages133-142.
Brian Roark, Margaret Mitchell and Kristy Holling-
shead (2007). Syntactic complexity measures for de-
tecting mild cognitive impairment. In the Proceed-
ings of the Workshop on BioNLP 2007: Biological,
Translational, and Clinical Language Processing,
Prague, Czech Republic.
Caroline E. Scarton, Daniel M. Almeida, Sandra M. A-
luísio (2009). Análise da Inteligibilidade de textos
via ferramentas de Processamento de Língua Natu-
ral: adaptando as métricas do Coh-Metrix para o
Português. In Proceedings of STIL-2009, São Carlos,
Brazil.
Sarah E. Schwarm and Mari Ostendorf (2005). Reading
Level Assessment Using Support Vector Machines
and Statistical Language Models. In the Proceedings
of the 43rd Annual Meeting of the ACL, pp 523–530.
Kathleen M. Sheehan, Irene Kostin and Yoko Futagi
(2007). Reading Level Assessment for Literary and
Expository Texts. In D. S. McNamara and J. G.
Trafton (Eds.), Proceedings of the 29th Annual Cog-
nitive Science Society, page 1853. Austin, TX: Cog-
nitive Science Society.
Advaith Siddharthan (2003). Syntactic Simplification
and Text Cohesion. PhD Thesis. University of Cam-
bridge.
Andreas Stolcke. SRILM -- an extensible language
modeling toolkit. In Proceedings of the International
Conference on Spoken Language Processing, 2002.
</reference>
<page confidence="0.997112">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.896257">
<title confidence="0.999741">Readability Assessment for Text Simplification</title>
<author confidence="0.999345">Lucia Caroline Carolina</author>
<affiliation confidence="0.9940035">of Computational Linguistics (NILC) Group in Computational Linguistics University of São Paulo University of Wolverhampton</affiliation>
<address confidence="0.969036">São Carlos - SP, Brazil Wolverhampton, UK</address>
<email confidence="0.999633">carol.scarton@gmail.com</email>
<abstract confidence="0.995401333333333">We describe a readability assessment approach to support the process of text simplification for poor literacy readers. Given an input text, the goal is to predict its readability level, which corresponds to the literacy level that is expected from the target reader: rudimentary, basic or advanced. We complement features traditionally used for readability assessment with a number of new features, and experiment with alternative ways to model this problem using machine learning methods, namely classification, regression and ranking. The best resulting model is embedded in an authoring tool for Text Simplification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sandra M Aluísio</author>
<author>Lucia Specia</author>
<author>Thiago A S Pardo</author>
<author>Erick G Maziero</author>
<author>Renata P M Fortes</author>
</authors>
<title>Towards Brazilian Portuguese Automatic Text Simplification Systems.</title>
<date>2008</date>
<booktitle>In the Proceedings of the 8th ACM Symposium on Document Engineering,</booktitle>
<pages>240--248</pages>
<contexts>
<context position="3010" citStr="Aluísio et al., 2008" startWordPosition="458" endWordPosition="461">cessibility of Web content&apos;. It states that for texts which demand reading skills more advanced than that of individuals with lower secondary education, one should offer an alternative version of the same content suitable for those individuals. While readability formulas for English have a long history – 200 formulas have been reported from 1920 to 1980s (Dubay, 2004) – the only tool available for Portuguese is an adaptation of the Flesch Reading Ease index. It evaluates the complexity of texts in a 4-level scale corresponding to grade levels (Martins et al., 1996). In the PorSimples project (Aluísio et al., 2008) we develop text adaptation methods (via text simplification and elaboration approaches) to improve the comprehensibility of texts published on government websites or by renowned news agencies, which are expected to be relevant to a large audience with various literacy levels. The project provides automatic simplification tools to aid (1) poorly literate readers to understand online content – a browser plug-in for automatically simplifying websites – and (2) authors producing texts for this audience – an authoring tool for guiding the creation of simplified versions of texts. This paper focuse</context>
</contexts>
<marker>Aluísio, Specia, Pardo, Maziero, Fortes, 2008</marker>
<rawString>Sandra M. Aluísio, Lucia Specia, Thiago A. S. Pardo, Erick G. Maziero, Renata P. M. Fortes (2008). Towards Brazilian Portuguese Automatic Text Simplification Systems. In the Proceedings of the 8th ACM Symposium on Document Engineering, pp. 240-248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eckhard Bick</author>
</authors>
<title>The Parsing System &amp;quot;Palavras&amp;quot;: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. PhD Thesis.</title>
<date>2000</date>
<institution>University of Århus, Denmark.</institution>
<contexts>
<context position="20405" citStr="Bick, 2000" startWordPosition="3192" endWordPosition="3193">OS tagger (Ratnaparkhi, 1996), a word frequency list compiled from a 700 milliontoken corpus2, a tool to identify reduced noun phrases (Oliveira et al., 2006), a list of connectives classified as positives/negatives and according to cohesion type (causal, temporal, additive or logical), a list of logical operators and WordNet.Br (Dias-da-Silva et al., 2008). In this paper we include seven new metrics to Coh-Metrix-PORT: features 13, 14, 21, and 39 to 42. We used TEP3 (Dias-da-Silva et al., 2003) to obtain the number of senses of words (and thus their ambiguity level), and the Palavras parser (Bick, 2000) to identify the higher level constituents. The remaining metrics were computed based on the POS tags. According to a report on the performance of each Coh-Metrix-PORT metric (Scarton et al., 2009), no individual feature provides sufficient indication to measure text complexity, and therefore the need to exploit their combination, and also to combine them with the other types of features described in this section. 4.1.2 Language-model Features Language model features were derived from a large corpus composed of a sample of the Brazilian newspaper Folha de São Paulo containing issues from 12 mo</context>
</contexts>
<marker>Bick, 2000</marker>
<rawString>Eckhard Bick (2000). The Parsing System &amp;quot;Palavras&amp;quot;: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework. PhD Thesis. University of Århus, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Burstein</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>CriterionSM Online Essay Evaluation: An Application for Automated Evaluation of Student Essays.</title>
<date>2003</date>
<booktitle>In the Proceedings of the Fifteenth Annual Conference on Innovative Applications of Artificial Intelligence,</booktitle>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="14322" citStr="Burstein et al., 2003" startWordPosition="2226" endWordPosition="2229">dience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty. Pitler and Nenkova (2008) propose a unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (Burstein et al., 2003). The following studies address readability assessment for specific audiences: learners of English as second language (Schwarm and Ostendorf, 2005; Heilman et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models for literary and expository texts, given that traditional metrics like Flesch-Kincaid Level score tend to overpredict the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate s</context>
</contexts>
<marker>Burstein, Chodorow, Leacock, 2003</marker>
<rawString>Jill Burstein, Martin Chodorow and Claudia Leacock (2003). CriterionSM Online Essay Evaluation: An Application for Automated Evaluation of Student Essays. In the Proceedings of the Fifteenth Annual Conference on Innovative Applications of Artificial Intelligence, Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnaldo Candido Jr</author>
<author>Erick Maziero</author>
<author>Caroline Gasperin</author>
<author>Thiago A S Pardo</author>
<author>Lucia Specia</author>
<author>M Sandra</author>
</authors>
<title>Aluisio</title>
<date>2009</date>
<booktitle>In NAACL-HLT Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>34--42</pages>
<location>Boulder’.</location>
<marker>Jr, Maziero, Gasperin, Pardo, Specia, Sandra, 2009</marker>
<rawString>Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin, Thiago A. S. Pardo, Lucia Specia, and Sandra M. Aluisio (2009). Supporting the Adaptation of Texts for Poor Literacy Readers: a Text Simplification Editor for Brazilian Portuguese. In NAACL-HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 34–42, Boulder’.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helena de M Caseli</author>
<author>Tiago de F Pereira</author>
<author>Lúcia Specia</author>
<author>Thiago A S Pardo</author>
</authors>
<title>Caroline Gasperin and Sandra Maria Aluísio</title>
<date>2009</date>
<booktitle>In the Proceedings of CICLing.</booktitle>
<marker>Caseli, Pereira, Specia, Pardo, 2009</marker>
<rawString>Helena de M. Caseli, Tiago de F. Pereira, Lúcia Specia, Thiago A. S. Pardo, Caroline Gasperin and Sandra Maria Aluísio (2009). Building a Brazilian Portuguese Parallel Corpus of Original and Simplified Texts. In the Proceedings of CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>The MRC psycholinguistic database.</title>
<date>1981</date>
<booktitle>In Quartely Jounal of Experimental Psychology, 33A,</booktitle>
<pages>497--505</pages>
<marker>Coltheart, 1981</marker>
<rawString>Max Coltheart (1981). The MRC psycholinguistic database. In Quartely Jounal of Experimental Psychology, 33A, pages 497-505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan T Dumais</author>
<author>George W Furnas</author>
<author>K Thomas</author>
</authors>
<title>Landauer e Richard Harshman</title>
<date>1990</date>
<journal>In Journal of the American Society For Information Science, V.</journal>
<volume>41</volume>
<pages>391--407</pages>
<marker>Deerwester, Dumais, Furnas, Thomas, 1990</marker>
<rawString>Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer e Richard Harshman (1990). Indexing By Latent Semantic Analysis. In Journal of the American Society For Information Science, V. 41, pages 391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bento C Dias-da-Silva</author>
<author>Helio R Moraes</author>
</authors>
<title>A construção de um thesaurus eletrônico para o português do Brasil.</title>
<date>2003</date>
<booktitle>In ALFA- Revista de Lingüística, V.</booktitle>
<volume>47</volume>
<pages>101--115</pages>
<marker>Dias-da-Silva, Moraes, 2003</marker>
<rawString>Bento C. Dias-da-Silva and Helio R. Moraes (2003). A construção de um thesaurus eletrônico para o português do Brasil. In ALFA- Revista de Lingüística, V. 47, N. 2, pages 101-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bento C Dias-da-Silva</author>
<author>Ariani Di Felippo</author>
<author>Maria das Graças V Nunes</author>
</authors>
<title>The automatic mapping of Princeton WordNet lexical conceptual relations onto the Brazilian Portuguese WordNet database.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th LREC,</booktitle>
<location>Marrakech, Morocco.</location>
<marker>Dias-da-Silva, Di Felippo, Nunes, 2008</marker>
<rawString>Bento C Dias-da-Silva, Ariani Di Felippo and Maria das Graças V. Nunes (2008). The automatic mapping of Princeton WordNet lexical conceptual relations onto the Brazilian Portuguese WordNet database. In Proceedings of the 6th LREC, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H DuBay</author>
</authors>
<title>The principles of readability. Costa Mesa, CA: Impact Information:</title>
<date>2004</date>
<note>http://www.i mpact-information.com/impactinfo/readability02.pdf</note>
<marker>DuBay, 2004</marker>
<rawString>William H. DuBay (2004). The principles of readability. Costa Mesa, CA: Impact Information: http://www.i mpact-information.com/impactinfo/readability02.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum (1998). WordNet: An electronic lexical database. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijun Feng</author>
</authors>
<title>Noémie Elhadad and Matt Huenerfauth</title>
<date>2009</date>
<booktitle>In the Proceedings of EACL</booktitle>
<pages>229--237</pages>
<marker>Feng, 2009</marker>
<rawString>Lijun Feng, Noémie Elhadad and Matt Huenerfauth (2009). Cognitively Motivated Features for Readability Assessment. In the Proceedings of EACL 2009, pages 229-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Glöckner</author>
<author>Sven Hartrumpf</author>
<author>Hermann Helbig</author>
</authors>
<title>Johannes Leveling and Rainer Osswald (2006b). An architecture for rating and controlling text readability.</title>
<date>2006</date>
<booktitle>In Proceedings of KONVENS</booktitle>
<pages>32--35</pages>
<location>Konstanz, Germany.</location>
<contexts>
<context position="15405" citStr="Glöckner et al. (2006)" startWordPosition="2386" endWordPosition="2389">ct the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate scale of measurement for reading difficulty – nominal, ordinal, or interval – by comparing the effectiveness of statistical models for each type of data. Petersen and Ostendorf (2009) use classification and regression techniques to predict a readability score. Miltsakali and Troutt (2007; 2008) propose an automatic tool to evaluate reading difficulty of Web texts in real time, addressing teenagers and adults with low literacy levels. Using machine learning, Glöckner et al. (2006) present a tool for automatically rating the readability of German texts using several linguistic information sources and a global readability score similar to the Flesch Reading Ease. 4 4. A Tool for Readability Assessment In this section we present our approach to readability assessment. It differs from previous work in the following aspects: (i) it uses a feature set with cognitively-motivated metrics and a number of additional features to provide a better explanation of the complexity of a text; (ii) it targets a new audience: people with different literacy levels; (iii) it investigates di</context>
</contexts>
<marker>Glöckner, Hartrumpf, Helbig, 2006</marker>
<rawString>Ingo Glöckner, Sven Hartrumpf, Hermann Helbig, Johannes Leveling and Rainer Osswald (2006b). An architecture for rating and controlling text readability. In Proceedings of KONVENS 2006, pages 32-35. Konstanz, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur C Graesser</author>
<author>Danielle S McNamara</author>
<author>M Max</author>
</authors>
<title>Louwerse and Zhiqiang Cai</title>
<date>2004</date>
<journal>In Behavioral Research Methods, Instruments, and Computers, V.</journal>
<volume>36</volume>
<pages>193--202</pages>
<contexts>
<context position="5783" citStr="Graesser et al., 2004" startWordPosition="886" endWordPosition="889">ehensive set of features, different learning techniques and targets a new language and application, as we discuss in Section 4. More specifically, we address the following research questions: 1. Given some training material, is it possible to detect the complexity level of Portuguese texts, which corresponds to the different literacy levels defined by INAF? 2. What is the best way to model this problem and which features are relevant? We experiment with nominal, ordinal and intervalbased modeling techniques and exploit a number of the cognitively motivated features proposed by Coh-Metrix 2.0 (Graesser et al., 2004) and adapted to Portuguese (called Coh-Metrix-PORT), along with a set of new features, including syntactic features to capture simplification operations and ngram language model features. In the remainder of this paper, we first provide some background information on the need for a readability assessment tool within our text simplification system (Section 2) and discuss prior work on readability assessment (Section 3), to then present our features and modeling techniques (Section 4) and the experiments performed to answer our research questions (Section 5). 2. Text Simplification in PorSimples</context>
<context position="17366" citStr="Graesser et al., 2004" startWordPosition="2690" endWordPosition="2693">lt considering unigrams, bigrams and trigrams probability and perplexity plus out-of-vocabulary rate scores. We later refer to a set of basic features, which consist of simple counts that do not require any linguistic tool or external resources to be computed. This set corresponds to features 1-3 and 9-11. 4.1.1 Coh-Metrix-Port The Coh-Metrix tool was developed to compute features potentially relevant to the comprehension of English texts through a number of measures informed by linguistics, psychology and cognitive studies. The main aspects covered by the measures are cohesion and coherence (Graesser et al., 2004). Coh-Metrix 2.0, the free version of the tool, contains 60 readability metrics. The Coh-MetrixPORT tool (Scarton et al., 2009) computes similar metrics for texts in Brazilian Portuguese. The major challenge to create such tool is the lack of some of the necessary linguistic resources. The following metrics are currently available in the tool (we refer to Table 2 for details): 1. Readability metric: feature 12. 2. Words and textual information: Basic counts: features 1 to 11. 1 Number of words 2 Number of sentences 3 Number of paragraphs 4 Number of verbs 5 Number of nouns 6 Number of adjectiv</context>
</contexts>
<marker>Graesser, McNamara, Max, 2004</marker>
<rawString>Arthur C. Graesser, Danielle S. McNamara, Max M. Louwerse and Zhiqiang Cai (2004). Coh-Metrix: Analysis of text on cohesion and language. In Behavioral Research Methods, Instruments, and Computers, V. 36, pages 193-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald K Hambleton</author>
<author>H Swaminathan</author>
<author>H Jane Rogers</author>
</authors>
<title>Fundamentals of item response theory.</title>
<date>1991</date>
<publisher>Sage Press.</publisher>
<location>Newbury Park, CA:</location>
<marker>Hambleton, Swaminathan, Rogers, 1991</marker>
<rawString>Ronald K. Hambleton, H. Swaminathan and H. Jane Rogers (1991). Fundamentals of item response theory. Newbury Park, CA: Sage Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Kevyn Collins-Thompson</author>
<author>Jamie Callan</author>
<author>Max Eskenazi</author>
</authors>
<title>Combining lexical and grammatical features to improve readability measures for first and second language texts.</title>
<date>2007</date>
<booktitle>In the Proceedings of NAACL HLT</booktitle>
<pages>460--467</pages>
<contexts>
<context position="14491" citStr="Heilman et al., 2007" startWordPosition="2251" endWordPosition="2254"> more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty. Pitler and Nenkova (2008) propose a unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (Burstein et al., 2003). The following studies address readability assessment for specific audiences: learners of English as second language (Schwarm and Ostendorf, 2005; Heilman et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models for literary and expository texts, given that traditional metrics like Flesch-Kincaid Level score tend to overpredict the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate scale of measurement for reading difficulty – nominal, ordinal, or interval – by comparing the effectiveness of statistical models for each type of data. Petersen and Ost</context>
</contexts>
<marker>Heilman, Collins-Thompson, Callan, Eskenazi, 2007</marker>
<rawString>Michael Heilman, Kevyn Collins-Thompson, Jamie Callan and Max Eskenazi (2007). Combining lexical and grammatical features to improve readability measures for first and second language texts. In the Proceedings of NAACL HLT 2007, pages 460-467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Kevyn Collins-Thompson</author>
<author>Maxine Eskenazi</author>
</authors>
<title>An Analysis of Statistical Models and Features for Reading Difficulty Prediction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>71--79</pages>
<contexts>
<context position="5020" citStr="Heilman et al., 2008" startWordPosition="764" endWordPosition="767">e. With our readability assessment tool, the author is able to automatically check the complexity/readability level of the original text, as well as modified versions of such text produced as he/she applies simplification operations offered by SIMPLIFICA, until the text reaches the expected level, adequate for the target reader. In this paper we present such readability assessment tool, developed as part of the PorSimples project, and discuss its application within the authoring tool. Different from previous work, the tool does not model text difficulty according to linear grade levels (e.g., Heilman et al., 2008), but instead maps the text into the three levels of literacy defined by INAF: rudimentary, basic or advanced. Moreover, it uses a more comprehensive set of features, different learning techniques and targets a new language and application, as we discuss in Section 4. More specifically, we address the following research questions: 1. Given some training material, is it possible to detect the complexity level of Portuguese texts, which corresponds to the different literacy levels defined by INAF? 2. What is the best way to model this problem and which features are relevant? We experiment with n</context>
<context position="14893" citStr="Heilman et al. (2008)" startWordPosition="2311" endWordPosition="2314"> the area of essay scoring (Burstein et al., 2003). The following studies address readability assessment for specific audiences: learners of English as second language (Schwarm and Ostendorf, 2005; Heilman et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models for literary and expository texts, given that traditional metrics like Flesch-Kincaid Level score tend to overpredict the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate scale of measurement for reading difficulty – nominal, ordinal, or interval – by comparing the effectiveness of statistical models for each type of data. Petersen and Ostendorf (2009) use classification and regression techniques to predict a readability score. Miltsakali and Troutt (2007; 2008) propose an automatic tool to evaluate reading difficulty of Web texts in real time, addressing teenagers and adults with low literacy levels. Using machine learning, Glöckner et al. (2006) present a tool for automatically rating the readability of German texts using several l</context>
<context position="27247" citStr="Heilman et al., 2008" startWordPosition="4253" endWordPosition="4256">atural 0.497 strong 0.05 Basic original 0.83 0.73 0.231 natural 0.334 strong 0.637 Syntactic original 0.891 0.81 0.180 natural 0.382 strong 0.714 Coh- original 0.878 0.8 0.183 Metrix- natural 0.432 PORT strong 0.709 Flesch original 0.746 0.56 0.310 natural 0.489 strong 0 Table 6: Ordinal classification The results of the standard and ordinal classification are comparable in terms of F-measure and correlation, but the mean absolute error is lower for the ordinal classification. This indicates that ordinal classification is more adequate to handle our classes, similarly to the results found in (Heilman et al., 2008). Results also show that distinguishing between natural and strong simplifications is a harder problem than distinguishing between these and original texts. This was expected, since these two levels of simplification share many features. However, the average performance achieved is considered satisfactory. Concerning the regression model (Table 7), the RBF kernel reaches the best correlation scores 7 among all models. However, its mean error rates are above the ones found for classification. A linear SVM (not shown here) achieves very poor results across all metrics. Features Corr. MAE All 0.8</context>
</contexts>
<marker>Heilman, Collins-Thompson, Eskenazi, 2008</marker>
<rawString>Michael Heilman, Kevyn Collins-Thompson and Maxine Eskenazi (2008). An Analysis of Statistical Models and Features for Reading Difficulty Prediction. In Proceedings of the 3rd Workshop on Innovative Use of NLP for Building Educational Applications, pages 71-79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>INAF</author>
</authors>
<title>Instituto P. Montenegro and Ação Educativa. INAF Brasil - Indicador de Alfabetismo Funcional -</title>
<date>2009</date>
<note>Available online at http://www. ibope. com.br/ipm/relatorios/relatorio_inaf_2009.pdf</note>
<contexts>
<context position="1395" citStr="INAF, 2009" startWordPosition="202" endWordPosition="203">th alternative ways to model this problem using machine learning methods, namely classification, regression and ranking. The best resulting model is embedded in an authoring tool for Text Simplification. 1 Introduction In Brazil, the National Indicator of Functional Literacy (INAF) index has been computed annually since 2001 to measure the levels of literacy of the Brazilian population. The 2009 report presented a worrying scenario: 7% of the individuals are illiterate; 21% are literate at the rudimentary level; 47% are literate at the basic level; only 25% are literate at the advanced level (INAF, 2009). These literacy levels are defined as: (1) Illiterate: individuals who cannot perform simple tasks such as reading words and phrases; (2) Rudimentary: individuals who can find explicit information in short and familiar texts (such as an advertisement or a short letter); (3) Basic: individuals who are functionally literate, i.e., they can read and understand texts of average length, and find information even when it is necessary to make some inference; and (4) Advanced: fully literate individuals, who can read longer texts, relating their parts, comparing and interpreting information, distingu</context>
</contexts>
<marker>INAF, 2009</marker>
<rawString>INAF (2009). Instituto P. Montenegro and Ação Educativa. INAF Brasil - Indicador de Alfabetismo Funcional - 2009. Available online at http://www. ibope. com.br/ipm/relatorios/relatorio_inaf_2009.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teresa B F Martins</author>
<author>Claudete M Ghiraldelo</author>
</authors>
<title>Maria das Graças V. Nunes e Osvaldo N. de Oliveira Jr.</title>
<date>1996</date>
<tech>ICMC Technical Report, N. 28,</tech>
<pages>11</pages>
<marker>Martins, Ghiraldelo, 1996</marker>
<rawString>Teresa B. F. Martins, Claudete M. Ghiraldelo, Maria das Graças V. Nunes e Osvaldo N. de Oliveira Jr. (1996). Readability formulas applied to textbooks in brazilian portuguese. ICMC Technical Report, N. 28, 11p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurélien Max</author>
</authors>
<title>Writing for Language-impaired Readers.</title>
<date>2006</date>
<booktitle>In Proceedings of CICLing,</booktitle>
<pages>567--570</pages>
<contexts>
<context position="6644" citStr="Max, 2006" startWordPosition="1016" endWordPosition="1017"> information on the need for a readability assessment tool within our text simplification system (Section 2) and discuss prior work on readability assessment (Section 3), to then present our features and modeling techniques (Section 4) and the experiments performed to answer our research questions (Section 5). 2. Text Simplification in PorSimples Text Simplification (TS) aims to maximize reading comprehension of written texts through their simplification. Simplification usually involves substituting complex by simpler words and breaking down and changing the syntax of complex, long sentences (Max, 2006; Siddharthan, 2003). To meet the needs of people with different levels of literacy, in the PorSimples project we propose two types of simplification: natural and strong. The first type results in texts adequate for people with a basic literacy level and the second, rudimentary level. The difference between these two is the degree of application of simplification operations to complex sentences. In strong simplification, operations are applied to all complex syntactic phenomena present in the text in order to make it as simple as possible, while in natural simplification these operations are a</context>
</contexts>
<marker>Max, 2006</marker>
<rawString>Aurélien Max (2006). Writing for Language-impaired Readers. In Proceedings of CICLing, pages 567-570.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danielle McNamara</author>
<author>Max Louwerse</author>
<author>Art Graesser</author>
</authors>
<title>Coh-Metrix: Automated cohesion and coherence scores to predict text readability and facilitate comprehension. Grant proposal.</title>
<date>2002</date>
<note>http://cohmetrix. memphis.edu/cohmetrixpr/publications.html</note>
<contexts>
<context position="9178" citStr="McNamara et al., 2002" startWordPosition="1432" endWordPosition="1435">texts The association between these two types of simplification and the literacy levels was identified by means of a corpus study. We have manually built a corpus of simplified texts at both natural and 2 strong levels and analyzed their linguistic structures according to the description of the two literacy levels. We verified that strong simplified sentences are more adequate for rudimentary level readers, and natural ones for basic level readers. This claim is supported by several studies which relate capabilities and performance of the working memory with reading levels (Siddharthan, 2003; McNamara et al., 2002). 2.1 The Rule-based Simplification System The association between simplification operations and the syntactic phenomena they address is implemented within a rule-based syntactic simplification system (Candido Jr. et al., 2009). This system is able to identify complex syntactic phenomena in a sentence and perform the appropriate operations to simplify each phenomenon. The simplification rules follow a manual for syntactic simplification in Portuguese also developed in PorSimples. They cover syntactic constructions such as apposition, relative clauses, coordination and subordination, which had </context>
</contexts>
<marker>McNamara, Louwerse, Graesser, 2002</marker>
<rawString>Danielle McNamara, Max Louwerse, and Art Graesser, 2002. Coh-Metrix: Automated cohesion and coherence scores to predict text readability and facilitate comprehension. Grant proposal. http://cohmetrix. memphis.edu/cohmetrixpr/publications.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Audrey Troutt</author>
</authors>
<title>Read-X: Automatic Evaluation of Reading Difficulty of Web Text.</title>
<date>2007</date>
<booktitle>In the Proceedings of E-Learn 2007,</booktitle>
<location>Quebec, Canada.</location>
<marker>Miltsakaki, Troutt, 2007</marker>
<rawString>Eleni Miltsakaki and Audrey Troutt (2007). Read-X: Automatic Evaluation of Reading Difficulty of Web Text. In the Proceedings of E-Learn 2007, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Audrey Troutt</author>
</authors>
<title>Real Time Web Text Classification and Analysis of Reading Difficulty.</title>
<date>2008</date>
<booktitle>In the Proceedings of the 3rd Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<location>Columbus, OH.</location>
<marker>Miltsakaki, Troutt, 2008</marker>
<rawString>Eleni Miltsakaki and Audrey Troutt (2008). Real Time Web Text Classification and Analysis of Reading Difficulty. In the Proceedings of the 3rd Workshop on Innovative Use of NLP for Building Educational Applications, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cláudia Oliveira</author>
<author>Maria C Freitas</author>
<author>Violeta Quental</author>
<author>Cí-cero N dos Santos</author>
<author>P L Renato</author>
<author>Lucas Souza</author>
</authors>
<title>A Set of NP-extraction rules for Portuguese: defining and learning.</title>
<date>2006</date>
<booktitle>In 7th Workshop on Computational Processing of Written and Spoken Portuguese,</booktitle>
<location>Itatiaia, Brazil.</location>
<contexts>
<context position="19952" citStr="Oliveira et al., 2006" startWordPosition="3117" endWordPosition="3120">vocabulary words 51 LM probability of unigrams 52 LM perplexity of unigrams 53 LM perplexity of unigrams, without line break 54 LM probability of bigrams 55 LM perplexity of bigrams 56 LM perplexity of bigrams, without line break 57 LM probability of trigrams 58 LM perplexity of trigrams 59 LM perplexity of trigrams, without line break Table 2. Feature set 5 4. Logical operators: features 25 to 29. The following resources for Portuguese were used: the MXPOST POS tagger (Ratnaparkhi, 1996), a word frequency list compiled from a 700 milliontoken corpus2, a tool to identify reduced noun phrases (Oliveira et al., 2006), a list of connectives classified as positives/negatives and according to cohesion type (causal, temporal, additive or logical), a list of logical operators and WordNet.Br (Dias-da-Silva et al., 2008). In this paper we include seven new metrics to Coh-Metrix-PORT: features 13, 14, 21, and 39 to 42. We used TEP3 (Dias-da-Silva et al., 2003) to obtain the number of senses of words (and thus their ambiguity level), and the Palavras parser (Bick, 2000) to identify the higher level constituents. The remaining metrics were computed based on the POS tags. According to a report on the performance of </context>
</contexts>
<marker>Oliveira, Freitas, Quental, Santos, Renato, Souza, 2006</marker>
<rawString>Cláudia Oliveira, Maria C. Freitas, Violeta Quental, Cí-cero N. dos Santos, Renato P. L. and Lucas Souza (2006). A Set of NP-extraction rules for Portuguese: defining and learning. In 7th Workshop on Computational Processing of Written and Spoken Portuguese, Itatiaia, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah E Petersen</author>
<author>Mari Ostendorf</author>
</authors>
<title>A machine learning approach to reading level assessment.</title>
<date>2009</date>
<journal>Computer Speech and Language</journal>
<volume>23</volume>
<pages>89--106</pages>
<contexts>
<context position="15104" citStr="Petersen and Ostendorf (2009)" startWordPosition="2342" endWordPosition="2345">an et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models for literary and expository texts, given that traditional metrics like Flesch-Kincaid Level score tend to overpredict the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate scale of measurement for reading difficulty – nominal, ordinal, or interval – by comparing the effectiveness of statistical models for each type of data. Petersen and Ostendorf (2009) use classification and regression techniques to predict a readability score. Miltsakali and Troutt (2007; 2008) propose an automatic tool to evaluate reading difficulty of Web texts in real time, addressing teenagers and adults with low literacy levels. Using machine learning, Glöckner et al. (2006) present a tool for automatically rating the readability of German texts using several linguistic information sources and a global readability score similar to the Flesch Reading Ease. 4 4. A Tool for Readability Assessment In this section we present our approach to readability assessment. It diffe</context>
</contexts>
<marker>Petersen, Ostendorf, 2009</marker>
<rawString>Sarah E. Petersen and Mari Ostendorf (2009). A machine learning approach to reading level assessment. Computer Speech and Language 23, 89-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Revisiting readability: A unified framework for predicting text quality.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="14067" citStr="Pitler and Nenkova (2008)" startWordPosition="2189" endWordPosition="2192">lity Assessment Recent work on readability assessment for the English language focus on: (i) the feature set used to capture the various aspects of readability, to evaluate the contribution of lexical, syntactic, semantic and discursive features; (ii) the audience of the texts the readability measurement is intended to; (iii) the genre effects on the calculation of text difficult; (iv) the type of learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty. Pitler and Nenkova (2008) propose a unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (Burstein et al., 2003). The following studies address readability assessment for specific audiences: learners of English as second language (Schwarm and Ostendorf, 2005; Heilman et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models</context>
</contexts>
<marker>Pitler, Nenkova, 2008</marker>
<rawString>Emily Pitler and Ani Nenkova (2008). Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Partof-Speech Tagger.</title>
<date>1996</date>
<booktitle>In Proceedings of the First Empirical Methods in Natural Language Processing Conference,</booktitle>
<pages>133--142</pages>
<contexts>
<context position="19823" citStr="Ratnaparkhi, 1996" startWordPosition="3097" endWordPosition="3098">dence of passive voice 47 Incidence of relative clauses 48 Incidence of coordination 49 Incidence of subordination 50 Out-of-vocabulary words 51 LM probability of unigrams 52 LM perplexity of unigrams 53 LM perplexity of unigrams, without line break 54 LM probability of bigrams 55 LM perplexity of bigrams 56 LM perplexity of bigrams, without line break 57 LM probability of trigrams 58 LM perplexity of trigrams 59 LM perplexity of trigrams, without line break Table 2. Feature set 5 4. Logical operators: features 25 to 29. The following resources for Portuguese were used: the MXPOST POS tagger (Ratnaparkhi, 1996), a word frequency list compiled from a 700 milliontoken corpus2, a tool to identify reduced noun phrases (Oliveira et al., 2006), a list of connectives classified as positives/negatives and according to cohesion type (causal, temporal, additive or logical), a list of logical operators and WordNet.Br (Dias-da-Silva et al., 2008). In this paper we include seven new metrics to Coh-Metrix-PORT: features 13, 14, 21, and 39 to 42. We used TEP3 (Dias-da-Silva et al., 2003) to obtain the number of senses of words (and thus their ambiguity level), and the Palavras parser (Bick, 2000) to identify the h</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi (1996). A Maximum Entropy Partof-Speech Tagger. In Proceedings of the First Empirical Methods in Natural Language Processing Conference, pages133-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Margaret Mitchell</author>
<author>Kristy Hollingshead</author>
</authors>
<title>Syntactic complexity measures for detecting mild cognitive impairment.</title>
<date>2007</date>
<booktitle>In the Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Roark, Mitchell, Hollingshead, 2007</marker>
<rawString>Brian Roark, Margaret Mitchell and Kristy Hollingshead (2007). Syntactic complexity measures for detecting mild cognitive impairment. In the Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline E Scarton</author>
<author>Daniel M Almeida</author>
<author>M Sandra</author>
</authors>
<title>Aluísio (2009). Análise da Inteligibilidade de textos via ferramentas de Processamento de Língua Natural: adaptando as métricas do Coh-Metrix para o Português.</title>
<date></date>
<booktitle>In Proceedings of STIL-2009, São Carlos,</booktitle>
<marker>Scarton, Almeida, Sandra, </marker>
<rawString>Caroline E. Scarton, Daniel M. Almeida, Sandra M. Aluísio (2009). Análise da Inteligibilidade de textos via ferramentas de Processamento de Língua Natural: adaptando as métricas do Coh-Metrix para o Português. In Proceedings of STIL-2009, São Carlos, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah E Schwarm</author>
<author>Mari Ostendorf</author>
</authors>
<title>Reading Level Assessment Using Support Vector Machines and Statistical Language Models.</title>
<date>2005</date>
<booktitle>In the Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="14468" citStr="Schwarm and Ostendorf, 2005" startWordPosition="2247" endWordPosition="2250">f learning technique which is more appropriate: those producing nominal, ordinal or interval scales of measurement, and (v) providing an application for the automatic assessment of reading difficulty. Pitler and Nenkova (2008) propose a unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (Burstein et al., 2003). The following studies address readability assessment for specific audiences: learners of English as second language (Schwarm and Ostendorf, 2005; Heilman et al., 2007), people with intellectual disabilities (Feng et al., 2009), and people with cognitive impairment caused by Alzheimer (Roark at al, 2007). Sheehan et al. (2007) focus on models for literary and expository texts, given that traditional metrics like Flesch-Kincaid Level score tend to overpredict the difficulty of literary texts and underpredict the difficulty of expository texts. Heilman et al. (2008) investigate an appropriate scale of measurement for reading difficulty – nominal, ordinal, or interval – by comparing the effectiveness of statistical models for each type of</context>
</contexts>
<marker>Schwarm, Ostendorf, 2005</marker>
<rawString>Sarah E. Schwarm and Mari Ostendorf (2005). Reading Level Assessment Using Support Vector Machines and Statistical Language Models. In the Proceedings of the 43rd Annual Meeting of the ACL, pp 523–530.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kathleen M Sheehan</author>
</authors>
<title>Irene Kostin and Yoko Futagi (2007). Reading Level Assessment for Literary and Expository Texts. In</title>
<booktitle>Proceedings of the 29th Annual Cognitive Science Society,</booktitle>
<pages>1853</pages>
<publisher>Cognitive Science Society.</publisher>
<location>Austin, TX:</location>
<marker>Sheehan, </marker>
<rawString>Kathleen M. Sheehan, Irene Kostin and Yoko Futagi (2007). Reading Level Assessment for Literary and Expository Texts. In D. S. McNamara and J. G. Trafton (Eds.), Proceedings of the 29th Annual Cognitive Science Society, page 1853. Austin, TX: Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Syntactic Simplification and Text Cohesion. PhD Thesis.</title>
<date>2003</date>
<institution>University of Cambridge.</institution>
<contexts>
<context position="6664" citStr="Siddharthan, 2003" startWordPosition="1018" endWordPosition="1019">n on the need for a readability assessment tool within our text simplification system (Section 2) and discuss prior work on readability assessment (Section 3), to then present our features and modeling techniques (Section 4) and the experiments performed to answer our research questions (Section 5). 2. Text Simplification in PorSimples Text Simplification (TS) aims to maximize reading comprehension of written texts through their simplification. Simplification usually involves substituting complex by simpler words and breaking down and changing the syntax of complex, long sentences (Max, 2006; Siddharthan, 2003). To meet the needs of people with different levels of literacy, in the PorSimples project we propose two types of simplification: natural and strong. The first type results in texts adequate for people with a basic literacy level and the second, rudimentary level. The difference between these two is the degree of application of simplification operations to complex sentences. In strong simplification, operations are applied to all complex syntactic phenomena present in the text in order to make it as simple as possible, while in natural simplification these operations are applied selectively, </context>
<context position="9154" citStr="Siddharthan, 2003" startWordPosition="1430" endWordPosition="1431">nal and simplified texts The association between these two types of simplification and the literacy levels was identified by means of a corpus study. We have manually built a corpus of simplified texts at both natural and 2 strong levels and analyzed their linguistic structures according to the description of the two literacy levels. We verified that strong simplified sentences are more adequate for rudimentary level readers, and natural ones for basic level readers. This claim is supported by several studies which relate capabilities and performance of the working memory with reading levels (Siddharthan, 2003; McNamara et al., 2002). 2.1 The Rule-based Simplification System The association between simplification operations and the syntactic phenomena they address is implemented within a rule-based syntactic simplification system (Candido Jr. et al., 2009). This system is able to identify complex syntactic phenomena in a sentence and perform the appropriate operations to simplify each phenomenon. The simplification rules follow a manual for syntactic simplification in Portuguese also developed in PorSimples. They cover syntactic constructions such as apposition, relative clauses, coordination and s</context>
</contexts>
<marker>Siddharthan, 2003</marker>
<rawString>Advaith Siddharthan (2003). Syntactic Simplification and Text Cohesion. PhD Thesis. University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM -- an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<contexts>
<context position="21122" citStr="Stolcke, 2002" startWordPosition="3306" endWordPosition="3307">According to a report on the performance of each Coh-Metrix-PORT metric (Scarton et al., 2009), no individual feature provides sufficient indication to measure text complexity, and therefore the need to exploit their combination, and also to combine them with the other types of features described in this section. 4.1.2 Language-model Features Language model features were derived from a large corpus composed of a sample of the Brazilian newspaper Folha de São Paulo containing issues from 12 months taken at random from 1994 to 2005. The corpus contains 96,868 texts and 26,425,483 tokens. SRILM (Stolcke, 2002), a standard language modelling toolkit, was used to produce the language model features. 4.2 Learning Techniques Given that the boundaries of literacy level classes are one of the subjects of our study, we exploit three different types of models in order to check 2 http://www2.lael.pucsp.br/corpora/bp/index.htm 3 http://www.nilc.icmc.usp.br/tep2/index.htm which of them can better distinguish among the three literacy levels. We therefore experiment with three types of machine learning algorithms: a standard classifier, an ordinal (ranking) classifier and a regressor. Each algorithm assumes dif</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. SRILM -- an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>