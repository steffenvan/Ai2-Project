<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.490623" genericHeader="abstract">
TRANSLATION BY STRUCTURAL CORRESPONDENCES
</sectionHeader>
<author confidence="0.851786">
Ronald M. Kaplan*
Klaus Netter**
Jurgen Wedekind**
Annie Zaenen*
</author>
<affiliation confidence="0.65362">
*Xerox Palo Alto Research Center,
</affiliation>
<address confidence="0.865284">
3333 Coyote Hill Road
Palo Alto, CA 94304, USA
</address>
<email confidence="0.759917">
Kaplan.pa@xerox.com
</email>
<address confidence="0.881745666666667">
** Institut fur Maschinelle Sprachverarbeitung,
17 Keplerstraik
D-7000 Stuttgart 1, FRG
</address>
<email confidence="0.984434">
Bualis@rus.uni-stuttgart.dbp.de
</email>
<sectionHeader confidence="0.99457" genericHeader="keywords">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999815111111111">
We sketch and illustrate an approach to
machine translation that exploits the potential
of simultaneous correspondences between
separate levels of linguistic representation, as
formalized in the LFG notion of codescriptions.
The approach is illustrated with examples
from English, German and French where the
source and the target language sentence show
noteworthy differences in linguistic analysis.
</bodyText>
<sectionHeader confidence="0.997502" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.992643463917526">
In this paper we sketch an approach to
machine translation that offers several
advantages compared to many of the other
strategies currently being pursued. We define
the relationship between the linguistic
structures of the source and target languages
in terms of a set of correspondence functions
instead of providing derivational or procedural
techniques for converting source into target.
This approach permits the mapping between
source and target to depend on information
from various levels of linguistic abstraction
while still preserving the modularity of
linguistic components and of source and target
grammars and lexicons. Our conceptual
framework depends on notions of structure,
structural description, and structural
correspondence. In the following sections we
outline these basic notions and show how they
can be used to deal with certain interesting
translation problems in a simple and
straightforward way. In its emphasis on
description-based techniques, our approach
shares some fundamental features with the
one proposed by Kay (1984), but we use an
explicit projection mechanism to separate out
and organize the intra- and inter-language
components.
Most existing translation systems are either
transfer-based or interlingua-based
Transfer-based systems usually specify a
single level of representation or abstraction at
which transfer is supposed to take place. A
source string is analyzed into a structure at
that level of representation, a transfer
program then converts this into a target
structure at the same level, and the target
string is then generated from this structure
Interlingua-based systems on the other hanc
require that a source string has to be analyzec
into a structure that is identical to a structure
from which a target string has to be generated.
Without further constraints, each of these
approaches could in principle be successful. Ar
interlingual representation could be devised
for example, to contain whatever informatior
is needed to make all the appropriat(
distinctions for all the sentences in all the
languages under consideration. Similarly, E
transfer structure could be arbitraril3
configured to allow for the contrastive analysi:
of any two particular languages. It seem:
unlikely that systems based on such ar
undisciplined arrangement of information wil
ever succeed in practice. Indeed, most
translation researchers have based theii
systems on representations that have SOMI
more general and independent motivation
The levels of traditional linguistic analysi:
(phonology, morphology, syntax, semantics
discourse, etc.) are attractive because the
provide structures with well-defined an(
coherent properties, but a single one of thes1
- 272 -
levels does not contain all the information
needed for adequate translation. The
D-structure level of Government-Binding
theory, for example, contains information
about the predicate-argument relations of a
clause but says nothing about the surface
constituent order that is necessary to
accurately distinguish between old and new
information or topic and comment. As another
example, the functional structures of
Lexical-Functional Grammar do not contain
the ordering information necessary to
determine the scope of quantifiers or other
operators.
Our proposal, as it is set forth below, allows
us to state simultaneous correspondences
between several levels of source-target
representations, and thus is neither
interlingual nor transfer-based. We can
achieve modularity of linguistic specifications,
by not requiring conceptually different kinds of
linguistic information to be combined into a
single structure. Yet that diverse information
is still accessible to determine the set of target
strings that adequately translate a source
string. We also achieve modularity of a more
basic sort: our correspondence mechanism
permits contrastive transfer rules that depend
on but do not duplicate the specifications of
independently motivated grammars of the
source and target languages (Isabelle and
Macklovitch, 1986; Netter and Wedekind,
1986).
</bodyText>
<sectionHeader confidence="0.9935765" genericHeader="method">
A GENERAL ARCHITECTURE FOR
LINGUISTIC DESCRIPTIONS
</sectionHeader>
<bodyText confidence="0.995953285714286">
Our approach uses the equality- and
description-based mechanisms of
Lexical-Functional Grammar. As introduced
by Kaplan and Bresnan (1982),
lexical-functional grammar assigns to every
sentence two levels of syntactic representation,
a constituent structure (c-structure) and a
functional structure (f-structure). These
structures are of different formal types—the
c-structure is a phrase-structure tree while the
f-structure is a hierarchical finite
function—and they characterize different
aspects of the information carried by the
sentence. The c-structure represents the
ordered arrangement of words and phrases in
the sentence while the f-structure explicitly
marks its grammatical functions (subject,
object, etc.). For each type of structure there is
a special notation or description-language in
which the properties of desirable instances of
that type can be specified. Constituent
structures are described by standard
context-free rule notation (augmented with a
variety of abbreviatory devices that do not
change its generative power), while
f-structures are described by Boolean
combinations of function-argument equalities
stated over variables that denote the
structures of interest. Kaplan and Bresnan
assumed a correspondence function mapping
between the nodes in the c-structure of a
sentence and the units of its f-structure, and
used that piecewise function to produce a
description of the f-structure (in its equational
language) by virtue of the mother-daughter,
order, and category relations of the c-structure.
The formal picture developed by Kaplan and
Bresnan, as clarified in Kaplan (1987), is
illustrated in the following structures for
sentence (1):
The c-structure appears on the left, the
f-structure on the right. The c-structure-
to-f-structure correspondence, 4), is shown by
the linking lines. The correspondence 4) is a
many-to-one function taking the S, VP and V
nodes all into the same outermost unit of the
f-stucture,
The node-configuration at the top of the tree
satisfies the statement S --0 NP VP in the
context-free description language for the
c-structure. As suggested by Kaplan (1987),
this is a simple way of defining a collection of
more specific properties of the tree, such as the
fact that the S node (labeled ni) is the mother
of the NP node (n2). These facts could also be
written in equational form as M(n2)=
</bodyText>
<equation confidence="0.450793">
The baby fell.
PRED &apos;fallqbabyp&apos; —
TENSE past
PRED &apos;baby&apos;
NUMB sg
SPEC [RED the]
EF +
f2
- 273 -
</equation>
<bodyText confidence="0.990308045454546">
where M denotes the function that takes a
tree-node into its mother. Similarly, the
outermost f-structure satisfies the assertions
(Ii TENSE) = past, (fi SUM =12, and
(f2 NUMB) = sg in the f-structure description
language. Given the illustrated
correspondence, we also know that fi =4)(ni)
and f2=4)(n2). Taking all these propositions
together, we can infer first that
(4)(n SuBJ) = 4)(n2) and then that
(4)(M(n2)) SuBJ)=4)(n2). This equation
identifies the subject in the f-structure in
terms of the mother-daughter relation in the
tree.
In LFG the f-structure assigned to a sentence
is the smallest one that satisfies the
conjunction of equations in its functional
description. The functional description is
determined from the trees that the c-structure
grammar provides for the string by a simple
matching process. A given tree is analyzed
with respect to the c-structure rules to identify
particular nodes of interest. Equations about
the f-structure corresponding to those nodes
(via 4)) are then derived by substituting those
nodes into equation-patterns or schemata.
Thus, still following Kaplan (1987), if *
appears in a schema to stand for the node
matching a given rule-category, the functional
description will include an equation containing
that node (or an expression such as n2 that
designates it) instead of *. The equation
(4)(M(n2)) suBJ)=4)(n2) that we inferred above
also results from instantiating the schema
(4)(M(*)) Sui3J) =4)(*) annotated to the NP
element of the S rule in (2a) when that
rule-element is matched against the tree in
(lb). Kaplan observes that the t and
metavariables in the Kaplan/Bresnan
formulation of LFG are simply convenient
abbreviations for the complex expressions
4)(M(*)) and 4)(*), respectively, thus explicating
the traditional, more palatable formulation in
(2b).
</bodyText>
<listItem confidence="0.84328725">
(2) (a) S NP VP
4)(M(*)) SuBJ) = 4)(*) 4)(M(*)) =4)(*)
(b) S —0 NP VP
( T suan= 1. T=
</listItem>
<bodyText confidence="0.999473754098361">
This basic conception of descriptions and
correspondences has been extended in several
ways. First, this framework has been
generalized to additional kinds of structures
that represent other subsystems of linguistic
information (Kaplan, 1987; Halvorsen, 1988).
These structures can be related by new
correspondences that permit appropriate
descriptions of more abstract structures to be
produced. Halvorsen and Kaplan (1988), for
example, discuss a level of semantic structure
that encodes predicate-argument relations and
quantifier scope, information that does not
enter into the kinds of syntactic
generalizations that the f-structure supports.
They point out how the semantic structure can
be set in correspondence with both c-structure
and f-structure units by means of related
mappings a and a&apos;. Kaplan (1987) raises the
possibility of further distinct structures and
correspondences to represent anaphoric
dependencies, discourse properties of
sentences, and other projections of the same
string.
Second, Kaplan (1988) and Halvorsen and
Kaplan (1988) discuss other methods for
deriving the descriptions necessary to
determine these abstract structures. The
arrangement outlined above, in which the
description of one kind of structure (the
f-structure) is derived by analyzing or
matching against another one, is an example of
what is called description-by-analysis. The
semantic interpretation mechanisms proposed
by Halvorsen (1983) and Reyle (1988) are other
examples of this descriptive technique. In this
method the grammar provides general
patterns to compare against a given structure
and these are then instantiated if the analysis
is satisfactory. One consequence of this
approach is that the structure in the range of
the correspondence, the one whose description
is being developed, can only have properties
that are derived from information explicitly
identified in the domain structure.
Another description mechanism is possible
when three or more structures are related
through correspondences. Suppose the
c-structure and f-structure are related by 4) as
in (2a) and that the function a then maps the
f-structure units into corresponding units of
semantic structure of the sort suggested by
Fenstad et al. (1987). The formal arrangement
is shown in Figure 1 (next page). This
configuration of cascaded correspondences
opens up a new descriptive possibility. If a and
4) are both structural correspondences, then so
is their composition a 0 4). Thus, even though
the units of the semantic structure correspond
directly only to the units of the f-structure and
have no immediate connection to the nodes of
</bodyText>
<figure confidence="0.996540846153846">
- 274 -
S V PRED
ry\ ft TENSE
NP SUBJ
fl 2,/\\
2A
Det N
The baby fell
&apos;fallqbabyp&apos; —
past
,... SPEC PRED thj
[
PRED &apos;baby&apos;
NUMB sq
EF +
14
ED IN
THE]
[
IEL bab
ARG1
POL 1
GD IND-LOO
rAEL PRECED
RG1
ARG2 LOC-D
—REL
ARG1
fall
IND
SPEC
COND
a
02
LOC
ol POL
[ND
COND
1
</figure>
<figureCaption confidence="0.998488">
Figure 1
</figureCaption>
<bodyText confidence="0.9998106875">
the c-structure, a semantic description can be
formulated in terms of c-structure relations.
The expression a(4)(M(*))) can appear on a
c-structure rule-element to designate the
semantic-structure unit corresponding to the
f-structure that corresponds to the mother of
the node that matches that rule-element.
Since projections are monadic functions, we
can remove the uninformative parentheses and
write (a4:M* ARGO = 0(4)M* SUBJ), or, using the
metavariable, (a I ARGO =a( Kw).
Schemata such as this can be freely mixed with
LFG&apos;s standard functional specifications in
lexical entries and c-structure rules. For
example, the lexical entry for fall might be
given as follows:
</bodyText>
<listItem confidence="0.792503">
(3) fall V (I PRED)=
</listItem>
<equation confidence="0.9737035">
(a I REL) = fall
T ARGO =0( t suflo
</equation>
<bodyText confidence="0.999853018518518">
Descriptions formulated by composing
separate correspondences have a surprising
characteristic: they allow the final range
structure (e.g. the semantic structure) to have
properties that cannot be inferred from any
information present in the intermediate (f-)
structure. But those properties can obtain only
if the intermediate structure is derived from an
initial (c-) structure with certain features. For
example, Kaplan and Maxwell (1988a) exploit
this capability to describe semantic structures
for coordinate constructions which necessarily
contain the logical conjunction appropriate to
the string even though there is no reasonable
place for that conjunction to be marked in the
f-structure. In sum, this method of description,
which has been called codescription, permits
information from a variety of different levels to
constrain a particular structure, even though
there are no direct correspondences linking
them together. It provides for modularity of
basic relationships while allowing certain
necessary restrictions to have their influence.
The descriptive architecture of LFG as
extended by Kaplan and Halvorsen provides
for multiple levels of structure to be related by
separate correspondences, and these
correspondences allow descriptions of the
various structures to be constructed, either by
analysis or composition, from the properties of
other structures. Earlier researchers have
applied these mechanisms to the linguistic
structures for sentences in a single language.
In this paper, we extend this system one step
further: we introduce correspondences
between structures for sentences in different
languages that stand in a translation relation
to one another. The description of the target
language structures are derived via analysis
and codescription from the source language
structures, by virtue of additional annotations
in c-structure rules and lexical entries. Those
descriptions are solved to find satisfying
solutions, and these solutions are then the
input to the target generation process.
In the two language arrangement sketched
below, we introduce the v correspondence to
map between the f-structure units of the source
language and the f-structure units of the target
language. The a correspondence maps from the
f-structure of each language to its own
corresponding semantic structure, and a
second transfer correspondence 1&apos; relates those
structures.
</bodyText>
<figure confidence="0.963640714285714">
- 275 -
Target
0 semantic structure
0 f-structure
1\4)
c-structure
0
</figure>
<bodyText confidence="0.999180327586207">
This arrangement allows us to describe the
target f-structure by composing 4:( and t to form
expressions such as t(4:af* ComP)= (-4•M*
XcomP) or simply t( t COMP) == (i t XC OMP))
This maps a COMP in the source f-structure into
an XCOMP in the target f-structure. The
relations asserted by this equation are depicted
in the following source-target diagram:
As another example, the equation
&amp;quot;e(c) t ARGO = (au t ARM) identifies the first
arguments in the source and target semantic
structures. The equation t&apos;a( t RoBJ)=
43(E t TOPIC) imposes the constraint that the
semantics of the source SUBJ will translate via
t&apos; into the semantics of the target TOPIC but
gives no further information about what those
semantic structures actually contain.
Our general correspondence architecture
thus applies naturally to the problem of
translation. But there are constraints on
correspondences specific to translation that
this general architecture does not address. For
instance, the description of the
target-language structures derived from the
source-language is incomplete. The target
structures may and usually will have
grammatical and semantic features that are
not determined by the source. It makes little
sense, for example, to include information
about grammatical gender in the transfer
process if this feature is exhaustively
determined by the grammar of the target
language. We can formalize the relation
between the information contained in the
transfer component and an adequate
translation of the source sentence into a target
sentence as follows: for a target sentence to be
an adequate translation of a given source
sentence, it must be the case that a minimal
structure assigned to that sentence by the
target grammar is subsumed by a minimal
solution to the transfer description. One
desirable consequence of this formalization is
that it permits two distinct target strings for a
source string whose meaning in the absence of
other information is vague but not ambiguous.
Thus this conceptual and notational
framework provides a powerful and flexible
system for imposing constraints on the form of
a target sentence by relating them to
information that appears at different levels of
source-language abstraction. This apparatus
allows us to avoid many of the problems
encountered by more derivational,
transformational or procedural models of
transfer. We will illustrate our proposal with
examples that have posed challenges for some
other approaches.
</bodyText>
<sectionHeader confidence="0.846048" genericHeader="method">
EXAMPLES
</sectionHeader>
<bodyText confidence="0.9973">
Changes in grammatical function. Some quite
trivial changes in structure occur when the
source and the target predicate differ in the
grammatical functions that they subcategorize
for. We will illustrate this with an example in
which a German transitive verb is translated
with an intransitive verb taking an oblique
complement in French:
</bodyText>
<listItem confidence="0.9999665">
(6) (a) Der Student beantwortet die Frage.
(b) L&apos;etudiant repond a la question.
</listItem>
<bodyText confidence="0.99360425">
We treat the oblique preposition as a PRED that
itself takes an object. Ignoring information
about tense, the lexical entry for beantworten
in the German lexicon looks as follows:
</bodyText>
<figure confidence="0.81831275">
(7) beantworten V
( t PRED)=&apos;beantworten&lt;( C SUBJ)( f OBJ))&apos;
while the transfer lexicon for beantworten
contains the following mapping specifications:
Source
Source Target
loto C r
ttlxcomP C
</figure>
<equation confidence="0.6868734">
- 276 -
I
(8) (t PRED FN) = repondre
(1 SuBJ) = t( t suBJ)
(I AOBJ OBJ) = I( t ow)
</equation>
<bodyText confidence="0.899384333333333">
We use the special attribute FN to designate the
function-name in semantic forms such as
&apos;beantworten &lt; ( t aro( t osm&gt;.. In this
transfer equation it identifies repondre as the
corresponding French predicate. This
specification controls lexical selection in the
target, for example, selecting the following
French lexical entry to be used in the
translation:
</bodyText>
<figure confidence="0.400991">
(9) repondre V
PRED)&amp;repondre&lt;( t SUBJ)( C AOBJ)&gt;&apos;
</figure>
<bodyText confidence="0.9995632">
With these entries and the appropriate but
trivial entries for der Student and die Frage we
get the following f-structure in the source
language and associated f-structure in the
target language for the sentence in (10):
</bodyText>
<figure confidence="0.977588071428571">
&apos; beantwortenqStudent],[Fragep 7
present
f21 RED &apos; Student &apos;
NUMB sg
GEND masc
S
EF +
fd3RED dej
PEC
PRED &apos; Frage &apos;
NUMB sg
GEND fern
A6 SPEC f82g)ITED dij
EF +
</figure>
<bodyText confidence="0.999083571428571">
In the previous example the effects of the
change in grammatical function between the
source and the target language are purely
local. In other cases there is a non-local
dependency between the subcategorizing verb
and a dislocated phrase. This is illustrated by
the relative clause in (11):
</bodyText>
<listItem confidence="0.9798625">
(11) (a) ...der Brief, den der Student zu
beantworten scheint.
(b) ...la lettre, a laquelle l&apos;etudiant
semble repondre.
</listItem>
<bodyText confidence="0.995137375">
...the letter, that the student seemed
to answer.
The within-clause functions of the relativized
phrases in the source and target language are
determined by predicates which may be
arbitrarily deeply embedded, but the
relativized phrase in the target language must
correspond to the one in the source language.
Let us assume that relative clauses can be
analyzed by the following slightly simplified
phrase structure rules, making use of
functional uncertainty (see Kaplan and
Maxwell 1988b for a technical discussion of
functional uncertainty) to capture the
non-local dependency of the relativized phrase
(equations on the head NP are ignored):
</bodyText>
<figure confidence="0.951499090909091">
(12) NP-. NP S&apos;
t RELADJ)=
(10)
PRED
TENSE
SUBJ
OBJ
-PREP &apos; repond reqetud i ant], [lip &apos; —
TENSE present
PRED &apos; etud i ant &apos;
GEND MASC
NUMB sg
SPEC &apos;04 RED 1 €1
T21
EF +
1PRED &apos;a&lt;[question]&gt;&apos;
PCASE AOBJ
PRED &apos;question&apos;
GEND FEM
NUMB sg
I85LE&apos;RED
SPEC FbEF +
</figure>
<page confidence="0.548121">
156
</page>
<bodyText confidence="0.986154333333333">
The second structure is the f-structure the
grammar of French assigns to the sentence in
(6b). This f-structure is the input for the
generation process. Other examples of this
kind are pairs like like and plaire and help and
helfen.
</bodyText>
<equation confidence="0.973140666666667">
S&apos; XP
( t REL-TOPIC) = t=
( XCOMP*GF) =
</equation>
<bodyText confidence="0.982325">
We can achieve the desired correspondence
between the source and the target by
augmenting the first rule with the following
transfer equations:
</bodyText>
<equation confidence="0.9390705">
(13) NP —&gt; NP S&apos;
RELADJ) =
z( t RELADJ) = (It RELADJ)
I( REL-TOPIC)=( REL-TOPIC)
</equation>
<bodyText confidence="0.996500222222222">
The effect of this rule is that the I value of the
relativized phrase (REL-TOPIC) in the source
language is identified with the relativized
phrase in the target language. However, the
source REL-TOPIC is also identified with a
within-clause function, say 0I3J, by the
uncertainty equation in (12). Lexical transfer
rules such as the one given in (8)
independently establish the correspondence
</bodyText>
<figure confidence="0.770520166666667">
z58
AOBJ
SUBJ
&apos;03
OBJ
- 277 -
</figure>
<bodyText confidence="0.958101272727273">
between source and target within-clause
functions. Thus, the target within-clause
function will be identified with the target
relativized phrase. This necessary relation is
accomplished by lexically and structurally
based transfer rules that do not make reference
to each other.
Differences in control. A slightly more complex
but similar case arises when the infinitival
complement of a raising verb is translated into
a finite clause, as in the following:
</bodyText>
<listItem confidence="0.759174666666667">
(14) (a) The student is likely to work.
(b) Il est probable que l&apos;etudiant
travaillera.
</listItem>
<bodyText confidence="0.999681133333333">
In this case the necessary information is
distributed in the following way over the
source, target, and transfer lexicons as shown
in Figure 2.Here the transfer projection builds
up an underspecified target structure, to which
the information given in the entry of probable
is added in the process of generation. Ignoring
the contribution of is, the f-structure for the
English sentence identifies the non-thematic
SUBJ of likely with the thematic SUBJ of work as
follows:
The corresponding French structure in (16)
contains an expletive SUBJ, il, for probable and
an overtly expressed SUBJ for travailler. The
latter is introduced by the transfer entry for
</bodyText>
<note confidence="0.506803">
work:
</note>
<table confidence="0.8738914">
RED &apos;probable&lt;[46:travailler]&gt;[il]&apos;
SUBJ [FORM i
&apos;TIRED &apos;travailler&lt;[19:otudiant])
COMPL que
PRED &apos;etudiant&apos;
GEND MASC
NUMB sg
SPEC T68 PRED
leJ
rEF +
</table>
<subsectionHeader confidence="0.634704">
Its
</subsectionHeader>
<bodyText confidence="0.996461">
Again this f-structure satisfies the transfer
description and is also assigned by the French
grammar to the target sentence.
The use of multiple projections. There is one
detail about the example in (14) that needs
further discussion. Simplifying matters
somewhat, there is a requirement that the
temporal reference point of the complement
has to follow the temporal reference point of
the clause containing likely, if the embedded
verb is a process verb. Basically the same
temporal relations have to hold in French with
probable. The way this is realized will depend
on what the tense of probable is, which in turn
is determined by the discourse up to that point.
A sentence similar to the one given in (13a) but
appearing in a narrative in the past would
translate as the following:
</bodyText>
<figure confidence="0.9933271875">
&apos;1ikelygworkp[student]r
PRED &apos;student&apos;
NUMB sg
SUBJ
SPEC rEF +
/66 PRED thj
/19
XCOMP
/46RED &apos;work&lt;[student
SUBJ [19:student]
[
&apos;PRED
f48
148
COMP
SUBJ
</figure>
<page confidence="0.31259">
146
</page>
<table confidence="0.781330571428572">
likely A probable A
( PRED) = xcomp)&gt;( suEu)&apos; (1 PRED) = &apos;probable&lt;(T comp)&gt;( suBJ).
(1 suto= (1 XCOMP SUBJ) ( SUBJ FORM) = ii
(1 COMP COMPL) =que
(t COMP TENSE) =future
(s1 PRED FN)=probable
t comP)=1( t xcomP)
</table>
<figureCaption confidence="0.894025">
Figure 2
</figureCaption>
<bodyText confidence="0.956601428571429">
- 278 -
likely it is realized in a different way. This can
be expressed by the following equation:
(17) II etait probable que l&apos;etudiant
travaillerait.
In the general case the choice of a French tense
does not depend on the tense of the English
sentence alone but is also determined by
information that is not part of the f-structure
itself. We postulate another projection, the
temporal structure, reached from the
f-structure through the correspondence x (from
xpovutos, temporal). It is not possible to
discuss here the specific characteristics of such
a structure. The only thing that we want to
express is the constraint that the event in the
embedded clause follows the event in the main
clause. We assume that the temporal structure
contains the following information for
likely-to-V, as suggested by Fenstad et al.
(1987):
</bodyText>
<figure confidence="0.7775725">
(18) likely V
(x t COND REL)= precede
(x f COND ARGO = (x f IND)
(X t COND ARG2 ID) = IND-Loc2
</figure>
<bodyText confidence="0.999796909090909">
This is meant to indicate that the temporal
reference point of the event denoted by the
embedded verb extends after the temporal
reference point of the main event. The time of
the main event is in part determined by the
tense of the verb be, which we ignore here. The
only point we want to make is that aspects of
these different projections can be specified in
different parts of the grammar. We assume
that French and English have the same
temporal structure but that in the context of
</bodyText>
<equation confidence="0.775072">
(19) x T = rE T
</equation>
<bodyText confidence="0.999973964285714">
Here the identity between x and xt provides an
interlingua-like approach to this particular
subpart of the relation between the two
languages. This is diagrammed in Figure 3.
Allowing these different projections to
simultaneously determine the surface
structure seems at first blush to complicate the
computational problem of generation, but a
moment of reflection will show that that is not
necessarily so. Although we have split up the
different equations among several projections
for conceptual clarity, computationally we can
consider them to define one big attribute value
structure with x and as special attributes, so
the generation problem in this framework
reduces to the problem of generating from
attribute-value structures which are formally
of the same type as f-structures (see Halvorsen
and Kaplan (1988), Wedekind (1988), and
Momma and Dorre (1987) for discussion).
Differences in embedding. The potential of the
system can also be illustrated with a case in
which we find one more level of embedding in
one language than we find in the other. This is
generally the case if a modifier-head relation
in the source language is reversed in the target
structure. One such example is the relation
between the sentences in (20):
</bodyText>
<listItem confidence="0.9964695">
(20) (a) The baby just fell.
(b) Lebebe vient de tomber.
</listItem>
<table confidence="0.819357411764706">
-PRED &apos;likelygworkP[student]r
RED &apos;student&apos;
NUMB sg
SUBJ +
rDEF fig SPEC f66 ]
XCOMP 146[UBJ [19:student]
RED &apos;workgstudent
7)RED &apos; probabl eqtravai 1 1 e r]&gt;[ i 1] &apos;
SUBJ [FORM i
&apos;RED &apos;travaillergetudiant]&gt;&apos;
COMPL que
FORM finite
PRED &apos;etudiant&apos;
COMP IGENO MASC
NUMB sg
SPEC rEF +
166 PRED ifj
</table>
<figure confidence="0.9812502">
U9
f48
PRED thj
148 146 SUBJ
[
X48 IND BD IND-LOCD
CONDREL precede
ARG1
ARG2 BD IND-LOCal
IND D
g IND-LOC
COND [ARG1
ARG2 go IND-LOCj
EL precede
rc48
</figure>
<figureCaption confidence="0.898926">
Figure 3
</figureCaption>
<bodyText confidence="0.917562666666667">
CP-T - 279 -
One way to encode this relation is given in the
following lexical entry for just (remember that
all the information about the structure of venir
in French will come from the lexicon and
grammar of French itself):
</bodyText>
<equation confidence="0.768590333333333">
(21)just ADV ( t PRED)= lust &lt; ( t ARG)&gt;&apos;
(I t PRED FN) = venir
xcomP) =I( I ARG)
</equation>
<bodyText confidence="0.99979225">
This assigns to just a semantic form that takes
an ARG function as its argument and maps it
into the French venir. This lexical entry is
combined with phrase-structure rule (22). This
rule introduces sentence adverbs and makes
the f-structure corresponding to the S node fill
the ARG function in the f-structure
corresponding to the Acov node.
</bodyText>
<equation confidence="0.833591">
(22) S-4 NP (ADV) VP
(I stai)= =( J, ARG)
</equation>
<bodyText confidence="0.999270161290323">
Note that the f-structure of the Am/ is not
assigned a function within the S-node&apos;s
f-structure, which is shown in (23). This is in
keeping with the fact that the adverb has no
functional interactions with the material in
the main clause.
The relation between the adverb and the
clause is instead represented only in the
f-structure associated with the Am/ node:
In the original formulation of LFG, the
f-structure of the highest node was singled out
and assigned a special status. In our current
theory we do not distinguish that structure
from all the others in the range of cp: the
grammatical analysis of a sentence includes
the complete enumeration of 4)-associations.
The S-node&apos;s f-structure typically does contain
the f-structures of all other nodes as subsidiary
elements, but not in this adverbial case. The
target structures corresponding to the various
f-structures are also not required to be
integrated. These target f-structures can then
be set in correspondence with any nodes of the
target c-structure, subject to the constraints
imposed by the target grammar. In this case,
the fact that venir takes an XCOMP which
corresponds to the ARG of just means that the
target f-structure mapped from the ADV&apos;s
f-structure will be associated with the highest
node of the target c-structure. This is shown in
(25).
</bodyText>
<figure confidence="0.54212275">
PRED &apos; tomberq pbebe &apos;
COMPL de
TENSE inf
123 SUBJ [14 : [Abe]
</figure>
<bodyText confidence="0.996085555555556">
The above analysis does not require a single
integrated source structure to map onto a
single integrated target structure. An
alternative analysis can handle differences of
embedding with completely integrated
structures. If we assign an explicit function to
the adverbial in the source sentence, we can
reverse the embedding in the target by
replacing (22) with (26):
</bodyText>
<equation confidence="0.863765333333333">
(26) S NP (ADV) VP
(I SADJ) =
IT = (-c 4. xcomP)
</equation>
<bodyText confidence="0.999943777777778">
In this case the embedded f-structure of the
source adverb will be mapped onto the
f-structure that corresponds to the root node of
the target c-structure, whereas the f-structure
of the source S is mapped onto the embedded
XCOMP in the target. The advantages and
disadvantages of these different approaches
will be investigated further in Netter and
Wedekind (forthcoming).
</bodyText>
<sectionHeader confidence="0.998008" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.999544444444445">
We have sketched and illustrated an approach
to machine translation that exploits the
potential of simultaneous correspondences
between different levels of linguistic
representation. This is made possible by the
equality and description based mechanisms oi
LFG. This approach relies mainly on
codescription, and thus it is different from
other LFG-based approaches that use g
</bodyText>
<figure confidence="0.991252861111111">
&apos;RED &apos;fallqbabyp&apos;
TENSE past
[
PRED &apos;baby&apos;
NUMB sg
/60 3RED th*j
EF +
. SPEC P
j1.8
( 23 )
SUBJ
[44
-PRED &apos;,justqfallp&apos;
&apos;RED &apos;fallqbabyp&apos;
TENSE past
PRED &apos;baby&apos;
ARG NUMB sg
/60[P)RED the]
r
EF +
SPEC
fi8
(24)
SUBJ
fe fs 4
(25)
RED &apos; veni rqtomberp[bebe]
-PRED &apos; !Abe&apos;
GEND MASC
NUMB sg
SPEC 133 PRED leJ
rEF +
SUBJ
114
XCOMP
- 280 -
</figure>
<bodyText confidence="0.999688052631579">
description-by-analysis mechanism to relate
the f-structure of a source language to the
f-structure of a target language (see for
example Kudo and Nomura, 1986). Our
proposal allows for partial specifications and
multi-level transfer. In that sense it also
differs from strategies pursued for example in
the Eurotra project (Arnold and des Tombe,
1987), where transfer is based on one level of
representation obtained by transforming the
surface structure in successive steps.
We see it as one of the main advantages of
our approach that it allows us to express
correspondences between separate pieces of
linguistically motivated representations and
in this way allows the translator to exploit the
linguistic descriptions of source and target
language in a more direct way than is usually
proposed.
</bodyText>
<sectionHeader confidence="0.998332" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.802847666666667">
Thanks to P.-K. Halvorsen, U. Heid, H. Kamp,
M. Kay and C. Rohrer for discussion and
comments.
</bodyText>
<sectionHeader confidence="0.959498" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.995848776315789">
Arnold, Douglas and Louis des Tombe (1987)
Basic theory and methodology in Eurotra. In
S. Nirenburg (ed.), Machine translation:
Theoretical and methodological issues.
Cambridge: Cambridge University Press,
114-135.
Fenstad, Jens Erik, Per-Kristian Halvorsen,
Tore Langholm, and Johan van Benthem
(1987) Situations, Language and Logic.
Dordrecht: D. Reidel.
Halvorsen, Per-Kristian (1983) Semantics for
lexical-functional grammars. Linguistic
Inquiry, 14(3), 567-613.
Halvorsen, Per-Kristian (1988) Situation
semantics and semantic interpreation in
constraint-base grammars. Proceedings of the
International Conference on Fifth Generation
Computer Systems, Tokyo, Japan, 471-478.
Halvorsen, Per-Kristian and Ronald Kaplan
(1988) Projections and semantic description.
Proceedings of the International Conference on
Fifth Generation Computer Systems, Tokyo,
Japan, 1116-1122.
Isabelle, Pierre and Elliott Macklovitch (1986)
Transfer and MT modularity. Proceedings of
Coling 1986, Bonn, 115-117.
Kaplan, Ronald (1987) Three seductions of
Computational Pyscholinguistics. In Peter
Whitelock et al. (eds.), Linguistic Theory and
Computer Applications. Academic Press,
London, 149-188.
Kaplan, Ronald (1988) Correspondences and
their inverses. Paper presented at the Syntax
and Semantics Workshop, April, Titisee, FRG.
Kaplan, Ronald and Joan Bresnan (1982)
Lexical Functional Grammar: a formal system
for Grammatical representation. In Joan
Bresnan (ed.), The Mental Representation of
Grammatical Relations. MIT Press,
Cambridge, Mass, 173- 281.
Kaplan, Ronald and John Maxwell (1988a).
Constituent coordination in
Lexical-Functional Grammar. Proceedings of
COLING 88, Budapest, 303-305.
Kaplan, Ronald and John Maxwell (1988b).
An algorithm for Functional Uncertainty.
Proceedings of COLING 88, Budapest,
297-302.
Kay, Martin (1984) Functional Unification
Grammar: A formalism for Machine
Translation. Proceedings of Coling 1984,
Stanford University, 75-78.
Kudo, Ikuo and Hirosato Nomura (1986)
Lexical-Functional Transfer: A Transfer
Framework in a Machine Translation System
based on LFG. Proceedings of Coling 1986,
Bonn, 112-114.
Momma, Stefan and Jochen Dorre (1987)
Generation from f-structures. In Ewan Klein
and Johan van Benthem (eds.) Categories,
Polymorphism and Unification, Edinburgh,
Amsterdam, 147-168.
Netter, Klaus and Jurgen Wedekind (1986)
An LFG-based Approach to Machine
Translation. Proceedings of IAI-MT 86,
Saarbrucken, 197-209.
Netter, Klaus and argen Wedekind (in prep.)
Transfer by projection. IMS, Stuttgart.
Reyle, Uwe (1988) Compositional semantics
for LFG. In Uwe Reyle and Christian Rohrer
(eds.), Natural language parsing and linguistic
theories. Dordrecht: D. Reidel, 448-479.
Wedekind, Jurgen (1988) Generation as
Structure Driven Derivation. Proceedings of
COLING 88, Budapest, 732-737.
- 281 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.464352">
<title confidence="0.999129">TRANSLATION BY STRUCTURAL CORRESPONDENCES</title>
<author confidence="0.9020875">Ronald M Kaplan Klaus Netter Jurgen Wedekind Annie Zaenen</author>
<affiliation confidence="0.998858">Xerox Palo Alto Research Center,</affiliation>
<address confidence="0.9991485">3333 Coyote Hill Road Palo Alto, CA 94304, USA</address>
<email confidence="0.99275">Kaplan.pa@xerox.com</email>
<affiliation confidence="0.956203">Institut fur Maschinelle Sprachverarbeitung,</affiliation>
<address confidence="0.967718">17 Keplerstraik D-7000 Stuttgart 1, FRG</address>
<email confidence="0.834576">Bualis@rus.uni-stuttgart.dbp.de</email>
<abstract confidence="0.9994235">We sketch and illustrate an approach to machine translation that exploits the potential of simultaneous correspondences between separate levels of linguistic representation, as in the of codescriptions. The approach is illustrated with examples from English, German and French where the source and the target language sentence show noteworthy differences in linguistic analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas Arnold</author>
<author>Louis des Tombe</author>
</authors>
<title>Basic theory and methodology in Eurotra.</title>
<date>1987</date>
<pages>114--135</pages>
<editor>In S. Nirenburg (ed.),</editor>
<publisher>Cambridge University Press,</publisher>
<marker>Arnold, Tombe, 1987</marker>
<rawString>Arnold, Douglas and Louis des Tombe (1987) Basic theory and methodology in Eurotra. In S. Nirenburg (ed.), Machine translation: Theoretical and methodological issues. Cambridge: Cambridge University Press, 114-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Erik Fenstad</author>
<author>Per-Kristian Halvorsen</author>
<author>Tore Langholm</author>
<author>Johan van Benthem</author>
</authors>
<date>1987</date>
<journal>Situations, Language</journal>
<marker>Fenstad, Halvorsen, Langholm, van Benthem, 1987</marker>
<rawString>Fenstad, Jens Erik, Per-Kristian Halvorsen, Tore Langholm, and Johan van Benthem (1987) Situations, Language and Logic. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per-Kristian Halvorsen</author>
</authors>
<title>Semantics for lexical-functional grammars.</title>
<date>1983</date>
<journal>Linguistic Inquiry,</journal>
<volume>14</volume>
<issue>3</issue>
<pages>567--613</pages>
<contexts>
<context position="10658" citStr="Halvorsen (1983)" startWordPosition="1561" endWordPosition="1562">e possibility of further distinct structures and correspondences to represent anaphoric dependencies, discourse properties of sentences, and other projections of the same string. Second, Kaplan (1988) and Halvorsen and Kaplan (1988) discuss other methods for deriving the descriptions necessary to determine these abstract structures. The arrangement outlined above, in which the description of one kind of structure (the f-structure) is derived by analyzing or matching against another one, is an example of what is called description-by-analysis. The semantic interpretation mechanisms proposed by Halvorsen (1983) and Reyle (1988) are other examples of this descriptive technique. In this method the grammar provides general patterns to compare against a given structure and these are then instantiated if the analysis is satisfactory. One consequence of this approach is that the structure in the range of the correspondence, the one whose description is being developed, can only have properties that are derived from information explicitly identified in the domain structure. Another description mechanism is possible when three or more structures are related through correspondences. Suppose the c-structure a</context>
</contexts>
<marker>Halvorsen, 1983</marker>
<rawString>Halvorsen, Per-Kristian (1983) Semantics for lexical-functional grammars. Linguistic Inquiry, 14(3), 567-613.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per-Kristian Halvorsen</author>
</authors>
<title>Situation semantics and semantic interpreation in constraint-base grammars.</title>
<date>1988</date>
<booktitle>Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>471--478</pages>
<location>Tokyo, Japan,</location>
<contexts>
<context position="9476" citStr="Halvorsen, 1988" startWordPosition="1395" endWordPosition="1396">he tree in (lb). Kaplan observes that the t and metavariables in the Kaplan/Bresnan formulation of LFG are simply convenient abbreviations for the complex expressions 4)(M(*)) and 4)(*), respectively, thus explicating the traditional, more palatable formulation in (2b). (2) (a) S NP VP 4)(M(*)) SuBJ) = 4)(*) 4)(M(*)) =4)(*) (b) S —0 NP VP ( T suan= 1. T= This basic conception of descriptions and correspondences has been extended in several ways. First, this framework has been generalized to additional kinds of structures that represent other subsystems of linguistic information (Kaplan, 1987; Halvorsen, 1988). These structures can be related by new correspondences that permit appropriate descriptions of more abstract structures to be produced. Halvorsen and Kaplan (1988), for example, discuss a level of semantic structure that encodes predicate-argument relations and quantifier scope, information that does not enter into the kinds of syntactic generalizations that the f-structure supports. They point out how the semantic structure can be set in correspondence with both c-structure and f-structure units by means of related mappings a and a&apos;. Kaplan (1987) raises the possibility of further distinct </context>
</contexts>
<marker>Halvorsen, 1988</marker>
<rawString>Halvorsen, Per-Kristian (1988) Situation semantics and semantic interpreation in constraint-base grammars. Proceedings of the International Conference on Fifth Generation Computer Systems, Tokyo, Japan, 471-478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per-Kristian Halvorsen</author>
<author>Ronald Kaplan</author>
</authors>
<title>Projections and semantic description.</title>
<date>1988</date>
<booktitle>Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>1116--1122</pages>
<location>Tokyo, Japan,</location>
<contexts>
<context position="9641" citStr="Halvorsen and Kaplan (1988)" startWordPosition="1416" endWordPosition="1419"> expressions 4)(M(*)) and 4)(*), respectively, thus explicating the traditional, more palatable formulation in (2b). (2) (a) S NP VP 4)(M(*)) SuBJ) = 4)(*) 4)(M(*)) =4)(*) (b) S —0 NP VP ( T suan= 1. T= This basic conception of descriptions and correspondences has been extended in several ways. First, this framework has been generalized to additional kinds of structures that represent other subsystems of linguistic information (Kaplan, 1987; Halvorsen, 1988). These structures can be related by new correspondences that permit appropriate descriptions of more abstract structures to be produced. Halvorsen and Kaplan (1988), for example, discuss a level of semantic structure that encodes predicate-argument relations and quantifier scope, information that does not enter into the kinds of syntactic generalizations that the f-structure supports. They point out how the semantic structure can be set in correspondence with both c-structure and f-structure units by means of related mappings a and a&apos;. Kaplan (1987) raises the possibility of further distinct structures and correspondences to represent anaphoric dependencies, discourse properties of sentences, and other projections of the same string. Second, Kaplan (1988</context>
<context position="26477" citStr="Halvorsen and Kaplan (1988)" startWordPosition="4110" endWordPosition="4113">ferent projections to simultaneously determine the surface structure seems at first blush to complicate the computational problem of generation, but a moment of reflection will show that that is not necessarily so. Although we have split up the different equations among several projections for conceptual clarity, computationally we can consider them to define one big attribute value structure with x and as special attributes, so the generation problem in this framework reduces to the problem of generating from attribute-value structures which are formally of the same type as f-structures (see Halvorsen and Kaplan (1988), Wedekind (1988), and Momma and Dorre (1987) for discussion). Differences in embedding. The potential of the system can also be illustrated with a case in which we find one more level of embedding in one language than we find in the other. This is generally the case if a modifier-head relation in the source language is reversed in the target structure. One such example is the relation between the sentences in (20): (20) (a) The baby just fell. (b) Lebebe vient de tomber. -PRED &apos;likelygworkP[student]r RED &apos;student&apos; NUMB sg SUBJ + rDEF fig SPEC f66 ] XCOMP 146[UBJ [19:student] RED &apos;workgstudent</context>
</contexts>
<marker>Halvorsen, Kaplan, 1988</marker>
<rawString>Halvorsen, Per-Kristian and Ronald Kaplan (1988) Projections and semantic description. Proceedings of the International Conference on Fifth Generation Computer Systems, Tokyo, Japan, 1116-1122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
<author>Elliott Macklovitch</author>
</authors>
<title>Transfer and MT modularity.</title>
<date>1986</date>
<booktitle>Proceedings of Coling</booktitle>
<pages>115--117</pages>
<location>Bonn,</location>
<contexts>
<context position="4775" citStr="Isabelle and Macklovitch, 1986" startWordPosition="676" endWordPosition="679">ations, and thus is neither interlingual nor transfer-based. We can achieve modularity of linguistic specifications, by not requiring conceptually different kinds of linguistic information to be combined into a single structure. Yet that diverse information is still accessible to determine the set of target strings that adequately translate a source string. We also achieve modularity of a more basic sort: our correspondence mechanism permits contrastive transfer rules that depend on but do not duplicate the specifications of independently motivated grammars of the source and target languages (Isabelle and Macklovitch, 1986; Netter and Wedekind, 1986). A GENERAL ARCHITECTURE FOR LINGUISTIC DESCRIPTIONS Our approach uses the equality- and description-based mechanisms of Lexical-Functional Grammar. As introduced by Kaplan and Bresnan (1982), lexical-functional grammar assigns to every sentence two levels of syntactic representation, a constituent structure (c-structure) and a functional structure (f-structure). These structures are of different formal types—the c-structure is a phrase-structure tree while the f-structure is a hierarchical finite function—and they characterize different aspects of the information c</context>
</contexts>
<marker>Isabelle, Macklovitch, 1986</marker>
<rawString>Isabelle, Pierre and Elliott Macklovitch (1986) Transfer and MT modularity. Proceedings of Coling 1986, Bonn, 115-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
</authors>
<title>Three seductions of Computational Pyscholinguistics.</title>
<date>1987</date>
<booktitle>Linguistic Theory and Computer Applications.</booktitle>
<pages>149--188</pages>
<editor>In Peter Whitelock et al. (eds.),</editor>
<publisher>Academic Press,</publisher>
<location>London,</location>
<contexts>
<context position="6470" citStr="Kaplan (1987)" startWordPosition="912" endWordPosition="913">es that do not change its generative power), while f-structures are described by Boolean combinations of function-argument equalities stated over variables that denote the structures of interest. Kaplan and Bresnan assumed a correspondence function mapping between the nodes in the c-structure of a sentence and the units of its f-structure, and used that piecewise function to produce a description of the f-structure (in its equational language) by virtue of the mother-daughter, order, and category relations of the c-structure. The formal picture developed by Kaplan and Bresnan, as clarified in Kaplan (1987), is illustrated in the following structures for sentence (1): The c-structure appears on the left, the f-structure on the right. The c-structureto-f-structure correspondence, 4), is shown by the linking lines. The correspondence 4) is a many-to-one function taking the S, VP and V nodes all into the same outermost unit of the f-stucture, The node-configuration at the top of the tree satisfies the statement S --0 NP VP in the context-free description language for the c-structure. As suggested by Kaplan (1987), this is a simple way of defining a collection of more specific properties of the tree</context>
<context position="8423" citStr="Kaplan (1987)" startWordPosition="1230" endWordPosition="1231">the mother-daughter relation in the tree. In LFG the f-structure assigned to a sentence is the smallest one that satisfies the conjunction of equations in its functional description. The functional description is determined from the trees that the c-structure grammar provides for the string by a simple matching process. A given tree is analyzed with respect to the c-structure rules to identify particular nodes of interest. Equations about the f-structure corresponding to those nodes (via 4)) are then derived by substituting those nodes into equation-patterns or schemata. Thus, still following Kaplan (1987), if * appears in a schema to stand for the node matching a given rule-category, the functional description will include an equation containing that node (or an expression such as n2 that designates it) instead of *. The equation (4)(M(n2)) suBJ)=4)(n2) that we inferred above also results from instantiating the schema (4)(M(*)) Sui3J) =4)(*) annotated to the NP element of the S rule in (2a) when that rule-element is matched against the tree in (lb). Kaplan observes that the t and metavariables in the Kaplan/Bresnan formulation of LFG are simply convenient abbreviations for the complex expressi</context>
<context position="10032" citStr="Kaplan (1987)" startWordPosition="1476" endWordPosition="1477">of linguistic information (Kaplan, 1987; Halvorsen, 1988). These structures can be related by new correspondences that permit appropriate descriptions of more abstract structures to be produced. Halvorsen and Kaplan (1988), for example, discuss a level of semantic structure that encodes predicate-argument relations and quantifier scope, information that does not enter into the kinds of syntactic generalizations that the f-structure supports. They point out how the semantic structure can be set in correspondence with both c-structure and f-structure units by means of related mappings a and a&apos;. Kaplan (1987) raises the possibility of further distinct structures and correspondences to represent anaphoric dependencies, discourse properties of sentences, and other projections of the same string. Second, Kaplan (1988) and Halvorsen and Kaplan (1988) discuss other methods for deriving the descriptions necessary to determine these abstract structures. The arrangement outlined above, in which the description of one kind of structure (the f-structure) is derived by analyzing or matching against another one, is an example of what is called description-by-analysis. The semantic interpretation mechanisms pr</context>
</contexts>
<marker>Kaplan, 1987</marker>
<rawString>Kaplan, Ronald (1987) Three seductions of Computational Pyscholinguistics. In Peter Whitelock et al. (eds.), Linguistic Theory and Computer Applications. Academic Press, London, 149-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
</authors>
<title>Correspondences and their inverses.</title>
<date>1988</date>
<booktitle>Paper presented at the Syntax and Semantics Workshop,</booktitle>
<location>April, Titisee, FRG.</location>
<contexts>
<context position="9641" citStr="Kaplan (1988)" startWordPosition="1418" endWordPosition="1419">)(M(*)) and 4)(*), respectively, thus explicating the traditional, more palatable formulation in (2b). (2) (a) S NP VP 4)(M(*)) SuBJ) = 4)(*) 4)(M(*)) =4)(*) (b) S —0 NP VP ( T suan= 1. T= This basic conception of descriptions and correspondences has been extended in several ways. First, this framework has been generalized to additional kinds of structures that represent other subsystems of linguistic information (Kaplan, 1987; Halvorsen, 1988). These structures can be related by new correspondences that permit appropriate descriptions of more abstract structures to be produced. Halvorsen and Kaplan (1988), for example, discuss a level of semantic structure that encodes predicate-argument relations and quantifier scope, information that does not enter into the kinds of syntactic generalizations that the f-structure supports. They point out how the semantic structure can be set in correspondence with both c-structure and f-structure units by means of related mappings a and a&apos;. Kaplan (1987) raises the possibility of further distinct structures and correspondences to represent anaphoric dependencies, discourse properties of sentences, and other projections of the same string. Second, Kaplan (1988</context>
<context position="26477" citStr="Kaplan (1988)" startWordPosition="4112" endWordPosition="4113">ions to simultaneously determine the surface structure seems at first blush to complicate the computational problem of generation, but a moment of reflection will show that that is not necessarily so. Although we have split up the different equations among several projections for conceptual clarity, computationally we can consider them to define one big attribute value structure with x and as special attributes, so the generation problem in this framework reduces to the problem of generating from attribute-value structures which are formally of the same type as f-structures (see Halvorsen and Kaplan (1988), Wedekind (1988), and Momma and Dorre (1987) for discussion). Differences in embedding. The potential of the system can also be illustrated with a case in which we find one more level of embedding in one language than we find in the other. This is generally the case if a modifier-head relation in the source language is reversed in the target structure. One such example is the relation between the sentences in (20): (20) (a) The baby just fell. (b) Lebebe vient de tomber. -PRED &apos;likelygworkP[student]r RED &apos;student&apos; NUMB sg SUBJ + rDEF fig SPEC f66 ] XCOMP 146[UBJ [19:student] RED &apos;workgstudent</context>
</contexts>
<marker>Kaplan, 1988</marker>
<rawString>Kaplan, Ronald (1988) Correspondences and their inverses. Paper presented at the Syntax and Semantics Workshop, April, Titisee, FRG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>Lexical Functional Grammar: a formal system for Grammatical representation.</title>
<date>1982</date>
<volume>173</volume>
<pages>281</pages>
<editor>In Joan Bresnan (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass,</location>
<contexts>
<context position="4994" citStr="Kaplan and Bresnan (1982)" startWordPosition="704" endWordPosition="707">ure. Yet that diverse information is still accessible to determine the set of target strings that adequately translate a source string. We also achieve modularity of a more basic sort: our correspondence mechanism permits contrastive transfer rules that depend on but do not duplicate the specifications of independently motivated grammars of the source and target languages (Isabelle and Macklovitch, 1986; Netter and Wedekind, 1986). A GENERAL ARCHITECTURE FOR LINGUISTIC DESCRIPTIONS Our approach uses the equality- and description-based mechanisms of Lexical-Functional Grammar. As introduced by Kaplan and Bresnan (1982), lexical-functional grammar assigns to every sentence two levels of syntactic representation, a constituent structure (c-structure) and a functional structure (f-structure). These structures are of different formal types—the c-structure is a phrase-structure tree while the f-structure is a hierarchical finite function—and they characterize different aspects of the information carried by the sentence. The c-structure represents the ordered arrangement of words and phrases in the sentence while the f-structure explicitly marks its grammatical functions (subject, object, etc.). For each type of </context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Kaplan, Ronald and Joan Bresnan (1982) Lexical Functional Grammar: a formal system for Grammatical representation. In Joan Bresnan (ed.), The Mental Representation of Grammatical Relations. MIT Press, Cambridge, Mass, 173- 281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
<author>John Maxwell</author>
</authors>
<title>Constituent coordination in Lexical-Functional Grammar.</title>
<date>1988</date>
<booktitle>Proceedings of COLING 88,</booktitle>
<pages>303--305</pages>
<location>Budapest,</location>
<contexts>
<context position="13291" citStr="Kaplan and Maxwell (1988" startWordPosition="1989" endWordPosition="1992">al specifications in lexical entries and c-structure rules. For example, the lexical entry for fall might be given as follows: (3) fall V (I PRED)= (a I REL) = fall T ARGO =0( t suflo Descriptions formulated by composing separate correspondences have a surprising characteristic: they allow the final range structure (e.g. the semantic structure) to have properties that cannot be inferred from any information present in the intermediate (f-) structure. But those properties can obtain only if the intermediate structure is derived from an initial (c-) structure with certain features. For example, Kaplan and Maxwell (1988a) exploit this capability to describe semantic structures for coordinate constructions which necessarily contain the logical conjunction appropriate to the string even though there is no reasonable place for that conjunction to be marked in the f-structure. In sum, this method of description, which has been called codescription, permits information from a variety of different levels to constrain a particular structure, even though there are no direct correspondences linking them together. It provides for modularity of basic relationships while allowing certain necessary restrictions to have t</context>
<context position="20357" citStr="Kaplan and Maxwell 1988" startWordPosition="3086" endWordPosition="3089">ause in (11): (11) (a) ...der Brief, den der Student zu beantworten scheint. (b) ...la lettre, a laquelle l&apos;etudiant semble repondre. ...the letter, that the student seemed to answer. The within-clause functions of the relativized phrases in the source and target language are determined by predicates which may be arbitrarily deeply embedded, but the relativized phrase in the target language must correspond to the one in the source language. Let us assume that relative clauses can be analyzed by the following slightly simplified phrase structure rules, making use of functional uncertainty (see Kaplan and Maxwell 1988b for a technical discussion of functional uncertainty) to capture the non-local dependency of the relativized phrase (equations on the head NP are ignored): (12) NP-. NP S&apos; t RELADJ)= (10) PRED TENSE SUBJ OBJ -PREP &apos; repond reqetud i ant], [lip &apos; — TENSE present PRED &apos; etud i ant &apos; GEND MASC NUMB sg SPEC &apos;04 RED 1 €1 T21 EF + 1PRED &apos;a&lt;[question]&gt;&apos; PCASE AOBJ PRED &apos;question&apos; GEND FEM NUMB sg I85LE&apos;RED SPEC FbEF + 156 The second structure is the f-structure the grammar of French assigns to the sentence in (6b). This f-structure is the input for the generation process. Other examples of this kin</context>
</contexts>
<marker>Kaplan, Maxwell, 1988</marker>
<rawString>Kaplan, Ronald and John Maxwell (1988a). Constituent coordination in Lexical-Functional Grammar. Proceedings of COLING 88, Budapest, 303-305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
<author>John Maxwell</author>
</authors>
<title>An algorithm for Functional Uncertainty.</title>
<date>1988</date>
<booktitle>Proceedings of COLING 88,</booktitle>
<pages>297--302</pages>
<location>Budapest,</location>
<contexts>
<context position="13291" citStr="Kaplan and Maxwell (1988" startWordPosition="1989" endWordPosition="1992">al specifications in lexical entries and c-structure rules. For example, the lexical entry for fall might be given as follows: (3) fall V (I PRED)= (a I REL) = fall T ARGO =0( t suflo Descriptions formulated by composing separate correspondences have a surprising characteristic: they allow the final range structure (e.g. the semantic structure) to have properties that cannot be inferred from any information present in the intermediate (f-) structure. But those properties can obtain only if the intermediate structure is derived from an initial (c-) structure with certain features. For example, Kaplan and Maxwell (1988a) exploit this capability to describe semantic structures for coordinate constructions which necessarily contain the logical conjunction appropriate to the string even though there is no reasonable place for that conjunction to be marked in the f-structure. In sum, this method of description, which has been called codescription, permits information from a variety of different levels to constrain a particular structure, even though there are no direct correspondences linking them together. It provides for modularity of basic relationships while allowing certain necessary restrictions to have t</context>
<context position="20357" citStr="Kaplan and Maxwell 1988" startWordPosition="3086" endWordPosition="3089">ause in (11): (11) (a) ...der Brief, den der Student zu beantworten scheint. (b) ...la lettre, a laquelle l&apos;etudiant semble repondre. ...the letter, that the student seemed to answer. The within-clause functions of the relativized phrases in the source and target language are determined by predicates which may be arbitrarily deeply embedded, but the relativized phrase in the target language must correspond to the one in the source language. Let us assume that relative clauses can be analyzed by the following slightly simplified phrase structure rules, making use of functional uncertainty (see Kaplan and Maxwell 1988b for a technical discussion of functional uncertainty) to capture the non-local dependency of the relativized phrase (equations on the head NP are ignored): (12) NP-. NP S&apos; t RELADJ)= (10) PRED TENSE SUBJ OBJ -PREP &apos; repond reqetud i ant], [lip &apos; — TENSE present PRED &apos; etud i ant &apos; GEND MASC NUMB sg SPEC &apos;04 RED 1 €1 T21 EF + 1PRED &apos;a&lt;[question]&gt;&apos; PCASE AOBJ PRED &apos;question&apos; GEND FEM NUMB sg I85LE&apos;RED SPEC FbEF + 156 The second structure is the f-structure the grammar of French assigns to the sentence in (6b). This f-structure is the input for the generation process. Other examples of this kin</context>
</contexts>
<marker>Kaplan, Maxwell, 1988</marker>
<rawString>Kaplan, Ronald and John Maxwell (1988b). An algorithm for Functional Uncertainty. Proceedings of COLING 88, Budapest, 297-302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional Unification Grammar: A formalism for Machine Translation.</title>
<date>1984</date>
<booktitle>Proceedings of Coling</booktitle>
<pages>75--78</pages>
<institution>Stanford University,</institution>
<contexts>
<context position="1806" citStr="Kay (1984)" startWordPosition="249" endWordPosition="250">target to depend on information from various levels of linguistic abstraction while still preserving the modularity of linguistic components and of source and target grammars and lexicons. Our conceptual framework depends on notions of structure, structural description, and structural correspondence. In the following sections we outline these basic notions and show how they can be used to deal with certain interesting translation problems in a simple and straightforward way. In its emphasis on description-based techniques, our approach shares some fundamental features with the one proposed by Kay (1984), but we use an explicit projection mechanism to separate out and organize the intra- and inter-language components. Most existing translation systems are either transfer-based or interlingua-based Transfer-based systems usually specify a single level of representation or abstraction at which transfer is supposed to take place. A source string is analyzed into a structure at that level of representation, a transfer program then converts this into a target structure at the same level, and the target string is then generated from this structure Interlingua-based systems on the other hanc require</context>
</contexts>
<marker>Kay, 1984</marker>
<rawString>Kay, Martin (1984) Functional Unification Grammar: A formalism for Machine Translation. Proceedings of Coling 1984, Stanford University, 75-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ikuo Kudo</author>
<author>Hirosato Nomura</author>
</authors>
<title>Lexical-Functional Transfer: A Transfer Framework in a Machine Translation System based on LFG.</title>
<date>1986</date>
<booktitle>Proceedings of Coling</booktitle>
<pages>112--114</pages>
<location>Bonn,</location>
<contexts>
<context position="31161" citStr="Kudo and Nomura, 1986" startWordPosition="4913" endWordPosition="4916">anisms oi LFG. This approach relies mainly on codescription, and thus it is different from other LFG-based approaches that use g &apos;RED &apos;fallqbabyp&apos; TENSE past [ PRED &apos;baby&apos; NUMB sg /60 3RED th*j EF + . SPEC P j1.8 ( 23 ) SUBJ [44 -PRED &apos;,justqfallp&apos; &apos;RED &apos;fallqbabyp&apos; TENSE past PRED &apos;baby&apos; ARG NUMB sg /60[P)RED the] r EF + SPEC fi8 (24) SUBJ fe fs 4 (25) RED &apos; veni rqtomberp[bebe] -PRED &apos; !Abe&apos; GEND MASC NUMB sg SPEC 133 PRED leJ rEF + SUBJ 114 XCOMP - 280 - description-by-analysis mechanism to relate the f-structure of a source language to the f-structure of a target language (see for example Kudo and Nomura, 1986). Our proposal allows for partial specifications and multi-level transfer. In that sense it also differs from strategies pursued for example in the Eurotra project (Arnold and des Tombe, 1987), where transfer is based on one level of representation obtained by transforming the surface structure in successive steps. We see it as one of the main advantages of our approach that it allows us to express correspondences between separate pieces of linguistically motivated representations and in this way allows the translator to exploit the linguistic descriptions of source and target language in a mo</context>
</contexts>
<marker>Kudo, Nomura, 1986</marker>
<rawString>Kudo, Ikuo and Hirosato Nomura (1986) Lexical-Functional Transfer: A Transfer Framework in a Machine Translation System based on LFG. Proceedings of Coling 1986, Bonn, 112-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Momma</author>
<author>Jochen Dorre</author>
</authors>
<title>Generation from f-structures.</title>
<date>1987</date>
<booktitle>In Ewan Klein and Johan van Benthem (eds.) Categories, Polymorphism and Unification,</booktitle>
<pages>147--168</pages>
<location>Edinburgh, Amsterdam,</location>
<contexts>
<context position="26522" citStr="Momma and Dorre (1987)" startWordPosition="4117" endWordPosition="4120"> surface structure seems at first blush to complicate the computational problem of generation, but a moment of reflection will show that that is not necessarily so. Although we have split up the different equations among several projections for conceptual clarity, computationally we can consider them to define one big attribute value structure with x and as special attributes, so the generation problem in this framework reduces to the problem of generating from attribute-value structures which are formally of the same type as f-structures (see Halvorsen and Kaplan (1988), Wedekind (1988), and Momma and Dorre (1987) for discussion). Differences in embedding. The potential of the system can also be illustrated with a case in which we find one more level of embedding in one language than we find in the other. This is generally the case if a modifier-head relation in the source language is reversed in the target structure. One such example is the relation between the sentences in (20): (20) (a) The baby just fell. (b) Lebebe vient de tomber. -PRED &apos;likelygworkP[student]r RED &apos;student&apos; NUMB sg SUBJ + rDEF fig SPEC f66 ] XCOMP 146[UBJ [19:student] RED &apos;workgstudent 7)RED &apos; probabl eqtravai 1 1 e r]&gt;[ i 1] &apos; S</context>
</contexts>
<marker>Momma, Dorre, 1987</marker>
<rawString>Momma, Stefan and Jochen Dorre (1987) Generation from f-structures. In Ewan Klein and Johan van Benthem (eds.) Categories, Polymorphism and Unification, Edinburgh, Amsterdam, 147-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Netter</author>
<author>Jurgen Wedekind</author>
</authors>
<title>An LFG-based Approach to Machine Translation.</title>
<date>1986</date>
<booktitle>Proceedings of IAI-MT 86, Saarbrucken,</booktitle>
<pages>197--209</pages>
<contexts>
<context position="4803" citStr="Netter and Wedekind, 1986" startWordPosition="680" endWordPosition="683">rlingual nor transfer-based. We can achieve modularity of linguistic specifications, by not requiring conceptually different kinds of linguistic information to be combined into a single structure. Yet that diverse information is still accessible to determine the set of target strings that adequately translate a source string. We also achieve modularity of a more basic sort: our correspondence mechanism permits contrastive transfer rules that depend on but do not duplicate the specifications of independently motivated grammars of the source and target languages (Isabelle and Macklovitch, 1986; Netter and Wedekind, 1986). A GENERAL ARCHITECTURE FOR LINGUISTIC DESCRIPTIONS Our approach uses the equality- and description-based mechanisms of Lexical-Functional Grammar. As introduced by Kaplan and Bresnan (1982), lexical-functional grammar assigns to every sentence two levels of syntactic representation, a constituent structure (c-structure) and a functional structure (f-structure). These structures are of different formal types—the c-structure is a phrase-structure tree while the f-structure is a hierarchical finite function—and they characterize different aspects of the information carried by the sentence. The </context>
</contexts>
<marker>Netter, Wedekind, 1986</marker>
<rawString>Netter, Klaus and Jurgen Wedekind (1986) An LFG-based Approach to Machine Translation. Proceedings of IAI-MT 86, Saarbrucken, 197-209.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Klaus Netter</author>
</authors>
<title>and argen Wedekind (in prep.) Transfer by projection. IMS,</title>
<location>Stuttgart.</location>
<marker>Netter, </marker>
<rawString>Netter, Klaus and argen Wedekind (in prep.) Transfer by projection. IMS, Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe Reyle</author>
</authors>
<title>Compositional semantics for LFG.</title>
<date>1988</date>
<booktitle>In Uwe Reyle and Christian Rohrer (eds.), Natural language parsing and linguistic theories.</booktitle>
<pages>448--479</pages>
<editor>D. Reidel,</editor>
<location>Dordrecht:</location>
<contexts>
<context position="10675" citStr="Reyle (1988)" startWordPosition="1564" endWordPosition="1565">her distinct structures and correspondences to represent anaphoric dependencies, discourse properties of sentences, and other projections of the same string. Second, Kaplan (1988) and Halvorsen and Kaplan (1988) discuss other methods for deriving the descriptions necessary to determine these abstract structures. The arrangement outlined above, in which the description of one kind of structure (the f-structure) is derived by analyzing or matching against another one, is an example of what is called description-by-analysis. The semantic interpretation mechanisms proposed by Halvorsen (1983) and Reyle (1988) are other examples of this descriptive technique. In this method the grammar provides general patterns to compare against a given structure and these are then instantiated if the analysis is satisfactory. One consequence of this approach is that the structure in the range of the correspondence, the one whose description is being developed, can only have properties that are derived from information explicitly identified in the domain structure. Another description mechanism is possible when three or more structures are related through correspondences. Suppose the c-structure and f-structure ar</context>
</contexts>
<marker>Reyle, 1988</marker>
<rawString>Reyle, Uwe (1988) Compositional semantics for LFG. In Uwe Reyle and Christian Rohrer (eds.), Natural language parsing and linguistic theories. Dordrecht: D. Reidel, 448-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jurgen Wedekind</author>
</authors>
<title>Generation as Structure Driven Derivation.</title>
<date>1988</date>
<booktitle>Proceedings of COLING 88,</booktitle>
<pages>732--737</pages>
<location>Budapest,</location>
<contexts>
<context position="26494" citStr="Wedekind (1988)" startWordPosition="4114" endWordPosition="4115">neously determine the surface structure seems at first blush to complicate the computational problem of generation, but a moment of reflection will show that that is not necessarily so. Although we have split up the different equations among several projections for conceptual clarity, computationally we can consider them to define one big attribute value structure with x and as special attributes, so the generation problem in this framework reduces to the problem of generating from attribute-value structures which are formally of the same type as f-structures (see Halvorsen and Kaplan (1988), Wedekind (1988), and Momma and Dorre (1987) for discussion). Differences in embedding. The potential of the system can also be illustrated with a case in which we find one more level of embedding in one language than we find in the other. This is generally the case if a modifier-head relation in the source language is reversed in the target structure. One such example is the relation between the sentences in (20): (20) (a) The baby just fell. (b) Lebebe vient de tomber. -PRED &apos;likelygworkP[student]r RED &apos;student&apos; NUMB sg SUBJ + rDEF fig SPEC f66 ] XCOMP 146[UBJ [19:student] RED &apos;workgstudent 7)RED &apos; probabl </context>
</contexts>
<marker>Wedekind, 1988</marker>
<rawString>Wedekind, Jurgen (1988) Generation as Structure Driven Derivation. Proceedings of COLING 88, Budapest, 732-737.</rawString>
</citation>
<citation valid="false">
<pages>281</pages>
<marker></marker>
<rawString>- 281 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>