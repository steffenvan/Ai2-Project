<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003450">
<title confidence="0.995914">
Tracking Initiative in Collaborative Dialogue Interactions
</title>
<author confidence="0.867822">
Jennifer Chu-Carroll and Michael K. Brown
</author>
<affiliation confidence="0.661445">
Bell Laboratories
</affiliation>
<address confidence="0.777916666666667">
Lucent Technologies
600 Mountain Avenue
Murray Hill, NJ 07974, U.S.A.
</address>
<email confidence="0.993776">
E-mail: {jencc,mkb} @bell-labs.com
</email>
<sectionHeader confidence="0.993724" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999921714285714">
In this paper, we argue for the need to dis-
tinguish between task and dialogue initiatives,
and present a model for tracking shifts in both
types of initiatives in dialogue interactions.
Our model predicts the initiative holders in the
next dialogue turn based on the current initia-
tive holders and the effect that observed cues
have on changing them. Our evaluation across
various corpora shows that the use of cues con-
sistently improves the accuracy in the system&apos;s
prediction of task and dialogue initiative hold-
ers by 2-4 and 8-13 percentage points, respec-
tively, thus illustrating the generality of our
model.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963105263158">
Naturally-occurring collaborative dialogues are very
rarely, if ever, one-sided. Instead, initiative of the in-
teraction shifts among participants in a primarily princi-
pled fashion, signaled by features such as linguistic cues,
prosodic cues and, in face-to-face interactions, eye gaze
and gestures. Thus, for a dialogue system to interact with
its user in a natural and coherent manner, it must recog-
nize the user&apos;s cues for initiative shifts and provide ap-
propriate cues in its responses to user utterances.
Previous work on mixed-initiative dialogues focused
on tracking a single thread of control among participants.
We argue that this view of initiative fails to distinguish
between task initiative and dialogue initiative, which to-
gether determine when and how an agent will address
an issue. Although physical cues, such as gestures and
eye gaze, play an important role in coordinating initia-
tive shifts in face-to-face interactions, a great deal of
information regarding initiative shifts can be extracted
from utterances based on linguistic and domain knowl-
edge alone. By taking into account such cues during dia-
logue interactions, the system is better able to determine
the task and dialogue initiative holders for each turn and
to tailor its response to user utterances accordingly.
In this paper, we show how distinguishing between
task and dialogue initiatives accounts for phenomena in
collaborative dialogues that previous models were unable
to explain. We show that a set of cues, which can be
recognized based on linguistic and domain knowledge
alone, can be utilized by a model for tracking initiative
to predict the task and dialogue initiative holders with
99.1% and 87.8% accuracies, respectively, in collabo-
rative planning dialogues. Furthermore, application of
our model to dialogues in various other collaborative en-
vironments consistently increases the accuracies in the
prediction of task and dialogue initiative holders by 2-4
and 8-13 percentage points, respectively, compared to a
simple prediction method without the use of cues, thus
illustrating the generality of our model.
</bodyText>
<sectionHeader confidence="0.838892" genericHeader="method">
2 Task Initiative vs. Dialogue Initiative
</sectionHeader>
<subsectionHeader confidence="0.998084">
2.1 Motivation
</subsectionHeader>
<bodyText confidence="0.99995855">
Previous work on mixed-initiative dialogues focused on
tracking and allocating a single thread of control, the
conversational lead, among participants. Novick (1988)
developed a computational model that utilizes meta-
locutionary acts, such as repeat and give-turn, to cap-
ture mixed-initiative behavior in dialogues. Whittaker
and Stenton (1988) devised rules for allocating dialogue
control based on utterance types, and Walker and Whit-
taker (1990) utilized these rules for an analytical study
on discourse segmentation. Kitano and Van Ess-Dykema
(1991) developed a plan-based dialogue understanding
model that tracks the conversational initiative based on
the domain and discourse plans behind the utterances.
Smith and Hipp (1994) developed a dialogue system that
varies its responses to user utterances based on four di-
alogue modes which model different levels of initiative
exhibited by dialogue participants. However, the dia-
logue mode is determined at the outset and cannot be
changed during the dialogue. Guinn (1996) subsequently
developed a system that allows change in the level of mi-
</bodyText>
<page confidence="0.992548">
262
</page>
<bodyText confidence="0.999341777777778">
tiative based on initiative-changing utterances and each
agent&apos;s competency in completing the current subtask.
However, we contend that merely maintaining the con-
versational lead is insufficient for modeling complex be-
havior commonly found in naturally-occurring collabo-
rative dialogues (SRI Transcripts, 1992; Gross, Allen,
and Traum, 1993; Heeman and Allen, 1995). For in-
stance, consider the alternative responses in utterances
(3a)-(3c), given by an advisor to a student&apos;s question:
</bodyText>
<listItem confidence="0.880070181818182">
(1) S: I want to take NLP to satisfy my seminar
course requirement.
(2) Who is teaching NLP?
(3a) A: Dr Smith is teaching NLP.
(3b) A: You can&apos;t take NLP because you haven&apos;t
taken Al, which is a prerequisite for NLP
(3c) A: You can&apos;t take NLP because you haven&apos;t
taken AI, which is a prerequisite for NLP
You should take distributed programming
to satisfy your requirement, and sign up
as a listener for NLP
</listItem>
<bodyText confidence="0.9963714">
Suppose we adopt a model that maintains a single
thread of control, such as that of (Whittaker and Stenton,
1988). In utterance (3a), A directly responds to S&apos;s ques-
tion; thus the conversational lead remains with S. On the
other hand, in (3b) and (3c), A takes the lead by initiating
a subdialogue to correct S&apos;s invalid proposal. However,
existing models cannot explain the difference in the two
responses, namely that in (3c), A actively participates in
the planning process by explicitly proposing domain ac-
tions, whereas in (3b), she merely conveys the invalid-
ity of S&apos;s proposal. Based on this observation, we argue
that it is necessary to distinguish between task initiative,
which tracks the lead in the development of the agents&apos;
plan, and dialogue initiative, which tracks the lead in de-
termining the current discourse focus (Chu-Carroll and
Brown, 1997).&apos; This distinction then allows us to explain
A&apos;s behavior from a response generation point of view: in
(3b), A responds to S&apos;s proposal by merely taking over
the dialogue initiative, i.e., informing S of the invalidity
of the proposal, while in (3c), A responds by taking over
both the task and dialogue initiatives, i.e., informing S of
the invalidity and suggesting a possible remedy.
An agent is said to have the task initiative if she is
directing how the agents&apos; task should be accomplished,
i.e., if her utterances directly propose actions that the
Although independently conceived, this distinction be-
tween task and dialogue initiatives is similar to the notion of
choice of task and choice of speaker in initiative in (Novick
and Sutton, 1997), and the distinction between control and ini-
tiative in (Jordan and Di Eugenio, 1997).
</bodyText>
<table confidence="0.996028">
TI: system TI: manager
DI: system 37 (3.5%) 274 (26.3%)
DI: manager 4 (0.4%) 727 (69.8%)
</table>
<tableCaption confidence="0.999644">
Table 1: Distribution of Task and Dialogue Initiatives
</tableCaption>
<bodyText confidence="0.999974826086956">
agents should perform. The utterances may propose
domain actions (Litman and Allen, 1987) that directly
contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s
send engine E2 to Corning.&amp;quot; On the other hand, they
may propose problem-solving actions (Allen, 1991;
Lambert and Carberry, 1991; Ramshaw, 1991) that con-
tribute not directly to the agents&apos; domain goal, but to how
they would go about achieving this goal, such as &amp;quot;Let&apos;s
look at the first [problem] first.&amp;quot; An agent is said to have
the dialogue initiative if she takes the conversational
lead in order to establish mutual beliefs, such as mutual
beliefs about a piece of domain knowledge or about the
validity of a proposal, between the agents. For instance,
in responding to agent A&apos;s proposal of sending a boxcar
to Corning via Dansville, agent B may take over the dia-
logue initiative (but not the task initiative) by saying &amp;quot;We
can&apos;t go by Dansville because we&apos;ve got Engine 1 going
on that track&amp;quot; Thus, when an agent takes over the task
initiative, she also takes over the dialogue initiative, since
a proposal of actions can be viewed as an attempt to es-
tablish the mutual belief that a set of actions be adopted.
On the other hand, an agent may take over the dialogue
initiative but not the task initiative, as in (3b) above.
</bodyText>
<subsectionHeader confidence="0.999848">
2.2 An Analysis of the TRAINS91 Dialogues
</subsectionHeader>
<bodyText confidence="0.999983368421053">
To analyze the distribution of task/dialogue initiatives
in collaborative planning dialogues, we annotated the
TRAINS91 dialogues (Gross, Allen, and Traum, 1993)
as follows: each dialogue turn is given two labels, task
initiative (T1) and dialogue initiative (DI), each of which
can be assigned one of two values, system or manager,
depending on which agent holds the task/dialogue initia-
tive during that turn.2
Table 1 shows the distribution of task and dialogue ini-
tiatives in the TRAINS91 dialogues. It shows that while
in the majority of turns, the task and dialogue initiatives
are held by the same agent, in approximately 1/4 of the
turns, the agents&apos; behavior can be better accounted for by
tracking the two types of initiatives separately.
To assess the reliability of our annotations, approxi-
mately 10% of the dialogues were annotated by two ad-
ditional coders. We then used the kappa statistic (Siegel
and Castellan, 1988; Carletta, 1996) to assess the level of
agreement between the three coders with respect to the
</bodyText>
<footnote confidence="0.633713333333333">
2 An agent holds the task initiative during a turn as long as
some utterance during the turn directly proposes how the agents
should accomplish their goal, as in utterance (3c).
</footnote>
<page confidence="0.998162">
263
</page>
<bodyText confidence="0.99992044">
task and dialogue initiative holders. In this experiment,
K is 0.57 for the task initiative holder agreement and K
is 0.69 for the dialogue initiative holder agreement.
Carletta suggests that content analysis researchers
consider K &gt;.8 as good reliability, with .67&lt; K &lt;.8
allowing tentative conclusions to be drawn (Carletta,
1996). Strictly based on this metric, our results indicate
that the three coders have a reasonable level of agree-
ment with respect to the dialogue initiative holders, but
do not have reliable agreement with respect to the task
initiative holders. However, the kappa statistic is known
to be highly problematic in measuring inter-coder reli-
ability when the likelihood of one category being cho-
sen overwhelms that of the other (Grove et al., 1981),
which is the case for the task initiative distribution in the
TRAINS91 corpus, as shown in Table 1. Furthermore, as
will be shown in Table 4, Section 4, the task and dialogue
initiative distributions in TRAINS91 are not at all repre-
sentative of collaborative dialogues. We expect that by
taking a sample of dialogues whose task/dialogue initia-
tive distributions are more representative of all dialogues,
we will lower the value of P(E), the probability of chance
agreement, and thus obtain a higher kappa coefficient of
agreement. However, we leave selecting and annotating
such a subset of representative dialogues for future work.
</bodyText>
<sectionHeader confidence="0.995534" genericHeader="method">
3 A Model for Tracking Initiative
</sectionHeader>
<bodyText confidence="0.999994472727273">
Our analysis shows that the task and dialogue initiatives
shift between the participants during the course of a di-
alogue. We contend that it is important for the agents
to take into account signals for such initiative shifts for
two reasons. First, recognizing and providing signals
for initiative shifts allow the agents to better coordinate
their actions, thus leading to more coherent and cooper-
ative dialogues. Second, by determining whether or not
it should hold the task and/or dialogue initiatives when
responding to user utterances, a dialogue system is able
to tailor its responses based on the distribution of initia-
tives, as illustrated by the previous dialogue (Chu-Carroll
and Brown, 1997). This section describes our model for
tracking initiative using cues identified from the user&apos;s
utterances.
Our model maintains, for each agent, a task initiative
index and a dialogue initiative index which measure the
amount of evidence available to support the agent hold-
ing the task and dialogue initiatives, respectively. After
each turn, new initiative indices are calculated based on
the current indices and the effects of the cues observed
during the turn. These cues may be explicit requests by
the speaker to give up his initiative, or implicit cues such
as ambiguous proposals. The new initiative indices then
determine the initiative holders for the next turn.
We adopt the Dempster-Shafer theory of evidence
(Shafer, 1976; Gordon and Shortliffe, 1984) as our un-
derlying model for inferring the accumulated effect of
multiple cues on determining the initiative indices. The
Dempster-Shafer theory is a mathematical theory for rea-
soning under uncertainty which operates over a set of
possible outcomes, 0. Associated with each piece of
evidence that may provide support for the possible out-
comes is a basic probability assignment (bpa), a func-
tion that represents the impact of the piece of evidence
on the subsets of 0. A bpa assigns a number in the range
[0,1] to each subset of 0 such that the numbers sum to 1.
The number assigned to the subset 01 then denotes the
amount of support the evidence directly provides for the
conclusions represented by 01. When multiple pieces
of evidence are present, Dempster&apos; s combination rule is
used to compute a new bpa from the individual bpa&apos; s to
represent their cumulative effect.
The reasons for selecting the Dempster-Shafer theory
as the basis for our model are twofold. First, unlike
the Bayesian model, it does not require a complete set
of a priori and conditional probabilities, which is dif-
ficult to obtain for sparse pieces of evidence. Second,
the Dempster-Shafer theory distinguishes between situ-
ations in which no evidence is available to support any
conclusion and those in which equal evidence is avail-
able to support each conclusion. Thus the outcome of
the model more accurately represents the amount of ev-
idence available to support a particular conclusion, i.e.,
the provability of the conclusion (Pearl, 1990).
</bodyText>
<subsectionHeader confidence="0.963562">
3.1 Cues for Tracking Initiative
</subsectionHeader>
<bodyText confidence="0.999991833333333">
In order to utilize the Dempster-Shafer theory for mod-
eling initiative, we must first identify the cues that pro-
vide evidence for initiative shifts. Whittaker, Stenton,
and Walker (Whittaker and Stenton, 1988; Walker and
Whittaker, 1990) have previously identified a set of ut-
terance intentions that serve as cues to indicate shifts or
lack of shifts in initiative, such as prompts and questions.
We analyzed our annotated TRAINS91 corpus and iden-
tified additional cues that may have contributed to the
shift or lack of shift in task/dialogue initiatives during
the interactions. This results in eight cue types, which are
grouped into three classes, based on the kind of knowl-
edge needed to recognize them. Table 2 shows the three
classes, the eight cue types, their subtypes if any, whether
a cue may affect merely the dialogue initiative or both
the task and dialogue initiatives, and the agent expected
to hold the initiative in the next turn.
The first cue class, explicit cues, includes explicit re-
quests by the speaker to give up or take over the initiative.
For instance, the utterance &amp;quot;Any suggestions?&amp;quot; indicates
the speaker&apos;s intention for the hearer to take over both
the task and dialogue initiatives. Such explicit cues can
be recognized by inferring the discourse and/or problem-
solving intentions conveyed by the speaker&apos;s utterances.
</bodyText>
<page confidence="0.994025">
264
</page>
<table confidence="0.9998278">
Class Cue Type Subtype Effect Initiative Example
Explicit Explicit requests give up both hearer &amp;quot;Any suggestions?&amp;quot; &amp;quot;Summarize the plan up to this point&amp;quot;
take over both speaker &amp;quot;Let me handle this one.&amp;quot;
Discourse End silence both hearer
No new info repetitions both hearer A: &amp;quot;Grab the tanker, pick up oranges, go to Elmira,
make them into orange juice.&amp;quot;
B: &amp;quot;We go to Elmira, we make orange juice, okay.&amp;quot;
prompts both hearer &amp;quot;Yeah &amp;quot;, &amp;quot;Ok&amp;quot;, &amp;quot;Right&amp;quot;
Questions domain DI speaker &amp;quot;How far is it from Bath to Corning?&amp;quot;
evaluation DI hearer &amp;quot;Can we do the mute the banana guy isn&apos;t doing?&amp;quot;
Obligation task both hearer A: &amp;quot;Any suggestions?&amp;quot;
fulfilled B: &amp;quot;Well, there&apos;s a boxcar at Dansville.&amp;quot;
&amp;quot;But you have to change your banana plan.&amp;quot;
A: &amp;quot;How long is it from Dansville to Corning?&amp;quot;
discourse DI hearer A: &amp;quot;Go ahead and fill up El with bananas.&amp;quot;
B: &amp;quot;Well, we have to get a boxcar.&amp;quot;
A: &amp;quot;Right, okay. It&apos;s shorter to Bath from Avon.&amp;quot;
Analytical Invalidity action both hearer A: &amp;quot;Let&apos;s get the tanker car to Elmira and fill it with 0J.
B: &amp;quot;You need to get oranges to the OJ factory.&amp;quot;
belief DI hearer A: &apos;It&apos;s shorter to Bath from Avon.&amp;quot;
B: &amp;quot;It&apos;s shorter to Dansville.&amp;quot;
&amp;quot;The map is slightly misleading.&amp;quot;
Suboptimality both hearer A: &amp;quot;Using Saudi on Thursday the eleventh.&amp;quot;
B: &amp;quot;It&apos;s sold out.&amp;quot;
A: &amp;quot;Is Friday open?&amp;quot;
B: &amp;quot;Economy on Pan Am is open on Thursday&amp;quot;
Ambiguity action both hearer A: &amp;quot;Take one of the engines from Corning.&amp;quot;
B: &amp;quot;Let&apos;s say engine E2.&amp;quot;
belief DI hearer A: &amp;quot;We would get back to Corning at 4.&amp;quot;
B: &amp;quot;4PM? 4AM?&amp;quot;
</table>
<tableCaption confidence="0.978756">
Table 2: Cues for Modeling Initiative
</tableCaption>
<bodyText confidence="0.985539979591837">
The second cue class, discourse cues, includes cues
that can be recognized using linguistic and discourse in-
formation, such as from the surface form of an utterance,
or from the discourse relationship between the current
and prior utterances. It consists of four cue types. The
first type is perceptible silence at the end of an utterance,
which suggests that the speaker has nothing more to say
and may intend to give up her initiative. The second type
includes utterances that do not contribute information
that has not been conveyed earlier in the dialogue. It can
be further classified into two groups: repetitions, a sub-
set of the informationally redundant utterances (Walker,
1992), in which the speaker paraphrases an utterance
by the hearer or repeats the utterance verbatim, and
prompts, in which the speaker merely acknowledges the
hearer&apos;s previous utterance(s). Repetitions and prompts
also suggest that the speaker has nothing more to say and
indicate that the hearer should take over the initiative
(Whittaker and Stenton, 1988). The third type includes
questions which, based on anticipated responses, are
divided into domain and evaluation questions. Domain
questions are questions in which the speaker intends
to obtain or verify a piece of domain knowledge.
They usually merely require a direct response and thus
typically do not result in an initiative shift. Evaluation
questions, on the other hand, are questions in which the
speaker intends to assess the quality of a proposed plan.
They often require an analysis of the proposal, and thus
frequently result in a shift in dialogue initiative. The
final type includes utterances that satisfy an outstanding
task or discourse obligation. Such obligations may have
resulted from a prior request by the hearer, or from an
interruption initiated by the speaker himself. In either
case, when the task/dialogue obligation is fulfilled, the
initiative may be reverted back to the hearer who held
the initiative prior to the request or interruption.
The third cue class, analytical cues, includes cues
that cannot be recognized without the hearer perform-
ing an evaluation on the speaker&apos;s proposal using the
hearer&apos;s private knowledge (Chu-Carroll and Carberry,
1994; Chu-Carroll and Carberry, 1995). After the eval-
uation, the hearer may find the proposal invalid, subop-
timal, or ambiguous. As a result, he may initiate a sub-
dialogue to resolve the problem, resulting in a shift in
task/dialogue initiatives.3
3 Whittaker, Stanton, and Walker treat subdialogues initiated
as a result of these cues as interruptions, motivated by their col-
laborative planning principles (Whittaker and Stanton, 1988:
Walker and Whittaker, 1990).
</bodyText>
<page confidence="0.988844">
265
</page>
<subsectionHeader confidence="0.998356">
3.2 Utilizing the Dempster-Shafer Theory
</subsectionHeader>
<bodyText confidence="0.990131264150944">
As discussed earlier, at the end of each turn, new
task/dialogue initiative indices are computed based on
the current indices and the effect of the observed cues
to determine the next task/dialogue initiative holders. In
terms of the Dempster-Shafer theory, new task/dialogue
bpa&apos;s (rnt-newirnd-net04 are computed by applying
Dempster s combination rule to the bpa&apos; s representing
the current initiative indices5 and the bpa of each
observed cue.
Evidently, some cues provide stronger evidence for
an initiative shift than others. Furthermore, a cue may
provide stronger support for a shift in dialogue initiative
than in task initiative. Thus, we associate with each cue
two bpa&apos; s to represent its effect on changing the current
task and dialogue initiative indices, respectively. We ex-
tended our annotations of the TRAINS91 dialogues to
include, in addition to the agent(s) holding the task and
dialogue initiatives for each turn, a list of cues observed
during that turn. Initially, each cue; is assigned the fol-
lowing bpa&apos;s: rnt _i (0) 1 and md_i(e) = 1, where
0 = {speaker,hearer}. In other words, we assume that
the cue has no effect on changing the current initiative
indices. We then developed a training algorithm (Train-
bpa, Figure 1) and applied it on the annotated data to
obtain the final bpa&apos;s.
For each turn, the task and dialogue bpa&apos; s for each
observed cue are used, along with the current initiative
indices, to determine the new initiative indices (step 2).
The combine function utilizes Dempster&apos; s combination
rule to combine pairs of bpa&apos;s until a final bpa is obtained
to represent the cumulative effect of the given bpa&apos; s. The
resulting bpa&apos;s are then used to predict the task/dialogue
initiative holders for the next turn (step 3). If this pre-
diction disagrees with the actual value in the annotated
data, Adjust-bpa is invoked to alter the bpa&apos;s for the ob-
served cues, and Reset-current-bpa is invoked to ad-
just the current bpa&apos; s to reflect the actual initiative holder
(step 4).
Adjust-bpa adjusts the bpa&apos;s for the observed cues
in favor of the actual initiative holder. We developed
three adjustment methods by varying the effect that a
disagreement between the actual and predicted initiative
holders will have on changing the bpa&apos; s for the observed
cues. The first is constant-increment where each time a
disagreement occurs, the value for the actual initiative
holder in the bpa is incremented by a constant (A), while
4Bpa&apos;s are represented by functions whose names take the
form of rn3.b. The subscript sub may be t-X or d-X, indicat-
ing that the function represents the task or dialogue bpa under
scenario X.
5The initiative indices are represented as bpa&apos;s. For in-
stance, the current task initiative indices take the following
form: mt—cur(speaker) = x and rnt—c.r(hearer) = 1 — x.
</bodyText>
<figure confidence="0.930489057142857">
Train-bpa(annotated-data):
1. m t —cur — default task initiative indices
ind—cur 4-- default dialogue initiative indices
cur-data 4— read(annotated-data)
cue-set 4— cues in cur-data
2. /* compute new initiative indices */
mt—obs 4— task initiative bpa&apos;s for cues in cue-set
inci—obs dialogue initiative bpa&apos;s for cues in cue-set
m combine(mt—cur, nit-01,5)
Md—new combbie(md—cur, Md—obs)
3. /* determine predicted next initiative holders */
If mt_ne.(speaker) &gt; m_ ,,(hearer),
t-predicted 4-- speaker
Else, t-predicted hearer
If ma—new(speaker) &gt; md—new(hearer),
d-predicted speaker
Else, d-predicted 4-- hearer
4. /&apos;find actual initiative holders and compare */
new-data read(annotated-data)
t-actual actual task initiative holder in new-data
d-actual 4-- actual dialogue initiative holder in new-data
If t-predicted t-actual, .
Adjust-bpa(cue-set,task)
Reset-current-bpa(mt_cur)
If d-predicted d-actual,
Adjust-bpa(cue-set,dialogue)
Reset-current-bpa(rad—cur)
5. If end-of-dialogue, return
Else, /swap roles of speaker and hearer */
me—cur(speaker) me—new(hearer)
Md—cur(Speaker) md—new(hearer)
rnt—cur(hearer) me—new(speaker)
md—cur(hearer) md—.e.(speaker)
cue-set cues in new-data
Goto step 2.
</figure>
<figureCaption confidence="0.999877">
Figure 1: Training Algorithm for Determining BPA s
</figureCaption>
<bodyText confidence="0.999915133333333">
that for 0 is decremented by A. The second method,
constant-increment-with-counter, associates with each
bpa for each cue a counter which is incremented when
a correct prediction is made, and decremented when an
incorrect prediction is made. If the counter is nega-
tive, the constant-increment method is invoked, and the
counter is reset to 0. This method ensures that a bpa will
only be adjusted if it has no &amp;quot;credit&amp;quot; for correct predic-
tions in the past. The third method, variable-increment-
with-counter, is a variation of constant-increment-with-
counter. However, instead of determining whether an
adjustment is needed, the counter determines the amount
to be adjusted. Each time the system makes an incorrect
prediction, the value for the actual initiative holder is in-
cremented by A/ 2&amp;quot;unt+1, and that for 0 decremented
</bodyText>
<page confidence="0.993344">
266
</page>
<figure confidence="0.999411612903226">
0.95
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0 5
delta
no redlction
const-inc
var-inc-wc
0.6
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0 5
delta
0.9
0.85
0.8
:1 0.75
0
0.7
0.65
. -4. • . ... &apos;&apos;&apos;&apos; .... ..&amp;quot; ....... ... .
,ii..........,...&amp;quot;
i
..P. i
no-prediction ---
const-inc
const-inc-wc .......
var-inc-wc
accuracy
1
0.99
0.98
0.97
0.96
(a) Task Initiative Prediction (b) Dialogue Initiative Prediction
</figure>
<figureCaption confidence="0.999982">
Figure 2: Comparison of Three Adjustment Methods
</figureCaption>
<bodyText confidence="0.997459066666667">
by the same amount.
In addition to experimenting with different adjustment
methods, we also varied the increment constant, A. For
each adjustment method, we ran 19 training sessions
with A ranging from 0.025 to 0.475, incrementing by
0.025 between each session, and evaluated the system
based on its accuracy in predicting the initiative holders
for each turn. We divided the TRANS91 corpus into
eight sets based on speaker/hearer pairs. For each A,
we cross-validated the results by applying the training
algorithm to seven dialogue sets and testing the resulting
bpa&apos; s on the remaining set. Figures 2(a) and 2(b) show
our system&apos;s performance in predicting the task and dia-
logue initiative holders, respectively, using the three ad-
justment methods.6
</bodyText>
<subsectionHeader confidence="0.914978">
3.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999706285714286">
Figure 2 shows that in the vast majority of cases, our
prediction methods yield better results than making pre-
dictions without cues. Furthermore, substantial improve-
ment is gained by the use of counters since they prevent
the effect of the &amp;quot;exceptions of the rules&amp;quot; from accu-
mulating and resulting in erroneous predictions. By re-
stricting the increment to be inversely exponentially re-
lated to the &amp;quot;credit&amp;quot; the bpa had in making correct pre-
dictions, variable-increment-with-counter obtains bet-
ter and more consistent results than constant-increment.
However, the exceptions of the rules still resulted in un-
desirable effects, thus the further improved performance
by constant-increment-with-counter.
We analyzed the cases in which the system, using
</bodyText>
<footnote confidence="0.670576333333333">
6For comparison purposes, the straight lines show the sys-
tem&apos;s performance without the use of cues, i.e., always predict
that the initiative remains with the current holder.
</footnote>
<bodyText confidence="0.999189966666667">
constant-increment-with-counter with A = 35,7 made
erroneous predictions. Tables 3(a) and 3(b) summarize
the results of our analysis with respect to task and di-
alogue initiatives, respectively. For each cue type, we
grouped the errors based on whether or not a shift oc-
curred in the actual dialogue. For instance, the first row
in Table 3(a) shows that when the cue invalid action is
detected, the system failed to predict a task initiative shift
in 2 out of 3 cases. On the other hand, it correctly pre-
dicted all 11 cases where no shift in task initiative oc-
curred. Table 3(a) also shows that when an analytical
cue is detected, the system correctly predicted all but one
case in which there was no shift in task initiative. How-
ever, 55% of the time, the system failed to predict a shift
in task initiative.8 This suggests that other features need
to be taken into account when evaluating user proposals
in order to more accurately model initiative shifts result-
ing from such cues. Similar observations can be made
about the errors in predicting dialogue initiative shifts
when analytical cues are observed (Table 3(b)).
Table 3(b) shows that when a perceptible silence is
detected at the end of an utterance, when the speaker
utters a prompt, or when an outstanding discourse
obligation is fulfilled (first three rows in table), the
system correctly predicted the dialogue initiative holder
in the vast majority of cases. However, for the cue class
questions, when the actual initiative shift differs from
the norm, i.e., speaker retaining initiative for evaluation
questions and hearer taking over initiative for domain
questions, the system&apos;s performance worsens. In the
</bodyText>
<footnote confidence="0.817057">
7 This is the value that yields the optimal results (Figure 2).
8 In the case of suboptimal actions, we encounter the sparse
data problem. Since there is only one instance of the cue in the
set of dialogues, when the cue is present in the testing set, it is
absent from the training set.
</footnote>
<page confidence="0.983208">
267
</page>
<table confidence="0.998932">
Cue Type Subtype Shift No-Shift
error total error total
Invalidity action 2 3 0 11
Suboptimality 1 1 0 0
Ambiguity action 3 7 1 5
(a) Task Initiative Errors
Cue Type Subtype Shift No-Shift
error total error total
End silence 13 41 0 53
No new info prompts 7 193 1 6
Questions domain 13 31 0 98
evaluation 8 28 5 7
Obligation fulfilled discourse 12 198 1 5
Invalidity 11 34 0 0
Suboptimality 1 1 0 0
Ambiguity 9 24 0 0
(b) Dialogue Initiative Errors
</table>
<tableCaption confidence="0.999794">
Table 3: Summary of Prediction Errors
</tableCaption>
<bodyText confidence="0.999957071428572">
case of domain questions, errors occur when 1) the re-
sponse requires more reasoning than do typical domain
questions, causing the hearer to take over the dialogue
initiative, or 2) the hearer, instead of merely responding
to the question, offers additional helpful information.
In the case of evaluation questions, errors occur when
1) the result of the evaluation is readily available to the
hearer, thus eliminating the need for an initiative shift,
or 2) the hearer provides extra information. We believe
that although it is difficult to predict when an agent
may include extra information in response to a question,
taking into account the cognitive load that a question
places on the hearer may allow us to more accurately
predict dialogue initiative shifts.
</bodyText>
<sectionHeader confidence="0.958439" genericHeader="method">
4 Applications in Other Environments
</sectionHeader>
<bodyText confidence="0.999970578947369">
To investigate the generality of our system, we applied
our training algorithm, using the constant-increment-
with-counter adjustment method with A = 0.35, on
the TRAINS91 corpus to obtain a set of bpa&apos; s. We
then evaluated the system on subsets of dialogues from
four other corpora: the TRA1NS93 dialogues (Heeman
and Allen, 1995), airline reservation dialogues (SRI
Transcripts, 1992), instruction-giving dialogues (Map
Task Dialogues, 1996), and non-task-oriented dialogues
(Switchboard Credit Card Corpus, 1992). In addition, we
applied our baseline strategy which makes predictions
without the use of cues to each corpus.
Table 4 shows a comparison between the dialogues
from the five corpora and the results of this evaluation.
Row 1 in the table shows the number of turns where the
expert9 holds the task/dialogue initiative, with percent-
ages shown in parentheses. This analysis shows that the
distribution of initiatives varies quite significantly across
corpora, with the distribution biased toward one agent in
the TRAINS and maptask corpora, and split fairly evenly
in the airline and switchboard dialogues. Row 2 shows
the results of applying our baseline prediction method
to the various corpora_ The numbers shown are correct
predictions in each instance, with the corresponding
percentages shown in parentheses. These results indicate
the difficulty of the prediction problem in each corpus
that the task/dialogue initiative distribution (row 1)
fails to convey. For instance, although the dialogue
initiative is distributed approximately 30/70% between
the two agents in the TRAINS91 corpus and 40/60%
in the airline dialogues, the prediction rates in row 2
shows that in both cases, the distribution is the result of
shifts in dialogue initiative in approximately 25% of the
dialogue turns. Row 3 in the table shows the prediction
results when applying our training algorithm using
the constant-increment-with-counter method. Finally,
the last row shows the improvement in percentage
points between our prediction method and the baseline
</bodyText>
<footnote confidence="0.9102104">
9The expert is assigned as follows: in the TRAINS domain,
the system; in the airline domain, the travel agent; in the map-
task domain, the instruction giver; and in the switchboard dia-
logues, the agent who holds the dialogue initiative the majority
of the time.
</footnote>
<page confidence="0.979448">
268
</page>
<table confidence="0.995919666666667">
Corpus TRAINS91 (1042) — TRAINS93 (256) Airline (332) Maptask (320) Switchboard (282)
(# turns) task - dialogue task dialogue task dialogue task dialogue task dialogue
Expert 41 311 37 101 194 193 320 277 N/A 166
control (3.9%) (29.8%) (14.4%) (39.5%) (58.4%) (58.1%) (100%) (86.6%) (59.9%)
No cue 1009 780 239 189 308 247 320 270 N/A 193
(96.8%) (74.9%) (93.3%) (73.8%) (92.8%) (74.4%) (100%) (84.4%) (68.4%)
const-mc- 1033 915 250 217 316 281 320 297 N/A 216
w-count (99.1%) (87.8%) (97.7%) (84.8%) (95.2%) (84.6%) (100%) (92.8%) (76.6%)
Improvement 2.3% 12.9% 4.4% 11.0% 2.4% 10.2% 0.0% 8.4% N/A 8.2%
</table>
<tableCaption confidence="0.999897">
Table 4: Comparison Across Different Application Environments
</tableCaption>
<bodyText confidence="0.9998283">
prediction method. To test the statistical significance
of the differences between the results obtained by the
two prediction algorithms, for each corpus, we applied
Cochran&apos; s Q test (Cochran, 1950) to the results in rows 2
and 3. The tests show that for all corpora, the differences
between the two algorithms when predicting the task and
dialogue initiative holders are statistically significant at
the levels of p&lt;0.05 and p&lt; 10-5, respectively.
Based on the results of our evaluation, we make the
following observations. First, Table 4 illustrates the gen-
erality of our prediction mechanism. Although the sys-
tem&apos;s performance varies across environments, the use
of cues consistently improves the system&apos;s accuracies in
predicting the task and dialogue initiative holders by 2-
4 percentage points (with the exception of the maptask
corpus in which there is no room for improvement)&amp;quot;
and 8-13 percentage points, respectively. Second, Ta-
ble 4 shows the specificity of the trained bpa&apos;s with re-
spect to application environments. Using our predic-
tion mechanism, the system&apos;s performances on the col-
laborative planning dialogues (TRAINS91, TRAINS93,
and airline reservation) most closely resemble one an-
other (last row in table). This suggests that the bpa&apos; s
may be somewhat sensitive to application environments
since they may affect how agents interpret cues. Third,
our prediction mechanism yields better results on task-
oriented dialogues. This is because such dialogues are
constrained by the goals; therefore, there are fewer di-
gressions and offers of unsolicited opinion as compared
to the switchboard corpus.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.996278153846154">
This paper discussed a model for tracking initiative be-
tween participants in mixed-initiative dialogue interac-
tions. We showed that distinguishing between task and
dialogue initiatives allows us to model phenomena in col-
laborative dialogues that existing systems are unable to
explain. We presented eight types of cues that affect ini-
tiative shifts in dialogues, and showed how our model
10In the maptask domain, the task initiative remains with one
agent. the instruction giver, throughout the dialogue.
predicts initiative shifts based on the current initiative
holders and and the effects that observed cues have on
changing them. Our experiments show that by utilizing
the constant-increment-with-counter adjustment method
in determining the basic probability assignments for each
cue, the system can correctly predict the task and dia-
logue initiative holders 99.1% and 87.8% of the time, re-
spectively, in the TRAINS91 corpus, compared to 96.8%
and 74.9% without the use of cues. The differences be-
tween these results are shown to be statistically signif-
icant using Cochran&apos;s Q test. In addition, we demon-
strated the generality of our model by applying it to dia-
logues in different application environments. The results
indicate that although the basic probability assignments
may be sensitive to application environments, the use of
cues in the prediction process significantly improves the
system&apos;s performance.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999985333333333">
We would like to thank Lyn Walker, Diane Litman, Bob
Carpenter, and Christer Samuelsson for their comments
on earlier drafts of this paper, Bob Carpenter and Christer
S amuelsson for participating in the coding reliability test,
as well as Jan van Santen and Lyn Walker for discussions
on statistical testing methods.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992787692307692">
Allen, James. 1991. Discourse structure in the TRAINS
project. In Darpa Speech and Natural Language
Workshop.
Carletta, Jean. 1996. Assessing agreement on classifi-
cation tasks: The kappa statistic. Computational Lin-
guistics, 22:249-254.
Chu-Carroll, Jennifer and Michael K. Brown. 1997. Ini-
tiative in collaborative interactions — its cues and ef-
fects. In Working Notes of the AAAI-97 Spring Sym-
posium on Computational Models for Mixed Initiative
Interaction, pages 16-22.
Chu-Carroll, Jennifer and Sandra Carberry. 1994. A
plan-based model for response generation in collab-
</reference>
<page confidence="0.978783">
269
</page>
<reference confidence="0.999742171717171">
orative task-oriented dialogues. In Proceedings of the
Twelfth National Conference on Artificial Intelligence,
pages 799-805.
Chu-Carroll, Jennifer and Sandra Carberry. 1995. Re-
sponse generation in collaborative negotiation. In Pro-
ceedings of the 33rd Annual Meeting of the Associa-
tion for Computational Linguistics, pages 136-143.
Cochran, W. G. 1950. The comparison of percentages in
matched samples. Biometrika, 37:256-266.
Gordon, Jean and Edward H. Shortliffe. 1984. The
Dempster-Shafer theory of evidence. In Bruce
Buchanan and Edward Shortliffe, editors, Rule-Based
Expert Systems: The MYCIN Experiments of the
Stanford Heuristic Programming Project. Addison-
Wesley, chapter 13, pages 272-292.
Gross, Derek, James F. Allen, and David R. Traum.
1993. The TRAINS 91 dialogues. Technical Report
TN92-1, Department of Computer Science, University
of Rochester.
Grove, William M., Nancy C. Andreasen, Patricia
McDonald-Scott, Martin B. Keller, and Robert W.
Shapiro. 1981. Reliability studies of psychiatric di-
agnosis. Archives of General Psychiatry, 38:408-413.
Guinn, Curry I. 1996. Mechanisms for mixed-initiative
htitnnn-er,rnputer collaborative discourse. In Proceed-
;;;.,0 of thc 3411,.innual Mccti,.o. of the far
Computational Linguistics, pages 278-285.
Heeman, Peter A. and James F. Allen. 1995. The
TRAINS 93 dialogues. Technical Report TN94-
2, Department of Computer Science, University of
Rochester.
Jordan, Pamela W. and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving dia-
logues. In Working Notes of the AAAI-97 Spring Sym-
posium on Computational Models for Mixed Initiative
Interaction, pages 81-84.
ICitano, Hiroalci and Carol Van Ess-Dykema. 1991. To-
ward a plan-based understanding model for mixed-
initiative dialogues. In Proceedings of the 29th An-
nual Meeting of the Association for Computational
Linguistics, pages 25-32.
Lambert, Lynn and Sandra Carberry. 1991. A tripartite
plan-based model of dialogue. In Proceedings of the
29th Annual Meeting of the Association for Computa-
tional Linguistics, pages 47-54.
Litman, Diane and James Allen. 1987. A plan recogni-
tion model for subdialogues in conversation. Cogni-
tive Science,11: 163-200.
Map Task Dialogues. 1996. Transcripts of DCIEM
Sleep Deprivation Study, conducted by Defense and
Civil Institute of Environmental Medicine, Canada,
and Human Communication Research Centre, Uni-
versity of Edinburgh and University of Glasgow, UK.
Distrubuted by HCRC and LDC.
Novick, David G. 1988. Control of Mixed-Initiative Dis-
course Through Meta-Locutionary Acts: A Computa-
tional Model. Ph.D. thesis, University of Oregon.
Novick, David G. and Stephen Sutton. 1997. What is
mixed-initiative interaction? In Working Notes of the
AAAI-97 Spring Symposium on Computational Mod-
els for Mixed Initiative Interaction, pages 114-116.
Pearl, Judea. 1990. Bayesian and belief-fuctions for-
malisms for evidential reasoning: A conceptual analy-
sis. In Glenn Shafer and Judea Pearl, editors, Read-
ings in Uncertain Reasoning. Morgan Kaufmann,
pages 540-574.
Ramshaw, Lance A. 1991. A three-level model for plan
exploration. In Proceedings of the 29th Annual Meet-
ing of the Association for Computational Linguistics,
pages 36-46.
Shafer, Glenn. 1976. A Mathematical Theory of Evi-
dence. Princeton University Press.
Siegel, Sidney. and N. John. Castellan, Jr. 1988. Non-
parametric Statistics for the Behavioral Sciences. Mc-
Graw Hill.
Smith, Ronnie W. and D. Richard Hipp. 1994. Spoken
Natural Language Dialog Systems - A Practical Ap-
proach. Oxford University Press.
SRI Transcripts. 1992. Transcripts derived from audio-
tape conversations made at SRI International, Menlo
Park, CA. Prepared by Jacqueline Kowtko under the
direction of Patti Price.
Switchboard Credit Card Corpus. 1992. Transcripts of
telephone conversations on the topic of credit card use,
collected at Texas Instruments. Produced by NIST,
available through LDC.
Walker, Marilyn and Steve Whittaker. 1990. Mixed
initiative in dialogue: An investigation into discourse
segmentation. In Proceedings of the 28th Annual
Meeting of the Association for Computational Lin-
guistics, pages 70-78.
Walker, Marilyn A. 1992. Redundancy in collabora-
tive dialogue. In Proceedings of the 15th International
Conference on Computational Linguistics, pages 345-
351.
Whittaker, Steve and Phil Stenton. 1988. Cues and con-
trol in expert-client dialogues. In Proceedings of the
26th Annual Meeting of the Association for Computa-
tional Linguistics, pages 123-130.
</reference>
<page confidence="0.996787">
270
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.887650">
<title confidence="0.999832">Tracking Initiative in Collaborative Dialogue Interactions</title>
<author confidence="0.999977">Chu-Carroll K Brown</author>
<affiliation confidence="0.958969">Bell Laboratories Lucent Technologies</affiliation>
<address confidence="0.9997295">600 Mountain Avenue Murray Hill, NJ 07974, U.S.A.</address>
<email confidence="0.999603">E-mail:{jencc,mkb}@bell-labs.com</email>
<abstract confidence="0.997679466666667">In this paper, we argue for the need to disbetween and present a model for tracking shifts in both types of initiatives in dialogue interactions. Our model predicts the initiative holders in the next dialogue turn based on the current initiative holders and the effect that observed cues have on changing them. Our evaluation across various corpora shows that the use of cues consistently improves the accuracy in the system&apos;s prediction of task and dialogue initiative holders by 2-4 and 8-13 percentage points, respectively, thus illustrating the generality of our model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Discourse structure in the TRAINS project.</title>
<date>1991</date>
<booktitle>In Darpa Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="7123" citStr="Allen, 1991" startWordPosition="1108" endWordPosition="1109">initiatives is similar to the notion of choice of task and choice of speaker in initiative in (Novick and Sutton, 1997), and the distinction between control and initiative in (Jordan and Di Eugenio, 1997). TI: system TI: manager DI: system 37 (3.5%) 274 (26.3%) DI: manager 4 (0.4%) 727 (69.8%) Table 1: Distribution of Task and Dialogue Initiatives agents should perform. The utterances may propose domain actions (Litman and Allen, 1987) that directly contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s send engine E2 to Corning.&amp;quot; On the other hand, they may propose problem-solving actions (Allen, 1991; Lambert and Carberry, 1991; Ramshaw, 1991) that contribute not directly to the agents&apos; domain goal, but to how they would go about achieving this goal, such as &amp;quot;Let&apos;s look at the first [problem] first.&amp;quot; An agent is said to have the dialogue initiative if she takes the conversational lead in order to establish mutual beliefs, such as mutual beliefs about a piece of domain knowledge or about the validity of a proposal, between the agents. For instance, in responding to agent A&apos;s proposal of sending a boxcar to Corning via Dansville, agent B may take over the dialogue initiative (but not the ta</context>
</contexts>
<marker>Allen, 1991</marker>
<rawString>Allen, James. 1991. Discourse structure in the TRAINS project. In Darpa Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--249</pages>
<contexts>
<context position="9142" citStr="Carletta, 1996" startWordPosition="1449" endWordPosition="1450"> depending on which agent holds the task/dialogue initiative during that turn.2 Table 1 shows the distribution of task and dialogue initiatives in the TRAINS91 dialogues. It shows that while in the majority of turns, the task and dialogue initiatives are held by the same agent, in approximately 1/4 of the turns, the agents&apos; behavior can be better accounted for by tracking the two types of initiatives separately. To assess the reliability of our annotations, approximately 10% of the dialogues were annotated by two additional coders. We then used the kappa statistic (Siegel and Castellan, 1988; Carletta, 1996) to assess the level of agreement between the three coders with respect to the 2 An agent holds the task initiative during a turn as long as some utterance during the turn directly proposes how the agents should accomplish their goal, as in utterance (3c). 263 task and dialogue initiative holders. In this experiment, K is 0.57 for the task initiative holder agreement and K is 0.69 for the dialogue initiative holder agreement. Carletta suggests that content analysis researchers consider K &gt;.8 as good reliability, with .67&lt; K &lt;.8 allowing tentative conclusions to be drawn (Carletta, 1996). Stric</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Carletta, Jean. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22:249-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Michael K Brown</author>
</authors>
<title>Initiative in collaborative interactions — its cues and effects.</title>
<date>1997</date>
<booktitle>In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction,</booktitle>
<pages>16--22</pages>
<contexts>
<context position="5879" citStr="Chu-Carroll and Brown, 1997" startWordPosition="904" endWordPosition="907">in (3b) and (3c), A takes the lead by initiating a subdialogue to correct S&apos;s invalid proposal. However, existing models cannot explain the difference in the two responses, namely that in (3c), A actively participates in the planning process by explicitly proposing domain actions, whereas in (3b), she merely conveys the invalidity of S&apos;s proposal. Based on this observation, we argue that it is necessary to distinguish between task initiative, which tracks the lead in the development of the agents&apos; plan, and dialogue initiative, which tracks the lead in determining the current discourse focus (Chu-Carroll and Brown, 1997).&apos; This distinction then allows us to explain A&apos;s behavior from a response generation point of view: in (3b), A responds to S&apos;s proposal by merely taking over the dialogue initiative, i.e., informing S of the invalidity of the proposal, while in (3c), A responds by taking over both the task and dialogue initiatives, i.e., informing S of the invalidity and suggesting a possible remedy. An agent is said to have the task initiative if she is directing how the agents&apos; task should be accomplished, i.e., if her utterances directly propose actions that the Although independently conceived, this disti</context>
<context position="11546" citStr="Chu-Carroll and Brown, 1997" startWordPosition="1834" endWordPosition="1837">e participants during the course of a dialogue. We contend that it is important for the agents to take into account signals for such initiative shifts for two reasons. First, recognizing and providing signals for initiative shifts allow the agents to better coordinate their actions, thus leading to more coherent and cooperative dialogues. Second, by determining whether or not it should hold the task and/or dialogue initiatives when responding to user utterances, a dialogue system is able to tailor its responses based on the distribution of initiatives, as illustrated by the previous dialogue (Chu-Carroll and Brown, 1997). This section describes our model for tracking initiative using cues identified from the user&apos;s utterances. Our model maintains, for each agent, a task initiative index and a dialogue initiative index which measure the amount of evidence available to support the agent holding the task and dialogue initiatives, respectively. After each turn, new initiative indices are calculated based on the current indices and the effects of the cues observed during the turn. These cues may be explicit requests by the speaker to give up his initiative, or implicit cues such as ambiguous proposals. The new ini</context>
</contexts>
<marker>Chu-Carroll, Brown, 1997</marker>
<rawString>Chu-Carroll, Jennifer and Michael K. Brown. 1997. Initiative in collaborative interactions — its cues and effects. In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction, pages 16-22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Sandra Carberry</author>
</authors>
<title>A plan-based model for response generation in collaborative task-oriented dialogues.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence,</booktitle>
<pages>799--805</pages>
<contexts>
<context position="19002" citStr="Chu-Carroll and Carberry, 1994" startWordPosition="3054" endWordPosition="3057">gue initiative. The final type includes utterances that satisfy an outstanding task or discourse obligation. Such obligations may have resulted from a prior request by the hearer, or from an interruption initiated by the speaker himself. In either case, when the task/dialogue obligation is fulfilled, the initiative may be reverted back to the hearer who held the initiative prior to the request or interruption. The third cue class, analytical cues, includes cues that cannot be recognized without the hearer performing an evaluation on the speaker&apos;s proposal using the hearer&apos;s private knowledge (Chu-Carroll and Carberry, 1994; Chu-Carroll and Carberry, 1995). After the evaluation, the hearer may find the proposal invalid, suboptimal, or ambiguous. As a result, he may initiate a subdialogue to resolve the problem, resulting in a shift in task/dialogue initiatives.3 3 Whittaker, Stanton, and Walker treat subdialogues initiated as a result of these cues as interruptions, motivated by their collaborative planning principles (Whittaker and Stanton, 1988: Walker and Whittaker, 1990). 265 3.2 Utilizing the Dempster-Shafer Theory As discussed earlier, at the end of each turn, new task/dialogue initiative indices are compu</context>
</contexts>
<marker>Chu-Carroll, Carberry, 1994</marker>
<rawString>Chu-Carroll, Jennifer and Sandra Carberry. 1994. A plan-based model for response generation in collaborative task-oriented dialogues. In Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 799-805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Sandra Carberry</author>
</authors>
<title>Response generation in collaborative negotiation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="19035" citStr="Chu-Carroll and Carberry, 1995" startWordPosition="3058" endWordPosition="3061">ncludes utterances that satisfy an outstanding task or discourse obligation. Such obligations may have resulted from a prior request by the hearer, or from an interruption initiated by the speaker himself. In either case, when the task/dialogue obligation is fulfilled, the initiative may be reverted back to the hearer who held the initiative prior to the request or interruption. The third cue class, analytical cues, includes cues that cannot be recognized without the hearer performing an evaluation on the speaker&apos;s proposal using the hearer&apos;s private knowledge (Chu-Carroll and Carberry, 1994; Chu-Carroll and Carberry, 1995). After the evaluation, the hearer may find the proposal invalid, suboptimal, or ambiguous. As a result, he may initiate a subdialogue to resolve the problem, resulting in a shift in task/dialogue initiatives.3 3 Whittaker, Stanton, and Walker treat subdialogues initiated as a result of these cues as interruptions, motivated by their collaborative planning principles (Whittaker and Stanton, 1988: Walker and Whittaker, 1990). 265 3.2 Utilizing the Dempster-Shafer Theory As discussed earlier, at the end of each turn, new task/dialogue initiative indices are computed based on the current indices </context>
</contexts>
<marker>Chu-Carroll, Carberry, 1995</marker>
<rawString>Chu-Carroll, Jennifer and Sandra Carberry. 1995. Response generation in collaborative negotiation. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Cochran</author>
</authors>
<title>The comparison of percentages in matched samples.</title>
<date>1950</date>
<journal>Biometrika,</journal>
<pages>37--256</pages>
<contexts>
<context position="32991" citStr="Cochran, 1950" startWordPosition="5273" endWordPosition="5274"> (58.4%) (58.1%) (100%) (86.6%) (59.9%) No cue 1009 780 239 189 308 247 320 270 N/A 193 (96.8%) (74.9%) (93.3%) (73.8%) (92.8%) (74.4%) (100%) (84.4%) (68.4%) const-mc- 1033 915 250 217 316 281 320 297 N/A 216 w-count (99.1%) (87.8%) (97.7%) (84.8%) (95.2%) (84.6%) (100%) (92.8%) (76.6%) Improvement 2.3% 12.9% 4.4% 11.0% 2.4% 10.2% 0.0% 8.4% N/A 8.2% Table 4: Comparison Across Different Application Environments prediction method. To test the statistical significance of the differences between the results obtained by the two prediction algorithms, for each corpus, we applied Cochran&apos; s Q test (Cochran, 1950) to the results in rows 2 and 3. The tests show that for all corpora, the differences between the two algorithms when predicting the task and dialogue initiative holders are statistically significant at the levels of p&lt;0.05 and p&lt; 10-5, respectively. Based on the results of our evaluation, we make the following observations. First, Table 4 illustrates the generality of our prediction mechanism. Although the system&apos;s performance varies across environments, the use of cues consistently improves the system&apos;s accuracies in predicting the task and dialogue initiative holders by 2- 4 percentage poin</context>
</contexts>
<marker>Cochran, 1950</marker>
<rawString>Cochran, W. G. 1950. The comparison of percentages in matched samples. Biometrika, 37:256-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Gordon</author>
<author>Edward H Shortliffe</author>
</authors>
<title>The Dempster-Shafer theory of evidence.</title>
<date>1984</date>
<booktitle>Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. AddisonWesley, chapter 13,</booktitle>
<pages>272--292</pages>
<editor>In Bruce Buchanan and Edward Shortliffe, editors,</editor>
<contexts>
<context position="12310" citStr="Gordon and Shortliffe, 1984" startWordPosition="1953" endWordPosition="1956">ch agent, a task initiative index and a dialogue initiative index which measure the amount of evidence available to support the agent holding the task and dialogue initiatives, respectively. After each turn, new initiative indices are calculated based on the current indices and the effects of the cues observed during the turn. These cues may be explicit requests by the speaker to give up his initiative, or implicit cues such as ambiguous proposals. The new initiative indices then determine the initiative holders for the next turn. We adopt the Dempster-Shafer theory of evidence (Shafer, 1976; Gordon and Shortliffe, 1984) as our underlying model for inferring the accumulated effect of multiple cues on determining the initiative indices. The Dempster-Shafer theory is a mathematical theory for reasoning under uncertainty which operates over a set of possible outcomes, 0. Associated with each piece of evidence that may provide support for the possible outcomes is a basic probability assignment (bpa), a function that represents the impact of the piece of evidence on the subsets of 0. A bpa assigns a number in the range [0,1] to each subset of 0 such that the numbers sum to 1. The number assigned to the subset 01 t</context>
</contexts>
<marker>Gordon, Shortliffe, 1984</marker>
<rawString>Gordon, Jean and Edward H. Shortliffe. 1984. The Dempster-Shafer theory of evidence. In Bruce Buchanan and Edward Shortliffe, editors, Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. AddisonWesley, chapter 13, pages 272-292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derek Gross</author>
<author>James F Allen</author>
<author>David R Traum</author>
</authors>
<title>The TRAINS 91 dialogues.</title>
<date>1993</date>
<tech>Technical Report TN92-1,</tech>
<institution>Department of Computer Science, University of Rochester.</institution>
<contexts>
<context position="4462" citStr="Gross, Allen, and Traum, 1993" startWordPosition="663" endWordPosition="667">ed on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed a system that allows change in the level of mi262 tiative based on initiative-changing utterances and each agent&apos;s competency in completing the current subtask. However, we contend that merely maintaining the conversational lead is insufficient for modeling complex behavior commonly found in naturally-occurring collaborative dialogues (SRI Transcripts, 1992; Gross, Allen, and Traum, 1993; Heeman and Allen, 1995). For instance, consider the alternative responses in utterances (3a)-(3c), given by an advisor to a student&apos;s question: (1) S: I want to take NLP to satisfy my seminar course requirement. (2) Who is teaching NLP? (3a) A: Dr Smith is teaching NLP. (3b) A: You can&apos;t take NLP because you haven&apos;t taken Al, which is a prerequisite for NLP (3c) A: You can&apos;t take NLP because you haven&apos;t taken AI, which is a prerequisite for NLP You should take distributed programming to satisfy your requirement, and sign up as a listener for NLP Suppose we adopt a model that maintains a sing</context>
<context position="8355" citStr="Gross, Allen, and Traum, 1993" startWordPosition="1316" endWordPosition="1320">initiative) by saying &amp;quot;We can&apos;t go by Dansville because we&apos;ve got Engine 1 going on that track&amp;quot; Thus, when an agent takes over the task initiative, she also takes over the dialogue initiative, since a proposal of actions can be viewed as an attempt to establish the mutual belief that a set of actions be adopted. On the other hand, an agent may take over the dialogue initiative but not the task initiative, as in (3b) above. 2.2 An Analysis of the TRAINS91 Dialogues To analyze the distribution of task/dialogue initiatives in collaborative planning dialogues, we annotated the TRAINS91 dialogues (Gross, Allen, and Traum, 1993) as follows: each dialogue turn is given two labels, task initiative (T1) and dialogue initiative (DI), each of which can be assigned one of two values, system or manager, depending on which agent holds the task/dialogue initiative during that turn.2 Table 1 shows the distribution of task and dialogue initiatives in the TRAINS91 dialogues. It shows that while in the majority of turns, the task and dialogue initiatives are held by the same agent, in approximately 1/4 of the turns, the agents&apos; behavior can be better accounted for by tracking the two types of initiatives separately. To assess th</context>
</contexts>
<marker>Gross, Allen, Traum, 1993</marker>
<rawString>Gross, Derek, James F. Allen, and David R. Traum. 1993. The TRAINS 91 dialogues. Technical Report TN92-1, Department of Computer Science, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Grove</author>
<author>Nancy C Andreasen</author>
<author>Patricia McDonald-Scott</author>
<author>Martin B Keller</author>
<author>Robert W Shapiro</author>
</authors>
<title>Reliability studies of psychiatric diagnosis.</title>
<date>1981</date>
<journal>Archives of General Psychiatry,</journal>
<pages>38--408</pages>
<contexts>
<context position="10175" citStr="Grove et al., 1981" startWordPosition="1616" endWordPosition="1619">lder agreement. Carletta suggests that content analysis researchers consider K &gt;.8 as good reliability, with .67&lt; K &lt;.8 allowing tentative conclusions to be drawn (Carletta, 1996). Strictly based on this metric, our results indicate that the three coders have a reasonable level of agreement with respect to the dialogue initiative holders, but do not have reliable agreement with respect to the task initiative holders. However, the kappa statistic is known to be highly problematic in measuring inter-coder reliability when the likelihood of one category being chosen overwhelms that of the other (Grove et al., 1981), which is the case for the task initiative distribution in the TRAINS91 corpus, as shown in Table 1. Furthermore, as will be shown in Table 4, Section 4, the task and dialogue initiative distributions in TRAINS91 are not at all representative of collaborative dialogues. We expect that by taking a sample of dialogues whose task/dialogue initiative distributions are more representative of all dialogues, we will lower the value of P(E), the probability of chance agreement, and thus obtain a higher kappa coefficient of agreement. However, we leave selecting and annotating such a subset of represe</context>
</contexts>
<marker>Grove, Andreasen, McDonald-Scott, Keller, Shapiro, 1981</marker>
<rawString>Grove, William M., Nancy C. Andreasen, Patricia McDonald-Scott, Martin B. Keller, and Robert W. Shapiro. 1981. Reliability studies of psychiatric diagnosis. Archives of General Psychiatry, 38:408-413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Curry I Guinn</author>
</authors>
<title>Mechanisms for mixed-initiative htitnnn-er,rnputer collaborative discourse.</title>
<date>1996</date>
<booktitle>In Proceed;;;.,0 of thc 3411,.innual Mccti,.o. of the far Computational Linguistics,</booktitle>
<pages>278--285</pages>
<contexts>
<context position="4048" citStr="Guinn (1996)" startWordPosition="607" endWordPosition="608">pes, and Walker and Whittaker (1990) utilized these rules for an analytical study on discourse segmentation. Kitano and Van Ess-Dykema (1991) developed a plan-based dialogue understanding model that tracks the conversational initiative based on the domain and discourse plans behind the utterances. Smith and Hipp (1994) developed a dialogue system that varies its responses to user utterances based on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed a system that allows change in the level of mi262 tiative based on initiative-changing utterances and each agent&apos;s competency in completing the current subtask. However, we contend that merely maintaining the conversational lead is insufficient for modeling complex behavior commonly found in naturally-occurring collaborative dialogues (SRI Transcripts, 1992; Gross, Allen, and Traum, 1993; Heeman and Allen, 1995). For instance, consider the alternative responses in utterances (3a)-(3c), given by an advisor to a student&apos;s question: (1) S: I want to take NLP to satisfy my </context>
</contexts>
<marker>Guinn, 1996</marker>
<rawString>Guinn, Curry I. 1996. Mechanisms for mixed-initiative htitnnn-er,rnputer collaborative discourse. In Proceed;;;.,0 of thc 3411,.innual Mccti,.o. of the far Computational Linguistics, pages 278-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter A Heeman</author>
<author>James F Allen</author>
</authors>
<title>The TRAINS 93 dialogues.</title>
<date>1995</date>
<tech>Technical Report TN94-2,</tech>
<institution>Department of Computer Science, University of Rochester.</institution>
<contexts>
<context position="4487" citStr="Heeman and Allen, 1995" startWordPosition="668" endWordPosition="671"> model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed a system that allows change in the level of mi262 tiative based on initiative-changing utterances and each agent&apos;s competency in completing the current subtask. However, we contend that merely maintaining the conversational lead is insufficient for modeling complex behavior commonly found in naturally-occurring collaborative dialogues (SRI Transcripts, 1992; Gross, Allen, and Traum, 1993; Heeman and Allen, 1995). For instance, consider the alternative responses in utterances (3a)-(3c), given by an advisor to a student&apos;s question: (1) S: I want to take NLP to satisfy my seminar course requirement. (2) Who is teaching NLP? (3a) A: Dr Smith is teaching NLP. (3b) A: You can&apos;t take NLP because you haven&apos;t taken Al, which is a prerequisite for NLP (3c) A: You can&apos;t take NLP because you haven&apos;t taken AI, which is a prerequisite for NLP You should take distributed programming to satisfy your requirement, and sign up as a listener for NLP Suppose we adopt a model that maintains a single thread of control, suc</context>
<context position="30137" citStr="Heeman and Allen, 1995" startWordPosition="4834" endWordPosition="4837"> that although it is difficult to predict when an agent may include extra information in response to a question, taking into account the cognitive load that a question places on the hearer may allow us to more accurately predict dialogue initiative shifts. 4 Applications in Other Environments To investigate the generality of our system, we applied our training algorithm, using the constant-incrementwith-counter adjustment method with A = 0.35, on the TRAINS91 corpus to obtain a set of bpa&apos; s. We then evaluated the system on subsets of dialogues from four other corpora: the TRA1NS93 dialogues (Heeman and Allen, 1995), airline reservation dialogues (SRI Transcripts, 1992), instruction-giving dialogues (Map Task Dialogues, 1996), and non-task-oriented dialogues (Switchboard Credit Card Corpus, 1992). In addition, we applied our baseline strategy which makes predictions without the use of cues to each corpus. Table 4 shows a comparison between the dialogues from the five corpora and the results of this evaluation. Row 1 in the table shows the number of turns where the expert9 holds the task/dialogue initiative, with percentages shown in parentheses. This analysis shows that the distribution of initiatives va</context>
</contexts>
<marker>Heeman, Allen, 1995</marker>
<rawString>Heeman, Peter A. and James F. Allen. 1995. The TRAINS 93 dialogues. Technical Report TN94-2, Department of Computer Science, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>Control and initiative in collaborative problem solving dialogues.</title>
<date>1997</date>
<booktitle>In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction,</booktitle>
<pages>81--84</pages>
<marker>Jordan, Di Eugenio, 1997</marker>
<rawString>Jordan, Pamela W. and Barbara Di Eugenio. 1997. Control and initiative in collaborative problem solving dialogues. In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction, pages 81-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroalci ICitano</author>
<author>Carol Van Ess-Dykema</author>
</authors>
<title>Toward a plan-based understanding model for mixedinitiative dialogues.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<marker>ICitano, Van Ess-Dykema, 1991</marker>
<rawString>ICitano, Hiroalci and Carol Van Ess-Dykema. 1991. Toward a plan-based understanding model for mixedinitiative dialogues. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Lambert</author>
<author>Sandra Carberry</author>
</authors>
<title>A tripartite plan-based model of dialogue.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>47--54</pages>
<contexts>
<context position="7151" citStr="Lambert and Carberry, 1991" startWordPosition="1110" endWordPosition="1113">s similar to the notion of choice of task and choice of speaker in initiative in (Novick and Sutton, 1997), and the distinction between control and initiative in (Jordan and Di Eugenio, 1997). TI: system TI: manager DI: system 37 (3.5%) 274 (26.3%) DI: manager 4 (0.4%) 727 (69.8%) Table 1: Distribution of Task and Dialogue Initiatives agents should perform. The utterances may propose domain actions (Litman and Allen, 1987) that directly contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s send engine E2 to Corning.&amp;quot; On the other hand, they may propose problem-solving actions (Allen, 1991; Lambert and Carberry, 1991; Ramshaw, 1991) that contribute not directly to the agents&apos; domain goal, but to how they would go about achieving this goal, such as &amp;quot;Let&apos;s look at the first [problem] first.&amp;quot; An agent is said to have the dialogue initiative if she takes the conversational lead in order to establish mutual beliefs, such as mutual beliefs about a piece of domain knowledge or about the validity of a proposal, between the agents. For instance, in responding to agent A&apos;s proposal of sending a boxcar to Corning via Dansville, agent B may take over the dialogue initiative (but not the task initiative) by saying &amp;quot;We</context>
</contexts>
<marker>Lambert, Carberry, 1991</marker>
<rawString>Lambert, Lynn and Sandra Carberry. 1991. A tripartite plan-based model of dialogue. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 47-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane Litman</author>
<author>James Allen</author>
</authors>
<title>A plan recognition model for subdialogues in conversation.</title>
<date>1987</date>
<booktitle>Cognitive Science,11:</booktitle>
<pages>163--200</pages>
<contexts>
<context position="6951" citStr="Litman and Allen, 1987" startWordPosition="1079" endWordPosition="1082">ing how the agents&apos; task should be accomplished, i.e., if her utterances directly propose actions that the Although independently conceived, this distinction between task and dialogue initiatives is similar to the notion of choice of task and choice of speaker in initiative in (Novick and Sutton, 1997), and the distinction between control and initiative in (Jordan and Di Eugenio, 1997). TI: system TI: manager DI: system 37 (3.5%) 274 (26.3%) DI: manager 4 (0.4%) 727 (69.8%) Table 1: Distribution of Task and Dialogue Initiatives agents should perform. The utterances may propose domain actions (Litman and Allen, 1987) that directly contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s send engine E2 to Corning.&amp;quot; On the other hand, they may propose problem-solving actions (Allen, 1991; Lambert and Carberry, 1991; Ramshaw, 1991) that contribute not directly to the agents&apos; domain goal, but to how they would go about achieving this goal, such as &amp;quot;Let&apos;s look at the first [problem] first.&amp;quot; An agent is said to have the dialogue initiative if she takes the conversational lead in order to establish mutual beliefs, such as mutual beliefs about a piece of domain knowledge or about the validity of a proposal, betwe</context>
</contexts>
<marker>Litman, Allen, 1987</marker>
<rawString>Litman, Diane and James Allen. 1987. A plan recognition model for subdialogues in conversation. Cognitive Science,11: 163-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Map Task Dialogues</author>
</authors>
<title>Transcripts of DCIEM Sleep Deprivation Study, conducted by Defense and</title>
<date>1996</date>
<institution>Civil Institute of Environmental Medicine, Canada, and Human Communication Research Centre, University of Edinburgh and University of Glasgow, UK.</institution>
<note>Distrubuted by HCRC and LDC.</note>
<contexts>
<context position="30249" citStr="Dialogues, 1996" startWordPosition="4848" endWordPosition="4849"> into account the cognitive load that a question places on the hearer may allow us to more accurately predict dialogue initiative shifts. 4 Applications in Other Environments To investigate the generality of our system, we applied our training algorithm, using the constant-incrementwith-counter adjustment method with A = 0.35, on the TRAINS91 corpus to obtain a set of bpa&apos; s. We then evaluated the system on subsets of dialogues from four other corpora: the TRA1NS93 dialogues (Heeman and Allen, 1995), airline reservation dialogues (SRI Transcripts, 1992), instruction-giving dialogues (Map Task Dialogues, 1996), and non-task-oriented dialogues (Switchboard Credit Card Corpus, 1992). In addition, we applied our baseline strategy which makes predictions without the use of cues to each corpus. Table 4 shows a comparison between the dialogues from the five corpora and the results of this evaluation. Row 1 in the table shows the number of turns where the expert9 holds the task/dialogue initiative, with percentages shown in parentheses. This analysis shows that the distribution of initiatives varies quite significantly across corpora, with the distribution biased toward one agent in the TRAINS and maptask</context>
</contexts>
<marker>Dialogues, 1996</marker>
<rawString>Map Task Dialogues. 1996. Transcripts of DCIEM Sleep Deprivation Study, conducted by Defense and Civil Institute of Environmental Medicine, Canada, and Human Communication Research Centre, University of Edinburgh and University of Glasgow, UK. Distrubuted by HCRC and LDC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Novick</author>
</authors>
<title>Control of Mixed-Initiative Discourse Through Meta-Locutionary Acts: A Computational Model.</title>
<date>1988</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Oregon.</institution>
<contexts>
<context position="3190" citStr="Novick (1988)" startWordPosition="480" endWordPosition="481">y, in collaborative planning dialogues. Furthermore, application of our model to dialogues in various other collaborative environments consistently increases the accuracies in the prediction of task and dialogue initiative holders by 2-4 and 8-13 percentage points, respectively, compared to a simple prediction method without the use of cues, thus illustrating the generality of our model. 2 Task Initiative vs. Dialogue Initiative 2.1 Motivation Previous work on mixed-initiative dialogues focused on tracking and allocating a single thread of control, the conversational lead, among participants. Novick (1988) developed a computational model that utilizes metalocutionary acts, such as repeat and give-turn, to capture mixed-initiative behavior in dialogues. Whittaker and Stenton (1988) devised rules for allocating dialogue control based on utterance types, and Walker and Whittaker (1990) utilized these rules for an analytical study on discourse segmentation. Kitano and Van Ess-Dykema (1991) developed a plan-based dialogue understanding model that tracks the conversational initiative based on the domain and discourse plans behind the utterances. Smith and Hipp (1994) developed a dialogue system that </context>
</contexts>
<marker>Novick, 1988</marker>
<rawString>Novick, David G. 1988. Control of Mixed-Initiative Discourse Through Meta-Locutionary Acts: A Computational Model. Ph.D. thesis, University of Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Novick</author>
<author>Stephen Sutton</author>
</authors>
<title>What is mixed-initiative interaction?</title>
<date>1997</date>
<booktitle>In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction,</booktitle>
<pages>114--116</pages>
<contexts>
<context position="6631" citStr="Novick and Sutton, 1997" startWordPosition="1028" endWordPosition="1031">proposal by merely taking over the dialogue initiative, i.e., informing S of the invalidity of the proposal, while in (3c), A responds by taking over both the task and dialogue initiatives, i.e., informing S of the invalidity and suggesting a possible remedy. An agent is said to have the task initiative if she is directing how the agents&apos; task should be accomplished, i.e., if her utterances directly propose actions that the Although independently conceived, this distinction between task and dialogue initiatives is similar to the notion of choice of task and choice of speaker in initiative in (Novick and Sutton, 1997), and the distinction between control and initiative in (Jordan and Di Eugenio, 1997). TI: system TI: manager DI: system 37 (3.5%) 274 (26.3%) DI: manager 4 (0.4%) 727 (69.8%) Table 1: Distribution of Task and Dialogue Initiatives agents should perform. The utterances may propose domain actions (Litman and Allen, 1987) that directly contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s send engine E2 to Corning.&amp;quot; On the other hand, they may propose problem-solving actions (Allen, 1991; Lambert and Carberry, 1991; Ramshaw, 1991) that contribute not directly to the agents&apos; domain goal, but to</context>
</contexts>
<marker>Novick, Sutton, 1997</marker>
<rawString>Novick, David G. and Stephen Sutton. 1997. What is mixed-initiative interaction? In Working Notes of the AAAI-97 Spring Symposium on Computational Models for Mixed Initiative Interaction, pages 114-116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judea Pearl</author>
</authors>
<title>Bayesian and belief-fuctions formalisms for evidential reasoning: A conceptual analysis.</title>
<date>1990</date>
<booktitle>In Glenn Shafer and Judea Pearl, editors, Readings in Uncertain Reasoning.</booktitle>
<pages>540--574</pages>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="13830" citStr="Pearl, 1990" startWordPosition="2207" endWordPosition="2208">ter-Shafer theory as the basis for our model are twofold. First, unlike the Bayesian model, it does not require a complete set of a priori and conditional probabilities, which is difficult to obtain for sparse pieces of evidence. Second, the Dempster-Shafer theory distinguishes between situations in which no evidence is available to support any conclusion and those in which equal evidence is available to support each conclusion. Thus the outcome of the model more accurately represents the amount of evidence available to support a particular conclusion, i.e., the provability of the conclusion (Pearl, 1990). 3.1 Cues for Tracking Initiative In order to utilize the Dempster-Shafer theory for modeling initiative, we must first identify the cues that provide evidence for initiative shifts. Whittaker, Stenton, and Walker (Whittaker and Stenton, 1988; Walker and Whittaker, 1990) have previously identified a set of utterance intentions that serve as cues to indicate shifts or lack of shifts in initiative, such as prompts and questions. We analyzed our annotated TRAINS91 corpus and identified additional cues that may have contributed to the shift or lack of shift in task/dialogue initiatives during the</context>
</contexts>
<marker>Pearl, 1990</marker>
<rawString>Pearl, Judea. 1990. Bayesian and belief-fuctions formalisms for evidential reasoning: A conceptual analysis. In Glenn Shafer and Judea Pearl, editors, Readings in Uncertain Reasoning. Morgan Kaufmann, pages 540-574.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
</authors>
<title>A three-level model for plan exploration.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>36--46</pages>
<contexts>
<context position="7167" citStr="Ramshaw, 1991" startWordPosition="1114" endWordPosition="1115">hoice of task and choice of speaker in initiative in (Novick and Sutton, 1997), and the distinction between control and initiative in (Jordan and Di Eugenio, 1997). TI: system TI: manager DI: system 37 (3.5%) 274 (26.3%) DI: manager 4 (0.4%) 727 (69.8%) Table 1: Distribution of Task and Dialogue Initiatives agents should perform. The utterances may propose domain actions (Litman and Allen, 1987) that directly contribute to achieving the agents&apos; goal, such as &amp;quot;Let&apos;s send engine E2 to Corning.&amp;quot; On the other hand, they may propose problem-solving actions (Allen, 1991; Lambert and Carberry, 1991; Ramshaw, 1991) that contribute not directly to the agents&apos; domain goal, but to how they would go about achieving this goal, such as &amp;quot;Let&apos;s look at the first [problem] first.&amp;quot; An agent is said to have the dialogue initiative if she takes the conversational lead in order to establish mutual beliefs, such as mutual beliefs about a piece of domain knowledge or about the validity of a proposal, between the agents. For instance, in responding to agent A&apos;s proposal of sending a boxcar to Corning via Dansville, agent B may take over the dialogue initiative (but not the task initiative) by saying &amp;quot;We can&apos;t go by Dan</context>
</contexts>
<marker>Ramshaw, 1991</marker>
<rawString>Ramshaw, Lance A. 1991. A three-level model for plan exploration. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 36-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Shafer</author>
</authors>
<title>A Mathematical Theory of Evidence.</title>
<date>1976</date>
<publisher>Princeton University Press.</publisher>
<contexts>
<context position="12280" citStr="Shafer, 1976" startWordPosition="1951" endWordPosition="1952">ntains, for each agent, a task initiative index and a dialogue initiative index which measure the amount of evidence available to support the agent holding the task and dialogue initiatives, respectively. After each turn, new initiative indices are calculated based on the current indices and the effects of the cues observed during the turn. These cues may be explicit requests by the speaker to give up his initiative, or implicit cues such as ambiguous proposals. The new initiative indices then determine the initiative holders for the next turn. We adopt the Dempster-Shafer theory of evidence (Shafer, 1976; Gordon and Shortliffe, 1984) as our underlying model for inferring the accumulated effect of multiple cues on determining the initiative indices. The Dempster-Shafer theory is a mathematical theory for reasoning under uncertainty which operates over a set of possible outcomes, 0. Associated with each piece of evidence that may provide support for the possible outcomes is a basic probability assignment (bpa), a function that represents the impact of the piece of evidence on the subsets of 0. A bpa assigns a number in the range [0,1] to each subset of 0 such that the numbers sum to 1. The numb</context>
</contexts>
<marker>Shafer, 1976</marker>
<rawString>Shafer, Glenn. 1976. A Mathematical Theory of Evidence. Princeton University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N John Castellan</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGraw Hill.</publisher>
<contexts>
<context position="9125" citStr="Castellan, 1988" startWordPosition="1447" endWordPosition="1448">ystem or manager, depending on which agent holds the task/dialogue initiative during that turn.2 Table 1 shows the distribution of task and dialogue initiatives in the TRAINS91 dialogues. It shows that while in the majority of turns, the task and dialogue initiatives are held by the same agent, in approximately 1/4 of the turns, the agents&apos; behavior can be better accounted for by tracking the two types of initiatives separately. To assess the reliability of our annotations, approximately 10% of the dialogues were annotated by two additional coders. We then used the kappa statistic (Siegel and Castellan, 1988; Carletta, 1996) to assess the level of agreement between the three coders with respect to the 2 An agent holds the task initiative during a turn as long as some utterance during the turn directly proposes how the agents should accomplish their goal, as in utterance (3c). 263 task and dialogue initiative holders. In this experiment, K is 0.57 for the task initiative holder agreement and K is 0.69 for the dialogue initiative holder agreement. Carletta suggests that content analysis researchers consider K &gt;.8 as good reliability, with .67&lt; K &lt;.8 allowing tentative conclusions to be drawn (Carle</context>
</contexts>
<marker>Castellan, 1988</marker>
<rawString>Siegel, Sidney. and N. John. Castellan, Jr. 1988. Nonparametric Statistics for the Behavioral Sciences. McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronnie W Smith</author>
<author>D Richard Hipp</author>
</authors>
<title>Spoken Natural Language Dialog Systems - A Practical Approach.</title>
<date>1994</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="3756" citStr="Smith and Hipp (1994)" startWordPosition="559" endWordPosition="562"> conversational lead, among participants. Novick (1988) developed a computational model that utilizes metalocutionary acts, such as repeat and give-turn, to capture mixed-initiative behavior in dialogues. Whittaker and Stenton (1988) devised rules for allocating dialogue control based on utterance types, and Walker and Whittaker (1990) utilized these rules for an analytical study on discourse segmentation. Kitano and Van Ess-Dykema (1991) developed a plan-based dialogue understanding model that tracks the conversational initiative based on the domain and discourse plans behind the utterances. Smith and Hipp (1994) developed a dialogue system that varies its responses to user utterances based on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed a system that allows change in the level of mi262 tiative based on initiative-changing utterances and each agent&apos;s competency in completing the current subtask. However, we contend that merely maintaining the conversational lead is insufficient for modeling complex behavior commonly </context>
</contexts>
<marker>Smith, Hipp, 1994</marker>
<rawString>Smith, Ronnie W. and D. Richard Hipp. 1994. Spoken Natural Language Dialog Systems - A Practical Approach. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SRI Transcripts</author>
</authors>
<title>Transcripts derived from audiotape conversations made at SRI International, Menlo Park, CA. Prepared by Jacqueline Kowtko under the direction of Patti Price.</title>
<date>1992</date>
<contexts>
<context position="4431" citStr="Transcripts, 1992" startWordPosition="661" endWordPosition="662">user utterances based on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed a system that allows change in the level of mi262 tiative based on initiative-changing utterances and each agent&apos;s competency in completing the current subtask. However, we contend that merely maintaining the conversational lead is insufficient for modeling complex behavior commonly found in naturally-occurring collaborative dialogues (SRI Transcripts, 1992; Gross, Allen, and Traum, 1993; Heeman and Allen, 1995). For instance, consider the alternative responses in utterances (3a)-(3c), given by an advisor to a student&apos;s question: (1) S: I want to take NLP to satisfy my seminar course requirement. (2) Who is teaching NLP? (3a) A: Dr Smith is teaching NLP. (3b) A: You can&apos;t take NLP because you haven&apos;t taken Al, which is a prerequisite for NLP (3c) A: You can&apos;t take NLP because you haven&apos;t taken AI, which is a prerequisite for NLP You should take distributed programming to satisfy your requirement, and sign up as a listener for NLP Suppose we adop</context>
<context position="30192" citStr="Transcripts, 1992" startWordPosition="4842" endWordPosition="4843">include extra information in response to a question, taking into account the cognitive load that a question places on the hearer may allow us to more accurately predict dialogue initiative shifts. 4 Applications in Other Environments To investigate the generality of our system, we applied our training algorithm, using the constant-incrementwith-counter adjustment method with A = 0.35, on the TRAINS91 corpus to obtain a set of bpa&apos; s. We then evaluated the system on subsets of dialogues from four other corpora: the TRA1NS93 dialogues (Heeman and Allen, 1995), airline reservation dialogues (SRI Transcripts, 1992), instruction-giving dialogues (Map Task Dialogues, 1996), and non-task-oriented dialogues (Switchboard Credit Card Corpus, 1992). In addition, we applied our baseline strategy which makes predictions without the use of cues to each corpus. Table 4 shows a comparison between the dialogues from the five corpora and the results of this evaluation. Row 1 in the table shows the number of turns where the expert9 holds the task/dialogue initiative, with percentages shown in parentheses. This analysis shows that the distribution of initiatives varies quite significantly across corpora, with the distr</context>
</contexts>
<marker>Transcripts, 1992</marker>
<rawString>SRI Transcripts. 1992. Transcripts derived from audiotape conversations made at SRI International, Menlo Park, CA. Prepared by Jacqueline Kowtko under the direction of Patti Price.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Switchboard Credit Card Corpus</author>
</authors>
<title>Transcripts of telephone conversations on the topic of credit card use, collected at Texas Instruments. Produced by NIST, available through LDC.</title>
<date>1992</date>
<contexts>
<context position="30321" citStr="Corpus, 1992" startWordPosition="4856" endWordPosition="4857">llow us to more accurately predict dialogue initiative shifts. 4 Applications in Other Environments To investigate the generality of our system, we applied our training algorithm, using the constant-incrementwith-counter adjustment method with A = 0.35, on the TRAINS91 corpus to obtain a set of bpa&apos; s. We then evaluated the system on subsets of dialogues from four other corpora: the TRA1NS93 dialogues (Heeman and Allen, 1995), airline reservation dialogues (SRI Transcripts, 1992), instruction-giving dialogues (Map Task Dialogues, 1996), and non-task-oriented dialogues (Switchboard Credit Card Corpus, 1992). In addition, we applied our baseline strategy which makes predictions without the use of cues to each corpus. Table 4 shows a comparison between the dialogues from the five corpora and the results of this evaluation. Row 1 in the table shows the number of turns where the expert9 holds the task/dialogue initiative, with percentages shown in parentheses. This analysis shows that the distribution of initiatives varies quite significantly across corpora, with the distribution biased toward one agent in the TRAINS and maptask corpora, and split fairly evenly in the airline and switchboard dialogu</context>
</contexts>
<marker>Corpus, 1992</marker>
<rawString>Switchboard Credit Card Corpus. 1992. Transcripts of telephone conversations on the topic of credit card use, collected at Texas Instruments. Produced by NIST, available through LDC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Steve Whittaker</author>
</authors>
<title>Mixed initiative in dialogue: An investigation into discourse segmentation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>70--78</pages>
<contexts>
<context position="3472" citStr="Walker and Whittaker (1990)" startWordPosition="518" endWordPosition="522">spectively, compared to a simple prediction method without the use of cues, thus illustrating the generality of our model. 2 Task Initiative vs. Dialogue Initiative 2.1 Motivation Previous work on mixed-initiative dialogues focused on tracking and allocating a single thread of control, the conversational lead, among participants. Novick (1988) developed a computational model that utilizes metalocutionary acts, such as repeat and give-turn, to capture mixed-initiative behavior in dialogues. Whittaker and Stenton (1988) devised rules for allocating dialogue control based on utterance types, and Walker and Whittaker (1990) utilized these rules for an analytical study on discourse segmentation. Kitano and Van Ess-Dykema (1991) developed a plan-based dialogue understanding model that tracks the conversational initiative based on the domain and discourse plans behind the utterances. Smith and Hipp (1994) developed a dialogue system that varies its responses to user utterances based on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is determined at the outset and cannot be changed during the dialogue. Guinn (1996) subsequently developed </context>
<context position="14102" citStr="Walker and Whittaker, 1990" startWordPosition="2246" endWordPosition="2249"> theory distinguishes between situations in which no evidence is available to support any conclusion and those in which equal evidence is available to support each conclusion. Thus the outcome of the model more accurately represents the amount of evidence available to support a particular conclusion, i.e., the provability of the conclusion (Pearl, 1990). 3.1 Cues for Tracking Initiative In order to utilize the Dempster-Shafer theory for modeling initiative, we must first identify the cues that provide evidence for initiative shifts. Whittaker, Stenton, and Walker (Whittaker and Stenton, 1988; Walker and Whittaker, 1990) have previously identified a set of utterance intentions that serve as cues to indicate shifts or lack of shifts in initiative, such as prompts and questions. We analyzed our annotated TRAINS91 corpus and identified additional cues that may have contributed to the shift or lack of shift in task/dialogue initiatives during the interactions. This results in eight cue types, which are grouped into three classes, based on the kind of knowledge needed to recognize them. Table 2 shows the three classes, the eight cue types, their subtypes if any, whether a cue may affect merely the dialogue initiat</context>
<context position="19462" citStr="Walker and Whittaker, 1990" startWordPosition="3124" endWordPosition="3127">es that cannot be recognized without the hearer performing an evaluation on the speaker&apos;s proposal using the hearer&apos;s private knowledge (Chu-Carroll and Carberry, 1994; Chu-Carroll and Carberry, 1995). After the evaluation, the hearer may find the proposal invalid, suboptimal, or ambiguous. As a result, he may initiate a subdialogue to resolve the problem, resulting in a shift in task/dialogue initiatives.3 3 Whittaker, Stanton, and Walker treat subdialogues initiated as a result of these cues as interruptions, motivated by their collaborative planning principles (Whittaker and Stanton, 1988: Walker and Whittaker, 1990). 265 3.2 Utilizing the Dempster-Shafer Theory As discussed earlier, at the end of each turn, new task/dialogue initiative indices are computed based on the current indices and the effect of the observed cues to determine the next task/dialogue initiative holders. In terms of the Dempster-Shafer theory, new task/dialogue bpa&apos;s (rnt-newirnd-net04 are computed by applying Dempster s combination rule to the bpa&apos; s representing the current initiative indices5 and the bpa of each observed cue. Evidently, some cues provide stronger evidence for an initiative shift than others. Furthermore, a cue may</context>
</contexts>
<marker>Walker, Whittaker, 1990</marker>
<rawString>Walker, Marilyn and Steve Whittaker. 1990. Mixed initiative in dialogue: An investigation into discourse segmentation. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pages 70-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Redundancy in collaborative dialogue.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>345--351</pages>
<contexts>
<context position="17460" citStr="Walker, 1992" startWordPosition="2817" endWordPosition="2818"> using linguistic and discourse information, such as from the surface form of an utterance, or from the discourse relationship between the current and prior utterances. It consists of four cue types. The first type is perceptible silence at the end of an utterance, which suggests that the speaker has nothing more to say and may intend to give up her initiative. The second type includes utterances that do not contribute information that has not been conveyed earlier in the dialogue. It can be further classified into two groups: repetitions, a subset of the informationally redundant utterances (Walker, 1992), in which the speaker paraphrases an utterance by the hearer or repeats the utterance verbatim, and prompts, in which the speaker merely acknowledges the hearer&apos;s previous utterance(s). Repetitions and prompts also suggest that the speaker has nothing more to say and indicate that the hearer should take over the initiative (Whittaker and Stenton, 1988). The third type includes questions which, based on anticipated responses, are divided into domain and evaluation questions. Domain questions are questions in which the speaker intends to obtain or verify a piece of domain knowledge. They usuall</context>
</contexts>
<marker>Walker, 1992</marker>
<rawString>Walker, Marilyn A. 1992. Redundancy in collaborative dialogue. In Proceedings of the 15th International Conference on Computational Linguistics, pages 345-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Phil Stenton</author>
</authors>
<title>Cues and control in expert-client dialogues.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>123--130</pages>
<contexts>
<context position="3368" citStr="Whittaker and Stenton (1988)" startWordPosition="503" endWordPosition="506">ccuracies in the prediction of task and dialogue initiative holders by 2-4 and 8-13 percentage points, respectively, compared to a simple prediction method without the use of cues, thus illustrating the generality of our model. 2 Task Initiative vs. Dialogue Initiative 2.1 Motivation Previous work on mixed-initiative dialogues focused on tracking and allocating a single thread of control, the conversational lead, among participants. Novick (1988) developed a computational model that utilizes metalocutionary acts, such as repeat and give-turn, to capture mixed-initiative behavior in dialogues. Whittaker and Stenton (1988) devised rules for allocating dialogue control based on utterance types, and Walker and Whittaker (1990) utilized these rules for an analytical study on discourse segmentation. Kitano and Van Ess-Dykema (1991) developed a plan-based dialogue understanding model that tracks the conversational initiative based on the domain and discourse plans behind the utterances. Smith and Hipp (1994) developed a dialogue system that varies its responses to user utterances based on four dialogue modes which model different levels of initiative exhibited by dialogue participants. However, the dialogue mode is </context>
<context position="5129" citStr="Whittaker and Stenton, 1988" startWordPosition="782" endWordPosition="785">, consider the alternative responses in utterances (3a)-(3c), given by an advisor to a student&apos;s question: (1) S: I want to take NLP to satisfy my seminar course requirement. (2) Who is teaching NLP? (3a) A: Dr Smith is teaching NLP. (3b) A: You can&apos;t take NLP because you haven&apos;t taken Al, which is a prerequisite for NLP (3c) A: You can&apos;t take NLP because you haven&apos;t taken AI, which is a prerequisite for NLP You should take distributed programming to satisfy your requirement, and sign up as a listener for NLP Suppose we adopt a model that maintains a single thread of control, such as that of (Whittaker and Stenton, 1988). In utterance (3a), A directly responds to S&apos;s question; thus the conversational lead remains with S. On the other hand, in (3b) and (3c), A takes the lead by initiating a subdialogue to correct S&apos;s invalid proposal. However, existing models cannot explain the difference in the two responses, namely that in (3c), A actively participates in the planning process by explicitly proposing domain actions, whereas in (3b), she merely conveys the invalidity of S&apos;s proposal. Based on this observation, we argue that it is necessary to distinguish between task initiative, which tracks the lead in the de</context>
<context position="14073" citStr="Whittaker and Stenton, 1988" startWordPosition="2242" endWordPosition="2245">. Second, the Dempster-Shafer theory distinguishes between situations in which no evidence is available to support any conclusion and those in which equal evidence is available to support each conclusion. Thus the outcome of the model more accurately represents the amount of evidence available to support a particular conclusion, i.e., the provability of the conclusion (Pearl, 1990). 3.1 Cues for Tracking Initiative In order to utilize the Dempster-Shafer theory for modeling initiative, we must first identify the cues that provide evidence for initiative shifts. Whittaker, Stenton, and Walker (Whittaker and Stenton, 1988; Walker and Whittaker, 1990) have previously identified a set of utterance intentions that serve as cues to indicate shifts or lack of shifts in initiative, such as prompts and questions. We analyzed our annotated TRAINS91 corpus and identified additional cues that may have contributed to the shift or lack of shift in task/dialogue initiatives during the interactions. This results in eight cue types, which are grouped into three classes, based on the kind of knowledge needed to recognize them. Table 2 shows the three classes, the eight cue types, their subtypes if any, whether a cue may affec</context>
<context position="17815" citStr="Whittaker and Stenton, 1988" startWordPosition="2869" endWordPosition="2872">give up her initiative. The second type includes utterances that do not contribute information that has not been conveyed earlier in the dialogue. It can be further classified into two groups: repetitions, a subset of the informationally redundant utterances (Walker, 1992), in which the speaker paraphrases an utterance by the hearer or repeats the utterance verbatim, and prompts, in which the speaker merely acknowledges the hearer&apos;s previous utterance(s). Repetitions and prompts also suggest that the speaker has nothing more to say and indicate that the hearer should take over the initiative (Whittaker and Stenton, 1988). The third type includes questions which, based on anticipated responses, are divided into domain and evaluation questions. Domain questions are questions in which the speaker intends to obtain or verify a piece of domain knowledge. They usually merely require a direct response and thus typically do not result in an initiative shift. Evaluation questions, on the other hand, are questions in which the speaker intends to assess the quality of a proposed plan. They often require an analysis of the proposal, and thus frequently result in a shift in dialogue initiative. The final type includes utt</context>
</contexts>
<marker>Whittaker, Stenton, 1988</marker>
<rawString>Whittaker, Steve and Phil Stenton. 1988. Cues and control in expert-client dialogues. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 123-130.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>