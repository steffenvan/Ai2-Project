<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000602">
<title confidence="0.998402">
Mining User Relations from Online Discussions using Sentiment Analysis
and Probabilistic Matrix Factorization
</title>
<author confidence="0.987169">
Minghui Qiu†, Liu Yang†4, Jing Jiang†† School of Information Systems, Singapore Management University, Singapore
</author>
<affiliation confidence="0.918865">
‡ School of Software and Microelectronics, Peking University, China
</affiliation>
<email confidence="0.99724">
{minghui.qiu.2010,jingjiang}@smu.edu.sg, yang.liu@pku.edu.cn
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999546666666667">
Advances in sentiment analysis have enabled
extraction of user relations implied in online
textual exchanges such as forum posts. How-
ever, recent studies in this direction only con-
sider direct relation extraction from text. As
user interactions can be sparse in online dis-
cussions, we propose to apply collaborative
filtering through probabilistic matrix factor-
ization to generalize and improve the opinion
matrices extracted from forum posts. Exper-
iments with two tasks show that the learned
latent factor representation can give good per-
formance on a relation polarity prediction task
and improve the performance of a subgroup
detection task.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908843137255">
The fast growth of the social Web has led to a large
amount of interest in online social network analysis.
Most existing work on social network analysis re-
lies on explicit links among users such as undirected
friendship relations (Liben-Nowell and Kleinberg,
2003), directed following relations (Hopcroft et al.,
2011) and trust/distrust relations (Leskovec et al.,
2010). However, besides these explicit social rela-
tions, the various kinds of interactions between on-
line users often suggest other implicit relations. In
particular, in online discussion forums, users inter-
act through textual posts and these exchanged texts
often reveal whether two users are friends or foes, or
whether two users share the same viewpoint towards
a given issue.
To uncover such implicit relations requires text
analysis and particularly sentiment analysis. Re-
cently, Hassan et al. (2012) studied predicting the
polarity of user interactions in online discussions
based on textual exchanges. They found that the au-
tomatically predicted signed relations had an accu-
racy above 80%. The extracted signed network was
further used to detect ideological subgroups. This is
a piece of pioneering work that extracts online social
relations based on text analysis.
In this paper, we further extend the idea of mining
social relations from online forum posts by incorpo-
rating collaborative filtering. Our work is motivated
by the observation that direct textual exchanges be-
tween users are sparse. For example, in the data set
we use, only around 13% of user-user pairs have di-
rect interactions. Collaborative filtering is a com-
monly used technique in recommender systems to
predict missing ratings. The key assumption is that
if two people have the same opinion on an item A,
they are likely to also have the same opinion on a
different item B. In online discussion forums, users
express their opinions about each other as well as
the various aspects of the topic under discussion, but
not every user comments on every aspect or every
other user. Collaborative filtering allows us to iden-
tify users with the same opinion even if they have not
directly interacted with each other or commented on
any common aspect.
Our method starts with extracting opinions on
users and topic aspects from online posts using sen-
timent analysis. The results are two matrices indi-
cating the sentiment polarity scores between pairs
of users and pairs of a user and an aspect. To in-
corporate collaborative filtering, we choose proba-
bilistic matrix factorization (PMF) (Salakhutdinov
</bodyText>
<page confidence="0.983581">
401
</page>
<note confidence="0.4708075">
Proceedings of NAACL-HLT 2013, pages 401–410,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999113">
and Mnih, 2008), a technique that has been success-
fully applied for collaborative filtering-based recom-
mendation problems. PMF automatically discovers
a low-rank representation for both users and items
based on observed rating data. In our problem, the
predicted sentiment polarity scores are treated as rat-
ing data, and the results of PMF are low-rank vectors
representing each user in online discussions.
We evaluate our method on two tasks. The first
is to predict the polarity of interactions between two
users not from their own textual exchanges but from
their interactions with other users or comments on
topic aspects. The second is to use the latent vectors
to group users based on viewpoints. We find that the
latent factor representation can produce good predic-
tion results for the first task and improve the cluster-
ing results of the second task compared with a num-
ber of baselines, showing the effectiveness of col-
laborative filtering for mining social relations from
online discussions.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999527892857143">
Our work is closely related to recent studies on
detecting subgroups from online discussions (Abu-
Jbara et al., 2012; Dasigi et al., 2012; Hassan et
al., 2012). Abu-Jbara et al. (2012) proposed to
build discussant attitude profiles (DAP) from on-
line posts and use these profiles to cluster users into
subgroups. A DAP is a vector that contains the
attitudes of a discussant towards other discussants
and a set of opinion targets. We also extract opin-
ions of users towards other users and opinion tar-
gets from posts, which are similar to DAPs. The
difference is that we further apply probabilistic ma-
trix factorization to derive a low-rank representation
from the raw opinion scores. Our comparison with
DAP-based clustering shows that probabilistic ma-
trix factorization can improve subgroup detection.
Hassan et al. (2012) proposed to predict the polar-
ity of interactions between users based on their tex-
tual exchanges. They defined a set of interaction
features using sentiment analysis and applied super-
vised learning for polarity prediction. In compari-
son, our work is unsupervised, that is, we do not use
any ground truth of interaction polarity for training.
Probabilistic matrix factorization was proposed
by Salakhutdinov and Mnih (2008) as a collabo-
rative filtering method for recommender systems.
It has attracted much attention and been extended
by Ma et al. (2008) and Wang and Blei (2011).
In particular, Ma et al. (2008) proposed a SocRec
model that combines social network information
with rating data using the PMF framework to per-
form social recommendation. Our model bears sim-
ilarity to SocRec in that we also consider two types
of interactions, i.e. user-user interactions and user-
aspect interactions. However, different from Ma et
al. (2008), we predict both the user-user and user-
aspect scores from textual posts using sentiment
analysis, and the user-user opinion polarity scores
are symmetric.
Part of our method uses sentiment analysis to ex-
tract opinions from text. This is built on top of a
large body of existing work on opinion extraction,
e.g. Choi et al. (2006) and Wu et al. (2009). As the
sentiment analysis component is not our main con-
tribution, we do not review existing work along this
direction in detail here. Interested readers can refer
to Pang and Lee (2008).
The idea of incorporating sentiment analysis into
collaborative filtering algorithms has been explored
by Kawamae (2011), Moshfeghi et al. (2011) and
Leung et al. (2011). While their work also com-
bines sentiment analysis with collaborative filtering,
the purpose is to improve the accuracy of item rec-
ommendation. In contrast, we borrow the idea and
technique of collaborative filtering to improve user
relation mining from online text.
</bodyText>
<sectionHeader confidence="0.910391" genericHeader="method">
3 Method Overview
</sectionHeader>
<bodyText confidence="0.999764333333333">
In this section, we provide an overview of our
method. We first introduce some concepts.
User: We use user to refer to a discussant in an on-
line discussion. Each user has an online ID, which
can be used by other users to refer to him/her in a
post. Users are both opinion holders and opinion
targets. For example, User 1 below expresses a neg-
ative opinion towards another user in the following
snippet.
</bodyText>
<subsubsectionHeader confidence="0.670056">
User 1: Actually, I have to disagree with you.
</subsubsectionHeader>
<bodyText confidence="0.9971015">
Aspect: We use topic aspect or aspect to refer to an
opinion target that is related to the topic under dis-
cussion. For example, when debating about whether
one should vote for Obama, people may express
</bodyText>
<page confidence="0.99796">
402
</page>
<bodyText confidence="0.998962833333333">
opinions on targets such as “President Obama” and
“Republican party,” as shown in the following snip-
pets. These aspects are all related to Obama’s pres-
idential campaign. As we will explain later, the as-
pects we consider are named entities and frequent
noun phrases.
</bodyText>
<construct confidence="0.7107145">
User 2: Americans should vote for President Obama be-
cause he picks good corporations as winners.
User 3: I simply point out how absolutely terrible the Re-
publican party is.
</construct>
<listItem confidence="0.850202">
Polarity Score: A sentiment polarity score is a
</listItem>
<bodyText confidence="0.939428416666667">
real number between 0 and 1, where 0 indicates a
completely negative opinion and 1 indicates a com-
pletely positive opinion.
User-User Opinion Matrix: The opinions ex-
tracted from posts between users are represented by
a user-user opinion matrix 5, where entry sij is a
polarity score between the i-th user and the j-th user.
We assume that the polarity scores are symmetric.
User-Aspect Opinion Matrix: The opinions held
by different users on the various topic aspects are
represented by a user-aspect opinion matrix R,
where entry ri�k is a polarity score indicating the i-th
user’s opinion towards the k-th aspect.
Given the matrices 5 and R, we perform proba-
bilistic matrix factorization to derive a low-rank vec-
tor representation for users and aspects such that if
the polarity score between two users or a user and
an aspect is high, the dot product between the corre-
sponding two vectors is also high.
In Section 4, we will explain in detail how we
identify topic aspects from a discussion thread and
how we obtain polarity scores from posts. In Sec-
tion 5, we will present the details of our probabilistic
matrix factorization model.
</bodyText>
<sectionHeader confidence="0.734358" genericHeader="method">
4 Construction of Opinion Matrices
</sectionHeader>
<bodyText confidence="0.9989715">
The opinion matrices are constructed from a single
forum thread discussing some controversial topic.
</bodyText>
<subsectionHeader confidence="0.996767">
4.1 Aspect Identification
</subsectionHeader>
<bodyText confidence="0.999978466666667">
As we have pointed out, there are two kinds of opin-
ion targets, namely users and aspects. Users are
clearly defined and can often be identified in posts
by their IDs or second person pronouns. For aspects,
however, there is not a pre-defined set. We observe
that these topic aspects are usually named entities
or noun phrases frequently mentioned. We therefore
use the OpenNLP toolkit1 to perform chunking and
obtain noun phrases and the Standford NER tagger2
to identify named entities from the posts.
Some of the candidate aspect phrases identified
above actually refer to the same actual aspect, e.g.
“Obama voter,” “Obama voters” and “the Obama
voter.” We remove stop words from each candidate
phrase and use the WordNet by Miller (1995) to ob-
tain the lemma of each word such that we can nor-
malize the candidate aspect phases to some extent.
Finally, to select salient aspects for a given discus-
sion topic, we count the number of times each candi-
date aspect has been expressed a positive or negative
opinion on by all users, and select those candidate
aspects which have opinion expressions from at least
M users. We set M to 2 in our experiments. Fig-
ure 1 shows the top salient aspects for the thread on
“Will you vote for Obama?” We acknowledge there
are still duplicate aspects in the results like “Repub-
lican Party” and “GOP”. To normalize these aspects,
some additional information such as Wikipedia en-
tries and Google snippets may be considered. We
will study this problem in our future work.
</bodyText>
<subsectionHeader confidence="0.992506">
4.2 Opinion Expression Identification
</subsectionHeader>
<bodyText confidence="0.999984538461539">
Our next step is to identify candidate opinion expres-
sions. This problem has been studied in Hu and Liu
(2004), Popescu and Etzioni (2005), and Hassan
and Radev (2010). Based on previous work, we do
the following. We first combine three popular sen-
timent lexicons to form a single sentiment lexicon:
the lexicon used in Hu and Liu (2004), MPQA Sub-
jectivity Lexicon by Wilson et al. (2005) and Senti-
WordNet by Baccianella et al. (2010). Our final sen-
timent lexicon contains 15,322 negative expressions
and 10,144 positive expressions. We then identify
candidate opinion expressions by searching for oc-
currences of words in this lexicon in the posts.
</bodyText>
<subsectionHeader confidence="0.998178">
4.3 Opinion Relation Extraction
</subsectionHeader>
<bodyText confidence="0.9998892">
Given a post that contains an aspect and an opin-
ion expression, we still need to determine whether
the opinion expression is used to describe the as-
pect. This is a relation extraction problem. We use a
supervised learning approach based on dependency
</bodyText>
<footnote confidence="0.9994315">
1http://opennlp.apache.org/
2http://nlp.stanford.edu/ner/index.shtml
</footnote>
<page confidence="0.998273">
403
</page>
<figure confidence="0.998195166666667">
100
80
60
40
20
0
</figure>
<figureCaption confidence="0.998892">
Figure 1: Salient aspects and number of users who express opinions on them in the thread “Will you vote for Obama?”
</figureCaption>
<figure confidence="0.540077333333333">
ID Dependency path rule Example
R1 ADJOP +— amod +— NTR I simply point out how terrible REPUBLICAN PARTY is.
R2 ADJOP → nsubj → NTR BUSH is even more reasonable for tax hike than Obama.
R3 VOP → dobj → NTR I would never support OBAMA.
R4 VOP → prep * → NTR I’ll vote for OBAMA.
R5 VOP → nsubjpass → NTR DEMOCRATIC PARTY are ultimately corrupted by love of money.
R6 NOP +— dobj +— V → nsubj → NTR PAKISTAN is increasing terrorist threat.
R7 ADJOP +— amod +— N → nsubj → NTR OBAMA was a top scorer for occidental college.
R8 ADVOP +— advmod +— V → nsubj → NTR OBAMA is smarter than people.
</figure>
<tableCaption confidence="0.9599285">
Table 1: Examples of frequent dependency path rules in our training data. OP and TR refer to the opinion and the
target. The opinion words are in italic and the aspect words are in uppercase.
</tableCaption>
<bodyText confidence="0.999965885714286">
paths. Previous work by Mintz et al. (2009), and Qiu
et al. (2009) has shown that the shortest path be-
tween a candidate opinion aspect and a candidate
opinion expression in the dependency parse tree can
be effective in extracting opinion relations. We use
the Stanford Parser from Klein and Manning (2003)
to obtain the dependency parse trees for each sen-
tence in the posts and then get the dependency paths
between each pair of candidate aspect and opinion
expression. We use dependency relations and POS
tags of nodes along the path to represent a depen-
dency path. Given a set of training sentences (we
use the one from Wu et al. (2009)), we can get a set
of dependency path rules based on their frequencies
in the training data. Table 1 shows the frequent de-
pendency path rules in our training data.
When a pair of aspect and opinion expression is
identified to be related, we use the polarity of the
opinion expression to label the relation. Finally,
given a pair of users, we use the percentage of pos-
itive interactions between them over all subjective
interactions (i.e. interactions with either positive or
negative opinions) as extracted from their exchanged
posts as the sentiment polarity score between the
two users, regardless of the reply-to direction of
the posts. Similarly, given a user and an aspect,
we also use the percentage of positive opinion re-
lations extracted as the sentiment polarity score be-
tween them. Thus the user-user opinion matrix and
the user-aspect opinion matrix are constructed. If
there is no subjective interaction detected between
two users or between a user and an aspect, the cor-
responding entry in the matrix is left empty. We will
see later that empty entries in the matrices are not
used in the probabilistic matrix factorization step.
</bodyText>
<sectionHeader confidence="0.977445" genericHeader="method">
5 Probabilistic Matrix Factorization
</sectionHeader>
<bodyText confidence="0.988470909090909">
As we have pointed out earlier, a problem with the
matrices extracted as described in Section 4 is that
the matrices are sparse, i.e. many entries are empty.
For the data set we use, we find that around 87% of
entries in the user-user opinion matrix and around
90% of entries in the user-aspect opinion matrix are
empty. In this section, we describe how we use
Probabilistic Matrix Factorization (PMF) to repre-
sent users and aspects in a latent factor space and
thus generalize the user preferences.
Our model is almost a direct application of proba-
</bodyText>
<page confidence="0.995736">
404
</page>
<bodyText confidence="0.999172631578947">
bilistic matrix factorization from Salakhutdinov and
Mnih (2008), originally proposed for recommender
systems. The main difference is that the user-user
opinion polarity scores are symmetric. Our model is
also similar to the one used by Ma et al. (2008). We
describe our model as follows.
We assume that there are K latent factors with
which both users and aspects can be represented. Let
ui E IR,K denote the vector in the latent factor space
for the i-th user, and ak the vector for the k-th aspect.
Recall that the opinions extracted from posts be-
tween users are represented by a user-user opinion
matrix S, and the opinions held by different users on
the various topic aspects are represented by a user-
aspect opinion matrix R. We assume that the polar-
ity scores si,j between the i-th and the j-th users and
ri,k between the i-th user and the k-th aspect in the
two matrices S and R are generated in the following
way:
</bodyText>
<equation confidence="0.8288505">
p(si,j|ui, uj, σ21) = N(si,j|g(uTi uj), σ21),
p(ri,k|ui, ak, σ22) = N(ri,k|g(uTi ak), σ22),
</equation>
<bodyText confidence="0.9997025">
where σ2 1 and σ22 are variance parameters, g(·) the
logistic function, and N(·|µ, σ2) is the normal dis-
tribution with mean µ and variance σ2.
We can see that with this generative assumption,
if two users are similar in terms of their dot product
in the latent factor space, then they are more likely
to have positive interactions as extracted from their
textual exchanges. Similarly, if a user and an aspect
are similar, then the user is more likely to express a
positive opinion on the aspect in his/her posts. The
latent factors can therefore encode user preferences
and similarity between two users in the latent factor
space reflects whether they share similar viewpoints.
We also place the following prior over ui and ak:
</bodyText>
<equation confidence="0.9996325">
p(ui|σ2U) = N(ui|~0, σ2UI),
p(ak|σ2A) = N(ak|~0, σ2AI),
</equation>
<bodyText confidence="0.997623142857143">
where σ2 U and σ2 A are two variance parameters for
users and aspects, respectively, and I is the identify
matrix.
Figure 2 shows the plate notation for the genera-
tive model.
Let U be a K xU matrix containing the vectors ui
for all U users, and A be an KxA matrix containing
</bodyText>
<figureCaption confidence="0.999301">
Figure 2: Probabilistic matrix factorization model on
opinion matrices.
</figureCaption>
<bodyText confidence="0.997392666666667">
the vectors ak for all A aspects. To automatically
learn U and A, we minimize the following objective
function:
</bodyText>
<equation confidence="0.822698">
λU F + λA
+ 2 ||U||2 2 ||A||2 F, (1)
</equation>
<bodyText confidence="0.876023">
where λ = σ2 1 U , and λA = σ2 1
</bodyText>
<equation confidence="0.9839955">
2 , λU = σ2 1 A , I(s) is
σ2 σ2 σ2
</equation>
<bodyText confidence="0.999671833333333">
an indicator function which equals 1 when s is not
empty and otherwise 0.
To optimize the objective function above, we can
perform gradient descent on U and A to find a local
optimum point. The derivation is similar to Ma et al.
(2008).
</bodyText>
<subsectionHeader confidence="0.640973">
Degenerate Versions of the Model
</subsectionHeader>
<bodyText confidence="0.9995031">
We refer to the complete model described above
as PMF-UOM (PMF model based on User Opinion
Matrices). PMF-UOM has the following two degen-
erate versions by considering either only the user-
user opinion matrix or only the user-aspect opinion
matrix.
PMF-UU: In this degenerate version of the model,
we use only the user-user opinion matrix to learn the
latent factor representation. Specifically, the objec-
tive function is modified such that we drop the sum
</bodyText>
<figure confidence="0.846953052631579">
G(U, A, S, R)
II(ri,k)(ri,k − g(uTiak))2
II(si,j)(si,j − g(uTi uj))2
=
+
1
2
U
i=1
A
E
k=1
λ1
2
U
i=1
U
E
j=1
</figure>
<page confidence="0.995068">
405
</page>
<bodyText confidence="0.999804714285714">
of the square errors involving R and the regularizer
on A.
PMF-UA: In this degenerate version of the model,
we use only the user-aspect opinion matrix to learn
the latent factor representation. Specifically, the ob-
jective function is modified such that we drop the
sum of the square errors involving S.
</bodyText>
<sectionHeader confidence="0.999636" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.998766">
In this section, we present our experiments that eval-
uate our model.
</bodyText>
<subsectionHeader confidence="0.999829">
6.1 Data Set and Experiment Settings
</subsectionHeader>
<bodyText confidence="0.999389125">
The data set we use comes from Abu-Jbara et al.
(2012) and Hassan et al. (2012). The data set
contains a set of discussion threads collected from
two political forums (Createdebate3 and Politicalfo-
rum4) and one Wikipedia discussion session. We
randomly select 6 threads from the original data set
to evaluate our model. Some details of the data we
use are listed in Table 2.
</bodyText>
<table confidence="0.998801428571429">
ID topic #sides #sentences #users
DS1 Vote for Obama 2 12492 197
DS2 Abortion Banned 6 3844 70
DS3 Profile Muslims 4 2167 69
DS4 England and USA 6 2030 62
DS5 Tax Cuts 2 1193 26
DS6 Political Spectrum 7 1130 50
</table>
<tableCaption confidence="0.999754">
Table 2: Some statistics of the data sets.
</tableCaption>
<bodyText confidence="0.99995025">
In our experiments, for the PMF-based methods,
we set the number of latent factors to be 10 as we
do not observe big difference when vary the latent
factor size from 10 to 50. For the other parame-
ters, we select the optimal setting for each thread
based on the average of 50 runs. AU is chosen
from {0.1, 0.01}, AA from {0.01, 0.001} and A from
{1,0.1}.
</bodyText>
<subsectionHeader confidence="0.999297">
6.2 Relation Polarity Prediction
</subsectionHeader>
<bodyText confidence="0.999956333333333">
The first task we use to evaluate our model is to pre-
dict the polarity of interactions between two users.
Different from Hassan et al. (2012), however, we
are not using this task to evaluate the accuracy of
sentiment analysis from text. Our experimental set-
ting is completely different in that we do not make
</bodyText>
<footnote confidence="0.999943">
3www.createdebate.com
4www.politicalforum.com
</footnote>
<bodyText confidence="0.999827142857143">
use of the text exchanges between the two users but
instead use their interactions with other users or as-
pects. The purpose is to test the effectiveness of col-
laborative filtering.
Experimental Setting: The experiments are set up
in the following way. Given a pair of users i and j
who have directly exchanged posts, i.e. si,j is not
empty, we first hide the value of si,j in the matrix S.
Let the altered matrix be S,(i,j). We then use S,(i,j)
instead of S in the learning process as described in
Section 5 to learn the latent factor representation.
Let fii and fij denote the learned latent vectors for
user i and user j. We predict the polarity of relation
between i and j as follows:
</bodyText>
<equation confidence="0.975769">
{1 if g(uTi uj) &gt; 0.5,
0 otherwise,
</equation>
<bodyText confidence="0.999766692307692">
where g(·) is the logistic function to convert the dot
product into a value between 0 and 1.
To judge the quality of the predicted polarity si,j,
we could compare it with si,j. But since si,j itself is
predicted from the textual exchanges between i and
j, it is not the ground truth. Instead, we ask two hu-
man annotators to assign the true polarity label for
user i and user j by reading the textual exchanges
between them and judging whether they are friends
or foes in the discussion thread. The annotators are
asked to assign a score of 0 (indicating a negative
relation), 0.5 (indicating a neutral relation) or 1 (in-
dicating a positive relation). The lowest agreement
score based on Cohen’s kappa coefficient among the
6 threads we use is 0.56, showing fair to good agree-
ment. As ground truth, we set the final polarity score
to 1 if the average score of the two annotators is
larger than 0.5 and 0 otherwise.
We compare the PMF-based methods with two
majority baselines: MBL-0 always predicts negative
relations for all the user pairs (assuming most rela-
tions are negative) and MBL-1 always predicts posi-
tive relations (assuming most relations are positive).
We use MAE (mean absolute error) and RMSE
(root mean square error) as defined below as perfor-
mance metrics:
</bodyText>
<equation confidence="0.997120375">
�si,j =
,
I
RMSE = 1I ,j (�si,j − li,j )2
V ,
N
MAE = E i,j |�si,j − li,j|
N
</equation>
<page confidence="0.997358">
406
</page>
<figureCaption confidence="0.9999305">
Figure 3: Comparing all the methods in terms of MAE.
Figure 4: Comparing all the methods in terms of RMSE.
</figureCaption>
<figure confidence="0.997972">
DS1 DS2 DS3 DS4 DS5 DS6
MAE
0.8
0.6
0.4
0.2
1.0
MB-1
MB-0
PMF-UU
PMF-UA
PMF-UOM
DS1 DS2 DS3 DS4 DS5 DS6
RMSE
0.8
0.6
0.4
0.2
1.0
MB-1
MB-0
PMF-UU
PMF-UA
PMF-UOM
</figure>
<bodyText confidence="0.999810884615384">
where N is the total number of user pairs we test,
and lij is the ground truth polarity score between
user i and user j.
Results: We show the results of our model and of
PMF-UU and PMF-UA in terms of MAE in Figure 3
and RMSE in Figure 4. The MAE values range be-
tween 0.31 and 0.44 except for DS5, which has a
higher error rate of 0.53. The results show that even
without knowing the textual exchanges between two
users, from their interactions with other users and/or
with topic aspects, we can still infer the polarity of
their relation with decent accuracy most of the time.
The results also show the comparison between our
model and the competing methods. We can see that
overall the complete model (PMF-UOM) performs
better than the two degenerate models (PMF-UU
and PMF-UA). The differences are statistically sig-
nificant at the 5% level without considering DS5, as
indicated by a 2-tailed paired t-test. Comparing to
the majority baselines, our model significantly out-
performs MBL-1 at 1% significance level while out-
performs MBL-0 on all the data sets except DS5. A
close examinations shows DS5 has very unbalanced
relations (around 83% of relations are negative). Ex-
cept for the unbalanced data set, our model has rea-
sonably good performance.
</bodyText>
<subsectionHeader confidence="0.999136">
6.3 Subgroup Detection
</subsectionHeader>
<bodyText confidence="0.999520111111111">
The second task we study is the problem of detecting
ideological subgroups from discussion threads. The
original data set has been labeled with the ground
truth for this problem, that is, for each thread the
number of viewpoints is known and the viewpoint
held by each user is labeled. A subgroup is defined
as a set of users holding the same viewpoint.
Experimental Setting: Through this second exper-
iment, we would like to verify the hypothesis that
using the learned latent factor representation U for
users, we can better detect subgroups than directly
using the opinion matrices 5 and R. For all the
methods we compare, we first construct a feature
vector representation for each user. We then apply
K-means clustering to group users. The number of
clusters is set to be the true number of viewpoints
for each thread. The different methods are described
below:
</bodyText>
<listItem confidence="0.999637647058823">
• PMF-based methods: We simply use the
learned latent vectors fii after optimizing the
objective function as the feature vectors to rep-
resent each user.
• BL-1: This is our own implementation to sim-
ulate the method by Abu-Jbara et al. (2012).
Here each user is represented by a (3 x (U +
A))-dimensional vector, where U is the num-
ber of users and A is the number of aspects,
i.e. (U + A) is the total number of opinion tar-
gets. For each opinion target, there are 3 di-
mensions in the feature vector, corresponding
to the number of positive, neutral and negative
opinion expressions towards the target from the
online posts.
• BL-2: BL-2 is similar to BL-1 except that we
only use a (U+A)-dimensional vector to repre-
</listItem>
<page confidence="0.997473">
407
</page>
<bodyText confidence="0.999873875">
sent each user. Here for each opinion target, we
directly use the corresponding sentiment polar-
ity score si,j or ri,j from the matrix 5 or R. For
empty entries in 5 and R, we use a score of 0.5.
We use Purity (the higher the better), Entropy (the
lower the better) and Rand Index (the higher the bet-
ter) to evaluate the performance of subgroup detec-
tion (Manning et al., 2008). We further use Accuracy
obtained by choosing the best alignment of clusters
with the ground truth class labels and computing the
percentage of users that are “classified” correctly.
Results: We first give an overview of the perfor-
mance of all the methods on the task. We show the
average performance of the methods on all the data
sets in Figure 5. Overall, our model has a better per-
formance than all the competing methods.
</bodyText>
<subsubsectionHeader confidence="0.632792">
Purity Entropy Accuracy RandIndex
</subsubsectionHeader>
<figureCaption confidence="0.9977095">
Figure 5: An overview of the average performance of all
the methods on the 6 threads.
</figureCaption>
<bodyText confidence="0.999255">
We present all the results in Table 3. We per-
form 2-tailed paired t-test on the results. We find
that PMF-UOM outperforms all the other methods
in terms of RandIndex at 5% significance level and
outperforms other methods in terms of Purity and
Entropy at 10% significance level. Furthermore,
the PMF-UOM model outperforms its degenerative
models PMF-UU and PMF-UA at 10% significance
level in terms of all the measures.
We observe that PMF-UOM achieves the best per-
formance in terms of all the measures for almost
all threads. In particular, comparison with BL-1
and BL-2 shows that collaborative filtering can gen-
eralize the user preferences and help better group
the users based on their viewpoints. The fact that
PMF-UOM outperforms both PMF-UU and PMF-
UA shows that it is important to consider both user-
user interactions and user-aspect interactions.
The Effects of Cluster Size: To test the effect of the
number of clusters on the experiment result, we vary
the number of clusters from 2 to 10 in all methods.
We find that all methods tend to achieve better re-
sults when the number of clusters equals the ground
truth cluster size. Overall, our method PMF-UOM
shows a better performance than the other four meth-
ods when the number of clusters changes, which in-
dicates the robustness of our method.
</bodyText>
<table confidence="0.99989535483871">
BL-1 BL-2 PMF-UU PMF-UA PMF-UOM
P 0.61 0.61 0.61 0.61 0.62
E 0.96 0.96 0.94 0.95 0.94
DS1 0.59 0.59 0.55 0.57 0.60
A 0.51 0.51 0.50 0.51 0.52
R
P 0.53 0.63 0.64 0.61 0.68
E 1.17 1.22 1.14 1.09 0.99
DS2 0.47 0.53 0.48 0.47 0.50
A 0.50 0.50 0.56 0.56 0.58
R
P 0.66 0.68 0.62 0.60 0.68
E 1.05 1.01 1.06 1.07 0.94
DS3 0.61 0.63 0.48 0.47 0.58
A 0.50 0.52 0.53 0.53 0.57
R
P 0.64 0.64 0.66 0.65 0.70
E 0.92 0.94 0.90 0.91 0.85
DS4 0.59 0.64 0.62 0.62 0.68
A 0.49 0.52 0.52 0.51 0.56
R
P 0.86 0.86 0.86 0.86 0.86
E 0.56 0.56 0.49 0.48 0.38
DS5 0.70 0.70 0.57 0.60 0.71
A 0.52 0.52 0.43 0.45 0.56
R
P 0.50 0.50 0.60 0.60 0.68
E 1.35 1.35 1.03 1.04 0.79
DS6 0.40 0.30 0.53 0.54 0.64
A 0.53 0.53 0.68 0.68 0.74
R
</table>
<tableCaption confidence="0.862483">
Table 3: Results on subgroup detection on all the 6
threads. P, E, A and R refer to Purity, Entropy, Accuracy
and RandIndex, respectively.
</tableCaption>
<sectionHeader confidence="0.998906" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999874">
In this paper, we studied how to use probabilistic
matrix factorization, a common technique for col-
laborative filtering, to improve relation mining from
online discussion forums. We first applied senti-
ment analysis to extract user-user opinions and user-
aspect opinions from forum posts. The extracted
opinions form two opinion matrices. We then ap-
plied probabilistic matrix factorization using these
</bodyText>
<figure confidence="0.998658333333333">
0.8
0.6
0.4
1.0
BL-1
BL-2
PMF-UU
PMF-UA
PMF-UOM
</figure>
<page confidence="0.995914">
408
</page>
<bodyText confidence="0.999967826086957">
two matrices to discover a low-rank latent factor
space which aims to better generalize the users’ un-
derlying preferences and indicate user similarities
based on their viewpoints. Using a data set with 6
discussion threads, we showed that the learned la-
tent vectors can be used to predict the polarity of
user relations well without using the users’ direct
interaction data, demonstrating the effectiveness of
collaborative filtering. We further found that for the
task of subgroup detection, the latent vectors gave
better performance than using the directly extracted
opinion data, again showing that collaborative fil-
tering through probabilistic matrix factorization can
help address the sparseness problem in the extracted
opinion matrices and help improve relation mining.
Our current work mainly focuses on the user opin-
ion matrices. As future work, we would like to ex-
plore how to incorporate textual contents without
opinionated expressions. One possible way is to
consider the combination of matrix factorization and
topic modeling as studied by Wang and Blei (2011)
where we can use topic modeling to study textual
contents.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999345">
We thank the reviewers for their valuable comments
on this work.
</bodyText>
<sectionHeader confidence="0.998587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999396805555556">
Amjad Abu-Jbara, Pradeep Dasigi, Mona Diab, and
Dragomir R. Radev. 2012. Subgroup detection in
ideological discussions. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics, pages 399–409.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining. In
LREC.
Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recog-
nition. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’06, pages 431–439, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Pradeep Dasigi, Weiwei Guo, and Mona T. Diab. 2012.
Genre independent subgroup detection in online dis-
cussion threads: A study of implicit attitude using
textual latent semantics. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics, pages 65–69.
Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing text polarity using random walks. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics, ACL ’10, pages 395–403,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev.
2012. Detecting subgroups in online discussions by
modeling positive and negative relations among par-
ticipants. In Proceedings of the 2012 EMNLP, pages
59–70.
John Hopcroft, Tiancheng Lou, and Jie Tang. 2011. Who
will follow you back?: reciprocal relationship predic-
tion. In Proceedings of the 20th ACM international
conference on Information and knowledge manage-
ment, pages 1137–1146.
Minqing Hu and Bing Liu. 2004. Mining and summariz-
ing customer reviews. In Proceedings of the 10th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 168–177.
Noriaki Kawamae. 2011. Predicting future reviews: sen-
timent analysis models for collaborative filtering. In
Proceedings of the fourth ACM international confer-
ence on Web search and data mining, WSDM ’11,
pages 605–614.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of the 41st An-
nual Meeting on Association for Computational Lin-
guistics - Volume 1, ACL ’03, pages 423–430, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg.
2010. Predicting positive and negative links in online
social networks. In Proceedings of the 19th interna-
tional conference on World wide web, pages 641–650.
Cane Wing-Ki Leung, Stephen Chi-Fai Chan, Fu-Lai
Chung, and Grace Ngai. 2011. A probabilistic rat-
ing inference framework for mining user preferences
from reviews. World Wide Web, 14(2):187–215.
David Liben-Nowell and Jon Kleinberg. 2003. The link
prediction problem for social networks. In Proceed-
ings of the twelfth international conference on Infor-
mation and knowledge management.
Hao Ma, Haixuan Yang, Michael R. Lyu, and Irwin King.
2008. Sorec: Social recommendation using proba-
bilistic matrix factorization. In Proc. of ACM interna-
tional conference on Information and knowledge man-
agement.
Christopher D. Manning, Prabhakar Raghavan, and Hin-
rich Schtze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, July.
</reference>
<page confidence="0.988878">
409
</page>
<reference confidence="0.999897862745098">
George A. Miller. 1995. Wordnet: A lexical database
for english. Communications of the ACM, Vol. 38, No.
11:39–41.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP: Volume 2 - Volume 2, ACL
’09, pages 1003–1011, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Yashar Moshfeghi, Benjamin Piwowarski, and Joe-
mon M. Jose. 2011. Handling data sparsity in collabo-
rative filtering using emotion and semantic based fea-
tures. In Proceedings of the 34th international ACM
SIGIR conference on Research and development in In-
formation Retrieval, SIGIR ’11, pages 625–634.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–
135, January.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing, HLT ’05, pages 339–346, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009.
Expanding domain sentiment lexicon through double
propagation. In Proceedings of the 21st international
jont conference on Artifical intelligence, IJCAI’09,
pages 1199–1204, San Francisco, CA, USA. Morgan
Kaufmann Publishers Inc.
Ruslan Salakhutdinov and Andriy Mnih. 2008. Prob-
abilistic matrix factorization. In Advances in Neural
Information Processing Systems, volume 20.
Chong Wang and David M. Blei. 2011. Collaborative
topic modeling for recommending scientific articles.
In Proceedings of the 17th ACM SIGKDD interna-
tional conference on Knowledge discovery and data
mining, pages 448–456.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-level
sentiment analysis. In HLT/EMNLP.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion mining.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume 3
- Volume 3, EMNLP ’09, pages 1533–1541, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.997019">
410
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.811811">
<title confidence="0.968505">Mining User Relations from Online Discussions using Sentiment and Probabilistic Matrix Factorization</title>
<author confidence="0.860454">Liu Jing of Information Systems</author>
<author confidence="0.860454">Singapore Management University</author>
<affiliation confidence="0.999703">of Software and Microelectronics, Peking University,</affiliation>
<email confidence="0.970964">yang.liu@pku.edu.cn</email>
<abstract confidence="0.998637625">Advances in sentiment analysis have enabled extraction of user relations implied in online textual exchanges such as forum posts. However, recent studies in this direction only consider direct relation extraction from text. As user interactions can be sparse in online discussions, we propose to apply collaborative filtering through probabilistic matrix factorization to generalize and improve the opinion matrices extracted from forum posts. Experiments with two tasks show that the learned latent factor representation can give good performance on a relation polarity prediction task and improve the performance of a subgroup detection task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Pradeep Dasigi</author>
<author>Mona Diab</author>
<author>Dragomir R Radev</author>
</authors>
<title>Subgroup detection in ideological discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>399--409</pages>
<contexts>
<context position="4889" citStr="Abu-Jbara et al. (2012)" startWordPosition="751" endWordPosition="754">ons with other users or comments on topic aspects. The second is to use the latent vectors to group users based on viewpoints. We find that the latent factor representation can produce good prediction results for the first task and improve the clustering results of the second task compared with a number of baselines, showing the effectiveness of collaborative filtering for mining social relations from online discussions. 2 Related Work Our work is closely related to recent studies on detecting subgroups from online discussions (AbuJbara et al., 2012; Dasigi et al., 2012; Hassan et al., 2012). Abu-Jbara et al. (2012) proposed to build discussant attitude profiles (DAP) from online posts and use these profiles to cluster users into subgroups. A DAP is a vector that contains the attitudes of a discussant towards other discussants and a set of opinion targets. We also extract opinions of users towards other users and opinion targets from posts, which are similar to DAPs. The difference is that we further apply probabilistic matrix factorization to derive a low-rank representation from the raw opinion scores. Our comparison with DAP-based clustering shows that probabilistic matrix factorization can improve su</context>
<context position="19414" citStr="Abu-Jbara et al. (2012)" startWordPosition="3250" endWordPosition="3253">ified such that we drop the sum G(U, A, S, R) II(ri,k)(ri,k − g(uTiak))2 II(si,j)(si,j − g(uTi uj))2 = + 1 2 U i=1 A E k=1 λ1 2 U i=1 U E j=1 405 of the square errors involving R and the regularizer on A. PMF-UA: In this degenerate version of the model, we use only the user-aspect opinion matrix to learn the latent factor representation. Specifically, the objective function is modified such that we drop the sum of the square errors involving S. 6 Experiments In this section, we present our experiments that evaluate our model. 6.1 Data Set and Experiment Settings The data set we use comes from Abu-Jbara et al. (2012) and Hassan et al. (2012). The data set contains a set of discussion threads collected from two political forums (Createdebate3 and Politicalforum4) and one Wikipedia discussion session. We randomly select 6 threads from the original data set to evaluate our model. Some details of the data we use are listed in Table 2. ID topic #sides #sentences #users DS1 Vote for Obama 2 12492 197 DS2 Abortion Banned 6 3844 70 DS3 Profile Muslims 4 2167 69 DS4 England and USA 6 2030 62 DS5 Tax Cuts 2 1193 26 DS6 Political Spectrum 7 1130 50 Table 2: Some statistics of the data sets. In our experiments, for t</context>
<context position="25456" citStr="Abu-Jbara et al. (2012)" startWordPosition="4325" endWordPosition="4328">representation U for users, we can better detect subgroups than directly using the opinion matrices 5 and R. For all the methods we compare, we first construct a feature vector representation for each user. We then apply K-means clustering to group users. The number of clusters is set to be the true number of viewpoints for each thread. The different methods are described below: • PMF-based methods: We simply use the learned latent vectors fii after optimizing the objective function as the feature vectors to represent each user. • BL-1: This is our own implementation to simulate the method by Abu-Jbara et al. (2012). Here each user is represented by a (3 x (U + A))-dimensional vector, where U is the number of users and A is the number of aspects, i.e. (U + A) is the total number of opinion targets. For each opinion target, there are 3 dimensions in the feature vector, corresponding to the number of positive, neutral and negative opinion expressions towards the target from the online posts. • BL-2: BL-2 is similar to BL-1 except that we only use a (U+A)-dimensional vector to repre407 sent each user. Here for each opinion target, we directly use the corresponding sentiment polarity score si,j or ri,j from </context>
</contexts>
<marker>Abu-Jbara, Dasigi, Diab, Radev, 2012</marker>
<rawString>Amjad Abu-Jbara, Pradeep Dasigi, Mona Diab, and Dragomir R. Radev. 2012. Subgroup detection in ideological discussions. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 399–409.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="11878" citStr="Baccianella et al. (2010)" startWordPosition="1920" endWordPosition="1923">ese aspects, some additional information such as Wikipedia entries and Google snippets may be considered. We will study this problem in our future work. 4.2 Opinion Expression Identification Our next step is to identify candidate opinion expressions. This problem has been studied in Hu and Liu (2004), Popescu and Etzioni (2005), and Hassan and Radev (2010). Based on previous work, we do the following. We first combine three popular sentiment lexicons to form a single sentiment lexicon: the lexicon used in Hu and Liu (2004), MPQA Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Our final sentiment lexicon contains 15,322 negative expressions and 10,144 positive expressions. We then identify candidate opinion expressions by searching for occurrences of words in this lexicon in the posts. 4.3 Opinion Relation Extraction Given a post that contains an aspect and an opinion expression, we still need to determine whether the opinion expression is used to describe the aspect. This is a relation extraction problem. We use a supervised learning approach based on dependency 1http://opennlp.apache.org/ 2http://nlp.stanford.edu/ner/index.shtml 403 100 80 60 40 20 0 Figure 1: S</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Eric Breck</author>
<author>Claire Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06,</booktitle>
<pages>431--439</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6795" citStr="Choi et al. (2006)" startWordPosition="1058" endWordPosition="1061">social network information with rating data using the PMF framework to perform social recommendation. Our model bears similarity to SocRec in that we also consider two types of interactions, i.e. user-user interactions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to </context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 431–439, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Weiwei Guo</author>
<author>Mona T Diab</author>
</authors>
<title>Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>65--69</pages>
<contexts>
<context position="4842" citStr="Dasigi et al., 2012" startWordPosition="743" endWordPosition="746"> textual exchanges but from their interactions with other users or comments on topic aspects. The second is to use the latent vectors to group users based on viewpoints. We find that the latent factor representation can produce good prediction results for the first task and improve the clustering results of the second task compared with a number of baselines, showing the effectiveness of collaborative filtering for mining social relations from online discussions. 2 Related Work Our work is closely related to recent studies on detecting subgroups from online discussions (AbuJbara et al., 2012; Dasigi et al., 2012; Hassan et al., 2012). Abu-Jbara et al. (2012) proposed to build discussant attitude profiles (DAP) from online posts and use these profiles to cluster users into subgroups. A DAP is a vector that contains the attitudes of a discussant towards other discussants and a set of opinion targets. We also extract opinions of users towards other users and opinion targets from posts, which are similar to DAPs. The difference is that we further apply probabilistic matrix factorization to derive a low-rank representation from the raw opinion scores. Our comparison with DAP-based clustering shows that pr</context>
</contexts>
<marker>Dasigi, Guo, Diab, 2012</marker>
<rawString>Pradeep Dasigi, Weiwei Guo, and Mona T. Diab. 2012. Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 65–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying text polarity using random walks.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>395--403</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11611" citStr="Hassan and Radev (2010)" startWordPosition="1873" endWordPosition="1876">pressions from at least M users. We set M to 2 in our experiments. Figure 1 shows the top salient aspects for the thread on “Will you vote for Obama?” We acknowledge there are still duplicate aspects in the results like “Republican Party” and “GOP”. To normalize these aspects, some additional information such as Wikipedia entries and Google snippets may be considered. We will study this problem in our future work. 4.2 Opinion Expression Identification Our next step is to identify candidate opinion expressions. This problem has been studied in Hu and Liu (2004), Popescu and Etzioni (2005), and Hassan and Radev (2010). Based on previous work, we do the following. We first combine three popular sentiment lexicons to form a single sentiment lexicon: the lexicon used in Hu and Liu (2004), MPQA Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Our final sentiment lexicon contains 15,322 negative expressions and 10,144 positive expressions. We then identify candidate opinion expressions by searching for occurrences of words in this lexicon in the posts. 4.3 Opinion Relation Extraction Given a post that contains an aspect and an opinion expression, we still need to deter</context>
</contexts>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir Radev. 2010. Identifying text polarity using random walks. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 395–403, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Amjad Abu-Jbara</author>
<author>Dragomir Radev</author>
</authors>
<title>Detecting subgroups in online discussions by modeling positive and negative relations among participants.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 EMNLP,</booktitle>
<pages>59--70</pages>
<contexts>
<context position="1892" citStr="Hassan et al. (2012)" startWordPosition="268" endWordPosition="271">inberg, 2003), directed following relations (Hopcroft et al., 2011) and trust/distrust relations (Leskovec et al., 2010). However, besides these explicit social relations, the various kinds of interactions between online users often suggest other implicit relations. In particular, in online discussion forums, users interact through textual posts and these exchanged texts often reveal whether two users are friends or foes, or whether two users share the same viewpoint towards a given issue. To uncover such implicit relations requires text analysis and particularly sentiment analysis. Recently, Hassan et al. (2012) studied predicting the polarity of user interactions in online discussions based on textual exchanges. They found that the automatically predicted signed relations had an accuracy above 80%. The extracted signed network was further used to detect ideological subgroups. This is a piece of pioneering work that extracts online social relations based on text analysis. In this paper, we further extend the idea of mining social relations from online forum posts by incorporating collaborative filtering. Our work is motivated by the observation that direct textual exchanges between users are sparse. </context>
<context position="4864" citStr="Hassan et al., 2012" startWordPosition="747" endWordPosition="750">t from their interactions with other users or comments on topic aspects. The second is to use the latent vectors to group users based on viewpoints. We find that the latent factor representation can produce good prediction results for the first task and improve the clustering results of the second task compared with a number of baselines, showing the effectiveness of collaborative filtering for mining social relations from online discussions. 2 Related Work Our work is closely related to recent studies on detecting subgroups from online discussions (AbuJbara et al., 2012; Dasigi et al., 2012; Hassan et al., 2012). Abu-Jbara et al. (2012) proposed to build discussant attitude profiles (DAP) from online posts and use these profiles to cluster users into subgroups. A DAP is a vector that contains the attitudes of a discussant towards other discussants and a set of opinion targets. We also extract opinions of users towards other users and opinion targets from posts, which are similar to DAPs. The difference is that we further apply probabilistic matrix factorization to derive a low-rank representation from the raw opinion scores. Our comparison with DAP-based clustering shows that probabilistic matrix fac</context>
<context position="19439" citStr="Hassan et al. (2012)" startWordPosition="3255" endWordPosition="3258">sum G(U, A, S, R) II(ri,k)(ri,k − g(uTiak))2 II(si,j)(si,j − g(uTi uj))2 = + 1 2 U i=1 A E k=1 λ1 2 U i=1 U E j=1 405 of the square errors involving R and the regularizer on A. PMF-UA: In this degenerate version of the model, we use only the user-aspect opinion matrix to learn the latent factor representation. Specifically, the objective function is modified such that we drop the sum of the square errors involving S. 6 Experiments In this section, we present our experiments that evaluate our model. 6.1 Data Set and Experiment Settings The data set we use comes from Abu-Jbara et al. (2012) and Hassan et al. (2012). The data set contains a set of discussion threads collected from two political forums (Createdebate3 and Politicalforum4) and one Wikipedia discussion session. We randomly select 6 threads from the original data set to evaluate our model. Some details of the data we use are listed in Table 2. ID topic #sides #sentences #users DS1 Vote for Obama 2 12492 197 DS2 Abortion Banned 6 3844 70 DS3 Profile Muslims 4 2167 69 DS4 England and USA 6 2030 62 DS5 Tax Cuts 2 1193 26 DS6 Political Spectrum 7 1130 50 Table 2: Some statistics of the data sets. In our experiments, for the PMF-based methods, we </context>
</contexts>
<marker>Hassan, Abu-Jbara, Radev, 2012</marker>
<rawString>Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev. 2012. Detecting subgroups in online discussions by modeling positive and negative relations among participants. In Proceedings of the 2012 EMNLP, pages 59–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hopcroft</author>
<author>Tiancheng Lou</author>
<author>Jie Tang</author>
</authors>
<title>Who will follow you back?: reciprocal relationship prediction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>1137--1146</pages>
<contexts>
<context position="1339" citStr="Hopcroft et al., 2011" startWordPosition="185" endWordPosition="188">actorization to generalize and improve the opinion matrices extracted from forum posts. Experiments with two tasks show that the learned latent factor representation can give good performance on a relation polarity prediction task and improve the performance of a subgroup detection task. 1 Introduction The fast growth of the social Web has led to a large amount of interest in online social network analysis. Most existing work on social network analysis relies on explicit links among users such as undirected friendship relations (Liben-Nowell and Kleinberg, 2003), directed following relations (Hopcroft et al., 2011) and trust/distrust relations (Leskovec et al., 2010). However, besides these explicit social relations, the various kinds of interactions between online users often suggest other implicit relations. In particular, in online discussion forums, users interact through textual posts and these exchanged texts often reveal whether two users are friends or foes, or whether two users share the same viewpoint towards a given issue. To uncover such implicit relations requires text analysis and particularly sentiment analysis. Recently, Hassan et al. (2012) studied predicting the polarity of user intera</context>
</contexts>
<marker>Hopcroft, Lou, Tang, 2011</marker>
<rawString>John Hopcroft, Tiancheng Lou, and Jie Tang. 2011. Who will follow you back?: reciprocal relationship prediction. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1137–1146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="11554" citStr="Hu and Liu (2004)" startWordPosition="1864" endWordPosition="1867">elect those candidate aspects which have opinion expressions from at least M users. We set M to 2 in our experiments. Figure 1 shows the top salient aspects for the thread on “Will you vote for Obama?” We acknowledge there are still duplicate aspects in the results like “Republican Party” and “GOP”. To normalize these aspects, some additional information such as Wikipedia entries and Google snippets may be considered. We will study this problem in our future work. 4.2 Opinion Expression Identification Our next step is to identify candidate opinion expressions. This problem has been studied in Hu and Liu (2004), Popescu and Etzioni (2005), and Hassan and Radev (2010). Based on previous work, we do the following. We first combine three popular sentiment lexicons to form a single sentiment lexicon: the lexicon used in Hu and Liu (2004), MPQA Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Our final sentiment lexicon contains 15,322 negative expressions and 10,144 positive expressions. We then identify candidate opinion expressions by searching for occurrences of words in this lexicon in the posts. 4.3 Opinion Relation Extraction Given a post that contains an</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noriaki Kawamae</author>
</authors>
<title>Predicting future reviews: sentiment analysis models for collaborative filtering.</title>
<date>2011</date>
<booktitle>In Proceedings of the fourth ACM international conference on Web search and data mining, WSDM ’11,</booktitle>
<pages>605--614</pages>
<contexts>
<context position="7125" citStr="Kawamae (2011)" startWordPosition="1113" endWordPosition="1114"> scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to improve user relation mining from online text. 3 Method Overview In this section, we provide an overview of our method. We first introduce some concepts. User: We use user to refer to a discussant in an online discussion. Each user has an online ID, which can be used by other users to refer to him/her in a post. Users are both o</context>
</contexts>
<marker>Kawamae, 2011</marker>
<rawString>Noriaki Kawamae. 2011. Predicting future reviews: sentiment analysis models for collaborative filtering. In Proceedings of the fourth ACM international conference on Web search and data mining, WSDM ’11, pages 605–614.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13669" citStr="Klein and Manning (2003)" startWordPosition="2237" endWordPosition="2240">nsubj → NTR OBAMA was a top scorer for occidental college. R8 ADVOP +— advmod +— V → nsubj → NTR OBAMA is smarter than people. Table 1: Examples of frequent dependency path rules in our training data. OP and TR refer to the opinion and the target. The opinion words are in italic and the aspect words are in uppercase. paths. Previous work by Mintz et al. (2009), and Qiu et al. (2009) has shown that the shortest path between a candidate opinion aspect and a candidate opinion expression in the dependency parse tree can be effective in extracting opinion relations. We use the Stanford Parser from Klein and Manning (2003) to obtain the dependency parse trees for each sentence in the posts and then get the dependency paths between each pair of candidate aspect and opinion expression. We use dependency relations and POS tags of nodes along the path to represent a dependency path. Given a set of training sentences (we use the one from Wu et al. (2009)), we can get a set of dependency path rules based on their frequencies in the training data. Table 1 shows the frequent dependency path rules in our training data. When a pair of aspect and opinion expression is identified to be related, we use the polarity of the o</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423–430, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jure Leskovec</author>
<author>Daniel Huttenlocher</author>
<author>Jon Kleinberg</author>
</authors>
<title>Predicting positive and negative links in online social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web,</booktitle>
<pages>641--650</pages>
<contexts>
<context position="1392" citStr="Leskovec et al., 2010" startWordPosition="192" endWordPosition="195">trices extracted from forum posts. Experiments with two tasks show that the learned latent factor representation can give good performance on a relation polarity prediction task and improve the performance of a subgroup detection task. 1 Introduction The fast growth of the social Web has led to a large amount of interest in online social network analysis. Most existing work on social network analysis relies on explicit links among users such as undirected friendship relations (Liben-Nowell and Kleinberg, 2003), directed following relations (Hopcroft et al., 2011) and trust/distrust relations (Leskovec et al., 2010). However, besides these explicit social relations, the various kinds of interactions between online users often suggest other implicit relations. In particular, in online discussion forums, users interact through textual posts and these exchanged texts often reveal whether two users are friends or foes, or whether two users share the same viewpoint towards a given issue. To uncover such implicit relations requires text analysis and particularly sentiment analysis. Recently, Hassan et al. (2012) studied predicting the polarity of user interactions in online discussions based on textual exchang</context>
</contexts>
<marker>Leskovec, Huttenlocher, Kleinberg, 2010</marker>
<rawString>Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. 2010. Predicting positive and negative links in online social networks. In Proceedings of the 19th international conference on World wide web, pages 641–650.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cane Wing-Ki Leung</author>
<author>Stephen Chi-Fai Chan</author>
<author>Fu-Lai Chung</author>
<author>Grace Ngai</author>
</authors>
<title>A probabilistic rating inference framework for mining user preferences from reviews. World Wide Web,</title>
<date>2011</date>
<contexts>
<context position="7174" citStr="Leung et al. (2011)" startWordPosition="1120" endWordPosition="1123">nalysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to improve user relation mining from online text. 3 Method Overview In this section, we provide an overview of our method. We first introduce some concepts. User: We use user to refer to a discussant in an online discussion. Each user has an online ID, which can be used by other users to refer to him/her in a post. Users are both opinion holders and opinion targets. For example, </context>
</contexts>
<marker>Leung, Chan, Chung, Ngai, 2011</marker>
<rawString>Cane Wing-Ki Leung, Stephen Chi-Fai Chan, Fu-Lai Chung, and Grace Ngai. 2011. A probabilistic rating inference framework for mining user preferences from reviews. World Wide Web, 14(2):187–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Liben-Nowell</author>
<author>Jon Kleinberg</author>
</authors>
<title>The link prediction problem for social networks.</title>
<date>2003</date>
<booktitle>In Proceedings of the twelfth international conference on Information and knowledge management.</booktitle>
<contexts>
<context position="1285" citStr="Liben-Nowell and Kleinberg, 2003" startWordPosition="178" endWordPosition="181">e to apply collaborative filtering through probabilistic matrix factorization to generalize and improve the opinion matrices extracted from forum posts. Experiments with two tasks show that the learned latent factor representation can give good performance on a relation polarity prediction task and improve the performance of a subgroup detection task. 1 Introduction The fast growth of the social Web has led to a large amount of interest in online social network analysis. Most existing work on social network analysis relies on explicit links among users such as undirected friendship relations (Liben-Nowell and Kleinberg, 2003), directed following relations (Hopcroft et al., 2011) and trust/distrust relations (Leskovec et al., 2010). However, besides these explicit social relations, the various kinds of interactions between online users often suggest other implicit relations. In particular, in online discussion forums, users interact through textual posts and these exchanged texts often reveal whether two users are friends or foes, or whether two users share the same viewpoint towards a given issue. To uncover such implicit relations requires text analysis and particularly sentiment analysis. Recently, Hassan et al.</context>
</contexts>
<marker>Liben-Nowell, Kleinberg, 2003</marker>
<rawString>David Liben-Nowell and Jon Kleinberg. 2003. The link prediction problem for social networks. In Proceedings of the twelfth international conference on Information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Ma</author>
<author>Haixuan Yang</author>
<author>Michael R Lyu</author>
<author>Irwin King</author>
</authors>
<title>Sorec: Social recommendation using probabilistic matrix factorization.</title>
<date>2008</date>
<booktitle>In Proc. of ACM international conference on Information and knowledge management.</booktitle>
<contexts>
<context position="6080" citStr="Ma et al. (2008)" startWordPosition="940" endWordPosition="943">torization can improve subgroup detection. Hassan et al. (2012) proposed to predict the polarity of interactions between users based on their textual exchanges. They defined a set of interaction features using sentiment analysis and applied supervised learning for polarity prediction. In comparison, our work is unsupervised, that is, we do not use any ground truth of interaction polarity for training. Probabilistic matrix factorization was proposed by Salakhutdinov and Mnih (2008) as a collaborative filtering method for recommender systems. It has attracted much attention and been extended by Ma et al. (2008) and Wang and Blei (2011). In particular, Ma et al. (2008) proposed a SocRec model that combines social network information with rating data using the PMF framework to perform social recommendation. Our model bears similarity to SocRec in that we also consider two types of interactions, i.e. user-user interactions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opini</context>
<context position="15989" citStr="Ma et al. (2008)" startWordPosition="2628" endWordPosition="2631"> that around 87% of entries in the user-user opinion matrix and around 90% of entries in the user-aspect opinion matrix are empty. In this section, we describe how we use Probabilistic Matrix Factorization (PMF) to represent users and aspects in a latent factor space and thus generalize the user preferences. Our model is almost a direct application of proba404 bilistic matrix factorization from Salakhutdinov and Mnih (2008), originally proposed for recommender systems. The main difference is that the user-user opinion polarity scores are symmetric. Our model is also similar to the one used by Ma et al. (2008). We describe our model as follows. We assume that there are K latent factors with which both users and aspects can be represented. Let ui E IR,K denote the vector in the latent factor space for the i-th user, and ak the vector for the k-th aspect. Recall that the opinions extracted from posts between users are represented by a user-user opinion matrix S, and the opinions held by different users on the various topic aspects are represented by a useraspect opinion matrix R. We assume that the polarity scores si,j between the i-th and the j-th users and ri,k between the i-th user and the k-th as</context>
<context position="18333" citStr="Ma et al. (2008)" startWordPosition="3061" endWordPosition="3064"> a K xU matrix containing the vectors ui for all U users, and A be an KxA matrix containing Figure 2: Probabilistic matrix factorization model on opinion matrices. the vectors ak for all A aspects. To automatically learn U and A, we minimize the following objective function: λU F + λA + 2 ||U||2 2 ||A||2 F, (1) where λ = σ2 1 U , and λA = σ2 1 2 , λU = σ2 1 A , I(s) is σ2 σ2 σ2 an indicator function which equals 1 when s is not empty and otherwise 0. To optimize the objective function above, we can perform gradient descent on U and A to find a local optimum point. The derivation is similar to Ma et al. (2008). Degenerate Versions of the Model We refer to the complete model described above as PMF-UOM (PMF model based on User Opinion Matrices). PMF-UOM has the following two degenerate versions by considering either only the useruser opinion matrix or only the user-aspect opinion matrix. PMF-UU: In this degenerate version of the model, we use only the user-user opinion matrix to learn the latent factor representation. Specifically, the objective function is modified such that we drop the sum G(U, A, S, R) II(ri,k)(ri,k − g(uTiak))2 II(si,j)(si,j − g(uTi uj))2 = + 1 2 U i=1 A E k=1 λ1 2 U i=1 U E j=1 </context>
</contexts>
<marker>Ma, Yang, Lyu, King, 2008</marker>
<rawString>Hao Ma, Haixuan Yang, Michael R. Lyu, and Irwin King. 2008. Sorec: Social recommendation using probabilistic matrix factorization. In Proc. of ACM international conference on Information and knowledge management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schtze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="26309" citStr="Manning et al., 2008" startWordPosition="4485" endWordPosition="4488">ns in the feature vector, corresponding to the number of positive, neutral and negative opinion expressions towards the target from the online posts. • BL-2: BL-2 is similar to BL-1 except that we only use a (U+A)-dimensional vector to repre407 sent each user. Here for each opinion target, we directly use the corresponding sentiment polarity score si,j or ri,j from the matrix 5 or R. For empty entries in 5 and R, we use a score of 0.5. We use Purity (the higher the better), Entropy (the lower the better) and Rand Index (the higher the better) to evaluate the performance of subgroup detection (Manning et al., 2008). We further use Accuracy obtained by choosing the best alignment of clusters with the ground truth class labels and computing the percentage of users that are “classified” correctly. Results: We first give an overview of the performance of all the methods on the task. We show the average performance of the methods on all the data sets in Figure 5. Overall, our model has a better performance than all the competing methods. Purity Entropy Accuracy RandIndex Figure 5: An overview of the average performance of all the methods on the 6 threads. We present all the results in Table 3. We perform 2-t</context>
</contexts>
<marker>Manning, Raghavan, Schtze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schtze. 2008. Introduction to Information Retrieval. Cambridge University Press, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<contexts>
<context position="10644" citStr="Miller (1995)" startWordPosition="1706" endWordPosition="1707">n be identified in posts by their IDs or second person pronouns. For aspects, however, there is not a pre-defined set. We observe that these topic aspects are usually named entities or noun phrases frequently mentioned. We therefore use the OpenNLP toolkit1 to perform chunking and obtain noun phrases and the Standford NER tagger2 to identify named entities from the posts. Some of the candidate aspect phrases identified above actually refer to the same actual aspect, e.g. “Obama voter,” “Obama voters” and “the Obama voter.” We remove stop words from each candidate phrase and use the WordNet by Miller (1995) to obtain the lemma of each word such that we can normalize the candidate aspect phases to some extent. Finally, to select salient aspects for a given discussion topic, we count the number of times each candidate aspect has been expressed a positive or negative opinion on by all users, and select those candidate aspects which have opinion expressions from at least M users. We set M to 2 in our experiments. Figure 1 shows the top salient aspects for the thread on “Will you vote for Obama?” We acknowledge there are still duplicate aspects in the results like “Republican Party” and “GOP”. To nor</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. Communications of the ACM, Vol. 38, No. 11:39–41.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09,</booktitle>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13407" citStr="Mintz et al. (2009)" startWordPosition="2193" endWordPosition="2196"> I would never support OBAMA. R4 VOP → prep * → NTR I’ll vote for OBAMA. R5 VOP → nsubjpass → NTR DEMOCRATIC PARTY are ultimately corrupted by love of money. R6 NOP +— dobj +— V → nsubj → NTR PAKISTAN is increasing terrorist threat. R7 ADJOP +— amod +— N → nsubj → NTR OBAMA was a top scorer for occidental college. R8 ADVOP +— advmod +— V → nsubj → NTR OBAMA is smarter than people. Table 1: Examples of frequent dependency path rules in our training data. OP and TR refer to the opinion and the target. The opinion words are in italic and the aspect words are in uppercase. paths. Previous work by Mintz et al. (2009), and Qiu et al. (2009) has shown that the shortest path between a candidate opinion aspect and a candidate opinion expression in the dependency parse tree can be effective in extracting opinion relations. We use the Stanford Parser from Klein and Manning (2003) to obtain the dependency parse trees for each sentence in the posts and then get the dependency paths between each pair of candidate aspect and opinion expression. We use dependency relations and POS tags of nodes along the path to represent a dependency path. Given a set of training sentences (we use the one from Wu et al. (2009)), we</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09, pages 1003–1011, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Moshfeghi</author>
<author>Benjamin Piwowarski</author>
<author>Joemon M Jose</author>
</authors>
<title>Handling data sparsity in collaborative filtering using emotion and semantic based features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, SIGIR ’11,</booktitle>
<pages>625--634</pages>
<contexts>
<context position="7150" citStr="Moshfeghi et al. (2011)" startWordPosition="1115" endWordPosition="1118">tual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to improve user relation mining from online text. 3 Method Overview In this section, we provide an overview of our method. We first introduce some concepts. User: We use user to refer to a discussant in an online discussion. Each user has an online ID, which can be used by other users to refer to him/her in a post. Users are both opinion holders and opinio</context>
</contexts>
<marker>Moshfeghi, Piwowarski, Jose, 2011</marker>
<rawString>Yashar Moshfeghi, Benjamin Piwowarski, and Joemon M. Jose. 2011. Handling data sparsity in collaborative filtering using emotion and semantic based features. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, SIGIR ’11, pages 625–634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="7003" citStr="Pang and Lee (2008)" startWordPosition="1095" endWordPosition="1098">nteractions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to improve user relation mining from online text. 3 Method Overview In this section, we provide an overview of our method. We first introduce some concepts. User: We use user to refer to a discussant in an onlin</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1– 135, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>339--346</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11582" citStr="Popescu and Etzioni (2005)" startWordPosition="1868" endWordPosition="1871">te aspects which have opinion expressions from at least M users. We set M to 2 in our experiments. Figure 1 shows the top salient aspects for the thread on “Will you vote for Obama?” We acknowledge there are still duplicate aspects in the results like “Republican Party” and “GOP”. To normalize these aspects, some additional information such as Wikipedia entries and Google snippets may be considered. We will study this problem in our future work. 4.2 Opinion Expression Identification Our next step is to identify candidate opinion expressions. This problem has been studied in Hu and Liu (2004), Popescu and Etzioni (2005), and Hassan and Radev (2010). Based on previous work, we do the following. We first combine three popular sentiment lexicons to form a single sentiment lexicon: the lexicon used in Hu and Liu (2004), MPQA Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Our final sentiment lexicon contains 15,322 negative expressions and 10,144 positive expressions. We then identify candidate opinion expressions by searching for occurrences of words in this lexicon in the posts. 4.3 Opinion Relation Extraction Given a post that contains an aspect and an opinion expre</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 339–346, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09,</booktitle>
<pages>1199--1204</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="13430" citStr="Qiu et al. (2009)" startWordPosition="2198" endWordPosition="2201">AMA. R4 VOP → prep * → NTR I’ll vote for OBAMA. R5 VOP → nsubjpass → NTR DEMOCRATIC PARTY are ultimately corrupted by love of money. R6 NOP +— dobj +— V → nsubj → NTR PAKISTAN is increasing terrorist threat. R7 ADJOP +— amod +— N → nsubj → NTR OBAMA was a top scorer for occidental college. R8 ADVOP +— advmod +— V → nsubj → NTR OBAMA is smarter than people. Table 1: Examples of frequent dependency path rules in our training data. OP and TR refer to the opinion and the target. The opinion words are in italic and the aspect words are in uppercase. paths. Previous work by Mintz et al. (2009), and Qiu et al. (2009) has shown that the shortest path between a candidate opinion aspect and a candidate opinion expression in the dependency parse tree can be effective in extracting opinion relations. We use the Stanford Parser from Klein and Manning (2003) to obtain the dependency parse trees for each sentence in the posts and then get the dependency paths between each pair of candidate aspect and opinion expression. We use dependency relations and POS tags of nodes along the path to represent a dependency path. Given a set of training sentences (we use the one from Wu et al. (2009)), we can get a set of depen</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09, pages 1199–1204, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Salakhutdinov</author>
<author>Andriy Mnih</author>
</authors>
<title>Probabilistic matrix factorization.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>20</volume>
<contexts>
<context position="5949" citStr="Salakhutdinov and Mnih (2008)" startWordPosition="918" endWordPosition="921">on to derive a low-rank representation from the raw opinion scores. Our comparison with DAP-based clustering shows that probabilistic matrix factorization can improve subgroup detection. Hassan et al. (2012) proposed to predict the polarity of interactions between users based on their textual exchanges. They defined a set of interaction features using sentiment analysis and applied supervised learning for polarity prediction. In comparison, our work is unsupervised, that is, we do not use any ground truth of interaction polarity for training. Probabilistic matrix factorization was proposed by Salakhutdinov and Mnih (2008) as a collaborative filtering method for recommender systems. It has attracted much attention and been extended by Ma et al. (2008) and Wang and Blei (2011). In particular, Ma et al. (2008) proposed a SocRec model that combines social network information with rating data using the PMF framework to perform social recommendation. Our model bears similarity to SocRec in that we also consider two types of interactions, i.e. user-user interactions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using senti</context>
<context position="15800" citStr="Salakhutdinov and Mnih (2008)" startWordPosition="2597" endWordPosition="2600">ctorization As we have pointed out earlier, a problem with the matrices extracted as described in Section 4 is that the matrices are sparse, i.e. many entries are empty. For the data set we use, we find that around 87% of entries in the user-user opinion matrix and around 90% of entries in the user-aspect opinion matrix are empty. In this section, we describe how we use Probabilistic Matrix Factorization (PMF) to represent users and aspects in a latent factor space and thus generalize the user preferences. Our model is almost a direct application of proba404 bilistic matrix factorization from Salakhutdinov and Mnih (2008), originally proposed for recommender systems. The main difference is that the user-user opinion polarity scores are symmetric. Our model is also similar to the one used by Ma et al. (2008). We describe our model as follows. We assume that there are K latent factors with which both users and aspects can be represented. Let ui E IR,K denote the vector in the latent factor space for the i-th user, and ak the vector for the k-th aspect. Recall that the opinions extracted from posts between users are represented by a user-user opinion matrix S, and the opinions held by different users on the vario</context>
</contexts>
<marker>Salakhutdinov, Mnih, 2008</marker>
<rawString>Ruslan Salakhutdinov and Andriy Mnih. 2008. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems, volume 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Wang</author>
<author>David M Blei</author>
</authors>
<title>Collaborative topic modeling for recommending scientific articles.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>448--456</pages>
<contexts>
<context position="6105" citStr="Wang and Blei (2011)" startWordPosition="945" endWordPosition="948">e subgroup detection. Hassan et al. (2012) proposed to predict the polarity of interactions between users based on their textual exchanges. They defined a set of interaction features using sentiment analysis and applied supervised learning for polarity prediction. In comparison, our work is unsupervised, that is, we do not use any ground truth of interaction polarity for training. Probabilistic matrix factorization was proposed by Salakhutdinov and Mnih (2008) as a collaborative filtering method for recommender systems. It has attracted much attention and been extended by Ma et al. (2008) and Wang and Blei (2011). In particular, Ma et al. (2008) proposed a SocRec model that combines social network information with rating data using the PMF framework to perform social recommendation. Our model bears similarity to SocRec in that we also consider two types of interactions, i.e. user-user interactions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is bu</context>
</contexts>
<marker>Wang, Blei, 2011</marker>
<rawString>Chong Wang and David M. Blei. 2011. Collaborative topic modeling for recommending scientific articles. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 448–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<contexts>
<context position="11832" citStr="Wilson et al. (2005)" startWordPosition="1912" endWordPosition="1915">ublican Party” and “GOP”. To normalize these aspects, some additional information such as Wikipedia entries and Google snippets may be considered. We will study this problem in our future work. 4.2 Opinion Expression Identification Our next step is to identify candidate opinion expressions. This problem has been studied in Hu and Liu (2004), Popescu and Etzioni (2005), and Hassan and Radev (2010). Based on previous work, we do the following. We first combine three popular sentiment lexicons to form a single sentiment lexicon: the lexicon used in Hu and Liu (2004), MPQA Subjectivity Lexicon by Wilson et al. (2005) and SentiWordNet by Baccianella et al. (2010). Our final sentiment lexicon contains 15,322 negative expressions and 10,144 positive expressions. We then identify candidate opinion expressions by searching for occurrences of words in this lexicon in the posts. 4.3 Opinion Relation Extraction Given a post that contains an aspect and an opinion expression, we still need to determine whether the opinion expression is used to describe the aspect. This is a relation extraction problem. We use a supervised learning approach based on dependency 1http://opennlp.apache.org/ 2http://nlp.stanford.edu/ner</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’09,</booktitle>
<pages>1533--1541</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6816" citStr="Wu et al. (2009)" startWordPosition="1063" endWordPosition="1066">ion with rating data using the PMF framework to perform social recommendation. Our model bears similarity to SocRec in that we also consider two types of interactions, i.e. user-user interactions and useraspect interactions. However, different from Ma et al. (2008), we predict both the user-user and useraspect scores from textual posts using sentiment analysis, and the user-user opinion polarity scores are symmetric. Part of our method uses sentiment analysis to extract opinions from text. This is built on top of a large body of existing work on opinion extraction, e.g. Choi et al. (2006) and Wu et al. (2009). As the sentiment analysis component is not our main contribution, we do not review existing work along this direction in detail here. Interested readers can refer to Pang and Lee (2008). The idea of incorporating sentiment analysis into collaborative filtering algorithms has been explored by Kawamae (2011), Moshfeghi et al. (2011) and Leung et al. (2011). While their work also combines sentiment analysis with collaborative filtering, the purpose is to improve the accuracy of item recommendation. In contrast, we borrow the idea and technique of collaborative filtering to improve user relation</context>
<context position="14002" citStr="Wu et al. (2009)" startWordPosition="2298" endWordPosition="2301">y Mintz et al. (2009), and Qiu et al. (2009) has shown that the shortest path between a candidate opinion aspect and a candidate opinion expression in the dependency parse tree can be effective in extracting opinion relations. We use the Stanford Parser from Klein and Manning (2003) to obtain the dependency parse trees for each sentence in the posts and then get the dependency paths between each pair of candidate aspect and opinion expression. We use dependency relations and POS tags of nodes along the path to represent a dependency path. Given a set of training sentences (we use the one from Wu et al. (2009)), we can get a set of dependency path rules based on their frequencies in the training data. Table 1 shows the frequent dependency path rules in our training data. When a pair of aspect and opinion expression is identified to be related, we use the polarity of the opinion expression to label the relation. Finally, given a pair of users, we use the percentage of positive interactions between them over all subjective interactions (i.e. interactions with either positive or negative opinions) as extracted from their exchanged posts as the sentiment polarity score between the two users, regardless</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’09, pages 1533–1541, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>