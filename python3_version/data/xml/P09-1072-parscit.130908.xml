<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008014">
<title confidence="0.998562">
Quantitative modeling of the neural representation of adjective-noun
phrases to account for fMRI activation
</title>
<author confidence="0.924434">
Kai-min K. Chang1 Vladimir L. Cherkassky2 Tom M. Mitchell3 Marcel Adam Just2
</author>
<affiliation confidence="0.9079388">
Language Technologies Institute1
Center for Cognitive Brain Imaging2
Machine Learning Department3
Carnegie Mellon University
Pittsburgh, PA 15213, U.S.A.
</affiliation>
<email confidence="0.999131">
{kkchang,cherkassky,tom.mitchell,just}@cmu.edu
</email>
<sectionHeader confidence="0.998594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999508380952381">
Recent advances in functional Magnetic
Resonance Imaging (fMRI) offer a significant
new approach to studying semantic represen-
tations in humans by making it possible to di-
rectly observe brain activity while people
comprehend words and sentences. In this
study, we investigate how humans compre-
hend adjective-noun phrases (e.g. strong dog)
while their neural activity is recorded. Classi-
fication analysis shows that the distributed
pattern of neural activity contains sufficient
signal to decode differences among phrases.
Furthermore, vector-based semantic models
can explain a significant portion of system-
atic variance in the observed neural activity.
Multiplicative composition models of the
two-word phrase outperform additive models,
consistent with the assumption that people
use adjectives to modify the meaning of the
noun, rather than conjoining the meaning of
the adjective and noun.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941775510204">
How humans represent meanings of individual
words and how lexical semantic knowledge is
combined to form complex concepts are issues
fundamental to the study of human knowledge.
There have been a variety of approaches from
different scientific communities trying to charac-
terize semantic representations. Linguists have
tried to characterize the meaning of a word with
feature-based approaches, such as semantic roles
(Kipper et al., 2006), as well as word-relation
approaches, such as WordNet (Miller, 1995).
Computational linguists have demonstrated that a
word’s meaning is captured to some extent by
the distribution of words and phrases with which
it commonly co-occurs (Church &amp; Hanks, 1990).
Psychologists have studied word meaning
through feature-norming studies (Cree &amp; McRae,
2003) in which human participants are asked to
list the features they associate with various
words. There are also efforts to recover the latent
semantic structure from text corpora using tech-
niques such as LSA (Landauer &amp; Dumais, 1997)
and topic models (Blei et al., 2003).
Recent advances in functional Magnetic
Resonance Imaging (fMRI) provide a significant
new approach to studying semantic
representations in humans by making it possible
to directly observe brain activity while people
comprehend words and sentences. fMRI
measures the hemodynamic response (changes in
blood flow and blood oxygenation) related to
neural activity in the human brain. Images can be
acquired at good spatial resolution and reason-
able temporal resolution – the activity level of
15,000 - 20,000 brain volume elements (voxels)
of about 50 mm3 each can be measured every 1
second. Recent multivariate analyses of fMRI
activity have shown that classifiers can be
trained to decode which of several visually pre-
sented objects or object categories a person is
contemplating, given the person’s fMRI-
measured neural activity (Cox and Savoy, 2003;
O&apos;Toole et al., 2005; Haynes and Rees, 2006;
Mitchell et al., 2004). Furthermore, Mitchell et
al. (2008) showed that word features computed
from the occurrences of stimulus words (within a
trillion-token Google text corpus that captures
the typical use of words in English text) can
predict the brain activity associated with the
</bodyText>
<page confidence="0.968439">
638
</page>
<note confidence="0.9996135">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999947391891892">
meaning of these words. They developed a
generative model that is capable of predicting
fMRI neural activity well enough that it can
successfully match words it has not yet
encountered to their previously unseen fMRI
images with accuracies far above chance level.
The distributed pattern of neural activity encodes
the meanings of words, and the model’s success
indicates some initial access to the encoding.
Given these early succesess in using fMRI to
discriminate categorial information and to model
lexical semantic representations of individual
words, it is interesting to ask whether a similar
approach can be used to study the representation
of adjective-noun phrases. In this study, we
applied the vector-based models of semantic
composition used in computational linguistics to
model neural activation patterns obtained while
subjects comprehended adjective-noun phrases.
In an object-contemplation task, human partici-
pants were presented with 12 text labels of ob-
jects (e.g. dog) and were instructed to think of
the same properties of the stimulus object consis-
tently during multiple presentations of each item.
The participants were also shown adjective-noun
phrases, where adjectives were used to modify
the meaning of nouns (e.g. strong dog).
Mitchell and Lapata (2008) presented a
framework for representing the meaning of
phrases and sentences in vector space. They
discussed how an additive model, a
multiplicative model, a weighted additive model,
a Kintsch (2001) model, and a model which
combines multiplicative and additive models can
be used to model human behavior in similiarity
judgements when human participants were
presented with a reference containing a subject-
verb phrase (e.g., horse ran) and two landmarks
(e.g., galloped and dissolved) and asked to
choose which landmark was most similiar to the
reference (in this case, galloped). They compared
the composition models to human similarity
ratings and found that all models were
statistically significantly correlated with human
judgements. Moreover, the multiplicative and
combined model performed signficantlly better
than the non-compositional models. Our
approach is similar to that of Mitchell and Lapata
(2008) in that we compared additive and
multiplicative models to non-compositional
models in terms of their ability to model human
data. Our work differs from these efforts because
we focus on modeling neural activity while
people comprehend adjective-noun phrases.
In section 2, we describe the experiment and
how functional brain images were acquired. In
section 3, we apply classifier analysis to see if
the distributed pattern of neural activity contains
sufficient signal to discriminate among phrases.
In section 4, we discuss a vector-based approach
to modeling the lexical semantic knowledge
using word occurrence measures in a text corpus.
Two composition models, namely the additive
and the multiplicative models, along with two
non-composition models, namely the adjective
and the noun models, are used to explain the
systematic variance in neural activation. Section
5 distinguishes between two types of adjectives
that are used in our stimuli: attribute-specifying
adjectives and object-modifying adjectives.
Classifier analysis suggests people interpret the
two types of adjectives differently. Finally, we
discuss some of the implications of our work and
suggest some future studies.
</bodyText>
<sectionHeader confidence="0.9977915" genericHeader="introduction">
2 Brain Imaging Experiments on Adjec-
tive-Noun Comprehension
</sectionHeader>
<subsectionHeader confidence="0.9964">
2.1 Experimental Paradigm
</subsectionHeader>
<bodyText confidence="0.999968666666667">
Nineteen right-handed adults (aged between 18
and 32) from the Carnegie Mellon community
participated and gave informed consent approved
by the University of Pittsburgh and Carnegie
Mellon Institutional Review Boards. Four addi-
tional participants were excluded from the analy-
sis due to head motion greater than 2.5 mm.
The stimuli were text labels of 12 concrete
nouns from 4 semantic categories with 3
exemplars per category. The 12 nouns were bear,
cat, dog (animal); bottle, cup, knife (utensil);
carrot, corn, tomato (vegetable); airplane, train,
and truck (vehicle; see Table 1). The fMRI
neural signatures of these objects have been
found in previous studies to elicit different neural
activity. The participants were also shown each
of the 12 nouns paired with an adjective, where
the adjectives are expected to emphasize certain
semantic properties of the nouns. For instance, in
the case of strong dog, the adjective is used to
emphasize the visual or physical aspect (e.g.
muscular) of a dog, as opposed to the behavioral
aspects (e.g. play, eat, petted) that people more
often associate with the term. Notice that the last
three adjectives in Table 1 are marked by aster-
isks to denote they are object-modifying adjec-
tives. These adjectives appear to behave differ-
ently from the ordinary attribute-specifying ad-
jectives. Section 5 is devoted to discussing the
different adjective types in more detail.
</bodyText>
<page confidence="0.998649">
639
</page>
<table confidence="0.999792230769231">
Adjective Noun Category
Soft Bear Animal
Large Cat Animal
Strong Dog Animal
Plastic Bottle Utensil
Small Cup Utensil
Sharp Knife Utensil
Hard Carrot Vegetable
Cut Corn Vegetable
Firm Tomato Vegetable
Paper* Airplane Vehicle
Model* Train Vehicle
Toy* Truck Vehicle
</table>
<tableCaption confidence="0.926264">
Table 1. Word stimuli. Asterisks mark the ob-
ject-modifying adjectives, as opposed to the or-
dinary attribute-specifying adjectives.
</tableCaption>
<bodyText confidence="0.999961315789474">
To ensure that participants had a consistent set
of properties to think about, they were each
asked to generate and write a set of properties for
each exemplar in a session prior to the scanning
session (such as “4 legs, house pet, fed by me”
for dog). However, nothing was done to elicit
consistency across participants. The entire set of
24 stimuli was presented 6 times during the
scanning session, in a different random order
each time. Participants silently viewed the
stimuli and were asked to think of the same item
properties consistently across the 6 presentations
of the items. Each stimulus was presented for 3s,
followed by a 7s rest period, during which the
participants were instructed to fixate on an X
displayed in the center of the screen. There were
two additional presentations of fixation, 31s
each, at the beginning and end of each session, to
provide a baseline measure of activity.
</bodyText>
<subsectionHeader confidence="0.999729">
2.2 Data Acquisition and Processing
</subsectionHeader>
<bodyText confidence="0.999737388888889">
Functional images were acquired on a Siemens
Allegra 3.0T scanner (Siemens, Erlangen,
Germany) at the Brain Imaging Research Center
of Carnegie Mellon University and the
University of Pittsburgh using a gradient echo
EPI pulse sequence with TR = 1000 ms, TE = 30
ms, and a 60° flip angle. Seventeen 5-mm thick
oblique-axial slices were imaged with a gap of 1-
mm between slices. The acquisition matrix was
64 x 64 with 3.125 x 3.125 x 5-mm voxels. Data
processing were performed with Statistical
Parametric Mapping software (SPM2, Wellcome
Department of Cognitive Neurology, London,
UK; Friston, 2005). The data were corrected for
slice timing, motion, and linear trend, and were
temporally smoothed with a high-pass filter
using a 190s cutoff. The data were normalized to
the MNI template brain image using a 12-
parameter affine transformation and resampled to
3 x 3 x 6-mm3 voxels.
The percent signal change (PSC) relative to
the fixation condition was computed for each
item presentation at each voxel. The mean of the
four images (mean PSC) acquired within a 4s
window, offset 4s from the stimulus onset (to
account for the delay in hemodynamic response),
provided the main input measure for subsequent
analysis. The mean PSC data for each word
presentation were further normalized to have
mean zero and variance one to equate the
variation between participants over exemplars.
Due to the inherent limitations in the temporal
properties of fMRI data, we consider here only
the spatial distribution of the neural activity after
the stimuli are comprehended and do not attempt
to model the cogntive process of comprehension.
</bodyText>
<sectionHeader confidence="0.934007333333333" genericHeader="method">
3 Does the distribution of neural activ-
ity encode sufficient signal to classify
adjective-noun phrases?
</sectionHeader>
<subsectionHeader confidence="0.999814">
3.1 Classifier Analysis
</subsectionHeader>
<bodyText confidence="0.999949892857143">
We are interested in whether the distribution of
neural activity encodes sufficient signal to de-
code both nouns and adjective-noun phrases.
Given the observed neural activity when partici-
pants comprehended the adjective-noun phrases,
Gaussian Naïve Bayes classifiers were trained to
identify cognitive states associated with viewing
stimuli from the evoked patterns of functional
activity (mean PSC). For instance, the classifier
would predict which of the 24 exemplars the par-
ticipant was viewing and thinking about. Sepa-
rate classifiers were also trained for classifying
the isolated nouns, the phrases, and the 4 seman-
tic categories.
Since fMRI acquires the neural activity at
15,000 – 20,000 distinct voxel locations, many of
which might not exhibit neural activity that en-
codes word or phrase meaning, the classifier
analysis selected the voxels whose responses to
the 24 different items were most stable across
presentations. Voxel stability was computed as
the average pairwise correlation between 24 item
vectors across presentations. The focus on the
most stable voxels effectively increased the
signal-to-noise ratio in the data and facilitated
further analysis by classifiers. Many of our
previous analyses have indicated that 120 voxels
is a set size suitable for our purposes.
</bodyText>
<page confidence="0.986264">
640
</page>
<bodyText confidence="0.999988">
Classification results were evaluated using 6-
fold cross validation, where one of the 6 repeti-
tions was left out for each fold. The voxel selec-
tion procedure was performed separately inside
each fold, using only the training data. Since
multiple classes were involved, rank accuracy
was used (Mitchell et al., 2004) to evaluate the
classifier. Given a new fMRI image to classify,
the classifier outputs a rank-ordered list of possi-
ble class labels from most to least likely. The
rank accuracy is defined as the percentile rank of
the correct class in this ordered output list. Rank
accuracy ranges from 0 to 1. Classification
analysis was performed separately for each par-
ticipant, and the mean rank accuracy was com-
puted over the participants.
</bodyText>
<subsectionHeader confidence="0.961757">
3.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999910909090909">
Table 2 shows the results of the exemplar-level
classification analysis. All classification accura-
cies were significantly higher than chance (p &lt;
0.05), where the chance level for each classifica-
tion is determined based on the empirical distri-
bution of rank accuracies for randomly generated
null models. One hundred null models were gen-
erated by permuting the class labels. The classi-
fier was able to distinguish among the 24 exem-
plars with mean rank accuracies close to 70%.
We also determined the classification accuracies
separately for nouns only and phrases only. Dis-
tinct classifiers were trained. Classification accu-
racies were significantly higher (p &lt; 0.05) for the
nouns, calculated with a paired t-test. For 3 par-
ticipants, the classifier did not achieve reliable
classification accuracies for the phrase stimuli.
Moreover, we determined the classification accu-
racies separately for each semantic category of
stimuli. There were no significant differences in
accuracy across categories, except for the differ-
ence between vegetables and vehicles.
</bodyText>
<table confidence="0.99897275">
Classifier Racc
All 24 exemplars 0.69
Nouns 0.71
Phrases 0.64
Animals 0.67
Tools 0.66
Vegetables 0.65
Vehicles 0.69
</table>
<tableCaption confidence="0.991602">
Table 2. Rank accuracies for classifiers. Distinct
</tableCaption>
<bodyText confidence="0.960692695652174">
classifiers were trained to distinguish all 24 ex-
amples, nouns only, phrases only, and only
words within each of the 4 semantic categories.
High classification accuracies indicate that the
distributed pattern of neural activity does encode
sufficient signal to discriminate differences
among stimuli. The classification accuracy for
the nouns was on par with previous research,
providing a replication of previous findings
(Mitchell et al, 2004). The classifiers performed
better on the nouns than the phrases, consistent
with our expectation that characterizing phrases
is more difficult than characterizing nouns in
isolation. It is easier for participants to recall
properties associated with a familiar object than
to comprehend a noun whose meaning is further
modified by an adjective. The classification
analysis also helps us to identify participants
whose mental representations for phrases are
consistent across phrase presentations. Subse-
quent regression analysis on phrase activation
will be based on subjects who perform the phrase
task well.
</bodyText>
<sectionHeader confidence="0.765182333333333" genericHeader="method">
4 Using vector-based models of seman-
tic representation to account for the
systematic variances in neural activity
</sectionHeader>
<subsectionHeader confidence="0.998505">
4.1 Lexical Semantic Representation
</subsectionHeader>
<bodyText confidence="0.999853620689655">
Computational linguists have demonstrated that a
word’s meaning is captured to some extent by
the distribution of words and phrases with which
it commonly co-occurs (Church and Hanks,
1990). Consequently, Mitchell et al. (2008) en-
coded the meaning of a word as a vector of in-
termediate semantic features computed from the
co-occurrences with stimulus words within the
Google trillion-token text corpus that captures
the typical use of words in English text. Moti-
vated by existing conjectures regarding the cen-
trality of sensory-motor features in neural repre-
sentations of objects (Caramazza and Shelton,
1998), they selected a set of 25 semantic features
defined by 25 verbs: see, hear, listen, taste,
smell, eat, touch, rub, lift, manipulate, run, push,
fill, move, ride, say, fear, open, approach, near,
enter, drive, wear, break, and clean. These verbs
generally correspond to basic sensory and motor
activities, actions performed on objects, and ac-
tions involving changes in spatial relationships.
Because there are only 12 stimuli in our ex-
periment, we consider only 5 sensory verbs (see
hear, smell, eat and touch) to avoid overfitting
with the full set of 25 verbs. Following the work
of Bullinaria and Levy (2007), we consider the
“basic semantic vector” which normalizes n(c,t),
the count of times context word c occurs within a
window of 5 words around the target word t. The
</bodyText>
<page confidence="0.994626">
641
</page>
<bodyText confidence="0.9994202">
The multiplicative model assumes the mean-
ing of the composition is the element-wise prod-
uct of the two vectors:
basic semantic vector is thus the vector of condi-
tional probabilities,
</bodyText>
<equation confidence="0.9831085">
p(t) E n(c, t)
c
p(c  |t) = p(c, t) = n(c, t)
p=C•u•v
</equation>
<bodyText confidence="0.9997505">
where all components are positive and sum to
one. Table 3 shows the semantic representation
for strong and dog. Notice that strong is heavily
loaded on see and smell, whereas dog is heavily
loaded on eat and see, consistent with the intui-
tive interpretation of these two words.
</bodyText>
<table confidence="0.992190333333333">
See Hear Smell Eat Touch
Strong 0.63 0.06 0.26 0.03 0.03
Dog 0.34 0.06 0.05 0.54 0.02
</table>
<tableCaption confidence="0.944954">
Table 3. The lexical semantic representation for
strong and dog.
</tableCaption>
<subsectionHeader confidence="0.962963">
4.2 Semantic Composition
</subsectionHeader>
<bodyText confidence="0.989104603174603">
We adopt the vector-based semantic composition
models discussed in Mitchell and Lapata (2008).
Let u and v denote the meaning of the adjective
and noun, respectively, and let p denote the com-
position of the two words in vector space. We
consider two non-composition models, the
adjective model and the noun model, as well as
two composition models, the additive model and
the multplicative model.
The adjective model assumes that the meaning
of the composition is the same as the adjective:
p=
The noun model assumes that the meaning of
the composition is the same as the noun:
p=
The adjective model and the noun model cor-
respond to the assumption that when people
comprehend phrases, they focus exclusively on
one of the two words. This serves as a baseline
for comparison to other models.
The additive model assumes the meaning of
the composition is a linear combination of the
adjective and noun vector:
p=A•u+B•v
where A and B are vectors of weighting coeffi-
cients.
Mitchell and Lapata (2008) fitted the parame-
ters of the weighting vectors A, B, and C, though
we assume A = B = C = 1, since we are interested
in the model comparison. Also, there are no
model complexity issues, since the number of
parameters in the four models is the same.
More critically, the additive model and multi-
plicative model correspond to different cognitive
processes. On the one hand, the additive model
assumes that people concatenate the meanings of
the two words when comprehending phrases. On
the other hand, the multiplicative model assumes
that the contribution of u is scaled to its rele-
vance to v, or vice versa. Notice that the former
assumption of the multiplicative model corre-
sponds to the modifier-head interpretation where
adjectives are used to modify the meaning of
nouns. To foreshadow our results, we found the
modifier-head interpretation of the multiplicative
model to best account for the neural activity ob-
served in adjective-noun phrase data.
Table 4 shows the semantic representation for
strong dog under each of the four models. Al-
though the multiplicative model appears to have
small loadings on all features, the relative distri-
bution of loadings still encodes sufficient infor-
mation, as our later analysis will show. Notice
how the additive model concatenates the mean-
ing of two words and is heavily loaded on see,
eat, and smell, whereas the multiplicative model
zeros out unshared features like eat and smell. As
a result, the multiplicative model predicts that the
visual aspects will be emphasized when a par-
ticipant is thinking about strong dog, while the
additive model predicts that, in addition, the be-
havioral aspects (e.g., eat, smell, and hear) of
dog will be emphasized.
</bodyText>
<table confidence="0.9928804">
See Hear Smell Eat Touch
Adj 0.63 0.06 0.26 0.03 0.03
Noun 0.34 0.06 0.05 0.54 0.02
Add 0.96 0.12 0.31 0.57 0.04
Multi 0.21 0.00 0.01 0.01 0.00
</table>
<tableCaption confidence="0.935832333333333">
Table 4. The semantic representation for strong
dog under the adjective, noun, additive, and
multiplicative models.
</tableCaption>
<figure confidence="0.885997">
u
v
</figure>
<page confidence="0.992015">
642
</page>
<bodyText confidence="0.999949863636364">
Notice that these 4 vector-based semantic
composition models ignore word order. This cor-
responds to the bag-of-words assumption, such
that the representation for strong dog will be the
same as that of dog strong. The bag-of-words
model is used as a simplifying assumption in
several semantic models, including LSA (Lan-
dauer &amp; Dumais, 1997) and topic models (Blei et
al., 2003).
There were two main hypotheses that we
tested. First, people usually regard the noun in
the adjective-noun pair as the linguistic head.
Therefore, meaning associated with the noun
should be more evoked. Thus, we predicted that
the noun model would outperform the adjective
model. Second, people make more interpreta-
tions that use adjectives to modify the meaning
of the noun, rather than disjunctive interpreta-
tions that add together or take the union of the
semantic features of the two words. Thus, we
predicted that the multiplicative model would
outperform the additive model.
</bodyText>
<subsectionHeader confidence="0.998143">
4.3 Regression Fit
</subsectionHeader>
<bodyText confidence="0.99976825">
In this analysis, we train a regression model to fit
the activation profile for the 12 phrase stimuli.
We focused on subjects for whom the classifier
established reliable classification accuracies for
the phrase stimuli. The regression model exam-
ined to what extent the semantic feature vectors
(explanatory variables) can account for the varia-
tion in neural activity (response variable) across
the 12 stimuli. All explanatory variables were
entered into the regression model simultane-
ously. More precisely, the predicted activity av at
voxel v in the brain for word w is given by
</bodyText>
<equation confidence="0.99562075">
n
av =I fi vi J i w v
� � + s
i=1
</equation>
<bodyText confidence="0.999970321428572">
where Ji(w) is the value of the ith intermediate
semantic feature for word w, ,Bvi is the regression
coefficient that specifies the degree to which the
ith intermediate semantic feature activates voxel
v, and εv is the model’s error term that represents
the unexplained variation in the response vari-
able. Least squares estimates of ,Bvi were obtained
to minimize the sum of squared errors in recon-
structing the training fMRI images. An L2 regu-
larization with lambda = 1.0 was added to pre-
vent overfitting given the high parameter-to-
data-points ratios. A regression model was
trained for each of the 120 voxels and the re-
ported R2 is the average across the 120 voxels.
R2 measures the amount of systematic variance
explained by the model. Regression results were
evaluated using 6-fold cross validation, where
one of the 6 repetitions was left out for each fold.
Linear regression assumes a linear dependency
among the variables and compares the variance
due to the independent variables against the vari-
ance due to the residual errors. While the linear-
ity assumption may be overly simplistic, it re-
flects the assumption that fMRI activity often
reflects a superimposition of contributions from
different sources, and has provided a useful first
order approximation in the field (Mitchell et al.,
2008).
</bodyText>
<subsectionHeader confidence="0.967263">
4.4 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999742821428571">
The second column of Table 5 shows the R2 re-
gression fit (averaged across 120 voxels) of the
adjective, noun, additive, and multiplicative
model to the neural activity observed in adjec-
tive-noun phrase data. The noun model signifi-
cantly (p &lt; 0.05) outperformed the adjective
model, estimated with a paired t-test. Moreover,
the difference between the additive and adjective
models was not significant, whereas the differ-
ence between the additive and noun models was
significant (p &lt; 0.05). The multiplicative model
significantly (p &lt; 0.05) outperformed both of the
non-compositional models, as well as the addi-
tive model.
More importantly, the two hypotheses that we
were testing were both verified. Notice Table 5
supports our hypothesis that the noun model
should outperform the adjective model based on
the assumption that the noun is generally more
central to the phrase meaning than is the adjec-
tive. Table 5 also supports our hypothesis that
the multiplicative model should outperform the
additive model, based on the assumption that
adjectives are used to emphasize particular se-
mantic features that will already be represented
in the semantic feature vector of the noun. Our
findings here are largely consistent with Mitchell
and Lapata (2008).
</bodyText>
<table confidence="0.9894946">
R2 Racc
Adjective 0.34 0.57
Noun 0.36 0.61
Additive 0.35 0.60
Multiplicative 0.42 0.62
</table>
<tableCaption confidence="0.981427">
Table 5. Regression fit and regression-based
</tableCaption>
<bodyText confidence="0.807192">
classification rank accuracy of the adjective,
noun, additive, and multiplicative models for
phrase stimuli.
</bodyText>
<page confidence="0.998465">
643
</page>
<bodyText confidence="0.999176633333333">
Following Mitchell et al. (2008), the regres-
sion model can be used to decode mental states.
Specifically, for each regression model, the esti-
mated regression weights can be used to generate
the predicted activity for each word. Then, a pre-
viously unseen neural activation vector is identi-
fied with the class of the predicted activation that
had the highest correlation with the given ob-
served neural activation vector. Notice that,
unlike Mitchell et al. (2008), where the regres-
sion model was used to make predictions for
items outside the training set, here we are just
showing that the regression model can be used
for classification purposes.
The third column of Table 5 shows the rank
accuracies classifying mental concepts using the
predicted activation from the adjective, noun,
additive, and multiplicative models. All rank ac-
curacies were significantly higher (p &lt; 0.05) than
chance, where the chance level for each classifi-
cation is again determined by permutation test-
ing. More importantly, here we observe a rank-
ing of these four models similar to that observed
for the regression analysis. Namely, the noun
model performs significantly better (p &lt; 0.05)
than the adjective model, and the multiplicative
model performs significantly better (p &lt; 0.05)
than the additive model. However, the difference
between the multiplicative model and the noun
model is not statistically significant in this case.
</bodyText>
<sectionHeader confidence="0.640035333333333" genericHeader="method">
5 Comparing the attribute-specifying
adjectives with the object-modifying
adjectives
</sectionHeader>
<bodyText confidence="0.999988892307693">
Some of the phrases contained adjectives that
changed the meaning of the noun. In the case of
vehicle nouns, adjectives were chosen to modify
the manipulability of the nouns (e.g., to make an
airplane more manipulable, paper was chosen as
the modifier). This type of modifier raises two
issues. First, these modifiers (e.g. paper, model,
toy) more typically assume the part of speech
(POS) tag of nouns, unlike our other modifiers
(e.g., soft, large, strong) whose typical POS tag
is adjective. Second, these modifiers combine
with the noun to denote a very different object
from the noun in isolation (paper airplane,
model train, toy truck), in comparison to other
cases where the adjective simply specifies an
attribute of the noun (soft bear, large cat, strong
dog, etc.). In order to study this difference, we
performed classification analysis separately for
the attribute-specifying adjectives and the object-
modifying adjectives.
Our hypothesis is that the phrases with attrib-
ute-specifying adjectives will be much more dif-
ficult to distinguish from the original nouns than
the adjectives that change the referent. For in-
stance, we hypothesize that it is much more dif-
ficult to distinguish the neural representation for
strong dog versus dog than it is to distinguish the
neural representation for paper airplane versus
airplane. To verify this, Gaussian Naïve Bayes
classifiers were trained to discriminate between
each of the 12 pairs of nouns and adjective-noun
phrases. The average classification for phrases
with object-modifying adjectives is 0.76,
whereas classification accuracies for phrases
with attribute-specifying adjectives are 0.68. The
difference is statistically significant at p &lt; 0.05.
This result supports our hypothesis.
Furthermore, we performed regression-based
classification separately for the two types of ad-
jectives. Notice that the number of phrases with
object-modifying adjectives is much less than the
number of phrases with attribute-specifying ad-
jectives (3 vs. 9). This affects the parameter-to-
data-points ratio in our regression model. Conse-
quently, an L2 regularization with lambda = 10.0
was used to prevent overfitting. Table 6 shows a
pattern similar to that seen in section 4 is ob-
served for the attribute-specifying adjectives.
That is, the noun model outperformed the adjec-
tive model and the multiplicative model outper-
formed the additive model when using attribute-
specifying adjectives. However, for the object-
modifying adjectives, the noun model no longer
outperformed the adjective model. Moreover, the
additive model performed better than the noun
model. Although neither difference is statistically
significant, this clearly shows a pattern different
from the attribute-specifying adjectives. This
result suggests that when interpreting phrases
like paper airplane, it is more important to con-
sider contributions from the adjectives, compared
to when interpreting phrases like strong dog,
where the contribution from the adjective is sim-
ply to specify a property of the item typically
referred to by the noun in isolation.
</bodyText>
<table confidence="0.965566833333333">
Attribute- Object-
specifying modifying
Adjective 0.57 0.65
Noun 0.62 0.64
Additive 0.61 0.65
Multiplicative 0.63 0.67
</table>
<tableCaption confidence="0.664284333333333">
Table 6. Separate regression-based classification
rank accuracy for phrases with attribute-
specifying or object-modifying adjectives.
</tableCaption>
<page confidence="0.997626">
644
</page>
<bodyText confidence="0.999974">
In light of this observation, we plan to extend
our analysis of adjective-nouns phrases to noun-
noun phrases, where participants will be shown
noun phrases (e.g. carrot knife) and instructed to
think of a likely meaning for the phrases. Unlike
adjective-noun phrases, where a single interpre-
tation often dominates, noun-noun combinations
allow multiple interpretations (e.g., carrot knife
can be interpreted as a knife that is specifically
used to cut carrots or a knife carved out of car-
rots). There exists an extensive literature on the
conceptual combination of noun-noun phrases.
Costello and Keane (1997) provide extensive
studies on the polysemy of conceptual combina-
tion. More importantly, they outline different
rules of combination, including property map-
ping, relational mapping, hybrid mapping, etc. It
will be interesting to see if different composition
models better account for neural activation when
different kinds of combination rules are used.
</bodyText>
<sectionHeader confidence="0.994857" genericHeader="conclusions">
6 Contribution and Conclusion
</sectionHeader>
<bodyText confidence="0.999994661538462">
Experimental results have shown that the distrib-
uted pattern of neural activity while people are
comprehending adjective-noun phrases does con-
tain sufficient information to decode the stimuli
with accuracies significantly above chance. Fur-
thermore, vector-based semantic models can ex-
plain a significant portion of systematic variance
in observed neural activity. Multiplicative com-
position models outperform additive models, a
trend that is consistent with the assumption that
people use adjectives to modify the meaning of
the noun, rather than conjoining the meaning of
the adjective and noun.
In this study, we represented the meaning of
both adjectives and nouns in terms of their co-
occurrences with 5 sensory verbs. While this
type of representation might be justified for con-
crete nouns (hypothesizing that their neural rep-
resentations are largely grounded in sensory-
motor features), it might be that a different repre-
sentation is needed for adjectives. Further re-
search is needed to investigate alternative repre-
sentations for both nouns and adjectives. More-
over, the composition models that we presented
here are overly simplistic in a number of ways.
We look forward to future research to extend the
intermediate representation and to experiment
with different modeling methodologies. An al-
ternative approach is to model the semantic rep-
resentation as a hidden variable using a genera-
tive probabilistic model that describes how neu-
ral activity is generated from some latent seman-
tic representation. We are currently exploring the
infinite latent semantic feature model (ILFM;
Griffiths &amp; Ghahramani, 2005), which assumes a
non-parametric Indian Buffet prior to the binary
feature vector and models neural activation with
a linear Gaussian model. The basic proposition
of the model is that the human semantic knowl-
edge system is capable of storing an infinite list
of features (or semantic components) associated
with a concept; however, only a subset is ac-
tively recalled during any given task (context-
dependent). Thus, a set of latent indicator vari-
ables is introduced to indicate whether a feature
is actively recalled at any given task. We are in-
vestigating if the compositional models also op-
erate in the learned latent semantic space.
The premise of our research relies on ad-
vancements in the fields of computational lin-
guistics and cognitive neuroimaging. Indeed, we
are at an especially opportune time in the history
of the study of language, when linguistic corpora
allow word meanings to be computed from the
distribution of word co-occurrence in a trillion-
token text corpus, and brain imaging technology
allows us to directly observe and model neural
activity associated with the conceptual combina-
tion of lexical items. An improved understanding
of language processing in the brain could yield a
more biologically-informed model of semantic
representation of lexical knowledge. We there-
fore look forward to further brain imaging stud-
ies shedding new light on the nature of human
representation of semantic knowledge.
</bodyText>
<sectionHeader confidence="0.998561" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.8952904">
This research was supported by the National Sci-
ence Foundation, Grant No. IIS-0835797, and by
the W. M. Keck Foundation. We would like to
thank Jennifer Moore for help in preparation of
the manuscript.
</bodyText>
<sectionHeader confidence="0.997138" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999779727272727">
Blei, D. M., Ng, A. Y., Jordan, and M. I.. 2003. La-
tent dirichlet allocation. Journal of Machine Learn-
ing Research 3, 993-1022.
Bullinaria, J., and Levy, J. 2007. Extracting semantic
representations from word co-occurrence statistics:
A computational study. Behavioral Research
Methods, 39:510-526.
Caramazza, A., and Shelton, J. R. 1998. Domain-
specific knowledge systems in the brain the ani-
mate inanimate distinction. Journal of Cognitive
Neuroscience 10(1), 1-34.
</reference>
<page confidence="0.985775">
645
</page>
<reference confidence="0.999888666666667">
Church, K. W., and Hanks, P. 1990. Word association
norms, mutual information, and lexicography.
Computational Linguistics, 16, 22-29.
Cree, G. S., and McRae, K. 2003. Analyzing the fac-
tors underlying the structure and computation of
the meaning of chipmunk, cherry, chisel, cheese,
and cello (and many other such concrete nouns).
Journal of Experimental Psychology: General
132(2), 163-201.
Costello, F., and Keane, M. 2001. Testing two theo-
ries of conceptual combination: Alignment versus
diagnosticity in the comprehension and production
of combined concepts. Journal of Experimental
Psychology: Learning, Memory &amp; Cognition,
27(1): 255-271.
Cox, D. D., and Savoy, R. L. 2003. Functioning mag-
netic resonance imaging (fMRI) &amp;quot;brain reading&amp;quot;:
Detecting and classifying distributed patterns of
fMRI activity in human visual cortex. NeuroImage
19, 261-270.
Friston, K. J. 2005. Models of brain function in neuro-
imaging. Annual Review of Psychology 56, 57-87.
Griffiths, T. L., and Ghahramani, Z. 2005. Infinite
latent feature models and the Indian buffet process.
Gatsby Unit Technical Report GCNU-TR-2005-
001.
Haynes, J. D., and Rees, G. 2006. Decoding mental
states from brain activity in humans. Nature Re-
views Neuroscience 7(7), 523-534.
Kintsch, W. 2001. Prediction. Cognitive Science,
25(2):173-202.
Landauer, T.K., and Dumais, S. T. 1997. A solution to
Plato’s problem: The latent semantic analysis the-
ory of acquisition, induction, and representation of
knowledge. Psychological Review, 104(2), 211-
240.
Miller, G. A. 1995. WordNet: A lexical database for
English. Communications of the ACM 38, 39-41.
Mitchell, J., and Lapata, M. 2008. Vector-based mod-
els of semantic composition. Proceedings of ACL-
08: HLT, 236-244.
Mitchell, T., Hutchinson, R., Niculescu, R. S.,
Pereira, F., Wang, X., Just, M. A., and Newman, S.
D. 2004. Learning to decode cognitive states from
brain images. Machine Learning 57, 145-175.
Mitchell, T., Shinkareva, S.V., Carlson, A., Chang,
K.M., Malave, V.L., Mason, R.A., and Just, M.A.
2008. Predicting human brain activity associated
with the meanings of nouns. Science 320, 1191-
1195.
O&apos;Toole, A. J., Jiang, F., Abdi, H., and Haxby, J. V.
2005. Partially distributed representations of ob-
jects and faces in ventral temporal cortex. Journal
of Cognitive Neuroscience, 17, 580-590.
</reference>
<page confidence="0.998868">
646
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.355485">
<title confidence="0.778405">Quantitative modeling of the neural representation of adjective-noun phrases to account for fMRI activation K. Vladimir L. Tom M. Marcel Adam Technologies for Cognitive Brain Learning</title>
<affiliation confidence="0.999698">Carnegie Mellon University</affiliation>
<address confidence="0.993528">Pittsburgh, PA 15213, U.S.A.</address>
<email confidence="0.999801">kkchang@cmu.edu</email>
<email confidence="0.999801">cherkassky@cmu.edu</email>
<email confidence="0.999801">tom.mitchell@cmu.edu</email>
<email confidence="0.999801">just@cmu.edu</email>
<abstract confidence="0.998417409090909">Recent advances in functional Magnetic Resonance Imaging (fMRI) offer a significant new approach to studying semantic representations in humans by making it possible to directly observe brain activity while people comprehend words and sentences. In this study, we investigate how humans compreadjective-noun phrases (e.g. while their neural activity is recorded. Classification analysis shows that the distributed pattern of neural activity contains sufficient signal to decode differences among phrases. Furthermore, vector-based semantic models can explain a significant portion of systematic variance in the observed neural activity. Multiplicative composition models of the two-word phrase outperform additive models, consistent with the assumption that people use adjectives to modify the meaning of the noun, rather than conjoining the meaning of the adjective and noun.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>A Y Ng</author>
<author>Jordan</author>
<author>M I</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research</journal>
<volume>3</volume>
<pages>993--1022</pages>
<contexts>
<context position="2363" citStr="Blei et al., 2003" startWordPosition="333" endWordPosition="336">as well as word-relation approaches, such as WordNet (Miller, 1995). Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church &amp; Hanks, 1990). Psychologists have studied word meaning through feature-norming studies (Cree &amp; McRae, 2003) in which human participants are asked to list the features they associate with various words. There are also efforts to recover the latent semantic structure from text corpora using techniques such as LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). Recent advances in functional Magnetic Resonance Imaging (fMRI) provide a significant new approach to studying semantic representations in humans by making it possible to directly observe brain activity while people comprehend words and sentences. fMRI measures the hemodynamic response (changes in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent mu</context>
<context position="21604" citStr="Blei et al., 2003" startWordPosition="3363" endWordPosition="3366">dj 0.63 0.06 0.26 0.03 0.03 Noun 0.34 0.06 0.05 0.54 0.02 Add 0.96 0.12 0.31 0.57 0.04 Multi 0.21 0.00 0.01 0.01 0.00 Table 4. The semantic representation for strong dog under the adjective, noun, additive, and multiplicative models. u v 642 Notice that these 4 vector-based semantic composition models ignore word order. This corresponds to the bag-of-words assumption, such that the representation for strong dog will be the same as that of dog strong. The bag-of-words model is used as a simplifying assumption in several semantic models, including LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). There were two main hypotheses that we tested. First, people usually regard the noun in the adjective-noun pair as the linguistic head. Therefore, meaning associated with the noun should be more evoked. Thus, we predicted that the noun model would outperform the adjective model. Second, people make more interpretations that use adjectives to modify the meaning of the noun, rather than disjunctive interpretations that add together or take the union of the semantic features of the two words. Thus, we predicted that the multiplicative model would outperform the additive model. 4.3 Regression Fi</context>
</contexts>
<marker>Blei, Ng, Jordan, I, 2003</marker>
<rawString>Blei, D. M., Ng, A. Y., Jordan, and M. I.. 2003. Latent dirichlet allocation. Journal of Machine Learning Research 3, 993-1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bullinaria</author>
<author>J Levy</author>
</authors>
<title>Extracting semantic representations from word co-occurrence statistics: A computational study.</title>
<date>2007</date>
<journal>Behavioral Research Methods,</journal>
<pages>39--510</pages>
<contexts>
<context position="17406" citStr="Bullinaria and Levy (2007)" startWordPosition="2652" endWordPosition="2655">Shelton, 1998), they selected a set of 25 semantic features defined by 25 verbs: see, hear, listen, taste, smell, eat, touch, rub, lift, manipulate, run, push, fill, move, ride, say, fear, open, approach, near, enter, drive, wear, break, and clean. These verbs generally correspond to basic sensory and motor activities, actions performed on objects, and actions involving changes in spatial relationships. Because there are only 12 stimuli in our experiment, we consider only 5 sensory verbs (see hear, smell, eat and touch) to avoid overfitting with the full set of 25 verbs. Following the work of Bullinaria and Levy (2007), we consider the “basic semantic vector” which normalizes n(c,t), the count of times context word c occurs within a window of 5 words around the target word t. The 641 The multiplicative model assumes the meaning of the composition is the element-wise product of the two vectors: basic semantic vector is thus the vector of conditional probabilities, p(t) E n(c, t) c p(c |t) = p(c, t) = n(c, t) p=C•u•v where all components are positive and sum to one. Table 3 shows the semantic representation for strong and dog. Notice that strong is heavily loaded on see and smell, whereas dog is heavily loade</context>
</contexts>
<marker>Bullinaria, Levy, 2007</marker>
<rawString>Bullinaria, J., and Levy, J. 2007. Extracting semantic representations from word co-occurrence statistics: A computational study. Behavioral Research Methods, 39:510-526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Caramazza</author>
<author>J R Shelton</author>
</authors>
<title>Domainspecific knowledge systems in the brain the animate inanimate distinction.</title>
<date>1998</date>
<journal>Journal of Cognitive Neuroscience</journal>
<volume>10</volume>
<issue>1</issue>
<pages>1--34</pages>
<contexts>
<context position="16794" citStr="Caramazza and Shelton, 1998" startWordPosition="2552" endWordPosition="2555">tic Representation Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church and Hanks, 1990). Consequently, Mitchell et al. (2008) encoded the meaning of a word as a vector of intermediate semantic features computed from the co-occurrences with stimulus words within the Google trillion-token text corpus that captures the typical use of words in English text. Motivated by existing conjectures regarding the centrality of sensory-motor features in neural representations of objects (Caramazza and Shelton, 1998), they selected a set of 25 semantic features defined by 25 verbs: see, hear, listen, taste, smell, eat, touch, rub, lift, manipulate, run, push, fill, move, ride, say, fear, open, approach, near, enter, drive, wear, break, and clean. These verbs generally correspond to basic sensory and motor activities, actions performed on objects, and actions involving changes in spatial relationships. Because there are only 12 stimuli in our experiment, we consider only 5 sensory verbs (see hear, smell, eat and touch) to avoid overfitting with the full set of 25 verbs. Following the work of Bullinaria and</context>
</contexts>
<marker>Caramazza, Shelton, 1998</marker>
<rawString>Caramazza, A., and Shelton, J. R. 1998. Domainspecific knowledge systems in the brain the animate inanimate distinction. Journal of Cognitive Neuroscience 10(1), 1-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>22--29</pages>
<contexts>
<context position="16374" citStr="Church and Hanks, 1990" startWordPosition="2487" endWordPosition="2490">ed by an adjective. The classification analysis also helps us to identify participants whose mental representations for phrases are consistent across phrase presentations. Subsequent regression analysis on phrase activation will be based on subjects who perform the phrase task well. 4 Using vector-based models of semantic representation to account for the systematic variances in neural activity 4.1 Lexical Semantic Representation Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church and Hanks, 1990). Consequently, Mitchell et al. (2008) encoded the meaning of a word as a vector of intermediate semantic features computed from the co-occurrences with stimulus words within the Google trillion-token text corpus that captures the typical use of words in English text. Motivated by existing conjectures regarding the centrality of sensory-motor features in neural representations of objects (Caramazza and Shelton, 1998), they selected a set of 25 semantic features defined by 25 verbs: see, hear, listen, taste, smell, eat, touch, rub, lift, manipulate, run, push, fill, move, ride, say, fear, open,</context>
<context position="2001" citStr="Church &amp; Hanks, 1990" startWordPosition="276" endWordPosition="279">nowledge is combined to form complex concepts are issues fundamental to the study of human knowledge. There have been a variety of approaches from different scientific communities trying to characterize semantic representations. Linguists have tried to characterize the meaning of a word with feature-based approaches, such as semantic roles (Kipper et al., 2006), as well as word-relation approaches, such as WordNet (Miller, 1995). Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church &amp; Hanks, 1990). Psychologists have studied word meaning through feature-norming studies (Cree &amp; McRae, 2003) in which human participants are asked to list the features they associate with various words. There are also efforts to recover the latent semantic structure from text corpora using techniques such as LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). Recent advances in functional Magnetic Resonance Imaging (fMRI) provide a significant new approach to studying semantic representations in humans by making it possible to directly observe brain activity while people comprehend words and</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K. W., and Hanks, P. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16, 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Cree</author>
<author>K McRae</author>
</authors>
<title>Analyzing the factors underlying the structure and computation of the meaning of chipmunk, cherry, chisel, cheese, and cello (and many other such concrete nouns).</title>
<date>2003</date>
<journal>Journal of Experimental Psychology: General</journal>
<volume>132</volume>
<issue>2</issue>
<pages>163--201</pages>
<contexts>
<context position="2095" citStr="Cree &amp; McRae, 2003" startWordPosition="288" endWordPosition="291">edge. There have been a variety of approaches from different scientific communities trying to characterize semantic representations. Linguists have tried to characterize the meaning of a word with feature-based approaches, such as semantic roles (Kipper et al., 2006), as well as word-relation approaches, such as WordNet (Miller, 1995). Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church &amp; Hanks, 1990). Psychologists have studied word meaning through feature-norming studies (Cree &amp; McRae, 2003) in which human participants are asked to list the features they associate with various words. There are also efforts to recover the latent semantic structure from text corpora using techniques such as LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). Recent advances in functional Magnetic Resonance Imaging (fMRI) provide a significant new approach to studying semantic representations in humans by making it possible to directly observe brain activity while people comprehend words and sentences. fMRI measures the hemodynamic response (changes in blood flow and blood oxygenatio</context>
</contexts>
<marker>Cree, McRae, 2003</marker>
<rawString>Cree, G. S., and McRae, K. 2003. Analyzing the factors underlying the structure and computation of the meaning of chipmunk, cherry, chisel, cheese, and cello (and many other such concrete nouns). Journal of Experimental Psychology: General 132(2), 163-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Costello</author>
<author>M Keane</author>
</authors>
<title>Testing two theories of conceptual combination: Alignment versus diagnosticity in the comprehension and production of combined concepts.</title>
<date>2001</date>
<journal>Journal of Experimental Psychology: Learning, Memory &amp; Cognition,</journal>
<volume>27</volume>
<issue>1</issue>
<pages>255--271</pages>
<marker>Costello, Keane, 2001</marker>
<rawString>Costello, F., and Keane, M. 2001. Testing two theories of conceptual combination: Alignment versus diagnosticity in the comprehension and production of combined concepts. Journal of Experimental Psychology: Learning, Memory &amp; Cognition, 27(1): 255-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Cox</author>
<author>R L Savoy</author>
</authors>
<title>Functioning magnetic resonance imaging (fMRI) &amp;quot;brain reading&amp;quot;: Detecting and classifying distributed patterns of fMRI activity in human visual cortex.</title>
<date>2003</date>
<journal>NeuroImage</journal>
<volume>19</volume>
<pages>261--270</pages>
<contexts>
<context position="3213" citStr="Cox and Savoy, 2003" startWordPosition="463" endWordPosition="466">rds and sentences. fMRI measures the hemodynamic response (changes in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent multivariate analyses of fMRI activity have shown that classifiers can be trained to decode which of several visually presented objects or object categories a person is contemplating, given the person’s fMRImeasured neural activity (Cox and Savoy, 2003; O&apos;Toole et al., 2005; Haynes and Rees, 2006; Mitchell et al., 2004). Furthermore, Mitchell et al. (2008) showed that word features computed from the occurrences of stimulus words (within a trillion-token Google text corpus that captures the typical use of words in English text) can predict the brain activity associated with the 638 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP meaning of these words. They developed a generative model that is capable of predicting fMRI neural activity </context>
</contexts>
<marker>Cox, Savoy, 2003</marker>
<rawString>Cox, D. D., and Savoy, R. L. 2003. Functioning magnetic resonance imaging (fMRI) &amp;quot;brain reading&amp;quot;: Detecting and classifying distributed patterns of fMRI activity in human visual cortex. NeuroImage 19, 261-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Friston</author>
</authors>
<title>Models of brain function in neuroimaging.</title>
<date>2005</date>
<journal>Annual Review of Psychology</journal>
<volume>56</volume>
<pages>57--87</pages>
<contexts>
<context position="10533" citStr="Friston, 2005" startWordPosition="1594" endWordPosition="1595">d Processing Functional images were acquired on a Siemens Allegra 3.0T scanner (Siemens, Erlangen, Germany) at the Brain Imaging Research Center of Carnegie Mellon University and the University of Pittsburgh using a gradient echo EPI pulse sequence with TR = 1000 ms, TE = 30 ms, and a 60° flip angle. Seventeen 5-mm thick oblique-axial slices were imaged with a gap of 1- mm between slices. The acquisition matrix was 64 x 64 with 3.125 x 3.125 x 5-mm voxels. Data processing were performed with Statistical Parametric Mapping software (SPM2, Wellcome Department of Cognitive Neurology, London, UK; Friston, 2005). The data were corrected for slice timing, motion, and linear trend, and were temporally smoothed with a high-pass filter using a 190s cutoff. The data were normalized to the MNI template brain image using a 12- parameter affine transformation and resampled to 3 x 3 x 6-mm3 voxels. The percent signal change (PSC) relative to the fixation condition was computed for each item presentation at each voxel. The mean of the four images (mean PSC) acquired within a 4s window, offset 4s from the stimulus onset (to account for the delay in hemodynamic response), provided the main input measure for subs</context>
</contexts>
<marker>Friston, 2005</marker>
<rawString>Friston, K. J. 2005. Models of brain function in neuroimaging. Annual Review of Psychology 56, 57-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Griffiths</author>
<author>Z Ghahramani</author>
</authors>
<title>Infinite latent feature models and the Indian buffet process. Gatsby Unit</title>
<date>2005</date>
<tech>Technical Report GCNU-TR-2005-001.</tech>
<contexts>
<context position="33082" citStr="Griffiths &amp; Ghahramani, 2005" startWordPosition="5137" endWordPosition="5140">d to investigate alternative representations for both nouns and adjectives. Moreover, the composition models that we presented here are overly simplistic in a number of ways. We look forward to future research to extend the intermediate representation and to experiment with different modeling methodologies. An alternative approach is to model the semantic representation as a hidden variable using a generative probabilistic model that describes how neural activity is generated from some latent semantic representation. We are currently exploring the infinite latent semantic feature model (ILFM; Griffiths &amp; Ghahramani, 2005), which assumes a non-parametric Indian Buffet prior to the binary feature vector and models neural activation with a linear Gaussian model. The basic proposition of the model is that the human semantic knowledge system is capable of storing an infinite list of features (or semantic components) associated with a concept; however, only a subset is actively recalled during any given task (contextdependent). Thus, a set of latent indicator variables is introduced to indicate whether a feature is actively recalled at any given task. We are investigating if the compositional models also operate in </context>
</contexts>
<marker>Griffiths, Ghahramani, 2005</marker>
<rawString>Griffiths, T. L., and Ghahramani, Z. 2005. Infinite latent feature models and the Indian buffet process. Gatsby Unit Technical Report GCNU-TR-2005-001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Haynes</author>
<author>G Rees</author>
</authors>
<title>Decoding mental states from brain activity in humans.</title>
<date>2006</date>
<journal>Nature Reviews Neuroscience</journal>
<volume>7</volume>
<issue>7</issue>
<pages>523--534</pages>
<contexts>
<context position="3258" citStr="Haynes and Rees, 2006" startWordPosition="471" endWordPosition="474">namic response (changes in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent multivariate analyses of fMRI activity have shown that classifiers can be trained to decode which of several visually presented objects or object categories a person is contemplating, given the person’s fMRImeasured neural activity (Cox and Savoy, 2003; O&apos;Toole et al., 2005; Haynes and Rees, 2006; Mitchell et al., 2004). Furthermore, Mitchell et al. (2008) showed that word features computed from the occurrences of stimulus words (within a trillion-token Google text corpus that captures the typical use of words in English text) can predict the brain activity associated with the 638 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP meaning of these words. They developed a generative model that is capable of predicting fMRI neural activity well enough that it can successfully match wo</context>
</contexts>
<marker>Haynes, Rees, 2006</marker>
<rawString>Haynes, J. D., and Rees, G. 2006. Decoding mental states from brain activity in humans. Nature Reviews Neuroscience 7(7), 523-534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kintsch</author>
</authors>
<date>2001</date>
<journal>Prediction. Cognitive Science,</journal>
<pages>25--2</pages>
<contexts>
<context position="5185" citStr="Kintsch (2001)" startWordPosition="767" endWordPosition="768">noun phrases. In an object-contemplation task, human participants were presented with 12 text labels of objects (e.g. dog) and were instructed to think of the same properties of the stimulus object consistently during multiple presentations of each item. The participants were also shown adjective-noun phrases, where adjectives were used to modify the meaning of nouns (e.g. strong dog). Mitchell and Lapata (2008) presented a framework for representing the meaning of phrases and sentences in vector space. They discussed how an additive model, a multiplicative model, a weighted additive model, a Kintsch (2001) model, and a model which combines multiplicative and additive models can be used to model human behavior in similiarity judgements when human participants were presented with a reference containing a subjectverb phrase (e.g., horse ran) and two landmarks (e.g., galloped and dissolved) and asked to choose which landmark was most similiar to the reference (in this case, galloped). They compared the composition models to human similarity ratings and found that all models were statistically significantly correlated with human judgements. Moreover, the multiplicative and combined model performed s</context>
</contexts>
<marker>Kintsch, 2001</marker>
<rawString>Kintsch, W. 2001. Prediction. Cognitive Science, 25(2):173-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>S T Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<pages>211--240</pages>
<contexts>
<context position="2326" citStr="Landauer &amp; Dumais, 1997" startWordPosition="326" endWordPosition="329">h as semantic roles (Kipper et al., 2006), as well as word-relation approaches, such as WordNet (Miller, 1995). Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church &amp; Hanks, 1990). Psychologists have studied word meaning through feature-norming studies (Cree &amp; McRae, 2003) in which human participants are asked to list the features they associate with various words. There are also efforts to recover the latent semantic structure from text corpora using techniques such as LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). Recent advances in functional Magnetic Resonance Imaging (fMRI) provide a significant new approach to studying semantic representations in humans by making it possible to directly observe brain activity while people comprehend words and sentences. fMRI measures the hemodynamic response (changes in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can </context>
<context position="21567" citStr="Landauer &amp; Dumais, 1997" startWordPosition="3355" endWordPosition="3359">l be emphasized. See Hear Smell Eat Touch Adj 0.63 0.06 0.26 0.03 0.03 Noun 0.34 0.06 0.05 0.54 0.02 Add 0.96 0.12 0.31 0.57 0.04 Multi 0.21 0.00 0.01 0.01 0.00 Table 4. The semantic representation for strong dog under the adjective, noun, additive, and multiplicative models. u v 642 Notice that these 4 vector-based semantic composition models ignore word order. This corresponds to the bag-of-words assumption, such that the representation for strong dog will be the same as that of dog strong. The bag-of-words model is used as a simplifying assumption in several semantic models, including LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). There were two main hypotheses that we tested. First, people usually regard the noun in the adjective-noun pair as the linguistic head. Therefore, meaning associated with the noun should be more evoked. Thus, we predicted that the noun model would outperform the adjective model. Second, people make more interpretations that use adjectives to modify the meaning of the noun, rather than disjunctive interpretations that add together or take the union of the semantic features of the two words. Thus, we predicted that the multiplicative model would outperform </context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, T.K., and Dumais, S. T. 1997. A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2), 211-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: A lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM</journal>
<volume>38</volume>
<pages>39--41</pages>
<contexts>
<context position="1812" citStr="Miller, 1995" startWordPosition="249" endWordPosition="250">fy the meaning of the noun, rather than conjoining the meaning of the adjective and noun. 1 Introduction How humans represent meanings of individual words and how lexical semantic knowledge is combined to form complex concepts are issues fundamental to the study of human knowledge. There have been a variety of approaches from different scientific communities trying to characterize semantic representations. Linguists have tried to characterize the meaning of a word with feature-based approaches, such as semantic roles (Kipper et al., 2006), as well as word-relation approaches, such as WordNet (Miller, 1995). Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church &amp; Hanks, 1990). Psychologists have studied word meaning through feature-norming studies (Cree &amp; McRae, 2003) in which human participants are asked to list the features they associate with various words. There are also efforts to recover the latent semantic structure from text corpora using techniques such as LSA (Landauer &amp; Dumais, 1997) and topic models (Blei et al., 2003). Recent advances in functional Magnetic Resonanc</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>Miller, G. A. 1995. WordNet: A lexical database for English. Communications of the ACM 38, 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mitchell</author>
<author>M Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>Proceedings of ACL08: HLT,</booktitle>
<pages>236--244</pages>
<contexts>
<context position="4986" citStr="Mitchell and Lapata (2008)" startWordPosition="735" endWordPosition="738">ctive-noun phrases. In this study, we applied the vector-based models of semantic composition used in computational linguistics to model neural activation patterns obtained while subjects comprehended adjective-noun phrases. In an object-contemplation task, human participants were presented with 12 text labels of objects (e.g. dog) and were instructed to think of the same properties of the stimulus object consistently during multiple presentations of each item. The participants were also shown adjective-noun phrases, where adjectives were used to modify the meaning of nouns (e.g. strong dog). Mitchell and Lapata (2008) presented a framework for representing the meaning of phrases and sentences in vector space. They discussed how an additive model, a multiplicative model, a weighted additive model, a Kintsch (2001) model, and a model which combines multiplicative and additive models can be used to model human behavior in similiarity judgements when human participants were presented with a reference containing a subjectverb phrase (e.g., horse ran) and two landmarks (e.g., galloped and dissolved) and asked to choose which landmark was most similiar to the reference (in this case, galloped). They compared the </context>
<context position="18358" citStr="Mitchell and Lapata (2008)" startWordPosition="2817" endWordPosition="2820">onditional probabilities, p(t) E n(c, t) c p(c |t) = p(c, t) = n(c, t) p=C•u•v where all components are positive and sum to one. Table 3 shows the semantic representation for strong and dog. Notice that strong is heavily loaded on see and smell, whereas dog is heavily loaded on eat and see, consistent with the intuitive interpretation of these two words. See Hear Smell Eat Touch Strong 0.63 0.06 0.26 0.03 0.03 Dog 0.34 0.06 0.05 0.54 0.02 Table 3. The lexical semantic representation for strong and dog. 4.2 Semantic Composition We adopt the vector-based semantic composition models discussed in Mitchell and Lapata (2008). Let u and v denote the meaning of the adjective and noun, respectively, and let p denote the composition of the two words in vector space. We consider two non-composition models, the adjective model and the noun model, as well as two composition models, the additive model and the multplicative model. The adjective model assumes that the meaning of the composition is the same as the adjective: p= The noun model assumes that the meaning of the composition is the same as the noun: p= The adjective model and the noun model correspond to the assumption that when people comprehend phrases, they fo</context>
<context position="25403" citStr="Mitchell and Lapata (2008)" startWordPosition="3979" endWordPosition="3982">e importantly, the two hypotheses that we were testing were both verified. Notice Table 5 supports our hypothesis that the noun model should outperform the adjective model based on the assumption that the noun is generally more central to the phrase meaning than is the adjective. Table 5 also supports our hypothesis that the multiplicative model should outperform the additive model, based on the assumption that adjectives are used to emphasize particular semantic features that will already be represented in the semantic feature vector of the noun. Our findings here are largely consistent with Mitchell and Lapata (2008). R2 Racc Adjective 0.34 0.57 Noun 0.36 0.61 Additive 0.35 0.60 Multiplicative 0.42 0.62 Table 5. Regression fit and regression-based classification rank accuracy of the adjective, noun, additive, and multiplicative models for phrase stimuli. 643 Following Mitchell et al. (2008), the regression model can be used to decode mental states. Specifically, for each regression model, the estimated regression weights can be used to generate the predicted activity for each word. Then, a previously unseen neural activation vector is identified with the class of the predicted activation that had the high</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Mitchell, J., and Lapata, M. 2008. Vector-based models of semantic composition. Proceedings of ACL08: HLT, 236-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mitchell</author>
<author>R Hutchinson</author>
<author>R S Niculescu</author>
<author>F Pereira</author>
<author>X Wang</author>
<author>M A Just</author>
<author>S D Newman</author>
</authors>
<title>Learning to decode cognitive states from brain images.</title>
<date>2004</date>
<journal>Machine Learning</journal>
<volume>57</volume>
<pages>145--175</pages>
<contexts>
<context position="3282" citStr="Mitchell et al., 2004" startWordPosition="475" endWordPosition="478"> in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent multivariate analyses of fMRI activity have shown that classifiers can be trained to decode which of several visually presented objects or object categories a person is contemplating, given the person’s fMRImeasured neural activity (Cox and Savoy, 2003; O&apos;Toole et al., 2005; Haynes and Rees, 2006; Mitchell et al., 2004). Furthermore, Mitchell et al. (2008) showed that word features computed from the occurrences of stimulus words (within a trillion-token Google text corpus that captures the typical use of words in English text) can predict the brain activity associated with the 638 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP meaning of these words. They developed a generative model that is capable of predicting fMRI neural activity well enough that it can successfully match words it has not yet encou</context>
<context position="13298" citStr="Mitchell et al., 2004" startWordPosition="2023" endWordPosition="2026">relation between 24 item vectors across presentations. The focus on the most stable voxels effectively increased the signal-to-noise ratio in the data and facilitated further analysis by classifiers. Many of our previous analyses have indicated that 120 voxels is a set size suitable for our purposes. 640 Classification results were evaluated using 6- fold cross validation, where one of the 6 repetitions was left out for each fold. The voxel selection procedure was performed separately inside each fold, using only the training data. Since multiple classes were involved, rank accuracy was used (Mitchell et al., 2004) to evaluate the classifier. Given a new fMRI image to classify, the classifier outputs a rank-ordered list of possible class labels from most to least likely. The rank accuracy is defined as the percentile rank of the correct class in this ordered output list. Rank accuracy ranges from 0 to 1. Classification analysis was performed separately for each participant, and the mean rank accuracy was computed over the participants. 3.2 Results and Discussion Table 2 shows the results of the exemplar-level classification analysis. All classification accuracies were significantly higher than chance (p</context>
<context position="15425" citStr="Mitchell et al, 2004" startWordPosition="2349" endWordPosition="2352">ehicles. Classifier Racc All 24 exemplars 0.69 Nouns 0.71 Phrases 0.64 Animals 0.67 Tools 0.66 Vegetables 0.65 Vehicles 0.69 Table 2. Rank accuracies for classifiers. Distinct classifiers were trained to distinguish all 24 examples, nouns only, phrases only, and only words within each of the 4 semantic categories. High classification accuracies indicate that the distributed pattern of neural activity does encode sufficient signal to discriminate differences among stimuli. The classification accuracy for the nouns was on par with previous research, providing a replication of previous findings (Mitchell et al, 2004). The classifiers performed better on the nouns than the phrases, consistent with our expectation that characterizing phrases is more difficult than characterizing nouns in isolation. It is easier for participants to recall properties associated with a familiar object than to comprehend a noun whose meaning is further modified by an adjective. The classification analysis also helps us to identify participants whose mental representations for phrases are consistent across phrase presentations. Subsequent regression analysis on phrase activation will be based on subjects who perform the phrase t</context>
</contexts>
<marker>Mitchell, Hutchinson, Niculescu, Pereira, Wang, Just, Newman, 2004</marker>
<rawString>Mitchell, T., Hutchinson, R., Niculescu, R. S., Pereira, F., Wang, X., Just, M. A., and Newman, S. D. 2004. Learning to decode cognitive states from brain images. Machine Learning 57, 145-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mitchell</author>
<author>S V Shinkareva</author>
<author>A Carlson</author>
<author>K M Chang</author>
<author>V L Malave</author>
<author>R A Mason</author>
<author>M A Just</author>
</authors>
<title>Predicting human brain activity associated with the meanings of nouns.</title>
<date>2008</date>
<journal>Science</journal>
<volume>320</volume>
<pages>1191--1195</pages>
<contexts>
<context position="3319" citStr="Mitchell et al. (2008)" startWordPosition="480" endWordPosition="483"> related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent multivariate analyses of fMRI activity have shown that classifiers can be trained to decode which of several visually presented objects or object categories a person is contemplating, given the person’s fMRImeasured neural activity (Cox and Savoy, 2003; O&apos;Toole et al., 2005; Haynes and Rees, 2006; Mitchell et al., 2004). Furthermore, Mitchell et al. (2008) showed that word features computed from the occurrences of stimulus words (within a trillion-token Google text corpus that captures the typical use of words in English text) can predict the brain activity associated with the 638 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP meaning of these words. They developed a generative model that is capable of predicting fMRI neural activity well enough that it can successfully match words it has not yet encountered to their previously unseen fMR</context>
<context position="16412" citStr="Mitchell et al. (2008)" startWordPosition="2492" endWordPosition="2495">analysis also helps us to identify participants whose mental representations for phrases are consistent across phrase presentations. Subsequent regression analysis on phrase activation will be based on subjects who perform the phrase task well. 4 Using vector-based models of semantic representation to account for the systematic variances in neural activity 4.1 Lexical Semantic Representation Computational linguists have demonstrated that a word’s meaning is captured to some extent by the distribution of words and phrases with which it commonly co-occurs (Church and Hanks, 1990). Consequently, Mitchell et al. (2008) encoded the meaning of a word as a vector of intermediate semantic features computed from the co-occurrences with stimulus words within the Google trillion-token text corpus that captures the typical use of words in English text. Motivated by existing conjectures regarding the centrality of sensory-motor features in neural representations of objects (Caramazza and Shelton, 1998), they selected a set of 25 semantic features defined by 25 verbs: see, hear, listen, taste, smell, eat, touch, rub, lift, manipulate, run, push, fill, move, ride, say, fear, open, approach, near, enter, drive, wear, b</context>
<context position="24123" citStr="Mitchell et al., 2008" startWordPosition="3777" endWordPosition="3780"> the amount of systematic variance explained by the model. Regression results were evaluated using 6-fold cross validation, where one of the 6 repetitions was left out for each fold. Linear regression assumes a linear dependency among the variables and compares the variance due to the independent variables against the variance due to the residual errors. While the linearity assumption may be overly simplistic, it reflects the assumption that fMRI activity often reflects a superimposition of contributions from different sources, and has provided a useful first order approximation in the field (Mitchell et al., 2008). 4.4 Results and Discussion The second column of Table 5 shows the R2 regression fit (averaged across 120 voxels) of the adjective, noun, additive, and multiplicative model to the neural activity observed in adjective-noun phrase data. The noun model significantly (p &lt; 0.05) outperformed the adjective model, estimated with a paired t-test. Moreover, the difference between the additive and adjective models was not significant, whereas the difference between the additive and noun models was significant (p &lt; 0.05). The multiplicative model significantly (p &lt; 0.05) outperformed both of the non-co</context>
<context position="25682" citStr="Mitchell et al. (2008)" startWordPosition="4019" endWordPosition="4022">ble 5 also supports our hypothesis that the multiplicative model should outperform the additive model, based on the assumption that adjectives are used to emphasize particular semantic features that will already be represented in the semantic feature vector of the noun. Our findings here are largely consistent with Mitchell and Lapata (2008). R2 Racc Adjective 0.34 0.57 Noun 0.36 0.61 Additive 0.35 0.60 Multiplicative 0.42 0.62 Table 5. Regression fit and regression-based classification rank accuracy of the adjective, noun, additive, and multiplicative models for phrase stimuli. 643 Following Mitchell et al. (2008), the regression model can be used to decode mental states. Specifically, for each regression model, the estimated regression weights can be used to generate the predicted activity for each word. Then, a previously unseen neural activation vector is identified with the class of the predicted activation that had the highest correlation with the given observed neural activation vector. Notice that, unlike Mitchell et al. (2008), where the regression model was used to make predictions for items outside the training set, here we are just showing that the regression model can be used for classifica</context>
</contexts>
<marker>Mitchell, Shinkareva, Carlson, Chang, Malave, Mason, Just, 2008</marker>
<rawString>Mitchell, T., Shinkareva, S.V., Carlson, A., Chang, K.M., Malave, V.L., Mason, R.A., and Just, M.A. 2008. Predicting human brain activity associated with the meanings of nouns. Science 320, 1191-1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J O&apos;Toole</author>
<author>F Jiang</author>
<author>H Abdi</author>
<author>J V Haxby</author>
</authors>
<title>Partially distributed representations of objects and faces in ventral temporal cortex.</title>
<date>2005</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>17</volume>
<pages>580--590</pages>
<contexts>
<context position="3235" citStr="O&apos;Toole et al., 2005" startWordPosition="467" endWordPosition="470">RI measures the hemodynamic response (changes in blood flow and blood oxygenation) related to neural activity in the human brain. Images can be acquired at good spatial resolution and reasonable temporal resolution – the activity level of 15,000 - 20,000 brain volume elements (voxels) of about 50 mm3 each can be measured every 1 second. Recent multivariate analyses of fMRI activity have shown that classifiers can be trained to decode which of several visually presented objects or object categories a person is contemplating, given the person’s fMRImeasured neural activity (Cox and Savoy, 2003; O&apos;Toole et al., 2005; Haynes and Rees, 2006; Mitchell et al., 2004). Furthermore, Mitchell et al. (2008) showed that word features computed from the occurrences of stimulus words (within a trillion-token Google text corpus that captures the typical use of words in English text) can predict the brain activity associated with the 638 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 638–646, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP meaning of these words. They developed a generative model that is capable of predicting fMRI neural activity well enough that it ca</context>
</contexts>
<marker>O&apos;Toole, Jiang, Abdi, Haxby, 2005</marker>
<rawString>O&apos;Toole, A. J., Jiang, F., Abdi, H., and Haxby, J. V. 2005. Partially distributed representations of objects and faces in ventral temporal cortex. Journal of Cognitive Neuroscience, 17, 580-590.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>