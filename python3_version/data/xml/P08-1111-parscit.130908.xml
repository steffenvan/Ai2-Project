<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019663">
<title confidence="0.9994135">
Evaluating a Crosslinguistic Grammar Resource:
A Case Study of Wambaya
</title>
<author confidence="0.998617">
Emily M. Bender
</author>
<affiliation confidence="0.995058">
University of Washington
Department of Linguistics
</affiliation>
<address confidence="0.9765135">
Box 354340
Seattle WA 98195-4340
</address>
<email confidence="0.99953">
ebender@u.washington.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999729263157895">
This paper evaluates the LinGO Grammar Ma-
trix, a cross-linguistic resource for the de-
velopment of precision broad coverage gram-
mars, by applying it to the Australian language
Wambaya. Despite large typological differ-
ences between Wambaya and the languages
on which the development of the resource was
based, the Grammar Matrix is found to pro-
vide a significant jump-start in the creation of
the grammar for Wambaya: With less than 5.5
person-weeks of development, the Wambaya
grammar was able to assign correct seman-
tic representations to 76% of the sentences in
a naturally occurring text. While the work
on Wambaya identified some areas of refine-
ment for the Grammar Matrix, 59% of the
Matrix-provided types were invoked in the fi-
nal Wambaya grammar, and only 4% of the
Matrix-provided types required modification.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999934382978724">
Hand-built grammars are often dismissed as too ex-
pensive to build on the one hand, and too brittle
on the other. Nevertheless, they are key to various
NLP applications, including those benefiting from
deep natural language understanding (e.g., textual
inference (Bobrow et al., 2007)), generation of well-
formed output (e.g., natural language weather alert
systems (Lareau and Wanner, 2007)) or both (as in
machine translation (Oepen et al., 2007)). Of par-
ticular interest here are applications concerning en-
dangered languages: Endangered languages repre-
sent a case of minimal linguistic resources, typically
lacking even moderately-sized corpora, let alone
treebanks. In the best case, one finds well-crafted
descriptive grammars, bilingual dictionaries, and a
handful of translated texts. The methods of pre-
cision grammar engineering are well-suited to tak-
ing advantage of such resources. At the same time,
the applications of interest in the context of endan-
gered languages emphasize linguistic precision: im-
plemented grammars can be used to enrich existing
linguistic documentation, to build grammar check-
ers in the context of language standardization, and
to create software language tutors in the context of
language preservation efforts.
The LinGO Grammar Matrix (Bender et al., 2002;
Bender and Flickinger, 2005; Drellishak and Ben-
der, 2005) is a toolkit for reducing the cost of creat-
ing broad-coverage precision grammars by prepack-
aging both a cross-linguistic core grammar and a
series of libraries of analyses of cross-linguistically
variable phenomena, such as major-constituent word
order or question formation. The Grammar Ma-
trix was developed initially on the basis of broad-
coverage grammars for English (Flickinger, 2000)
and Japanese (Siegel and Bender, 2002), and has
since been extended and refined as it has been used
in the development of broad-coverage grammars for
Norwegian (Hellan and Haugereid, 2003), Modern
Greek (Kordoni and Neu, 2005), and Spanish (Ma-
rimon et al., 2007), as well as being applied to 42
other languages from a variety of language families
in a classroom context (Bender, 2007).
This paper aims to evaluate both the utility of the
Grammar Matrix in jump-starting precision gram-
mar development and the current state of its cross-
linguistic hypotheses through a case study of a
</bodyText>
<page confidence="0.965122">
977
</page>
<note confidence="0.716433">
Proceedings of ACL-08: HLT, pages 977–985,
</note>
<page confidence="0.538396">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999760769230769">
language typologically very different from any of
the languages above: the non-Pama-Nyungan Aus-
tralian language Wambaya (Nordlinger, 1998).
The remainder of this paper is structured as fol-
lows: §2 provides background on the Grammar Ma-
trix and Wambaya, and situates the project with re-
spect to related work. §3 presents the implemented
grammar of Wambaya, describes its development,
and evaluates it against unseen, naturally occurring
text. §4 uses the Wambaya grammar and its devel-
opment as one point of reference to measure the use-
fulness and cross-linguistic validity of the Grammar
Matrix. §5 provides further discussion.
</bodyText>
<sectionHeader confidence="0.99632" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.974106">
2.1 The LinGO Grammar Matrix
</subsectionHeader>
<bodyText confidence="0.99995027027027">
The LinGO Grammar Matrix is situated theoreti-
cally within Head-Driven Phrase Structure Gram-
mar (HPSG; Pollard and Sag, 1994), a lexicalist,
constraint-based framework. Grammars in HPSG
are expressed as a collection of typed feature struc-
tures which are arranged into a hierarchy such that
information shared across multiple lexical entries or
construction types is represented only on a single su-
pertype. The Matrix is written in the TDL (type de-
scription language) formalism, which is interpreted
by the LKB parser, generator, and grammar develop-
ment environment (Copestake, 2002). It is compati-
ble with the broader range of DELPH-IN tools, e.g.,
for machine translation (Lønning and Oepen, 2006),
treebanking (Oepen et al., 2004) and parse selection
(Toutanova et al., 2005).
The Grammar Matrix consists of a cross-
linguistic core type hierarchy and a collection of
phenomenon-specific libraries. The core type hierar-
chy defines the basic feature geometry, the ways that
heads combine with arguments and adjuncts, linking
types for relating syntactic to semantic arguments,
and the constraints required to compositionally build
up semantic representations in the format of Min-
imal Recursion Semantics (Copestake et al., 2005;
Flickinger and Bender, 2003). The libraries provide
collections of analyses for cross-linguistically vari-
able phenomena. The current libraries include anal-
yses of major constituent word order (SOV, SVO,
etc), sentential negation, coordination, and yes-no
question formation. The Matrix is accessed through
a web-based configuration system1 which elicits ty-
pological information from the user-linguist through
a questionnaire and then outputs a grammar consist-
ing of the Matrix core plus selected types and con-
straints from the libraries according to the specifica-
tions in the questionnaire.
</bodyText>
<subsectionHeader confidence="0.996338">
2.2 Wambaya
</subsectionHeader>
<bodyText confidence="0.999967869565217">
Wambaya is a recently extinct language of the West
Barkly family from the Northern Territory in Aus-
tralia (Nordlinger, 1998). Wambaya was selected
for this project because of its typological properties
and because it is extraordinarily well-documented
by Nordlinger in her 1998 descriptive grammar.
Perhaps the most striking feature of Wambaya is
its word order: it is a radically non-configurational
language with a second position auxiliary/clitic clus-
ter. That is, aside from the constraint that verbal
clauses require a clitic cluster (marking subject and
object agreement and tense, aspect and mood) in
second position, the word order is otherwise free, to
the point that noun phrases can be non-contiguous,
with head nouns and their modifiers separated by un-
related words. Furthermore, head nouns are gener-
ally not required: argument positions can be instan-
tiated by modifiers only, or, if the referent is clear
from the context, by no nominal constituent of any
kind. It has a rich system of case marking, and ad-
nominal modifiers agree with the heads they modify
in case, number, and four genders. An example is
given in (1) (Nordlinger, 1998, 223).2
</bodyText>
<equation confidence="0.969173">
(1) Ngaragana-nguja ngiy-a
grog-PROP.IV.ACC 3.SG.NM.A-PST
gujinganjanga-ni jiyawu ngabulu.
mother.II.ERG give milk.IV.ACC
</equation>
<bodyText confidence="0.91228375">
‘(His) mother gave (him) milk with grog in
it.’ [wmb]
In (1), ngaragana-nguja (‘grog-proprietive’, or
‘having grog’) is a modifier of ngabulu milk. They
agree in case (accusative) and gender (class IV), but
they are not contiguous within the sentence.
To relate such discontinuous noun phrases to ap-
propriate semantic representations where ‘having-
</bodyText>
<footnote confidence="0.99671225">
1http://www.delph-in.net/matrix/customize/matrix.cgi
2In this example, the glosses II, IV, and NM indicate gender
and ACC and ERG indicate case. A stands for ‘agent’, PST for
‘past’, and PROP for ‘proprietive’.
</footnote>
<page confidence="0.996901">
978
</page>
<bodyText confidence="0.99993912">
grog’ and ‘milk’ are predicated of the same entity re-
quires a departure from the ordinary way that heads
are combined with arguments and modifiers com-
bined with heads in HPSG in general and in the
Matrix in particular.3 In the Grammar Matrix, as
in most work in HPSG, lexical heads record the de-
pendents they require in valence lists (SUBJ, COMPS,
SPR). When a head combines with one of its ar-
guments, the result is a phrase with the same va-
lence requirements as the head daughter, minus the
one corresponding to the argument that was just sat-
isfied. In contrast, the project described here has
explored a non-cancellation analysis for Wambaya:
even after a head combines with one of its argu-
ments, that argument remains on the appropriate va-
lence list of the mother, so that it is visible for further
combination with modifiers. In addition, heads can
combine directly with modifiers of their arguments
(as opposed to just modifiers of themselves).
Argument realization and the combination of
heads and modifiers are fairly fundamental aspects
of the system implemented in the Matrix. In light
of the departure described above, it is interesting to
see to what extent the Matrix can still support rapid
development of a precision grammar for Wambaya.
</bodyText>
<subsectionHeader confidence="0.665416">
2.3 Related Work
</subsectionHeader>
<bodyText confidence="0.9998906875">
There are currently many multilingual grammar en-
gineering projects under active development, in-
cluding ParGram, (Butt et al., 2002; King et al.,
2005), the MetaGrammar project (Kinyon et al.,
2006), KPML (Bateman et al., 2005), Grammix
(M¨uller, 2007) and OpenCCG (Baldridge et al.,
2007). Among approaches to multilingual grammar
engineering, the Grammar Matrix’s distinguishing
characteristics include the deployment of a shared
core grammar for crosslinguistically consistent con-
straints and a series of libraries modeling vary-
ing linguistic properties. Thus while other work
has successfully exploited grammar porting between
typologically related languages (e.g., Kim et al.,
2003), to my knowledge, no other grammar port-
ing project has covered the same typological dis-
</bodyText>
<footnote confidence="0.7248006">
3A linearization-based analysis as suggested by Donohue
and Sag (1999) for discontinuous constituents in Warlpiri (an-
other Australian language), is not available, because it relies on
disassociating the constituent structure from the surface order of
words in a way that is not compatible with the TDL formalism.
</footnote>
<bodyText confidence="0.9997044">
tance attempted here. The current project is also
situated within a broader trend of using computa-
tional linguistics in the service of endangered lan-
guage documentation (e.g., Robinson et al., 2007,
see also www.emeld.org).
</bodyText>
<sectionHeader confidence="0.932228" genericHeader="method">
3 Wambaya grammar
</sectionHeader>
<subsectionHeader confidence="0.993171">
3.1 Development
</subsectionHeader>
<bodyText confidence="0.999986090909091">
The Wambaya grammar was developed on the basis
of the grammatical description in Nordlinger 1998,
including the Wambaya-English translation lexicon
and glosses of individual example sentences. The
development test suite consisted of all 794 distinct
positive examples from Ch. 3–8 of the descriptive
grammar. This includes elicited examples as well
as (sometimes simplified) naturally occurring exam-
ples. They range in length from one to thirteen
words (mean: 3.65). The test suite was extracted
from the descriptive grammar at the beginning of the
project and used throughout with only minor refine-
ments as errors in formatting were discovered. The
regression testing facilities of [incr tsdbo)] allowed
for rapid experimentation with alternative analyses
as new phenomena were brought into the grammar
(cf. Oepen et al., 2002).
With no prior knowledge of this language beyond
its most general typological properties, we were able
to develop in under 5.5 person-weeks of develop-
ment time (210 hours) a grammar able to assign ap-
propriate analyses to 91% of the examples in the de-
velopment set.4 The 210 hours include 25 hours of
an RA’s time entering lexical entries, 7 hours spent
preparing the development test suite, and 15 hours
treebanking (using the LinGO Redwoods software
(Oepen et al., 2004) to annotate the intended parse
for each item). The remainder of the time was ordi-
nary grammar development work.5
In addition, this grammar has relatively low am-
biguity, assigning on average 11.89 parses per item
in the development set. This reflects the fact that the
grammar is modeling grammaticality: the rules are
</bodyText>
<footnote confidence="0.9971165">
4An additional 6% received some analysis, but not one that
matched the translation given in the reference grammar.
5These numbers do not include the time put into the origi-
nal field work and descriptive grammar work. Nordlinger (p.c.)
estimates that as roughly 28 linguist-months, plus the native
speaker consultants’ time.
</footnote>
<page confidence="0.998001">
979
</page>
<bodyText confidence="0.993829">
meant to exclude ungrammatical strings as well as
are unwarranted analyses of grammatical strings.
</bodyText>
<subsectionHeader confidence="0.998503">
3.2 Scope
</subsectionHeader>
<bodyText confidence="0.99492">
The grammar encodes mutually interoperable anal-
yses of a wide variety of linguistic phenomena, in-
cluding:
</bodyText>
<listItem confidence="0.996474181818182">
• Word order: second position clitic cluster, other-
wise free word order, discontinuous noun phrases
• Argument optionality: argument positions with no
overt head
• Linking of syntactic to semantic arguments
• Case: case assignment by verbs to dependents
• Agreement: subject and object agreement in per-
son and number (and to some extent gender) marked
in the clitic cluster, agreement between nouns and
adnominal modifiers in case, number and gender
• Lexical adverbs, including manner, time, and loca-
tion, and adverbs of negation, which vary by clause
type (declarative, imperative, or interrogative)
• Derived event modifiers: nominals (nouns, adjec-
tives, noun phrases) used as event modifiers with
meaning dependent on their case marking
• Lexical adjectives, including demonstratives ad-
verbs, numerals, and possessive adjectives, as well
as ordinary intersective adjectives
• Derived nominal modifiers: modifiers of nouns de-
rived from nouns, adjectives and verbs, including the
proprietive, privative, and ‘origin’ constructions
• Subordinate clauses: clausal complements of
verbs like “tell” and “remember”, non-finite subor-
dinate clauses such as purposives (“in order to”) and
clauses expressing prior or simultaneous events
• Verbless clauses: nouns, adjectives, and adverbs,
lexical or derived, functioning as predicates
• Illocutionary force: imperatives, declaratives, and
interrogatives (including wh questions)
• Coordination: of clauses and noun phrases
• Other: inalienable possession, secondary predi-
cates, causatives of verbs and adjectives
</listItem>
<subsectionHeader confidence="0.999314">
3.3 Sample Analysis
</subsectionHeader>
<bodyText confidence="0.999989023809524">
This section provides a brief description of the anal-
ysis of radical non-configurationality in order to
give a sense of the linguistic detail encoded in the
Wambaya grammar and give context for the evalu-
ation of the Wambaya grammar and the Grammar
Matrix in later sections.
The linguistic analyses encoded in the grammar
serve to map the surface strings to semantic repre-
sentations (in Minimal Recursion Semantics (MRS)
format (Copestake et al., 2005)). The MRS in Fig-
ure 1 is assigned to the example in (1).6 It in-
cludes the basic propositional structure: a situation
of ‘giving’ in which the first argument, or agent, is
‘mother’, the second (recipient) is some third-person
entity, and the third (patient), is ‘milk’ which is also
related to ‘grog’ through the proprietive relation. It
is marked as past tense, and as potentially a state-
ment or a question, depending on the intonation.7,8
A simple tree display of the parse giving rise to
this MRS is given in Figure 2. The non-branching
nodes at the bottom of the tree represent the lexical
rules which associate morphosyntactic information
with a word according to its suffixes. The general
left-branching structure of the tree is a result of the
analysis of the second-position clitic cluster: The
clitic clusters are treated as argument-composition
auxiliaries, which combine with a lexical verb and
‘inherit’ all of the verb’s arguments. The auxiliaries
first pick up all dependents to the right, and then
combine with exactly one constituent to the left.
The grammar is able to connect x7 (the index of
‘milk’) to both the ARG3 position of the ‘give’ rela-
tion and the ARG1 position of the proprietive rela-
tion, despite the separation between ngaraganaguja
(‘grog-PROP.IV.ACC’) and ngabulu (‘milk.IV.ACC’)
in the surface structure, as follows: The auxiliary
ngiya is subject to the constraints in (2), meaning
that it combines with a verb as its first complement
and then the verb’s complements as its remaining
complements.9 The auxiliary can combine with its
complements in any order, thanks to a series of head-
complement rules which realize the nth element of
</bodyText>
<footnote confidence="0.932624571428571">
6The grammar in fact finds 42 parses for this example. The
one associated with the MRS in Figure 1 best matches the in-
tended interpretation as indicated by the gloss of the example.
7The relations are given English predicate names for the
convenience of the grammar developer, and these are not in-
tended as any kind of interlingua.
8This MRS is ‘fragmented’ in the sense that the labels of
several of the elementary predications (eps) are not related to
any argument position of any other ep. This is related to the
fact that the grammar doesn’t yet introduce quantifiers for any
of the nominal arguments.
9In this and other attribute value matrices displayed, feature
paths are abbreviated and detail not relevant to the current point
is suppressed.
</footnote>
<page confidence="0.916444">
980
</page>
<equation confidence="0.99273055">
LTOP h1
 INDEX e2 (prop-or-ques, past)
  
   give v rel
 proprietive a rel 
 *      
    LBL h1 
mother n rel   +
grog n rel LBL h5
   milk n rel
     
  ARG0 e2    
 RELS  LBL h3 ,  ARG0 e6  ,  LBL h8 ,  , LBL h5 
     
 ARG0 x4 (3, iv)  ARG1 x7 (3, iv)   
ARG1 x9
ARG0 x9 (3sg, ii)  ARG0 x7
  ARG2 x10 (3)  
 ARG2 x4 ARG3 x7
HCONS ( )
</equation>
<figureCaption confidence="0.995273">
Figure 1: MRS for (1)
</figureCaption>
<figure confidence="0.99171384">
V
V
N V N V N
N V N jiyawu ngabulu
Ngaraganaguja V N
V gujinganjangani
ngiya
V
ADJ
ADJ
ADJ
V
V
V
N
N
V:‘give’
 SUBJ ( 1 )
COMPS ( 2 , 3 )
INST +
,


*COMPS
(3) 
p

 
2 N
 
INDEX x10 
 CASE acc 
INST −
 
3 N:‘milk’
 INDEX x7 
 
, CASE acc 
INST +
hrase
HEAD verb [AUX +]
 
*1 N:‘mother’ +
 
SUBJ INDEX x9 
 CASE erg 
INST +

                
+          
</figure>
<figureCaption confidence="0.999846">
Figure 2: Phrase structure tree for (1)
</figureCaption>
<bodyText confidence="0.999702764705882">
the COMPS list. It this example, it first picks up
the subject gujinganjangani (‘mother-ERG’), then
the main verb jiyawu (‘give’), and then the object
ngabulu (‘milk-ACC’).
The resulting V node over ngiya gujinganjangani
jiyawu ngabulu is associated with the constraints
sketched in (3).
Unlike in typical HPSG approaches, the informa-
tion about the realized arguments is still exposed
in the COMPS and SUBJ lists of this constituent.10
This makes the necessary information available
to separately-attaching modifiers (such as ngara-
ganaguja (‘grog-PROP.IV.ACC’)) so that they can
check for case and number/gender compatibility and
connect the semantic index of the argument they
modify to a role in their own semantic contribution
(in this case, the ARG1 of the ‘proprietive’ relation).
</bodyText>
<subsectionHeader confidence="0.834304">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.999224">
The grammar was evaluated against a sample of nat-
urally occurring data taken from one of the texts
transcribed and translated by Nordlinger (1998)
(“The two Eaglehawks”, told by Molly Nurlanyma
Grueman). Of the 92 sentences in this text, 20 over-
lapped with items in the development set, so the
</bodyText>
<footnote confidence="0.9284455">
10The feature INST, newly proposed for this analysis, records
the fact that they have been instantiated by lexical heads.
</footnote>
<figure confidence="0.96790025">
(2) lexeme
 HEAD verb [AUX +]
 SUBJ ( 1 )
 / HEAD verb [AUX −]
COMPS ( SUBJ ( 1 ) +ED 2
\ COMPS 2


</figure>
<page confidence="0.980487">
981
</page>
<table confidence="0.970628">
correct parsed unparsed average
incorrect ambiguity
Existing 50% 8% 42% 10.62
vocab 76% 8% 14% 12.56
w/added
vocab
</table>
<tableCaption confidence="0.999964">
Table 1: Grammar performance on held-out data
</tableCaption>
<bodyText confidence="0.99981995">
evaluation was carried out only on the remaining
72 sentences. The evaluation was run twice: once
with the grammar exactly as is, including the exist-
ing lexicon, and a second time after new lexical en-
tries were added, using only existing lexical types.
In some cases, the orthographic components of the
lexical rules were also adjusted to accommodate the
new lexical entries. In both test runs, the analyses of
each test item were hand-checked against the trans-
lation provided by Nordlinger (1998). An item is
counted as correctly analyzed if the set of analyses
returned by the parser includes at least one with an
MRS that matches the dependency structure, illocu-
tionary force, tense, aspect, mood, person, number,
and gender information indicated.
The results are shown in Table 1: With only lexi-
cal additions, the grammar was able to assign a cor-
rect parse to 55 (76%) of the test sentences, with
an average ambiguity over these sentences of 12.56
parses/item.
</bodyText>
<subsectionHeader confidence="0.962315">
3.5 Parse selection
</subsectionHeader>
<bodyText confidence="0.999915217391305">
The parsed portion of the development set (732
items) constitutes a sufficiently large corpus to train
a parse selection model using the Redwoods disam-
biguation technology (Toutanova et al., 2005). As
part of the grammar development process, the parses
were annotated using the Redwoods parse selection
tool (Oepen et al., 2004). The resulting treebank
was used to select appropriate parameters by 10-fold
cross-validation, applying the experimentation envi-
ronment and feature templates of (Velldal, 2007).
The optimal feature set included 2-level grandpar-
enting, 3-grams of lexical entry types, and both con-
stituent weight features. In the cross-validation tri-
als on the development set, this model achieved a
parse selection accuracy of 80.2% (random choice
baseline: 23.9%). A model with the same features
was then trained on all 544 ambiguous examples
from the development set and used to rank the parses
of the test set. It ranked the correct parse (exact
match) highest in 75.0% of the test sentences. This
is well above the random-choice baseline of 18.4%,
and affirms the cross-linguistic validity of the parse-
selection techniques.
</bodyText>
<subsectionHeader confidence="0.969895">
3.6 Summary
</subsectionHeader>
<bodyText confidence="0.999668857142857">
This section has presented the Matrix-derived gram-
mar of Wambaya, illustrating its semantic represen-
tations and analyses and measuring its performance
against held-out data. I hope to have shown the
grammar to be reasonably substantial, and thus an
interesting case study with which to evaluate the
Grammar Matrix itself.
</bodyText>
<sectionHeader confidence="0.985319" genericHeader="evaluation">
4 Evaluation of Grammar Matrix
</sectionHeader>
<bodyText confidence="0.999971666666667">
It is not possible to directly compare the develop-
ment of a grammar for the same language, by the
same grammar engineer, with and without the assis-
tance of the Grammar Matrix. Therefore, in this sec-
tion, I evaluate the usefulness of the Grammar Ma-
trix by measuring the extent to which the Wambaya
grammar as developed makes use of types defined in
Matrix as well as the extent to which Matrix-defined
types had to be modified. The former is in some
sense a measure of the usefulness of the Matrix, and
the latter is a measure of its correctness.
While the libraries and customization system
were used in the initial grammar development, this
evaluation primarily concerns itself with the Matrix
core type hierarchy. The customization-provided
Wambaya-specific type definitions for word order,
lexical types, and coordination constructions were
used for inspiration, but most needed fairly exten-
sive modification. This is particularly unsurprising
for basic word order, where the closest available op-
tion (“free word order”) was taken, in the absence
of a pre-packaged analysis of non-configurationality
and second-position phenomena. The other changes
to the library output were largely side-effects of this
fundamental difference.
Table 2 presents some measurements of the over-
all size of the Wambaya grammar. Since HPSG
grammars consist of types organized into a hierarchy
and instances of those types, the unit of measure for
these evaluations will be types and/or instances. The
</bodyText>
<page confidence="0.990868">
982
</page>
<table confidence="0.999120625">
N
Matrix types 891
ordinary 390
pos disjunctions 591
Wambaya-specific types 911
Phrase structure rules 83
Lexical rules 161
Lexical entries 1528
</table>
<tableCaption confidence="0.977299">
Table 2: Size of Wambaya grammar
</tableCaption>
<table confidence="0.986526">
Matrix core types w/ POS types
Directly used 132 34% 136 15%
Indirectly used 98 25% 584 66%
Total types used 230 59% 720 81%
Types unused 160 41% 171 19%
Types modified 16 4% 16 2%
Total 390 100% 891 100%
</table>
<tableCaption confidence="0.999957">
Table 3: Matrix core types used in Wambaya grammar
</tableCaption>
<bodyText confidence="0.999963597402598">
Wambaya grammar includes 891 types defined in
the Matrix core type hierarchy. These in turn include
390 ordinary types, and 591 ‘disjunctive’ types, the
powerset of 9 part of speech types. These are pro-
vided in the Matrix so that Matrix users can easily
refer to classes of, say, “nouns and verbs” or “nouns
and verbs and adjectives”. The Wambaya-specific
portion of the grammar includes 911 types. These
types are invoked in the definitions of the phrase
structure rules, lexical rules, and lexical entries.
Including the disjunctive part-of-speech types,
just under half (49%) of the types in the grammar are
provided by the Matrix. However, it is necessary to
look more closely; just because a type is provided in
the Matrix core hierarchy doesn’t mean that it is in-
voked by any rules or lexical entries of the Wambaya
grammar. The breakdown of types used is given in
Table 3. Types that are used directly are either called
as supertypes for types defined in the Wambaya-
specific portion of the grammar, or used as the value
of some feature in a type constraint in the Wambaya-
specific portion of the grammar. Types that are used
indirectly are either ancestor types to types that are
used directly, or types that are used as the value of
a feature in a constraint in the Matrix core types
on a type that is used (directly or indirectly) by the
Wambaya-specific portion of the grammar.
Relatively few (16) of the Matrix-provided types
needed to be modified. These were types that
were useful, but somehow unsuitable, and typically
deeply interwoven into the type system, such that
not using and them and defining parallel types in
their place would be inconvenient.
Setting aside the types for part of speech disjunc-
tions, 59% of the Matrix-provided types are invoked
by the Wambaya-specific portion of the grammar.
While further development of the Wambaya gram-
mar might make use of some of the remaining 41%
of the types, this work suggests that there is a sub-
stantial amount of information in the Matrix core
type hierarchy which would better be stored as part
of the typological libraries. In particular, the analy-
ses of argument realization implemented in the Ma-
trix were not used for this grammar. The types
associated with argument realization in configura-
tional languages should be moved into the word-
order library, which should also be extended to in-
clude an analysis of Wambaya-style radical non-
configurationality. At the same time, the lexical
amalgamation analysis of the features used in long-
distance dependencies (Sag, 1997) was found to be
incompatible with the approach to argument realiza-
tion in Wambaya, and a phrasal amalgamation anal-
ysis was implemented instead. This again suggests
that lexical v. phrasal amalgamation should be en-
coded in the libraries, and selected according to the
word order pattern of the language.
As for parts of speech, of the nine types provided
by the Matrix, five were used in the Wambaya gram-
mar (verb, noun, adj, adv, and det) and four were not
(num, conj, comp, and adp(osition)). Four disjunc-
tive types were directly invoked, to describe phe-
nomena applying to nouns and adjectives, verbs and
adverbs, anything but nouns, and anything but de-
terminers. While it was convenient to have the dis-
junctive types predefined, it also seems that a much
smaller set of types would suffice in this case. Since
the nine proposed part of speech types have varying
crosslinguistic validity (e.g., not all languages have
conjunctions), it might be better to provide software
support for creating the disjunctive types as the need
arises, rather than predefining them.
Even though the number of Matrix-provided types
is small compared to the grammar as a whole, the
relatively short development time indicates that the
types that were incorporated were quite useful. In
providing the fundamental organization of the gram-
</bodyText>
<page confidence="0.997313">
983
</page>
<bodyText confidence="0.999859157894737">
mar, to the extent that that organization is consistent
with the language modeled, these types significantly
ease the path to creating a working grammar.
The short development time required to create the
Wambaya grammar presents a qualitative evaluation
of the Grammar Matrix as a crosslinguistic resource,
as one goal of the Grammar Matrix is to reduce the
cost of developing precision grammars. The fact
that a grammar capable of assigning valid analy-
ses to an interesting portion of sentences from natu-
rally occurring text could be developed in less than
5.5 person-weeks of effort suggests that this goal
is indeed met. This is particularly encouraging in
the case of endangered and other resource-poor lan-
guages. A grammar such as the one described here
could be a significant aide in analyzing additional
texts as they are collected, and in identifying con-
structions that have not yet been analyzed (cf. Bald-
win et al, 2005).
</bodyText>
<sectionHeader confidence="0.998834" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999988233333333">
This paper has presented a precision, hand-built
grammar for the Australian language Wambaya, and
through that grammar a case study evaluation of
the LinGO Grammar Matrix. True validation of
the Matrix qua hypothesized linguistic universals re-
quires many more such case studies, but this first
test is promising. Even though Wambaya is in some
respects very different from the well-studied lan-
guages on which the Matrix is based, the existing
machinery otherwise worked quite well, providing a
significant jump-start to the grammar development
process. While the Wambaya grammar has a long
way to go to reach the complexity and range of
linguistic phenomena handled by, for example, the
LinGO English Resource Grammar, it was shown to
provide analyses of an interesting portion of a natu-
rally occurring text. This suggests that the method-
ology of building such grammars could be profitably
incorporated into language documentation efforts.
The Grammar Matrix allows new grammars to di-
rectly leverage the expertise in grammar engineering
gained in extensive work on previous grammars of
better-studied languages. Furthermore, the design
of the Matrix is such that it is not a static object,
but intended to evolve and be refined as more lan-
guages are brought into its purview. Generalizing
the core hierarchy and libraries of the Matrix to sup-
port languages like Wambaya can extend its typo-
logical reach and further its development as an in-
vestigation in computational linguistic typology.
</bodyText>
<sectionHeader confidence="0.995492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.975121111111111">
I would like to thank Rachel Nordlinger for pro-
viding access to the data used in this work in elec-
tronic form, as well as for answering questions about
Wambaya; Russ Hugo for data entry of the lexicon;
Stephan Oepen for assistance with the parse ranking
experiments; and Scott Drellishak, Stephan Oepen,
and Laurie Poulson for general discussion. This ma-
terial is based upon work supported by the National
Science Foundation under Grant No. BCS-0644097.
</bodyText>
<sectionHeader confidence="0.998907" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999466727272727">
J. Baldridge, S. Chatterjee, A. Palmer, and B. Wing.
2007. DotCCG and VisCCG: Wiki and programming
paradigms for improved grammar engineering with
OpenCCG. In T.H. King and E.M. Bender, editors,
GEAF 2007, Stanford, CA. CSLI.
T. Baldwin, J. Beavers, E.M. Bender, D. Flickinger, Ara
Kim, and S. Oepen. 2005. Beauty and the beast: What
running a broad-coverage precision grammar over the
BNC taught us about the grammar — and the corpus.
In S. Kepser and M. Reis, editors, Linguistic Evidence:
Empirical, Theoretical, and Computational Perspec-
tives, pages 49–70. Mouton de Gruyter, Berlin.
J.A. Bateman, I. Kruijff-Korbayov´a, and G.-J. Kruijff.
2005. Multilingual resource sharing across both re-
lated and unrelated languages: An implemented, open-
source framework for practical natural language gen-
eration. Research on Language and Computation,
3(2):191–219.
E.M. Bender and D. Flickinger. 2005. Rapid prototyping
of scalable grammars: Towards modularity in exten-
sions to a language-independent core. In IJCNLP-05
(Posters/Demos), Jeju Island, Korea.
E.M. Bender, D. Flickinger, and S. Oepen. 2002. The
grammar matrix: An open-source starter-kit for the
rapid development of cross-linguistically consistent
broad-coverage precision grammars. In J. Carroll,
N. Oostdijk, and R. Sutcliffe, editors, Proceedings of
the Workshop on Grammar Engineering and Evalua-
tion, COLING 19, pages 8–14, Taipei, Taiwan.
E.M. Bender. 2007. Combining research and pedagogy
in the development of a crosslinguistic grammar re-
source. In T.H. King and E.M. Bender, editors, GEAF
2007, Stanford, CA. CSLI.
</reference>
<page confidence="0.993613">
984
</page>
<reference confidence="0.99922341509434">
D.G. Bobrow, C. Condoravdi, R.S. Crouch, V. de Paiva,
L. Karttunen, T.H. King, R. Nairn, L. Price, and A Za-
enen. 2007. Precision-focused textual inference. In
ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, Prague, Czech Republic.
M. Butt, H. Dyvik, T.H. King, H. Masuichi, and
C. Rohrer. 2002. The parallel grammar project. In
J. Carroll, N. Oostdijk, and R. Sutcliffe, editors, Pro-
ceedings of the Workshop on Grammar Engineering
and Evaluation at COLING 19, pages 1–7.
A. Copestake, D. Flickinger, C. Pollard, and I.A. Sag.
2005. Minimal recursion semantics: An introduction.
Research on Language &amp; Computation, 3(2–3):281–
332.
A. Copestake. 2002. Implementing Typed Feature Struc-
ture Grammars. CSLI, Stanford, CA.
C. Donohue and I.A. Sag. 1999. Domains in Warlpiri.
Paper presented at HPSG 99, University of Edinburgh.
S. Drellishak and E.M. Bender. 2005. A coordination
module for a crosslinguistic grammar resource. In Ste-
fan M¨uller, editor, HPSG 2005, pages 108–128, Stan-
ford. CSLI.
D. Flickinger and E.M. Bender. 2003. Compositional se-
mantics in a multilingual grammar resource. In E.M.
Bender, D. Flickinger, F. Fouvry, and M. Siegel, edi-
tors, Proceedings of the Workshop on Ideas and Strate-
gies for Multilingual Grammar Development, ESSLLI
2003, pages 33–42, Vienna, Austria.
D. Flickinger. 2000. On building a more efficient gram-
mar by exploiting types. Natural Language Engineer-
ing, 6 (1):15–28.
L. Hellan and P. Haugereid. 2003. NorSource: An ex-
ercise in Matrix grammar-building design. In E.M.
Bender, D. Flickinger, F. Fouvry, and M. Siegel, edi-
tors, Proceedings of the Workshop on Ideas and Strate-
gies for Multilingual Grammar Development, ESSLLI
2003, pages 41–48, Vienna, Austria.
R. Kim, M. Dalrymple, R.M. Kaplan, T.H. King, H. Ma-
suichi, and T. Ohkuma. 2003. Multilingual grammar
development via grammar porting. In E.M. Bender,
D. Flickinger, F. Fouvry, and M. Siegel, editors, Pro-
ceedings of the Workshop on Ideas and Strategies for
Multilingual Grammar Development, ESSLLI 2003,
pages 49–56, Vienna, Austria.
T.H. King, M. Forst, J. Kuhn, and M. Butt. 2005. The
feature space in parallel grammar writing. Research
on Language and Computation, 3(2):139–163.
A. Kinyon, O. Rambow, T. Scheffler, S.W. Yoon, and
A.K. Joshi. 2006. The metagrammar goes multilin-
gual: A cross-linguistic look at the V2-phenomenon.
In TAG+8, Sydney, Australia.
V. Kordoni and J. Neu. 2005. Deep analysis of Modern
Greek. In K-Y Su, J. Tsujii, and J-H Lee, editors, Lec-
ture Notes in Computer Science, volume 3248, pages
674–683. Springer-Verlag, Berlin.
F. Lareau and L. Wanner. 2007. Towards a generic
multilingual dependency grammar for text generation.
In T.H. King and E.M. Bender, editors, GEAF 2007,
pages 203–223, Stanford, CA. CSLI.
J.T. Lønning and S. Oepen. 2006. Re-usable tools for
precision machine translation. In COLINGJACL 2006
Interactive Presentation Sessions, pages 53 – 56, Syd-
ney, Australia.
M. Marimon, N. Bel, and N. Seghezzi. 2007. Test-suite
construction for a Spanish grammar. In T.H. King
and E.M. Bender, editors, GEAF 2007, Stanford, CA.
CSLI.
Stefan M¨uller. 2007. The Grammix CD-ROM: A soft-
ware collection for developing typed feature structure
grammars. In T.H. King and E.M. Bender, editors,
GEAF 2007, Stanford, CA. CSLI.
R. Nordlinger. 1998. A Grammar of Wambaya, Northern
Australia. Research School of Pacific and Asian Stud-
ies, The Australian National University, Canberra.
S. Oepen, E.M. Bender, U. Callmeier, D. Flickinger, and
M. Siegel. 2002. Parallel distributed grammar engi-
neering for practical applications. In Proceedings of
the Workshop on Grammar Engineering and Evalua-
tion, COLING 19, Taipei, Taiwan.
S. Oepen, D. Flickinger, K. Toutanova, and C.D. Man-
ning. 2004. LinGO Redwoods. A rich and dynamic
treebank for HPSG. Journal ofResearch on Language
and Computation, 2(4):575 – 596.
Stephan Oepen, Erik Velldal, Jan Tore Lnning, Paul
Meurer, Victoria Rosn, and Dan Flickinger. 2007.
Towards hybrid quality-oriented machine translation.
On linguistics and probabilities in MT. In TMI 2007,
Skvde, Sweden.
C. Pollard and I.A. Sag. 1994. Head-Driven Phrase
Structure Grammar. CSLI, Stanford, CA.
S. Robinson, G. Aumann, and S. Bird. 2007. Managing
fieldwork data with Toolbox and the Natural Language
Toolkit. Language Documentation and Conservation,
1:44–57.
I.A. Sag. 1997. English relative clause constructions.
Journal ofLinguistics, 33(2):431–484.
M. Siegel and E.M. Bender. 2002. Efficient deep pro-
cessing of Japanese. In Proceedings of the 3rd Work-
shop on Asian Language Resources and International
Standardization, COLING 19, Taipei, Taiwan.
K. Toutanova, C.D. Manning, D. Flickinger, and
S. Oepen. 2005. Stochastic HPSG parse selection
using the Redwoods corpus. Journal of Research on
Language and Computation, 3(1):83–105.
E. Velldal. 2007. Empirical Realization Ranking. Ph.D.
thesis, University of Oslo, Department of Informatics.
</reference>
<page confidence="0.998729">
985
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.852483">
<title confidence="0.997883">Evaluating a Crosslinguistic Grammar Resource: A Case Study of Wambaya</title>
<author confidence="0.999996">Emily M Bender</author>
<affiliation confidence="0.9999215">University of Washington Department of Linguistics</affiliation>
<address confidence="0.999104">Box 354340 Seattle WA 98195-4340</address>
<email confidence="0.999783">ebender@u.washington.edu</email>
<abstract confidence="0.986648">This paper evaluates the LinGO Grammar Matrix, a cross-linguistic resource for the development of precision broad coverage grammars, by applying it to the Australian language Wambaya. Despite large typological differences between Wambaya and the languages on which the development of the resource was based, the Grammar Matrix is found to provide a significant jump-start in the creation of the grammar for Wambaya: With less than 5.5 person-weeks of development, the Wambaya grammar was able to assign correct semantic representations to 76% of the sentences in a naturally occurring text. While the work on Wambaya identified some areas of refinement for the Grammar Matrix, 59% of the Matrix-provided types were invoked in the final Wambaya grammar, and only 4% of the Matrix-provided types required modification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Baldridge</author>
<author>S Chatterjee</author>
<author>A Palmer</author>
<author>B Wing</author>
</authors>
<title>DotCCG and VisCCG: Wiki and programming paradigms for improved grammar engineering with OpenCCG.</title>
<date>2007</date>
<booktitle>GEAF 2007,</booktitle>
<editor>In T.H. King and E.M. Bender, editors,</editor>
<publisher>CSLI.</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="9382" citStr="Baldridge et al., 2007" startWordPosition="1442" endWordPosition="1445">of themselves). Argument realization and the combination of heads and modifiers are fairly fundamental aspects of the system implemented in the Matrix. In light of the departure described above, it is interesting to see to what extent the Matrix can still support rapid development of a precision grammar for Wambaya. 2.3 Related Work There are currently many multilingual grammar engineering projects under active development, including ParGram, (Butt et al., 2002; King et al., 2005), the MetaGrammar project (Kinyon et al., 2006), KPML (Bateman et al., 2005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered the same typological dis3A linearization-based analysis as suggested by Donohue and Sag (1999) for discontinuous constituents in Warlpiri </context>
</contexts>
<marker>Baldridge, Chatterjee, Palmer, Wing, 2007</marker>
<rawString>J. Baldridge, S. Chatterjee, A. Palmer, and B. Wing. 2007. DotCCG and VisCCG: Wiki and programming paradigms for improved grammar engineering with OpenCCG. In T.H. King and E.M. Bender, editors, GEAF 2007, Stanford, CA. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>J Beavers</author>
<author>E M Bender</author>
<author>D Flickinger</author>
<author>Ara Kim</author>
<author>S Oepen</author>
</authors>
<title>Beauty and the beast: What running a broad-coverage precision grammar over the BNC taught us about the grammar — and the corpus.</title>
<date>2005</date>
<booktitle>Linguistic Evidence: Empirical, Theoretical, and Computational Perspectives,</booktitle>
<pages>49--70</pages>
<editor>In S. Kepser and M. Reis, editors,</editor>
<location>Berlin.</location>
<contexts>
<context position="28663" citStr="Baldwin et al, 2005" startWordPosition="4661" endWordPosition="4665">one goal of the Grammar Matrix is to reduce the cost of developing precision grammars. The fact that a grammar capable of assigning valid analyses to an interesting portion of sentences from naturally occurring text could be developed in less than 5.5 person-weeks of effort suggests that this goal is indeed met. This is particularly encouraging in the case of endangered and other resource-poor languages. A grammar such as the one described here could be a significant aide in analyzing additional texts as they are collected, and in identifying constructions that have not yet been analyzed (cf. Baldwin et al, 2005). 5 Conclusion This paper has presented a precision, hand-built grammar for the Australian language Wambaya, and through that grammar a case study evaluation of the LinGO Grammar Matrix. True validation of the Matrix qua hypothesized linguistic universals requires many more such case studies, but this first test is promising. Even though Wambaya is in some respects very different from the well-studied languages on which the Matrix is based, the existing machinery otherwise worked quite well, providing a significant jump-start to the grammar development process. While the Wambaya grammar has a </context>
</contexts>
<marker>Baldwin, Beavers, Bender, Flickinger, Kim, Oepen, 2005</marker>
<rawString>T. Baldwin, J. Beavers, E.M. Bender, D. Flickinger, Ara Kim, and S. Oepen. 2005. Beauty and the beast: What running a broad-coverage precision grammar over the BNC taught us about the grammar — and the corpus. In S. Kepser and M. Reis, editors, Linguistic Evidence: Empirical, Theoretical, and Computational Perspectives, pages 49–70. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
<author>I Kruijff-Korbayov´a</author>
<author>G-J Kruijff</author>
</authors>
<title>Multilingual resource sharing across both related and unrelated languages: An implemented, opensource framework for practical natural language generation.</title>
<date>2005</date>
<journal>Research on Language and Computation,</journal>
<volume>3</volume>
<issue>2</issue>
<marker>Bateman, Kruijff-Korbayov´a, Kruijff, 2005</marker>
<rawString>J.A. Bateman, I. Kruijff-Korbayov´a, and G.-J. Kruijff. 2005. Multilingual resource sharing across both related and unrelated languages: An implemented, opensource framework for practical natural language generation. Research on Language and Computation, 3(2):191–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Bender</author>
<author>D Flickinger</author>
</authors>
<title>Rapid prototyping of scalable grammars: Towards modularity in extensions to a language-independent core.</title>
<date>2005</date>
<booktitle>In IJCNLP-05 (Posters/Demos),</booktitle>
<location>Jeju Island,</location>
<contexts>
<context position="2355" citStr="Bender and Flickinger, 2005" startWordPosition="352" endWordPosition="355">inds well-crafted descriptive grammars, bilingual dictionaries, and a handful of translated texts. The methods of precision grammar engineering are well-suited to taking advantage of such resources. At the same time, the applications of interest in the context of endangered languages emphasize linguistic precision: implemented grammars can be used to enrich existing linguistic documentation, to build grammar checkers in the context of language standardization, and to create software language tutors in the context of language preservation efforts. The LinGO Grammar Matrix (Bender et al., 2002; Bender and Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugerei</context>
</contexts>
<marker>Bender, Flickinger, 2005</marker>
<rawString>E.M. Bender and D. Flickinger. 2005. Rapid prototyping of scalable grammars: Towards modularity in extensions to a language-independent core. In IJCNLP-05 (Posters/Demos), Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Bender</author>
<author>D Flickinger</author>
<author>S Oepen</author>
</authors>
<title>The grammar matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars.</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 19,</booktitle>
<pages>8--14</pages>
<editor>In J. Carroll, N. Oostdijk, and R. Sutcliffe, editors,</editor>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2326" citStr="Bender et al., 2002" startWordPosition="348" endWordPosition="351"> the best case, one finds well-crafted descriptive grammars, bilingual dictionaries, and a handful of translated texts. The methods of precision grammar engineering are well-suited to taking advantage of such resources. At the same time, the applications of interest in the context of endangered languages emphasize linguistic precision: implemented grammars can be used to enrich existing linguistic documentation, to build grammar checkers in the context of language standardization, and to create software language tutors in the context of language preservation efforts. The LinGO Grammar Matrix (Bender et al., 2002; Bender and Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for N</context>
</contexts>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>E.M. Bender, D. Flickinger, and S. Oepen. 2002. The grammar matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars. In J. Carroll, N. Oostdijk, and R. Sutcliffe, editors, Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 19, pages 8–14, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Bender</author>
</authors>
<title>Combining research and pedagogy in the development of a crosslinguistic grammar resource.</title>
<date>2007</date>
<booktitle>GEAF 2007,</booktitle>
<editor>In T.H. King and E.M. Bender, editors,</editor>
<publisher>CSLI.</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="3159" citStr="Bender, 2007" startWordPosition="481" endWordPosition="482">of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics language typologically very different from any of the languages above: the non-Pama-Nyungan Australian language Wambaya (Nordlinger, 1998). The remainder of this paper is structured as follows: §2 provides background on the Grammar Matrix and Wambaya, and situates the proje</context>
</contexts>
<marker>Bender, 2007</marker>
<rawString>E.M. Bender. 2007. Combining research and pedagogy in the development of a crosslinguistic grammar resource. In T.H. King and E.M. Bender, editors, GEAF 2007, Stanford, CA. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>C Condoravdi</author>
<author>R S Crouch</author>
<author>V de Paiva</author>
<author>L Karttunen</author>
<author>T H King</author>
<author>R Nairn</author>
<author>L Price</author>
<author>A Zaenen</author>
</authors>
<title>Precision-focused textual inference.</title>
<date>2007</date>
<booktitle>In ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Bobrow, Condoravdi, Crouch, de Paiva, Karttunen, King, Nairn, Price, Zaenen, 2007</marker>
<rawString>D.G. Bobrow, C. Condoravdi, R.S. Crouch, V. de Paiva, L. Karttunen, T.H. King, R. Nairn, L. Price, and A Zaenen. 2007. Precision-focused textual inference. In ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
<author>H Dyvik</author>
<author>T H King</author>
<author>H Masuichi</author>
<author>C Rohrer</author>
</authors>
<title>The parallel grammar project.</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on Grammar Engineering and Evaluation at COLING 19,</booktitle>
<pages>1--7</pages>
<editor>In J. Carroll, N. Oostdijk, and R. Sutcliffe, editors,</editor>
<contexts>
<context position="9224" citStr="Butt et al., 2002" startWordPosition="1417" endWordPosition="1420">visible for further combination with modifiers. In addition, heads can combine directly with modifiers of their arguments (as opposed to just modifiers of themselves). Argument realization and the combination of heads and modifiers are fairly fundamental aspects of the system implemented in the Matrix. In light of the departure described above, it is interesting to see to what extent the Matrix can still support rapid development of a precision grammar for Wambaya. 2.3 Related Work There are currently many multilingual grammar engineering projects under active development, including ParGram, (Butt et al., 2002; King et al., 2005), the MetaGrammar project (Kinyon et al., 2006), KPML (Bateman et al., 2005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting </context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>M. Butt, H. Dyvik, T.H. King, H. Masuichi, and C. Rohrer. 2002. The parallel grammar project. In J. Carroll, N. Oostdijk, and R. Sutcliffe, editors, Proceedings of the Workshop on Grammar Engineering and Evaluation at COLING 19, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Minimal recursion semantics: An introduction.</title>
<date>2005</date>
<journal>Research on Language &amp; Computation,</journal>
<volume>3</volume>
<issue>2</issue>
<pages>332</pages>
<contexts>
<context position="5378" citStr="Copestake et al., 2005" startWordPosition="817" endWordPosition="820">h the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal Recursion Semantics (Copestake et al., 2005; Flickinger and Bender, 2003). The libraries provide collections of analyses for cross-linguistically variable phenomena. The current libraries include analyses of major constituent word order (SOV, SVO, etc), sentential negation, coordination, and yes-no question formation. The Matrix is accessed through a web-based configuration system1 which elicits typological information from the user-linguist through a questionnaire and then outputs a grammar consisting of the Matrix core plus selected types and constraints from the libraries according to the specifications in the questionnaire. 2.2 Wam</context>
<context position="14629" citStr="Copestake et al., 2005" startWordPosition="2232" endWordPosition="2235">ing wh questions) • Coordination: of clauses and noun phrases • Other: inalienable possession, secondary predicates, causatives of verbs and adjectives 3.3 Sample Analysis This section provides a brief description of the analysis of radical non-configurationality in order to give a sense of the linguistic detail encoded in the Wambaya grammar and give context for the evaluation of the Wambaya grammar and the Grammar Matrix in later sections. The linguistic analyses encoded in the grammar serve to map the surface strings to semantic representations (in Minimal Recursion Semantics (MRS) format (Copestake et al., 2005)). The MRS in Figure 1 is assigned to the example in (1).6 It includes the basic propositional structure: a situation of ‘giving’ in which the first argument, or agent, is ‘mother’, the second (recipient) is some third-person entity, and the third (patient), is ‘milk’ which is also related to ‘grog’ through the proprietive relation. It is marked as past tense, and as potentially a statement or a question, depending on the intonation.7,8 A simple tree display of the parse giving rise to this MRS is given in Figure 2. The non-branching nodes at the bottom of the tree represent the lexical rules </context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>A. Copestake, D. Flickinger, C. Pollard, and I.A. Sag. 2005. Minimal recursion semantics: An introduction. Research on Language &amp; Computation, 3(2–3):281– 332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<location>CSLI, Stanford, CA.</location>
<contexts>
<context position="4734" citStr="Copestake, 2002" startWordPosition="722" endWordPosition="723">round 2.1 The LinGO Grammar Matrix The LinGO Grammar Matrix is situated theoretically within Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994), a lexicalist, constraint-based framework. Grammars in HPSG are expressed as a collection of typed feature structures which are arranged into a hierarchy such that information shared across multiple lexical entries or construction types is represented only on a single supertype. The Matrix is written in the TDL (type description language) formalism, which is interpreted by the LKB parser, generator, and grammar development environment (Copestake, 2002). It is compatible with the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>A. Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Donohue</author>
<author>I A Sag</author>
</authors>
<date>1999</date>
<institution>University of Edinburgh.</institution>
<note>Domains in Warlpiri. Paper presented at HPSG 99,</note>
<contexts>
<context position="9938" citStr="Donohue and Sag (1999)" startWordPosition="1519" endWordPosition="1522">005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered the same typological dis3A linearization-based analysis as suggested by Donohue and Sag (1999) for discontinuous constituents in Warlpiri (another Australian language), is not available, because it relies on disassociating the constituent structure from the surface order of words in a way that is not compatible with the TDL formalism. tance attempted here. The current project is also situated within a broader trend of using computational linguistics in the service of endangered language documentation (e.g., Robinson et al., 2007, see also www.emeld.org). 3 Wambaya grammar 3.1 Development The Wambaya grammar was developed on the basis of the grammatical description in Nordlinger 1998, i</context>
</contexts>
<marker>Donohue, Sag, 1999</marker>
<rawString>C. Donohue and I.A. Sag. 1999. Domains in Warlpiri. Paper presented at HPSG 99, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Drellishak</author>
<author>E M Bender</author>
</authors>
<title>A coordination module for a crosslinguistic grammar resource.</title>
<date>2005</date>
<pages>108--128</pages>
<editor>In Stefan M¨uller, editor, HPSG</editor>
<publisher>CSLI.</publisher>
<location>Stanford.</location>
<contexts>
<context position="2385" citStr="Drellishak and Bender, 2005" startWordPosition="356" endWordPosition="360"> grammars, bilingual dictionaries, and a handful of translated texts. The methods of precision grammar engineering are well-suited to taking advantage of such resources. At the same time, the applications of interest in the context of endangered languages emphasize linguistic precision: implemented grammars can be used to enrich existing linguistic documentation, to build grammar checkers in the context of language standardization, and to create software language tutors in the context of language preservation efforts. The LinGO Grammar Matrix (Bender et al., 2002; Bender and Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordon</context>
</contexts>
<marker>Drellishak, Bender, 2005</marker>
<rawString>S. Drellishak and E.M. Bender. 2005. A coordination module for a crosslinguistic grammar resource. In Stefan M¨uller, editor, HPSG 2005, pages 108–128, Stanford. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
<author>E M Bender</author>
</authors>
<title>Compositional semantics in a multilingual grammar resource.</title>
<date>2003</date>
<booktitle>Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003,</booktitle>
<pages>33--42</pages>
<editor>In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors,</editor>
<location>Vienna, Austria.</location>
<contexts>
<context position="5408" citStr="Flickinger and Bender, 2003" startWordPosition="821" endWordPosition="824">ELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal Recursion Semantics (Copestake et al., 2005; Flickinger and Bender, 2003). The libraries provide collections of analyses for cross-linguistically variable phenomena. The current libraries include analyses of major constituent word order (SOV, SVO, etc), sentential negation, coordination, and yes-no question formation. The Matrix is accessed through a web-based configuration system1 which elicits typological information from the user-linguist through a questionnaire and then outputs a grammar consisting of the Matrix core plus selected types and constraints from the libraries according to the specifications in the questionnaire. 2.2 Wambaya Wambaya is a recently ext</context>
</contexts>
<marker>Flickinger, Bender, 2003</marker>
<rawString>D. Flickinger and E.M. Bender. 2003. Compositional semantics in a multilingual grammar resource. In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors, Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003, pages 33–42, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<pages>1--15</pages>
<contexts>
<context position="2774" citStr="Flickinger, 2000" startWordPosition="417" endWordPosition="418">ontext of language standardization, and to create software language tutors in the context of language preservation efforts. The LinGO Grammar Matrix (Bender et al., 2002; Bender and Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings o</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>D. Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6 (1):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hellan</author>
<author>P Haugereid</author>
</authors>
<title>NorSource: An exercise in Matrix grammar-building design.</title>
<date>2003</date>
<booktitle>Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003,</booktitle>
<pages>41--48</pages>
<editor>In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors,</editor>
<location>Vienna, Austria.</location>
<contexts>
<context position="2963" citStr="Hellan and Haugereid, 2003" startWordPosition="445" endWordPosition="448">nd Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics language typologically very different from any of the languages above: the non</context>
</contexts>
<marker>Hellan, Haugereid, 2003</marker>
<rawString>L. Hellan and P. Haugereid. 2003. NorSource: An exercise in Matrix grammar-building design. In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors, Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003, pages 41–48, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kim</author>
<author>M Dalrymple</author>
<author>R M Kaplan</author>
<author>T H King</author>
<author>H Masuichi</author>
<author>T Ohkuma</author>
</authors>
<title>Multilingual grammar development via grammar porting.</title>
<date>2003</date>
<booktitle>Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003,</booktitle>
<pages>49--56</pages>
<editor>In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors,</editor>
<location>Vienna, Austria.</location>
<contexts>
<context position="9780" citStr="Kim et al., 2003" startWordPosition="1494" endWordPosition="1497">der active development, including ParGram, (Butt et al., 2002; King et al., 2005), the MetaGrammar project (Kinyon et al., 2006), KPML (Bateman et al., 2005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered the same typological dis3A linearization-based analysis as suggested by Donohue and Sag (1999) for discontinuous constituents in Warlpiri (another Australian language), is not available, because it relies on disassociating the constituent structure from the surface order of words in a way that is not compatible with the TDL formalism. tance attempted here. The current project is also situated within a broader trend of using computational linguistics in the service of endangered language documentation (e.g., Robinson et al., 2007, </context>
</contexts>
<marker>Kim, Dalrymple, Kaplan, King, Masuichi, Ohkuma, 2003</marker>
<rawString>R. Kim, M. Dalrymple, R.M. Kaplan, T.H. King, H. Masuichi, and T. Ohkuma. 2003. Multilingual grammar development via grammar porting. In E.M. Bender, D. Flickinger, F. Fouvry, and M. Siegel, editors, Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development, ESSLLI 2003, pages 49–56, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H King</author>
<author>M Forst</author>
<author>J Kuhn</author>
<author>M Butt</author>
</authors>
<title>The feature space in parallel grammar writing.</title>
<date>2005</date>
<journal>Research on Language and Computation,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="9244" citStr="King et al., 2005" startWordPosition="1421" endWordPosition="1424"> combination with modifiers. In addition, heads can combine directly with modifiers of their arguments (as opposed to just modifiers of themselves). Argument realization and the combination of heads and modifiers are fairly fundamental aspects of the system implemented in the Matrix. In light of the departure described above, it is interesting to see to what extent the Matrix can still support rapid development of a precision grammar for Wambaya. 2.3 Related Work There are currently many multilingual grammar engineering projects under active development, including ParGram, (Butt et al., 2002; King et al., 2005), the MetaGrammar project (Kinyon et al., 2006), KPML (Bateman et al., 2005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered </context>
</contexts>
<marker>King, Forst, Kuhn, Butt, 2005</marker>
<rawString>T.H. King, M. Forst, J. Kuhn, and M. Butt. 2005. The feature space in parallel grammar writing. Research on Language and Computation, 3(2):139–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kinyon</author>
<author>O Rambow</author>
<author>T Scheffler</author>
<author>S W Yoon</author>
<author>A K Joshi</author>
</authors>
<title>The metagrammar goes multilingual: A cross-linguistic look at the V2-phenomenon.</title>
<date>2006</date>
<booktitle>In TAG+8,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="9291" citStr="Kinyon et al., 2006" startWordPosition="1428" endWordPosition="1431">ds can combine directly with modifiers of their arguments (as opposed to just modifiers of themselves). Argument realization and the combination of heads and modifiers are fairly fundamental aspects of the system implemented in the Matrix. In light of the departure described above, it is interesting to see to what extent the Matrix can still support rapid development of a precision grammar for Wambaya. 2.3 Related Work There are currently many multilingual grammar engineering projects under active development, including ParGram, (Butt et al., 2002; King et al., 2005), the MetaGrammar project (Kinyon et al., 2006), KPML (Bateman et al., 2005), Grammix (M¨uller, 2007) and OpenCCG (Baldridge et al., 2007). Among approaches to multilingual grammar engineering, the Grammar Matrix’s distinguishing characteristics include the deployment of a shared core grammar for crosslinguistically consistent constraints and a series of libraries modeling varying linguistic properties. Thus while other work has successfully exploited grammar porting between typologically related languages (e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered the same typological dis3A linearization-based </context>
</contexts>
<marker>Kinyon, Rambow, Scheffler, Yoon, Joshi, 2006</marker>
<rawString>A. Kinyon, O. Rambow, T. Scheffler, S.W. Yoon, and A.K. Joshi. 2006. The metagrammar goes multilingual: A cross-linguistic look at the V2-phenomenon. In TAG+8, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Kordoni</author>
<author>J Neu</author>
</authors>
<title>Deep analysis of Modern Greek.</title>
<date>2005</date>
<booktitle>Lecture Notes in Computer Science,</booktitle>
<volume>3248</volume>
<pages>674--683</pages>
<editor>In K-Y Su, J. Tsujii, and J-H Lee, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="3001" citStr="Kordoni and Neu, 2005" startWordPosition="451" endWordPosition="454"> 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics language typologically very different from any of the languages above: the non-Pama-Nyungan Australian language Wamb</context>
</contexts>
<marker>Kordoni, Neu, 2005</marker>
<rawString>V. Kordoni and J. Neu. 2005. Deep analysis of Modern Greek. In K-Y Su, J. Tsujii, and J-H Lee, editors, Lecture Notes in Computer Science, volume 3248, pages 674–683. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Lareau</author>
<author>L Wanner</author>
</authors>
<title>Towards a generic multilingual dependency grammar for text generation.</title>
<date>2007</date>
<pages>203--223</pages>
<editor>In T.H. King and E.M. Bender, editors, GEAF</editor>
<publisher>CSLI.</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="1426" citStr="Lareau and Wanner, 2007" startWordPosition="215" endWordPosition="218">the work on Wambaya identified some areas of refinement for the Grammar Matrix, 59% of the Matrix-provided types were invoked in the final Wambaya grammar, and only 4% of the Matrix-provided types required modification. 1 Introduction Hand-built grammars are often dismissed as too expensive to build on the one hand, and too brittle on the other. Nevertheless, they are key to various NLP applications, including those benefiting from deep natural language understanding (e.g., textual inference (Bobrow et al., 2007)), generation of wellformed output (e.g., natural language weather alert systems (Lareau and Wanner, 2007)) or both (as in machine translation (Oepen et al., 2007)). Of particular interest here are applications concerning endangered languages: Endangered languages represent a case of minimal linguistic resources, typically lacking even moderately-sized corpora, let alone treebanks. In the best case, one finds well-crafted descriptive grammars, bilingual dictionaries, and a handful of translated texts. The methods of precision grammar engineering are well-suited to taking advantage of such resources. At the same time, the applications of interest in the context of endangered languages emphasize lin</context>
</contexts>
<marker>Lareau, Wanner, 2007</marker>
<rawString>F. Lareau and L. Wanner. 2007. Towards a generic multilingual dependency grammar for text generation. In T.H. King and E.M. Bender, editors, GEAF 2007, pages 203–223, Stanford, CA. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Lønning</author>
<author>S Oepen</author>
</authors>
<title>Re-usable tools for precision machine translation.</title>
<date>2006</date>
<booktitle>In COLINGJACL 2006 Interactive Presentation Sessions, pages 53 – 56,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="4850" citStr="Lønning and Oepen, 2006" startWordPosition="739" endWordPosition="742">ase Structure Grammar (HPSG; Pollard and Sag, 1994), a lexicalist, constraint-based framework. Grammars in HPSG are expressed as a collection of typed feature structures which are arranged into a hierarchy such that information shared across multiple lexical entries or construction types is represented only on a single supertype. The Matrix is written in the TDL (type description language) formalism, which is interpreted by the LKB parser, generator, and grammar development environment (Copestake, 2002). It is compatible with the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal Recursion Semantics (Copestake et al., 2005; Flickinger and Bender, 2003). The libraries provide collections of ana</context>
</contexts>
<marker>Lønning, Oepen, 2006</marker>
<rawString>J.T. Lønning and S. Oepen. 2006. Re-usable tools for precision machine translation. In COLINGJACL 2006 Interactive Presentation Sessions, pages 53 – 56, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marimon</author>
<author>N Bel</author>
<author>N Seghezzi</author>
</authors>
<title>Test-suite construction for a Spanish grammar.</title>
<date>2007</date>
<booktitle>GEAF 2007,</booktitle>
<editor>In T.H. King and E.M. Bender, editors,</editor>
<publisher>CSLI.</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="3037" citStr="Marimon et al., 2007" startWordPosition="457" endWordPosition="461">cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics language typologically very different from any of the languages above: the non-Pama-Nyungan Australian language Wambaya (Nordlinger, 1998). The remainde</context>
</contexts>
<marker>Marimon, Bel, Seghezzi, 2007</marker>
<rawString>M. Marimon, N. Bel, and N. Seghezzi. 2007. Test-suite construction for a Spanish grammar. In T.H. King and E.M. Bender, editors, GEAF 2007, Stanford, CA. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan M¨uller</author>
</authors>
<title>The Grammix CD-ROM: A software collection for developing typed feature structure grammars.</title>
<date>2007</date>
<booktitle>GEAF 2007,</booktitle>
<editor>In T.H. King and E.M. Bender, editors,</editor>
<publisher>CSLI.</publisher>
<location>Stanford, CA.</location>
<marker>M¨uller, 2007</marker>
<rawString>Stefan M¨uller. 2007. The Grammix CD-ROM: A software collection for developing typed feature structure grammars. In T.H. King and E.M. Bender, editors, GEAF 2007, Stanford, CA. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nordlinger</author>
</authors>
<title>A Grammar of Wambaya,</title>
<date>1998</date>
<institution>Australia. Research School of Pacific and Asian Studies, The Australian National University,</institution>
<location>Northern</location>
<contexts>
<context position="3623" citStr="Nordlinger, 1998" startWordPosition="549" endWordPosition="550"> Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics language typologically very different from any of the languages above: the non-Pama-Nyungan Australian language Wambaya (Nordlinger, 1998). The remainder of this paper is structured as follows: §2 provides background on the Grammar Matrix and Wambaya, and situates the project with respect to related work. §3 presents the implemented grammar of Wambaya, describes its development, and evaluates it against unseen, naturally occurring text. §4 uses the Wambaya grammar and its development as one point of reference to measure the usefulness and cross-linguistic validity of the Grammar Matrix. §5 provides further discussion. 2 Background 2.1 The LinGO Grammar Matrix The LinGO Grammar Matrix is situated theoretically within Head-Driven </context>
<context position="6107" citStr="Nordlinger, 1998" startWordPosition="925" endWordPosition="926">phenomena. The current libraries include analyses of major constituent word order (SOV, SVO, etc), sentential negation, coordination, and yes-no question formation. The Matrix is accessed through a web-based configuration system1 which elicits typological information from the user-linguist through a questionnaire and then outputs a grammar consisting of the Matrix core plus selected types and constraints from the libraries according to the specifications in the questionnaire. 2.2 Wambaya Wambaya is a recently extinct language of the West Barkly family from the Northern Territory in Australia (Nordlinger, 1998). Wambaya was selected for this project because of its typological properties and because it is extraordinarily well-documented by Nordlinger in her 1998 descriptive grammar. Perhaps the most striking feature of Wambaya is its word order: it is a radically non-configurational language with a second position auxiliary/clitic cluster. That is, aside from the constraint that verbal clauses require a clitic cluster (marking subject and object agreement and tense, aspect and mood) in second position, the word order is otherwise free, to the point that noun phrases can be non-contiguous, with head n</context>
<context position="10535" citStr="Nordlinger 1998" startWordPosition="1612" endWordPosition="1613">hue and Sag (1999) for discontinuous constituents in Warlpiri (another Australian language), is not available, because it relies on disassociating the constituent structure from the surface order of words in a way that is not compatible with the TDL formalism. tance attempted here. The current project is also situated within a broader trend of using computational linguistics in the service of endangered language documentation (e.g., Robinson et al., 2007, see also www.emeld.org). 3 Wambaya grammar 3.1 Development The Wambaya grammar was developed on the basis of the grammatical description in Nordlinger 1998, including the Wambaya-English translation lexicon and glosses of individual example sentences. The development test suite consisted of all 794 distinct positive examples from Ch. 3–8 of the descriptive grammar. This includes elicited examples as well as (sometimes simplified) naturally occurring examples. They range in length from one to thirteen words (mean: 3.65). The test suite was extracted from the descriptive grammar at the beginning of the project and used throughout with only minor refinements as errors in formatting were discovered. The regression testing facilities of [incr tsdbo)]</context>
<context position="18911" citStr="Nordlinger (1998)" startWordPosition="3053" endWordPosition="3054">ormation about the realized arguments is still exposed in the COMPS and SUBJ lists of this constituent.10 This makes the necessary information available to separately-attaching modifiers (such as ngaraganaguja (‘grog-PROP.IV.ACC’)) so that they can check for case and number/gender compatibility and connect the semantic index of the argument they modify to a role in their own semantic contribution (in this case, the ARG1 of the ‘proprietive’ relation). 3.4 Evaluation The grammar was evaluated against a sample of naturally occurring data taken from one of the texts transcribed and translated by Nordlinger (1998) (“The two Eaglehawks”, told by Molly Nurlanyma Grueman). Of the 92 sentences in this text, 20 overlapped with items in the development set, so the 10The feature INST, newly proposed for this analysis, records the fact that they have been instantiated by lexical heads. (2) lexeme  HEAD verb [AUX +]  SUBJ ( 1 )  / HEAD verb [AUX −] COMPS ( SUBJ ( 1 ) +ED 2 \ COMPS 2   981 correct parsed unparsed average incorrect ambiguity Existing 50% 8% 42% 10.62 vocab 76% 8% 14% 12.56 w/added vocab Table 1: Grammar performance on held-out data evaluation was carried out only on the remaining </context>
</contexts>
<marker>Nordlinger, 1998</marker>
<rawString>R. Nordlinger. 1998. A Grammar of Wambaya, Northern Australia. Research School of Pacific and Asian Studies, The Australian National University, Canberra.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>E M Bender</author>
<author>U Callmeier</author>
<author>D Flickinger</author>
<author>M Siegel</author>
</authors>
<title>Parallel distributed grammar engineering for practical applications.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 19,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="11267" citStr="Oepen et al., 2002" startWordPosition="1719" endWordPosition="1722">test suite consisted of all 794 distinct positive examples from Ch. 3–8 of the descriptive grammar. This includes elicited examples as well as (sometimes simplified) naturally occurring examples. They range in length from one to thirteen words (mean: 3.65). The test suite was extracted from the descriptive grammar at the beginning of the project and used throughout with only minor refinements as errors in formatting were discovered. The regression testing facilities of [incr tsdbo)] allowed for rapid experimentation with alternative analyses as new phenomena were brought into the grammar (cf. Oepen et al., 2002). With no prior knowledge of this language beyond its most general typological properties, we were able to develop in under 5.5 person-weeks of development time (210 hours) a grammar able to assign appropriate analyses to 91% of the examples in the development set.4 The 210 hours include 25 hours of an RA’s time entering lexical entries, 7 hours spent preparing the development test suite, and 15 hours treebanking (using the LinGO Redwoods software (Oepen et al., 2004) to annotate the intended parse for each item). The remainder of the time was ordinary grammar development work.5 In addition, t</context>
</contexts>
<marker>Oepen, Bender, Callmeier, Flickinger, Siegel, 2002</marker>
<rawString>S. Oepen, E.M. Bender, U. Callmeier, D. Flickinger, and M. Siegel. 2002. Parallel distributed grammar engineering for practical applications. In Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 19, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>D Flickinger</author>
<author>K Toutanova</author>
<author>C D Manning</author>
</authors>
<title>LinGO Redwoods. A rich and dynamic treebank for HPSG.</title>
<date>2004</date>
<journal>Journal ofResearch on Language and Computation,</journal>
<volume>2</volume>
<issue>4</issue>
<pages>596</pages>
<contexts>
<context position="4884" citStr="Oepen et al., 2004" startWordPosition="744" endWordPosition="747">d Sag, 1994), a lexicalist, constraint-based framework. Grammars in HPSG are expressed as a collection of typed feature structures which are arranged into a hierarchy such that information shared across multiple lexical entries or construction types is represented only on a single supertype. The Matrix is written in the TDL (type description language) formalism, which is interpreted by the LKB parser, generator, and grammar development environment (Copestake, 2002). It is compatible with the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal Recursion Semantics (Copestake et al., 2005; Flickinger and Bender, 2003). The libraries provide collections of analyses for cross-linguistically var</context>
<context position="11739" citStr="Oepen et al., 2004" startWordPosition="1799" endWordPosition="1802">f [incr tsdbo)] allowed for rapid experimentation with alternative analyses as new phenomena were brought into the grammar (cf. Oepen et al., 2002). With no prior knowledge of this language beyond its most general typological properties, we were able to develop in under 5.5 person-weeks of development time (210 hours) a grammar able to assign appropriate analyses to 91% of the examples in the development set.4 The 210 hours include 25 hours of an RA’s time entering lexical entries, 7 hours spent preparing the development test suite, and 15 hours treebanking (using the LinGO Redwoods software (Oepen et al., 2004) to annotate the intended parse for each item). The remainder of the time was ordinary grammar development work.5 In addition, this grammar has relatively low ambiguity, assigning on average 11.89 parses per item in the development set. This reflects the fact that the grammar is modeling grammaticality: the rules are 4An additional 6% received some analysis, but not one that matched the translation given in the reference grammar. 5These numbers do not include the time put into the original field work and descriptive grammar work. Nordlinger (p.c.) estimates that as roughly 28 linguist-months, </context>
<context position="20775" citStr="Oepen et al., 2004" startWordPosition="3368" endWordPosition="3371"> mood, person, number, and gender information indicated. The results are shown in Table 1: With only lexical additions, the grammar was able to assign a correct parse to 55 (76%) of the test sentences, with an average ambiguity over these sentences of 12.56 parses/item. 3.5 Parse selection The parsed portion of the development set (732 items) constitutes a sufficiently large corpus to train a parse selection model using the Redwoods disambiguation technology (Toutanova et al., 2005). As part of the grammar development process, the parses were annotated using the Redwoods parse selection tool (Oepen et al., 2004). The resulting treebank was used to select appropriate parameters by 10-fold cross-validation, applying the experimentation environment and feature templates of (Velldal, 2007). The optimal feature set included 2-level grandparenting, 3-grams of lexical entry types, and both constituent weight features. In the cross-validation trials on the development set, this model achieved a parse selection accuracy of 80.2% (random choice baseline: 23.9%). A model with the same features was then trained on all 544 ambiguous examples from the development set and used to rank the parses of the test set. It</context>
</contexts>
<marker>Oepen, Flickinger, Toutanova, Manning, 2004</marker>
<rawString>S. Oepen, D. Flickinger, K. Toutanova, and C.D. Manning. 2004. LinGO Redwoods. A rich and dynamic treebank for HPSG. Journal ofResearch on Language and Computation, 2(4):575 – 596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Erik Velldal</author>
<author>Jan Tore Lnning</author>
<author>Paul Meurer</author>
<author>Victoria Rosn</author>
<author>Dan Flickinger</author>
</authors>
<title>Towards hybrid quality-oriented machine translation. On linguistics and probabilities in MT.</title>
<date>2007</date>
<booktitle>In TMI 2007, Skvde,</booktitle>
<contexts>
<context position="1483" citStr="Oepen et al., 2007" startWordPosition="225" endWordPosition="228">e Grammar Matrix, 59% of the Matrix-provided types were invoked in the final Wambaya grammar, and only 4% of the Matrix-provided types required modification. 1 Introduction Hand-built grammars are often dismissed as too expensive to build on the one hand, and too brittle on the other. Nevertheless, they are key to various NLP applications, including those benefiting from deep natural language understanding (e.g., textual inference (Bobrow et al., 2007)), generation of wellformed output (e.g., natural language weather alert systems (Lareau and Wanner, 2007)) or both (as in machine translation (Oepen et al., 2007)). Of particular interest here are applications concerning endangered languages: Endangered languages represent a case of minimal linguistic resources, typically lacking even moderately-sized corpora, let alone treebanks. In the best case, one finds well-crafted descriptive grammars, bilingual dictionaries, and a handful of translated texts. The methods of precision grammar engineering are well-suited to taking advantage of such resources. At the same time, the applications of interest in the context of endangered languages emphasize linguistic precision: implemented grammars can be used to en</context>
</contexts>
<marker>Oepen, Velldal, Lnning, Meurer, Rosn, Flickinger, 2007</marker>
<rawString>Stephan Oepen, Erik Velldal, Jan Tore Lnning, Paul Meurer, Victoria Rosn, and Dan Flickinger. 2007. Towards hybrid quality-oriented machine translation. On linguistics and probabilities in MT. In TMI 2007, Skvde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<date>1994</date>
<booktitle>Head-Driven Phrase Structure Grammar. CSLI,</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="4277" citStr="Pollard and Sag, 1994" startWordPosition="651" endWordPosition="654"> structured as follows: §2 provides background on the Grammar Matrix and Wambaya, and situates the project with respect to related work. §3 presents the implemented grammar of Wambaya, describes its development, and evaluates it against unseen, naturally occurring text. §4 uses the Wambaya grammar and its development as one point of reference to measure the usefulness and cross-linguistic validity of the Grammar Matrix. §5 provides further discussion. 2 Background 2.1 The LinGO Grammar Matrix The LinGO Grammar Matrix is situated theoretically within Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994), a lexicalist, constraint-based framework. Grammars in HPSG are expressed as a collection of typed feature structures which are arranged into a hierarchy such that information shared across multiple lexical entries or construction types is represented only on a single supertype. The Matrix is written in the TDL (type description language) formalism, which is interpreted by the LKB parser, generator, and grammar development environment (Copestake, 2002). It is compatible with the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al.</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I.A. Sag. 1994. Head-Driven Phrase Structure Grammar. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Robinson</author>
<author>G Aumann</author>
<author>S Bird</author>
</authors>
<title>Managing fieldwork data with Toolbox and the Natural Language Toolkit. Language Documentation and Conservation,</title>
<date>2007</date>
<pages>1--44</pages>
<contexts>
<context position="10378" citStr="Robinson et al., 2007" startWordPosition="1587" endWordPosition="1590">e.g., Kim et al., 2003), to my knowledge, no other grammar porting project has covered the same typological dis3A linearization-based analysis as suggested by Donohue and Sag (1999) for discontinuous constituents in Warlpiri (another Australian language), is not available, because it relies on disassociating the constituent structure from the surface order of words in a way that is not compatible with the TDL formalism. tance attempted here. The current project is also situated within a broader trend of using computational linguistics in the service of endangered language documentation (e.g., Robinson et al., 2007, see also www.emeld.org). 3 Wambaya grammar 3.1 Development The Wambaya grammar was developed on the basis of the grammatical description in Nordlinger 1998, including the Wambaya-English translation lexicon and glosses of individual example sentences. The development test suite consisted of all 794 distinct positive examples from Ch. 3–8 of the descriptive grammar. This includes elicited examples as well as (sometimes simplified) naturally occurring examples. They range in length from one to thirteen words (mean: 3.65). The test suite was extracted from the descriptive grammar at the beginni</context>
</contexts>
<marker>Robinson, Aumann, Bird, 2007</marker>
<rawString>S. Robinson, G. Aumann, and S. Bird. 2007. Managing fieldwork data with Toolbox and the Natural Language Toolkit. Language Documentation and Conservation, 1:44–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Sag</author>
</authors>
<title>English relative clause constructions.</title>
<date>1997</date>
<journal>Journal ofLinguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="26411" citStr="Sag, 1997" startWordPosition="4294" endWordPosition="4295"> work suggests that there is a substantial amount of information in the Matrix core type hierarchy which would better be stored as part of the typological libraries. In particular, the analyses of argument realization implemented in the Matrix were not used for this grammar. The types associated with argument realization in configurational languages should be moved into the wordorder library, which should also be extended to include an analysis of Wambaya-style radical nonconfigurationality. At the same time, the lexical amalgamation analysis of the features used in longdistance dependencies (Sag, 1997) was found to be incompatible with the approach to argument realization in Wambaya, and a phrasal amalgamation analysis was implemented instead. This again suggests that lexical v. phrasal amalgamation should be encoded in the libraries, and selected according to the word order pattern of the language. As for parts of speech, of the nine types provided by the Matrix, five were used in the Wambaya grammar (verb, noun, adj, adv, and det) and four were not (num, conj, comp, and adp(osition)). Four disjunctive types were directly invoked, to describe phenomena applying to nouns and adjectives, ver</context>
</contexts>
<marker>Sag, 1997</marker>
<rawString>I.A. Sag. 1997. English relative clause constructions. Journal ofLinguistics, 33(2):431–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siegel</author>
<author>E M Bender</author>
</authors>
<title>Efficient deep processing of Japanese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization, COLING 19,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2813" citStr="Siegel and Bender, 2002" startWordPosition="421" endWordPosition="424">on, and to create software language tutors in the context of language preservation efforts. The LinGO Grammar Matrix (Bender et al., 2002; Bender and Flickinger, 2005; Drellishak and Bender, 2005) is a toolkit for reducing the cost of creating broad-coverage precision grammars by prepackaging both a cross-linguistic core grammar and a series of libraries of analyses of cross-linguistically variable phenomena, such as major-constituent word order or question formation. The Grammar Matrix was developed initially on the basis of broadcoverage grammars for English (Flickinger, 2000) and Japanese (Siegel and Bender, 2002), and has since been extended and refined as it has been used in the development of broad-coverage grammars for Norwegian (Hellan and Haugereid, 2003), Modern Greek (Kordoni and Neu, 2005), and Spanish (Marimon et al., 2007), as well as being applied to 42 other languages from a variety of language families in a classroom context (Bender, 2007). This paper aims to evaluate both the utility of the Grammar Matrix in jump-starting precision grammar development and the current state of its crosslinguistic hypotheses through a case study of a 977 Proceedings of ACL-08: HLT, pages 977–985, Columbus,</context>
</contexts>
<marker>Siegel, Bender, 2002</marker>
<rawString>M. Siegel and E.M. Bender. 2002. Efficient deep processing of Japanese. In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization, COLING 19, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>C D Manning</author>
<author>D Flickinger</author>
<author>S Oepen</author>
</authors>
<title>Stochastic HPSG parse selection using the Redwoods corpus.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="4929" citStr="Toutanova et al., 2005" startWordPosition="751" endWordPosition="754">sed framework. Grammars in HPSG are expressed as a collection of typed feature structures which are arranged into a hierarchy such that information shared across multiple lexical entries or construction types is represented only on a single supertype. The Matrix is written in the TDL (type description language) formalism, which is interpreted by the LKB parser, generator, and grammar development environment (Copestake, 2002). It is compatible with the broader range of DELPH-IN tools, e.g., for machine translation (Lønning and Oepen, 2006), treebanking (Oepen et al., 2004) and parse selection (Toutanova et al., 2005). The Grammar Matrix consists of a crosslinguistic core type hierarchy and a collection of phenomenon-specific libraries. The core type hierarchy defines the basic feature geometry, the ways that heads combine with arguments and adjuncts, linking types for relating syntactic to semantic arguments, and the constraints required to compositionally build up semantic representations in the format of Minimal Recursion Semantics (Copestake et al., 2005; Flickinger and Bender, 2003). The libraries provide collections of analyses for cross-linguistically variable phenomena. The current libraries includ</context>
<context position="20643" citStr="Toutanova et al., 2005" startWordPosition="3347" endWordPosition="3350">yses returned by the parser includes at least one with an MRS that matches the dependency structure, illocutionary force, tense, aspect, mood, person, number, and gender information indicated. The results are shown in Table 1: With only lexical additions, the grammar was able to assign a correct parse to 55 (76%) of the test sentences, with an average ambiguity over these sentences of 12.56 parses/item. 3.5 Parse selection The parsed portion of the development set (732 items) constitutes a sufficiently large corpus to train a parse selection model using the Redwoods disambiguation technology (Toutanova et al., 2005). As part of the grammar development process, the parses were annotated using the Redwoods parse selection tool (Oepen et al., 2004). The resulting treebank was used to select appropriate parameters by 10-fold cross-validation, applying the experimentation environment and feature templates of (Velldal, 2007). The optimal feature set included 2-level grandparenting, 3-grams of lexical entry types, and both constituent weight features. In the cross-validation trials on the development set, this model achieved a parse selection accuracy of 80.2% (random choice baseline: 23.9%). A model with the s</context>
</contexts>
<marker>Toutanova, Manning, Flickinger, Oepen, 2005</marker>
<rawString>K. Toutanova, C.D. Manning, D. Flickinger, and S. Oepen. 2005. Stochastic HPSG parse selection using the Redwoods corpus. Journal of Research on Language and Computation, 3(1):83–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Velldal</author>
</authors>
<title>Empirical Realization Ranking.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Oslo, Department of Informatics.</institution>
<contexts>
<context position="20952" citStr="Velldal, 2007" startWordPosition="3393" endWordPosition="3394">the test sentences, with an average ambiguity over these sentences of 12.56 parses/item. 3.5 Parse selection The parsed portion of the development set (732 items) constitutes a sufficiently large corpus to train a parse selection model using the Redwoods disambiguation technology (Toutanova et al., 2005). As part of the grammar development process, the parses were annotated using the Redwoods parse selection tool (Oepen et al., 2004). The resulting treebank was used to select appropriate parameters by 10-fold cross-validation, applying the experimentation environment and feature templates of (Velldal, 2007). The optimal feature set included 2-level grandparenting, 3-grams of lexical entry types, and both constituent weight features. In the cross-validation trials on the development set, this model achieved a parse selection accuracy of 80.2% (random choice baseline: 23.9%). A model with the same features was then trained on all 544 ambiguous examples from the development set and used to rank the parses of the test set. It ranked the correct parse (exact match) highest in 75.0% of the test sentences. This is well above the random-choice baseline of 18.4%, and affirms the cross-linguistic validity</context>
</contexts>
<marker>Velldal, 2007</marker>
<rawString>E. Velldal. 2007. Empirical Realization Ranking. Ph.D. thesis, University of Oslo, Department of Informatics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>