<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004901">
<title confidence="0.9985415">
On the Elements of an Accurate
Tree-to-String Machine Translation System
</title>
<author confidence="0.999705">
Graham Neubig, Kevin Duh
</author>
<affiliation confidence="0.9992695">
Graduate School of Information Science
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.836491">
8916-5 Takayama-cho, Ikoma-shi, Nara, Japan
</address>
<email confidence="0.999628">
{neubig,kevinduh}@is.naist.jp
</email>
<sectionHeader confidence="0.997399" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999949045454545">
While tree-to-string (T2S) translation the-
oretically holds promise for efficient, ac-
curate translation, in previous reports T2S
systems have often proven inferior to other
machine translation (MT) methods such as
phrase-based or hierarchical phrase-based
MT. In this paper, we attempt to clarify
the reason for this performance gap by
investigating a number of peripheral ele-
ments that affect the accuracy of T2S sys-
tems, including parsing, alignment, and
search. Based on detailed experiments
on the English-Japanese and Japanese-
English pairs, we show how a basic T2S
system that performs on par with phrase-
based systems can be improved by 2.6-4.6
BLEU, greatly exceeding existing state-
of-the-art methods. These results indi-
cate that T2S systems indeed hold much
promise, but the above-mentioned ele-
ments must be taken seriously in construc-
tion of these systems.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999842745454546">
In recent years, syntactic parsing is being viewed
as an ever-more important element of statistical
machine translation (SMT) systems, particularly
for translation between languages with large dif-
ferences in word order. There are many ways of
incorporating syntax into MT systems, including
the use of string-to-tree translation (S2T) to ensure
the syntactic well-formedness of the output (Gal-
ley et al., 2006; Shen et al., 2008), tree-to-string
(T2S) using source-side parsing as a hint during
the translation process (Liu et al., 2006), or pre-
or post-ordering to help compensate for reorder-
ing problems experienced by non-syntactic meth-
ods such as phrase-based MT (PBMT) (Collins et
al., 2005; Sudoh et al., 2011). Among these, T2S
translation has a number of attractive theoretical
properties, such as joint consideration of global re-
ordering and lexical choice while maintaining rel-
atively fast decoding times.
However, building an accurate T2S system is
not trivial. On one hand, there have been multiple
reports (mainly from groups with a long history
of building T2S systems) stating that systems us-
ing source-side syntax greatly out-perform phrase-
based systems (Mi et al., 2008; Liu et al., 2011;
Zhang et al., 2011; Tamura et al., 2013). On the
other hand, there have been also been multiple re-
ports noting the exact opposite result that source-
side syntax systems perform worse than Hiero,
S2T, PBMT, or PBMT with pre-ordering (Ambati
and Lavie, 2008; Xie et al., 2011; Kaljahi et al.,
2012). In this paper, we argue that this is due to the
fact that T2S systems have the potential to achieve
high accuracy, but are also less robust, with a num-
ber of peripheral elements having a large effect on
translation accuracy.
Our motivation in writing this paper is to pro-
vide a first step in examining and codifying the
more important elements that make it possible to
construct a highly accurate T2S MT system. To do
so, we perform an empirical study of the effect of
parsing accuracy, packed forest input, alignment
accuracy, and search. The reason why we choose
these elements is that past work that has reported
low accuracy for T2S systems has often neglected
to consider one or all of these elements.
As a result of our tests on English-Japanese (en-
ja) and Japanese-English (ja-en) machine transla-
tion, we find that a T2S system not considering
these elements performs only slightly better than a
standard PBMT system. However, after account-
ing for all these elements we see large increases of
accuracy, with the final system greatly exceeding
not only standard PBMT, but also state-of-the-art
methods based on syntactic pre- or post-ordering.
</bodyText>
<page confidence="0.986976">
143
</page>
<bodyText confidence="0.5496525">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 143–149,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.98961" genericHeader="method">
2 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.997206">
2.1 Systems Compared
</subsectionHeader>
<bodyText confidence="0.99994956">
In our experiments, we use a translation model
based on T2S tree transducers (Graehl and Knight,
2004), constructed using the Travatar toolkit (Neu-
big, 2013). Rules are extracted using the GHKM
algorithm (Galley et al., 2006), and rules with
up to 5 composed minimal rules, up to 2 non-
terminals, and up to 10 terminals are used.
We also prepare 3 baselines not based on T2S
to provide a comparison with other systems in the
literature. The first two baselines are standard sys-
tems using PBMT or Hiero trained using Moses
(Koehn et al., 2007). We use default settings, ex-
cept for setting the reordering limit or maximum
chart span to the best-performing value of 24. As
our last baselines, we use two methods based on
syntactic pre- or post-ordering, which are state-of-
the-art methods for the language pairs. Specifi-
cally, for en-ja translation we use the head finaliza-
tion pre-ordering method of (Isozaki et al., 2010b),
and for ja-en translation, we use the syntactic post-
ordering method of (Goto et al., 2012). For all
systems, T2S or otherwise, the language model is
a Kneser-Ney 5-gram, and tuning is performed to
maximize BLEU score using minimum error rate
training (Och, 2003).
</bodyText>
<subsectionHeader confidence="0.999351">
2.2 Data and Evaluation
</subsectionHeader>
<bodyText confidence="0.999988235294118">
We perform all of our experiments on en-ja
and ja-en translation over data from the NTCIR
PatentMT task (Goto et al., 2011), the most stan-
dard benchmark task for these language pairs. We
use the training data from NTCIR 7/8, a total of
approximately 3.0M sentences, and perform tun-
ing on the NTCIR 7 dry run, testing on the NTCIR
7 formal run data. As evaluation measures, we use
the standard BLEU (Papineni et al., 2002) as well
as RIBES (Isozaki et al., 2010a), a reordering-
based metric that has been shown to have high
correlation with human evaluations on the NTCIR
data. We measure significance of results using
bootstrap resampling at p &lt; 0.05 (Koehn, 2004).
In tables, bold numbers indicate the best system
and all systems that were not significantly differ-
ent from the best system.
</bodyText>
<subsectionHeader confidence="0.999212">
2.3 Motivational Experiment
</subsectionHeader>
<bodyText confidence="0.982112333333333">
Before going into a detailed analysis, we first
present results that stress the importance of the el-
ements described in the introduction. To do so,
</bodyText>
<table confidence="0.997903857142857">
System en-ja ja-en
BLEU RIBES BLEU RIBES
PBMT 35.84 72.89 30.49 69.80
Hiero 34.45 72.94 29.41 69.51
Pre/Post 36.69 77.05 29.42 73.85
T2S-all 36.23 76.60 31.15 72.87
T2S+all 40.84 80.15 33.70 75.94
</table>
<tableCaption confidence="0.999843">
Table 1: Overall results for five systems.
</tableCaption>
<bodyText confidence="0.999864384615385">
we compare the 3 non-T2S baselines with two
T2S systems that vary the settings of the parser,
alignment, and search, as described in the follow-
ing Sections 3, 4, and 5. The first system “T2S-
all” is a system that uses the worst settings1 for
each of these elements, while the second system
“T2S+all” uses the best settings.2 The results for
the systems are shown in Table 1.
The most striking result is that T2S+all signif-
icantly exceeds all of the baselines, even includ-
ing the pre/post-ordering baselines, which provide
state-of-the-art results on this task. The gains are
particularly striking on en-ja, with a gain of over 4
BLEU points over the closest system, but still sig-
nificant on the ja-en task, where the use of source-
side syntax has proven less effective in previous
work (Sudoh et al., 2011). The next thing to notice
is that if we had instead used T2S-all, our conclu-
sion would have been much different. This system
is able to achieve respectable accuracy compared
to PBMT or Hiero, but does not exceed the more
competitive pre/post-ordering systems.3 With this
result in hand, we will investigate the contribution
of each of these elements in detail in the following
sections. In the remainder of the paper settings
follow T2S+all except when otherwise noted.
</bodyText>
<sectionHeader confidence="0.998236" genericHeader="method">
3 Parsing
</sectionHeader>
<subsectionHeader confidence="0.999993">
3.1 Parsing Overview
</subsectionHeader>
<bodyText confidence="0.932451">
As T2S translation uses parse trees both in train-
ing and testing of the system, an accurate syntactic
parser is required. In order to test the extent that
parsing accuracy affects translation, we use two
1Stanford/Eda, GIZA++, pop-limit 5000 cube pruning.
2Egret forests, Nile, pop-limit 5000 hypergraph search.
3We have also observed similar trends on other genres and
language pairs. For example, in a Japanese-Chinese/English
medical conversation task (Neubig et al., 2013), forests,
alignment, and search resulted in BLEU increases of en-ja
24.55→30.81, ja-en 19.28→22.46, zh-ja 15.22→20.67, ja-zh
30.88→33.89.
</bodyText>
<page confidence="0.993498">
144
</page>
<bodyText confidence="0.999916317073171">
different syntactic parsers and examine the trans-
lation accuracy realized by each parser.
For English, the two most widely referenced
parsers are the Stanford Parser and Berkeley
Parser. In this work, we compare the Stanford
Parser’s CFG model, with the Berkeley Parser’s
latent variable model. In previous reports, it has
been noted (Kummerfeld et al., 2012) that the la-
tent variable model of the Berkeley parser tends to
have the higher accuracy of the two, so if the accu-
racy of a system using this model is higher then it
is likely that parsing accuracy is important for T2S
translation. Instead of the Berkeley Parser itself,
we use a clone Egret,4 which achieves nearly iden-
tical accuracy, and is able to output packed forests
for use in MT, as mentioned below. Trees are
right-binarized, with the exception of phrase-final
punctuation, which is split off before any other el-
ement in the phrase.
For Japanese, our first method uses the MST-
based pointwise dependency parser of Flannery et
al. (2011), as implemented in the Eda toolkit.5
In order to convert dependencies into phrase-
structure trees typically used in T2S translation,
we use the head rules implemented in the Travatar
toolkit. In addition, we also train a latent variable
CFG using the Berkeley Parser and use Egret for
parsing. Both models are trained on the Japanese
Word Dependency Treebank (Mori et al., 2014).
In addition, Mi et al. (2008) have proposed a
method for forest-to-string (F2S) translation us-
ing packed forests to encode many possible sen-
tence interpretations. By doing so, it is possible to
resolve some of the ambiguity in syntactic inter-
pretation at translation time, potentially increasing
translation accuracy. However, the great majority
of recent works on T2S translation do not consider
multiple syntactic parses (e.g. Liu et al. (2011),
Zhang et al. (2011)), and thus it is important to
confirm the potential gains that could be acquired
by taking ambiguity into account.
</bodyText>
<subsectionHeader confidence="0.999973">
3.2 Effect of Parsing and Forest Input
</subsectionHeader>
<bodyText confidence="0.999852666666667">
In Table 2 we show the results for Stanford/Eda
with 1-best tree input vs. Egret with trees or
forests as input. Forests are those containing all
edges in the 100-best parses.
First looking at the difference between the two
parsers, we can see that the T2S system using
</bodyText>
<footnote confidence="0.999819">
4http://code.google.com/p/egret-parser
5http://plata.ar.media.kyoto-u.ac.jp/tool/EDA
</footnote>
<table confidence="0.9968608">
en-ja ja-en
System BLEU RIBES BLEU RIBES
Stan/Eda 38.95 78.47 32.56 73.03
Egret-T 39.26 79.26 32.97 74.94
Egret-F 40.84 80.15 33.70 75.94
</table>
<tableCaption confidence="0.9968625">
Table 2: Results for Stanford/Eda, Egret with tree
input, and Egret with forest input.
</tableCaption>
<figure confidence="0.5923">
Forest n-best Cutoff
</figure>
<figureCaption confidence="0.943736333333333">
Figure 1: BLEU scores using various levels of for-
est pruning. Numbers in the graph indicate decod-
ing time in seconds/sentence.
</figureCaption>
<bodyText confidence="0.999898846153846">
Egret achieves greater accuracy than that using the
other two parsers. This improvement is particu-
larly obvious in RIBES, indicating that an increase
in parsing accuracy has a larger effect on global
reordering than on lexical choice. When going
from T2S to F2S translation using Egret, we see
another large gain in accuracy, although this time
with the gain in BLEU being more prominent. We
believe this is related to the observation of Zhang
and Chiang (2012) that F2S translation is not nec-
essarily helping fixing parsing errors, but instead
giving the translation system the freedom to ignore
the parse somewhat, allowing for less syntactically
motivated but more fluent translations.
As passing some degree of syntactic ambigu-
ity on to the decoder through F2S translation has
proven useful, a next natural question is how much
of this ambiguity we need to preserve in our forest.
The pruning criterion that we use for the forest is
based on including all edges that appear in one or
more of the n-best parses, so we perform transla-
tion setting n to 1 (trees), 3, 6, 12, 25, 50, 100, and
200. Figure 1 shows results for these settings with
regards to translation accuracy and speed. Over-
all, we can see that every time we double the size
of the forest we get an approximately linear in-
</bodyText>
<figure confidence="0.986988571428572">
420
3.73 4.61
3.06 3.21 3.70
41
40
2.58
2.03
1.75
39
35
BLEU
1 10 100
320
34
33
1.39 1.50
1.61 1.74 2.05 2.07
1.32
1.21
en-ja
ja-en
</figure>
<page confidence="0.992375">
145
</page>
<bodyText confidence="0.999951333333333">
crease in BLEU at the cost of an increase in decod-
ing time. Interestingly, the increases in BLEU did
not show any sign of saturating even when setting
the n-best cutoff to 200, although larger cutoffs re-
sulted in exceedingly large translation forests that
required large amounts of memory.
</bodyText>
<sectionHeader confidence="0.99968" genericHeader="method">
4 Alignment
</sectionHeader>
<subsectionHeader confidence="0.999849">
4.1 Alignment Overview
</subsectionHeader>
<bodyText confidence="0.999970620689655">
The second element that we investigate is align-
ment accuracy. It has been noted in many previ-
ous works that significant gains in alignment accu-
racy do not make a significant difference in trans-
lation results (Ayan and Dorr, 2006; Ganchev et
al., 2008). However, none of these works have ex-
plicitly investigated the effect on T2S translation,
so it is not clear whether these results carry over to
our current situation.
As our baseline aligner, we use the GIZA++ im-
plementation of the IBM models (Och and Ney,
2003) with the default options. To test the effect
of improved alignment accuracy, we use the dis-
criminative alignment method of Riesa and Marcu
(2010) as implemented in the Nile toolkit.6 This
method has the ability to use source- and target-
side syntactic information, and has been shown to
improve the accuracy of S2T translation.
We trained Nile and tested both methods on
the Japanese-English alignments provided with
the Kyoto Free Translation Task (Neubig, 2011)
(430k parallel sentences, 1074 manually aligned
training sentences, and 120 manually aligned test
sentences).7 As creating manual alignment data is
costly, we also created two training sets that con-
sisted of 1/4 and 1/16 of the total data to test if
we can achieve an effect with smaller amounts of
manually annotated data. The details of data size
and alignment accuracy are shown in Table 3.
</bodyText>
<subsectionHeader confidence="0.999293">
4.2 Effect of Alignment on Translation
</subsectionHeader>
<bodyText confidence="0.999849857142857">
In Table 4, we show results when we vary the
aligner between GIZA++ and Nile. For reference,
we also demonstrate results when using the same
alignments for PBMT and Hiero.
From this, we can see that while for PBMT and
Hiero systems the results are mixed, as has been
noted in previous work (Fraser and Marcu, 2007),
</bodyText>
<footnote confidence="0.9924512">
6http://code.google.com/p/nile
7This data is from Wikipedia articles about Kyoto City,
and is an entirely different genre than our MT test data. It is
likely that creating aligned data that matches the MT genre
would provide larger gains in MT accuracy.
</footnote>
<table confidence="0.999824">
Name Sent. Prec. Rec. F-meas
GIZA++ 0 60.46 55.48 57.86
Nile/16 68 70.21 60.81 65.17
Nile/4 269 72.85 62.70 67.40
Nile 1074 72.73 63.97 68.07
</table>
<tableCaption confidence="0.9844635">
Table 3: Alignment accuracy (%) by method and
number of manually annotated training sentences.
</tableCaption>
<table confidence="0.9997293">
System en-ja ja-en
BLEU RIBES BLEU RIBES
PBMT-G 35.84 72.89 30.49 69.80
PBMT-N 36.05 71.84 30.77 69.75
Hiero-G 34.45 72.94 29.41 69.51
Hiero-N 33.90 72.63 28.90 69.83
T2S-G 39.57 78.94 32.62 75.19
T2S-N/16 40.79 80.05 32.82 74.89
T2S-N/4 40.97 80.32 33.35 75.46
T2S-N 40.84 80.15 33.70 75.94
</table>
<tableCaption confidence="0.9977">
Table 4: Results varying the aligner (GIZA++ vs.
</tableCaption>
<bodyText confidence="0.5090445">
Nile), including results for Nile when using 1/4 or
1/16 of the annotated training data.
</bodyText>
<figureCaption confidence="0.995235">
Figure 2: Probabilities for SVO→SOV rules.
</figureCaption>
<bodyText confidence="0.999876">
improving the alignment accuracy gives signifi-
cant gains for T2S translation. The reason for this
difference is two-fold. The first is that in rule
extraction in syntax-based translation (Galley et
al., 2006), a single mistaken alignment crossing
phrase boundaries results not only in a bad rule be-
ing extracted, but also prevents the extraction of a
number of good rules. This is reflected in the size
of the rule table; the en-ja system built using Nile
contains 92.8M rules, while the GIZA++ system
contains only 83.3M rules, a 11.2% drop.
The second reason why alignment is important
is that while one of the merits of T2S models is
their ability to perform global re-ordering, it is dif-
ficult to learn good reorderings from bad align-
ments. We show an example of this in Figure 2.
When translating SVO English to SOV Japanese,
we expect rules containing a verb and a following
noun phrase (VO) to have a high probability of be-
ing reversed (to OV), possibly with the addition of
</bodyText>
<page confidence="0.994309">
146
</page>
<figure confidence="0.988815322580645">
Pop Limit
410
40
398
38
37
6
36
34
33
4
32
31
2
30
290
BLEU (T2S)
0.08 0.12
0.09
0.25 0.43 0.76
0.27 0.38 0.71 1.75 4.34 8.73 en-ja HS
1.75 2.96 4.80
en-ja CP
0.08
0.10 0.14 0.25 0.37 0.57 1.21 2.22 3.97
0.13 0.24 0.44 0.64 1.60 3.83 5.74
0.10
100 1000 10000
ja-en HS
ja-en CP
Pop Limit
</figure>
<figureCaption confidence="0.99893">
Figure 3: Hypergraph search (HS) and cube
</figureCaption>
<bodyText confidence="0.64375">
pruning (CP) results for F2S and T2S. Numbers
above and below the lines indicate time in sec-
onds/sentence for HS and CP respectively.
</bodyText>
<sectionHeader confidence="0.869442" genericHeader="evaluation">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998825541666667">
In this paper, we discussed the importance of three
peripheral elements that contribute greatly to the
accuracy of T2S machine translation: parsing,
alignment, and search. Put together, a T2S sys-
tem that uses the more effective settings for these
three elements greatly outperforms a system that
uses more standard settings, as well as the current
state-of-the-art on English-Japanese and Japanese-
English translation tasks.
Based on these results we draw three conclu-
sions. The first is that given the very competitive
results presented here, T2S systems do seem to
have the potential to achieve high accuracy, even
when compared to strong baselines incorporating
syntactic reordering into a phrase-based system.
The second is that when going forward with re-
search on T2S translation, one should first be sure
to account for these three elements to ensure a
sturdy foundation for any further improvements.
Finally, considering the fact that parsing and align-
ment for each of these languages is far from per-
fect, further research investment in these fields
may very well have the potential to provide ad-
ditional gains in accuracy in the T2S framework.
</bodyText>
<footnote confidence="0.3632825">
Acknowledgments: This work was supported
by JSPS KAKENHI Grant Number 25730136.
</footnote>
<figure confidence="0.98119275">
100 1000 10000
BLEU (F2S)
37
35
420
41
408
39
38 6
34 4
33
32
2
31
300
0.42 0.72 1.07 1.81 3.73 5.60 9.59 4.43 9.60 17.40
1.04 1.77
0.66 en-ja HS
en-ja CP
0.33
0.33
0.43
0.30 0.41 0.58 0.91 2.05 3.54 6.44
0.43 0.71 1.01 2.29 4.73 9.18
ja-en HS
ja-en CP
0.22
0.24 0.32
</figure>
<bodyText confidence="0.999236">
the Japanese direct object particle “wo.” From the
figure, we can see that the probabilities learned by
Nile match this intuition, while the probabilities
learned by GIZA heavily favor no reordering.
Finally, looking at the amount of data needed to
train the model, we can see that a relatively small
amount of manually annotated data proves suffi-
cient for large gains in alignment accuracy, with
even 68 sentences showing a 7.31 point gain in F-
measure over GIZA++. This is because Nile’s fea-
ture set uses generalizable POS/syntactic informa-
tion and also because mis-alignments of common
function words (e.g. a/the) will be covered even
by small sets of training data. Looking at the MT
results, we can see that even the smaller data sets
allow for gains in accuracy, although the gains are
more prominent for en-ja.
</bodyText>
<sectionHeader confidence="0.998212" genericHeader="conclusions">
5 Search
</sectionHeader>
<subsectionHeader confidence="0.99981">
5.1 Search Overview
</subsectionHeader>
<bodyText confidence="0.999998071428571">
Finally, we examine the effect that the choice of
search algorithm has on the accuracy of transla-
tion. The most standard search algorithm for T2S
translation is bottom-up beam search using cube
pruning (CP, Chiang (2007)). However, there are
a number of other search algorithms that have
been proposed for tree-based translation in gen-
eral (Huang and Chiang, 2007) or T2S systems
in particular (Huang and Mi, 2010; Feng et al.,
2012). In this work, we compare CP and the hy-
pergraph search (HS) method of Heafield et al.
(2013), which is also a bottom-up pruning algo-
rithm but performs more efficient search by group-
ing together similar language model states.
</bodyText>
<subsectionHeader confidence="0.999807">
5.2 Effect of Search
</subsectionHeader>
<bodyText confidence="0.999927133333333">
Figure 3 shows BLEU and decoding speed results
using HS or CP on T2S and F2S translation, us-
ing a variety of pop limits. From this, we can see
that HS out-performs CP for both F2S and T2S,
especially with smaller pop limits. Comparing the
graphs for F2S and T2S translation, it is notable
that the shapes of the graphs for the two meth-
ods are strikingly similar. This result is somewhat
surprising, as the overall search space of F2S is
larger and it would be natural for the characteris-
tics of the search algorithm to vary between these
two settings. Finally, comparing ja-en and en-ja,
search is simpler for the former, a result of the fact
that the Japanese sentences contain more words,
and thus more LM evaluations per sentence.
</bodyText>
<page confidence="0.997408">
147
</page>
<sectionHeader confidence="0.995627" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996024267326733">
Vamshi Ambati and Alon Lavie. 2008. Improving syn-
tax driven translation models by re-structuring diver-
gent and non-isomorphic parse tree structures. In
Proc. AMTA, pages 235–244.
Necip Ayan and Bonnie Dorr. 2006. Going beyond
AER: an extensive analysis of word alignments and
their impact on MT. In Proc. ACL.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201–228.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proc. ACL, pages 531–540.
Yang Feng, Yang Liu, Qun Liu, and Trevor Cohn.
2012. Left-to-right tree-to-string decoding with pre-
diction. In Proc. EMNLP, pages 1191–1200.
Daniel Flannery, Yusuke Miyao, Graham Neubig, and
Shinsuke Mori. 2011. Training dependency parsers
from partially annotated corpora. In Proc. IJCNLP,
pages 776–784.
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine trans-
lation. Computational Linguistics, 33(3):293–303.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proc.
ACL, pages 961–968.
Kuzman Ganchev, Jo˜ao V. Grac¸a, and Ben Taskar.
2008. Better alignments = better translations? In
Proc. ACL.
Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and
Benjamin K. Tsou. 2011. Overview of the patent
machine translation task at the NTCIR-9 workshop.
In Proceedings of NTCIR, volume 9, pages 559–578.
Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012.
Post-ordering by parsing for Japanese-English sta-
tistical machine translation. In Proc. ACL, pages
311–316.
Jonathan Graehl and Kevin Knight. 2004. Training
tree transducers. In Proc. HLT, pages 105–112.
Kenneth Heafield, Philipp Koehn, and Alon Lavie.
2013. Grouping language model boundary words to
speed k–best extraction from hypergraphs. In Proc.
NAACL, pages 958–968.
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In Proc. ACL, pages 144–151.
Liang Huang and Haitao Mi. 2010. Efficient incre-
mental decoding for tree-to-string translation. In
Proc. EMNLP, pages 273–283.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010a. Automatic
evaluation of translation quality for distant language
pairs. In Proc. EMNLP, pages 944–952.
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and
Kevin Duh. 2010b. Head finalization: A simple
reordering rule for SOV languages. In Proc. WMT
and MetricsMATR.
Rasoul Samad Zadeh Kaljahi, Raphael Rubino, Johann
Roturier, and Jennifer Foster. 2012. A detailed
analysis of phrase-based and syntax-based machine
translation: The search for systematic differences.
In Proc. AMTA.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ACL, pages 177–180.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP.
Jonathan K Kummerfeld, David Hall, James R Cur-
ran, and Dan Klein. 2012. Parser showdown at the
wall street corral: an empirical investigation of er-
ror types in parser output. In Proc. EMNLP, pages
1048–1059.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proc. ACL.
Yang Liu, Qun Liu, and Yajuan L¨u. 2011. Adjoin-
ing tree-to-string translation. In Proc. ACL, pages
1278–1287.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proc. ACL, pages 192–199.
Shinsuke Mori, Hideki Ogura, and Tetsuro Sasada.
2014. A Japanese word dependency corpus. In
Proc. LREC.
Graham Neubig, Sakriani Sakti, Tomoki Toda, Satoshi
Nakamura, Yuji Matsumoto, Ryosuke Isotani, and
Yukichi Ikeda. 2013. Towards high-reliability
speech translation in the medical domain. In Proc.
MedNLP, pages 22–29.
Graham Neubig. 2011. The Kyoto free translation
task.http://www.phontron.com/kftt.
Graham Neubig. 2013. Travatar: A forest-to-string
machine translation engine based on tree transduc-
ers. In Proc. ACL Demo Track, pages 91–96.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
</reference>
<page confidence="0.979489">
148
</page>
<reference confidence="0.9999200625">
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. ACL, pages
160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proc. ACL,
pages 311–318.
Jason Riesa and Daniel Marcu. 2010. Hierarchical
search for word alignment. In Proc. ACL, pages
157–166.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proc. ACL, pages 577–585.
Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. 2011. Post-ordering
in statistical machine translation. In Proc. MT Sum-
mit.
Akihiro Tamura, Taro Watanabe, Eiichiro Sumita, Hi-
roya Takamura, and Manabu Okumura. 2013. Part-
of-speech induction in dependency trees for statisti-
cal machine translation. In Proc. ACL, pages 841–
851.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proc. EMNLP, pages 216–226.
Hui Zhang and David Chiang. 2012. An exploration
of forest-to-string translation: Does translation help
or hurt parsing? In Proc. ACL, pages 317–321.
Hao Zhang, Licheng Fang, Peng Xu, and Xiaoyun Wu.
2011. Binarized forest to string translation. In Proc.
ACL, pages 835–845.
</reference>
<page confidence="0.998975">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.918583">
<title confidence="0.9964825">On the Elements of an Tree-to-String Machine Translation System</title>
<author confidence="0.999344">Graham Neubig</author>
<author confidence="0.999344">Kevin</author>
<affiliation confidence="0.999825">Graduate School of Information Nara Institute of Science and</affiliation>
<address confidence="0.933219">8916-5 Takayama-cho, Ikoma-shi, Nara,</address>
<abstract confidence="0.99964552173913">While tree-to-string (T2S) translation theoretically holds promise for efficient, accurate translation, in previous reports T2S systems have often proven inferior to other machine translation (MT) methods such as phrase-based or hierarchical phrase-based MT. In this paper, we attempt to clarify the reason for this performance gap by investigating a number of peripheral elements that affect the accuracy of T2S systems, including parsing, alignment, and search. Based on detailed experiments on the English-Japanese and Japanese- English pairs, we show how a basic T2S system that performs on par with phrasebased systems can be improved by 2.6-4.6 BLEU, greatly exceeding existing stateof-the-art methods. These results indicate that T2S systems indeed hold much promise, but the above-mentioned elements must be taken seriously in construction of these systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Vamshi Ambati</author>
<author>Alon Lavie</author>
</authors>
<title>Improving syntax driven translation models by re-structuring divergent and non-isomorphic parse tree structures.</title>
<date>2008</date>
<booktitle>In Proc. AMTA,</booktitle>
<pages>235--244</pages>
<contexts>
<context position="2599" citStr="Ambati and Lavie, 2008" startWordPosition="394" endWordPosition="397">ordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (Ambati and Lavie, 2008; Xie et al., 2011; Kaljahi et al., 2012). In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy. Our motivation in writing this paper is to provide a first step in examining and codifying the more important elements that make it possible to construct a highly accurate T2S MT system. To do so, we perform an empirical study of the effect of parsing accuracy, packed forest input, alignment accuracy, and search. The reason why we</context>
</contexts>
<marker>Ambati, Lavie, 2008</marker>
<rawString>Vamshi Ambati and Alon Lavie. 2008. Improving syntax driven translation models by re-structuring divergent and non-isomorphic parse tree structures. In Proc. AMTA, pages 235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Necip Ayan</author>
<author>Bonnie Dorr</author>
</authors>
<title>Going beyond AER: an extensive analysis of word alignments and their impact on MT.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="13101" citStr="Ayan and Dorr, 2006" startWordPosition="2140" endWordPosition="2143">320 34 33 1.39 1.50 1.61 1.74 2.05 2.07 1.32 1.21 en-ja ja-en 145 crease in BLEU at the cost of an increase in decoding time. Interestingly, the increases in BLEU did not show any sign of saturating even when setting the n-best cutoff to 200, although larger cutoffs resulted in exceedingly large translation forests that required large amounts of memory. 4 Alignment 4.1 Alignment Overview The second element that we investigate is alignment accuracy. It has been noted in many previous works that significant gains in alignment accuracy do not make a significant difference in translation results (Ayan and Dorr, 2006; Ganchev et al., 2008). However, none of these works have explicitly investigated the effect on T2S translation, so it is not clear whether these results carry over to our current situation. As our baseline aligner, we use the GIZA++ implementation of the IBM models (Och and Ney, 2003) with the default options. To test the effect of improved alignment accuracy, we use the discriminative alignment method of Riesa and Marcu (2010) as implemented in the Nile toolkit.6 This method has the ability to use source- and targetside syntactic information, and has been shown to improve the accuracy of S2</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip Ayan and Bonnie Dorr. 2006. Going beyond AER: an extensive analysis of word alignments and their impact on MT. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="19592" citStr="Chiang (2007)" startWordPosition="3249" endWordPosition="3250">over GIZA++. This is because Nile’s feature set uses generalizable POS/syntactic information and also because mis-alignments of common function words (e.g. a/the) will be covered even by small sets of training data. Looking at the MT results, we can see that even the smaller data sets allow for gains in accuracy, although the gains are more prominent for en-ja. 5 Search 5.1 Search Overview Finally, we examine the effect that the choice of search algorithm has on the accuracy of translation. The most standard search algorithm for T2S translation is bottom-up beam search using cube pruning (CP, Chiang (2007)). However, there are a number of other search algorithms that have been proposed for tree-based translation in general (Huang and Chiang, 2007) or T2S systems in particular (Huang and Mi, 2010; Feng et al., 2012). In this work, we compare CP and the hypergraph search (HS) method of Heafield et al. (2013), which is also a bottom-up pruning algorithm but performs more efficient search by grouping together similar language model states. 5.2 Effect of Search Figure 3 shows BLEU and decoding speed results using HS or CP on T2S and F2S translation, using a variety of pop limits. From this, we can s</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>531--540</pages>
<contexts>
<context position="1834" citStr="Collins et al., 2005" startWordPosition="269" endWordPosition="272">nt element of statistical machine translation (SMT) systems, particularly for translation between languages with large differences in word order. There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (Galley et al., 2006; Shen et al., 2008), tree-to-string (T2S) using source-side parsing as a hint during the translation process (Liu et al., 2006), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been mu</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kucerova. 2005. Clause restructuring for statistical machine translation. In Proc. ACL, pages 531–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Feng</author>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Trevor Cohn</author>
</authors>
<title>Left-to-right tree-to-string decoding with prediction.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>1191--1200</pages>
<contexts>
<context position="19805" citStr="Feng et al., 2012" startWordPosition="3283" endWordPosition="3286">g data. Looking at the MT results, we can see that even the smaller data sets allow for gains in accuracy, although the gains are more prominent for en-ja. 5 Search 5.1 Search Overview Finally, we examine the effect that the choice of search algorithm has on the accuracy of translation. The most standard search algorithm for T2S translation is bottom-up beam search using cube pruning (CP, Chiang (2007)). However, there are a number of other search algorithms that have been proposed for tree-based translation in general (Huang and Chiang, 2007) or T2S systems in particular (Huang and Mi, 2010; Feng et al., 2012). In this work, we compare CP and the hypergraph search (HS) method of Heafield et al. (2013), which is also a bottom-up pruning algorithm but performs more efficient search by grouping together similar language model states. 5.2 Effect of Search Figure 3 shows BLEU and decoding speed results using HS or CP on T2S and F2S translation, using a variety of pop limits. From this, we can see that HS out-performs CP for both F2S and T2S, especially with smaller pop limits. Comparing the graphs for F2S and T2S translation, it is notable that the shapes of the graphs for the two methods are strikingly</context>
</contexts>
<marker>Feng, Liu, Liu, Cohn, 2012</marker>
<rawString>Yang Feng, Yang Liu, Qun Liu, and Trevor Cohn. 2012. Left-to-right tree-to-string decoding with prediction. In Proc. EMNLP, pages 1191–1200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Flannery</author>
<author>Yusuke Miyao</author>
<author>Graham Neubig</author>
<author>Shinsuke Mori</author>
</authors>
<title>Training dependency parsers from partially annotated corpora.</title>
<date>2011</date>
<booktitle>In Proc. IJCNLP,</booktitle>
<pages>776--784</pages>
<contexts>
<context position="9393" citStr="Flannery et al. (2011)" startWordPosition="1521" endWordPosition="1524">le model of the Berkeley parser tends to have the higher accuracy of the two, so if the accuracy of a system using this model is higher then it is likely that parsing accuracy is important for T2S translation. Instead of the Berkeley Parser itself, we use a clone Egret,4 which achieves nearly identical accuracy, and is able to output packed forests for use in MT, as mentioned below. Trees are right-binarized, with the exception of phrase-final punctuation, which is split off before any other element in the phrase. For Japanese, our first method uses the MSTbased pointwise dependency parser of Flannery et al. (2011), as implemented in the Eda toolkit.5 In order to convert dependencies into phrasestructure trees typically used in T2S translation, we use the head rules implemented in the Travatar toolkit. In addition, we also train a latent variable CFG using the Berkeley Parser and use Egret for parsing. Both models are trained on the Japanese Word Dependency Treebank (Mori et al., 2014). In addition, Mi et al. (2008) have proposed a method for forest-to-string (F2S) translation using packed forests to encode many possible sentence interpretations. By doing so, it is possible to resolve some of the ambigu</context>
</contexts>
<marker>Flannery, Miyao, Neubig, Mori, 2011</marker>
<rawString>Daniel Flannery, Yusuke Miyao, Graham Neubig, and Shinsuke Mori. 2011. Training dependency parsers from partially annotated corpora. In Proc. IJCNLP, pages 776–784.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="14599" citStr="Fraser and Marcu, 2007" startWordPosition="2393" endWordPosition="2396">anual alignment data is costly, we also created two training sets that consisted of 1/4 and 1/16 of the total data to test if we can achieve an effect with smaller amounts of manually annotated data. The details of data size and alignment accuracy are shown in Table 3. 4.2 Effect of Alignment on Translation In Table 4, we show results when we vary the aligner between GIZA++ and Nile. For reference, we also demonstrate results when using the same alignments for PBMT and Hiero. From this, we can see that while for PBMT and Hiero systems the results are mixed, as has been noted in previous work (Fraser and Marcu, 2007), 6http://code.google.com/p/nile 7This data is from Wikipedia articles about Kyoto City, and is an entirely different genre than our MT test data. It is likely that creating aligned data that matches the MT genre would provide larger gains in MT accuracy. Name Sent. Prec. Rec. F-meas GIZA++ 0 60.46 55.48 57.86 Nile/16 68 70.21 60.81 65.17 Nile/4 269 72.85 62.70 67.40 Nile 1074 72.73 63.97 68.07 Table 3: Alignment accuracy (%) by method and number of manually annotated training sentences. System en-ja ja-en BLEU RIBES BLEU RIBES PBMT-G 35.84 72.89 30.49 69.80 PBMT-N 36.05 71.84 30.77 69.75 Hier</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Computational Linguistics, 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>961--968</pages>
<contexts>
<context position="1549" citStr="Galley et al., 2006" startWordPosition="223" endWordPosition="227">ing existing stateof-the-art methods. These results indicate that T2S systems indeed hold much promise, but the above-mentioned elements must be taken seriously in construction of these systems. 1 Introduction In recent years, syntactic parsing is being viewed as an ever-more important element of statistical machine translation (SMT) systems, particularly for translation between languages with large differences in word order. There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (Galley et al., 2006; Shen et al., 2008), tree-to-string (T2S) using source-side parsing as a hint during the translation process (Liu et al., 2006), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple</context>
<context position="4274" citStr="Galley et al., 2006" startWordPosition="666" endWordPosition="669">th the final system greatly exceeding not only standard PBMT, but also state-of-the-art methods based on syntactic pre- or post-ordering. 143 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 143–149, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Experimental Setup 2.1 Systems Compared In our experiments, we use a translation model based on T2S tree transducers (Graehl and Knight, 2004), constructed using the Travatar toolkit (Neubig, 2013). Rules are extracted using the GHKM algorithm (Galley et al., 2006), and rules with up to 5 composed minimal rules, up to 2 nonterminals, and up to 10 terminals are used. We also prepare 3 baselines not based on T2S to provide a comparison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for</context>
<context position="15773" citStr="Galley et al., 2006" startWordPosition="2580" endWordPosition="2583">0.49 69.80 PBMT-N 36.05 71.84 30.77 69.75 Hiero-G 34.45 72.94 29.41 69.51 Hiero-N 33.90 72.63 28.90 69.83 T2S-G 39.57 78.94 32.62 75.19 T2S-N/16 40.79 80.05 32.82 74.89 T2S-N/4 40.97 80.32 33.35 75.46 T2S-N 40.84 80.15 33.70 75.94 Table 4: Results varying the aligner (GIZA++ vs. Nile), including results for Nile when using 1/4 or 1/16 of the annotated training data. Figure 2: Probabilities for SVO→SOV rules. improving the alignment accuracy gives significant gains for T2S translation. The reason for this difference is two-fold. The first is that in rule extraction in syntax-based translation (Galley et al., 2006), a single mistaken alignment crossing phrase boundaries results not only in a bad rule being extracted, but also prevents the extraction of a number of good rules. This is reflected in the size of the rule table; the en-ja system built using Nile contains 92.8M rules, while the GIZA++ system contains only 83.3M rules, a 11.2% drop. The second reason why alignment is important is that while one of the merits of T2S models is their ability to perform global re-ordering, it is difficult to learn good reorderings from bad alignments. We show an example of this in Figure 2. When translating SVO En</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proc. ACL, pages 961–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jo˜ao V Grac¸a</author>
<author>Ben Taskar</author>
</authors>
<title>Better alignments = better translations? In</title>
<date>2008</date>
<booktitle>Proc. ACL.</booktitle>
<marker>Ganchev, Grac¸a, Taskar, 2008</marker>
<rawString>Kuzman Ganchev, Jo˜ao V. Grac¸a, and Ben Taskar. 2008. Better alignments = better translations? In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Bin Lu</author>
<author>Ka Po Chow</author>
<author>Eiichiro Sumita</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Overview of the patent machine translation task at the NTCIR-9 workshop.</title>
<date>2011</date>
<booktitle>In Proceedings of NTCIR,</booktitle>
<volume>9</volume>
<pages>559--578</pages>
<contexts>
<context position="5381" citStr="Goto et al., 2011" startWordPosition="857" endWordPosition="860">on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for en-ja translation we use the head finalization pre-ordering method of (Isozaki et al., 2010b), and for ja-en translation, we use the syntactic postordering method of (Goto et al., 2012). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score using minimum error rate training (Och, 2003). 2.2 Data and Evaluation We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data. As evaluation measures, we use the standard BLEU (Papineni et al., 2002) as well as RIBES (Isozaki et al., 2010a), a reorderingbased metric that has been shown to have high correlation with human evaluations on the NTCIR data. We measure significance of results using bootstrap resampling at p &lt; 0.05 (Koehn, 2004). In tables, bold numbers indicate the best system and all s</context>
</contexts>
<marker>Goto, Lu, Chow, Sumita, Tsou, 2011</marker>
<rawString>Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and Benjamin K. Tsou. 2011. Overview of the patent machine translation task at the NTCIR-9 workshop. In Proceedings of NTCIR, volume 9, pages 559–578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Masao Utiyama</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Post-ordering by parsing for Japanese-English statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>311--316</pages>
<contexts>
<context position="5060" citStr="Goto et al., 2012" startWordPosition="803" endWordPosition="806">ison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for en-ja translation we use the head finalization pre-ordering method of (Isozaki et al., 2010b), and for ja-en translation, we use the syntactic postordering method of (Goto et al., 2012). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score using minimum error rate training (Och, 2003). 2.2 Data and Evaluation We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data. As evaluation measures, we use the standard BLEU (Pap</context>
</contexts>
<marker>Goto, Utiyama, Sumita, 2012</marker>
<rawString>Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012. Post-ordering by parsing for Japanese-English statistical machine translation. In Proc. ACL, pages 311–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
</authors>
<title>Training tree transducers.</title>
<date>2004</date>
<booktitle>In Proc. HLT,</booktitle>
<pages>105--112</pages>
<contexts>
<context position="4151" citStr="Graehl and Knight, 2004" startWordPosition="647" endWordPosition="650">tly better than a standard PBMT system. However, after accounting for all these elements we see large increases of accuracy, with the final system greatly exceeding not only standard PBMT, but also state-of-the-art methods based on syntactic pre- or post-ordering. 143 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 143–149, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Experimental Setup 2.1 Systems Compared In our experiments, we use a translation model based on T2S tree transducers (Graehl and Knight, 2004), constructed using the Travatar toolkit (Neubig, 2013). Rules are extracted using the GHKM algorithm (Galley et al., 2006), and rules with up to 5 composed minimal rules, up to 2 nonterminals, and up to 10 terminals are used. We also prepare 3 baselines not based on T2S to provide a comparison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two me</context>
</contexts>
<marker>Graehl, Knight, 2004</marker>
<rawString>Jonathan Graehl and Kevin Knight. 2004. Training tree transducers. In Proc. HLT, pages 105–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Philipp Koehn</author>
<author>Alon Lavie</author>
</authors>
<title>Grouping language model boundary words to speed k–best extraction from hypergraphs.</title>
<date>2013</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>958--968</pages>
<contexts>
<context position="19898" citStr="Heafield et al. (2013)" startWordPosition="3301" endWordPosition="3304">ains in accuracy, although the gains are more prominent for en-ja. 5 Search 5.1 Search Overview Finally, we examine the effect that the choice of search algorithm has on the accuracy of translation. The most standard search algorithm for T2S translation is bottom-up beam search using cube pruning (CP, Chiang (2007)). However, there are a number of other search algorithms that have been proposed for tree-based translation in general (Huang and Chiang, 2007) or T2S systems in particular (Huang and Mi, 2010; Feng et al., 2012). In this work, we compare CP and the hypergraph search (HS) method of Heafield et al. (2013), which is also a bottom-up pruning algorithm but performs more efficient search by grouping together similar language model states. 5.2 Effect of Search Figure 3 shows BLEU and decoding speed results using HS or CP on T2S and F2S translation, using a variety of pop limits. From this, we can see that HS out-performs CP for both F2S and T2S, especially with smaller pop limits. Comparing the graphs for F2S and T2S translation, it is notable that the shapes of the graphs for the two methods are strikingly similar. This result is somewhat surprising, as the overall search space of F2S is larger an</context>
</contexts>
<marker>Heafield, Koehn, Lavie, 2013</marker>
<rawString>Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2013. Grouping language model boundary words to speed k–best extraction from hypergraphs. In Proc. NAACL, pages 958–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="19736" citStr="Huang and Chiang, 2007" startWordPosition="3270" endWordPosition="3273"> function words (e.g. a/the) will be covered even by small sets of training data. Looking at the MT results, we can see that even the smaller data sets allow for gains in accuracy, although the gains are more prominent for en-ja. 5 Search 5.1 Search Overview Finally, we examine the effect that the choice of search algorithm has on the accuracy of translation. The most standard search algorithm for T2S translation is bottom-up beam search using cube pruning (CP, Chiang (2007)). However, there are a number of other search algorithms that have been proposed for tree-based translation in general (Huang and Chiang, 2007) or T2S systems in particular (Huang and Mi, 2010; Feng et al., 2012). In this work, we compare CP and the hypergraph search (HS) method of Heafield et al. (2013), which is also a bottom-up pruning algorithm but performs more efficient search by grouping together similar language model states. 5.2 Effect of Search Figure 3 shows BLEU and decoding speed results using HS or CP on T2S and F2S translation, using a variety of pop limits. From this, we can see that HS out-performs CP for both F2S and T2S, especially with smaller pop limits. Comparing the graphs for F2S and T2S translation, it is not</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Faster decoding with integrated language models. In Proc. ACL, pages 144–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Haitao Mi</author>
</authors>
<title>Efficient incremental decoding for tree-to-string translation.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>273--283</pages>
<contexts>
<context position="19785" citStr="Huang and Mi, 2010" startWordPosition="3279" endWordPosition="3282">mall sets of training data. Looking at the MT results, we can see that even the smaller data sets allow for gains in accuracy, although the gains are more prominent for en-ja. 5 Search 5.1 Search Overview Finally, we examine the effect that the choice of search algorithm has on the accuracy of translation. The most standard search algorithm for T2S translation is bottom-up beam search using cube pruning (CP, Chiang (2007)). However, there are a number of other search algorithms that have been proposed for tree-based translation in general (Huang and Chiang, 2007) or T2S systems in particular (Huang and Mi, 2010; Feng et al., 2012). In this work, we compare CP and the hypergraph search (HS) method of Heafield et al. (2013), which is also a bottom-up pruning algorithm but performs more efficient search by grouping together similar language model states. 5.2 Effect of Search Figure 3 shows BLEU and decoding speed results using HS or CP on T2S and F2S translation, using a variety of pop limits. From this, we can see that HS out-performs CP for both F2S and T2S, especially with smaller pop limits. Comparing the graphs for F2S and T2S translation, it is notable that the shapes of the graphs for the two me</context>
</contexts>
<marker>Huang, Mi, 2010</marker>
<rawString>Liang Huang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string translation. In Proc. EMNLP, pages 273–283.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
<author>Kevin Duh</author>
</authors>
<title>Katsuhito Sudoh, and Hajime Tsukada. 2010a. Automatic evaluation of translation quality for distant language pairs.</title>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>944--952</pages>
<marker>Isozaki, Hirao, Duh, </marker>
<rawString>Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010a. Automatic evaluation of translation quality for distant language pairs. In Proc. EMNLP, pages 944–952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Kevin Duh</author>
</authors>
<title>Head finalization: A simple reordering rule for SOV languages. In</title>
<date>2010</date>
<booktitle>Proc. WMT and MetricsMATR.</booktitle>
<contexts>
<context position="4966" citStr="Isozaki et al., 2010" startWordPosition="787" endWordPosition="790">nd up to 10 terminals are used. We also prepare 3 baselines not based on T2S to provide a comparison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for en-ja translation we use the head finalization pre-ordering method of (Isozaki et al., 2010b), and for ja-en translation, we use the syntactic postordering method of (Goto et al., 2012). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score using minimum error rate training (Och, 2003). 2.2 Data and Evaluation We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run,</context>
</contexts>
<marker>Isozaki, Sudoh, Tsukada, Duh, 2010</marker>
<rawString>Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and Kevin Duh. 2010b. Head finalization: A simple reordering rule for SOV languages. In Proc. WMT and MetricsMATR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rasoul Samad Zadeh Kaljahi</author>
<author>Raphael Rubino</author>
<author>Johann Roturier</author>
<author>Jennifer Foster</author>
</authors>
<title>A detailed analysis of phrase-based and syntax-based machine translation: The search for systematic differences. In</title>
<date>2012</date>
<booktitle>Proc. AMTA.</booktitle>
<contexts>
<context position="2640" citStr="Kaljahi et al., 2012" startWordPosition="402" endWordPosition="405">ing relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (Ambati and Lavie, 2008; Xie et al., 2011; Kaljahi et al., 2012). In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy. Our motivation in writing this paper is to provide a first step in examining and codifying the more important elements that make it possible to construct a highly accurate T2S MT system. To do so, we perform an empirical study of the effect of parsing accuracy, packed forest input, alignment accuracy, and search. The reason why we choose these elements is that past work </context>
</contexts>
<marker>Kaljahi, Rubino, Roturier, Foster, 2012</marker>
<rawString>Rasoul Samad Zadeh Kaljahi, Raphael Rubino, Johann Roturier, and Jennifer Foster. 2012. A detailed analysis of phrase-based and syntax-based machine translation: The search for systematic differences. In Proc. AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="4590" citStr="Koehn et al., 2007" startWordPosition="725" endWordPosition="728">ation for Computational Linguistics 2 Experimental Setup 2.1 Systems Compared In our experiments, we use a translation model based on T2S tree transducers (Graehl and Knight, 2004), constructed using the Travatar toolkit (Neubig, 2013). Rules are extracted using the GHKM algorithm (Galley et al., 2006), and rules with up to 5 composed minimal rules, up to 2 nonterminals, and up to 10 terminals are used. We also prepare 3 baselines not based on T2S to provide a comparison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for en-ja translation we use the head finalization pre-ordering method of (Isozaki et al., 2010b), and for ja-en translation, we use the syntactic postordering method of (Goto et al., 2012). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score usi</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="5921" citStr="Koehn, 2004" startWordPosition="954" endWordPosition="955">n translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data. As evaluation measures, we use the standard BLEU (Papineni et al., 2002) as well as RIBES (Isozaki et al., 2010a), a reorderingbased metric that has been shown to have high correlation with human evaluations on the NTCIR data. We measure significance of results using bootstrap resampling at p &lt; 0.05 (Koehn, 2004). In tables, bold numbers indicate the best system and all systems that were not significantly different from the best system. 2.3 Motivational Experiment Before going into a detailed analysis, we first present results that stress the importance of the elements described in the introduction. To do so, System en-ja ja-en BLEU RIBES BLEU RIBES PBMT 35.84 72.89 30.49 69.80 Hiero 34.45 72.94 29.41 69.51 Pre/Post 36.69 77.05 29.42 73.85 T2S-all 36.23 76.60 31.15 72.87 T2S+all 40.84 80.15 33.70 75.94 Table 1: Overall results for five systems. we compare the 3 non-T2S baselines with two T2S systems t</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan K Kummerfeld</author>
<author>David Hall</author>
<author>James R Curran</author>
<author>Dan Klein</author>
</authors>
<title>Parser showdown at the wall street corral: an empirical investigation of error types in parser output.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>1048--1059</pages>
<contexts>
<context position="8748" citStr="Kummerfeld et al., 2012" startWordPosition="1408" endWordPosition="1411">ther genres and language pairs. For example, in a Japanese-Chinese/English medical conversation task (Neubig et al., 2013), forests, alignment, and search resulted in BLEU increases of en-ja 24.55→30.81, ja-en 19.28→22.46, zh-ja 15.22→20.67, ja-zh 30.88→33.89. 144 different syntactic parsers and examine the translation accuracy realized by each parser. For English, the two most widely referenced parsers are the Stanford Parser and Berkeley Parser. In this work, we compare the Stanford Parser’s CFG model, with the Berkeley Parser’s latent variable model. In previous reports, it has been noted (Kummerfeld et al., 2012) that the latent variable model of the Berkeley parser tends to have the higher accuracy of the two, so if the accuracy of a system using this model is higher then it is likely that parsing accuracy is important for T2S translation. Instead of the Berkeley Parser itself, we use a clone Egret,4 which achieves nearly identical accuracy, and is able to output packed forests for use in MT, as mentioned below. Trees are right-binarized, with the exception of phrase-final punctuation, which is split off before any other element in the phrase. For Japanese, our first method uses the MSTbased pointwis</context>
</contexts>
<marker>Kummerfeld, Hall, Curran, Klein, 2012</marker>
<rawString>Jonathan K Kummerfeld, David Hall, James R Curran, and Dan Klein. 2012. Parser showdown at the wall street corral: an empirical investigation of error types in parser output. In Proc. EMNLP, pages 1048–1059.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Treeto-string alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="1677" citStr="Liu et al., 2006" startWordPosition="244" endWordPosition="247">ements must be taken seriously in construction of these systems. 1 Introduction In recent years, syntactic parsing is being viewed as an ever-more important element of statistical machine translation (SMT) systems, particularly for translation between languages with large differences in word order. There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (Galley et al., 2006; Shen et al., 2008), tree-to-string (T2S) using source-side parsing as a hint during the translation process (Liu et al., 2006), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly </context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2006. Treeto-string alignment template for statistical machine translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Yajuan L¨u</author>
</authors>
<title>Adjoining tree-to-string translation.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1278--1287</pages>
<marker>Liu, Liu, L¨u, 2011</marker>
<rawString>Yang Liu, Qun Liu, and Yajuan L¨u. 2011. Adjoining tree-to-string translation. In Proc. ACL, pages 1278–1287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
</authors>
<title>Forestbased translation.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="2325" citStr="Mi et al., 2008" startWordPosition="346" endWordPosition="349">compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (Ambati and Lavie, 2008; Xie et al., 2011; Kaljahi et al., 2012). In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy. Our motivation in writing this paper is to provide a first</context>
<context position="9802" citStr="Mi et al. (2008)" startWordPosition="1589" endWordPosition="1592">th the exception of phrase-final punctuation, which is split off before any other element in the phrase. For Japanese, our first method uses the MSTbased pointwise dependency parser of Flannery et al. (2011), as implemented in the Eda toolkit.5 In order to convert dependencies into phrasestructure trees typically used in T2S translation, we use the head rules implemented in the Travatar toolkit. In addition, we also train a latent variable CFG using the Berkeley Parser and use Egret for parsing. Both models are trained on the Japanese Word Dependency Treebank (Mori et al., 2014). In addition, Mi et al. (2008) have proposed a method for forest-to-string (F2S) translation using packed forests to encode many possible sentence interpretations. By doing so, it is possible to resolve some of the ambiguity in syntactic interpretation at translation time, potentially increasing translation accuracy. However, the great majority of recent works on T2S translation do not consider multiple syntactic parses (e.g. Liu et al. (2011), Zhang et al. (2011)), and thus it is important to confirm the potential gains that could be acquired by taking ambiguity into account. 3.2 Effect of Parsing and Forest Input In Tabl</context>
</contexts>
<marker>Mi, Huang, Liu, 2008</marker>
<rawString>Haitao Mi, Liang Huang, and Qun Liu. 2008. Forestbased translation. In Proc. ACL, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinsuke Mori</author>
<author>Hideki Ogura</author>
<author>Tetsuro Sasada</author>
</authors>
<title>A Japanese word dependency corpus.</title>
<date>2014</date>
<booktitle>In Proc. LREC.</booktitle>
<contexts>
<context position="9771" citStr="Mori et al., 2014" startWordPosition="1583" endWordPosition="1586">ow. Trees are right-binarized, with the exception of phrase-final punctuation, which is split off before any other element in the phrase. For Japanese, our first method uses the MSTbased pointwise dependency parser of Flannery et al. (2011), as implemented in the Eda toolkit.5 In order to convert dependencies into phrasestructure trees typically used in T2S translation, we use the head rules implemented in the Travatar toolkit. In addition, we also train a latent variable CFG using the Berkeley Parser and use Egret for parsing. Both models are trained on the Japanese Word Dependency Treebank (Mori et al., 2014). In addition, Mi et al. (2008) have proposed a method for forest-to-string (F2S) translation using packed forests to encode many possible sentence interpretations. By doing so, it is possible to resolve some of the ambiguity in syntactic interpretation at translation time, potentially increasing translation accuracy. However, the great majority of recent works on T2S translation do not consider multiple syntactic parses (e.g. Liu et al. (2011), Zhang et al. (2011)), and thus it is important to confirm the potential gains that could be acquired by taking ambiguity into account. 3.2 Effect of P</context>
</contexts>
<marker>Mori, Ogura, Sasada, 2014</marker>
<rawString>Shinsuke Mori, Hideki Ogura, and Tetsuro Sasada. 2014. A Japanese word dependency corpus. In Proc. LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
<author>Yuji Matsumoto</author>
<author>Ryosuke Isotani</author>
<author>Yukichi Ikeda</author>
</authors>
<title>Towards high-reliability speech translation in the medical domain.</title>
<date>2013</date>
<booktitle>In Proc. MedNLP,</booktitle>
<pages>22--29</pages>
<contexts>
<context position="8246" citStr="Neubig et al., 2013" startWordPosition="1334" endWordPosition="1337">il in the following sections. In the remainder of the paper settings follow T2S+all except when otherwise noted. 3 Parsing 3.1 Parsing Overview As T2S translation uses parse trees both in training and testing of the system, an accurate syntactic parser is required. In order to test the extent that parsing accuracy affects translation, we use two 1Stanford/Eda, GIZA++, pop-limit 5000 cube pruning. 2Egret forests, Nile, pop-limit 5000 hypergraph search. 3We have also observed similar trends on other genres and language pairs. For example, in a Japanese-Chinese/English medical conversation task (Neubig et al., 2013), forests, alignment, and search resulted in BLEU increases of en-ja 24.55→30.81, ja-en 19.28→22.46, zh-ja 15.22→20.67, ja-zh 30.88→33.89. 144 different syntactic parsers and examine the translation accuracy realized by each parser. For English, the two most widely referenced parsers are the Stanford Parser and Berkeley Parser. In this work, we compare the Stanford Parser’s CFG model, with the Berkeley Parser’s latent variable model. In previous reports, it has been noted (Kummerfeld et al., 2012) that the latent variable model of the Berkeley parser tends to have the higher accuracy of the tw</context>
</contexts>
<marker>Neubig, Sakti, Toda, Nakamura, Matsumoto, Isotani, Ikeda, 2013</marker>
<rawString>Graham Neubig, Sakriani Sakti, Tomoki Toda, Satoshi Nakamura, Yuji Matsumoto, Ryosuke Isotani, and Yukichi Ikeda. 2013. Towards high-reliability speech translation in the medical domain. In Proc. MedNLP, pages 22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
</authors>
<title>The Kyoto free translation task.http://www.phontron.com/kftt.</title>
<date>2011</date>
<contexts>
<context position="13851" citStr="Neubig, 2011" startWordPosition="2266" endWordPosition="2267">her these results carry over to our current situation. As our baseline aligner, we use the GIZA++ implementation of the IBM models (Och and Ney, 2003) with the default options. To test the effect of improved alignment accuracy, we use the discriminative alignment method of Riesa and Marcu (2010) as implemented in the Nile toolkit.6 This method has the ability to use source- and targetside syntactic information, and has been shown to improve the accuracy of S2T translation. We trained Nile and tested both methods on the Japanese-English alignments provided with the Kyoto Free Translation Task (Neubig, 2011) (430k parallel sentences, 1074 manually aligned training sentences, and 120 manually aligned test sentences).7 As creating manual alignment data is costly, we also created two training sets that consisted of 1/4 and 1/16 of the total data to test if we can achieve an effect with smaller amounts of manually annotated data. The details of data size and alignment accuracy are shown in Table 3. 4.2 Effect of Alignment on Translation In Table 4, we show results when we vary the aligner between GIZA++ and Nile. For reference, we also demonstrate results when using the same alignments for PBMT and H</context>
</contexts>
<marker>Neubig, 2011</marker>
<rawString>Graham Neubig. 2011. The Kyoto free translation task.http://www.phontron.com/kftt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
</authors>
<title>Travatar: A forest-to-string machine translation engine based on tree transducers.</title>
<date>2013</date>
<booktitle>In Proc. ACL Demo Track,</booktitle>
<pages>91--96</pages>
<contexts>
<context position="4206" citStr="Neubig, 2013" startWordPosition="656" endWordPosition="658">for all these elements we see large increases of accuracy, with the final system greatly exceeding not only standard PBMT, but also state-of-the-art methods based on syntactic pre- or post-ordering. 143 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 143–149, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Experimental Setup 2.1 Systems Compared In our experiments, we use a translation model based on T2S tree transducers (Graehl and Knight, 2004), constructed using the Travatar toolkit (Neubig, 2013). Rules are extracted using the GHKM algorithm (Galley et al., 2006), and rules with up to 5 composed minimal rules, up to 2 nonterminals, and up to 10 terminals are used. We also prepare 3 baselines not based on T2S to provide a comparison with other systems in the literature. The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al., 2007). We use default settings, except for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which a</context>
</contexts>
<marker>Neubig, 2013</marker>
<rawString>Graham Neubig. 2013. Travatar: A forest-to-string machine translation engine based on tree transducers. In Proc. ACL Demo Track, pages 91–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="13388" citStr="Och and Ney, 2003" startWordPosition="2190" endWordPosition="2193">ly large translation forests that required large amounts of memory. 4 Alignment 4.1 Alignment Overview The second element that we investigate is alignment accuracy. It has been noted in many previous works that significant gains in alignment accuracy do not make a significant difference in translation results (Ayan and Dorr, 2006; Ganchev et al., 2008). However, none of these works have explicitly investigated the effect on T2S translation, so it is not clear whether these results carry over to our current situation. As our baseline aligner, we use the GIZA++ implementation of the IBM models (Och and Ney, 2003) with the default options. To test the effect of improved alignment accuracy, we use the discriminative alignment method of Riesa and Marcu (2010) as implemented in the Nile toolkit.6 This method has the ability to use source- and targetside syntactic information, and has been shown to improve the accuracy of S2T translation. We trained Nile and tested both methods on the Japanese-English alignments provided with the Kyoto Free Translation Task (Neubig, 2011) (430k parallel sentences, 1074 manually aligned training sentences, and 120 manually aligned test sentences).7 As creating manual alignm</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="5232" citStr="Och, 2003" startWordPosition="833" endWordPosition="834">t for setting the reordering limit or maximum chart span to the best-performing value of 24. As our last baselines, we use two methods based on syntactic pre- or post-ordering, which are state-ofthe-art methods for the language pairs. Specifically, for en-ja translation we use the head finalization pre-ordering method of (Isozaki et al., 2010b), and for ja-en translation, we use the syntactic postordering method of (Goto et al., 2012). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score using minimum error rate training (Och, 2003). 2.2 Data and Evaluation We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data. As evaluation measures, we use the standard BLEU (Papineni et al., 2002) as well as RIBES (Isozaki et al., 2010a), a reorderingbased metric that has been shown to have high correlation with human evaluations on the NTCIR data</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="5679" citStr="Papineni et al., 2002" startWordPosition="911" endWordPosition="914">12). For all systems, T2S or otherwise, the language model is a Kneser-Ney 5-gram, and tuning is performed to maximize BLEU score using minimum error rate training (Och, 2003). 2.2 Data and Evaluation We perform all of our experiments on en-ja and ja-en translation over data from the NTCIR PatentMT task (Goto et al., 2011), the most standard benchmark task for these language pairs. We use the training data from NTCIR 7/8, a total of approximately 3.0M sentences, and perform tuning on the NTCIR 7 dry run, testing on the NTCIR 7 formal run data. As evaluation measures, we use the standard BLEU (Papineni et al., 2002) as well as RIBES (Isozaki et al., 2010a), a reorderingbased metric that has been shown to have high correlation with human evaluations on the NTCIR data. We measure significance of results using bootstrap resampling at p &lt; 0.05 (Koehn, 2004). In tables, bold numbers indicate the best system and all systems that were not significantly different from the best system. 2.3 Motivational Experiment Before going into a detailed analysis, we first present results that stress the importance of the elements described in the introduction. To do so, System en-ja ja-en BLEU RIBES BLEU RIBES PBMT 35.84 72.</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. ACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riesa</author>
<author>Daniel Marcu</author>
</authors>
<title>Hierarchical search for word alignment.</title>
<date>2010</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>157--166</pages>
<contexts>
<context position="13534" citStr="Riesa and Marcu (2010)" startWordPosition="2214" endWordPosition="2217">is alignment accuracy. It has been noted in many previous works that significant gains in alignment accuracy do not make a significant difference in translation results (Ayan and Dorr, 2006; Ganchev et al., 2008). However, none of these works have explicitly investigated the effect on T2S translation, so it is not clear whether these results carry over to our current situation. As our baseline aligner, we use the GIZA++ implementation of the IBM models (Och and Ney, 2003) with the default options. To test the effect of improved alignment accuracy, we use the discriminative alignment method of Riesa and Marcu (2010) as implemented in the Nile toolkit.6 This method has the ability to use source- and targetside syntactic information, and has been shown to improve the accuracy of S2T translation. We trained Nile and tested both methods on the Japanese-English alignments provided with the Kyoto Free Translation Task (Neubig, 2011) (430k parallel sentences, 1074 manually aligned training sentences, and 120 manually aligned test sentences).7 As creating manual alignment data is costly, we also created two training sets that consisted of 1/4 and 1/16 of the total data to test if we can achieve an effect with sm</context>
</contexts>
<marker>Riesa, Marcu, 2010</marker>
<rawString>Jason Riesa and Daniel Marcu. 2010. Hierarchical search for word alignment. In Proc. ACL, pages 157–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>577--585</pages>
<contexts>
<context position="1569" citStr="Shen et al., 2008" startWordPosition="228" endWordPosition="231">the-art methods. These results indicate that T2S systems indeed hold much promise, but the above-mentioned elements must be taken seriously in construction of these systems. 1 Introduction In recent years, syntactic parsing is being viewed as an ever-more important element of statistical machine translation (SMT) systems, particularly for translation between languages with large differences in word order. There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (Galley et al., 2006; Shen et al., 2008), tree-to-string (T2S) using source-side parsing as a hint during the translation process (Liu et al., 2006), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly fro</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proc. ACL, pages 577–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsuhito Sudoh</author>
<author>Xianchao Wu</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Post-ordering in statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proc. MT Summit.</booktitle>
<contexts>
<context position="1855" citStr="Sudoh et al., 2011" startWordPosition="273" endWordPosition="276">cal machine translation (SMT) systems, particularly for translation between languages with large differences in word order. There are many ways of incorporating syntax into MT systems, including the use of string-to-tree translation (S2T) to ensure the syntactic well-formedness of the output (Galley et al., 2006; Shen et al., 2008), tree-to-string (T2S) using source-side parsing as a hint during the translation process (Liu et al., 2006), or preor post-ordering to help compensate for reordering problems experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting</context>
<context position="7268" citStr="Sudoh et al., 2011" startWordPosition="1180" endWordPosition="1183"> “T2Sall” is a system that uses the worst settings1 for each of these elements, while the second system “T2S+all” uses the best settings.2 The results for the systems are shown in Table 1. The most striking result is that T2S+all significantly exceeds all of the baselines, even including the pre/post-ordering baselines, which provide state-of-the-art results on this task. The gains are particularly striking on en-ja, with a gain of over 4 BLEU points over the closest system, but still significant on the ja-en task, where the use of sourceside syntax has proven less effective in previous work (Sudoh et al., 2011). The next thing to notice is that if we had instead used T2S-all, our conclusion would have been much different. This system is able to achieve respectable accuracy compared to PBMT or Hiero, but does not exceed the more competitive pre/post-ordering systems.3 With this result in hand, we will investigate the contribution of each of these elements in detail in the following sections. In the remainder of the paper settings follow T2S+all except when otherwise noted. 3 Parsing 3.1 Parsing Overview As T2S translation uses parse trees both in training and testing of the system, an accurate syntac</context>
</contexts>
<marker>Sudoh, Wu, Duh, Tsukada, Nagata, 2011</marker>
<rawString>Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. 2011. Post-ordering in statistical machine translation. In Proc. MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
</authors>
<title>Taro Watanabe, Eiichiro Sumita, Hiroya Takamura, and Manabu Okumura.</title>
<date>2013</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>841--851</pages>
<marker>Tamura, 2013</marker>
<rawString>Akihiro Tamura, Taro Watanabe, Eiichiro Sumita, Hiroya Takamura, and Manabu Okumura. 2013. Partof-speech induction in dependency trees for statistical machine translation. In Proc. ACL, pages 841– 851.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Xie</author>
<author>Haitao Mi</author>
<author>Qun Liu</author>
</authors>
<title>A novel dependency-to-string model for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>216--226</pages>
<contexts>
<context position="2617" citStr="Xie et al., 2011" startWordPosition="398" endWordPosition="401">ice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (Ambati and Lavie, 2008; Xie et al., 2011; Kaljahi et al., 2012). In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy. Our motivation in writing this paper is to provide a first step in examining and codifying the more important elements that make it possible to construct a highly accurate T2S MT system. To do so, we perform an empirical study of the effect of parsing accuracy, packed forest input, alignment accuracy, and search. The reason why we choose these elem</context>
</contexts>
<marker>Xie, Mi, Liu, 2011</marker>
<rawString>Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel dependency-to-string model for statistical machine translation. In Proc. EMNLP, pages 216–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zhang</author>
<author>David Chiang</author>
</authors>
<title>An exploration of forest-to-string translation: Does translation help or hurt parsing?</title>
<date>2012</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>317--321</pages>
<contexts>
<context position="11584" citStr="Zhang and Chiang (2012)" startWordPosition="1869" endWordPosition="1872">forest input. Forest n-best Cutoff Figure 1: BLEU scores using various levels of forest pruning. Numbers in the graph indicate decoding time in seconds/sentence. Egret achieves greater accuracy than that using the other two parsers. This improvement is particularly obvious in RIBES, indicating that an increase in parsing accuracy has a larger effect on global reordering than on lexical choice. When going from T2S to F2S translation using Egret, we see another large gain in accuracy, although this time with the gain in BLEU being more prominent. We believe this is related to the observation of Zhang and Chiang (2012) that F2S translation is not necessarily helping fixing parsing errors, but instead giving the translation system the freedom to ignore the parse somewhat, allowing for less syntactically motivated but more fluent translations. As passing some degree of syntactic ambiguity on to the decoder through F2S translation has proven useful, a next natural question is how much of this ambiguity we need to preserve in our forest. The pruning criterion that we use for the forest is based on including all edges that appear in one or more of the n-best parses, so we perform translation setting n to 1 (tree</context>
</contexts>
<marker>Zhang, Chiang, 2012</marker>
<rawString>Hui Zhang and David Chiang. 2012. An exploration of forest-to-string translation: Does translation help or hurt parsing? In Proc. ACL, pages 317–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Licheng Fang</author>
<author>Peng Xu</author>
<author>Xiaoyun Wu</author>
</authors>
<title>Binarized forest to string translation.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>835--845</pages>
<contexts>
<context position="2363" citStr="Zhang et al., 2011" startWordPosition="354" endWordPosition="357">experienced by non-syntactic methods such as phrase-based MT (PBMT) (Collins et al., 2005; Sudoh et al., 2011). Among these, T2S translation has a number of attractive theoretical properties, such as joint consideration of global reordering and lexical choice while maintaining relatively fast decoding times. However, building an accurate T2S system is not trivial. On one hand, there have been multiple reports (mainly from groups with a long history of building T2S systems) stating that systems using source-side syntax greatly out-perform phrasebased systems (Mi et al., 2008; Liu et al., 2011; Zhang et al., 2011; Tamura et al., 2013). On the other hand, there have been also been multiple reports noting the exact opposite result that sourceside syntax systems perform worse than Hiero, S2T, PBMT, or PBMT with pre-ordering (Ambati and Lavie, 2008; Xie et al., 2011; Kaljahi et al., 2012). In this paper, we argue that this is due to the fact that T2S systems have the potential to achieve high accuracy, but are also less robust, with a number of peripheral elements having a large effect on translation accuracy. Our motivation in writing this paper is to provide a first step in examining and codifying the m</context>
<context position="10240" citStr="Zhang et al. (2011)" startWordPosition="1656" endWordPosition="1659">variable CFG using the Berkeley Parser and use Egret for parsing. Both models are trained on the Japanese Word Dependency Treebank (Mori et al., 2014). In addition, Mi et al. (2008) have proposed a method for forest-to-string (F2S) translation using packed forests to encode many possible sentence interpretations. By doing so, it is possible to resolve some of the ambiguity in syntactic interpretation at translation time, potentially increasing translation accuracy. However, the great majority of recent works on T2S translation do not consider multiple syntactic parses (e.g. Liu et al. (2011), Zhang et al. (2011)), and thus it is important to confirm the potential gains that could be acquired by taking ambiguity into account. 3.2 Effect of Parsing and Forest Input In Table 2 we show the results for Stanford/Eda with 1-best tree input vs. Egret with trees or forests as input. Forests are those containing all edges in the 100-best parses. First looking at the difference between the two parsers, we can see that the T2S system using 4http://code.google.com/p/egret-parser 5http://plata.ar.media.kyoto-u.ac.jp/tool/EDA en-ja ja-en System BLEU RIBES BLEU RIBES Stan/Eda 38.95 78.47 32.56 73.03 Egret-T 39.26 79</context>
</contexts>
<marker>Zhang, Fang, Xu, Wu, 2011</marker>
<rawString>Hao Zhang, Licheng Fang, Peng Xu, and Xiaoyun Wu. 2011. Binarized forest to string translation. In Proc. ACL, pages 835–845.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>