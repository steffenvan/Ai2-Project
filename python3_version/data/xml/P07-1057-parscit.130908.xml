<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.034832">
<title confidence="0.9981215">
Clustering Clauses for High-Level Relation Detection: An
Information-theoretic Approach
</title>
<author confidence="0.998406">
Samuel Brody
</author>
<affiliation confidence="0.9984025">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.997181">
s.brody@sms.ed.ac.uk
</email>
<sectionHeader confidence="0.983077" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999927722222222">
Recently, there has been a rise of in-
terest in unsupervised detection of high-
level semantic relations involving com-
plex units, such as phrases and whole
sentences. Typically such approaches are
faced with two main obstacles: data
sparseness and correctly generalizing
from the examples. In this work, we
describe the Clustered Clause represen-
tation, which utilizes information-based
clustering and inter-sentence dependen-
cies to create a simplified and generalized
representation of the grammatical clause.
We implement an algorithm which uses
this representation to detect a predefined
set of high-level relations, and demon-
strate our model’s effectiveness in over-
coming both the problems mentioned.
</bodyText>
<sectionHeader confidence="0.997332" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999884823529412">
The semantic relationship between words, and
the extraction of meaning from syntactic data
has been one of the main points of research in
the field of computational linguistics (see Sec-
tion 5 and references therein). Until recently,
the focus has remained largely either at the sin-
gle word or sentence level (for instance: depen-
dency extraction, word-to-word semantic simi-
larity from syntax, etc.) or on relations between
units at a very high context level such as the
entire paragraph or document (e.g. categorizing
documents by topic).
Recently there have been several attempts to
define frameworks for detecting and studying in-
teractions at an intermediate context level, and
involving whole clauses or sentences. Dagan
et al. (2005) have emphasized the importance
of detecting textual-entailment/implication be-
tween two sentences, and its place as a key com-
ponent in many real-world applications, such as
Information Retrieval and Question Answering.
When designing such a framework, one is
faced with several obstacles. As we approach
higher levels of complexity, the problem of defin-
ing the basic units we study (e.g. words, sen-
tences etc.) and the increasing amount of in-
teractions make the task very difficult. In addi-
tion, the data sparseness problem becomes more
acute as the data units become more complex
and have an increasing number of possible val-
ues, despite the fact that many of these values
have similar or identical meaning.
In this paper we demonstrate an approach
to solving the complexity and data sparse-
ness problems in the task of detecting rela-
tions between sentences or clauses. We present
the Clustered Clause structure, which utilizes
information-based clustering and dependencies
within the sentence to create a simplified and
generalized representation of the grammatical
clause and is designed to overcome both these
problems.
The clustering method we employ is an inte-
gral part of the model. We evaluate our clusters
against semantic similarity measures defined on
the human-annotated WordNet structure (Fell-
baum, 1998). The results of these comparisons
show that our cluster members are very similar
semantically. We also define a high-level rela-
tion detection task involving relations between
clauses, evaluate our results, and demonstrate
</bodyText>
<page confidence="0.973245">
448
</page>
<note confidence="0.926054">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 448–455,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.991105333333333">
the effectiveness of using our model in this task.
This work extends selected parts of Brody
(2005), where further details can be found.
</bodyText>
<sectionHeader confidence="0.906291" genericHeader="method">
2 Model Construction
</sectionHeader>
<bodyText confidence="0.999734392857143">
When designing our framework, we must ad-
dress the complexity and sparseness problems
encountered when dealing with whole sentences.
Our solution to these issues combines two ele-
ments. First, to reduce complexity, we simplify
a grammatical clause to its primary components
- the subject, verb and object. Secondly, to pro-
vide a generalization framework which will en-
able us to overcome data-sparseness, we cluster
each part of the clause using data from within
the clause itself. By combining the simplified
clause structure and the clustering we produce
our Clustered Clause model - a triplet of clusters
representing a generalized clause.
The Simplified Clause: In order to extract
clauses from the text, we use Lin&apos;s parser MINI-
PAR (Lin, 1994). The output of the parser is
a dependency tree of each sentence, also con-
taining lemmatized versions of the component
words. We extract the verb, subject and object
of every clause (including subordinate clauses),
and use this triplet of values, the simplified
clause, in place of the original complete clause.
As seen in Figure 1, these components make up
the top (root) triangle of the clause parse tree.
We also use the lemmatized form of the words
provided by the parser, to further reduce com-
plexity.
</bodyText>
<figureCaption confidence="0.821996333333333">
Figure 1: The parse tree for the sentence “John
found a solution to the problem”. The subject-
verb-object triplet is marked with a border.
</figureCaption>
<bodyText confidence="0.9936441">
Clustering Clause Components: For our
model, we cluster the data to provide both gen-
eralization, by using a cluster to represent a
more generalized concept shared by its compo-
nent words, and a form of dimensionality reduc-
tion, by using fewer units (clusters) to represent
a much larger amount of words.
We chose to use the Sequential Information
Bottleneck algorithm (Slonim et al., 2002) for
our clustering tasks. The information Bottle-
neck principle views the clustering task as an
optimization problem, where the clustering algo-
rithm attempts to group together values of one
variable while retaining as much information as
possible regarding the values of another (target)
variable. There is a trade-off between the com-
pactness of the clustering and the amount of re-
tained information. This algorithm (and others
based on the IB principle) is especially suited for
use with graphical models or dependency struc-
tures, since the distance measure it employs in
the clustering is defined solely by the depen-
dency relation between two variables, and there-
fore required no external parameters. The val-
ues of one variable are clustered using their co-
occurrence distribution with regard to the values
of the second (target) variable in the dependency
relation. As an example, consider the following
subject-verb co-occurrence matrix:
S \ V tell scratch drink
dog 0 4 5
John 4 0 9
cat 0 6 3
man 6 1 2
The value in cell (i, j) indicates the number
of times the noun i occurred as the subject of
the verb j. Calculating the Mutual Information
between the subjects variable (S) and verbs vari-
able (V) in this table, we get MI(5,V) = 0.52
bits. Suppose we wish to cluster the subject
nouns into two clusters while preserving the
highest Mutual Information with regard to the
verbs. The following co-occurrence matrix is the
optimal clustering, and retains a M.I. value of
0.4 bits (77% of original):
Clustered S \ V tell scratch drink
{dog,cat} 0 10 8
{John,man} 10 1 11
Notice that although the values in the drink
column are higher than in others, and we may be
</bodyText>
<page confidence="0.998832">
449
</page>
<bodyText confidence="0.995772951807229">
tempted to cluster together dog and John based
on this column, the informativeness of this verb
is smaller - if we know the verb is tell we can be
sure the noun is not dog or cat, whereas if we
know it is drink, we can only say it is slightly
more probable that the noun is John or dog.
Our dependency structure consists of three
variables: subject, verb, and object, and we take
advantage of the subject-verb and verb-object
dependencies in our clustering. The clustering
was performed on each variable separately, in
a two phase procedure (see Figure 2). In the
first stage, we clustered the subject variable into
200 clustersi, using the subject-verb dependency
(i.e. the verb variable was the target). The same
was done with the object variable, using the
verb-object dependency. In the second phase, we
wish to cluster the verb values with regard to
both the subject and object variables. We could
not use all pairs of subjects and objects values as
the target variable in this task, since too many
such combinations exist. Instead, we used a vari-
able composed of all the pairs of subject and ob-
ject clusters as the target for the verb clustering.
In this fashion we produced 100 verb clusters.
Figure 2: The two clustering phases. Arrows rep-
resent dependencies between the variables which
are used in the clustering.
Combining the Model Elements: Having
obtained our three clustered variables, our orig-
inal simplified clause triplet can now be used
to produce the Clustered Clause model. This
model represents a clause in the data by a triplet
of cluster indexes, one cluster index for each
clustered variable. In order to map a clause in
&apos;The chosen numbers of clusters are such that each
the resulting clustered variables preserved approximately
half of the co-occurrence mutual information that existed
between the original (unclustered) variable and its target.
the text to its corresponding clustered clause,
it is first parsed and lemmatized to obtain the
subject, verb and object values, as described
above, and then assigned to the clustered clause
in which the subject cluster index is that of
the cluster containing the subject word of the
clause, and the same for the verb and object
words. For example, the sentence “The terrorist
threw the grenade” would be converted to the
triplet (terrorist, throw, grenade) and assigned
to the clustered clause composed of the three
clusters to which these words belong. Other
triplets assigned to this clustered clause might
include (fundamentalist, throw, bomb) or (mil-
itant, toss, explosive). Applying this procedure
to the entire text corpus results in a distilla-
tion of the text into a series of clustered clauses
containing the essential information about the
actions described in the text.
Technical Specifications: For this work we
chose to use the entire Reuters Corpus (En-
glish, release 2000), containing 800,000 news
articles collected uniformly from 20/8/1996 to
19/8/1997. Before clustering, several prepro-
cessing steps were taken. We had a very large
amount of word values for each of the Sub-
ject (85,563), Verb (4,593) and Object (74,842)
grammatical categories. Many of the words were
infrequent proper nouns or rare verbs and were
of little interest in the pattern recognition task.
We therefore removed the less frequent words
- those appearing in their category less than
one hundred times. We also cleaned our data
by removing all words that were one letter in
length, other than the word T. These were
mostly initials in names of people or compa-
nies, which were uninformative without the sur-
rounding context. This processing step brought
us to the final count of 2,874,763 clause triplets
(75.8% of the original number), containing 3,153
distinct subjects, 1,716 distinct verbs, and 3,312
distinct objects. These values were clustered as
described above. The clusters were used to con-
vert the simplified clauses into clustered clauses.
</bodyText>
<sectionHeader confidence="0.930753" genericHeader="method">
3 Evaluating Cluster Quality
</sectionHeader>
<bodyText confidence="0.9942255">
Examples of some of the resulting clusters are
provided in Table 1. When manually examin-
</bodyText>
<page confidence="0.978713">
450
</page>
<table confidence="0.999553631578947">
“Technical Developements&amp;quot; (Subject
Cluster 160): treatment, drug, method, tactic,
version, technology, software, design, device, vaccine,
ending, tool, mechanism, technique, instrument,
therapy, concept, model
“Ideals/Virtues” (Object Cluster 14):
sovereignty, dominance, logic, validity, legitimacy,
freedom, discipline, viability, referendum, wisdom,
innocence, credential, integrity, independence
“Emphasis Verbs” (Verb Cluster 92): im-
ply, signify, highlight, mirror, exacerbate, mark, sig-
nal, underscore, compound, precipitate, mask, illus-
trate, herald, reinforce, suggest, underline, aggra-
vate, reflect, demonstrate, spell, indicate, deepen
“Plans” (Object Cluster 33): journey, ar-
rangement, trip, effort, attempt, revolution, pull-
out, handover, sweep, preparation, filing, start, play,
repatriation, redeployment, landing, visit, push,
transition, process
</table>
<tableCaption confidence="0.999908">
Table 1: Example clusters (labeled manually).
</tableCaption>
<bodyText confidence="0.999932970588235">
ing the clusters, we noticed the “fine-tuning&amp;quot;
of some of the clusters. For instance, we had
a cluster of countries involved in military con-
flicts, and another for other countries; a cluster
for winning game scores, and another for ties;
etc. The fact that the algorithm separated these
clusters indicates that the distinction between
them is important with regard to the interac-
tions within the clause. For instance, in the first
example, the context in which countries from the
first cluster appear is very different from that in-
volving countries in the second cluster.
The effect of the dependencies we use is also
strongly felt. Many clusters can be described by
labels such as “things that are thrown” (rock,
flower, bottle, grenade and others), or “verbs
describing attacks” (spearhead, foil, intensify,
mount, repulse and others). While such crite-
ria may not be the first choice of someone who
is asked to cluster verbs or nouns, they repre-
sent unifying themes which are very appropri-
ate to pattern detection tasks, in which we wish
to detect connections between actions described
in the clauses. For instance, we would like to
detect the relation between throwing and mil-
itary/police action (much of the throwing de-
scribed in the news reports fits this relation). In
order to do this, we must have clusters which
unite the words relevant to those actions. Other
criteria for clustering would most likely not be
suitable, since they would probably not put egg,
bottle and rock in the same category. In this re-
spect, our clustering method provides a more
effective modeling of the domain knowledge.
</bodyText>
<subsectionHeader confidence="0.992009">
3.1 Evaluation via Semantic Resource
</subsectionHeader>
<bodyText confidence="0.992236071428571">
Since the success of our pattern detection task
depends to a large extent on the quality of our
clusters, we performed an experiment designed
to evaluate semantic similarity between mem-
bers of our clusters. For this purpose we made
use of the WordNet Similarity package (Peder-
sen et al., 2004). This package contains many
similarity measures, and we selected three of
them (Resnik (1995), Leacock and Chodorow
(1997), Hirst and St-Onge (1997)), which make
use of different aspects of WordNet (hierarchy
and graph structure). We measured the average
pairwise similarity between any two words ap-
pearing in the same cluster. We then performed
the same calculation on a random grouping of
the words, and compared the two scores. The re-
sults (Fig. 3) show that our clustering, based on
co-occurrence statistics and dependencies within
the sentence, correlates with a purely semantic
similarity as represented by the WordNet struc-
ture, and cannot be attributed to chance.
Figure 3: Inter-cluster similarity (average pair-
wise similarity between cluster members) in our
clustering (light) and a random one (dark). Ran-
dom clustering was performed 10 times. Aver-
age values are shown with error bars to indicate
standard deviation. Only Hirst &amp; St-Onge mea-
sure verb similarity.
</bodyText>
<sectionHeader confidence="0.994416" genericHeader="method">
4 Relation Detection Task
</sectionHeader>
<bodyText confidence="0.999847">
Motivation: In order to demonstrate the use
of our model, we chose a relation detection task.
The workshop on entailment mentioned in the
introduction was mainly focused on detecting
whether or not an entailment relation exists be-
tween two texts. In this work we present a com-
</bodyText>
<page confidence="0.981261">
451
</page>
<bodyText confidence="0.989071666666667">
plementary approach - a method designed to au- currence probability for each pattern3. In or-
tomatically detect relations between portions of der to estimate the mean and standard devia-
text and generate a knowledge base of the de- tion values, we created 100 simulated sequences
tected relations in a generalized form. As stated of triplets (representing clustered clauses) which
by (Dagan et al., 2005), such relations are im- were independently distributed and varied only
portant for IR applications. In addition, the pat- in their overall probability of occurrence. We
terns we employ are likely to be useful in other then estimated the mean and standard devia-
linguistic tasks involving whole clauses, such as tion for any pair of clauses in the actual data
paraphrase acquisition. using the simulated sequences.
Pattern Definition: For our relation detec- (X, V C36, OC7) →10 (X, V C57, OC85)
tion task, we searched for instances of prede- storm, lash, province ... storm, cross, Cuba
fined patterns indicating a relation between two quake, shake, city ... quake, hit, Iran
clustered clauses. We restricted the search to earthquake, jolt, city ... earthquake, hit, Iran
clause pairs which co-occur within a distance of (X, V C40, OC165) →10 (X, V C52, OC152)
ten clauses from each other. In addition to the police, arrest, leader ... police, search, mosque
distance restriction, we required an anchor: a police, detain, leader ... police, search, mosque
noun that appears in both clauses, to further police, arrest, member ... police, raid, enclave
strengthen the relation between them. Noun an- (SC39, V C21, X) →10 (X, beat 4, OC155)
chors establish the fact that the two compo- sun, report, earnings ... earnings,beat,expectation
nent actions described by the pattern involve the xerox, report, earnings ... earnings, beat, forecast
same entities, implying a direct connection be- microsoft,release,result ... result, beat, forecast
tween them. The use of verb anchors was also (X, V C57, OC7) →10 (X, cause 4, OC153)
tested, but found to be less helpful in detect- storm, hit, coast ... storm, cause, damage
ing significant patterns, since in most cases it cyclone, near, coast ... cyclone, cause, damage
simply found verbs which tend to repeat them- earthquake,hit,northwest ... earthquake,cause,damage
selves frequently in a context. The method we quake , hit, northwest ... quake, cause, casualty
describe assumes that statistically significant co- earthquake,hit,city ... earthquake,cause,damage
occurrences indicate a relationship between the Table 2: Example Patterns
clauses, but does not attempt to determine the
type of relation.
Significance Calculation: The patterns de-
tected by the system were scored using the sta-
tistical p-value measure. This value represents
the probability of detecting a certain number
of occurrences of a given pattern in the data
under the independence assumption, i.e. assum-
ing there is no connection between the two
halves of the pattern. If the system has detected
k instances of a certain pattern, we calculate
the probability of encountering this number of
instances under the independence assumption.
The smaller the probability, the higher the sig-
nificance. We consider patterns with a chance
probability lower than 5% to be significant.
We assume a Gaussian-like distribution of oc-
4.1 Pattern Detection Results
In Table 2 we present several examples of
high ranking (i.e. significance) patterns with
different anchorings detected by our method.
The detected patterns are represented using
the notation of the form (SCi, V Cj, X) —*,,,
(X, V Ci,, OCj,). X indicates the anchoring
word. In the example notation, the anchoring
word is the object of the first clause and the
subject of the second (O-S for short). n indicates
the maximal distance between the two clauses.
The terms SC, V C or OC with a subscripted
index represent the cluster containing the sub-
ject, verb or object (respectively) of the appro-
priate clause. For instance, in the first example
in Table 2, V C36 indicates verb cluster no. 36,
containing the verbs lash, shake and jolt, among
others.
3Based on Gwadera et al. (2003), dealing with a sim-
ilar, though simpler, case.
4In two of the patterns, instead of a cluster for the
verb, we have a single word - beat or cause. This is the
result of an automatic post-processing stage intended to
prevent over-generalization. If all the instances of the pat-
2Our experiments showed that increasing the distance
beyond this point did not result in significant increase in
the number of detected patterns.
</bodyText>
<table confidence="0.948378142857143">
452
Anchoring Number of
System Patterns Found
Subject-Subject 428
Object-Object 291
Subject-Object 180
Object-Subject 178
</table>
<tableCaption confidence="0.999754">
Table 3: Numbers of patterns found (p &lt; 5%)
</tableCaption>
<bodyText confidence="0.990902910714286">
Table 3 lists the number of patterns found,
for each anchoring system. The different anchor-
ing systems produce quantitatively different re-
sults. Anchoring between the same categories
produces more patterns than between the same
noun in different grammatical roles. This is ex-
pected, since many nouns can only play a certain
part in the clause (for instance, many verbs can-
not have an inanimate entity as their subject).
The number of instances of patterns we found
for the anchored template might be considered
low, and it is likely that some patterns were
missed simply because their occurrence proba-
bility was very low and not enough instances of
the pattern occurred in the text. In Section 4 we
stated that in this task, we were more interested
in precision than in recall. In order to detect a
wider range of patterns, a less restricted defini-
tion of the patterns, or a different significance
indicator, should be used (see Sec. 6).
Human Evaluation: In order to better de-
termine the quality of patterns detected by our
system, and confirm that the statistical signif-
icance testing is consistent with human judg-
ment, we performed an evaluation experiment
with the help of 22 human judges. We presented
each of the judges with 60 example groups, 15
for each type of anchoring. Each example group
contained three clause pairs conforming to the
anchoring relation. The clauses were presented
in a normalized form consisting only of a sub-
ject, object and verb converted to past tense,
with the addition of necessary determiners and
prepositions. For example, the triplet (police,
detain, leader) was converted to “The police de-
tained the leader”. In half the cases (randomly
tern in the text contained the same word in a certain po-
sition (in these examples - the verb position in the second
clause), this word was placed in that position in the gen-
eralized pattern, rather than the cluster it belonged to.
Since we have no evidence for the fact that other words
in the cluster can fit that position, using the cluster in-
dicator would be over-generalizing.
selected), these clause pairs were actual exam-
ples (instances) of a pattern detected by our sys-
tem (instances group), such as those appearing
in Table 2. In the other half, we listed three
clause pairs, each of which conformed to the
anchoring specification listed in Section 4, but
which were randomly sampled from the data,
and so had no connection to one another (base-
line group). We asked the judges to rate on a
scale of 1-5 whether they thought the clause
pairs were a good set of examples of a common
relation linking the first clause in each pair to
the second one.
</bodyText>
<table confidence="0.998824428571429">
Instances Instances Baseline Baseline
Score StdDev Score StdDev
All 3.5461 0.4780 2.6341 0.4244
O-S 3.9266 0.6058 2.8761 0.5096
O-O 3.4938 0.5144 2.7464 0.6205
S-O 3.4746 0.7340 2.5758 0.6314
S-S 3.2398 0.4892 2.3584 0.5645
</table>
<tableCaption confidence="0.998269">
Table 4: Results for human evaluation
</tableCaption>
<bodyText confidence="0.994843851851852">
Table 4 reports the overall average scores for
baseline and instances groups, and for each of
the four anchoring types individually. The scores
were averaged over all examples and all judges.
An ANOVA showed the difference in scores be-
tween the baseline and instance groups to be
significant (p &lt; 0.001) in all four cases.
Achievement of Model Goals: We em-
ployed clustering in our model to overcome data-
sparseness. The importance of this decision was
evident in our results. For example, the second
pattern shown in Table 2 appeared only four
times in the text. In these instances, verb cluster
40 was represented twice by the verb arrest and
twice by detain. Two appearances are within the
statistical deviation of all but the rarest words,
and would not have been detected as significant
without the clustering effect. This means the
pattern would have been overlooked, despite the
strongly intuitive connection it represents. The
system detected several such patterns.
The other reason for clustering was general-
ization. Even in cases where patterns involving
single words could have been detected, it would
have been impossible to unify similar patterns
into generalized ones. In addition, when encoun-
tering a new clause which differs slightly from
</bodyText>
<page confidence="0.98085">
453
</page>
<bodyText confidence="0.999129588888889">
the ones we recognized in the original data, there ilar clauses are clustered together in the same
would be no way to recognize it and draw the ap- Clustered-Clause, which could be compared to
propriate conclusions. For example, there would clustering DIRT&apos;s paths using its similarity mea-
be no way to relate the sentence “The typhoon sure. Despite these similarities, there are several
approached the coast” to the fourth example pat- important differences between the two systems.
tern, and the connection with the resulting dam- Our method uses only the relationships inside
age would not be recognized. the path or clause in the clustering procedure,
5 Comparison with Previous Work so the similarity is based on the structure it-
The relationship between textual features and self. Furthermore, Lin and Pantel did not create
semantics and the use of syntax as an indica- path clusters or generalized paths, so that while
tor of semantics has been widespread. Following their method allowed them to compare phrases
the idea proposed in Harris’ Distributional Hy- for similarity, there is no convenient way to iden-
pothesis (Harris, 1985), that words occurring in tify high level contextual relationships between
similar contexts are semantically similar, many two nearby sentences. This is one of the signifi-
works have used different definitions of context cant advantages that clustering has over similar-
to identify various types of semantic similarity. ity measures - it allows a group of similar objects
Hindle (1990) uses a mutual-information based to be represented by a single unit.
metric derived from the distribution of subject, There have been several attempts to formu-
verb and object in a large corpus to classify late and detect relationships at a higher context
nouns. Pereira et al. (1993) cluster nouns ac- level. The VerbOcean project (Chklovski and
cording to their distribution as direct objects Pantel, 2004) deals with relations between verbs.
of verbs, using information-theoretic tools (the It presents an automatically acquired network
predecessors of the tools we use in this work). of such relations, similar to the WordNet frame-
They suggest that information theoretic mea- work. Though the patterns used to acquire the
sures can also measure semantic relatedness. relations are usually parts of a single sentence,
These works focus only on relatedness of indi- the relationships themselves can also be used
vidual words and do not describe how the au- to describe connections between different sen-
tomatic estimation of semantic similarity can tences, especially the enablement and happens-
be useful in real-world tasks. In our work we before relations. Since verbs are the central part
demonstrate that using clusters as generalized of the clause, VerbOcean can be viewed as de-
word units helps overcome the sparseness and tecting relations between clauses as whole units,
generalization problems typically encountered as well as those between individual words. As
when attempting to extract high-level patterns a solution to the data sparseness problem, web
from text, as required for many applications. queries are used. Torisawa (2006) addresses a
The DIRT system (Lin and Pantel, 2001) similar problem, but focuses on temporal re-
deals with inference rules, and employs the no- lations, and makes use of the phenomena of
tion of paths between two nouns in a sentence’s Japanese coordinate sentences. Neither of these
parse tree. The system extracts such path struc- approaches attempt to create generalized rela-
tures from text, and provides a similarity mea- tions or group verbs into clusters, though in
sure between two such paths by comparing the the case of VerbOcean this could presumably
words which fill the same slots in the two paths. be done using the similarity and strength values
After extracting the paths, the system finds which are defined and detected by the system.
groups of similar paths. This approach bears 6 Future Work
several similarities to the ideas described in this The clustered clause model presents many di-
paper, since our structure can be seen as a rections for further research. It may be produc-
specific path in the parse tree (probably the tive to extend the model further, and include
most basic one, see Fig. 1). In our setup, sim- other parts of the sentence, such as adjectives
454
and adverbs. Clustering nouns by the adjectives
that describe them may provide a more intu-
itive grouping. The addition of further elements
to the structure may also allow the detection of
new kinds of relations.
The news-oriented domain of the corpus we
used strongly influenced our results. If we were
interested in more mundane relations, involving
day-to-day actions of individuals, a literary cor-
pus would probably be more suitable.
In defining our pattern template, several ele-
ments were tailored specifically to our task. We
limited ourselves to a very restricted set of pat-
terns in order to better demonstrate the effec-
tiveness of our model. For a more general knowl-
edge acquisition task, several of these restric-
tions may be relaxed, allowing a much larger
set of relations to be detected. For example, a
less strict significance filter, such as the support
and confidence measures commonly used in data
mining, may be preferable. These can be set to
different thresholds, according to the user’s pref-
erence.
In our current work, in order to prevent over-
generalization, we employed a single step post-
processing algorithm which detected the incor-
rect use of an entire cluster in place of a single
word (see footnote for Table 2). This method
allows only two levels of generalization - sin-
gle words and whole clusters. A more appro-
priate way to handle generalization would be
to use a hierarchical clustering algorithm. The
Agglomerative Information Bottleneck (Slonim
and Tishby, 1999) is an example of such an al-
gorithm, and could be employed for this task.
Use of a hierarchical method would result in
several levels of clusters, representing different
levels of generalization. It would be relatively
easy to modify our procedure to reduce general-
ization to the level indicated by the pattern ex-
amples in the text, producing a more accurate
description of the patterns detected.
</bodyText>
<sectionHeader confidence="0.997103" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998262">
The author acknowledges the support of EPSRC grant
EP/C538447/1. The author would like to thank Naftali
Tishby and Mirella Lapata for their supervision and as-
sistance on large portions of the work presented here. I
would also like to thank the anonymous reviewers and
my friends and colleagues for their helpful comments.
</bodyText>
<sectionHeader confidence="0.992101" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999413653846154">
Brody, Samuel. 2005. Cluster-Based Pattern Recognition
in Natural Language Text. Master’s thesis, Hebrew
University, Jerusalem, Israel.
Chklovski, T. and P. Pantel. 2004. Verbocean: Mining
the web for fine-grained semantic verb relations. In
Proc. of EMNLP. pages 33–40.
Dagan, I., O. Glickman, and B. Magnini. 2005. The
pascal recognising textual entailment challenge. In
Proceedings of the PASCAL Challenges Workshop on
Recognising Textual Entailment.
Fellbaum, Christiane, editor. 1998. WordNet: An Elec-
tronic Database. MIT Press, Cambridge, MA.
Gwadera, R., M. Atallah, and W. Szpankowski. 2003.
Reliable detection of episodes in event sequences. In
ICDM.
Harris, Z. 1985. Distributional structure. Katz, J. J.
(ed.) The Philosophy of Linguistics pages 26–47.
Hindle, Donald. 1990. Noun classification from predicate-
argument structures. In Meeting of the ACL. pages
268–275.
Hirst, G. and D. St-Onge. 1997. Lexical chains as repre-
sentation of context for the detection and correction
of malapropisms. In WordNet: An Electronic Lexical
Database, ed., Christiane Fellbaum. MIT Press.
Leacock, C. and M. Chodorow. 1997. Combining local
context and wordnet similarity for word sense identi-
fication. In WordNet: An Electronic Lexical Database,
ed., Christiane Fellbaum. MIT Press.
Lin, Dekang. 1994. Principar - an efficient, broad-
coverage, principle-based parser. In COLING. pages
482–488.
Lin, Dekang and Patrick Pantel. 2001. DIRT - discovery
of inference rules from text. In Knowledge Discovery
and Data Mining. pages 323–328.
Pedersen, T., S. Patwardhan, and J. Michelizzi. 2004.
Wordnet::similarity - measuring the relatedness of con-
cepts. In Proc. of AAAI-04.
Pereira, F., N. Tishby, and L. Lee. 1993. Distributional
clustering of english words. In Meeting of the Associ-
ation for Computational Linguistics. pages 183–190.
Resnik, Philip. 1995. Using information content to eval-
uate semantic similarity in a taxonomy. In IJCAI.
pages 448–453.
Slonim, N., N. Friedman, and N. Tishby. 2002. Unsu-
pervised document classification using sequential in-
formation maximization. In Proc. of SIGIR&apos;02.
Slonim, N. and N. Tishby. 1999. Agglomerative informa-
tion bottleneck. In Proc. of NIPS-12.
Torisawa, Kentaro. 2006. Acquiring inference rules with
temporal constraints by using japanese coordinated
sentences and noun-verb co-occurrences. In Proceed-
ings of NAACL. pages 57–64.
</reference>
<page confidence="0.999052">
455
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966061">
<title confidence="0.999003">Clustering Clauses for High-Level Relation Detection: An Information-theoretic Approach</title>
<author confidence="0.999952">Samuel Brody</author>
<affiliation confidence="0.9998515">School of Informatics University of Edinburgh</affiliation>
<email confidence="0.998083">s.brody@sms.ed.ac.uk</email>
<abstract confidence="0.998378315789474">Recently, there has been a rise of interest in unsupervised detection of highlevel semantic relations involving complex units, such as phrases and whole sentences. Typically such approaches are faced with two main obstacles: data sparseness and correctly generalizing from the examples. In this work, we the Clause representation, which utilizes information-based clustering and inter-sentence dependencies to create a simplified and generalized representation of the grammatical clause. We implement an algorithm which uses this representation to detect a predefined set of high-level relations, and demonstrate our model’s effectiveness in overcoming both the problems mentioned.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
</authors>
<title>Cluster-Based Pattern Recognition in Natural Language Text. Master’s thesis,</title>
<date>2005</date>
<institution>Hebrew University,</institution>
<location>Jerusalem,</location>
<contexts>
<context position="3458" citStr="Brody (2005)" startWordPosition="516" endWordPosition="517">inst semantic similarity measures defined on the human-annotated WordNet structure (Fellbaum, 1998). The results of these comparisons show that our cluster members are very similar semantically. We also define a high-level relation detection task involving relations between clauses, evaluate our results, and demonstrate 448 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 448–455, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics the effectiveness of using our model in this task. This work extends selected parts of Brody (2005), where further details can be found. 2 Model Construction When designing our framework, we must address the complexity and sparseness problems encountered when dealing with whole sentences. Our solution to these issues combines two elements. First, to reduce complexity, we simplify a grammatical clause to its primary components - the subject, verb and object. Secondly, to provide a generalization framework which will enable us to overcome data-sparseness, we cluster each part of the clause using data from within the clause itself. By combining the simplified clause structure and the clusterin</context>
</contexts>
<marker>Brody, 2005</marker>
<rawString>Brody, Samuel. 2005. Cluster-Based Pattern Recognition in Natural Language Text. Master’s thesis, Hebrew University, Jerusalem, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovski</author>
<author>P Pantel</author>
</authors>
<title>Verbocean: Mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<pages>33--40</pages>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Chklovski, T. and P. Pantel. 2004. Verbocean: Mining the web for fine-grained semantic verb relations. In Proc. of EMNLP. pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>B Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>In Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</booktitle>
<contexts>
<context position="1629" citStr="Dagan et al. (2005)" startWordPosition="235" endWordPosition="238">oints of research in the field of computational linguistics (see Section 5 and references therein). Until recently, the focus has remained largely either at the single word or sentence level (for instance: dependency extraction, word-to-word semantic similarity from syntax, etc.) or on relations between units at a very high context level such as the entire paragraph or document (e.g. categorizing documents by topic). Recently there have been several attempts to define frameworks for detecting and studying interactions at an intermediate context level, and involving whole clauses or sentences. Dagan et al. (2005) have emphasized the importance of detecting textual-entailment/implication between two sentences, and its place as a key component in many real-world applications, such as Information Retrieval and Question Answering. When designing such a framework, one is faced with several obstacles. As we approach higher levels of complexity, the problem of defining the basic units we study (e.g. words, sentences etc.) and the increasing amount of interactions make the task very difficult. In addition, the data sparseness problem becomes more acute as the data units become more complex and have an increas</context>
<context position="15524" citStr="Dagan et al., 2005" startWordPosition="2460" endWordPosition="2463">ose a relation detection task. The workshop on entailment mentioned in the introduction was mainly focused on detecting whether or not an entailment relation exists between two texts. In this work we present a com451 plementary approach - a method designed to au- currence probability for each pattern3. In ortomatically detect relations between portions of der to estimate the mean and standard deviatext and generate a knowledge base of the de- tion values, we created 100 simulated sequences tected relations in a generalized form. As stated of triplets (representing clustered clauses) which by (Dagan et al., 2005), such relations are im- were independently distributed and varied only portant for IR applications. In addition, the pat- in their overall probability of occurrence. We terns we employ are likely to be useful in other then estimated the mean and standard devialinguistic tasks involving whole clauses, such as tion for any pair of clauses in the actual data paraphrase acquisition. using the simulated sequences. Pattern Definition: For our relation detec- (X, V C36, OC7) →10 (X, V C57, OC85) tion task, we searched for instances of prede- storm, lash, province ... storm, cross, Cuba fined pattern</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Dagan, I., O. Glickman, and B. Magnini. 2005. The pascal recognising textual entailment challenge. In Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Database.</title>
<date>1998</date>
<editor>Fellbaum, Christiane, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Fellbaum, Christiane, editor. 1998. WordNet: An Electronic Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gwadera</author>
<author>M Atallah</author>
<author>W Szpankowski</author>
</authors>
<title>Reliable detection of episodes in event sequences.</title>
<date>2003</date>
<booktitle>In ICDM.</booktitle>
<contexts>
<context position="19266" citStr="Gwadera et al. (2003)" startWordPosition="3054" endWordPosition="3057">represented using the notation of the form (SCi, V Cj, X) —*,,, (X, V Ci,, OCj,). X indicates the anchoring word. In the example notation, the anchoring word is the object of the first clause and the subject of the second (O-S for short). n indicates the maximal distance between the two clauses. The terms SC, V C or OC with a subscripted index represent the cluster containing the subject, verb or object (respectively) of the appropriate clause. For instance, in the first example in Table 2, V C36 indicates verb cluster no. 36, containing the verbs lash, shake and jolt, among others. 3Based on Gwadera et al. (2003), dealing with a similar, though simpler, case. 4In two of the patterns, instead of a cluster for the verb, we have a single word - beat or cause. This is the result of an automatic post-processing stage intended to prevent over-generalization. If all the instances of the pat2Our experiments showed that increasing the distance beyond this point did not result in significant increase in the number of detected patterns. 452 Anchoring Number of System Patterns Found Subject-Subject 428 Object-Object 291 Subject-Object 180 Object-Subject 178 Table 3: Numbers of patterns found (p &lt; 5%) Table 3 list</context>
</contexts>
<marker>Gwadera, Atallah, Szpankowski, 2003</marker>
<rawString>Gwadera, R., M. Atallah, and W. Szpankowski. 2003. Reliable detection of episodes in event sequences. In ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1985</date>
<booktitle>The Philosophy of Linguistics</booktitle>
<pages>26--47</pages>
<editor>Katz, J. J. (ed.)</editor>
<contexts>
<context position="25142" citStr="Harris, 1985" startWordPosition="4029" endWordPosition="4030">g dam- Our method uses only the relationships inside age would not be recognized. the path or clause in the clustering procedure, 5 Comparison with Previous Work so the similarity is based on the structure itThe relationship between textual features and self. Furthermore, Lin and Pantel did not create semantics and the use of syntax as an indica- path clusters or generalized paths, so that while tor of semantics has been widespread. Following their method allowed them to compare phrases the idea proposed in Harris’ Distributional Hy- for similarity, there is no convenient way to idenpothesis (Harris, 1985), that words occurring in tify high level contextual relationships between similar contexts are semantically similar, many two nearby sentences. This is one of the signifiworks have used different definitions of context cant advantages that clustering has over similarto identify various types of semantic similarity. ity measures - it allows a group of similar objects Hindle (1990) uses a mutual-information based to be represented by a single unit. metric derived from the distribution of subject, There have been several attempts to formuverb and object in a large corpus to classify late and det</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Harris, Z. 1985. Distributional structure. Katz, J. J. (ed.) The Philosophy of Linguistics pages 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicateargument structures.</title>
<date>1990</date>
<booktitle>In Meeting of the ACL.</booktitle>
<pages>268--275</pages>
<contexts>
<context position="25525" citStr="Hindle (1990)" startWordPosition="4087" endWordPosition="4088">, so that while tor of semantics has been widespread. Following their method allowed them to compare phrases the idea proposed in Harris’ Distributional Hy- for similarity, there is no convenient way to idenpothesis (Harris, 1985), that words occurring in tify high level contextual relationships between similar contexts are semantically similar, many two nearby sentences. This is one of the signifiworks have used different definitions of context cant advantages that clustering has over similarto identify various types of semantic similarity. ity measures - it allows a group of similar objects Hindle (1990) uses a mutual-information based to be represented by a single unit. metric derived from the distribution of subject, There have been several attempts to formuverb and object in a large corpus to classify late and detect relationships at a higher context nouns. Pereira et al. (1993) cluster nouns ac- level. The VerbOcean project (Chklovski and cording to their distribution as direct objects Pantel, 2004) deals with relations between verbs. of verbs, using information-theoretic tools (the It presents an automatically acquired network predecessors of the tools we use in this work). of such relat</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, Donald. 1990. Noun classification from predicateargument structures. In Meeting of the ACL. pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representation of context for the detection and correction of malapropisms.</title>
<date>1997</date>
<booktitle>In WordNet: An Electronic Lexical Database, ed., Christiane Fellbaum.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="13991" citStr="Hirst and St-Onge (1997)" startWordPosition="2214" endWordPosition="2217">ut egg, bottle and rock in the same category. In this respect, our clustering method provides a more effective modeling of the domain knowledge. 3.1 Evaluation via Semantic Resource Since the success of our pattern detection task depends to a large extent on the quality of our clusters, we performed an experiment designed to evaluate semantic similarity between members of our clusters. For this purpose we made use of the WordNet Similarity package (Pedersen et al., 2004). This package contains many similarity measures, and we selected three of them (Resnik (1995), Leacock and Chodorow (1997), Hirst and St-Onge (1997)), which make use of different aspects of WordNet (hierarchy and graph structure). We measured the average pairwise similarity between any two words appearing in the same cluster. We then performed the same calculation on a random grouping of the words, and compared the two scores. The results (Fig. 3) show that our clustering, based on co-occurrence statistics and dependencies within the sentence, correlates with a purely semantic similarity as represented by the WordNet structure, and cannot be attributed to chance. Figure 3: Inter-cluster similarity (average pairwise similarity between clus</context>
</contexts>
<marker>Hirst, St-Onge, 1997</marker>
<rawString>Hirst, G. and D. St-Onge. 1997. Lexical chains as representation of context for the detection and correction of malapropisms. In WordNet: An Electronic Lexical Database, ed., Christiane Fellbaum. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and wordnet similarity for word sense identification.</title>
<date>1997</date>
<booktitle>In WordNet: An Electronic Lexical Database, ed., Christiane Fellbaum.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="13965" citStr="Leacock and Chodorow (1997)" startWordPosition="2210" endWordPosition="2213">nce they would probably not put egg, bottle and rock in the same category. In this respect, our clustering method provides a more effective modeling of the domain knowledge. 3.1 Evaluation via Semantic Resource Since the success of our pattern detection task depends to a large extent on the quality of our clusters, we performed an experiment designed to evaluate semantic similarity between members of our clusters. For this purpose we made use of the WordNet Similarity package (Pedersen et al., 2004). This package contains many similarity measures, and we selected three of them (Resnik (1995), Leacock and Chodorow (1997), Hirst and St-Onge (1997)), which make use of different aspects of WordNet (hierarchy and graph structure). We measured the average pairwise similarity between any two words appearing in the same cluster. We then performed the same calculation on a random grouping of the words, and compared the two scores. The results (Fig. 3) show that our clustering, based on co-occurrence statistics and dependencies within the sentence, correlates with a purely semantic similarity as represented by the WordNet structure, and cannot be attributed to chance. Figure 3: Inter-cluster similarity (average pairwi</context>
</contexts>
<marker>Leacock, Chodorow, 1997</marker>
<rawString>Leacock, C. and M. Chodorow. 1997. Combining local context and wordnet similarity for word sense identification. In WordNet: An Electronic Lexical Database, ed., Christiane Fellbaum. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Principar - an efficient, broadcoverage, principle-based parser.</title>
<date>1994</date>
<booktitle>In COLING.</booktitle>
<pages>482--488</pages>
<contexts>
<context position="4262" citStr="Lin, 1994" startWordPosition="644" endWordPosition="645"> solution to these issues combines two elements. First, to reduce complexity, we simplify a grammatical clause to its primary components - the subject, verb and object. Secondly, to provide a generalization framework which will enable us to overcome data-sparseness, we cluster each part of the clause using data from within the clause itself. By combining the simplified clause structure and the clustering we produce our Clustered Clause model - a triplet of clusters representing a generalized clause. The Simplified Clause: In order to extract clauses from the text, we use Lin&apos;s parser MINIPAR (Lin, 1994). The output of the parser is a dependency tree of each sentence, also containing lemmatized versions of the component words. We extract the verb, subject and object of every clause (including subordinate clauses), and use this triplet of values, the simplified clause, in place of the original complete clause. As seen in Figure 1, these components make up the top (root) triangle of the clause parse tree. We also use the lemmatized form of the words provided by the parser, to further reduce complexity. Figure 1: The parse tree for the sentence “John found a solution to the problem”. The subject</context>
</contexts>
<marker>Lin, 1994</marker>
<rawString>Lin, Dekang. 1994. Principar - an efficient, broadcoverage, principle-based parser. In COLING. pages 482–488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Knowledge Discovery and Data Mining.</booktitle>
<pages>323--328</pages>
<contexts>
<context position="27218" citStr="Lin and Pantel, 2001" startWordPosition="4347" endWordPosition="4350">enablement and happensbe useful in real-world tasks. In our work we before relations. Since verbs are the central part demonstrate that using clusters as generalized of the clause, VerbOcean can be viewed as deword units helps overcome the sparseness and tecting relations between clauses as whole units, generalization problems typically encountered as well as those between individual words. As when attempting to extract high-level patterns a solution to the data sparseness problem, web from text, as required for many applications. queries are used. Torisawa (2006) addresses a The DIRT system (Lin and Pantel, 2001) similar problem, but focuses on temporal redeals with inference rules, and employs the no- lations, and makes use of the phenomena of tion of paths between two nouns in a sentence’s Japanese coordinate sentences. Neither of these parse tree. The system extracts such path struc- approaches attempt to create generalized relatures from text, and provides a similarity mea- tions or group verbs into clusters, though in sure between two such paths by comparing the the case of VerbOcean this could presumably words which fill the same slots in the two paths. be done using the similarity and strength </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Lin, Dekang and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Knowledge Discovery and Data Mining. pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>Wordnet::similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proc. of AAAI-04.</booktitle>
<contexts>
<context position="13842" citStr="Pedersen et al., 2004" startWordPosition="2191" endWordPosition="2195">s which unite the words relevant to those actions. Other criteria for clustering would most likely not be suitable, since they would probably not put egg, bottle and rock in the same category. In this respect, our clustering method provides a more effective modeling of the domain knowledge. 3.1 Evaluation via Semantic Resource Since the success of our pattern detection task depends to a large extent on the quality of our clusters, we performed an experiment designed to evaluate semantic similarity between members of our clusters. For this purpose we made use of the WordNet Similarity package (Pedersen et al., 2004). This package contains many similarity measures, and we selected three of them (Resnik (1995), Leacock and Chodorow (1997), Hirst and St-Onge (1997)), which make use of different aspects of WordNet (hierarchy and graph structure). We measured the average pairwise similarity between any two words appearing in the same cluster. We then performed the same calculation on a random grouping of the words, and compared the two scores. The results (Fig. 3) show that our clustering, based on co-occurrence statistics and dependencies within the sentence, correlates with a purely semantic similarity as r</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., S. Patwardhan, and J. Michelizzi. 2004. Wordnet::similarity - measuring the relatedness of concepts. In Proc. of AAAI-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>N Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of english words.</title>
<date>1993</date>
<booktitle>In Meeting of the Association for Computational Linguistics.</booktitle>
<pages>183--190</pages>
<contexts>
<context position="25808" citStr="Pereira et al. (1993)" startWordPosition="4132" endWordPosition="4135">textual relationships between similar contexts are semantically similar, many two nearby sentences. This is one of the signifiworks have used different definitions of context cant advantages that clustering has over similarto identify various types of semantic similarity. ity measures - it allows a group of similar objects Hindle (1990) uses a mutual-information based to be represented by a single unit. metric derived from the distribution of subject, There have been several attempts to formuverb and object in a large corpus to classify late and detect relationships at a higher context nouns. Pereira et al. (1993) cluster nouns ac- level. The VerbOcean project (Chklovski and cording to their distribution as direct objects Pantel, 2004) deals with relations between verbs. of verbs, using information-theoretic tools (the It presents an automatically acquired network predecessors of the tools we use in this work). of such relations, similar to the WordNet frameThey suggest that information theoretic mea- work. Though the patterns used to acquire the sures can also measure semantic relatedness. relations are usually parts of a single sentence, These works focus only on relatedness of indi- the relationship</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira, F., N. Tishby, and L. Lee. 1993. Distributional clustering of english words. In Meeting of the Association for Computational Linguistics. pages 183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In IJCAI.</booktitle>
<pages>448--453</pages>
<contexts>
<context position="13936" citStr="Resnik (1995)" startWordPosition="2208" endWordPosition="2209">be suitable, since they would probably not put egg, bottle and rock in the same category. In this respect, our clustering method provides a more effective modeling of the domain knowledge. 3.1 Evaluation via Semantic Resource Since the success of our pattern detection task depends to a large extent on the quality of our clusters, we performed an experiment designed to evaluate semantic similarity between members of our clusters. For this purpose we made use of the WordNet Similarity package (Pedersen et al., 2004). This package contains many similarity measures, and we selected three of them (Resnik (1995), Leacock and Chodorow (1997), Hirst and St-Onge (1997)), which make use of different aspects of WordNet (hierarchy and graph structure). We measured the average pairwise similarity between any two words appearing in the same cluster. We then performed the same calculation on a random grouping of the words, and compared the two scores. The results (Fig. 3) show that our clustering, based on co-occurrence statistics and dependencies within the sentence, correlates with a purely semantic similarity as represented by the WordNet structure, and cannot be attributed to chance. Figure 3: Inter-clust</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, Philip. 1995. Using information content to evaluate semantic similarity in a taxonomy. In IJCAI. pages 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Slonim</author>
<author>N Friedman</author>
<author>N Tishby</author>
</authors>
<title>Unsupervised document classification using sequential information maximization.</title>
<date>2002</date>
<booktitle>In Proc. of SIGIR&apos;02.</booktitle>
<contexts>
<context position="5295" citStr="Slonim et al., 2002" startWordPosition="816" endWordPosition="819">so use the lemmatized form of the words provided by the parser, to further reduce complexity. Figure 1: The parse tree for the sentence “John found a solution to the problem”. The subjectverb-object triplet is marked with a border. Clustering Clause Components: For our model, we cluster the data to provide both generalization, by using a cluster to represent a more generalized concept shared by its component words, and a form of dimensionality reduction, by using fewer units (clusters) to represent a much larger amount of words. We chose to use the Sequential Information Bottleneck algorithm (Slonim et al., 2002) for our clustering tasks. The information Bottleneck principle views the clustering task as an optimization problem, where the clustering algorithm attempts to group together values of one variable while retaining as much information as possible regarding the values of another (target) variable. There is a trade-off between the compactness of the clustering and the amount of retained information. This algorithm (and others based on the IB principle) is especially suited for use with graphical models or dependency structures, since the distance measure it employs in the clustering is defined s</context>
</contexts>
<marker>Slonim, Friedman, Tishby, 2002</marker>
<rawString>Slonim, N., N. Friedman, and N. Tishby. 2002. Unsupervised document classification using sequential information maximization. In Proc. of SIGIR&apos;02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Slonim</author>
<author>N Tishby</author>
</authors>
<title>Agglomerative information bottleneck.</title>
<date>1999</date>
<booktitle>In Proc. of NIPS-12.</booktitle>
<contexts>
<context position="29845" citStr="Slonim and Tishby, 1999" startWordPosition="4784" endWordPosition="4787">d confidence measures commonly used in data mining, may be preferable. These can be set to different thresholds, according to the user’s preference. In our current work, in order to prevent overgeneralization, we employed a single step postprocessing algorithm which detected the incorrect use of an entire cluster in place of a single word (see footnote for Table 2). This method allows only two levels of generalization - single words and whole clusters. A more appropriate way to handle generalization would be to use a hierarchical clustering algorithm. The Agglomerative Information Bottleneck (Slonim and Tishby, 1999) is an example of such an algorithm, and could be employed for this task. Use of a hierarchical method would result in several levels of clusters, representing different levels of generalization. It would be relatively easy to modify our procedure to reduce generalization to the level indicated by the pattern examples in the text, producing a more accurate description of the patterns detected. Acknowledgments The author acknowledges the support of EPSRC grant EP/C538447/1. The author would like to thank Naftali Tishby and Mirella Lapata for their supervision and assistance on large portions of</context>
</contexts>
<marker>Slonim, Tishby, 1999</marker>
<rawString>Slonim, N. and N. Tishby. 1999. Agglomerative information bottleneck. In Proc. of NIPS-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
</authors>
<title>Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<pages>57--64</pages>
<contexts>
<context position="27167" citStr="Torisawa (2006)" startWordPosition="4340" endWordPosition="4341">mantic similarity can tences, especially the enablement and happensbe useful in real-world tasks. In our work we before relations. Since verbs are the central part demonstrate that using clusters as generalized of the clause, VerbOcean can be viewed as deword units helps overcome the sparseness and tecting relations between clauses as whole units, generalization problems typically encountered as well as those between individual words. As when attempting to extract high-level patterns a solution to the data sparseness problem, web from text, as required for many applications. queries are used. Torisawa (2006) addresses a The DIRT system (Lin and Pantel, 2001) similar problem, but focuses on temporal redeals with inference rules, and employs the no- lations, and makes use of the phenomena of tion of paths between two nouns in a sentence’s Japanese coordinate sentences. Neither of these parse tree. The system extracts such path struc- approaches attempt to create generalized relatures from text, and provides a similarity mea- tions or group verbs into clusters, though in sure between two such paths by comparing the the case of VerbOcean this could presumably words which fill the same slots in the tw</context>
</contexts>
<marker>Torisawa, 2006</marker>
<rawString>Torisawa, Kentaro. 2006. Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences. In Proceedings of NAACL. pages 57–64.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>