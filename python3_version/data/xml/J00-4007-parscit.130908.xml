<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000024">
<note confidence="0.795604">
Computational Linguistics Volume 26, Number 4
</note>
<title confidence="0.9956475">
Artificial Intelligence and Literary Creativity:
Inside the Mind of BRUTUS, a Storytelling Machine
</title>
<author confidence="0.897859">
Selmer Bringsjord and David A. Ferrucci
</author>
<affiliation confidence="0.825854">
(Rensselaer Polytechic Institute and IBM T.J. Watson Research Center)
</affiliation>
<table confidence="0.31642775">
Mahwah, NJ: Lawrence Erlbaum
Associates, 2000, xxxii+230 pp;
hardbound, ISBN 0-8058-1986-X, $59.95;
paperbound, ISBN 0-8058-1987-8, $27.50
</table>
<figure confidence="0.5485125">
Reviewed by
Ronald de Sousa
</figure>
<affiliation confidence="0.580622">
University of Toronto
</affiliation>
<bodyText confidence="0.951193857142857">
BRUTUS is a program that tells stories. The stories are intriguing, they hold a hint
of mystery, and—not least impressive—they are written in correct English prose. An
example (p. 124) is shown in Figure 1. This remarkable feat is grounded in a complex
architecture making use of a number of levels, each of which is parameterized so as
to become a locus of possible variation.
The specific BRUTUS] implementation that illustrates the program&apos;s prowess ex-
ploits the theme of betrayal, which receives an elaborate analysis, culminating in a set
</bodyText>
<subsectionHeader confidence="0.924806">
Betrayal in Self-Deception
</subsectionHeader>
<bodyText confidence="0.96712472">
Dave Striver loved the university. He loved its ivy-covered clocktowers, its ancient and sturdy
brick, and its sun-splashed verdant greens and eager youth. He also loved the fact that the
university is free of the stark unforgiving trials of the business world—only this isn&apos;t a fact:
academia has its own tests, and some are as merciless as any in the marketplace. A prime
example is the dissertation defense: to earn the Ph.D., to become a doctor, one must pass an
oral examination on one&apos;s dissertation. This was a test Professor Edward Hart enjoyed giving.
Dave wanted desperately to be a doctor. But he needed the signatures of three people on
the first page of his dissertation, the priceless inscriptions which, together, would certify that he
had passed his defense. One of the signatures had to come from Professor Hart, and Hart had
often said—to others and to himself—that he was honored to help Dave secure his well-earned
dream.
Well before the defense, Striver gave Hart a penultimate copy of his thesis. Hart read it and
told Dave that it was absolutely first-rate, and that he would gladly sign it at the defense. They
even shook hands in Hart&apos;s book-lined office. Dave noticed that Hart&apos;s eyes were bright and
trustful, and his bearing paternal.
At the defense, Dave thought that he eloquently summarized Chapter 3 of his dissertation.
There were two questions, one from Professor Rodman and one from Dr. Teer; Dave answered
both, apparently to everyone&apos;s satisfaction. There were no further objections.
Professor Rodman signed. He slid the tome to Teer; she too signed, and then slid it in front
of Hart. Hart didn&apos;t move.
&amp;quot;Ed?&amp;quot; Rodman said.
Hart still sat motionless. Dave felt slightly dizzy.
&amp;quot;Edward, are you going to sign?&amp;quot;
Later, Hart sat alone in his office, in his big leather chair, saddened by Dave&apos;s failure. He
tried to think of ways he could help Dave achieve his dream.
</bodyText>
<figureCaption confidence="0.69121">
Figure 1
</figureCaption>
<bodyText confidence="0.853584">
An example of a story by BRUTLISi
</bodyText>
<page confidence="0.995885">
642
</page>
<subsectionHeader confidence="0.794607">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.699265">
of necessary and sufficient conditions (Defb 8, pp. 98-99) in terms of actions, goals,
and beliefs of two agents, the betrayer and the betrayed. This illustrates the sort of
thematic knowledge in which BRUTUS&apos;s stories are grounded. Thematic knowledge
is part of the knowledge level, which also comprises the following:
</bodyText>
<listItem confidence="0.951369">
1. More general domain knowledge pertaining to the kinds of things that
may constitute the subject matter of stories: agents, events, beliefs, goals,
actions, and reaction (pp. 175-179);
2. Linguistic knowledge, pertaining to morphology, syntax, paragraph,
and discourse structure (pp. 167,180-182);
3. Literary knowledge, incorporating principles of storytelling, including
story-grammars, designed to achieve specific literary objectives such as
triggering imaging in the reader, causing the reading to project personal
consciousness onto the characters. Literary knowledge also includes
rhetorical tropes, evaluative valences, analogies, and image associations
(pp. 182-185);
4. A special level of literary augmented grammars (LAGs) brings the
rhetorical knowledge of the literary knowledge level to bear on the
syntax controlled by the linguistic level (pp. 185-489).
</listItem>
<bodyText confidence="0.896013">
Story generation uses the knowledge of the kinds just listed in four types of de-
velopments through time at the process level:
</bodyText>
<listItem confidence="0.996991307692308">
1. Thematic concept instantiation sets the &amp;quot;stage&amp;quot; for a given story,
exploiting thematic knowledge for a chosen theme;
2. Plot generation takes the characters and characteristics identified in the
&amp;quot;stage&amp;quot;-setting phase and generates a scenario, using domain and
thematic knowledge, particularly of action and reactive behavior. It
results in a detailed scenario that generates consequences inferred from
the knowledge level by production rules, and deploys a temporal
sequence of events. The production rules follow ordinary first-order
logic, but extensions are promised making use of temporal logic,
conditional logic, and deoritic logic, as well as &amp;quot;logics of action,
deliberate action, intending etc&amp;quot; (p. 100).
3. Story structure expansion takes place on the basis of story grammars, at
each choice-point of which sentence-types are produced.
</listItem>
<bodyText confidence="0.99431125">
Linguistic and literary knowledge are then used for language
generation, that is, the production of specific linguistic structures down
to the level of sentences, phrases, and words (pp. 194-197).
An example of a production rule used in the sample story is as follows (p. 179):
</bodyText>
<footnote confidence="0.548737333333333">
Rule committee_members_behavior
IF
Candidate is some person and
Thesis is the thesis of Candidate and
the committee of the Candidate includes Member and
Request_To_Sign is some request and
</footnote>
<page confidence="0.992774">
643
</page>
<figure confidence="0.685918125">
Computational Linguistics Volume 26, Number 4
Member is the requestee of Request_To_Sign and
The requester of Request_To_Sign is the chairman of the committee and
Thesis is the document of subject of Request_To_Sign and
Status of Request_To_Sign is pending
THEN
do answer(Member, Request_To_Sign) and
do sign(Member, Thesis)
</figure>
<bodyText confidence="0.999899692307692">
The literary themes at the heart of BRUTUS&apos;s stories are chosen for intrinsic in-
terestingness: &amp;quot;The central thrust of BRUTUS&apos;s approach to story generation is ... to
begin with a well-established, interesting literary theme like betrayal, and then work
down&amp;quot; (p. 199). So the interestingness is canned, and the complexity of the architecture
makes for a startling air of creativity. But can interestingness be formalized? And is
BRUTUS really creative?
Some—such as Hofstadter and the Fluid Analogies Research Group (1995)—have
boldly tackled the challenge of endowing machines with creativity. Naysayers—such
as Dreyfus (1992)—have claimed to show that the enterprise is impossible in principle.
The former have tended to be workers in AT, the latter philosophers. Bringsjord and
Ferrucci are unusual in that they belong to both camps at once. They &amp;quot;cheerfully
operate under the belief that human (literary) creativity is beyond computation—and
yet strive to craft the appearance of creativity from suitably configured computation&amp;quot;
(p. 149).
I know of no reason to dispute the authors&apos; claim (repeated on the website devoted
to machine and book&apos;) that BRUTUS is &amp;quot;the world&apos;s most advanced story generator.&amp;quot;
The approach is ingenious and thorough, and the results quite impressive. By contrast,
the arguments against Strong Al, despite being couched in clean deductive form,
remain unconvincing.
Bringsjord and Ferrucci may seem to have stacked the deck against BRUTUS (and
in favor of their philosophical thesis) by insisting that all computer storytelling must
proceed exclusively by means of the traditional tools of databases and algorithms.
Their &amp;quot;approach is a thoroughly logic-based one. Neural nets and dynamical systems
are nowhere to be found in this volume&amp;quot; (p. 26). Their &amp;quot;explanation&amp;quot; of this strategy
&amp;quot;is based on two stories, one involving Tchaikovsky, and the other involving Sherlock
Holmes.&amp;quot; The first notes that Tchaikovsky convinced audiences that his sixth Sym-
phony was worth listening to by renaming it Pathetique, and talking of the range of
emotional experiences he intended it to express. No robot composer, the authors assert,
could provide that sort of gloss. The second alleges that even if some conneetionist
robot descended from MIT&apos;s COG were to emulate the powers of Sherlock Holmes, it
could never explain how it accomplished its feats of inference without using language
and deductive logic.
Take the latter &amp;quot;explanation&amp;quot; first. Most of Sherlock Holmes&apos;s &amp;quot;deductions&amp;quot; are ac-
tually inductions, or crucially rest on prior—and often dubious—inductive inferences
(such as &amp;quot;dogs always bark at strangers,&amp;quot; in their example drawn from the story of
Silver Blaze, p. 31). But suppose the detective&apos;s reasoning were exclusively logical.
Bringsjord and Ferrucci stress the fact that the nature of this reasoning couldn&apos;t be
&amp;quot;gleaned from neural nets&amp;quot; any more than our own could be read off a brain scan
(p. 30), Quite, but so what? That doesn&apos;t show that the logical reasoning didn&apos;t super-
</bodyText>
<footnote confidence="0.977268">
1 http://www.rpiedu/deptippcs/BRUTUS/bniths.htnal
</footnote>
<page confidence="0.990452">
644
</page>
<subsectionHeader confidence="0.810457">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999741137931034">
vene on the lower-level activity of both nets and neurons.
In this connection, Bringsjord and Ferrucci make a revealing observation: unless
we can analyze &amp;quot;what cognizers think and say&amp;quot; in logical terms, then the robot&apos;s
&amp;quot;success will be impenetrable, and will thus fail to advance our understanding of
how detectives do what they do&amp;quot;. And they conclude: &amp;quot;Since we desire not only to
build literarily creative agents but to understand them, our use of logic goes without
saying&amp;quot;, though of course &amp;quot;it&apos;s fine with us, if this computation takes the form of
neural networks in action&amp;quot; (p. 31).
This remark about understanding is reminiscent of the old joke about looking for
your keys under the lamp, because that is where the light is. If that just is the way
the brain works, and logical inferences, like conscious states and creative innovations,
are just supervenient on those unintelligible processes, then consciousness, creativity,
and logic will all be emergent properties of a system the inner workings of which are
simply too complex to be understood in detail. That may well be regrettable, but this
hardly constitutes a good reason for thinking it&apos;s not true.
In fact, what neural nets notoriously seem to be good at is precisely inductive
learning and pattern recognition. These are not all that Sherlock Holmes needs, but
they are certainly key items in his toolbox. So why should neural nets be relegated to
the implementation level of the deductive components of reasoning? Bringsjord and
Ferrucci&apos;s answer rests on the fact that there can in principle be no difference between
the logical powers of neural nets and those of symbolic systems: &amp;quot;Neural nets can
be rendered as cellular automata, cellular automata can be rendered as ... [Turing
machinesr—and Turing machines are in principle equivalent to traditional symbolic
computers (p. 38).
The problem is that this argument can as easily be stood on its head. Despite a
long tradition of invoking GOdel to the contrary (Penrose 1994, pp. 171-209), there is
no consensus that our own brains cannot be &amp;quot;rendered&amp;quot; as neural nets, and therefore
as Turing machines. So the argument simply begs the question. It gives me no reason
to reject the following alternative argument:
</bodyText>
<listItem confidence="0.9987386">
1. Humans are creative.
2. Human brains are neural nets.
3. Therefore neural nets can be creative.
4. Neural nets are logically equivalent to Turing machines.
5. Therefore Turing machines can be creative.
</listItem>
<bodyText confidence="0.999508714285714">
The same strong whiff of question-begging affects the authors&apos; endorsement of
well-known arguments against interpreting even the most spectacular success of their
own program as a vindication of Strong Al. Let&apos;s look at just two of these arguments.
First, what I&apos;ll call the Direct Argument (DA). It appeals to the idea of novelty
contained in creativity. DA rests on the plausible thought that creativity must involve
the capacity to produce something new. But what is new? DA purports to show that
no deterministic machine can ever count as creative:
</bodyText>
<listItem confidence="0.997719">
1. Only something that merely implements algorithms counts as a genuine
machine.
2. Nothing can count as creative if it produces nothing new.
3. Algorithms produce nothing new.
</listItem>
<page confidence="0.982809">
645
</page>
<listItem confidence="0.757267666666667">
Computational Linguistics Volume 26, Number 4
4. Nothing that merely implements algorithms can count as creative (2, 3).
5. Conclusion: No machine can be creative (1, 4).
</listItem>
<bodyText confidence="0.998487093023256">
DA seems impossibly short. Its premises beg important questions. Proposition (4)
would entail that no standard mathematical proofs can be creative, since a mathe-
matical proof typically implements algorithms. Premise (3) is sometimes advanced as
the thesis that the conclusion of a valid deductive argument is &amp;quot;contained&amp;quot; in the
premises, so that deductive arguments produce no new knowledge. Yet both mathe-
maticians and those who &amp;quot;know no mathematics&amp;quot; would be puzzled by the claim that
there is nothing the former know that the latter do not.
A crucial underlying assumption is that we ourselves do not implement algorithms
when we think creatively. Bringsjord and Ferrucci admit that &amp;quot;raw origination ... may
well be impossible,&amp;quot; but they claim to give examples of &amp;quot;a type of creativity in which
something utterly and completely new is produced (e.g., non-Euclidean geometry)&amp;quot;
(p. xix). But the example undermines the thesis. The elaboration of non-Euclidean
geometries required little more than a change of perspective after Giovanni Girolamo
Saccheri&apos;s purported proof of the parallels postulate by reductio ad absurdum (Saccheri
and Halsted 1986). All that was needed was to notice that the &amp;quot;absurd&amp;quot; consequences
entailed no contradiction. Bolyiai&apos;s and Lobachewski&apos;s creative recognition of that fact
could certainly be attained by formal methods, but required the choice of a crucial
change in attitude.
In the light of this example, the best prospect for creative machines seems to me
to lie in selectionist systems. If variation and selection was good enough for God, it
should be good enough for Al. Or are the products of biological evolution merely
algorithmic and therefore not creative enough for Bringsjord and Ferrucci? I&apos;m not
sure: the issue seems to hang, for them, on whether there is an algorithm to effect
the selection task. Their fifth chapter is devoted to showing that interestingness, like
creativity itself, while recognizable by humans, is not recognized by means of any
computable procedure. To be sure, a human organism brought up on multifarious
experience can learn to recognize creativity without ever becoming fully conscious of the
procedures responsible for that recognition. Since neural nets are good at learning to
recognize patterns even when we don&apos;t really understand how they do it, the argument
seems insufficient to establish that machines couldn&apos;t learn to recognize creativity and
(in the context of a selectionist system) thereby learn to be creative.
Bringsjord and Ferrucci&apos;s Arg4 (ID. 74) purports to derive the conclusion that &amp;quot;Com-
puters can&apos;t write sophisticated fiction.&amp;quot; Crucial to this argument is the proposition:
10. &amp;quot;There&apos;s something it&apos;s like to be a&amp;quot; conscious states are not
formalizable..
which is the conclusion of Arg3 and rests, in turn, on this premise:
4. Alvin, prior to his [first ever] first-person long-lost-friend experience,
doesn&apos;t know what it&apos;s like to meet a long-lost friend in the flesh. (p. 71)
In the much-discussed form in which it was put by Frank Jackson (1982), the place of
Alvin is taken by Mary, a brain specialist who has been brought up in a purely black-
and-white environment and knows, by description, &amp;quot;everything there is to know&amp;quot;
about color. It is somehow supposed to be obvious that when suddenly confronted
with the first-person experience of colors, she learns something she didn&apos;t know before
</bodyText>
<page confidence="0.996167">
646
</page>
<subsectionHeader confidence="0.836865">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999965620689655">
(p. 53). But why should telling that science-fiction story compel us to believe that? The
story is a thought experiment, and thought experiments don&apos;t tell us what must be
the case, but only what we think we would think if something were the case. There is
no manifest logical incoherence involved in giving the story a different conclusion, in
which the third-person knowledge would be sufficient to generate first-person knowl-
edge. That there is such a logical incoherence is what Bringsjord and Ferrucci purport
to prove; so they are not entitled to stuff this claim into a premise.
Towards the end of the book, Bringsjord and Ferrucci write:
Computer programs are not human; they are not affected by the emo-
tional elements that are part and parcel of human drama. In fact, it is
hard to even imagine how a computer could discover, from a sea of
swimming Os and is, what might be compelling to a living, feeling
human being. (p. 198)
Well, yes, it&apos;s hard to imagine, but then in the same sense it&apos;s hard to imagine
how a brain could discover anything from a sea of swimming neurotransmitter drops,
phosphorus ions, and the rest of it. We don&apos;t realty know how it happens. But our
ignorance and the failure of our imagination should not be confused with logical im-
possibility. Perhaps, indeed, the right kind of ignorance lies at the heart of what passes
for creativity. The methods used by BRUTUS look mechanical when they are used on
only a relatively small knowledge domain. But Bringsjord and Ferrucci have failed to
show that merely scaling up could not make all the difference between merely simu-
lated creativity and the real thing. Appeals to uncomputability in the explanation of
human powers, like nineteenth-century appeals to entelechies and vital spirit, under-
estimate the power of well-placed ignorance to create key illusions. BRUTUS may not
be creative yet, because we see too well, thanks to its authors&apos; excellent exposition,
just how it works. But once we raise the degree of its complexity and the diversity of
its knowledge base, our skepticism may be harder to maintain. The key to creativity
may just be nothing more than just enough of the right kind of ignorance in the face
of complexity.
</bodyText>
<sectionHeader confidence="0.976928" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.997597789473684">
Dreyfus, Hubert L. 1992. What Computers Still
Can&apos;t Do: A critique of artificial reason. The
MIT Press, Cambridge, MA.
Hofstadter, Douglas R., and the Fluid
Analogies Research Group. 1995. Fluid
Concepts and Creative Analogies: Computer
Models of the Fundamental Mechanisms of
Thought. Basic Books, New York.
Jackson, Frank. 1982. Epiphenomenal Qualia.
Philosophical Quarterly, 32: 127-136.
Penrose, Roger. 1994. Shadows of the Mind: A
Search for the Missing Science of
Consciousness. Oxford University Press,
Oxford and New York.
Saccheri, Girolamo and George B. Halsted.
1986. Cirolamo Saccheri&apos;s Euclides vindicatus.
Edited and translated by George B.
Halsted. Chelsea Publishing Co., New
York.
</reference>
<bodyText confidence="0.7046015">
Ronald de Sousa is the author of The Rationality of Emotion (The MIT Press, 1987). His research
interests include the modeling of mind and rational processes, and the philosophy of language,
biology, cognitive science, and artificial life. De Sousa&apos;s address is: Department of Philosophy,
University of Toronto, Toronto, Ontario, Canada M5S 1A1; e-mail: sousa@chass.utoronto.ca.
</bodyText>
<page confidence="0.997981">
647
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000068">
<note confidence="0.666665">Linguistics 26, Number 4</note>
<title confidence="0.919243">Artificial Intelligence and Literary Creativity: Inside the Mind of BRUTUS, a Storytelling Machine</title>
<author confidence="0.999158">Selmer Bringsjord</author>
<author confidence="0.999158">David A Ferrucci</author>
<affiliation confidence="0.997309">(Rensselaer Polytechic Institute and IBM T.J. Watson Research Center)</affiliation>
<address confidence="0.706292">Mahwah, NJ: Lawrence Erlbaum</address>
<note confidence="0.84634675">Associates, 2000, xxxii+230 pp; hardbound, ISBN 0-8058-1986-X, $59.95; paperbound, ISBN 0-8058-1987-8, $27.50 Reviewed by</note>
<author confidence="0.961194">Ronald de_Sousa</author>
<affiliation confidence="0.9966">University of Toronto</affiliation>
<abstract confidence="0.968524268571429">BRUTUS is a program that tells stories. The stories are intriguing, they hold a hint of mystery, and—not least impressive—they are written in correct English prose. An example (p. 124) is shown in Figure 1. This remarkable feat is grounded in a complex architecture making use of a number of levels, each of which is parameterized so as to become a locus of possible variation. The specific BRUTUS] implementation that illustrates the program&apos;s prowess exploits the theme of betrayal, which receives an elaborate analysis, culminating in a set Betrayal in Self-Deception Dave Striver loved the university. He loved its ivy-covered clocktowers, its ancient and sturdy and its sun-splashed verdant greens eager He also loved the fact that the university is free of the stark unforgiving trials of the business world—only this isn&apos;t a fact: academia has its own tests, and some are as merciless as any in the marketplace. A prime example is the dissertation defense: to earn the Ph.D., to become a doctor, one must pass an examination on one&apos;s dissertation. This was a test Professor Edward enjoyed Dave wanted desperately to be a doctor. But he needed the signatures of three people on the first page of his dissertation, the priceless inscriptions which, together, would certify that he had passed his defense. One of the signatures had to come from Professor Hart, and Hart had often said—to others and to himself—that he was honored to help Dave secure his well-earned dream. Well before the defense, Striver gave Hart a penultimate copy of his thesis. Hart read it and Dave that it was absolutely first-rate, and he would gladly sign it at the defense. They shook hands in Hart&apos;s book-lined Dave noticed that Hart&apos;s eyes were bright and trustful, and his bearing paternal. the defense, Dave thought that he eloquently summarized Chapter 3 of his were two questions, one from Professor Rodman and one from Dr. Dave answered apparently to everyone&apos;s There were no further objections. Professor Rodman signed. He slid the tome to Teer; she too signed, and then slid it in front of Hart. Hart didn&apos;t move. &amp;quot;Ed?&amp;quot; Rodman said. sat motionless. felt slightly dizzy. &amp;quot;Edward, are you going to sign?&amp;quot; Later, Hart sat alone in his office, in his big leather chair, saddened by Dave&apos;s failure. He tried to think of ways he could help Dave achieve his dream. Figure 1 An example of a story by BRUTLISi 642 Book Reviews of necessary and sufficient conditions (Defb 8, pp. 98-99) in terms of actions, goals, and beliefs of two agents, the betrayer and the betrayed. This illustrates the sort of knowledge which BRUTUS&apos;s stories are grounded. Thematic knowledge part of the level, also comprises the following: More general knowledge to the kinds of things that may constitute the subject matter of stories: agents, events, beliefs, goals, and reaction Linguistic knowledge, to morphology, syntax, paragraph, and discourse structure (pp. 167,180-182); Literary knowledge, principles of storytelling, including story-grammars, designed to achieve specific literary objectives such as triggering imaging in the reader, causing the reading to project personal consciousness onto the characters. Literary knowledge also includes rhetorical tropes, evaluative valences, analogies, and image associations (pp. 182-185); A special level of augmented grammars brings the rhetorical knowledge of the literary knowledge level to bear on the syntax controlled by the linguistic level (pp. 185-489). Story generation uses the knowledge of the kinds just listed in four types of dethrough time at the level: Thematic concept instantiation the &amp;quot;stage&amp;quot; for a given story, exploiting thematic knowledge for a chosen theme; Plot generation the characters and characteristics identified in the &amp;quot;stage&amp;quot;-setting phase and generates a scenario, using domain and thematic knowledge, particularly of action and reactive behavior. It results in a detailed scenario that generates consequences inferred from the knowledge level by production rules, and deploys a temporal sequence of events. The production rules follow ordinary first-order logic, but extensions are promised making use of temporal logic, conditional logic, and deoritic logic, as well as &amp;quot;logics of action, deliberate action, intending etc&amp;quot; (p. 100). Story structure expansion place on the basis of story grammars, at each choice-point of which sentence-types are produced. and literary knowledge are then used for is, the production of specific linguistic structures down to the level of sentences, phrases, and words (pp. 194-197). An example of a production rule used in the sample story is as follows (p. 179): Rule committee_members_behavior IF Candidate is some person and Thesis is the thesis of Candidate and the committee of the Candidate includes Member and Request_To_Sign is some request and 643 Computational Linguistics Volume 26, Number 4 Member is the requestee of Request_To_Sign and The requester of Request_To_Sign is the chairman of the committee and Thesis is the document of subject of Request_To_Sign and Status of Request_To_Sign is pending THEN do answer(Member, Request_To_Sign) and do sign(Member, Thesis) The literary themes at the heart of BRUTUS&apos;s stories are chosen for intrinsic interestingness: &amp;quot;The central thrust of BRUTUS&apos;s approach to story generation is ... to begin with a well-established, interesting literary theme like betrayal, and then work down&amp;quot; (p. 199). So the interestingness is canned, and the complexity of the architecture for a startling air of creativity. interestingness be formalized? And is BRUTUS really creative? Some—such as Hofstadter and the Fluid Analogies Research Group (1995)—have boldly tackled the challenge of endowing machines with creativity. Naysayers—such as Dreyfus (1992)—have claimed to show that the enterprise is impossible in principle. The former have tended to be workers in AT, the latter philosophers. Bringsjord and Ferrucci are unusual in that they belong to both camps at once. They &amp;quot;cheerfully operate under the belief that human (literary) creativity is beyond computation—and yet strive to craft the appearance of creativity from suitably configured computation&amp;quot; (p. 149). I know of no reason to dispute the authors&apos; claim (repeated on the website devoted to machine and book&apos;) that BRUTUS is &amp;quot;the world&apos;s most advanced story generator.&amp;quot; The approach is ingenious and thorough, and the results quite impressive. By contrast, the arguments against Strong Al, despite being couched in clean deductive form, remain unconvincing. Bringsjord and Ferrucci may seem to have stacked the deck against BRUTUS (and in favor of their philosophical thesis) by insisting that all computer storytelling must proceed exclusively by means of the traditional tools of databases and algorithms. Their &amp;quot;approach is a thoroughly logic-based one. Neural nets and dynamical systems are nowhere to be found in this volume&amp;quot; (p. 26). Their &amp;quot;explanation&amp;quot; of this strategy &amp;quot;is based on two stories, one involving Tchaikovsky, and the other involving Sherlock Holmes.&amp;quot; The first notes that Tchaikovsky convinced audiences that his sixth Symwas worth listening to by renaming it talking of the range of emotional experiences he intended it to express. No robot composer, the authors assert, could provide that sort of gloss. The second alleges that even if some conneetionist robot descended from MIT&apos;s COG were to emulate the powers of Sherlock Holmes, it could never explain how it accomplished its feats of inference without using language and deductive logic. Take the latter &amp;quot;explanation&amp;quot; first. Most of Sherlock Holmes&apos;s &amp;quot;deductions&amp;quot; are actually inductions, or crucially rest on prior—and often dubious—inductive inferences (such as &amp;quot;dogs always bark at strangers,&amp;quot; in their example drawn from the story of Silver Blaze, p. 31). But suppose the detective&apos;s reasoning were exclusively logical. Bringsjord and Ferrucci stress the fact that the nature of this reasoning couldn&apos;t be &amp;quot;gleaned from neural nets&amp;quot; any more than our own could be read off a brain scan 30), Quite, but so what? That doesn&apos;t show that the logical reasoning didn&apos;t super- 1 http://www.rpiedu/deptippcs/BRUTUS/bniths.htnal 644 vene on the lower-level activity of both nets and neurons. In this connection, Bringsjord and Ferrucci make a revealing observation: unless we can analyze &amp;quot;what cognizers think and say&amp;quot; in logical terms, then the robot&apos;s &amp;quot;success will be impenetrable, and will thus fail to advance our understanding of how detectives do what they do&amp;quot;. And they conclude: &amp;quot;Since we desire not only to build literarily creative agents but to understand them, our use of logic goes without saying&amp;quot;, though of course &amp;quot;it&apos;s fine with us, if this computation takes the form neural networks in action&amp;quot; (p. 31). This remark about understanding is reminiscent of the old joke about looking for your keys under the lamp, because that is where the light is. If that just is the way the brain works, and logical inferences, like conscious states and creative innovations, are just supervenient on those unintelligible processes, then consciousness, creativity, and logic will all be emergent properties of a system the inner workings of which are simply too complex to be understood in detail. That may well be regrettable, but this hardly constitutes a good reason for thinking it&apos;s not true. In fact, what neural nets notoriously seem to be good at is precisely inductive learning and pattern recognition. These are not all that Sherlock Holmes needs, but they are certainly key items in his toolbox. So why should neural nets be relegated to the implementation level of the deductive components of reasoning? Bringsjord and Ferrucci&apos;s answer rests on the fact that there can in principle be no difference between the logical powers of neural nets and those of symbolic systems: &amp;quot;Neural nets can be rendered as cellular automata, cellular automata can be rendered as ... [Turing machinesr—and Turing machines are in principle equivalent to traditional symbolic computers (p. 38). The problem is that this argument can as easily be stood on its head. Despite a tradition of invoking GOdel to the contrary (Penrose there is that our own brains cannot be &amp;quot;rendered&amp;quot; as neural nets, and therefore as Turing machines. So the argument simply begs the question. It gives me no reason following alternative argument: 1. Humans are creative. 2. Human brains are neural nets. 3. Therefore neural nets can be creative. 4. Neural nets are logically equivalent to Turing machines. 5. Therefore Turing machines can be creative. The same strong whiff of question-begging affects the authors&apos; endorsement of well-known arguments against interpreting even the most spectacular success of their own program as a vindication of Strong Al. Let&apos;s look at just two of these arguments. what I&apos;ll call the Direct Argument (DA). to the idea of novelty contained in creativity. DA rests on the plausible thought that creativity must involve the capacity to produce something new. But what is new? DA purports to show that no deterministic machine can ever count as creative: 1. Only something that merely implements algorithms counts as a genuine machine. 2. Nothing can count as creative if it produces nothing new. 3. Algorithms produce nothing new.</abstract>
<note confidence="0.8241304">645 Computational Linguistics Volume 26, Number 4 4. Nothing that merely implements algorithms can count as creative (2, 3). 5. Conclusion: No machine can be creative (1, 4). DA seems impossibly short. Its premises beg important questions. Proposition (4)</note>
<abstract confidence="0.995971739726027">would entail that no standard mathematical proofs can be creative, since a mathematical proof typically implements algorithms. Premise (3) is sometimes advanced as the thesis that the conclusion of a valid deductive argument is &amp;quot;contained&amp;quot; in the premises, so that deductive arguments produce no new knowledge. Yet both mathematicians and those who &amp;quot;know no mathematics&amp;quot; would be puzzled by the claim that there is nothing the former know that the latter do not. A crucial underlying assumption is that we ourselves do not implement algorithms when we think creatively. Bringsjord and Ferrucci admit that &amp;quot;raw origination ... may well be impossible,&amp;quot; but they claim to give examples of &amp;quot;a type of creativity in which something utterly and completely new is produced (e.g., non-Euclidean geometry)&amp;quot; the example undermines the thesis. The elaboration of non-Euclidean geometries required little more than a change of perspective after Giovanni Girolamo Saccheri&apos;s purported proof of the parallels postulate by reductio ad absurdum (Saccheri and Halsted 1986). All that was needed was to notice that the &amp;quot;absurd&amp;quot; consequences entailed no contradiction. Bolyiai&apos;s and Lobachewski&apos;s creative recognition of that fact could certainly be attained by formal methods, but required the choice of a crucial change in attitude. In the light of this example, the best prospect for creative machines seems to me to lie in selectionist systems. If variation and selection was good enough for God, it should be good enough for Al. Or are the products of biological evolution merely algorithmic and therefore not creative enough for Bringsjord and Ferrucci? I&apos;m not sure: the issue seems to hang, for them, on whether there is an algorithm to effect the selection task. Their fifth chapter is devoted to showing that interestingness, like itself, while humans, is not recognized by means of any computable procedure. To be sure, a human organism brought up on multifarious can learn to recognize creativity ever becoming fully conscious of the responsible that recognition. Since neural nets are good at learning to recognize patterns even when we don&apos;t really understand how they do it, the argument seems insufficient to establish that machines couldn&apos;t learn to recognize creativity and the context of a selectionist system) to be creative. Bringsjord and Ferrucci&apos;s Arg4 (ID. 74) purports to derive the conclusion that &amp;quot;Computers can&apos;t write sophisticated fiction.&amp;quot; Crucial to this argument is the proposition: 10. &amp;quot;There&apos;s something it&apos;s like to be a&amp;quot; conscious states are not formalizable.. which is the conclusion of Arg3 and rests, in turn, on this premise: 4. Alvin, prior to his [first ever] first-person long-lost-friend experience, doesn&apos;t know what it&apos;s like to meet a long-lost friend in the flesh. (p. 71) In the much-discussed form in which it was put by Frank Jackson (1982), the place of Alvin is taken by Mary, a brain specialist who has been brought up in a purely blackand-white environment and knows, by description, &amp;quot;everything there is to know&amp;quot; about color. It is somehow supposed to be obvious that when suddenly confronted the experience of she learns something she didn&apos;t know before 646 Book Reviews (p. 53). But why should telling that science-fiction story compel us to believe that? The story is a thought experiment, and thought experiments don&apos;t tell us what must be the case, but only what we think we would think if something were the case. There is no manifest logical incoherence involved in giving the story a different conclusion, in which the third-person knowledge would be sufficient to generate first-person knowledge. That there is such a logical incoherence is what Bringsjord and Ferrucci purport to prove; so they are not entitled to stuff this claim into a premise. Towards the end of the book, Bringsjord and Ferrucci write: Computer programs are not human; they are not affected by the emotional elements that are part and parcel of human drama. In fact, it is to even a computer could discover, from a sea of swimming Os and is, what might be compelling to a living, feeling human being. (p. 198) Well, yes, it&apos;s hard to imagine, but then in the same sense it&apos;s hard to imagine how a brain could discover anything from a sea of swimming neurotransmitter drops, phosphorus ions, and the rest of it. We don&apos;t realty know how it happens. But our ignorance and the failure of our imagination should not be confused with logical impossibility. Perhaps, indeed, the right kind of ignorance lies at the heart of what passes for creativity. The methods used by BRUTUS look mechanical when they are used on only a relatively small knowledge domain. But Bringsjord and Ferrucci have failed to that scaling could not make all the difference between merely simulated creativity and the real thing. Appeals to uncomputability in the explanation of human powers, like nineteenth-century appeals to entelechies and vital spirit, underestimate the power of well-placed ignorance to create key illusions. BRUTUS may not be creative yet, because we see too well, thanks to its authors&apos; excellent exposition, just how it works. But once we raise the degree of its complexity and the diversity of its knowledge base, our skepticism may be harder to maintain. The key to creativity may just be nothing more than just enough of the right kind of ignorance in the face of complexity.</abstract>
<title confidence="0.719005">References</title>
<author confidence="0.746472">L Hubert</author>
<note confidence="0.9501385">Do: A critique of artificial reason. MIT Press, Cambridge, MA. Hofstadter, Douglas R., and the Fluid Research Group. 1995.</note>
<title confidence="0.4084405">Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of</title>
<address confidence="0.63011475">Books, New York. Jackson, Frank. 1982. Epiphenomenal Qualia. Quarterly, Roger. 1994. of the Mind: A</address>
<affiliation confidence="0.9461205">Search for the Missing Science of University Press,</affiliation>
<address confidence="0.59036">and York.</address>
<note confidence="0.702249666666667">Saccheri, Girolamo and George B. Halsted. Saccheri&apos;s Euclides vindicatus. Edited and translated by George B.</note>
<title confidence="0.264274">Chelsea Publishing New</title>
<abstract confidence="0.614751">York. de Sousa the author of Rationality of Emotion Press, 1987). His research interests include the modeling of mind and rational processes, and the philosophy of language, biology, cognitive science, and artificial life. De Sousa&apos;s address is: Department of Philosophy, University of Toronto, Toronto, Ontario, Canada M5S 1A1; e-mail: sousa@chass.utoronto.ca.</abstract>
<intro confidence="0.619488">647</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hubert L Dreyfus</author>
</authors>
<title>What Computers Still Can&apos;t Do: A critique of artificial reason.</title>
<date>1992</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6565" citStr="Dreyfus (1992)" startWordPosition="1006" endWordPosition="1007">themes at the heart of BRUTUS&apos;s stories are chosen for intrinsic interestingness: &amp;quot;The central thrust of BRUTUS&apos;s approach to story generation is ... to begin with a well-established, interesting literary theme like betrayal, and then work down&amp;quot; (p. 199). So the interestingness is canned, and the complexity of the architecture makes for a startling air of creativity. But can interestingness be formalized? And is BRUTUS really creative? Some—such as Hofstadter and the Fluid Analogies Research Group (1995)—have boldly tackled the challenge of endowing machines with creativity. Naysayers—such as Dreyfus (1992)—have claimed to show that the enterprise is impossible in principle. The former have tended to be workers in AT, the latter philosophers. Bringsjord and Ferrucci are unusual in that they belong to both camps at once. They &amp;quot;cheerfully operate under the belief that human (literary) creativity is beyond computation—and yet strive to craft the appearance of creativity from suitably configured computation&amp;quot; (p. 149). I know of no reason to dispute the authors&apos; claim (repeated on the website devoted to machine and book&apos;) that BRUTUS is &amp;quot;the world&apos;s most advanced story generator.&amp;quot; The approach is ing</context>
</contexts>
<marker>Dreyfus, 1992</marker>
<rawString>Dreyfus, Hubert L. 1992. What Computers Still Can&apos;t Do: A critique of artificial reason. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas R Hofstadter</author>
</authors>
<title>and the Fluid Analogies Research Group.</title>
<date>1995</date>
<publisher>Basic Books,</publisher>
<location>New York.</location>
<marker>Hofstadter, 1995</marker>
<rawString>Hofstadter, Douglas R., and the Fluid Analogies Research Group. 1995. Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought. Basic Books, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Jackson</author>
</authors>
<date>1982</date>
<journal>Epiphenomenal Qualia. Philosophical Quarterly,</journal>
<volume>32</volume>
<pages>127--136</pages>
<contexts>
<context position="15415" citStr="Jackson (1982)" startWordPosition="2407" endWordPosition="2408">he context of a selectionist system) thereby learn to be creative. Bringsjord and Ferrucci&apos;s Arg4 (ID. 74) purports to derive the conclusion that &amp;quot;Computers can&apos;t write sophisticated fiction.&amp;quot; Crucial to this argument is the proposition: 10. &amp;quot;There&apos;s something it&apos;s like to be a&amp;quot; conscious states are not formalizable.. which is the conclusion of Arg3 and rests, in turn, on this premise: 4. Alvin, prior to his [first ever] first-person long-lost-friend experience, doesn&apos;t know what it&apos;s like to meet a long-lost friend in the flesh. (p. 71) In the much-discussed form in which it was put by Frank Jackson (1982), the place of Alvin is taken by Mary, a brain specialist who has been brought up in a purely blackand-white environment and knows, by description, &amp;quot;everything there is to know&amp;quot; about color. It is somehow supposed to be obvious that when suddenly confronted with the first-person experience of colors, she learns something she didn&apos;t know before 646 Book Reviews (p. 53). But why should telling that science-fiction story compel us to believe that? The story is a thought experiment, and thought experiments don&apos;t tell us what must be the case, but only what we think we would think if something were</context>
</contexts>
<marker>Jackson, 1982</marker>
<rawString>Jackson, Frank. 1982. Epiphenomenal Qualia. Philosophical Quarterly, 32: 127-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Penrose</author>
</authors>
<title>Shadows of the Mind: A Search for the Missing Science of Consciousness.</title>
<date>1994</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford and New York.</location>
<contexts>
<context position="11018" citStr="Penrose 1994" startWordPosition="1712" endWordPosition="1713">ould neural nets be relegated to the implementation level of the deductive components of reasoning? Bringsjord and Ferrucci&apos;s answer rests on the fact that there can in principle be no difference between the logical powers of neural nets and those of symbolic systems: &amp;quot;Neural nets can be rendered as cellular automata, cellular automata can be rendered as ... [Turing machinesr—and Turing machines are in principle equivalent to traditional symbolic computers (p. 38). The problem is that this argument can as easily be stood on its head. Despite a long tradition of invoking GOdel to the contrary (Penrose 1994, pp. 171-209), there is no consensus that our own brains cannot be &amp;quot;rendered&amp;quot; as neural nets, and therefore as Turing machines. So the argument simply begs the question. It gives me no reason to reject the following alternative argument: 1. Humans are creative. 2. Human brains are neural nets. 3. Therefore neural nets can be creative. 4. Neural nets are logically equivalent to Turing machines. 5. Therefore Turing machines can be creative. The same strong whiff of question-begging affects the authors&apos; endorsement of well-known arguments against interpreting even the most spectacular success of</context>
</contexts>
<marker>Penrose, 1994</marker>
<rawString>Penrose, Roger. 1994. Shadows of the Mind: A Search for the Missing Science of Consciousness. Oxford University Press, Oxford and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Girolamo Saccheri</author>
<author>George B Halsted</author>
</authors>
<title>Cirolamo Saccheri&apos;s Euclides vindicatus. Edited and translated by</title>
<date>1986</date>
<publisher>Chelsea Publishing Co.,</publisher>
<location>New York.</location>
<contexts>
<context position="13518" citStr="Saccheri and Halsted 1986" startWordPosition="2103" endWordPosition="2106">the latter do not. A crucial underlying assumption is that we ourselves do not implement algorithms when we think creatively. Bringsjord and Ferrucci admit that &amp;quot;raw origination ... may well be impossible,&amp;quot; but they claim to give examples of &amp;quot;a type of creativity in which something utterly and completely new is produced (e.g., non-Euclidean geometry)&amp;quot; (p. xix). But the example undermines the thesis. The elaboration of non-Euclidean geometries required little more than a change of perspective after Giovanni Girolamo Saccheri&apos;s purported proof of the parallels postulate by reductio ad absurdum (Saccheri and Halsted 1986). All that was needed was to notice that the &amp;quot;absurd&amp;quot; consequences entailed no contradiction. Bolyiai&apos;s and Lobachewski&apos;s creative recognition of that fact could certainly be attained by formal methods, but required the choice of a crucial change in attitude. In the light of this example, the best prospect for creative machines seems to me to lie in selectionist systems. If variation and selection was good enough for God, it should be good enough for Al. Or are the products of biological evolution merely algorithmic and therefore not creative enough for Bringsjord and Ferrucci? I&apos;m not sure: t</context>
</contexts>
<marker>Saccheri, Halsted, 1986</marker>
<rawString>Saccheri, Girolamo and George B. Halsted. 1986. Cirolamo Saccheri&apos;s Euclides vindicatus. Edited and translated by George B. Halsted. Chelsea Publishing Co., New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>