<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000124">
<title confidence="0.964187">
Multi-Source Transfer of Delexicalized Dependency Parsers
</title>
<author confidence="0.961289">
Ryan McDonald Slav Petrov Keith Hall
</author>
<affiliation confidence="0.879218">
Google Google Google
</affiliation>
<address confidence="0.941246">
New York, NY New York, NY Z¨urich
</address>
<email confidence="0.999478">
ryanmcd@google.com slav@google.com kbhall@google.com
</email>
<sectionHeader confidence="0.995652" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999918789473684">
We present a simple method for transferring
dependency parsers from source languages
with labeled training data to target languages
without labeled training data. We first demon-
strate that delexicalized parsers can be di-
rectly transferred between languages, produc-
ing significantly higher accuracies than unsu-
pervised parsers. We then use a constraint
driven learning algorithm where constraints
are drawn from parallel corpora to project the
final parser. Unlike previous work on project-
ing syntactic resources, we show that simple
methods for introducing multiple source lan-
guages can significantly improve the overall
quality of the resulting parsers. The projected
parsers from our system result in state-of-the-
art performance when compared to previously
studied unsupervised and projected parsing
systems across eight different languages.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958">
Statistical parsing has been one of the most active ar-
eas of research in the computational linguistics com-
munity since the construction of the Penn Treebank
(Marcus et al., 1993). This includes work on phrase-
structure parsing (Collins, 1997; Charniak, 2000;
Petrov et al., 2006), dependency parsing (McDonald
et al., 2005; Nivre et al., 2006) as well as a num-
ber of other formalisms (Clark and Curran, 2004;
Wang and Harper, 2004; Shen and Joshi, 2008).
As underlying modeling techniques have improved,
these parsers have begun to converge to high lev-
els of accuracy for English newswire text. Subse-
quently, researchers have begun to look at both port-
ing these parsers to new domains (Gildea, 2001; Mc-
Closky et al., 2006; Petrov et al., 2010) and con-
structing parsers for new languages (Collins et al.,
1999; Buchholz and Marsi, 2006; Nivre et al., 2007).
One major obstacle in building statistical parsers
for new languages is that they often lack the manu-
ally annotated resources available for English. This
observation has led to a vast amount of research
on unsupervised grammar induction (Carroll and
Charniak, 1992; Klein and Manning, 2004; Smith
and Eisner, 2005; Cohen and Smith, 2009; Berg-
Kirkpatrick and Klein, 2010; Naseem et al., 2010;
Spitkovsky et al., 2010; Blunsom and Cohn, 2010).
Grammar induction systems have seen large ad-
vances in quality, but parsing accuracies still signif-
icantly lag behind those of supervised systems. Fur-
thermore, they are often trained and evaluated under
idealized conditions, e.g., only on short sentences
or assuming the existence of gold-standard part-of-
speech (POS) tags.1 The reason for these assump-
tions is clear. Unsupervised grammar induction is
difficult given the complexity of the analysis space.
These assumptions help to give the model traction.
The study of unsupervised grammar induction has
many merits. Most notably, it increases our under-
standing of how computers (and possibly humans)
learn in the absence of any explicit feedback. How-
ever, the gold POS tag assumption weakens any con-
clusions that can be drawn, as part-of-speech are
also a form of syntactic analysis, only shallower.
Furthermore, from a practical standpoint, it is rarely
the case that we are completely devoid of resources
for most languages. This point has been made by
</bodyText>
<footnote confidence="0.597762">
1A notable exception is the work of Seginer (2007).
</footnote>
<page confidence="0.980882">
62
</page>
<note confidence="0.9579415">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999950583333333">
studies that transfer parsers to new languages by
projecting syntax across word alignments extracted
from parallel corpora (Hwa et al., 2005; Ganchev et
al., 2009; Smith and Eisner, 2009). Although again,
most of these studies also assume the existence of
POS tags.
In this work we present a method for creating de-
pendency parsers for languages for which no labeled
training data is available. First, we train a source
side English parser that, crucially, is delexicalized so
that its predictions rely soley on the part-of-speech
tags of the input sentence, in the same vein as Ze-
man and Resnik (2008). We empirically show that
directly transferring delexicalized models (i.e. pars-
ing a foreign language POS sequence with an En-
glish parser) already outperforms state-of-the-art un-
supervised parsers by a significant margin. This re-
sult holds in the presence of both gold POS tags as
well as automatic tags projected from English. This
emphasizes that even for languages with no syntac-
tic resources – or possibly even parallel data – sim-
ple transfer methods can already be more powerful
than grammar induction systems.
Next, we use this delexicalized English parser to
seed a perceptron learner for the target language.
The model is trained to update towards parses that
are in high agreement with a source side English
parse based on constraints drawn from alignments in
the parallel data. We use the augmented-loss learn-
ing procedure (Hall et al., 2011) which is closely
related to constraint driven learning (Chang et al.,
2007; Chang et al., 2010). The resulting parser con-
sistently improves on the directly transferred delex-
icalized parser, reducing relative errors by 8% on
average, and as much as 18% on some languages.
Finally, we show that by transferring parsers from
multiple source languages we can further reduce er-
rors by 16% over the directly transferred English
baseline. This is consistent with previous work on
multilingual part-of-speech (Snyder et al., 2009) and
grammar (Berg-Kirkpatrick and Klein, 2010; Cohen
and Smith, 2009) induction, that shows that adding
languages leads to improvements.
We present a comprehensive set of experiments
on eight Indo-European languages for which a sig-
nificant amount of parallel data exists. We make
no language specific enhancements in our experi-
ments. We report results for sentences of all lengths,
</bodyText>
<note confidence="0.870089">
ROOT A hearing is scheduled on the issue today
</note>
<figureCaption confidence="0.997704">
Figure 1: An example (unlabeled) dependency tree.
</figureCaption>
<bodyText confidence="0.999794166666667">
as well as with gold and automatically induced
part-of-speech tags. We also report results on sen-
tences of length 10 or less with gold part-of-speech
tags to compare with previous work. Our results
consistently outperform the previous state-of-the-art
across all languages and training configurations.
</bodyText>
<sectionHeader confidence="0.989204" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.99649219047619">
In this paper we focus on transferring dependency
parsers between languages. A dependency parser
takes a tokenized input sentence (optionally part-of-
speech tagged) and produces a connected tree where
directed arcs represent a syntactic head-modifier re-
lationship. An example of such a tree is given in
Figure 1. Dependency tree arcs are often labeled
with the role of the syntactic relationship, e.g., is to
hearing might be labeled as SUBJECT. However, we
focus on unlabeled parsing in order to reduce prob-
lems that arise due to different treebank annotation
schemes. Of course, even for unlabeled dependen-
cies, significant variations in the annotation schemes
remain. For example, in the Danish treebank deter-
miners govern adjectives and nouns in noun phrases,
while in most other treebanks the noun is the head of
the noun phrase. Unlike previous work (Zeman and
Resnik, 2008; Smith and Eisner, 2009), we do not
apply any transformations to the treebanks, which
makes our results easier to reproduce, but systemat-
ically underestimates accuracy.
</bodyText>
<subsectionHeader confidence="0.996755">
2.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.9991473">
The treebank data in our experiments are from the
CoNLL shared-tasks on dependency parsing (Buch-
holz and Marsi, 2006; Nivre et al., 2007). We use
English (en) only as a source language throughout
the paper. Additionally, we use the following eight
languages as both source and target languages: Dan-
ish (da), Dutch (nl), German (de), Greek (el), Italian
(it), Portuguese (pt), Spanish (es) and Swedish (sv).
For languages that were included in both the 2006
and 2007 tasks, we used the treebank from the lat-
</bodyText>
<page confidence="0.999019">
63
</page>
<bodyText confidence="0.999574314285714">
ter. We focused on this subset of languages because
they are Indo-European and a significant amount of
parallel data exists for each language. By present-
ing results on eight languages our study is already
more comprehensive than most previous work in this
area. However, the restriction to Indo-European lan-
guages does make the results less conclusive when
one wishes to transfer a parser from English to Chi-
nese, for example. To account for this, we report
additional results in the discussion for non-Indo-
European languages. For all data sets we used the
predefined training and testing splits.
Our approach relies on a consistent set of part-
of-speech tags across languages and treebanks. For
this we used the universal tagset from Petrov et
al. (2011), which includes: NOUN (nouns), VERB
(verbs), ADJ (adjectives), ADV (adverbs), PRON
(pronouns), DET (determiners), ADP (prepositions
orpostpositions), NUM (numerals), CONJ (conjunc-
tions), PRT (particles), PUNC (punctuation marks)
and X (a catch-all tag). Similar tagsets are used by
other studies on grammar induction and projection
(Naseem et al., 2010; Zeman and Resnik, 2008). For
all our experiments we replaced the language spe-
cific part-of-speech tags in the treebanks with these
universal tags.
Like all treebank projection studies we require a
corpus of parallel text for each pair of languages we
study. For this we used the Europarl corpus version
5 (Koehn, 2005). The corpus was preprocessed in
standard ways and word aligned by running six it-
erations of IBM Model 1 (Brown et al., 1993), fol-
lowed by six iterations of the HMM model (Vogel et
al., 1996) in both directions. We then intersect word
alignments to generate one-to-one alignments.
</bodyText>
<subsectionHeader confidence="0.998216">
2.2 Parsing Model
</subsectionHeader>
<bodyText confidence="0.999690416666667">
All of our parsing models are based on the
transition-based dependency parsing paradigm
(Nivre, 2008). Specifically, all models use an
arc-eager transition strategy and are trained using
the averaged perceptron algorithm as in Zhang and
Clark (2008) with a beam size of 8. The features
used by all models are: the part-of-speech tags of
the first four words on the buffer and of the top two
words on the stack; the word identities of the first
two words on the buffer and of the top word on the
stack; the word identity of the syntactic head of
the top word on the stack (if available). All feature
conjunctions are included. For treebanks with
non-projective trees we use the pseudo-projective
parsing technique to transform the treebank into
projective structures (Nivre and Nilsson, 2005).
We focus on using this parsing system for two
reasons. First, the parser is near state-of-the-art on
English parsing benchmarks and second, and more
importantly, the parser is extremely fast to train and
run, making it easy to run a large number of exper-
iments. Preliminary experiments using a different
dependency parser – MSTParser (McDonald et al.,
2005) – resulted in similar empirical observations.
</bodyText>
<subsectionHeader confidence="0.991005">
2.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999989333333333">
All systems are evaluated using unlabeled attach-
ment score (UAS), which is the percentage of words
(ignoring punctuation tokens) in a corpus that mod-
ify the correct head (Buchholz and Marsi, 2006).
Furthermore, we evaluate with both gold-standard
part-of-speech tags, as well as predicted part-of-
speech tags from the projected part-of-speech tagger
of Das and Petrov (2011).2 This tagger relies only on
labeled training data for English, and achieves accu-
racies around 85% on the languages that we con-
sider. We evaluate in the former setting to compare
to previous studies that make this assumption. We
evaluate in the latter setting to measure performance
in a more realistic scenario – when no target lan-
guage resources are available.
</bodyText>
<sectionHeader confidence="0.977066" genericHeader="method">
3 Transferring from English
</sectionHeader>
<bodyText confidence="0.999959">
To simplify discussion, we first focus on the most
common instantiation of parser transfer in the liter-
ature: transferring from English to other languages.
In the next section we expand our system to allow
for the inclusion of multiple source languages.
</bodyText>
<subsectionHeader confidence="0.99984">
3.1 Direct Transfer
</subsectionHeader>
<bodyText confidence="0.9996898">
We start with the observation that discriminatively
trained dependency parsers rely heavily on part-of-
speech tagging features. For example, when train-
ing and testing a parser on our English data, a parser
with all features obtains an UAS of 89.3%3 whereas
</bodyText>
<footnote confidence="0.996012">
2Available at http://code.google.com/p/pos-projection/
3The best system at CoNLL 2007 achieved 90.1% and used
a richer part-of-speech tagset (Nivre et al., 2007).
</footnote>
<page confidence="0.999278">
64
</page>
<bodyText confidence="0.999904933333334">
a delexicalized parser – a parser that only has non-
lexical features – obtains an UAS of 82.5%. The
key observation is that part-of-speech tags contain a
significant amount of information for unlabeled de-
pendency parsing.
This observation combined with our universal
part-of-speech tagset, leads to the idea of direct
transfer, i.e., directly parsing the target language
with the source language parser without relying on
parallel corpora. This idea has been previously ex-
plored by Zeman and Resnik (2008) and recently by
Søgaard (2011). Because we use a mapping of the
treebank specific part-of-speech tags to a common
tagset, the performance of a such a system is easy to
measure – simply parse the target language data set
with a delexicalized parser trained on the source lan-
guage data. We conducted two experiments. In the
first, we assumed that the test set for each target lan-
guage had gold part-of-speech tags, and in the sec-
ond we used predicted part-of-speech tags from the
projection tagger of Das and Petrov (2011), which
also uses English as the source language.
UAS for all sentence lengths without punctuation
are given in Table 1. We report results for both the
English direct transfer parser (en-dir.) as well as a
baseline unsupervised grammar induction system –
the dependency model with valence (DMV) of Klein
and Manning (2004), as obtained by the implemen-
tation of Ganchev et al. (2010). We trained on sen-
tences of length 10 or less and evaluated on all sen-
tences from the test set.4 For DMV, we reversed the
direction of all dependencies if this led to higher per-
formance. From this table we can see that direct
transfer is a very strong baseline and is over 20%
absolute better than the DMV model for both gold
and predicted POS tags. Table 4, which we will dis-
cuss in more detail later, further shows that the direct
transfer parser also significantly outperforms state-
of-the-art unsupervised grammar induction models,
but in a more limited setting of sentences of length
less than 10.
Direct transfer works for a couple of reasons.
First, part-of-speech tags contain a significant
amount of information for parsing unlabeled depen-
dencies. Second, this information can be transferred,
</bodyText>
<footnote confidence="0.8249415">
4Training on all sentences results in slightly lower accura-
cies on average.
</footnote>
<bodyText confidence="0.999741357142857">
to some degree, across languages and treebank stan-
dards. This is because, at least for Indo-European
languages, there is some regularity in how syntax
is expressed, e.g., primarily SVO, prepositional, etc.
Even though there are some differences with respect
to relative location of certain word classes, strong
head-modifier POS tag preferences can still help re-
solve these, especially when no other viable alter-
natives are available. Consider for example an arti-
ficial sentence with a tag sequence: ‘VERB NOUN
ADJ DET PUNC’. The English parser still predicts
that the NOUN and PUNC modify the VERB and the
ADJ and DET modify the NOUN, even though in the
English data such noun phrases are unlikely.5
</bodyText>
<subsectionHeader confidence="0.999634">
3.2 Projected Transfer
</subsectionHeader>
<bodyText confidence="0.999995965517241">
Unlike most language transfer systems for parsers,
the direct transfer approach does not rely on project-
ing syntax across aligned parallel corpora (modulo
the fact that non-gold tags come from a system that
uses parallel corpora). In this section we describe
a simple mechanism for projecting from the direct
transfer system using large amounts of parallel data
in a similar vein to Hwa et al. (2005), Ganchev et
al. (2009), Smith and Eisner (2009) inter alia. The
algorithm is based on the work of Hall et al. (2011)
for training extrinsic parser objective functions and
borrows heavily from ideas in learning with weak
supervision including work on learning with con-
straints (Chang et al., 2007) and posterior regular-
ization (Ganchev et al., 2010). In our case, the
weak signals come from aligned source and target
sentences, and the agreement in their corresponding
parses, which is similar to posterior regularization
or the bilingual view of Smith and Smith (2004) and
Burkett et al. (2010).
The algorithm is given in Figure 2. It starts by
labeling a set of target language sentences with a
parser, which in our case is the direct transfer parser
from the previous section (line 1). Next, it uses
these parsed target sentences to ‘seed’ a new parser
by training a parameter vector using the predicted
parses as a gold standard via standard perceptron
updates for J rounds (lines 3-6). This generates a
parser that emulates the direct transfer parser, but
</bodyText>
<footnote confidence="0.9600825">
5This requires a transition-based parser with a beam greater
than 1 to allow for ambiguity to be resolved at later stages.
</footnote>
<page confidence="0.997622">
65
</page>
<figure confidence="0.993497714285714">
seed-stage
projection-stage
Notation:
x: input sentence
y: dependency tree
a: alignment
w: parameter vector
</figure>
<figureCaption confidence="0.722049">
φ(x, y): feature vector
</figureCaption>
<bodyText confidence="0.793777">
DP: dependency parser, i.e., DP : x -+ y
</bodyText>
<equation confidence="0.823139666666667">
Input:
X = {xi}ni=1: target language sentences
P = {(xsi, xti, ai)}mi=1: aligned source-target sentences
</equation>
<listItem confidence="0.824273916666667">
DPdelex: delexicalized source parser
DPlex: lexicalized source parser
Algorithm:
1. Let X0 = {(xi, yi)}ni=1 where yi = DPdelex(xi)
2. w = 0
3. for j : 1 ... J
4. for xi : x1 ... xn
5. Let y = argmaxy w · φ(xi, y)
6. w = w + φ(xt, yi) − φ(xi, y)
7. for (xsi, xti, ai) : (xs1, xt1, a1) ... (xsm, xsm, am)
8. Let ys = DPlex(xsi )
9. Let Yt = {y1 i , ... , yki }, where:
</listItem>
<equation confidence="0.9906525">
yki = argmaxy/E{y1 i ,...,yk−1
i } w · φ(xti, y)
10. Let yt = argmaxytEYt ALIGN(ys, yt, ai)
11. w = w + φ(xi, yt) − φ(xi, y1i
)
return DP* such that DP*(x) = argmaxy w · φ(x, y)
</equation>
<bodyText confidence="0.99936492">
that are considered ‘good’ by some external met-
ric. The algorithm then updates towards that out-
put. In this case ‘goodness’ is determined through
the pre-specified sentence alignment and how well
the target language parse aligns with the English
parse. As a result, the model will, ideally, converge
to a state where it predicts target parses that align as
closely as possible with the corresponding English
parses. However, since we seed the learner with the
direct transfer parser, we bias the parameters to se-
lect parses that both align well and also have high
scores under the direct transfer model. This helps
to not only constrain the search space at the start
of learning, but also helps to bias dependencies be-
tween words that are not part of the alignment.
So far we have not defined the ALIGN function
that is used to score potential parses. Let a =
{(s(1), t(1)), ... , (s(n), t(n))} be an alignment where
s(i) is a word in the source sentence xs (not nec-
essarily the ith word) and t(i) is similarly a word
in the target sentence xt (again, not necessarily the
ith word). The notation (s(i), t(i)) E a indicates
two words are the ith aligned pair in a. We define
the ALIGN function to encode the Direct Correspon-
dence Assumption (DCA) from Hwa et al. (2005):
</bodyText>
<figureCaption confidence="0.96523575">
Figure 2: Perceptron-based learning algorithm for train- ALIGN(ys, yt, a) SCORE(ys, yt, (s(i), s(j)), (t(i), t(j)))
ing a parser by seeding the model with a direct transfer E=
parser and projecting constraints across parallel corpora. (s(i),t(i))Ea
(s(j),t(j))Ea
</figureCaption>
<bodyText confidence="0.999841235294118">
has now been lexicalized and is working in the space
of target language sentences. Next, the algorithm it-
erates over the sentences in the parallel corpus. It
parses the English sentence with an English parser
(line 8, again a lexicalized parser). It then uses the
current target language parameter vector to create
a k-best parse list for the target sentence (line 9).
From this list, it selects the parse whose dependen-
cies align most closely with the English parse via the
pre-specified alignment (line 10, also see below for
the definition of the ALIGN function). It then uses
this selected parse as a proxy to the gold standard
parse to update the parameters (line 11).
The intuition is simple. The parser starts with
non-random accuracies by emulating the direct
transfer model and slowly tries to induce better pa-
rameters by selecting parses from its k-best list
</bodyText>
<equation confidence="0.9946578">
SCORE(ys, yt, (s(i), s(j)), (t(i), t(j)))
+1 if (s(i), s(j)) E ys and (t(i), t(j)) E yt
−1 if (s(i), s(j)) E ys and (t(i), t(j)) E/ yt
−1 if (s(i), s(j)) E/ ys and (t(i), t(j)) E yt
0 otherwise
</equation>
<bodyText confidence="0.999760363636364">
The notation (i, j) E y indicates that a dependency
from head i to modifier j is in tree y. The ALIGN
function rewards aligned head-modifier pairs and
penalizes unaligned pairs when a possible alignment
exists. For all other cases it is agnostic, i.e., when
one or both of the modifier or head are not aligned.
Figure 3 shows an example of aligned English-
Greek sentences, the English parse and a potential
Greek parse. In this case the ALIGN function re-
turns a value of 2. This is because there are three
aligned dependencies: took→book, book→the and
</bodyText>
<figure confidence="0.63634525">
= I
66
flrjpg To RiRAio aTr6 Tov T(ov
She took the book from John
</figure>
<figureCaption confidence="0.998048333333333">
Figure 3: A Greek and English sentence pair. Word
alignments are shown as dashed lines, dependency arcs
as solid lines.
</figureCaption>
<bodyText confidence="0.999875864864865">
from→John. These add 3 to the score. There is
one incorrectly aligned dependency: the preposi-
tion mistakenly modifies the noun on the Greek side.
This subtracts 1. Finally, there are two dependencies
that do not align: the subject on the English side
and a determiner to a proper noun on the Greek side.
These do not effect the result.
The learning algorithm in Figure 2 is an instance
of augmented-loss training (Hall et al., 2011) which
is closely related to the constraint driven learning al-
gorithms of Chang et al. (2007). In that work, ex-
ternal constraints on output structures are used to
help guide the learner to good parameter regions.
In our model, we use constraints drawn from paral-
lel data exactly in the same manner. Since posterior
regularization is closely related to constraint driven
learning, this makes our algorithm also similar to the
parser projection approach of Ganchev et al. (2009).
There are a couple of differences. First, we bias our
model towards the direct transfer model, which is
already quite powerful. Second, our alignment con-
straints are used to select parses from a k-best list,
whereas in posterior regularization they are used as
soft constraints on full model expectations during
training. The latter is beneficial as the use of k-best
lists does not limit the class of parsers to those whose
parameters and search space decompose neatly with
the DCA loss function. An empirical comparison to
Ganchev et al. (2009) is given in Section 5.
Results are given in Table 1 under the column en-
proj. For all experiments we train the seed-stage
perceptron for 5 iterations (J = 5) and we use one
hundred times as much parallel data as seed stage
non-parallel data (m = 100n). The seed-stage non-
parallel data is the training portion of each treebank,
stripped of all dependency annotations. After train-
ing the projected parser we average the parameters
</bodyText>
<tableCaption confidence="0.9006968">
Table 1: UAS for the unsupervised DMV model (DMV),
a delexicalized English direct transfer parser (en-dir.)
and a English projected parser (en-proj.). Measured on
all sentence lengths for both gold and predicted part-of-
speech tags as input.
</tableCaption>
<bodyText confidence="0.999601578947369">
of the model (Collins, 2002). The parsers evaluated
using predicted part-of-speech tags use the predicted
tags at both training and testing time and are thus
free of any target language specific resources.
When compared with the direct transfer model
(en-dir. in Table 1), we can see that there is an im-
provement for every single language, reducing rela-
tive error by 8% on average (57.0% to 60.4%) and
up to 18% for Dutch (60.8 to 67.8%). One could
wonder whether the true power of the projection
model comes from the re-lexicalization step – lines
3-6 of the algorithm. However, if just this step is run,
then the average UAS only increases from 57.0%
to 57.4%, showing that most of the improvement
comes from the projection stage. Note that the re-
sults in Table 1 indicate that parsers using predicted
part-of-speech tags are only slightly worse than the
parsers using gold tags (about 2-3% absolute), show-
ing that these methods are robust to tagging errors.
</bodyText>
<sectionHeader confidence="0.995033" genericHeader="method">
4 Multi-Source Transfer
</sectionHeader>
<bodyText confidence="0.999779416666667">
The previous section focused on transferring an En-
glish parser to a new target language. However,
there are over 20 treebanks available for a variety
of language groups including Indo-European, Altaic
(including Japanese), Semitic, and Sino-Tibetan.
Many of these are even in standardized formats
(Buchholz and Marsi, 2006; Nivre et al., 2007). Past
studies have shown that for both part-of-speech tag-
ging and grammar induction, learning with multiple
comparable languages leads to improvements (Co-
hen and Smith, 2009; Snyder et al., 2009; Berg-
Kirkpatrick and Klein, 2010). In this section we ex-
</bodyText>
<figure confidence="0.861496258064516">
gold-POS
DMV en-dir. en-proj.
33.4 45.9 48.2
18.0 47.2 50.9
39.9 63.9 66.8
28.5 53.3 55.8
43.1 57.7 60.8
38.5 60.8 67.8
20.1 69.2 71.3
44.0 58.3 61.3
33.2 57.0 60.4
pred-POS
DMV en-dir. en-proj.
18.4 44.0 45.5
30.3 44.7 47.4
21.2 63.0 65.2
19.9 50.2 52.4
37.7 53.7 56.3
19.9 62.1 66.5
21.0 66.2 67.7
33.8 56.5 59.7
25.3 55.0 57.6
da
de
el
es
it
nl
pt
sv
avg
</figure>
<page confidence="0.995299">
67
</page>
<table confidence="0.997029363636364">
da de el Source Training Language nl pt sv
en es it
da 79.2 45.2 44.0 45.9 45.0 48.6 46.1 48.1 47.8
de 34.3 83.9 53.2 47.2 45.8 53.4 55.8 55.5 46.2
el 33.3 52.5 77.5 63.9 41.6 59.3 57.3 58.6 47.5
en 34.4 37.9 45.7 82.5 28.5 38.6 43.7 42.3 43.7
es 38.1 49.4 57.3 53.3 79.7 68.4 51.2 66.7 41.4
it 44.8 56.7 66.8 57.7 64.7 79.3 57.6 69.1 50.9
nl 38.7 43.7 62.1 60.8 40.9 50.4 73.6 58.5 44.2
pt 42.5 52.0 66.6 69.2 68.5 74.7 67.1 84.6 52.1
sv 44.5 57.0 57.8 58.3 46.3 53.4 54.5 66.8 84.8
</table>
<tableCaption confidence="0.99834775">
Table 2: UAS for all source-target language pairs. Each column represents which source language was used to train a
delexicalized parser and each row represents which target language test data was used. Bold numbers are when source
equals target and underlined numbers are the single best UAS for a target language. Results are for all sentence lengths
without punctuation.
</tableCaption>
<subsectionHeader confidence="0.561901">
Target Test Language
</subsectionHeader>
<bodyText confidence="0.998152970588236">
amine whether this is also true for parser transfer.
Table 2 shows the matrix of source-target lan-
guage UAS for all nine languages we consider (the
original eight target languages plus English). We
can see that there is a wide range from 33.3% to
74.7%. There is also a wide range of values depend-
ing on the source training data and/or target testing
data, e.g., Portuguese as a source tends to parse tar-
get languages much better than Danish, and is also
more amenable as a target testing language. Some
of these variations are expected, e.g., the Romance
languages (Spanish, Italian and Portuguese) tend to
transfer well to one another. However, some are
unexpected, e.g., Greek being the best source lan-
guage for Dutch, as well as German being one of the
worst. This is almost certainly due to different an-
notation schemes across treebanks. Overall, Table 2
does indicate that there are possible gains in accu-
racy through the inclusion of additional languages.
In order to take advantage of treebanks in multi-
ple languages, our multi-source system simply con-
catenates the training data from all non-target lan-
guages. In other words, the multi-source direct
transfer parser for Danish will be trained by first
concatenating the training corpora of the remain-
ing eight languages, training a delexicalized parser
on this data and then directly using this parser to
analyze the Danish test data. For the multi-source
projected parser, the procedure is identical to that
in Section 3.2 except that we use the multi-source
direct transfer model to seed the algorithm instead
of the English-only direct transfer model. For these
experiments we still only use English-target parallel
data because that is the format of the readily avail-
able data in the Europarl corpus.
Table 3 presents four sets of results. The first
(best-source) is the direct transfer results for the ora-
cle single-best source language per target language.
The second (avg-source) is the mean UAS over all
source languages per target language. The third
(multi-dir.) is the multi-source direct transfer sys-
tem. The fourth and final result set (multi-proj.)
is the multi-source projected system. The resulting
parsers are typically much more accurate than the
English direct transfer system (Table 1). On aver-
age, the multi-source direct transfer system reduces
errors by 10% relative over the English-only direct
transfer system. These improvements are not consis-
tent. For Greek and Dutch we see significant losses
relative to the English-only system. An inspection of
Table 2 shows that for these two languages English
is a particularly good source training language.
For the multi-source projected system the results
are mixed. Some languages see basically no change
relative the multi-source direct transfer model, while
some languages see modest to significant increases.
But again, there is an overall trend to better mod-
els. In particular, starting with an English-only di-
rect transfer parser with 57.0% UAS on average,
by adding parallel corpora and multiple source lan-
guages we finish with parser having 63.8% UAS
on average, which is a relative reduction in error
of roughly 16% and more than doubles the perfor-
mance of a DMV model (Table 1).
Interestingly, the multi-source systems provide,
on average, accuracies near that of the single-best
source language and significantly better than the av-
erage source UAS. Thus, even this simple method of
</bodyText>
<page confidence="0.997954">
68
</page>
<table confidence="0.998103161290323">
best-source avg-source gold-POS
source gold-POS gold-POS multi-dir. multi-proj.
it 48.6 46.3 48.9 49.5
nl 55.8 48.9 56.7 56.6
en 63.9 51.7 60.1 65.1
it 68.4 53.2 64.2 64.5
pt 69.1 58.5 64.1 65.0
el 62.1 49.9 55.8 65.7
it 74.8 61.6 74.0 75.6
pt 66.8 54.8 65.3 68.0
63.7 51.6 61.1 63.8
pred-POS
multi-dir. multi-proj.
46.2 47.5
51.7 52.0
58.5 63.0
55.6 56.5
56.8 58.9
54.3 64.4
67.7 70.3
58.3 62.1
56.1 59.3
da
de
el
es
it
nl
pt
sv
avg
</table>
<tableCaption confidence="0.97034">
Table 3: UAS for multi-source direct (multi-dir.) and projected (multi-proj.) transfer systems. best-source is the best
source model from the languages in Table 2 (excluding the target language). avg-source is the mean UAS over the
source models for the target (excluding target language).
</tableCaption>
<bodyText confidence="0.99980325">
multi-source transfer already provides strong perfor-
mance gains. We expect that more principled tech-
niques will lead to further improvements. For exam-
ple, recent work by Søgaard (2011) explores data set
sub-sampling methods. Unlike our work, Søgaard
found that simply concatenating all the data led to
degradation in performance. Cohen et al. (2011) ex-
plores the idea learning language specific mixture
coefficients for models trained independently on the
target language treebanks. However, their results
show that this method often did not significantly out-
perform uniform mixing.
</bodyText>
<sectionHeader confidence="0.991049" genericHeader="method">
5 Comparison
</sectionHeader>
<bodyText confidence="0.999702333333333">
Comparing unsupervised and parser projection sys-
tems is difficult as many publications use non-
overlapping sets of languages or different evaluation
criteria. We compare to the following three systems
that do not augment the treebanks and report results
for some of the languages that we considered:
</bodyText>
<listItem confidence="0.903058">
• USR: The weakly supervised system of
</listItem>
<bodyText confidence="0.8761615">
Naseem et al. (2010), in which manually de-
fined universal syntactic rules (USR) are used
to constrain a probabilistic Bayesian model. In
addition to their original results, we also report
results using the same part-of-speech tagset as
the systems described in this paper (USR†).
This is useful for two reasons. First, it makes
the comparison more direct. Second, we can
generate USR results for all eight languages
and not just for the languages that they report.
</bodyText>
<listItem confidence="0.958656727272727">
• PGI: The phylogenetic grammar induction
(PGI) model of Berg-Kirkpatrick and Klein
(2010), in which the parameters of completely
unsupervised DMV models for multiple lan-
guages are coupled via a phylogenetic prior.
• PR: The posterior regularization (PR) approach
of Ganchev et al. (2009), in which a supervised
English parser is used to generate constraints
that are projected using a parallel corpus and
used to regularize a target language parser. We
report results without treebank specific rules.
</listItem>
<bodyText confidence="0.999691884615384">
Table 4 gives results comparing the models pre-
sented in this work to those three systems. For this
comparison we use sentences of length 10 or less
after punctuation has been removed in order to be
consistent with reported results. The overall trends
carry over from the full treebank setting to this re-
duced sentence length setup: the projected mod-
els outperform the direct transfer models and multi-
source transfer gives higher accuracy than transfer-
ring only from English. Most previous work has as-
sumed gold part-of-speech tags, but as the code for
USR is publicly available we were able to train it
using the same projected part-of-speech tags used
in our models. These results are also given in Ta-
ble 4 under USR†. Again, we can see that the multi-
source systems (both direct and projected) signifi-
cantly outperform the unsupervised models.
It is not surprising that a parser transferred from
annotated resources does significantly better than
unsupervised systems since it has much more in-
formation from which to learn. The PR system of
Ganchev et al. (2009) is similar to ours as it also
projects syntax across parallel corpora. For Span-
ish we can see that the multi-source direct trans-
fer parser is better (75.1% versus 70.6%), and this
is also true for the multi-source projected parser
</bodyText>
<page confidence="0.998447">
69
</page>
<table confidence="0.969378083333333">
←− gold-POS −→
en-dir. en-proj. multi-dir. multi-proj. USR† USR PGI PR
53.2 57.4 58.4 58.8 55.1 51.9 41.6
65.9 67.0 74.9 72.0 60.0
73.9 73.9 73.5 78.7 60.3
58.0 62.3 75.1 73.2 68.3 67.2 58.4 70.6
65.5 69.9 75.5 75.5 47.9
67.6 72.2 58.8 70.7 44.0 45.1
77.9 80.6 81.1 86.2 70.9 71.5 63.0
70.4 71.3 76.0 77.6 52.6 58.3
66.6 69.4 71.7 74.1 57.4
← pred-POS →
</table>
<tableCaption confidence="0.39183">
multi-dir. multi-proj.
</tableCaption>
<figure confidence="0.959873178571429">
54.9 54.6
63.7 63.4
65.2 74.3
59.1 56.8
65.5 70.2
56.3 67.2
74.0 79.2
72.0 73.9
63.9 67.5
da
de
el
es
it
nl
pt
sv
avg
USR†
41.7
55.1
53.4
43.3
41.4
38.8
66.4
59.4
49.9
</figure>
<tableCaption confidence="0.719424666666667">
Table 4: UAS on sentences of length 10 or less without punctuation, comparing the systems presented in this work
to three representative systems from related work. en-dir./en-proj. are the direct/projected English parsers and multi-
dir./multi-proj. are the multi-source direct/projected parsers. Section 5 contains a description of the baseline systems.
</tableCaption>
<bodyText confidence="0.999341954545454">
(73.2%). Ganchev et al. also report results for
Bulgarian. We trained a multi-source direct trans-
fer parser for Bulgarian which obtained a score of
72.8% versus 67.8% for the PR system. If we only
use English as a source language, as in Ganchev et
al., the English direct transfer model achieves 66.1%
on Bulgarian and 69.3% on Spanish versus 67.8%
and 70.6% for PR. In this setting the English pro-
jected model gets 72.0% on Spanish. Thus, under
identical conditions the direct transfer model obtains
accuracies comparable to PR.6
Another projection based system is that of Smith
and Eisner (2009), who report results for German
(68.5%) and Spanish (64.8%) on sentences of length
15 and less inclusive of punctuation. Smith and Eis-
ner use custom splits of the data and modify a sub-
set of the dependencies. The multi-source projected
parser obtains 71.9% for German and 67.8% for
Spanish on this setup.7 If we cherry-pick the source
language the results can improve, e.g., for Spanish
we can obtain 71.7% and 70.8% by directly transfer-
ring parsers form Italian or Portuguese respectively.
</bodyText>
<sectionHeader confidence="0.999768" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999903">
One fundamental point the above experiments il-
lustrate is that even for languages for which no
resources exist, simple methods for transferring
parsers work remarkably well. In particular, if
</bodyText>
<footnote confidence="0.9943865">
6Note that the last set of results was obtained by using the
same English training data as Ganchev et al. Using the CoNLL
2007 English data set for training, the English direct transfer
model is 63.2% for Bulgarian and 58.0% for Spanish versus
67.8% and 70.6% for PR, highlighting the large impact that dif-
ference treebank annotation standards can have.
7Data sets and evaluation criteria obtained via communica-
tions with David Smith and Jason Eisner.
</footnote>
<bodyText confidence="0.999781314285714">
one can transfer part-of-speech tags, then a large
part of transferring unlabeled dependencies has been
solved. This observation should lead to a new base-
line in unsupervised and projected grammar induc-
tion – the UAS of a delexicalized English parser.
Of course, our experiments focus strictly on Indo-
European languages. Preliminary experiments for
Arabic (ar), Chinese (zh), and Japanese (ja) suggest
similar direct transfer methods are applicable. For
example, on the CoNLL test sets, a DMV model
obtains UAS of 28.7/41.8/34.6% for ar/zh/ja re-
spectively, whereas an English direct transfer parser
obtains 32.1/53.8/32.2% and a multi-source direct
transfer parser obtains 39.9/41.7/43.3%. In this
setting only Indo-European languages are used as
source data. Thus, even across language groups di-
rect transfer is a reasonable baseline. However, this
is not necessary as treebanks are available for a num-
ber of language groups, e.g., Indo-European, Altaic,
Semitic, and Sino-Tibetan.
The second fundamental observation is that when
available, multiple sources should be used. Even
through naive multi-source methods (concatenating
data), it is possible to build a system that has compa-
rable accuracy to the single-best source for all lan-
guages. This advantage does not come simply from
having more data. In fact, if we randomly sam-
pled from the multi-source data until the training set
size was equivalent to the size of the English data,
then the results still hold (and in fact go up slightly
for some languages). This suggests that even bet-
ter transfer models can be produced by separately
weighting each of the sources depending on the tar-
get language – either weighting by hand, if we know
the language group of the target language, or auto-
</bodyText>
<page confidence="0.992798">
70
</page>
<bodyText confidence="0.988724">
matically, if we do not. As previously mentioned,
the latter has been explored in both Søgaard (2011)
and Cohen et al. (2011).
</bodyText>
<sectionHeader confidence="0.99871" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999984142857143">
We presented a simple, yet effective approach
for projecting parsers from languages with labeled
training data to languages without any labeled train-
ing data. Central to our approach is the idea of
delexicalizing the models, which combined with a
standardized part-of-speech tagset allows us to di-
rectly transfer models between languages. We then
use a constraint driven learning algorithm to adapt
the transferred parsers to the respective target lan-
guage, obtaining an additional 16% error reduc-
tion on average in a multi-source setting. Our final
parsers achieve state-of-the-art accuracies on eight
Indo-European languages, significantly outperform-
ing previous unsupervised and projected systems.
Acknowledgements: We would like to thank Kuz-
man Ganchev, Valentin Spitkovsky and Dipanjan
Das for numerous discussions on this topic and com-
ments on earlier drafts of this paper. We would
also like to thank Shay Cohen, Dipanjan Das, Noah
Smith and Anders Søgaard for sharing early drafts
of their recent related work.
</bodyText>
<sectionHeader confidence="0.998532" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999801150684932">
T. Berg-Kirkpatrick and D. Klein. 2010. Phylogenetic
grammar induction. In Proc. of ACL.
P. Blunsom and T. Cohn. 2010. Unsupervised induction
of tree substitution grammars for dependency parsing.
Proc. of EMNLP.
P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: parameter estimation. Computa-
tional Linguistics, 19.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL.
D. Burkett, S. Petrov, J. Blitzer, and D. Klein. 2010.
Learning better monolingual models with unannotated
bilingual text. In Proc. of CoNLL.
G. Carroll and E. Charniak. 1992. Two experiments on
learning probabilistic dependency grammars from cor-
pora. In Proc. of the Working Notes of the Workshop
Statistically-Based NLP Techniques.
M.W. Chang, L. Ratinov, and D. Roth. 2007. Guiding
semi-supervision with constraint-driven learning. In
Proc. of ACL.
M. Chang, D. Goldwasser, D. Roth, and V. Srikumar.
2010. Structured output learning with indirect super-
vision. In Proc. of ICML.
E. Charniak. 2000. A maximum-entropy-inspired parser.
In Proc. of NAACL.
S. Clark and J. R. Curran. 2004. Parsing the WSJ using
CCG and log-linear models. In Proc. of ACL.
S.B. Cohen and N.A. Smith. 2009. Shared logistic nor-
mal distributions for soft parameter tying in unsuper-
vised grammar induction. In Proc. of NAACL.
S.B. Cohen, D. Das, and N.A. Smith. 2011. Unsuper-
vised structure prediction with non-parallel multilin-
gual guidance. In Proc. of EMNLP.
M. Collins, J. Hajiˇc, L. Ramshaw, and C. Tillmann. 1999.
A statistical parser for Czech. In Proc. of ACL.
M. Collins. 1997. Three generative, lexicalised models
for statistical parsing. In Proc. of ACL.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. ofACL.
D. Das and S. Petrov. 2011. Unsupervised part-of-
speech tagging with bilingual graph-based projections.
In Proc. of ACL-HLT.
K. Ganchev, J. Gillenwater, and B. Taskar. 2009. De-
pendency grammar induction via bitext projection con-
straints. In Proc. of ACL-IJCNLP.
K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar.
2010. Posterior regularization for structured latent
variable models. Journal of Machine Learning Re-
search.
D. Gildea. 2001. Corpus variation and parser perfor-
mance. In Proc of EMNLP.
K. Hall, R. McDonald, J. Katz-Brown, and M. Ringgaard.
2011. Training dependency parsers by jointly optimiz-
ing multiple objectives. In Proc. of EMNLP.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Ko-
lak. 2005. Bootstrapping parsers via syntactic projec-
tion across parallel texts. Natural Language Engineer-
ing, 11(03):311–325.
D. Klein and C. D. Manning. 2004. Corpus-based induc-
tion of syntactic structure: models of dependency and
constituency. In Proc. of ACL.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In MT Summit.
M. P. Marcus, Mary Ann Marcinkiewicz, and Beatrice
Santorini. 1993. Building a large annotated corpus of
English: the Penn treebank. Computational Linguis-
tics, 19.
D. McClosky, E. Charniak, and M. Johnson. 2006.
Reranking and self-training for parser adaptation. In
Proc. of ACL.
</reference>
<page confidence="0.97971">
71
</page>
<reference confidence="0.999912015384615">
R. McDonald, K. Crammer, and F. Pereira. 2005. Online
large-margin training of dependency parsers. In Proc.
of ACL.
T. Naseem, H. Chen, R. Barzilay, and M. Johnson. 2010.
Using universal linguistic knowledge to guide gram-
mar induction. In Proc. of EMNLP.
J. Nivre and J. Nilsson. 2005. Pseudo-projective depen-
dency parsing. In Proc. of ACL.
J. Nivre, J. Hall, and J. Nilsson. 2006. Maltparser: A
data-driven parser-generator for dependency parsing.
In Proc. of LREC.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc. of
EMNLP-CoNLL.
J. Nivre. 2008. Algorithms for deterministic incremen-
tal dependency parsing. Computational Linguistics,
34(4):513–553.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006.
Learning accurate, compact, and interpretable tree an-
notation. In Proc. of ACL.
S. Petrov, P. Chang, M. Ringgaard, and H. Alshawi.
2010. Uptraining for accurate deterministic question
parsing. In EMNLP ’10.
S. Petrov, D. Das, and R. McDonald. 2011. A universal
part-of-speech tagset. In ArXiv:1104.2086.
Y. Seginer. 2007. Fast unsupervised incremental parsing.
In Proc. of ACL.
L. Shen and A.K. Joshi. 2008. Ltag dependency parsing
with bidirectional incremental construction. In Proc.
of EMNLP.
N.A. Smith and J. Eisner. 2005. Contrastive estimation:
Training log-linear models on unlabeled data. In Proc.
of ACL.
D.A. Smith and J. Eisner. 2009. Parser adaptation and
projection with quasi-synchronous grammar features.
In Proc. of EMNLP.
D.A. Smith and N.A. Smith. 2004. Bilingual parsing
with factored estimation: Using english to parse ko-
rean. In Proc. of EMNLP.
B. Snyder, T. Naseem, J. Eisenstein, and R. Barzilay.
2009. Adding more languages improves unsupervised
multilingual part-of-speech tagging: A Bayesian non-
parametric approach. In Proc. of NAACL.
A. Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In Proc.
ACL.
V.I. Spitkovsky, H. Alshawi, and D. Jurafsky. 2010.
From baby steps to leapfrog: How “less is more” in un-
supervised dependency parsing. In Proc. of NAACL-
HLT.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
word alignment in statistical translation. In Proc. of
COLING.
W. Wang and M. P. Harper. 2004. A statistical con-
straint dependency grammar (CDG) parser. In Proc. of
the Workshop on Incremental Parsing: Bringing Engi-
neering and Cognition Together.
D. Zeman and P. Resnik. 2008. Cross-language parser
adaptation between related languages. In NLP for Less
Privileged Languages.
Y. Zhang and S. Clark. 2008. A Tale of Two
Parsers: Investigating and Combining Graph-based
and Transition-based Dependency Parsing. In Proc.
of EMNLP.
</reference>
<page confidence="0.998719">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.299157">
<title confidence="0.999986">Multi-Source Transfer of Delexicalized Dependency Parsers</title>
<author confidence="0.7580855">Ryan McDonald Slav Petrov Keith Hall Google Google Google</author>
<affiliation confidence="0.434322">New York, NY New York, NY Z¨urich</affiliation>
<email confidence="0.998203">ryanmcd@google.comslav@google.comkbhall@google.com</email>
<abstract confidence="0.9998499">We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data. We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsupervised parsers. We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser. Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Berg-Kirkpatrick</author>
<author>D Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="5646" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="877" endWordPosition="880">e use the augmented-loss learning procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induction, that shows that adding languages leads to improvements. We present a comprehensive set of experiments on eight Indo-European languages for which a significant amount of parallel data exists. We make no language specific enhancements in our experiments. We report results for sentences of all lengths, ROOT A hearing is scheduled on the issue today Figure 1: An example (unlabeled) dependency tree. as well as with gold and automatically induced part-of-speech tags. We also report results on sentences of length 10 or less with gold part-of-speech tags to compare </context>
<context position="31703" citStr="Berg-Kirkpatrick and Klein (2010)" startWordPosition="5219" endWordPosition="5222">e of the languages that we considered: • USR: The weakly supervised system of Naseem et al. (2010), in which manually defined universal syntactic rules (USR) are used to constrain a probabilistic Bayesian model. In addition to their original results, we also report results using the same part-of-speech tagset as the systems described in this paper (USR†). This is useful for two reasons. First, it makes the comparison more direct. Second, we can generate USR results for all eight languages and not just for the languages that they report. • PGI: The phylogenetic grammar induction (PGI) model of Berg-Kirkpatrick and Klein (2010), in which the parameters of completely unsupervised DMV models for multiple languages are coupled via a phylogenetic prior. • PR: The posterior regularization (PR) approach of Ganchev et al. (2009), in which a supervised English parser is used to generate constraints that are projected using a parallel corpus and used to regularize a target language parser. We report results without treebank specific rules. Table 4 gives results comparing the models presented in this work to those three systems. For this comparison we use sentences of length 10 or less after punctuation has been removed in or</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>T. Berg-Kirkpatrick and D. Klein. 2010. Phylogenetic grammar induction. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>T Cohn</author>
</authors>
<title>Unsupervised induction of tree substitution grammars for dependency parsing.</title>
<date>2010</date>
<booktitle>Proc. of EMNLP.</booktitle>
<contexts>
<context position="2367" citStr="Blunsom and Cohn, 2010" startWordPosition="358" endWordPosition="361">ew domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis space. These assumptions help to give the model traction. The study of unsupervised grammar induction has many merits. Most notably, it increases our </context>
</contexts>
<marker>Blunsom, Cohn, 2010</marker>
<rawString>P. Blunsom and T. Cohn. 2010. Unsupervised induction of tree substitution grammars for dependency parsing. Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>S A Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="9521" citStr="Brown et al., 1993" startWordPosition="1493" endWordPosition="1496">ctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of our parsing models are based on the transition-based dependency parsing paradigm (Nivre, 2008). Specifically, all models use an arc-eager transition strategy and are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all models are: the part-of-speech tags of the first four words on the buffer and of the top two words on the stack; the word identi</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL.</booktitle>
<contexts>
<context position="1904" citStr="Buchholz and Marsi, 2006" startWordPosition="284" endWordPosition="287">tructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervise</context>
<context position="7576" citStr="Buchholz and Marsi, 2006" startWordPosition="1177" endWordPosition="1181">ation schemes. Of course, even for unlabeled dependencies, significant variations in the annotation schemes remain. For example, in the Danish treebank determiners govern adjectives and nouns in noun phrases, while in most other treebanks the noun is the head of the noun phrase. Unlike previous work (Zeman and Resnik, 2008; Smith and Eisner, 2009), we do not apply any transformations to the treebanks, which makes our results easier to reproduce, but systematically underestimates accuracy. 2.1 Data Sets The treebank data in our experiments are from the CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). We use English (en) only as a source language throughout the paper. Additionally, we use the following eight languages as both source and target languages: Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) and Swedish (sv). For languages that were included in both the 2006 and 2007 tasks, we used the treebank from the lat63 ter. We focused on this subset of languages because they are Indo-European and a significant amount of parallel data exists for each language. By presenting results on eight languages our study is already mo</context>
<context position="11103" citStr="Buchholz and Marsi, 2006" startWordPosition="1751" endWordPosition="1754">n, 2005). We focus on using this parsing system for two reasons. First, the parser is near state-of-the-art on English parsing benchmarks and second, and more importantly, the parser is extremely fast to train and run, making it easy to run a large number of experiments. Preliminary experiments using a different dependency parser – MSTParser (McDonald et al., 2005) – resulted in similar empirical observations. 2.3 Evaluation All systems are evaluated using unlabeled attachment score (UAS), which is the percentage of words (ignoring punctuation tokens) in a corpus that modify the correct head (Buchholz and Marsi, 2006). Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-ofspeech tags from the projected part-of-speech tagger of Das and Petrov (2011).2 This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider. We evaluate in the former setting to compare to previous studies that make this assumption. We evaluate in the latter setting to measure performance in a more realistic scenario – when no target language resources are available. 3 Transferring from English To simplify discussion, we firs</context>
<context position="24553" citStr="Buchholz and Marsi, 2006" startWordPosition="4031" endWordPosition="4034"> the improvement comes from the projection stage. Note that the results in Table 1 indicate that parsers using predicted part-of-speech tags are only slightly worse than the parsers using gold tags (about 2-3% absolute), showing that these methods are robust to tagging errors. 4 Multi-Source Transfer The previous section focused on transferring an English parser to a new target language. However, there are over 20 treebanks available for a variety of language groups including Indo-European, Altaic (including Japanese), Semitic, and Sino-Tibetan. Many of these are even in standardized formats (Buchholz and Marsi, 2006; Nivre et al., 2007). Past studies have shown that for both part-of-speech tagging and grammar induction, learning with multiple comparable languages leads to improvements (Cohen and Smith, 2009; Snyder et al., 2009; BergKirkpatrick and Klein, 2010). In this section we exgold-POS DMV en-dir. en-proj. 33.4 45.9 48.2 18.0 47.2 50.9 39.9 63.9 66.8 28.5 53.3 55.8 43.1 57.7 60.8 38.5 60.8 67.8 20.1 69.2 71.3 44.0 58.3 61.3 33.2 57.0 60.4 pred-POS DMV en-dir. en-proj. 18.4 44.0 45.5 30.3 44.7 47.4 21.2 63.0 65.2 19.9 50.2 52.4 37.7 53.7 56.3 19.9 62.1 66.5 21.0 66.2 67.7 33.8 56.5 59.7 25.3 55.0 57</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Burkett</author>
<author>S Petrov</author>
<author>J Blitzer</author>
<author>D Klein</author>
</authors>
<title>Learning better monolingual models with unannotated bilingual text.</title>
<date>2010</date>
<booktitle>In Proc. of CoNLL.</booktitle>
<contexts>
<context position="16372" citStr="Burkett et al. (2010)" startWordPosition="2608" endWordPosition="2611"> vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in Figure 2. It starts by labeling a set of target language sentences with a parser, which in our case is the direct transfer parser from the previous section (line 1). Next, it uses these parsed target sentences to ‘seed’ a new parser by training a parameter vector using the predicted parses as a gold standard via standard perceptron updates for J rounds (lines 3-6). This generates a parser that emulates the direct transfer parser, but 5This requires a transition-based parser with a beam greater than 1 to allow for ambiguity to be resolved at later stages. 65 seed-sta</context>
</contexts>
<marker>Burkett, Petrov, Blitzer, Klein, 2010</marker>
<rawString>D. Burkett, S. Petrov, J. Blitzer, and D. Klein. 2010. Learning better monolingual models with unannotated bilingual text. In Proc. of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carroll</author>
<author>E Charniak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Proc. of the Working Notes of the Workshop Statistically-Based NLP Techniques.</booktitle>
<contexts>
<context position="2191" citStr="Carroll and Charniak, 1992" startWordPosition="329" endWordPosition="332">mproved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the c</context>
</contexts>
<marker>Carroll, Charniak, 1992</marker>
<rawString>G. Carroll and E. Charniak. 1992. Two experiments on learning probabilistic dependency grammars from corpora. In Proc. of the Working Notes of the Workshop Statistically-Based NLP Techniques.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semi-supervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="5152" citStr="Chang et al., 2007" startWordPosition="801" endWordPosition="804">cted from English. This emphasizes that even for languages with no syntactic resources – or possibly even parallel data – simple transfer methods can already be more powerful than grammar induction systems. Next, we use this delexicalized English parser to seed a perceptron learner for the target language. The model is trained to update towards parses that are in high agreement with a source side English parse based on constraints drawn from alignments in the parallel data. We use the augmented-loss learning procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induction, that shows that adding languages leads to improvements. We present a c</context>
<context position="16074" citStr="Chang et al., 2007" startWordPosition="2560" endWordPosition="2563">h does not rely on projecting syntax across aligned parallel corpora (modulo the fact that non-gold tags come from a system that uses parallel corpora). In this section we describe a simple mechanism for projecting from the direct transfer system using large amounts of parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in Figure 2. It starts by labeling a set of target language sentences with a parser, which in our case is the direct transfer parser from the previous section (line 1). Next, it uses these parsed target sentences to ‘seed’ a new parser by training a parameter vector using the </context>
<context position="21645" citStr="Chang et al. (2007)" startWordPosition="3552" endWordPosition="3555">ish sentence pair. Word alignments are shown as dashed lines, dependency arcs as solid lines. from→John. These add 3 to the score. There is one incorrectly aligned dependency: the preposition mistakenly modifies the noun on the Greek side. This subtracts 1. Finally, there are two dependencies that do not align: the subject on the English side and a determiner to a proper noun on the Greek side. These do not effect the result. The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al., 2011) which is closely related to the constraint driven learning algorithms of Chang et al. (2007). In that work, external constraints on output structures are used to help guide the learner to good parameter regions. In our model, we use constraints drawn from parallel data exactly in the same manner. Since posterior regularization is closely related to constraint driven learning, this makes our algorithm also similar to the parser projection approach of Ganchev et al. (2009). There are a couple of differences. First, we bias our model towards the direct transfer model, which is already quite powerful. Second, our alignment constraints are used to select parses from a k-best list, whereas</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M.W. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-supervision with constraint-driven learning. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>D Goldwasser</author>
<author>D Roth</author>
<author>V Srikumar</author>
</authors>
<title>Structured output learning with indirect supervision.</title>
<date>2010</date>
<booktitle>In Proc. of ICML.</booktitle>
<contexts>
<context position="5173" citStr="Chang et al., 2010" startWordPosition="805" endWordPosition="808">his emphasizes that even for languages with no syntactic resources – or possibly even parallel data – simple transfer methods can already be more powerful than grammar induction systems. Next, we use this delexicalized English parser to seed a perceptron learner for the target language. The model is trained to update towards parses that are in high agreement with a source side English parse based on constraints drawn from alignments in the parallel data. We use the augmented-loss learning procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induction, that shows that adding languages leads to improvements. We present a comprehensive set of e</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>M. Chang, D. Goldwasser, D. Roth, and V. Srikumar. 2010. Structured output learning with indirect supervision. In Proc. of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="1327" citStr="Charniak, 2000" startWordPosition="187" endWordPosition="188"> resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A maximum-entropy-inspired parser. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1477" citStr="Clark and Curran, 2004" startWordPosition="212" endWordPosition="215">ng parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. T</context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>S. Clark and J. R. Curran. 2004. Parsing the WSJ using CCG and log-linear models. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S B Cohen</author>
<author>N A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="2263" citStr="Cohen and Smith, 2009" startWordPosition="341" endWordPosition="344">English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis space. These assumptions help to give the mode</context>
<context position="5670" citStr="Cohen and Smith, 2009" startWordPosition="881" endWordPosition="884">procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induction, that shows that adding languages leads to improvements. We present a comprehensive set of experiments on eight Indo-European languages for which a significant amount of parallel data exists. We make no language specific enhancements in our experiments. We report results for sentences of all lengths, ROOT A hearing is scheduled on the issue today Figure 1: An example (unlabeled) dependency tree. as well as with gold and automatically induced part-of-speech tags. We also report results on sentences of length 10 or less with gold part-of-speech tags to compare with previous work. Our </context>
<context position="24748" citStr="Cohen and Smith, 2009" startWordPosition="4060" endWordPosition="4064">(about 2-3% absolute), showing that these methods are robust to tagging errors. 4 Multi-Source Transfer The previous section focused on transferring an English parser to a new target language. However, there are over 20 treebanks available for a variety of language groups including Indo-European, Altaic (including Japanese), Semitic, and Sino-Tibetan. Many of these are even in standardized formats (Buchholz and Marsi, 2006; Nivre et al., 2007). Past studies have shown that for both part-of-speech tagging and grammar induction, learning with multiple comparable languages leads to improvements (Cohen and Smith, 2009; Snyder et al., 2009; BergKirkpatrick and Klein, 2010). In this section we exgold-POS DMV en-dir. en-proj. 33.4 45.9 48.2 18.0 47.2 50.9 39.9 63.9 66.8 28.5 53.3 55.8 43.1 57.7 60.8 38.5 60.8 67.8 20.1 69.2 71.3 44.0 58.3 61.3 33.2 57.0 60.4 pred-POS DMV en-dir. en-proj. 18.4 44.0 45.5 30.3 44.7 47.4 21.2 63.0 65.2 19.9 50.2 52.4 37.7 53.7 56.3 19.9 62.1 66.5 21.0 66.2 67.7 33.8 56.5 59.7 25.3 55.0 57.6 da de el es it nl pt sv avg 67 da de el Source Training Language nl pt sv en es it da 79.2 45.2 44.0 45.9 45.0 48.6 46.1 48.1 47.8 de 34.3 83.9 53.2 47.2 45.8 53.4 55.8 55.5 46.2 el 33.3 52.5 </context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>S.B. Cohen and N.A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S B Cohen</author>
<author>D Das</author>
<author>N A Smith</author>
</authors>
<title>Unsupervised structure prediction with non-parallel multilingual guidance.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="30563" citStr="Cohen et al. (2011)" startWordPosition="5042" endWordPosition="5045">ti-source direct (multi-dir.) and projected (multi-proj.) transfer systems. best-source is the best source model from the languages in Table 2 (excluding the target language). avg-source is the mean UAS over the source models for the target (excluding target language). multi-source transfer already provides strong performance gains. We expect that more principled techniques will lead to further improvements. For example, recent work by Søgaard (2011) explores data set sub-sampling methods. Unlike our work, Søgaard found that simply concatenating all the data led to degradation in performance. Cohen et al. (2011) explores the idea learning language specific mixture coefficients for models trained independently on the target language treebanks. However, their results show that this method often did not significantly outperform uniform mixing. 5 Comparison Comparing unsupervised and parser projection systems is difficult as many publications use nonoverlapping sets of languages or different evaluation criteria. We compare to the following three systems that do not augment the treebanks and report results for some of the languages that we considered: • USR: The weakly supervised system of Naseem et al. (</context>
<context position="37928" citStr="Cohen et al. (2011)" startWordPosition="6245" endWordPosition="6248">ntage does not come simply from having more data. In fact, if we randomly sampled from the multi-source data until the training set size was equivalent to the size of the English data, then the results still hold (and in fact go up slightly for some languages). This suggests that even better transfer models can be produced by separately weighting each of the sources depending on the target language – either weighting by hand, if we know the language group of the target language, or auto70 matically, if we do not. As previously mentioned, the latter has been explored in both Søgaard (2011) and Cohen et al. (2011). 7 Conclusions We presented a simple, yet effective approach for projecting parsers from languages with labeled training data to languages without any labeled training data. Central to our approach is the idea of delexicalizing the models, which combined with a standardized part-of-speech tagset allows us to directly transfer models between languages. We then use a constraint driven learning algorithm to adapt the transferred parsers to the respective target language, obtaining an additional 16% error reduction on average in a multi-source setting. Our final parsers achieve state-of-the-art a</context>
</contexts>
<marker>Cohen, Das, Smith, 2011</marker>
<rawString>S.B. Cohen, D. Das, and N.A. Smith. 2011. Unsupervised structure prediction with non-parallel multilingual guidance. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>J Hajiˇc</author>
<author>L Ramshaw</author>
<author>C Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In Proc. of</booktitle>
<marker>Collins, Hajiˇc, Ramshaw, Tillmann, 1999</marker>
<rawString>M. Collins, J. Hajiˇc, L. Ramshaw, and C. Tillmann. 1999. A statistical parser for Czech. In Proc. of ACL. M. Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="23274" citStr="Collins, 2002" startWordPosition="3823" endWordPosition="3824">l experiments we train the seed-stage perceptron for 5 iterations (J = 5) and we use one hundred times as much parallel data as seed stage non-parallel data (m = 100n). The seed-stage nonparallel data is the training portion of each treebank, stripped of all dependency annotations. After training the projected parser we average the parameters Table 1: UAS for the unsupervised DMV model (DMV), a delexicalized English direct transfer parser (en-dir.) and a English projected parser (en-proj.). Measured on all sentence lengths for both gold and predicted part-ofspeech tags as input. of the model (Collins, 2002). The parsers evaluated using predicted part-of-speech tags use the predicted tags at both training and testing time and are thus free of any target language specific resources. When compared with the direct transfer model (en-dir. in Table 1), we can see that there is an improvement for every single language, reducing relative error by 8% on average (57.0% to 60.4%) and up to 18% for Dutch (60.8 to 67.8%). One could wonder whether the true power of the projection model comes from the re-lexicalization step – lines 3-6 of the algorithm. However, if just this step is run, then the average UAS o</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Das</author>
<author>S Petrov</author>
</authors>
<title>Unsupervised part-ofspeech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-HLT.</booktitle>
<contexts>
<context position="11280" citStr="Das and Petrov (2011)" startWordPosition="1776" endWordPosition="1779">r is extremely fast to train and run, making it easy to run a large number of experiments. Preliminary experiments using a different dependency parser – MSTParser (McDonald et al., 2005) – resulted in similar empirical observations. 2.3 Evaluation All systems are evaluated using unlabeled attachment score (UAS), which is the percentage of words (ignoring punctuation tokens) in a corpus that modify the correct head (Buchholz and Marsi, 2006). Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-ofspeech tags from the projected part-of-speech tagger of Das and Petrov (2011).2 This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider. We evaluate in the former setting to compare to previous studies that make this assumption. We evaluate in the latter setting to measure performance in a more realistic scenario – when no target language resources are available. 3 Transferring from English To simplify discussion, we first focus on the most common instantiation of parser transfer in the literature: transferring from English to other languages. In the next section we expand our system to allow fo</context>
<context position="13393" citStr="Das and Petrov (2011)" startWordPosition="2118" endWordPosition="2121">thout relying on parallel corpora. This idea has been previously explored by Zeman and Resnik (2008) and recently by Søgaard (2011). Because we use a mapping of the treebank specific part-of-speech tags to a common tagset, the performance of a such a system is easy to measure – simply parse the target language data set with a delexicalized parser trained on the source language data. We conducted two experiments. In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language. UAS for all sentence lengths without punctuation are given in Table 1. We report results for both the English direct transfer parser (en-dir.) as well as a baseline unsupervised grammar induction system – the dependency model with valence (DMV) of Klein and Manning (2004), as obtained by the implementation of Ganchev et al. (2010). We trained on sentences of length 10 or less and evaluated on all sentences from the test set.4 For DMV, we reversed the direction of all dependencies if this led to higher performance. From this table we can see tha</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>D. Das and S. Petrov. 2011. Unsupervised part-ofspeech tagging with bilingual graph-based projections. In Proc. of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-IJCNLP.</booktitle>
<contexts>
<context position="3785" citStr="Ganchev et al., 2009" startWordPosition="576" endWordPosition="579">are also a form of syntactic analysis, only shallower. Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. This point has been made by 1A notable exception is the work of Seginer (2007). 62 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009). Although again, most of these studies also assume the existence of POS tags. In this work we present a method for creating dependency parsers for languages for which no labeled training data is available. First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as Zeman and Resnik (2008). We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser) already outperforms s</context>
<context position="15800" citStr="Ganchev et al. (2009)" startWordPosition="2515" endWordPosition="2518">The English parser still predicts that the NOUN and PUNC modify the VERB and the ADJ and DET modify the NOUN, even though in the English data such noun phrases are unlikely.5 3.2 Projected Transfer Unlike most language transfer systems for parsers, the direct transfer approach does not rely on projecting syntax across aligned parallel corpora (modulo the fact that non-gold tags come from a system that uses parallel corpora). In this section we describe a simple mechanism for projecting from the direct transfer system using large amounts of parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in </context>
<context position="22028" citStr="Ganchev et al. (2009)" startWordPosition="3614" endWordPosition="3617"> the Greek side. These do not effect the result. The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al., 2011) which is closely related to the constraint driven learning algorithms of Chang et al. (2007). In that work, external constraints on output structures are used to help guide the learner to good parameter regions. In our model, we use constraints drawn from parallel data exactly in the same manner. Since posterior regularization is closely related to constraint driven learning, this makes our algorithm also similar to the parser projection approach of Ganchev et al. (2009). There are a couple of differences. First, we bias our model towards the direct transfer model, which is already quite powerful. Second, our alignment constraints are used to select parses from a k-best list, whereas in posterior regularization they are used as soft constraints on full model expectations during training. The latter is beneficial as the use of k-best lists does not limit the class of parsers to those whose parameters and search space decompose neatly with the DCA loss function. An empirical comparison to Ganchev et al. (2009) is given in Section 5. Results are given in Table 1</context>
<context position="31901" citStr="Ganchev et al. (2009)" startWordPosition="5250" endWordPosition="5253">. In addition to their original results, we also report results using the same part-of-speech tagset as the systems described in this paper (USR†). This is useful for two reasons. First, it makes the comparison more direct. Second, we can generate USR results for all eight languages and not just for the languages that they report. • PGI: The phylogenetic grammar induction (PGI) model of Berg-Kirkpatrick and Klein (2010), in which the parameters of completely unsupervised DMV models for multiple languages are coupled via a phylogenetic prior. • PR: The posterior regularization (PR) approach of Ganchev et al. (2009), in which a supervised English parser is used to generate constraints that are projected using a parallel corpus and used to regularize a target language parser. We report results without treebank specific rules. Table 4 gives results comparing the models presented in this work to those three systems. For this comparison we use sentences of length 10 or less after punctuation has been removed in order to be consistent with reported results. The overall trends carry over from the full treebank setting to this reduced sentence length setup: the projected models outperform the direct transfer mo</context>
<context position="33178" citStr="Ganchev et al. (2009)" startWordPosition="5462" endWordPosition="5465"> transferring only from English. Most previous work has assumed gold part-of-speech tags, but as the code for USR is publicly available we were able to train it using the same projected part-of-speech tags used in our models. These results are also given in Table 4 under USR†. Again, we can see that the multisource systems (both direct and projected) significantly outperform the unsupervised models. It is not surprising that a parser transferred from annotated resources does significantly better than unsupervised systems since it has much more information from which to learn. The PR system of Ganchev et al. (2009) is similar to ours as it also projects syntax across parallel corpora. For Spanish we can see that the multi-source direct transfer parser is better (75.1% versus 70.6%), and this is also true for the multi-source projected parser 69 ←− gold-POS −→ en-dir. en-proj. multi-dir. multi-proj. USR† USR PGI PR 53.2 57.4 58.4 58.8 55.1 51.9 41.6 65.9 67.0 74.9 72.0 60.0 73.9 73.9 73.5 78.7 60.3 58.0 62.3 75.1 73.2 68.3 67.2 58.4 70.6 65.5 69.9 75.5 75.5 47.9 67.6 72.2 58.8 70.7 44.0 45.1 77.9 80.6 81.1 86.2 70.9 71.5 63.0 70.4 71.3 76.0 77.6 52.6 58.3 66.6 69.4 71.7 74.1 57.4 ← pred-POS → multi-dir. </context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>K. Ganchev, J. Gillenwater, and B. Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proc. of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Grac¸a</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research.</journal>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
</authors>
<title>Corpus variation and parser performance.</title>
<date>2001</date>
<booktitle>In Proc of EMNLP.</booktitle>
<contexts>
<context position="1768" citStr="Gildea, 2001" startWordPosition="262" endWordPosition="263">ional linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010).</context>
</contexts>
<marker>Gildea, 2001</marker>
<rawString>D. Gildea. 2001. Corpus variation and parser performance. In Proc of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hall</author>
<author>R McDonald</author>
<author>J Katz-Brown</author>
<author>M Ringgaard</author>
</authors>
<title>Training dependency parsers by jointly optimizing multiple objectives.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="5077" citStr="Hall et al., 2011" startWordPosition="789" endWordPosition="792">holds in the presence of both gold POS tags as well as automatic tags projected from English. This emphasizes that even for languages with no syntactic resources – or possibly even parallel data – simple transfer methods can already be more powerful than grammar induction systems. Next, we use this delexicalized English parser to seed a perceptron learner for the target language. The model is trained to update towards parses that are in high agreement with a source side English parse based on constraints drawn from alignments in the parallel data. We use the augmented-loss learning procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induct</context>
<context position="15894" citStr="Hall et al. (2011)" startWordPosition="2533" endWordPosition="2536">fy the NOUN, even though in the English data such noun phrases are unlikely.5 3.2 Projected Transfer Unlike most language transfer systems for parsers, the direct transfer approach does not rely on projecting syntax across aligned parallel corpora (modulo the fact that non-gold tags come from a system that uses parallel corpora). In this section we describe a simple mechanism for projecting from the direct transfer system using large amounts of parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in Figure 2. It starts by labeling a set of target language sentences with a parser, which in our</context>
<context position="21552" citStr="Hall et al., 2011" startWordPosition="3536" endWordPosition="3539">= I 66 flrjpg To RiRAio aTr6 Tov T(ov She took the book from John Figure 3: A Greek and English sentence pair. Word alignments are shown as dashed lines, dependency arcs as solid lines. from→John. These add 3 to the score. There is one incorrectly aligned dependency: the preposition mistakenly modifies the noun on the Greek side. This subtracts 1. Finally, there are two dependencies that do not align: the subject on the English side and a determiner to a proper noun on the Greek side. These do not effect the result. The learning algorithm in Figure 2 is an instance of augmented-loss training (Hall et al., 2011) which is closely related to the constraint driven learning algorithms of Chang et al. (2007). In that work, external constraints on output structures are used to help guide the learner to good parameter regions. In our model, we use constraints drawn from parallel data exactly in the same manner. Since posterior regularization is closely related to constraint driven learning, this makes our algorithm also similar to the parser projection approach of Ganchev et al. (2009). There are a couple of differences. First, we bias our model towards the direct transfer model, which is already quite powe</context>
</contexts>
<marker>Hall, McDonald, Katz-Brown, Ringgaard, 2011</marker>
<rawString>K. Hall, R. McDonald, J. Katz-Brown, and M. Ringgaard. 2011. Training dependency parsers by jointly optimizing multiple objectives. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>03</issue>
<contexts>
<context position="3763" citStr="Hwa et al., 2005" startWordPosition="572" endWordPosition="575">as part-of-speech are also a form of syntactic analysis, only shallower. Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. This point has been made by 1A notable exception is the work of Seginer (2007). 62 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009). Although again, most of these studies also assume the existence of POS tags. In this work we present a method for creating dependency parsers for languages for which no labeled training data is available. First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as Zeman and Resnik (2008). We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser)</context>
<context position="15777" citStr="Hwa et al. (2005)" startWordPosition="2511" endWordPosition="2514">OUN ADJ DET PUNC’. The English parser still predicts that the NOUN and PUNC modify the VERB and the ADJ and DET modify the NOUN, even though in the English data such noun phrases are unlikely.5 3.2 Projected Transfer Unlike most language transfer systems for parsers, the direct transfer approach does not rely on projecting syntax across aligned parallel corpora (modulo the fact that non-gold tags come from a system that uses parallel corpora). In this section we describe a simple mechanism for projecting from the direct transfer system using large amounts of parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The</context>
<context position="19055" citStr="Hwa et al. (2005)" startWordPosition="3105" endWordPosition="3108">ce at the start of learning, but also helps to bias dependencies between words that are not part of the alignment. So far we have not defined the ALIGN function that is used to score potential parses. Let a = {(s(1), t(1)), ... , (s(n), t(n))} be an alignment where s(i) is a word in the source sentence xs (not necessarily the ith word) and t(i) is similarly a word in the target sentence xt (again, not necessarily the ith word). The notation (s(i), t(i)) E a indicates two words are the ith aligned pair in a. We define the ALIGN function to encode the Direct Correspondence Assumption (DCA) from Hwa et al. (2005): Figure 2: Perceptron-based learning algorithm for train- ALIGN(ys, yt, a) SCORE(ys, yt, (s(i), s(j)), (t(i), t(j))) ing a parser by seeding the model with a direct transfer E= parser and projecting constraints across parallel corpora. (s(i),t(i))Ea (s(j),t(j))Ea has now been lexicalized and is working in the space of target language sentences. Next, the algorithm iterates over the sentences in the parallel corpus. It parses the English sentence with an English parser (line 8, again a lexicalized parser). It then uses the current target language parameter vector to create a k-best parse list </context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11(03):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="2216" citStr="Klein and Manning, 2004" startWordPosition="333" endWordPosition="336">begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis</context>
<context position="13715" citStr="Klein and Manning (2004)" startWordPosition="2170" endWordPosition="2173">t with a delexicalized parser trained on the source language data. We conducted two experiments. In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language. UAS for all sentence lengths without punctuation are given in Table 1. We report results for both the English direct transfer parser (en-dir.) as well as a baseline unsupervised grammar induction system – the dependency model with valence (DMV) of Klein and Manning (2004), as obtained by the implementation of Ganchev et al. (2010). We trained on sentences of length 10 or less and evaluated on all sentences from the test set.4 For DMV, we reversed the direction of all dependencies if this led to higher performance. From this table we can see that direct transfer is a very strong baseline and is over 20% absolute better than the DMV model for both gold and predicted POS tags. Table 4, which we will discuss in more detail later, further shows that the direct transfer parser also significantly outperforms stateof-the-art unsupervised grammar induction models, but </context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>D. Klein and C. D. Manning. 2004. Corpus-based induction of syntactic structure: models of dependency and constituency. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="9396" citStr="Koehn, 2005" startWordPosition="1472" endWordPosition="1473">), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions orpostpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of our parsing models are based on the transition-based dependency parsing paradigm (Nivre, 2008). Specifically, all models use an arc-eager transition strategy and are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all mod</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="1249" citStr="Marcus et al., 1993" startWordPosition="174" endWordPosition="177">el corpora to project the final parser. Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new la</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>M. P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the Penn treebank. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McClosky</author>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Reranking and self-training for parser adaptation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1791" citStr="McClosky et al., 2006" startWordPosition="264" endWordPosition="268">ics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction syst</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>D. McClosky, E. Charniak, and M. Johnson. 2006. Reranking and self-training for parser adaptation. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1392" citStr="McDonald et al., 2005" startWordPosition="195" endWordPosition="198">ltiple source languages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new langua</context>
<context position="10845" citStr="McDonald et al., 2005" startWordPosition="1711" endWordPosition="1714">yntactic head of the top word on the stack (if available). All feature conjunctions are included. For treebanks with non-projective trees we use the pseudo-projective parsing technique to transform the treebank into projective structures (Nivre and Nilsson, 2005). We focus on using this parsing system for two reasons. First, the parser is near state-of-the-art on English parsing benchmarks and second, and more importantly, the parser is extremely fast to train and run, making it easy to run a large number of experiments. Preliminary experiments using a different dependency parser – MSTParser (McDonald et al., 2005) – resulted in similar empirical observations. 2.3 Evaluation All systems are evaluated using unlabeled attachment score (UAS), which is the percentage of words (ignoring punctuation tokens) in a corpus that modify the correct head (Buchholz and Marsi, 2006). Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-ofspeech tags from the projected part-of-speech tagger of Das and Petrov (2011).2 This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider. We evaluate in the former sett</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Naseem</author>
<author>H Chen</author>
<author>R Barzilay</author>
<author>M Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="2317" citStr="Naseem et al., 2010" startWordPosition="350" endWordPosition="353">gun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis space. These assumptions help to give the model traction. The study of unsupervised grammar inductio</context>
<context position="9076" citStr="Naseem et al., 2010" startWordPosition="1417" endWordPosition="1420">ussion for non-IndoEuropean languages. For all data sets we used the predefined training and testing splits. Our approach relies on a consistent set of partof-speech tags across languages and treebanks. For this we used the universal tagset from Petrov et al. (2011), which includes: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions orpostpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments.</context>
<context position="31168" citStr="Naseem et al. (2010)" startWordPosition="5134" endWordPosition="5137">n et al. (2011) explores the idea learning language specific mixture coefficients for models trained independently on the target language treebanks. However, their results show that this method often did not significantly outperform uniform mixing. 5 Comparison Comparing unsupervised and parser projection systems is difficult as many publications use nonoverlapping sets of languages or different evaluation criteria. We compare to the following three systems that do not augment the treebanks and report results for some of the languages that we considered: • USR: The weakly supervised system of Naseem et al. (2010), in which manually defined universal syntactic rules (USR) are used to constrain a probabilistic Bayesian model. In addition to their original results, we also report results using the same part-of-speech tagset as the systems described in this paper (USR†). This is useful for two reasons. First, it makes the comparison more direct. Second, we can generate USR results for all eight languages and not just for the languages that they report. • PGI: The phylogenetic grammar induction (PGI) model of Berg-Kirkpatrick and Klein (2010), in which the parameters of completely unsupervised DMV models f</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>T. Naseem, H. Chen, R. Barzilay, and M. Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="10486" citStr="Nivre and Nilsson, 2005" startWordPosition="1653" endWordPosition="1656">d are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all models are: the part-of-speech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available). All feature conjunctions are included. For treebanks with non-projective trees we use the pseudo-projective parsing technique to transform the treebank into projective structures (Nivre and Nilsson, 2005). We focus on using this parsing system for two reasons. First, the parser is near state-of-the-art on English parsing benchmarks and second, and more importantly, the parser is extremely fast to train and run, making it easy to run a large number of experiments. Preliminary experiments using a different dependency parser – MSTParser (McDonald et al., 2005) – resulted in similar empirical observations. 2.3 Evaluation All systems are evaluated using unlabeled attachment score (UAS), which is the percentage of words (ignoring punctuation tokens) in a corpus that modify the correct head (Buchholz</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>J. Nivre and J. Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="1413" citStr="Nivre et al., 2006" startWordPosition="199" endWordPosition="202"> can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they ofte</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>J. Nivre, J. Hall, and J. Nilsson. 2006. Maltparser: A data-driven parser-generator for dependency parsing. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="9796" citStr="Nivre, 2008" startWordPosition="1538" endWordPosition="1539">the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of our parsing models are based on the transition-based dependency parsing paradigm (Nivre, 2008). Specifically, all models use an arc-eager transition strategy and are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all models are: the part-of-speech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available). All feature conjunctions are included. For treebanks with non-projective trees we use the pseudo-projective parsin</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>J. Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>L Barrett</author>
<author>R Thibaux</author>
<author>D Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1349" citStr="Petrov et al., 2006" startWordPosition="189" endWordPosition="192">how that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers. The projected parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in </context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>P Chang</author>
<author>M Ringgaard</author>
<author>H Alshawi</author>
</authors>
<title>Uptraining for accurate deterministic question parsing.</title>
<date>2010</date>
<booktitle>In EMNLP ’10.</booktitle>
<contexts>
<context position="1813" citStr="Petrov et al., 2010" startWordPosition="269" endWordPosition="272"> construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large ad</context>
</contexts>
<marker>Petrov, Chang, Ringgaard, Alshawi, 2010</marker>
<rawString>S. Petrov, P. Chang, M. Ringgaard, and H. Alshawi. 2010. Uptraining for accurate deterministic question parsing. In EMNLP ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<booktitle>In ArXiv:1104.2086.</booktitle>
<contexts>
<context position="8723" citStr="Petrov et al. (2011)" startWordPosition="1369" endWordPosition="1372">anguage. By presenting results on eight languages our study is already more comprehensive than most previous work in this area. However, the restriction to Indo-European languages does make the results less conclusive when one wishes to transfer a parser from English to Chinese, for example. To account for this, we report additional results in the discussion for non-IndoEuropean languages. For all data sets we used the predefined training and testing splits. Our approach relies on a consistent set of partof-speech tags across languages and treebanks. For this we used the universal tagset from Petrov et al. (2011), which includes: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions orpostpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languag</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2011. A universal part-of-speech tagset. In ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Seginer</author>
</authors>
<title>Fast unsupervised incremental parsing.</title>
<date>2007</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="3425" citStr="Seginer (2007)" startWordPosition="527" endWordPosition="528">lysis space. These assumptions help to give the model traction. The study of unsupervised grammar induction has many merits. Most notably, it increases our understanding of how computers (and possibly humans) learn in the absence of any explicit feedback. However, the gold POS tag assumption weakens any conclusions that can be drawn, as part-of-speech are also a form of syntactic analysis, only shallower. Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. This point has been made by 1A notable exception is the work of Seginer (2007). 62 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009). Although again, most of these studies also assume the existence of POS tags. In this work we present a method for creating dependency parsers for languages for which no labeled training data is available. First, w</context>
</contexts>
<marker>Seginer, 2007</marker>
<rawString>Y. Seginer. 2007. Fast unsupervised incremental parsing. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>A K Joshi</author>
</authors>
<title>Ltag dependency parsing with bidirectional incremental construction.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1523" citStr="Shen and Joshi, 2008" startWordPosition="220" endWordPosition="223">em result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of re</context>
</contexts>
<marker>Shen, Joshi, 2008</marker>
<rawString>L. Shen and A.K. Joshi. 2008. Ltag dependency parsing with bidirectional incremental construction. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="2240" citStr="Smith and Eisner, 2005" startWordPosition="337" endWordPosition="340"> levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis space. These assumption</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N.A. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Smith</author>
<author>J Eisner</author>
</authors>
<title>Parser adaptation and projection with quasi-synchronous grammar features.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="3810" citStr="Smith and Eisner, 2009" startWordPosition="580" endWordPosition="583">tactic analysis, only shallower. Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. This point has been made by 1A notable exception is the work of Seginer (2007). 62 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009). Although again, most of these studies also assume the existence of POS tags. In this work we present a method for creating dependency parsers for languages for which no labeled training data is available. First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as Zeman and Resnik (2008). We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser) already outperforms state-of-the-art unsupervi</context>
<context position="7301" citStr="Smith and Eisner, 2009" startWordPosition="1135" endWordPosition="1138">ch a tree is given in Figure 1. Dependency tree arcs are often labeled with the role of the syntactic relationship, e.g., is to hearing might be labeled as SUBJECT. However, we focus on unlabeled parsing in order to reduce problems that arise due to different treebank annotation schemes. Of course, even for unlabeled dependencies, significant variations in the annotation schemes remain. For example, in the Danish treebank determiners govern adjectives and nouns in noun phrases, while in most other treebanks the noun is the head of the noun phrase. Unlike previous work (Zeman and Resnik, 2008; Smith and Eisner, 2009), we do not apply any transformations to the treebanks, which makes our results easier to reproduce, but systematically underestimates accuracy. 2.1 Data Sets The treebank data in our experiments are from the CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). We use English (en) only as a source language throughout the paper. Additionally, we use the following eight languages as both source and target languages: Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) and Swedish (sv). For languages that were included i</context>
<context position="15825" citStr="Smith and Eisner (2009)" startWordPosition="2519" endWordPosition="2522">l predicts that the NOUN and PUNC modify the VERB and the ADJ and DET modify the NOUN, even though in the English data such noun phrases are unlikely.5 3.2 Projected Transfer Unlike most language transfer systems for parsers, the direct transfer approach does not rely on projecting syntax across aligned parallel corpora (modulo the fact that non-gold tags come from a system that uses parallel corpora). In this section we describe a simple mechanism for projecting from the direct transfer system using large amounts of parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in Figure 2. It starts by la</context>
<context position="34908" citStr="Smith and Eisner (2009)" startWordPosition="5759" endWordPosition="5762"> of the baseline systems. (73.2%). Ganchev et al. also report results for Bulgarian. We trained a multi-source direct transfer parser for Bulgarian which obtained a score of 72.8% versus 67.8% for the PR system. If we only use English as a source language, as in Ganchev et al., the English direct transfer model achieves 66.1% on Bulgarian and 69.3% on Spanish versus 67.8% and 70.6% for PR. In this setting the English projected model gets 72.0% on Spanish. Thus, under identical conditions the direct transfer model obtains accuracies comparable to PR.6 Another projection based system is that of Smith and Eisner (2009), who report results for German (68.5%) and Spanish (64.8%) on sentences of length 15 and less inclusive of punctuation. Smith and Eisner use custom splits of the data and modify a subset of the dependencies. The multi-source projected parser obtains 71.9% for German and 67.8% for Spanish on this setup.7 If we cherry-pick the source language the results can improve, e.g., for Spanish we can obtain 71.7% and 70.8% by directly transferring parsers form Italian or Portuguese respectively. 6 Discussion One fundamental point the above experiments illustrate is that even for languages for which no r</context>
</contexts>
<marker>Smith, Eisner, 2009</marker>
<rawString>D.A. Smith and J. Eisner. 2009. Parser adaptation and projection with quasi-synchronous grammar features. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Smith</author>
<author>N A Smith</author>
</authors>
<title>Bilingual parsing with factored estimation: Using english to parse korean.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="16346" citStr="Smith and Smith (2004)" startWordPosition="2603" endWordPosition="2606"> parallel data in a similar vein to Hwa et al. (2005), Ganchev et al. (2009), Smith and Eisner (2009) inter alia. The algorithm is based on the work of Hall et al. (2011) for training extrinsic parser objective functions and borrows heavily from ideas in learning with weak supervision including work on learning with constraints (Chang et al., 2007) and posterior regularization (Ganchev et al., 2010). In our case, the weak signals come from aligned source and target sentences, and the agreement in their corresponding parses, which is similar to posterior regularization or the bilingual view of Smith and Smith (2004) and Burkett et al. (2010). The algorithm is given in Figure 2. It starts by labeling a set of target language sentences with a parser, which in our case is the direct transfer parser from the previous section (line 1). Next, it uses these parsed target sentences to ‘seed’ a new parser by training a parameter vector using the predicted parses as a gold standard via standard perceptron updates for J rounds (lines 3-6). This generates a parser that emulates the direct transfer parser, but 5This requires a transition-based parser with a beam greater than 1 to allow for ambiguity to be resolved at</context>
</contexts>
<marker>Smith, Smith, 2004</marker>
<rawString>D.A. Smith and N.A. Smith. 2004. Bilingual parsing with factored estimation: Using english to parse korean. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>T Naseem</author>
<author>J Eisenstein</author>
<author>R Barzilay</author>
</authors>
<title>Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian nonparametric approach.</title>
<date>2009</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="5600" citStr="Snyder et al., 2009" startWordPosition="871" endWordPosition="874">alignments in the parallel data. We use the augmented-loss learning procedure (Hall et al., 2011) which is closely related to constraint driven learning (Chang et al., 2007; Chang et al., 2010). The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages. Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline. This is consistent with previous work on multilingual part-of-speech (Snyder et al., 2009) and grammar (Berg-Kirkpatrick and Klein, 2010; Cohen and Smith, 2009) induction, that shows that adding languages leads to improvements. We present a comprehensive set of experiments on eight Indo-European languages for which a significant amount of parallel data exists. We make no language specific enhancements in our experiments. We report results for sentences of all lengths, ROOT A hearing is scheduled on the issue today Figure 1: An example (unlabeled) dependency tree. as well as with gold and automatically induced part-of-speech tags. We also report results on sentences of length 10 or </context>
<context position="24769" citStr="Snyder et al., 2009" startWordPosition="4065" endWordPosition="4068">showing that these methods are robust to tagging errors. 4 Multi-Source Transfer The previous section focused on transferring an English parser to a new target language. However, there are over 20 treebanks available for a variety of language groups including Indo-European, Altaic (including Japanese), Semitic, and Sino-Tibetan. Many of these are even in standardized formats (Buchholz and Marsi, 2006; Nivre et al., 2007). Past studies have shown that for both part-of-speech tagging and grammar induction, learning with multiple comparable languages leads to improvements (Cohen and Smith, 2009; Snyder et al., 2009; BergKirkpatrick and Klein, 2010). In this section we exgold-POS DMV en-dir. en-proj. 33.4 45.9 48.2 18.0 47.2 50.9 39.9 63.9 66.8 28.5 53.3 55.8 43.1 57.7 60.8 38.5 60.8 67.8 20.1 69.2 71.3 44.0 58.3 61.3 33.2 57.0 60.4 pred-POS DMV en-dir. en-proj. 18.4 44.0 45.5 30.3 44.7 47.4 21.2 63.0 65.2 19.9 50.2 52.4 37.7 53.7 56.3 19.9 62.1 66.5 21.0 66.2 67.7 33.8 56.5 59.7 25.3 55.0 57.6 da de el es it nl pt sv avg 67 da de el Source Training Language nl pt sv en es it da 79.2 45.2 44.0 45.9 45.0 48.6 46.1 48.1 47.8 de 34.3 83.9 53.2 47.2 45.8 53.4 55.8 55.5 46.2 el 33.3 52.5 77.5 63.9 41.6 59.3 5</context>
</contexts>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2009</marker>
<rawString>B. Snyder, T. Naseem, J. Eisenstein, and R. Barzilay. 2009. Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian nonparametric approach. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Søgaard</author>
</authors>
<title>Data point selection for crosslanguage adaptation of dependency parsers.</title>
<date>2011</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="12903" citStr="Søgaard (2011)" startWordPosition="2034" endWordPosition="2035">chieved 90.1% and used a richer part-of-speech tagset (Nivre et al., 2007). 64 a delexicalized parser – a parser that only has nonlexical features – obtains an UAS of 82.5%. The key observation is that part-of-speech tags contain a significant amount of information for unlabeled dependency parsing. This observation combined with our universal part-of-speech tagset, leads to the idea of direct transfer, i.e., directly parsing the target language with the source language parser without relying on parallel corpora. This idea has been previously explored by Zeman and Resnik (2008) and recently by Søgaard (2011). Because we use a mapping of the treebank specific part-of-speech tags to a common tagset, the performance of a such a system is easy to measure – simply parse the target language data set with a delexicalized parser trained on the source language data. We conducted two experiments. In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language. UAS for all sentence lengths without punctuation are given i</context>
<context position="30398" citStr="Søgaard (2011)" startWordPosition="5019" endWordPosition="5020">ulti-dir. multi-proj. 46.2 47.5 51.7 52.0 58.5 63.0 55.6 56.5 56.8 58.9 54.3 64.4 67.7 70.3 58.3 62.1 56.1 59.3 da de el es it nl pt sv avg Table 3: UAS for multi-source direct (multi-dir.) and projected (multi-proj.) transfer systems. best-source is the best source model from the languages in Table 2 (excluding the target language). avg-source is the mean UAS over the source models for the target (excluding target language). multi-source transfer already provides strong performance gains. We expect that more principled techniques will lead to further improvements. For example, recent work by Søgaard (2011) explores data set sub-sampling methods. Unlike our work, Søgaard found that simply concatenating all the data led to degradation in performance. Cohen et al. (2011) explores the idea learning language specific mixture coefficients for models trained independently on the target language treebanks. However, their results show that this method often did not significantly outperform uniform mixing. 5 Comparison Comparing unsupervised and parser projection systems is difficult as many publications use nonoverlapping sets of languages or different evaluation criteria. We compare to the following th</context>
<context position="37904" citStr="Søgaard (2011)" startWordPosition="6242" endWordPosition="6243">anguages. This advantage does not come simply from having more data. In fact, if we randomly sampled from the multi-source data until the training set size was equivalent to the size of the English data, then the results still hold (and in fact go up slightly for some languages). This suggests that even better transfer models can be produced by separately weighting each of the sources depending on the target language – either weighting by hand, if we know the language group of the target language, or auto70 matically, if we do not. As previously mentioned, the latter has been explored in both Søgaard (2011) and Cohen et al. (2011). 7 Conclusions We presented a simple, yet effective approach for projecting parsers from languages with labeled training data to languages without any labeled training data. Central to our approach is the idea of delexicalizing the models, which combined with a standardized part-of-speech tagset allows us to directly transfer models between languages. We then use a constraint driven learning algorithm to adapt the transferred parsers to the respective target language, obtaining an additional 16% error reduction on average in a multi-source setting. Our final parsers ac</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>A. Søgaard. 2011. Data point selection for crosslanguage adaptation of dependency parsers. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Spitkovsky</author>
<author>H Alshawi</author>
<author>D Jurafsky</author>
</authors>
<title>From baby steps to leapfrog: How “less is more” in unsupervised dependency parsing.</title>
<date>2010</date>
<booktitle>In Proc. of NAACLHLT.</booktitle>
<contexts>
<context position="2342" citStr="Spitkovsky et al., 2010" startWordPosition="354" endWordPosition="357">orting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; BergKirkpatrick and Klein, 2010; Naseem et al., 2010; Spitkovsky et al., 2010; Blunsom and Cohn, 2010). Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems. Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.1 The reason for these assumptions is clear. Unsupervised grammar induction is difficult given the complexity of the analysis space. These assumptions help to give the model traction. The study of unsupervised grammar induction has many merits. Most n</context>
</contexts>
<marker>Spitkovsky, Alshawi, Jurafsky, 2010</marker>
<rawString>V.I. Spitkovsky, H. Alshawi, and D. Jurafsky. 2010. From baby steps to leapfrog: How “less is more” in unsupervised dependency parsing. In Proc. of NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="9587" citStr="Vogel et al., 1996" startWordPosition="1506" endWordPosition="1509">all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of our parsing models are based on the transition-based dependency parsing paradigm (Nivre, 2008). Specifically, all models use an arc-eager transition strategy and are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all models are: the part-of-speech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on t</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based word alignment in statistical translation. In Proc. of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
</authors>
<title>A statistical constraint dependency grammar (CDG) parser.</title>
<date>2004</date>
<booktitle>In Proc. of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together.</booktitle>
<contexts>
<context position="1500" citStr="Wang and Harper, 2004" startWordPosition="216" endWordPosition="219">d parsers from our system result in state-of-theart performance when compared to previously studied unsupervised and projected parsing systems across eight different languages. 1 Introduction Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (Marcus et al., 1993). This includes work on phrasestructure parsing (Collins, 1997; Charniak, 2000; Petrov et al., 2006), dependency parsing (McDonald et al., 2005; Nivre et al., 2006) as well as a number of other formalisms (Clark and Curran, 2004; Wang and Harper, 2004; Shen and Joshi, 2008). As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text. Subsequently, researchers have begun to look at both porting these parsers to new domains (Gildea, 2001; McClosky et al., 2006; Petrov et al., 2010) and constructing parsers for new languages (Collins et al., 1999; Buchholz and Marsi, 2006; Nivre et al., 2007). One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English. This observation has led</context>
</contexts>
<marker>Wang, Harper, 2004</marker>
<rawString>W. Wang and M. P. Harper. 2004. A statistical constraint dependency grammar (CDG) parser. In Proc. of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zeman</author>
<author>P Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In NLP for Less Privileged Languages.</booktitle>
<contexts>
<context position="4224" citStr="Zeman and Resnik (2008)" startWordPosition="650" endWordPosition="654">utational Linguistics studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (Hwa et al., 2005; Ganchev et al., 2009; Smith and Eisner, 2009). Although again, most of these studies also assume the existence of POS tags. In this work we present a method for creating dependency parsers for languages for which no labeled training data is available. First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as Zeman and Resnik (2008). We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser) already outperforms state-of-the-art unsupervised parsers by a significant margin. This result holds in the presence of both gold POS tags as well as automatic tags projected from English. This emphasizes that even for languages with no syntactic resources – or possibly even parallel data – simple transfer methods can already be more powerful than grammar induction systems. Next, we use this delexicalized English parser to seed a perceptron learner for the</context>
<context position="7276" citStr="Zeman and Resnik, 2008" startWordPosition="1131" endWordPosition="1134">onship. An example of such a tree is given in Figure 1. Dependency tree arcs are often labeled with the role of the syntactic relationship, e.g., is to hearing might be labeled as SUBJECT. However, we focus on unlabeled parsing in order to reduce problems that arise due to different treebank annotation schemes. Of course, even for unlabeled dependencies, significant variations in the annotation schemes remain. For example, in the Danish treebank determiners govern adjectives and nouns in noun phrases, while in most other treebanks the noun is the head of the noun phrase. Unlike previous work (Zeman and Resnik, 2008; Smith and Eisner, 2009), we do not apply any transformations to the treebanks, which makes our results easier to reproduce, but systematically underestimates accuracy. 2.1 Data Sets The treebank data in our experiments are from the CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). We use English (en) only as a source language throughout the paper. Additionally, we use the following eight languages as both source and target languages: Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) and Swedish (sv). For langu</context>
<context position="9101" citStr="Zeman and Resnik, 2008" startWordPosition="1421" endWordPosition="1424">ropean languages. For all data sets we used the predefined training and testing splits. Our approach relies on a consistent set of partof-speech tags across languages and treebanks. For this we used the universal tagset from Petrov et al. (2011), which includes: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions orpostpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all tag). Similar tagsets are used by other studies on grammar induction and projection (Naseem et al., 2010; Zeman and Resnik, 2008). For all our experiments we replaced the language specific part-of-speech tags in the treebanks with these universal tags. Like all treebank projection studies we require a corpus of parallel text for each pair of languages we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of</context>
<context position="12872" citStr="Zeman and Resnik (2008)" startWordPosition="2027" endWordPosition="2030">ection/ 3The best system at CoNLL 2007 achieved 90.1% and used a richer part-of-speech tagset (Nivre et al., 2007). 64 a delexicalized parser – a parser that only has nonlexical features – obtains an UAS of 82.5%. The key observation is that part-of-speech tags contain a significant amount of information for unlabeled dependency parsing. This observation combined with our universal part-of-speech tagset, leads to the idea of direct transfer, i.e., directly parsing the target language with the source language parser without relying on parallel corpora. This idea has been previously explored by Zeman and Resnik (2008) and recently by Søgaard (2011). Because we use a mapping of the treebank specific part-of-speech tags to a common tagset, the performance of a such a system is easy to measure – simply parse the target language data set with a delexicalized parser trained on the source language data. We conducted two experiments. In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language. UAS for all sentence lengths </context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>D. Zeman and P. Resnik. 2008. Cross-language parser adaptation between related languages. In NLP for Less Privileged Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="9944" citStr="Zhang and Clark (2008)" startWordPosition="1558" endWordPosition="1561">ges we study. For this we used the Europarl corpus version 5 (Koehn, 2005). The corpus was preprocessed in standard ways and word aligned by running six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. We then intersect word alignments to generate one-to-one alignments. 2.2 Parsing Model All of our parsing models are based on the transition-based dependency parsing paradigm (Nivre, 2008). Specifically, all models use an arc-eager transition strategy and are trained using the averaged perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. The features used by all models are: the part-of-speech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available). All feature conjunctions are included. For treebanks with non-projective trees we use the pseudo-projective parsing technique to transform the treebank into projective structures (Nivre and Nilsson, 2005). We focus on using this parsing system for two reasons. F</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. 2008. A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing. In Proc. of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>