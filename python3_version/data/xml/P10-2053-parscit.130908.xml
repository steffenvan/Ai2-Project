<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.975168">
Extracting Sequences from the Web
</title>
<author confidence="0.999245">
Anthony Fader, Stephen Soderland, and Oren Etzioni
</author>
<affiliation confidence="0.99976">
University of Washington, Seattle
</affiliation>
<email confidence="0.993294">
lafader,soderlan,etzionif@cs.washington.edu
</email>
<sectionHeader confidence="0.997317" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998473615384615">
Classical Information Extraction (IE) sys-
tems fill slots in domain-specific frames.
This paper reports on SEQ, a novel
open IE system that leverages a domain-
independent frame to extract ordered se-
quences such as presidents of the United
States or the most common causes of death
in the U.S. SEQ leverages regularities
about sequences to extract a coherent set
of sequences from Web text. SEQ nearly
doubles the area under the precision-recall
curve compared to an extractor that does
not exploit these regularities.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.8967505">
Classical IE systems fill slots in domain-specific
frames such as the time and location slots in sem-
inar announcements (Freitag, 2000) or the terror-
ist organization slot in news stories (Chieu et al.,
2003). In contrast, open IE systems are domain-
independent, but extract “flat” sets of assertions
that are not organized into frames and slots
(Sekine, 2006; Banko et al., 2007). This paper
reports on SEQ—an open IE system that leverages
a domain-independent frame to extract ordered se-
quences of objects from Web text. We show that
the novel, domain-independent sequence frame in
SEQ substantially boosts the precision and recall
of the system and yields coherent sequences fil-
tered from low-precision extractions (Table 1).
Sequence extraction is distinct from set expan-
sion (Etzioni et al., 2004; Wang and Cohen, 2007)
because sequences are ordered and because the ex-
traction process does not require seeds or HTML
lists as input.
The domain-independent sequence frame con-
sists of a sequence name s (e.g., presidents of the
United States), and a set of ordered pairs (x, k)
where x is a string naming a member of the se-
quence with name s, and k is an integer indicating
Most common cause of death in the United States:
1. heart disease, 2. cancer, 3. stroke, 4. COPD,
5. pneumonia, 6. cirrhosis, 7. AIDS, 8. chronic liver
disease, 9. sepsis, 10. suicide, 11. septic shock.
Largest tobacco company in the world:
</bodyText>
<listItem confidence="0.989900125">
1. Philip Morris, 2. BAT, 3. Japan Tobacco,
4. Imperial Tobacco, 5. Altadis.
Largest rodent in the world:
1. Capybara, 2. Beaver, 3. Patagonian Cavies. 4. Maras.
Sign of the zodiac:
1. Aries, 2. Taurus, 3. Gemini, 4. Cancer, 5. Leo,
6. Virgo, 7. Libra, 8. Scorpio, 9. Sagittarius,
10. Capricorn, 11. Aquarius, 12. Pisces, 13. Ophiuchus.
</listItem>
<tableCaption confidence="0.9717315">
Table 1: Examples of sequences extracted by SEQ
from unstructured Web text.
</tableCaption>
<bodyText confidence="0.99938025">
its position (e.g., (Washington, 1) and (JFK, 35)).
The task of sequence extraction is to automatically
instantiate sequence frames given a corpus of un-
structured text.
By definition, sequences have two properties
that we can leverage in creating a sequence ex-
tractor: functionality and density. Functionality
means position k in a sequence is occupied by a
single real-world entity x. Density means that if
a value has been observed at position k then there
must exist values for all i &lt; k, and possibly more
after it.
</bodyText>
<sectionHeader confidence="0.945858" genericHeader="method">
2 The SEQ System
</sectionHeader>
<bodyText confidence="0.999892545454545">
Sequence extraction has two parts: identify-
ing possible extractions (x, k, s) from text, and
then classifying those extractions as either cor-
rect or incorrect. In the following section, we
describe a way to identify candidate extractions
from text using a set of lexico-syntactic patterns.
We then show that classifying extractions based
on sentence-level features and redundancy alone
yields low precision, which is improved by lever-
aging the functionality and density properties of
sequences as done in our SEQ system.
</bodyText>
<page confidence="0.976936">
286
</page>
<note confidence="0.725386">
Proceedings of the ACL 2010 Conference Short Papers, pages 286–290,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.581502375">
Example
the fifth
the very first
the best
the very best
the third biggest
the most popular
the second least likely
</figure>
<bodyText confidence="0.997782">
we define the measure totalConf that takes into
account redundancy in an input corpus C. As
Downey et al. observed (2005), extractions that
occur more frequently in multiple distinct sen-
tences are more likely to be correct.
</bodyText>
<table confidence="0.863033125">
Pattern
the ORD
the RB ORD
the JJS
the RB JJS
the ORD JJS
the RBS JJ
the ORD RBS JJ
</table>
<tableCaption confidence="0.964909">
Table 2: The patterns used by SEQ to detect ordi-
</tableCaption>
<bodyText confidence="0.575157">
nal phrases are noun phrases that begin with one
of the part-of-speech patterns listed above.
</bodyText>
<subsectionHeader confidence="0.994344">
2.1 Generating Sequence Extractions
</subsectionHeader>
<bodyText confidence="0.999952166666667">
To obtain candidate sequence extractions (x, k, s)
from text, the SEQ system finds sentences in its
input corpus that contain an ordinal phrase (OP).
Table 2 lists the lexico-syntactic patterns SEQ uses
to detect ordinal phrases. The value of k is set to
the integer corresponding to the ordinal number in
the OP.1
Next, SEQ takes each sentence that contains an
ordinal phrase o, and finds candidate items of the
form (x, k) for the sequence with name s. SEQ
constrains x to be an NP that is disjoint from o, and
s to be an NP (which may have post-modifying
PPs or clauses) following the ordinal number in o.
For example, given the sentence “With help
from his father, JFK was elected as the 35th Pres-
ident of the United States in 1960”, SEQ finds
the candidate sequences with names “President”,
“President of the United States”, and “President of
the United States in 1960”, each of which has can-
didate extractions (JFK, 35), (his father, 35), and
(help, 35). We use heuristics to filter out many of
the candidate values (e.g., no value should cross a
sentence-like boundary, and x should be at most
some distance from the OP).
This process of generating candidate ex-
tractions has high coverage, but low preci-
sion. The first step in identifying correct ex-
tractions is to compute a confidence measure
localConf(x, k, s|sentence), which measures
how likely (x, k, s) is given the sentence it came
from. We do this using domain-independent syn-
tactic features based on POS tags and the pattern-
based features “x {is,are,was,were} the kth s” and
“the kth s {is,are,was,were} x”. The features are
then combined using a Naive Bayes classifier.
In addition to the local, sentence-based features,
</bodyText>
<footnote confidence="0.848807333333333">
1Sequences often use a superlative for the first item (k =
1) such as “the deepest lake in Africa”, “the second deepest
lake in Africa” (or “the 2nd deepest ...”), etc.
</footnote>
<equation confidence="0.991793">
totalConf(x, k, s|C) =
� localConf(x, k, s|sentence) (1)
sentenceEC
</equation>
<subsectionHeader confidence="0.991656">
2.2 Challenges
</subsectionHeader>
<bodyText confidence="0.998497825">
The scores localConf and totalConf are not suffi-
cient to identify valid sequence extractions. They
tend to give high scores to extractions where the
sequence scope is too general or too specific. In
our running example, the sequence name “Presi-
dent” is too general – many countries and orga-
nizations have a president. The sequence name
“President of the United States in 1960” is too spe-
cific – there were not multiple U.S. presidents in
1960.
These errors can be explained as violations of
functionality and density. The sequence with
name “President” will have many distinct candi-
date extractions in its positions, which is a vio-
lation of functionality. The sequence with name
“President of the United States in 1960” will not
satisfy density, since it will have extractions for
only one position.
In the next section, we present the details of how
SEQ incorporates functionality and density into its
assessment of a candidate extraction.
Given an extraction (x, k, s), SEQ must clas-
sify it as either correct or incorrect. SEQ breaks
this problem down into two parts: (1) determining
whether s is a correct sequence name, and (2) de-
termining whether (x, k) is an item in s, assuming
s is correct.
A joint probabilistic model of these two deci-
sions would require a significant amount of la-
beled data. To get around this problem, we repre-
sent each (x, k, s) as a vector of features and train
two Naive Bayes classifiers: one for classifying s
and one for classifying (x, k). We then rank ex-
tractions by taking the product of the two classi-
fiers’ confidence scores.
We now describe the features used in the two
classifiers and how the classifiers are trained.
Classifying Sequences To classify a sequence
name s, SEQ uses features to measure the func-
tionality and density of s. Functionality means
</bodyText>
<page confidence="0.971955">
287
</page>
<bodyText confidence="0.8922265">
Precision
that a correct sequence with name s has one cor-
rect value x at each position k, possibly with ad-
ditional noise due to extraction errors and synony-
mous values of x. For a fixed sequence name s
and position k, we can weight each of the candi-
date x values in that position by their normalized
total confidence:
</bodyText>
<equation confidence="0.991493">
w
( x |k s , C) = totalCon f (x, k, s|C)
Ex, totalConf(x&apos;, k, s|C)
</equation>
<bodyText confidence="0.9999744">
For overly general sequences, the distribution of
weights for a position will tend to be more flat,
since there are many equally-likely candidate x
values. To measure this property, we use a func-
tion analogous to information entropy:
</bodyText>
<equation confidence="0.9635695">
H(k, s|C) = − � w(x|k, s, C)lo92 w(x|k, s, C)
x
</equation>
<bodyText confidence="0.997858076923077">
Sequences s that are too general will tend to have
high values of H(k, s|C) for many values of k.
We found that a good measure of the overall non-
functionality of s is the average value of H(k, s|C)
fork = 1, 2, 3, 4.
For a sequence name s that is too specific, we
would expect that there are only a few filled-in po-
sitions. We model the density of s with two met-
rics. The first is numFilledPos(s|C), the num-
ber of distinct values of k such that there is some
extraction (x, k) for s in the corpus. The second
is total5eqConf(s|C), which is the sum of the
scores of most confident x in each position:
</bodyText>
<equation confidence="0.9994275">
total5eqConf(s|C) =
totalConf(x, k, s|C) (2)
</equation>
<bodyText confidence="0.999774083333333">
The functionality and density features are com-
bined using a Naive Bayes classifier. To train the
classifier, we use a set of sequence names s labeled
as either correct or incorrect, which we describe in
Section 3.
Classifying Sequence Items To classify (x, k)
given s, SEQ uses two features: the total con-
fidence totalConf(x, k, s|C) and the same total
confidence normalized to sum to 1 over all x, hold-
ing k and s constant. To train the classifier, we use
a set of extractions (x, k, s) where s is known to
be a correct sequence name.
</bodyText>
<sectionHeader confidence="0.998099" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.98974">
This section reports on two experiments. First, we
measured how the density and functionality fea-
tures improve performance on the sequence name
</bodyText>
<figure confidence="0.635304">
Recall
</figure>
<figureCaption confidence="0.8705185">
Figure 1: Using density or functionality features
alone is effective in identifying correct sequence
</figureCaption>
<bodyText confidence="0.996029363636364">
names. Combining both types of features outper-
forms either by a statistically significant margin
(paired t-test, p &lt; 0.05).
classification sub-task (Figure 1). Second, we
report on SEQ’s performance on the sequence-
extraction task (Figure 2).
To create a test set, we selected all sentences
containing ordinal phrases from Banko’s 500M
Web page corpus (2008). To enrich this set O,
we obtained additional sentences from Bing.com
as follows. For each sequence name s satis-
fying localConf(x, k, s|sentence) &gt; 0.5 for
some sentence in O, we queried Bing.com for
“the kth s” for k = 1, 2,... until no more hits
were returned.2 For each query, we downloaded
the search snippets and added them to our cor-
pus. This procedure resulted in making 95,611
search engine queries. The final corpus contained
3, 716, 745 distinct sentences containing an OP.
Generating candidate extractions using the
method from Section 2.1 resulted in a set of over
40 million distinct extractions, the vast majority
of which are incorrect. To get a sample with
a significant number of correct extractions, we
filtered this set to include only extractions with
totalConf(x, k, s|C) &gt; 0.8 for some sentence,
resulting in a set of 2, 409, 211 extractions.
We then randomly sampled and manually la-
beled 2,000 of these extractions for evaluation.
We did a Web search to verify the correctness of
the sequence name s and that x is the kth item in
the sequence. In some cases, the ordering rela-
tion of the sequence name was ambiguous (e.g.,
</bodyText>
<footnote confidence="0.974653666666667">
2We queried for both the numeric form of the ordinal and
the number spelled out (e.g “the 2nd ...” and “the second ...”).
We took up to 100 results per query.
</footnote>
<page confidence="0.7136745">
2
2
</page>
<figure confidence="0.971374363636364">
Both Feature Sets
Only Density
Only Functionality
Max c n
�
k
max
x
288
Precision
Recall
</figure>
<figureCaption confidence="0.819637">
Figure 2: SEQ outperforms the baseline systems,
increasing the area under the curve by 247% rela-
tive to LOCAL and by 90% relative to REDUND.
</figureCaption>
<bodyText confidence="0.999934393939394">
“largest state in the US” could refer to land area or
population), which could lead to merging two dis-
tinct sequences. In practice, we found that most
ordering relations were used in a consistent way
(e.g., “largest city in” always means largest by
population) and only about 5% of the sequence
names in our sample have an ambiguous ordering
relation.
We compute precision-recall curves relative to
this random sample by changing a confidence
threshold. Precision is the percentage of correct
extractions above a threshold, while recall is the
percentage correct above a threshold divided by
the total number of correct extractions. Because
SEQ requires training data, we used 15-fold cross
validation on the labeled sample.
The functionality and density features boost
SEQ’s ability to correctly identify sequence
names. Figure 1 shows how well SEQ can iden-
tify correct sequence names using only functional-
ity, only density, and using functionality and den-
sity in concert. The baseline used is the maximum
value of localConf(x, k, s) over all (x, k). Both
the density features and the functionality features
are effective at this task, but using both types of
features resulted in a statistically significant im-
provement over using either type of feature in-
dividually (paired t-test of area under the curve,
p &lt; 0.05).
We measure SEQ’s efficacy on the complete
sequence-extraction task by contrasting it with two
baseline systems. The first is LOCAL, which
ranks extractions by localConf.3 The second is
</bodyText>
<footnote confidence="0.477027">
3If an extraction arises from multiple sentences, we use
</footnote>
<bodyText confidence="0.999947157894737">
REDUND, which ranks extractions by totalConf.
Figure 2 shows the precision-recall curves for each
system on the test data. The area under the curves
for SEQ, REDUND, and LOCAL are 0.59, 0.31,
and 0.17, respectively. The low precision and flat
curve for LOCAL suggests that localConf is not
informative for classifying extractions on its own.
REDUND outperformed LOCAL, especially at
the high-precision part of the curve. On the subset
of extractions with correct s, REDUND can iden-
tify x as the kth item with precision of 0.85 at re-
call 0.80. This is consistent with previous work on
redundancy-based extractors on the Web. How-
ever, REDUND still suffered from the problems
of over-specification and over-generalization de-
scribed in Section 2. SEQ reduces the negative ef-
fects of these problems by decreasing the scores
of sequence names that appear too general or too
specific.
</bodyText>
<sectionHeader confidence="0.999989" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999963461538462">
There has been extensive work in extracting lists
or sets of entities from the Web. These extrac-
tors rely on either (1) HTML features (Cohen
et al., 2002; Wang and Cohen, 2007) to extract
from structured text or (2) lexico-syntactic pat-
terns (Hearst, 1992; Etzioni et al., 2005) to ex-
tract from unstructured text. SEQ is most similar
to this second type of extractor, but additionally
leverages the sequence regularities of functionality
and density. These regularities allow the system to
overcome the poor performance of the purely syn-
tactic extractor LOCAL and the redundancy-based
extractor REDUND.
</bodyText>
<sectionHeader confidence="0.999511" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999875692307692">
We have demonstrated that an extractor leveraging
sequence regularities can greatly outperform ex-
tractors without this knowledge. Identifying likely
sequence names and then filling in sequence items
proved to be an effective approach to sequence ex-
traction.
One line of future research is to investigate
other types of domain-independent frames that ex-
hibit useful regularities. Other examples include
events (with regularities about actor, location, and
time) and a generic organization-role frame (with
regularities about person, organization, and role
played).
</bodyText>
<figure confidence="0.509394">
the maximal localConf.
2
2
SEQ
REDUND
LOCAL
</figure>
<page confidence="0.754877">
289
</page>
<sectionHeader confidence="0.632439" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9472637">
Richard C. Wang and William W. Cohen. 2007.
Language-independent set expansion of named enti-
ties using the web. In ICDM, pages 342–350. IEEE
Computer Society.
This research was supported in part by NSF
grant IIS-0803481, ONR grant N00014-08-1-
0431, DARPA contract FA8750-09-C-0179, and
an NSF Graduate Research Fellowship, and was
carried out at the University of Washington’s Tur-
ing Center.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865804878049">
Michele Banko and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proceedings of ACL-08: HLT, pages 28–36.
Michele Banko, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In IJ-
CAI, pages 2670–2676.
H. Chieu, H. Ng, and Y. Lee. 2003. Closing the
gap: Learning-based information extraction rival-
ing knowledge-engineering methods. In ACL, pages
216–223.
William W. Cohen, Matthew Hurst, and Lee S. Jensen.
2002. A flexible learning system for wrapping ta-
bles and lists in html documents. In In International
World Wide Web Conference, pages 232–241.
Doug Downey, Oren Etzioni, and Stephen Soderland.
2005. A probabilistic model of redundancy in infor-
mation extraction. In IJCAI, pages 1034–1041.
O. Etzioni, M. Cafarella, D. Downey, A. Popescu,
T. Shaked, S. Soderland, D. Weld, and A. Yates.
2004. Methods for domain-independent informa-
tion extraction from the Web: An experimental com-
parison. In Proceedings of the Nineteenth National
Conference on Artificial Intelligence (AAAI-2004),
pages 391–398.
Oren Etzioni, Michael Cafarella, Doug Downey,
Ana maria Popescu, Tal Shaked, Stephen Soderl,
Daniel S. Weld, and Er Yates. 2005. Unsupervised
named-entity extraction from the web: An experi-
mental study. Artificial Intelligence, 165:91–134.
D. Freitag. 2000. Machine learning for information
extraction in informal domains. Machine Learning,
39(2-3):169–202.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In COLING, pages
539–545.
Satoshi Sekine. 2006. On-demand information extrac-
tion. In Proceedings of the COLING/ACL on Main
conference poster sessions, pages 731–738, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.997125">
290
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974574">
<title confidence="0.998896">Extracting Sequences from the Web</title>
<author confidence="0.999932">Anthony Fader</author>
<author confidence="0.999932">Stephen Soderland</author>
<author confidence="0.999932">Oren Etzioni</author>
<affiliation confidence="0.979634">University of Washington, Seattle</affiliation>
<abstract confidence="0.999690571428572">Classical Information Extraction (IE) systems fill slots in domain-specific frames. paper reports on a novel IE system that leverages a domainto extract ordered sequences such as presidents of the United States or the most common causes of death the U.S. regularities about sequences to extract a coherent set sequences from Web text. doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
</authors>
<title>The tradeoffs between open and traditional relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>28--36</pages>
<marker>Banko, Etzioni, 2008</marker>
<rawString>Michele Banko and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. In Proceedings of ACL-08: HLT, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matthew Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web. In</title>
<date>2007</date>
<booktitle>IJCAI,</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="1080" citStr="Banko et al., 2007" startWordPosition="161" endWordPosition="164">. SEQ leverages regularities about sequences to extract a coherent set of sequences from Web text. SEQ nearly doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities. 1 Introduction Classical IE systems fill slots in domain-specific frames such as the time and location slots in seminar announcements (Freitag, 2000) or the terrorist organization slot in news stories (Chieu et al., 2003). In contrast, open IE systems are domainindependent, but extract “flat” sets of assertions that are not organized into frames and slots (Sekine, 2006; Banko et al., 2007). This paper reports on SEQ—an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text. We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions (Table 1). Sequence extraction is distinct from set expansion (Etzioni et al., 2004; Wang and Cohen, 2007) because sequences are ordered and because the extraction process does not require seeds or HTML lists as input. The domain-independent sequence frame consi</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In IJCAI, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chieu</author>
<author>H Ng</author>
<author>Y Lee</author>
</authors>
<title>Closing the gap: Learning-based information extraction rivaling knowledge-engineering methods.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>216--223</pages>
<contexts>
<context position="909" citStr="Chieu et al., 2003" startWordPosition="133" endWordPosition="136"> open IE system that leverages a domainindependent frame to extract ordered sequences such as presidents of the United States or the most common causes of death in the U.S. SEQ leverages regularities about sequences to extract a coherent set of sequences from Web text. SEQ nearly doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities. 1 Introduction Classical IE systems fill slots in domain-specific frames such as the time and location slots in seminar announcements (Freitag, 2000) or the terrorist organization slot in news stories (Chieu et al., 2003). In contrast, open IE systems are domainindependent, but extract “flat” sets of assertions that are not organized into frames and slots (Sekine, 2006; Banko et al., 2007). This paper reports on SEQ—an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text. We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions (Table 1). Sequence extraction is distinct from set expansion (Etzioni et al., 2004; Wang a</context>
</contexts>
<marker>Chieu, Ng, Lee, 2003</marker>
<rawString>H. Chieu, H. Ng, and Y. Lee. 2003. Closing the gap: Learning-based information extraction rivaling knowledge-engineering methods. In ACL, pages 216–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Matthew Hurst</author>
<author>Lee S Jensen</author>
</authors>
<title>A flexible learning system for wrapping tables and lists in html documents.</title>
<date>2002</date>
<booktitle>In In International World Wide Web Conference,</booktitle>
<pages>232--241</pages>
<contexts>
<context position="14713" citStr="Cohen et al., 2002" startWordPosition="2494" endWordPosition="2497">subset of extractions with correct s, REDUND can identify x as the kth item with precision of 0.85 at recall 0.80. This is consistent with previous work on redundancy-based extractors on the Web. However, REDUND still suffered from the problems of over-specification and over-generalization described in Section 2. SEQ reduces the negative effects of these problems by decreasing the scores of sequence names that appear too general or too specific. 4 Related Work There has been extensive work in extracting lists or sets of entities from the Web. These extractors rely on either (1) HTML features (Cohen et al., 2002; Wang and Cohen, 2007) to extract from structured text or (2) lexico-syntactic patterns (Hearst, 1992; Etzioni et al., 2005) to extract from unstructured text. SEQ is most similar to this second type of extractor, but additionally leverages the sequence regularities of functionality and density. These regularities allow the system to overcome the poor performance of the purely syntactic extractor LOCAL and the redundancy-based extractor REDUND. 5 Conclusions We have demonstrated that an extractor leveraging sequence regularities can greatly outperform extractors without this knowledge. Identi</context>
</contexts>
<marker>Cohen, Hurst, Jensen, 2002</marker>
<rawString>William W. Cohen, Matthew Hurst, and Lee S. Jensen. 2002. A flexible learning system for wrapping tables and lists in html documents. In In International World Wide Web Conference, pages 232–241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Downey</author>
<author>Oren Etzioni</author>
<author>Stephen Soderland</author>
</authors>
<title>A probabilistic model of redundancy in information extraction.</title>
<date>2005</date>
<booktitle>In IJCAI,</booktitle>
<pages>1034--1041</pages>
<marker>Downey, Etzioni, Soderland, 2005</marker>
<rawString>Doug Downey, Oren Etzioni, and Stephen Soderland. 2005. A probabilistic model of redundancy in information extraction. In IJCAI, pages 1034–1041.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>D Downey</author>
<author>A Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D Weld</author>
<author>A Yates</author>
</authors>
<title>Methods for domain-independent information extraction from the Web: An experimental comparison.</title>
<date>2004</date>
<booktitle>In Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-2004),</booktitle>
<pages>391--398</pages>
<contexts>
<context position="1501" citStr="Etzioni et al., 2004" startWordPosition="226" endWordPosition="229">stories (Chieu et al., 2003). In contrast, open IE systems are domainindependent, but extract “flat” sets of assertions that are not organized into frames and slots (Sekine, 2006; Banko et al., 2007). This paper reports on SEQ—an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text. We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions (Table 1). Sequence extraction is distinct from set expansion (Etzioni et al., 2004; Wang and Cohen, 2007) because sequences are ordered and because the extraction process does not require seeds or HTML lists as input. The domain-independent sequence frame consists of a sequence name s (e.g., presidents of the United States), and a set of ordered pairs (x, k) where x is a string naming a member of the sequence with name s, and k is an integer indicating Most common cause of death in the United States: 1. heart disease, 2. cancer, 3. stroke, 4. COPD, 5. pneumonia, 6. cirrhosis, 7. AIDS, 8. chronic liver disease, 9. sepsis, 10. suicide, 11. septic shock. Largest tobacco compan</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2004</marker>
<rawString>O. Etzioni, M. Cafarella, D. Downey, A. Popescu, T. Shaked, S. Soderland, D. Weld, and A. Yates. 2004. Methods for domain-independent information extraction from the Web: An experimental comparison. In Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-2004), pages 391–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>Ana maria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderl</author>
<author>Daniel S Weld</author>
<author>Er Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: An experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<pages>165--91</pages>
<contexts>
<context position="14838" citStr="Etzioni et al., 2005" startWordPosition="2514" endWordPosition="2517"> consistent with previous work on redundancy-based extractors on the Web. However, REDUND still suffered from the problems of over-specification and over-generalization described in Section 2. SEQ reduces the negative effects of these problems by decreasing the scores of sequence names that appear too general or too specific. 4 Related Work There has been extensive work in extracting lists or sets of entities from the Web. These extractors rely on either (1) HTML features (Cohen et al., 2002; Wang and Cohen, 2007) to extract from structured text or (2) lexico-syntactic patterns (Hearst, 1992; Etzioni et al., 2005) to extract from unstructured text. SEQ is most similar to this second type of extractor, but additionally leverages the sequence regularities of functionality and density. These regularities allow the system to overcome the poor performance of the purely syntactic extractor LOCAL and the redundancy-based extractor REDUND. 5 Conclusions We have demonstrated that an extractor leveraging sequence regularities can greatly outperform extractors without this knowledge. Identifying likely sequence names and then filling in sequence items proved to be an effective approach to sequence extraction. One</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderl, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, Ana maria Popescu, Tal Shaked, Stephen Soderl, Daniel S. Weld, and Er Yates. 2005. Unsupervised named-entity extraction from the web: An experimental study. Artificial Intelligence, 165:91–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
</authors>
<title>Machine learning for information extraction in informal domains.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="837" citStr="Freitag, 2000" startWordPosition="122" endWordPosition="123">slots in domain-specific frames. This paper reports on SEQ, a novel open IE system that leverages a domainindependent frame to extract ordered sequences such as presidents of the United States or the most common causes of death in the U.S. SEQ leverages regularities about sequences to extract a coherent set of sequences from Web text. SEQ nearly doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities. 1 Introduction Classical IE systems fill slots in domain-specific frames such as the time and location slots in seminar announcements (Freitag, 2000) or the terrorist organization slot in news stories (Chieu et al., 2003). In contrast, open IE systems are domainindependent, but extract “flat” sets of assertions that are not organized into frames and slots (Sekine, 2006; Banko et al., 2007). This paper reports on SEQ—an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text. We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions (Table 1). Sequence</context>
</contexts>
<marker>Freitag, 2000</marker>
<rawString>D. Freitag. 2000. Machine learning for information extraction in informal domains. Machine Learning, 39(2-3):169–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In COLING,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="14815" citStr="Hearst, 1992" startWordPosition="2512" endWordPosition="2513"> 0.80. This is consistent with previous work on redundancy-based extractors on the Web. However, REDUND still suffered from the problems of over-specification and over-generalization described in Section 2. SEQ reduces the negative effects of these problems by decreasing the scores of sequence names that appear too general or too specific. 4 Related Work There has been extensive work in extracting lists or sets of entities from the Web. These extractors rely on either (1) HTML features (Cohen et al., 2002; Wang and Cohen, 2007) to extract from structured text or (2) lexico-syntactic patterns (Hearst, 1992; Etzioni et al., 2005) to extract from unstructured text. SEQ is most similar to this second type of extractor, but additionally leverages the sequence regularities of functionality and density. These regularities allow the system to overcome the poor performance of the purely syntactic extractor LOCAL and the redundancy-based extractor REDUND. 5 Conclusions We have demonstrated that an extractor leveraging sequence regularities can greatly outperform extractors without this knowledge. Identifying likely sequence names and then filling in sequence items proved to be an effective approach to s</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In COLING, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>On-demand information extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>731--738</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1059" citStr="Sekine, 2006" startWordPosition="159" endWordPosition="160">ath in the U.S. SEQ leverages regularities about sequences to extract a coherent set of sequences from Web text. SEQ nearly doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities. 1 Introduction Classical IE systems fill slots in domain-specific frames such as the time and location slots in seminar announcements (Freitag, 2000) or the terrorist organization slot in news stories (Chieu et al., 2003). In contrast, open IE systems are domainindependent, but extract “flat” sets of assertions that are not organized into frames and slots (Sekine, 2006; Banko et al., 2007). This paper reports on SEQ—an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text. We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions (Table 1). Sequence extraction is distinct from set expansion (Etzioni et al., 2004; Wang and Cohen, 2007) because sequences are ordered and because the extraction process does not require seeds or HTML lists as input. The domain-independent</context>
</contexts>
<marker>Sekine, 2006</marker>
<rawString>Satoshi Sekine. 2006. On-demand information extraction. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 731–738, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>