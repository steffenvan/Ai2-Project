<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.993292">
Omnia Mutantur, Nihil Interit: Connecting Past with Present by Find-
ing Corresponding Terms across Time
</title>
<author confidence="0.999802">
Yating Zhang*, Adam Jatowt*, Sourav S Bhowmick+, Katsumi Tanaka*
</author>
<affiliation confidence="0.999435">
*School of Informatics, Kyoto University
+School of Computer Engineering, Nanyang Technological University
</affiliation>
<email confidence="0.9857485">
{zhang,adam,tanaka}@dl.kuis.kyoto-u.ac.jp
assourav@ntu.edu.sg
</email>
<sectionHeader confidence="0.99377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993419066666667">
In the current fast-paced world, people tend to
possess limited knowledge about things from
the past. For example, some young users may
not know that Walkman played similar func-
tion as iPod does nowadays. In this paper, we
approach the temporal correspondence prob-
lem in which, given an input term (e.g., iPod)
and the target time (e.g. 1980s), the task is to
find the counterpart of the query that existed
in the target time. We propose an approach
that transforms word contexts across time
based on their neural network representations.
We then experimentally demonstrate the ef-
fectiveness of our method on the New York
Times Annotated Corpus.
</bodyText>
<sectionHeader confidence="0.998562" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949352941177">
What music device 30 years ago played similar
role as iPod does nowadays? Who are today’s
Beatles? Who was a counterpart of President Chi-
rac in 1988? These and many other similar ques-
tions may be difficult to answer by average users
(especially, by young ones). This is because peo-
ple tend to possess less knowledge about the past
than about the contemporary time.
In this work we propose an effective method to
solve the problem of finding counterpart terms
across time. In particular, for an input pair of a
term (e.g., iPod) and the target time (e.g. 1980s),
we find the corresponding term that existed in the
target time (walkman). We consider temporal
counterparts to be terms which are semantically
similar, yet, which existed in different time.
Knowledge of temporal counterparts can help
to alleviate the problem of terminology gap for us-
ers searching within temporal document collec-
tions such as archives. For example, given a user’s
query and the target time frame, a new modified
query that represents the same meaning could be
suggested to improve search results. Essentially,
it would mean letting searchers use the knowledge
they possess on the current world to perform
search within unknown collections such as ones
containing documents from the distant past. Fur-
thermore, solving temporal correspondence prob-
lem can help timeline construction, temporal sum-
marization, reference forecasting and can have ap-
plications in education.
The problem of temporal counterpart detection
is however not trivial. The key difficulty comes
from the change of the entire context that results
in low overlap of context across time. In other
words, it is difficult to find temporal counterpart
terms by directly comparing context vectors
across time. This fact is nicely portrayed by the
Latin proverb: “omnia mutantur, nihil interit” (in
English: “everything changes, nothing perishes”)
which indicates that there are no completely static
things, yet, many things and concepts are still sim-
ilar across time. Another challenge is the lack of
training data. If we have had enough training pairs
of input terms and their temporal counterparts,
then it would have become possible to represent
the task as a typical machine learning problem.
However, it is difficult to collect multiple training
pairs over various domains and for arbitrary time.
In view of the challenges mentioned above, we
propose an approach that transforms term repre-
sentations from one vector space (e.g., one de-
rived from the present documents) to another vec-
tor space (e.g., one obtained from the past docu-
ments). Terms in both the vector spaces are repre-
sented by the distributed vector representation
(Mikolov et al. 2013a; Mikolov et al. 2013c). Our
method then matches the terms by comparing
their relative positions in the vector spaces of dif-
ferent time periods alleviating the problem of low
overlap between word contexts over time. It also
does not require to manually prepare seed pairs of
temporal counterparts. We further improve this
method by automatically generating reference
points that more precisely represent target terms
in the form of local graphs. In result, our approach
consists of finding global and local correspond-
ence between terms over time.
</bodyText>
<page confidence="0.984191">
645
</page>
<note confidence="0.978240333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 645–655,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.9991325">
To sum up, we make the following contribu-
tions in this paper: (1) we propose an efficient
method to find temporal counterparts by trans-
forming the representation of terms within differ-
ent temporal spaces, (2) we then enhance the
global correspondence method by considering
also the local context of terms (local correspond-
ence) and (3) we perform extensive experiments
on the New York Times Annotated Corpus
(Sandhaus, 2008), including the search from the
present to the past and vice versa, which prove the
effectiveness of our approach.
</bodyText>
<sectionHeader confidence="0.991343" genericHeader="method">
2 Global Correspondence Across Time
</sectionHeader>
<bodyText confidence="0.99986575">
Let the base time denoted as TB mean the time pe-
riod associated with the input term and let the tar-
get time, TT, mean the time period in which we
want to find this term’s counterparts. Typically,
for users, the base time is the present time and the
target time is some selected time period in the
past. Note however, that we do not impose any re-
striction on the order and the distance of the both
times. Hence, it is possible to search for present
counterparts of terms that existed in the past.
In our approach we first represent all the terms
in the base time and in the target time within their
respective semantic vector spaces, χB and χT.
Then, we construct a transformation matrix to
bridge the two vector spaces. Algorithm 1 sum-
marizes the procedures needed to compute the
global transformation. We will explain it in Sec-
tion 2.1 and 2.2.
Algorithm 1 Overview of Global Transformation
Input: query q, base time TB and target time TT
</bodyText>
<listItem confidence="0.9927034">
1. Construct word representation model for
corpus in the base time, D(TB), and in the
target time, D(TT). (Section 2.1)
2. Construct transformation matrix M be-
tween D(TB) and D(TT) by first collecting
CFTs as training pairs and then learning M
using Eq. 1. (Section 2.2)
3. Rank the words in target time by their cor-
respondence scores (Eq. 2)
Output: ranked list of temporal counterparts
</listItem>
<subsectionHeader confidence="0.944515">
2.1 Vector space word representations
</subsectionHeader>
<bodyText confidence="0.998699235294118">
Distributed representation of words by neural
network was first proposed by Rumelhart et al.
(1986). More recently, Mikolov et al. (2013a,
2013c) introduced the Skip-gram model which
utilizes a simplified neural network architecture
for learning vector representations of words from
unstructured text data. We apply this model due to
its advantages: (1) it can capture precise semantic
word relationships; (2) due to the simplified neu-
ral network architecture, the model can easily
scale to millions of words. After applying the
Skip-gram model, the documents in the base time,
D(TB), are converted to a mXp matrix where n is
the vocabulary size and p are the dimensions of
feature vectors. Similarly, the documents in the
target time, D(TT), are represented as a nXq matrix
(as shown in Fig. 1).
</bodyText>
<figureCaption confidence="0.987042">
Figure 1: Word vector representations for the base
and the target time.
</figureCaption>
<subsectionHeader confidence="0.995125">
2.2 Transformation across vector spaces
</subsectionHeader>
<bodyText confidence="0.999621333333333">
Our goal is to compare words in the base time and
the target time in order to find temporal counter-
parts. However, it is impossible to directly com-
pare words in two different semantic vector
spaces, as the features in both spaces have no di-
rect correspondence between each other (as can be
seen in Fig. 1). To solve this problem, we propose
to train a transformation matrix in order to build
the connection between different vector spaces.
The key idea is that the relative positions of words
in each vector space should remain more or less
stable. In other words, a temporal counterpart
term should have similar relative position in its
own vector space as the position of the queried
term in the base time space. Fig. 2 conceptually
portrays this idea as the correspondence between
the context of Walkman and the context of iPod
(only two dimensions are shown for simplicity).
</bodyText>
<figureCaption confidence="0.591493333333333">
Figure 2: Conceptual view of the across-time
transformation by matching similar relative geo-
metric positions in each space.
</figureCaption>
<bodyText confidence="0.8871755">
Our task is then to train the transformation ma-
trix to automatically “rotate” the base vector space
</bodyText>
<figure confidence="0.974436117647059">
target time base time Vector Space
(e.g. 1987-1991) (e.g. 2003-2007) Representation
t
Training by using
Skip-gram model
Training by using
Skip-gram model
base time
(e.g. 2003-2007)
target time
(e.g. 1987-1991)
music
music
walkman
iPod
cassette
mp3
</figure>
<page confidence="0.998352">
646
</page>
<bodyText confidence="0.999919785714286">
into the target vector space. Suppose we have K
pairs of temporal counterparts {(w1, w1),...,(wk,
wk,)} where wi is a base time term and wi is its
counterpart in the target time. Then the transfor-
mation matrix M can be computed by minimizing
the differences between M∙wi and wi as given in
Eq. 1. The latter part of Eq. 1 is added as regular-
ization to overcome the problem of overfitting. In-
tuitively, matrix M is obtained by making sure that
the sum of Euclidean 2-norms between trans-
formed query vectors and their counterparts is
minimal on K seed query-counterpart pairs. Eq.1
is used for solving regularized least squares prob-
lem (γ equals to 0.02).
</bodyText>
<equation confidence="0.973341">
(1)
</equation>
<bodyText confidence="0.988320292682927">
However, as mentioned before, the other chal-
lenge is that the training pairs are difficult to be
obtained. It is non-trivial to prepare large enough
training data that would also cover various do-
mains and any possible combinations of the base
and target time periods. We apply here a simple
trick that performs reasonably well. We select
terms that (a) have the same syntactic forms in the
base and the target time periods and (b) are fre-
quent in the both time periods. Such Common
Frequent Terms (CFTs) are then used as the train-
ing data. Essentially, we assume here that very
frequent terms (e.g., man, women, water, dog, see,
three) change their meanings only to small extent.
The reasoning is that the more frequently the word
is used, the harder is to change its dominant mean-
ing (or the longer time it takes to make the mean-
ing shift) as the word is commonly used by many
people. The phenomenon that words used more
often in everyday language had evolved more
slowly has been observed in several languages in-
cluding English, Spanish, Russian and Greek
(Pargel et al., 2007; Lieberman et al. 2007). Then,
using the common frequent terms as the training
pairs, we solve Eq. 1 as the least squares problem.
Note that the number of CFTs is heuristically de-
cided. In Sec. 5 we discuss transformation perfor-
mance with regards to different numbers of CFTs.
After obtaining matrix M, we can then trans-
form the base time term, q, first by multiplying its
vector representation with the transformation ma-
trix M, and then by calculating the cosine similar-
ity between such transformed vector and the vec-
tors of all the terms in the target time. We call the
result of this similarity comparison the corre-
spondence score between the input term q in the
base time and a given term w in the target time
(see Eq. 2). A term which has the highest corre-
spondence score could be then considered as tem-
poral counterpart of q.
(2)
</bodyText>
<sectionHeader confidence="0.958054" genericHeader="method">
3 Local Correspondence across Time
</sectionHeader>
<bodyText confidence="0.9998774">
The method described above computes “global
similarity” between terms across time. In result,
the discovered counterparts can be similar to the
query term for variety of reasons, some of which
may not always lead to the best results. For in-
stance, the global transformation finds VCR as the
temporal counterpart of iPod in 1980s simply be-
cause both of them can have recording and play-
back functions. Macintosh is another term judged
to be strongly corresponding to iPod since both
are produced by Apple. Clearly, although VCR
and Macintosh are somewhat similar to iPod, they
are far from being its counterparts. The global
transformation, as presented in the previous sec-
tion, may thus fail to find correct counterparts due
to neglecting fundamental relations between a
query term and its context.
Inspired by these observations, we propose an-
other method for leveraging the informative con-
text terms of an input query term called reference
points. They are used to help mapping the query
to its correct temporal counterpart by considering
the relation between the query and the reference
points. We call this kind of similarity matching as
local correspondence in contrast to global corre-
spondence described in Sec. 2. In the following
sub-sections, we first introduce the desired char-
acteristics of the reference points and we then pro-
pose three computation methods for selecting
them. Finally, we describe how to find temporal
counterparts using the selected reference points.
Algorithm 2 shows the process of computing the
local transformation.
Algorithm 2 Overview of Local Transformation
Input: query q, base time TB and target time TT
</bodyText>
<listItem confidence="0.9724658">
1. Construct the local graph of q by detecting
the reference points in the context of q.
(Section 3.1)
2. Compute similarity of the local graph of q
with all the local graphs of candidate tem-
poral counterparts in the target time. (Sec-
tion 3.2)
3. Rank the candidate temporal counterparts
in the target time by graph similarity score
(Eq. 4).
</listItem>
<bodyText confidence="0.843433">
Output: ranked list of temporal counterparts
</bodyText>
<page confidence="0.992082">
647
</page>
<subsectionHeader confidence="0.996667">
3.1 Reference points detection
</subsectionHeader>
<bodyText confidence="0.99997672">
Reference points are terms in the query’s context
which help to build connection between the query
and its temporal counterparts. Reference points
should have at least some of the following charac-
teristics: (a) have high relation with the query (b)
be sufficiently general and (c) be independent
from each other.
Note that it does not mean that the selected ref-
erence point should have exactly same surface
form across time. Let us consider the previous ex-
ample query iPod and 1980s as the target time.
The term music could be a candidate reference
point for this query. Its temporal counterpart has
exactly the same syntax form in the target time
(music). However, mp3 could be another refer-
ence point. Even though mp3 did not exist in
1980s, it can still be referred to storage devices at
the target time such as cassette or disk helping
thus to find the correct counterparts of iPod, that
is, walkman and CD player.
Since different reference points will lead to dif-
ferent answers, we propose three methods for se-
lecting the reference points. Each one considers
the previously mentioned characteristics of refer-
ence points to different extent. Note that, if neces-
sary, the choice of the references points can be left
to users.
Term co-occurrence. The first approach satis-
fies the reference points’ characteristics of being
related to the query. To select reference points us-
ing this approach we rank context terms by multi-
plying two factors: tf(c) and relatedness(q,c),
where tf(c) is the frequency of a context term c,
while relatedness(q,c) is the relation strength of q
and c measured by the χ2 test. The test is con-
ducted based on the hypothesis that
P(c|q)=P(c|q̄), according to which the term c has
the same probability of occurring in documents
containing query q and in the documents not con-
taining q. We then use the inverse of the p-value
obtained from the test as relatedness(q,c).
Lexico-syntactic patterns. As the second ap-
proach we propose using hypernyms of terms.
This corresponds to the characteristic of reference
points to be general words. General terms are pre-
ferred rather than specific or detailed ones since
the former are more probable to be associated with
correct temporal counterparts1. This is because
detailed or specific terms are less likely to have
corresponding terms in the target time. To detect
</bodyText>
<footnote confidence="0.845554">
1 We have experimented with hyponyms and coordinate
terms used as reference points and found the results are
worse than when using hypernyms.
</footnote>
<bodyText confidence="0.999685730769231">
hypernyms on the fly, we adopt the method pro-
posed by Ohshima et al. (2010) that uses bi-direc-
tional lexico-syntactic patterns due to its high
speed and the lack of requirements for using ex-
ternal ontologies. The latter is important since, to
the best of our knowledge, there are no ready on-
tology resources for arbitrary periods in the past
(e.g., there seems to be no Wordnet for the past).
Semantic clustering. The last method chooses
reference points from clusters of context terms.
The purpose of applying clustering is to avoid
choosing semantically similar reference points.
Clustering helps to select typical terms from dif-
ferent sematic clusters to provide diverse informa-
tive context.
For grouping the context terms we utilize the
bisecting k-means algorithm. It is superior over k-
means and the agglomerative approach (Steinbach
et al., 2000) in terms of accuracy. The procedure
of bisecting k-means is to, first, select a cluster to
split and then to utilize the basic k-means to form
two sub-clusters. These two steps are repeated un-
til the desired number of clusters is obtained. The
distance between any two terms w1, w2 is the in-
verse of cosine similarity between their vector
representations.
</bodyText>
<listItem confidence="0.604364">
(3)
</listItem>
<subsectionHeader confidence="0.998948">
3.2 Local graph matching
</subsectionHeader>
<bodyText confidence="0.999977666666667">
Formulation. The local graph of query q is a
star shaped graph, denoted as SqFB, in which q is
the internal node, and the set of reference points,
𝐹B = {f1, f2,..., fu}, are leaf nodes where u is the
number of reference points. Our objective is to
find a local graph SwFT in the target vector space
that is most similar to SqFB in the base vector space.
w denotes here the temporal counterpart of q and
FT is the set of terms in the target vector space that
corresponds to FB.
Algorithm. Step (1): to compare the similarity
between two graphs in different vector spaces,
every node (i.e. term) in SqFB is required to be
transformed first to allow for comparison under
the same vector space. So the transformed vector
representation of q becomes M•q and FB is trans-
formed to {M•f1, M•f2 ..., M•fu} (recall that M is
the transformation matrix). Step (2): for each node
in SqFB, we then choose the top k candidate terms
with the highest correspondence score in the tar-
get space. Note that we would need to perform k•ku
</bodyText>
<page confidence="0.994243">
648
</page>
<bodyText confidence="0.976843333333333">
combinations of nodes (or candidate local graphs)
in total, to find the best graph with the highest
graph similarity. The computation time becomes
then an issue as the number of comparisons grows
in polynomial way with the increase in the number
of candidate terms. However, we manage to re-
duce the number of combinations to k•k•u by as-
suming the reference points be independent of
each other. Then, for every selected candidate
temporal counterpart, we only choose the set of
corresponding terms FT which maximizes the cur-
rent graph similarity. By default we set k equal to
1000. The process is shown in Algorithm 3.
Algorithm 3 Local Graph Matching
Input: local graph of q, SqFB
</bodyText>
<equation confidence="0.845568076923077">
W = top k corresponding terms of q (by Eq. 2)
FF = {top k corresponding terms of each f in
reference points FB={ f0, f1, ..., fu}} (by Eq. 2)
for w = W[1:k] do:
sum_cos = 0 # total graph similarity score
for F = FF[1:u] do:
max_cos = 0 # current maximum similar-
ity
for c = F[1:k] do:
find c which maximizes current graph
similarity
end for
sum_cos += max_cos
</equation>
<listItem confidence="0.433937">
end for
end for
</listItem>
<bodyText confidence="0.997304352941177">
sort W by sum_cos of each w in W.
Output: sorted W as ranked list of temporal
counterparts
Graph similarity computation. To compute
the similarity of two star shaped graphs, we take
both the semantic and relational similarities into
consideration. Fig. 3 conceptually portrays this
idea. Since all the computation is done under the
same vector space (after transformation), the se-
mantic meaning is represented by the absolute po-
sition of the term, that is, by its vector representa-
tion in the vector space. On the other hand, the re-
lation is described by the difference of two term
vectors. Finally, the graph similarity function
g(SqFB,SwFT) is defined as the combination of the
relational similarity function, h(SqFB,SwFT), and se-
mantic similarity function, z(SqFB,SwFT), as follows:
</bodyText>
<equation confidence="0.840298533333333">
g S SF   
( , ) (1 ) ( , )
q w q
FB T    h S S
F B T
w q w
F F
 ( ,
z S S
F B T
f f
  max(R R
B T
 )
q w
</equation>
<bodyText confidence="0.99951065">
where RqfB is the difference of vectors between q
and fB in FB represented as [q-fB]. RwfT is the differ-
ence of vectors between w and fT in FT, [w-fT],
where fT is selected from k candidates correspond-
ing terms of fB. fT maximizes the cosine similarity
between [q- fB] and [w- fT]. X is set to 0.5 by de-
fault. Intuitively, SqFB is a graph composed of
query and its reference points, while SwFT is a
graph containing candidate word w and its refer-
ence points. The first maximum in Eq. 4 finds for
each reference point in the base time, fB, the top-k
candidate terms corresponding to fB in the target
time. Next, it finds within k such fT that similarity
between [q- fB] and [w- fT] is maximum (relational
similarity). The second maximum in Eq. 4 is same
as the first one with the exception that it computes
the semantic similarity instead of the relational
similarity. The two summations in Eq. 4 aggregate
both the similarity scores over all the reference
points.
</bodyText>
<figure confidence="0.556095">
base time target time
(e.g. 2003-2007) (e.g. 1987-1991)
</figure>
<figureCaption confidence="0.9780125">
Figure 3: The concept of computing semantic and
relational similarity in matching local graphs.
</figureCaption>
<sectionHeader confidence="0.997757" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.990462">
4.1 Training sets
</subsectionHeader>
<bodyText confidence="0.999873764705882">
For the experiments we use the New York Times
Annotated Corpus (Sandhaus, 2008). This dataset
contains over 1.8 million newspaper articles pub-
lished between 1987 and 2007. We first divide it
into four parts according to article publication
time: [1987-1991], [1992-1996], [1997-2001] and
[2002-2007]. Each time period contains then
around half a million articles. We next train the
model of distributed vector representation sepa-
rately for each time period. The vocabulary size
of the entire corpus is 360k, while the vocabulary
size of each time period is around 300k.
In the experiments, we first focus on the pair of
time periods separated by the longest time gap,
that is, [2002, 2007] as the base time and [1987,
1991] as the target time. We also repeat the exper-
iment using more recent target time: [1992, 1996].
</bodyText>
<figure confidence="0.830347130434783">
semantic similarity
relational similarity
apple
sony
ipod
mp3
walkman
music
music
cassette
)
)

(1

(4)
fB
 FB,fT
FT
   max(  cos( , ) cos( , ) )
f f  q w
B T
fB FB,fT FT
</figure>
<page confidence="0.70312">
649
</page>
<table confidence="0.999868">
q tc BOW LSI-Com LSI-Tran GT LT-Cooc LT-Lex LT-Clust
[2002,2007] [1987,1991] (baseline) (baseline) (baseline) (proposed) (proposed) (proposed) (proposed)
Putin Yeltsin 1000+ 252 353 24 1 1 1
Chirac Mitterrand 1000+ 8 1 7 19 1 3
iPod Walkman 1000+ 20 131 3 13 1 16
Merkel Kohl 1000+ 1000+ 537 142 76 7 102
Facebook Usenet 1000+ 1000+ 1000+ 1 1 1 1
Linux Unix 1000+ 11 1 20 1 1 1
email letter 1000+ 1000+ 464 1 35 1 17
email mail 1000+ 1 9 7 2 6 11
email fax 1000+ 1000+ 10 3 1 4 2
Pixar Tristar 1000+ 549 1 1 1 1 1
Pixar Disney 1000+ 4 4 3 2 2 4
Serbia Yugoslavia 1000+ 15 1000+ 1 1 1 1
mp3 compact disk 1000+ 56 44 58 17 19 22
Rogge Samaranch 1000+ 4 22 42 82 34 44
N
Berlin Bonn 1000+ 43 265 62 40 48 56
Czech Czechoslovakia 1000+ 1 3 4 3 7 4
USB floppy disk 1000+ 209 1000+ 20 1 1 4
spam junk mail 1000+ 1000+ 37 5 61 1 1
Kosovo Yugoslavia 1000+ 59 1000+ 14 10 6 11
</table>
<tableCaption confidence="0.681108333333333">
Table 1: Example results where q is the input term and tc is the matching temporal counterpart. The
numbers are the ranks of the correct temporal counterpart in the results ranked by each method. Since
we output only the top 1000 results, ranks lower than 1000 are represented as 1000+.
</tableCaption>
<subsectionHeader confidence="0.99901">
4.2 Test sets
</subsectionHeader>
<bodyText confidence="0.99999116">
As far as we know there is no standard test bench
for temporal correspondence finding. We then had
to manually create test sets containing queries in
the base time and their correct temporal counter-
parts in the target time. In this process we used
external resources including the Wikipedia, a
Web search engine and several historical text-
books. The test terms cover three types of entities:
persons, locations and objects.
The examples of the test queries and their tem-
poral counterparts for [1987, 1991] are shown in
Table 1 where q denotes the input term and tc is
the correct counterpart. Note that the expected an-
swer is not required to be single neither exhaus-
tive. For example, there can be many answers for
the same query term, such as letter, mail, fax, all
being commonly used counterparts in 1980s for
email. Furthermore, as we do not care for recall in
this research, we do not require all the correct
counterpart terms to be found. In total, there are
95 pairs of terms (query and its counterpart) re-
sulting from 54 input query terms for the task of
mapping [2002, 2007] with [1987, 1991], and 50
term pairs created from 25 input query terms for
matching [2002, 2007] and [1992, 1996].
</bodyText>
<subsectionHeader confidence="0.994726">
4.3 Evaluation measures and baselines
</subsectionHeader>
<bodyText confidence="0.9992194">
We use the Mean Reciprocal Rank (MRR) as a
main metric to evaluate the ranked search results
for each method. MRR is expressed as the mean
of the inverse ranks for each test where a correct
result appears. It is calculated as follows:
</bodyText>
<equation confidence="0.942263333333333">
MRR 1  1 (5)
 i1
N ranki
</equation>
<bodyText confidence="0.998831333333333">
where ranki is the rank of a correct counterpart at
the i-th test. I is the number of query-answer
pairs. MRR’s values range between [0,1]. The
higher the value, the more correct the method is.
Besides MRR, we also report precision @1, @5,
@10 and @20. They are equal to the rates of tests
in which the correct counterpart term tc was found
in the top 1, 5, 10 and 20 results, respectively.
Baselines. We prepare three baselines:
</bodyText>
<listItem confidence="0.998972428571429">
(1) Bag of words approach (BOR) without
transformation: this method directly compares the
context of the query in the base time with the con-
text of the candidate term in the target time. We
use it to examine whether the distributed vector
representation and transformation are necessary.
(2) Latent Semantic Indexing (LSI) without
</listItem>
<bodyText confidence="0.86037375">
transformation (LSI-Com): we first merge the
documents in the base time and the documents in
the target time. Then, we train LSI (Deerwester,
1988) on such combined collection to represent
each term by the same distribution of detected top-
ics. We next search for the terms that exist in the
target period and that are also semantically similar
to the queried terms by comparing their vector
</bodyText>
<page confidence="0.995457">
650
</page>
<bodyText confidence="0.962949666666667">
representations. The purpose of using LSI-Com is
to check the need for the transformation over time.
(3) Latent Semantic Indexing (LSI) with
transformation (LSI-Tran): we train two LSI
models separately on the documents in the base
time and the documents in the target time. Then
we train the transformation matrix in the same
way as we did for our proposed methods. Lastly,
for a given input query, we compare its trans-
formed vector representation with terms in the tar-
get time. LSI-Tran is used to investigate if LSI can
be an alternative for the vector representation un-
der our transformation scenario.
Proposed Methods. All our methods use the
neural network based term representation. The
first one is the method without considering the lo-
cal context graph called GT (see Sec. 2). By test-
ing it we want to investigate the necessity of trans-
forming the context of the query in the target time.
We also test the three variants of the proposed
approach that applies the local graph (explained in
Sec. 3). The first one, LT-Lex, constructs the lo-
cal graph by using the hypernyms of terms. LT-
Cooc applies term co-occurrence to select the ref-
erence points. Finally, LT-Clust clusters the con-
text terms by their semantic meanings and selects
the most common term from each cluster.
</bodyText>
<subsectionHeader confidence="0.996305">
4.4 Parameter settings
</subsectionHeader>
<bodyText confidence="0.999822">
We set the parameters as follows:
</bodyText>
<listItem confidence="0.839813857142857">
(1) num_of_dim: we experimentally set the num-
ber of dimensions of the Skip-gram model and the
number of topics of LSI to be 200.
(2) num_of_CFTs: we utilize the top 5% (18k
words) of Common Frequent Terms to train the
transformation matrix. We have tried other num-
bers but we found 5% to perform best (see Fig. 4).
(3) u: the number of reference points (same as the
number of semantic clusters) is set to be 5. Ac-
cording to the results, we found that increasing the
number of reference points does not always im-
prove the results. The performance depends rather
on whether the reference points are general
enough, as too detailed ones hurt the results.
</listItem>
<sectionHeader confidence="0.996908" genericHeader="method">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999978375">
First, we look at the results of finding temporal
counterparts in [1987, 1991]. The average scores
for each method are shown in Table 2. Table 1
shows detailed results for few example queries.
The main finding is that all our methods outper-
form the baselines when measured by MRR and
by the precisions at different ranks. In the follow-
ing subsections we discuss the results in detail.
</bodyText>
<subsectionHeader confidence="0.997107">
5.1 Context change over time
</subsectionHeader>
<bodyText confidence="0.999941222222222">
The first observation is that the task is quite diffi-
cult as evidenced by extremely poor performance
of the bag of words approach (BOW). The correct
answers in BOW approach are usually found at
ranks 10k-30k (recall that the vocabulary size is
360k). This suggests little overlap in the contexts
of query and counterpart terms. The fact that all
our methods outperform the baselines suggests
that the across-time transformation is helpful.
</bodyText>
<subsectionHeader confidence="0.99997">
5.2 Using local context graph
</subsectionHeader>
<bodyText confidence="0.99997825">
We can observe from Table 2 that, in general, us-
ing the local context graph improves the results.
The best performing approach, LT-Lex, improves
GT method, which uses only global similarity
matching, by 24% when measured using MRR. It
increases the precision at certain levels of top
ranks, especially, at the top 1, where it boosts the
performance by 44%. LT-Lex uses the hyper-
nyms of query as reference points in the local
graph. This suggests that using generalized con-
text terms as reference points is most helpful for
finding correct temporal counterparts. On the
other hand, LT-Cooc and LT-Clust usually fail to
improve GT. It may be because the term co-oc-
currence and semantic clustering approaches de-
tect less general terms that tend to capture too de-
tailed information which is then poorly related to
the temporal counterpart. For example, LT-Cooc
detects {music, Apple, computer, digital, iTunes}
as the reference points of the query iPod. While
music is shared by iPod’s counterpart (walkman)
and Apple can be considered analogical to Sony,
other terms (i.e., computer, digital, iTunes) are ra-
ther too specific and unique for iPod.
</bodyText>
<subsectionHeader confidence="0.999824">
5.3 Using neural network model
</subsectionHeader>
<bodyText confidence="0.9996182">
When comparing the results of LSI-Com and
LSI-Tran in Table 2, we can see that using the
transformation does not help LSI to enhance the
performance but, on the contrary, it makes the re-
sults worse.
</bodyText>
<table confidence="0.9988695">
Method MRR P@1 P@5 P@10 P@20
BOW 4.1E-5 0 0 0 0
LSI-Com 0.206 15.8 27.3 29.5 38.6
LSI-Tran 0.112 7.9 13.6 21.6 22.7
GT 0.298 16.8 44.2 56.8 73.7
LT-Cooc 0.283 18.8 35.3 50.6 62.4
LT-Lex 0.369 24.2 49.5 63.2 71.6
LT-Clust 0.285 14.7 42.1 55.1 65.2
</table>
<tableCaption confidence="0.9837075">
Table 2: Results of searching from present to past
(present: 2002-2007; past: 1987-1991).
</tableCaption>
<page confidence="0.998484">
651
</page>
<bodyText confidence="0.99989">
Yet, as discussed above, applying the transfor-
mation is good idea in the case of the Neural Net-
work Model. We believe the reason for this is be-
cause it is difficult to perform the global transfor-
mation between topics underling the dimensions
of LSI, in contrast to transforming “semantic di-
mensions” of Neural Network Model.
</bodyText>
<subsectionHeader confidence="0.995977">
5.4 Effect of the number of CFTs
</subsectionHeader>
<bodyText confidence="0.982619166666667">
Fig. 4 shows MRR results for different numbers
of Common Frequent Terms (CFTs) when apply-
ing GT method. Note that the level of 0.10% (the
first point) corresponds to using 658 stop words as
seed pairs. As mentioned before, 5% of CFTs al-
lows to obtain the best results.
</bodyText>
<figure confidence="0.9977219">
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0.00% 2.00% 4.00% 6.00% 8.00% 10.00% 12.00% 14.00% 16.00%
Percentage of used CFTs
</figure>
<figureCaption confidence="0.9959835">
Figure 4: Results of MRR for GT method depend-
ing on number of used CFTs.
</figureCaption>
<subsectionHeader confidence="0.997451">
5.5 Searching from past to present
</subsectionHeader>
<bodyText confidence="0.999491909090909">
We next analyze the case of searching from the
past to the present. This scenario may apply to the
case of a user (perhaps, an older person) who pos-
sesses knowledge about the past term but does not
know its modern counterparts.
Table 3 shows the performance. We can see
that, again, all our approaches outperform all the
baselines using all the measures. LT-Lex is the
best performing approach, when measured by
MRR and P@1 and P@20. LT-Cooc this time re-
turns the best results at P@5 and P@10.
</bodyText>
<table confidence="0.99974325">
Method MRR P@1 P@5 P@10 P@20
BOW 3.4E-5 0 0 0 0
LSI-Com 0.181 13.2 19.7 28.9 35.5
LSI-Tran 0.109 5.3 17.1 21.1 23.7
GT 0.226 15.2 27.3 33.3 45.5
LT-Cooc 0.231 14.7 30.7 36 46.7
LT-Lex 0.235 16.7 28.8 31.8 48.5
LT-Clust 0.228 13.6 28.8 31.8 47
</table>
<tableCaption confidence="0.9487735">
Table 3: Average scores of searching from past to
present (present: 2002-2007; past: 1987-1991).
</tableCaption>
<bodyText confidence="0.995514625">
The objective of testing the search from the past
to present is to prove our methods work in both
directions. As for now, we can only conclude the
performance is asymmetrical. Yet, we might spec-
ulate that, along with the increase in distance,
searching from past to present could be harder due
to present world becoming relatively more diverse
when seen from the distant past.
</bodyText>
<subsectionHeader confidence="0.922711">
5.6 Results using different time period
</subsectionHeader>
<bodyText confidence="0.999496769230769">
Finally, we perform additional experiment using
another target time period [1992, 1996] to verify
whether our approach is still superior on different
target time. For the experiment we use the best
performing baseline listed in Table 2, LSI-Com,
and the best proposed approach, LT-Lex, as well
as GT. The results are shown in Tables 4 and 5.
LT-Lex outperforms the other baselines in both
the search from the present to the past (Table 4)
and from the past to the present (Table 5). Note
that since the query-answers pairs for [1992,
1996] are different than ones for [1987, 1991],
their results cannot be directly compared.
</bodyText>
<table confidence="0.99857525">
Method MRR P@1 P@5 P@10 P@20
LSI-Com 0.115 10.6 14.9 21.3 23.4
GT 0.132 8.5 27.7 40.4 53.2
LT-Lex 0.169 10.6 34.1 48.9 55.3
</table>
<tableCaption confidence="0.930703">
Table 4: Results of searching from present to past
(present: 2002-2007; past: 1992-1996).
</tableCaption>
<table confidence="0.9993525">
Method MRR P@1 P@5 P@10 P@20
LSI-Com 0.148 11.6 18.6 23.3 30.2
GT 0.184 11.6 23.3 30.2 44.2
LT-Lex 0.212 14 28 32.6 44.2
</table>
<tableCaption confidence="0.9861645">
Table 5: Results of searching from past to present
(present: 2002-2007; past: 1992-1996).
</tableCaption>
<subsectionHeader confidence="0.995171">
5.7 Confidence of Results
</subsectionHeader>
<bodyText confidence="0.999991625">
The approach described in this paper will al-
ways try to output some matching terms to a query
in the target time period. However in some cases,
no term corresponding to the one in the base time
existed in the target time (e.g. when the semantic
concept behind the term was not yet born or, on
the contrary, it has already felt out of use). For ex-
ample, junk mail may not have any equivalent in
texts created around 1800s. A simple solution to
this problem would be to use Eqs. 2 and 4 to serve
as measures of confidence behind each result in
order to decide whether the found counterparts
should or not be shown to users. Note however
that the scores returned by Eqs. 2 and 4 need to be
first normalized according to the distance between
the target time and the base time periods.
</bodyText>
<page confidence="0.997431">
652
</page>
<sectionHeader confidence="0.999917" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999539540540541">
Temporal changes in word meaning have been an
important topic of study within historical linguis-
tics (Aitchison, 2001; Campbell 2004; Labov,
2010; Hughes, 1988). Some researchers employed
computational methods for analyzing changes in
word senses over time (Mihalcea and Nastase,
2012; Kim et al., 2014; Jatowt and Duh, 2014;
Kulkarni et al., 2015). For example, Mihalcea and
Nastase (2012) classified words to one of three
past epochs based on words’ contexts. Kim et al.
(2014) and Kulkarni et al. (2015) computed the
degree of meaning change by applying neural net-
works for word representation. Jatowt and Duh
(2014) used also sentiment analysis and word pair
comparison for meaning change estimation. Our
objective is different as we search for correspond-
ing terms across time, and, in our case, temporal
counterparts can have different syntactic forms.
Some works considered computing term simi-
larity across time (Kalurachchi et al., 2010; Kan-
habua et al. 2010; Tahmasebi et al. 2012, Berber-
ich et al. 2009). Kalurachchi et al. (2010) pro-
posed to discover semantically identical tempo-
rally altering concepts by applying association
rule mining, assuming that the concepts referred
by similar events (verbs) are semantically related.
Kanhabua et al. (2010) discovered the change of
terms through the comparison of temporal Wik-
ipedia snapshots. Berberich et al. (2009) ap-
proached the problem by introducing a HMM
model and measuring the across-time sematic
similarity between two terms by comparing the
contexts captured by co-occurrence measures.
Tahmasebi et al. (2012) improved their approach
by first detecting the periods of name change and
then by analyzing the contexts during the change
periods to find the temporal co-references of dif-
ferent names. There are important differences be-
tween those works and ours. First, the previous
works mainly focused on detecting changes of the
names of the same, single entity over time. For ex-
ample, the objective was to look for the previous
name of Pope Benedict (i.e. Joseph Ratzinger) or
the previous name of St. Petersburg (i.e. Lenin-
grad). Second, these approaches relied on apply-
ing the co-occurrence statistics according to the
intuition that if two terms share similar contexts,
then these terms are semantically similar. In our
work, we do not require the context to be literally
same but to have the same meaning.
Transfer Learning (Pan et al., 2010) is related
to some extent to our work. It has been mainly
used in tasks such as POS tagging (Blitzer et al.,
2006), text classification (Blitzer et al., 2007; Ling
et al., 2008; Wang et al., 2011; Xue et al., 2008),
learning to rank (Cai et al., 2011; Gao et al., 2010;
Wang et al., 2009) and content-based retrieval
(Kato et al., 2012). The temporal correspondence
problem can be also understood as a transfer
learning as it is a search process that uses samples
in the base time for inferring correspondent in-
stances existing in the target time. However, the
difference is that we do not only consider the
structural correspondence but we also utilize the
semantic similarity across time.
The idea of distance-preserving projections is
also used in automatic translation (Mikolov et al.,
2013b). Our research problem is however more
difficult and is still unexplored. In the traditional
language translation, languages usually share
same concepts, while in the across-time transla-
tion concepts evolve and thus may be similar but
not always same. Furthermore, the lack of training
data is another key problem.
</bodyText>
<sectionHeader confidence="0.998052" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999992238095238">
This work approaches the problem of finding tem-
poral counterparts as a way to build a “bridge”
across different times. Knowing corresponding
terms across time can have direct usage in sup-
porting search within longitudinal document col-
lections or be helpful for constructing evolution
timelines. We first discuss the key challenge of
the temporal counterpart detection – the fact that
contexts of terms change, too. We then propose
the global correspondence method using transfor-
mation between two vector spaces. Based on this,
we then introduce more refined approach of com-
puting the local correspondence. Through experi-
ments we demonstrate that the local correspond-
ence using hypernyms outperforms both the base-
lines and the global correspondence approach.
In the future, we plan to test our approaches
over longer time spans and to design the way to
automatically “explain” temporal counterparts by
outputting “evidence” terms for clarifying the
similarity between the counterparts.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999034125">
We thank Makoto P. Kato for valuable comments.
This work was supported in part by Grants-in-Aid
for Scientific Research (Nos. 15H01718,
15K12158) from MEXT of Japan and by the JST
Research Promotion Program Sakigake: “Analyz-
ing Collective Memory and Developing Methods
for Knowledge Extraction from Historical Docu-
ments”.
</bodyText>
<page confidence="0.999109">
653
</page>
<sectionHeader confidence="0.990391" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999835708333333">
J. Aitchison, Language Change, Progress or Decay?
Cambridge University Press, 2001.
K. Berberich, S. J. Bedathur, M. Sozio and G. Weikum,
Bridging the Terminology Gap in Web Archive
Search, In Proc. of WebDB’09, 2009.
J. Blitzer, M. Dredze, and F. Pereira. Biographies, Bol-
lywood, Boom-boxes and Blenders: Domain Adap-
tion for Sentiment Classification. In Proc. of ACL,
pages 440-447, 2007.
J. Blitzer, R. McDonald, and F. Pereira. Domain adap-
tion with structural correspondence learning. In
Proceedings of the 2006 conference on empirical
methods in natural language processing. Associa-
tion for Computational Linguistics (EMNLP),
pages 120-128, 2006.
P. Cai, W. Gao, A. Zhou et al. Relevant knowledge
helps in choosing right teacher: active query selec-
tion for ranking adaptation. In Proceedings of the
34th international ACM SIGIR conference on Re-
search and development in Information Retrieval,
pages 115-124, 2001.
L. Campbell, Historical Linguistics, 2nd edition, MIT
Press, 2004.
S. Deerwester et al., Improving Information Retrieval
with Latent Semantic Indexing, In Proceedings of
the 51st Annual Meeting of the American Society
for Information Science, 25, pages 36–40, 1988.
W. Gao, P. Cai, K.F. Wong et al. Learning to rank only
using training data from related domain. In Pro-
ceedings of the 33rd international ACM SIGIR con-
ference on Research and development in infor-
mation retrieval, pages 162-169, 2010.
G. Hughes, Words in Time: A Social History of the
English Vocabulary. Basil Blackwell, 1988.
A. Jatowt and K. Duh. A framework for analyzing se-
mantic change of words across time. In Proc. of
JCDL, pages 229-238, 2014.
A. Kalurachchi, A. S. Varde, S. Bedathur, G. Weikum,
J. Peng and A. Feldman, Incorporating Terminol-
ogy Evolution for Query Translation in Text Re-
trieval with Association Rules, In Proceedings of
the 19th ACM international Conference on Infor-
mation and Knowledge Management (CIKM),
pages 1789-1792, 2010.
N. Kanhabua, K. Nørvåg, Exploiting Time-based Syn-
onyms in Searching Document Archives, In Pro-
ceedings of the 10th annual joint conference on
Digital libraries (JCDL), pages 79-88, 2010.
M. P. Kato, H. Ohshima and K. Tanaka. Content-based
Retrieval for Heterogeneous Domains: Domain
Adaption by Relative Aggregation Points. In Pro-
ceedings of the 35th international ACM SIGIR con-
ference on Research and development in infor-
mation retrieval, pages 811-820, 2012.
Y. Kim, Y-I. Chiu, K. Hanaki, D. Hegde and S. Petrov.
Temporal Analysis of Language through Neural
Language Models. In Proceedings of the ACL 2014
Workshop on Language Technologies and Compu-
tational Social Science, pp. 61-65, 2014.
V. Kulkarni, R. Al-Rfou, B. Perozzi, and S. Skiena.
2014. Statistically Significant Detection of Lin-
guistic Change. In Proc. of WWW, pages 625-635,
2015.
W. Labov. Principles of Linguistic Change (Social Fac-
tors), Wiley-Blackwell, 2010.
E. Lieberman, J.-B. Michel, J. Jackson, T. Tang, M. A.
Nowak. Quantifying the evolutionary dynamics of
language. Nature, 449, 713-716, 2007.
X. Ling, W. Dai, G. R. Xue, Q. Yang and Y. Yu. Spec-
tral domain-transfer learning. In Proceedings of the
14th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 488-
496, 2008.
R. Mihalcea, and V. Nastase, “Word Epoch Disambig-
uation: Finding How Words Change Over Time” in
Proceedings of ACL (2) 2012, pp. 259-263, 2012.
T. Mikolov, K. Chen, G. Corrado and J. Dean. Efficient
Estimation of Word Representations in Vector
Space. In ICLR Workshop, 2013a.
T. Mikolov, QV. Le, I. Sutskever. Exploiting similari-
ties among languages for machine translation.
CoRR, abs/1309.4168, 2013b.
T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J.
Dean. Distributed Representation of Phrases and
Their Compositionality. In Advances in Neural In-
formation Processing Systems (NIPS), pages 3111-
3119, 2013c.
H. Ohshima and K. Tanaka. High-speed Detection of
Ontological Knowledge and Bi-directional Lexico-
Syntactic Patterns from the Web. Journal of Soft-
ware, 5(2): 195-205, 2010.
S. Pan and Q. Yang. A survey on transfer learning.
IEEE Transactions on Knowledge and Data Engi-
neering, 22(10): 1345-1359, 2010.
M. Pargel, Q. D. Atkinson and A. Meade. Frequency of
word-use predicts rates of lexical evolution
</reference>
<page confidence="0.99009">
654
</page>
<reference confidence="0.992674685714286">
throughout Indo-European history. Nature, 449,
717-720, 2007.
D. E. Rumelhart, G. E. Hinton, R.J. Williams. Learning
internal representations by error propagation. Cali-
fornia Univ, San Diego La Jolla Inst. For Cognitive
Science, 1985.
E. Sandhaus. The New York Times Annotated Corpus
Overview. The New York Times Company, Re-
search and Development, pp. 1-22, 2008.
https://catalog.ldc.up-
enn.edu/docs/LDC2008T19/new_york_times_an-
notated_corpus.pdf
M. Steinbach, G. Karypis, V. Kumar. A comparison of
document clustering techniques. In Proc. of KDD
workshop on text mining. 2000, 400(1): 525-526.
N. Tahmasebi, G. Gossen, N. Kanhabua, H. Holzmann,
and T. Risse. NEER: An Unsupervised Method for
Named Entity Evolution Recognition, In Proc. of
Coling, pages 2553-2568, 2012.
H. Wang, H. Huang, F. Nie, and C. Ding. Cross-lan-
guage web page classification via dual knowledge
transfer using nonnegative matrix tri-factorization.
In Proceedings of the 34th international ACM
SIGIR conference on Research and development in
Information Retrieval, pages 933-942, 2011.
B. Wang, J. Tang, W. Fan, S. Chen, Z. Yang and Y. Liu.
Heterogeneous cross domain ranking in latent
space. In Proceedings of the 18th ACM conference
on Information and knowledge management
(CIKM), pages 987-996, 2009.
G. Xue, W. Dai, Q. Yang, and Y. Yu. Topic-bridged plsa
for cross-domain text classification. In Proceedings
of the 31st annual international ACM SIGIR con-
ference on Research and development in infor-
mation retrieval, pages 627-634, 2008.
</reference>
<page confidence="0.998843">
655
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208273">
<title confidence="0.9780655">Omnia Mutantur, Nihil Interit: Connecting Past with Present by Finding Corresponding Terms across Time</title>
<author confidence="0.998262">Adam Sourav S Katsumi</author>
<affiliation confidence="0.7045335">of Informatics, Kyoto of Computer Engineering, Nanyang Technological</affiliation>
<email confidence="0.936027">assourav@ntu.edu.sg</email>
<abstract confidence="0.985091">In the current fast-paced world, people tend to possess limited knowledge about things from the past. For example, some young users may not know that Walkman played similar function as iPod does nowadays. In this paper, we the correspondence probwhich, given an input term (e.g., and the target time (e.g. 1980s), the task is to find the counterpart of the query that existed in the target time. We propose an approach that transforms word contexts across time based on their neural network representations. We then experimentally demonstrate the effectiveness of our method on the New York</abstract>
<note confidence="0.607504">Times Annotated Corpus.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Aitchison</author>
</authors>
<title>Language Change, Progress or Decay?</title>
<date>2001</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="34852" citStr="Aitchison, 2001" startWordPosition="5988" endWordPosition="5989">ary, it has already felt out of use). For example, junk mail may not have any equivalent in texts created around 1800s. A simple solution to this problem would be to use Eqs. 2 and 4 to serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objectiv</context>
</contexts>
<marker>Aitchison, 2001</marker>
<rawString>J. Aitchison, Language Change, Progress or Decay? Cambridge University Press, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Berberich</author>
<author>S J Bedathur</author>
<author>M Sozio</author>
<author>G Weikum</author>
</authors>
<title>Bridging the Terminology Gap in Web Archive Search,</title>
<date>2009</date>
<booktitle>In Proc. of WebDB’09,</booktitle>
<contexts>
<context position="35747" citStr="Berberich et al. 2009" startWordPosition="6128" endWordPosition="6132"> classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered computing term similarity across time (Kalurachchi et al., 2010; Kanhabua et al. 2010; Tahmasebi et al. 2012, Berberich et al. 2009). Kalurachchi et al. (2010) proposed to discover semantically identical temporally altering concepts by applying association rule mining, assuming that the concepts referred by similar events (verbs) are semantically related. Kanhabua et al. (2010) discovered the change of terms through the comparison of temporal Wikipedia snapshots. Berberich et al. (2009) approached the problem by introducing a HMM model and measuring the across-time sematic similarity between two terms by comparing the contexts captured by co-occurrence measures. Tahmasebi et al. (2012) improved their approach by first dete</context>
</contexts>
<marker>Berberich, Bedathur, Sozio, Weikum, 2009</marker>
<rawString>K. Berberich, S. J. Bedathur, M. Sozio and G. Weikum, Bridging the Terminology Gap in Web Archive Search, In Proc. of WebDB’09, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bollywood Biographies</author>
</authors>
<title>Boom-boxes and Blenders: Domain Adaption for Sentiment Classification.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>440--447</pages>
<marker>Biographies, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaption for Sentiment Classification. In Proc. of ACL, pages 440-447, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Domain adaption with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 conference on empirical methods in natural language processing. Association for Computational Linguistics (EMNLP),</booktitle>
<pages>120--128</pages>
<contexts>
<context position="37260" citStr="Blitzer et al., 2006" startWordPosition="6373" endWordPosition="6376"> same, single entity over time. For example, the objective was to look for the previous name of Pope Benedict (i.e. Joseph Ratzinger) or the previous name of St. Petersburg (i.e. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-pr</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>J. Blitzer, R. McDonald, and F. Pereira. Domain adaption with structural correspondence learning. In Proceedings of the 2006 conference on empirical methods in natural language processing. Association for Computational Linguistics (EMNLP), pages 120-128, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cai</author>
<author>W Gao</author>
<author>A Zhou</author>
</authors>
<title>Relevant knowledge helps in choosing right teacher: active query selection for ranking adaptation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>115--124</pages>
<marker>Cai, Gao, Zhou, 2001</marker>
<rawString>P. Cai, W. Gao, A. Zhou et al. Relevant knowledge helps in choosing right teacher: active query selection for ranking adaptation. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 115-124, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Campbell</author>
</authors>
<title>Historical Linguistics, 2nd edition,</title>
<date>2004</date>
<publisher>MIT Press,</publisher>
<contexts>
<context position="34867" citStr="Campbell 2004" startWordPosition="5990" endWordPosition="5991">dy felt out of use). For example, junk mail may not have any equivalent in texts created around 1800s. A simple solution to this problem would be to use Eqs. 2 and 4 to serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different </context>
</contexts>
<marker>Campbell, 2004</marker>
<rawString>L. Campbell, Historical Linguistics, 2nd edition, MIT Press, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
</authors>
<title>Improving Information Retrieval with Latent Semantic Indexing,</title>
<date>1988</date>
<journal>Meeting of the American Society for Information Science,</journal>
<booktitle>In Proceedings of the 51st Annual</booktitle>
<volume>25</volume>
<pages>36--40</pages>
<contexts>
<context position="25899" citStr="Deerwester, 1988" startWordPosition="4432" endWordPosition="4433">n which the correct counterpart term tc was found in the top 1, 5, 10 and 20 results, respectively. Baselines. We prepare three baselines: (1) Bag of words approach (BOR) without transformation: this method directly compares the context of the query in the base time with the context of the candidate term in the target time. We use it to examine whether the distributed vector representation and transformation are necessary. (2) Latent Semantic Indexing (LSI) without transformation (LSI-Com): we first merge the documents in the base time and the documents in the target time. Then, we train LSI (Deerwester, 1988) on such combined collection to represent each term by the same distribution of detected topics. We next search for the terms that exist in the target period and that are also semantically similar to the queried terms by comparing their vector 650 representations. The purpose of using LSI-Com is to check the need for the transformation over time. (3) Latent Semantic Indexing (LSI) with transformation (LSI-Tran): we train two LSI models separately on the documents in the base time and the documents in the target time. Then we train the transformation matrix in the same way as we did for our pro</context>
</contexts>
<marker>Deerwester, 1988</marker>
<rawString>S. Deerwester et al., Improving Information Retrieval with Latent Semantic Indexing, In Proceedings of the 51st Annual Meeting of the American Society for Information Science, 25, pages 36–40, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gao</author>
<author>P Cai</author>
<author>K F Wong</author>
</authors>
<title>Learning to rank only using training data from related domain.</title>
<date>2010</date>
<booktitle>In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>162--169</pages>
<contexts>
<context position="37414" citStr="Gao et al., 2010" startWordPosition="6402" endWordPosition="6405">t. Petersburg (i.e. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b). Our research problem is however more difficult and is still unexplored</context>
</contexts>
<marker>Gao, Cai, Wong, 2010</marker>
<rawString>W. Gao, P. Cai, K.F. Wong et al. Learning to rank only using training data from related domain. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, pages 162-169, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hughes</author>
</authors>
<title>Words in Time: A Social History of the English Vocabulary.</title>
<date>1988</date>
<publisher>Basil Blackwell,</publisher>
<contexts>
<context position="34895" citStr="Hughes, 1988" startWordPosition="5994" endWordPosition="5995">mple, junk mail may not have any equivalent in texts created around 1800s. A simple solution to this problem would be to use Eqs. 2 and 4 to serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for correspondi</context>
</contexts>
<marker>Hughes, 1988</marker>
<rawString>G. Hughes, Words in Time: A Social History of the English Vocabulary. Basil Blackwell, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jatowt</author>
<author>K Duh</author>
</authors>
<title>A framework for analyzing semantic change of words across time.</title>
<date>2014</date>
<booktitle>In Proc. of JCDL,</booktitle>
<pages>229--238</pages>
<contexts>
<context position="35059" citStr="Jatowt and Duh, 2014" startWordPosition="6017" endWordPosition="6020">s of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered computing term similarity across time (Kalur</context>
</contexts>
<marker>Jatowt, Duh, 2014</marker>
<rawString>A. Jatowt and K. Duh. A framework for analyzing semantic change of words across time. In Proc. of JCDL, pages 229-238, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kalurachchi</author>
<author>A S Varde</author>
<author>S Bedathur</author>
<author>G Weikum</author>
<author>J Peng</author>
<author>A Feldman</author>
</authors>
<title>Incorporating Terminology Evolution for Query Translation in Text Retrieval with Association Rules,</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>1789--1792</pages>
<contexts>
<context position="35678" citStr="Kalurachchi et al., 2010" startWordPosition="6115" endWordPosition="6118"> 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered computing term similarity across time (Kalurachchi et al., 2010; Kanhabua et al. 2010; Tahmasebi et al. 2012, Berberich et al. 2009). Kalurachchi et al. (2010) proposed to discover semantically identical temporally altering concepts by applying association rule mining, assuming that the concepts referred by similar events (verbs) are semantically related. Kanhabua et al. (2010) discovered the change of terms through the comparison of temporal Wikipedia snapshots. Berberich et al. (2009) approached the problem by introducing a HMM model and measuring the across-time sematic similarity between two terms by comparing the contexts captured by co-occurrence me</context>
</contexts>
<marker>Kalurachchi, Varde, Bedathur, Weikum, Peng, Feldman, 2010</marker>
<rawString>A. Kalurachchi, A. S. Varde, S. Bedathur, G. Weikum, J. Peng and A. Feldman, Incorporating Terminology Evolution for Query Translation in Text Retrieval with Association Rules, In Proceedings of the 19th ACM international Conference on Information and Knowledge Management (CIKM), pages 1789-1792, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kanhabua</author>
<author>K Nørvåg</author>
</authors>
<title>Exploiting Time-based Synonyms in Searching Document Archives,</title>
<date>2010</date>
<booktitle>In Proceedings of the 10th annual joint conference on Digital libraries (JCDL),</booktitle>
<pages>79--88</pages>
<marker>Kanhabua, Nørvåg, 2010</marker>
<rawString>N. Kanhabua, K. Nørvåg, Exploiting Time-based Synonyms in Searching Document Archives, In Proceedings of the 10th annual joint conference on Digital libraries (JCDL), pages 79-88, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Kato</author>
<author>H Ohshima</author>
<author>K Tanaka</author>
</authors>
<title>Content-based Retrieval for Heterogeneous Domains: Domain Adaption by Relative Aggregation Points.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>811--820</pages>
<contexts>
<context position="37482" citStr="Kato et al., 2012" startWordPosition="6413" endWordPosition="6416"> applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b). Our research problem is however more difficult and is still unexplored. In the traditional language translation, languages usually share s</context>
</contexts>
<marker>Kato, Ohshima, Tanaka, 2012</marker>
<rawString>M. P. Kato, H. Ohshima and K. Tanaka. Content-based Retrieval for Heterogeneous Domains: Domain Adaption by Relative Aggregation Points. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pages 811-820, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Kim</author>
<author>Y-I Chiu</author>
<author>K Hanaki</author>
<author>D Hegde</author>
<author>S Petrov</author>
</authors>
<title>Temporal Analysis of Language through Neural Language Models.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science,</booktitle>
<pages>61--65</pages>
<contexts>
<context position="35037" citStr="Kim et al., 2014" startWordPosition="6013" endWordPosition="6016">o serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered computing term similar</context>
</contexts>
<marker>Kim, Chiu, Hanaki, Hegde, Petrov, 2014</marker>
<rawString>Y. Kim, Y-I. Chiu, K. Hanaki, D. Hegde and S. Petrov. Temporal Analysis of Language through Neural Language Models. In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pp. 61-65, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Kulkarni</author>
<author>R Al-Rfou</author>
<author>B Perozzi</author>
<author>S Skiena</author>
</authors>
<title>Statistically Significant Detection of Linguistic Change.</title>
<date>2014</date>
<booktitle>In Proc. of WWW,</booktitle>
<pages>625--635</pages>
<marker>Kulkarni, Al-Rfou, Perozzi, Skiena, 2014</marker>
<rawString>V. Kulkarni, R. Al-Rfou, B. Perozzi, and S. Skiena. 2014. Statistically Significant Detection of Linguistic Change. In Proc. of WWW, pages 625-635, 2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Labov</author>
</authors>
<title>Principles of Linguistic Change (Social Factors),</title>
<date>2010</date>
<location>Wiley-Blackwell,</location>
<contexts>
<context position="34880" citStr="Labov, 2010" startWordPosition="5992" endWordPosition="5993">use). For example, junk mail may not have any equivalent in texts created around 1800s. A simple solution to this problem would be to use Eqs. 2 and 4 to serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search </context>
</contexts>
<marker>Labov, 2010</marker>
<rawString>W. Labov. Principles of Linguistic Change (Social Factors), Wiley-Blackwell, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lieberman</author>
<author>J-B Michel</author>
<author>J Jackson</author>
<author>T Tang</author>
<author>M A Nowak</author>
</authors>
<title>Quantifying the evolutionary dynamics of language.</title>
<date>2007</date>
<journal>Nature,</journal>
<volume>449</volume>
<pages>713--716</pages>
<contexts>
<context position="10477" citStr="Lieberman et al. 2007" startWordPosition="1713" endWordPosition="1716">n Frequent Terms (CFTs) are then used as the training data. Essentially, we assume here that very frequent terms (e.g., man, women, water, dog, see, three) change their meanings only to small extent. The reasoning is that the more frequently the word is used, the harder is to change its dominant meaning (or the longer time it takes to make the meaning shift) as the word is commonly used by many people. The phenomenon that words used more often in everyday language had evolved more slowly has been observed in several languages including English, Spanish, Russian and Greek (Pargel et al., 2007; Lieberman et al. 2007). Then, using the common frequent terms as the training pairs, we solve Eq. 1 as the least squares problem. Note that the number of CFTs is heuristically decided. In Sec. 5 we discuss transformation performance with regards to different numbers of CFTs. After obtaining matrix M, we can then transform the base time term, q, first by multiplying its vector representation with the transformation matrix M, and then by calculating the cosine similarity between such transformed vector and the vectors of all the terms in the target time. We call the result of this similarity comparison the correspond</context>
</contexts>
<marker>Lieberman, Michel, Jackson, Tang, Nowak, 2007</marker>
<rawString>E. Lieberman, J.-B. Michel, J. Jackson, T. Tang, M. A. Nowak. Quantifying the evolutionary dynamics of language. Nature, 449, 713-716, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ling</author>
<author>W Dai</author>
<author>G R Xue</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Spectral domain-transfer learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>488--496</pages>
<contexts>
<context position="37322" citStr="Ling et al., 2008" startWordPosition="6383" endWordPosition="6386">look for the previous name of Pope Benedict (i.e. Joseph Ratzinger) or the previous name of St. Petersburg (i.e. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mi</context>
</contexts>
<marker>Ling, Dai, Xue, Yang, Yu, 2008</marker>
<rawString>X. Ling, W. Dai, G. R. Xue, Q. Yang and Y. Yu. Spectral domain-transfer learning. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 488-496, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>V Nastase</author>
</authors>
<title>Word Epoch Disambiguation: Finding How Words Change Over Time”</title>
<date>2012</date>
<booktitle>in Proceedings of ACL</booktitle>
<volume>2</volume>
<pages>259--263</pages>
<contexts>
<context position="35019" citStr="Mihalcea and Nastase, 2012" startWordPosition="6009" endWordPosition="6012">uld be to use Eqs. 2 and 4 to serve as measures of confidence behind each result in order to decide whether the found counterparts should or not be shown to users. Note however that the scores returned by Eqs. 2 and 4 need to be first normalized according to the distance between the target time and the base time periods. 652 6 Related Work Temporal changes in word meaning have been an important topic of study within historical linguistics (Aitchison, 2001; Campbell 2004; Labov, 2010; Hughes, 1988). Some researchers employed computational methods for analyzing changes in word senses over time (Mihalcea and Nastase, 2012; Kim et al., 2014; Jatowt and Duh, 2014; Kulkarni et al., 2015). For example, Mihalcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered comp</context>
</contexts>
<marker>Mihalcea, Nastase, 2012</marker>
<rawString>R. Mihalcea, and V. Nastase, “Word Epoch Disambiguation: Finding How Words Change Over Time” in Proceedings of ACL (2) 2012, pp. 259-263, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
<author>K Chen</author>
<author>G Corrado</author>
<author>J Dean</author>
</authors>
<title>Efficient Estimation of Word Representations in Vector Space.</title>
<date>2013</date>
<booktitle>In ICLR Workshop,</booktitle>
<contexts>
<context position="3699" citStr="Mikolov et al. 2013" startWordPosition="577" endWordPosition="580">ugh training pairs of input terms and their temporal counterparts, then it would have become possible to represent the task as a typical machine learning problem. However, it is difficult to collect multiple training pairs over various domains and for arbitrary time. In view of the challenges mentioned above, we propose an approach that transforms term representations from one vector space (e.g., one derived from the present documents) to another vector space (e.g., one obtained from the past documents). Terms in both the vector spaces are represented by the distributed vector representation (Mikolov et al. 2013a; Mikolov et al. 2013c). Our method then matches the terms by comparing their relative positions in the vector spaces of different time periods alleviating the problem of low overlap between word contexts over time. It also does not require to manually prepare seed pairs of temporal counterparts. We further improve this method by automatically generating reference points that more precisely represent target terms in the form of local graphs. In result, our approach consists of finding global and local correspondence between terms over time. 645 Proceedings of the 53rd Annual Meeting of the As</context>
<context position="6589" citStr="Mikolov et al. (2013" startWordPosition="1054" endWordPosition="1057">formation Input: query q, base time TB and target time TT 1. Construct word representation model for corpus in the base time, D(TB), and in the target time, D(TT). (Section 2.1) 2. Construct transformation matrix M between D(TB) and D(TT) by first collecting CFTs as training pairs and then learning M using Eq. 1. (Section 2.2) 3. Rank the words in target time by their correspondence scores (Eq. 2) Output: ranked list of temporal counterparts 2.1 Vector space word representations Distributed representation of words by neural network was first proposed by Rumelhart et al. (1986). More recently, Mikolov et al. (2013a, 2013c) introduced the Skip-gram model which utilizes a simplified neural network architecture for learning vector representations of words from unstructured text data. We apply this model due to its advantages: (1) it can capture precise semantic word relationships; (2) due to the simplified neural network architecture, the model can easily scale to millions of words. After applying the Skip-gram model, the documents in the base time, D(TB), are converted to a mXp matrix where n is the vocabulary size and p are the dimensions of feature vectors. Similarly, the documents in the target time, </context>
<context position="37940" citStr="Mikolov et al., 2013" startWordPosition="6485" endWordPosition="6488">08; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b). Our research problem is however more difficult and is still unexplored. In the traditional language translation, languages usually share same concepts, while in the across-time translation concepts evolve and thus may be similar but not always same. Furthermore, the lack of training data is another key problem. 7 Conclusions and Future Work This work approaches the problem of finding temporal counterparts as a way to build a “bridge” across different times. Knowing corresponding terms across time can have direct usage in supporting search within longitudinal document collections or be help</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>T. Mikolov, K. Chen, G. Corrado and J. Dean. Efficient Estimation of Word Representations in Vector Space. In ICLR Workshop, 2013a.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Sutskever Le</author>
</authors>
<title>Exploiting similarities among languages for machine translation.</title>
<journal>CoRR,</journal>
<volume>1309</volume>
<pages>2013</pages>
<marker>Le, </marker>
<rawString>T. Mikolov, QV. Le, I. Sutskever. Exploiting similarities among languages for machine translation. CoRR, abs/1309.4168, 2013b.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T Mikolov</author>
<author>I Sutskever</author>
<author>K Chen</author>
<author>G Corrado</author>
<author>J Dean</author>
</authors>
<title>Distributed Representation of Phrases and Their Compositionality.</title>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>3111--3119</pages>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, </marker>
<rawString>T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed Representation of Phrases and Their Compositionality. In Advances in Neural Information Processing Systems (NIPS), pages 3111-3119, 2013c.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ohshima</author>
<author>K Tanaka</author>
</authors>
<title>High-speed Detection of Ontological Knowledge and Bi-directional LexicoSyntactic Patterns from the Web.</title>
<date>2010</date>
<journal>Journal of Software,</journal>
<volume>5</volume>
<issue>2</issue>
<pages>195--205</pages>
<marker>Ohshima, Tanaka, 2010</marker>
<rawString>H. Ohshima and K. Tanaka. High-speed Detection of Ontological Knowledge and Bi-directional LexicoSyntactic Patterns from the Web. Journal of Software, 5(2): 195-205, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pan</author>
<author>Q Yang</author>
</authors>
<title>A survey on transfer learning.</title>
<date>2010</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>22</volume>
<issue>10</issue>
<pages>1345--1359</pages>
<marker>Pan, Yang, 2010</marker>
<rawString>S. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, 22(10): 1345-1359, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pargel</author>
<author>Q D Atkinson</author>
<author>A Meade</author>
</authors>
<title>Frequency of word-use predicts rates of lexical evolution throughout Indo-European history.</title>
<date>2007</date>
<journal>Nature,</journal>
<volume>449</volume>
<pages>717--720</pages>
<contexts>
<context position="10453" citStr="Pargel et al., 2007" startWordPosition="1709" endWordPosition="1712">e periods. Such Common Frequent Terms (CFTs) are then used as the training data. Essentially, we assume here that very frequent terms (e.g., man, women, water, dog, see, three) change their meanings only to small extent. The reasoning is that the more frequently the word is used, the harder is to change its dominant meaning (or the longer time it takes to make the meaning shift) as the word is commonly used by many people. The phenomenon that words used more often in everyday language had evolved more slowly has been observed in several languages including English, Spanish, Russian and Greek (Pargel et al., 2007; Lieberman et al. 2007). Then, using the common frequent terms as the training pairs, we solve Eq. 1 as the least squares problem. Note that the number of CFTs is heuristically decided. In Sec. 5 we discuss transformation performance with regards to different numbers of CFTs. After obtaining matrix M, we can then transform the base time term, q, first by multiplying its vector representation with the transformation matrix M, and then by calculating the cosine similarity between such transformed vector and the vectors of all the terms in the target time. We call the result of this similarity c</context>
</contexts>
<marker>Pargel, Atkinson, Meade, 2007</marker>
<rawString>M. Pargel, Q. D. Atkinson and A. Meade. Frequency of word-use predicts rates of lexical evolution throughout Indo-European history. Nature, 449, 717-720, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Rumelhart</author>
<author>G E Hinton</author>
<author>R J Williams</author>
</authors>
<title>Learning internal representations by error propagation.</title>
<date>1985</date>
<institution>California Univ, San Diego La Jolla Inst. For Cognitive Science,</institution>
<marker>Rumelhart, Hinton, Williams, 1985</marker>
<rawString>D. E. Rumelhart, G. E. Hinton, R.J. Williams. Learning internal representations by error propagation. California Univ, San Diego La Jolla Inst. For Cognitive Science, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sandhaus</author>
</authors>
<title>The New York Times Annotated Corpus Overview.</title>
<date>2008</date>
<booktitle>Company, Research and Development,</booktitle>
<pages>1--22</pages>
<publisher>The</publisher>
<location>New York Times</location>
<note>https://catalog.ldc.upenn.edu/docs/LDC2008T19/new_york_times_annotated_corpus.pdf</note>
<contexts>
<context position="4936" citStr="Sandhaus, 2008" startWordPosition="768" endWordPosition="769">ional Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 645–655, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics To sum up, we make the following contributions in this paper: (1) we propose an efficient method to find temporal counterparts by transforming the representation of terms within different temporal spaces, (2) we then enhance the global correspondence method by considering also the local context of terms (local correspondence) and (3) we perform extensive experiments on the New York Times Annotated Corpus (Sandhaus, 2008), including the search from the present to the past and vice versa, which prove the effectiveness of our approach. 2 Global Correspondence Across Time Let the base time denoted as TB mean the time period associated with the input term and let the target time, TT, mean the time period in which we want to find this term’s counterparts. Typically, for users, the base time is the present time and the target time is some selected time period in the past. Note however, that we do not impose any restriction on the order and the distance of the both times. Hence, it is possible to search for present c</context>
<context position="21314" citStr="Sandhaus, 2008" startWordPosition="3596" endWordPosition="3597"> within k such fT that similarity between [q- fB] and [w- fT] is maximum (relational similarity). The second maximum in Eq. 4 is same as the first one with the exception that it computes the semantic similarity instead of the relational similarity. The two summations in Eq. 4 aggregate both the similarity scores over all the reference points. base time target time (e.g. 2003-2007) (e.g. 1987-1991) Figure 3: The concept of computing semantic and relational similarity in matching local graphs. 4 Experimental Setup 4.1 Training sets For the experiments we use the New York Times Annotated Corpus (Sandhaus, 2008). This dataset contains over 1.8 million newspaper articles published between 1987 and 2007. We first divide it into four parts according to article publication time: [1987, 1988, 1989, 1990, 1991], [1992, 1993, 1994, 1995, 1996], [1997, 1998, 1999, 2000, 2001] and [2002, 2003, 2004, 2005, 2006, 2007]. Each time period contains then around half a million articles. We next train the model of distributed vector representation separately for each time period. The vocabulary size of the entire corpus is 360k, while the vocabulary size of each time period is around 300k. In the experiments, we firs</context>
</contexts>
<marker>Sandhaus, 2008</marker>
<rawString>E. Sandhaus. The New York Times Annotated Corpus Overview. The New York Times Company, Research and Development, pp. 1-22, 2008. https://catalog.ldc.upenn.edu/docs/LDC2008T19/new_york_times_annotated_corpus.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steinbach</author>
<author>G Karypis</author>
<author>V Kumar</author>
</authors>
<title>A comparison of document clustering techniques.</title>
<date>2000</date>
<booktitle>In Proc. of KDD workshop on text mining.</booktitle>
<volume>400</volume>
<issue>1</issue>
<pages>525--526</pages>
<contexts>
<context position="16717" citStr="Steinbach et al., 2000" startWordPosition="2751" endWordPosition="2754">ant since, to the best of our knowledge, there are no ready ontology resources for arbitrary periods in the past (e.g., there seems to be no Wordnet for the past). Semantic clustering. The last method chooses reference points from clusters of context terms. The purpose of applying clustering is to avoid choosing semantically similar reference points. Clustering helps to select typical terms from different sematic clusters to provide diverse informative context. For grouping the context terms we utilize the bisecting k-means algorithm. It is superior over kmeans and the agglomerative approach (Steinbach et al., 2000) in terms of accuracy. The procedure of bisecting k-means is to, first, select a cluster to split and then to utilize the basic k-means to form two sub-clusters. These two steps are repeated until the desired number of clusters is obtained. The distance between any two terms w1, w2 is the inverse of cosine similarity between their vector representations. (3) 3.2 Local graph matching Formulation. The local graph of query q is a star shaped graph, denoted as SqFB, in which q is the internal node, and the set of reference points, 𝐹B = {f1, f2,..., fu}, are leaf nodes where u is the number of refe</context>
</contexts>
<marker>Steinbach, Karypis, Kumar, 2000</marker>
<rawString>M. Steinbach, G. Karypis, V. Kumar. A comparison of document clustering techniques. In Proc. of KDD workshop on text mining. 2000, 400(1): 525-526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tahmasebi</author>
<author>G Gossen</author>
<author>N Kanhabua</author>
<author>H Holzmann</author>
<author>T Risse</author>
</authors>
<title>NEER: An Unsupervised Method for Named Entity Evolution Recognition,</title>
<date>2012</date>
<booktitle>In Proc. of Coling,</booktitle>
<pages>2553--2568</pages>
<contexts>
<context position="35723" citStr="Tahmasebi et al. 2012" startWordPosition="6124" endWordPosition="6127">lcea and Nastase (2012) classified words to one of three past epochs based on words’ contexts. Kim et al. (2014) and Kulkarni et al. (2015) computed the degree of meaning change by applying neural networks for word representation. Jatowt and Duh (2014) used also sentiment analysis and word pair comparison for meaning change estimation. Our objective is different as we search for corresponding terms across time, and, in our case, temporal counterparts can have different syntactic forms. Some works considered computing term similarity across time (Kalurachchi et al., 2010; Kanhabua et al. 2010; Tahmasebi et al. 2012, Berberich et al. 2009). Kalurachchi et al. (2010) proposed to discover semantically identical temporally altering concepts by applying association rule mining, assuming that the concepts referred by similar events (verbs) are semantically related. Kanhabua et al. (2010) discovered the change of terms through the comparison of temporal Wikipedia snapshots. Berberich et al. (2009) approached the problem by introducing a HMM model and measuring the across-time sematic similarity between two terms by comparing the contexts captured by co-occurrence measures. Tahmasebi et al. (2012) improved thei</context>
</contexts>
<marker>Tahmasebi, Gossen, Kanhabua, Holzmann, Risse, 2012</marker>
<rawString>N. Tahmasebi, G. Gossen, N. Kanhabua, H. Holzmann, and T. Risse. NEER: An Unsupervised Method for Named Entity Evolution Recognition, In Proc. of Coling, pages 2553-2568, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wang</author>
<author>H Huang</author>
<author>F Nie</author>
<author>C Ding</author>
</authors>
<title>Cross-language web page classification via dual knowledge transfer using nonnegative matrix tri-factorization.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>933--942</pages>
<contexts>
<context position="37341" citStr="Wang et al., 2011" startWordPosition="6387" endWordPosition="6390">us name of Pope Benedict (i.e. Joseph Ratzinger) or the previous name of St. Petersburg (i.e. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b</context>
</contexts>
<marker>Wang, Huang, Nie, Ding, 2011</marker>
<rawString>H. Wang, H. Huang, F. Nie, and C. Ding. Cross-language web page classification via dual knowledge transfer using nonnegative matrix tri-factorization. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 933-942, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wang</author>
<author>J Tang</author>
<author>W Fan</author>
<author>S Chen</author>
<author>Z Yang</author>
<author>Y Liu</author>
</authors>
<title>Heterogeneous cross domain ranking in latent space.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management (CIKM),</booktitle>
<pages>987--996</pages>
<contexts>
<context position="37434" citStr="Wang et al., 2009" startWordPosition="6406" endWordPosition="6409">. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b). Our research problem is however more difficult and is still unexplored. In the traditional</context>
</contexts>
<marker>Wang, Tang, Fan, Chen, Yang, Liu, 2009</marker>
<rawString>B. Wang, J. Tang, W. Fan, S. Chen, Z. Yang and Y. Liu. Heterogeneous cross domain ranking in latent space. In Proceedings of the 18th ACM conference on Information and knowledge management (CIKM), pages 987-996, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Xue</author>
<author>W Dai</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Topic-bridged plsa for cross-domain text classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>627--634</pages>
<contexts>
<context position="37360" citStr="Xue et al., 2008" startWordPosition="6391" endWordPosition="6394">edict (i.e. Joseph Ratzinger) or the previous name of St. Petersburg (i.e. Leningrad). Second, these approaches relied on applying the co-occurrence statistics according to the intuition that if two terms share similar contexts, then these terms are semantically similar. In our work, we do not require the context to be literally same but to have the same meaning. Transfer Learning (Pan et al., 2010) is related to some extent to our work. It has been mainly used in tasks such as POS tagging (Blitzer et al., 2006), text classification (Blitzer et al., 2007; Ling et al., 2008; Wang et al., 2011; Xue et al., 2008), learning to rank (Cai et al., 2011; Gao et al., 2010; Wang et al., 2009) and content-based retrieval (Kato et al., 2012). The temporal correspondence problem can be also understood as a transfer learning as it is a search process that uses samples in the base time for inferring correspondent instances existing in the target time. However, the difference is that we do not only consider the structural correspondence but we also utilize the semantic similarity across time. The idea of distance-preserving projections is also used in automatic translation (Mikolov et al., 2013b). Our research pro</context>
</contexts>
<marker>Xue, Dai, Yang, Yu, 2008</marker>
<rawString>G. Xue, W. Dai, Q. Yang, and Y. Yu. Topic-bridged plsa for cross-domain text classification. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 627-634, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>