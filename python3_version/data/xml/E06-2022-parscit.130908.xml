<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016530">
<title confidence="0.497358571428571">
Multilingual Term Extraction from Domain-specific Corpora
Using Morphological Structure
Delphine Bernhard
TIMC-IMAG
Institut de l’Ing´enierie et de l’Information de Sant´e
Facult´e de M´edecine
F-38706 LA TRONCHE cedex
</title>
<email confidence="0.991167">
Delphine.Bernhard@imag.fr
</email>
<sectionHeader confidence="0.995489" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99947175">
Morphologically complex terms com-
posed from Greek or Latin elements are
frequent in scientific and technical texts.
Word forming units are thus relevant cues
for the identification of terms in domain-
specific texts. This article describes a
method for the automatic extraction of
terms relying on the detection of classi-
cal prefixes and word-initial combining
forms. Word-forming units are identi-
fied using a regular expression. The sys-
tem then extracts terms by selecting words
which either begin or coalesce with these
elements. Next, terms are grouped in fam-
ilies which are displayed as a weighted list
in HTML format.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996530952381">
Many methods for the automatic extraction of
terms make use of patterns describing the structure
of terms. This approach is especially helpful for
multi-word terms. Depending on the method, pat-
terns rely on morpho-syntactic properties (Daille,
1996; Ibekwe-SanJuan, 1998), the co-occurrence
of terms and connectors (Enguehard, 1992; Ba-
roni and Bernardini, 2004) or the alternation of
informative and non-informative words (Vergne,
2005). These patterns use words as basic units
and thus apply to multi-word terms. Methods for
the acquisition of single-word terms generally de-
pend on frequency-related information. For in-
stance, the frequency of occurrence of a word in
a domain-specific corpus can be compared with
its frequency of occurrence in a reference corpus
(Rayson and Garside, 2000; Baroni and Bernar-
dini, 2004). Technical words usually have a high
relative frequency difference between the domain-
specific corpus and the reference corpus.
In this paper, we present a pattern-based tech-
nique to extract single-word terms. In technical
and scientific domains like medicine many terms
are derivatives or neoclassical compounds (Cot-
tez, 1984). There are several types of classical
word-forming units: prefixes (extra-, anti-), ini-
tial combining forms (hydro-, pharmaco-), suf-
fixes (-ism) and final combining forms (-graphy,
-logy). Interestingly, these units are rather con-
stant in many European languages (Namer, 2005).
Consequently, instead of relying on a subword dic-
tionary to analyse compounds like (Schulz et al.,
2002), our method makes use of these regularities
to automatically extract prefixes and initial com-
bining forms from corpora. The system then iden-
tifies terms by selecting words which either begin
or coalesce with these units. Moreover, forming
elements are used to group terms in morphological
and hence semantic families. The different stages
of the process are detailed in section 2. Section 3
describes the results of experiments performed on
four corpora, in English and in French.
</bodyText>
<sectionHeader confidence="0.572987" genericHeader="method">
2 Description of the method
</sectionHeader>
<subsectionHeader confidence="0.998904">
2.1 Extraction of words
</subsectionHeader>
<bodyText confidence="0.999717666666667">
The system takes as input a corpus of texts. Para-
graphs written in another language than the target
language are filtered out. Texts are then tokenised
and words are converted to lowercase. Besides,
words containing digits or other non-word charac-
ters are eliminated. However, hyphenated words
are kept since hyphens mark morpheme bound-
aries. This preliminary step produces a word fre-
quency list for the corpus.
</bodyText>
<page confidence="0.996491">
171
</page>
<subsectionHeader confidence="0.999837">
2.2 Acquisition of combining forms
</subsectionHeader>
<bodyText confidence="0.999788266666667">
Prefixes and initial combining forms are auto-
matically acquired using the following regular
expression: ([aio]-)?(\w{3,}[aio])-. This regu-
lar expression represents character strings whose
length is higher or equal to 4, ending with a,
i or o and immediately followed by a hyphen.
The first part of the regular expression accounts
for words where several prefixes or combining
forms follow one another (as for instance in
the French word “h´epato-gastro-ent´erologues”).
This regular expression applies to English but
also to other languages like French or German:
see for instance “chimio-radioth´erapie” in French,
“chemo-radiotherapy” in English or “Chemo-
radiotherapie” in German.
</bodyText>
<subsectionHeader confidence="0.999119">
2.3 Identification of terms
</subsectionHeader>
<bodyText confidence="0.999961307692308">
Terms are identified using the following pattern
describing their morphological structure: E+W
where E is a prefix or combining form and W is a
word whose length is higher than 3; the ‘+’ charac-
ter represents the possible succession of several E
elements at the beginning of a term. Prefixes and
combining forms may be separated by a hyphen.
When this pattern applies to one of the words in
the corpus, two terms are recognised, one with a
E+W structure and the other with a W structure.
For instance, given the word “ferrobasalts”, the
system identifies the terms “ferrobasalts” (E+W)
and “basalts” (W).
</bodyText>
<subsectionHeader confidence="0.999475">
2.4 Conflation of terms
</subsectionHeader>
<bodyText confidence="0.980797333333333">
Term variants are grouped in order to ease the
analysis of results. The method for terms confla-
tion can be decomposed in two stages:
1. Terms containing the same word W belong to
the same family, represented by the word W.
For instance, both “chemotherapy” and “ra-
diotherapy” contain the word “therapy”: they
belong to the same family of terms, repre-
sented by the word “therapy”.
2. Two families are merged if they are rep-
resented by words sharing the same ini-
tial substring (with a minimum initial sub-
string length of 4) and if the same prefix
or combining form occurs in one term of
each family. Consider for instance the fam-
ilies F1= [oncology, psycho-oncology, radio-
oncology, neuro-oncology, psychooncology,
neurooncology] and F2 = [oncologist, neuro-
oncologist]. The terms representing F1 (“on-
cology”) and F2 (“oncologist”) share an ini-
tial substring of length 7. Moreover the
terms “neuro-oncology” from F1 and “neuro-
oncologist” from F2 contain the combining
form “neuro”. Families F1 and F2 are there-
fore united.
When terms have been conflated, we select the
most frequent term as a family’s representative.
</bodyText>
<subsectionHeader confidence="0.983142">
2.5 Data visualisation
</subsectionHeader>
<bodyText confidence="0.999962066666667">
The results obtained are displayed as a weighted
list in HTML format. Such lists, also named “heat
maps” or “tag clouds” when they describe tags1
usually represent the terms and topics which ap-
pear most frequently on websites or RSS feeds
(Wikipedia, 2006). They can also be used to rep-
resent any kind of word list (V´eronis, 2005). Dif-
ferent colours and font sizes are used depending
on the word’s frequency of occurrence. We have
adapted this method to visualise the list of ex-
tracted terms. Since several hundred terms may
be extracted, only the terms representing a fam-
ily are displayed on the weighted list. Weight is
given by the cumulated frequency of all the terms
belonging to the family (see Figure 1).
</bodyText>
<figureCaption confidence="0.99408">
Figure 1: Term cloud example (Corpus: BC en)
</figureCaption>
<bodyText confidence="0.99819825">
Further information (terms and frequencies) is
displayed thanks to tooltips (see Figure 2), us-
ing the JavaScript overLIB libray ( http://www.
bosrup.com/web/overlib).
</bodyText>
<footnote confidence="0.982146">
1See for example TagCloud: http://www.
tagcloud.com
</footnote>
<page confidence="0.986135">
172
</page>
<figureCaption confidence="0.993865">
Figure 2: Detailed term family displayed as a
tooltip (Corpus: V fr)
</figureCaption>
<sectionHeader confidence="0.993083" genericHeader="evaluation">
3 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.946324">
3.1 Corpora
</subsectionHeader>
<bodyText confidence="0.999720705882353">
The system has been experimented on 4 corpora
covering the domains of volcanology (V) and
breast cancer (BC), in English (en) and in French
(fr). The corpora have been automatically built
from the web, using the methodology described
in (Baroni and Bernardini, 2004), via the Ya-
hoo! Search Web Services ( http://developer.
yahoo.net/search/). The size of the corpora ob-
tained are given in Table 1. This table also gives
the number of key words, i.e., single-word terms
extracted by comparing the frequency of occur-
rence of words in both corpora for each language
(Rayson and Garside, 2000). Only terms with a
log-likelihood of 3.8 or higher (p&lt;0.05) have been
kept in the key words list. Table 2 gives a nu-
merical overview of the results obtained by our
method.
</bodyText>
<table confidence="0.9994254">
Corpus Tokens Word forms Key words
BC fr 1,451,809 46,834 13,700
BC en 7,044,146 88,726 17,602
V fr 1,777,030 59,909 13,673
V en 2,929,591 48,257 19,641
</table>
<tableCaption confidence="0.999907">
Table 1: Size of the corpora
</tableCaption>
<subsectionHeader confidence="0.997341">
3.2 Prefixes and initial combining forms
</subsectionHeader>
<bodyText confidence="0.9997448">
As shown by Table 2, the number of prefixes and
initial combining forms identified is proportion-
ally less for the volcanology corpora both in En-
glish and in French. Medical corpora seem to
be more adapted to the method since the num-
</bodyText>
<table confidence="0.9988965">
Corpus Word-forming Terms Term
elements families
BC fr 334 4,248 911
BC en 382 5,444 1,338
V fr 182 1,842 583
V en 188 1,648 564
</table>
<tableCaption confidence="0.8661215">
Table 2: Number of word-forming elements, terms
and term families identified for each corpus
</tableCaption>
<bodyText confidence="0.998823">
ber of terms extracted is higher. The prefixes
and combining forms identified are also highly
dependent on the corpus domain. For instance,
amongst the most frequent combining forms ex-
tracted for the BC corpora, we find “radio” and
“chemo” (“chimio” in French) and for the V cor-
pora, “strato” and “volcano”.
</bodyText>
<subsectionHeader confidence="0.88098">
3.3 Terms
</subsectionHeader>
<bodyText confidence="0.999944806451613">
The overlap percentage between the list of terms
and the list of key words ranges from 38.65%
(V fr) to 56.92% (V en) of the total amount of
terms extracted. If we compare both the list of key
words and the list of terms extracted for the BC en
corpus with the Unified Medical Language Sys-
tem Metathesaurus (http://www.nlm.nih.gov/
research/umls/) we notice that some highly spe-
cific terms like “disease”, “blood” or “x-ray” are
not identified by our method, while they occur
in the key words list. These are usually mor-
phologically simple terms, also used in everyday
language. Conversely, terms with low frequency
like “adenoacanthoma”, “chondroma” or “mam-
motomy” are correctly identified by the pattern-
based approach but are missing in the key words
list. Both methods are therefore complementary.
In some cases, stop-words are extracted. This
is a side effect of the pattern used to retrieve
terms. Remember that terms are words which co-
alesce with combining forms, possibly with hy-
phenation. In English hyphens are sometimes mis-
takenly used instead of the dash to mark com-
ment clauses. Consider for instance the follow-
ing sentence: “As this magma-which drives one
of the worlds largest volcanic systems-rises, it
pushes up the Earths crust beneath the Yellow-
stone Plateau.”. Here “magma” is identified as
a combining form since it ends with ‘a’ and is
directly followed by a hyphen. Consequently,
“which” is wrongly identified as a term.
</bodyText>
<page confidence="0.997254">
173
</page>
<subsectionHeader confidence="0.960387">
3.4 Term families
</subsectionHeader>
<bodyText confidence="0.999914230769231">
Several types of term variants are grouped by the
term conflation algorithm: (a) graphical and ortho-
graphical variants like “tumour” (British variant)
and “tumor” (American variant); (b) inflectional
variants like “tumor” and “tumors”; (c) deriva-
tional variants like “tumor” and “tumoral”.
Two types of conflation errors may however oc-
cur: over-conflation, i.e., the conflation of terms
which do not belong to the same morphologi-
cal family and under-conflation, i.e. the absence
of conflation for morphologically related terms.
Some cases of over-conflation are obvious, such
as the grouping of “significant” with “cant”. In
some other cases it is more difficult to tell. This
especially applies to the conflation of terms com-
posed of word final combining forms like “-gram”
or “-graph”. Under-conflation occurs when no
combining form is shared between terms belong-
ing to families represented by graphically similar
terms. For instance, the following term families
are extracted from the French volcanology corpus
(V fr): F1= [basalte, m´etabasalte, m´eta-basalte],
F2= [basaltes, ferro-basaltes, pal´eobasaltes] and
F3= [basaltique, and´esitico-basaltique]. These
families are not conflated, even though they ob-
viously belong to the same morphological family.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999927176470588">
We have presented a method for the automatic ac-
quisition of terms from domain-specific texts us-
ing morphological structure. The method also
groups terms in morphological families. Fami-
lies are displayed as a weighted list, thus giving
an instant overview of the main topics in the cor-
pus under study. Results obtained from the first
experiments confirm the usefulness of a morpho-
logical pattern based approach for the extraction
of terms from domain-specific corpora and espe-
cially medical texts. The method for the identifi-
cation of compound words could be improved by
an automatic approach to morphological segmen-
tation as done by (Creutz and Lagus, 2004). Term
clustering could be ameliorated as well by investi-
gating the usefulness of stemming to avoid under-
conflation.
</bodyText>
<sectionHeader confidence="0.998161" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987232759259259">
Marco Baroni and Silvia Bernardini. 2004. Boot-
CaT: Bootstrapping Corpora and Terms from the
Web. In Proceedings of the Fourth International
Conference on Language Resources and Evaluation
(LREC), pages 1313–1316.
Henri Cottez. 1984. Dictionnaire des structures du vo-
cabulaire savant. ´El´ements et mod`eles deformation.
Le Robert, Paris, 3rd edition.
Mathias Creutz and Krista Lagus. 2004. Induc-
tion of a Simple Morphology for Highly-Inflecting
Languages. In Proceedings of the 7th Meeting of
the ACL Special Interest Group in Computational
Phonology (SIGPHON), pages 43–51.
B´eatrice Daille. 1996. Study and Implementation of
Combined Techniques for Automatic Extraction of
Terminology. In Judith Klavans and Philip Resnik,
editors, The Balancing Act: Combining Symbolic
and Statistical Approaches to Language, pages 49–
66. The MIT Press, Cambridge, Massachusetts.
Chantal Enguehard. 1992. ANA, Apprentissage Na-
turel Automatique d’un R´eseau S´emantique. Ph.D.
thesis, Universit´e de Technologie de Compi`egne.
Fidelia Ibekwe-SanJuan. 1998. Terminological vari-
ation, a means of identifying research topics from
texts. In Proceedings of the Joint International Con-
ference on Computational Linguistics (COLING-
ACL’98), pages 564–570.
Fiammetta Namer. 2005. Morphos´emantique pour
l’appariement de termes dans le vocabulaire m´edical
: approche multilingue. In Actes de TALN 2005,
pages 63–72.
Paul Rayson and Roger Garside. 2000. Comparing
Corpora using Frequency Profiling. In Proceedings
of the ACL Workshop on Comparing Corpora, pages
1–6.
Stefan Schulz, Martin Honeck, and Udo Hahn. 2002.
Biomedical Text Retrieval in Languages with a
Complex Morphology. In Proceedings of the ACL
Workshop on Natural Language Processing in the
Biomedical Domain, pages 61–68.
Jacques Vergne. 2005. Une m´ethode ind´ependante
des langues pour indexer les documents de l’internet
par extraction de termes de structure contrˆol´ee. In
Actes de la Conf´erence Internationale sur le Docu-
ment ´Electronique (CIDE 8), pages 155–168.
Jean V´eronis. 2005. Nuage de mots d’aujourd’hui.
http://aixtal.blogspot.com/2005/07/
lexique-nuage-de-mots-daujourdhui.
html. [Online; accessed 31-January-2006].
Wikipedia. 2006. RSS (file format) —
Wikipedia, The Free Encyclopedia. http:
//en.wikipedia.org/w/index.php?title=
RSS_(file_format)&amp;oldid=37472136. [On-
line; accessed 31-January-2006].
</reference>
<page confidence="0.998419">
174
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.370602">
<title confidence="0.9935135">Multilingual Term Extraction from Domain-specific Corpora Using Morphological Structure</title>
<author confidence="0.991902">Delphine Bernhard</author>
<affiliation confidence="0.913172333333333">TIMC-IMAG Institut de l’Ing´enierie et de l’Information de Sant´e Facult´e de M´edecine</affiliation>
<address confidence="0.879979">F-38706 LA TRONCHE cedex</address>
<email confidence="0.584724">Delphine.Bernhard@imag.fr</email>
<abstract confidence="0.992406352941177">Morphologically complex terms composed from Greek or Latin elements are frequent in scientific and technical texts. Word forming units are thus relevant cues for the identification of terms in domainspecific texts. This article describes a method for the automatic extraction of terms relying on the detection of classical prefixes and word-initial combining forms. Word-forming units are identified using a regular expression. The system then extracts terms by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>BootCaT: Bootstrapping Corpora and Terms from the Web.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1313--1316</pages>
<contexts>
<context position="1251" citStr="Baroni and Bernardini, 2004" startWordPosition="177" endWordPosition="181">d-forming units are identified using a regular expression. The system then extracts terms by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format. 1 Introduction Many methods for the automatic extraction of terms make use of patterns describing the structure of terms. This approach is especially helpful for multi-word terms. Depending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the reference corpus. In this paper</context>
<context position="7236" citStr="Baroni and Bernardini, 2004" startWordPosition="1128" endWordPosition="1131">m cloud example (Corpus: BC en) Further information (terms and frequencies) is displayed thanks to tooltips (see Figure 2), using the JavaScript overLIB libray ( http://www. bosrup.com/web/overlib). 1See for example TagCloud: http://www. tagcloud.com 172 Figure 2: Detailed term family displayed as a tooltip (Corpus: V fr) 3 Experiments and results 3.1 Corpora The system has been experimented on 4 corpora covering the domains of volcanology (V) and breast cancer (BC), in English (en) and in French (fr). The corpora have been automatically built from the web, using the methodology described in (Baroni and Bernardini, 2004), via the Yahoo! Search Web Services ( http://developer. yahoo.net/search/). The size of the corpora obtained are given in Table 1. This table also gives the number of key words, i.e., single-word terms extracted by comparing the frequency of occurrence of words in both corpora for each language (Rayson and Garside, 2000). Only terms with a log-likelihood of 3.8 or higher (p&lt;0.05) have been kept in the key words list. Table 2 gives a numerical overview of the results obtained by our method. Corpus Tokens Word forms Key words BC fr 1,451,809 46,834 13,700 BC en 7,044,146 88,726 17,602 V fr 1,77</context>
</contexts>
<marker>Baroni, Bernardini, 2004</marker>
<rawString>Marco Baroni and Silvia Bernardini. 2004. BootCaT: Bootstrapping Corpora and Terms from the Web. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC), pages 1313–1316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henri Cottez</author>
</authors>
<title>Dictionnaire des structures du vocabulaire savant. ´El´ements et mod`eles deformation. Le Robert, Paris, 3rd edition.</title>
<date>1984</date>
<contexts>
<context position="2037" citStr="Cottez, 1984" startWordPosition="298" endWordPosition="300">isition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the reference corpus. In this paper, we present a pattern-based technique to extract single-word terms. In technical and scientific domains like medicine many terms are derivatives or neoclassical compounds (Cottez, 1984). There are several types of classical word-forming units: prefixes (extra-, anti-), initial combining forms (hydro-, pharmaco-), suffixes (-ism) and final combining forms (-graphy, -logy). Interestingly, these units are rather constant in many European languages (Namer, 2005). Consequently, instead of relying on a subword dictionary to analyse compounds like (Schulz et al., 2002), our method makes use of these regularities to automatically extract prefixes and initial combining forms from corpora. The system then identifies terms by selecting words which either begin or coalesce with these un</context>
</contexts>
<marker>Cottez, 1984</marker>
<rawString>Henri Cottez. 1984. Dictionnaire des structures du vocabulaire savant. ´El´ements et mod`eles deformation. Le Robert, Paris, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Induction of a Simple Morphology for Highly-Inflecting Languages.</title>
<date>2004</date>
<booktitle>In Proceedings of the 7th Meeting of the ACL Special Interest Group in Computational Phonology (SIGPHON),</booktitle>
<pages>43--51</pages>
<marker>Creutz, Lagus, 2004</marker>
<rawString>Mathias Creutz and Krista Lagus. 2004. Induction of a Simple Morphology for Highly-Inflecting Languages. In Proceedings of the 7th Meeting of the ACL Special Interest Group in Computational Phonology (SIGPHON), pages 43–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B´eatrice Daille</author>
</authors>
<title>Study and Implementation of Combined Techniques for Automatic Extraction of Terminology.</title>
<date>1996</date>
<booktitle>The Balancing Act: Combining Symbolic and Statistical Approaches to Language,</booktitle>
<pages>49--66</pages>
<editor>In Judith Klavans and Philip Resnik, editors,</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1138" citStr="Daille, 1996" startWordPosition="165" endWordPosition="166">ion of terms relying on the detection of classical prefixes and word-initial combining forms. Word-forming units are identified using a regular expression. The system then extracts terms by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format. 1 Introduction Many methods for the automatic extraction of terms make use of patterns describing the structure of terms. This approach is especially helpful for multi-word terms. Depending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually ha</context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>B´eatrice Daille. 1996. Study and Implementation of Combined Techniques for Automatic Extraction of Terminology. In Judith Klavans and Philip Resnik, editors, The Balancing Act: Combining Symbolic and Statistical Approaches to Language, pages 49– 66. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chantal Enguehard</author>
</authors>
<title>ANA, Apprentissage Naturel Automatique d’un R´eseau S´emantique.</title>
<date>1992</date>
<tech>Ph.D. thesis, Universit´e de Technologie de Compi`egne.</tech>
<contexts>
<context position="1221" citStr="Enguehard, 1992" startWordPosition="175" endWordPosition="176">bining forms. Word-forming units are identified using a regular expression. The system then extracts terms by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format. 1 Introduction Many methods for the automatic extraction of terms make use of patterns describing the structure of terms. This approach is especially helpful for multi-word terms. Depending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the r</context>
</contexts>
<marker>Enguehard, 1992</marker>
<rawString>Chantal Enguehard. 1992. ANA, Apprentissage Naturel Automatique d’un R´eseau S´emantique. Ph.D. thesis, Universit´e de Technologie de Compi`egne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fidelia Ibekwe-SanJuan</author>
</authors>
<title>Terminological variation, a means of identifying research topics from texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the Joint International Conference on Computational Linguistics (COLINGACL’98),</booktitle>
<pages>564--570</pages>
<contexts>
<context position="1161" citStr="Ibekwe-SanJuan, 1998" startWordPosition="167" endWordPosition="168">elying on the detection of classical prefixes and word-initial combining forms. Word-forming units are identified using a regular expression. The system then extracts terms by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format. 1 Introduction Many methods for the automatic extraction of terms make use of patterns describing the structure of terms. This approach is especially helpful for multi-word terms. Depending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative freq</context>
</contexts>
<marker>Ibekwe-SanJuan, 1998</marker>
<rawString>Fidelia Ibekwe-SanJuan. 1998. Terminological variation, a means of identifying research topics from texts. In Proceedings of the Joint International Conference on Computational Linguistics (COLINGACL’98), pages 564–570.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fiammetta Namer</author>
</authors>
<title>Morphos´emantique pour l’appariement de termes dans le vocabulaire m´edical : approche multilingue.</title>
<date>2005</date>
<booktitle>In Actes de TALN</booktitle>
<pages>63--72</pages>
<contexts>
<context position="2314" citStr="Namer, 2005" startWordPosition="338" endWordPosition="339">i, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the reference corpus. In this paper, we present a pattern-based technique to extract single-word terms. In technical and scientific domains like medicine many terms are derivatives or neoclassical compounds (Cottez, 1984). There are several types of classical word-forming units: prefixes (extra-, anti-), initial combining forms (hydro-, pharmaco-), suffixes (-ism) and final combining forms (-graphy, -logy). Interestingly, these units are rather constant in many European languages (Namer, 2005). Consequently, instead of relying on a subword dictionary to analyse compounds like (Schulz et al., 2002), our method makes use of these regularities to automatically extract prefixes and initial combining forms from corpora. The system then identifies terms by selecting words which either begin or coalesce with these units. Moreover, forming elements are used to group terms in morphological and hence semantic families. The different stages of the process are detailed in section 2. Section 3 describes the results of experiments performed on four corpora, in English and in French. 2 Descriptio</context>
</contexts>
<marker>Namer, 2005</marker>
<rawString>Fiammetta Namer. 2005. Morphos´emantique pour l’appariement de termes dans le vocabulaire m´edical : approche multilingue. In Actes de TALN 2005, pages 63–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Rayson</author>
<author>Roger Garside</author>
</authors>
<title>Comparing Corpora using Frequency Profiling.</title>
<date>2000</date>
<booktitle>In Proceedings of the ACL Workshop on Comparing Corpora,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="1680" citStr="Rayson and Garside, 2000" startWordPosition="244" endWordPosition="247">epending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the reference corpus. In this paper, we present a pattern-based technique to extract single-word terms. In technical and scientific domains like medicine many terms are derivatives or neoclassical compounds (Cottez, 1984). There are several types of classical word-forming units: prefixes (extra-, anti-), initial combining forms (hydro-, pharmaco-), suffixes (-ism) and final combining forms (-graphy, -logy). Interestingly, these units are rather constant in man</context>
<context position="7559" citStr="Rayson and Garside, 2000" startWordPosition="1182" endWordPosition="1185">Experiments and results 3.1 Corpora The system has been experimented on 4 corpora covering the domains of volcanology (V) and breast cancer (BC), in English (en) and in French (fr). The corpora have been automatically built from the web, using the methodology described in (Baroni and Bernardini, 2004), via the Yahoo! Search Web Services ( http://developer. yahoo.net/search/). The size of the corpora obtained are given in Table 1. This table also gives the number of key words, i.e., single-word terms extracted by comparing the frequency of occurrence of words in both corpora for each language (Rayson and Garside, 2000). Only terms with a log-likelihood of 3.8 or higher (p&lt;0.05) have been kept in the key words list. Table 2 gives a numerical overview of the results obtained by our method. Corpus Tokens Word forms Key words BC fr 1,451,809 46,834 13,700 BC en 7,044,146 88,726 17,602 V fr 1,777,030 59,909 13,673 V en 2,929,591 48,257 19,641 Table 1: Size of the corpora 3.2 Prefixes and initial combining forms As shown by Table 2, the number of prefixes and initial combining forms identified is proportionally less for the volcanology corpora both in English and in French. Medical corpora seem to be more adapted</context>
</contexts>
<marker>Rayson, Garside, 2000</marker>
<rawString>Paul Rayson and Roger Garside. 2000. Comparing Corpora using Frequency Profiling. In Proceedings of the ACL Workshop on Comparing Corpora, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schulz</author>
<author>Martin Honeck</author>
<author>Udo Hahn</author>
</authors>
<title>Biomedical Text Retrieval in Languages with a Complex Morphology.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Natural Language Processing in the Biomedical Domain,</booktitle>
<pages>61--68</pages>
<contexts>
<context position="2420" citStr="Schulz et al., 2002" startWordPosition="353" endWordPosition="356">ific corpus and the reference corpus. In this paper, we present a pattern-based technique to extract single-word terms. In technical and scientific domains like medicine many terms are derivatives or neoclassical compounds (Cottez, 1984). There are several types of classical word-forming units: prefixes (extra-, anti-), initial combining forms (hydro-, pharmaco-), suffixes (-ism) and final combining forms (-graphy, -logy). Interestingly, these units are rather constant in many European languages (Namer, 2005). Consequently, instead of relying on a subword dictionary to analyse compounds like (Schulz et al., 2002), our method makes use of these regularities to automatically extract prefixes and initial combining forms from corpora. The system then identifies terms by selecting words which either begin or coalesce with these units. Moreover, forming elements are used to group terms in morphological and hence semantic families. The different stages of the process are detailed in section 2. Section 3 describes the results of experiments performed on four corpora, in English and in French. 2 Description of the method 2.1 Extraction of words The system takes as input a corpus of texts. Paragraphs written in</context>
</contexts>
<marker>Schulz, Honeck, Hahn, 2002</marker>
<rawString>Stefan Schulz, Martin Honeck, and Udo Hahn. 2002. Biomedical Text Retrieval in Languages with a Complex Morphology. In Proceedings of the ACL Workshop on Natural Language Processing in the Biomedical Domain, pages 61–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Vergne</author>
</authors>
<title>Une m´ethode ind´ependante des langues pour indexer les documents de l’internet par extraction de termes de structure contrˆol´ee.</title>
<date>2005</date>
<booktitle>In Actes de la Conf´erence Internationale sur le Document ´Electronique (CIDE 8),</booktitle>
<pages>155--168</pages>
<contexts>
<context position="1326" citStr="Vergne, 2005" startWordPosition="190" endWordPosition="191">by selecting words which either begin or coalesce with these elements. Next, terms are grouped in families which are displayed as a weighted list in HTML format. 1 Introduction Many methods for the automatic extraction of terms make use of patterns describing the structure of terms. This approach is especially helpful for multi-word terms. Depending on the method, patterns rely on morpho-syntactic properties (Daille, 1996; Ibekwe-SanJuan, 1998), the co-occurrence of terms and connectors (Enguehard, 1992; Baroni and Bernardini, 2004) or the alternation of informative and non-informative words (Vergne, 2005). These patterns use words as basic units and thus apply to multi-word terms. Methods for the acquisition of single-word terms generally depend on frequency-related information. For instance, the frequency of occurrence of a word in a domain-specific corpus can be compared with its frequency of occurrence in a reference corpus (Rayson and Garside, 2000; Baroni and Bernardini, 2004). Technical words usually have a high relative frequency difference between the domainspecific corpus and the reference corpus. In this paper, we present a pattern-based technique to extract single-word terms. In tec</context>
</contexts>
<marker>Vergne, 2005</marker>
<rawString>Jacques Vergne. 2005. Une m´ethode ind´ependante des langues pour indexer les documents de l’internet par extraction de termes de structure contrˆol´ee. In Actes de la Conf´erence Internationale sur le Document ´Electronique (CIDE 8), pages 155–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean V´eronis</author>
</authors>
<title>Nuage de mots d’aujourd’hui.</title>
<date>2005</date>
<note>http://aixtal.blogspot.com/2005/07/ lexique-nuage-de-mots-daujourdhui. html. [Online; accessed 31-January-2006].</note>
<marker>V´eronis, 2005</marker>
<rawString>Jean V´eronis. 2005. Nuage de mots d’aujourd’hui. http://aixtal.blogspot.com/2005/07/ lexique-nuage-de-mots-daujourdhui. html. [Online; accessed 31-January-2006].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia</author>
</authors>
<title>RSS (file format) — Wikipedia, The Free Encyclopedia.</title>
<date>2006</date>
<note>http: //en.wikipedia.org/w/index.php?title= RSS_(file_format)&amp;oldid=37472136. [Online; accessed 31-January-2006].</note>
<contexts>
<context position="6138" citStr="Wikipedia, 2006" startWordPosition="951" endWordPosition="952">representing F1 (“oncology”) and F2 (“oncologist”) share an initial substring of length 7. Moreover the terms “neuro-oncology” from F1 and “neurooncologist” from F2 contain the combining form “neuro”. Families F1 and F2 are therefore united. When terms have been conflated, we select the most frequent term as a family’s representative. 2.5 Data visualisation The results obtained are displayed as a weighted list in HTML format. Such lists, also named “heat maps” or “tag clouds” when they describe tags1 usually represent the terms and topics which appear most frequently on websites or RSS feeds (Wikipedia, 2006). They can also be used to represent any kind of word list (V´eronis, 2005). Different colours and font sizes are used depending on the word’s frequency of occurrence. We have adapted this method to visualise the list of extracted terms. Since several hundred terms may be extracted, only the terms representing a family are displayed on the weighted list. Weight is given by the cumulated frequency of all the terms belonging to the family (see Figure 1). Figure 1: Term cloud example (Corpus: BC en) Further information (terms and frequencies) is displayed thanks to tooltips (see Figure 2), using </context>
</contexts>
<marker>Wikipedia, 2006</marker>
<rawString>Wikipedia. 2006. RSS (file format) — Wikipedia, The Free Encyclopedia. http: //en.wikipedia.org/w/index.php?title= RSS_(file_format)&amp;oldid=37472136. [Online; accessed 31-January-2006].</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>