<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000275">
<title confidence="0.998686">
Interaction Grammar for the Persian Language:
Noun and Adjectival Phrases
</title>
<author confidence="0.988763">
Masood Ghayoomi Bruno Guillaume
</author>
<affiliation confidence="0.970255">
Nancy2 University LORIA - INRIA, BP 239
</affiliation>
<address confidence="0.834109">
54506 Vandoeuvre, Nancy cedex, France 54506 Vandoeuvre, Nancy cedex, France
</address>
<email confidence="0.986948">
masood29@gmail.com Bruno.Guillaume@loria.fr
</email>
<sectionHeader confidence="0.995653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994731133333333">
In this paper we propose a modelization of
the construction of Persian noun and adjec-
tival phrases in a phrase structure grammar.
This modelization uses the Interaction
Grammar (IG) formalism by taking advan-
tage of the polarities on features and tree
descriptions for the various constructions
that we studied. The proposed grammar was
implemented with a Metagrammar compiler
named XMG. A small test suite was built
and tested with a parser based on IG, called
LEOPAR. The experimental results show
that we could parse the phrases successfully,
even the most complex ones which have
various constructions in them.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993428125">
Interaction Grammar (IG) is a grammatical for-
malism which is based on the notions of polar-
ized features and tree descriptions.
Polarities express the resource sensitivity of
natural language by modeling the distinction be-
tween saturated and unsaturated syntactic con-
struction (Guillaume and Perrier, 2008).
IG focuses on the syntactic level of a natural lan-
guage. This formalism is designed in such a way
that it can be linked with a lexicon, independent
of any formalism. The notion of polarity that is at
the heart of IG will be discussed in section 2.2.
In IG, the parsing output of a sentence is an or-
dered tree where nodes represent syntactic con-
stituents described by feature structures.
What we are interested in is studying the con-
struction of constituencies of the Persian lan-
guage according to IG. Among various
constituencies in the language, we have focused
on the construction of Persian noun phrases and
adjectival phrases as the first step to build a
grammar for this language.
The current work covers only noun and adjecti-
val phrases; it is only a first step toward a full
coverage of Persian grammar. The grammar pre-
sented here could have been expressed in Tree
Adjoining Grammar (TAG) or even in Context
Free Grammar with features, but we strongly
believe that the modelization of the verbal con-
struction of Persian, which is much more com-
plex, can benefit from advanced specificities of
IG, like polarities, underspecifications and trees.
</bodyText>
<sectionHeader confidence="0.96197" genericHeader="method">
2 Previous Studies
</sectionHeader>
<subsectionHeader confidence="0.539309">
2.1 IG for French and English
</subsectionHeader>
<bodyText confidence="0.999958916666667">
The first natural language considered within IG
was French. A large coverage grammar which
covers most of the frequent constructions of
French, including coordination, has been built
(Perrier, 2007; Le Roux and Perrier, 2007).
Recently, using the fact that the French and Eng-
lish languages have many syntactic similarities,
Planul (2008) proposed an English IG built by
modifying the French one. These two grammars
were tested on the Test Suite for Natural Lan-
guage Processing (TSNLP; Oepen et al, 1996).
Both cover 85% of the sentences in the TSNLP.
</bodyText>
<subsectionHeader confidence="0.982644">
2.2 Polarity
</subsectionHeader>
<bodyText confidence="0.999930666666667">
The notion of polarity is based on the old idea of
Tesnière (1934), Jespersen (1935), and Adjuk-
iewicz (1935) that a sentence is considered as a
molecule with its words as the atoms; every word
is equipped with a valence which expresses its
capacity of interaction with other words, so that
syntactic composition appears as a chemical re-
action (Gaiffe and Perrier, 2004). Apparently, it
seems Nasr (1995) was the first to propose a
</bodyText>
<page confidence="0.982819">
107
</page>
<note confidence="0.9968635">
Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.998260672727273">
formalism that explicitly uses the polarized struc-
ture in computational linguistics. Then re-
searches such as Muskens and Krahmer (1998),
Duchier and Thater (1999), and Perrier (2000)
proposed grammatical formalisms in which po-
larity is also explicitly used. However, Categorial
Grammar was the first grammatical formalism
that exploited implicitly the idea of polarity
(Lambek, 1958). Recently, Kahane (2006)
showed that well-known formalisms such as
CFG, TAG, HPSG, and LFG could be viewed as
polarized formalisms.
IG has highlighted the fundamental mechanism
of neutralization between polarities underlying
CG in such a way that polarities are attached to
the features used for describing constituents and
not to the constituents themselves. Polarization
of a grammatical formalism consists of adding
polarities to its syntactic structure to obtain a po-
larized formalism in which neutralization of po-
larities is used to control syntactic composition.
In this way, the resource sensitivity of syntactic
composition is made explicit (Kahane, 2004).
In trees expressing syntactic structures, nodes
that represent constituents are labeled with po-
larities with the following meanings: A constitu-
ent labeled with a negative polarity (&lt;-)
represents an expected constituent, whereas a
constituent labeled with the positive polarity (-&gt;)
represents an available resource. Both of these
polarities can unify to build a constituent which
is labeled with a saturated neutral polarity (&lt;=&gt;)
that cannot interact with any other constituents.
The composition of structures is guided by the
principle of neutralization that every positive
label must unify with a negative label, and vice
versa. Nodes that are labeled with the simple
neutral polarity (=) do not behave as consumable
resources and can be superposed with any other
nodes any number of times; they represent con-
stituents or features indifferently.
The notion of saturation in terms of polarity is
defined as a saturated structure that has all its
polarities neutral, whereas an unsaturated struc-
ture keeps positive or negative polarities which
express its ability to interact with other struc-
tures. A complete syntactic tree must be satu-
rated; that means it is without positive or
negative nodes and it can not be composed with
other structures: so all labels are associated with
the polarity of = or &lt;=&gt;.
The set of polarities {-&gt; , &lt;- , = , &lt;=&gt;} is
equipped with the operation of compositional
unification as defined in the table below (Bon-
fante et al, 2004):
</bodyText>
<equation confidence="0.6799368">
&lt;- -&gt; = &lt;=&gt;
&lt;- &lt;=&gt; &lt;-
-&gt; &lt;=&gt; -&gt;
= &lt;- -&gt; = &lt;=&gt;
&lt;=&gt; &lt;=&gt;
</equation>
<tableCaption confidence="0.996174">
Table 1. Polarity compositions on the nodes
</tableCaption>
<subsectionHeader confidence="0.994403">
2.3 Tree Description Logic in IG
</subsectionHeader>
<bodyText confidence="0.999079318181818">
Another specification of IG is that syntactic
structures can be underspecified: these structures
are trees descriptions. It is possible, for instance,
to impose that a node dominates another node
without giving the length of the domination path.
Guillaume and Perrier (2008) have defined four
kinds of relations:
- Immediate dominance relations: N &gt; M means
that M is an immediate sub-constituent of N.
- Underspecified dominance relations: N &gt;* M
means that the constituent N includes another
constituent M at a more or less deep level. (With
this kind of node relations, long distance depend-
encies and possibilities of applying modifiers
could be expressed.)
- Immediate precedence relations: N &lt;&lt; M means
that the constituent M precedes the constituent N
immediately in the linear order of the sentence.
- Underspecified precedence relations: N &lt;&lt;+ M
means that the constituent M precedes the con-
stituent N in the linear order of the sentence but
the relation between them cannot be identified.
</bodyText>
<sectionHeader confidence="0.972611" genericHeader="method">
3 The Persian Language Properties
</sectionHeader>
<bodyText confidence="0.999952714285714">
Persian is a member of the Indo-European lan-
guage family and has many features in common
with the other languages in this family in terms
of morphology, syntax, phonology, and lexicon.
Although Persian uses a modified version of the
Arabic alphabet, the two languages differ from
one another in many respects.
Persian is a null-subject language with SOV
word order in unmarked structures. However, the
word order is relatively free. The subject mood is
widely used. Verbs are inflected in the language
and they indicate tense and aspect, and agree
with subject in person and number. The language
does not make use of gender (Māhootiān, 1997).
In noun phrases, the sequence of words is around
at least one noun, namely the head word. So, the
noun phrase could be either a single unit noun, or
a sequence of other elements with a noun. The
syntax of Persian allows for having elements be-
fore a noun head _prenominal, and after the noun
head _postnominal.
</bodyText>
<page confidence="0.995947">
108
</page>
<bodyText confidence="0.999980208333333">
To make a phrase, there are some restrictions for
the elements surrounding a head to make a con-
stituent; otherwise the sequence of elements will
be ill-formed, that is, ungrammatical.
Nouns belong to an open class of words. The
noun could be a common noun, a proper noun, or
a pronoun. If this noun is not a proper noun or a
pronoun, some elements can come before it and
some after it (Māhootiān, 1997). Some of the
prenominal elements coming before a noun head
are cardinal numbers, ordinal numbers, superla-
tive adjectives, and indefinite determiners; post-
nominal elements are nouns and noun phrases,
adjectives and adjectival phrases, adjectival
clauses with conjunctions, indefinite post-
determiners, prepositional phrases, adverbs of
place and time, ordinal numbers, possessive ad-
jectives, and Ezafeh.
The syntactical structure of an adjectival phrase
is simple. It is made up of a head adjective and
elements that come before and after the head. An
adjectival phrase is a modifier of a noun. The
elements coming before a simple adjective are
adverbs of quantity and prepositional phrases.
</bodyText>
<sectionHeader confidence="0.993262" genericHeader="method">
4 Required Tools
</sectionHeader>
<subsectionHeader confidence="0.999386">
4.1 Test Suite
</subsectionHeader>
<bodyText confidence="0.999986041666667">
The test suite is a set of controlled data that is
systematically organized and documented. In this
case, the test suite is a kind of reference data dif-
ferent from data in large collections of text cor-
pora. A test suite should have the following
advantages: it should have a broad coverage on
the structural level, so you can find many struc-
tures of a language with a minimal lexicon; it
could be multilingual, so the structure of the lan-
guages could be compared; it should be a consis-
tent and highly structured linguistic annotation.
The differences between a test suite and a corpus
are: that in test suite there is a control on the
data, that the data has a systematic coverage, that
the data has a non-redundant representation, that
the data is annotated coherently, and that relevant
ungrammatical constructions are included inten-
tionally in a test suite (Oepen et al, 1996).
Since our end goal is to develop a fragment of
Persian grammar, to the best of our knowledge
no already developed test suite for our target
constructions was available; so we built a very
small test suite with only 50 examples based on a
small lexicon _only 41 entries.
</bodyText>
<subsectionHeader confidence="0.937539">
4.2 XMG
</subsectionHeader>
<bodyText confidence="0.9999866">
The XMG system is usually called a &amp;quot;meta-
grammar compiler&amp;quot; is a tool for designing large-
scale grammars for natural language. This system
has been designed and implemented in the
framework of Benoit Crabbé (2005).
XMG has provided a compact representation of
grammatical information which combines ele-
mentary fragments of information to produce a
fully redundant, strongly lexicalized grammar.
The role of such a language is to allow us to
solve two problems that arise while developing
grammars: to reach a good factorization in the
shared structures, and to control the way the
fragments are combined.
It is possible to use XMG as a tool for both tree
descriptions in IG and TAG. Since there isnot
any built-in graphical representation for IG in
XMG, LEOPAR is used to display the grammar.
LEOPAR is a parser for processing natural lan-
guages based on the IG formalism.
</bodyText>
<subsectionHeader confidence="0.992832">
4.3 LEOPAR
</subsectionHeader>
<bodyText confidence="0.999974">
LEOPAR is a tool chain constructed based on IG
(Guillaume et al, 2008). It is a parser for IG that
can be used as a standalone parser in which in-
puts are sentences and outputs are constitu-
ent trees. But it also provides a graphical user
interface which is mostly useful for testing and
debugging during the stages of developing the
grammar. The interface can be used for interac-
tive or automated parsing. LEOPAR also pro-
vides several visualization modes for the
different steps in the parsing process. Further-
more, it offers some tools to deal with lexicons:
they can be expressed in a factorized way and
they can be compiled to improve parsing effi-
ciency.
LEOPAR is based on UTF8 encoding, so it sup-
ports Persian characters. It is also modified to
take into account the right-to-left languages. For
our designed grammar we have taken the advan-
tage of this parser for IG.
</bodyText>
<sectionHeader confidence="0.995085" genericHeader="method">
5 Designing the Grammar
</sectionHeader>
<bodyText confidence="0.998423571428571">
In this section we explicitly describe the tree
construction of the Persian noun and adjectival
phrase structures which are polarized. We have
provided the elementary syntactic structures de-
rived from the existing rules in the language and
then polarized the features in the trees which are
named initial polarized tree descriptions.
</bodyText>
<page confidence="0.996499">
109
</page>
<bodyText confidence="0.999984285714286">
To be more comprehensible and clear, nodes are
indexed for addressing. More importantly, the
trees should be read from right-to-left to match
the writing system in the right-to-left language.
For clarity in the tree representations in this pa-
per, no features are given to the nodes. But while
developing the grammar with XMG, polarized
features are given to the nodes to put a control on
constructing the trees and avoid over-generating
some constructions.
There are some constructions whose tree repre-
sentations are the same but represent two differ-
ent constructions, so they could be described
from two different points of views. Such trees are
described in the sections corresponding to the
relevant constructions. Some morphophonemic
phenomena were considered at the syntactic
level, while developing our grammar. Such a
phenomenon is defined at the feature level for
the lexicon which will be described in their rele-
vant sections.
</bodyText>
<subsectionHeader confidence="0.905396">
5.1 Noun Construction
</subsectionHeader>
<bodyText confidence="0.999963333333333">
A noun phrase could consist of several elements
or only one head noun element. If the element of
a noun phrase (N1) is a noun, it is anchored to a
lexicon item (N2) which could be a common
noun, or a proper noun. The symbol ◊ has been
used for the nodes that are anchored to a lexical
</bodyText>
<equation confidence="0.9005775">
item. -&gt; N1
= N2◊
</equation>
<bodyText confidence="0.999819428571429">
The tree of a common noun and a proper noun
are the same, but features should be given to the
tree to make a distinction between the anchored
nouns. With the help of features, we can make
some restrictions to avoid some constructions.
Features and their values are not fully discussed
here.
</bodyText>
<subsectionHeader confidence="0.995756">
5.2 Pronoun Construction
</subsectionHeader>
<bodyText confidence="0.998725">
A pronoun can appear both in subject and object
positions to make a noun. In this construction,
node N3 is anchored to a pronoun:
</bodyText>
<equation confidence="0.6348525">
-&gt; N3
= PRON◊
</equation>
<bodyText confidence="0.999961142857143">
A pronoun cannot be used in all constructions.
For example, N3 cannot be plugged into N5 in a
determiner construction because a determiner
could not come before a pronoun. To avoid this
construction, some features have been used for
the node N5 to stop the unification with some N
nodes like N3.
</bodyText>
<subsectionHeader confidence="0.970411">
5.3 Determiner Construction
</subsectionHeader>
<bodyText confidence="0.999978933333334">
In Persian a determiner comes before a common
noun or a noun phrase, and not a proper noun or
a pronoun.
Persian does not benefit from the definite deter-
miner, but there are two kinds of indefinite de-
terminers: one comes before a noun as a separate
lexical item and the other one comes after a noun
(post-determiner) which is joined to the end of
the noun as described below:
If the determiner comes before a noun, there
must be a tree in which a Det node is anchored to
a lexicon item that is a determiner and which
comes immediately before a noun. In other
words, some lexical items which are determiners
could attach to this node:
</bodyText>
<equation confidence="0.977438">
-&gt; N4
`- N5 = Det◊
</equation>
<bodyText confidence="0.99791675">
If the determiner comes after a noun (i.e. if it is a
post-determiner), then it can be joined to the end
of a noun. The post-determiner (P-Det) and the
preceding noun (N7), make a noun (N6):
</bodyText>
<equation confidence="0.873643">
-&gt; N6
= P-Det◊ `- N7
</equation>
<bodyText confidence="0.999946384615385">
The post-determiner has three different written
forms: ‘ﯼ’ /i/, ‘ﯽﻳ’ /yi/, and ‘ﯼا’ /?i/. The reason
to have them is phonological. In our formalism
we have considered this phonological phenome-
non at a syntactic level.
If the post-determiner construction is used after
an adjective in the linguistic data, it does not be-
long to the adjective (since the adjective is only
the modifier of the noun), but it belongs to the
noun. According to the phonological context and
the final sound of the adjective, the post-
determiner that belongs to the noun changes and
takes one of the written forms.
</bodyText>
<subsectionHeader confidence="0.972374">
5.4 Ezafeh Construction
</subsectionHeader>
<bodyText confidence="0.999756333333333">
One of the properties of Persian is that usually
short vowels are not written. In this language, the
Ezafeh construction is represented by the short
vowel ‘ِ-’ /e/ after consonants or ‘ِﯼ’ /ye/ after
vowels at the end of a noun or an adjective.
Here we try to give a formal representation of
such construction that is described from a purely
syntactical point of view. Ezafeh (Ez) appears on
(Kahnemuyipour, 2002): a noun before another
noun (attributive); a noun before an adjective; a
noun before a possessor (noun or pronoun); an
adjective before another adjective; a pronoun
</bodyText>
<page confidence="0.99507">
110
</page>
<bodyText confidence="0.999697166666667">
before an adjective; first names before last
names; a combination of the above.
Note that Ezafeh only appears on a noun when it
is modified. In other words, it does not appear on
a bare noun (e.g. ‘YVA’ /ketab/ &apos;book&apos;). In Ezafeh
construction, the node Ez is anchored to the
Ezafeh lexeme. The below tree could make a
noun phrase (N8) with Ezafeh construction, in
which a common noun or a proper noun on N9 is
followed by an Ezafeh (Ez) and another common
noun, proper noun, pronoun or another noun
phrase plugs to the node N10:
</bodyText>
<equation confidence="0.868499">
-&apos; N8
`- N10 = N
= EzO `- N9
</equation>
<bodyText confidence="0.9999414">
The below tree could make a noun phrase (N11)
with Ezafeh construction in which a common
noun or a proper noun on N12 is modified by an
adjectival phrase on node ADJ1. Ezafeh has to be
used after the noun to link it to the adjective:
</bodyText>
<equation confidence="0.901188">
-&apos; N11
`- ADJ1 = N
= EzO `- N12
</equation>
<bodyText confidence="0.998164">
Based on the final sound of the word which is
just before Ezafeh, there are two written forms
for Ezafeh, depending on whether the noun ends
with a consonant or a vowel.
As we have already said, Ezafeh contraction
could be used for an adjective (ADJ1). After this
construction, another adjectival phrase (ADJ3
and ADJ4) with Ezafeh could appear too. It
should be mentioned that ADJ4 is plugged into
an adjective without Ezafeh construction:
</bodyText>
<equation confidence="0.904513333333333">
-&apos;ADJ2
`-ADJ4 =ADJ
= EzO `-ADJ3
</equation>
<subsectionHeader confidence="0.949561">
5.5 Possessive Construction
</subsectionHeader>
<bodyText confidence="0.999848931034483">
In Persian there are two different constructions
for possessive. One is a separate lexical item as a
common noun, a proper noun, or a pronoun. The
second is a possessive pronoun that is a kind of
suffix which attaches to the end of the noun. In
the first construction, a noun with an Ezafeh con-
struction is used and then a common noun, a
proper noun, or a pronoun as a separate lexical
item follows. In the latter construction, there is a
common noun and the joined possessive pro-
noun. The two constructions are discussed here:
In section 5.4 we described Ezafeh construction
(N8). This tree could be used for possessive con-
struction, too. In this tree an Ezafeh is used after
a common noun and Ezafeh is followed by either
a common noun or a proper noun. A pronoun
could not be used in N9 with Ezafeh. Such a kind
of construction is avoided by defining features.
The possessive construction as a suffix could
come after both a noun and an adjective. The
general property of the joined possessive pro-
nouns is that there is an agreement between the
subject and the possessive pronoun in terms of
number and person, no matter whether it is used
after a noun or an adjective.
If the joined possessive pronoun (S-P) is used
after a noun (N14), we would have the tree N13
in which the possessive pronoun is anchored to
the suffix (S-P):
</bodyText>
<equation confidence="0.6064345">
-&apos; N13
= S-PO `- N14
</equation>
<bodyText confidence="0.9999845">
Based on the phonological reasons and consider-
ing Persian syllables, as was discussed previ-
ously in section 5.3, this suffix would have
different written forms based on the phonological
context it appears in: after a consonant, the vowel
/V, or any other vowels except /W. For adjec-
tives, there is no suffix possessive pronoun. In
the linguistic data, this pronoun could appear
after the adjective. But the point is that the adjec-
tive is only the modifier of the noun. This pos-
sessive pronoun, in fact, belongs to the noun and
not the adjective, but based on the phonological
rules (i.e. the final sound of the adjective) only
one of the written forms would appear after that.
</bodyText>
<subsectionHeader confidence="0.996318">
5.6 Count noun Construction
</subsectionHeader>
<bodyText confidence="0.891905714285714">
There are some nouns in Persian referred to as
count nouns which have collocational relations
with the head noun that is counted. So, in such a
construction, the node C-N is anchored to a lexi-
cal item that is a count noun:
-&apos; N15
`- N16 = C-NO
</bodyText>
<subsectionHeader confidence="0.983134">
5.7 Object Construction
</subsectionHeader>
<bodyText confidence="0.999641">
In Persian, a noun phrase can appear both in sub-
ject and object positions. If the noun phrase ap-
pears in a subject position, it does not require any
indicator. But if the noun phrase appears in the
direct object position (N18), the marker ‘►-)’ /rV
is used to indicate that this noun phrase (N17) is
a direct object. We call this marker ‘Object Indi-
</bodyText>
<page confidence="0.99737">
111
</page>
<bodyText confidence="0.9138322">
cator’ (O-I) so the node is anchored to the object
maker. The representation of the tree for the ob-
ject construction (N17) is the followings:
-&apos; N17
= O-I◊ `- N18
</bodyText>
<subsectionHeader confidence="0.993568">
5.7 Conjunction Construction
</subsectionHeader>
<bodyText confidence="0.999888428571429">
In Persian, there is a construction to modify the
preceding noun phrase with an adjective clause
which we have named the Conjunction construc-
tion. In such a construction, there are a noun
phrase (N20), a conjunctor (Conj), and a clause
to modify the noun phrase (S1). In the tree, the
conjunction node is anchored to a conjunctor:
</bodyText>
<equation confidence="0.947389666666667">
-&apos; N19
= S `- N20
`- S1 = Conj◊
</equation>
<subsectionHeader confidence="0.97382">
5.8 Adjective Constructions
</subsectionHeader>
<bodyText confidence="0.999851428571429">
There are two classes of adjectives: the first class
comes before a noun head, the second one after.
There are three kinds of adjectives in the first
class which can be differentiated from each other
with the help of features. The first class of adjec-
tives contains superlative adjectives, cardinal
numbers, and ordinal numbers that modify a
noun, a count noun, or a noun phrase. Usually,
the adjectives coming before a noun phrase are in
complementary distribution; i.e. the presence of
one means the absence of the two others.
The following tree represents the adjective con-
struction coming before a noun (N22). The ad-
jective ADJ5 is anchored to a lexical item:
</bodyText>
<equation confidence="0.692887">
-&apos; N21
`- N22 =ADJ5◊
</equation>
<bodyText confidence="0.9999059">
The second class of adjectives (which comes af-
ter a noun) contains mostly simple adjectives,
ordinal numbers and comparative adjectives.
As we have already described tree N11 in section
5.4, to have an adjective after a noun the noun
must have an Ezafeh construction. So, this tree
represents a construction where an adjective
(ADJ1) comes after a noun (N12).
To saturate ADJ1, the tree ADJ6 is required
which is anchored to an adjective lexical item:
</bodyText>
<equation confidence="0.4895085">
-&apos;ADJ6
=ADJ7◊
</equation>
<bodyText confidence="0.997442428571429">
In some adjective constructions, a prepositional
phrase could be used which comes before or after
some adjective constituents. With the help of
some features, we have made restrictions on the
kind of adjective and the preposition lexical item
that could plug into this node.
If a preposition is used before the adjective
</bodyText>
<equation confidence="0.856471875">
(ADJ9), it is a comparative adjective:
-&apos;ADJ8
=ADJ9◊ `- P1
If the preposition is used after the adjective
(ADJ11), it is either a comparative or a simple
adjective:
-&apos;ADJ10
`- P2 =ADJ11◊
</equation>
<subsectionHeader confidence="0.987712">
5.9 Preposition Construction
</subsectionHeader>
<bodyText confidence="0.999921333333333">
In Persian a common noun, a proper noun, a pro-
noun, or a noun phrase could come after a
preposition (P4) to make a prepositional phrase
</bodyText>
<equation confidence="0.9849455">
(P3): -&apos; P3
`- N23 = P4◊
</equation>
<bodyText confidence="0.55354425">
If the preposition construction is used in an ad-
jective construction, only some specific preposi-
tions can be used. Once again, the restrictions are
encoded with features.
</bodyText>
<sectionHeader confidence="0.949516" genericHeader="evaluation">
6 Implementation and Results
</sectionHeader>
<bodyText confidence="0.999840153846154">
So far we have explicitly described the noun and
adjectival phrase constructions in Persian accord-
ing to the constituency rules that are extracted
from the linguistic data. These rules are repre-
sented by polarized trees. Since we wanted to
study the noun and adjectival phrase structures,
they required data. We have gathered this data
for our purpose as a test suite.
To design IG for the constructions that were de-
scribed, we have used XMG as the basic tool to
have the initial tree descriptions. While describ-
ing the trees in XMG, several operators will be
used to polarizing features. The categories of the
nodes are considered as features, so the nodes are
polarized. Using XMG, we have done factoriza-
tions and defined classes for general trees. Three
factorized general trees are defined in our XMG
coding. We have also defined 17 classes for cod-
ing of trees to represent the constructions as de-
scribed.
The output of XMG is given to LEOPAR to dis-
play the graphical representations of the tree
structures and also parse the data. The test suite
is given to LEOPAR for parsing.
Having the developed trees and the test suite, we
successfully parsed all available phrases, from
</bodyText>
<page confidence="0.994442">
112
</page>
<bodyText confidence="0.99985125">
the simplest to the most complex ones that had a
variety of constructions in them. Example 1 has a
simple construction, example 2 is of medium
complexity, and example 3 is the most complex:
</bodyText>
<reference confidence="0.961585">
1. لﺎﻴﻧاد بﺎﺘﮐ
/ketāb/ (/e/) /dāniyāl/
book (Ez) Daniel
‘the book of Daniel / Daniel’s book’
2. وا بﺎﺘﮐ ﻦﻴﻟوا رﺎﺸﺘﻧا ﺎﺑ نﺎﻣﺰﻤه
/hamzamān/ /bā/ /entešār/ (/e/) /avvalin/
in coincidence with publishing (Ez) the first
/ketāb/ (/e/) /?u/
book (Ez) his/her
</reference>
<bodyText confidence="0.98276176923077">
‘in coincidence with the publishing of his/her
first book’
ﻪﮐ ار لﺎﻴﻧاد ﻢﻬﻣ ﺪیﺪﺟ بﺎﺘﮐ ﺪﻠﺟ ود نﺁ
/ān/ /do/ /jeld/ /ketāb/ (/e/) /jadid/ (/e/)
that two volume book (Ez) new (Ez)
/mohem/ (/e/) /dāniyal/ /rā/ /ke/
important (Ez) Daniel POBJ that
‘the two new important book volumes of Daniel
that’
We know from section 5.4 that Ezafeh is pro-
nounced but not written. Since the anchored
nodes require a lexical item, we put the word
‘ﻪﻓﺎﺿا’ /ezāfe/ ‘Ezafeh’ in the lexicon to have a
real representation of Ezafeh. Also, wherever
Ezafeh is used in the test suite, this word is re-
placed.
As a sample, we give a brief description of pars-
ing the phrases 1 and 2 with LEOPAR and dis-
play the outputs.
In our test suite, phrase 1 is found as
‘لﺎﻴﻧاد ﻪﻓﺎﺿا بﺎﺘﮐ’. In this phrase, the common
noun /ketāb/ is followed by a proper noun
/dāniyāl/ with Ezafeh. The possessive construc-
tion (N8) would be used to parse this phrase.
In parsing this phrase, firstly LEOPAR reads the
words and matches them with the lexical items
available in the lexicon to identify their catego-
ries. Then it plugs these words into the nodes in
the trees that have the same syntactic category
and have an anchored node. Finally, it gives the
parsed graphical representation of the phrase.
For this phrase, the Ezafeh construction tree is
used in such a way that N2 is anchored to the
word /ketāb/ and N1 plugs into N9 to saturate it.
Then, N2 is again anchored to the word /dāniyāl/
and N1 plugs in to saturate N10. The final parsed
phrase is such that all internal nodes are saturated
and have neutral polarity, as shown in Figure 1.
As another example, consider phrase 2, which is
</bodyText>
<figureCaption confidence="0.9246925">
Figure 1: Parsing the phrase ‘لﺎﻴﻧاد بﺎﺘﮐ’
with LEOPAR
Figure 2: Parsing the phrase‘وا بﺎﺘﮐ ﻦﻴﻟوا رﺎﺸﺘﻧا ﺎﺑ نﺎﻣﺰﻤه’
with LEOPAR
</figureCaption>
<bodyText confidence="0.975117">
found as ‘وا ﻪﻓﺎﺿا بﺎﺘﮐ ﻦﻴﻟوا ﻪﻓﺎﺿا رﺎﺸﺘﻧا ﺎﺑ نﺎﻣﺰﻤه’ in
our test-suite. Since some various constructions
are used to build this phrase, we could say that it
</bodyText>
<page confidence="0.997436">
113
</page>
<bodyText confidence="0.9999825625">
is a complex phrase. Firstly it takes the adjective
phrase construction (ADJ10). P3, the preposi-
tional phrase, plugs into P2. Since a noun or a
noun phrase could be used after a preposition
(N23), the Ezafeh construction (N8) that takes
the noun plugs to this node. Another Ezafeh con-
struction (N8) will be plugged into N10. The ad-
jective construction (ADJ5) for ordinal numbers
as the modifier of a noun (N22) could be used
while a noun (N1) would plug into N22. Finally,
the pronoun (N3) plugs into the unsaturated noun
position in the second Ezafeh construction. Pars-
ing the phrase with LEOPAR, the result has all
internal nodes saturated and neutralized, and no
polarities on the nodes are left unsaturated, as
shown in Figure 2.
</bodyText>
<sectionHeader confidence="0.993077" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99993065">
In our research we have used IG to represent the
construction of Persian noun and adjectival
phrases in trees. XMG was used to represent the
constructions using factorization and inherited
hierarchy relations. Then, with the help of XMG,
we defined IG by taking advantage of polarities
on the features and tree descriptions for the vari-
ous constructions that are introduced. Then, we
used LEOPAR for the graphical representations
of the trees and parsing the phrases. Finally, we
applied our test suite to the parser to check
whether we had the correct parsing and represen-
tation of the phrases. The experimental results
showed that we could parse the phrases success-
fully, including the most complex ones, which
have various constructions in them.
In the next step of our research, we would like to
study the construction of prepositions and, more
importantly, verbs in depth to make it possible to
parse at the sentence level.
</bodyText>
<sectionHeader confidence="0.999269" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999134524590164">
Adjukiewcz K., 1935. “Die syntaktiche konnexität”
Studia Philadelphica 1, pp. 1-27.
Bonfante G. and B. Guillaume and G. Perrier, 2004.
“Polarization and abstraction of grammatical for-
malism as methods for lexical disambiguation” In
Proc.s of 20th Int. Conf. on CL, Genève.
Candito, M. H., 1996. ‘A principle-based hierarchical
representa-tion of LTAGs’. COLING-96.
Crabbé, B., 2005. “Grammatical development with
XMG”. LACL 05.
Duchier and Thater, 1999. “Parsing with tree descrip-
tions: A constraint based approach” In Proc.s of
NLU and Logic Programming, New Mexico.
Gaiffe, B. and G. Perrier, 2004. ‘Tools for parsing
natural language’ ESSLLI 2004.
Guillaume B. and G. Perrier, 2008. “Interaction
Grammars” INRIA Research Report 6621:
http://hal.inria.fr/inria-00288376/
Guillaume B. and J. Le Roux and J. Marchand and G.
Perrier and K. Fort and J. Planul, 2008, “A Tool-
chain for Grammarians” CoLING 08, Manchester.
Jesperson , O., 1935. Analytic Syntax. Allen and
Uwin, London.
Kahane, S., 2004. “Grammaries d’unification polari-
sées” In 11iéme Conf. sur le TAL, Fés, Maroc.
Kahane, S., 2006. “Polarized unification grammars”.
In Proce.s of 21st Int. Conf. on CL and 44th An-
nual Meeting of the ACL. Sydney, Australia.
Kahnemuyipour, A., 2000. &amp;quot;Persian Ezafe construc-
tion revisited: Evidence for modifier phrase,&amp;quot; An-
nual Conf. of the Canadian Linguistic Association.
Lambek, J., 1958. &amp;quot;The mathematics of sentence
structure&amp;quot;, The American Mathematical Monthly
65: 154–170.
Leopar: a parser for Interaction Grammar
http://leopar.loria.fr/
Le Roux, J. and G. Perrier, 2007. “Modélisation de la
coordination dans les Grammaires d’Interaction”,
Traitement Automatique des Langues (TAL 47-3)
Māhootiān, Sh, 1997. Persian. Routledge.
Muskens and Krahmer, 1998. “Talking about trees
and truth conditions”. In Logical Aspects of CL,
Grenoble, France, Dec 1998.
Nasr A., 1995. “A formalism and a parser for lexical-
ized dependency grammars” In Proce.s of 4th Int.
Workshop on Parsing Technologies, Prague.
Oepen, S. and K. Netter and J. Klein, 1996. “TSNLP-
Test suites for natural language processing”. In
Linguistic Database, CSLI Lecture Notes. Center
for the Study of Language and information.
Perrier, G., 2000. “Interaction grammar” Coling 2000.
Perrier, G., 2007. &amp;quot;A French Interaction Grammar&amp;quot;,
RANLP 2007, Borovets Bulgarie.
Planul, J., 2008. Construction d&apos;une Grammaire d&apos;In-
teraction pour l&apos;anglais, Master thesis, Université
Nancy 2, France.
Tesnière L., 1934. “Comment construire une syntaxe”
Bulletin de la Faculté des Lettres de Strasbourg 7-
12iéme. pp. 219-229.
XMG Documentation
http/wiki.loria.fr/wiki/XMG/Documentation
</reference>
<page confidence="0.998399">
114
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.766859">
<title confidence="0.9989905">Interaction Grammar for the Persian Noun and Adjectival Phrases</title>
<author confidence="0.999697">Masood Ghayoomi Bruno Guillaume</author>
<affiliation confidence="0.852411">University - INRIA, BP 239</affiliation>
<address confidence="0.982022">54506 Vandoeuvre, Nancy cedex, France 54506 Vandoeuvre, Nancy cedex, France</address>
<email confidence="0.943213">masood29@gmail.comBruno.Guillaume@loria.fr</email>
<abstract confidence="0.9960079375">In this paper we propose a modelization of the construction of Persian noun and adjectival phrases in a phrase structure grammar. This modelization uses the Interaction Grammar (IG) formalism by taking advantage of the polarities on features and tree descriptions for the various constructions that we studied. The proposed grammar was implemented with a Metagrammar compiler named XMG. A small test suite was built and tested with a parser based on IG, called LEOPAR. The experimental results show that we could parse the phrases successfully, even the most complex ones which have various constructions in them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>ketāb/ (/e/) /dāniyāl/ book (Ez) Daniel ‘the book of Daniel / Daniel’s book’ 2. وا بﺎﺘﮐ ﻦﻴﻟوا رﺎﺸﺘﻧا ﺎﺑ نﺎﻣﺰﻤه /hamzamān/ /bā/ /entešār/ (/e/) /avvalin/ in coincidence with publishing (Ez) the first /ketāb/ (/e/) /?u/ book (Ez) his/her</title>
<marker></marker>
<rawString>1. لﺎﻴﻧاد بﺎﺘﮐ /ketāb/ (/e/) /dāniyāl/ book (Ez) Daniel ‘the book of Daniel / Daniel’s book’ 2. وا بﺎﺘﮐ ﻦﻴﻟوا رﺎﺸﺘﻧا ﺎﺑ نﺎﻣﺰﻤه /hamzamān/ /bā/ /entešār/ (/e/) /avvalin/ in coincidence with publishing (Ez) the first /ketāb/ (/e/) /?u/ book (Ez) his/her</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Adjukiewcz</author>
</authors>
<title>Die syntaktiche konnexität”</title>
<date>1935</date>
<journal>Studia Philadelphica</journal>
<volume>1</volume>
<pages>1--27</pages>
<marker>Adjukiewcz, 1935</marker>
<rawString>Adjukiewcz K., 1935. “Die syntaktiche konnexität” Studia Philadelphica 1, pp. 1-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bonfante</author>
<author>B Guillaume</author>
<author>G Perrier</author>
</authors>
<title>Polarization and abstraction of grammatical formalism as methods for lexical disambiguation”</title>
<date>2004</date>
<booktitle>In Proc.s of 20th Int. Conf. on CL,</booktitle>
<location>Genève.</location>
<contexts>
<context position="6071" citStr="Bonfante et al, 2004" startWordPosition="959" endWordPosition="963">erently. The notion of saturation in terms of polarity is defined as a saturated structure that has all its polarities neutral, whereas an unsaturated structure keeps positive or negative polarities which express its ability to interact with other structures. A complete syntactic tree must be saturated; that means it is without positive or negative nodes and it can not be composed with other structures: so all labels are associated with the polarity of = or &lt;=&gt;. The set of polarities {-&gt; , &lt;- , = , &lt;=&gt;} is equipped with the operation of compositional unification as defined in the table below (Bonfante et al, 2004): &lt;- -&gt; = &lt;=&gt; &lt;- &lt;=&gt; &lt;- -&gt; &lt;=&gt; -&gt; = &lt;- -&gt; = &lt;=&gt; &lt;=&gt; &lt;=&gt; Table 1. Polarity compositions on the nodes 2.3 Tree Description Logic in IG Another specification of IG is that syntactic structures can be underspecified: these structures are trees descriptions. It is possible, for instance, to impose that a node dominates another node without giving the length of the domination path. Guillaume and Perrier (2008) have defined four kinds of relations: - Immediate dominance relations: N &gt; M means that M is an immediate sub-constituent of N. - Underspecified dominance relations: N &gt;* M means that the cons</context>
</contexts>
<marker>Bonfante, Guillaume, Perrier, 2004</marker>
<rawString>Bonfante G. and B. Guillaume and G. Perrier, 2004. “Polarization and abstraction of grammatical formalism as methods for lexical disambiguation” In Proc.s of 20th Int. Conf. on CL, Genève.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Candito</author>
</authors>
<title>A principle-based hierarchical representa-tion of LTAGs’.</title>
<date>1996</date>
<pages>96</pages>
<marker>Candito, 1996</marker>
<rawString>Candito, M. H., 1996. ‘A principle-based hierarchical representa-tion of LTAGs’. COLING-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Crabbé</author>
</authors>
<title>Grammatical development with XMG”.</title>
<date>2005</date>
<journal>LACL</journal>
<volume>05</volume>
<contexts>
<context position="10687" citStr="Crabbé (2005)" startWordPosition="1743" endWordPosition="1744">ed coherently, and that relevant ungrammatical constructions are included intentionally in a test suite (Oepen et al, 1996). Since our end goal is to develop a fragment of Persian grammar, to the best of our knowledge no already developed test suite for our target constructions was available; so we built a very small test suite with only 50 examples based on a small lexicon _only 41 entries. 4.2 XMG The XMG system is usually called a &amp;quot;metagrammar compiler&amp;quot; is a tool for designing largescale grammars for natural language. This system has been designed and implemented in the framework of Benoit Crabbé (2005). XMG has provided a compact representation of grammatical information which combines elementary fragments of information to produce a fully redundant, strongly lexicalized grammar. The role of such a language is to allow us to solve two problems that arise while developing grammars: to reach a good factorization in the shared structures, and to control the way the fragments are combined. It is possible to use XMG as a tool for both tree descriptions in IG and TAG. Since there isnot any built-in graphical representation for IG in XMG, LEOPAR is used to display the grammar. LEOPAR is a parser f</context>
</contexts>
<marker>Crabbé, 2005</marker>
<rawString>Crabbé, B., 2005. “Grammatical development with XMG”. LACL 05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duchier</author>
<author>Thater</author>
</authors>
<title>Parsing with tree descriptions: A constraint based approach”</title>
<date>1999</date>
<booktitle>In Proc.s of NLU and Logic Programming,</booktitle>
<location>New Mexico.</location>
<contexts>
<context position="3722" citStr="Duchier and Thater (1999)" startWordPosition="594" endWordPosition="597">ce is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguistics. Then researches such as Muskens and Krahmer (1998), Duchier and Thater (1999), and Perrier (2000) proposed grammatical formalisms in which polarity is also explicitly used. However, Categorial Grammar was the first grammatical formalism that exploited implicitly the idea of polarity (Lambek, 1958). Recently, Kahane (2006) showed that well-known formalisms such as CFG, TAG, HPSG, and LFG could be viewed as polarized formalisms. IG has highlighted the fundamental mechanism of neutralization between polarities underlying CG in such a way that polarities are attached to the features used for describing constituents and not to the constituents themselves. Polarization of a </context>
</contexts>
<marker>Duchier, Thater, 1999</marker>
<rawString>Duchier and Thater, 1999. “Parsing with tree descriptions: A constraint based approach” In Proc.s of NLU and Logic Programming, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gaiffe</author>
<author>G Perrier</author>
</authors>
<title>Tools for parsing natural language’ ESSLLI</title>
<date>2004</date>
<contexts>
<context position="3344" citStr="Gaiffe and Perrier, 2004" startWordPosition="536" endWordPosition="539">c similarities, Planul (2008) proposed an English IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguistics. Then researches such as Muskens and Krahmer (1998), Duchier and Thater (1999), and Perrier (2000) proposed grammatical formalisms in which polarity is also explicitly used. However, Categorial Grammar was the first grammatical formalism that exploited implicitly the idea of polarity (Lambek, 1958).</context>
</contexts>
<marker>Gaiffe, Perrier, 2004</marker>
<rawString>Gaiffe, B. and G. Perrier, 2004. ‘Tools for parsing natural language’ ESSLLI 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Guillaume</author>
<author>G Perrier</author>
</authors>
<date>2008</date>
<journal>Interaction Grammars” INRIA Research Report</journal>
<volume>6621</volume>
<pages>00288376</pages>
<contexts>
<context position="1209" citStr="Guillaume and Perrier, 2008" startWordPosition="175" endWordPosition="178">ied. The proposed grammar was implemented with a Metagrammar compiler named XMG. A small test suite was built and tested with a parser based on IG, called LEOPAR. The experimental results show that we could parse the phrases successfully, even the most complex ones which have various constructions in them. 1 Introduction Interaction Grammar (IG) is a grammatical formalism which is based on the notions of polarized features and tree descriptions. Polarities express the resource sensitivity of natural language by modeling the distinction between saturated and unsaturated syntactic construction (Guillaume and Perrier, 2008). IG focuses on the syntactic level of a natural language. This formalism is designed in such a way that it can be linked with a lexicon, independent of any formalism. The notion of polarity that is at the heart of IG will be discussed in section 2.2. In IG, the parsing output of a sentence is an ordered tree where nodes represent syntactic constituents described by feature structures. What we are interested in is studying the construction of constituencies of the Persian language according to IG. Among various constituencies in the language, we have focused on the construction of Persian noun</context>
<context position="6478" citStr="Guillaume and Perrier (2008)" startWordPosition="1031" endWordPosition="1034">tures: so all labels are associated with the polarity of = or &lt;=&gt;. The set of polarities {-&gt; , &lt;- , = , &lt;=&gt;} is equipped with the operation of compositional unification as defined in the table below (Bonfante et al, 2004): &lt;- -&gt; = &lt;=&gt; &lt;- &lt;=&gt; &lt;- -&gt; &lt;=&gt; -&gt; = &lt;- -&gt; = &lt;=&gt; &lt;=&gt; &lt;=&gt; Table 1. Polarity compositions on the nodes 2.3 Tree Description Logic in IG Another specification of IG is that syntactic structures can be underspecified: these structures are trees descriptions. It is possible, for instance, to impose that a node dominates another node without giving the length of the domination path. Guillaume and Perrier (2008) have defined four kinds of relations: - Immediate dominance relations: N &gt; M means that M is an immediate sub-constituent of N. - Underspecified dominance relations: N &gt;* M means that the constituent N includes another constituent M at a more or less deep level. (With this kind of node relations, long distance dependencies and possibilities of applying modifiers could be expressed.) - Immediate precedence relations: N &lt;&lt; M means that the constituent M precedes the constituent N immediately in the linear order of the sentence. - Underspecified precedence relations: N &lt;&lt;+ M means that the const</context>
</contexts>
<marker>Guillaume, Perrier, 2008</marker>
<rawString>Guillaume B. and G. Perrier, 2008. “Interaction Grammars” INRIA Research Report 6621: http://hal.inria.fr/inria-00288376/</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Guillaume</author>
<author>J Le Roux</author>
<author>J Marchand</author>
<author>G Perrier</author>
<author>K Fort</author>
<author>J Planul</author>
</authors>
<date>2008</date>
<journal>A Toolchain for Grammarians” CoLING</journal>
<volume>08</volume>
<location>Manchester.</location>
<marker>Guillaume, Le Roux, Marchand, Perrier, Fort, Planul, 2008</marker>
<rawString>Guillaume B. and J. Le Roux and J. Marchand and G. Perrier and K. Fort and J. Planul, 2008, “A Toolchain for Grammarians” CoLING 08, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesperson</author>
</authors>
<title>Analytic Syntax. Allen and Uwin,</title>
<date>1935</date>
<location>London.</location>
<marker>Jesperson, 1935</marker>
<rawString>Jesperson , O., 1935. Analytic Syntax. Allen and Uwin, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kahane</author>
</authors>
<title>Grammaries d’unification polarisées”</title>
<date>2004</date>
<booktitle>In 11iéme Conf. sur le TAL, Fés, Maroc.</booktitle>
<contexts>
<context position="4607" citStr="Kahane, 2004" startWordPosition="725" endWordPosition="726">rmalisms such as CFG, TAG, HPSG, and LFG could be viewed as polarized formalisms. IG has highlighted the fundamental mechanism of neutralization between polarities underlying CG in such a way that polarities are attached to the features used for describing constituents and not to the constituents themselves. Polarization of a grammatical formalism consists of adding polarities to its syntactic structure to obtain a polarized formalism in which neutralization of polarities is used to control syntactic composition. In this way, the resource sensitivity of syntactic composition is made explicit (Kahane, 2004). In trees expressing syntactic structures, nodes that represent constituents are labeled with polarities with the following meanings: A constituent labeled with a negative polarity (&lt;-) represents an expected constituent, whereas a constituent labeled with the positive polarity (-&gt;) represents an available resource. Both of these polarities can unify to build a constituent which is labeled with a saturated neutral polarity (&lt;=&gt;) that cannot interact with any other constituents. The composition of structures is guided by the principle of neutralization that every positive label must unify with</context>
</contexts>
<marker>Kahane, 2004</marker>
<rawString>Kahane, S., 2004. “Grammaries d’unification polarisées” In 11iéme Conf. sur le TAL, Fés, Maroc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kahane</author>
</authors>
<title>Polarized unification grammars”.</title>
<date>2006</date>
<booktitle>In Proce.s of 21st Int. Conf. on CL and 44th Annual Meeting of the ACL.</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="3968" citStr="Kahane (2006)" startWordPosition="630" endWordPosition="631">y, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguistics. Then researches such as Muskens and Krahmer (1998), Duchier and Thater (1999), and Perrier (2000) proposed grammatical formalisms in which polarity is also explicitly used. However, Categorial Grammar was the first grammatical formalism that exploited implicitly the idea of polarity (Lambek, 1958). Recently, Kahane (2006) showed that well-known formalisms such as CFG, TAG, HPSG, and LFG could be viewed as polarized formalisms. IG has highlighted the fundamental mechanism of neutralization between polarities underlying CG in such a way that polarities are attached to the features used for describing constituents and not to the constituents themselves. Polarization of a grammatical formalism consists of adding polarities to its syntactic structure to obtain a polarized formalism in which neutralization of polarities is used to control syntactic composition. In this way, the resource sensitivity of syntactic comp</context>
</contexts>
<marker>Kahane, 2006</marker>
<rawString>Kahane, S., 2006. “Polarized unification grammars”. In Proce.s of 21st Int. Conf. on CL and 44th Annual Meeting of the ACL. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kahnemuyipour</author>
</authors>
<title>Persian Ezafe construction revisited: Evidence for modifier phrase,&amp;quot; Annual Conf. of the Canadian Linguistic Association.</title>
<date>2000</date>
<marker>Kahnemuyipour, 2000</marker>
<rawString>Kahnemuyipour, A., 2000. &amp;quot;Persian Ezafe construction revisited: Evidence for modifier phrase,&amp;quot; Annual Conf. of the Canadian Linguistic Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>The mathematics of sentence structure&amp;quot;,</title>
<date>1958</date>
<journal>The American Mathematical Monthly</journal>
<volume>65</volume>
<pages>154--170</pages>
<contexts>
<context position="3943" citStr="Lambek, 1958" startWordPosition="627" endWordPosition="628">Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguistics. Then researches such as Muskens and Krahmer (1998), Duchier and Thater (1999), and Perrier (2000) proposed grammatical formalisms in which polarity is also explicitly used. However, Categorial Grammar was the first grammatical formalism that exploited implicitly the idea of polarity (Lambek, 1958). Recently, Kahane (2006) showed that well-known formalisms such as CFG, TAG, HPSG, and LFG could be viewed as polarized formalisms. IG has highlighted the fundamental mechanism of neutralization between polarities underlying CG in such a way that polarities are attached to the features used for describing constituents and not to the constituents themselves. Polarization of a grammatical formalism consists of adding polarities to its syntactic structure to obtain a polarized formalism in which neutralization of polarities is used to control syntactic composition. In this way, the resource sens</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Lambek, J., 1958. &amp;quot;The mathematics of sentence structure&amp;quot;, The American Mathematical Monthly 65: 154–170.</rawString>
</citation>
<citation valid="false">
<title>Leopar: a parser for Interaction Grammar http://leopar.loria.fr/</title>
<marker></marker>
<rawString>Leopar: a parser for Interaction Grammar http://leopar.loria.fr/</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Le Roux</author>
<author>G Perrier</author>
</authors>
<date>2007</date>
<booktitle>Modélisation de la coordination dans les Grammaires d’Interaction”, Traitement Automatique des Langues (TAL</booktitle>
<pages>47--3</pages>
<marker>Le Roux, Perrier, 2007</marker>
<rawString>Le Roux, J. and G. Perrier, 2007. “Modélisation de la coordination dans les Grammaires d’Interaction”, Traitement Automatique des Langues (TAL 47-3)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sh Māhootiān</author>
</authors>
<title>Muskens and Krahmer,</title>
<date>1997</date>
<booktitle>In Logical Aspects of CL,</booktitle>
<location>Grenoble, France,</location>
<contexts>
<context position="7877" citStr="Māhootiān, 1997" startWordPosition="1263" endWordPosition="1264">e Indo-European language family and has many features in common with the other languages in this family in terms of morphology, syntax, phonology, and lexicon. Although Persian uses a modified version of the Arabic alphabet, the two languages differ from one another in many respects. Persian is a null-subject language with SOV word order in unmarked structures. However, the word order is relatively free. The subject mood is widely used. Verbs are inflected in the language and they indicate tense and aspect, and agree with subject in person and number. The language does not make use of gender (Māhootiān, 1997). In noun phrases, the sequence of words is around at least one noun, namely the head word. So, the noun phrase could be either a single unit noun, or a sequence of other elements with a noun. The syntax of Persian allows for having elements before a noun head _prenominal, and after the noun head _postnominal. 108 To make a phrase, there are some restrictions for the elements surrounding a head to make a constituent; otherwise the sequence of elements will be ill-formed, that is, ungrammatical. Nouns belong to an open class of words. The noun could be a common noun, a proper noun, or a pronoun</context>
</contexts>
<marker>Māhootiān, 1997</marker>
<rawString>Māhootiān, Sh, 1997. Persian. Routledge. Muskens and Krahmer, 1998. “Talking about trees and truth conditions”. In Logical Aspects of CL, Grenoble, France, Dec 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nasr</author>
</authors>
<title>A formalism and a parser for lexicalized dependency grammars”</title>
<date>1995</date>
<booktitle>In Proce.s of 4th Int. Workshop on Parsing Technologies,</booktitle>
<location>Prague.</location>
<contexts>
<context position="3378" citStr="Nasr (1995)" startWordPosition="543" endWordPosition="544">h IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguistics. Then researches such as Muskens and Krahmer (1998), Duchier and Thater (1999), and Perrier (2000) proposed grammatical formalisms in which polarity is also explicitly used. However, Categorial Grammar was the first grammatical formalism that exploited implicitly the idea of polarity (Lambek, 1958). Recently, Kahane (2006) showed th</context>
</contexts>
<marker>Nasr, 1995</marker>
<rawString>Nasr A., 1995. “A formalism and a parser for lexicalized dependency grammars” In Proce.s of 4th Int. Workshop on Parsing Technologies, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>K Netter</author>
<author>J Klein</author>
</authors>
<title>TSNLPTest suites for natural language processing”.</title>
<date>1996</date>
<booktitle>In Linguistic Database, CSLI Lecture Notes. Center for the Study of Language</booktitle>
<contexts>
<context position="2914" citStr="Oepen et al, 1996" startWordPosition="462" endWordPosition="465">cificities of IG, like polarities, underspecifications and trees. 2 Previous Studies 2.1 IG for French and English The first natural language considered within IG was French. A large coverage grammar which covers most of the frequent constructions of French, including coordination, has been built (Perrier, 2007; Le Roux and Perrier, 2007). Recently, using the fact that the French and English languages have many syntactic similarities, Planul (2008) proposed an English IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Sin</context>
<context position="10197" citStr="Oepen et al, 1996" startWordPosition="1655" endWordPosition="1658">should have a broad coverage on the structural level, so you can find many structures of a language with a minimal lexicon; it could be multilingual, so the structure of the languages could be compared; it should be a consistent and highly structured linguistic annotation. The differences between a test suite and a corpus are: that in test suite there is a control on the data, that the data has a systematic coverage, that the data has a non-redundant representation, that the data is annotated coherently, and that relevant ungrammatical constructions are included intentionally in a test suite (Oepen et al, 1996). Since our end goal is to develop a fragment of Persian grammar, to the best of our knowledge no already developed test suite for our target constructions was available; so we built a very small test suite with only 50 examples based on a small lexicon _only 41 entries. 4.2 XMG The XMG system is usually called a &amp;quot;metagrammar compiler&amp;quot; is a tool for designing largescale grammars for natural language. This system has been designed and implemented in the framework of Benoit Crabbé (2005). XMG has provided a compact representation of grammatical information which combines elementary fragments of </context>
</contexts>
<marker>Oepen, Netter, Klein, 1996</marker>
<rawString>Oepen, S. and K. Netter and J. Klein, 1996. “TSNLPTest suites for natural language processing”. In Linguistic Database, CSLI Lecture Notes. Center for the Study of Language and information. Perrier, G., 2000. “Interaction grammar” Coling 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Perrier</author>
</authors>
<title>A French Interaction Grammar&amp;quot;,</title>
<date>2007</date>
<institution>Borovets Bulgarie.</institution>
<location>RANLP</location>
<contexts>
<context position="2608" citStr="Perrier, 2007" startWordPosition="413" endWordPosition="414">verage of Persian grammar. The grammar presented here could have been expressed in Tree Adjoining Grammar (TAG) or even in Context Free Grammar with features, but we strongly believe that the modelization of the verbal construction of Persian, which is much more complex, can benefit from advanced specificities of IG, like polarities, underspecifications and trees. 2 Previous Studies 2.1 IG for French and English The first natural language considered within IG was French. A large coverage grammar which covers most of the frequent constructions of French, including coordination, has been built (Perrier, 2007; Le Roux and Perrier, 2007). Recently, using the fact that the French and English languages have many syntactic similarities, Planul (2008) proposed an English IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which express</context>
</contexts>
<marker>Perrier, 2007</marker>
<rawString>Perrier, G., 2007. &amp;quot;A French Interaction Grammar&amp;quot;, RANLP 2007, Borovets Bulgarie.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Planul</author>
</authors>
<title>Construction d&apos;une Grammaire d&apos;Interaction pour l&apos;anglais,</title>
<date>2008</date>
<journal>Master thesis, Université Nancy</journal>
<volume>2</volume>
<contexts>
<context position="2748" citStr="Planul (2008)" startWordPosition="435" endWordPosition="436">mar with features, but we strongly believe that the modelization of the verbal construction of Persian, which is much more complex, can benefit from advanced specificities of IG, like polarities, underspecifications and trees. 2 Previous Studies 2.1 IG for French and English The first natural language considered within IG was French. A large coverage grammar which covers most of the frequent constructions of French, including coordination, has been built (Perrier, 2007; Le Roux and Perrier, 2007). Recently, using the fact that the French and English languages have many syntactic similarities, Planul (2008) proposed an English IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Ap</context>
</contexts>
<marker>Planul, 2008</marker>
<rawString>Planul, J., 2008. Construction d&apos;une Grammaire d&apos;Interaction pour l&apos;anglais, Master thesis, Université Nancy 2, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Tesnière</author>
</authors>
<title>Comment construire une syntaxe”</title>
<date>1934</date>
<booktitle>Bulletin de la Faculté des Lettres de Strasbourg</booktitle>
<pages>7--12</pages>
<contexts>
<context position="3041" citStr="Tesnière (1934)" startWordPosition="488" endWordPosition="489">al language considered within IG was French. A large coverage grammar which covers most of the frequent constructions of French, including coordination, has been built (Perrier, 2007; Le Roux and Perrier, 2007). Recently, using the fact that the French and English languages have many syntactic similarities, Planul (2008) proposed an English IG built by modifying the French one. These two grammars were tested on the Test Suite for Natural Language Processing (TSNLP; Oepen et al, 1996). Both cover 85% of the sentences in the TSNLP. 2.2 Polarity The notion of polarity is based on the old idea of Tesnière (1934), Jespersen (1935), and Adjukiewicz (1935) that a sentence is considered as a molecule with its words as the atoms; every word is equipped with a valence which expresses its capacity of interaction with other words, so that syntactic composition appears as a chemical reaction (Gaiffe and Perrier, 2004). Apparently, it seems Nasr (1995) was the first to propose a 107 Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 107–114, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP formalism that explicitly uses the polarized structure in computational linguisti</context>
</contexts>
<marker>Tesnière, 1934</marker>
<rawString>Tesnière L., 1934. “Comment construire une syntaxe” Bulletin de la Faculté des Lettres de Strasbourg 7-12iéme. pp. 219-229.</rawString>
</citation>
<citation valid="false">
<institution>XMG Documentation</institution>
<marker></marker>
<rawString>XMG Documentation</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>