<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000376">
<title confidence="0.955484">
Incremental Parser Generation for Tree Adjoining Grammars*
</title>
<author confidence="0.989993">
Anoop Sarkar
</author>
<affiliation confidence="0.998797">
University of Pennsylvania
Department of Computer and Information Science
</affiliation>
<address confidence="0.855759">
200 S. 33rd St., Philadelphia PA 19104-6389, USA
</address>
<email confidence="0.965176">
anoopOlinc.cis.upenn.edu
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978153846154">
This paper describes the incremental
generation of parse tables for the LR-
type parsing of Tree Adjoining Languages
(TALs). The algorithm presented han-
dles modifications to the input grammar
by updating the parser generated so far.
In this paper, a lazy generation of LR-
type parsers for TALs is defined in which
parse tables are created by need while
parsing. We then describe an incremental
parser generator for TALs which responds
to modification of the input grammar by
updating parse tables built so far.
</bodyText>
<sectionHeader confidence="0.955155" genericHeader="method">
1 LR Parser Generation
</sectionHeader>
<bodyText confidence="0.9641309375">
Tree Adjoining Grammars (TAGs) are tree rewrit-
ing systems which combine trees with the sin-
gle operation of adjoining. (Schabes and Vijay-
Shanker, 1990) describes the construction of an LR
parsing algorithm for TAGs&apos;. Parser generation
here is taken to be the construction of LR(0) ta-
bles (i.e., without any lookahead) for a particular
TAG 2. The moves made by the parser can be ex-
plained by an automaton which is weakly equivalent
to TAGs called Bottom-Up Embedded Pushdown
Automata (BEPDA) (Schabes and Vijay-Shanker,
1990)3. Storage in a BEPDA is a sequence of stacks,
*This work is partially supported by NSF grant NSF-
STC SBR 8920230 ARPA grant N00014-94 and ARO
grant DAAH04-94-G0426. Thanks to Breck Baldwin,
Dania Egedi, Jason Eisner, B. Srinivas and the three
anonymous reviewers for their valuable comments.
&apos;Familiarity with TAGs and their parsing techniques
is assumed throughout the paper, see (Schabes and
Joshi, 1991) for an introduction. We assume that our
definition of TAG does not have the substitution opera-
tion. See (Aho et al., 1986) for details on LR parsing.
&apos;The algorithm described here can be extended to use
SLR(1) tables (Schabes and Vijay-Shanker, 1990).
&apos;Note that the LR(0) tables considered here are deter-
ministic and hence correspond to a subset of the TALs.
Techniques developed in (Tomita, 1986) can be used to
resolve nondeterminism in the parser.
where new stacks can be introduced above and be-
low the top stack in the automaton. Recognition of
adjunction is equivalent to the unwrap move shown
in Fig. 1.
</bodyText>
<subsectionHeader confidence="0.769469">
1.1 left of foot of
</subsectionHeader>
<figure confidence="0.9840774">
spine of
611—
liftwrap
LA rightoubma
1:11&apos;
</figure>
<figureCaption confidence="0.999998">
Figure 1: Recognition of adjunction in a BEPDA.
</figureCaption>
<bodyText confidence="0.9786384">
The LR parser (of (Schabes and Vijay-Shanker,
1990)) uses a parsing table and a sequence of stacks
(Fig. 1) to parse the input. The parsing table en-
codes the actions taken by the parser as follows (us-
ing two GOTO functions):
</bodyText>
<listItem confidence="0.9997324">
• Shift to a new state, pushed onto a new stack
which appears on top of the current sequence
of stacks. The current input token is removed.
• Resume Right when the parser has reached
right and below a node (in a dotted tree, ex-
plained below) on which an auxiliary tree has
been adjoined. The GOTOfoot function en-
codes the proper state such that the string to
the right of the footnode can be recognized.
• Reduce Root, the parser executes an unwrap
move to recognize adjunction (Fig. 1). The
proper state for the parser after adjunction is
given by the GOTOright function.
• Accept and Error functions as in conventional
LR parsing.
</listItem>
<bodyText confidence="0.999918666666667">
There are four positions for a dot associated with
a symbol in a dotted tree: left above, left below,
right below and right above. A dotted tree has one
such dotted symbol. The tree traversal in Fig. 2
scans the frontier of the tree from left to right while
trying to recognize possible adjunctions between the
</bodyText>
<page confidence="0.994506">
375
</page>
<bodyText confidence="0.8275535">
above and below positions of the dot. Adjunction on
a node is recorded by marking it with an asterisk4.
</bodyText>
<figure confidence="0.7020565">
Ai
t
</figure>
<figureCaption confidence="0.996668">
Figure 2: Left to right dotted tree traversal.
</figureCaption>
<bodyText confidence="0.984602888888889">
The parse table is built as a finite state automaton
(FSA) with each state defined to be a set of dotted
trees. The closure operations on states in the parse
table are defined in Fig. 3. All the states in the parse
table must be closed under these operations5.
The FSA is built as follows: in state 0 put all the
initial trees with the dot left and above the root.
The state is then closed. New states are built by
three transitions: s{ &apos;a} {e}, a is a terminal
</bodyText>
<equation confidence="0.32338725">
Prsght
symbol; s, {A.} {A.}, 0 can adjoin at node
P foot
A; s,{,,A.} 53{A,}, A is a footnode. Entries in
</equation>
<bodyText confidence="0.624368">
the parse table are determined as follows:
</bodyText>
<listItem confidence="0.989582">
• a shift for each transition in the FSA.
• resume right if there is a node B* with the
dot right and below it.
• reduce root if there is a rootnode in an aux-
iliary tree with the dot right and above it.
• accept and error with the usual interpreta-
tion.
</listItem>
<bodyText confidence="0.99979025">
The items created in each state before closure applies
are called the kernels of each state in the FSA. The
initial trees with the dot left and above the root form
the kernel for state 0.
</bodyText>
<sectionHeader confidence="0.933029" genericHeader="method">
2 Lazy Parser Generation
</sectionHeader>
<bodyText confidence="0.999900266666667">
The algorithm described so far assumes that the
parse table is precompiled before the parser is used.
Lazy parser generation generates only those parts of
the parser that become necessary during actual pars-
ing. The approach is an extension of the algorithm
for CFGs given in (Heering et al., 1990; Heering et
al., 1989). To modify the LR parsing strategy given
earlier we move the closure and computation of tran-
sitions from the table generation stage to the LR
parser. The lazy technique expands a kernel state
only when the parser, looking at the current input,
indicates so. For example, a TAG and correspond-
ing FSA is shown in Fig. 4 (na rules out adjunction
at a node)6 . Computation of closure and transitions
in the state occurs while parsing as in Fig. 5 which
</bodyText>
<footnote confidence="0.9947172">
4For example, B*. This differs from the usual nota-
tion for marking a footnode with an asterisk.
5Fig. 5 is a partial FSA for the grammar in Fig. 4.
Unexpanded kernel states are marked with a bold-
faced outline, acceptance states with double-lines.
</footnote>
<bodyText confidence="0.976466857142857">
is the result of the LR parser expanding the FSA in
Fig. 4 while parsing the string aec.
The modified parse function checks the type of the
state and may expand the kernel states while pars-
ing a sentence. Memory use in the lazy technique
is greater as the FSA is needed during parsing and
parser generation.
</bodyText>
<note confidence="0.555371">
TAG G: a: s
</note>
<figureCaption confidence="0.9259954">
Figure 4: TAG G where L(G) = { anecn } and corre-
sponding FSA after lazy parse table generation.
Figure 5: The FSA after parsing the string aec.
Figure 6: New tree added to G with L(G)
{anbmecndm}
</figureCaption>
<sectionHeader confidence="0.998084" genericHeader="method">
3 Incremental Parser Generation
</sectionHeader>
<bodyText confidence="0.999770714285714">
An incremental parser generator responds to gram-
mar updates by throwing away only that information
from the FSA of the old grammar that is inconsistent
in the updated grammar. Incremental behaviour is
obtained by selecting the states in the parse table af-
fected by the change in the grammar and returning
them to their kernel form (i.e. remove items added
by the closure operations). The parse table FSA will
now become a disconnected graph. The lazy parser
will expand the states using the new grammar. All
states in the disconnected graph are kept as the lazy
parser will reconnect with those states (when the
transitions between states are computed) that are
unaffected by the change in the grammar. Consider
</bodyText>
<figure confidence="0.998134127659575">
Na JR. )Ra
a ft .1%. as
s„f, snf,
Na 5aaNa
a5 a S a S,
•
Na
SmC3
N. )NN na
as. a5. as.
•
.S.ca
I
e*e
hoot
a
s.
A.° A&amp;quot;. Ana
as as a S
S ca S&apos;Ne
j
C
ARR
as as.
NN Na
a S as
Snce
as&apos;&apos;
i&apos;„ca
3
13 2-[
S S. S
I. 1 1
CCC
•
• S
1 .1 .1 as
eee
Na
PTRa
as
Ca S
N.
a
FSA:
FSA: 0
&apos;S
</figure>
<page confidence="0.75381">
376
</page>
<table confidence="0.576746428571428">
, A-----A A-- A. .A.
A---- r\
A
•
Left Completion
Adjunction Pr ediction Skip Node Ak AL
Move Dot Up Move Dot Down
</table>
<figureCaption confidence="0.998262">
Figure 3: Closure Operations.
</figureCaption>
<bodyText confidence="0.9245895">
the addition of a tree to the grammar (deletion will
be similar).
</bodyText>
<listItem confidence="0.998505777777778">
• for an initial tree a return state 0 to kernel form
adding a with the dot left and above the root
node. Also return all states where a possible
Left Completion on a can occur to their kernel
form.
• for an auxiliary tree # return all states where a
possible Adjunction Prediction on /3 can occur
and all states with a 13right transition to their
kernel form.
</listItem>
<bodyText confidence="0.886245888888889">
For example, the addition of the tree in Fig. 6
causes the FSA to fragment into the disconnected
graph in Fig. 7. It is crucial to keep the discon-
nected states around; consider the re-expansion of a
single state in Fig. 8. All states compatible with the
modified grammar are eventually reused.
J.. )7..
as as as
SZ.vn SN„c„
</bodyText>
<figureCaption confidence="0.99906">
Figure 7: The parse table after the addition of 7.
</figureCaption>
<bodyText confidence="0.999947857142857">
The approach presented above causes certain
states to become unreachable from the start state7.
Frequent modifications of a grammar can cause
many unreachable states. A garbage collection
scheme defined in (Heering et al., 1990) can be used
here which avoids overregeneration by retaining un-
reachable states.
</bodyText>
<sectionHeader confidence="0.999571" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.873910571428572">
What we have described above is work in progress in
implementing an LR-type parser for a wide-coverage
lexicalized grammar of English using TAGs (XTAG
Group, 1995). Incremental parser generation allows
the addition and deletion of elementary trees from a
&apos;Quantitative results on the performance of the algo-
rithm presented are forthcoming.
</bodyText>
<figureCaption confidence="0.9918235">
Figure 8: The parse table after expansion of state 0
with the modified grammar.
</figureCaption>
<bodyText confidence="0.9983766">
TAG without recompilation of the parse table for the
updated grammar. This allows precompilation of
top-down dependencies such as the prediction of ad-
junction while having the flexibility given by Earley-
style parsers.
</bodyText>
<sectionHeader confidence="0.998862" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.97695244">
Aho, Alfred V., Ravi Sethi and Jeffrey D. Ullman, Corn-
pilers: Principles, Techniques and Tools, Addison
Wesley, Reading, MA, 1986.
Heering, Jan, Paul Klint and Jan Rekers, Incremental
Generation of Parsers, In IEEE Transactions on Soft-
ware Engineering, vol. 16, no. 12, pp. 1344-1350, 1990.
Heering, Jan, Paul Mint and Jan Rekers, Incremental
Generation of Parsers, In ACM SIGPLAN Notices
(SIGPLAN &apos;89 Conference on Programming Lan-
guage Design and Implementation), vol. 24, no. 7, pp.
179-191, 1989.
Schabes, Yves and K. Vijay-Shanker, Deterministic Left
to Right Parsing of Tree Adjoining Languages, In 28th
Meeting of the Association for Computational Lin-
guistics (ACL &apos;90), Pittsburgh, PA, 1990.
Schabes, Yves and Aravind K. Joshi, Parsing with Lexi-
calized Tree Adjoining Grammars, In Tomita, Masaru
(ed.) Current Issues in Parsing Technologies, Kluwer
Academic, Dordrecht, The Netherlands, 1991.
Tomita, Masaru, Efficient Parsing for Natural Language:
A Fast Algorithm for Practical Systems, Kluwer Aca-
demic, Dordrecht, The Netherlands, 1986.
XTAG Research Group, A Lexicalized Tree Adjoining
Grammar for English, IRCS Technical Report 95-03,
University of Pennsylvania, Philadelphia, PA. 1995.
</reference>
<figure confidence="0.992662896551724">
,aaaa
°s a5 a
St, St, S,,c,
•
a
A I:
as: —c —c
3 1 c
C a5 25
■•■•
S„f, sal
0
2
Sa S
rt
d d
b s b S
„ no na
as
s S
.r:&amp;quot;&apos;
d d
b5,, b
a
S„„
Jaa .fna
as as as
2
3
</figure>
<page confidence="0.941184">
377
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.295199">
<title confidence="0.997579">Incremental Parser Generation for Tree Adjoining Grammars*</title>
<author confidence="0.997749">Anoop Sarkar</author>
<affiliation confidence="0.9996895">University of Pennsylvania Department of Computer and Information Science</affiliation>
<address confidence="0.999707">200 S. 33rd St., Philadelphia PA 19104-6389, USA</address>
<email confidence="0.9996">anoopOlinc.cis.upenn.edu</email>
<abstract confidence="0.988749375">This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs). The algorithm presented handles modifications to the input grammar by updating the parser generated so far. In this paper, a lazy generation of LRtype parsers for TALs is defined in which parse tables are created by need while parsing. We then describe an incremental parser generator for TALs which responds to modification of the input grammar by updating parse tables built so far. 1 LR Parser Generation Tree Adjoining Grammars (TAGs) are tree rewriting systems which combine trees with the sinoperation of and Vijay- Shanker, 1990) describes the construction of an LR parsing algorithm for TAGs&apos;. Parser generation here is taken to be the construction of LR(0) tables (i.e., without any lookahead) for a particular The moves made by the parser can be explained by an automaton which is weakly equivalent</abstract>
<note confidence="0.7567494">to TAGs called Bottom-Up Embedded Pushdown Automata (BEPDA) (Schabes and Vijay-Shanker, Storage in a BEPDA is a sequence of stacks, *This work is partially supported by NSF grant NSF- STC SBR 8920230 ARPA grant N00014-94 and ARO grant DAAH04-94-G0426. Thanks to Breck Baldwin, Dania Egedi, Jason Eisner, B. Srinivas and the three anonymous reviewers for their valuable comments. &apos;Familiarity with TAGs and their parsing techniques is assumed throughout the paper, see (Schabes and</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Ravi Sethi</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1986</date>
<booktitle>Cornpilers: Principles, Techniques and Tools,</booktitle>
<publisher>Addison Wesley,</publisher>
<location>Reading, MA,</location>
<contexts>
<context position="1812" citStr="Aho et al., 1986" startWordPosition="283" endWordPosition="286">Gs called Bottom-Up Embedded Pushdown Automata (BEPDA) (Schabes and Vijay-Shanker, 1990)3. Storage in a BEPDA is a sequence of stacks, *This work is partially supported by NSF grant NSFSTC SBR 8920230 ARPA grant N00014-94 and ARO grant DAAH04-94-G0426. Thanks to Breck Baldwin, Dania Egedi, Jason Eisner, B. Srinivas and the three anonymous reviewers for their valuable comments. &apos;Familiarity with TAGs and their parsing techniques is assumed throughout the paper, see (Schabes and Joshi, 1991) for an introduction. We assume that our definition of TAG does not have the substitution operation. See (Aho et al., 1986) for details on LR parsing. &apos;The algorithm described here can be extended to use SLR(1) tables (Schabes and Vijay-Shanker, 1990). &apos;Note that the LR(0) tables considered here are deterministic and hence correspond to a subset of the TALs. Techniques developed in (Tomita, 1986) can be used to resolve nondeterminism in the parser. where new stacks can be introduced above and below the top stack in the automaton. Recognition of adjunction is equivalent to the unwrap move shown in Fig. 1. 1.1 left of foot of spine of 611— liftwrap LA rightoubma 1:11&apos; Figure 1: Recognition of adjunction in a BEPDA. </context>
</contexts>
<marker>Aho, Sethi, Ullman, 1986</marker>
<rawString>Aho, Alfred V., Ravi Sethi and Jeffrey D. Ullman, Cornpilers: Principles, Techniques and Tools, Addison Wesley, Reading, MA, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Heering</author>
<author>Paul Klint</author>
<author>Jan Rekers</author>
</authors>
<title>Incremental Generation of Parsers, In</title>
<date>1990</date>
<journal>IEEE Transactions on Software Engineering,</journal>
<volume>16</volume>
<pages>1344--1350</pages>
<contexts>
<context position="5113" citStr="Heering et al., 1990" startWordPosition="888" endWordPosition="891">otnode in an auxiliary tree with the dot right and above it. • accept and error with the usual interpretation. The items created in each state before closure applies are called the kernels of each state in the FSA. The initial trees with the dot left and above the root form the kernel for state 0. 2 Lazy Parser Generation The algorithm described so far assumes that the parse table is precompiled before the parser is used. Lazy parser generation generates only those parts of the parser that become necessary during actual parsing. The approach is an extension of the algorithm for CFGs given in (Heering et al., 1990; Heering et al., 1989). To modify the LR parsing strategy given earlier we move the closure and computation of transitions from the table generation stage to the LR parser. The lazy technique expands a kernel state only when the parser, looking at the current input, indicates so. For example, a TAG and corresponding FSA is shown in Fig. 4 (na rules out adjunction at a node)6 . Computation of closure and transitions in the state occurs while parsing as in Fig. 5 which 4For example, B*. This differs from the usual notation for marking a footnode with an asterisk. 5Fig. 5 is a partial FSA for th</context>
<context position="8543" citStr="Heering et al., 1990" startWordPosition="1535" endWordPosition="1538">heir kernel form. For example, the addition of the tree in Fig. 6 causes the FSA to fragment into the disconnected graph in Fig. 7. It is crucial to keep the disconnected states around; consider the re-expansion of a single state in Fig. 8. All states compatible with the modified grammar are eventually reused. J.. )7.. as as as SZ.vn SN„c„ Figure 7: The parse table after the addition of 7. The approach presented above causes certain states to become unreachable from the start state7. Frequent modifications of a grammar can cause many unreachable states. A garbage collection scheme defined in (Heering et al., 1990) can be used here which avoids overregeneration by retaining unreachable states. 4 Conclusion What we have described above is work in progress in implementing an LR-type parser for a wide-coverage lexicalized grammar of English using TAGs (XTAG Group, 1995). Incremental parser generation allows the addition and deletion of elementary trees from a &apos;Quantitative results on the performance of the algorithm presented are forthcoming. Figure 8: The parse table after expansion of state 0 with the modified grammar. TAG without recompilation of the parse table for the updated grammar. This allows prec</context>
</contexts>
<marker>Heering, Klint, Rekers, 1990</marker>
<rawString>Heering, Jan, Paul Klint and Jan Rekers, Incremental Generation of Parsers, In IEEE Transactions on Software Engineering, vol. 16, no. 12, pp. 1344-1350, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Heering</author>
<author>Paul Mint</author>
<author>Jan Rekers</author>
</authors>
<title>Incremental Generation of Parsers,</title>
<date>1989</date>
<booktitle>In ACM SIGPLAN Notices (SIGPLAN &apos;89 Conference on Programming Language Design and Implementation),</booktitle>
<volume>24</volume>
<pages>179--191</pages>
<contexts>
<context position="5136" citStr="Heering et al., 1989" startWordPosition="892" endWordPosition="895"> tree with the dot right and above it. • accept and error with the usual interpretation. The items created in each state before closure applies are called the kernels of each state in the FSA. The initial trees with the dot left and above the root form the kernel for state 0. 2 Lazy Parser Generation The algorithm described so far assumes that the parse table is precompiled before the parser is used. Lazy parser generation generates only those parts of the parser that become necessary during actual parsing. The approach is an extension of the algorithm for CFGs given in (Heering et al., 1990; Heering et al., 1989). To modify the LR parsing strategy given earlier we move the closure and computation of transitions from the table generation stage to the LR parser. The lazy technique expands a kernel state only when the parser, looking at the current input, indicates so. For example, a TAG and corresponding FSA is shown in Fig. 4 (na rules out adjunction at a node)6 . Computation of closure and transitions in the state occurs while parsing as in Fig. 5 which 4For example, B*. This differs from the usual notation for marking a footnode with an asterisk. 5Fig. 5 is a partial FSA for the grammar in Fig. 4. Un</context>
</contexts>
<marker>Heering, Mint, Rekers, 1989</marker>
<rawString>Heering, Jan, Paul Mint and Jan Rekers, Incremental Generation of Parsers, In ACM SIGPLAN Notices (SIGPLAN &apos;89 Conference on Programming Language Design and Implementation), vol. 24, no. 7, pp. 179-191, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Deterministic Left to Right Parsing of Tree Adjoining Languages,</title>
<date>1990</date>
<booktitle>In 28th Meeting of the Association for Computational Linguistics (ACL &apos;90),</booktitle>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="1283" citStr="Schabes and Vijay-Shanker, 1990" startWordPosition="197" endWordPosition="200"> responds to modification of the input grammar by updating parse tables built so far. 1 LR Parser Generation Tree Adjoining Grammars (TAGs) are tree rewriting systems which combine trees with the single operation of adjoining. (Schabes and VijayShanker, 1990) describes the construction of an LR parsing algorithm for TAGs&apos;. Parser generation here is taken to be the construction of LR(0) tables (i.e., without any lookahead) for a particular TAG 2. The moves made by the parser can be explained by an automaton which is weakly equivalent to TAGs called Bottom-Up Embedded Pushdown Automata (BEPDA) (Schabes and Vijay-Shanker, 1990)3. Storage in a BEPDA is a sequence of stacks, *This work is partially supported by NSF grant NSFSTC SBR 8920230 ARPA grant N00014-94 and ARO grant DAAH04-94-G0426. Thanks to Breck Baldwin, Dania Egedi, Jason Eisner, B. Srinivas and the three anonymous reviewers for their valuable comments. &apos;Familiarity with TAGs and their parsing techniques is assumed throughout the paper, see (Schabes and Joshi, 1991) for an introduction. We assume that our definition of TAG does not have the substitution operation. See (Aho et al., 1986) for details on LR parsing. &apos;The algorithm described here can be extend</context>
</contexts>
<marker>Schabes, Vijay-Shanker, 1990</marker>
<rawString>Schabes, Yves and K. Vijay-Shanker, Deterministic Left to Right Parsing of Tree Adjoining Languages, In 28th Meeting of the Association for Computational Linguistics (ACL &apos;90), Pittsburgh, PA, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing with Lexicalized Tree Adjoining Grammars,</title>
<date>1991</date>
<booktitle>Current Issues in Parsing Technologies,</booktitle>
<editor>In Tomita, Masaru (ed.)</editor>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht, The Netherlands,</location>
<contexts>
<context position="1689" citStr="Schabes and Joshi, 1991" startWordPosition="261" endWordPosition="264"> lookahead) for a particular TAG 2. The moves made by the parser can be explained by an automaton which is weakly equivalent to TAGs called Bottom-Up Embedded Pushdown Automata (BEPDA) (Schabes and Vijay-Shanker, 1990)3. Storage in a BEPDA is a sequence of stacks, *This work is partially supported by NSF grant NSFSTC SBR 8920230 ARPA grant N00014-94 and ARO grant DAAH04-94-G0426. Thanks to Breck Baldwin, Dania Egedi, Jason Eisner, B. Srinivas and the three anonymous reviewers for their valuable comments. &apos;Familiarity with TAGs and their parsing techniques is assumed throughout the paper, see (Schabes and Joshi, 1991) for an introduction. We assume that our definition of TAG does not have the substitution operation. See (Aho et al., 1986) for details on LR parsing. &apos;The algorithm described here can be extended to use SLR(1) tables (Schabes and Vijay-Shanker, 1990). &apos;Note that the LR(0) tables considered here are deterministic and hence correspond to a subset of the TALs. Techniques developed in (Tomita, 1986) can be used to resolve nondeterminism in the parser. where new stacks can be introduced above and below the top stack in the automaton. Recognition of adjunction is equivalent to the unwrap move shown</context>
</contexts>
<marker>Schabes, Joshi, 1991</marker>
<rawString>Schabes, Yves and Aravind K. Joshi, Parsing with Lexicalized Tree Adjoining Grammars, In Tomita, Masaru (ed.) Current Issues in Parsing Technologies, Kluwer Academic, Dordrecht, The Netherlands, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaru Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems,</title>
<date>1986</date>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht, The</location>
<contexts>
<context position="2088" citStr="Tomita, 1986" startWordPosition="329" endWordPosition="330">nia Egedi, Jason Eisner, B. Srinivas and the three anonymous reviewers for their valuable comments. &apos;Familiarity with TAGs and their parsing techniques is assumed throughout the paper, see (Schabes and Joshi, 1991) for an introduction. We assume that our definition of TAG does not have the substitution operation. See (Aho et al., 1986) for details on LR parsing. &apos;The algorithm described here can be extended to use SLR(1) tables (Schabes and Vijay-Shanker, 1990). &apos;Note that the LR(0) tables considered here are deterministic and hence correspond to a subset of the TALs. Techniques developed in (Tomita, 1986) can be used to resolve nondeterminism in the parser. where new stacks can be introduced above and below the top stack in the automaton. Recognition of adjunction is equivalent to the unwrap move shown in Fig. 1. 1.1 left of foot of spine of 611— liftwrap LA rightoubma 1:11&apos; Figure 1: Recognition of adjunction in a BEPDA. The LR parser (of (Schabes and Vijay-Shanker, 1990)) uses a parsing table and a sequence of stacks (Fig. 1) to parse the input. The parsing table encodes the actions taken by the parser as follows (using two GOTO functions): • Shift to a new state, pushed onto a new stack whi</context>
</contexts>
<marker>Tomita, 1986</marker>
<rawString>Tomita, Masaru, Efficient Parsing for Natural Language: A Fast Algorithm for Practical Systems, Kluwer Academic, Dordrecht, The Netherlands, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG Research</author>
</authors>
<title>Group, A Lexicalized Tree Adjoining Grammar for English,</title>
<date>1995</date>
<tech>IRCS Technical Report 95-03,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker>Research, 1995</marker>
<rawString>XTAG Research Group, A Lexicalized Tree Adjoining Grammar for English, IRCS Technical Report 95-03, University of Pennsylvania, Philadelphia, PA. 1995.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>