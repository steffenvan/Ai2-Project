<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.033055">
<title confidence="0.991603">
Predicate Argument Structure Analysis using Transformation-based
Learning
</title>
<author confidence="0.859971">
Hirotoshi Taira Sanae Fujita Masaaki Nagata
</author>
<affiliation confidence="0.588443">
NTT Communication Science Laboratories
</affiliation>
<address confidence="0.851766">
2-4, Hikaridai, Seika-cho, Souraku-gun, Kyoto 619-0237, Japan
</address>
<email confidence="0.998466">
{taira,sanae}@cslab.kecl.ntt.co.jp nagata.masaaki@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.993881" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999754705882353">
Maintaining high annotation consistency
in large corpora is crucial for statistical
learning; however, such work is hard,
especially for tasks containing semantic
elements. This paper describes predi-
cate argument structure analysis using
transformation-based learning. An advan-
tage of transformation-based learning is
the readability of learned rules. A dis-
advantage is that the rule extraction pro-
cedure is time-consuming. We present
incremental-based, transformation-based
learning for semantic processing tasks. As
an example, we deal with Japanese pred-
icate argument analysis and show some
tendencies of annotators for constructing
a corpus with our method.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.980353481481481">
Automatic predicate argument structure analysis
(PAS) provides information of “who did what
to whom” and is an important base tool for
such various text processing tasks as machine
translation information extraction (Hirschman et
al., 1999), question answering (Narayanan and
Harabagiu, 2004; Shen and Lapata, 2007), and
summarization (Melli et al., 2005). Most re-
cent approaches to predicate argument structure
analysis are statistical machine learning methods
such as support vector machines (SVMs)(Pradhan
et al., 2004). For predicate argument struc-
ture analysis, we have the following represen-
tative large corpora: FrameNet (Fillmore et al.,
2001), PropBank (Palmer et al., 2005), and Nom-
Bank (Meyers et al., 2004) in English, the Chi-
nese PropBank (Xue, 2008) in Chinese, the
GDA Corpus (Hashida, 2005), Kyoto Text Corpus
Ver.4.0 (Kawahara et al., 2002), and the NAIST
Text Corpus (Iida et al., 2007) in Japanese.
The construction of such large corpora is strenu-
ous and time-consuming. Additionally, maintain-
ing high annotation consistency in such corpora
is crucial for statistical learning; however, such
work is hard, especially for tasks containing se-
mantic elements. For example, in Japanese cor-
pora, distinguishing true dative (or indirect object)
arguments from time-type argument is difficult be-
cause the arguments of both types are often ac-
companied with the ‘ni’ case marker.
A problem with such statistical learners as SVM
is the lack of interpretability; if accuracy is low, we
cannot identify the problems in the annotations.
We are focusing on transformation-based learn-
ing (TBL). An advantage for such learning meth-
ods is that we can easily interpret the learned
model. The tasks in most previous research are
such simple tagging tasks as part-of-speech tag-
ging, insertion and deletion of parentheses in syn-
tactic parsing, and chunking (Brill, 1995; Brill,
1993; Ramshaw and Marcus, 1995). Here we ex-
periment with a complex task: Japanese PASs.
TBL can be slow, so we proposed an incremen-
tal training method to speed up the training. We
experimented with a Japanese PAS corpus with a
graph-based TBL. From the experiments, we in-
terrelated the annotation tendency on the dataset.
The rest of this paper is organized as follows.
Section 2 describes Japanese predicate structure,
our graph expression of it, and our improved
method. The results of experiments using the
NAIST Text Corpus, which is our target corpus,
are reported in Section 3, and our conclusion is
provided in Section 4.
</bodyText>
<sectionHeader confidence="0.9197875" genericHeader="method">
2 Predicate argument structure and
graph transformation learning
</sectionHeader>
<bodyText confidence="0.9998375">
First, we illustrate the structure of a Japanese sen-
tence in Fig. 1. In Japanese, we can divide a sen-
tence into bunsetsu phrases (BP). A BP usually
consists of one or more content words and zero,
</bodyText>
<page confidence="0.973105">
162
</page>
<note confidence="0.843522">
Proceedings of the ACL 2010 Conference Short Papers, pages 162–167,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.99947">
Figure 1: Graph expression for PAS
</figureCaption>
<bodyText confidence="0.999987638888889">
one, or more than one functional words. Syn-
tactic dependency between bunsetsu phrases can
be defined. Japanese dependency parsers such as
Cabocha (Kudo and Matsumoto, 2002) can extract
BPs and their dependencies with about 90% accu-
racy.
Since predicates and arguments in Japanese are
mainly annotated on the head content word in
each BP, we can deal with BPs as candidates of
predicates or arguments. In our experiments, we
mapped each BP to an argument candidate node
of graphs. We also mapped each predicate to a
predicate node. Each predicate-argument relation
is identified by an edge between a predicate and an
argument, and the argument type is mapped to the
edge label. In our experiments below, we defined
five argument types: nominative (subjective), ac-
cusative (direct objective), dative (indirect objec-
tive), time, and location. We use five transforma-
tion types: a) add or b) delete a predicate node, c)
add or d) delete an edge between an predicate and
an argument node, e) change a label (= an argu-
ment type) to another label (Fig. 2). We explain
the existence of an edge between a predicate and
an argument labeled t candidate node as that the
predicate and the argument have a t type relation-
ship.
Transformation-based learning was proposed
by (Brill, 1995). Below we explain our learn-
ing strategy when we directly adapt the learning
method to our graph expression of PASs. First, un-
structured texts from the training data are inputted.
After pre-processing, each text is mapped to an
initial graph. In our experiments, the initial graph
has argument candidate nodes with corresponding
BPs and no predicate nodes or edges. Next, com-
</bodyText>
<figureCaption confidence="0.993328">
Figure 2: Transform types
</figureCaption>
<bodyText confidence="0.9999949">
paring the current graphs with the gold standard
graph structure in the training data, we find the dif-
ferent statuses of the nodes and edges among the
graphs. We extract such transformation rule candi-
dates as ‘add node’ and ‘change edge label’ with
constraints, including ‘the corresponding BP in-
cludes a verb’ and ‘the argument candidate and the
predicate node have a syntactic dependency.’ The
extractions are executed based on the rule tem-
plates given in advance. Each extracted rule is
evaluated for the current graphs, and error reduc-
tion is calculated. The best rule for the reduction
is selected as a new rule and inserted at the bottom
of the current rule list. The new rule is applied to
the current graphs, which are transferred to other
graph structures. This procedure is iterated until
the total errors for the gold standard graphs be-
come zero. When the process is completed, the
rule list is the final model. In the test phase, we it-
eratively transform nodes and edges in the graphs
mapped from the test data, based on rules in the
model like decision lists. The last graph after all
rule adaptations is the system output of the PAS.
In this procedure, the calculation of error reduc-
tion is very time-consuming, because we have to
check many constraints from the candidate rules
for all training samples. The calculation order is
O(MN), where M is the number of articles and
N is the number of candidate rules. Additionally,
an edge rule usually has three types of constraints:
‘pred node constraint,’ ‘argument candidate node
constraint,’ and ‘relation constraint.’ The num-
ber of combinations and extracted rules are much
larger than one of the rules for the node rules.
Ramshaw et al. proposed an index-based efficient
reduction method for the calculation of error re-
duction (Ramshaw and Marcus, 1994). However,
in PAS tasks, we need to check the exclusiveness
of the argument types (for example, a predicate ar-
gument structure does not have two nominative ar-
</bodyText>
<page confidence="0.99573">
163
</page>
<bodyText confidence="0.9999455">
guments), and we cannot directly use the method.
Jijkoun et al. only used candidate rules that hap-
pen in the current and gold standard graphs and
used SVM learning for constraint checks (Jijkoun
and de Rijke, 2007). This method is effective
for achieving high accuracy; however, it loses the
readability of the rules. This is contrary to our aim
to extract readable rules.
To reduce the calculations while maintaining
readability, we propose an incremental method
and describe its procedure below. In this proce-
dure, we first have PAS graphs for only one arti-
cle. After the total errors among the current and
gold standard graphs become zero in the article,
we proceed to the next article. For the next article,
we first adapt the rules learned from the previous
article. After that, we extract new rules from the
two articles until the total errors for the articles be-
come zero. We continue these processes until the
last article. Additionally, we count the number of
rule occurrences and only use the rule candidates
that happen more than once, because most such
rules harm the accuracy. We save and use these
rules again if the occurrence increases.
</bodyText>
<sectionHeader confidence="0.999903" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99916">
3.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999488428571429">
We used the articles in the NAIST Text Cor-
pus version 1.4β (Iida et al., 2007) based on the
Mainichi Shinbun Corpus (Mainichi, 1995), which
were taken from news articles published in the
Japanese Mainichi Shinbun newspaper. We used
articles published on January 1st for training ex-
amples and on January 3rd for test examples.
Three original argument types are defined in the
NAIST Text Corpus: nominative (or subjective),
accusative (or direct object), and dative (or indi-
rect object). For evaluation of the difficult anno-
tation cases, we also added annotations for ‘time’
and ‘location’ types by ourselves. We show the
dataset distribution in Table 1. We extracted the
BP units and dependencies among these BPs from
the dataset using Cabocha, a Japanese dependency
parser, as pre-processing. After that, we adapted
our incremental learning to the training data. We
used two constraint templates in Tables 2 and 3
for predicate nodes and edges when extracting the
rule candidates.
</bodyText>
<tableCaption confidence="0.985585">
Table 1: Data distribution
</tableCaption>
<table confidence="0.9995662">
Training Test
95 74
1,129 687
3,261 2,038
3,877 2,468
1,717 971
1,012 701
632 376
371 295
145 125
</table>
<tableCaption confidence="0.971695">
Table 4: Total performances (F1-measure (%))
</tableCaption>
<table confidence="0.999621">
Type System P R F1
Pred. Baseline 89.4 85.1 87.2
Our system 91.8 85.3 88.4
Arg. Baseline 79.3 59.5 68.0
Our system 81.9 62.4 70.8
</table>
<subsectionHeader confidence="0.728065">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.99988203030303">
Our incremental method takes an hour. In com-
parison, the original TBL cannot even extract one
rule in a day. The results of predicate and argu-
ment type predictions are shown in Table 4. Here,
‘Baseline’ is the baseline system that predicts the
BSs that contain verbs, adjectives, and da form
nouns (‘to be’ in English) as predicates and pre-
dicts argument types for BSs having syntactical
dependency with a predicted predicate BS, based
on the following rules: 1) BSs containing nomina-
tive (ga) / accusative (wo) / dative (ni) case mark-
ers are predicted to be nominative, accusative, and
dative, respectively. 2) BSs containing a topic case
marker (wa) are predicted to be nominative. 3)
When a word sense category from a Japanese on-
tology of the head word in BS belongs to a ‘time’
or ‘location’ category, the BS is predicted to be a
‘time’ and ‘location’ type argument. In all preci-
sion, recall, and F1-measure, our system outper-
formed the baseline system.
Next, we show our system’s learning curve in
Fig. 3. The number of final rules was 68. This
indicates that the first twenty rules are mainly ef-
fective rules for the performance. The curve also
shows that no overfitting happened. Next, we
show the performance for every argument type in
Table 5. ‘TBL,’ which stands for ‘transformation-
based learning,’ is our system. In this table,
the performance of the dative and time types im-
proved, even though they are difficult to distin-
guish. On the other hand, the performance of the
location type argument in our system is very low.
Our method learns rules as decreasing errors of
</bodyText>
<figure confidence="0.992985111111111">
# of Articles
# of Sentences
# of Predicates
# of Arguments
Nom.
Acc.
Dat.
Time
Loc.
</figure>
<page confidence="0.995782">
164
</page>
<tableCaption confidence="0.998611">
Table 2: Predicate node constraint templates
</tableCaption>
<table confidence="0.995769428571429">
Pred. Node Constraint Template Rule Example
Constraint Description Pred. Node Constraint Operation
pos1 noun, verb, adjective, etc. pos1=‘ADJECTIVE’ add pred node
pos2 independent, attached word, etc. pos2=‘DEPENDENT WORD’ del pred node
pos1 &amp; pos2 above two features combination pos1=‘VERB’ &amp; pos2=‘ANCILLARY WORD’ add pred node
‘da’ da form (copula) ‘da form’ add pred node
lemma word base form lemma=‘%’ add pred node
</table>
<tableCaption confidence="0.985876">
Table 3: Edge constraint templates
</tableCaption>
<table confidence="0.999190823529412">
Edge Constraint Template Rule Example
Arg. Cand. Pred. Node Relation Edge Constraint Operation
Const. Const. Const.
FW (=func. ∗ dep(arg → pred) FW of Arg. =‘wa(TOP)’ &amp; dep(arg → pred) add NOM edge
word)
∗ FW dep(arg ← pred) FW of Pred. =‘na(ADNOMINAL)’ &amp; dep(arg add NOM edge
← pred)
SemCat ∗ dep(arg → pred) SemCat of Arg. = ‘TIME’ &amp; dep(arg → pred) add TIME edge
(=semantic
category)
FW passive form dep(arg → pred) FW of Arg. =‘ga(NOM) &amp; Pred.: passive form chg edge label
NOM → ACC
∗ kform (= type ∗ kform of Pred. = continuative ‘ta’ form add NOM edge
of inflected
form)
SemCat Pred. SemCat ∗ SemCat of Arg. = ‘HUMAN’ &amp; Pred. SemCat add NOM edge
= ‘PHYSICAL MOVE’
</table>
<figureCaption confidence="0.9991065">
Figure 3: Learning curves: x-axis = number of
rules; y-axis: F1-measure (%)
</figureCaption>
<bodyText confidence="0.999907037037037">
all arguments, and the performance of the location
type argument is probably sacrificed for total error
reduction because the number of location type ar-
guments is much smaller than the number of other
argument types (Table 1), and the improvement of
the performance-based learning for location type
arguments is relatively low. To confirm this, we
performed an experiment in which we gave the
rules of the baseline system to our system as initial
rules and subsequently performed our incremen-
tal learning. ‘Base + TBL’ shows the experiment.
The performance for the location type argument
improved drastically. However, the total perfor-
mance of the arguments was below the original
TBL. Moreover, the ‘Base + TBL’ performance
surpassed the baseline system. This indicates that
our system learned a reasonable model.
Finally, we show some interesting extracted
rules in Fig. 4. The first rule stands for an ex-
pression where the sentence ends with the per-
formance of something, which is often seen in
Japanese newspaper articles. The second and third
rules represent that annotators of this dataset tend
to annotate time types for which the semantic cate-
gory of the argument is time, even if the argument
looks like the dat. type, and annotators tend to an-
notate dat. type for arguments that have an dat.
</bodyText>
<page confidence="0.998184">
165
</page>
<figureCaption confidence="0.998889">
Figure 4: Examples of extracted rules
</figureCaption>
<table confidence="0.816232714285714">
Table 5: Results for every arg. type (F-measure
(%))
System Args. Nom. Acc. Dat. Time Loc.
Base 68.0 65.8 79.6 70.5 51.5 38.0
TBL 70.8 64.9 86.4 74.8 59.6 1.7
Base + TBL 69.5 63.9 85.8 67.8 55.8 37.4
type case marker.
</table>
<sectionHeader confidence="0.827325" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999947230769231">
We performed experiments for Japanese predicate
argument structure analysis using transformation-
based learning and extracted rules that indicate the
tendencies annotators have. We presented an in-
cremental procedure to speed up rule extraction.
The performance of PAS analysis improved, espe-
cially, the dative and time types, which are difficult
to distinguish. Moreover, when time expressions
are attached to the ‘ni’ case, the learned model
showed a tendency to annotate them as dative ar-
guments in the used corpus. Our method has po-
tential for dative predictions and interpreting the
tendencies of annotator inconsistencies.
</bodyText>
<sectionHeader confidence="0.913961" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.864885">
We thank Kevin Duh for his valuable comments.
</bodyText>
<sectionHeader confidence="0.997974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.922536833333333">
Eric Brill. 1993. Transformation-based error-driven
parsing. In Proc. of the Third International Work-
shop on Parsing Technologies.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational Lin-
guistics, 21(4):543–565.
Charles J. Fillmore, Charles Wooters, and Collin F.
Baker. 2001. Building a large lexical databank
which provides deep semantics. In Proc. of the Pa-
cific Asian Conference on Language, Information
and Computation (PACLING).
Kouichi Hashida. 2005. Global document annotation
(GDA) manual. http://i-content.org/GDA/.
Lynette Hirschman, Patricia Robinson, Lisa
Ferro, Nancy Chinchor, Erica Brown,
Ralph Grishman, and Beth Sundheim.
1999. Hub-4 Event’99 general guidelines.
http://www.itl.nist.gov/iaui/894.02/related projects/muc/.
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji
Matsumoto. 2007. Annotating a Japanese text cor-
pus with predicate-argument and coreference rela-
tions. In Proc. of ACL 2007 Workshop on Linguistic
Annotation, pages 132–139.
Valentin Jijkoun and Maarten de Rijke. 2007. Learn-
ing to transform linguistic graphs. In Proc. of
the Second Workshop on TextGraphs: Graph-
Based Algorithms for Natural Language Processing
(TextGraphs-2), pages 53–60. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.994028">
166
</page>
<reference confidence="0.998486814814815">
Daisuke Kawahara, Sadao Kurohashi, and Koichi
Hashida. 2002. Construction of a Japanese
relevance-tagged corpus (in Japanese). Proc. of the
8th Annual Meeting of the Association for Natural
Language Processing, pages 495–498.
Taku Kudo and Yuji Matsumoto. 2002. Japanese
dependency analysis using cascaded chunking. In
Proc. of the 6th Conference on Natural Language
Learning 2002 (CoNLL 2002).
Mainichi. 1995. CD Mainichi Shinbun 94. Nichigai
Associates Co.
Gabor Melli, Yang Wang, Yudong Liu, Mehdi M.
Kashani, Zhongmin Shi, Baohua Gu, Anoop Sarkar,
and Fred Popowich. 2005. Description of
SQUASH, the SFU question answering summary
handler for the DUC-2005 summarization task. In
Proc. of DUC 2005.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. The NomBank project:
An interim report. In Proc. of HLT-NAACL 2004
Workshop on Frontiers in Corpus Annotation.
Srini Narayanan and Sanda Harabagiu. 2004. Ques-
tion answering based on semantic structures. In
Proc. of the 20th International Conference on Com-
putational Linguistics (COLING).
M. Palmer, P. Kingsbury, and D. Gildea. 2005. The
proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31(1):71–106.
Sameer Pradhan, Waybe Ward, Kadri Hacioglu, James
Martin, and Dan Jurafsky. 2004. Shallow semantic
parsing using support vector machines. In Proc. of
the Human Language Technology Conference/North
American Chapter of the Association of Computa-
tional Linguistics HLT/NAACL 2004.
Lance Ramshaw and Mitchell Marcus. 1994. Explor-
ing the statistical derivation of transformational rule
sequences for part-of-speech tagging. In The Bal-
ancing Act: Proc. of the ACL Workshop on Com-
bining Symbolic and Statistical Approaches to Lan-
guage.
Lance Ramshaw and Mitchell Marcus. 1995. Text
chunking using transformation-based learning. In
Proc. of the third workshop on very large corpora,
pages 82–94.
Dan Shen and Mirella Lapata. 2007. Using se-
mantic roles to improve question answering. In
Proc. of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing
and Computational Natural Language Learning
(EMNLP/CoNLL), pages 12–21.
Nianwen Xue. 2008. Labeling Chinese predicates
with semantic roles. Computational Linguistics,
34(2):224–255.
</reference>
<page confidence="0.997755">
167
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.949555">
<title confidence="0.999909">Predicate Argument Structure Analysis using Transformation-based Learning</title>
<author confidence="0.989661">Hirotoshi Taira Sanae Fujita Masaaki Nagata</author>
<affiliation confidence="0.999777">NTT Communication Science Laboratories</affiliation>
<address confidence="0.995487">2-4, Hikaridai, Seika-cho, Souraku-gun, Kyoto 619-0237, Japan</address>
<email confidence="0.976952">nagata.masaaki@lab.ntt.co.jp</email>
<abstract confidence="0.999209444444445">Maintaining high annotation consistency in large corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. This paper describes predicate argument structure analysis using transformation-based learning. An advantage of transformation-based learning is the readability of learned rules. A disadvantage is that the rule extraction procedure is time-consuming. We present incremental-based, transformation-based learning for semantic processing tasks. As an example, we deal with Japanese predicate argument analysis and show some tendencies of annotators for constructing a corpus with our method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven parsing.</title>
<date>1993</date>
<booktitle>In Proc. of the Third International Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="2849" citStr="Brill, 1993" startWordPosition="407" endWordPosition="408">rom time-type argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with such statistical learners as SVM is the lack of interpretability; if accuracy is low, we cannot identify the problems in the annotations. We are focusing on transformation-based learning (TBL). An advantage for such learning methods is that we can easily interpret the learned model. The tasks in most previous research are such simple tagging tasks as part-of-speech tagging, insertion and deletion of parentheses in syntactic parsing, and chunking (Brill, 1995; Brill, 1993; Ramshaw and Marcus, 1995). Here we experiment with a complex task: Japanese PASs. TBL can be slow, so we proposed an incremental training method to speed up the training. We experimented with a Japanese PAS corpus with a graph-based TBL. From the experiments, we interrelated the annotation tendency on the dataset. The rest of this paper is organized as follows. Section 2 describes Japanese predicate structure, our graph expression of it, and our improved method. The results of experiments using the NAIST Text Corpus, which is our target corpus, are reported in Section 3, and our conclusion i</context>
</contexts>
<marker>Brill, 1993</marker>
<rawString>Eric Brill. 1993. Transformation-based error-driven parsing. In Proc. of the Third International Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="2836" citStr="Brill, 1995" startWordPosition="405" endWordPosition="406">) arguments from time-type argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with such statistical learners as SVM is the lack of interpretability; if accuracy is low, we cannot identify the problems in the annotations. We are focusing on transformation-based learning (TBL). An advantage for such learning methods is that we can easily interpret the learned model. The tasks in most previous research are such simple tagging tasks as part-of-speech tagging, insertion and deletion of parentheses in syntactic parsing, and chunking (Brill, 1995; Brill, 1993; Ramshaw and Marcus, 1995). Here we experiment with a complex task: Japanese PASs. TBL can be slow, so we proposed an incremental training method to speed up the training. We experimented with a Japanese PAS corpus with a graph-based TBL. From the experiments, we interrelated the annotation tendency on the dataset. The rest of this paper is organized as follows. Section 2 describes Japanese predicate structure, our graph expression of it, and our improved method. The results of experiments using the NAIST Text Corpus, which is our target corpus, are reported in Section 3, and our</context>
<context position="5197" citStr="Brill, 1995" startWordPosition="797" endWordPosition="798"> the edge label. In our experiments below, we defined five argument types: nominative (subjective), accusative (direct objective), dative (indirect objective), time, and location. We use five transformation types: a) add or b) delete a predicate node, c) add or d) delete an edge between an predicate and an argument node, e) change a label (= an argument type) to another label (Fig. 2). We explain the existence of an edge between a predicate and an argument labeled t candidate node as that the predicate and the argument have a t type relationship. Transformation-based learning was proposed by (Brill, 1995). Below we explain our learning strategy when we directly adapt the learning method to our graph expression of PASs. First, unstructured texts from the training data are inputted. After pre-processing, each text is mapped to an initial graph. In our experiments, the initial graph has argument candidate nodes with corresponding BPs and no predicate nodes or edges. Next, comFigure 2: Transform types paring the current graphs with the gold standard graph structure in the training data, we find the different statuses of the nodes and edges among the graphs. We extract such transformation rule cand</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Charles Wooters</author>
<author>Collin F Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<booktitle>In Proc. of the Pacific Asian Conference on Language, Information and Computation (PACLING).</booktitle>
<contexts>
<context position="1620" citStr="Fillmore et al., 2001" startWordPosition="209" endWordPosition="212">structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect o</context>
</contexts>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>Charles J. Fillmore, Charles Wooters, and Collin F. Baker. 2001. Building a large lexical databank which provides deep semantics. In Proc. of the Pacific Asian Conference on Language, Information and Computation (PACLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kouichi Hashida</author>
</authors>
<title>Global document annotation (GDA)</title>
<date>2005</date>
<note>manual. http://i-content.org/GDA/.</note>
<contexts>
<context position="1775" citStr="Hashida, 2005" startWordPosition="238" endWordPosition="239"> information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with s</context>
</contexts>
<marker>Hashida, 2005</marker>
<rawString>Kouichi Hashida. 2005. Global document annotation (GDA) manual. http://i-content.org/GDA/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Patricia Robinson</author>
<author>Lisa Ferro</author>
<author>Nancy Chinchor</author>
<author>Erica Brown</author>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<date>1999</date>
<note>Hub-4 Event’99 general guidelines. http://www.itl.nist.gov/iaui/894.02/related projects/muc/.</note>
<contexts>
<context position="1209" citStr="Hirschman et al., 1999" startWordPosition="151" endWordPosition="154">ation-based learning is the readability of learned rules. A disadvantage is that the rule extraction procedure is time-consuming. We present incremental-based, transformation-based learning for semantic processing tasks. As an example, we deal with Japanese predicate argument analysis and show some tendencies of annotators for constructing a corpus with our method. 1 Introduction Automatic predicate argument structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawah</context>
</contexts>
<marker>Hirschman, Robinson, Ferro, Chinchor, Brown, Grishman, Sundheim, 1999</marker>
<rawString>Lynette Hirschman, Patricia Robinson, Lisa Ferro, Nancy Chinchor, Erica Brown, Ralph Grishman, and Beth Sundheim. 1999. Hub-4 Event’99 general guidelines. http://www.itl.nist.gov/iaui/894.02/related projects/muc/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating a Japanese text corpus with predicate-argument and coreference relations.</title>
<date>2007</date>
<booktitle>In Proc. of ACL 2007 Workshop on Linguistic Annotation,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="1873" citStr="Iida et al., 2007" startWordPosition="253" endWordPosition="256"> 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with such statistical learners as SVM is the lack of interpretability; if accuracy is low, we cannot ide</context>
<context position="8848" citStr="Iida et al., 2007" startWordPosition="1411" endWordPosition="1414">cle, we proceed to the next article. For the next article, we first adapt the rules learned from the previous article. After that, we extract new rules from the two articles until the total errors for the articles become zero. We continue these processes until the last article. Additionally, we count the number of rule occurrences and only use the rule candidates that happen more than once, because most such rules harm the accuracy. We save and use these rules again if the occurrence increases. 3 Experiments 3.1 Experimental Settings We used the articles in the NAIST Text Corpus version 1.4β (Iida et al., 2007) based on the Mainichi Shinbun Corpus (Mainichi, 1995), which were taken from news articles published in the Japanese Mainichi Shinbun newspaper. We used articles published on January 1st for training examples and on January 3rd for test examples. Three original argument types are defined in the NAIST Text Corpus: nominative (or subjective), accusative (or direct object), and dative (or indirect object). For evaluation of the difficult annotation cases, we also added annotations for ‘time’ and ‘location’ types by ourselves. We show the dataset distribution in Table 1. We extracted the BP units</context>
</contexts>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007. Annotating a Japanese text corpus with predicate-argument and coreference relations. In Proc. of ACL 2007 Workshop on Linguistic Annotation, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
</authors>
<title>Learning to transform linguistic graphs.</title>
<date>2007</date>
<booktitle>In Proc. of the Second Workshop on TextGraphs: GraphBased Algorithms for Natural Language Processing (TextGraphs-2),</booktitle>
<pages>53--60</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Jijkoun, de Rijke, 2007</marker>
<rawString>Valentin Jijkoun and Maarten de Rijke. 2007. Learning to transform linguistic graphs. In Proc. of the Second Workshop on TextGraphs: GraphBased Algorithms for Natural Language Processing (TextGraphs-2), pages 53–60. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Koichi Hashida</author>
</authors>
<title>Construction of a Japanese relevance-tagged corpus (in</title>
<date>2002</date>
<booktitle>Japanese). Proc. of the 8th Annual Meeting of the Association for Natural Language Processing,</booktitle>
<pages>495--498</pages>
<contexts>
<context position="1826" citStr="Kawahara et al., 2002" startWordPosition="244" endWordPosition="247">1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with such statistical learners as SVM is the lack of inte</context>
</contexts>
<marker>Kawahara, Kurohashi, Hashida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Koichi Hashida. 2002. Construction of a Japanese relevance-tagged corpus (in Japanese). Proc. of the 8th Annual Meeting of the Association for Natural Language Processing, pages 495–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th Conference on Natural Language Learning</booktitle>
<contexts>
<context position="4097" citStr="Kudo and Matsumoto, 2002" startWordPosition="608" endWordPosition="611">. 2 Predicate argument structure and graph transformation learning First, we illustrate the structure of a Japanese sentence in Fig. 1. In Japanese, we can divide a sentence into bunsetsu phrases (BP). A BP usually consists of one or more content words and zero, 162 Proceedings of the ACL 2010 Conference Short Papers, pages 162–167, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Figure 1: Graph expression for PAS one, or more than one functional words. Syntactic dependency between bunsetsu phrases can be defined. Japanese dependency parsers such as Cabocha (Kudo and Matsumoto, 2002) can extract BPs and their dependencies with about 90% accuracy. Since predicates and arguments in Japanese are mainly annotated on the head content word in each BP, we can deal with BPs as candidates of predicates or arguments. In our experiments, we mapped each BP to an argument candidate node of graphs. We also mapped each predicate to a predicate node. Each predicate-argument relation is identified by an edge between a predicate and an argument, and the argument type is mapped to the edge label. In our experiments below, we defined five argument types: nominative (subjective), accusative (</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Proc. of the 6th Conference on Natural Language Learning 2002 (CoNLL 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mainichi</author>
</authors>
<date>1995</date>
<journal>CD Mainichi Shinbun 94. Nichigai Associates Co.</journal>
<contexts>
<context position="8902" citStr="Mainichi, 1995" startWordPosition="1421" endWordPosition="1422">, we first adapt the rules learned from the previous article. After that, we extract new rules from the two articles until the total errors for the articles become zero. We continue these processes until the last article. Additionally, we count the number of rule occurrences and only use the rule candidates that happen more than once, because most such rules harm the accuracy. We save and use these rules again if the occurrence increases. 3 Experiments 3.1 Experimental Settings We used the articles in the NAIST Text Corpus version 1.4β (Iida et al., 2007) based on the Mainichi Shinbun Corpus (Mainichi, 1995), which were taken from news articles published in the Japanese Mainichi Shinbun newspaper. We used articles published on January 1st for training examples and on January 3rd for test examples. Three original argument types are defined in the NAIST Text Corpus: nominative (or subjective), accusative (or direct object), and dative (or indirect object). For evaluation of the difficult annotation cases, we also added annotations for ‘time’ and ‘location’ types by ourselves. We show the dataset distribution in Table 1. We extracted the BP units and dependencies among these BPs from the dataset usi</context>
</contexts>
<marker>Mainichi, 1995</marker>
<rawString>Mainichi. 1995. CD Mainichi Shinbun 94. Nichigai Associates Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Melli</author>
<author>Yang Wang</author>
<author>Yudong Liu</author>
<author>Mehdi M Kashani</author>
<author>Zhongmin Shi</author>
<author>Baohua Gu</author>
<author>Anoop Sarkar</author>
<author>Fred Popowich</author>
</authors>
<title>Description of SQUASH, the SFU question answering summary handler for the DUC-2005 summarization task.</title>
<date>2005</date>
<booktitle>In Proc. of DUC</booktitle>
<contexts>
<context position="1324" citStr="Melli et al., 2005" startWordPosition="167" endWordPosition="170">consuming. We present incremental-based, transformation-based learning for semantic processing tasks. As an example, we deal with Japanese predicate argument analysis and show some tendencies of annotators for constructing a corpus with our method. 1 Introduction Automatic predicate argument structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpor</context>
</contexts>
<marker>Melli, Wang, Liu, Kashani, Shi, Gu, Sarkar, Popowich, 2005</marker>
<rawString>Gabor Melli, Yang Wang, Yudong Liu, Mehdi M. Kashani, Zhongmin Shi, Baohua Gu, Anoop Sarkar, and Fred Popowich. 2005. Description of SQUASH, the SFU question answering summary handler for the DUC-2005 summarization task. In Proc. of DUC 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekely</author>
<author>Veronika Zielinska</author>
<author>Brian Young</author>
<author>Ralph Grishman</author>
</authors>
<title>The NomBank project: An interim report.</title>
<date>2004</date>
<booktitle>In Proc. of HLT-NAACL 2004 Workshop on Frontiers in Corpus Annotation.</booktitle>
<contexts>
<context position="1687" citStr="Meyers et al., 2004" startWordPosition="221" endWordPosition="224">m” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type argument is difficult because the a</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekely, Veronika Zielinska, Brian Young, and Ralph Grishman. 2004. The NomBank project: An interim report. In Proc. of HLT-NAACL 2004 Workshop on Frontiers in Corpus Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Question answering based on semantic structures.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="1260" citStr="Narayanan and Harabagiu, 2004" startWordPosition="157" endWordPosition="160">arned rules. A disadvantage is that the rule extraction procedure is time-consuming. We present incremental-based, transformation-based learning for semantic processing tasks. As an example, we deal with Japanese predicate argument analysis and show some tendencies of annotators for constructing a corpus with our method. 1 Introduction Automatic predicate argument structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida </context>
</contexts>
<marker>Narayanan, Harabagiu, 2004</marker>
<rawString>Srini Narayanan and Sanda Harabagiu. 2004. Question answering based on semantic structures. In Proc. of the 20th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>P Kingsbury</author>
<author>D Gildea</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="1652" citStr="Palmer et al., 2005" startWordPosition="214" endWordPosition="217">information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type </context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>M. Palmer, P. Kingsbury, and D. Gildea. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Waybe Ward</author>
<author>Kadri Hacioglu</author>
<author>James Martin</author>
<author>Dan Jurafsky</author>
</authors>
<title>Shallow semantic parsing using support vector machines.</title>
<date>2004</date>
<booktitle>In Proc. of the Human Language Technology Conference/North American Chapter of the Association of Computational Linguistics HLT/NAACL</booktitle>
<contexts>
<context position="1491" citStr="Pradhan et al., 2004" startWordPosition="190" endWordPosition="193">s and show some tendencies of annotators for constructing a corpus with our method. 1 Introduction Automatic predicate argument structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is har</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>Sameer Pradhan, Waybe Ward, Kadri Hacioglu, James Martin, and Dan Jurafsky. 2004. Shallow semantic parsing using support vector machines. In Proc. of the Human Language Technology Conference/North American Chapter of the Association of Computational Linguistics HLT/NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
</authors>
<title>Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging.</title>
<date>1994</date>
<booktitle>In The Balancing Act: Proc. of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language.</booktitle>
<contexts>
<context position="7415" citStr="Ramshaw and Marcus, 1994" startWordPosition="1167" endWordPosition="1170">reduction is very time-consuming, because we have to check many constraints from the candidate rules for all training samples. The calculation order is O(MN), where M is the number of articles and N is the number of candidate rules. Additionally, an edge rule usually has three types of constraints: ‘pred node constraint,’ ‘argument candidate node constraint,’ and ‘relation constraint.’ The number of combinations and extracted rules are much larger than one of the rules for the node rules. Ramshaw et al. proposed an index-based efficient reduction method for the calculation of error reduction (Ramshaw and Marcus, 1994). However, in PAS tasks, we need to check the exclusiveness of the argument types (for example, a predicate argument structure does not have two nominative ar163 guments), and we cannot directly use the method. Jijkoun et al. only used candidate rules that happen in the current and gold standard graphs and used SVM learning for constraint checks (Jijkoun and de Rijke, 2007). This method is effective for achieving high accuracy; however, it loses the readability of the rules. This is contrary to our aim to extract readable rules. To reduce the calculations while maintaining readability, we prop</context>
</contexts>
<marker>Ramshaw, Marcus, 1994</marker>
<rawString>Lance Ramshaw and Mitchell Marcus. 1994. Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging. In The Balancing Act: Proc. of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proc. of the</booktitle>
<pages>82--94</pages>
<contexts>
<context position="2876" citStr="Ramshaw and Marcus, 1995" startWordPosition="409" endWordPosition="412"> argument is difficult because the arguments of both types are often accompanied with the ‘ni’ case marker. A problem with such statistical learners as SVM is the lack of interpretability; if accuracy is low, we cannot identify the problems in the annotations. We are focusing on transformation-based learning (TBL). An advantage for such learning methods is that we can easily interpret the learned model. The tasks in most previous research are such simple tagging tasks as part-of-speech tagging, insertion and deletion of parentheses in syntactic parsing, and chunking (Brill, 1995; Brill, 1993; Ramshaw and Marcus, 1995). Here we experiment with a complex task: Japanese PASs. TBL can be slow, so we proposed an incremental training method to speed up the training. We experimented with a Japanese PAS corpus with a graph-based TBL. From the experiments, we interrelated the annotation tendency on the dataset. The rest of this paper is organized as follows. Section 2 describes Japanese predicate structure, our graph expression of it, and our improved method. The results of experiments using the NAIST Text Corpus, which is our target corpus, are reported in Section 3, and our conclusion is provided in Section 4. 2 </context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance Ramshaw and Mitchell Marcus. 1995. Text chunking using transformation-based learning. In Proc. of the third workshop on very large corpora, pages 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Mirella Lapata</author>
</authors>
<title>Using semantic roles to improve question answering.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL),</booktitle>
<pages>12--21</pages>
<contexts>
<context position="1284" citStr="Shen and Lapata, 2007" startWordPosition="161" endWordPosition="164">that the rule extraction procedure is time-consuming. We present incremental-based, transformation-based learning for semantic processing tasks. As an example, we deal with Japanese predicate argument analysis and show some tendencies of annotators for constructing a corpus with our method. 1 Introduction Automatic predicate argument structure analysis (PAS) provides information of “who did what to whom” and is an important base tool for such various text processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanes</context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>Dan Shen and Mirella Lapata. 2007. Using semantic roles to improve question answering. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 12–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling Chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="1732" citStr="Xue, 2008" startWordPosition="231" endWordPosition="232">processing tasks as machine translation information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004; Shen and Lapata, 2007), and summarization (Melli et al., 2005). Most recent approaches to predicate argument structure analysis are statistical machine learning methods such as support vector machines (SVMs)(Pradhan et al., 2004). For predicate argument structure analysis, we have the following representative large corpora: FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005), and NomBank (Meyers et al., 2004) in English, the Chinese PropBank (Xue, 2008) in Chinese, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002), and the NAIST Text Corpus (Iida et al., 2007) in Japanese. The construction of such large corpora is strenuous and time-consuming. Additionally, maintaining high annotation consistency in such corpora is crucial for statistical learning; however, such work is hard, especially for tasks containing semantic elements. For example, in Japanese corpora, distinguishing true dative (or indirect object) arguments from time-type argument is difficult because the arguments of both types are often accompanied </context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling Chinese predicates with semantic roles. Computational Linguistics, 34(2):224–255.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>