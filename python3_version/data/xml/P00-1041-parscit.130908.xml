<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.977452">
Headline Generation Based on Statistical Translation
</title>
<author confidence="0.996382">
Michele Banko
</author>
<affiliation confidence="0.9199345">
Computer Science Department
Johns Hopkins University
</affiliation>
<address confidence="0.957868">
Baltimore, MD 21218
</address>
<email confidence="0.998738">
banko@cs.jhu.edu
</email>
<author confidence="0.496924">
Vibhu O. Mittal
</author>
<affiliation confidence="0.406839">
Just Research
</affiliation>
<address confidence="0.852676">
4616 Henry Street
Pittsburgh, PA 15213
</address>
<email confidence="0.997575">
mittal@justresearch.com
</email>
<note confidence="0.754103">
Michael J. Witbrock
Lycos Inc.
</note>
<address confidence="0.7853955">
400-2 Totten Pond Road
Waltham, MA 023451
</address>
<email confidence="0.996985">
mwitbrock@lycos.com
</email>
<sectionHeader confidence="0.993874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999661636363636">
Extractive summarization techniques
cannot generate document summaries
shorter than a single sentence, some-
thing that is often required. An ideal
summarization system would under-
stand each document and generate an
appropriate summary directly from the
results of that understanding. A more
practical approach to this problem re-
sults in the use of an approximation:
viewing summarization as a problem
analogous to statistical machine trans-
lation. The issue then becomes one of
generating a target document in a more
concise language from a source docu-
ment in a more verbose language. This
paper presents results on experiments
using this approach, in which statisti-
cal models of the term selection and
term ordering are jointly applied to pro-
duce summaries in a style learned from
a training corpus.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99962325">
Generating effective summaries requires the abil-
ity to select, evaluate, order and aggregate items
of information according to their relevance to
a particular subject or for a particular purpose.
Most previous work on summarization has fo-
cused on extractive summarization: selecting text
spans - either complete sentences or paragraphs
– from the original document. These extracts are
</bodyText>
<footnote confidence="0.97835225">
Vibhu Mittal is now at Xerox PARC, 3333 Coyote
Hill Road, Palo Alto, CA 94304, USA. e-mail: vmit-
tal@parc.xerox.com; Michael Witbrock’s initial work on
this system was performed whilst at Just Research.
</footnote>
<bodyText confidence="0.99985144">
then arranged in a linear order (usually the same
order as in the original document) to form a sum-
mary document. There are several possible draw-
backs to this approach, one of which is the fo-
cus of this paper: the inability to generate co-
herent summaries shorter than the smallest text-
spans being considered – usually a sentence, and
sometimes a paragraph. This can be a problem,
because in many situations, a short headline style
indicative summary is desired. Since, in many
cases, the most important information in the doc-
ument is scattered across multiple sentences, this
is a problem for extractive summarization; worse,
sentences ranked best for summary selection of-
ten tend to be even longer than the average sen-
tence in the document.
This paper describes an alternative approach to
summarization capable of generating summaries
shorter than a sentence, some examples of which
are given in Figure 1. It does so by building sta-
tistical models for content selection and surface
realization. This paper reviews the framework,
discusses some of the pros and cons of this ap-
proach using examples from our corpus of news
wire stories, and presents an initial evaluation.
</bodyText>
<sectionHeader confidence="0.999853" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998774181818182">
Most previous work on summarization focused
on extractive methods, investigating issues such
as cue phrases (Luhn, 1958), positional indi-
cators (Edmundson, 1964), lexical occurrence
statistics (Mathis et al., 1973), probabilistic mea-
sures for token salience (Salton et al., 1997), and
the use of implicit discourse structure (Marcu,
1997). Work on combining an information ex-
traction phase followed by generation has also
been reported: for instance, the FRUMP sys-
tem (DeJong, 1982) used templates for both in-
</bodyText>
<listItem confidence="0.99621">
1: time -3.76 Beam 40
2: new customers -4.41 Beam 81
3: dell computer products -5.30 Beam 88
4: new power macs strategy -6.04 Beam 90
5: apple to sell macintosh users -8.20 Beam 86
6: new power macs strategy on internet -9.35 Beam 88
7: apple to sell power macs distribution strategy -10.32 Beam 89
8: new power macs distribution strategy on internet products -11.81 Beam 88
9: apple to sell power macs distribution strategy on internet -13.09 Beam 86
</listItem>
<figureCaption confidence="0.9980775">
Figure 1: Sample output from the system for a variety of target summary lengths from a single
input document.
</figureCaption>
<bodyText confidence="0.999831642857143">
formation extraction and presentation. More
recently, summarizers using sophisticated post-
extraction strategies, such as revision (McKeown
et al., 1999; Jing and McKeown, 1999; Mani et
al., 1999), and sophisticated grammar-based gen-
eration (Radev and McKeown, 1998) have also
been presented.
The work reported in this paper is most closely
related to work on statistical machine transla-
tion, particularly the ‘IBM-style’ work on CAN-
DIDE (Brown et al., 1993). This approach
was based on a statistical translation model that
mapped between sets of words in a source lan-
guage and sets of words in a target language, at
the same time using an ordering model to con-
strain possible token sequences in a target lan-
guage based on likelihood. In a similar vein,
a summarizer can be considered to be ‘translat-
ing’ between two languages: one verbose and the
other succinct (Berger and Lafferty, 1999; Wit-
brock and Mittal, 1999). However, by definition,
the translation during summarization is lossy, and
consequently, somewhat easier to design and ex-
periment with. As we will discuss in this paper,
we built several models of varying complexity;1
even the simplest one did reasonably well at sum-
marization, whereas it would have been severely
deficient at (traditional) translation.
</bodyText>
<footnote confidence="0.997244666666667">
1We have very recently become aware of related work
that builds upon more complex, structured models – syn-
tax trees – to compress single sentences (Knight and Marcu,
2000); our work differs from that work in (i) the level of
compression possible (much more) and, (ii) accuracy possi-
ble (less).
</footnote>
<sectionHeader confidence="0.981237" genericHeader="method">
3 The System
</sectionHeader>
<bodyText confidence="0.999873285714286">
As in any language generation task, summariza-
tion can be conceptually modeled as consisting
of two major sub-tasks: (1) content selection, and
(2) surface realization. Parameters for statistical
models of both of these tasks were estimated from
a training corpus of approximately 25,000 1997
Reuters news-wire articles on politics, technol-
ogy, health, sports and business. The target docu-
ments – the summaries – that the system needed
to learn the translation mapping to, were the head-
lines accompanying the news stories.
The documents were preprocessed before
training: formatting and mark-up information,
such as font changes and SGML/HTML tags, was
removed; punctuation, except apostrophes, was
also removed. Apart from these two steps, no
other normalization was performed. It is likely
that further processing, such as lemmatization,
might be useful, producing smaller and better lan-
guage models, but this was not evaluated for this
paper.
</bodyText>
<subsectionHeader confidence="0.999604">
3.1 Content Selection
</subsectionHeader>
<bodyText confidence="0.9994723">
Content selection requires that the system learn a
model of the relationship between the appearance
of some features in a document and the appear-
ance of corresponding features in the summary.
This can be modeled by estimating the likelihood
of some token appearing in a summary given that
some tokens (one or more, possibly different to-
kens) appeared in the document to be summa-
rized. The very simplest, “zero-level” model for
this relationship is the case when the two tokens
</bodyText>
<figure confidence="0.525562">
Proportion of documents
Length in words
</figure>
<figureCaption confidence="0.9975135">
Figure 2: Distribution of Headline Lengths for
early 1997 Reuters News Stories.
</figureCaption>
<bodyText confidence="0.999991270833334">
in the document and the summary are identical.
This can be computed as the conditional proba-
bility of a word occurring in the summary given
that the word appeared in the document:
where and represent the bags of words
that the headline and the document contain.
Once the parameters of a content selection
model have been estimated from a suitable doc-
ument/summary corpus, the model can be used to
compute selection scores for candidate summary
terms, given the terms occurring in a particular
source document. Specific subsets of terms, rep-
resenting the core summary content of an article,
can then be compared for suitability in generating
a summary. This can be done at two levels (1)
likelihood of the length of resulting summaries,
given the source document, and (2) likelihood of
forming a coherently ordered summary from the
content selected.
The length of the summary can also be learned
as a function of the source document. The sim-
plest model for document length is a fixed length
based on document genre. For the discussions in
this paper, this will be the model chosen. Figure 2
shows the distribution of headline length. As can
be seen, a Gaussian distribution could also model
the likely lengths quite accurately.
Finally, to simplify parameter estimation for
the content selection model, we can assume that
the likelihood of a word in the summary is inde-
pendent of other words in the summary. In this
case, the probability of any particular summary-
content candidate can be calculated simply as the
product of the probabilities of the terms in the
candidate set. Therefore, the overall probability
of a candidate summary, , consisting of words
, under the simplest, zero-level,
summary model based on the previous assump-
tions, can be computed as the product of the like-
lihood of (i) the terms selected for the summary,
(ii) the length of the resulting summary, and (iii)
the most likely sequencing of the terms in the con-
tent set.
In general, the probability of a word appearing
in a summary cannot be considered to be inde-
pendent of the structure of the summary, but the
independence assumption is an initial modeling
choice.
</bodyText>
<subsectionHeader confidence="0.999727">
3.2 Surface Realization
</subsectionHeader>
<bodyText confidence="0.999854166666667">
The probability of any particular surface ordering
as a headline candidate can be computed by mod-
eling the probability of word sequences. The sim-
plest model is a bigram language model, where
the probability of a word sequence is approxi-
mated by the product of the probabilities of seeing
each term given its immediate left context. Prob-
abilities for sequences that have not been seen
in the training data are estimated using back-off
weights (Katz, 1987). As mentioned earlier, in
principle, surface linearization calculations can
be carried out with respect to any textual spans
from characters on up, and could take into ac-
count additional information at the phrase level.
They could also, of course, be extended to use
higher order n-grams, providing that sufficient
numbers of training headlines were available to
estimate the probabilities.
</bodyText>
<figure confidence="0.999215583333333">
0 2 4 6 8 10 12
0.4
Summary lengths
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
headlines
</figure>
<subsectionHeader confidence="0.988893">
3.3 Search
</subsectionHeader>
<bodyText confidence="0.999921580645161">
Even though content selection and summary
structure generation have been presented sepa-
rately, there is no reason for them to occur inde-
pendently, and in fact, in our current implementa-
tion, they are used simultaneously to contribute to
an overall weighting scheme that ranks possible
summary candidates against each other. Thus, the
overall score used in ranking can be obtained as
a weighted combination of the content and struc-
ture model log probabilities. Cross-validation is
used to learn weights , and for a particular
document genre.
To generate a summary, it is necessary to find a
sequence of words that maximizes the probability,
under the content selection and summary struc-
ture models, that it was generated from the doc-
ument to be summarized. In the simplest, zero-
level model that we have discussed, since each
summary term is selected independently, and the
summary structure model is first order Markov,
it is possible to use Viterbi beam search (Forney,
1973) to efficiently find a near-optimal summary.
2 Other statistical models might require the use
of a different heuristic search algorithm. An ex-
ample of the results of a search for candidates of
various lengths is shown in Figure 1. It shows the
set of headlines generated by the system when run
against a real news story discussing Apple Com-
puter’s decision to start direct internet sales and
comparing it to the strategy of other computer
makers.
</bodyText>
<footnote confidence="0.870152888888889">
2In the experiments discussed in the following section, a
beam width of three, and a minimum beam size of twenty
states was used. In other experiments, we also tried to
strongly discourage paths that repeated terms, by reweight-
ing after backtracking at every state, since, otherwise, bi-
grams that start repeating often seem to pathologically over-
whelm the search; this reweighting violates the first order
Markovian assumptions, but seems to to more good than
harm.
</footnote>
<sectionHeader confidence="0.996825" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.992219294117647">
Zero level–Model: The system was trained on
approximately 25,000 news articles from Reuters
dated between 1/Jan/1997 and 1/Jun/1997. Af-
ter punctuation had been stripped, these contained
about 44,000 unique tokens in the articles and
slightly more than 15,000 tokens in the headlines.
Representing all the pairwise conditional proba-
bilities for all combinations of article and head-
line words3 added significant complexity, so we
simplified our model further and investigated the
effectiveness of training on a more limited vocab-
ulary: the set of all the words that appeared in any
of the headlines.4 Conditional probabilities for
words in the headlines that also appeared in the
articles were computed. As discussed earlier, in
our zero-level model, the system was also trained
on bigram transition probabilities as an approx-
imation to the headline syntax. Sample output
from the system using this simplified model is
shown in Figures 1 and 3.
Zero Level–Performance Evaluation: The
zero-level model, that we have discussed so far,
works surprisingly well, given its strong inde-
pendence assumptions and very limited vocabu-
lary. There are problems, some of which are most
likely due to lack of sufficient training data.5 Ide-
ally, we should want to evaluate the system’s per-
formance in terms both of content selection suc-
cess and realization quality. However, it is hard
to computationally evaluate coherence and phras-
ing effectiveness, so we have, to date, restricted
ourselves to the content aspect, which is more
amenable to a quantitative analysis. (We have ex-
perience doing much more laborious human eval-
</bodyText>
<footnote confidence="0.682544352941176">
3This requires a matrix with 660 million entries, or about
2.6GB of memory. This requirement can be significantly re-
duced by using a threshold to prune values and using a sparse
matrix representation for the remaining pairs. However, in-
ertia and the easy availability of the CMU-Cambridge Sta-
tistical Modeling Toolkit – which generates the full matrix
– have so far conspired to prevent us from exercising that
option.
4An alternative approach to limiting the size of the map-
pings that need to be estimated would be to use only the top
words, where could have a small value in the hundreds,
rather than the thousands, together with the words appear-
ing in the headlines. This would limit the size of the model
while still allowing more flexible content selection.
5We estimate that approximately 100MB of training data
would give us reasonable estimates for the models that we
would like to evaluate; we had access to much less.
</footnote>
<note confidence="0.308598">
&lt;HEADLINE&gt; U.S. Pushes for
Mideast Peace &lt;/HEADLINE&gt;
</note>
<bodyText confidence="0.986421214285714">
President Clinton met with his top
Mideast advisers, including Secre-
tary of State Madeleine Albright and
U.S. peace envoy Dennis Ross, in
preparation for a session with Israel
Prime Minister Benjamin Netanyahu
tomorrow. Palestinian leader Yasser
Arafat is to meet with Clinton later this
week. Published reports in Israel say
Netanyahu will warn Clinton that Israel
can’t withdraw from more than nine
percent of the West Bank in its next
scheduled pullback, although Clinton
wants a 12-15 percent pullback.
</bodyText>
<listItem confidence="0.986669714285714">
1: clinton -6 0
2: clinton wants -15 2
3: clinton netanyahu arafat -21 24
4: clinton to mideast peace -28 98
5: clinton to meet netanyahu arafat -33 298
6: clinton to meet netanyahu arafat is- -40 1291
rael
</listItem>
<figureCaption confidence="0.8507336">
Figure 3: Sample article (with original headline)
and system generated output using the simplest,
zero-level, lexical model. Numbers to the right
are log probabilities of the string, and search
beam size, respectively.
</figureCaption>
<bodyText confidence="0.999752">
uation, and plan to do so with our statistical ap-
proach as well, once the model is producing sum-
maries that might be competitive with alternative
approaches.)
After training, the system was evaluated on a
separate, previously unseen set of 1000 Reuters
news stories, distributed evenly amongst the same
topics found in the training set. For each of these
stories, headlines were generated for a variety of
lengths and compared against the (i) the actual
headlines, as well as (ii) the sentence ranked as
the most important summary sentence. The lat-
ter is interesting because it helps suggest the de-
gree to which headlines used a different vocabu-
lary from that used in the story itself.6 Term over-
</bodyText>
<footnote confidence="0.967564">
6The summarizer we used here to test was an off-the-
</footnote>
<table confidence="0.976061571428572">
Gen. Headline Word Percentage of
Length (words) Overlap complete matches
4 0.2140 19.71%
5 0.2027 14.10%
6 0.2080 12.14%
7 0.1754 08.70%
8 0.1244 11.90%
</table>
<tableCaption confidence="0.986895">
Table 1: Evaluating the use of the simplest lexi-
</tableCaption>
<bodyText confidence="0.967420107142857">
cal model for content selection on 1000 Reuters
news articles. The headline length given is that a
which the overlap between the terms in the target
headline and the generated summary was maxi-
mized. The percentage of complete matches in-
dicates how many of the summaries of a given
length had all their terms included in the target
headline.
lap between the generated headlines and the test
standards (both the actual headline and the sum-
mary sentence) was the metric of performance.
For each news article, the maximum overlap
between the actual headline and the generated
headline was noted; the length at which this
overlap was maximal was also taken into ac-
count. Also tallied were counts of headlines that
matched completely – that is, all of the words in
the generated headline were present in the actual
headline – as well as their lengths. These statis-
tics illustrate the system’s performance in select-
ing content words for the headlines. Actual head-
lines are often, also, ungrammatical, incomplete
phrases. It is likely that more sophisticated lan-
guage models, such as structure models (Chelba,
1997; Chelba and Jelinek, 1998), or longer n-
gram models would lead to the system generating
headlines that were more similar in phrasing to
real headlines because longer range dependencies
</bodyText>
<footnote confidence="0.798862">
shelf Carnegie Mellon University summarizer, which was
the top ranked extraction based summarizer for news stories
at the 1998 DARPA-TIPSTER evaluation workshop (Tip,
1998). This summarizer uses a weighted combination of
sentence position, lexical features and simple syntactical
measures such as sentence length to rank sentences. The
use of this summarizer should not be taken as a indicator of
its value as a testing standard; it has more to do with the ease
of use and the fact that it was a reasonable candidate.
</footnote>
<table confidence="0.995643625">
Overlap with headline Overlap with summary
L Lex +Position +POS +Position+POS Lex +Position +POS +Position+POS
1 0.37414 0.39888 0.30522 0.40538 0.61589 0.70787 0.64919 0.67741
2 0.24818 0.26923 0.27246 0.27838 0.57447 0.63905 0.57831 0.63315
3 0.21831 0.24612 0.20388 0.25048 0.55251 0.63760 0.55610 0.62726
4 0.21404 0.24011 0.18721 0.25741 0.56167 0.65819 0.52982 0.61099
5 0.20272 0.21685 0.18447 0.21947 0.55099 0.63371 0.53578 0.58584
6 0.20804 0.19886 0.17593 0.21168 0.55817 0.60511 0.51466 0.58802
</table>
<tableCaption confidence="0.996656">
Table 2: Overlap between terms in the generated headlines and in the original headlines and extracted
</tableCaption>
<bodyText confidence="0.974421818181818">
summary sentences, respectively, of the article. Using Part of Speech (POS) and information about a
token’s location in the source document, in addition to the lexical information, helps improve perfor-
mance on the Reuters’ test set.
could be taken into account. Table 1 shows the re-
sults of these term selection schemes. As can be
seen, even with such an impoverished language
model, the system does quite well: when the gen-
erated headlines are four words long almost one
in every five has all of its words matched in the
article s actual headline. This percentage drops,
as is to be expected, as headlines get longer.
Multiple Selection Models: POS and Position
As we mentioned earlier, the zero-level model
that we have discussed so far can be extended to
take into account additional information both for
the content selection and for the surface realiza-
tion strategy. We will briefly discuss the use of
two additional sources of information: (i) part of
speech (POS) information, and (ii) positional in-
formation.
POS information can be used both in content
selection – to learn which word-senses are more
likely to be part of a headline – and in surface re-
alization. Training a POS model for both these
tasks requires far less data than training a lexi-
cal model, since the number of POS tags is much
smaller. We used a mixture model (McLachlan
and Basford, 1988) – combining the lexical and
the POS probabilities – for both the content se-
lection and the linearization tasks.
Another indicator of salience is positional in-
formation, which has often been cited as one of
the most important cues for summarization by ex-
</bodyText>
<listItem confidence="0.982547173913043">
1: clinton -23.27
2: clinton wants -52.44
3: clinton in albright -76.20
4: clinton to meet albright -105.5
5: clinton in israel for albright -129.9
6: clinton in israel to meet albright -158.57
(a) System generated output using a lexical + POS model.
1: clinton -3.71
2: clinton mideast -12.53
3: clinton netanyahu arafat -17.66
4: clinton netanyahu arafat israel -23.1
5: clinton to meet netanyahu arafat -28.8
6: clinton to meet netanyahu arafat israel -34.38
(b) System generated output using a lexical + positional
model.
1: clinton -21.66
2: clinton wants -51.12
3: clinton in israel - 58.13
4: clinton meet with israel -78.47
5: clinton to meet with israel -87.08
6: clinton to meet with netanyahu arafat -107.44
(c) System generated output using a lexical + POS + posi-
tional model.
</listItem>
<figureCaption confidence="0.95393075">
Figure 4: Output generated by the system using
augmented lexical models. Numbers to the right
are log probabilities of the generated strings un-
der the generation model.
</figureCaption>
<table confidence="0.997064">
Original term Generated term Original headline Generated headline
Nations Top Judge Rehnquist Wall Street Stocks Decline Dow Jones index lower
Kaczynski Unabomber Suspect 49ers Roll Over Vikings 38-22 49ers to nfc title game
ER Top-Rated Hospital Drama Corn, Wheat Prices Fall soybean grain prices lower
Drugs Cocaine Many Hopeful on N. Ireland Ac- britain ireland hopeful of irish
cord peace
</table>
<tableCaption confidence="0.997457">
Table 3: Some pairs of target headline and generated summary terms that were counted as errors by
</tableCaption>
<bodyText confidence="0.965996454545455">
the evaluation, but which are semantically equivalent, together with some “equally good” generated
headlines that were counted as wrong in the evaluation.
traction (Hovy and Lin, 1997; Mittal et al., 1999).
We trained a content selection model based on the
position of the tokens in the training set in their
respective documents. There are several models
of positional salience that have been proposed for
sentence selection; we used the simplest possible
one: estimating the probability of a token appear-
ing in the headline given that it appeared in the
1st, 2nd, 3rd or 4th quartile of the body of the ar-
ticle. We then tested mixtures of the lexical and
POS models, lexical and positional models, and
all three models combined together. Sample out-
put for the article in Figure 3, using both lexi-
cal and POS/positional information can be seen
in Figure 4. As can be seen in Table 2,7 Al-
though adding the POS information alone does
not seem to provide any benefit, positional infor-
mation does. When used in combination, each of
the additional information sources seems to im-
prove the overall model of summary generation.
Problems with evaluation: Some of the statis-
tics that we presented in the previous discus-
sion suggest that this relatively simple statisti-
cal summarization system is not very good com-
pared to some of the extraction based summa-
rization systems that have been presented else-
where (e.g., (Radev and Mani, 1997)). However,
it is worth emphasizing that many of the head-
lines generated by the system were quite good,
but were penalized because our evaluation met-
ric was based on the word-error rate and the gen-
erated headline terms did not exactly match the
original ones. A quick manual scan of some of the
failures that might have been scored as successes
7Unlike the data in Table 1, these headlines contain only
six words or fewer.
in a subjective manual evaluation indicated that
some of these errors could not have been avoided
without adding knowledge to the system, for ex-
ample, allowing the use of alternate terms for re-
ferring to collective nouns. Some of these errors
are shown in Table 3.
</bodyText>
<sectionHeader confidence="0.998044" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999975">
This paper has presented an alternative to ex-
tractive summarization: an approach that makes
it possible to generate coherent summaries that
are shorter than a single sentence and that at-
tempt to conform to a particular style. Our ap-
proach applies statistical models of the term se-
lection and term ordering processes to produce
short summaries, shorter than those reported pre-
viously. Furthermore, with a slight generaliza-
tion of the system described here, the summaries
need not contain any of the words in the original
document, unlike previous statistical summariza-
tion systems. Given good training corpora, this
approach can also be used to generate headlines
from a variety of formats: in one case, we experi-
mented with corpora that contained Japanese doc-
uments and English headlines. This resulted in a
working system that could simultaneously trans-
late and summarize Japanese documents.8
The performance of the system could be im-
proved by improving either content selection or
linearization. This can be through the use of more
sophisticated models, such as additional language
models that take into account the signed distance
between words in the original story to condition
</bodyText>
<footnote confidence="0.6255585">
8Since our initial corpus was constructed by running a
simple lexical translation system over Japanese headlines,
the results were poor, but we have high hopes that usable
summaries may be produced by training over larger corpora.
</footnote>
<bodyText confidence="0.999561225806452">
the probability that they should appear separated
by some distance in the headline.
Recently, we have extended the model to gen-
erate multi-sentential summaries as well: for in-
stance, given an initial sentence such as “Clinton
to meet visit MidEast.” and words that are related
to nouns (“Clinton” and “mideast”) in the first
sentence, the system biases the content selection
model to select other nouns that have high mu-
tual information with these nouns. In the exam-
ple sentence, this generated the subsequent sen-
tence “US urges Israel plan.” This model cur-
rently has several problems that we are attempt-
ing to address: for instance, the fact that the
words co-occur in adjacent sentences in the train-
ing set is not sufficient to build coherent adjacent
sentences (problems with pronominal references,
cue phrases, sequence, etc. abound). Further-
more, our initial experiments have suffered from
a lack of good training and testing corpora; few
of the news stories we have in our corpora con-
tain multi-sentential headlines.
While the results so far can only be seen as in-
dicative, this breed of non-extractive summariza-
tion holds a great deal of promise, both because of
its potential to integrate many types of informa-
tion about source documents and intended sum-
maries, and because of its potential to produce
very brief coherent summaries. We expect to im-
prove both the quality and scope of the summaries
produced in future work.
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999927042857143">
Adam Berger and John Lafferty. 1999. Information retrieval
as statistical translation. In Proc. of the 22nd ACMSIGIR
Conference (SIGIR-99), Berkeley, CA.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estimation.
Computational Linguistics, (2):263–312.
Ciprian Chelba and F. Jelinek. 1998. Exploiting syntac-
tic structure for language modeling. In Proc. ofACL-98,
Montreal, Canada. ACL.
Ciprian Chelba. 1997. A structured language model. In
Proc. of the ACL-97, Madrid, Spain. ACL.
Gerald F. DeJong. 1982. An overview of the FRUMP sys-
tem. In Wendy G. Lehnert and Martin H. Ringle, editors,
Strategies for Natural Language Processing, pages 149–
176. Lawrence Erlbaum Associates, Hillsdale, NJ.
H. P. Edmundson. 1964. Problems in automatic extracting.
Communications of the ACM, 7:259–263.
G. D. Forney. 1973. The Viterbi Algorithm. Proc. of the
IEEE, pages 268–278.
Eduard Hovy and Chin Yew Lin. 1997. Automated text
summarization in SUMMARIST. In Proc. of the Wkshp on
Intelligent Scalable Text Summarization, ACL-97.
Hongyan Jing and Kathleen McKeown. 1999. The decom-
position of human-written summary sentences. In Proc.
of the 22nd ACM SIGIR Conference, Berkeley, CA.
S. Katz. 1987. Estimation of probabilities from sparse data
for the language model component of a speech recog-
nizer. IEEE Transactions on Acoustics, Speech and Sig-
nal Processing, 24.
Kevin Knight and Daniel Marcu. 2000. Statistics-based
summarization — step one: Sentence compression. In
Proc. ofAAAI-2000, Austin, TX.
P. H. Luhn. 1958. Automatic creation of literature abstracts.
IBM Journal, pages 159–165.
Inderjeet Mani, Barbara Gates, and Eric Bloedorn. 1999.
Improving summaries by revising them. In Proc. ofACL-
99, Baltimore, MD.
Daniel Marcu. 1997. From discourse structures to text sum-
maries. In Proc. of the ACL’97 Wkshp on Intelligent Text
Summarization, pages 82–88, Spain.
B. A. Mathis, J. E. Rush, and C. E. Young. 1973. Improve-
ment of automatic abstracts by the use of structural anal-
ysis. JASIS, 24:101–109.
Kathleen R. McKeown, J. Klavans, V. Hatzivassiloglou,
R. Barzilay, and E. Eskin. 1999. Towards Multidoc-
ument Summarization by Reformulation: Progress and
Prospects. In Proc. ofAAAI-99. AAAI.
G.J. McLachlan and K. E. Basford. 1988. Mixture Models.
Marcel Dekker, New York, NY.
Vibhu O. Mittal, Mark Kantrowitz, Jade Goldstein, and
Jaime Carbonell. 1999. Selecting Text Spans for Doc-
ument Summaries: Heuristics and Metrics. In Proc. of
AAAI-99, pages 467–473, Orlando, FL, July. AAAI.
Dragomir Radev and Inderjeet Mani, editors. 1997. Proc.
of the Workshop on Intelligent Scalable Text Summariza-
tion, ACL/EACL-97 (Madrid). ACL, Madrid, Spain.
Dragomir Radev and Kathy McKeown. 1998. Gener-
ating natural language summaries from multiple online
sources. Compuutational Linguistics.
Gerard Salton, A. Singhal, M. Mitra, and C. Buckley. 1997.
Automatic text structuring and summary. Info. Proc. and
Management, 33(2):193–207, March.
1998. Tipster text phase III 18-month workshop notes, May.
Fairfax, VA.
Michael Witbrock and Vibhu O. Mittal. 1999. Head-
line generation: A framework for generating highly-
condensed non-extractive summaries. In Proc. of the
22nd ACM SIGIR Conference (SIGIR-99), pages 315–
316, Berkeley, CA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981253">
<title confidence="0.999827">Headline Generation Based on Statistical Translation</title>
<author confidence="0.999995">Michele Banko</author>
<affiliation confidence="0.999842">Computer Science Department Johns Hopkins University</affiliation>
<address confidence="0.999885">Baltimore, MD 21218</address>
<email confidence="0.999727">banko@cs.jhu.edu</email>
<author confidence="0.997689">Vibhu O Mittal</author>
<affiliation confidence="0.996269">Just Research</affiliation>
<address confidence="0.999472">4616 Henry Street Pittsburgh, PA 15213</address>
<email confidence="0.999324">mittal@justresearch.com</email>
<author confidence="0.999997">Michael J Witbrock</author>
<affiliation confidence="0.999702">Lycos Inc.</affiliation>
<address confidence="0.999644">400-2 Totten Pond Road Waltham, MA 023451</address>
<email confidence="0.999814">mwitbrock@lycos.com</email>
<abstract confidence="0.999571347826087">Extractive summarization techniques cannot generate document summaries shorter than a single sentence, something that is often required. An ideal summarization system would understand each document and generate an appropriate summary directly from the results of that understanding. A more practical approach to this problem results in the use of an approximation: viewing summarization as a problem analogous to statistical machine translation. The issue then becomes one of generating a target document in a more concise language from a source document in a more verbose language. This paper presents results on experiments using this approach, in which statistical models of the term selection and term ordering are jointly applied to produce summaries in a style learned from a training corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Information retrieval as statistical translation.</title>
<date>1999</date>
<booktitle>In Proc. of the 22nd ACMSIGIR Conference (SIGIR-99),</booktitle>
<location>Berkeley, CA.</location>
<contexts>
<context position="4898" citStr="Berger and Lafferty, 1999" startWordPosition="775" endWordPosition="778">8) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be considered to be ‘translating’ between two languages: one verbose and the other succinct (Berger and Lafferty, 1999; Witbrock and Mittal, 1999). However, by definition, the translation during summarization is lossy, and consequently, somewhat easier to design and experiment with. As we will discuss in this paper, we built several models of varying complexity;1 even the simplest one did reasonably well at summarization, whereas it would have been severely deficient at (traditional) translation. 1We have very recently become aware of related work that builds upon more complex, structured models – syntax trees – to compress single sentences (Knight and Marcu, 2000); our work differs from that work in (i) the </context>
</contexts>
<marker>Berger, Lafferty, 1999</marker>
<rawString>Adam Berger and John Lafferty. 1999. Information retrieval as statistical translation. In Proc. of the 22nd ACMSIGIR Conference (SIGIR-99), Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>2--263</pages>
<contexts>
<context position="4467" citStr="Brown et al., 1993" startWordPosition="699" endWordPosition="702">cs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation extraction and presentation. More recently, summarizers using sophisticated postextraction strategies, such as revision (McKeown et al., 1999; Jing and McKeown, 1999; Mani et al., 1999), and sophisticated grammar-based generation (Radev and McKeown, 1998) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be considered to be ‘translating’ between two languages: one verbose and the other succinct (Berger and Lafferty, 1999; Witbrock and Mittal, 1999). However, by definition, the translation during summarization is lossy, and consequently, somewhat easier to design and experiment with. As </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, (2):263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
<author>F Jelinek</author>
</authors>
<title>Exploiting syntactic structure for language modeling.</title>
<date>1998</date>
<booktitle>In Proc. ofACL-98,</booktitle>
<publisher>ACL.</publisher>
<location>Montreal, Canada.</location>
<contexts>
<context position="17757" citStr="Chelba and Jelinek, 1998" startWordPosition="2881" endWordPosition="2884">e maximum overlap between the actual headline and the generated headline was noted; the length at which this overlap was maximal was also taken into account. Also tallied were counts of headlines that matched completely – that is, all of the words in the generated headline were present in the actual headline – as well as their lengths. These statistics illustrate the system’s performance in selecting content words for the headlines. Actual headlines are often, also, ungrammatical, incomplete phrases. It is likely that more sophisticated language models, such as structure models (Chelba, 1997; Chelba and Jelinek, 1998), or longer ngram models would lead to the system generating headlines that were more similar in phrasing to real headlines because longer range dependencies shelf Carnegie Mellon University summarizer, which was the top ranked extraction based summarizer for news stories at the 1998 DARPA-TIPSTER evaluation workshop (Tip, 1998). This summarizer uses a weighted combination of sentence position, lexical features and simple syntactical measures such as sentence length to rank sentences. The use of this summarizer should not be taken as a indicator of its value as a testing standard; it has more </context>
</contexts>
<marker>Chelba, Jelinek, 1998</marker>
<rawString>Ciprian Chelba and F. Jelinek. 1998. Exploiting syntactic structure for language modeling. In Proc. ofACL-98, Montreal, Canada. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
</authors>
<title>A structured language model.</title>
<date>1997</date>
<booktitle>In Proc. of the ACL-97,</booktitle>
<publisher>ACL.</publisher>
<location>Madrid,</location>
<contexts>
<context position="17730" citStr="Chelba, 1997" startWordPosition="2879" endWordPosition="2880">ws article, the maximum overlap between the actual headline and the generated headline was noted; the length at which this overlap was maximal was also taken into account. Also tallied were counts of headlines that matched completely – that is, all of the words in the generated headline were present in the actual headline – as well as their lengths. These statistics illustrate the system’s performance in selecting content words for the headlines. Actual headlines are often, also, ungrammatical, incomplete phrases. It is likely that more sophisticated language models, such as structure models (Chelba, 1997; Chelba and Jelinek, 1998), or longer ngram models would lead to the system generating headlines that were more similar in phrasing to real headlines because longer range dependencies shelf Carnegie Mellon University summarizer, which was the top ranked extraction based summarizer for news stories at the 1998 DARPA-TIPSTER evaluation workshop (Tip, 1998). This summarizer uses a weighted combination of sentence position, lexical features and simple syntactical measures such as sentence length to rank sentences. The use of this summarizer should not be taken as a indicator of its value as a tes</context>
</contexts>
<marker>Chelba, 1997</marker>
<rawString>Ciprian Chelba. 1997. A structured language model. In Proc. of the ACL-97, Madrid, Spain. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald F DeJong</author>
</authors>
<title>An overview of the FRUMP system.</title>
<date>1982</date>
<booktitle>Strategies for Natural Language Processing,</booktitle>
<pages>149</pages>
<editor>In Wendy G. Lehnert and Martin H. Ringle, editors,</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="3421" citStr="DeJong, 1982" startWordPosition="528" endWordPosition="529"> and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation e</context>
</contexts>
<marker>DeJong, 1982</marker>
<rawString>Gerald F. DeJong. 1982. An overview of the FRUMP system. In Wendy G. Lehnert and Martin H. Ringle, editors, Strategies for Natural Language Processing, pages 149– 176. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Edmundson</author>
</authors>
<title>Problems in automatic extracting.</title>
<date>1964</date>
<journal>Communications of the ACM,</journal>
<pages>7--259</pages>
<contexts>
<context position="3100" citStr="Edmundson, 1964" startWordPosition="479" endWordPosition="480">document. This paper describes an alternative approach to summarization capable of generating summaries shorter than a sentence, some examples of which are given in Figure 1. It does so by building statistical models for content selection and surface realization. This paper reviews the framework, discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell p</context>
</contexts>
<marker>Edmundson, 1964</marker>
<rawString>H. P. Edmundson. 1964. Problems in automatic extracting. Communications of the ACM, 7:259–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Forney</author>
</authors>
<title>The Viterbi Algorithm.</title>
<date>1973</date>
<booktitle>Proc. of the IEEE,</booktitle>
<pages>268--278</pages>
<contexts>
<context position="11229" citStr="Forney, 1973" startWordPosition="1812" endWordPosition="1813">g can be obtained as a weighted combination of the content and structure model log probabilities. Cross-validation is used to learn weights , and for a particular document genre. To generate a summary, it is necessary to find a sequence of words that maximizes the probability, under the content selection and summary structure models, that it was generated from the document to be summarized. In the simplest, zerolevel model that we have discussed, since each summary term is selected independently, and the summary structure model is first order Markov, it is possible to use Viterbi beam search (Forney, 1973) to efficiently find a near-optimal summary. 2 Other statistical models might require the use of a different heuristic search algorithm. An example of the results of a search for candidates of various lengths is shown in Figure 1. It shows the set of headlines generated by the system when run against a real news story discussing Apple Computer’s decision to start direct internet sales and comparing it to the strategy of other computer makers. 2In the experiments discussed in the following section, a beam width of three, and a minimum beam size of twenty states was used. In other experiments, w</context>
</contexts>
<marker>Forney, 1973</marker>
<rawString>G. D. Forney. 1973. The Viterbi Algorithm. Proc. of the IEEE, pages 268–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Chin Yew Lin</author>
</authors>
<title>Automated text summarization in SUMMARIST.</title>
<date>1997</date>
<booktitle>In Proc. of the Wkshp on Intelligent Scalable Text Summarization, ACL-97.</booktitle>
<contexts>
<context position="22294" citStr="Hovy and Lin, 1997" startWordPosition="3616" endWordPosition="3619"> headline Nations Top Judge Rehnquist Wall Street Stocks Decline Dow Jones index lower Kaczynski Unabomber Suspect 49ers Roll Over Vikings 38-22 49ers to nfc title game ER Top-Rated Hospital Drama Corn, Wheat Prices Fall soybean grain prices lower Drugs Cocaine Many Hopeful on N. Ireland Ac- britain ireland hopeful of irish cord peace Table 3: Some pairs of target headline and generated summary terms that were counted as errors by the evaluation, but which are semantically equivalent, together with some “equally good” generated headlines that were counted as wrong in the evaluation. traction (Hovy and Lin, 1997; Mittal et al., 1999). We trained a content selection model based on the position of the tokens in the training set in their respective documents. There are several models of positional salience that have been proposed for sentence selection; we used the simplest possible one: estimating the probability of a token appearing in the headline given that it appeared in the 1st, 2nd, 3rd or 4th quartile of the body of the article. We then tested mixtures of the lexical and POS models, lexical and positional models, and all three models combined together. Sample output for the article in Figure 3, </context>
</contexts>
<marker>Hovy, Lin, 1997</marker>
<rawString>Eduard Hovy and Chin Yew Lin. 1997. Automated text summarization in SUMMARIST. In Proc. of the Wkshp on Intelligent Scalable Text Summarization, ACL-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
<author>Kathleen McKeown</author>
</authors>
<title>The decomposition of human-written summary sentences.</title>
<date>1999</date>
<booktitle>In Proc. of the 22nd ACM SIGIR Conference,</booktitle>
<location>Berkeley, CA.</location>
<contexts>
<context position="4185" citStr="Jing and McKeown, 1999" startWordPosition="654" endWordPosition="657">tegy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation extraction and presentation. More recently, summarizers using sophisticated postextraction strategies, such as revision (McKeown et al., 1999; Jing and McKeown, 1999; Mani et al., 1999), and sophisticated grammar-based generation (Radev and McKeown, 1998) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be co</context>
</contexts>
<marker>Jing, McKeown, 1999</marker>
<rawString>Hongyan Jing and Kathleen McKeown. 1999. The decomposition of human-written summary sentences. In Proc. of the 22nd ACM SIGIR Conference, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Katz</author>
</authors>
<title>Estimation of probabilities from sparse data for the language model component of a speech recognizer.</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustics, Speech and Signal Processing,</journal>
<volume>24</volume>
<contexts>
<context position="9771" citStr="Katz, 1987" startWordPosition="1573" endWordPosition="1574">nnot be considered to be independent of the structure of the summary, but the independence assumption is an initial modeling choice. 3.2 Surface Realization The probability of any particular surface ordering as a headline candidate can be computed by modeling the probability of word sequences. The simplest model is a bigram language model, where the probability of a word sequence is approximated by the product of the probabilities of seeing each term given its immediate left context. Probabilities for sequences that have not been seen in the training data are estimated using back-off weights (Katz, 1987). As mentioned earlier, in principle, surface linearization calculations can be carried out with respect to any textual spans from characters on up, and could take into account additional information at the phrase level. They could also, of course, be extended to use higher order n-grams, providing that sufficient numbers of training headlines were available to estimate the probabilities. 0 2 4 6 8 10 12 0.4 Summary lengths 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0 headlines 3.3 Search Even though content selection and summary structure generation have been presented separately, there is no reason for</context>
</contexts>
<marker>Katz, 1987</marker>
<rawString>S. Katz. 1987. Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Transactions on Acoustics, Speech and Signal Processing, 24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistics-based summarization — step one: Sentence compression.</title>
<date>2000</date>
<booktitle>In Proc. ofAAAI-2000,</booktitle>
<location>Austin, TX.</location>
<contexts>
<context position="5453" citStr="Knight and Marcu, 2000" startWordPosition="862" endWordPosition="865">uages: one verbose and the other succinct (Berger and Lafferty, 1999; Witbrock and Mittal, 1999). However, by definition, the translation during summarization is lossy, and consequently, somewhat easier to design and experiment with. As we will discuss in this paper, we built several models of varying complexity;1 even the simplest one did reasonably well at summarization, whereas it would have been severely deficient at (traditional) translation. 1We have very recently become aware of related work that builds upon more complex, structured models – syntax trees – to compress single sentences (Knight and Marcu, 2000); our work differs from that work in (i) the level of compression possible (much more) and, (ii) accuracy possible (less). 3 The System As in any language generation task, summarization can be conceptually modeled as consisting of two major sub-tasks: (1) content selection, and (2) surface realization. Parameters for statistical models of both of these tasks were estimated from a training corpus of approximately 25,000 1997 Reuters news-wire articles on politics, technology, health, sports and business. The target documents – the summaries – that the system needed to learn the translation mapp</context>
</contexts>
<marker>Knight, Marcu, 2000</marker>
<rawString>Kevin Knight and Daniel Marcu. 2000. Statistics-based summarization — step one: Sentence compression. In Proc. ofAAAI-2000, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Luhn</author>
</authors>
<title>Automatic creation of literature abstracts.</title>
<date>1958</date>
<journal>IBM Journal,</journal>
<pages>159--165</pages>
<contexts>
<context position="3059" citStr="Luhn, 1958" startWordPosition="474" endWordPosition="475">er than the average sentence in the document. This paper describes an alternative approach to summarization capable of generating summaries shorter than a sentence, some examples of which are given in Figure 1. It does so by building statistical models for content selection and surface realization. This paper reviews the framework, discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on </context>
</contexts>
<marker>Luhn, 1958</marker>
<rawString>P. H. Luhn. 1958. Automatic creation of literature abstracts. IBM Journal, pages 159–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Barbara Gates</author>
<author>Eric Bloedorn</author>
</authors>
<title>Improving summaries by revising them.</title>
<date>1999</date>
<booktitle>In Proc. ofACL99,</booktitle>
<location>Baltimore, MD.</location>
<contexts>
<context position="4205" citStr="Mani et al., 1999" startWordPosition="658" endWordPosition="661">ple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation extraction and presentation. More recently, summarizers using sophisticated postextraction strategies, such as revision (McKeown et al., 1999; Jing and McKeown, 1999; Mani et al., 1999), and sophisticated grammar-based generation (Radev and McKeown, 1998) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be considered to be ‘tran</context>
</contexts>
<marker>Mani, Gates, Bloedorn, 1999</marker>
<rawString>Inderjeet Mani, Barbara Gates, and Eric Bloedorn. 1999. Improving summaries by revising them. In Proc. ofACL99, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>From discourse structures to text summaries.</title>
<date>1997</date>
<booktitle>In Proc. of the ACL’97 Wkshp on Intelligent Text Summarization,</booktitle>
<pages>82--88</pages>
<contexts>
<context position="3277" citStr="Marcu, 1997" startWordPosition="505" endWordPosition="506">s so by building statistical models for content selection and surface realization. This paper reviews the framework, discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on i</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. From discourse structures to text summaries. In Proc. of the ACL’97 Wkshp on Intelligent Text Summarization, pages 82–88, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Mathis</author>
<author>J E Rush</author>
<author>C E Young</author>
</authors>
<title>Improvement of automatic abstracts by the use of structural analysis.</title>
<date>1973</date>
<journal>JASIS,</journal>
<pages>24--101</pages>
<contexts>
<context position="3153" citStr="Mathis et al., 1973" startWordPosition="484" endWordPosition="487">roach to summarization capable of generating summaries shorter than a sentence, some examples of which are given in Figure 1. It does so by building statistical models for content selection and surface realization. This paper reviews the framework, discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new</context>
</contexts>
<marker>Mathis, Rush, Young, 1973</marker>
<rawString>B. A. Mathis, J. E. Rush, and C. E. Young. 1973. Improvement of automatic abstracts by the use of structural analysis. JASIS, 24:101–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>J Klavans</author>
<author>V Hatzivassiloglou</author>
<author>R Barzilay</author>
<author>E Eskin</author>
</authors>
<title>Towards Multidocument Summarization by Reformulation: Progress and Prospects.</title>
<date>1999</date>
<booktitle>In Proc. ofAAAI-99.</booktitle>
<publisher>AAAI.</publisher>
<contexts>
<context position="4161" citStr="McKeown et al., 1999" startWordPosition="650" endWordPosition="653">4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation extraction and presentation. More recently, summarizers using sophisticated postextraction strategies, such as revision (McKeown et al., 1999; Jing and McKeown, 1999; Mani et al., 1999), and sophisticated grammar-based generation (Radev and McKeown, 1998) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein</context>
</contexts>
<marker>McKeown, Klavans, Hatzivassiloglou, Barzilay, Eskin, 1999</marker>
<rawString>Kathleen R. McKeown, J. Klavans, V. Hatzivassiloglou, R. Barzilay, and E. Eskin. 1999. Towards Multidocument Summarization by Reformulation: Progress and Prospects. In Proc. ofAAAI-99. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J McLachlan</author>
<author>K E Basford</author>
</authors>
<title>Mixture Models.</title>
<date>1988</date>
<publisher>Marcel Dekker,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="20408" citStr="McLachlan and Basford, 1988" startWordPosition="3309" endWordPosition="3312"> can be extended to take into account additional information both for the content selection and for the surface realization strategy. We will briefly discuss the use of two additional sources of information: (i) part of speech (POS) information, and (ii) positional information. POS information can be used both in content selection – to learn which word-senses are more likely to be part of a headline – and in surface realization. Training a POS model for both these tasks requires far less data than training a lexical model, since the number of POS tags is much smaller. We used a mixture model (McLachlan and Basford, 1988) – combining the lexical and the POS probabilities – for both the content selection and the linearization tasks. Another indicator of salience is positional information, which has often been cited as one of the most important cues for summarization by ex1: clinton -23.27 2: clinton wants -52.44 3: clinton in albright -76.20 4: clinton to meet albright -105.5 5: clinton in israel for albright -129.9 6: clinton in israel to meet albright -158.57 (a) System generated output using a lexical + POS model. 1: clinton -3.71 2: clinton mideast -12.53 3: clinton netanyahu arafat -17.66 4: clinton netany</context>
</contexts>
<marker>McLachlan, Basford, 1988</marker>
<rawString>G.J. McLachlan and K. E. Basford. 1988. Mixture Models. Marcel Dekker, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vibhu O Mittal</author>
<author>Mark Kantrowitz</author>
<author>Jade Goldstein</author>
<author>Jaime Carbonell</author>
</authors>
<title>Selecting Text Spans for Document Summaries: Heuristics and Metrics.</title>
<date>1999</date>
<booktitle>In Proc. of AAAI-99,</booktitle>
<pages>467--473</pages>
<publisher>AAAI.</publisher>
<location>Orlando, FL,</location>
<contexts>
<context position="22316" citStr="Mittal et al., 1999" startWordPosition="3620" endWordPosition="3623">p Judge Rehnquist Wall Street Stocks Decline Dow Jones index lower Kaczynski Unabomber Suspect 49ers Roll Over Vikings 38-22 49ers to nfc title game ER Top-Rated Hospital Drama Corn, Wheat Prices Fall soybean grain prices lower Drugs Cocaine Many Hopeful on N. Ireland Ac- britain ireland hopeful of irish cord peace Table 3: Some pairs of target headline and generated summary terms that were counted as errors by the evaluation, but which are semantically equivalent, together with some “equally good” generated headlines that were counted as wrong in the evaluation. traction (Hovy and Lin, 1997; Mittal et al., 1999). We trained a content selection model based on the position of the tokens in the training set in their respective documents. There are several models of positional salience that have been proposed for sentence selection; we used the simplest possible one: estimating the probability of a token appearing in the headline given that it appeared in the 1st, 2nd, 3rd or 4th quartile of the body of the article. We then tested mixtures of the lexical and POS models, lexical and positional models, and all three models combined together. Sample output for the article in Figure 3, using both lexical and</context>
</contexts>
<marker>Mittal, Kantrowitz, Goldstein, Carbonell, 1999</marker>
<rawString>Vibhu O. Mittal, Mark Kantrowitz, Jade Goldstein, and Jaime Carbonell. 1999. Selecting Text Spans for Document Summaries: Heuristics and Metrics. In Proc. of AAAI-99, pages 467–473, Orlando, FL, July. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir Radev</author>
<author>Inderjeet Mani</author>
<author>editors</author>
</authors>
<date>1997</date>
<booktitle>Proc. of the Workshop on Intelligent Scalable Text Summarization, ACL/EACL-97</booktitle>
<location>(Madrid). ACL, Madrid, Spain.</location>
<marker>Radev, Mani, editors, 1997</marker>
<rawString>Dragomir Radev and Inderjeet Mani, editors. 1997. Proc. of the Workshop on Intelligent Scalable Text Summarization, ACL/EACL-97 (Madrid). ACL, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir Radev</author>
<author>Kathy McKeown</author>
</authors>
<title>Generating natural language summaries from multiple online sources. Compuutational Linguistics.</title>
<date>1998</date>
<contexts>
<context position="4275" citStr="Radev and McKeown, 1998" startWordPosition="667" endWordPosition="670">tegy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Beam 88 9: apple to sell power macs distribution strategy on internet -13.09 Beam 86 Figure 1: Sample output from the system for a variety of target summary lengths from a single input document. formation extraction and presentation. More recently, summarizers using sophisticated postextraction strategies, such as revision (McKeown et al., 1999; Jing and McKeown, 1999; Mani et al., 1999), and sophisticated grammar-based generation (Radev and McKeown, 1998) have also been presented. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be considered to be ‘translating’ between two languages: one verbose and the other succinct (Be</context>
</contexts>
<marker>Radev, McKeown, 1998</marker>
<rawString>Dragomir Radev and Kathy McKeown. 1998. Generating natural language summaries from multiple online sources. Compuutational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>A Singhal</author>
<author>M Mitra</author>
<author>C Buckley</author>
</authors>
<title>Automatic text structuring and summary.</title>
<date>1997</date>
<booktitle>Info. Proc. and Management,</booktitle>
<volume>33</volume>
<issue>2</issue>
<location>Fairfax, VA.</location>
<contexts>
<context position="3218" citStr="Salton et al., 1997" startWordPosition="494" endWordPosition="497">an a sentence, some examples of which are given in Figure 1. It does so by building statistical models for content selection and surface realization. This paper reviews the framework, discusses some of the pros and cons of this approach using examples from our corpus of news wire stories, and presents an initial evaluation. 2 Related Work Most previous work on summarization focused on extractive methods, investigating issues such as cue phrases (Luhn, 1958), positional indicators (Edmundson, 1964), lexical occurrence statistics (Mathis et al., 1973), probabilistic measures for token salience (Salton et al., 1997), and the use of implicit discourse structure (Marcu, 1997). Work on combining an information extraction phase followed by generation has also been reported: for instance, the FRUMP system (DeJong, 1982) used templates for both in1: time -3.76 Beam 40 2: new customers -4.41 Beam 81 3: dell computer products -5.30 Beam 88 4: new power macs strategy -6.04 Beam 90 5: apple to sell macintosh users -8.20 Beam 86 6: new power macs strategy on internet -9.35 Beam 88 7: apple to sell power macs distribution strategy -10.32 Beam 89 8: new power macs distribution strategy on internet products -11.81 Bea</context>
</contexts>
<marker>Salton, Singhal, Mitra, Buckley, 1997</marker>
<rawString>Gerard Salton, A. Singhal, M. Mitra, and C. Buckley. 1997. Automatic text structuring and summary. Info. Proc. and Management, 33(2):193–207, March. 1998. Tipster text phase III 18-month workshop notes, May. Fairfax, VA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Witbrock</author>
<author>Vibhu O Mittal</author>
</authors>
<title>Headline generation: A framework for generating highlycondensed non-extractive summaries.</title>
<date>1999</date>
<booktitle>In Proc. of the 22nd ACM SIGIR Conference (SIGIR-99),</booktitle>
<pages>315--316</pages>
<location>Berkeley, CA.</location>
<contexts>
<context position="4926" citStr="Witbrock and Mittal, 1999" startWordPosition="779" endWordPosition="783">. The work reported in this paper is most closely related to work on statistical machine translation, particularly the ‘IBM-style’ work on CANDIDE (Brown et al., 1993). This approach was based on a statistical translation model that mapped between sets of words in a source language and sets of words in a target language, at the same time using an ordering model to constrain possible token sequences in a target language based on likelihood. In a similar vein, a summarizer can be considered to be ‘translating’ between two languages: one verbose and the other succinct (Berger and Lafferty, 1999; Witbrock and Mittal, 1999). However, by definition, the translation during summarization is lossy, and consequently, somewhat easier to design and experiment with. As we will discuss in this paper, we built several models of varying complexity;1 even the simplest one did reasonably well at summarization, whereas it would have been severely deficient at (traditional) translation. 1We have very recently become aware of related work that builds upon more complex, structured models – syntax trees – to compress single sentences (Knight and Marcu, 2000); our work differs from that work in (i) the level of compression possibl</context>
</contexts>
<marker>Witbrock, Mittal, 1999</marker>
<rawString>Michael Witbrock and Vibhu O. Mittal. 1999. Headline generation: A framework for generating highlycondensed non-extractive summaries. In Proc. of the 22nd ACM SIGIR Conference (SIGIR-99), pages 315– 316, Berkeley, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>