<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.080420">
<title confidence="0.9490855">
RavenCalendar: A Multimodal Dialog System for Managing a
Personal Calendar∗
</title>
<author confidence="0.986014">
Svetlana Stenchikova and Basia Mucha and Sarah Hoffman and Amanda Stent
</author>
<affiliation confidence="0.968305">
Department of Computer Science
Stony Brook University
</affiliation>
<address confidence="0.895926">
Stony Brook, NY 11794-4400
</address>
<email confidence="0.998793">
sveta,basia,shoffman,stent@cs.sunysb.edu
</email>
<sectionHeader confidence="0.999561" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997972896551724">
Dialog applications for managing calendars have
been developed for every generation of dialog
systems research (Heidorn, 1978; Yankelovich,
1994; Constantinides and others, 1998; Horvitz
and Paek, 2000; Vo and Wood, 1996; Huang
and others, 2001). Today, Web-based calendar
applications are widely used. A spoken dialog
interface to a Web-based calendar application
permits convenient use of the system on a hand-
held device or over the telephone.
In this demo, we present RavenCalendar,
a multimodal dialog system built around the
Google Calendar and Google Maps Web appli-
cations. RavenCalendar allows the user to cre-
ate, modify and remove calendar events, query
for events, and hear descriptions of events. In
our demonstration we will focus on two aspects
of RavenCalendar: its flexible approach to lan-
guage understanding and dialog management,
and its multimodal interface.
Flexible dialog management In RavenCal-
endar, during event management or event query-
ing a user can provide event information either
in a single utterance (e.g. “Add a meeting for
tomorrow from two to three in the computer sci-
ence lounge” or by engaging in a subdialog with
the system (Table 1). This functionality is made
possible because we use the Ravenclaw dialog
manager (Bohus and Rudnicky, 2003).
</bodyText>
<footnote confidence="0.9879104">
∗We would like to thank Dan Bohus, Antoine Raux,
and Thomas Harris for providing Olympus, and for an-
swering many questions about Ravenclaw. This research
is based on work supported by the National Science Foun-
dation under grant no. 0325188.
</footnote>
<table confidence="0.884517888888889">
S: Welcome to RavenCalendar,
the automated dialog calendar system.
S: What can I do for you today?
U: add a meeting for Monday
S: For what time do you want to add the meeting?
U: from ten until eleven
S: The event was added type meeting
for tomorrow starting at ten a.m.
U: List all events for the next week
</table>
<tableCaption confidence="0.999457">
Table 1: Sample dialog with RavenCalendar
</tableCaption>
<bodyText confidence="0.99801975">
Multimodality A RavenCalendar user may
interact with the calendar directly using the
Google Calendar interface, or may interact
through RavenCalendar using text, speech, map
gestures or a combination of these media. A user
may use the Google Maps interface to specify
the location of an event; the system uses Google
Maps to display the locations of events.
</bodyText>
<sectionHeader confidence="0.985161" genericHeader="categories and subject descriptors">
2 System Description
</sectionHeader>
<bodyText confidence="0.9831485">
RavenCalendar, whose architecture is shown in
Figure 1, is developed using Ravenclaw and
Olympus (Bohus and others, 2007). Olympus
is a dialog system shell; Ravenclaw is the Olym-
pus dialog manager. In developing RavenCal-
endar, we chose to use an existing dialog shell
to save time on system development. (We are
gradually replacing the Olympus components
for speech recognition, generation and TTS.)
RavenCalendar is one of the first dialog systems
based on Olympus to be developed outside of
CMU. Other Olympus-based systems developed
at CMU include the Let’s Go (Raux and oth-
ers, 2005), Room Line, and LARRI (Bohus and
Rudnicky, 2002) systems.
Flexible dialog management The Raven-
claw dialog manager (Bohus and Rudnicky,
2003) allows “object-oriented” specification of a
</bodyText>
<page confidence="0.976782">
15
</page>
<author confidence="0.240222">
NAACL HLT Demonstration Program, pages 15–16,
</author>
<affiliation confidence="0.742453">
Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<figureCaption confidence="0.999875">
Figure 1: RavenCalendar Design
</figureCaption>
<bodyText confidence="0.999524764705882">
dialog structure. In RavenCalendar, we define
the dialog as a graph. Each node in the graph
is a minimal dialog component that performs a
specific action and has pre- and post-conditions.
The dialog flow is determined by edges between
nodes. With this structure, we maximize the
reuse of minimal dialog components. Ravenclaw
gives a natural way to define a dialog, but fine-
tuning the dialog manager was the most chal-
lenging part of system development.
Multimodality In RavenCalendar, a back-
end server integrates with Google Calendar for
storing event data. Also, a maps front end server
integrates with Google Maps. In addition to the
locations recognized by Google Maps, an XML
file with pre-selected location-name mappings
helps the user specify locations.
</bodyText>
<sectionHeader confidence="0.961828" genericHeader="conclusions">
3 Current and Future Work
</sectionHeader>
<bodyText confidence="0.999906571428572">
We are currently modifying RavenCalendar
to use grammar-based speech recognition for
tighter integration of speech recognition and
parsing, to automatically modify its parsing
grammar to accommodate the words in the
user’s calendar, to permit trainable, adaptable
response generation, and to connect to addi-
tional Web services and Web-based data re-
sources. This last topic is particularly inter-
esting to us. RavenCalendar already uses sev-
eral Web-based applications, but there are many
other Web services of potential utility to mo-
bile users. We are now building a component
for RavenClaw that searches a list of URLs for
event types of interest to the user (e.g. sports
events, music events), and automatically notifies
the user of events of interest. In the future, we
plan to incorporate additional Web-based func-
tionality, with the ultimate goal of creating a
general-purpose dialog interface to Web appli-
cations and services.
</bodyText>
<sectionHeader confidence="0.997341" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981232757575758">
D. Bohus et al. 2007. Olympus: an open-source
framework for conversational spoken language in-
terface research. In Proceedings of the Workshop
”Bridging the Gap” at HLT/NAACL 2007.
D. Bohus and A. Rudnicky. 2002. LARRI: A
language-based maintenance and repair assistant.
In Proceedings of IDS.
D. Bohus and A. Rudnicky. 2003. Ravenclaw: Dia-
log management using hierarchical task decompo-
sition and an expectation agenda. In Proceedings
of Eurospeech.
P. Constantinides et al. 1998. A schema based ap-
proach to dialog control. In Proceedings of ICSLP.
G. Heidorn. 1978. Natural language dialogue for
managing an on-line calendar. In Proceedings of
ACM/CSCER.
E. Horvitz and T. Paek. 2000. DeepListener: Har-
nessing expected utility to guide clarification dia-
log in spoken language systems. In Proceedings of
ICSLP.
X. Huang et al. 2001. MIPAD: A next generation
PDA prototype. In Proceedings of ICSLP.
A. Raux et al. 2005. Let’s go public! Taking a spo-
ken dialog system to the real world. In Proceedings
of Interspeech.
M. Tue Vo and C. Wood. 1996. Building an appli-
cation framework for speech and pen input inte-
gration in multimodal learning interfaces. In Pro-
ceedings of ICASSP.
N. Yankelovich. 1994. Talking vs taking: Speech ac-
cess to remote computers. In Proceedings of the
Conference on Human Factors in Computing Sys-
tems.
</reference>
<page confidence="0.998687">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.899801">
<title confidence="0.999978">RavenCalendar: A Multimodal Dialog System for Managing</title>
<author confidence="0.999728">Stenchikova Mucha Hoffman</author>
<affiliation confidence="0.996687">Department of Computer</affiliation>
<author confidence="0.9573015">Stony Brook Stony Brook</author>
<author confidence="0.9573015">NY</author>
<email confidence="0.982531">sveta,basia,shoffman,stent@cs.sunysb.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bohus</author>
</authors>
<title>Olympus: an open-source framework for conversational spoken language interface research.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop ”Bridging the Gap” at HLT/NAACL</booktitle>
<marker>Bohus, 2007</marker>
<rawString>D. Bohus et al. 2007. Olympus: an open-source framework for conversational spoken language interface research. In Proceedings of the Workshop ”Bridging the Gap” at HLT/NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bohus</author>
<author>A Rudnicky</author>
</authors>
<title>LARRI: A language-based maintenance and repair assistant.</title>
<date>2002</date>
<booktitle>In Proceedings of IDS.</booktitle>
<contexts>
<context position="3169" citStr="Bohus and Rudnicky, 2002" startWordPosition="498" endWordPosition="501">ar, whose architecture is shown in Figure 1, is developed using Ravenclaw and Olympus (Bohus and others, 2007). Olympus is a dialog system shell; Ravenclaw is the Olympus dialog manager. In developing RavenCalendar, we chose to use an existing dialog shell to save time on system development. (We are gradually replacing the Olympus components for speech recognition, generation and TTS.) RavenCalendar is one of the first dialog systems based on Olympus to be developed outside of CMU. Other Olympus-based systems developed at CMU include the Let’s Go (Raux and others, 2005), Room Line, and LARRI (Bohus and Rudnicky, 2002) systems. Flexible dialog management The Ravenclaw dialog manager (Bohus and Rudnicky, 2003) allows “object-oriented” specification of a 15 NAACL HLT Demonstration Program, pages 15–16, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics Figure 1: RavenCalendar Design dialog structure. In RavenCalendar, we define the dialog as a graph. Each node in the graph is a minimal dialog component that performs a specific action and has pre- and post-conditions. The dialog flow is determined by edges between nodes. With this structure, we maximize the reuse of minimal </context>
</contexts>
<marker>Bohus, Rudnicky, 2002</marker>
<rawString>D. Bohus and A. Rudnicky. 2002. LARRI: A language-based maintenance and repair assistant. In Proceedings of IDS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bohus</author>
<author>A Rudnicky</author>
</authors>
<title>Ravenclaw: Dialog management using hierarchical task decomposition and an expectation agenda.</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="1561" citStr="Bohus and Rudnicky, 2003" startWordPosition="230" endWordPosition="233">nts, query for events, and hear descriptions of events. In our demonstration we will focus on two aspects of RavenCalendar: its flexible approach to language understanding and dialog management, and its multimodal interface. Flexible dialog management In RavenCalendar, during event management or event querying a user can provide event information either in a single utterance (e.g. “Add a meeting for tomorrow from two to three in the computer science lounge” or by engaging in a subdialog with the system (Table 1). This functionality is made possible because we use the Ravenclaw dialog manager (Bohus and Rudnicky, 2003). ∗We would like to thank Dan Bohus, Antoine Raux, and Thomas Harris for providing Olympus, and for answering many questions about Ravenclaw. This research is based on work supported by the National Science Foundation under grant no. 0325188. S: Welcome to RavenCalendar, the automated dialog calendar system. S: What can I do for you today? U: add a meeting for Monday S: For what time do you want to add the meeting? U: from ten until eleven S: The event was added type meeting for tomorrow starting at ten a.m. U: List all events for the next week Table 1: Sample dialog with RavenCalendar Multimo</context>
<context position="3261" citStr="Bohus and Rudnicky, 2003" startWordPosition="511" endWordPosition="514"> and others, 2007). Olympus is a dialog system shell; Ravenclaw is the Olympus dialog manager. In developing RavenCalendar, we chose to use an existing dialog shell to save time on system development. (We are gradually replacing the Olympus components for speech recognition, generation and TTS.) RavenCalendar is one of the first dialog systems based on Olympus to be developed outside of CMU. Other Olympus-based systems developed at CMU include the Let’s Go (Raux and others, 2005), Room Line, and LARRI (Bohus and Rudnicky, 2002) systems. Flexible dialog management The Ravenclaw dialog manager (Bohus and Rudnicky, 2003) allows “object-oriented” specification of a 15 NAACL HLT Demonstration Program, pages 15–16, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics Figure 1: RavenCalendar Design dialog structure. In RavenCalendar, we define the dialog as a graph. Each node in the graph is a minimal dialog component that performs a specific action and has pre- and post-conditions. The dialog flow is determined by edges between nodes. With this structure, we maximize the reuse of minimal dialog components. Ravenclaw gives a natural way to define a dialog, but finetuning the dial</context>
</contexts>
<marker>Bohus, Rudnicky, 2003</marker>
<rawString>D. Bohus and A. Rudnicky. 2003. Ravenclaw: Dialog management using hierarchical task decomposition and an expectation agenda. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Constantinides</author>
</authors>
<title>A schema based approach to dialog control.</title>
<date>1998</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<marker>Constantinides, 1998</marker>
<rawString>P. Constantinides et al. 1998. A schema based approach to dialog control. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heidorn</author>
</authors>
<title>Natural language dialogue for managing an on-line calendar.</title>
<date>1978</date>
<booktitle>In Proceedings of ACM/CSCER.</booktitle>
<marker>Heidorn, 1978</marker>
<rawString>G. Heidorn. 1978. Natural language dialogue for managing an on-line calendar. In Proceedings of ACM/CSCER.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Horvitz</author>
<author>T Paek</author>
</authors>
<title>DeepListener: Harnessing expected utility to guide clarification dialog in spoken language systems.</title>
<date>2000</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<marker>Horvitz, Paek, 2000</marker>
<rawString>E. Horvitz and T. Paek. 2000. DeepListener: Harnessing expected utility to guide clarification dialog in spoken language systems. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
</authors>
<title>MIPAD: A next generation PDA prototype.</title>
<date>2001</date>
<booktitle>In Proceedings of ICSLP.</booktitle>
<marker>Huang, 2001</marker>
<rawString>X. Huang et al. 2001. MIPAD: A next generation PDA prototype. In Proceedings of ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Raux</author>
</authors>
<title>Let’s go public! Taking a spoken dialog system to the real world.</title>
<date>2005</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<marker>Raux, 2005</marker>
<rawString>A. Raux et al. 2005. Let’s go public! Taking a spoken dialog system to the real world. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tue Vo</author>
<author>C Wood</author>
</authors>
<title>Building an application framework for speech and pen input integration in multimodal learning interfaces.</title>
<date>1996</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<marker>Vo, Wood, 1996</marker>
<rawString>M. Tue Vo and C. Wood. 1996. Building an application framework for speech and pen input integration in multimodal learning interfaces. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Yankelovich</author>
</authors>
<title>Talking vs taking: Speech access to remote computers.</title>
<date>1994</date>
<booktitle>In Proceedings of the Conference on Human Factors in Computing Systems.</booktitle>
<marker>Yankelovich, 1994</marker>
<rawString>N. Yankelovich. 1994. Talking vs taking: Speech access to remote computers. In Proceedings of the Conference on Human Factors in Computing Systems.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>