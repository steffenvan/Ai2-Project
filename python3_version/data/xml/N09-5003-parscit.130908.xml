<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002707">
<title confidence="0.918281">
STAT: Speech Transcription Analysis Tool
</title>
<author confidence="0.656957">
Stephen A. Kunath
</author>
<note confidence="0.532301333333333">
Program in Linguistics
3e4 George Mason University
Fairfax, VA 22030
</note>
<email confidence="0.996518">
skunath@gmu.edu
</email>
<note confidence="0.6623985">
Steven H. Weinberger
Program in Linguistics
3e4 George Mason University
Fairfax, VA 22030
</note>
<email confidence="0.997641">
weinberg@gmu.edu
</email>
<sectionHeader confidence="0.993817" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9983534">
The Speech Transcription Analysis Tool
(STAT) is an open source tool for aligning
and comparing two phonetically transcribed
texts of human speech. The output analysis is
a parameterized set of phonological differ-
ences. These differences are based upon a se-
lectable set of binary phonetic features such as
[voice], [continuant], [high], etc. STAT was
initially designed to provide sets of
phonological speech patterns in the compari-
sons of various English accents found in the
Speech Accent Archive http://accent.gmu.edu,
but its scope and utility expand to matters of
language assessment, phonetic training, foren-
sic linguistics, and speech recognition.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949388888889">
The theoretical and practical value of studying
human accented speech is of interest to language
teachers, linguists, and computational linguists. It
is also part of the research program behind the
Speech Accent Archive (http://accent.gmu.edu)
housed at George Mason University. The Archive
is a growing database of English speech varieties
that contains more than 1,100 samples of native
and non-native speakers reading from the same
English paragraph. The non-native speakers of
English come from more than 250 language back-
grounds and include a variety of different levels of
English speech abilities. The native samples dem-
onstrate the various dialects of English speech
from around the world. All samples include pho-
netic transcriptions, phonological generalizations,
demographic and geographic information. For
comparison purposes, the Archive also includes
</bodyText>
<page confidence="0.952005">
9
</page>
<bodyText confidence="0.99991104">
phonetic sound inventories from more than 200
world languages so that researchers can perform
various contrastive analyses and accented speech
studies.
No matter how subtle an accent is, human lis-
teners can immediately and automatically notice
that speakers are different. For example, Chinese
speakers of English sound different from French
speakers of English. The Speech Accent Archive
stores and presents data that specifies and codifies
these speech differences at the phonetic segment
level. Trained human linguists compare a standard
speech sample with phonetically transcribed
speech samples from each (non-standard or non-
native) speaker and distill from this analysis a set
of phonological speech patterns (PSPs) for each
speaker. Essentially, the task is to discover the
precise factors or features responsible for humans
to categorize say, a Vietnamese speaker of English
differently from a so-called standard English
speaker. While such analyses are theoretically and
practically valuable, the process of comparing two
phonetically transcribed speech samples requires
explicit training, is time-consuming, and is difficult
to update.
</bodyText>
<sectionHeader confidence="0.884381" genericHeader="method">
2 Phonological Speech Patterns
</sectionHeader>
<bodyText confidence="0.998970833333333">
As an example of how we manually derive the
PSPs for a non-native English speaker, we begin
by comparing the narrow phonetic transcription of
a “standard” North American English sample (1),
with a representative non-native speaker of English
(here a Vietnamese speaker (2)):
</bodyText>
<footnote confidence="0.6000372">
(1) [pʰl̥iiːz kʰɑlˠ stɛlə æskɚ ɾə bɹɪ̃ŋ ðiiːz θɪ̃ŋz
wɪθɚ fɹʌ̃m ðə stɔɹ sɪks spũunz əv fɹɛʃ snoʊ
pʰiiːz faɪːv θɪk sl̥æːbz əv bluː ʧiiːz æn meɪbi ə
snæk˺ fɚ hɚ bɹʌðɚ bɑːb wii ɑlˠso niiː̃ɾə smɑlˠ
pʰl̥æstɪk˺ sneɪk æ̃nə bɪːɡ tʰɔɪ fɹ̥ɑːɡ fɚ ðə kʰɪːdz
</footnote>
<note confidence="0.302961">
Proceedings of NAACL HLT 2009: Demonstrations, pages 9–12,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.922915">
ʃii kə̃n skʷuup˺ ðiiːz θɪŋ̃z ɪ̃ntə θɹ̥ii ɹɛːd˺ bæːɡz
æ̃ːn wii wɪlˠ ɡoʊ miit hɚ wɛ̃nzdeɪ æt˺ ðə tʰɹ̥eɪ̃n
steɪʃə̃n]
</bodyText>
<listItem confidence="0.805600714285714">
(2) [pli kolˠ stɛlɔ as xɜ ṯʊ bɹɪŋ ði θɪŋɡ̥s wɪd̪ xɜː
fɹɔm ə st̪ɔː sɪxs spuːn ɔf fɹɛʃ noʊ piːz faiθ t̪ɪk
ə̆ slæp˺ ɔ βlu çiːs ẽn meɪbi ɛ snæk˺ fɔ xɜː bɹʌðə
bɔʔ wi ɔlˠsɔ niːt ʔʌ psmɔːlˠ plæstɪk snex ɛnʌ
bix tɔɪ fɹɔx fɔ ðə kiːs ʃi kʲẽːn skuʔ lɪ θʰɪŋɡ̥s ɪntʊ
tɹiː ɹɛd̥ bæɣz̥ ɛn wĭ wil ɡo mit˺ xɜ wɛnz̥deɪ a
ðəs tɹeɪ̃n steɪʃɪn]
</listItem>
<bodyText confidence="0.9995395">
Each of these phonetic transcriptions are con-
structed by 3 to 4 trained linguists, and disagree-
ments are settled by consensus. As is the case with
all such transcriptions, they remain works in pro-
gress. Two of these trained linguists do a pencil
and paper word-by-word comparison of the two
transcriptions in (1) and (2). Their analysis of the
data may find the following PSPs listed in (3):
</bodyText>
<listItem confidence="0.997058166666667">
(3) (a) final obstruent devoicing ([çiːs])
(b) non aspiration ([piːz])
(c) final consonant deletion ([pli])
(d) vowel epenthesis ([ə̆slæp˺])
(e) substitution of [x] for velars and glot-
tals ([bix])
</listItem>
<bodyText confidence="0.99989975">
This is just a partial list. Some speakers may have
more, and some speakers may have less. But the
essential claim here is that each speaker’s English
accent is the sum of their PSPs.
There are certain problems associated with this
manual process. Foremost among them is the cost
and time to train linguists to perform uniform PSP
analyses. Analysts must know what to look for—
they must decide what is important and what
should be ignored. This brings us to the second
drawback of manual analysis: the lack of a quick
and parameterized method of comparison.
If researchers need to test hypotheses about ad-
ditional but uncatalogued PSPs, or if they need to
simply search for a defined subset of PSPs, addi-
tional manual analyses are necessary. A third prob-
lem appears in the proper selection of one arbitrary
standard “base” sample for the comparisons. At
times researchers may want to compare non-
natives with American English native samples, and
at other times they may need to compare non-
natives with British, or other varieties of native
English. This requires multiple manual compari-
sons, and they take human time and energy. Fi-
nally, as mentioned above, narrow phonetic
transcriptions may need to be modified as collabo-
rators join the analysis. But when these are
changed, they necessitate concomitant change in
the register of PSPs.
Automating PSP generation not only solves
these problems, but also opens up new research
possibilities.
</bodyText>
<sectionHeader confidence="0.9946255" genericHeader="method">
3 An Automated System: Research Poten-
tials
</sectionHeader>
<bodyText confidence="0.999969685714286">
We have developed a computational tool that will
automatically compare two phonetically-
transcribed speech samples and generate a set of
PSPs describing the speech differences. Automat-
ing the comparison process will be of great use to
the archive and to any speech scientist who tran-
scribes and analyzes spoken language. It will allow
fast and pointed comparisons of any two phoneti-
cally transcribed speech samples. Instead of sim-
ply comparing a “standard” North American native
speaker and a non-native speaker, it will be quite
simple to perform many accent comparisons, in-
cluding those between a native British English
speaker and a non-native speaker. It will also be
possible to quickly and easily derive a composite
result. That is, after a number of analyses, we can
determine what a typical Russian speaker of Eng-
lish will do with his vowels and consonants. This
promises to be a great empirical improvement over
the pronouncements that are currently offered in
the appendices of various ESL teacher-training
textbooks.
For the analysis of individual speakers, this tool
has direct use in matters of linguistic assessment.
It will be useful in the fields of ESL pronunciation
assessment (Anderson-Hsieh, Johnson, and Kohler,
1992). These kinds of assessments will naturally
lead to a theory of weighted PSPs.
The tool also serves as a fast and systematic
method of checking human transcription accuracy
and thereby facilitates better methods of phonetic
transcription (Cucchiarini, 1996; Shriberg, Hinke,
&amp; Trost-Steffen, 1987).
Finally, the tool can provide a needed human
factor diagnostic to guide research in spectro-
</bodyText>
<page confidence="0.99679">
10
</page>
<bodyText confidence="0.998631333333333">
graphic speech analysis. And because speech rec-
ognition and speaker identification programs must
ultimately deal with different accented speech, the
results from the STAT analyses will contribute to
this work (Bartkova &amp; Jouvet, 2007; Deshpande,
Chikkerur, &amp; Govindaraju, 2005).
</bodyText>
<sectionHeader confidence="0.988713" genericHeader="method">
4 System Overview
</sectionHeader>
<bodyText confidence="0.999948444444444">
Linguists who transcribe speech into a phonetic
representation may use a tool such as PRAAT, to
play the audio source file and a text editor to input
the transcription. The result is normally a Unicode
text file that has an IPA transcription of the audio
file. STAT provides linguists with an easy way to
play back an audio source file and share it with
other linguists. A key feature that STAT provides
in addition to transcription tools is a mechanism to
manage a corpus of phonetic transcriptions. Once a
corpus of phonetic transcriptions is created, lin-
guists can use STAT’s phonological speech pattern
analysis tools to describe differences between dif-
ferent speakers’ accents.
The STAT system incorporates several distinct
components. Users interact with the system pri-
marily via a web interface. All user interfaces are
implemented with Ruby on Rails and various
JavaScript libraries. Backend processes and algo-
rithms are implemented in Java. An open source
web application bundle including the front-end
web interfaces and backend libraries will be made
available as an open source library suitable for use
in other applications in the future. We believe that
the transcription alignment and speech pattern
analysis components of STAT make it a unique
tool for linguists studying speech processes.
</bodyText>
<subsectionHeader confidence="0.998383">
4.1 Language Management
</subsectionHeader>
<bodyText confidence="0.999282818181818">
The language management component of STAT
provides basic transcribed audio corpus manage-
ment. This module allows a user to define a new
speaker source language, e.g. Japanese, and specify
attributes of the language, e.g. a phonetic inven-
tory. All transcriptions are then associated with a
speaker source language. STAT offers robust
search capabilities that allow a linguist to search by
things such as speaker demographics, phonetic in-
ventories, phonological speech processes, and
speech quality assessments.
</bodyText>
<figureCaption confidence="0.987893">
Figure 1: STAT provides an initial alignment and asso-
ciated PSPs. Provided alignments and PSPs can be
</figureCaption>
<bodyText confidence="0.6444385">
manually changed by a linguist, recomputed, and anno-
tated.
</bodyText>
<subsectionHeader confidence="0.987187">
4.2 Transcription Management
</subsectionHeader>
<bodyText confidence="0.9999863">
Whenever a transcription is to be made by lin-
guists, a new transcription record is created, asso-
ciated with a source language, and the audio file is
attached to the transcription record. Once the audio
file has been made available, linguists are able to
use a web interface to play the audio recording and
create phonetic transcriptions. The transcription
management interface then allows a senior linguist
to adjudicate differences between transcriptions
and select an authoritative transcription.
</bodyText>
<subsectionHeader confidence="0.999462">
4.3 Transcription Alignment and Analysis
</subsectionHeader>
<bodyText confidence="0.9999755">
Once an authoritative transcription for a speaker
has been created a linguist can then compare the
transcription with the previously transcribed
speech of another speaker. This alignment process
is the core of the system. The first stage of the
comparison is to create a word and phone level
alignment between the two transcriptions. The
alignment is performed by our special implementa-
tion of Kondrak’s phonetic alignment algorithm
(Kondrak, 2000). The output from this part of the
system is a complete phone-to-phone to alignment
of two transcriptions. Figure 1 shows an example
alignment with PSPs that a linguist is able to make
adjustments to or mark correct. After alignment a
linguist can perform an assessment of the speaker’s
speech abilities and make other notes.
To help linguists who do work with a variety of
different languages and research needs, the settings
for the phonemic cluster parser, phoneme distance
measures, and alignment algorithm coefficient can
</bodyText>
<page confidence="0.997098">
11
</page>
<bodyText confidence="0.999577333333333">
be easily changed inside of STAT. Linguists can
also control the set of constraints used for the
phonological speech patterns analysis.
</bodyText>
<subsectionHeader confidence="0.99853">
4.4 Phonological Speech Pattern Analysis
</subsectionHeader>
<bodyText confidence="0.99981">
Once the transcription alignment has been com-
pleted, the phonological speech pattern analysis
can begin. This analysis evaluates all phonetic dif-
ferences between the two transcriptions under
analysis. These differences are then processed by
our algorithm and used to determine unique
phonological speech patterns. All potential
phonological speech patterns are returned to the
linguist for verification. As the system encounters
and stores more and more phonological speech
pattern analyses for a particular language, general
descriptions are made about peoples’ accents from
a particular language background.
</bodyText>
<sectionHeader confidence="0.999671" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999962625">
Our initial design of STAT uses manually deter-
mined weights of phonological features used to
align transcriptions and determine phonological
speech processes. In the next major release of
STAT we intend to integrate automated methods to
propose weight settings based on language selec-
tions.
We are currently planning on integrating a
spectrographic analysis mechanism that will allow
for the transcriptions to be time synchronized with
the original speech sample. After this we will be
investigating the integration of several speaker ac-
cent identification algorithms. We will also be in-
vestigating applications of this tool to help speech
pathologists in the identification and assessment of
disordered speech patterns.
</bodyText>
<sectionHeader confidence="0.999828" genericHeader="method">
6 References
</sectionHeader>
<reference confidence="0.997616214285714">
Anderson-Hsieh, J., Johnson, R., &amp; Kohler, K. (1992).
The relationship between native speaker judgments
of non-native pronunciation and deviance in segmen-
tals, prosody, and syllable structure. Language
Learning, 42, 529-555.
Bartkova, K., &amp; Jouvet, D. (2007). On using units
trained on foreign data for improved multiple accent
speech recognition. Speech Communication, 49, 836-
846.
Cucchiarini, C. (1996). Assessing transcription agree-
ment: methodological aspects. Clinical Linguistics &amp;
Phonetics, 10, 131-155.
Deshpande, S., Chikkerur, S., &amp; Govindaraju, V.
(2005). Accent classification in speech. Proceedings
of the 4th IEEE Workshop on Automatic Identification
Advanced Technologies.
Kondrak, G. (2000). A new algorithm for the alignment
of phonetic sequences. In Proceedings of the First
Conference on North American Chapter of the Asso-
ciation For Computational Linguistics (Seattle,
Washington, April 29 - May 04, 2000). ACM Inter-
national Conference Proceeding Series, vol. 4.
Morgan Kaufmann Publishers, San Francisco, CA,
288-295.
Shriberg, L., Hinke, R., &amp; Trost-Steffen, C. (1987). A
procedure to select and train persons for narrow pho-
netic transcription by consensus. Clinical Linguistics
&amp; Phonetics, 1, 171-189.
</reference>
<page confidence="0.998455">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.345368">
<title confidence="0.998017">STAT: Speech Transcription Analysis Tool</title>
<author confidence="0.846856">Stephen A Program in</author>
<affiliation confidence="0.655665">3e4 George Mason</affiliation>
<address confidence="0.995598">Fairfax, VA 22030</address>
<email confidence="0.999639">skunath@gmu.edu</email>
<author confidence="0.889987">Steven H Program in</author>
<affiliation confidence="0.67687">3e4 George Mason</affiliation>
<address confidence="0.995298">Fairfax, VA 22030</address>
<email confidence="0.999721">weinberg@gmu.edu</email>
<abstract confidence="0.9971055625">The Speech Transcription Analysis Tool (STAT) is an open source tool for aligning and comparing two phonetically transcribed texts of human speech. The output analysis is a parameterized set of phonological differences. These differences are based upon a selectable set of binary phonetic features such as [voice], [continuant], [high], etc. STAT was initially designed to provide sets of phonological speech patterns in the comparisons of various English accents found in the Accent Archivehttp://accent.gmu.edu, but its scope and utility expand to matters of language assessment, phonetic training, forensic linguistics, and speech recognition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Anderson-Hsieh</author>
<author>R Johnson</author>
<author>K Kohler</author>
</authors>
<title>The relationship between native speaker judgments of non-native pronunciation and deviance in segmentals, prosody, and syllable structure.</title>
<date>1992</date>
<journal>Language Learning,</journal>
<volume>42</volume>
<pages>529--555</pages>
<contexts>
<context position="7382" citStr="Anderson-Hsieh, Johnson, and Kohler, 1992" startWordPosition="1157" endWordPosition="1161"> a native British English speaker and a non-native speaker. It will also be possible to quickly and easily derive a composite result. That is, after a number of analyses, we can determine what a typical Russian speaker of English will do with his vowels and consonants. This promises to be a great empirical improvement over the pronouncements that are currently offered in the appendices of various ESL teacher-training textbooks. For the analysis of individual speakers, this tool has direct use in matters of linguistic assessment. It will be useful in the fields of ESL pronunciation assessment (Anderson-Hsieh, Johnson, and Kohler, 1992). These kinds of assessments will naturally lead to a theory of weighted PSPs. The tool also serves as a fast and systematic method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost-Steffen, 1987). Finally, the tool can provide a needed human factor diagnostic to guide research in spectro10 graphic speech analysis. And because speech recognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this wo</context>
</contexts>
<marker>Anderson-Hsieh, Johnson, Kohler, 1992</marker>
<rawString>Anderson-Hsieh, J., Johnson, R., &amp; Kohler, K. (1992). The relationship between native speaker judgments of non-native pronunciation and deviance in segmentals, prosody, and syllable structure. Language Learning, 42, 529-555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bartkova</author>
<author>D Jouvet</author>
</authors>
<title>On using units trained on foreign data for improved multiple accent speech recognition.</title>
<date>2007</date>
<journal>Speech Communication,</journal>
<volume>49</volume>
<pages>836--846</pages>
<contexts>
<context position="8009" citStr="Bartkova &amp; Jouvet, 2007" startWordPosition="1251" endWordPosition="1254">hese kinds of assessments will naturally lead to a theory of weighted PSPs. The tool also serves as a fast and systematic method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost-Steffen, 1987). Finally, the tool can provide a needed human factor diagnostic to guide research in spectro10 graphic speech analysis. And because speech recognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this work (Bartkova &amp; Jouvet, 2007; Deshpande, Chikkerur, &amp; Govindaraju, 2005). 4 System Overview Linguists who transcribe speech into a phonetic representation may use a tool such as PRAAT, to play the audio source file and a text editor to input the transcription. The result is normally a Unicode text file that has an IPA transcription of the audio file. STAT provides linguists with an easy way to play back an audio source file and share it with other linguists. A key feature that STAT provides in addition to transcription tools is a mechanism to manage a corpus of phonetic transcriptions. Once a corpus of phonetic transcrip</context>
</contexts>
<marker>Bartkova, Jouvet, 2007</marker>
<rawString>Bartkova, K., &amp; Jouvet, D. (2007). On using units trained on foreign data for improved multiple accent speech recognition. Speech Communication, 49, 836-846.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cucchiarini</author>
</authors>
<title>Assessing transcription agreement: methodological aspects.</title>
<date>1996</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<volume>10</volume>
<pages>131--155</pages>
<contexts>
<context position="7639" citStr="Cucchiarini, 1996" startWordPosition="1198" endWordPosition="1199">es to be a great empirical improvement over the pronouncements that are currently offered in the appendices of various ESL teacher-training textbooks. For the analysis of individual speakers, this tool has direct use in matters of linguistic assessment. It will be useful in the fields of ESL pronunciation assessment (Anderson-Hsieh, Johnson, and Kohler, 1992). These kinds of assessments will naturally lead to a theory of weighted PSPs. The tool also serves as a fast and systematic method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost-Steffen, 1987). Finally, the tool can provide a needed human factor diagnostic to guide research in spectro10 graphic speech analysis. And because speech recognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this work (Bartkova &amp; Jouvet, 2007; Deshpande, Chikkerur, &amp; Govindaraju, 2005). 4 System Overview Linguists who transcribe speech into a phonetic representation may use a tool such as PRAAT, to play the audio source file and a text editor to input the transcriptio</context>
</contexts>
<marker>Cucchiarini, 1996</marker>
<rawString>Cucchiarini, C. (1996). Assessing transcription agreement: methodological aspects. Clinical Linguistics &amp; Phonetics, 10, 131-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deshpande</author>
<author>S Chikkerur</author>
<author>V Govindaraju</author>
</authors>
<title>Accent classification in speech.</title>
<date>2005</date>
<booktitle>Proceedings of the 4th IEEE Workshop on Automatic Identification Advanced Technologies.</booktitle>
<contexts>
<context position="8052" citStr="Deshpande, Chikkerur, &amp; Govindaraju, 2005" startWordPosition="1255" endWordPosition="1259"> will naturally lead to a theory of weighted PSPs. The tool also serves as a fast and systematic method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost-Steffen, 1987). Finally, the tool can provide a needed human factor diagnostic to guide research in spectro10 graphic speech analysis. And because speech recognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this work (Bartkova &amp; Jouvet, 2007; Deshpande, Chikkerur, &amp; Govindaraju, 2005). 4 System Overview Linguists who transcribe speech into a phonetic representation may use a tool such as PRAAT, to play the audio source file and a text editor to input the transcription. The result is normally a Unicode text file that has an IPA transcription of the audio file. STAT provides linguists with an easy way to play back an audio source file and share it with other linguists. A key feature that STAT provides in addition to transcription tools is a mechanism to manage a corpus of phonetic transcriptions. Once a corpus of phonetic transcriptions is created, linguists can use STAT’s </context>
</contexts>
<marker>Deshpande, Chikkerur, Govindaraju, 2005</marker>
<rawString>Deshpande, S., Chikkerur, S., &amp; Govindaraju, V. (2005). Accent classification in speech. Proceedings of the 4th IEEE Workshop on Automatic Identification Advanced Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Conference on North American Chapter of the Association For Computational Linguistics</booktitle>
<volume>4</volume>
<pages>288--295</pages>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>Seattle, Washington,</location>
<contexts>
<context position="11091" citStr="Kondrak, 2000" startWordPosition="1726" endWordPosition="1727">ce then allows a senior linguist to adjudicate differences between transcriptions and select an authoritative transcription. 4.3 Transcription Alignment and Analysis Once an authoritative transcription for a speaker has been created a linguist can then compare the transcription with the previously transcribed speech of another speaker. This alignment process is the core of the system. The first stage of the comparison is to create a word and phone level alignment between the two transcriptions. The alignment is performed by our special implementation of Kondrak’s phonetic alignment algorithm (Kondrak, 2000). The output from this part of the system is a complete phone-to-phone to alignment of two transcriptions. Figure 1 shows an example alignment with PSPs that a linguist is able to make adjustments to or mark correct. After alignment a linguist can perform an assessment of the speaker’s speech abilities and make other notes. To help linguists who do work with a variety of different languages and research needs, the settings for the phonemic cluster parser, phoneme distance measures, and alignment algorithm coefficient can 11 be easily changed inside of STAT. Linguists can also control the set o</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Kondrak, G. (2000). A new algorithm for the alignment of phonetic sequences. In Proceedings of the First Conference on North American Chapter of the Association For Computational Linguistics (Seattle, Washington, April 29 - May 04, 2000). ACM International Conference Proceeding Series, vol. 4. Morgan Kaufmann Publishers, San Francisco, CA, 288-295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shriberg</author>
<author>R Hinke</author>
<author>C Trost-Steffen</author>
</authors>
<title>A procedure to select and train persons for narrow phonetic transcription by consensus.</title>
<date>1987</date>
<journal>Clinical Linguistics &amp; Phonetics,</journal>
<volume>1</volume>
<pages>171--189</pages>
<contexts>
<context position="7679" citStr="Shriberg, Hinke, &amp; Trost-Steffen, 1987" startWordPosition="1200" endWordPosition="1204">pirical improvement over the pronouncements that are currently offered in the appendices of various ESL teacher-training textbooks. For the analysis of individual speakers, this tool has direct use in matters of linguistic assessment. It will be useful in the fields of ESL pronunciation assessment (Anderson-Hsieh, Johnson, and Kohler, 1992). These kinds of assessments will naturally lead to a theory of weighted PSPs. The tool also serves as a fast and systematic method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost-Steffen, 1987). Finally, the tool can provide a needed human factor diagnostic to guide research in spectro10 graphic speech analysis. And because speech recognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this work (Bartkova &amp; Jouvet, 2007; Deshpande, Chikkerur, &amp; Govindaraju, 2005). 4 System Overview Linguists who transcribe speech into a phonetic representation may use a tool such as PRAAT, to play the audio source file and a text editor to input the transcription. The result is normally a Unicode text</context>
</contexts>
<marker>Shriberg, Hinke, Trost-Steffen, 1987</marker>
<rawString>Shriberg, L., Hinke, R., &amp; Trost-Steffen, C. (1987). A procedure to select and train persons for narrow phonetic transcription by consensus. Clinical Linguistics &amp; Phonetics, 1, 171-189.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>