<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.230577">
<title confidence="0.99718">
A System for Real-time Twitter Sentiment Analysis of
2012 U.S. Presidential Election Cycle
</title>
<author confidence="0.9658875">
Hao Wang*, Dogan Can**, Abe Kazemzadeh**,
FranVois Bar* and Shrikanth Narayanan**
</author>
<affiliation confidence="0.954033666666667">
Annenberg Innovation Laboratory (AIL)*
Signal Analysis and Interpretation Laboratory (SAIL)**
University of Southern California, Los Angeles, CA
</affiliation>
<email confidence="0.645061">
{haowang@, dogancan@, kazemzad@, fbar@, shri@sipi}.usc.edu
</email>
<sectionHeader confidence="0.993508" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989130434783">
This paper describes a system for real-time
analysis of public sentiment toward
presidential candidates in the 2012 U.S.
election as expressed on Twitter, a micro-
blogging service. Twitter has become a
central site where people express their
opinions and views on political parties and
candidates. Emerging events or news are
often followed almost instantly by a burst
in Twitter volume, providing a unique
opportunity to gauge the relation between
expressed public sentiment and electoral
events. In addition, sentiment analysis can
help explore how these events affect public
opinion. While traditional content analysis
takes days or weeks to complete, the
system demonstrated here analyzes
sentiment in the entire Twitter traffic about
the election, delivering results instantly and
continuously. It offers the public, the
media, politicians and scholars a new and
timely perspective on the dynamics of the
electoral process and public opinion.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999913621621621">
Social media platforms have become an important
site for political conversations throughout the
world. In the year leading up to the November
2012 presidential election in the United States, we
have developed a tool for real-time analysis of
sentiment expressed through Twitter, a micro-
blogging service, toward the incumbent President,
Barack Obama, and the nine republican
challengers - four of whom remain in the running
as of this writing. With this analysis, we seek to
explore whether Twitter provides insights into the
unfolding of the campaigns and indications of
shifts in public opinion.
Twitter allows users to post tweets, messages of
up to 140 characters, on its social network. Twitter
usage is growing rapidly. The company reports
over 100 million active users worldwide, together
sending over 250 million tweets each day (Twitter,
2012). It was actively used by 13% of on-line
American adults as of May 2011, up from 8% a
year prior (Pew Research Center, 2011). More than
two thirds of U.S. congress members have created
a Twitter account and many are actively using
Twitter to reach their constituents (Lassen &amp;
Brown, 2010; TweetCongress, 2012). Since
October 12, 2012, we have gathered over 36
million tweets about the 2012 U.S. presidential
candidates, a quarter million per day on average.
During one of the key political events, the Dec 15,
2011 primary debate in Iowa, we collected more
than half a million relevant tweets in just a few
hours. This kind of ‘big data’ vastly outpaces the
capacity of traditional content analysis approaches,
calling for novel computational approaches.
Most work to date has focused on post-facto
analysis of tweets, with results coming days or
even months after the collection time. However,
</bodyText>
<page confidence="0.996409">
115
</page>
<note confidence="0.815433">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 115–120,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.999300647058823">
Recorded
data
Real-time
Twitter data
Throttle
Preprocessing
e.g.,Tokenization
Match Tweet
to Candidate
Sentiment
Model
Aggregate by
Candidate
Online
Human
Annotation
Visualization
</figure>
<figureCaption confidence="0.999993">
Figure 1. The system architecture for real-time processing Twitter data
</figureCaption>
<bodyText confidence="0.999976">
because tweets are short and easy to send, they
lend themselves to quick and dynamic expression
of instant reactions to current events. We expect
automated real-time sentiment analysis of this
user-generated data can provide fast indications of
changes in opinion, showing for example how an
audience reacts to particular candidate’s statements
during a political debate. The system we present
here, along with the dashboards displaying analysis
results with drill-down ability, is precisely aimed at
generating real-time insights as events unfold.
Beyond the sheer scale of the task and the need
to keep up with a rapid flow of tweets, we had to
address two additional issues. First, the vernacular
used on Twitter differs significantly from common
language and we have trained our sentiment model
on its idiosyncrasies. Second, tweets in general,
and political tweets in particular, tend to be quite
sarcastic, presenting significant challenges for
computer models (Gonz‡lez-Ib‡–ez et al., 2011).
We will present our approaches to these issues in a
separate publication. Here, we focus on presenting
the overall system and the visualization dashboards
we have built. In section 2, we begin with a review
of related work; we then turn in section 3 to a
description of our system’s architecture and its
components (input, preprocessing, sentiment
model, result aggregation, and visualization); in
sections 4 and 5 we evaluate our early experience
with this system and discuss next steps.
</bodyText>
<sectionHeader confidence="0.999488" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999960310344827">
In the last decade, interest in mining sentiment and
opinions in text has grown rapidly, due in part to
the large increase of the availability of documents
and messages expressing personal opinions (Pang
&amp; Lee, 2008). In particular, sentiment in Twitter
data has been used for prediction or measurement
in a variety of domains, such as stock market,
politics and social movements (Bollen et al., 2011;
Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff,
2011). For example, Tumasjan (2010) found tweet
volume about the political parties to be a good
predictor for the outcome of the 2009 German
election, while Choy et al. (2011) failed to predict
with Twitter sentiment the ranking of the four
candidates in Singapore’s 2011 presidential election.
Past studies of political sentiment on social
networks have been either post-hoc and/or carried
out on small and static samples. To address these
issues, we built a unique infrastructure and
sentiment model to analyze in real-time public
sentiment on Twitter toward the 2012 U.S.
presidential candidates. Our effort to gauge
political sentiment is based on bringing together
social science scholarship with advanced
computational methodology: our approach
combines real-time data processing and statistical
sentiment modeling informed by, and contributing
to, an understanding of the cultural and political
practices at work through the use of Twitter.
</bodyText>
<sectionHeader confidence="0.971748" genericHeader="method">
3 The System
</sectionHeader>
<bodyText confidence="0.999954933333333">
For accuracy and speed, we built our real-time data
processing infrastructure on the IBM’s InfoSphere
Streams platform (IBM, 2012), which enables us to
write our own analysis and visualization modules
and assemble them into a real-time processing
pipeline. Streams applications are highly scalable
so we can adjust our system to handle higher
volume of data by adding more servers and by
distributing processing tasks. Twitter traffic often
balloons during big events (e.g. televised debates
or primary election days) and stays low between
events, making high scalability strongly desirable.
Figure 1 shows our system’s architecture and its
modules. Next, we introduce our data source and
each individual module.
</bodyText>
<page confidence="0.994146">
116
</page>
<subsectionHeader confidence="0.962707">
3.1 Input/Data Source
</subsectionHeader>
<bodyText confidence="0.998376923076923">
We chose the micro-blogging service Twitter as
our data source because it is a major source of
online political commentary and discussion in the
U.S. People comment on and discuss politics by
posting messages and ‘re-tweeting’ others’
messages. It played a significant role in political
events worldwide, such as the Arab Spring
Movement and the Moldovian protests in 2009. In
response to events, Twitter volume goes up sharply
and significantly. For example, during a republican
debate, we receive several hundred thousand to a
million tweets in just a few hours for all the
candidates combined.
Twitter’s public API provides only 1% or less of
its entire traffic (the “firehose”), without control
over the sampling procedure, which is likely
insufficient for accurate analysis of public
sentiment. Instead, we collect all relevant tweets in
real-time from the entire Twitter traffic via Gnip
Power Track, a commercial Twitter data provider.
To cope with this challenge during the later stages
of the campaign, when larger Twitter traffic is
expected, our system can handle huge traffic bursts
over short time periods by distributing the
processing to more servers, even though most of
the times its processing load is minimal.
Since our application targets the political
domain (specifically the current Presidential
election cycle), we manually construct rules that
are simple logical keyword combinations to
retrieve relevant tweets – those about candidates
and events (including common typos in candidate
names). For example, our rules for Mitt Romney
include Romney, @MittRomney, @PlanetRomney,
@MittNews, @believeinromney, #romney, #mitt,
#mittromney, and #mitt2012. Our system is
tracking the tweets for nine Republican candidates
(some of whom have suspended their campaign)
and Barack Obama using about 200 rules in total.
</bodyText>
<subsectionHeader confidence="0.999074">
3.2 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999590666666667">
The text of tweets differs from the text in articles,
books, or even spoken language. It includes many
idiosyncratic uses, such as emoticons, URLs, RT
for re-tweet, @ for user mentions, # for hashtags,
and repetitions. It is necessary to preprocess and
normalize the text.
As standard in NLP practices, the text is
tokenized for later processing. We use certain rules
to handle the special cases in tweets. We compared
several Twitter-specific tokenizers, such as
TweetMotif (O&apos;Connor et al., 2010) and found
Christopher Potts’ basic Twitter tokenizer best
suited as our base. In summary, our tokenizer
correctly handles URLs, common emoticons,
phone numbers, HTML tags, twitter mentions and
hashtags, numbers with fractions and decimals,
repetition of symbols and Unicode characters (see
Figure 2 for an example).
</bodyText>
<subsectionHeader confidence="0.9711">
3.3 Sentiment Model
</subsectionHeader>
<bodyText confidence="0.999961846153846">
The design of the sentiment model used in our
system was based on the assumption that the
opinions expressed would be highly subjective and
contextualized. Therefore, for generating data for
model training and testing, we used a crowd-
sourcing approach to do sentiment annotation on
in-domain political data.
To create a baseline sentiment model, we used
Amazon Mechanical Turk (AMT) to get as varied
a population of annotators as possible. We
designed an interface that allowed annotators to
perform the annotations outside of AMT so that
they could participate anonymously. The Turkers
were asked their age, gender, and to describe their
political orientation. Then they were shown a
series of tweets and asked to annotate the tweets&apos;
sentiment (positive, negative, neutral, or unsure),
whether the tweet was sarcastic or humorous, the
sentiment on a scale from positive to negative, and
the tweet author&apos;s political orientation on a slider
scale from conservative to liberal. Our sentiment
model is based on the sentiment label and the
sarcasm and humor labels. Our training data
consists of nearly 17000 tweets (16% positive,
56% negative, 18% neutral, 10% unsure),
including nearly 2000 that were multiply annotated
</bodyText>
<figure confidence="0.83200425">
Tweet WAAAAAH!!! RT @politico: Romney: Santorum&apos;s &apos;dirty tricks&apos; could steal Michigan:
http://t.co/qEns1Pmi #MIprimary #tcot #teaparty #GOP
Tokens WAAAAAH !!! RT @politico : Romney : Santorum&apos;s &apos; dirty tricks &apos; could steal
Michigan : http://politi.co/wYUz7m #MIprimary #tcot #teaparty #GOP
</figure>
<figureCaption confidence="0.999855">
Figure 2. The output tokens of a sample tweet from our tokenizer
</figureCaption>
<page confidence="0.979286">
117
</page>
<figureCaption confidence="0.999483">
Figure 3. Dashboard for volume, sentiment and trending words
</figureCaption>
<bodyText confidence="0.998546263157895">
to calculate inter-annotator agreement. About 800
Turkers contributed to our annotation.
The statistical classifier we use for sentiment
analysis is a naïve Bayes model on unigram
features. Our features are calculated from
tokenization of the tweets that attempts to preserve
punctuation that may signify sentiment (e.g.,
emoticons and exclamation points) as well as
twitter specific phenomena (e.g., extracting intact
URLs). Based on the data we collected our
classifier performs at 59% accuracy on the four
category classification of negative, positive,
neutral, or unsure. These results exceed the
baseline of classifying all the data as negative, the
most prevalent sentiment category (56%). The
choice of our model was not strictly motivated by
global accuracy, but took into account class-wise
performance so that the model performed well on
each sentiment category.
</bodyText>
<subsectionHeader confidence="0.987353">
3.4 Aggregation
</subsectionHeader>
<bodyText confidence="0.999971555555556">
Because our system receives tweets continuously
and uses multiple rules to track each candidate’s
tweets, our display must aggregate sentiment and
tweet volume within each time period for each
candidate. For volume, the system outputs the
number of tweets every minute for each candidate.
For sentiment, the system outputs the number of
positive, negative, neutral and unsure tweets in a
sliding five-minute window.
</bodyText>
<subsectionHeader confidence="0.919323">
3.5 Display and Visualization
</subsectionHeader>
<bodyText confidence="0.999980342857143">
We designed an Ajax-based HTML dashboard
(Figure 3) to display volume and sentiment by
candidate as well as trending words and system
statistics. The dashboard pulls updated data from a
web server and refreshes its display every 30
seconds. In Figure 3, the top-left bar graph shows
the number of positive and negative tweets about
each candidate (right and left bars, respectively) in
the last five minutes as an indicator of sentiment
towards the candidates. We chose to display both
positive and negative sentiment, instead of the
difference between these two, because events
typically trigger sharp variations in both positive
and negative tweet volume. The top-right chart
displays the number of tweets for each candidate
every minute in the last two hours. We chose this
time window because a live-broadcast primary
debate usually lasts about two hours. The bottom-
left shows system statistics, including the total
number of tweets, the number of seconds since
system start and the average data rate. The bottom-
right table shows trending words of the last five
minutes, computed using TF-IDF measure as
follows: tweets about all candidates in a minute are
treated as a single “document”; trending words are
the tokens from the current minute with the highest
TF-IDF weights when using the last two hours as a
corpus (i.e., 120 “documents”). Qualitative
examination suggests that the simple TF-IDF
metric effectively identifies the most prominent
words when an event occurs.
The dashboard gives a synthetic overview of
volume and sentiment for the candidates, but it is
often desirable to view selected tweets and their
sentiments. The dashboard includes another page
</bodyText>
<page confidence="0.996635">
118
</page>
<figureCaption confidence="0.998863">
Figure 5. Dashboard for most positive, negative and frequent tweets
</figureCaption>
<bodyText confidence="0.9950799">
(Figure 4) that displays the most positive, negative
and frequent tweets, as well as some random
neutral tweets. It also shows the total volume over
time and a tag cloud of the most frequent words in
the last five minutes across all candidates. Another
crucial feature of this page is that clicking on one
of the tweets brings up an annotation interface, so
the user can provide his/her own assessment of the
sentiment expressed in the tweet. The next section
describes the annotation interface.
</bodyText>
<subsectionHeader confidence="0.997884">
3.6 Annotation Interface
</subsectionHeader>
<bodyText confidence="0.9999941">
The online annotation interface shown in Figure 5
lets dashboard (Figure 4) users provide their own
judgment of a tweet. The tweet’s text is displayed
at the top, and users can rate the sentiment toward
the candidate mentioned in the tweet as positive,
negative or neutral or mark it as unsure. There are
also two options to specify whether a tweet is
sarcastic and/or funny. This interface is a
simplified version of the one we used to collect
annotations from Amazon Mechanical Turk so that
annotation can be performed quickly on a single
tweet. The online interface is designed to be used
while watching a campaign event and can be
displayed on a tablet or smart phone.
The feedback from users allows annotation of
recent data as well as the ability to correct
misclassifications. As a future step, we plan to
establish an online feedback loop between users
and the sentiment model, so users’ judgment serves
to train the model actively and iteratively.
</bodyText>
<sectionHeader confidence="0.995971" genericHeader="method">
4 System Evaluation
</sectionHeader>
<bodyText confidence="0.9996702">
In Section 3.3, we described our preliminary
sentiment model that automatically classifies
tweets into four categories: positive, negative,
neutral or unsure. It copes well with the negative
bias in political tweets. In addition to evaluating
</bodyText>
<figureCaption confidence="0.984319">
Figure 4. Online sentiment annotation interface
</figureCaption>
<page confidence="0.995894">
119
</page>
<bodyText confidence="0.999962068181818">
the model using annotated data, we have also
begun conducting correlational analysis of
aggregated sentiment with political events and
news, as well as indicators such as poll and
election results. We are exploring whether
variations in twitter sentiment and tweet volume
are predictive or reflective of real-world events and
news. While this quantitative analysis is part of
ongoing work, we present below some quantitative
and qualitative expert observations indicative of
promising research directions.
One finding is that tweet volume is largely
driven by campaign events. Of the 50 top hourly
intervals between Oct 12, 2011 and Feb 29, 2012,
ranked by tweet volume, all but two correspond
either to President Obama’s State of the Union
address, televised primary debates or moments
when caucus or primary election results were
released. Out of the 100 top hourly intervals, all
but 18 correspond to such events. The 2012 State
of the Union address on Jan 24 is another good
example. It caused the biggest volume we have
seen in a single day since last October, 1.37
million tweets in total for that day. Both positive
and negative tweets for President Obama increased
three to four times comparing to an average day.
During the Republican Primary debate on Jan 19,
2012 in Charleston, NC one of the Republican
candidates, Newt Gingrich, was asked about his
ex-wife at the beginning of the debate. Within
minutes, our dashboard showed his negative
sentiment increase rapidly Ð it became three times
more negative in just two minutes. This illustrates
how tweet volume and sentiment are extremely
responsive to emerging events in the real world
(Vergeer et al., 2011).
These examples confirm our assessment that it
is especially relevant to offer a system that can
provide real-time analysis during key moments in
the election cycle. As the election continues and
culminates with the presidential vote this
November, we hope that our system will provide
rich insights into the evolution of public sentiment
toward the contenders.
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999928357142857">
We presented a system for real-time Twitter
sentiment analysis of the ongoing 2012 U.S.
presidential election. We use the Twitter “firehose”
and expert-curated rules and keywords to get a full
and accurate picture of the online political
landscape. Our real-time data processing
infrastructure and statistical sentiment model
evaluates public sentiment changes in response to
emerging political events and news as they unfold.
The architecture and method are generic, and can
be easily adopted and extended to other domains
(for instance, we used the system for gauging
sentiments about films and actors surrounding
Oscar nomination and selection).
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999626380952381">
Bollen, J., Mao, H., &amp; Zeng, X. (2011). Twitter mood
predicts the stock market. Journal of Computational
Science, 2(1), 1-8. doi: 10.1016/j.jocs.2010.12.007
Choy, M., Cheong, L. F. M., Ma, N. L., &amp; Koo, P. S.
(2011). A sentiment analysis of Singapore Presidential
Election 2011 using Twitter data with census correction.
Gonz‡lez-Ib‡–ez, R., Muresan, S., &amp; Wacholder, N.
(2011). Identifying Sarcasm in Twitter: A Closer Look.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics.
IBM. (2012). InfoSphere Streams, from http://www-
01.ibm.com/software/data/infosphere/streams/
Lassen, D. S., &amp; Brown, A. R. (2010). Twitter: The
Electoral Connection? Social Science Computer Review.
O&apos;Connor, B., Krieger, M., &amp; Ahn, D. (2010). TweetMotif:
Exploratory Search and Topic Summarization for
Twitter. In Proceedings of the the Fourth International
AAAI Conference on Weblogs and Social Media,
Washington, DC.
Pang, B., &amp; Lee, L. (2008). Opinion Mining and Sentiment
Analysis. Foundations and Trends in Information
Retrieval, 2(1-2), 1-135. doi: 10.1561/1500000011
Pew Research Center. (2011). 13% of online adults use
Twitter. Retrieved from http://www.pewinternet.org/
~/media//Files/Reports/2011/Twitter%20Update%2020
11.pdf
Tumasjan, A., Sprenger, T. O., Sandner, P. G., &amp; Welpe, I.
M. (2010). Predicting Elections with Twitter: What 140
Characters Reveal about Political Sentiment.
TweetCongress. (2012). Congress Members on Twitter
Retrieved Mar 18, 2012, from
http://tweetcongress.org/members/
Twitter. (2012). What is Twitter Retrieved Mar 18, 2012,
from https://business.twitter.com/en/basics/what-is-
twitter/
Vergeer, M., Hermans, L., &amp; Sams, S. (2011). Is the voter
only a tweet away? Micro blogging during the 2009
European Parliament election campaign in the
Netherlands. First Monday [Online], 16(8).
Zeitzoff, T. (2011). Using Social Media to Measure
Conflict Dynamics. Journal of Conflict Resolution,
55(6), 938-969. doi: 10.1177/0022002711408014
</reference>
<page confidence="0.99628">
120
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.497266">
<title confidence="0.994671">A System for Real-time Twitter Sentiment Analysis</title>
<author confidence="0.787251666666667">U S Presidential Election Cycle Hao Wang</author>
<author confidence="0.787251666666667">Dogan Can</author>
<author confidence="0.787251666666667">Abe FranVois Bar</author>
<author confidence="0.787251666666667">Shrikanth</author>
<affiliation confidence="0.999180333333333">Annenberg Innovation Laboratory Signal Analysis and Interpretation Laboratory University of Southern California, Los Angeles,</affiliation>
<email confidence="0.999026">haowang@.usc.edu</email>
<email confidence="0.999026">dogancan@.usc.edu</email>
<email confidence="0.999026">kazemzad@.usc.edu</email>
<email confidence="0.999026">fbar@.usc.edu</email>
<email confidence="0.999026">shri@sipi.usc.edu</email>
<abstract confidence="0.999361208333333">This paper describes a system for real-time analysis of public sentiment toward presidential candidates in the 2012 U.S. election as expressed on Twitter, a microblogging service. Twitter has become a central site where people express their opinions and views on political parties and candidates. Emerging events or news are often followed almost instantly by a burst in Twitter volume, providing a unique opportunity to gauge the relation between expressed public sentiment and electoral events. In addition, sentiment analysis can help explore how these events affect public opinion. While traditional content analysis takes days or weeks to complete, the system demonstrated here analyzes sentiment in the entire Twitter traffic about the election, delivering results instantly and continuously. It offers the public, the media, politicians and scholars a new and timely perspective on the dynamics of the electoral process and public opinion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bollen</author>
<author>H Mao</author>
<author>X Zeng</author>
</authors>
<title>Twitter mood predicts the stock market.</title>
<date>2011</date>
<journal>Journal of Computational Science,</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--8</pages>
<contexts>
<context position="5448" citStr="Bollen et al., 2011" startWordPosition="824" endWordPosition="827">chitecture and its components (input, preprocessing, sentiment model, result aggregation, and visualization); in sections 4 and 5 we evaluate our early experience with this system and discuss next steps. 2 Related Work In the last decade, interest in mining sentiment and opinions in text has grown rapidly, due in part to the large increase of the availability of documents and messages expressing personal opinions (Pang &amp; Lee, 2008). In particular, sentiment in Twitter data has been used for prediction or measurement in a variety of domains, such as stock market, politics and social movements (Bollen et al., 2011; Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff, 2011). For example, Tumasjan (2010) found tweet volume about the political parties to be a good predictor for the outcome of the 2009 German election, while Choy et al. (2011) failed to predict with Twitter sentiment the ranking of the four candidates in Singapore’s 2011 presidential election. Past studies of political sentiment on social networks have been either post-hoc and/or carried out on small and static samples. To address these issues, we built a unique infrastructure and sentiment model to analyze in real-time public sentiment on </context>
</contexts>
<marker>Bollen, Mao, Zeng, 2011</marker>
<rawString>Bollen, J., Mao, H., &amp; Zeng, X. (2011). Twitter mood predicts the stock market. Journal of Computational Science, 2(1), 1-8. doi: 10.1016/j.jocs.2010.12.007</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Choy</author>
<author>L F M Cheong</author>
<author>N L Ma</author>
<author>P S Koo</author>
</authors>
<title>A sentiment analysis of Singapore Presidential Election</title>
<date>2011</date>
<contexts>
<context position="5467" citStr="Choy et al., 2011" startWordPosition="828" endWordPosition="831">mponents (input, preprocessing, sentiment model, result aggregation, and visualization); in sections 4 and 5 we evaluate our early experience with this system and discuss next steps. 2 Related Work In the last decade, interest in mining sentiment and opinions in text has grown rapidly, due in part to the large increase of the availability of documents and messages expressing personal opinions (Pang &amp; Lee, 2008). In particular, sentiment in Twitter data has been used for prediction or measurement in a variety of domains, such as stock market, politics and social movements (Bollen et al., 2011; Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff, 2011). For example, Tumasjan (2010) found tweet volume about the political parties to be a good predictor for the outcome of the 2009 German election, while Choy et al. (2011) failed to predict with Twitter sentiment the ranking of the four candidates in Singapore’s 2011 presidential election. Past studies of political sentiment on social networks have been either post-hoc and/or carried out on small and static samples. To address these issues, we built a unique infrastructure and sentiment model to analyze in real-time public sentiment on Twitter toward the </context>
</contexts>
<marker>Choy, Cheong, Ma, Koo, 2011</marker>
<rawString>Choy, M., Cheong, L. F. M., Ma, N. L., &amp; Koo, P. S. (2011). A sentiment analysis of Singapore Presidential Election 2011 using Twitter data with census correction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gonz‡lez-Ib‡–ez</author>
<author>S Muresan</author>
<author>N Wacholder</author>
</authors>
<title>Identifying Sarcasm in Twitter: A Closer Look.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Gonz‡lez-Ib‡–ez, Muresan, Wacholder, 2011</marker>
<rawString>Gonz‡lez-Ib‡–ez, R., Muresan, S., &amp; Wacholder, N. (2011). Identifying Sarcasm in Twitter: A Closer Look. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IBM</author>
</authors>
<title>InfoSphere Streams,</title>
<date>2012</date>
<note>from http://www01.ibm.com/software/data/infosphere/streams/</note>
<contexts>
<context position="6593" citStr="IBM, 2012" startWordPosition="998" endWordPosition="999"> and sentiment model to analyze in real-time public sentiment on Twitter toward the 2012 U.S. presidential candidates. Our effort to gauge political sentiment is based on bringing together social science scholarship with advanced computational methodology: our approach combines real-time data processing and statistical sentiment modeling informed by, and contributing to, an understanding of the cultural and political practices at work through the use of Twitter. 3 The System For accuracy and speed, we built our real-time data processing infrastructure on the IBM’s InfoSphere Streams platform (IBM, 2012), which enables us to write our own analysis and visualization modules and assemble them into a real-time processing pipeline. Streams applications are highly scalable so we can adjust our system to handle higher volume of data by adding more servers and by distributing processing tasks. Twitter traffic often balloons during big events (e.g. televised debates or primary election days) and stays low between events, making high scalability strongly desirable. Figure 1 shows our system’s architecture and its modules. Next, we introduce our data source and each individual module. 116 3.1 Input/Dat</context>
</contexts>
<marker>IBM, 2012</marker>
<rawString>IBM. (2012). InfoSphere Streams, from http://www01.ibm.com/software/data/infosphere/streams/</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Lassen</author>
<author>A R Brown</author>
</authors>
<title>Twitter: The Electoral Connection? Social Science Computer Review.</title>
<date>2010</date>
<contexts>
<context position="2487" citStr="Lassen &amp; Brown, 2010" startWordPosition="370" endWordPosition="373">o the unfolding of the campaigns and indications of shifts in public opinion. Twitter allows users to post tweets, messages of up to 140 characters, on its social network. Twitter usage is growing rapidly. The company reports over 100 million active users worldwide, together sending over 250 million tweets each day (Twitter, 2012). It was actively used by 13% of on-line American adults as of May 2011, up from 8% a year prior (Pew Research Center, 2011). More than two thirds of U.S. congress members have created a Twitter account and many are actively using Twitter to reach their constituents (Lassen &amp; Brown, 2010; TweetCongress, 2012). Since October 12, 2012, we have gathered over 36 million tweets about the 2012 U.S. presidential candidates, a quarter million per day on average. During one of the key political events, the Dec 15, 2011 primary debate in Iowa, we collected more than half a million relevant tweets in just a few hours. This kind of ‘big data’ vastly outpaces the capacity of traditional content analysis approaches, calling for novel computational approaches. Most work to date has focused on post-facto analysis of tweets, with results coming days or even months after the collection time. H</context>
</contexts>
<marker>Lassen, Brown, 2010</marker>
<rawString>Lassen, D. S., &amp; Brown, A. R. (2010). Twitter: The Electoral Connection? Social Science Computer Review.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B O&apos;Connor</author>
<author>M Krieger</author>
<author>D Ahn</author>
</authors>
<title>TweetMotif: Exploratory Search and Topic Summarization for Twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the the Fourth International AAAI Conference on Weblogs and Social</booktitle>
<location>Media, Washington, DC.</location>
<contexts>
<context position="9551" citStr="O&apos;Connor et al., 2010" startWordPosition="1447" endWordPosition="1450"> candidates (some of whom have suspended their campaign) and Barack Obama using about 200 rules in total. 3.2 Preprocessing The text of tweets differs from the text in articles, books, or even spoken language. It includes many idiosyncratic uses, such as emoticons, URLs, RT for re-tweet, @ for user mentions, # for hashtags, and repetitions. It is necessary to preprocess and normalize the text. As standard in NLP practices, the text is tokenized for later processing. We use certain rules to handle the special cases in tweets. We compared several Twitter-specific tokenizers, such as TweetMotif (O&apos;Connor et al., 2010) and found Christopher Potts’ basic Twitter tokenizer best suited as our base. In summary, our tokenizer correctly handles URLs, common emoticons, phone numbers, HTML tags, twitter mentions and hashtags, numbers with fractions and decimals, repetition of symbols and Unicode characters (see Figure 2 for an example). 3.3 Sentiment Model The design of the sentiment model used in our system was based on the assumption that the opinions expressed would be highly subjective and contextualized. Therefore, for generating data for model training and testing, we used a crowdsourcing approach to do senti</context>
</contexts>
<marker>O&apos;Connor, Krieger, Ahn, 2010</marker>
<rawString>O&apos;Connor, B., Krieger, M., &amp; Ahn, D. (2010). TweetMotif: Exploratory Search and Topic Summarization for Twitter. In Proceedings of the the Fourth International AAAI Conference on Weblogs and Social Media, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and Trends</title>
<date>2008</date>
<booktitle>in Information Retrieval,</booktitle>
<volume>2</volume>
<issue>1</issue>
<pages>1--135</pages>
<contexts>
<context position="5264" citStr="Pang &amp; Lee, 2008" startWordPosition="794" endWordPosition="797">the overall system and the visualization dashboards we have built. In section 2, we begin with a review of related work; we then turn in section 3 to a description of our system’s architecture and its components (input, preprocessing, sentiment model, result aggregation, and visualization); in sections 4 and 5 we evaluate our early experience with this system and discuss next steps. 2 Related Work In the last decade, interest in mining sentiment and opinions in text has grown rapidly, due in part to the large increase of the availability of documents and messages expressing personal opinions (Pang &amp; Lee, 2008). In particular, sentiment in Twitter data has been used for prediction or measurement in a variety of domains, such as stock market, politics and social movements (Bollen et al., 2011; Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff, 2011). For example, Tumasjan (2010) found tweet volume about the political parties to be a good predictor for the outcome of the 2009 German election, while Choy et al. (2011) failed to predict with Twitter sentiment the ranking of the four candidates in Singapore’s 2011 presidential election. Past studies of political sentiment on social networks have been ei</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, B., &amp; Lee, L. (2008). Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval, 2(1-2), 1-135. doi: 10.1561/1500000011</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pew Research Center</author>
</authors>
<title>13% of online adults use Twitter.</title>
<date>2011</date>
<note>Retrieved from http://www.pewinternet.org/ ~/media//Files/Reports/2011/Twitter%20Update%2020 11.pdf</note>
<contexts>
<context position="2323" citStr="Center, 2011" startWordPosition="345" endWordPosition="346"> republican challengers - four of whom remain in the running as of this writing. With this analysis, we seek to explore whether Twitter provides insights into the unfolding of the campaigns and indications of shifts in public opinion. Twitter allows users to post tweets, messages of up to 140 characters, on its social network. Twitter usage is growing rapidly. The company reports over 100 million active users worldwide, together sending over 250 million tweets each day (Twitter, 2012). It was actively used by 13% of on-line American adults as of May 2011, up from 8% a year prior (Pew Research Center, 2011). More than two thirds of U.S. congress members have created a Twitter account and many are actively using Twitter to reach their constituents (Lassen &amp; Brown, 2010; TweetCongress, 2012). Since October 12, 2012, we have gathered over 36 million tweets about the 2012 U.S. presidential candidates, a quarter million per day on average. During one of the key political events, the Dec 15, 2011 primary debate in Iowa, we collected more than half a million relevant tweets in just a few hours. This kind of ‘big data’ vastly outpaces the capacity of traditional content analysis approaches, calling for </context>
</contexts>
<marker>Center, 2011</marker>
<rawString>Pew Research Center. (2011). 13% of online adults use Twitter. Retrieved from http://www.pewinternet.org/ ~/media//Files/Reports/2011/Twitter%20Update%2020 11.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tumasjan</author>
<author>T O Sprenger</author>
<author>P G Sandner</author>
<author>I M Welpe</author>
</authors>
<date>2010</date>
<booktitle>Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment.</booktitle>
<contexts>
<context position="5490" citStr="Tumasjan et al., 2010" startWordPosition="832" endWordPosition="835">eprocessing, sentiment model, result aggregation, and visualization); in sections 4 and 5 we evaluate our early experience with this system and discuss next steps. 2 Related Work In the last decade, interest in mining sentiment and opinions in text has grown rapidly, due in part to the large increase of the availability of documents and messages expressing personal opinions (Pang &amp; Lee, 2008). In particular, sentiment in Twitter data has been used for prediction or measurement in a variety of domains, such as stock market, politics and social movements (Bollen et al., 2011; Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff, 2011). For example, Tumasjan (2010) found tweet volume about the political parties to be a good predictor for the outcome of the 2009 German election, while Choy et al. (2011) failed to predict with Twitter sentiment the ranking of the four candidates in Singapore’s 2011 presidential election. Past studies of political sentiment on social networks have been either post-hoc and/or carried out on small and static samples. To address these issues, we built a unique infrastructure and sentiment model to analyze in real-time public sentiment on Twitter toward the 2012 U.S. presidential </context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Tumasjan, A., Sprenger, T. O., Sandner, P. G., &amp; Welpe, I. M. (2010). Predicting Elections with Twitter: What 140 Characters Reveal about Political Sentiment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TweetCongress</author>
</authors>
<date>2012</date>
<note>Congress Members on Twitter</note>
<contexts>
<context position="2509" citStr="TweetCongress, 2012" startWordPosition="374" endWordPosition="375"> campaigns and indications of shifts in public opinion. Twitter allows users to post tweets, messages of up to 140 characters, on its social network. Twitter usage is growing rapidly. The company reports over 100 million active users worldwide, together sending over 250 million tweets each day (Twitter, 2012). It was actively used by 13% of on-line American adults as of May 2011, up from 8% a year prior (Pew Research Center, 2011). More than two thirds of U.S. congress members have created a Twitter account and many are actively using Twitter to reach their constituents (Lassen &amp; Brown, 2010; TweetCongress, 2012). Since October 12, 2012, we have gathered over 36 million tweets about the 2012 U.S. presidential candidates, a quarter million per day on average. During one of the key political events, the Dec 15, 2011 primary debate in Iowa, we collected more than half a million relevant tweets in just a few hours. This kind of ‘big data’ vastly outpaces the capacity of traditional content analysis approaches, calling for novel computational approaches. Most work to date has focused on post-facto analysis of tweets, with results coming days or even months after the collection time. However, 115 Proceeding</context>
</contexts>
<marker>TweetCongress, 2012</marker>
<rawString>TweetCongress. (2012). Congress Members on Twitter</rawString>
</citation>
<citation valid="true">
<authors>
<author>Twitter</author>
</authors>
<title>What is Twitter Retrieved</title>
<date>2012</date>
<note>from https://business.twitter.com/en/basics/what-istwitter/</note>
<contexts>
<context position="2199" citStr="Twitter, 2012" startWordPosition="321" endWordPosition="322">s of sentiment expressed through Twitter, a microblogging service, toward the incumbent President, Barack Obama, and the nine republican challengers - four of whom remain in the running as of this writing. With this analysis, we seek to explore whether Twitter provides insights into the unfolding of the campaigns and indications of shifts in public opinion. Twitter allows users to post tweets, messages of up to 140 characters, on its social network. Twitter usage is growing rapidly. The company reports over 100 million active users worldwide, together sending over 250 million tweets each day (Twitter, 2012). It was actively used by 13% of on-line American adults as of May 2011, up from 8% a year prior (Pew Research Center, 2011). More than two thirds of U.S. congress members have created a Twitter account and many are actively using Twitter to reach their constituents (Lassen &amp; Brown, 2010; TweetCongress, 2012). Since October 12, 2012, we have gathered over 36 million tweets about the 2012 U.S. presidential candidates, a quarter million per day on average. During one of the key political events, the Dec 15, 2011 primary debate in Iowa, we collected more than half a million relevant tweets in jus</context>
</contexts>
<marker>Twitter, 2012</marker>
<rawString>Twitter. (2012). What is Twitter Retrieved Mar 18, 2012, from https://business.twitter.com/en/basics/what-istwitter/</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vergeer</author>
<author>L Hermans</author>
<author>S Sams</author>
</authors>
<title>Is the voter only a tweet away? Micro blogging during the 2009 European Parliament election campaign in the Netherlands.</title>
<date>2011</date>
<journal>First Monday [Online],</journal>
<volume>16</volume>
<issue>8</issue>
<contexts>
<context position="18070" citStr="Vergeer et al., 2011" startWordPosition="2787" endWordPosition="2790">ce last October, 1.37 million tweets in total for that day. Both positive and negative tweets for President Obama increased three to four times comparing to an average day. During the Republican Primary debate on Jan 19, 2012 in Charleston, NC one of the Republican candidates, Newt Gingrich, was asked about his ex-wife at the beginning of the debate. Within minutes, our dashboard showed his negative sentiment increase rapidly Ð it became three times more negative in just two minutes. This illustrates how tweet volume and sentiment are extremely responsive to emerging events in the real world (Vergeer et al., 2011). These examples confirm our assessment that it is especially relevant to offer a system that can provide real-time analysis during key moments in the election cycle. As the election continues and culminates with the presidential vote this November, we hope that our system will provide rich insights into the evolution of public sentiment toward the contenders. 5 Conclusion We presented a system for real-time Twitter sentiment analysis of the ongoing 2012 U.S. presidential election. We use the Twitter “firehose” and expert-curated rules and keywords to get a full and accurate picture of the onl</context>
</contexts>
<marker>Vergeer, Hermans, Sams, 2011</marker>
<rawString>Vergeer, M., Hermans, L., &amp; Sams, S. (2011). Is the voter only a tweet away? Micro blogging during the 2009 European Parliament election campaign in the Netherlands. First Monday [Online], 16(8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zeitzoff</author>
</authors>
<title>Using Social Media to Measure Conflict Dynamics.</title>
<date>2011</date>
<journal>Journal of Conflict Resolution,</journal>
<volume>55</volume>
<issue>6</issue>
<pages>938--969</pages>
<contexts>
<context position="5507" citStr="Zeitzoff, 2011" startWordPosition="836" endWordPosition="837">model, result aggregation, and visualization); in sections 4 and 5 we evaluate our early experience with this system and discuss next steps. 2 Related Work In the last decade, interest in mining sentiment and opinions in text has grown rapidly, due in part to the large increase of the availability of documents and messages expressing personal opinions (Pang &amp; Lee, 2008). In particular, sentiment in Twitter data has been used for prediction or measurement in a variety of domains, such as stock market, politics and social movements (Bollen et al., 2011; Choy et al., 2011; Tumasjan et al., 2010; Zeitzoff, 2011). For example, Tumasjan (2010) found tweet volume about the political parties to be a good predictor for the outcome of the 2009 German election, while Choy et al. (2011) failed to predict with Twitter sentiment the ranking of the four candidates in Singapore’s 2011 presidential election. Past studies of political sentiment on social networks have been either post-hoc and/or carried out on small and static samples. To address these issues, we built a unique infrastructure and sentiment model to analyze in real-time public sentiment on Twitter toward the 2012 U.S. presidential candidates. Our e</context>
</contexts>
<marker>Zeitzoff, 2011</marker>
<rawString>Zeitzoff, T. (2011). Using Social Media to Measure Conflict Dynamics. Journal of Conflict Resolution, 55(6), 938-969. doi: 10.1177/0022002711408014</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>