<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020000">
<title confidence="0.9987025">
Identification of Multi-word Expressions by
Combining Multiple Linguistic Information Sources
</title>
<author confidence="0.966749">
Yulia Tsvetkov Shuly Wintner
</author>
<affiliation confidence="0.9852405">
Language Technologies Institute Department of Computer Science
Carnegie Mellon University University of Haifa
</affiliation>
<email confidence="0.998061">
yulia.tsvetkov@gmail.com shuly@cs.haifa.ac.il
</email>
<sectionHeader confidence="0.993869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99967075">
We propose an architecture for expressing
various linguistically-motivated features that
help identify multi-word expressions in nat-
ural language texts. The architecture com-
bines various linguistically-motivated clas-
sification features in a Bayesian Network.
We introduce novel ways for computing
many of these features, and manually de-
fine linguistically-motivated interrelationships
among them, which the Bayesian network
models. Our methodology is almost en-
tirely unsupervised and completely language-
independent; it relies on few language re-
sources and is thus suitable for a large num-
ber of languages. Furthermore, unlike much
recent work, our approach can identify ex-
pressions of various types and syntactic con-
structions. We demonstrate a significant im-
provement in identification accuracy, com-
pared with less sophisticated baselines.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993028">
Multi-word Expressions (MWEs) are lexical items
that consist of multiple orthographic words (e.g.,
ad hoc, by and large, New York, kick the bucket).
MWEs are numerous and constitute a significant
portion of the lexicon of any natural language (Jack-
endoff, 1997; Erman and Warren, 2000; Sag et
al., 2002). They are a heterogeneous class of con-
structions with diverse sets of characteristics, dis-
tinguished by their idiosyncratic behavior. Mor-
phologically, some MWEs allow some of their con-
stituents to freely inflect while restricting (or pre-
venting) the inflection of other constituents. In
some cases MWEs may allow constituents to un-
dergo non-standard morphological inflections that
836
they would not undergo in isolation. Syntactically,
some MWEs behave like words while other are
phrases; some occur in one rigid pattern (and a fixed
order), while others permit various syntactic trans-
formations. Semantically, the compositionality of
MWEs is gradual, ranging from fully compositional
to idiomatic (Bannard et al., 2003).
Because of their prevalence and irregularity,
MWEs must be stored in lexicons of natural lan-
guage processing applications. Correct handling of
MWEs has been proven beneficial for various ap-
plications, including information retrieval, building
ontologies, text alignment, and machine translation.
We propose a novel architecture for identifying
MWEs of various types and syntactic categories in
monolingual corpora. Unlike much existing work,
which focuses on a particular syntactic construction,
our approach addresses MWEs of all types by focus-
ing on the general idiosyncratic properties of MWEs
rather than on specific properties of each sub-class
thereof. While we only evaluate our methodol-
ogy on bi-grams, it can in principle be extended
to longer MWEs. The architecture uses Bayesian
Networks (BN) to express multiple interdependent
linguistically-motivated features.
First, we automatically generate a small (training)
set of MWE and non-MWE bi-grams (positive and
negative instances, respectively). We then define a
set of linguistically-motivated features that embody
observed characteristics of MWEs. We augment
these by features that reflect collocation measures.
Finally, we define dependencies among these fea-
tures, expressed in the structure of a Bayesian Net-
work model, which we then use for classification.
This is a directed graph, whose nodes express the
features used for classification, and whose edges de-
</bodyText>
<note confidence="0.948618">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 836–845,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99865004587156">
fine causal relationships among these features. In 2 Related Work
this architecture, learning does not result in a black Early approaches to MWEs identification concen-
box, expressed solely as feature weights. Rather, the trated on their collocational behavior (Church and
structure of the BN allows us to learn the impact of Hanks, 1990). Pecina (2008) compares 55 differ-
different MWE features on the classification. The ent association measures in ranking German Adj-
result is a new unsupervised method for identifying N and PP-Verb collocation candidates. He shows
MWEs of various types in text corpora. It com- that combining different collocation measures using
bines statistics with a large array of linguistically- standard statistical classification methods improves
motivated features, organized in an architecture that over using a single collocation measure. Other re-
reflects interdependencies among the features. sults (Chang et al., 2002; Villavicencio et al., 2007)
The contribution of this work is manifold. First, suggest that some collocation measures (especially
we show how to generate training material (al- PMI and Log-likelihood) are superior to others for
most) automatically, so the method is almost com- identifying MWEs.
pletely unsupervised. The methodology we advo- Soon, however, it became clear that mere co-
cate is thus language-independent, requiring rela- occurrence measurements are not enough to identify
tively few language resources, and is therefore op- MWEs, and their linguistic properties should be ex-
timal for medium-density languages (Varga et al., ploited as well (Piao et al., 2005). Hybrid methods
2005). Second, we propose several linguistically- that combine word statistics with linguistic informa-
motivated features that can be computed from data tion exploit morphological, syntactic and semantic
and that are demonstrably productive for improv- idiosyncrasies to extract idiomatic MWEs.
ing the accuracy of MWE identification. These fea- Ramisch et al. (2008) evaluate a number of asso-
ture focus on the expression of linguistic idiosyn- ciation measures on the task of identifying English
crasies of various types, a phenomenon typical of Verb-Particle Constructions and German Adjective-
MWEs. We propose novel computational model- Noun pairs. They show that adding linguistic infor-
ing of many of these features; in particular, we ac- mation (mostly POS and POS-sequence patterns) to
count for the morphological idiosyncrasy of MWEs the association measure yields a significant improve-
using a histogram of the number of inflected forms, ment in performance over using pure frequency.
in a technique that draws from image processing. Several works address the lexical fixedness or syn-
Third, we advocate the use of Bayesian Networks tactic fixedness of (certain types of) MWEs in order
as a mechanism for expressing manually-crafted de- to extract them from texts. An expression is con-
pendencies among features; the use of BN signifi- sidered lexically fixed if replacing any of its con-
cantly improves the classification accuracy. Finally, stituents by a semantically (and syntactically) sim-
we demonstrate the utility of our methodology by ilar word generally results in an invalid or literal
applying it to Hebrew.1 Our evaluation shows that expression. Syntactically fixed expressions prohibit
the use of linguistically-motivated features results in (or restrict) syntactic variation. For example, Van de
reduction of 23% of the errors compared with a col- Cruys and Villada Moir´on (2007) use lexical fixed-
location baseline; organizing the knowledge in a BN ness to extract Dutch Verb-Noun idiomatic com-
reduces the error rate by additional 8.7%. binations (VNICs). Bannard (2007) uses syntac-
After discussing related work in the next section, tic fixedness to identify English VNICs. Another
we describe in Section 3 the methodology we pro- work uses both the syntactic and the lexical fixed-
pose, including a detailed discussion of the features ness of VNICs in order to distinguish them from
and their implementation. Section 4 provides a thor- non-idiomatic ones, and eventually to extract them
ough evaluation of the results. We conclude with from corpora (Fazly and Stevenson, 2006).
suggestions for future research. While these approaches are in line with ours, they
require lexical semantic resources (e.g., a database
that determines semantic similarity among words)
and syntactic resources (parsers) that are unavail-
1To facilitate readability we use a transliteration of Hebrew
using Roman characters; the letters used, in Hebrew lexico-
graphic order, are abgdhwzxTiklmns‘pcqrˇst.
837
able for Hebrew (and many other languages). Our matic word aligner applied to a parallel (Portuguese-
approach only requires morphological processing English) corpus. A BN was used to combine the pre-
and a bilingual dictionary, which are more readily- dictions of the various features on the test set, but
available for several languages. Note also that the structure of the network is not described. The
these approaches target a specific syntactic construc- combined classifier resulted in a much higher accu-
tion, whereas ours is adequate for various types of racy than any of the two methods alone. However,
MWEs. the BN does not play any special role in this work,
Several properties of Hebrew MWEs are de- and its structure does not reflect any insights or intu-
scribed by Al-Haj (2010); Al-Haj and Wintner itions on the structure of the problem domain or on
(2010) use them in order to construct an SVM-based interdependencies among features.
classifier that can distinguish between MWE and We, too, acknowledge the importance of combin-
non-MWE noun-noun constructions in Hebrew. The ing different types of knowledge in the hard task of
features of the SVM reflect several morphological MWE identification. In particular, we also believe
and morpho-syntactic properties of such construc- that collocation measures are highly important for
tions. The resulting classifier performs much bet- this task, but cannot completely solve the problem:
ter than a naive baseline, reducing over one third of linguistically-motivated features are mandatory in
the errors. We rely on some of these insights, as order to improve the accuracy of the classifier. In
we implement more of the linguistic properties of this work we focus on various properties of different
MWEs. Again, our methodology is not limited to a types of MWEs, and define general features that may
particular construction: indeed, we demonstrate that accurately apply to some, but not necessarily all of
our general methodology, trained on automatically- them. An architecture of Bayesian Networks is op-
generated, general training data, performs almost as timal for this task: it enables us to define weighted
well as the noun-noun-specific approach of Al-Haj dependencies among features, such that certain fea-
and Wintner (2010) on the very same dataset. tures are more significant for identifying some class
Recently, Tsvetkov and Wintner (2010b) intro- of MWEs, whereas others are more prominent in
duced a general methodology for extracting MWEs identifying other classes. As we show below, this ar-
from bilingual corpora, and applied it to Hebrew. chitecture results in significant improvements over a
The results were a highly accurate set of Hebrew more naive combination of features.
MWEs, of various types, along with their English 3 Methodology
translations. A major limitation of this work is that 3.1 Motivation
it can only be used to identify MWEs in the bilingual The task we address is identification of MWEs, of
corpus, and is thus limited in its scope. We use this various types and syntactic constructions, in mono-
methodology to extract both positive and negative lingual corpora.2 Several properties of MWEs make
instances for our training set in the current work; but this task challenging: MWEs exhibit idiosyncrasies
we extrapolate the results much further by extend- on a variety of levels, orthographic, morphological,
ing the method to monolingual corpora, which are syntactic and of course semantic (Al-Haj, 2010).
typically much larger than bilingual ones. They are also extremely diverse: for example, on
Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an en-
for classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to
For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003).
known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of
parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sug-
ment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification
2003; Denoyer and Gallinari, 2004). Very recently,
Ramisch et al. (2010) have used BN for Portuguese
MWE identification. The features used for classi-
fication were of two kinds: (1) various collocation
measures; (2) bi-grams aligned together by an auto-
838
2For simplicity, we focus on bi-grams of tokens (MWEs of
length 2) in this work; the methodology, however, is easily ex-
tensible to longer n-grams.
(Duan et al., 2009; Weller and Fritzinger, 2010;
Ramisch et al., 2010; Hazelbeck and Saito, 2010).
We believe that Bayesian Networks provide an op-
timal architecture for expressing various pieces of
knowledge aimed at MWE identification, for the fol-
lowing reasons (Heckerman, 1995):
</bodyText>
<listItem confidence="0.803245875">
• In contrast to many other classification meth-
ods, BN can learn (and express) causal relation-
ships between features. This facilitates better
understanding of the problem domain.
• BN can encode not only statistical data, but also
prior domain knowledge and human intuitions,
in the form of interdependencies among fea-
tures. We do indeed use this possibility here.
</listItem>
<subsectionHeader confidence="0.991392">
3.2 Linguistically-motivated Features
</subsectionHeader>
<bodyText confidence="0.999981223684211">
Based on the observations of Al-Haj (2010), we
define several linguistically-motivated features that
are aimed at capturing some of the unique proper-
ties of MWEs. While many idiosyncratic properties
of MWEs have been previously studied, we intro-
duce novel ways to express those properties as com-
putable features informing a classifier. Note that
many of the features we describe below are com-
pletely language-independent; others are applicable
to a wide range of languages, while few are specific
to morphologically-rich languages, and can be ex-
hibited in different ways in different languages. The
methodology we advocate, however, is completely
universal.
A common theme for all these features is idiosyn-
cracy: they are all aimed at locating some linguis-
tic property on which MWEs may differ from non-
MWEs. Below we detail these properties, along
with the features that we define to reflect them. In
all cases, the feature is applied to a candidate MWE,
defined here as a bi-gram of tokens (all possible bi-
grams are potential candidates). To compute the fea-
tures, we use a 46M-token monolingual Hebrew cor-
pus (Itai and Wintner, 2008), which we pre-process
as in Tsvetkov and Wintner (2010b). All statistics
are computed from this large corpus. Likewise, we
compute these features on a small training corpus,
which we generate automatically (see Section 3.4).
Orthographic variation Sometimes, MWEs are
written with dashes instead of inter-token spaces.
We define a binary feature, DASH, whose value is 1
iff the dash character appears in some surface form
of the candidate MWE. For example, xd-cddi (one
sided) “unilateral”.
Hapax legomena MWEs sometimes include con-
stituents that have no usage outside the particular
expression, and are hence not included in lexicons.
We define a feature, HAPAX, whose value is a binary
vector with 1 in the i-th place iff the i-th word of the
candidate is not in the lexicon, and does not occur
in other bi-grams at the same location. For exam-
ple, hwqws pwqws “hocus-pocus”. In order to filter
out potential errors, candidates must occur at least 5
times in the corpus in order for this feature to fire.
Frozen form MWE constituents sometimes occur
in one fixed, frozen form. We define a feature,
FROZEN, whose value is a binary vector with 1 in the
i-th place iff the i-th word of the candidate never in-
flects in the context of this expression. Example: bit
xwlim (house-of sick-people) “hospital”; the noun
xwlim must be in the plural in this MWE.
Partial morphological inflection In some cases,
MWE constituents undergo a (strict but non-empty)
subset of the full inflections that they would undergo
in isolation. We capture this property with a tech-
nique that has been proven useful in the area of im-
age processing (Jain, 1989, Section 7.3). We com-
pute a histogram of the distribution in the corpus of
all the possible surface forms of each constituent of
an MWE candidate. Such histograms can compactly
represent distributional information on morphologi-
cal behavior, in the same way that histograms of the
distribution of gray levels in a picture are used to
represent the picture itself.
Our assumption is that the inflection histograms
of non-MWEs are more uniform than the histograms
of MWEs, in which some inflections may be more
frequent and others may be altogether missing. Of
course, restrictions on the histogram may stem from
the part of speech of the expression; such constraints
are captured by dependencies in the BN structure.
Since each MWE is idiosyncratic in its own
way, we do not expect the histograms of MWEs to
have some specific pattern, except non-uniformity.
We therefore sort the columns of each histogram,
thereby losing information pertaining to the specific
</bodyText>
<page confidence="0.992323">
839
</page>
<bodyText confidence="0.999578325">
inflections, and retaining only information about the
idiosyncrasy of the histogram. Offline, we compute
the average histogram for positive and negative ex-
amples: The average histogram of MWEs is shorter
and less uniform than the average histogram of non-
MWEs. We define as feature, HIST, the Li (Manhat-
tan) distance between the histogram of the candidate
and the closest average histogram.
For example, the MWE bit mepv (house-of law)
“court” occurs in the following inflected forms:
bit hmepv “the court” (75%); bit mepv “a court”
(15%); bti hmepv “the courts” (8%); and bti mepv
“courts” (2%). The histogram for this candidate
is thus (75, 15, 8, 2). In contrast, the non-MWE
txwm mepv (domain-of law) “domain of the law”,
which is syntactically identical, occurs in nine dif-
ferent inflected forms, and its sorted histogram is
(59, 14, 7, 7, 5, 2, 2, 2, 2).
Context We hypothesize that MWEs tend to con-
strain their (semantic) context more strongly than
non-MWEs. We expect words that occur imme-
diately after MWEs to vary less freely than words
that immediately follow other expressions. One mo-
tivation for this hypothesis is the observation that
MWEs tend to be less polysemous than free com-
binations of words, thereby limiting the possible se-
mantic context in which they can occur.
We define a feature, CONTEXT, as follows. We
first compute a histogram of the frequencies of
words following each candidate MWE. We trim the
tail of the histogram by removing words whose fre-
quency is lower than 0.1% (the expectation is that
non-MWEs would have a much longer tail). Off-
line, we compute the same histograms for positive
and negative examples and average them as above.
The value of CONTEXT is 1 iff the histogram of the
candidate is closer (in terms of Li distance) to the
positive average.
For example, the histogram of bit mepv “court”
includes 15 values, dominated by bit mepv yliwn
“supreme court” (20%) and bit mepv mxwzi “dis-
trict court” (13%), followed by contexts whose fre-
quency ranges between 5% and 0.6%. In con-
trast, the non-MWE txwm mepv “domain-of law”
has a much shorter histogram, namely (12,11,6):
over 70% of the words following this expression oc-
cur less than 0.1% and are hence in the trimmed tail.
Syntactic diversity MWEs can belong to various
part of speech categories. We define as feature, POS,
the category of the candidate, with values obtained
by selecting frequent tuples of POS tags. For exam-
ple, Noun-Noun, PropN-PropN, Noun-Adj, etc.
Translational equivalents Since MWEs are of-
ten idiomatic, they tend to be translated in a non-
literal way, sometimes to a single word. We use
a dictionary to generate word-by-word translations
of candidate MWEs to English, and check the num-
ber of occurrences of the English literal translation
in a large English corpus.3 Due to differences in
word order between the two languages, we create
two variants for each translation, corresponding to
both possible orders. We expect non-MWEs to have
some literal translational equivalent (possibly with
frequency that correlates with their frequency in He-
brew), whereas for MWEs we expect no (or few) lit-
eral translations. We define a binary feature, TRANS,
whose value is 1 iff some literal translation of the
candidate occurs more than 5 times in the corpus.
For example, the MWE htxtn ym (marry with)
“marry” is literally translated as with marry, marry
with, together marry and marry together, none of
which occurs in the corpus.
Collocation As a baseline, statistical association
measure, we use a heuristic variant of pointwise mu-
tual information (PMI), promoting also collocations
whose constituents are frequent (Tsvetkov and Wint-
ner, 2010b). We define a binary feature, PMI, with
values (low and high) reflecting the threshold that
maximizes the accuracy of MWE classification in
Tsvetkov and Wintner (2010b).
</bodyText>
<subsectionHeader confidence="0.8805955">
3.3 Feature Interdependencies Expressed as a
Bayesian Network
</subsectionHeader>
<bodyText confidence="0.999927555555555">
A Bayesian Network (Jensen and Nielsen, 2007) is
organized as a graph whose nodes are random vari-
ables and whose edges represent interdependencies
among those variables. We use a particular type
of BN, known as causal networks, in which di-
rected edges lead to a variable from each of its direct
causes. This facilitates the expression of domain
knowledge (and intuitions, beliefs, etc.) as struc-
tural properties of the network. We use the BN as
</bodyText>
<footnote confidence="0.939409">
3We use a 120M-token newspaper corpus.
</footnote>
<page confidence="0.992229">
840
</page>
<bodyText confidence="0.999890375">
a classification device: training amounts to comput-
ing the joint probability distribution of the training
set, whereas classification maximizes the posterior
probability of the particular node (variable) being
queried.
For MWE identification we define a BN whose
nodes correspond to the features described in Sec-
tion 3.2. In addition, we define a node MWE for
the complete classification task. Over these nodes
we impose the structure depicted graphically in Fig-
ure 1. This structure, which we motivate below, is
manually defined: it reflects our understanding of
the problem domain and is a result of thorough ex-
perimentations. That said, it can of course be mod-
ified in various ways, and in particular, new nodes
can be easily added to reflect additional features.
</bodyText>
<figureCaption confidence="0.998213">
Figure 1: Bayesian Network for MWE identification
</figureCaption>
<bodyText confidence="0.999946138888889">
All nodes depend on MWE, as all are affected
by whether or not the candidate is a MWE. The
POS of an expression influences its morphological
inflection, hence the edges from POS to HIST and
to FROZEN. For example, Hebrew noun-noun con-
structions allow their constituents to undergo the full
inflectional paradigm, but when such a construction
is a MWE, inflection is severely constrained (Al-Haj
and Wintner, 2010); similarly, when one of the con-
stituents of a MWE is a conjunction, the entire ex-
pression is very likely to be frozen.
Hapaxes clearly affect all statistical metrics,
hence the edge from HAPAX to PMI, and also the
existence of literal translation, since if a word is not
in the lexicon, it does not have a translation, hence
the edge from HAPAX to TRANS. Also, we assume
that there is a correlation between the frequency (and
PMI) of a candidate and whether or not a literal
translation of the expression exists, hence the edge
from PMI to TRANS. The edges from PMI and HIST
to CONTEXT are justified by the correlation between
the frequency and variability of an expression and
the variability of the context in which it occurs.
Once the structure of the network is established,
the conditional probabilities of each dependency
have to be determined. We compute the conditional
probability tables from our training data (see below)
using Weka (Hall et al., 2009), and obtain values
for P(X  |X1, ... , Xk) for each variable X and all
variables Xi, 1 G i G k, such that the graph in-
cludes an edge from Xi to X (parents of X). We
then perform inference on the network in order to
compute P(Xmwe  |X1, ... , Xk), where Xmwe
corresponds to the node MWE, and X1, ... , Xk are
the variables corresponding to all other nodes in the
network. Using Bayes Rule,
</bodyText>
<equation confidence="0.991265">
P(Xmwe  |X1, ... , Xk) a
P(X1, ... , Xk  |Xmwe) x P(Xmwe)
</equation>
<bodyText confidence="0.9999404">
We define the prior, P(Xmwe), to be 0.41:
this is the percentage of MWEs in WordNet 1.7
(Fellbaum, 1998). The conditional probabilities
P(X1, ... , Xk  |Xmwe) are determined by Weka
from the conditional probability tables:
</bodyText>
<equation confidence="0.546177">
P(X1, ... , Xk  |Xmwe) = Πki=1P(Xi  |pai)
</equation>
<bodyText confidence="0.9980505">
where k is the number of nodes in the BN (other than
Xmwe) and pai is the set of parents of Xi.
</bodyText>
<subsectionHeader confidence="0.98736">
3.4 Automatic Generation of Training Data
</subsectionHeader>
<bodyText confidence="0.99995125">
For training we need samples of positive and nega-
tive instances of MWEs, each associated with a vec-
tor of the values of all features discussed in Sec-
tion 3.2. We generate this training material auto-
matically. We use a small Hebrew-English bilin-
gual corpus (Tsvetkov and Wintner, 2010a). We
word-align the corpus with Giza++ (Och and Ney,
2003), and then apply the (completely unsupervised)
</bodyText>
<figure confidence="0.985135714285714">
DASH HAPAX CNTXT
PMI
MWE
TRANS
FRZN
HIST
POS
</figure>
<page confidence="0.994069">
841
</page>
<bodyText confidence="0.989413913043478">
algorithm of Tsvetkov and Wintner (2010b), which
extracts MWE candidates from the aligned corpus
and re-ranks them using statistics computed from a
large monolingual corpus. The core idea behind this
method is that MWEs tend to be translated in non-
literal ways; in a parallel corpus, words that are 1:1
aligned typically indicate literal translations and are
hence unlikely constituents of MWEs.
The result is a set of 134,001 Hebrew bi-gram
types (from the bilingual corpus), classified as either
1:1 aligned (implying they are likely not MWEs)
or unaligned (in which case they may or may not
be MWEs). In addition, for each bi-gram we
have a PMI score; naturally, higher PMI scores
are indicative of MWEs. We thus divide the set
into four classes: aligned bi-grams with high PMI
score, aligned bi-grams with low PMI score, mis-
aligned with high PMI and misaligned with low
PMI. Aligned bi-grams, independently of their PMI
score, are more likely non-MWEs; high-PMI mis-
aligned bi-grams are very likely MWEs; and the sta-
tus of low-PMI misaligned bi-grams is unclear, and
must be further investigated. This is summarized in
</bodyText>
<tableCaption confidence="0.940239">
Table 1.
</tableCaption>
<table confidence="0.845330333333333">
Misaligned Aligned
High PMI MWE non-MWE
Low PMI unclear non-MWE
</table>
<tableCaption confidence="0.997536">
Table 1: Classification of bi-grams
</tableCaption>
<bodyText confidence="0.995060666666667">
We set the threshold that separates low PMI from
high PMI as in Tsvetkov and Wintner (2010b). The
results of this classification is depicted in Table 2.
</bodyText>
<table confidence="0.99828525">
Misaligned Aligned Total
High PMI 2,203 493 2,696
Low PMI 61,314 69,991 131,305
Total 63,517 70,484 134,001
</table>
<tableCaption confidence="0.990661">
Table 2: Statistics of the sample space from which the
training set is generated
</tableCaption>
<bodyText confidence="0.999960258064516">
We assume that all bi-grams in the ‘Aligned’ col-
umn are non-MWEs. Additionally, we assume that
the 2,203 misaligned bi-grams with high PMI scores
are likely MWEs. As for the set of over 61,000 mis-
aligned low-PMI bi-grams, certainly many of them
are non-MWEs, but some may be MWEs, and we
are interested in including them as positive examples
of MWEs with low PMI scores. We therefore manu-
ally annotate a sample of 50 MWEs from this partic-
ular set (we had to manually go over a few thousands
of bi-grams to select this sample). This is the only
supervision provided in this work.
The remaining question is how to determine the
sizes of samples from each of the other three classes.
We use two guidelines: first, we would like the ra-
tio of MWEs to non-MWEs in the training set to be
41 : 59, reflecting the ratio in WordNet (the prior
MWE probability). Second, we would like classifi-
cation by PMI score only to yield a reasonable base-
line; the baseline is defined as the ratio of the sum of
high-PMI MWEs plus low-PMI non-MWEs to the
size of the training set. We choose 67%, the PMI
baseline reported by Al-Haj and Wintner (2010). As
a result of these two considerations, we end up with
training sets whose sizes are depicted in Table 3. We
randomly select from the sample space this many in-
stances for each class. Since much of the procedure
of preparing training data is automatic, the results
may be somewhat noisy. As Bayesian Network are
known to be robust to noisy data, we expect the BN
to compensate for this problem.
</bodyText>
<table confidence="0.998795">
MWE non-MWE Total
High PMI 300 232 532
Low PMI 50 272 322
Total 350 504 854
</table>
<tableCaption confidence="0.999662">
Table 3: Sizes of each training set
</tableCaption>
<sectionHeader confidence="0.998457" genericHeader="introduction">
4 Results and Evaluation
</sectionHeader>
<bodyText confidence="0.999000909090909">
We use the training set described above for train-
ing and evaluation: we perform 10-fold cross vali-
dation experiments, reporting Precision, Recall, Ac-
curacy and F-measure in three setups: one (SVM)
in which we train an SVM classifier4 with the
features described in Section 3.2; one (BN-auto)
in which we train a BN but let Weka determine
its structure (using the K2 algorithm); and one
(BN) in which we train a Bayesian Network whose
structure reflects manually-crafted linguistically-
motivated knowledge, as depicted in Figure 1. The
</bodyText>
<footnote confidence="0.9847025">
4We use Weka SMO with the PolyKernel setup; experimen-
tation with several other kernels yielded worse results.
</footnote>
<page confidence="0.993564">
842
</page>
<bodyText confidence="0.7666845">
results, along with the PMI baseline figures, are
listed in Table 4.
</bodyText>
<table confidence="0.9996388">
Accuracy Prec. Recall F-score
PMI 66.98% 0.73 0.67 0.67
BN-auto 71.19% 0.71 0.71 0.71
SVM 74.59% 0.75 0.75 0.75
BN 76.82% 0.77 0.77 0.77
</table>
<tableCaption confidence="0.999946">
Table 4: 10-fold cross validation evaluation results
</tableCaption>
<bodyText confidence="0.9995224375">
The linguistically-motivated features defined in
Section 3.2 are clearly helpful in the classification
task: the accuracy of the SVM, informed by these
features, is close to 75%, reducing the error rate
of the PMI baseline by 23%. The contribution
of the Bayesian Network is also highly significant,
reducing almost 7% more errors (8.7% of the er-
rors made by the SVM classifier), or a total of al-
most 30% error-rate reduction with respect to the
baseline. Interestingly, a BN whose structure does
not reflect prior knowledge, but is rather learned au-
tomatically, performs poorly. It is the combination
of linguistically-motivated features with feature in-
terdependencies reflecting domain knowledge that
contribute to the best performance.
As a further demonstration of the utility of our
approach, we evaluate the algorithm on an addi-
tional test set that was used for evaluation in the past
(Tsvetkov and Wintner, 2010b; Al-Haj and Wintner,
2010). This is a small annotated corpus, NN, of He-
brew noun-noun constructions. The corpus consists
of 413 high-frequency bi-grams of the same syntac-
tic construction; of those, 178 are tagged as MWEs
(in this case, noun compounds) and 235 as non-
MWEs. This corpus consolidates the annotation of
three annotators: only instances on which all three
agreed were included. Since it includes both posi-
tive and negative instances, this corpus facilitates a
robust evaluation of precision and recall.
We train a Bayesian Network on the training set
described in Section 3.4 and use it to classify the set
NN. We compare the results of this classifier with a
PMI baseline (using the same threshold as above),
and also with the classification results reported by
Al-Haj and Wintner (2010) (AW); the latter reflects
10-fold cross-validation evaluation using the entire
set, so it should be considered an upper bound for
any classifier that uses a general training corpus.
The results are depicted in Table 5. They clearly
demonstrate that the linguistically-motivated fea-
tures we define provide a significant improvement in
classification accuracy over the baseline PMI mea-
sure. Note that our F-score, 0.77, is very close to
the best result of 0.79 obtained by Al-Haj and Wint-
ner (2010) as the average of 10-fold cross valida-
tion runs, using only high-frequency noun-noun con-
structions for training. We interpret this result as a
further proof of the robustness of our architecture.
</bodyText>
<table confidence="0.999551">
Accuracy Precision Recall F-score
PMI 71.43% 0.71 0.71 0.71
BN 77.00% 0.77 0.77 0.77
AW 80.77% 0.77 0.81 0.79
</table>
<tableCaption confidence="0.999844">
Table 5: Evaluation results: noun-noun constructions
</tableCaption>
<bodyText confidence="0.99998268">
Finally, we have used the trained BN to classify
the entire set of bi-grams present in the (Hebrew
side of the) parallel corpus described in Tsvetkov
and Wintner (2010a). Of the 134,000 candidates,
only 4,000 are classified as MWEs. We sort this
list of potential MWEs by the probability assigned
by the BN to the positive value of the variable
Xmwe. The resulting sorted list is dominated by
high-PMI bi-grams, especially proper names, all of
which are indeed MWEs. The first non-MWE (false
positive) occurs in the 50th place on the list; it is
crpt niqwla “France Nicolas”, which is obviously a
sub-sequence of the larger MWE, neia crpt niqwla
srqwzi “French president Nicolas Sarkozy”. Simi-
lar sub-sequences are also present, but only five are
in the top-100. Such false positives can be reduced
when longer MWEs are extracted, as it can be as-
sumed that a sub-sequence of a longer MWE does
not have to be identified. Other false positives in the
top-100 include some highly frequent expressions,
but over 85 of the top-100 are clearly MWEs.
While more careful evaluation is required in order
to estimate the rate of true positives in this list, we
trust that the vast majority of the positive results are
indeed MWEs.
</bodyText>
<sectionHeader confidence="0.979845" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9916175">
We presented a novel architecture for identifying
MWEs in text corpora. The main insights we em-
</bodyText>
<page confidence="0.996528">
843
</page>
<bodyText confidence="0.999978">
phasize are sophisticated computational encoding of
linguistic knowledge that focuses on the idiosyn-
cratic behavior of such expressions. This is reflected
in two ways in our work: by defining computable
features that reflect different facets of irregulari-
ties; and by framing the features as part of a larger
Bayesian Network that accounts for interdependen-
cies among them. We also introduce a method for
automatically generating a training set for this task,
which renders the classification almost entirely un-
supervised. The result is a nearly-unsupervised,
language-independent classification method that can
identify MWEs of various lengths, types and con-
structions. Evaluation on Hebrew shows significant
improvement in the accuracy of the classifier com-
pared with the state of the art.
The modular architecture of BN facilitates easy
exploration with more features. We are currently in-
vestigating the contribution of various other sources
of information to the classification task. For exam-
ple, Hebrew lacks large-scale lexical semantic re-
sources. However, it is possible to literally trans-
late a MWE candidate to English and rely on the
English WordNet for generating synonyms of the lit-
eral translation. Such “literal synonyms” can then be
back-translated to Hebrew. The assumption is that
if a back-translated expression has a high PMI, the
original candidate is very likely not a MWE. While
such a feature may contribute little on its own, in-
corporating it in a well-structured BN may improve
performance.
While our methodology is applicable to MWEs
of any length, we have so far only evaluated it on bi-
grams. In the future, we intend to extend the evalu-
ation to longer n-grams. We also plan to apply the
methodology to languages other than Hebrew.
</bodyText>
<sectionHeader confidence="0.997492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99726375">
This research was supported by THE ISRAEL
SCIENCE FOUNDATION (grants No. 137/06,
1269/07). We are grateful to Gennadi Lembersky
for his continuous help.
</bodyText>
<sectionHeader confidence="0.99683" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985190754385965">
Hassan Al-Haj and Shuly Wintner. 2010. Identifying
multi-word expressions by leveraging morphological
and syntactic idiosyncrasy. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics (COLING 2010), pages 10–18, Beijing, China,
August. Coling 2010 Organizing Committee.
Hassan Al-Haj. 2010. Hebrew multiword expressions:
Linguistic properties, lexical representation, morpho-
logical processing, and automatic acquisition. Mas-
ter’s thesis, University of Haifa, February.
Colin Bannard, Timothy Baldwin, and Alex Lascarides.
2003. A statistical approach to the semantics of verb-
particles. In Diana McCarthy Francis Bond, Anna Ko-
rhonen and Aline Villavicencio, editors, Proceedings
of the ACL 2003 Workshop on Multiword Expressions:
Analysis, Acquisition and Treatment, pages 65–72.
Colin Bannard. 2007. A measure of syntactic flexibility
for automatically identifying multiword expressions in
corpora. In Proceedings of the Workshop on A Broader
Perspective on Multiword Expressions, pages 1–8. As-
sociation for Computational Linguistics.
P´avel Calado, Marco Cristo, Edleno Silva De Moura,
Nivio Ziviani, Berthier A. Ribeiro-Neto, and Mar-
cos Andr´e Gonc¸alves. 2003. Combining link-based
and content-based methods for web document classifi-
cation. In Proceedings of CIKM-03, 12th ACM Inter-
national Conference on Information and Knowledge
Management, pages 394–401, New Orleans, US. ACM
Press, New York, US.
Baobao Chang, Pernilla Danielsson, and Wolfgang Teu-
bert. 2002. Extraction of translation unit from
Chinese-English parallel corpora. In Proceedings of
the first SIGHAN workshop on Chinese language pro-
cessing, pages 1–5, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicogra-
phy. Computational Linguistics, 16(1):22–29.
Ludovic Denoyer and Patrick Gallinari. 2004. Bayesian
network model for semi-structured document classi-
fication. Information Processing and Management,
40(5):807–827.
Jianyong Duan, Mei Zhang, Lijing Tong, and Feng Guo.
2009. A hybrid approach to improve bilingual mul-
tiword expression extraction. In Thanaruk Theera-
munkong, Boonserm Kijsirikul, Nick Cercone, and
Tu-Bao Ho, editors, Advances in Knowledge Discov-
ery and Data Mining, volume 5476 of Lecture Notes
in Computer Science, pages 541–547. Springer, Berlin
and Heidelberg.
Britt Erman and Beatrice Warren. 2000. The idiom prin-
ciple and the open choice principle. Text, 20(1):29–62.
Afsaneh Fazly and Suzanne Stevenson. 2006. Automat-
ically constructing a lexicon of verb phrase idiomatic
combinations. In Proceedings of the 11th Conference
of the European Chapter of the Association for Com-
putational Linguistics (EACL), pages 337–344.
</reference>
<page confidence="0.994315">
844
</page>
<reference confidence="0.999676532710281">
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. Language, Speech and Com-
munication. MIT Press.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an update.
SIGKDD Explorations, 11(1):10–18.
Gregory Hazelbeck and Hiroaki Saito. 2010. A hybrid
approach for functional expression identification in a
japanese reading assistant. In Proceedings of the 2010
Workshop on Multiword Expressions: from Theory to
Applications, pages 81–84, Beijing, China, August.
Coling 2010 Organizing Committee.
David Heckerman. 1995. A tutorial on learning with
Bayesian networks. Technical Report MSR-TR-95-
06, Microsoft Research, March.
Alon Itai and Shuly Wintner. 2008. Language resources
for Hebrew. Language Resources and Evaluation,
42(1):75–98, March.
Ray Jackendoff. 1997. The Architecture of the Language
Faculty. MIT Press, Cambridge, USA.
Anil K. Jain. 1989. Fundamentals of digital image pro-
cessing. Prentice-Hall, Inc., NJ, USA.
Finn V. Jensen and Thomas D. Nielsen. 2007. Bayesian
Networks and Decision Graphs. Springer, 2nd edition.
Wai Lam, Kon F. Low, and Chao Y. Ho. 1997. Using a
bayesian network induction approach for text catego-
rization. In Martha E. Pollack, editor, Proceedings of
IJCAI-97, 15th International Joint Conference on Ar-
tificial Intelligence, pages 745–750, Nagoya, JP. Mor-
gan Kaufmann Publishers, San Francisco, US.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Pavel Pecina. 2008. A machine learning approach to
multiword expression extraction. In Proceedings of
the LREC Workshop Towards a Shared Task for Multi-
word Expressions.
Leonid Peshkin, Avi Pfeffer, and Virginia Savova. 2003.
Bayesian nets in syntactic categorization of novel
words. In Proceedings of the 2003 Conference of the
North American Chapter of the Association for Com-
putational Linguistics on Human Language Technol-
ogy: companion volume of the Proceedings of HLT-
NAACL 2003–short papers - Volume 2, NAACL ’03,
pages 79–81, Morristown, NJ, USA. Association for
Computational Linguistics.
Scott Songlin Piao, Paul Rayson, Dawn Archer, and Tony
McEnery. 2005. Comparing and combining a se-
mantic tagger and a statistical tool for mwe extraction.
Computer Speech and Language, 19(4):378–397.
Carlos Ramisch, Paulo Schreiner, Marco Idiart, and
Alline Villavicencio. 2008. An evaluation of meth-
ods for the extraction of multiword expressions. In
Proceedings of the LREC Workshop Towards a Shared
Task for Multiword Expressions.
Carlos Ramisch, Helena de Medeiros Caseli, Aline
Villavicencio, Andr´e Machado, and Maria Finatto.
2010. A hybrid approach for multiword expression
identification. In Thiago Pardo, Ant´onio Branco,
Aldebaro Klautau, Renata Vieira, and Vera de Lima,
editors, Computational Processing of the Portuguese
Language, volume 6001 of Lecture Notes in Computer
Science, pages 65–74. Springer.
Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-
take, and Dan Flickinger. 2002. Multiword expres-
sions: A pain in the neck for NLP. In Proceedings of
the Third International Conference on Intelligent Text
Processing and Computational Linguistics (CICLING
2002), pages 1–15, Mexico City, Mexico.
Virginia Savova and Leonid Peshkin. 2005. Dependency
parsing with dynamic bayesian network. In Proceed-
ings of the 20th national conference on Artificial intel-
ligence - Volume 3, pages 1112–1117. AAAI Press.
Yulia Tsvetkov and Shuly Wintner. 2010a. Automatic
acquisition of parallel corpora from websites with dy-
namic content. In Proceedings of the Seventh confer-
ence on International Language Resources and Eval-
uation (LREC’10), pages 3389–3392. European Lan-
guage Resources Association (ELRA), May.
Yulia Tsvetkov and Shuly Wintner. 2010b. Extraction
of multi-word expressions from small parallel corpora.
In Proceedings of the 23rd International Conference
on Computational Linguistics (COLING 2010), Au-
gust.
Tim Van de Cruys and Bego˜na Villada Moir´on. 2007.
Semantics-based multiword expression extraction. In
Proceedings of the Workshop on A Broader Perspec-
tive on Multiword Expressions, pages 25–32, Prague,
Czech Republic, June. Association for Computational
Linguistics.
D´aniel Varga, P´eter Hal´acsy, Andr´as Kornai, Viktor
Nagy, L´aszl´o N´emeth, and Viktor Tr´on. 2005. Par-
allel corpora for medium density languages. In Pro-
ceedings of RANLP’2005, pages 590–596.
Aline Villavicencio, Valia Kordoni, Yi Zhang, Marco
Idiart, and Carlos Ramisch. 2007. Validation and
evaluation of automatically acquired multiword ex-
pressions for grammar engineering. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
1034–1043.
Marion Weller and Fabienne Fritzinger. 2010. A hy-
brid approach for the identification of multiword ex-
pressions. In Proceedings of the SLTC 2010 Workshop
on Compounds and Multiword Expressions, October.
</reference>
<page confidence="0.998852">
845
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.800901">
<title confidence="0.999114">Identification of Multi-word Expressions Combining Multiple Linguistic Information Sources</title>
<author confidence="0.965115">Yulia Tsvetkov Shuly Wintner</author>
<affiliation confidence="0.9707875">Language Technologies Institute Department of Computer Science Carnegie Mellon University University of Haifa</affiliation>
<email confidence="0.981042">yulia.tsvetkov@gmail.comshuly@cs.haifa.ac.il</email>
<abstract confidence="0.993006619047619">We propose an architecture for expressing various linguistically-motivated features that help identify multi-word expressions in natural language texts. The architecture combines various linguistically-motivated classification features in a Bayesian Network. We introduce novel ways for computing many of these features, and manually define linguistically-motivated interrelationships among them, which the Bayesian network models. Our methodology is almost entirely unsupervised and completely languageindependent; it relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hassan Al-Haj</author>
<author>Shuly Wintner</author>
</authors>
<title>Identifying multi-word expressions by leveraging morphological and syntactic idiosyncrasy.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010),</booktitle>
<pages>10--18</pages>
<location>Beijing, China,</location>
<contexts>
<context position="23033" citStr="Al-Haj and Wintner, 2010" startWordPosition="3584" endWordPosition="3587">rough experimentations. That said, it can of course be modified in various ways, and in particular, new nodes can be easily added to reflect additional features. Figure 1: Bayesian Network for MWE identification All nodes depend on MWE, as all are affected by whether or not the candidate is a MWE. The POS of an expression influences its morphological inflection, hence the edges from POS to HIST and to FROZEN. For example, Hebrew noun-noun constructions allow their constituents to undergo the full inflectional paradigm, but when such a construction is a MWE, inflection is severely constrained (Al-Haj and Wintner, 2010); similarly, when one of the constituents of a MWE is a conjunction, the entire expression is very likely to be frozen. Hapaxes clearly affect all statistical metrics, hence the edge from HAPAX to PMI, and also the existence of literal translation, since if a word is not in the lexicon, it does not have a translation, hence the edge from HAPAX to TRANS. Also, we assume that there is a correlation between the frequency (and PMI) of a candidate and whether or not a literal translation of the expression exists, hence the edge from PMI to TRANS. The edges from PMI and HIST to CONTEXT are justified</context>
<context position="27979" citStr="Al-Haj and Wintner (2010)" startWordPosition="4455" endWordPosition="4458"> to select this sample). This is the only supervision provided in this work. The remaining question is how to determine the sizes of samples from each of the other three classes. We use two guidelines: first, we would like the ratio of MWEs to non-MWEs in the training set to be 41 : 59, reflecting the ratio in WordNet (the prior MWE probability). Second, we would like classification by PMI score only to yield a reasonable baseline; the baseline is defined as the ratio of the sum of high-PMI MWEs plus low-PMI non-MWEs to the size of the training set. We choose 67%, the PMI baseline reported by Al-Haj and Wintner (2010). As a result of these two considerations, we end up with training sets whose sizes are depicted in Table 3. We randomly select from the sample space this many instances for each class. Since much of the procedure of preparing training data is automatic, the results may be somewhat noisy. As Bayesian Network are known to be robust to noisy data, we expect the BN to compensate for this problem. MWE non-MWE Total High PMI 300 232 532 Low PMI 50 272 322 Total 350 504 854 Table 3: Sizes of each training set 4 Results and Evaluation We use the training set described above for training and evaluatio</context>
<context position="30366" citStr="Al-Haj and Wintner, 2010" startWordPosition="4851" endWordPosition="4854">re errors (8.7% of the errors made by the SVM classifier), or a total of almost 30% error-rate reduction with respect to the baseline. Interestingly, a BN whose structure does not reflect prior knowledge, but is rather learned automatically, performs poorly. It is the combination of linguistically-motivated features with feature interdependencies reflecting domain knowledge that contribute to the best performance. As a further demonstration of the utility of our approach, we evaluate the algorithm on an additional test set that was used for evaluation in the past (Tsvetkov and Wintner, 2010b; Al-Haj and Wintner, 2010). This is a small annotated corpus, NN, of Hebrew noun-noun constructions. The corpus consists of 413 high-frequency bi-grams of the same syntactic construction; of those, 178 are tagged as MWEs (in this case, noun compounds) and 235 as nonMWEs. This corpus consolidates the annotation of three annotators: only instances on which all three agreed were included. Since it includes both positive and negative instances, this corpus facilitates a robust evaluation of precision and recall. We train a Bayesian Network on the training set described in Section 3.4 and use it to classify the set NN. We c</context>
<context position="31636" citStr="Al-Haj and Wintner (2010)" startWordPosition="5057" endWordPosition="5061">PMI baseline (using the same threshold as above), and also with the classification results reported by Al-Haj and Wintner (2010) (AW); the latter reflects 10-fold cross-validation evaluation using the entire set, so it should be considered an upper bound for any classifier that uses a general training corpus. The results are depicted in Table 5. They clearly demonstrate that the linguistically-motivated features we define provide a significant improvement in classification accuracy over the baseline PMI measure. Note that our F-score, 0.77, is very close to the best result of 0.79 obtained by Al-Haj and Wintner (2010) as the average of 10-fold cross validation runs, using only high-frequency noun-noun constructions for training. We interpret this result as a further proof of the robustness of our architecture. Accuracy Precision Recall F-score PMI 71.43% 0.71 0.71 0.71 BN 77.00% 0.77 0.77 0.77 AW 80.77% 0.77 0.81 0.79 Table 5: Evaluation results: noun-noun constructions Finally, we have used the trained BN to classify the entire set of bi-grams present in the (Hebrew side of the) parallel corpus described in Tsvetkov and Wintner (2010a). Of the 134,000 candidates, only 4,000 are classified as MWEs. We sort</context>
</contexts>
<marker>Al-Haj, Wintner, 2010</marker>
<rawString>Hassan Al-Haj and Shuly Wintner. 2010. Identifying multi-word expressions by leveraging morphological and syntactic idiosyncrasy. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), pages 10–18, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Al-Haj</author>
</authors>
<title>Hebrew multiword expressions: Linguistic properties, lexical representation, morphological processing, and automatic acquisition. Master’s thesis,</title>
<date>2010</date>
<institution>University of Haifa,</institution>
<contexts>
<context position="9217" citStr="Al-Haj (2010)" startWordPosition="1359" endWordPosition="1360">used to combine the preand a bilingual dictionary, which are more readily- dictions of the various features on the test set, but available for several languages. Note also that the structure of the network is not described. The these approaches target a specific syntactic construc- combined classifier resulted in a much higher accution, whereas ours is adequate for various types of racy than any of the two methods alone. However, MWEs. the BN does not play any special role in this work, Several properties of Hebrew MWEs are de- and its structure does not reflect any insights or intuscribed by Al-Haj (2010); Al-Haj and Wintner itions on the structure of the problem domain or on (2010) use them in order to construct an SVM-based interdependencies among features. classifier that can distinguish between MWE and We, too, acknowledge the importance of combinnon-MWE noun-noun constructions in Hebrew. The ing different types of knowledge in the hard task of features of the SVM reflect several morphological MWE identification. In particular, we also believe and morpho-syntactic properties of such construc- that collocation measures are highly important for tions. The resulting classifier performs much b</context>
<context position="11924" citStr="Al-Haj, 2010" startWordPosition="1779" endWordPosition="1780"> can only be used to identify MWEs in the bilingual The task we address is identification of MWEs, of corpus, and is thus limited in its scope. We use this various types and syntactic constructions, in monomethodology to extract both positive and negative lingual corpora.2 Several properties of MWEs make instances for our training set in the current work; but this task challenging: MWEs exhibit idiosyncrasies we extrapolate the results much further by extend- on a variety of levels, orthographic, morphological, ing the method to monolingual corpora, which are syntactic and of course semantic (Al-Haj, 2010). typically much larger than bilingual ones. They are also extremely diverse: for example, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification</context>
<context position="13736" citStr="Al-Haj (2010)" startWordPosition="2061" endWordPosition="2062"> Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Heckerman, 1995): • In contrast to many other classification methods, BN can learn (and express) causal relationships between features. This facilitates better understanding of the problem domain. • BN can encode not only statistical data, but also prior domain knowledge and human intuitions, in the form of interdependencies among features. We do indeed use this possibility here. 3.2 Linguistically-motivated Features Based on the observations of Al-Haj (2010), we define several linguistically-motivated features that are aimed at capturing some of the unique properties of MWEs. While many idiosyncratic properties of MWEs have been previously studied, we introduce novel ways to express those properties as computable features informing a classifier. Note that many of the features we describe below are completely language-independent; others are applicable to a wide range of languages, while few are specific to morphologically-rich languages, and can be exhibited in different ways in different languages. The methodology we advocate, however, is comple</context>
</contexts>
<marker>Al-Haj, 2010</marker>
<rawString>Hassan Al-Haj. 2010. Hebrew multiword expressions: Linguistic properties, lexical representation, morphological processing, and automatic acquisition. Master’s thesis, University of Haifa, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verbparticles.</title>
<date>2003</date>
<booktitle>Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>65--72</pages>
<editor>In Diana McCarthy Francis Bond, Anna Korhonen and Aline Villavicencio, editors,</editor>
<contexts>
<context position="2169" citStr="Bannard et al., 2003" startWordPosition="301" endWordPosition="304"> by their idiosyncratic behavior. Morphologically, some MWEs allow some of their constituents to freely inflect while restricting (or preventing) the inflection of other constituents. In some cases MWEs may allow constituents to undergo non-standard morphological inflections that 836 they would not undergo in isolation. Syntactically, some MWEs behave like words while other are phrases; some occur in one rigid pattern (and a fixed order), while others permit various syntactic transformations. Semantically, the compositionality of MWEs is gradual, ranging from fully compositional to idiomatic (Bannard et al., 2003). Because of their prevalence and irregularity, MWEs must be stored in lexicons of natural language processing applications. Correct handling of MWEs has been proven beneficial for various applications, including information retrieval, building ontologies, text alignment, and machine translation. We propose a novel architecture for identifying MWEs of various types and syntactic categories in monolingual corpora. Unlike much existing work, which focuses on a particular syntactic construction, our approach addresses MWEs of all types by focusing on the general idiosyncratic properties of MWEs r</context>
<context position="12314" citStr="Bannard et al., 2003" startWordPosition="1838" endWordPosition="1841">g: MWEs exhibit idiosyncrasies we extrapolate the results much further by extend- on a variety of levels, orthographic, morphological, ing the method to monolingual corpora, which are syntactic and of course semantic (Al-Haj, 2010). typically much larger than bilingual ones. They are also extremely diverse: for example, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWE</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verbparticles. In Diana McCarthy Francis Bond, Anna Korhonen and Aline Villavicencio, editors, Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
</authors>
<title>A measure of syntactic flexibility for automatically identifying multiword expressions in corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7518" citStr="Bannard (2007)" startWordPosition="1091" endWordPosition="1092">(and syntactically) simwe demonstrate the utility of our methodology by ilar word generally results in an invalid or literal applying it to Hebrew.1 Our evaluation shows that expression. Syntactically fixed expressions prohibit the use of linguistically-motivated features results in (or restrict) syntactic variation. For example, Van de reduction of 23% of the errors compared with a col- Cruys and Villada Moir´on (2007) use lexical fixedlocation baseline; organizing the knowledge in a BN ness to extract Dutch Verb-Noun idiomatic comreduces the error rate by additional 8.7%. binations (VNICs). Bannard (2007) uses syntacAfter discussing related work in the next section, tic fixedness to identify English VNICs. Another we describe in Section 3 the methodology we pro- work uses both the syntactic and the lexical fixedpose, including a detailed discussion of the features ness of VNICs in order to distinguish them from and their implementation. Section 4 provides a thor- non-idiomatic ones, and eventually to extract them ough evaluation of the results. We conclude with from corpora (Fazly and Stevenson, 2006). suggestions for future research. While these approaches are in line with ours, they require </context>
</contexts>
<marker>Bannard, 2007</marker>
<rawString>Colin Bannard. 2007. A measure of syntactic flexibility for automatically identifying multiword expressions in corpora. In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P´avel Calado</author>
<author>Marco Cristo</author>
<author>Edleno Silva De Moura</author>
<author>Nivio Ziviani</author>
<author>Berthier A Ribeiro-Neto</author>
<author>Marcos Andr´e Gonc¸alves</author>
</authors>
<title>Combining link-based and content-based methods for web document classification.</title>
<date>2003</date>
<booktitle>In Proceedings of CIKM-03, 12th ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>394--401</pages>
<publisher>ACM Press,</publisher>
<location>New Orleans, US.</location>
<marker>Calado, Cristo, De Moura, Ziviani, Ribeiro-Neto, Gonc¸alves, 2003</marker>
<rawString>P´avel Calado, Marco Cristo, Edleno Silva De Moura, Nivio Ziviani, Berthier A. Ribeiro-Neto, and Marcos Andr´e Gonc¸alves. 2003. Combining link-based and content-based methods for web document classification. In Proceedings of CIKM-03, 12th ACM International Conference on Information and Knowledge Management, pages 394–401, New Orleans, US. ACM Press, New York, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baobao Chang</author>
<author>Pernilla Danielsson</author>
<author>Wolfgang Teubert</author>
</authors>
<title>Extraction of translation unit from Chinese-English parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the first SIGHAN workshop on Chinese language processing,</booktitle>
<pages>1--5</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4739" citStr="Chang et al., 2002" startWordPosition="672" endWordPosition="675">, 1990). Pecina (2008) compares 55 differdifferent MWE features on the classification. The ent association measures in ranking German Adjresult is a new unsupervised method for identifying N and PP-Verb collocation candidates. He shows MWEs of various types in text corpora. It com- that combining different collocation measures using bines statistics with a large array of linguistically- standard statistical classification methods improves motivated features, organized in an architecture that over using a single collocation measure. Other rereflects interdependencies among the features. sults (Chang et al., 2002; Villavicencio et al., 2007) The contribution of this work is manifold. First, suggest that some collocation measures (especially we show how to generate training material (al- PMI and Log-likelihood) are superior to others for most) automatically, so the method is almost com- identifying MWEs. pletely unsupervised. The methodology we advo- Soon, however, it became clear that mere cocate is thus language-independent, requiring rela- occurrence measurements are not enough to identify tively few language resources, and is therefore op- MWEs, and their linguistic properties should be extimal for</context>
</contexts>
<marker>Chang, Danielsson, Teubert, 2002</marker>
<rawString>Baobao Chang, Pernilla Danielsson, and Wolfgang Teubert. 2002. Extraction of translation unit from Chinese-English parallel corpora. In Proceedings of the first SIGHAN workshop on Chinese language processing, pages 1–5, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ludovic Denoyer</author>
<author>Patrick Gallinari</author>
</authors>
<title>Bayesian network model for semi-structured document classification.</title>
<date>2004</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>40--5</pages>
<contexts>
<context position="12641" citStr="Denoyer and Gallinari, 2004" startWordPosition="1888" endWordPosition="1891">, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identificat</context>
</contexts>
<marker>Denoyer, Gallinari, 2004</marker>
<rawString>Ludovic Denoyer and Patrick Gallinari. 2004. Bayesian network model for semi-structured document classification. Information Processing and Management, 40(5):807–827.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianyong Duan</author>
<author>Mei Zhang</author>
<author>Lijing Tong</author>
<author>Feng Guo</author>
</authors>
<title>A hybrid approach to improve bilingual multiword expression extraction.</title>
<date>2009</date>
<booktitle>In Thanaruk Theeramunkong, Boonserm Kijsirikul, Nick Cercone, and Tu-Bao Ho, editors, Advances in Knowledge Discovery and Data Mining,</booktitle>
<volume>5476</volume>
<pages>541--547</pages>
<publisher>Springer,</publisher>
<location>Berlin and Heidelberg.</location>
<contexts>
<context position="13027" citStr="Duan et al., 2009" startWordPosition="1952" endWordPosition="1955">parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Heckerman, 1995): • In contrast to many other classification methods, BN can learn (and express) causal relationships between features. This facilitates better understanding of the problem domain. • BN can encode not only statistical data, but also prior domain knowledge and human intuitions, in the form of interdependencies among features. We do indee</context>
</contexts>
<marker>Duan, Zhang, Tong, Guo, 2009</marker>
<rawString>Jianyong Duan, Mei Zhang, Lijing Tong, and Feng Guo. 2009. A hybrid approach to improve bilingual multiword expression extraction. In Thanaruk Theeramunkong, Boonserm Kijsirikul, Nick Cercone, and Tu-Bao Ho, editors, Advances in Knowledge Discovery and Data Mining, volume 5476 of Lecture Notes in Computer Science, pages 541–547. Springer, Berlin and Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Britt Erman</author>
<author>Beatrice Warren</author>
</authors>
<title>The idiom principle and the open choice principle.</title>
<date>2000</date>
<journal>Text,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="1428" citStr="Erman and Warren, 2000" startWordPosition="190" endWordPosition="193"> relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines. 1 Introduction Multi-word Expressions (MWEs) are lexical items that consist of multiple orthographic words (e.g., ad hoc, by and large, New York, kick the bucket). MWEs are numerous and constitute a significant portion of the lexicon of any natural language (Jackendoff, 1997; Erman and Warren, 2000; Sag et al., 2002). They are a heterogeneous class of constructions with diverse sets of characteristics, distinguished by their idiosyncratic behavior. Morphologically, some MWEs allow some of their constituents to freely inflect while restricting (or preventing) the inflection of other constituents. In some cases MWEs may allow constituents to undergo non-standard morphological inflections that 836 they would not undergo in isolation. Syntactically, some MWEs behave like words while other are phrases; some occur in one rigid pattern (and a fixed order), while others permit various syntactic</context>
</contexts>
<marker>Erman, Warren, 2000</marker>
<rawString>Britt Erman and Beatrice Warren. 2000. The idiom principle and the open choice principle. Text, 20(1):29–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>337--344</pages>
<contexts>
<context position="8024" citStr="Fazly and Stevenson, 2006" startWordPosition="1170" endWordPosition="1173">ess to extract Dutch Verb-Noun idiomatic comreduces the error rate by additional 8.7%. binations (VNICs). Bannard (2007) uses syntacAfter discussing related work in the next section, tic fixedness to identify English VNICs. Another we describe in Section 3 the methodology we pro- work uses both the syntactic and the lexical fixedpose, including a detailed discussion of the features ness of VNICs in order to distinguish them from and their implementation. Section 4 provides a thor- non-idiomatic ones, and eventually to extract them ough evaluation of the results. We conclude with from corpora (Fazly and Stevenson, 2006). suggestions for future research. While these approaches are in line with ours, they require lexical semantic resources (e.g., a database that determines semantic similarity among words) and syntactic resources (parsers) that are unavail1To facilitate readability we use a transliteration of Hebrew using Roman characters; the letters used, in Hebrew lexicographic order, are abgdhwzxTiklmns‘pcqrˇst. 837 able for Hebrew (and many other languages). Our matic word aligner applied to a parallel (Portugueseapproach only requires morphological processing English) corpus. A BN was used to combine the </context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 337–344.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database. Language, Speech and Communication.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. Language, Speech and Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="23996" citStr="Hall et al., 2009" startWordPosition="3750" endWordPosition="3753"> to TRANS. Also, we assume that there is a correlation between the frequency (and PMI) of a candidate and whether or not a literal translation of the expression exists, hence the edge from PMI to TRANS. The edges from PMI and HIST to CONTEXT are justified by the correlation between the frequency and variability of an expression and the variability of the context in which it occurs. Once the structure of the network is established, the conditional probabilities of each dependency have to be determined. We compute the conditional probability tables from our training data (see below) using Weka (Hall et al., 2009), and obtain values for P(X |X1, ... , Xk) for each variable X and all variables Xi, 1 G i G k, such that the graph includes an edge from Xi to X (parents of X). We then perform inference on the network in order to compute P(Xmwe |X1, ... , Xk), where Xmwe corresponds to the node MWE, and X1, ... , Xk are the variables corresponding to all other nodes in the network. Using Bayes Rule, P(Xmwe |X1, ... , Xk) a P(X1, ... , Xk |Xmwe) x P(Xmwe) We define the prior, P(Xmwe), to be 0.41: this is the percentage of MWEs in WordNet 1.7 (Fellbaum, 1998). The conditional probabilities P(X1, ... , Xk |Xmwe</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Hazelbeck</author>
<author>Hiroaki Saito</author>
</authors>
<title>A hybrid approach for functional expression identification in a japanese reading assistant.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications,</booktitle>
<pages>81--84</pages>
<location>Beijing, China,</location>
<contexts>
<context position="13106" citStr="Hazelbeck and Saito, 2010" startWordPosition="1964" endWordPosition="1967"> much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Heckerman, 1995): • In contrast to many other classification methods, BN can learn (and express) causal relationships between features. This facilitates better understanding of the problem domain. • BN can encode not only statistical data, but also prior domain knowledge and human intuitions, in the form of interdependencies among features. We do indeed use this possibility here. 3.2 Linguistically-motivated Features Based on the</context>
</contexts>
<marker>Hazelbeck, Saito, 2010</marker>
<rawString>Gregory Hazelbeck and Hiroaki Saito. 2010. A hybrid approach for functional expression identification in a japanese reading assistant. In Proceedings of the 2010 Workshop on Multiword Expressions: from Theory to Applications, pages 81–84, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Heckerman</author>
</authors>
<title>A tutorial on learning with Bayesian networks.</title>
<date>1995</date>
<tech>Technical Report MSR-TR-95-06,</tech>
<institution>Microsoft Research,</institution>
<contexts>
<context position="13289" citStr="Heckerman, 1995" startWordPosition="1993" endWordPosition="1994">(2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Heckerman, 1995): • In contrast to many other classification methods, BN can learn (and express) causal relationships between features. This facilitates better understanding of the problem domain. • BN can encode not only statistical data, but also prior domain knowledge and human intuitions, in the form of interdependencies among features. We do indeed use this possibility here. 3.2 Linguistically-motivated Features Based on the observations of Al-Haj (2010), we define several linguistically-motivated features that are aimed at capturing some of the unique properties of MWEs. While many idiosyncratic propert</context>
</contexts>
<marker>Heckerman, 1995</marker>
<rawString>David Heckerman. 1995. A tutorial on learning with Bayesian networks. Technical Report MSR-TR-95-06, Microsoft Research, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Itai</author>
<author>Shuly Wintner</author>
</authors>
<title>Language resources for Hebrew. Language Resources and Evaluation,</title>
<date>2008</date>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="14828" citStr="Itai and Wintner, 2008" startWordPosition="2236" endWordPosition="2239">ally-rich languages, and can be exhibited in different ways in different languages. The methodology we advocate, however, is completely universal. A common theme for all these features is idiosyncracy: they are all aimed at locating some linguistic property on which MWEs may differ from nonMWEs. Below we detail these properties, along with the features that we define to reflect them. In all cases, the feature is applied to a candidate MWE, defined here as a bi-gram of tokens (all possible bigrams are potential candidates). To compute the features, we use a 46M-token monolingual Hebrew corpus (Itai and Wintner, 2008), which we pre-process as in Tsvetkov and Wintner (2010b). All statistics are computed from this large corpus. Likewise, we compute these features on a small training corpus, which we generate automatically (see Section 3.4). Orthographic variation Sometimes, MWEs are written with dashes instead of inter-token spaces. We define a binary feature, DASH, whose value is 1 iff the dash character appears in some surface form of the candidate MWE. For example, xd-cddi (one sided) “unilateral”. Hapax legomena MWEs sometimes include constituents that have no usage outside the particular expression, and</context>
</contexts>
<marker>Itai, Wintner, 2008</marker>
<rawString>Alon Itai and Shuly Wintner. 2008. Language resources for Hebrew. Language Resources and Evaluation, 42(1):75–98, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The Architecture of the Language Faculty.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="1404" citStr="Jackendoff, 1997" startWordPosition="187" endWordPosition="189">ageindependent; it relies on few language resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines. 1 Introduction Multi-word Expressions (MWEs) are lexical items that consist of multiple orthographic words (e.g., ad hoc, by and large, New York, kick the bucket). MWEs are numerous and constitute a significant portion of the lexicon of any natural language (Jackendoff, 1997; Erman and Warren, 2000; Sag et al., 2002). They are a heterogeneous class of constructions with diverse sets of characteristics, distinguished by their idiosyncratic behavior. Morphologically, some MWEs allow some of their constituents to freely inflect while restricting (or preventing) the inflection of other constituents. In some cases MWEs may allow constituents to undergo non-standard morphological inflections that 836 they would not undergo in isolation. Syntactically, some MWEs behave like words while other are phrases; some occur in one rigid pattern (and a fixed order), while others </context>
</contexts>
<marker>Jackendoff, 1997</marker>
<rawString>Ray Jackendoff. 1997. The Architecture of the Language Faculty. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil K Jain</author>
</authors>
<title>Fundamentals of digital image processing.</title>
<date>1989</date>
<publisher>Prentice-Hall, Inc., NJ, USA.</publisher>
<contexts>
<context position="16461" citStr="Jain, 1989" startWordPosition="2512" endWordPosition="2513">constituents sometimes occur in one fixed, frozen form. We define a feature, FROZEN, whose value is a binary vector with 1 in the i-th place iff the i-th word of the candidate never inflects in the context of this expression. Example: bit xwlim (house-of sick-people) “hospital”; the noun xwlim must be in the plural in this MWE. Partial morphological inflection In some cases, MWE constituents undergo a (strict but non-empty) subset of the full inflections that they would undergo in isolation. We capture this property with a technique that has been proven useful in the area of image processing (Jain, 1989, Section 7.3). We compute a histogram of the distribution in the corpus of all the possible surface forms of each constituent of an MWE candidate. Such histograms can compactly represent distributional information on morphological behavior, in the same way that histograms of the distribution of gray levels in a picture are used to represent the picture itself. Our assumption is that the inflection histograms of non-MWEs are more uniform than the histograms of MWEs, in which some inflections may be more frequent and others may be altogether missing. Of course, restrictions on the histogram may</context>
</contexts>
<marker>Jain, 1989</marker>
<rawString>Anil K. Jain. 1989. Fundamentals of digital image processing. Prentice-Hall, Inc., NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Finn V Jensen</author>
<author>Thomas D Nielsen</author>
</authors>
<title>Bayesian Networks and Decision Graphs.</title>
<date>2007</date>
<publisher>Springer,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="21360" citStr="Jensen and Nielsen, 2007" startWordPosition="3312" endWordPosition="3315">h) “marry” is literally translated as with marry, marry with, together marry and marry together, none of which occurs in the corpus. Collocation As a baseline, statistical association measure, we use a heuristic variant of pointwise mutual information (PMI), promoting also collocations whose constituents are frequent (Tsvetkov and Wintner, 2010b). We define a binary feature, PMI, with values (low and high) reflecting the threshold that maximizes the accuracy of MWE classification in Tsvetkov and Wintner (2010b). 3.3 Feature Interdependencies Expressed as a Bayesian Network A Bayesian Network (Jensen and Nielsen, 2007) is organized as a graph whose nodes are random variables and whose edges represent interdependencies among those variables. We use a particular type of BN, known as causal networks, in which directed edges lead to a variable from each of its direct causes. This facilitates the expression of domain knowledge (and intuitions, beliefs, etc.) as structural properties of the network. We use the BN as 3We use a 120M-token newspaper corpus. 840 a classification device: training amounts to computing the joint probability distribution of the training set, whereas classification maximizes the posterior</context>
</contexts>
<marker>Jensen, Nielsen, 2007</marker>
<rawString>Finn V. Jensen and Thomas D. Nielsen. 2007. Bayesian Networks and Decision Graphs. Springer, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wai Lam</author>
<author>Kon F Low</author>
<author>Chao Y Ho</author>
</authors>
<title>Using a bayesian network induction approach for text categorization.</title>
<date>1997</date>
<booktitle>Proceedings of IJCAI-97, 15th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>745--750</pages>
<editor>In Martha E. Pollack, editor,</editor>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>Nagoya, JP.</location>
<contexts>
<context position="12542" citStr="Lam et al., 1997" startWordPosition="1874" endWordPosition="1877">typically much larger than bilingual ones. They are also extremely diverse: for example, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks </context>
</contexts>
<marker>Lam, Low, Ho, 1997</marker>
<rawString>Wai Lam, Kon F. Low, and Chao Y. Ho. 1997. Using a bayesian network induction approach for text categorization. In Martha E. Pollack, editor, Proceedings of IJCAI-97, 15th International Joint Conference on Artificial Intelligence, pages 745–750, Nagoya, JP. Morgan Kaufmann Publishers, San Francisco, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="25183" citStr="Och and Ney, 2003" startWordPosition="3973" endWordPosition="3976">babilities P(X1, ... , Xk |Xmwe) are determined by Weka from the conditional probability tables: P(X1, ... , Xk |Xmwe) = Πki=1P(Xi |pai) where k is the number of nodes in the BN (other than Xmwe) and pai is the set of parents of Xi. 3.4 Automatic Generation of Training Data For training we need samples of positive and negative instances of MWEs, each associated with a vector of the values of all features discussed in Section 3.2. We generate this training material automatically. We use a small Hebrew-English bilingual corpus (Tsvetkov and Wintner, 2010a). We word-align the corpus with Giza++ (Och and Ney, 2003), and then apply the (completely unsupervised) DASH HAPAX CNTXT PMI MWE TRANS FRZN HIST POS 841 algorithm of Tsvetkov and Wintner (2010b), which extracts MWE candidates from the aligned corpus and re-ranks them using statistics computed from a large monolingual corpus. The core idea behind this method is that MWEs tend to be translated in nonliteral ways; in a parallel corpus, words that are 1:1 aligned typically indicate literal translations and are hence unlikely constituents of MWEs. The result is a set of 134,001 Hebrew bi-gram types (from the bilingual corpus), classified as either 1:1 al</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>A machine learning approach to multiword expression extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop Towards</booktitle>
<contexts>
<context position="4143" citStr="Pecina (2008)" startWordPosition="589" endWordPosition="590">s express the features used for classification, and whose edges deProceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 836–845, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics fine causal relationships among these features. In 2 Related Work this architecture, learning does not result in a black Early approaches to MWEs identification concenbox, expressed solely as feature weights. Rather, the trated on their collocational behavior (Church and structure of the BN allows us to learn the impact of Hanks, 1990). Pecina (2008) compares 55 differdifferent MWE features on the classification. The ent association measures in ranking German Adjresult is a new unsupervised method for identifying N and PP-Verb collocation candidates. He shows MWEs of various types in text corpora. It com- that combining different collocation measures using bines statistics with a large array of linguistically- standard statistical classification methods improves motivated features, organized in an architecture that over using a single collocation measure. Other rereflects interdependencies among the features. sults (Chang et al., 2002; Vi</context>
</contexts>
<marker>Pecina, 2008</marker>
<rawString>Pavel Pecina. 2008. A machine learning approach to multiword expression extraction. In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Leonid Peshkin</author>
<author>Avi Pfeffer</author>
<author>Virginia Savova</author>
</authors>
<title>Bayesian nets in syntactic categorization of novel words.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLTNAACL 2003–short papers - Volume 2, NAACL ’03,</booktitle>
<pages>79--81</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="12350" citStr="Peshkin et al., 2003" startWordPosition="1844" endWordPosition="1847">trapolate the results much further by extend- on a variety of levels, orthographic, morphological, ing the method to monolingual corpora, which are syntactic and of course semantic (Al-Haj, 2010). typically much larger than bilingual ones. They are also extremely diverse: for example, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the met</context>
</contexts>
<marker>Peshkin, Pfeffer, Savova, 2003</marker>
<rawString>Leonid Peshkin, Avi Pfeffer, and Virginia Savova. 2003. Bayesian nets in syntactic categorization of novel words. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLTNAACL 2003–short papers - Volume 2, NAACL ’03, pages 79–81, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Songlin Piao</author>
<author>Paul Rayson</author>
<author>Dawn Archer</author>
<author>Tony McEnery</author>
</authors>
<title>Comparing and combining a semantic tagger and a statistical tool for mwe extraction. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="5415" citStr="Piao et al., 2005" startWordPosition="773" endWordPosition="776">k is manifold. First, suggest that some collocation measures (especially we show how to generate training material (al- PMI and Log-likelihood) are superior to others for most) automatically, so the method is almost com- identifying MWEs. pletely unsupervised. The methodology we advo- Soon, however, it became clear that mere cocate is thus language-independent, requiring rela- occurrence measurements are not enough to identify tively few language resources, and is therefore op- MWEs, and their linguistic properties should be extimal for medium-density languages (Varga et al., ploited as well (Piao et al., 2005). Hybrid methods 2005). Second, we propose several linguistically- that combine word statistics with linguistic informamotivated features that can be computed from data tion exploit morphological, syntactic and semantic and that are demonstrably productive for improv- idiosyncrasies to extract idiomatic MWEs. ing the accuracy of MWE identification. These fea- Ramisch et al. (2008) evaluate a number of assoture focus on the expression of linguistic idiosyn- ciation measures on the task of identifying English crasies of various types, a phenomenon typical of Verb-Particle Constructions and Germa</context>
</contexts>
<marker>Piao, Rayson, Archer, McEnery, 2005</marker>
<rawString>Scott Songlin Piao, Paul Rayson, Dawn Archer, and Tony McEnery. 2005. Comparing and combining a semantic tagger and a statistical tool for mwe extraction. Computer Speech and Language, 19(4):378–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Alline Villavicencio</author>
</authors>
<title>An evaluation of methods for the extraction of multiword expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop Towards</booktitle>
<contexts>
<context position="5798" citStr="Ramisch et al. (2008)" startWordPosition="826" endWordPosition="829">occurrence measurements are not enough to identify tively few language resources, and is therefore op- MWEs, and their linguistic properties should be extimal for medium-density languages (Varga et al., ploited as well (Piao et al., 2005). Hybrid methods 2005). Second, we propose several linguistically- that combine word statistics with linguistic informamotivated features that can be computed from data tion exploit morphological, syntactic and semantic and that are demonstrably productive for improv- idiosyncrasies to extract idiomatic MWEs. ing the accuracy of MWE identification. These fea- Ramisch et al. (2008) evaluate a number of assoture focus on the expression of linguistic idiosyn- ciation measures on the task of identifying English crasies of various types, a phenomenon typical of Verb-Particle Constructions and German AdjectiveMWEs. We propose novel computational model- Noun pairs. They show that adding linguistic inforing of many of these features; in particular, we ac- mation (mostly POS and POS-sequence patterns) to count for the morphological idiosyncrasy of MWEs the association measure yields a significant improveusing a histogram of the number of inflected forms, ment in performance ove</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Alline Villavicencio. 2008. An evaluation of methods for the extraction of multiword expressions. In Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Helena de Medeiros Caseli</author>
<author>Aline Villavicencio</author>
<author>Andr´e Machado</author>
<author>Maria Finatto</author>
</authors>
<title>A hybrid approach for multiword expression identification.</title>
<date>2010</date>
<booktitle>Computational Processing of the Portuguese Language,</booktitle>
<volume>6001</volume>
<pages>65--74</pages>
<editor>In Thiago Pardo, Ant´onio Branco, Aldebaro Klautau, Renata Vieira, and Vera de Lima, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="12679" citStr="Ramisch et al. (2010)" startWordPosition="1894" endWordPosition="1897">n used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Hecker</context>
</contexts>
<marker>Ramisch, Caseli, Villavicencio, Machado, Finatto, 2010</marker>
<rawString>Carlos Ramisch, Helena de Medeiros Caseli, Aline Villavicencio, Andr´e Machado, and Maria Finatto. 2010. A hybrid approach for multiword expression identification. In Thiago Pardo, Ant´onio Branco, Aldebaro Klautau, Renata Vieira, and Vera de Lima, editors, Computational Processing of the Portuguese Language, volume 6001 of Lecture Notes in Computer Science, pages 65–74. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING</booktitle>
<pages>1--15</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="1447" citStr="Sag et al., 2002" startWordPosition="194" endWordPosition="197">resources and is thus suitable for a large number of languages. Furthermore, unlike much recent work, our approach can identify expressions of various types and syntactic constructions. We demonstrate a significant improvement in identification accuracy, compared with less sophisticated baselines. 1 Introduction Multi-word Expressions (MWEs) are lexical items that consist of multiple orthographic words (e.g., ad hoc, by and large, New York, kick the bucket). MWEs are numerous and constitute a significant portion of the lexicon of any natural language (Jackendoff, 1997; Erman and Warren, 2000; Sag et al., 2002). They are a heterogeneous class of constructions with diverse sets of characteristics, distinguished by their idiosyncratic behavior. Morphologically, some MWEs allow some of their constituents to freely inflect while restricting (or preventing) the inflection of other constituents. In some cases MWEs may allow constituents to undergo non-standard morphological inflections that 836 they would not undergo in isolation. Syntactically, some MWEs behave like words while other are phrases; some occur in one rigid pattern (and a fixed order), while others permit various syntactic transformations. S</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2002), pages 1–15, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Virginia Savova</author>
<author>Leonid Peshkin</author>
</authors>
<title>Dependency parsing with dynamic bayesian network.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th national conference on Artificial intelligence -</booktitle>
<volume>3</volume>
<pages>1112--1117</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="12444" citStr="Savova and Peshkin, 2005" startWordPosition="1859" endWordPosition="1862">logical, ing the method to monolingual corpora, which are syntactic and of course semantic (Al-Haj, 2010). typically much larger than bilingual ones. They are also extremely diverse: for example, on Bayesian Networks have only scarcely been used the semantic dimension alone, MWEs cover an enfor classification in natural language applications. tire spectrum, ranging from frozen, fixed idioms to For example, BN were used for POS tagging of un- free combinations of words (Bannard et al., 2003). known words (Peshkin et al., 2003); dependency Such a complex task calls for a combination of parsing (Savova and Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Frit</context>
</contexts>
<marker>Savova, Peshkin, 2005</marker>
<rawString>Virginia Savova and Leonid Peshkin. 2005. Dependency parsing with dynamic bayesian network. In Proceedings of the 20th national conference on Artificial intelligence - Volume 3, pages 1112–1117. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulia Tsvetkov</author>
<author>Shuly Wintner</author>
</authors>
<title>Automatic acquisition of parallel corpora from websites with dynamic content.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>3389--3392</pages>
<contexts>
<context position="10832" citStr="Tsvetkov and Wintner (2010" startWordPosition="1604" endWordPosition="1607">dology is not limited to a types of MWEs, and define general features that may particular construction: indeed, we demonstrate that accurately apply to some, but not necessarily all of our general methodology, trained on automatically- them. An architecture of Bayesian Networks is opgenerated, general training data, performs almost as timal for this task: it enables us to define weighted well as the noun-noun-specific approach of Al-Haj dependencies among features, such that certain feaand Wintner (2010) on the very same dataset. tures are more significant for identifying some class Recently, Tsvetkov and Wintner (2010b) intro- of MWEs, whereas others are more prominent in duced a general methodology for extracting MWEs identifying other classes. As we show below, this arfrom bilingual corpora, and applied it to Hebrew. chitecture results in significant improvements over a The results were a highly accurate set of Hebrew more naive combination of features. MWEs, of various types, along with their English 3 Methodology translations. A major limitation of this work is that 3.1 Motivation it can only be used to identify MWEs in the bilingual The task we address is identification of MWEs, of corpus, and is thus</context>
<context position="14883" citStr="Tsvetkov and Wintner (2010" startWordPosition="2245" endWordPosition="2248">nt ways in different languages. The methodology we advocate, however, is completely universal. A common theme for all these features is idiosyncracy: they are all aimed at locating some linguistic property on which MWEs may differ from nonMWEs. Below we detail these properties, along with the features that we define to reflect them. In all cases, the feature is applied to a candidate MWE, defined here as a bi-gram of tokens (all possible bigrams are potential candidates). To compute the features, we use a 46M-token monolingual Hebrew corpus (Itai and Wintner, 2008), which we pre-process as in Tsvetkov and Wintner (2010b). All statistics are computed from this large corpus. Likewise, we compute these features on a small training corpus, which we generate automatically (see Section 3.4). Orthographic variation Sometimes, MWEs are written with dashes instead of inter-token spaces. We define a binary feature, DASH, whose value is 1 iff the dash character appears in some surface form of the candidate MWE. For example, xd-cddi (one sided) “unilateral”. Hapax legomena MWEs sometimes include constituents that have no usage outside the particular expression, and are hence not included in lexicons. We define a featur</context>
<context position="21081" citStr="Tsvetkov and Wintner, 2010" startWordPosition="3270" endWordPosition="3274">relates with their frequency in Hebrew), whereas for MWEs we expect no (or few) literal translations. We define a binary feature, TRANS, whose value is 1 iff some literal translation of the candidate occurs more than 5 times in the corpus. For example, the MWE htxtn ym (marry with) “marry” is literally translated as with marry, marry with, together marry and marry together, none of which occurs in the corpus. Collocation As a baseline, statistical association measure, we use a heuristic variant of pointwise mutual information (PMI), promoting also collocations whose constituents are frequent (Tsvetkov and Wintner, 2010b). We define a binary feature, PMI, with values (low and high) reflecting the threshold that maximizes the accuracy of MWE classification in Tsvetkov and Wintner (2010b). 3.3 Feature Interdependencies Expressed as a Bayesian Network A Bayesian Network (Jensen and Nielsen, 2007) is organized as a graph whose nodes are random variables and whose edges represent interdependencies among those variables. We use a particular type of BN, known as causal networks, in which directed edges lead to a variable from each of its direct causes. This facilitates the expression of domain knowledge (and intuit</context>
<context position="25123" citStr="Tsvetkov and Wintner, 2010" startWordPosition="3963" endWordPosition="3966">centage of MWEs in WordNet 1.7 (Fellbaum, 1998). The conditional probabilities P(X1, ... , Xk |Xmwe) are determined by Weka from the conditional probability tables: P(X1, ... , Xk |Xmwe) = Πki=1P(Xi |pai) where k is the number of nodes in the BN (other than Xmwe) and pai is the set of parents of Xi. 3.4 Automatic Generation of Training Data For training we need samples of positive and negative instances of MWEs, each associated with a vector of the values of all features discussed in Section 3.2. We generate this training material automatically. We use a small Hebrew-English bilingual corpus (Tsvetkov and Wintner, 2010a). We word-align the corpus with Giza++ (Och and Ney, 2003), and then apply the (completely unsupervised) DASH HAPAX CNTXT PMI MWE TRANS FRZN HIST POS 841 algorithm of Tsvetkov and Wintner (2010b), which extracts MWE candidates from the aligned corpus and re-ranks them using statistics computed from a large monolingual corpus. The core idea behind this method is that MWEs tend to be translated in nonliteral ways; in a parallel corpus, words that are 1:1 aligned typically indicate literal translations and are hence unlikely constituents of MWEs. The result is a set of 134,001 Hebrew bi-gram ty</context>
<context position="26600" citStr="Tsvetkov and Wintner (2010" startWordPosition="4208" endWordPosition="4211">ive of MWEs. We thus divide the set into four classes: aligned bi-grams with high PMI score, aligned bi-grams with low PMI score, misaligned with high PMI and misaligned with low PMI. Aligned bi-grams, independently of their PMI score, are more likely non-MWEs; high-PMI misaligned bi-grams are very likely MWEs; and the status of low-PMI misaligned bi-grams is unclear, and must be further investigated. This is summarized in Table 1. Misaligned Aligned High PMI MWE non-MWE Low PMI unclear non-MWE Table 1: Classification of bi-grams We set the threshold that separates low PMI from high PMI as in Tsvetkov and Wintner (2010b). The results of this classification is depicted in Table 2. Misaligned Aligned Total High PMI 2,203 493 2,696 Low PMI 61,314 69,991 131,305 Total 63,517 70,484 134,001 Table 2: Statistics of the sample space from which the training set is generated We assume that all bi-grams in the ‘Aligned’ column are non-MWEs. Additionally, we assume that the 2,203 misaligned bi-grams with high PMI scores are likely MWEs. As for the set of over 61,000 misaligned low-PMI bi-grams, certainly many of them are non-MWEs, but some may be MWEs, and we are interested in including them as positive examples of MWE</context>
<context position="30338" citStr="Tsvetkov and Wintner, 2010" startWordPosition="4847" endWordPosition="4850">ficant, reducing almost 7% more errors (8.7% of the errors made by the SVM classifier), or a total of almost 30% error-rate reduction with respect to the baseline. Interestingly, a BN whose structure does not reflect prior knowledge, but is rather learned automatically, performs poorly. It is the combination of linguistically-motivated features with feature interdependencies reflecting domain knowledge that contribute to the best performance. As a further demonstration of the utility of our approach, we evaluate the algorithm on an additional test set that was used for evaluation in the past (Tsvetkov and Wintner, 2010b; Al-Haj and Wintner, 2010). This is a small annotated corpus, NN, of Hebrew noun-noun constructions. The corpus consists of 413 high-frequency bi-grams of the same syntactic construction; of those, 178 are tagged as MWEs (in this case, noun compounds) and 235 as nonMWEs. This corpus consolidates the annotation of three annotators: only instances on which all three agreed were included. Since it includes both positive and negative instances, this corpus facilitates a robust evaluation of precision and recall. We train a Bayesian Network on the training set described in Section 3.4 and use it </context>
<context position="32163" citStr="Tsvetkov and Wintner (2010" startWordPosition="5143" endWordPosition="5146">t our F-score, 0.77, is very close to the best result of 0.79 obtained by Al-Haj and Wintner (2010) as the average of 10-fold cross validation runs, using only high-frequency noun-noun constructions for training. We interpret this result as a further proof of the robustness of our architecture. Accuracy Precision Recall F-score PMI 71.43% 0.71 0.71 0.71 BN 77.00% 0.77 0.77 0.77 AW 80.77% 0.77 0.81 0.79 Table 5: Evaluation results: noun-noun constructions Finally, we have used the trained BN to classify the entire set of bi-grams present in the (Hebrew side of the) parallel corpus described in Tsvetkov and Wintner (2010a). Of the 134,000 candidates, only 4,000 are classified as MWEs. We sort this list of potential MWEs by the probability assigned by the BN to the positive value of the variable Xmwe. The resulting sorted list is dominated by high-PMI bi-grams, especially proper names, all of which are indeed MWEs. The first non-MWE (false positive) occurs in the 50th place on the list; it is crpt niqwla “France Nicolas”, which is obviously a sub-sequence of the larger MWE, neia crpt niqwla srqwzi “French president Nicolas Sarkozy”. Similar sub-sequences are also present, but only five are in the top-100. Such</context>
</contexts>
<marker>Tsvetkov, Wintner, 2010</marker>
<rawString>Yulia Tsvetkov and Shuly Wintner. 2010a. Automatic acquisition of parallel corpora from websites with dynamic content. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), pages 3389–3392. European Language Resources Association (ELRA), May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulia Tsvetkov</author>
<author>Shuly Wintner</author>
</authors>
<title>Extraction of multi-word expressions from small parallel corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="10832" citStr="Tsvetkov and Wintner (2010" startWordPosition="1604" endWordPosition="1607">dology is not limited to a types of MWEs, and define general features that may particular construction: indeed, we demonstrate that accurately apply to some, but not necessarily all of our general methodology, trained on automatically- them. An architecture of Bayesian Networks is opgenerated, general training data, performs almost as timal for this task: it enables us to define weighted well as the noun-noun-specific approach of Al-Haj dependencies among features, such that certain feaand Wintner (2010) on the very same dataset. tures are more significant for identifying some class Recently, Tsvetkov and Wintner (2010b) intro- of MWEs, whereas others are more prominent in duced a general methodology for extracting MWEs identifying other classes. As we show below, this arfrom bilingual corpora, and applied it to Hebrew. chitecture results in significant improvements over a The results were a highly accurate set of Hebrew more naive combination of features. MWEs, of various types, along with their English 3 Methodology translations. A major limitation of this work is that 3.1 Motivation it can only be used to identify MWEs in the bilingual The task we address is identification of MWEs, of corpus, and is thus</context>
<context position="14883" citStr="Tsvetkov and Wintner (2010" startWordPosition="2245" endWordPosition="2248">nt ways in different languages. The methodology we advocate, however, is completely universal. A common theme for all these features is idiosyncracy: they are all aimed at locating some linguistic property on which MWEs may differ from nonMWEs. Below we detail these properties, along with the features that we define to reflect them. In all cases, the feature is applied to a candidate MWE, defined here as a bi-gram of tokens (all possible bigrams are potential candidates). To compute the features, we use a 46M-token monolingual Hebrew corpus (Itai and Wintner, 2008), which we pre-process as in Tsvetkov and Wintner (2010b). All statistics are computed from this large corpus. Likewise, we compute these features on a small training corpus, which we generate automatically (see Section 3.4). Orthographic variation Sometimes, MWEs are written with dashes instead of inter-token spaces. We define a binary feature, DASH, whose value is 1 iff the dash character appears in some surface form of the candidate MWE. For example, xd-cddi (one sided) “unilateral”. Hapax legomena MWEs sometimes include constituents that have no usage outside the particular expression, and are hence not included in lexicons. We define a featur</context>
<context position="21081" citStr="Tsvetkov and Wintner, 2010" startWordPosition="3270" endWordPosition="3274">relates with their frequency in Hebrew), whereas for MWEs we expect no (or few) literal translations. We define a binary feature, TRANS, whose value is 1 iff some literal translation of the candidate occurs more than 5 times in the corpus. For example, the MWE htxtn ym (marry with) “marry” is literally translated as with marry, marry with, together marry and marry together, none of which occurs in the corpus. Collocation As a baseline, statistical association measure, we use a heuristic variant of pointwise mutual information (PMI), promoting also collocations whose constituents are frequent (Tsvetkov and Wintner, 2010b). We define a binary feature, PMI, with values (low and high) reflecting the threshold that maximizes the accuracy of MWE classification in Tsvetkov and Wintner (2010b). 3.3 Feature Interdependencies Expressed as a Bayesian Network A Bayesian Network (Jensen and Nielsen, 2007) is organized as a graph whose nodes are random variables and whose edges represent interdependencies among those variables. We use a particular type of BN, known as causal networks, in which directed edges lead to a variable from each of its direct causes. This facilitates the expression of domain knowledge (and intuit</context>
<context position="25123" citStr="Tsvetkov and Wintner, 2010" startWordPosition="3963" endWordPosition="3966">centage of MWEs in WordNet 1.7 (Fellbaum, 1998). The conditional probabilities P(X1, ... , Xk |Xmwe) are determined by Weka from the conditional probability tables: P(X1, ... , Xk |Xmwe) = Πki=1P(Xi |pai) where k is the number of nodes in the BN (other than Xmwe) and pai is the set of parents of Xi. 3.4 Automatic Generation of Training Data For training we need samples of positive and negative instances of MWEs, each associated with a vector of the values of all features discussed in Section 3.2. We generate this training material automatically. We use a small Hebrew-English bilingual corpus (Tsvetkov and Wintner, 2010a). We word-align the corpus with Giza++ (Och and Ney, 2003), and then apply the (completely unsupervised) DASH HAPAX CNTXT PMI MWE TRANS FRZN HIST POS 841 algorithm of Tsvetkov and Wintner (2010b), which extracts MWE candidates from the aligned corpus and re-ranks them using statistics computed from a large monolingual corpus. The core idea behind this method is that MWEs tend to be translated in nonliteral ways; in a parallel corpus, words that are 1:1 aligned typically indicate literal translations and are hence unlikely constituents of MWEs. The result is a set of 134,001 Hebrew bi-gram ty</context>
<context position="26600" citStr="Tsvetkov and Wintner (2010" startWordPosition="4208" endWordPosition="4211">ive of MWEs. We thus divide the set into four classes: aligned bi-grams with high PMI score, aligned bi-grams with low PMI score, misaligned with high PMI and misaligned with low PMI. Aligned bi-grams, independently of their PMI score, are more likely non-MWEs; high-PMI misaligned bi-grams are very likely MWEs; and the status of low-PMI misaligned bi-grams is unclear, and must be further investigated. This is summarized in Table 1. Misaligned Aligned High PMI MWE non-MWE Low PMI unclear non-MWE Table 1: Classification of bi-grams We set the threshold that separates low PMI from high PMI as in Tsvetkov and Wintner (2010b). The results of this classification is depicted in Table 2. Misaligned Aligned Total High PMI 2,203 493 2,696 Low PMI 61,314 69,991 131,305 Total 63,517 70,484 134,001 Table 2: Statistics of the sample space from which the training set is generated We assume that all bi-grams in the ‘Aligned’ column are non-MWEs. Additionally, we assume that the 2,203 misaligned bi-grams with high PMI scores are likely MWEs. As for the set of over 61,000 misaligned low-PMI bi-grams, certainly many of them are non-MWEs, but some may be MWEs, and we are interested in including them as positive examples of MWE</context>
<context position="30338" citStr="Tsvetkov and Wintner, 2010" startWordPosition="4847" endWordPosition="4850">ficant, reducing almost 7% more errors (8.7% of the errors made by the SVM classifier), or a total of almost 30% error-rate reduction with respect to the baseline. Interestingly, a BN whose structure does not reflect prior knowledge, but is rather learned automatically, performs poorly. It is the combination of linguistically-motivated features with feature interdependencies reflecting domain knowledge that contribute to the best performance. As a further demonstration of the utility of our approach, we evaluate the algorithm on an additional test set that was used for evaluation in the past (Tsvetkov and Wintner, 2010b; Al-Haj and Wintner, 2010). This is a small annotated corpus, NN, of Hebrew noun-noun constructions. The corpus consists of 413 high-frequency bi-grams of the same syntactic construction; of those, 178 are tagged as MWEs (in this case, noun compounds) and 235 as nonMWEs. This corpus consolidates the annotation of three annotators: only instances on which all three agreed were included. Since it includes both positive and negative instances, this corpus facilitates a robust evaluation of precision and recall. We train a Bayesian Network on the training set described in Section 3.4 and use it </context>
<context position="32163" citStr="Tsvetkov and Wintner (2010" startWordPosition="5143" endWordPosition="5146">t our F-score, 0.77, is very close to the best result of 0.79 obtained by Al-Haj and Wintner (2010) as the average of 10-fold cross validation runs, using only high-frequency noun-noun constructions for training. We interpret this result as a further proof of the robustness of our architecture. Accuracy Precision Recall F-score PMI 71.43% 0.71 0.71 0.71 BN 77.00% 0.77 0.77 0.77 AW 80.77% 0.77 0.81 0.79 Table 5: Evaluation results: noun-noun constructions Finally, we have used the trained BN to classify the entire set of bi-grams present in the (Hebrew side of the) parallel corpus described in Tsvetkov and Wintner (2010a). Of the 134,000 candidates, only 4,000 are classified as MWEs. We sort this list of potential MWEs by the probability assigned by the BN to the positive value of the variable Xmwe. The resulting sorted list is dominated by high-PMI bi-grams, especially proper names, all of which are indeed MWEs. The first non-MWE (false positive) occurs in the 50th place on the list; it is crpt niqwla “France Nicolas”, which is obviously a sub-sequence of the larger MWE, neia crpt niqwla srqwzi “French president Nicolas Sarkozy”. Similar sub-sequences are also present, but only five are in the top-100. Such</context>
</contexts>
<marker>Tsvetkov, Wintner, 2010</marker>
<rawString>Yulia Tsvetkov and Shuly Wintner. 2010b. Extraction of multi-word expressions from small parallel corpora. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
<author>Bego˜na Villada Moir´on</author>
</authors>
<title>Semantics-based multiword expression extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Van de Cruys, Moir´on, 2007</marker>
<rawString>Tim Van de Cruys and Bego˜na Villada Moir´on. 2007. Semantics-based multiword expression extraction. In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D´aniel Varga</author>
<author>P´eter Hal´acsy</author>
<author>Andr´as Kornai</author>
<author>Viktor Nagy</author>
<author>L´aszl´o N´emeth</author>
<author>Viktor Tr´on</author>
</authors>
<title>Parallel corpora for medium density languages.</title>
<date>2005</date>
<booktitle>In Proceedings of RANLP’2005,</booktitle>
<pages>590--596</pages>
<marker>Varga, Hal´acsy, Kornai, Nagy, N´emeth, Tr´on, 2005</marker>
<rawString>D´aniel Varga, P´eter Hal´acsy, Andr´as Kornai, Viktor Nagy, L´aszl´o N´emeth, and Viktor Tr´on. 2005. Parallel corpora for medium density languages. In Proceedings of RANLP’2005, pages 590–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
<author>Valia Kordoni</author>
<author>Yi Zhang</author>
<author>Marco Idiart</author>
<author>Carlos Ramisch</author>
</authors>
<title>Validation and evaluation of automatically acquired multiword expressions for grammar engineering.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1034--1043</pages>
<contexts>
<context position="4768" citStr="Villavicencio et al., 2007" startWordPosition="676" endWordPosition="679">8) compares 55 differdifferent MWE features on the classification. The ent association measures in ranking German Adjresult is a new unsupervised method for identifying N and PP-Verb collocation candidates. He shows MWEs of various types in text corpora. It com- that combining different collocation measures using bines statistics with a large array of linguistically- standard statistical classification methods improves motivated features, organized in an architecture that over using a single collocation measure. Other rereflects interdependencies among the features. sults (Chang et al., 2002; Villavicencio et al., 2007) The contribution of this work is manifold. First, suggest that some collocation measures (especially we show how to generate training material (al- PMI and Log-likelihood) are superior to others for most) automatically, so the method is almost com- identifying MWEs. pletely unsupervised. The methodology we advo- Soon, however, it became clear that mere cocate is thus language-independent, requiring rela- occurrence measurements are not enough to identify tively few language resources, and is therefore op- MWEs, and their linguistic properties should be extimal for medium-density languages (Va</context>
</contexts>
<marker>Villavicencio, Kordoni, Zhang, Idiart, Ramisch, 2007</marker>
<rawString>Aline Villavicencio, Valia Kordoni, Yi Zhang, Marco Idiart, and Carlos Ramisch. 2007. Validation and evaluation of automatically acquired multiword expressions for grammar engineering. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1034–1043.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marion Weller</author>
<author>Fabienne Fritzinger</author>
</authors>
<title>A hybrid approach for the identification of multiword expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the SLTC 2010 Workshop on Compounds and Multiword Expressions,</booktitle>
<contexts>
<context position="13056" citStr="Weller and Fritzinger, 2010" startWordPosition="1956" endWordPosition="1959"> Peshkin, 2005); and docu- multiple approaches, and much research indeed sugment classification (Lam et al., 1997; Calado et al., gests “hybrid” approaches to MWE identification 2003; Denoyer and Gallinari, 2004). Very recently, Ramisch et al. (2010) have used BN for Portuguese MWE identification. The features used for classification were of two kinds: (1) various collocation measures; (2) bi-grams aligned together by an auto838 2For simplicity, we focus on bi-grams of tokens (MWEs of length 2) in this work; the methodology, however, is easily extensible to longer n-grams. (Duan et al., 2009; Weller and Fritzinger, 2010; Ramisch et al., 2010; Hazelbeck and Saito, 2010). We believe that Bayesian Networks provide an optimal architecture for expressing various pieces of knowledge aimed at MWE identification, for the following reasons (Heckerman, 1995): • In contrast to many other classification methods, BN can learn (and express) causal relationships between features. This facilitates better understanding of the problem domain. • BN can encode not only statistical data, but also prior domain knowledge and human intuitions, in the form of interdependencies among features. We do indeed use this possibility here. </context>
</contexts>
<marker>Weller, Fritzinger, 2010</marker>
<rawString>Marion Weller and Fabienne Fritzinger. 2010. A hybrid approach for the identification of multiword expressions. In Proceedings of the SLTC 2010 Workshop on Compounds and Multiword Expressions, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>