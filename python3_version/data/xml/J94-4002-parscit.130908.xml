<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997301">
An Algorithm for Pronominal Anaphora
Resolution
</title>
<author confidence="0.999957">
Shalom Lappin* Herbert J. Leassi
</author>
<affiliation confidence="0.977817">
SOAS, University of London Sietec Systemtechnik
</affiliation>
<bodyText confidence="0.997898944444444">
This paper presents an algorithm for identifying the noun phrase antecedents of third person
pronouns and lexical anaphors (reflexives and reciprocals). The algorithm applies to the syntactic
representations generated by McCord&apos;s Slot Grammar parser and relies on salience measures
derived from syntactic structure and a simple dynamic model of attentional state. Like the parser,
the algorithm is implemented in Prolog. The authors have tested it extensively on computer
manual texts and conducted a blind test on manual text containing 360 pronoun occurrences.
The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun
occurrences. The relative contributions of the algorithm&apos;s components to its overall success rate
in this blind test are examined. Experiments were conducted with an enhancement of the al-
gorithm that contributes statistically modelled information concerning semantic and real-world
relations to the algorithm&apos;s decision procedure. Interestingly, this enhancement only marginally
improves the algorithm&apos;s performance (by 2%). The algorithm is compared with other approaches
to anaphora resolution that have been proposed in the literature. In particular, the search proce-
dure of Hobbs&apos; algorithm was implemented in the Slot Grammar framework and applied to the
sentences in the blind test set. The authors&apos; algorithm achieves a higher rate of success (4%)
than Hobbs&apos; algorithm. The relation of the algorithm to the centering approach is discussed, as
well as to models of anaphora resolution that invoke a variety of informational factors in ranking
antecedent candidates.
</bodyText>
<sectionHeader confidence="0.991943" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.993063">
We present an algorithm for identifying both intrasentential and intersentential an-
tecedents of pronouns in text. We refer to this algorithm as RAP (Resolution of Ana-
phora Procedure). RAP applies to the syntactic structures of McCord&apos;s (1990, 1993, in
press) Slot Grammar parser, and like the parser, it is implemented in Prolog. It relies
on measures of salience derived from syntactic structure and a simple dynamic model
of attentional state to select the antecedent noun phrase (NP) of a pronoun from a
list of candidates. It does not employ semantic conditions (beyond those implicit in
grammatical number and gender agreement) or real-world knowledge in evaluating
candidate antecedents; nor does it model intentional or global discourse structure (as
in Grosz and Sidner 1986).
</bodyText>
<affiliation confidence="0.542130571428571">
* School of Oriental and African Studies, University of London, London WC1H OXG, UK. E-mail:
slappin@clus1.ulcc.ac.uk
Most of the first author&apos;s work on this paper was done while he was a Research Staff Member in the
Computer Science Department of the IBM T.J. Watson Research Center.
t Sietec Systemtechnik (Siemens AG), D-13623 Berlin, Germany. E-mail: leass@sietec.de
The second author&apos;s work on this paper was done while he was a visiting scientist at the IBM
Germany Scientific Center.
</affiliation>
<note confidence="0.8776215">
© 1994 Association for Computational Linguistics
Computational Linguistics Volume 20, Number 4
</note>
<bodyText confidence="0.9984517">
In Section 2 we present RAP and discuss its main properties. We provide examples
of its output for different sorts of cases in Section 3. Most of these examples are taken
from the computer manual texts on which we trained the algorithm. We give the results
of a blind test in Section 4, as well as an analysis of the relative contributions of the
algorithm&apos;s components to the overall success rate. In Section 5 we discuss a procedure
developed by Dagan (1992) for using statistically measured lexical preference patterns
to reevaluate RAP&apos;s salience rankings of antecedent candidates. We present the results
of a comparative blind test of RAP and this procedure. Finally, in Section 6 we compare
RAP to several other approaches to anaphora resolution that have been proposed in
the computational literature.
</bodyText>
<sectionHeader confidence="0.956063" genericHeader="keywords">
2. The Anaphora Resolution Algorithm
</sectionHeader>
<bodyText confidence="0.856457">
RAP contains the following main components.
</bodyText>
<listItem confidence="0.99361364">
• An intrasentential syntactic filter for ruling out anaphoric dependence of
a pronoun on an NP on syntactic grounds (This filter is presented in
Lappin and McCord 1990a.)
• A morphological filter for ruling out anaphoric dependence of a pronoun
on an NP due to non-agreement of person, number, or gender features
• A procedure for identifying pleonastic (semantically empty) pronouns
• An anaphor binding algorithm for identifying the possible antecedent
binder of a lexical anaphor (reciprocal or reflexive pronoun) within the
same sentence (This algorithm is presented in Lappin and McCord
1990b.)
• A procedure for assigning values to several salience parameters
(grammatical role, parallelism of grammatical roles, frequency of
mention, proximity, and sentence recency) for an NP. (Earlier versions of
these procedures are presented in Leass and Schwa11 1991.) This
procedure employs a grammatical role hierarchy according to which the
evaluation rules assign higher salience weights to (i) subject over
non-subject NPs, (ii) direct objects over other complements,
(iii) arguments of a verb over adjuncts and objects of prepositional
phrase (PP) adjuncts of the verb, and (iv) head nouns over complements
of head nouns.1
• A procedure for identifying anaphorically linked NPs as an equivalence
class for which a global salience value is computed as the sum of the
salience values of its elements.
• A decision procedure for selecting the preferred element of a list of
antecedent candidates for a pronoun.
</listItem>
<bodyText confidence="0.568134142857143">
1 This hierarchy is more or less identical to the NP accessibility hierarchy proposed by Keenan and
Comrie (1977). Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraints
on syntactic relations, including reflexive binding. Lappin (1985) employs it as a salience hierarchy to
state a non-coreference constraint for pronouns. Guenthner and Lehmann (1983) use a similar salience
ranking of grammatical roles to formulate rules of anaphora resolution. Centering approaches to
anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida,
and Cote 1990).
</bodyText>
<page confidence="0.992035">
536
</page>
<note confidence="0.937256">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<subsectionHeader confidence="0.665703">
2.1 Some Preliminary Details
</subsectionHeader>
<bodyText confidence="0.999220125">
RAP has been implemented for both ESG and GSG (English and German Slot Gram-
mars); we will limit ourselves here to a discussion of the English version. The differ-
ences between the two versions are at present minimal, primarily owing to the fact
that we have devoted most of our attention to analysis of English. As with Slot Gram-
mar systems in general (McCord 1989b, 1993, in press), an architecture was adopted
that &amp;quot;factors out&amp;quot; language-specific elements of the algorithm.
We have integrated RAP into McCord&apos;s (1989a, 1989b) Logic-Based Machine Trans-
lation System (LMT). (We are grateful to Michael McCord and Ullrike Schwa11 for their
help in implementing this integration.) When the algorithm identifies the antecedent
of a pronoun in the source language, the agreement features of the head of the NP cor-
responding to the antecedent in the target language are used to generate the pronoun
in the target language. Thus, for example, neuter third person pronouns in English are
mapped into pronouns with the correct gender feature in German, in which inanimate
nouns are marked for gender.
RAP operates primarily on a clausal representation of the Slot Grammar analysis of
the current sentence in a text (McCord et al. 1992). The clausal representation consists
of a set of Prolog unit clauses that provide information on the head—argument and
head—adjunct relations of the phrase structure that the Slot Grammar assigns to a
sentence (phrase). Clausal representations of the previous four sentences in the text are
retained in the Prolog workspace. The discourse representation used by our algorithm
consists of these clausal representations, together with additional unit clauses declaring
discourse referents evoked by NPs in the text and specifying anaphoric links among
discourse referents.2 All information pertaining to a discourse referent or its evoking
NP is accessed via an identifier (ID), a Prolog term containing two integers. The first
integer identifies the sentence in which the evoking NP occurs, with the sentences in
a text being numbered consecutively. The second integer indicates the position of the
NP&apos;s head word in the sentence.
2.1.1 The Syntactic Filter on Pronoun—NP Coreference. The filter consists of six con-
ditions for NP—pronoun non-coreference within a sentence. To state these conditions,
we use the following terminology. The agreement features of an NP are its number,
person, and gender features. We will say that a phrase P is in the argument domain
of a phrase N iff P and N are both arguments of the same head. We will say that P
is in the adjunct domain of N iff N is an argument of a head H, P is the object of a
preposition PREP, and PREP is an adjunct of H. P is in the NP domain of N iff N is
the determiner of a noun Q and (i) P is an argument of Q, or (ii) P is the object of a
preposition PREP and PREP is an adjunct of Q. A phrase P is contained in a phrase Q
iff (i) P is either an argument or an adjunct of Q, i.e., P is immediately contained in Q,
or (ii) P is immediately contained in some phrase R, and R is contained in Q.
A pronoun P is non-coreferential with a (non-reflexive or non-reciprocal) noun
phrase N if any of the following conditions hold:
</bodyText>
<listItem confidence="0.996621666666667">
1. P and N have incompatible agreement features.
2. P is in the argument domain of N.
3. P is in the adjunct domain of N.
</listItem>
<bodyText confidence="0.903505">
2 The number of sentences whose syntactic representations are retained is a parametrically specified
value of the algorithm. Our decision to set this value at four is motivated by our experience with the
technical texts we have been working with.
</bodyText>
<page confidence="0.986741">
537
</page>
<note confidence="0.475821">
Computational Linguistics Volume 20, Number 4
</note>
<listItem confidence="0.97556425">
4. P is an argument of a head H, N is not a pronoun, and N is contained
in H.
5. P is in the NP domain of N.
6. P is a determiner of a noun Q, and N is contained in Q.
</listItem>
<figureCaption confidence="0.925289">
Examples of coindexings that would be rejected by these conditions are given in
Figure I.
</figureCaption>
<tableCaption confidence="0.9693035">
Condition 1:
The woman i said that hei is funny.
Condition 2:
Shei likes heri.
Johni seems to want to see him.
Condition 3:
She; sat near heri.
Condition 4:
He believes that the mani is amusing.
This is the man, he, said Johni wrote about.
Condition 5:
Johni&apos;s portrait of him; is interesting.
Condition 6:
Hisi portrait of John; is interesting.
</tableCaption>
<figureCaption confidence="0.659441333333333">
His, description of the portrait by John; is interesting.
Figure 1
Conditions on NP—pronoun non-coreference (examples).
</figureCaption>
<bodyText confidence="0.9676419375">
2.1.2 Test for Pleonastic Pronouns. The tests are partly syntactic and partly lexical. A
class of modal adjectives is specified. It includes the following items (and their corre-
sponding morphological negations, as well as comparative and superlative forms).
necessary possible certain likely important
good useful advisable convenient sufficient
economical easy desirable difficult legal
A class of cognitive verbs with the following elements is also specified.
recommend think believe know anticipate assume expect
It appearing in the constructions of Figure 2 is considered pleonastic (Cogv-ed = passive
participle of cognitive verb); syntactic variants of these constructions (It is not/may be
M od a lad j... , Wouldn&apos;t it be M od a lad j... , etc.) are recognized as well.
To our knowledge, no other computational treatment of pronominal anaphora
resolution has addressed the problem of pleonastic pronouns. It could be argued that
recognizing pleonastic uses of pronouns is a task for levels of syntactic/semantic anal-
ysis that precede anaphora resolution. With the help of semantic classes defined in the
lexicon, it should be possible to include exhaustive tests for these constructions in
</bodyText>
<page confidence="0.992609">
538
</page>
<note confidence="0.617898">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<bodyText confidence="0.993768428571429">
It is Modaladj that S
It is Modaladj (for NP) to VP
It is Cogv-ed that S
It seems/appears/means/follows (that) S
NP makes/finds it Modaladj (for NP) to VP
It is time to VP
It is thanks to NP that S
</bodyText>
<figureCaption confidence="0.855405">
Figure 2
</figureCaption>
<subsectionHeader confidence="0.636297">
Pleonastic uses of it.
</subsectionHeader>
<bodyText confidence="0.72326">
analysis grammars.3
</bodyText>
<subsubsectionHeader confidence="0.508208">
2.1.3 The Anaphor Binding Algorithm. The notion higher argument slot used in the
</subsubsectionHeader>
<bodyText confidence="0.9923155">
following formulation of the binding algorithm is defined by the following hierarchy
of argument slots:
</bodyText>
<equation confidence="0.803182">
subj &gt; agent &gt; obj &gt; (iobjlpobj)
</equation>
<bodyText confidence="0.995080428571429">
Here subj is the surface subject slot, agent is the deep subject slot of a verb heading a
passive VP, obj is the direct object slot, lob] is the indirect object slot, and pobj is the
object of a PP complement of a verb, as in put NP on NP. We assume the definitions
of argument domain, adjunct domain, and NP domain given above.
A noun phrase N is a possible antecedent binder for a lexical anaphor (i.e., re-
ciprocal or reflexive pronoun) A iff N and A do not have incompatible agreement
features, and one of the following five conditions holds.
</bodyText>
<listItem confidence="0.998880727272727">
1. A is in the argument domain of N, and N fills a higher argument slot
than A.
2. A is in the adjunct domain of N.
3. A is in the NP domain of N.
4. N is an argument of a verb V. there is an NP Q in the argument domain
or the adjunct domain of N such that Q has no noun determiner, and
(i) A is an argument of Q, or (ii) A is an argument of a preposition PREP
and PREP is an adjunct of Q.
5. A is a determiner of a noun Q, and (i) Q is in the argument domain of N
and N fills a higher argument slot than Q, or (ii) Q is in the adjunct
domain of N.
</listItem>
<subsectionHeader confidence="0.404967">
Examples of bindings licensed by these conditions are given in Figure 3.
</subsectionHeader>
<bodyText confidence="0.743256">
2.1.4 Salience Weighting. Salience weighting is accomplished using salience factors. A
given salience factor is associated with one or more discourse referents. These dis-
course referents are said to be in the factor&apos;s scope. A weight is associated with each
</bodyText>
<footnote confidence="0.996968">
3 ESG does, in fact, recognize some pleonastic uses of it, viz, in constructions involving extraposed
sentential subjects, as in It surprised me that he was there. A special slot, su bj(it), is used. We expect that
enhancements to ESG and to the Slot Grammar English lexicon will ultimately render our tests for
pleonastic pronouns redundant.
</footnote>
<page confidence="0.992432">
539
</page>
<note confidence="0.497854">
Computational Linguistics Volume 20, Number 4
</note>
<tableCaption confidence="0.9757185">
Condition 1:
They, wanted to see themselves,.
Mary knows the people, who John introduced to each other,.
Condition 2:
He; worked by himself,.
Which friends; plan to travel with each other;?
Condition 3:
John likes Bi114&apos;s portrait of himself,.
Condition 4:
They, told stories about themselves,.
Condition 5:
[John and Mary], like each otheri&apos;s portraits.
</tableCaption>
<figureCaption confidence="0.659273">
Figure 3
</figureCaption>
<subsectionHeader confidence="0.531827">
Conditions for antecedent NP—lexical anaphor binding.
</subsectionHeader>
<bodyText confidence="0.999224916666667">
factor, reflecting its relative contribution to the total salience of individual discourse
referents. Initial weights are degraded in the course of processing.
The use of salience factors in our algorithm is based on Alshawi&apos;s (1987) context
mechanism. Other than sentence recency, the factors used in RAP differ from Alshawi&apos;s
and are more specific to the task of pronominal anaphora resolution. Alshawi&apos;s frame-
work is designed to deal with a broad class of language interpretation problems,
including reference resolution, word sense disambiguation, and the interpretation of
implicit relations. While Alshawi does propose emphasis factors for memory entities
that are &amp;quot;referents for noun phrases playing syntactic roles regarded as foregrounding
the referent&amp;quot; (Alshawi 1987, p. 17), only topics of sentences in the passive voice and
the agents of certain be clauses receive such emphasis in his system. Our emphasis
salience factors realize a much more detailed measure of structural salience.
Degradation of salience factors occurs as the first step in processing a new sentence
in the text. All salience factors that have been assigned prior to the appearance of this
sentence have their weights degraded by a factor of two. When the weight of a given
salience factor reaches zero, the factor is removed.
A sentence recency salience factor is created for the current sentence. Its scope is all
discourse referents introduced by the current sentence.
The discourse referents evoked by the current sentence are tested to see whether
other salience factors should apply. If at least one discourse referent&apos; satisfies the
conditions for a given factor type, a new salience factor of that type is created, with
the appropriate discourse referents in its scope.
In addition to sentence recency, the algorithm employs the following salience fac-
tors:
</bodyText>
<subsectionHeader confidence="0.99901">
Subject emphasis
</subsectionHeader>
<bodyText confidence="0.7507245">
Existential emphasis: predicate nominal in an existential construction, as in
There are only a few restrictions on LQL query construction for WordSmith.
</bodyText>
<footnote confidence="0.995289">
4 In this paper we do not distinguish between properties of a discourse referent and properties of the NP
that evokes it.
</footnote>
<page confidence="0.992831">
540
</page>
<note confidence="0.892624">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<tableCaption confidence="0.996354">
Table 1
</tableCaption>
<table confidence="0.8782399">
Salience factor types with initial weights
Factor type Initial weight
Sentence recency 100
Subject emphasis 80
Existential emphasis 70
Accusative emphasis 50
Indirect object and oblique complement emphasis 40
Head noun emphasis 80
Non-adverbial emphasis 50
Accusative emphasis: direct object (i.e., verbal complement in accusative case)
</table>
<subsectionHeader confidence="0.920827">
Indirect object and oblique complement emphasis
</subsectionHeader>
<bodyText confidence="0.937552764705882">
Head noun emphasis: any NP not contained in another NP, using the Slot Grammar
notion of &amp;quot;containment within a phrase&amp;quot; (see Section 2.1.1). This factor increases the
salience value of an NP that is not embedded within another NP (as its complement
or adjunct). Examples of NPs not receiving head noun emphasis are
the configuration information copied by Backup configuration
the assembly in bay C
the connector labeled P3 on the flat cable
Non-adverbial emphasis: any NP not contained in an adverbial PP demarcated by a
separator. Like head noun emphasis, this factor penalizes NPs in certain embedded
constructions. Examples of NPs not receiving non-adverbial emphasis are
Throughout the first section of this guide, these symbols are also
used ...
In the Panel definition panel, select the &amp;quot;Specify&amp;quot; option from the
action bar.
The initial weights for each of the above factor types are given in Table 1. Note
that the relative weighting of some of these factors realizes a hierarchy of grammatical
roles.&apos;
</bodyText>
<listItem confidence="0.572854666666667">
2.1.5 Equivalence Classes. We treat the antecedent—anaphor relation in much the same
way as the &amp;quot;equality&amp;quot; condition of Discourse Representation Theory (DRT) (Kamp
1981), as in
</listItem>
<equation confidence="0.878397">
U = y.
</equation>
<bodyText confidence="0.9861585">
This indicates that the discourse referent u, evoked by an anaphoric NP, is anaphori-
cally linked to a previously introduced discourse referent y. To avoid confusion with
</bodyText>
<footnote confidence="0.997476666666667">
5 The specific values of the weights are arbitrary. The significance of the weighting procedure is in the
comparative relations among the factors as defined by the weights. We have determined the efficacy of
this relational structure of salience factors (and refined it) experimentally (see Section 4.2).
</footnote>
<page confidence="0.982544">
541
</page>
<figure confidence="0.4602596">
Computational Linguistics Volume 20, Number 4
mathematical equality (which, unlike the relation discussed here, is symmetric), we
represent the relation between an anaphor u and its antecedent y by
y antecedes u.
Two discourse referents u and y are said to be co-referential,&apos; written as
</figure>
<construct confidence="0.6075785">
coref (u, y)
if any of the following holds:
</construct>
<listItem confidence="0.99949325">
• y antecedes u
• u antecedes y
• z antecedes u for some discourse referent z and coref(z,y)
• z antecedes y for some z and coref(z,u)
</listItem>
<bodyText confidence="0.802702666666667">
Also, coref(u,u) is true for any discourse referent u. The coref relation defines equiva-
lence classes of discourse referents, with all discourse referents in an &amp;quot;anaphoric chain&amp;quot;
forming one class:
</bodyText>
<equation confidence="0.981803">
equiv(u) =- {y I coref(u, y)}
</equation>
<bodyText confidence="0.86906">
Each equivalence class of discourse referents (some of which consist of only one
member) has a salience weight associated with it. This weight is the sum of the current
weight of all salience factors in whose scope at least one member of the equivalence
class lies.
Equivalence classes, along with the sentence recency factor and the salience degra-
dation mechanism, constitute a dynamic system for computing the relative attentional
prominence of denotational NPs in text.
</bodyText>
<subsectionHeader confidence="0.999715">
2.2 The Resolution Procedure
</subsectionHeader>
<bodyText confidence="0.992686">
RAP&apos;s procedure for identifying antecedents of pronouns is as follows.
</bodyText>
<listItem confidence="0.99470525">
1. Create a list of IDs for all NPs in the current sentence and classify them
as to their type (definite NP, pleonastic pronoun, other pronoun,
indefinite NP).
2. Examine all NPs occurring in the current sentence.
a. Distinguish among NPs that evoke new discourse referents,
those that evoke discourse referents which are presumably
coreferential with already listed discourse referents, and NPs
that are used non-referentially.
b. Apply salience factors to the discourse referents evoked in the
previous step as appropriate.
c. Apply the syntactic filter and reflexive binding algorithm (first
phase).
</listItem>
<footnote confidence="0.770508">
6 We have not attempted to distinguish among various types of anaphoric relations between discourse
referents. Our use of &amp;quot;coreference&amp;quot; is in the spirit of Sidner&apos;s (1981) &amp;quot;co-specification&amp;quot; and Webber&apos;s
(1988) &amp;quot;reference,,,.&amp;quot;
</footnote>
<page confidence="0.982846">
542
</page>
<bodyText confidence="0.358515">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</bodyText>
<listItem confidence="0.625009454545455">
(i) If the current sentence contains any personal or
possessive pronouns, a list of pairs of IDs from the
current sentence is generated. This list contains the
pronoun—NP pairs in the sentence for which coreference
can be ruled out on syntactic grounds (using the
conditions stated above).
(ii) If the current sentence contains any lexical anaphors
(i.e., reciprocal or reflexive pronouns), a list of ID pairs
is generated. Each lexical anaphor is paired with all of
its possible antecedent binders.
d. If any non-pleonastic pronouns are present in the current
</listItem>
<bodyText confidence="0.993882571428571">
sentence, attempt to identify their antecedents. Resolution is
attempted in the order of pronoun occurrence in the sentence.
In the case of lexical anaphors (reflexive or reciprocal pronouns), the possible an-
tecedent binders were identified by the anaphor binding algorithm. If more than one
candidate was found, the one with the highest salience weight was chosen (see second
example of Section 3.1).
In the case of third person pronouns, resolution proceeds as follows:
</bodyText>
<listItem confidence="0.844244">
1. A list of possible antecedent candidates is created. It contains the most
</listItem>
<bodyText confidence="0.985932818181818">
recent discourse referent of each equivalence class. The salience weight
of each candidate is calculated and included in the list. The salience
weight of a candidate can be modified in several ways:
a. If a candidate follows the pronoun, its salience weight is
reduced substantially (i.e., cataphora is strongly penalized).
b. If a candidate fills the same slot as the pronoun, its weight is
increased slightly (i.e., parallelism of grammatical roles is
rewarded).
It is important to note that, unlike the salience factors described in
Section 2.1.4, these modifications of the salience weights of candidates
are local to the the resolution of a particular pronoun.
</bodyText>
<listItem confidence="0.767756666666667">
2. A salience threshold is applied; only those candidates whose salience
weight is above the threshold are considered further.
3. The possible agreement features (number and gender) for the pronoun
</listItem>
<bodyText confidence="0.9987365">
are determined. The possible sg (singular) and pl (plural) genders are
determined; either of these can be a disjunction or nil. Pronominal forms
in many languages are ambiguous as to number and gender; such
ambiguities are taken into account by RAP&apos;s morphological filter and by
the algorithm as a whole. The search splits to consider singular and
plural antecedents separately (steps 4-6) to allow a general treatment of
number ambiguity (as in the Spanish possessive pronoun su or the
German pronoun sie occurring as an accusative object).
</bodyText>
<listItem confidence="0.8770845">
4. The best sg candidate (if any) is selected:
a. If no sg genders were determined for the pronoun, proceed to
Step 5.
b. Otherwise, apply the morphological filter.
</listItem>
<page confidence="0.992881">
543
</page>
<subsectionHeader confidence="0.429475">
Computational Linguistics Volume 20, Number 4
</subsectionHeader>
<bodyText confidence="0.9293646">
c. The syntactic filter is applied, using the list of disjoint
pronoun-NP pairs generated earlier. The filter excludes any
candidate paired in the list with the pronoun being resolved, as
well as any candidate that is anaphorically linked to an NP
paired with the pronoun.
</bodyText>
<listItem confidence="0.773826857142857">
d. If more than one candidate remains, choose the candidate with
the highest salience weight. If several candidates have (exactly)
the highest weight, choose the candidate closest to the anaphor.
Proximity is measured on the surface string and is not
directional.
e. The remaining candidate is considered the best sg candidate.
5. The best pl candidate (if any) is selected. The procedure parallels that
outlined above for the best sg candidate:
a. If no pl gender is specified for the pronoun, proceed to Step 6.
b. Otherwise, apply the morphological filter.
c. Apply the syntactic filter.
d. If more than one candidate remains, choose the candidate with
the highest salience weight; if several candidates have the
highest weight, choose the candidate closest to the anaphor.
e. The remaining candidate is considered the best pl candidate.
6. Given the best sg and pl candidates, find the best overall candidate:
a. If a sg candidate was found, but no pl candidate, or vice versa,
choose that candidate as the antecedent.
b. If both a sg and a pl candidate were found, choose the candidate
with the greater salience weight (this will never arise in analysis
of English text, as all English pronominal forms are
</listItem>
<bodyText confidence="0.98885575">
unambiguous as to number).
7. The selected candidate is declared to be the antecedent of the pronoun.
The following properties of RAP are worth noting. First, it applies a powerful
syntactic and morphological filter to lists of pronoun—NP pairs to reduce the set of
possible NP antecedents for each pronoun. Second, NP salience measures are specified
largely in terms of syntactic properties and relations (as well as frequency of occur-
rence). These include a hierarchy of grammatical roles, level of phrasal embedding,
and parallelism of grammatical role. Semantic constraints and real-world knowledge
play no role in filtering or salience ranking. Third, proximity of an NP relative to a pro-
noun is used to select an antecedent in cases in which several candidates have equal
salience weighting. Fourth, intrasentential antecedents are preferred to intersentential
candidates. This preference is achieved by three mechanisms:
</bodyText>
<listItem confidence="0.997678">
• An additional salience value is assigned to NPs in the current sentence.
• The salience values of antecedent candidates in preceding sentences are
progressively degraded relative to the salience values of NPs in the
current sentence.
• Proximity is used to resolve ties among antecedent candidates with
equal salience values.
</listItem>
<bodyText confidence="0.865613">
The fifth property which we note is that anaphora is strongly preferred to cataphora.
</bodyText>
<page confidence="0.985674">
544
</page>
<note confidence="0.758123">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<subsectionHeader confidence="0.649644">
3. Examples of RAP&apos;s Output
</subsectionHeader>
<bodyText confidence="0.999857222222222">
RAP generates the list of non-coreferential pronoun—NP pairs for the current sentence,
the list of pleonastic pronouns, if any, in the current sentence, the list of possible
antecedent NP—lexical anaphor pairs, if any, for the current sentence, and the list of
pronoun—antecedent NP pairs that it has identified, for which antecedents may appear
in preceding sentences in the text. Each NP appearing in any of the first three lists is
represented by its lexical head followed by the integer that corresponds to its position
in the sequence of tokens in the input string of the current sentence. The NPs in the
pairs of the pronoun—antecedent list are represented by their lexical heads followed
by their IDs, displayed as a list of two integers.&apos;
</bodyText>
<subsectionHeader confidence="0.999879">
3.1 Lexical Anaphors
</subsectionHeader>
<bodyText confidence="0.874338642857143">
After installation of the option, the backup copy of the Reference
Diskette was started for the computer to automatically configure
itself.
Antecedent NP--lexical anaphor pairs.
computer.18 - itself.22
Anaphor--Antecedent links.
itself.(1.22) to computer.(1.18)
John talked to Bill about himself.
Antecedent NP--lexical anaphor pairs.
John.1 - himself.6, Bill.4 - himself.6
Anaphor--Antecedent links.
himself.(1.6) to John.(1.1)
In the second example, Joh n.(1.1) was preferred to Bi I I.(1.4) owing to its higher salience
weight.
</bodyText>
<subsectionHeader confidence="0.999909">
3.2 Pleonastic and Non-Lexical Anaphoric Pronouns in the Same Sentence
</subsectionHeader>
<bodyText confidence="0.86750975">
Most of the copyright notices are embedded in the EXEC, but this
keyword makes it possible for a user-supplied function to have its
own copyright notice.
Non-coreferential pronoun--NP pairs.
</bodyText>
<equation confidence="0.934498">
it.16 - most.1, it.16 - notice.5, it.16 - keyword.14,
it.16 - function.23, it.16 - user.20, it.16 - notice.29,
it.16 - copyright.28, its.26 - most.1, its.26 - notice.5,
its.26 - notice.29, its.26 - copyright.28
</equation>
<footnote confidence="0.379424">
7 Recall that the first integer identifies the sentence in which the NP appears, and the second indicates
the position of its head word in the sentence.
</footnote>
<page confidence="0.978123">
545
</page>
<figure confidence="0.8680616">
Computational Linguistics Volume 20, Number 4
Pleonastic Pronouns.
it.16
Anaphor--Antecedent links.
its.(1.26) to function.(1.23)
</figure>
<bodyText confidence="0.91461425">
function. (1.23) and keyword .(1.14) share the highest salience weight of all candidates
that pass the morphological and syntactic filters; they are both subjects and therefore
higher in salience than the third candidate, EXEC.(1.10). function. (1.23) is then selected
as the antecedent owing to its proximity to the anaphor.
</bodyText>
<subsectionHeader confidence="0.98862">
3.3 Multiple Cases of Intrasentential Anaphora
</subsectionHeader>
<bodyText confidence="0.9903405">
Because of this, MicroEMACS cannot process an incoming ESC until it
knows what character follows it.
</bodyText>
<equation confidence="0.847380428571428">
Non-coreferential pronoun--NP pairs.
it.12 - character.15, it.17 - character.15
Anaphor--Antecedent links.
it.(1.12) to MicroEMACS.(1.4)
it.(1.17) to ESC.(1.10)
M i c ro E MACS. (1.4) is preferred over ESC.(1.10) as an antecedent of it.(1.12)—
MicroEMACS.(1.4) receives subject emphasis versus the lower object emphasis of
</equation>
<bodyText confidence="0.905161">
ESC.(1.10). In addition, M icroEMACS.(1.4) is rewarded because it fills the same gram-
matical role as the anaphor being resolved.
In the case of it.(1.17), the parallelism reward works in favor of ESC.(1.10), causing
it to be chosen, despite the general preference for subjects over objects.
</bodyText>
<sectionHeader confidence="0.329437" genericHeader="introduction">
3.4 Intersentential and Intrasentential Anaphora in the Same Sentence
</sectionHeader>
<bodyText confidence="0.547655875">
At this point, emacs is waiting for a command.
It is prepared to see if the variable keys are TRUE, and executes
some lines if they are.
Non-coreferential pronoun--NP pairs.
it.1 - key.9, it.1 - line.16, it.1 - they.18, they.18 - it.1
Anaphor--Antecedent links.
it.(2.1) to emacs.(1.5)
they.(2.18) to key.(2.9)
</bodyText>
<subsectionHeader confidence="0.814892">
3.5 Displaying Discourse Referents
</subsectionHeader>
<bodyText confidence="0.998255">
The discourse referents currently defined can be displayed with their salience weights.
The display for the two-sentence text of Section 3.4 is as follows: the members of
an equivalence class are displayed on one line. Since salience factors from previous
sentences are degraded by a factor of two when each new sentence is processed,
</bodyText>
<page confidence="0.989537">
546
</page>
<note confidence="0.812447">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<bodyText confidence="0.86117">
discourse referents from earlier sentences that are not members of anaphoric chains
extending into the current sentence rapidly become &amp;quot;uncompetitive.&amp;quot;
</bodyText>
<table confidence="0.978375607142857">
Salience weight Discourse referent(s)
465 emacs.(1.5) s(it,1).(2.1)
310 s(key,1).(2.9) s(they,1).(2.18)
280 s(line,1).(2.16)
135 s(command,2).(1.10)
90 s(point,4).(1.3)
3.6 Detailed Displays of Salience Weights
You have not waited for the file to close.
You may have asked to print on the virtual printer, but it cannot
print until the output file is closed.
Non-coreferential pronoun--NP pairs:
you.1 - printer.10, you.1 - it.13, you.1 - output.19,
you.1 - file.20, it.13 - you.1, it.13 - output.19,
it.13 - file.20
Salience values:
printer.(2.10) - 270
file.(1.7) - 190
Salience factor values: file. (1.7)
printer.(2.10) sentence_rec - 50
sentence_rec - 100 non_adverbial_emph - 25
non_adverbial_emph - 50 subj_emph - 40
pobj_emph - 40 head_emph - 40
head_emph - 80
Local salience factor values:
file. (1.7)
parallel_roles_reward - 35
Anaphor--Antecedent links:
it.(2.13) to printer.(2.10)
</table>
<bodyText confidence="0.956274428571429">
This example illustrates the strong preference for intrasentential antecedents. print-
er.(2.10) is selected, despite the fact that it is much lower on the hierarchy of grammat-
ical roles than the other candidate, file.(1.7), which also benefits from the parallelism
reward. Degradation of salience weight for the candidate from the previous sentence
is substantial enough to offset these factors.
The PARTNUM tag prints a part number on the document.
&amp;name.&apos;s initial setting places it on the back cover.
</bodyText>
<page confidence="0.961585">
547
</page>
<table confidence="0.980960038461538">
Computational Linguistics Volume 20, Number 4
Non-coreferential pronoun--NP pairs:
it.6 - setting.4, it.6 - cover.10
Salience values:
number.(1.7) - 175 tag. (1.3). - 25
tag. (1.3) - 155 sentence_rec - 50 - 25
scsym(name).(2.1) - 150 non_adverbial_emph
document.(1.10) - 135 subj_emph - 40
PARTNUM.(1.2) - 75 head_emph - 40
Salience factor values: document. (1.10)
number.(1.7) sentence_rec - 50
sentence_rec - 50 non_adverbial_emph
non_adverbial_emph - 25 pobj_emph - 20
acc_emph - 25 head_emph - 40
head_emph - 40
scsym(name).(2.1)
sentence_rec - 100
non_adverbial_emph - 50
PARTNUM.(1.2)
sentence_rec - 50
non_adverbial_emph - 25
Local salience factor values:
number. (1,7)
parallel_roles_reward - 35
Anaphor--Antecedent links:
s(it,1).(2.6) to s(number,1).(1.7)
</table>
<bodyText confidence="0.6116585">
Four candidates receive a similar salience weighting in this example. Two po-
tential intrasentential candidates that would have received a high salience ranking,
sett ing.(2.4) and cover.(2.10), are ruled out by the syntactic filter. The remaining in-
trasentential candidate, scsym(name).(2.1)8 ranks relatively low, as it is a possessive
determiner—it scores lower than two candidates from the previous sentence. The par-
allelism reward causes num ber.(1.7) to be preferred.
</bodyText>
<subsectionHeader confidence="0.789529">
4. Testing of RAP on Manual Texts
</subsectionHeader>
<bodyText confidence="0.9406975">
We tuned RAP on a corpus of five computer manuals containing a total of approxi-
mately 82,000 words. From this corpus we extracted sentences with 560 occurrences
</bodyText>
<footnote confidence="0.884099333333333">
8 &amp;name. is a document formatting symbol: it is replaced by a predefined character string when the text
is formatted. ESG treats such symbols as being unspecified for number and gender; number may be
assigned during parsing, owing to agreement constraints.
</footnote>
<page confidence="0.973897">
548
</page>
<note confidence="0.504145">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<tableCaption confidence="0.639342">
Table 2
</tableCaption>
<table confidence="0.9931438">
Results of training phase
Total Intersentential cases Intrasentential cases
Number of pronoun occurrences 560 89 471
Number of cases that the algorithm 475 (85%) 72 (81%) 403 (86%)
resolves correctly
</table>
<bodyText confidence="0.99902978125">
of third person pronouns (including reflexives and reciprocals) and their antece-
dents.&apos;
In the training phase, we refined our tests for pleonastic pronouns and exper-
imented extensively with salience weighting. Our goal was, of course, to optimize
RAP&apos;s success rate with the training corpus. We proceeded heuristically, analyzing
cases of failure and attempting to eliminate them in as general a manner as possible.
The parallelism reward was introduced at this time, as it seemed to make a sub-
stantial contribution to the overall success rate. A salience factor that was originally
present, viz, matrix emphasis, was revised to become the non-adverbial emphasis factor.
In its original form, this factor contributed to the salience of any NP not contained in
a subordinate clause or in an adverbial PP demarcated by a separator. This was found
to be too general, especially since the relative positions of a given pronoun and its
antecedent candidates are not taken into account. The revised factor could be thought
of as an adverbial penalty factor, since it in effect penalizes NPs occurring in adverbial
pps.io
We also experimented with the initial weights for the various factors and with the
size of the parallelism reward and cataphora penalty, again attempting to optimize
RAP&apos;s overall success rate. A value of 35 was chosen for the parallelism reward; this
is just large enough to offset the preference for subjects over accusative objects. A
much larger value (175) was found to be necessary for the cataphora penalty. The
final results that we obtained for the training corpus are given in Table 2.
Interestingly, the syntactic—morphological filter reduces the set of possible an-
tecedents to a single NP, or identifies the pronoun as pleonastic in 163 of the 475
cases (34%) that the algorithm resolves correctly.&apos; It significantly restricts the size of
the candidate list in most of the other cases, in which the antecedent is selected on the
basis of salience ranking and proximity. This indicates the importance of a powerful
syntactic—morphological filtering component in an anaphora resolution system.
We then performed a blind test of RAP on a test set of 345 sentences randomly
selected from a corpus of 48 computer manuals containing 1.25 million words.&apos; The
results which we obtained for the test corpus (without any further modifications of
RAP) are given in Table 3.13
This blind test provides the basis for a comparative evaluation of RAP and Dagan&apos;s
</bodyText>
<listItem confidence="0.767758">
• 9 These sentences and those used in the blind test were edited slightly to overcome parse inaccuracies.
Rather than revise the lexicon, we made lexical substitutions to improve parses. In some cases
constructions had to be simplified. However, such changes did not alter the syntactic relations among
the pronoun and its possible antecedents.
</listItem>
<footnote confidence="0.732743666666667">
For a discussion of ESG&apos;s parsing accuracy, see McCord (1993).
10 See comments at the end of Section 4 about refining RAP&apos;s measures of structural salience.
11 Forty-three of the pronoun occurrences in the training corpus 8%) were pleonastic; a random sample
of 245 pronoun occurrences extracted from our test corpus included 15 pleonastic pronouns (— 6%).
12 The test set was filtered in order to satisfy the conditions of our experiments on the role of statistically
measured lexical preference in enhancing RAP&apos;s performance. See Section 5.1 for a discussion of these
</footnote>
<page confidence="0.974573">
549
</page>
<table confidence="0.931691142857143">
Computational Linguistics Volume 20, Number 4
Table 3
Results of blind test
Total Intersentential cases Intrasentential cases
Number of pronoun occurrences 360 70 290
Number of cases that the algorithm 310 (86%) 52 (74%) 258 (89%)
resolves correctly
</table>
<listItem confidence="0.5801302">
(1992) system, RAPSTAT, which employs both RAP&apos;s salience weighting mechanism
and statistically measured lexical preferences, as well as for a detailed analysis of the
relative contributions of the various elements of RAP&apos;s salience weighting mechanism
to its overall success rate. We will discuss the blind test in greater detail in the following
sections.
</listItem>
<subsectionHeader confidence="0.999515">
4.1 Limitations of the Current Algorithm
</subsectionHeader>
<bodyText confidence="0.944840038461539">
Several classes of errors that RAP makes are worthy of discussion. The first occurs
with many cases of intersentential anaphora, such as the following:
This green indicator is lit when the controller is on.
It shows that the DC power supply voltages are at the correct
levels.
Morphological and syntactic filtering exclude all possible intrasentential candidates.
Because the level of sentential embedding does not contribute to RAP&apos;s salience weight-
ing mechanism, indicator.(1.3) and controller.(1.8) are ranked equally, since both are
subjects. RAP then erroneously chooses control ler.(1.8) as the antecedent, since it is
closer to the pronoun than the other candidate.
The next class of errors involves antecedents that receive a low salience weighting
owing to the fact that the evoking NP is embedded in a matrix NP or is in another
structurally nonprominent position (such as object of an adverbial PP).
The users you enroll may not necessarily be new to the system
and may already have a user profile and a system distribution
directory entry.
&amp;ofc. checks for the existence of these objects and only
creates them as necessary.
Despite the general preference for intrasentential candidates, user.(1.2) is selected as
the antecedent, since the only factor contributing to the salience weight of object. (2.8)
is sentence recency. Selectional restrictions or statistically measured lexical preferences
(see Section 5) could clearly help in at least some of these cases.
In another class of cases, RAP fails because semantic/pragmatic information is
required to identify the correct antecedent.
conditions.
13 Proper resolution was determined by a consensus of three opinions, including that of the first author.
</bodyText>
<page confidence="0.996803">
550
</page>
<note confidence="0.952275">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<tableCaption confidence="0.7422375">
Table 4
Relative contribution of elements of salience weighting mechanism
</tableCaption>
<table confidence="0.999057">
Total correct Correctly disagrees with RAP Incorrectly disagrees with RAP
I 310 (86%)
II 308 (86%) 2 4
III 308 (86%) 2 4
IV 302 (84%) 3 11
V 301 (84%) 9
VI 297 (83%) 12 25
VII 294 (82%) 1 17
VIII 231 (64%) 79
IX 212 (59%) 21 119
X 184 (51%) 17 143
</table>
<figureCaption confidence="0.650422">
Again, the Migration Aid produces an exception report
automatically at the end of every migration run.
</figureCaption>
<bodyText confidence="0.903399">
As you did with the function, use it to verify that the items
have been restored to your system successfully.
funct ion.(2.6) is selected as the antecedent, rather than a id .(1.5).
</bodyText>
<subsectionHeader confidence="0.998765">
4.2 The Relative Contributions of the Salience Weighting Mechanisms
</subsectionHeader>
<bodyText confidence="0.814267523809524">
Using the test corpus of our blind test, we conducted experiments with modified
versions of RAP, in which various elements of the salience weighting mechanism
were switched off. We present the results in Table 4 and discuss their significance.
Ten variants are presented in Table 4; they are as follows:
I &amp;quot;standard&amp;quot; RAP (as used in the blind test)
II parallelism reward deactivated
III non-adverbial and head emphasis deactivated
IV matrix emphasis used instead of non-adverbial emphasis
V cataphora penalty deactivated
VI subject, existential, accusative, and indirect object/oblique complement
emphasis (i.e., hierarchy of grammatical roles) deactivated
VII equivalence classes deactivated
VIII sentence recency and salience degradation deactivated
IX all &amp;quot;structural&amp;quot; salience weighting deactivated (II + III + V + VI)
X all salience weighting and degradation deactivated
The single most important element of the salience weighting mechanism is the
recency preference (sentence recency factor and salience degradation; see VIII). This is
not surprising, given the relative scarcity of intersentential anaphora in our test corpus
(less than 20% of the pronoun occurrences had antecedents in the preceding sentence).
Deactivating the equivalence class mechanism also led to a significant deterioration
in RAP&apos;s performance; in this variant (VII), only the salience factors applying to a
</bodyText>
<page confidence="0.994859">
551
</page>
<note confidence="0.749863">
Computational Linguistics Volume 20, Number 4
</note>
<bodyText confidence="0.999829129032258">
particular NP contribute to its salience weight, without any contribution from other
anaphorically linked NPs. The performance of the syntactic filter is degraded some-
what in this variant as well, since NPs that are anaphorically linked to an NP fulfilling
the criteria for disjoint reference will no longer be rejected as antecedent candidates.
The results for VII and VIII indicate that attentional state plays a significant role in
pronominal anaphora resolution and that even a simple model of attentional state can
be quite effective.
Deactivating the syntax-based elements of the salience weighting mechanism in-
dividually led to relatively small deteriorations in the overall success rate (II, III, IV,
V. and VI). Eliminating the hierarchy of grammatical roles (VI), for example, led to
a deterioration of less than 4%. Despite the comparatively small degradation in per-
formance that resulted from turning off these elements individually, their combined
effect is quite significant, as the results of IX show. This suggests that the syntactic
salience factors operate in a complex and highly interdependent manner for anaphora
resolution.
X relies solely on syntactic/morphological filtering and proximity to choose an
antecedent. Note that the sentence pairs of the blind test set were selected so that,
for each pronoun occurrence, at least two antecedent candidates remained after syn-
tactic/morphological filtering (see Section 5.1). In the 17 cases in which X correctly
disagreed with RAP, the proper antecedent happened to be the most proximate can-
didate.
We suspect that RAP&apos;s overall success rate can be improved (perhaps by 5% or
more) by refining its measures of structural salience. Other measures of embeddedness,
or perhaps of &amp;quot;distance&amp;quot; between anaphor and candidate measured in terms of clausal
and NP boundaries, may be more effective than the current mechanisms for non-
adverbial and head emphasis.&apos; Empirical studies of patterns of pronominal anaphora
in corpora (ideally in accurately and uniformly parsed corpora) could be helpful in
defining the most effective measures of structural salience. One might use such studies
to obtain statistical data for determining the reliability of each proposed measure as a
predictor of the antecedent—anaphor relation and the orthogonality (independence) of
all proposed measures.
</bodyText>
<sectionHeader confidence="0.620302" genericHeader="related work">
5. Salience and Statistically Measured Lexical Preference
</sectionHeader>
<bodyText confidence="0.978518277777778">
Dagan (1992) constructs a procedure, which he refers to as RAPSTAT, for using sta-
tistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings
of antecedent candidates. RAPSTAT assigns a statistical score to each element of a
candidate list that RAP generates; this score is intended to provide a measure (relative
to a corpus) of the preference that lexical semantic/pragmatic factors impose upon the
candidate as a possible antecedent for a given pronoun.&apos;
14 Such a distance measure is reminiscent of Hobbs&apos; (1978) tree search procedure. See Section 6.1 for a
discussion of Hobbs&apos; algorithm and its limitations.
The results for IV confirm our suspicions from the training phase that matrix emphasis (rewarding
NPs not contained in a subordinate clause) does not contribute significantly to successful resolution.
15 Assume that P is a non-pleonastic and non-reflexive pronoun in a sentence such that RAP generates
the non-empty list L of antecedent candidates for P. Let H be the lexical head (generally a verb or a
noun) of which P is an argument or an adjunct in the sentence. RAPSTAT computes a statistical score
for each element C, of L, on the basis of the frequency, in a corpus, with which Ci occurs in the same
grammatical relation with H as P occurs with H in the sentence. The statistical score that RAPSTAT
assigns to Ci is intended to model the probability of the event where C, stands in the relevant
grammatical relation to H, given the occurrence of C, (but taken independently of the other elements
of L).
</bodyText>
<page confidence="0.991229">
552
</page>
<note confidence="0.803669">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<bodyText confidence="0.99623008">
RAPSTAT reevaluates RAP&apos;s ranking of the elements of the antecedent candidate
list L in a way that combines both the statistical scores and the salience values of the
candidates. The elements of L appear in descending order of salience value. RAPSTAT
processes L as follows. Initially, it considers the first two elements C1 and C2 of L. If (i)
the difference in salience scores between C1 and C2 does not exceed a parametrically
specified value (the salience difference threshold) and (ii) the statistical score of C2 is
significantly greater than that of C1, then RAPSTAT will substitute the former for the
latter as the currently preferred candidate. If conditions (i) and (ii) do not hold, RAP-
STAT confirms RAP&apos;s selection of C1 as the preferred antecedent. If these conditions
do hold, then RAPSTAT selects C2 as the currently preferred candidate and proceeds
to compare it with the next element of L. It repeats this procedure for each successive
pair of candidates in L until either (i) or (ii) fails or the list is completed. In either case,
the last currently preferred candidate is selected as the antecedent.
An example of a case in which RAPSTAT overules RAP is the following.
The Send Message display is shown, allowing you to enter your
message and specify where it will be sent.
The two top candidates in the list that RAP generates for it.(1.17) are display.(1.4) with
a salience value of 345 and message.(1.13), which has a salience value of 315. In the
corpus that we used for testing RAPSTAT, the verb—object pair send—display appears
only once, whereas send—message occurs 289 times. As a result, message receives a
considerably higher statistical score than display. The salience difference threshold that
we used for the test is 100, and conditions (i) and (ii) hold for these two candidates.
The difference between the salience value of message and the third element of the
candidate list is greater than 100. Therefore, RAPSTAT correctly selects message as the
antecedent of it.
</bodyText>
<subsectionHeader confidence="0.998647">
5.1 A Blind Test of RAP and RAPSTAT
</subsectionHeader>
<bodyText confidence="0.989414636363636">
Dagan et al. (in press) report a comparative blind test of RAP and RAPSTAT. To con-
struct a database of grammatical relation counts for RAPSTAT, we applied the Slot
Grammar parser to a corpus of 1.25 million words of text from 48 computer manu-
als. We automatically extracted all lexical tuples and recorded their frequencies in the
parsed corpus. We then constructed a test set of pronouns by randomly selecting from
the corpus sentences containing at least one non-pleonastic third person pronoun oc-
currence. For each such sentence in the set, we included the sentence that immediately
precedes it in the text (when the preceding sentence does not contain a pronoun).&apos; We
filtered the test set so that for each pronoun occurrence in the set, (i) RAP generates a
candidate list with at least two elements, (ii) the actual antecedent NP appears in the
candidate list, and (iii) there is a total tuple frequency greater than 1 for the candidate
See Dagan 1992 and Dagan et al. (in press) for a discussion of this lexical statistical approach to
ranking antecedent candidates and possible alternatives.
16 In the interests of simplicity and uniformity we discarded sentence pairs in which the first sentence
contains a pronoun. We decided to limit the text preceding the sentence containing the pronoun to one
sentence because we found that in the manuals which we used to tune the algorithm, almost all cases
of intersentential anaphora involved an antecedent in the immediately preceding sentence. Moreover,
the progressive decline in the salience values of antecedent candidates in previous sentences ensures
that a candidate appearing in a sentence which is more than one sentence prior to the current one will
be selected only if no candidates exist in either the current or the preceding sentence. As such cases are
relatively rare in the type of text we studied, we limited our test set to textual units containing the
current and the preceding sentence.
</bodyText>
<page confidence="0.997015">
553
</page>
<note confidence="0.808098">
Computational Linguistics Volume 20, Number 4
</note>
<bodyText confidence="0.970296333333333">
list (in most cases, it was considerably larger).17 The test set contains 345 sentence
pairs with a total of 360 pronoun occurrences. The results of the blind test for RAP
and RAPSTAT are as follows.&apos;
</bodyText>
<table confidence="0.997698090909091">
RAP RAPSTAT
Total correct: 310 (86%) 319 (89%)
Total decided: 360 (100%) 182 (51%)
Correctly decided: 310 (86%) 144 (79%)
RAPSTAT 41(22% of cases decided)
Disagrees with RAP:
Correctly disagrees with RAP: 25 (61%)
Incorrectly disagrees with RAP: 16 (39%)
RAP/RAPSTAT
Both wrong: 22 (12%)
Either RAP or RAPSTAT is correct: 335 (93%)
</table>
<bodyText confidence="0.9999112">
When we further analyzed the results of the blind test, we found that RAPSTAT&apos;s
success depends in large part on its use of salience information. If RAPSTAT&apos;s statis-
tically based lexical preference scores are used as the only criterion for selecting an
antecedent, the statistical selection procedure disagrees with RAP in 151 out of 338
instances. RAP is correct in 120 (79%) of these cases and the statistical decision in 31
(21%) of the cases. When salience is factored into RAPSTAT&apos;s decision procedure, the
rate of disagreement between RAP and RAPSTAT declines sharply, and RAPSTAT&apos;s
performance slightly surpasses that of RAP, yielding the results that we obtained in
the blind test.
In general, RAPSTAT is a conservative statistical extension of RAP. It permits sta-
tistically measured lexical preference to overturn salience-based decisions only in cases
in which the difference between the salience values of two candidates is small and
the statistical preference for the less salient candidate is comparatively large.&apos; The
comparative blind test indicates that incorporating statistical information on lexical
preference patterns into a salience-based anaphora resolution procedure can yield a
modest improvement in performance relative to a system that relies only on syntactic
salience for antecedent selection. Our analysis of these results also shows that statis-
tically measured lexical preference patterns alone provide a far less efficient basis for
anaphora resolution than an algorithm based on syntactic and attentional measures of
salience.&apos;
</bodyText>
<subsectionHeader confidence="0.883524">
6. Comparison with Other Approaches to Anaphora Resolution
</subsectionHeader>
<bodyText confidence="0.9990565">
We will briefly compare our algorithm with several other approaches to anaphora
resolution that have been suggested.
</bodyText>
<footnote confidence="0.895806625">
17 In previous tests of RAP we found that it generates a candidate list that includes the correct antecedent
of the pronoun in approximately 98% of the cases to which it applies.
18 We take RAPSTAT as deciding a case when it considers at least two candidates rather than deferring to
RAP after the initial candidate because of a large salience difference between this candidate and the
next one in the list. In cases in which RAPSTAT does not make an independent decision, it endorses
RAP&apos;s selection. RAPSTAT&apos;s total success rate includes both sorts of cases.
19 John Justeson did the statistical analysis of the comparative blind test of RAP and RAPSTAT. These
results are described in Dagan et al. (in press).
</footnote>
<note confidence="0.399703">
20 Dagan (1992) reaches a similar conclusion on the basis of a much smaller experiment.
</note>
<page confidence="0.99527">
554
</page>
<note confidence="0.914654">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<subsectionHeader confidence="0.991097">
6.1 Hobbs&apos; Algorithm
</subsectionHeader>
<bodyText confidence="0.999713217391304">
Hobbs&apos; (1978) algorithm relies on a simple tree search procedure formulated in terms
of depth of embedding and left—right order. By contrast, RAP uses a multi-dimensional
measure of salience that invokes a variety of syntactic properties specified in terms
of the head—argument structures of Slot Grammar, as well as a model of attentional
state.
Hobbs&apos; tree search procedure selects the first candidate encountered by a left—
right depth first search of the tree outside of a minimal path to the pronoun that
satisfies certain configurational constraints. The algorithm chooses as the antecedent
of a pronoun P the first NP, in the tree obtained by left-to-right breadth-first traversal
of the branches to the left of the path T such that (i) T is the path from the NP
dominating P to the first NP or S dominating this NP, (ii) T contains an NP or S node
N that contains the NP dominating P. and (iii) N does not contain NP,. If an antecedent
satisfying this condition is not found in the sentence containing P. the algorithm selects
the first NP obtained by a left-to-right breadth first search of the surface structures of
preceding sentences in the text.
We have implemented a version of Hobbs&apos; algorithm for Slot Grammar. The origi-
nal formulation of the algorithm encodes syntactic constraints on pronominal anaphora
in the definition of the domain to which the search for an antecedent NP applies. In
our implementation of the algorithm, we have factored out the search procedure and
substituted RAP&apos;s syntactic—morphological filter for Hobbs&apos; procedural filter. Let the
Mods (modifiers) of a head H be the sisters of H in the Slot Grammar representation
of the phrase that H heads. Our specification of Hobbs&apos; algorithm for Slot Grammar
is as follows:
</bodyText>
<listItem confidence="0.98805725">
1. Find a node N1 such that (i) N1 contains the pronoun P; (ii) N1 is an S or
NP; and (iii) it is not the case that there is a node N1, such that N1
contains N1, and N1, satisfies (i) and (ii).
2. Check the list of Mods of N1 left to right for NPs that are not elements of
the list of pairs &lt;P—NP&gt; identified by the syntactic-morphological filter
as noncoreferential and that occur to the left of P.
3. Select the leftmost NP in the filtered list of NP Mods of Ni.
4. If this list is nil, then repeat steps 2 and 3 recursively for each Mod in
the list of Mods of N1, each Mod in this second list of Mods, etc., until
an NP antecedent is found.
5. If no NP antecedent is found by applying step 4, then identify a node N2
that is the first NP/S containing N1.
6. If N2 is an NP and is not an element of the list of pairs &lt;P—NP&gt;
identified by the filter, propose it as the antecedent.
7. Otherwise, apply steps 2-4 to N2
8. If no antecedent NP is found, continue to apply steps 5 and 6 and then
steps 2-4 to progressively higher NP/S nodes.
9. If no antecedent NPs are found at the highest S of the sentence, then
take N1 to be the highest S node of the immediately preceding sentence
and apply steps 2-4 to N1.
</listItem>
<page confidence="0.996074">
555
</page>
<note confidence="0.692679">
Computational Linguistics Volume 20, Number 4
</note>
<tableCaption confidence="0.997034">
Table 5
</tableCaption>
<table confidence="0.944757111111111">
Results of blind test (Hobbs&apos; algorithm)
Total Intersentential cases Intrasentential cases
Number of pronoun occurrences 360 70 290
Number of cases that the 295 (82%) 61(87%) 234 (81%)
algorithm resolves correctly
Number of cases for which HOBBS 22 9 13
correctly disagrees with RAP
Number of cases for which HOBBS 38 4 34
incorrectly disagrees with RAP
</table>
<bodyText confidence="0.999480555555556">
We ran this version of Hobbs&apos; algorithm on the test set that we used for the blind
test of RAP and RAPSTAT; the results appear in Table 5.
It is important to note that the test set does not include pleonastic pronouns or
lexical anaphors (reflexive or reciprocal pronouns), neither of which are dealt with by
Hobbs&apos; algorithm. Moreover, our Slot Grammar implementation of the algorithm gives
it the full advantage of RAP&apos;s syntactic—morphological filter, which is more powerful
than the configurational filter built into the original specification of the algorithm.
Therefore, the test results provide a direct comparison of RAP&apos;s salience metric and
Hobbs&apos; search procedure.
Hobbs&apos; algorithm was more successful than RAP in resolving intersentential ana-
phora (87% versus 74% correct).&apos; Because intersentential anaphora is relatively rare in
our corpus of computer manual texts and because RAP&apos;s success rate for intrasentential
anaphora is higher than Hobbs&apos; (89% versus 81%), RAP&apos;s overall success rate on the
blind test set is 4% higher than that of our version of Hobbs&apos; algorithm. This indicates
that RAP&apos;s salience metric provides a more reliable basis for antecedent selection than
Hobbs&apos; search procedure for the text domain on which we tested both algorithms.
It is clear from the relatively high rate of agreement between RAP and Hobbs&apos;
algorithm on the test set (they agree in 83% of the cases) that there is a significant
degree of convergence between salience as measured by RAP and the configurational
prominence defined by Hobbs&apos; search procedure. This is to be expected in English,
in which grammatical roles are identified by means of phrase order. However, in
languages in which grammatical roles are case marked and word order is relatively
free, we expect that there will be greater divergence in the predictions of the two
algorithms. The salience measures used by RAP have application to a wider class
of languages than Hobbs&apos; order-based search procedure. This procedure relies on a
correspondence of grammatical roles and linear precedence relations that holds for a
comparatively small class of languages.
</bodyText>
<subsectionHeader confidence="0.987194">
6.2 Discourse Based Methods
</subsectionHeader>
<bodyText confidence="0.850106333333334">
Most of the work in this area seeks to formulate general principles of discourse struc-
ture and interpretation and to integrate methods of anaphora resolution into a com-
putational model of discourse interpretation (and sometimes of generation as well).
Sidner (1981, 1983), Grosz, Joshi, and Weinstein (1983, 1986), Grosz and Sidner (1986),
21 The difficulty that RAP encounters with such cases was discussed in Section 4.1. We are experimenting
with refinements in RAP&apos;s scoring mechanism to improve its performance in these and other cases.
</bodyText>
<page confidence="0.994029">
556
</page>
<note confidence="0.85885">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<bodyText confidence="0.998878142857143">
Brennan, Friedman, and Pollard (1987), and Webber (1988) present different versions
of this approach. Dynamic properties of discourse, especially coherence and focusing,
are invoked as the primary basis for identifying antecedence candidates; selecting a
candidate as the antecedent of a pronoun in discourse involves additional constraints
of a syntactic, semantic, and pragmatic nature.
In developing our algorithm, we have not attempted to consider elements of dis-
course structure beyond the simple model of attentional state realized by equivalence
classes of discourse referents, salience degradation, and the sentence recency salience
factor. The results of our experiments with computer manual texts (see Section 4.2)
indicate that, at least for certain text domains, relatively simple models of discourse
structure can be quite useful in pronominal anaphora resolution. We suspect that many
aspects of discourse models discussed in the literature will remain computationally
intractable for quite some time, at least for broad-coverage systems.
A more extensive treatment of discourse structure would no doubt improve the
performance of a structurally based algorithm such as RAP. At the very least, for-
matting information concerning paragraph and section boundaries, list elements, etc.,
should be taken into account. A treatment of definite NP resolution would also pre-
sumably lead to more accurate resolution of pronominal anaphora, since it would
improve the reliability of the salience weighting mechanism.
However, some current discourse-based approaches to anaphora resolution assign
too dominant a role to coherence and focus in antecedent selection. As a result, they
establish a strong preference for intersentential over intrasentential anaphora resolu-
tion. This is the case with the anaphora resolution algorithm described by Brennan,
Friedman, and Pollard (1987). This algorithm is based on the centering approach to
modeling attentional structure in discourse (Grosz, Joshi, and Weinstein 1983, 1986).22
Constraints and rules for centering are applied by the algorithm as part of the selection
procedure for identifying the antecedents of pronouns in a discourse. The algorithm
strongly prefers intersentential antecedents that preserve the center or maximize con-
tinuity in center change, to intrasentential antecedents that cause radical center shifts.
This strong preference for intersentential antecedents is inappropriate for at least some
text domains—in our corpus of computer manual texts, for example, we estimate
that less than 20% of referentially used third person pronouns have intersentential
antecedents.&apos;
There is a second difficulty with the Brennan et al. centering algorithm. It uses a
hierarchy of grammatical roles quite similar to that of RAP, but this role hierarchy does
not directly influence antecedent selection. Whereas the hierarchy in RAP contributes
to a multi-dimensional measure of the relative salience of all antecedent candidates,
in Brennan et al. 1987, it is used only to constrain the choice of the backward-looking
center, Cb, of an utterance. It does not serve as a general preference measure for an-
tecedence. The items in the forward center list, Cf, are ranked according to the hier-
archy of grammatical roles. For an utterance Un, Cb(Un) is required to be the highest
ranked element of Cf (1.1i) that is realized in U. If an element E in the list of possible
</bodyText>
<footnote confidence="0.844401777777778">
22 &amp;quot;A discourse segment consists of a sequence of utterances 111, . . , Um. With each utterance, Un is
associated with a list of forward-looking centers, Cf (U„), consisting of those discourse entities that are
directly realized or realized by linguistic expressions in that utterance. Ranking of an entity on this list
corresponds roughly to the likelihood that it will be the primary focus of subsequent discourse; the
first entity on this list is the preferred center, Cp(11,,). Lin actually centers, or is &apos;about,&apos; only one entity at
a time, the backward-looking center, Cb(U„). The backward center is a confirmation of an entity that has
already been introduced into the discourse; more specifically, it must be realized in the immediately
preceding utterance, U„_1&amp;quot; (Brennan, Friedman, and Pollard 1987, p. 155).
23 This estimate is based on the small random sample used in our blind test (see Section 5.1).
</footnote>
<page confidence="0.97973">
557
</page>
<note confidence="0.796863">
Computational Linguistics Volume 20, Number 4
</note>
<bodyText confidence="0.999245035714286">
forward centers, Cf (11,_1), is identified as the antecedent of a pronoun in LIE, then E is
realized in U. The Brennan et al. centering algorithm does not require that the highest
ranked element of Cf (Un_i ) actually be realized in Un, but only that Cb(1.1&amp;quot;,) be the high-
est ranked element of Cf (Un_i) which is, in fact, realized in U. Antecedent selection
is constrained by rules that sustain cohesion in the relations between the backward
centers of successive utterances in a discourse, but it is not determined directly by the
role hierarchy used to rank the forward centers of a previous utterance. Therefore, an
NP in Un_1 that is relatively low in the hierarchy of grammatical roles can serve as an
antecedent of a pronoun in Lin, provided that no higher ranked NP in U„_1 is taken as
the antecedent of some other pronoun or definite NP in Un. 24 An example will serve
to illustrate the problem with this approach.
The display shows you the status of all the printers.
It also provides options that control printers.
The (ranked) forward center list for the first sentence is as follows:
( [DISPLAY] [STATUS] [YOU] [PRINTERS] ) .
Applying the filters and ranking mechanism of Brennan, Friedman, and Pollard (1987)
yields two possible anchors.25 Each anchor determines a choice of Cb(LI) and the
antecedent of it. One anchor identifies both with display, whereas the second takes
both to be status. The hierarchy of grammatical roles is not used to select display over
status. Nothing in the algorithm rules out the choice of status as the backward center
for the second sentence and as the antecedent of it. If this selection is made, display is
not realized in the second sentence, and so Cb(Un) is status, which is then the highest
ranked element of Cf (Un_i) that is realized in Un, as required by constraint 3 of the
Brennan et al. centering algorithm.
In general, we agree with Alshawi (1987, p. 62) that an algorithm/model relying
on the relative salience of all entities evoked by a text, with a mechanism for removing
or filtering entities whose salience falls below a threshold, is preferable to models that
&amp;quot;make assumptions about a single (if shifting) focus of attention.&amp;quot;&apos;
</bodyText>
<subsectionHeader confidence="0.887364">
6.3 Mixed Models
</subsectionHeader>
<bodyText confidence="0.999562125">
This approach seeks to combine a variety of syntactic, semantic, and discourse factors
into a multi-dimensional metric for ranking antecedent candidates. On this view, the
score of a candidate is a composite of several distinct scoring procedures, each of which
reflects the prominence of the candidate with respect to a specific type of information
or property. The systems described by Asher and Wada (1988), Carbonell and Brown
(1988), and Rich and LuperFoy (1988) are examples of this mixed evaluation strategy.
In general, these systems use composite scoring procedures that assign a global
rank to an antecedent candidate on the basis of the scores that it receives from several
</bodyText>
<reference confidence="0.273613111111111">
24 Other factors, such as level of embedding, may also be considered in generating an ordering for the list
of forward-looking centers. Walker, Iida, and Cote (1990) discuss ordering conditions appropriate for
Japanese.
25 An anchor is an association between a backward-looking center, Cb, and a list of forward-looking
centers, Cf, for an utterance. An anchor establishes a link between a pronoun and its antecedent by
associating the reference marker of the antecedent with that of the pronoun in the Cf list of the
utterance.
26 See Walker (1989) for a comparison of the algorithm of Brennan, Friedman, and Pollard (1987) with
that of Hobbs (1978) based on a hand simulation.
</reference>
<page confidence="0.992424">
558
</page>
<note confidence="0.844237">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<bodyText confidence="0.999790961538462">
evaluation metrics. Each such metric scores the likelihood of the candidate relative to
a distinct informational factor. Thus, for example, Rich and LuperFoy (1988) propose
a system that computes the global preference value of a candidate from the scores
provided by a set of constraint source modules, in which each module invokes dif-
ferent sorts of conditions for ranking the antecedent candidate. The set of modules
includes (among others) syntactic and morphological filters for checking agreement
and syntactic conditions on disjoint reference, a procedure for applying semantic se-
lection restrictions to a verb and its arguments, a component that uses contextual and
real-world knowledge, and modules that represent both the local and global focus of
discourse. The global ranking of an antecedent candidate is a function of the scores
that it receives from each of the constraint source modules.
Our algorithm also uses a mixed evaluation strategy. We have taken inspiration
from the discussions of scoring procedures in the works cited above, but we have
avoided constraint sources involving complex inferencing mechanisms and real-world
knowledge, typically required for evaluating the semantic/pragmatic suitability of an-
tecedent candidates or for determining details of discourse structure. In general, it
seems to us that reliable large scale modelling of real-world and contextual factors is
beyond the capabilities of current computational systems. Even constructing a com-
prehensive, computationally viable system of semantic selection restrictions and an
associated type hierarchy for a natural language is an exceedingly difficult problem,
which, to our knowledge, has yet to be solved. Moreover, our experiments with sta-
tistically based lexical preference information casts doubt on the efficacy of relatively
inexpensive (and superficial) methods for capturing semantic and pragmatic factors for
purposes of anaphora resolution. Our results suggest that scoring procedures which
rely primarily on tractable syntactic and attentional (recency) properties can yield a
broad coverage anaphora resolution system that achieves a good level of performance.
</bodyText>
<sectionHeader confidence="0.972797" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.998338272727272">
We have designed and implemented an algorithm for pronominal anaphora resolution
that employs measures of discourse salience derived from syntactic structure and a
simple dynamic model of attentional state. We have performed a blind test of this
algorithm on a substantial set of cases taken from a corpus of computer manual text
and found it to provide good coverage for this set. It scored higher than a version of
Hobbs&apos; algorithm that we implemented for Slot Grammar.
Results of experiments with the test corpus show that the syntax-based elements
of our salience weighting mechanism contribute in a complexly interdependent way to
the overall effectiveness of the algorithm. The results also support the view that atten-
tional state plays a significant role in pronominal anaphora resolution and demonstrate
that even a simple model of attentional state can be quite effective.
The addition of statistically measured lexical preferences to the range of factors that
the algorithm considers only marginally improved its performance on the blind test
set. Analysis of the results indicates that lexical preference information can be useful in
cases in which the syntactic salience ranking does not provide a clear decision among
the top candidates, and there is a strong lexical preference for one of the less salient
candidates.
The relatively high success rate of the algorithm suggests the viability of a com-
putational model of anaphora resolution in which the relative salience of an NP in
discourse is determined, in large part, by structural factors. In this model, semantic
and real-world knowledge conditions apply to the output of an algorithm that re-
solves pronominal anaphora on the basis of syntactic measures of salience, recency,
</bodyText>
<page confidence="0.994465">
559
</page>
<note confidence="0.800127">
Computational Linguistics Volume 20, Number 4
</note>
<bodyText confidence="0.998728333333333">
and frequency of mention. These conditions are invoked only in cases in which salience
does not provide a clear-cut decision and/or there is substantial semantic—pragmatic
support for one of the less salient candidates.&apos;
</bodyText>
<sectionHeader confidence="0.932735" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997937111111111">
We would like to thank Martin Chodorow,
Ido Dagan, John Justeson, Slava Katz,
Michael McCord, Hubert Lehman, Amnon
Ribak, Ulrike Schwa11, and Marilyn Walker
for helpful discussion of many of the ideas
and proposals presented here. The blind test
and evaluation of RAPSTAT reported here
was done jointly with Ido Dagan, John
Justeson, and Amnon Ribak. An early
version of this paper was presented at the
Cognitive Science Colloquium of the
University of Pennsylvania, in January 1992,
and we are grateful to the participants of
the colloquium for their reactions and
suggestions. We are also grateful to several
anonymous reviewers of Computational
Linguistics for helpful comments on earlier
drafts of the paper.
</bodyText>
<sectionHeader confidence="0.925225" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9972215">
Alshawi, Hiyan (1987). Memory and Context
for Language Interpretation. Cambridge:
Cambridge University Press.
Asher, Nicholas, and Wada, Hajime (1988).
&amp;quot;A computational account of syntactic,
semantic and discourse principles for
anaphora resolution.&amp;quot; Journal of Semantics
6:309-344.
Bosch, Peter (1988). &amp;quot;Some good reasons for
shallow pronoun processing.&amp;quot; In
Proceedings, IBM Conference on Natural
Language Processing. New York:
Thornwood.
Brennan, Susan; Friedman, Marilyn; and
Pollard, Carl (1987). &amp;quot;A centering
approach to pronouns.&amp;quot; In Proceedings,
25th Annual Meeting of the Association for
Computational Linguistics, 155-162.
Carbonell, Jaime, and Brown, Ralf (1988).
&amp;quot;Anaphora resolution: A multi-strategy
approach.&amp;quot; In Proceedings, 12th
International Conference on Computational
Linguistics, 96-101.
Dagan, Ido (1992). &amp;quot;Multilingual statistical
approaches for natural language
disambiguation&amp;quot; (in Hebrew). Doctoral
dissertation, Israel Institute of Technology,
Haifa, Israel.
Dagan, Ido; Justeson, John; Lappin, Shalom;
Leass, Herbert; and Ribak, Amnon (in
press). &amp;quot;Syntax and lexical statistics in
anaphora resolution.&amp;quot; Applied Artificial
Intelligence.
Grosz, Barbara; Joshi, Aravind; and
Weinstein, Scott (1983). &amp;quot;Providing a
unified account of definite noun phrases
in discourse.&amp;quot; In Proceedings, 21st Annual
Meeting of the Association of Computational
Linguistics, 44-50.
Grosz, Barbara; Joshi, Aravind; and
Weinstein, Scott (1986, unpublished).
&amp;quot;Towards a computational theory of
discourse interpretation.&amp;quot; Harvard
University and University of
Pennsylvania.
Grosz, Barbara, and Sidner, Candice (1986).
&amp;quot;Attention, intentions, and the structure
of discourse.&amp;quot; Computational Linguistics
12:175-204.
Guenthner, Franz, and Lehmann, Hubert
(1983). &amp;quot;Rules for pronominalization.&amp;quot; In
Proceedings, First Annual Meeting of the
European Chapter of the ACL, 144-151.
Hobbs, Jerry (1978). &amp;quot;Resolving pronoun
references.&amp;quot; Lingua 44:311-338.
Johnson, David (1977). &amp;quot;On relational
constraints on grammars.&amp;quot; In Syntax and
Semantics 8, edited by P. Cole and
J. Sadock, 151-178. New York: Academic
Press.
Kamp, Hans (1981). &amp;quot;A theory of truth and
semantic representation.&amp;quot; In Formal
Methods in the Study of Language, edited by
J. Groenendijk, T. Janssen, and
M. Stokhof. Amsterdam: Mathematisch
Centrum Tracts.
Keenan, Edward, and Comrie, Bernard
(1977). &amp;quot;Noun phrase accessibility and
universal grammar.&amp;quot; Linguistic Inquiry
8:62-100.
Lappin, Shalom (1985). &amp;quot;Pronominal
binding and coreference.&amp;quot; Theoretical
Linguistics 12:241-263.
Lappin, Shalom, and McCord, Michael
(1990a). &amp;quot;A syntactic filter on pronominal
anaphora in slot grammar.&amp;quot; In Proceedings,
28th Annual Meeting of the Association for
Computational Linguistics, 135-142.
Lappin, Shalom, and McCord, Michael
(1990b). &amp;quot;Anaphora resolution in slot
grammar.&amp;quot; Computational Linguistics
16:197-212.
27 Bosch (1988) suggests a psychological processing model in which hearers rely on first pass syntactically
based strategies for initial linking of pronouns to antecedent NPs.
</reference>
<page confidence="0.962104">
560
</page>
<note confidence="0.674965">
Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution
</note>
<reference confidence="0.99983146969697">
Leass, Herbert, and Schwa11, Ulrike (1991).
&amp;quot;An anaphora resolution procedure for
machine translation.&amp;quot; IWBS Report 172,
IBM Germany Scientific Center,
Heidelberg, Germany.
McCord, Michael (1989a). &amp;quot;Design of LMT:
A prolog-based machine translation
system.&amp;quot; Computational Linguistics
15:33-52.
McCord, Michael (1989b). &amp;quot;A new version
of the machine translation system LMT.&amp;quot;
Literary and Linguistic Computing 4:218-229.
McCord, Michael (1990). &amp;quot;Slot grammar: A
system for simpler construction of
practical natural language grammars.&amp;quot; In
Natural Language and Logic: International
Scientific Symposium, edited by R. Studer,
118-145. Lecture Notes in Computer
Science, Berlin: Springer Verlag.
McCord, Michael (1993). &amp;quot;Heuristics for
broad-coverage natural language
parsing.&amp;quot; In Proceedings, ARPA Human
Language Technology Workshop, University
of Pennsylvania.
McCord, Michael (in press). &amp;quot;The slot
grammar system.&amp;quot; In Unification in
Grammar, edited by Jurgen Wedekin and
Christian Rohrer (also IBM Research
Report RC 17313). Cambridge, MA: MIT
Press.
McCord, Michael; Bernth, Arendse; Lappin,
Shalom; and Zadrozny, Wlodek (1992).
&amp;quot;Natural language processing within a
slot grammar framework.&amp;quot; International
Journal on Artificial Intelligence Tools
1:229-277.
Rich, Elaine, and LuperFoy, Susann (1988).
&amp;quot;An architecture for anaphora resolution.&amp;quot;
In Proceedings, ACL Conference on Applied
Natural Language Processing, 18-24.
Sidner, Candice (1981). &amp;quot;Focusing for
interpretation of pronouns.&amp;quot; American
Journal of Computational Linguistics
7:217-231.
Sidner, Candice (1983). &amp;quot;Focusing in the
comprehension of definite anaphora.&amp;quot; In
Computational Models of Discourse, edited
by Michael Brady and Robert Berwick,
267-330. Cambridge, MA: MIT Press.
Walker, Marilyn (1989). &amp;quot;Evaluating
discourse processing algorithms.&amp;quot; In
Proceedings, 27th Annual Meeting of the
Association for Computational Linguistics,
251-261.
Walker, Marilyn; Iida, Masayo; and Cote,
Sharon (1990). &amp;quot;Centering in Japanese
discourse.&amp;quot; In Proceedings, 13th
International Conference on Computational
Linguistics, 1-6.
Webber, Bonnie (1988). &amp;quot;Discourse Deixis:
Reference to discourse segments.&amp;quot; In
Proceedings, 26th Annual Meeting of the
Association for Computational Linguistics,
113-121.
Williams, Edwin (1984). &amp;quot;Grammatical
relations.&amp;quot; Linguistic Inquiry 15:639-673.
</reference>
<page confidence="0.99789">
561
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.708896">
<title confidence="0.999122">An Algorithm for Pronominal Anaphora Resolution</title>
<author confidence="0.999915">Shalom Lappin Herbert J Leassi</author>
<affiliation confidence="0.765008">SOAS, University of London Sietec Systemtechnik</affiliation>
<abstract confidence="0.996092166666667">This paper presents an algorithm for identifying the noun phrase antecedents of third person pronouns and lexical anaphors (reflexives and reciprocals). The algorithm applies to the syntactic representations generated by McCord&apos;s Slot Grammar parser and relies on salience measures derived from syntactic structure and a simple dynamic model of attentional state. Like the parser, the algorithm is implemented in Prolog. The authors have tested it extensively on computer manual texts and conducted a blind test on manual text containing 360 pronoun occurrences. The algorithm successfully identifies the antecedent of the pronoun for 86% of these pronoun occurrences. The relative contributions of the algorithm&apos;s components to its overall success rate in this blind test are examined. Experiments were conducted with an enhancement of the algorithm that contributes statistically modelled information concerning semantic and real-world relations to the algorithm&apos;s decision procedure. Interestingly, this enhancement only marginally improves the algorithm&apos;s performance (by 2%). The algorithm is compared with other approaches to anaphora resolution that have been proposed in the literature. In particular, the search procedure of Hobbs&apos; algorithm was implemented in the Slot Grammar framework and applied to the sentences in the blind test set. The authors&apos; algorithm achieves a higher rate of success (4%) than Hobbs&apos; algorithm. The relation of the algorithm to the centering approach is discussed, as well as to models of anaphora resolution that invoke a variety of informational factors in ranking antecedent candidates.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Other</author>
</authors>
<title>factors, such as level of embedding, may also be considered in generating an ordering for the list of forward-looking centers.</title>
<date>1990</date>
<location>Walker, Iida, and Cote</location>
<marker>Other, 1990</marker>
<rawString>24 Other factors, such as level of embedding, may also be considered in generating an ordering for the list of forward-looking centers. Walker, Iida, and Cote (1990) discuss ordering conditions appropriate for Japanese.</rawString>
</citation>
<citation valid="false">
<title>25 An anchor is an association between a backward-looking center, Cb, and a list of forward-looking centers, Cf, for an utterance. An anchor establishes a link between a pronoun and its antecedent by associating the reference marker of the antecedent with that of the pronoun in the Cf list of the utterance.</title>
<marker></marker>
<rawString>25 An anchor is an association between a backward-looking center, Cb, and a list of forward-looking centers, Cf, for an utterance. An anchor establishes a link between a pronoun and its antecedent by associating the reference marker of the antecedent with that of the pronoun in the Cf list of the utterance.</rawString>
</citation>
<citation valid="true">
<authors>
<author>See Walker</author>
</authors>
<title>for a comparison of the algorithm of Brennan,</title>
<date>1989</date>
<location>Friedman, and Pollard</location>
<marker>Walker, 1989</marker>
<rawString>26 See Walker (1989) for a comparison of the algorithm of Brennan, Friedman, and Pollard (1987) with that of Hobbs (1978) based on a hand simulation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>Memory and Context for Language Interpretation. Cambridge:</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="15407" citStr="Alshawi 1987" startWordPosition="2516" endWordPosition="2517">use of salience factors in our algorithm is based on Alshawi&apos;s (1987) context mechanism. Other than sentence recency, the factors used in RAP differ from Alshawi&apos;s and are more specific to the task of pronominal anaphora resolution. Alshawi&apos;s framework is designed to deal with a broad class of language interpretation problems, including reference resolution, word sense disambiguation, and the interpretation of implicit relations. While Alshawi does propose emphasis factors for memory entities that are &amp;quot;referents for noun phrases playing syntactic roles regarded as foregrounding the referent&amp;quot; (Alshawi 1987, p. 17), only topics of sentences in the passive voice and the agents of certain be clauses receive such emphasis in his system. Our emphasis salience factors realize a much more detailed measure of structural salience. Degradation of salience factors occurs as the first step in processing a new sentence in the text. All salience factors that have been assigned prior to the appearance of this sentence have their weights degraded by a factor of two. When the weight of a given salience factor reaches zero, the factor is removed. A sentence recency salience factor is created for the current sent</context>
<context position="65990" citStr="Alshawi (1987" startWordPosition="10540" endWordPosition="10541">LI) and the antecedent of it. One anchor identifies both with display, whereas the second takes both to be status. The hierarchy of grammatical roles is not used to select display over status. Nothing in the algorithm rules out the choice of status as the backward center for the second sentence and as the antecedent of it. If this selection is made, display is not realized in the second sentence, and so Cb(Un) is status, which is then the highest ranked element of Cf (Un_i) that is realized in Un, as required by constraint 3 of the Brennan et al. centering algorithm. In general, we agree with Alshawi (1987, p. 62) that an algorithm/model relying on the relative salience of all entities evoked by a text, with a mechanism for removing or filtering entities whose salience falls below a threshold, is preferable to models that &amp;quot;make assumptions about a single (if shifting) focus of attention.&amp;quot;&apos; 6.3 Mixed Models This approach seeks to combine a variety of syntactic, semantic, and discourse factors into a multi-dimensional metric for ranking antecedent candidates. On this view, the score of a candidate is a composite of several distinct scoring procedures, each of which reflects the prominence of the </context>
</contexts>
<marker>Alshawi, 1987</marker>
<rawString>Alshawi, Hiyan (1987). Memory and Context for Language Interpretation. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Hajime Wada</author>
</authors>
<title>A computational account of syntactic, semantic and discourse principles for anaphora resolution.&amp;quot;</title>
<date>1988</date>
<journal>Journal of Semantics</journal>
<pages>6--309</pages>
<marker>Asher, Wada, 1988</marker>
<rawString>Asher, Nicholas, and Wada, Hajime (1988). &amp;quot;A computational account of syntactic, semantic and discourse principles for anaphora resolution.&amp;quot; Journal of Semantics 6:309-344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Bosch</author>
</authors>
<title>Some good reasons for shallow pronoun processing.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, IBM Conference on Natural Language Processing.</booktitle>
<location>New York: Thornwood.</location>
<marker>Bosch, 1988</marker>
<rawString>Bosch, Peter (1988). &amp;quot;Some good reasons for shallow pronoun processing.&amp;quot; In Proceedings, IBM Conference on Natural Language Processing. New York: Thornwood.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Brennan</author>
<author>Marilyn Friedman</author>
<author>Carl Pollard</author>
</authors>
<title>A centering approach to pronouns.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>155--162</pages>
<contexts>
<context position="62708" citStr="Brennan et al. 1987" startWordPosition="9975" endWordPosition="9978">ference for intersentential antecedents is inappropriate for at least some text domains—in our corpus of computer manual texts, for example, we estimate that less than 20% of referentially used third person pronouns have intersentential antecedents.&apos; There is a second difficulty with the Brennan et al. centering algorithm. It uses a hierarchy of grammatical roles quite similar to that of RAP, but this role hierarchy does not directly influence antecedent selection. Whereas the hierarchy in RAP contributes to a multi-dimensional measure of the relative salience of all antecedent candidates, in Brennan et al. 1987, it is used only to constrain the choice of the backward-looking center, Cb, of an utterance. It does not serve as a general preference measure for antecedence. The items in the forward center list, Cf, are ranked according to the hierarchy of grammatical roles. For an utterance Un, Cb(Un) is required to be the highest ranked element of Cf (1.1i) that is realized in U. If an element E in the list of possible 22 &amp;quot;A discourse segment consists of a sequence of utterances 111, . . , Um. With each utterance, Un is associated with a list of forward-looking centers, Cf (U„), consisting of those disc</context>
</contexts>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>Brennan, Susan; Friedman, Marilyn; and Pollard, Carl (1987). &amp;quot;A centering approach to pronouns.&amp;quot; In Proceedings, 25th Annual Meeting of the Association for Computational Linguistics, 155-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Ralf Brown</author>
</authors>
<title>Anaphora resolution: A multi-strategy approach.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, 12th International Conference on Computational Linguistics,</booktitle>
<pages>96--101</pages>
<marker>Carbonell, Brown, 1988</marker>
<rawString>Carbonell, Jaime, and Brown, Ralf (1988). &amp;quot;Anaphora resolution: A multi-strategy approach.&amp;quot; In Proceedings, 12th International Conference on Computational Linguistics, 96-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
</authors>
<title>Multilingual statistical approaches for natural language disambiguation&amp;quot; (in Hebrew). Doctoral dissertation,</title>
<date>1992</date>
<institution>Israel Institute of Technology,</institution>
<location>Haifa,</location>
<contexts>
<context position="3605" citStr="Dagan (1992)" startWordPosition="547" endWordPosition="548">visiting scientist at the IBM Germany Scientific Center. © 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 4 In Section 2 we present RAP and discuss its main properties. We provide examples of its output for different sorts of cases in Section 3. Most of these examples are taken from the computer manual texts on which we trained the algorithm. We give the results of a blind test in Section 4, as well as an analysis of the relative contributions of the algorithm&apos;s components to the overall success rate. In Section 5 we discuss a procedure developed by Dagan (1992) for using statistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings of antecedent candidates. We present the results of a comparative blind test of RAP and this procedure. Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature. 2. The Anaphora Resolution Algorithm RAP contains the following main components. • An intrasentential syntactic filter for ruling out anaphoric dependence of a pronoun on an NP on syntactic grounds (This filter is presented in Lappin and McCord 1990a.</context>
<context position="44680" citStr="Dagan (1992)" startWordPosition="7057" endWordPosition="7058">ms of clausal and NP boundaries, may be more effective than the current mechanisms for nonadverbial and head emphasis.&apos; Empirical studies of patterns of pronominal anaphora in corpora (ideally in accurately and uniformly parsed corpora) could be helpful in defining the most effective measures of structural salience. One might use such studies to obtain statistical data for determining the reliability of each proposed measure as a predictor of the antecedent—anaphor relation and the orthogonality (independence) of all proposed measures. 5. Salience and Statistically Measured Lexical Preference Dagan (1992) constructs a procedure, which he refers to as RAPSTAT, for using statistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings of antecedent candidates. RAPSTAT assigns a statistical score to each element of a candidate list that RAP generates; this score is intended to provide a measure (relative to a corpus) of the preference that lexical semantic/pragmatic factors impose upon the candidate as a possible antecedent for a given pronoun.&apos; 14 Such a distance measure is reminiscent of Hobbs&apos; (1978) tree search procedure. See Section 6.1 for a discussion of Hobbs&apos; algo</context>
<context position="49299" citStr="Dagan 1992" startWordPosition="7829" endWordPosition="7830">We then constructed a test set of pronouns by randomly selecting from the corpus sentences containing at least one non-pleonastic third person pronoun occurrence. For each such sentence in the set, we included the sentence that immediately precedes it in the text (when the preceding sentence does not contain a pronoun).&apos; We filtered the test set so that for each pronoun occurrence in the set, (i) RAP generates a candidate list with at least two elements, (ii) the actual antecedent NP appears in the candidate list, and (iii) there is a total tuple frequency greater than 1 for the candidate See Dagan 1992 and Dagan et al. (in press) for a discussion of this lexical statistical approach to ranking antecedent candidates and possible alternatives. 16 In the interests of simplicity and uniformity we discarded sentence pairs in which the first sentence contains a pronoun. We decided to limit the text preceding the sentence containing the pronoun to one sentence because we found that in the manuals which we used to tune the algorithm, almost all cases of intersentential anaphora involved an antecedent in the immediately preceding sentence. Moreover, the progressive decline in the salience values of </context>
<context position="53349" citStr="Dagan (1992)" startWordPosition="8469" endWordPosition="8470">pronoun in approximately 98% of the cases to which it applies. 18 We take RAPSTAT as deciding a case when it considers at least two candidates rather than deferring to RAP after the initial candidate because of a large salience difference between this candidate and the next one in the list. In cases in which RAPSTAT does not make an independent decision, it endorses RAP&apos;s selection. RAPSTAT&apos;s total success rate includes both sorts of cases. 19 John Justeson did the statistical analysis of the comparative blind test of RAP and RAPSTAT. These results are described in Dagan et al. (in press). 20 Dagan (1992) reaches a similar conclusion on the basis of a much smaller experiment. 554 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 6.1 Hobbs&apos; Algorithm Hobbs&apos; (1978) algorithm relies on a simple tree search procedure formulated in terms of depth of embedding and left—right order. By contrast, RAP uses a multi-dimensional measure of salience that invokes a variety of syntactic properties specified in terms of the head—argument structures of Slot Grammar, as well as a model of attentional state. Hobbs&apos; tree search procedure selects the first candidate encountered by </context>
</contexts>
<marker>Dagan, 1992</marker>
<rawString>Dagan, Ido (1992). &amp;quot;Multilingual statistical approaches for natural language disambiguation&amp;quot; (in Hebrew). Doctoral dissertation, Israel Institute of Technology, Haifa, Israel.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ido Dagan</author>
<author>John Justeson</author>
<author>Shalom Lappin</author>
</authors>
<title>Leass, Herbert; and Ribak, Amnon (in press). &amp;quot;Syntax and lexical statistics in anaphora resolution.&amp;quot;</title>
<journal>Applied Artificial Intelligence.</journal>
<marker>Dagan, Justeson, Lappin, </marker>
<rawString>Dagan, Ido; Justeson, John; Lappin, Shalom; Leass, Herbert; and Ribak, Amnon (in press). &amp;quot;Syntax and lexical statistics in anaphora resolution.&amp;quot; Applied Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Aravind Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Providing a unified account of definite noun phrases in discourse.&amp;quot;</title>
<date>1983</date>
<booktitle>In Proceedings, 21st Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>44--50</pages>
<marker>Grosz, Joshi, Weinstein, 1983</marker>
<rawString>Grosz, Barbara; Joshi, Aravind; and Weinstein, Scott (1983). &amp;quot;Providing a unified account of definite noun phrases in discourse.&amp;quot; In Proceedings, 21st Annual Meeting of the Association of Computational Linguistics, 44-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Aravind Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>unpublished). &amp;quot;Towards a computational theory of discourse interpretation.&amp;quot;</title>
<date>1986</date>
<institution>Harvard University and University of Pennsylvania.</institution>
<marker>Grosz, Joshi, Weinstein, 1986</marker>
<rawString>Grosz, Barbara; Joshi, Aravind; and Weinstein, Scott (1986, unpublished). &amp;quot;Towards a computational theory of discourse interpretation.&amp;quot; Harvard University and University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candice Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.&amp;quot;</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<pages>12--175</pages>
<contexts>
<context position="2557" citStr="Grosz and Sidner 1986" startWordPosition="374" endWordPosition="377">f Anaphora Procedure). RAP applies to the syntactic structures of McCord&apos;s (1990, 1993, in press) Slot Grammar parser, and like the parser, it is implemented in Prolog. It relies on measures of salience derived from syntactic structure and a simple dynamic model of attentional state to select the antecedent noun phrase (NP) of a pronoun from a list of candidates. It does not employ semantic conditions (beyond those implicit in grammatical number and gender agreement) or real-world knowledge in evaluating candidate antecedents; nor does it model intentional or global discourse structure (as in Grosz and Sidner 1986). * School of Oriental and African Studies, University of London, London WC1H OXG, UK. E-mail: slappin@clus1.ulcc.ac.uk Most of the first author&apos;s work on this paper was done while he was a Research Staff Member in the Computer Science Department of the IBM T.J. Watson Research Center. t Sietec Systemtechnik (Siemens AG), D-13623 Berlin, Germany. E-mail: leass@sietec.de The second author&apos;s work on this paper was done while he was a visiting scientist at the IBM Germany Scientific Center. © 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 4 In Section 2</context>
<context position="59407" citStr="Grosz and Sidner (1986)" startWordPosition="9495" endWordPosition="9498">res used by RAP have application to a wider class of languages than Hobbs&apos; order-based search procedure. This procedure relies on a correspondence of grammatical roles and linear precedence relations that holds for a comparatively small class of languages. 6.2 Discourse Based Methods Most of the work in this area seeks to formulate general principles of discourse structure and interpretation and to integrate methods of anaphora resolution into a computational model of discourse interpretation (and sometimes of generation as well). Sidner (1981, 1983), Grosz, Joshi, and Weinstein (1983, 1986), Grosz and Sidner (1986), 21 The difficulty that RAP encounters with such cases was discussed in Section 4.1. We are experimenting with refinements in RAP&apos;s scoring mechanism to improve its performance in these and other cases. 556 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution Brennan, Friedman, and Pollard (1987), and Webber (1988) present different versions of this approach. Dynamic properties of discourse, especially coherence and focusing, are invoked as the primary basis for identifying antecedence candidates; selecting a candidate as the antecedent of a pronoun in discourse </context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara, and Sidner, Candice (1986). &amp;quot;Attention, intentions, and the structure of discourse.&amp;quot; Computational Linguistics 12:175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Guenthner</author>
<author>Hubert Lehmann</author>
</authors>
<title>Rules for pronominalization.&amp;quot;</title>
<date>1983</date>
<booktitle>In Proceedings, First Annual Meeting of the European Chapter of the ACL,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="5932" citStr="Guenthner and Lehmann (1983)" startWordPosition="899" endWordPosition="902"> linked NPs as an equivalence class for which a global salience value is computed as the sum of the salience values of its elements. • A decision procedure for selecting the preferred element of a list of antecedent candidates for a pronoun. 1 This hierarchy is more or less identical to the NP accessibility hierarchy proposed by Keenan and Comrie (1977). Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraints on syntactic relations, including reflexive binding. Lappin (1985) employs it as a salience hierarchy to state a non-coreference constraint for pronouns. Guenthner and Lehmann (1983) use a similar salience ranking of grammatical roles to formulate rules of anaphora resolution. Centering approaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 2.1 Some Preliminary Details RAP has been implemented for both ESG and GSG (English and German Slot Grammars); we will limit ourselves here to a discussion of the English version. The differences between the two versions are at present minimal, primarily owing to the fact </context>
</contexts>
<marker>Guenthner, Lehmann, 1983</marker>
<rawString>Guenthner, Franz, and Lehmann, Hubert (1983). &amp;quot;Rules for pronominalization.&amp;quot; In Proceedings, First Annual Meeting of the European Chapter of the ACL, 144-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Resolving pronoun references.&amp;quot;</title>
<date>1978</date>
<journal>Lingua</journal>
<pages>44--311</pages>
<marker>Hobbs, 1978</marker>
<rawString>Hobbs, Jerry (1978). &amp;quot;Resolving pronoun references.&amp;quot; Lingua 44:311-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Johnson</author>
</authors>
<title>On relational constraints on grammars.&amp;quot;</title>
<date>1977</date>
<booktitle>In Syntax and Semantics 8, edited</booktitle>
<pages>151--178</pages>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="5675" citStr="Johnson (1977)" startWordPosition="864" endWordPosition="865">(ii) direct objects over other complements, (iii) arguments of a verb over adjuncts and objects of prepositional phrase (PP) adjuncts of the verb, and (iv) head nouns over complements of head nouns.1 • A procedure for identifying anaphorically linked NPs as an equivalence class for which a global salience value is computed as the sum of the salience values of its elements. • A decision procedure for selecting the preferred element of a list of antecedent candidates for a pronoun. 1 This hierarchy is more or less identical to the NP accessibility hierarchy proposed by Keenan and Comrie (1977). Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraints on syntactic relations, including reflexive binding. Lappin (1985) employs it as a salience hierarchy to state a non-coreference constraint for pronouns. Guenthner and Lehmann (1983) use a similar salience ranking of grammatical roles to formulate rules of anaphora resolution. Centering approaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 2.1 Some Prelimi</context>
</contexts>
<marker>Johnson, 1977</marker>
<rawString>Johnson, David (1977). &amp;quot;On relational constraints on grammars.&amp;quot; In Syntax and Semantics 8, edited by P. Cole and J. Sadock, 151-178. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
</authors>
<title>A theory of truth and semantic representation.&amp;quot;</title>
<date>1981</date>
<booktitle>In Formal Methods in the Study of Language,</booktitle>
<note>edited by</note>
<contexts>
<context position="18429" citStr="Kamp 1981" startWordPosition="2991" endWordPosition="2992">penalizes NPs in certain embedded constructions. Examples of NPs not receiving non-adverbial emphasis are Throughout the first section of this guide, these symbols are also used ... In the Panel definition panel, select the &amp;quot;Specify&amp;quot; option from the action bar. The initial weights for each of the above factor types are given in Table 1. Note that the relative weighting of some of these factors realizes a hierarchy of grammatical roles.&apos; 2.1.5 Equivalence Classes. We treat the antecedent—anaphor relation in much the same way as the &amp;quot;equality&amp;quot; condition of Discourse Representation Theory (DRT) (Kamp 1981), as in U = y. This indicates that the discourse referent u, evoked by an anaphoric NP, is anaphorically linked to a previously introduced discourse referent y. To avoid confusion with 5 The specific values of the weights are arbitrary. The significance of the weighting procedure is in the comparative relations among the factors as defined by the weights. We have determined the efficacy of this relational structure of salience factors (and refined it) experimentally (see Section 4.2). 541 Computational Linguistics Volume 20, Number 4 mathematical equality (which, unlike the relation discussed </context>
</contexts>
<marker>Kamp, 1981</marker>
<rawString>Kamp, Hans (1981). &amp;quot;A theory of truth and semantic representation.&amp;quot; In Formal Methods in the Study of Language, edited by J. Groenendijk, T. Janssen, and M. Stokhof. Amsterdam: Mathematisch Centrum Tracts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Keenan</author>
<author>Bernard Comrie</author>
</authors>
<title>Noun phrase accessibility and universal grammar.&amp;quot;</title>
<date>1977</date>
<journal>Linguistic Inquiry</journal>
<pages>8--62</pages>
<contexts>
<context position="5659" citStr="Keenan and Comrie (1977)" startWordPosition="860" endWordPosition="863">ect over non-subject NPs, (ii) direct objects over other complements, (iii) arguments of a verb over adjuncts and objects of prepositional phrase (PP) adjuncts of the verb, and (iv) head nouns over complements of head nouns.1 • A procedure for identifying anaphorically linked NPs as an equivalence class for which a global salience value is computed as the sum of the salience values of its elements. • A decision procedure for selecting the preferred element of a list of antecedent candidates for a pronoun. 1 This hierarchy is more or less identical to the NP accessibility hierarchy proposed by Keenan and Comrie (1977). Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraints on syntactic relations, including reflexive binding. Lappin (1985) employs it as a salience hierarchy to state a non-coreference constraint for pronouns. Guenthner and Lehmann (1983) use a similar salience ranking of grammatical roles to formulate rules of anaphora resolution. Centering approaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution </context>
</contexts>
<marker>Keenan, Comrie, 1977</marker>
<rawString>Keenan, Edward, and Comrie, Bernard (1977). &amp;quot;Noun phrase accessibility and universal grammar.&amp;quot; Linguistic Inquiry 8:62-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
</authors>
<title>Pronominal binding and coreference.&amp;quot;</title>
<date>1985</date>
<journal>Theoretical Linguistics</journal>
<pages>12--241</pages>
<contexts>
<context position="5816" citStr="Lappin (1985)" startWordPosition="884" endWordPosition="885">erb, and (iv) head nouns over complements of head nouns.1 • A procedure for identifying anaphorically linked NPs as an equivalence class for which a global salience value is computed as the sum of the salience values of its elements. • A decision procedure for selecting the preferred element of a list of antecedent candidates for a pronoun. 1 This hierarchy is more or less identical to the NP accessibility hierarchy proposed by Keenan and Comrie (1977). Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraints on syntactic relations, including reflexive binding. Lappin (1985) employs it as a salience hierarchy to state a non-coreference constraint for pronouns. Guenthner and Lehmann (1983) use a similar salience ranking of grammatical roles to formulate rules of anaphora resolution. Centering approaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 2.1 Some Preliminary Details RAP has been implemented for both ESG and GSG (English and German Slot Grammars); we will limit ourselves here to a discussion o</context>
</contexts>
<marker>Lappin, 1985</marker>
<rawString>Lappin, Shalom (1985). &amp;quot;Pronominal binding and coreference.&amp;quot; Theoretical Linguistics 12:241-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Michael McCord</author>
</authors>
<title>A syntactic filter on pronominal anaphora in slot grammar.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 28th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>135--142</pages>
<contexts>
<context position="4203" citStr="Lappin and McCord 1990" startWordPosition="635" endWordPosition="638">eveloped by Dagan (1992) for using statistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings of antecedent candidates. We present the results of a comparative blind test of RAP and this procedure. Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature. 2. The Anaphora Resolution Algorithm RAP contains the following main components. • An intrasentential syntactic filter for ruling out anaphoric dependence of a pronoun on an NP on syntactic grounds (This filter is presented in Lappin and McCord 1990a.) • A morphological filter for ruling out anaphoric dependence of a pronoun on an NP due to non-agreement of person, number, or gender features • A procedure for identifying pleonastic (semantically empty) pronouns • An anaphor binding algorithm for identifying the possible antecedent binder of a lexical anaphor (reciprocal or reflexive pronoun) within the same sentence (This algorithm is presented in Lappin and McCord 1990b.) • A procedure for assigning values to several salience parameters (grammatical role, parallelism of grammatical roles, frequency of mention, proximity, and sentence re</context>
</contexts>
<marker>Lappin, McCord, 1990</marker>
<rawString>Lappin, Shalom, and McCord, Michael (1990a). &amp;quot;A syntactic filter on pronominal anaphora in slot grammar.&amp;quot; In Proceedings, 28th Annual Meeting of the Association for Computational Linguistics, 135-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Michael McCord</author>
</authors>
<title>Anaphora resolution in slot grammar.&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<pages>16--197</pages>
<contexts>
<context position="4203" citStr="Lappin and McCord 1990" startWordPosition="635" endWordPosition="638">eveloped by Dagan (1992) for using statistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings of antecedent candidates. We present the results of a comparative blind test of RAP and this procedure. Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature. 2. The Anaphora Resolution Algorithm RAP contains the following main components. • An intrasentential syntactic filter for ruling out anaphoric dependence of a pronoun on an NP on syntactic grounds (This filter is presented in Lappin and McCord 1990a.) • A morphological filter for ruling out anaphoric dependence of a pronoun on an NP due to non-agreement of person, number, or gender features • A procedure for identifying pleonastic (semantically empty) pronouns • An anaphor binding algorithm for identifying the possible antecedent binder of a lexical anaphor (reciprocal or reflexive pronoun) within the same sentence (This algorithm is presented in Lappin and McCord 1990b.) • A procedure for assigning values to several salience parameters (grammatical role, parallelism of grammatical roles, frequency of mention, proximity, and sentence re</context>
</contexts>
<marker>Lappin, McCord, 1990</marker>
<rawString>Lappin, Shalom, and McCord, Michael (1990b). &amp;quot;Anaphora resolution in slot grammar.&amp;quot; Computational Linguistics 16:197-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bosch</author>
</authors>
<title>suggests a psychological processing model in which hearers rely on first pass syntactically based strategies for initial linking of pronouns to antecedent NPs.</title>
<date>1988</date>
<marker>Bosch, 1988</marker>
<rawString>27 Bosch (1988) suggests a psychological processing model in which hearers rely on first pass syntactically based strategies for initial linking of pronouns to antecedent NPs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Leass</author>
<author>Ulrike Schwa11</author>
</authors>
<title>An anaphora resolution procedure for machine translation.&amp;quot;</title>
<date>1991</date>
<tech>IWBS Report 172,</tech>
<institution>IBM Germany Scientific Center,</institution>
<location>Heidelberg, Germany.</location>
<marker>Leass, Schwa11, 1991</marker>
<rawString>Leass, Herbert, and Schwa11, Ulrike (1991). &amp;quot;An anaphora resolution procedure for machine translation.&amp;quot; IWBS Report 172, IBM Germany Scientific Center, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
</authors>
<title>Design of LMT: A prolog-based machine translation system.&amp;quot;</title>
<date>1989</date>
<journal>Computational Linguistics</journal>
<pages>15--33</pages>
<contexts>
<context position="6651" citStr="McCord 1989" startWordPosition="1017" endWordPosition="1018">proaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 2.1 Some Preliminary Details RAP has been implemented for both ESG and GSG (English and German Slot Grammars); we will limit ourselves here to a discussion of the English version. The differences between the two versions are at present minimal, primarily owing to the fact that we have devoted most of our attention to analysis of English. As with Slot Grammar systems in general (McCord 1989b, 1993, in press), an architecture was adopted that &amp;quot;factors out&amp;quot; language-specific elements of the algorithm. We have integrated RAP into McCord&apos;s (1989a, 1989b) Logic-Based Machine Translation System (LMT). (We are grateful to Michael McCord and Ullrike Schwa11 for their help in implementing this integration.) When the algorithm identifies the antecedent of a pronoun in the source language, the agreement features of the head of the NP corresponding to the antecedent in the target language are used to generate the pronoun in the target language. Thus, for example, neuter third person pronoun</context>
</contexts>
<marker>McCord, 1989</marker>
<rawString>McCord, Michael (1989a). &amp;quot;Design of LMT: A prolog-based machine translation system.&amp;quot; Computational Linguistics 15:33-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
</authors>
<title>A new version of the machine translation system LMT.&amp;quot;</title>
<date>1989</date>
<journal>Literary and Linguistic Computing</journal>
<pages>4--218</pages>
<contexts>
<context position="6651" citStr="McCord 1989" startWordPosition="1017" endWordPosition="1018">proaches to anaphora resolution use similar hierarchies as well (Brennan, Friedman, and Pollard 1987; Walker, Iida, and Cote 1990). 536 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution 2.1 Some Preliminary Details RAP has been implemented for both ESG and GSG (English and German Slot Grammars); we will limit ourselves here to a discussion of the English version. The differences between the two versions are at present minimal, primarily owing to the fact that we have devoted most of our attention to analysis of English. As with Slot Grammar systems in general (McCord 1989b, 1993, in press), an architecture was adopted that &amp;quot;factors out&amp;quot; language-specific elements of the algorithm. We have integrated RAP into McCord&apos;s (1989a, 1989b) Logic-Based Machine Translation System (LMT). (We are grateful to Michael McCord and Ullrike Schwa11 for their help in implementing this integration.) When the algorithm identifies the antecedent of a pronoun in the source language, the agreement features of the head of the NP corresponding to the antecedent in the target language are used to generate the pronoun in the target language. Thus, for example, neuter third person pronoun</context>
</contexts>
<marker>McCord, 1989</marker>
<rawString>McCord, Michael (1989b). &amp;quot;A new version of the machine translation system LMT.&amp;quot; Literary and Linguistic Computing 4:218-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
</authors>
<title>Slot grammar: A system for simpler construction of practical natural language grammars.&amp;quot;</title>
<date>1990</date>
<booktitle>In Natural Language and Logic: International Scientific Symposium, edited by R. Studer, 118-145. Lecture Notes in Computer Science,</booktitle>
<publisher>Springer Verlag.</publisher>
<location>Berlin:</location>
<contexts>
<context position="4203" citStr="McCord 1990" startWordPosition="637" endWordPosition="638"> Dagan (1992) for using statistically measured lexical preference patterns to reevaluate RAP&apos;s salience rankings of antecedent candidates. We present the results of a comparative blind test of RAP and this procedure. Finally, in Section 6 we compare RAP to several other approaches to anaphora resolution that have been proposed in the computational literature. 2. The Anaphora Resolution Algorithm RAP contains the following main components. • An intrasentential syntactic filter for ruling out anaphoric dependence of a pronoun on an NP on syntactic grounds (This filter is presented in Lappin and McCord 1990a.) • A morphological filter for ruling out anaphoric dependence of a pronoun on an NP due to non-agreement of person, number, or gender features • A procedure for identifying pleonastic (semantically empty) pronouns • An anaphor binding algorithm for identifying the possible antecedent binder of a lexical anaphor (reciprocal or reflexive pronoun) within the same sentence (This algorithm is presented in Lappin and McCord 1990b.) • A procedure for assigning values to several salience parameters (grammatical role, parallelism of grammatical roles, frequency of mention, proximity, and sentence re</context>
</contexts>
<marker>McCord, 1990</marker>
<rawString>McCord, Michael (1990). &amp;quot;Slot grammar: A system for simpler construction of practical natural language grammars.&amp;quot; In Natural Language and Logic: International Scientific Symposium, edited by R. Studer, 118-145. Lecture Notes in Computer Science, Berlin: Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
</authors>
<title>Heuristics for broad-coverage natural language parsing.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, ARPA Human Language Technology Workshop,</booktitle>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="37184" citStr="McCord (1993)" startWordPosition="5904" endWordPosition="5905">ords.&apos; The results which we obtained for the test corpus (without any further modifications of RAP) are given in Table 3.13 This blind test provides the basis for a comparative evaluation of RAP and Dagan&apos;s • 9 These sentences and those used in the blind test were edited slightly to overcome parse inaccuracies. Rather than revise the lexicon, we made lexical substitutions to improve parses. In some cases constructions had to be simplified. However, such changes did not alter the syntactic relations among the pronoun and its possible antecedents. For a discussion of ESG&apos;s parsing accuracy, see McCord (1993). 10 See comments at the end of Section 4 about refining RAP&apos;s measures of structural salience. 11 Forty-three of the pronoun occurrences in the training corpus 8%) were pleonastic; a random sample of 245 pronoun occurrences extracted from our test corpus included 15 pleonastic pronouns (— 6%). 12 The test set was filtered in order to satisfy the conditions of our experiments on the role of statistically measured lexical preference in enhancing RAP&apos;s performance. See Section 5.1 for a discussion of these 549 Computational Linguistics Volume 20, Number 4 Table 3 Results of blind test Total Inte</context>
</contexts>
<marker>McCord, 1993</marker>
<rawString>McCord, Michael (1993). &amp;quot;Heuristics for broad-coverage natural language parsing.&amp;quot; In Proceedings, ARPA Human Language Technology Workshop, University of Pennsylvania.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael McCord</author>
</authors>
<title>The slot grammar system.&amp;quot;</title>
<booktitle>In Unification in Grammar, edited by Jurgen Wedekin and Christian Rohrer (also IBM Research Report RC 17313).</booktitle>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>McCord, </marker>
<rawString>McCord, Michael (in press). &amp;quot;The slot grammar system.&amp;quot; In Unification in Grammar, edited by Jurgen Wedekin and Christian Rohrer (also IBM Research Report RC 17313). Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael McCord</author>
<author>Arendse Bernth</author>
<author>Shalom Lappin</author>
<author>Wlodek Zadrozny</author>
</authors>
<title>Natural language processing within a slot grammar framework.&amp;quot;</title>
<date>1992</date>
<journal>International Journal on Artificial Intelligence Tools</journal>
<pages>1--229</pages>
<contexts>
<context position="7514" citStr="McCord et al. 1992" startWordPosition="1152" endWordPosition="1155"> and Ullrike Schwa11 for their help in implementing this integration.) When the algorithm identifies the antecedent of a pronoun in the source language, the agreement features of the head of the NP corresponding to the antecedent in the target language are used to generate the pronoun in the target language. Thus, for example, neuter third person pronouns in English are mapped into pronouns with the correct gender feature in German, in which inanimate nouns are marked for gender. RAP operates primarily on a clausal representation of the Slot Grammar analysis of the current sentence in a text (McCord et al. 1992). The clausal representation consists of a set of Prolog unit clauses that provide information on the head—argument and head—adjunct relations of the phrase structure that the Slot Grammar assigns to a sentence (phrase). Clausal representations of the previous four sentences in the text are retained in the Prolog workspace. The discourse representation used by our algorithm consists of these clausal representations, together with additional unit clauses declaring discourse referents evoked by NPs in the text and specifying anaphoric links among discourse referents.2 All information pertaining </context>
</contexts>
<marker>McCord, Bernth, Lappin, Zadrozny, 1992</marker>
<rawString>McCord, Michael; Bernth, Arendse; Lappin, Shalom; and Zadrozny, Wlodek (1992). &amp;quot;Natural language processing within a slot grammar framework.&amp;quot; International Journal on Artificial Intelligence Tools 1:229-277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Rich</author>
<author>Susann LuperFoy</author>
</authors>
<title>An architecture for anaphora resolution.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>18--24</pages>
<marker>Rich, LuperFoy, 1988</marker>
<rawString>Rich, Elaine, and LuperFoy, Susann (1988). &amp;quot;An architecture for anaphora resolution.&amp;quot; In Proceedings, ACL Conference on Applied Natural Language Processing, 18-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candice Sidner</author>
</authors>
<title>Focusing for interpretation of pronouns.&amp;quot;</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics</journal>
<pages>7--217</pages>
<contexts>
<context position="59333" citStr="Sidner (1981" startWordPosition="9486" endWordPosition="9487">ce in the predictions of the two algorithms. The salience measures used by RAP have application to a wider class of languages than Hobbs&apos; order-based search procedure. This procedure relies on a correspondence of grammatical roles and linear precedence relations that holds for a comparatively small class of languages. 6.2 Discourse Based Methods Most of the work in this area seeks to formulate general principles of discourse structure and interpretation and to integrate methods of anaphora resolution into a computational model of discourse interpretation (and sometimes of generation as well). Sidner (1981, 1983), Grosz, Joshi, and Weinstein (1983, 1986), Grosz and Sidner (1986), 21 The difficulty that RAP encounters with such cases was discussed in Section 4.1. We are experimenting with refinements in RAP&apos;s scoring mechanism to improve its performance in these and other cases. 556 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution Brennan, Friedman, and Pollard (1987), and Webber (1988) present different versions of this approach. Dynamic properties of discourse, especially coherence and focusing, are invoked as the primary basis for identifying antecedence cand</context>
</contexts>
<marker>Sidner, 1981</marker>
<rawString>Sidner, Candice (1981). &amp;quot;Focusing for interpretation of pronouns.&amp;quot; American Journal of Computational Linguistics 7:217-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candice Sidner</author>
</authors>
<title>Focusing in the comprehension of definite anaphora.&amp;quot;</title>
<date>1983</date>
<booktitle>In Computational Models of Discourse, edited by Michael Brady and</booktitle>
<pages>267--330</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Sidner, 1983</marker>
<rawString>Sidner, Candice (1983). &amp;quot;Focusing in the comprehension of definite anaphora.&amp;quot; In Computational Models of Discourse, edited by Michael Brady and Robert Berwick, 267-330. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
</authors>
<title>Evaluating discourse processing algorithms.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>251--261</pages>
<marker>Walker, 1989</marker>
<rawString>Walker, Marilyn (1989). &amp;quot;Evaluating discourse processing algorithms.&amp;quot; In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics, 251-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Masayo Iida</author>
<author>Sharon Cote</author>
</authors>
<title>Centering in Japanese discourse.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 13th International Conference on Computational Linguistics,</booktitle>
<pages>1--6</pages>
<marker>Walker, Iida, Cote, 1990</marker>
<rawString>Walker, Marilyn; Iida, Masayo; and Cote, Sharon (1990). &amp;quot;Centering in Japanese discourse.&amp;quot; In Proceedings, 13th International Conference on Computational Linguistics, 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
</authors>
<title>Discourse Deixis: Reference to discourse segments.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>113--121</pages>
<contexts>
<context position="59754" citStr="Webber (1988)" startWordPosition="9550" endWordPosition="9551">iscourse structure and interpretation and to integrate methods of anaphora resolution into a computational model of discourse interpretation (and sometimes of generation as well). Sidner (1981, 1983), Grosz, Joshi, and Weinstein (1983, 1986), Grosz and Sidner (1986), 21 The difficulty that RAP encounters with such cases was discussed in Section 4.1. We are experimenting with refinements in RAP&apos;s scoring mechanism to improve its performance in these and other cases. 556 Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution Brennan, Friedman, and Pollard (1987), and Webber (1988) present different versions of this approach. Dynamic properties of discourse, especially coherence and focusing, are invoked as the primary basis for identifying antecedence candidates; selecting a candidate as the antecedent of a pronoun in discourse involves additional constraints of a syntactic, semantic, and pragmatic nature. In developing our algorithm, we have not attempted to consider elements of discourse structure beyond the simple model of attentional state realized by equivalence classes of discourse referents, salience degradation, and the sentence recency salience factor. The res</context>
</contexts>
<marker>Webber, 1988</marker>
<rawString>Webber, Bonnie (1988). &amp;quot;Discourse Deixis: Reference to discourse segments.&amp;quot; In Proceedings, 26th Annual Meeting of the Association for Computational Linguistics, 113-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edwin Williams</author>
</authors>
<title>Grammatical relations.&amp;quot;</title>
<date>1984</date>
<journal>Linguistic Inquiry</journal>
<pages>15--639</pages>
<marker>Williams, 1984</marker>
<rawString>Williams, Edwin (1984). &amp;quot;Grammatical relations.&amp;quot; Linguistic Inquiry 15:639-673.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>