<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.284714">
<title confidence="0.997249">
Bridging the Inflection Morphology Gap for Arabic Statistical Machine
Translation
</title>
<author confidence="0.992182">
Andreas Zollmann and Ashish Venugopal and Stephan Vogel
</author>
<affiliation confidence="0.9800765">
School of Computer Science
Carnegie Mellon University
</affiliation>
<email confidence="0.997455">
{zollmann,ashishv,stephan.vogel}@cs.cmu.edu
</email>
<sectionHeader confidence="0.995622" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999789588235294">
Statistical machine translation (SMT) is
based on the ability to effectively learn
word and phrase relationships from par-
allel corpora, a process which is consid-
erably more difficult when the extent of
morphological expression differs signifi-
cantly across the source and target lan-
guages. We present techniques that se-
lect appropriate word segmentations in
the morphologically rich source language
based on contextual relationships in the
target language. Our results take ad-
vantage of existing word level morpho-
logical analysis components to improve
translation quality above state-of-the-art
on a limited-data Arabic to English speech
translation task.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999251777777778">
The problem of translating from a language ex-
hibiting rich inflectional morphology to a language
exhibiting relatively poor inflectional morphology
presents several challenges to the existing compo-
nents of the statistical machine translation (SMT)
process. This inflection gap causes an abundance of
surface word forms 1 in the source language com-
pared with relatively few forms in the target lan-
guage. This mismatch aggravates several issues
</bodyText>
<footnote confidence="0.713233">
1We use the term surface form to refer to a series of charac-
ters separated by whitespace
</footnote>
<bodyText confidence="0.999412424242424">
found in natural language processing: more un-
known words forms in unseen data, more words oc-
curring only once, more distinct words and lower
token-to-type ratios (mean number of occurrences
over all distinct words) in the source language than
in the target language.
Lexical relationships under the standard IBM
models (Brown et al., 1993) do not account for
many-to-many mappings, and phrase extraction re-
lies heavily on the accuracy of the IBM word-to-
word alignment. In this work, we propose an ap-
proach to bridge the inflectional gap that addresses
the issues described above through a series of pre-
processing steps based on the Buckwalter Arabic
Morphological Analyzer (BAMA) tool (Buckwalter,
2004). While (Lee et al., 2003) develop accurate
segmentation models of Arabic surface word forms
using manually segmented data, we rely instead on
the translated context in the target language, lever-
aging the manually constructed lexical gloss from
BAMA to select the appropriate segmented sense for
each Arabic source word.
Our technique, applied as preprocessing to the
source corpus, splits and normalizes surface words
based on the target sentence context. In contrast
to (Popovic and Ney, 2004) and (Nießen and Ney,
2004), we do not modify the IBM models, and we
leave reordering effects to the decoder. Statistically
significant improvements (Zhang and Vogel, 2004)
in BLEU and NIST translation score over a lightly
stemmed baseline are reported on the available and
well known BTEC IWSLT’05 Arabic-English cor-
pus (Eck and Hori, 2005).
</bodyText>
<page confidence="0.971147">
201
</page>
<note confidence="0.9232595">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.696846" genericHeader="method">
2 Arabic Morphology in Recent Work
</sectionHeader>
<bodyText confidence="0.99995906060606">
Arabic-to-English machine translation exemplifies
some of the issues caused by the inflection gap. Re-
fer to (Buckwalter, 2005) and (Larkey et al., 2002)
for examples that highlight morphological inflection
for a simple Modern Standard Arabic (MSA) word
and basic stemming operations that we use as our
baseline system.
(Nießen and Ney, 2000) tackle the inflection gap
for German-to-English word alignment by perform-
ing a series of morphological operations on the Ger-
man text. They fragment words based on a full
morphological analysis of the sentence, but need to
use domain specific and hand written rules to deal
with ambiguous fragmentation. (Nießen and Ney,
2004) also extend the corpus by annotating each
source word with morphological information and
building a hierarchical lexicon. The experimental
results show dramatic improvements from sentence-
level restructuring (question inversion, separated
verb prefixes and merging phrases), but limited im-
provement from the hierarchical lexicon, especially
as the size of the training data increases.
We conduct our morphological analysis at the
word level, using Buckwalter Arabic Morphological
Analyzer (BAMA) version 2.0 (Buckwalter, 2004).
BAMA analyzes a given surface word, returning a
set of potential segmentations (order of a dozen) for
the source word into prefixes, stems, and suffixes.
Our techniques select the appropriate splitting from
that set by taking into account the target sides (full
sentences) of that word’s occurrences in the training
corpus. We now describe each splitting technique
that we apply.
</bodyText>
<subsectionHeader confidence="0.96856">
2.1 BAMA: Simple fragment splitting
</subsectionHeader>
<bodyText confidence="0.9999728">
We begin by simply replacing each Arabic word
with the fragments representing the first of the pos-
sible splittings returned by the BAMA tool. BAMA
uses simple word-based heuristics to rank the split-
ting alternatives.
</bodyText>
<subsectionHeader confidence="0.993724">
2.2 CONTEXT: Single Sense selection
</subsectionHeader>
<bodyText confidence="0.999893555555556">
In the step CONTEXT, we take advantage of the
gloss information provided in BAMA’s lexicon.
Each potential splitting corresponds to a particular
choice of prefix, stem and suffix, all of which exist
in the manually constructed lexicon, along with a set
of possible translations (glosses) for each fragment.
We select a fragmentation (choice of splitting for the
source word) whose corresponding glosses have the
most target side matches in the parallel translation
(of the full sentence). The choice of fragmentation
is saved and used for all occurrences of the surface
form word in training and testing, introducing con-
text sensitivity without parsing solutions. In case of
unseen words during testing, we segment it simply
using the first alternative from the BAMA tool. This
allows us to still translate an unseen test word cor-
rectly even if the surface form was never seen during
training.
</bodyText>
<subsectionHeader confidence="0.942927">
2.3 CORRMATCH: Correspondence matching
</subsectionHeader>
<bodyText confidence="0.999798764705882">
The Arabic language often encodes linguistic in-
formation within the surface word form that is not
present in English. Word fragments that represent
this missing information are misleading in the trans-
lation process unless explicitly aligned to the NULL
word on the target side. In this step we explicitly
remove fragments that correspond to lexical infor-
mation that is not represented in English. While
(Lee, 2004) builds part of speech models to recog-
nize such elements, we use the fact that their corre-
sponding English translations in the BAMA lexicon
are empty. Examples of such fragments are case and
gender markers. As an example of CORRMATCH
removal, we present the Arabic sentence ” h‘*A lA
ya zAl u gayor naZiyf ” (after BAMA only) which
becomes ”h‘*A lA ya zAl gayor naZiyf” after the
CORRMATCH stage. The ”u” has been removed.
</bodyText>
<sectionHeader confidence="0.999599" genericHeader="method">
3 Experimental Framework
</sectionHeader>
<bodyText confidence="0.99997275">
We evaluate the impact of inflectional splitting on
the BTEC (Takezawa et al., 2002) IWSLT05 Ara-
bic language data track. The “Supplied” data track
includes a 20K Arabic/English sentence pair train-
ing set, as well as a development (“DevSet”) and
test (“Test05”) set of 500 Arabic sentences each and
16 reference translations per Arabic sentence. De-
tails regarding the IWSLT evaluation criteria and
data topic and collection methods are available in
(Eck and Hori, 2005). We also evaluate on test and
development data randomly sampled from the com-
plete supplied dev and test data, due to considera-
</bodyText>
<page confidence="0.995817">
202
</page>
<bodyText confidence="0.999796">
tions noted by (Josep M.Crego, 2005) regarding the
similarity of the development and test data sets.
</bodyText>
<subsectionHeader confidence="0.99892">
3.1 System description
</subsectionHeader>
<bodyText confidence="0.998345777777778">
Translation experiments were conducted using the
(Vogel et al., 2003) system with reordering and fu-
ture cost estimation. We trained translation parame-
ters for 10 scores (language model, word and phrase
count, and 6 translation model scores from (Vogel,
2005) ) with Minimum Error Rate training on the
development set. We optimized separately for both
the NIST (Doddington, 2002) and the BLEU metrics
(Papineni et al., 2002).
</bodyText>
<sectionHeader confidence="0.994155" genericHeader="method">
4 Translation Results
</sectionHeader>
<bodyText confidence="0.999916086956522">
Table 1 and 2 shows the results of each stage
of inflectional splitting on the BLEU and NIST
metrics. Basic orthographic normalization serves
as a baseline (merging all Alif, tar marbuta, ee
forms to the base form). The test set NIST scores
show steady improvements of up to 5 percent rel-
ative, as more sophisticated splitting techniques
are used, ie BAMA+CONTEXT+CORRMATCH.
These improvements are statistically significant over
the baseline in both metrics as measured by the tech-
niques in (Zhang and Vogel, 2004).
Our NIST results for all the final stages of inflec-
tional splitting would place us above the top NIST
scores from the ISWLT evaluation on the supplied
test set.2 On both DevSet/Test05 and the randomly
split data, we see more dramatic improvements in
the NIST scores than in BLEU. This might be due to
the NIST metric’s sensitivity to correctly translating
certain high gain words in the test corpus. Inflec-
tional splitting techniques that cause previously un-
known surface form words to be translated correctly
after splitting can significantly impact the overall
score.
</bodyText>
<sectionHeader confidence="0.988943" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99953225">
This work shows the potential for significant im-
provements in machine translation quality by di-
rectly bridging the inflectional gap across language
pairs. Our method takes advantage of source and
</bodyText>
<footnote confidence="0.99199175">
2The IWSLT evaluation did not allow systems to train sep-
arately for evaluation on BLEU or NIST, but results from the
proceedings indicate that top performers in each metric opti-
mized towards the respective metric.
</footnote>
<bodyText confidence="0.999975590909091">
target language context when conducting morpho-
logical analysis of each surface word form, while
avoiding complex parsing engines or refinements to
the alignment training process. Our results are pre-
sented on moderately sized corpora rather than the
scarce resource domain that has been traditionally
employed to highlight the impact of detailed mor-
phological analysis.
By showing the impact of simple processing steps
we encourage the creation of simple word and gloss
level analysis tools for new languages and show
that small investments in this direction (compared
to high octane context sensitive parsing tools) can
yield dramatic improvements, especially when rapid
development of machine translation tools becomes
increasingly relevant to the research community.
While our work focused on processing the morpho-
logically rich language and then translating ”down”
into the morphologically poor language, we plan to
use the analysis tools developed here to model the
reverse translation process as well, the harder task
of translating ”up” into a highly inflected space.
</bodyText>
<sectionHeader confidence="0.988654" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994357045454546">
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Comput. Linguist., 19(2):263–311.
Tim Buckwalter. 2004. Buckwalter Arabic Mor-
phological Analyzer Version 2.0. LDC Cata-
log No. LDC2004L02, Linguistic Data Consortium,
www.ldc.upenn.edu/Catalog.
Tim Buckwalter. 2005.
www.qamus.org/morphology.htm.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In In Proc. ARPA Workshop on Human Lan-
guage Technology.
Matthias Eck and Chiori Hori. 2005. Overview of the
IWSLT 2005 evaluation campaign. In Proceedings of
International Workshop on Spoken Language Transla-
tion, pages 11–17.
Jose B.Marino Josep M.Crego, Adria de Gispert. 2005.
The talp ngram-based smt system for iwslt’05. In Pro-
ceedings of International Workshop on Spoken Lan-
guage Translation, pages 191–198.
</reference>
<page confidence="0.996924">
203
</page>
<table confidence="0.9997654">
Inflection system NIST – Dev. NIST – Test BLEU – Dev. BLEU – Test
No preprocessing 9.33 9.44 51.1 49.7
Orthographic normalization (baseline) 9.41 9.51 51.0 49.7
BAMA 9.90 9.76 (+2.5%) 52.0 50.2 (+1%)
BAMA+CONTEXT+CORRMATCH 9.91 10.02 (+5.3%) 52.8 52.0 (+4.7%)
</table>
<tableCaption confidence="0.9837835">
Table 1: Translation results for each stage of inflectional splitting for the merged, sampled dev. and test
data, highest scores in bold, relative improvements in brackets
</tableCaption>
<table confidence="0.9998058">
Inflection system NIST – Dev. NIST – Test BLEU – Dev. BLEU – Test
No preprocessing 9.46 9.38 51.1 49.6
Orthographic normalization (baseline) 9.58 9.35 52.1 49.8
BAMA 10.10 9.60 (+2.7%) 53.8 48.8 (-2%)
BAMA+CONTEXT+CORRMATCH 10.08 9.79 (+4.7%) 53.7 50.6 (+1.6%)
</table>
<tableCaption confidence="0.960439">
Table 2: Translation results for each stage of inflectional splitting for the BTEC Supplied DevSet/Test05
data, highest scores in bold, relative improvements in brackets
</tableCaption>
<reference confidence="0.998964803921569">
Leah Larkey, Lisa Ballesteros, and Margaret Connell.
2002. Improving stemming for arabic information re-
trieval: Light stemming and co-occurrence analysis.
In Proc. of the 25th annual international ACM SIGIR
conference on Research and development information
retrieval.
Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-
sama Emam, and Hany Hassan. 2003. Language
model based arabic word segmentation. In ACL, Sap-
poro, Japan, July 6-7.
Young-Suk Lee. 2004. Morphological analysis for sta-
tistical machine translation. In Proceedings of the Hu-
man Language Technology and North American As-
sociation for Computational Linguistics Conference
(HLT/NAACL), Boston,MA, May 27-June 1.
Sonja Nießen and Hermann Ney. 2000. Improving SMT
quality with morpho-syntactic analysis. In The 18th
International Conference on Computational Linguis-
tics.
Sonja Nießen and Herman Ney. 2004. Statistical ma-
chine translation with scarce resources using morpho-
syntactic information. Comput. Linguist., 30(2):181–
204.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
Association of Computational Linguistics, pages 311–
318.
H. Popovic and Hermann Ney. 2004. Improving word
alignment quality using morpho-syntactic informa-
tion. In 20th International Conference on Computa-
tional Linguistics (CoLing), Geneva, Switzerland.
Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sugaya,
Hirofumi Yamamoto, and Seiichi Yamamoto. 2002.
Toward a broad-coverage bilingual corpus for speech
translation of travel conversations in the real world. In
Proc. of LREC 2002, pages 147–152, Las Palmas, Ca-
nary Islands, Spain, May.
Stephan Vogel, Ying Zhang, Fei Huang, Alicia Trib-
ble, Ashish Venogupal, Bing Zhao, and Alex Waibel.
2003. The CMU statistical translation system. In Pro-
ceedings of MT Summit IX, New Orleans, LA, Septem-
ber.
Stephan Vogel. 2005. PESA: Phrase pair extraction as
sentence splitting. In Proceedings of MT Summit X,
Phuket,Thailand, September.
Ying Zhang and Stephan Vogel. 2004. Measuring confi-
dence intervals for the machine translation evaluation
metrics. In Proceedings of the 10th International Con-
ference on Theoretical and Methodological Issues in
Machine Translation (TMII), Baltimore, MD, October.
</reference>
<page confidence="0.99889">
204
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971988">
<title confidence="0.9993355">Bridging the Inflection Morphology Gap for Arabic Statistical Machine Translation</title>
<author confidence="0.992235">Zollmann Venugopal</author>
<affiliation confidence="0.995271">School of Computer Carnegie Mellon</affiliation>
<abstract confidence="0.999428944444444">Statistical machine translation (SMT) is based on the ability to effectively learn word and phrase relationships from parallel corpora, a process which is considerably more difficult when the extent of morphological expression differs significantly across the source and target languages. We present techniques that select appropriate word segmentations in the morphologically rich source language based on contextual relationships in the target language. Our results take advantage of existing word level morphological analysis components to improve translation quality above state-of-the-art on a limited-data Arabic to English speech translation task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1786" citStr="Brown et al., 1993" startWordPosition="257" endWordPosition="260">ess. This inflection gap causes an abundance of surface word forms 1 in the source language compared with relatively few forms in the target language. This mismatch aggravates several issues 1We use the term surface form to refer to a series of characters separated by whitespace found in natural language processing: more unknown words forms in unseen data, more words occurring only once, more distinct words and lower token-to-type ratios (mean number of occurrences over all distinct words) in the source language than in the target language. Lexical relationships under the standard IBM models (Brown et al., 1993) do not account for many-to-many mappings, and phrase extraction relies heavily on the accuracy of the IBM word-toword alignment. In this work, we propose an approach to bridge the inflectional gap that addresses the issues described above through a series of preprocessing steps based on the Buckwalter Arabic Morphological Analyzer (BAMA) tool (Buckwalter, 2004). While (Lee et al., 2003) develop accurate segmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gl</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Comput. Linguist., 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 2.0.</title>
<date>2004</date>
<booktitle>LDC Catalog No. LDC2004L02, Linguistic Data Consortium,</booktitle>
<location>www.ldc.upenn.edu/Catalog.</location>
<contexts>
<context position="2150" citStr="Buckwalter, 2004" startWordPosition="317" endWordPosition="318">rds occurring only once, more distinct words and lower token-to-type ratios (mean number of occurrences over all distinct words) in the source language than in the target language. Lexical relationships under the standard IBM models (Brown et al., 1993) do not account for many-to-many mappings, and phrase extraction relies heavily on the accuracy of the IBM word-toword alignment. In this work, we propose an approach to bridge the inflectional gap that addresses the issues described above through a series of preprocessing steps based on the Buckwalter Arabic Morphological Analyzer (BAMA) tool (Buckwalter, 2004). While (Lee et al., 2003) develop accurate segmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the deco</context>
<context position="4403" citStr="Buckwalter, 2004" startWordPosition="656" endWordPosition="657">pecific and hand written rules to deal with ambiguous fragmentation. (Nießen and Ney, 2004) also extend the corpus by annotating each source word with morphological information and building a hierarchical lexicon. The experimental results show dramatic improvements from sentencelevel restructuring (question inversion, separated verb prefixes and merging phrases), but limited improvement from the hierarchical lexicon, especially as the size of the training data increases. We conduct our morphological analysis at the word level, using Buckwalter Arabic Morphological Analyzer (BAMA) version 2.0 (Buckwalter, 2004). BAMA analyzes a given surface word, returning a set of potential segmentations (order of a dozen) for the source word into prefixes, stems, and suffixes. Our techniques select the appropriate splitting from that set by taking into account the target sides (full sentences) of that word’s occurrences in the training corpus. We now describe each splitting technique that we apply. 2.1 BAMA: Simple fragment splitting We begin by simply replacing each Arabic word with the fragments representing the first of the possible splittings returned by the BAMA tool. BAMA uses simple word-based heuristics t</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer Version 2.0. LDC Catalog No. LDC2004L02, Linguistic Data Consortium, www.ldc.upenn.edu/Catalog.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<date>2005</date>
<note>www.qamus.org/morphology.htm.</note>
<contexts>
<context position="3336" citStr="Buckwalter, 2005" startWordPosition="499" endWordPosition="500"> reordering effects to the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the issues caused by the inflection gap. Refer to (Buckwalter, 2005) and (Larkey et al., 2002) for examples that highlight morphological inflection for a simple Modern Standard Arabic (MSA) word and basic stemming operations that we use as our baseline system. (Nießen and Ney, 2000) tackle the inflection gap for German-to-English word alignment by performing a series of morphological operations on the German text. They fragment words based on a full morphological analysis of the sentence, but need to use domain specific and hand written rules to deal with ambiguous fragmentation. (Nießen and Ney, 2004) also extend the corpus by annotating each source word with</context>
</contexts>
<marker>Buckwalter, 2005</marker>
<rawString>Tim Buckwalter. 2005. www.qamus.org/morphology.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In</title>
<date>2002</date>
<booktitle>In Proc. ARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="7970" citStr="Doddington, 2002" startWordPosition="1229" endWordPosition="1230">te on test and development data randomly sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and test data sets. 3.1 System description Translation experiments were conducted using the (Vogel et al., 2003) system with reordering and future cost estimation. We trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (Vogel, 2005) ) with Minimum Error Rate training on the development set. We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al., 2002). 4 Translation Results Table 1 and 2 shows the results of each stage of inflectional splitting on the BLEU and NIST metrics. Basic orthographic normalization serves as a baseline (merging all Alif, tar marbuta, ee forms to the base form). The test set NIST scores show steady improvements of up to 5 percent relative, as more sophisticated splitting techniques are used, ie BAMA+CONTEXT+CORRMATCH. These improvements are statistically significant over the baseline in both metrics as measured by the techniques in (Zhang and Vogel, 2004). Our NIST result</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In In Proc. ARPA Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Eck</author>
<author>Chiori Hori</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2005</date>
<booktitle>In Proceedings of International Workshop on Spoken Language Translation,</booktitle>
<pages>11--17</pages>
<contexts>
<context position="2986" citStr="Eck and Hori, 2005" startWordPosition="446" endWordPosition="449">structed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the issues caused by the inflection gap. Refer to (Buckwalter, 2005) and (Larkey et al., 2002) for examples that highlight morphological inflection for a simple Modern Standard Arabic (MSA) word and basic stemming operations that we use as our baseline system. (Nießen and Ney, 2000) tackle the inflection gap for Germ</context>
<context position="7337" citStr="Eck and Hori, 2005" startWordPosition="1126" endWordPosition="1129">r naZiyf ” (after BAMA only) which becomes ”h‘*A lA ya zAl gayor naZiyf” after the CORRMATCH stage. The ”u” has been removed. 3 Experimental Framework We evaluate the impact of inflectional splitting on the BTEC (Takezawa et al., 2002) IWSLT05 Arabic language data track. The “Supplied” data track includes a 20K Arabic/English sentence pair training set, as well as a development (“DevSet”) and test (“Test05”) set of 500 Arabic sentences each and 16 reference translations per Arabic sentence. Details regarding the IWSLT evaluation criteria and data topic and collection methods are available in (Eck and Hori, 2005). We also evaluate on test and development data randomly sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and test data sets. 3.1 System description Translation experiments were conducted using the (Vogel et al., 2003) system with reordering and future cost estimation. We trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (Vogel, 2005) ) with Minimum Error Rate training on the development set. We optimized separately for</context>
</contexts>
<marker>Eck, Hori, 2005</marker>
<rawString>Matthias Eck and Chiori Hori. 2005. Overview of the IWSLT 2005 evaluation campaign. In Proceedings of International Workshop on Spoken Language Translation, pages 11–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jose B Marino Josep M Crego</author>
<author>Adria de Gispert</author>
</authors>
<title>The talp ngram-based smt system for iwslt’05.</title>
<date>2005</date>
<booktitle>In Proceedings of International Workshop on Spoken Language Translation,</booktitle>
<pages>191--198</pages>
<marker>Crego, de Gispert, 2005</marker>
<rawString>Jose B.Marino Josep M.Crego, Adria de Gispert. 2005. The talp ngram-based smt system for iwslt’05. In Proceedings of International Workshop on Spoken Language Translation, pages 191–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leah Larkey</author>
<author>Lisa Ballesteros</author>
<author>Margaret Connell</author>
</authors>
<title>Improving stemming for arabic information retrieval: Light stemming and co-occurrence analysis.</title>
<date>2002</date>
<booktitle>In Proc. of the 25th annual international ACM SIGIR conference on Research and development information retrieval.</booktitle>
<contexts>
<context position="3362" citStr="Larkey et al., 2002" startWordPosition="502" endWordPosition="505">the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the issues caused by the inflection gap. Refer to (Buckwalter, 2005) and (Larkey et al., 2002) for examples that highlight morphological inflection for a simple Modern Standard Arabic (MSA) word and basic stemming operations that we use as our baseline system. (Nießen and Ney, 2000) tackle the inflection gap for German-to-English word alignment by performing a series of morphological operations on the German text. They fragment words based on a full morphological analysis of the sentence, but need to use domain specific and hand written rules to deal with ambiguous fragmentation. (Nießen and Ney, 2004) also extend the corpus by annotating each source word with morphological information</context>
</contexts>
<marker>Larkey, Ballesteros, Connell, 2002</marker>
<rawString>Leah Larkey, Lisa Ballesteros, and Margaret Connell. 2002. Improving stemming for arabic information retrieval: Light stemming and co-occurrence analysis. In Proc. of the 25th annual international ACM SIGIR conference on Research and development information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Ossama Emam</author>
<author>Hany Hassan</author>
</authors>
<title>Language model based arabic word segmentation.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>6--7</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="2176" citStr="Lee et al., 2003" startWordPosition="320" endWordPosition="323">ore distinct words and lower token-to-type ratios (mean number of occurrences over all distinct words) in the source language than in the target language. Lexical relationships under the standard IBM models (Brown et al., 1993) do not account for many-to-many mappings, and phrase extraction relies heavily on the accuracy of the IBM word-toword alignment. In this work, we propose an approach to bridge the inflectional gap that addresses the issues described above through a series of preprocessing steps based on the Buckwalter Arabic Morphological Analyzer (BAMA) tool (Buckwalter, 2004). While (Lee et al., 2003) develop accurate segmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the decoder. Statistically signifi</context>
</contexts>
<marker>Lee, Papineni, Roukos, Emam, Hassan, 2003</marker>
<rawString>Young-Suk Lee, Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan. 2003. Language model based arabic word segmentation. In ACL, Sapporo, Japan, July 6-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT/NAACL), Boston,MA,</booktitle>
<contexts>
<context position="6421" citStr="Lee, 2004" startWordPosition="975" endWordPosition="976">rst alternative from the BAMA tool. This allows us to still translate an unseen test word correctly even if the surface form was never seen during training. 2.3 CORRMATCH: Correspondence matching The Arabic language often encodes linguistic information within the surface word form that is not present in English. Word fragments that represent this missing information are misleading in the translation process unless explicitly aligned to the NULL word on the target side. In this step we explicitly remove fragments that correspond to lexical information that is not represented in English. While (Lee, 2004) builds part of speech models to recognize such elements, we use the fact that their corresponding English translations in the BAMA lexicon are empty. Examples of such fragments are case and gender markers. As an example of CORRMATCH removal, we present the Arabic sentence ” h‘*A lA ya zAl u gayor naZiyf ” (after BAMA only) which becomes ”h‘*A lA ya zAl gayor naZiyf” after the CORRMATCH stage. The ”u” has been removed. 3 Experimental Framework We evaluate the impact of inflectional splitting on the BTEC (Takezawa et al., 2002) IWSLT05 Arabic language data track. The “Supplied” data track inclu</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Young-Suk Lee. 2004. Morphological analysis for statistical machine translation. In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference (HLT/NAACL), Boston,MA, May 27-June 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonja Nießen</author>
<author>Hermann Ney</author>
</authors>
<title>Improving SMT quality with morpho-syntactic analysis.</title>
<date>2000</date>
<booktitle>In The 18th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="3551" citStr="Nießen and Ney, 2000" startWordPosition="531" endWordPosition="534">BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the issues caused by the inflection gap. Refer to (Buckwalter, 2005) and (Larkey et al., 2002) for examples that highlight morphological inflection for a simple Modern Standard Arabic (MSA) word and basic stemming operations that we use as our baseline system. (Nießen and Ney, 2000) tackle the inflection gap for German-to-English word alignment by performing a series of morphological operations on the German text. They fragment words based on a full morphological analysis of the sentence, but need to use domain specific and hand written rules to deal with ambiguous fragmentation. (Nießen and Ney, 2004) also extend the corpus by annotating each source word with morphological information and building a hierarchical lexicon. The experimental results show dramatic improvements from sentencelevel restructuring (question inversion, separated verb prefixes and merging phrases),</context>
</contexts>
<marker>Nießen, Ney, 2000</marker>
<rawString>Sonja Nießen and Hermann Ney. 2000. Improving SMT quality with morpho-syntactic analysis. In The 18th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonja Nießen</author>
<author>Herman Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morphosyntactic information.</title>
<date>2004</date>
<journal>Comput. Linguist.,</journal>
<volume>30</volume>
<issue>2</issue>
<pages>204</pages>
<contexts>
<context position="2672" citStr="Nießen and Ney, 2004" startWordPosition="396" endWordPosition="399">ocessing steps based on the Buckwalter Arabic Morphological Analyzer (BAMA) tool (Buckwalter, 2004). While (Lee et al., 2003) develop accurate segmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the </context>
</contexts>
<marker>Nießen, Ney, 2004</marker>
<rawString>Sonja Nießen and Herman Ney. 2004. Statistical machine translation with scarce resources using morphosyntactic information. Comput. Linguist., 30(2):181– 204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association of Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="8015" citStr="Papineni et al., 2002" startWordPosition="1235" endWordPosition="1238"> sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and test data sets. 3.1 System description Translation experiments were conducted using the (Vogel et al., 2003) system with reordering and future cost estimation. We trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (Vogel, 2005) ) with Minimum Error Rate training on the development set. We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al., 2002). 4 Translation Results Table 1 and 2 shows the results of each stage of inflectional splitting on the BLEU and NIST metrics. Basic orthographic normalization serves as a baseline (merging all Alif, tar marbuta, ee forms to the base form). The test set NIST scores show steady improvements of up to 5 percent relative, as more sophisticated splitting techniques are used, ie BAMA+CONTEXT+CORRMATCH. These improvements are statistically significant over the baseline in both metrics as measured by the techniques in (Zhang and Vogel, 2004). Our NIST results for all the final stages of inflectional sp</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the Association of Computational Linguistics, pages 311– 318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Popovic</author>
<author>Hermann Ney</author>
</authors>
<title>Improving word alignment quality using morpho-syntactic information.</title>
<date>2004</date>
<booktitle>In 20th International Conference on Computational Linguistics (CoLing),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="2645" citStr="Popovic and Ney, 2004" startWordPosition="391" endWordPosition="394">ve through a series of preprocessing steps based on the Buckwalter Arabic Morphological Analyzer (BAMA) tool (Buckwalter, 2004). While (Lee et al., 2003) develop accurate segmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translati</context>
</contexts>
<marker>Popovic, Ney, 2004</marker>
<rawString>H. Popovic and Hermann Ney. 2004. Improving word alignment quality using morpho-syntactic information. In 20th International Conference on Computational Linguistics (CoLing), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Toshiyuki Takezawa</author>
<author>Eiichiro Sumita</author>
<author>Fumiaki Sugaya</author>
<author>Hirofumi Yamamoto</author>
<author>Seiichi Yamamoto</author>
</authors>
<title>Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world.</title>
<date>2002</date>
<booktitle>In Proc. of LREC</booktitle>
<pages>147--152</pages>
<location>Las Palmas, Canary Islands, Spain,</location>
<contexts>
<context position="6953" citStr="Takezawa et al., 2002" startWordPosition="1065" endWordPosition="1068">at correspond to lexical information that is not represented in English. While (Lee, 2004) builds part of speech models to recognize such elements, we use the fact that their corresponding English translations in the BAMA lexicon are empty. Examples of such fragments are case and gender markers. As an example of CORRMATCH removal, we present the Arabic sentence ” h‘*A lA ya zAl u gayor naZiyf ” (after BAMA only) which becomes ”h‘*A lA ya zAl gayor naZiyf” after the CORRMATCH stage. The ”u” has been removed. 3 Experimental Framework We evaluate the impact of inflectional splitting on the BTEC (Takezawa et al., 2002) IWSLT05 Arabic language data track. The “Supplied” data track includes a 20K Arabic/English sentence pair training set, as well as a development (“DevSet”) and test (“Test05”) set of 500 Arabic sentences each and 16 reference translations per Arabic sentence. Details regarding the IWSLT evaluation criteria and data topic and collection methods are available in (Eck and Hori, 2005). We also evaluate on test and development data randomly sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and </context>
</contexts>
<marker>Takezawa, Sumita, Sugaya, Yamamoto, Yamamoto, 2002</marker>
<rawString>Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sugaya, Hirofumi Yamamoto, and Seiichi Yamamoto. 2002. Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world. In Proc. of LREC 2002, pages 147–152, Las Palmas, Canary Islands, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Ying Zhang</author>
<author>Fei Huang</author>
<author>Alicia Tribble</author>
<author>Ashish Venogupal</author>
<author>Bing Zhao</author>
<author>Alex Waibel</author>
</authors>
<title>The CMU statistical translation system.</title>
<date>2003</date>
<booktitle>In Proceedings of MT Summit IX,</booktitle>
<location>New Orleans, LA,</location>
<contexts>
<context position="7661" citStr="Vogel et al., 2003" startWordPosition="1178" endWordPosition="1181">ish sentence pair training set, as well as a development (“DevSet”) and test (“Test05”) set of 500 Arabic sentences each and 16 reference translations per Arabic sentence. Details regarding the IWSLT evaluation criteria and data topic and collection methods are available in (Eck and Hori, 2005). We also evaluate on test and development data randomly sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and test data sets. 3.1 System description Translation experiments were conducted using the (Vogel et al., 2003) system with reordering and future cost estimation. We trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (Vogel, 2005) ) with Minimum Error Rate training on the development set. We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al., 2002). 4 Translation Results Table 1 and 2 shows the results of each stage of inflectional splitting on the BLEU and NIST metrics. Basic orthographic normalization serves as a baseline (merging all Alif, tar marbuta, ee forms to the base form). The te</context>
</contexts>
<marker>Vogel, Zhang, Huang, Tribble, Venogupal, Zhao, Waibel, 2003</marker>
<rawString>Stephan Vogel, Ying Zhang, Fei Huang, Alicia Tribble, Ashish Venogupal, Bing Zhao, and Alex Waibel. 2003. The CMU statistical translation system. In Proceedings of MT Summit IX, New Orleans, LA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
</authors>
<title>PESA: Phrase pair extraction as sentence splitting.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X, Phuket,Thailand,</booktitle>
<contexts>
<context position="7850" citStr="Vogel, 2005" startWordPosition="1210" endWordPosition="1211">SLT evaluation criteria and data topic and collection methods are available in (Eck and Hori, 2005). We also evaluate on test and development data randomly sampled from the complete supplied dev and test data, due to considera202 tions noted by (Josep M.Crego, 2005) regarding the similarity of the development and test data sets. 3.1 System description Translation experiments were conducted using the (Vogel et al., 2003) system with reordering and future cost estimation. We trained translation parameters for 10 scores (language model, word and phrase count, and 6 translation model scores from (Vogel, 2005) ) with Minimum Error Rate training on the development set. We optimized separately for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al., 2002). 4 Translation Results Table 1 and 2 shows the results of each stage of inflectional splitting on the BLEU and NIST metrics. Basic orthographic normalization serves as a baseline (merging all Alif, tar marbuta, ee forms to the base form). The test set NIST scores show steady improvements of up to 5 percent relative, as more sophisticated splitting techniques are used, ie BAMA+CONTEXT+CORRMATCH. These improvements are statistically</context>
</contexts>
<marker>Vogel, 2005</marker>
<rawString>Stephan Vogel. 2005. PESA: Phrase pair extraction as sentence splitting. In Proceedings of MT Summit X, Phuket,Thailand, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Stephan Vogel</author>
</authors>
<title>Measuring confidence intervals for the machine translation evaluation metrics.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMII),</booktitle>
<location>Baltimore, MD,</location>
<contexts>
<context position="2817" citStr="Zhang and Vogel, 2004" startWordPosition="418" endWordPosition="421">egmentation models of Arabic surface word forms using manually segmented data, we rely instead on the translated context in the target language, leveraging the manually constructed lexical gloss from BAMA to select the appropriate segmented sense for each Arabic source word. Our technique, applied as preprocessing to the source corpus, splits and normalizes surface words based on the target sentence context. In contrast to (Popovic and Ney, 2004) and (Nießen and Ney, 2004), we do not modify the IBM models, and we leave reordering effects to the decoder. Statistically significant improvements (Zhang and Vogel, 2004) in BLEU and NIST translation score over a lightly stemmed baseline are reported on the available and well known BTEC IWSLT’05 Arabic-English corpus (Eck and Hori, 2005). 201 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 201–204, New York, June 2006. c�2006 Association for Computational Linguistics 2 Arabic Morphology in Recent Work Arabic-to-English machine translation exemplifies some of the issues caused by the inflection gap. Refer to (Buckwalter, 2005) and (Larkey et al., 2002) for examples that highlight morphological inflection f</context>
<context position="8553" citStr="Zhang and Vogel, 2004" startWordPosition="1321" endWordPosition="1324">ly for both the NIST (Doddington, 2002) and the BLEU metrics (Papineni et al., 2002). 4 Translation Results Table 1 and 2 shows the results of each stage of inflectional splitting on the BLEU and NIST metrics. Basic orthographic normalization serves as a baseline (merging all Alif, tar marbuta, ee forms to the base form). The test set NIST scores show steady improvements of up to 5 percent relative, as more sophisticated splitting techniques are used, ie BAMA+CONTEXT+CORRMATCH. These improvements are statistically significant over the baseline in both metrics as measured by the techniques in (Zhang and Vogel, 2004). Our NIST results for all the final stages of inflectional splitting would place us above the top NIST scores from the ISWLT evaluation on the supplied test set.2 On both DevSet/Test05 and the randomly split data, we see more dramatic improvements in the NIST scores than in BLEU. This might be due to the NIST metric’s sensitivity to correctly translating certain high gain words in the test corpus. Inflectional splitting techniques that cause previously unknown surface form words to be translated correctly after splitting can significantly impact the overall score. 5 Conclusion and Future Work</context>
</contexts>
<marker>Zhang, Vogel, 2004</marker>
<rawString>Ying Zhang and Stephan Vogel. 2004. Measuring confidence intervals for the machine translation evaluation metrics. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMII), Baltimore, MD, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>