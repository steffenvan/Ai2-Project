<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005016">
<title confidence="0.881409">
Translingual Document Representations from Discriminative Projections
</title>
<author confidence="0.981704">
John C. Platt Kristina Toutanova Wen-tau Yih
</author>
<affiliation confidence="0.957023">
Microsoft Research
</affiliation>
<address confidence="0.944508">
1 Microsoft Way
Redmond, WA 98005, USA
</address>
<email confidence="0.999728">
{jplatt,kristout,scottyih}@microsoft.com
</email>
<sectionHeader confidence="0.997399" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999306">
Representing documents by vectors that are
independent of language enhances machine
translation and multilingual text categoriza-
tion. We use discriminative training to create
a projection of documents from multiple lan-
guages into a single translingual vector space.
We explore two variants to create these pro-
jections: Oriented Principal Component Anal-
ysis (OPCA) and Coupled Probabilistic Latent
Semantic Analysis (CPLSA). Both of these
variants start with a basic model of docu-
ments (PCA and PLSA). Each model is then
made discriminative by encouraging compa-
rable document pairs to have similar vector
representations. We evaluate these algorithms
on two tasks: parallel document retrieval
for Wikipedia and Europarl documents, and
cross-lingual text classification on Reuters.
The two discriminative variants, OPCA and
CPLSA, significantly outperform their corre-
sponding baselines. The largest differences in
performance are observed on the task of re-
trieval when the documents are only compa-
rable and not parallel. The OPCA method is
shown to perform best.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996505">
Given the growth of multiple languages on the In-
ternet, Natural Language Processing must operate
on dozens of languages. It is becoming critical that
computers reach high performance on the following
two tasks:
</bodyText>
<listItem confidence="0.924416">
• Comparable and parallel document re-
</listItem>
<bodyText confidence="0.923470727272727">
trieval — Cross-language information retrieval
and text categorization have become impor-
tant with the growth of the Web (Oard and
Diekema, 1998). In addition, machine trans-
lation (MT) systems can be improved by
training on sentences extracted from paral-
lel or comparable documents mined from the
Web (Munteanu and Marcu, 2005). Compa-
rable documents can also be used for learning
word-level translation lexicons (Fung and Yee,
1998; Rapp, 1999).
</bodyText>
<listItem confidence="0.973661571428571">
• Cross-language text categorization — Appli-
cations of text categorization, such as sentiment
classification (Pang et al., 2002), are now re-
quired to run on multiple languages. Catego-
rization is usually trained on the language of
the developer: it needs to be easily extended to
other languages.
</listItem>
<bodyText confidence="0.99999">
There are two broad approaches to comparable
document retrieval and cross-language text catego-
rization. One approach is to translate queries or a
training set from different languages into a single
target language. Standard monolingual retrieval and
classification algorithms can then be applied in the
target language.
Alternatively, a cross-language system can project
a bag-of-words vector into a translingual lower-
dimensional vector space. Ideally, vectors in this
space represent the semantics of a document, inde-
pendent of the language.
The advantage of pre-translation is that MT sys-
tems tend to preserve the meaning of documents.
However, MT can be very slow (more than 1 second
per document), preventing its use on large training
sets. When full MT is not practical, a fast word-by-
word translation model can be used instead, (Balles-
teros and Croft, 1996) but may be less accurate.
Conversely, applying a projection into a low-
dimensional space is quick. Linear projection al-
gorithms use matrix-sparse vector multiplication,
which can be easily parallelized. However, as seen
in section 3, the accuracies of previous projection
</bodyText>
<page confidence="0.967579">
251
</page>
<note confidence="0.8197735">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 251–261,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.997947285714286">
techniques are not as high as machine translation.
This paper presents two techniques: Oriented
PCA and Coupled PLSA. These techniques retain
the high speed of projection, while approaching or
exceeding the quality level of word glossing. We im-
prove the quality of the projections by the use of dis-
criminative training: we minimize the difference be-
tween comparable documents in the projected vec-
tor space. Oriented PCA minimizes the difference
by modifying the eigensystem of PCA (Diamantaras
and Kung, 1996), while Coupled PLSA uses poste-
rior regularization (Graca et al., 2008; Ganchev et
al., 2009) on the topic assignments of the compara-
ble documents.
</bodyText>
<subsectionHeader confidence="0.862726">
1.1 Previous work
</subsectionHeader>
<bodyText confidence="0.999936697674419">
There has been extensive work in projecting mono-
lingual documents into a vector space. The ini-
tial algorithm for projecting documents was Latent
Semantic Analysis (LSA), which modeled bag-of-
word vectors as low-rank Gaussians (Deerwester et
al., 1990). Subsequent projection algorithms were
based on generative models of individual terms in
the documents, including Probabilistic Latent Se-
mantic Analysis (PLSA) (Hofmann, 1999) and La-
tent Dirichlet Allocation (LDA) (Blei et al., 2003).
Work on cross-lingual projections followed a sim-
ilar pattern of moving from Gaussian models to
term-wise generative models. Cross-language La-
tent Semantic Indexing (CL-LSI) (Dumais et al.,
1997) applied LSA to concatenated comparable doc-
uments from multiple languages. Similarly, Polylin-
gual Topic Models (PLTM) (Mimno et al., 2009)
generalized LDA to tuples of documents from mul-
tiple languages. The experiments in section 3 use
CL-LSI and an algorithm similar to PLTM as bench-
marks.
The closest previous work to this paper is the
use of Canonical Correlation Analysis (CCA) to find
projections for multiple languages whose results are
maximally correlated with each other (Vinokourov
et al., 2003).
PLSA-, LDA-, and CCA-based cross-lingual
models have also been trained without the use of par-
allel or comparable documents, using only knowl-
edge from a translation dictionary to achieve sharing
of topics across languages (Haghighi et al., 2008; Ja-
garlamudi and Daum´e, 2010; Zhang et al., 2010).
Such work is complementary to ours and can be
used to extend the models to domains lacking par-
allel documents.
Outside of NLP, researchers have designed al-
gorithms to find discriminative projections. We
build on the Oriented Principal Component Analysis
(OPCA) algorithm (Diamantaras and Kung, 1996),
which finds projections that maximize a signal-to-
noise ratio (as defined by the user). OPCA has been
used to create discriminative features for audio fin-
gerprinting (Burges et al., 2003).
</bodyText>
<subsectionHeader confidence="0.99988">
1.2 Structure of paper
</subsectionHeader>
<bodyText confidence="0.999970357142857">
This paper now presents two algorithms for translin-
gual document projection (in section 2): OPCA and
Coupled PLSA (CPLSA). To explain OPCA, we
first review CL-LSI in section 2.1, then discuss the
details of OPCA (section 2.2), and compare it to
CCA (section 2.3). To explain CPLSA, we first
introduce Joint PLSA (JPLSA), analogous to CL-
LSI, in section 2.4, and then describe the details of
CPLSA (section 2.5).
We have evaluated these algorithms on two dif-
ferent tasks: comparable document retrieval (sec-
tion 3.2) and cross-language text categorization
(section 3.3). We discuss the findings of the evalua-
tions and extensions to the algorithms in section 4.
</bodyText>
<sectionHeader confidence="0.9993955" genericHeader="method">
2 Algorithms for translingual document
projection
</sectionHeader>
<subsectionHeader confidence="0.999535">
2.1 Cross-language Latent Semantic Indexing
</subsectionHeader>
<bodyText confidence="0.992453857142857">
Cross-language Latent Semantic Indexing (CL-LSI)
is Latent Semantic Analysis (LSA) applied to multi-
ple languages. First, we review the mathematics of
LSA.
LSA models an n x k document-term matrix D,
where n is the number of documents and k is the
number of terms. The model of the document-term
matrix is a low-rank Gaussian. Originally, LSA was
presented as performing a Singular Value Decompo-
sition (Deerwester et al., 1990), but here we present
it as eigendecomposition, to clarify its relationship
with OPCA.
LSA first computes the correlation matrix be-
tween terms:
</bodyText>
<equation confidence="0.98922">
C = DT D. (1)
</equation>
<page confidence="0.74868">
252
</page>
<bodyText confidence="0.587014">
The Rayleigh quotient for a vector v~ with the matrix
</bodyText>
<equation confidence="0.849127">
C is
~vT C~v ~vT~v , (2)
</equation>
<bodyText confidence="0.999926428571429">
and is equal to the variance of the data projected us-
ing the vector ~v, normalized by the length of ~v, if D
has columns that are zero mean. Good projections
retain a large amount of variance. LSA maximizes
the Rayleigh ratio by taking its derivative against v~
and setting it to zero. This yields a set of projections
that are eigenvectors of C,
</bodyText>
<equation confidence="0.994402">
C~vj = λj~vj, (3)
</equation>
<bodyText confidence="0.999651466666667">
where λj is the jth-largest eigenvalue. Each eigen-
value is also the variance of the data when projected
by the corresponding eigenvector ~vj. LSA simply
uses top d eigenvectors as projections.
LSA is very similar to Principal Components
Analysis (PCA). The only difference is that the cor-
relation matrix C is used, instead of the covariance
matrix. In practice, the document-term matrix D is
sparse, so the column means are close to zero, and
the correlation matrix is close to the covariance ma-
trix.
There are a number of methods to form the
document-term matrix D. One method that works
well in practice is to compute the log(tf)-idf weight-
ing: (Dumais, 1990; Wild et al., 2005)
</bodyText>
<equation confidence="0.992007">
Dij = 1o92(fij + 1)1o92(n/dj), (4)
</equation>
<bodyText confidence="0.9999338">
where fij is the number of times term j occurs in
document i, n is the total number of documents,
and dj is the total number of documents that con-
tain term j. Applying a logarthm to the term counts
makes the distribution of matrix entries approach
Gaussian, which makes the LSA model more valid.
Cross-language LSI is an application of LSA
where each row of D is formed by concatenating
comparable or parallel documents in multiple lan-
guages. If a single term occurs in multiple lan-
guages, the term only has one slot in the concate-
nation, and the term count accumulates for all lan-
guages. Such terms could be proper nouns, such as
“Smith” or “Merkel”.
In general, the elements of D are computed via
</bodyText>
<equation confidence="0.973093">
)fm ij + 1 1o92(n/dj), (5)
</equation>
<bodyText confidence="0.998635">
where fmij is the number of times term j occurs in
document i in language m. Here, dj is the number
of documents term j appears in, and n is the total
number of documents across all languages.
Because CL-LSI is simply LSA applied to con-
catenated documents, it models terms in document
vectors jointly across languages as a single low-rank
Gaussian.
</bodyText>
<subsectionHeader confidence="0.992836">
2.2 Oriented Principal Component Analysis
</subsectionHeader>
<bodyText confidence="0.999435444444445">
The limitations of CL-LSI can be illustrated by con-
sidering Oriented Principal Components Analysis
(OPCA), a generalization of PCA. A user of OPCA
computes a signal covariance matrix S and a noise
covariance matrix N. OPCA projections ~vj max-
imize the ratio of the variance of the signal pro-
jected by ~vj to the variance of the noise projected
by ~vj. This signal-to-noise ratio is the generalized
Rayleigh quotient: (Diamantaras and Kung, 1996)
</bodyText>
<equation confidence="0.9648715">
~vT S~v (6)
vTN~v
</equation>
<bodyText confidence="0.999441333333333">
Taking the derivative of the Rayleigh quotient with
respect to the projections v~ and setting it to zero
yields the generalized eigenproblem
</bodyText>
<equation confidence="0.974566">
S~vj = λjN~vj. (7)
</equation>
<bodyText confidence="0.99983680952381">
This eigenproblem has no local minima, and can be
solved with commonly available parallel code.
PCA is a specialization of OPCA, where the noise
covariance matrix is assumed to be the identity (i.e.,
uncorrelated noise). PCA projections maximize the
signal-to-noise ratio where the signal is the empiri-
cal covariance of the data, and the noise is spherical
white noise. PCA projections are not truly appropri-
ate for forming multilingual document projections.
Instead, we want multilingual document projec-
tions to maximize the projected covariance of doc-
ument vectors across all languages, while simulta-
neously minimizing the projected distance between
comparable documents (see Figure 1). OPCA gives
us a framework for finding such discriminative pro-
jections. The covariance matrix for all documents
is the signal covariance in OPCA, and captures the
meaning of documents across all languages. The
projection of this covariance matrix should be max-
imized. The covariance matrix formed from differ-
ences between comparable documents is the noise
</bodyText>
<equation confidence="0.7665055">
Dij = 1o92 I E
\ m
</equation>
<page confidence="0.922152">
253
</page>
<bodyText confidence="0.962961333333333">
covariance in OPCA: we wish to minimize the lat-
ter covariance, to make the projection language-
independent.
Specifically, we create the weighted document-
term matrix Dm for each language:
Dij,m = lo92(fmij + 1)log2(n/dj). (8)
We then derive a signal covariance matrix over all
languages:
e
</bodyText>
<equation confidence="0.777245">
X DTmDm/n − ~µTm~µm, (9)
S =
m
</equation>
<bodyText confidence="0.966871428571429">
where ~µm is the mean of each Dm over its columns,
and a noise covariance matrix,
XN = (Dm − D)T (Dm − D)/n + γI, (10) Figure 1: OPCA finds a projection that maximizes the
m variance of all documents, while minimizing distance be-
tween comparable documents
where D is the mean across all languages of the
document-term matrix,
</bodyText>
<equation confidence="0.994846">
1 X Dm, (11)
D = M
m
</equation>
<bodyText confidence="0.999764142857143">
and M is the number of languages. Applying equa-
tion (7) to these matrices and taking the top gener-
alized eigenvectors yields the projection matrix for
OPCA.
Note the regularization term of γI in equation
(10). The empirical sample of comparable docu-
ments may not cover the entire space of translation
noise the system will encounter in the test set. For
safety, we add a regularizer that prevents the vari-
ance of a term from getting too small. We tuned γ
on the development sets in section 3.2: for log(tf)-
idf weighted vectors, C = 0.1 works well for the
data sets and dimensionalities that we tried. We use
C = 0.1 for all final tests.
</bodyText>
<subsectionHeader confidence="0.998573">
2.3 Canonical Correlation Analysis
</subsectionHeader>
<bodyText confidence="0.996937454545455">
Canonical Correlation Analysis (CCA) is a tech-
nique that is related to OPCA. CCA was kernelized
and applied to creating cross-language document
models by (Vinokourov et al., 2003). In CCA, a lin-
ear projection is found for each language, such that
the projections of the corpus from each language are
maximally correlated with each other. Similar to
OPCA, this linear projection can be found by find-
ing the top generalized eigenvectors of the system
(7), where S is now a matrix of cross-correlations
that the projection maximizes,
</bodyText>
<equation confidence="0.9186938">
&amp;quot; #
0 C12
S = ,(12)
C21 0
and N is a matrix of autocorrelations that the projec-
tion minimizes,
&amp;quot; #
C11 + γI 0
N = .(13)
0 C22 + γI
</equation>
<bodyText confidence="0.994415333333333">
Here, Cij is the (cross-)covariance matrix, with di-
mension equal to the vocabulary size, that is com-
puted between the document vectors for languages
i and j. Analogous to OPCA, γ is a regularization
term, set by optimizing performance on a validation
set. Like OPCA, these matrices can be generalized
to more than two languages. Unlike OPCA, CCA
finds projections that maximize the cross-covariance
between the projected vectors, instead of minimiz-
ing Euclidean distance.1
By definition, CCA cannot take advantage of the
information that same term occurs simultaneously in
comparable documents. As shown in section 3, this
1Note that the eigenvectors have length equal to the sum of
the length of the vocabularies of each language. The projections
for each language are created by splitting the eigenvectors into
sections, each with length equal to the vocabulary size for each
language.
</bodyText>
<page confidence="0.988775">
254
</page>
<bodyText confidence="0.999980714285714">
information is useful and helps OPCA perform bet-
ter then CCA. In addition, CCA encourages compa-
rable documents to be projected to vectors that are
mutually linearly predictable. This is not the same
OPCA’s projected vectors that have low Euclidean
distance: the latter may be preferred by algorithms
that consume the projections.
</bodyText>
<subsectionHeader confidence="0.999462">
2.4 Cross-language Topic Models
</subsectionHeader>
<bodyText confidence="0.99995575">
We now turn to a baseline generative model that
is analogous to CL-LSI. Our baseline joint PLSA
model (JPLSA) is closely related to the poly-lingual
LDA model of (Mimno et al., 2009). The graphical
model for JPLSA is shown at the top in Figure 2.
We describe the model for two languages, but it is
straightforward to generalize to more than two lan-
guages, as in (Mimno et al., 2009).
</bodyText>
<figureCaption confidence="0.9808415">
Figure 2: Graphical models for JPLSA (top) and CPLSA
(bottom)
</figureCaption>
<bodyText confidence="0.999871307692308">
The model sees documents di as sequences of
words w1, w2,... , wnz from a vocabulary V . There
are T cross-language topics, each of which has a dis-
tribution φt over words in V . In the case of mod-
els for two languages, we define the vocabulary V
to contain word types from both languages. In this
way, each topic is shared across languages.
Each topic-specific distribution φt, for t =
1... T, is drawn from a symmetric Dirichlet prior
with concentration parameter β. Given the topic-
specific word distributions, the generative process
for a corpus of paired documents [d1i , d2i] in two lan-
guages L1 and L2 is described in the next paragraph.
For each pair of documents, pick a distribution
over topics θi, from a symmetric Dirichlet prior with
concentration parameter α. Then generate the doc-
uments d1i and d2i in turn. Each word token in each
document is generated independently by first pick-
ing a topic z from a multinomial distribution with
parameter θi (MULTI(θi)), and then generating the
word token from the topic-specific word distribution
for the chosen topic MULTI(φz).
The probability of a document pair [d1, d2] with
words [wi, w12, ... ,w1 n1], [wi, w22, ... , w2n2], topic
assignments [zi, ... , z1n1], [zi, ... , z2n2], and a com-
mon topic vector θ is given by:
</bodyText>
<equation confidence="0.963931">
P(z2j |θ)P(w2j |φz2j )
</equation>
<bodyText confidence="0.999992652173913">
The difference between the JPLSA model and the
poly-lingual topic model of (Mimno et al., 2009)
is that we merge the vocabularies in the two lan-
guages and learn topic-specific word distributions
over these merged vocabularies, instead of having
pairs of topic-specific word distributions, one for
each language, like in (Mimno et al., 2009). Thus
our model is more similar to the CL-LSI model, be-
cause it can be seen as viewing a pair of documents
in two languages as one bigger document containing
the words in both documents.
Another difference between our model and the
poly-lingual LDA model of (Mimno et al., 2009)
is that we use maximum aposteriori (MAP) instead
of Bayesian inference. Recently, MAP inference
was shown to perform comparably to the best in-
ference method for LDA (Asuncion et al., 2009),
if the hyper-parameters are chosen optimally for
the inference method. Our initial experiments with
Bayesian versus MAP inference for parallel docu-
ment retrieval using JPLSA confirmed this result.
In practice our baseline model outperforms poly-
lingual LDA as mentioned in our experiments.
</bodyText>
<subsectionHeader confidence="0.7694715">
2.5 Coupled Probabilistic Latent Semantic
Analysis
</subsectionHeader>
<bodyText confidence="0.999692428571429">
The JPLSA model assumes that a pair of translated
or comparable documents have a common topic dis-
tribution θ. JPLSA fits its parameters to optimize the
probability of the data, given this assumption.
For the task of comparable document retrieval, we
want our topic model to assign similar topic distri-
butions θ to a pair of corresponding documents. But
</bodyText>
<figure confidence="0.998683714285714">
a
a
e
a&apos;
a2
z
z
z
z
W
W
W
W
N&apos;
N2
N&apos;
N2
D
D
�
T
�
T
0
0
P(θ|α) n 1 P(z1j |θ)P(w1j j ) n2
H H
j=1 j=1
</figure>
<page confidence="0.991935">
255
</page>
<bodyText confidence="0.99997230952381">
this is not exactly what the JPLSA model is doing.
Instead, it derives a common topic vector θ which
explains the union of all tokens in the English and
foreign documents, instead of making sure that the
best topic assignment for the English document is
close to the best topic assignment of the foreign doc-
ument. This difference becomes especially appar-
ent when corresponding documents have different
lengths. In this case, the model will tend to derive
a topic vector θ which explains the longer document
best, making the sum of the two documents’ log-
likelihoods higher. Modeling the shorter document’s
best topic carries little weight.
Modeling both documents equally is what Cou-
pled PLSA (CPLSA) is designed to do. The graphi-
cal model for CPLSA is shown at the bottom of Fig-
ure 2. In this figure, the topic vectors of a pair of
documents in two languages are shown completely
independent. We use the log-likelihood according to
this model, but also add a regularization term, which
tries to make the topic assignments of correspond-
ing documents close. In particular, we use poste-
rior regularization (Graca et al., 2008; Ganchev et
al., 2009) to place linear constraints on the expec-
tations of topic assignments to two corresponding
documents.
For two linked documents d1 and d2, we would
like our model to be such that the expected fraction
of tokens in d1 that get assigned topic t is approxi-
mately the same as the expected fraction of tokens in
d2 that get assigned the same topic t, for each topic
t = 1... T. This is exactly what we need to make
each pair of corresponding documents close.
Let z1 and z2 denote vectors of topic assignments
to the tokens in document d1 and d2, respectively.
Their dimensionality is equal to the lengths of the
two documents, n1 and n2. We define a space of
posterior distributions Q over hidden topic assign-
ments to the tokens in d1 and d2, that has the desired
property: the expected fraction of each topic is ap-
proximately equal in d1 and d2. We can formulate
this constrained space Q as follows:
</bodyText>
<equation confidence="0.99613425">
Q = {q1(z1),q2(z2)}
such that
En1 t)
Eq1 [ j=1
ni ] − Eq2 [ Ej 1 n2 t) ] ≤ 6t
n n2
En21 1(z2 = t) En11 1(z1 = t)
Eq2[ n2 j ] − Eq1 [ n1 ] ≤ 6t
</equation>
<bodyText confidence="0.99266675">
We then formulate an objective function that max-
imizes the log-likelihood of the data while simulta-
neously minimizing the KL-divergence between the
desired distribution set Q and the posterior distri-
bution according to the model: P(z1|d1, θ1, φ) and
P(z2|d2, θ2, φ).
The objective function for a single document pair
is as follows:
</bodyText>
<equation confidence="0.996717666666667">
log P(d1|θ1, φ) + log P(d2|θ2, φ)
−KL(Q||P(z1|d1, θ1, φ), P(z2|d2, θ2, φ))
−||6||
</equation>
<bodyText confidence="0.971407580645161">
The final corpus-wide objective is summed over
document-pairs, and also contains terms for the
probabilities of the parameters θ and φ given the
Dirichlet priors. The norm of 6 is minimized, which
makes the expected proportions of topics in two doc-
uments as close as possible.
Following (Ganchev et al., 2009), we fit the pa-
rameters by an EM-like algorithm, where for each
document pair, after finding the posterior distri-
bution of the hidden variables, we find the KL-
projection of this posterior onto the constraint set,
and take expected counts with respect to this projec-
tion; these expected counts are used in the M-step.
The projection is found using a simple projected gra-
dient algorithm.2
For both the baseline JPLSA and the CPLSA
models, we performed learning through MAP infer-
ence using EM (with a projection step for CPLSA).
We did up to 500 iterations for each model, and did
early stopping based on task performance on the de-
velopment set. The JPLSA model required more it-
erations before reaching its peak accuracy, tending
to require around 300 to 450 iterations for conver-
gence. CPLSA required fewer iterations, but each
iteration was slower due to the projection step.
2We initialized the models deterministically by assigning
each word to exactly one topic to begin with, such that all topics
have roughly the same number of words. Words were sorted by
frequency and thus words of similar frequency are more likely
to be assigned to the same topic.This initialization method out-
performed random initialization and we use it for all models.
</bodyText>
<page confidence="0.99575">
256
</page>
<bodyText confidence="0.999971571428572">
All models use α = 1.1 and Q = 1.01 for the
values of the concentration parameters. We found
that the performance of the models was not very sen-
sitive to these values, in the region that we tested
(α, Q E [1.001, 1.1]). Higher hyper-parameter val-
ues resulted in faster convergence, but the final per-
formance was similar across these different values.
</bodyText>
<sectionHeader confidence="0.998645" genericHeader="method">
3 Experimental validation
</sectionHeader>
<bodyText confidence="0.999955375">
We test the proposed discriminative projections ver-
sus more established cross-language models on the
two tasks described in the introduction: retrieving
comparable documents from a corpus, and training
a classifier in one language and using it in another.
We measure accuracy on a test set, and also examine
the sensitivity to dimensionality of the projection on
development sets.
</bodyText>
<subsectionHeader confidence="0.998914">
3.1 Speed of training and evaluation
</subsectionHeader>
<bodyText confidence="0.999959636363636">
We first test the speed of the various algorithms dis-
cussed in this paper, compared to a full machine
translation system. When finding document projec-
tions, CL-LSI, OPCA, CCA, JPLSA, and CPLSA
are equally fast: they perform a matrix multiplica-
tion and require O(nk) operations, where n is the
number of distinct words in the documents and k is
the dimensionality of the projection.3 A single CPU
core can read the indexed documents into memory
and take logarithms at 216K words per second. Pro-
jecting into a 2000-dimensional space operates at
41K words per second. Translating word-by-word
operates at 274K words per second. In contrast, ma-
chine translation processes 50 words per second, ap-
proximately 3 orders of magnitude slower.
Total training time for OPCA on 43,380 pairs of
comparable documents was 90 minutes, running on
an 8-core CPU for 2000 dimensions. On the same
corpus, JPLSA requires 31 minutes per iteration and
CPLSA requires 377 minutes per iteration. CPLSA
requires a factor of five times fewer iterations: over-
all, it is twice as slow as JPLSA.
</bodyText>
<subsectionHeader confidence="0.999808">
3.2 Retrieval of comparable documents
</subsectionHeader>
<bodyText confidence="0.9999665">
In comparable document retrieval, a query is a doc-
ument in one language, which is compared to a cor-
</bodyText>
<footnote confidence="0.935226333333333">
3For JPLSA and CPLSA this is the case only when perform-
ing a single EM iteration at test time, which we found to per-
form best.
</footnote>
<bodyText confidence="0.999981045454546">
pus of documents in another language. By mapping
all documents into the same vector space, the com-
parison is a vector comparison. For our experiments
with CL-LSI, OPCA, and CCA, we use cosine sim-
ilarity between vectors to rank the documents.
For the JPLSA and CPLSA models, we map the
documents to corresponding topic vectors 0, and
compute distance between these probability vectors.
The mapping to topic vectors requires EM iterations,
or folding-in (Hofmann, 1999). We found that per-
forming a single EM iteration resulted in best per-
formance so we used this for all models. For com-
puting distance we used the L1-norm of the differ-
ence, which worked a bit better than the Jensen-
Shannon divergence between the topic vectors used
in (Mimno et al., 2009).
We test all algorithms on the Europarl data set
of documents in English and Spanish, and a set of
Wikipedia articles in English and Spanish that con-
tain interlanguage links between them (i.e., articles
that the Wikipedia community have identified as
comparable across languages).
For the Europarl data set, we use 52,685 doc-
uments as training, 11,933 documents as a devel-
opment set, and 18,415 documents as a final test
set. Documents are defined as speeches by a sin-
gle speaker, as in (Mimno et al., 2009).4 For the
Wikipedia set, we use 43,380 training documents,
8,675 development documents, and 8,675 final test
set documents.
For both corpora, the terms are extracted by word-
breaking all documents, removing the top 50 most
frequent terms and keeping the next 20,000 most fre-
quent terms. No stemming or folding is applied.
We assess performance by testing each document
in English against all possible documents in Span-
ish, and vice versa. We measure the Top-1 accu-
racy (i.e., whether the true comparable is the clos-
est in the test set), and the Mean Reciprocal Rank
of the true comparable, and report the average per-
formance over the two retrieval directions. Ties are
counted as errors.
We tuned the dimensionality of the projections on
the development set, as shown in Figures 3 and 4.
</bodyText>
<footnote confidence="0.993992">
4The training section contains documents from the years 96
through 99 and the year 02; the dev section contains documents
from 01, and the test section contains documents from 00 plus
the first 9 months of 03.
</footnote>
<page confidence="0.995168">
257
</page>
<bodyText confidence="0.99995975">
We chose the best dimension on the development set
for each algorithm, and used it on the final test set.
The regularization -y was tuned for CCA: -y = 10 for
Europarl, and -y = 3 for Wikipedia.
</bodyText>
<figureCaption confidence="0.96748025">
Figure 3: Mean reciprocal rank versus dimension for Eu-
roparl
Figure 4: Mean reciprocal rank versus dimension for
Wikipedia
</figureCaption>
<bodyText confidence="0.999933105263158">
In the two figures, we evaluate the five projec-
tion methods, as well as a word-by-word transla-
tion method (denoted by WbW in the graphs). Here
“word-by-word” refers to using cosine distance after
applying a word-by-word translation model to the
Spanish documents.
The word-by-word translation model was trained
on the Europarl training set, using the WDHMM
model (He, 2007), which performs similarly to IBM
Model 4. The probability matrix of generating
English words from Spanish words was multiplied
by each document’s log(tf)-idf vector to produce a
translated document vector. We found that multi-
plying the probability matrix to the log(tf)-idf vector
was more accurate on the development set than mul-
tiplying the tf vector directly. This vector was either
tested as-is, or mapped through LSA learned from
the English training set of the corpus. In the figures,
the dimensionality of WbW translation refers to the
dimensionality of monolingual LSA.
The overall ordering of the six models is dif-
ferent for the Europarl and Wikipedia development
datasets. The discriminative models outperform
the corresponding generative ones (OPCA vs CL-
LSI) and (CPLSA vs JPLSA) for both datasets, and
OPCA performs best overall, dominating the best
fast-translation based model, as well as the other
projection methods, including CCA.
On Europarl, JPLSA and CPLSA outperform CL-
LSI, with the best dimension or JPLSA also slightly
outperforming the best setting for the word-by-word
translation model, whereas on Wikipedia the PLSA-
based models are significantly worse than the other
models.
The results on the final test set, evaluating each
model using its best dimensionality setting, confirm
the trends observed on the development set. The fi-
nal results are shown in Tables 1 and 2. For these
experiments, we use the unpaired t-test with Bon-
ferroni correction to determine the smallest set of
algorithms that have statistically significantly better
accuracy than the rest. The p-value threshold for sig-
nificance is chosen to be 0.05. The accuracies for
these significantly superior algorithms are shown in
boldface.
For Wikipedia and Europarl, we include an ad-
ditional baseline model,“Untranslated”: this refers
to applying cosine distance to both the Spanish and
English documents directly (since they share some
vocabulary terms). For Wikipedia, comparable doc-
uments seem to share many common terms, so co-
sine distance between untranslated documents is a
reasonable benchmark.
From the final Europarl results we can see that the
best models can learn to retrieve parallel documents
from the narrow Europarl domain very well. All
dimensionality reduction methods can learn from
</bodyText>
<page confidence="0.992862">
258
</page>
<bodyText confidence="0.999648270833334">
cleanly parallel data, but discriminative training can
bring additional error reduction.
In previously reported work, (Mimno et al., 2009)
evaluate parallel document retrieval using PLTM on
Europarl speeches in English and Spanish, using
training and test sets of size similar to ours. They
report an accuracy of 81.2% when restricting to test
documents of length at least 100 and using 50 topics.
JPLSA with 50 topics obtains accuracy of 98.9% for
documents of that length.
The final Wikipedia results are also similar to the
the development set results. The problem setting for
Wikipedia is different, because corresponding doc-
uments linked in Wikipedia may have widely vary-
ing degrees of parallelism. While most linked doc-
uments share some main topics, they could cover
different numbers of sub-topics at varying depths.
Thus the training data of linked documents is noisy,
which makes it hard for projection methods to learn.
The word-by-word translation model in this setting
is trained on clean, but out-of-domain parallel data
(Europarl), so it has the disadvantage that it may not
have a good coverage of the vocabulary; however,
it is not able to make use of the Wikipedia train-
ing data since it requires sentence-aligned transla-
tions. We find it encouraging that the best projection
method OPCA outperformed word-by-word trans-
lation. This means that OPCA is able to uncover
topic correspondence given only comparable docu-
ment pairs, and to learn well in this noisy setting.
The PLSA-based models fare worse on Wikipedia
document retrieval. CPLSA outperforms JPLSA
more strongly, but both are worse than CL-LSI and
even the Untranslated baseline. We think this is
partly explained by the diverse vocabulary in the het-
erogenous Wikipedia collection. All other models
use log(tf)-idf weighting, which automatically as-
signs importance weights to terms, whereas the topic
models use word counts. This weighting is very use-
ful for Wikipedia. For example, if we apply the
untranslated matching using raw word counts, the
MRR is 0.1024 on the test set, compared to 0.5383
for log(tf)-idf. We hypothesize that using a hierar-
chical topic model that automatically learns about
more general and more topic-specific words would
be helpful in this case. It is also possible that PLSA-
based models require cleaner data to learn well.
The overall conclusion is that OPCA outper-
</bodyText>
<table confidence="0.998963888888889">
Algorithm Dimension Accuracy MRR
OPCA 1000 0.9742 0.9806
CPLSA 1000 0.9716 0.9782
Word-by-word N/A 0.9707 0.9779
Word-by-word 5000 0.9706 0.9778
JPLSA 1000 0.9645 0.9726
CCA 1500 0.9613 0.9705
CL-LSI 3000 0.9457 0.9595
Untranslated N/A 0.1595 0.2564
</table>
<tableCaption confidence="0.961719">
Table 1: Test results for comparable document retrieval
in Europarl. Boldface indicates statistically significant
superior results.
</tableCaption>
<table confidence="0.99983">
Algorithm Dimension Accuracy MRR
OPCA 2000 0.7255 0.7734
Word-by-word N/A 0.7033 0.7467
CCA 1500 0.6894 0.7378
Word-by-word 5000 0.6786 0.7236
CL-LSI 5000 0.5302 0.6130
Untranslated N/A 0.4692 0.5383
CPLSA 200 0.4579 0.5130
JPLSA 1000 0.3322 0.3619
</table>
<tableCaption confidence="0.941308">
Table 2: Test results for comparable document retrieval
in Wikipedia. Boldface indicates statistically significant
best result.
</tableCaption>
<bodyText confidence="0.9945855">
formed all other document retrieval methods we
tested, including fast machine translation of docu-
ments. Additionally, both discriminative projection
methods outperformed their generative counterparts.
</bodyText>
<subsectionHeader confidence="0.999721">
3.3 Cross-language text classification
</subsectionHeader>
<bodyText confidence="0.9998758">
The second task is to train a text categorization sys-
tem in one language, and test it with documents in
another. To evaluate on this task, we use the Mul-
tilingual Reuters Collection, defined and provided
by (Amini et al., 2009). We test the English/Spanish
language pair. The collection has news articles in
English and Spanish, each of which has been trans-
lated to the other by the Portage translation sys-
tem (Ueffing et al., 2007).
From the English news corpus, we take 13,131
documents as training, 1,875 documents as develop-
ment, and 1,875 documents as test. We take the En-
glish training documents translated into Spanish as
our comparable training data. For testing, we use the
entire Spanish news corpus of 12,342 documents, ei-
</bodyText>
<page confidence="0.99275">
259
</page>
<bodyText confidence="0.999519782608696">
ther mapped with cross-lingual projection, or trans-
lated by Portage.
The data set was provided by (Amini et al.,
2009) as already-processed document vectors, using
BM25 weighting. Thus, we only test OPCA, CL-
LSI, and related methods: JPLSA and CPLSA re-
quire modeling the term counts directly.
The performance on the task is measured by clas-
sification accuracy on the six disjoint category la-
bels defined by (Amini et al., 2009). To introduce
minimal bias due to the classifier model, we use 1-
nearest neighbor on top of the cosine distance be-
tween vectors as a classifier. For all of the tech-
niques, we treated the vocabulary in each language
as completely separate, using the top 10,000 terms
from each language.
Note that no Spanish labeled data is provided
for training any of these algorithms: only English
and translated English news is labeled. The op-
timal dimension (and -y for CCA) on the devel-
opment set was chosen to maximize the accuracy
of English classification and translated English-to-
Spanish classification.
</bodyText>
<table confidence="0.998822444444444">
Algorithm Dim. English Spanish
Accuracy Accuracy
Full MT 50 0.8483 0.6484
OPCA 100 0.8412 0.5954
Word-by-word 50 0.8483 0.5780
CCA 150 0.8388 0.5384
Full MT N/A 0.8046 0.5323
CL-LSI 150 0.8401 0.5105
Word-by-word N/A 0.8046 0.4481
</table>
<tableCaption confidence="0.953443">
Table 3: Test results for cross-language text categoriza-
tion
</tableCaption>
<bodyText confidence="0.99990465">
The test classification accuracy is shown in Ta-
ble 3. As above, the smallest set of superior al-
gorithms as determined by Bonferroni-corrected t-
tests are shown in boldface. The results for MT and
word-by-word translation use the log(tf)-idf vector
directly for documents that were written in English,
and use a Spanish-to-English translated vector if the
document was written in Spanish. As in section 3.2,
word-by-word translation multiplied each log(tf)-idf
vector by the translation probability matrix trained
on Europarl.
The tests show that OPCA is better than CCA,
CL-LSI, plain word-by-word translation, and even
full translation for Spanish documents. However,
if we post-process full translation by an LSI model
trained on the English training set, full translation
is the most accurate. If full translation is time-
prohibitive, then OPCA is the best method: it is sig-
nificantly better than word-by-word translation fol-
lowed by LSI.
</bodyText>
<sectionHeader confidence="0.99923" genericHeader="evaluation">
4 Discussion and Extensions
</sectionHeader>
<bodyText confidence="0.999964210526316">
OPCA extends naturally to multiple languages.
However, it requires memory and computation time
that scales quadratically with the size of the vocab-
ulary. As the number of languages goes up, it may
become impractical to perform OPCA directly on a
large vocabulary.
Researchers have solved the problem of scaling
OPCA by using Distortion Discriminant Analysis
(DDA) (Burges et al., 2003). DDA performs OPCA
in two stages which avoids the need for solving a
very large generalized eigensystem. As future work,
DDA could be applied to mapping documents in
many languages simultaneously.
Spherical Admixture Models (Reisinger et al.,
2010) have recently been proposed that combine an
LDA-like hierarchical generative model with the use
of tf-idf representations. A similar model could be
used for CPLSA: future work will show whether
such a model can outperform OPCA.
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999953">
This paper presents two different methods for creat-
ing discriminative projections: OPCA and CPLSA.
Both of these methods avoid the use of artificial
concatenated documents. Instead, they model docu-
ments in multiple languages, with the constraint that
comparable documents should map to similar loca-
tions in the projected space.
When compared to other techniques, OPCA had
the highest accuracy while still having a run-time
that allowed scaling to large data sets. We therefore
recommend the use of OPCA as a pre-processing
step for large-scale comparable document retrieval
or cross-language text categorization.
</bodyText>
<page confidence="0.990662">
260
</page>
<sectionHeader confidence="0.998341" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999953367924528">
Massih-Reza Amini, Nicolas Usunier, and Cyril Goutte.
2009. Learning from multiple partially observed
views - an application to multilingual text categoriza-
tion. In Advances in Neural Information Processing
Systems 22 (NIPS 2009), pages 28–36.
Arthur Asuncion, Max Welling, Padhraic Smyth, and
Yee Whye Teh. 2009. On smoothing and inference
for topic models. In Proceedings of Uncertainty in Ar-
tificial Intelligence, pages 27–34.
Lisa Ballesteros and Bruce Croft. 1996. Dictionary
methods for cross-lingual information retrieval. In
Proceedings of the 7th International DEXA Confer-
ence on Database and Expert Systems Applications,
pages 791–801.
David M. Blei, Andrew Y. Ng, Michael I. Jordan, and
John Lafferty. 2003. Latent Dirichlet allocation.
Journal of Machine Learning Research, 3:993–1022.
Christopher J.C. Burges, John C. Platt, and Soumya Jana.
2003. Distortion discriminant analysis for audio fin-
gerprinting. IEEE Transactions on Speech and Audio
Processing, 11(3):165–174.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41(6):391–
407.
Konstantinos I. Diamantaras and S.Y. Kung. 1996. Prin-
cipal Component Neural Networks: Theory andAppli-
cations. Wiley-Interscience.
Susan T. Dumais, Todd A. Letsche, Michael L. Littman,
and Thomas K. Landauer. 1997. Automatic cross-
language retrieval using latent semantic indexing. In
AAAI-97 Spring Symposium Series: Cross-Language
Text and Speech Retrieval.
Susan T. Dumais. 1990. Enhancing performance in la-
tent semantic indexing (LSI) retrieval. Technical Re-
port TM-ARH-017527, Bellcore.
Pascale Fung and Lo Yuen Yee. 1998. An IR approach
for translating new words from nonparallel, compa-
rable texts. In Proceedings of COLING-ACL, pages
414–420.
Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, and
Ben Taskar. 2009. Posterior regularization for struc-
tured latent variable models. Technical Report MS-
CIS-09-16, University of Pennsylvania.
Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008.
Expectation maximization and posterior constraints.
In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, edi-
tors, Advances in Neural Information Processing Sys-
tems 20, pages 569–576. MIT Press, Cambridge, MA.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proc. ACL, pages 771–
779.
Xiaodong He. 2007. Using word-dependent transition
models in HMM based word alignment for statistical
machine translation. In ACL 2nd Statistical MT work-
shop, pages 80–87.
Thomas Hofmann. 1999. Probabilistic latent semantic
analysis. In Proceedings of Uncertainty in Artificial
Intelligence, pages 289–296.
Jagadeesh Jagarlamudi and Hal Daum´e, III. 2010. Ex-
tracting multilingual topics from unaligned compara-
ble corpora. In ECIR.
David Mimno, Hanna W. Wallach, Jason Naradowsky,
David A. Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of Empir-
ical Methods in Natural Language Processing, pages
880–889.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Computational Linguistics,
31:477–504.
Douglas W. Oard and Anne R. Diekema. 1998. Cross-
language information retrieval. In Martha Williams,
editor, Annual Review of Information Science (ARIST),
volume 33, pages 223–256.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using ma-
chine learning techniques. In Proc. EMNLP, pages
79–86.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated English and German cor-
pora. In Proceedings of the ACL, pages 519–526.
Joseph Reisinger, Austin Waters, Bryan Silverthorn, and
Raymond J. Mooney. 2010. Spherical topic models.
In Proc. ICML.
Nicola Ueffing, Michel Simard, Samuel Larkin, and
J. Howard Johnson. 2007. NRC’s PORTAGE system
for WMT 2007. In ACL-2007 2nd Workshop on SMT,
pages 185–188.
Alexei Vinokourov, John Shawe-Taylor, and Nello Cris-
tianini. 2003. Inferring a semantic representation
of text via cross-language correlation analysis. In
S. Thrun S. Becker and K. Obermayer, editors, Ad-
vances in Neural Information Processing Systems 15,
pages 1473–1480, Cambridge, MA. MIT Press.
Fridolin Wild, Christina Stahl, Gerald Stermsek, and
Gustaf Neumann. 2005. Parameters driving effective-
ness of automated essay scoring with LSA. In Pro-
ceedings 9th Internaional Computer-Assisted Assess-
ment Conference, pages 485–494.
Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010.
Cross-lingual latent topic extraction. In Proc. ACL,
pages 1128–1137, Uppsala, Sweden. Association for
Computational Linguistics.
</reference>
<page confidence="0.997824">
261
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.596902">
<title confidence="0.997548">Translingual Document Representations from Discriminative Projections</title>
<author confidence="0.996979">John C Platt Kristina Toutanova Wen-tau Yih</author>
<affiliation confidence="0.796524">Microsoft 1 Microsoft</affiliation>
<address confidence="0.993746">Redmond, WA 98005,</address>
<abstract confidence="0.998050192307692">Representing documents by vectors that are independent of language enhances machine translation and multilingual text categorization. We use discriminative training to create a projection of documents from multiple languages into a single translingual vector space. We explore two variants to create these projections: Oriented Principal Component Analysis (OPCA) and Coupled Probabilistic Latent Semantic Analysis (CPLSA). Both of these variants start with a basic model of documents (PCA and PLSA). Each model is then made discriminative by encouraging comparable document pairs to have similar vector representations. We evaluate these algorithms on two tasks: parallel document retrieval for Wikipedia and Europarl documents, and cross-lingual text classification on Reuters. The two discriminative variants, OPCA and CPLSA, significantly outperform their corresponding baselines. The largest differences in performance are observed on the task of retrieval when the documents are only comparable and not parallel. The OPCA method is shown to perform best.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Massih-Reza Amini</author>
<author>Nicolas Usunier</author>
<author>Cyril Goutte</author>
</authors>
<title>Learning from multiple partially observed views - an application to multilingual text categorization.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems 22 (NIPS</booktitle>
<pages>28--36</pages>
<contexts>
<context position="33339" citStr="Amini et al., 2009" startWordPosition="5482" endWordPosition="5485">PLSA 1000 0.3322 0.3619 Table 2: Test results for comparable document retrieval in Wikipedia. Boldface indicates statistically significant best result. formed all other document retrieval methods we tested, including fast machine translation of documents. Additionally, both discriminative projection methods outperformed their generative counterparts. 3.3 Cross-language text classification The second task is to train a text categorization system in one language, and test it with documents in another. To evaluate on this task, we use the Multilingual Reuters Collection, defined and provided by (Amini et al., 2009). We test the English/Spanish language pair. The collection has news articles in English and Spanish, each of which has been translated to the other by the Portage translation system (Ueffing et al., 2007). From the English news corpus, we take 13,131 documents as training, 1,875 documents as development, and 1,875 documents as test. We take the English training documents translated into Spanish as our comparable training data. For testing, we use the entire Spanish news corpus of 12,342 documents, ei259 ther mapped with cross-lingual projection, or translated by Portage. The data set was prov</context>
</contexts>
<marker>Amini, Usunier, Goutte, 2009</marker>
<rawString>Massih-Reza Amini, Nicolas Usunier, and Cyril Goutte. 2009. Learning from multiple partially observed views - an application to multilingual text categorization. In Advances in Neural Information Processing Systems 22 (NIPS 2009), pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur Asuncion</author>
<author>Max Welling</author>
<author>Padhraic Smyth</author>
<author>Yee Whye Teh</author>
</authors>
<title>On smoothing and inference for topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of Uncertainty in Artificial Intelligence,</booktitle>
<pages>27--34</pages>
<contexts>
<context position="17410" citStr="Asuncion et al., 2009" startWordPosition="2843" endWordPosition="2846">ibutions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (Mimno et al., 2009). Thus our model is more similar to the CL-LSI model, because it can be seen as viewing a pair of documents in two languages as one bigger document containing the words in both documents. Another difference between our model and the poly-lingual LDA model of (Mimno et al., 2009) is that we use maximum aposteriori (MAP) instead of Bayesian inference. Recently, MAP inference was shown to perform comparably to the best inference method for LDA (Asuncion et al., 2009), if the hyper-parameters are chosen optimally for the inference method. Our initial experiments with Bayesian versus MAP inference for parallel document retrieval using JPLSA confirmed this result. In practice our baseline model outperforms polylingual LDA as mentioned in our experiments. 2.5 Coupled Probabilistic Latent Semantic Analysis The JPLSA model assumes that a pair of translated or comparable documents have a common topic distribution θ. JPLSA fits its parameters to optimize the probability of the data, given this assumption. For the task of comparable document retrieval, we want our</context>
</contexts>
<marker>Asuncion, Welling, Smyth, Teh, 2009</marker>
<rawString>Arthur Asuncion, Max Welling, Padhraic Smyth, and Yee Whye Teh. 2009. On smoothing and inference for topic models. In Proceedings of Uncertainty in Artificial Intelligence, pages 27–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Ballesteros</author>
<author>Bruce Croft</author>
</authors>
<title>Dictionary methods for cross-lingual information retrieval.</title>
<date>1996</date>
<booktitle>In Proceedings of the 7th International DEXA Conference on Database and Expert Systems Applications,</booktitle>
<pages>791--801</pages>
<contexts>
<context position="3151" citStr="Ballesteros and Croft, 1996" startWordPosition="466" endWordPosition="470"> retrieval and classification algorithms can then be applied in the target language. Alternatively, a cross-language system can project a bag-of-words vector into a translingual lowerdimensional vector space. Ideally, vectors in this space represent the semantics of a document, independent of the language. The advantage of pre-translation is that MT systems tend to preserve the meaning of documents. However, MT can be very slow (more than 1 second per document), preventing its use on large training sets. When full MT is not practical, a fast word-byword translation model can be used instead, (Ballesteros and Croft, 1996) but may be less accurate. Conversely, applying a projection into a lowdimensional space is quick. Linear projection algorithms use matrix-sparse vector multiplication, which can be easily parallelized. However, as seen in section 3, the accuracies of previous projection 251 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 251–261, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics techniques are not as high as machine translation. This paper presents two techniques: Oriented PCA and Coupled PLSA. These tech</context>
</contexts>
<marker>Ballesteros, Croft, 1996</marker>
<rawString>Lisa Ballesteros and Bruce Croft. 1996. Dictionary methods for cross-lingual information retrieval. In Proceedings of the 7th International DEXA Conference on Database and Expert Systems Applications, pages 791–801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
<author>John Lafferty</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="4782" citStr="Blei et al., 2003" startWordPosition="711" endWordPosition="714">ior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followed a similar pattern of moving from Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections fo</context>
</contexts>
<marker>Blei, Ng, Jordan, Lafferty, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, Michael I. Jordan, and John Lafferty. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher J C Burges</author>
<author>John C Platt</author>
<author>Soumya Jana</author>
</authors>
<title>Distortion discriminant analysis for audio fingerprinting.</title>
<date>2003</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="6268" citStr="Burges et al., 2003" startWordPosition="941" endWordPosition="944"> dictionary to achieve sharing of topics across languages (Haghighi et al., 2008; Jagarlamudi and Daum´e, 2010; Zhang et al., 2010). Such work is complementary to ours and can be used to extend the models to domains lacking parallel documents. Outside of NLP, researchers have designed algorithms to find discriminative projections. We build on the Oriented Principal Component Analysis (OPCA) algorithm (Diamantaras and Kung, 1996), which finds projections that maximize a signal-tonoise ratio (as defined by the user). OPCA has been used to create discriminative features for audio fingerprinting (Burges et al., 2003). 1.2 Structure of paper This paper now presents two algorithms for translingual document projection (in section 2): OPCA and Coupled PLSA (CPLSA). To explain OPCA, we first review CL-LSI in section 2.1, then discuss the details of OPCA (section 2.2), and compare it to CCA (section 2.3). To explain CPLSA, we first introduce Joint PLSA (JPLSA), analogous to CLLSI, in section 2.4, and then describe the details of CPLSA (section 2.5). We have evaluated these algorithms on two different tasks: comparable document retrieval (section 3.2) and cross-language text categorization (section 3.3). We disc</context>
<context position="36518" citStr="Burges et al., 2003" startWordPosition="5991" endWordPosition="5994">e English training set, full translation is the most accurate. If full translation is timeprohibitive, then OPCA is the best method: it is significantly better than word-by-word translation followed by LSI. 4 Discussion and Extensions OPCA extends naturally to multiple languages. However, it requires memory and computation time that scales quadratically with the size of the vocabulary. As the number of languages goes up, it may become impractical to perform OPCA directly on a large vocabulary. Researchers have solved the problem of scaling OPCA by using Distortion Discriminant Analysis (DDA) (Burges et al., 2003). DDA performs OPCA in two stages which avoids the need for solving a very large generalized eigensystem. As future work, DDA could be applied to mapping documents in many languages simultaneously. Spherical Admixture Models (Reisinger et al., 2010) have recently been proposed that combine an LDA-like hierarchical generative model with the use of tf-idf representations. A similar model could be used for CPLSA: future work will show whether such a model can outperform OPCA. 5 Conclusions This paper presents two different methods for creating discriminative projections: OPCA and CPLSA. Both of t</context>
</contexts>
<marker>Burges, Platt, Jana, 2003</marker>
<rawString>Christopher J.C. Burges, John C. Platt, and Soumya Jana. 2003. Distortion discriminant analysis for audio fingerprinting. IEEE Transactions on Speech and Audio Processing, 11(3):165–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan T Dumais</author>
<author>George W Furnas</author>
<author>Thomas K Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<pages>407</pages>
<contexts>
<context position="4548" citStr="Deerwester et al., 1990" startWordPosition="678" endWordPosition="681">minative training: we minimize the difference between comparable documents in the projected vector space. Oriented PCA minimizes the difference by modifying the eigensystem of PCA (Diamantaras and Kung, 1996), while Coupled PLSA uses posterior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followed a similar pattern of moving from Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of do</context>
<context position="7471" citStr="Deerwester et al., 1990" startWordPosition="1133" endWordPosition="1136">section 3.3). We discuss the findings of the evaluations and extensions to the algorithms in section 4. 2 Algorithms for translingual document projection 2.1 Cross-language Latent Semantic Indexing Cross-language Latent Semantic Indexing (CL-LSI) is Latent Semantic Analysis (LSA) applied to multiple languages. First, we review the mathematics of LSA. LSA models an n x k document-term matrix D, where n is the number of documents and k is the number of terms. The model of the document-term matrix is a low-rank Gaussian. Originally, LSA was presented as performing a Singular Value Decomposition (Deerwester et al., 1990), but here we present it as eigendecomposition, to clarify its relationship with OPCA. LSA first computes the correlation matrix between terms: C = DT D. (1) 252 The Rayleigh quotient for a vector v~ with the matrix C is ~vT C~v ~vT~v , (2) and is equal to the variance of the data projected using the vector ~v, normalized by the length of ~v, if D has columns that are zero mean. Good projections retain a large amount of variance. LSA maximizes the Rayleigh ratio by taking its derivative against v~ and setting it to zero. This yields a set of projections that are eigenvectors of C, C~vj = λj~vj</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391– 407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Konstantinos I Diamantaras</author>
<author>S Y Kung</author>
</authors>
<title>Principal Component Neural Networks: Theory andApplications.</title>
<date>1996</date>
<publisher>Wiley-Interscience.</publisher>
<contexts>
<context position="4132" citStr="Diamantaras and Kung, 1996" startWordPosition="613" endWordPosition="616">ocessing, pages 251–261, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics techniques are not as high as machine translation. This paper presents two techniques: Oriented PCA and Coupled PLSA. These techniques retain the high speed of projection, while approaching or exceeding the quality level of word glossing. We improve the quality of the projections by the use of discriminative training: we minimize the difference between comparable documents in the projected vector space. Oriented PCA minimizes the difference by modifying the eigensystem of PCA (Diamantaras and Kung, 1996), while Coupled PLSA uses posterior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Lat</context>
<context position="6080" citStr="Diamantaras and Kung, 1996" startWordPosition="911" endWordPosition="914">ther (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of parallel or comparable documents, using only knowledge from a translation dictionary to achieve sharing of topics across languages (Haghighi et al., 2008; Jagarlamudi and Daum´e, 2010; Zhang et al., 2010). Such work is complementary to ours and can be used to extend the models to domains lacking parallel documents. Outside of NLP, researchers have designed algorithms to find discriminative projections. We build on the Oriented Principal Component Analysis (OPCA) algorithm (Diamantaras and Kung, 1996), which finds projections that maximize a signal-tonoise ratio (as defined by the user). OPCA has been used to create discriminative features for audio fingerprinting (Burges et al., 2003). 1.2 Structure of paper This paper now presents two algorithms for translingual document projection (in section 2): OPCA and Coupled PLSA (CPLSA). To explain OPCA, we first review CL-LSI in section 2.1, then discuss the details of OPCA (section 2.2), and compare it to CCA (section 2.3). To explain CPLSA, we first introduce Joint PLSA (JPLSA), analogous to CLLSI, in section 2.4, and then describe the details </context>
<context position="10355" citStr="Diamantaras and Kung, 1996" startWordPosition="1641" endWordPosition="1644">s simply LSA applied to concatenated documents, it models terms in document vectors jointly across languages as a single low-rank Gaussian. 2.2 Oriented Principal Component Analysis The limitations of CL-LSI can be illustrated by considering Oriented Principal Components Analysis (OPCA), a generalization of PCA. A user of OPCA computes a signal covariance matrix S and a noise covariance matrix N. OPCA projections ~vj maximize the ratio of the variance of the signal projected by ~vj to the variance of the noise projected by ~vj. This signal-to-noise ratio is the generalized Rayleigh quotient: (Diamantaras and Kung, 1996) ~vT S~v (6) vTN~v Taking the derivative of the Rayleigh quotient with respect to the projections v~ and setting it to zero yields the generalized eigenproblem S~vj = λjN~vj. (7) This eigenproblem has no local minima, and can be solved with commonly available parallel code. PCA is a specialization of OPCA, where the noise covariance matrix is assumed to be the identity (i.e., uncorrelated noise). PCA projections maximize the signal-to-noise ratio where the signal is the empirical covariance of the data, and the noise is spherical white noise. PCA projections are not truly appropriate for formi</context>
</contexts>
<marker>Diamantaras, Kung, 1996</marker>
<rawString>Konstantinos I. Diamantaras and S.Y. Kung. 1996. Principal Component Neural Networks: Theory andApplications. Wiley-Interscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan T Dumais</author>
<author>Todd A Letsche</author>
<author>Michael L Littman</author>
<author>Thomas K Landauer</author>
</authors>
<title>Automatic crosslanguage retrieval using latent semantic indexing.</title>
<date>1997</date>
<booktitle>In AAAI-97 Spring Symposium Series: Cross-Language Text and Speech Retrieval.</booktitle>
<contexts>
<context position="4978" citStr="Dumais et al., 1997" startWordPosition="739" endWordPosition="742">ments into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followed a similar pattern of moving from Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections for multiple languages whose results are maximally correlated with each other (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of par</context>
</contexts>
<marker>Dumais, Letsche, Littman, Landauer, 1997</marker>
<rawString>Susan T. Dumais, Todd A. Letsche, Michael L. Littman, and Thomas K. Landauer. 1997. Automatic crosslanguage retrieval using latent semantic indexing. In AAAI-97 Spring Symposium Series: Cross-Language Text and Speech Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan T Dumais</author>
</authors>
<title>Enhancing performance in latent semantic indexing (LSI) retrieval.</title>
<date>1990</date>
<tech>Technical Report TM-ARH-017527, Bellcore.</tech>
<contexts>
<context position="8737" citStr="Dumais, 1990" startWordPosition="1360" endWordPosition="1361">envalue is also the variance of the data when projected by the corresponding eigenvector ~vj. LSA simply uses top d eigenvectors as projections. LSA is very similar to Principal Components Analysis (PCA). The only difference is that the correlation matrix C is used, instead of the covariance matrix. In practice, the document-term matrix D is sparse, so the column means are close to zero, and the correlation matrix is close to the covariance matrix. There are a number of methods to form the document-term matrix D. One method that works well in practice is to compute the log(tf)-idf weighting: (Dumais, 1990; Wild et al., 2005) Dij = 1o92(fij + 1)1o92(n/dj), (4) where fij is the number of times term j occurs in document i, n is the total number of documents, and dj is the total number of documents that contain term j. Applying a logarthm to the term counts makes the distribution of matrix entries approach Gaussian, which makes the LSA model more valid. Cross-language LSI is an application of LSA where each row of D is formed by concatenating comparable or parallel documents in multiple languages. If a single term occurs in multiple languages, the term only has one slot in the concatenation, and t</context>
</contexts>
<marker>Dumais, 1990</marker>
<rawString>Susan T. Dumais. 1990. Enhancing performance in latent semantic indexing (LSI) retrieval. Technical Report TM-ARH-017527, Bellcore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<pages>414--420</pages>
<contexts>
<context position="1977" citStr="Fung and Yee, 1998" startWordPosition="284" endWordPosition="287">ral Language Processing must operate on dozens of languages. It is becoming critical that computers reach high performance on the following two tasks: • Comparable and parallel document retrieval — Cross-language information retrieval and text categorization have become important with the growth of the Web (Oard and Diekema, 1998). In addition, machine translation (MT) systems can be improved by training on sentences extracted from parallel or comparable documents mined from the Web (Munteanu and Marcu, 2005). Comparable documents can also be used for learning word-level translation lexicons (Fung and Yee, 1998; Rapp, 1999). • Cross-language text categorization — Applications of text categorization, such as sentiment classification (Pang et al., 2002), are now required to run on multiple languages. Categorization is usually trained on the language of the developer: it needs to be easily extended to other languages. There are two broad approaches to comparable document retrieval and cross-language text categorization. One approach is to translate queries or a training set from different languages into a single target language. Standard monolingual retrieval and classification algorithms can then be a</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An IR approach for translating new words from nonparallel, comparable texts. In Proceedings of COLING-ACL, pages 414–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joao Graca</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2009</date>
<tech>Technical Report MSCIS-09-16,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="4225" citStr="Ganchev et al., 2009" startWordPosition="628" endWordPosition="631">tional Linguistics techniques are not as high as machine translation. This paper presents two techniques: Oriented PCA and Coupled PLSA. These techniques retain the high speed of projection, while approaching or exceeding the quality level of word glossing. We improve the quality of the projections by the use of discriminative training: we minimize the difference between comparable documents in the projected vector space. Oriented PCA minimizes the difference by modifying the eigensystem of PCA (Diamantaras and Kung, 1996), while Coupled PLSA uses posterior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followe</context>
<context position="19355" citStr="Ganchev et al., 2009" startWordPosition="3182" endWordPosition="3185">sum of the two documents’ loglikelihoods higher. Modeling the shorter document’s best topic carries little weight. Modeling both documents equally is what Coupled PLSA (CPLSA) is designed to do. The graphical model for CPLSA is shown at the bottom of Figure 2. In this figure, the topic vectors of a pair of documents in two languages are shown completely independent. We use the log-likelihood according to this model, but also add a regularization term, which tries to make the topic assignments of corresponding documents close. In particular, we use posterior regularization (Graca et al., 2008; Ganchev et al., 2009) to place linear constraints on the expectations of topic assignments to two corresponding documents. For two linked documents d1 and d2, we would like our model to be such that the expected fraction of tokens in d1 that get assigned topic t is approximately the same as the expected fraction of tokens in d2 that get assigned the same topic t, for each topic t = 1... T. This is exactly what we need to make each pair of corresponding documents close. Let z1 and z2 denote vectors of topic assignments to the tokens in document d1 and d2, respectively. Their dimensionality is equal to the lengths o</context>
<context position="21116" citStr="Ganchev et al., 2009" startWordPosition="3507" endWordPosition="3510">usly minimizing the KL-divergence between the desired distribution set Q and the posterior distribution according to the model: P(z1|d1, θ1, φ) and P(z2|d2, θ2, φ). The objective function for a single document pair is as follows: log P(d1|θ1, φ) + log P(d2|θ2, φ) −KL(Q||P(z1|d1, θ1, φ), P(z2|d2, θ2, φ)) −||6|| The final corpus-wide objective is summed over document-pairs, and also contains terms for the probabilities of the parameters θ and φ given the Dirichlet priors. The norm of 6 is minimized, which makes the expected proportions of topics in two documents as close as possible. Following (Ganchev et al., 2009), we fit the parameters by an EM-like algorithm, where for each document pair, after finding the posterior distribution of the hidden variables, we find the KLprojection of this posterior onto the constraint set, and take expected counts with respect to this projection; these expected counts are used in the M-step. The projection is found using a simple projected gradient algorithm.2 For both the baseline JPLSA and the CPLSA models, we performed learning through MAP inference using EM (with a projection step for CPLSA). We did up to 500 iterations for each model, and did early stopping based o</context>
</contexts>
<marker>Ganchev, Graca, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, and Ben Taskar. 2009. Posterior regularization for structured latent variable models. Technical Report MSCIS-09-16, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao Graca</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2008</date>
<booktitle>Advances in Neural Information Processing Systems 20,</booktitle>
<pages>569--576</pages>
<editor>In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4202" citStr="Graca et al., 2008" startWordPosition="624" endWordPosition="627">ociation for Computational Linguistics techniques are not as high as machine translation. This paper presents two techniques: Oriented PCA and Coupled PLSA. These techniques retain the high speed of projection, while approaching or exceeding the quality level of word glossing. We improve the quality of the projections by the use of discriminative training: we minimize the difference between comparable documents in the projected vector space. Oriented PCA minimizes the difference by modifying the eigensystem of PCA (Diamantaras and Kung, 1996), while Coupled PLSA uses posterior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-ling</context>
<context position="19332" citStr="Graca et al., 2008" startWordPosition="3178" endWordPosition="3181">nt best, making the sum of the two documents’ loglikelihoods higher. Modeling the shorter document’s best topic carries little weight. Modeling both documents equally is what Coupled PLSA (CPLSA) is designed to do. The graphical model for CPLSA is shown at the bottom of Figure 2. In this figure, the topic vectors of a pair of documents in two languages are shown completely independent. We use the log-likelihood according to this model, but also add a regularization term, which tries to make the topic assignments of corresponding documents close. In particular, we use posterior regularization (Graca et al., 2008; Ganchev et al., 2009) to place linear constraints on the expectations of topic assignments to two corresponding documents. For two linked documents d1 and d2, we would like our model to be such that the expected fraction of tokens in d1 that get assigned topic t is approximately the same as the expected fraction of tokens in d2 that get assigned the same topic t, for each topic t = 1... T. This is exactly what we need to make each pair of corresponding documents close. Let z1 and z2 denote vectors of topic assignments to the tokens in document d1 and d2, respectively. Their dimensionality is</context>
</contexts>
<marker>Graca, Ganchev, Taskar, 2008</marker>
<rawString>Joao Graca, Kuzman Ganchev, and Ben Taskar. 2008. Expectation maximization and posterior constraints. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 569–576. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="5728" citStr="Haghighi et al., 2008" startWordPosition="856" endWordPosition="859">l., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections for multiple languages whose results are maximally correlated with each other (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of parallel or comparable documents, using only knowledge from a translation dictionary to achieve sharing of topics across languages (Haghighi et al., 2008; Jagarlamudi and Daum´e, 2010; Zhang et al., 2010). Such work is complementary to ours and can be used to extend the models to domains lacking parallel documents. Outside of NLP, researchers have designed algorithms to find discriminative projections. We build on the Oriented Principal Component Analysis (OPCA) algorithm (Diamantaras and Kung, 1996), which finds projections that maximize a signal-tonoise ratio (as defined by the user). OPCA has been used to create discriminative features for audio fingerprinting (Burges et al., 2003). 1.2 Structure of paper This paper now presents two algorit</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proc. ACL, pages 771– 779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
</authors>
<title>Using word-dependent transition models in HMM based word alignment for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL 2nd Statistical MT workshop,</booktitle>
<pages>80--87</pages>
<contexts>
<context position="27445" citStr="He, 2007" startWordPosition="4578" endWordPosition="4579"> on the final test set. The regularization -y was tuned for CCA: -y = 10 for Europarl, and -y = 3 for Wikipedia. Figure 3: Mean reciprocal rank versus dimension for Europarl Figure 4: Mean reciprocal rank versus dimension for Wikipedia In the two figures, we evaluate the five projection methods, as well as a word-by-word translation method (denoted by WbW in the graphs). Here “word-by-word” refers to using cosine distance after applying a word-by-word translation model to the Spanish documents. The word-by-word translation model was trained on the Europarl training set, using the WDHMM model (He, 2007), which performs similarly to IBM Model 4. The probability matrix of generating English words from Spanish words was multiplied by each document’s log(tf)-idf vector to produce a translated document vector. We found that multiplying the probability matrix to the log(tf)-idf vector was more accurate on the development set than multiplying the tf vector directly. This vector was either tested as-is, or mapped through LSA learned from the English training set of the corpus. In the figures, the dimensionality of WbW translation refers to the dimensionality of monolingual LSA. The overall ordering </context>
</contexts>
<marker>He, 2007</marker>
<rawString>Xiaodong He. 2007. Using word-dependent transition models in HMM based word alignment for statistical machine translation. In ACL 2nd Statistical MT workshop, pages 80–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Proceedings of Uncertainty in Artificial Intelligence,</booktitle>
<pages>289--296</pages>
<contexts>
<context position="4724" citStr="Hofmann, 1999" startWordPosition="703" endWordPosition="704">ntaras and Kung, 1996), while Coupled PLSA uses posterior regularization (Graca et al., 2008; Ganchev et al., 2009) on the topic assignments of the comparable documents. 1.1 Previous work There has been extensive work in projecting monolingual documents into a vector space. The initial algorithm for projecting documents was Latent Semantic Analysis (LSA), which modeled bag-ofword vectors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followed a similar pattern of moving from Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of C</context>
<context position="24958" citStr="Hofmann, 1999" startWordPosition="4151" endWordPosition="4152">is compared to a cor3For JPLSA and CPLSA this is the case only when performing a single EM iteration at test time, which we found to perform best. pus of documents in another language. By mapping all documents into the same vector space, the comparison is a vector comparison. For our experiments with CL-LSI, OPCA, and CCA, we use cosine similarity between vectors to rank the documents. For the JPLSA and CPLSA models, we map the documents to corresponding topic vectors 0, and compute distance between these probability vectors. The mapping to topic vectors requires EM iterations, or folding-in (Hofmann, 1999). We found that performing a single EM iteration resulted in best performance so we used this for all models. For computing distance we used the L1-norm of the difference, which worked a bit better than the JensenShannon divergence between the topic vectors used in (Mimno et al., 2009). We test all algorithms on the Europarl data set of documents in English and Spanish, and a set of Wikipedia articles in English and Spanish that contain interlanguage links between them (i.e., articles that the Wikipedia community have identified as comparable across languages). For the Europarl data set, we us</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic analysis. In Proceedings of Uncertainty in Artificial Intelligence, pages 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagarlamudi</author>
<author>Hal Daum´e</author>
</authors>
<title>Extracting multilingual topics from unaligned comparable corpora.</title>
<date>2010</date>
<booktitle>In ECIR.</booktitle>
<marker>Jagarlamudi, Daum´e, 2010</marker>
<rawString>Jagadeesh Jagarlamudi and Hal Daum´e, III. 2010. Extracting multilingual topics from unaligned comparable corpora. In ECIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna W Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing,</booktitle>
<pages>880--889</pages>
<contexts>
<context position="5116" citStr="Mimno et al., 2009" startWordPosition="759" endWordPosition="762">ors as low-rank Gaussians (Deerwester et al., 1990). Subsequent projection algorithms were based on generative models of individual terms in the documents, including Probabilistic Latent Semantic Analysis (PLSA) (Hofmann, 1999) and Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Work on cross-lingual projections followed a similar pattern of moving from Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections for multiple languages whose results are maximally correlated with each other (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of parallel or comparable documents, using only knowledge from a translation dictionary to achieve sharing of topics across languages (Haghighi </context>
<context position="15039" citStr="Mimno et al., 2009" startWordPosition="2429" endWordPosition="2432">ions, each with length equal to the vocabulary size for each language. 254 information is useful and helps OPCA perform better then CCA. In addition, CCA encourages comparable documents to be projected to vectors that are mutually linearly predictable. This is not the same OPCA’s projected vectors that have low Euclidean distance: the latter may be preferred by algorithms that consume the projections. 2.4 Cross-language Topic Models We now turn to a baseline generative model that is analogous to CL-LSI. Our baseline joint PLSA model (JPLSA) is closely related to the poly-lingual LDA model of (Mimno et al., 2009). The graphical model for JPLSA is shown at the top in Figure 2. We describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (Mimno et al., 2009). Figure 2: Graphical models for JPLSA (top) and CPLSA (bottom) The model sees documents di as sequences of words w1, w2,... , wnz from a vocabulary V . There are T cross-language topics, each of which has a distribution φt over words in V . In the case of models for two languages, we define the vocabulary V to contain word types from both languages. In this way, each topic is shared across langua</context>
<context position="16697" citStr="Mimno et al., 2009" startWordPosition="2724" endWordPosition="2727">n generate the documents d1i and d2i in turn. Each word token in each document is generated independently by first picking a topic z from a multinomial distribution with parameter θi (MULTI(θi)), and then generating the word token from the topic-specific word distribution for the chosen topic MULTI(φz). The probability of a document pair [d1, d2] with words [wi, w12, ... ,w1 n1], [wi, w22, ... , w2n2], topic assignments [zi, ... , z1n1], [zi, ... , z2n2], and a common topic vector θ is given by: P(z2j |θ)P(w2j |φz2j ) The difference between the JPLSA model and the poly-lingual topic model of (Mimno et al., 2009) is that we merge the vocabularies in the two languages and learn topic-specific word distributions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (Mimno et al., 2009). Thus our model is more similar to the CL-LSI model, because it can be seen as viewing a pair of documents in two languages as one bigger document containing the words in both documents. Another difference between our model and the poly-lingual LDA model of (Mimno et al., 2009) is that we use maximum aposteriori (MAP) instead of Bayesian inference. Rec</context>
<context position="25244" citStr="Mimno et al., 2009" startWordPosition="4202" endWordPosition="4205">our experiments with CL-LSI, OPCA, and CCA, we use cosine similarity between vectors to rank the documents. For the JPLSA and CPLSA models, we map the documents to corresponding topic vectors 0, and compute distance between these probability vectors. The mapping to topic vectors requires EM iterations, or folding-in (Hofmann, 1999). We found that performing a single EM iteration resulted in best performance so we used this for all models. For computing distance we used the L1-norm of the difference, which worked a bit better than the JensenShannon divergence between the topic vectors used in (Mimno et al., 2009). We test all algorithms on the Europarl data set of documents in English and Spanish, and a set of Wikipedia articles in English and Spanish that contain interlanguage links between them (i.e., articles that the Wikipedia community have identified as comparable across languages). For the Europarl data set, we use 52,685 documents as training, 11,933 documents as a development set, and 18,415 documents as a final test set. Documents are defined as speeches by a single speaker, as in (Mimno et al., 2009).4 For the Wikipedia set, we use 43,380 training documents, 8,675 development documents, and</context>
<context position="29881" citStr="Mimno et al., 2009" startWordPosition="4950" endWordPosition="4953">is refers to applying cosine distance to both the Spanish and English documents directly (since they share some vocabulary terms). For Wikipedia, comparable documents seem to share many common terms, so cosine distance between untranslated documents is a reasonable benchmark. From the final Europarl results we can see that the best models can learn to retrieve parallel documents from the narrow Europarl domain very well. All dimensionality reduction methods can learn from 258 cleanly parallel data, but discriminative training can bring additional error reduction. In previously reported work, (Mimno et al., 2009) evaluate parallel document retrieval using PLTM on Europarl speeches in English and Spanish, using training and test sets of size similar to ours. They report an accuracy of 81.2% when restricting to test documents of length at least 100 and using 50 topics. JPLSA with 50 topics obtains accuracy of 98.9% for documents of that length. The final Wikipedia results are also similar to the the development set results. The problem setting for Wikipedia is different, because corresponding documents linked in Wikipedia may have widely varying degrees of parallelism. While most linked documents share </context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>David Mimno, Hanna W. Wallach, Jason Naradowsky, David A. Smith, and Andrew McCallum. 2009. Polylingual topic models. In Proceedings of Empirical Methods in Natural Language Processing, pages 880–889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving machine translation performance by exploiting non-parallel corpora.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--477</pages>
<contexts>
<context position="1873" citStr="Munteanu and Marcu, 2005" startWordPosition="268" endWordPosition="271">CA method is shown to perform best. 1 Introduction Given the growth of multiple languages on the Internet, Natural Language Processing must operate on dozens of languages. It is becoming critical that computers reach high performance on the following two tasks: • Comparable and parallel document retrieval — Cross-language information retrieval and text categorization have become important with the growth of the Web (Oard and Diekema, 1998). In addition, machine translation (MT) systems can be improved by training on sentences extracted from parallel or comparable documents mined from the Web (Munteanu and Marcu, 2005). Comparable documents can also be used for learning word-level translation lexicons (Fung and Yee, 1998; Rapp, 1999). • Cross-language text categorization — Applications of text categorization, such as sentiment classification (Pang et al., 2002), are now required to run on multiple languages. Categorization is usually trained on the language of the developer: it needs to be easily extended to other languages. There are two broad approaches to comparable document retrieval and cross-language text categorization. One approach is to translate queries or a training set from different languages i</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving machine translation performance by exploiting non-parallel corpora. Computational Linguistics, 31:477–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas W Oard</author>
<author>Anne R Diekema</author>
</authors>
<title>Crosslanguage information retrieval.</title>
<date>1998</date>
<booktitle>Annual Review of Information Science (ARIST),</booktitle>
<volume>33</volume>
<pages>223--256</pages>
<editor>In Martha Williams, editor,</editor>
<contexts>
<context position="1691" citStr="Oard and Diekema, 1998" startWordPosition="239" endWordPosition="242">tperform their corresponding baselines. The largest differences in performance are observed on the task of retrieval when the documents are only comparable and not parallel. The OPCA method is shown to perform best. 1 Introduction Given the growth of multiple languages on the Internet, Natural Language Processing must operate on dozens of languages. It is becoming critical that computers reach high performance on the following two tasks: • Comparable and parallel document retrieval — Cross-language information retrieval and text categorization have become important with the growth of the Web (Oard and Diekema, 1998). In addition, machine translation (MT) systems can be improved by training on sentences extracted from parallel or comparable documents mined from the Web (Munteanu and Marcu, 2005). Comparable documents can also be used for learning word-level translation lexicons (Fung and Yee, 1998; Rapp, 1999). • Cross-language text categorization — Applications of text categorization, such as sentiment classification (Pang et al., 2002), are now required to run on multiple languages. Categorization is usually trained on the language of the developer: it needs to be easily extended to other languages. The</context>
</contexts>
<marker>Oard, Diekema, 1998</marker>
<rawString>Douglas W. Oard and Anne R. Diekema. 1998. Crosslanguage information retrieval. In Martha Williams, editor, Annual Review of Information Science (ARIST), volume 33, pages 223–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2120" citStr="Pang et al., 2002" startWordPosition="304" endWordPosition="307"> tasks: • Comparable and parallel document retrieval — Cross-language information retrieval and text categorization have become important with the growth of the Web (Oard and Diekema, 1998). In addition, machine translation (MT) systems can be improved by training on sentences extracted from parallel or comparable documents mined from the Web (Munteanu and Marcu, 2005). Comparable documents can also be used for learning word-level translation lexicons (Fung and Yee, 1998; Rapp, 1999). • Cross-language text categorization — Applications of text categorization, such as sentiment classification (Pang et al., 2002), are now required to run on multiple languages. Categorization is usually trained on the language of the developer: it needs to be easily extended to other languages. There are two broad approaches to comparable document retrieval and cross-language text categorization. One approach is to translate queries or a training set from different languages into a single target language. Standard monolingual retrieval and classification algorithms can then be applied in the target language. Alternatively, a cross-language system can project a bag-of-words vector into a translingual lowerdimensional ve</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proc. EMNLP, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="1990" citStr="Rapp, 1999" startWordPosition="288" endWordPosition="289">ing must operate on dozens of languages. It is becoming critical that computers reach high performance on the following two tasks: • Comparable and parallel document retrieval — Cross-language information retrieval and text categorization have become important with the growth of the Web (Oard and Diekema, 1998). In addition, machine translation (MT) systems can be improved by training on sentences extracted from parallel or comparable documents mined from the Web (Munteanu and Marcu, 2005). Comparable documents can also be used for learning word-level translation lexicons (Fung and Yee, 1998; Rapp, 1999). • Cross-language text categorization — Applications of text categorization, such as sentiment classification (Pang et al., 2002), are now required to run on multiple languages. Categorization is usually trained on the language of the developer: it needs to be easily extended to other languages. There are two broad approaches to comparable document retrieval and cross-language text categorization. One approach is to translate queries or a training set from different languages into a single target language. Standard monolingual retrieval and classification algorithms can then be applied in the</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. In Proceedings of the ACL, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Austin Waters</author>
<author>Bryan Silverthorn</author>
<author>Raymond J Mooney</author>
</authors>
<title>Spherical topic models.</title>
<date>2010</date>
<booktitle>In Proc. ICML.</booktitle>
<contexts>
<context position="36767" citStr="Reisinger et al., 2010" startWordPosition="6029" endWordPosition="6032">s naturally to multiple languages. However, it requires memory and computation time that scales quadratically with the size of the vocabulary. As the number of languages goes up, it may become impractical to perform OPCA directly on a large vocabulary. Researchers have solved the problem of scaling OPCA by using Distortion Discriminant Analysis (DDA) (Burges et al., 2003). DDA performs OPCA in two stages which avoids the need for solving a very large generalized eigensystem. As future work, DDA could be applied to mapping documents in many languages simultaneously. Spherical Admixture Models (Reisinger et al., 2010) have recently been proposed that combine an LDA-like hierarchical generative model with the use of tf-idf representations. A similar model could be used for CPLSA: future work will show whether such a model can outperform OPCA. 5 Conclusions This paper presents two different methods for creating discriminative projections: OPCA and CPLSA. Both of these methods avoid the use of artificial concatenated documents. Instead, they model documents in multiple languages, with the constraint that comparable documents should map to similar locations in the projected space. When compared to other techni</context>
</contexts>
<marker>Reisinger, Waters, Silverthorn, Mooney, 2010</marker>
<rawString>Joseph Reisinger, Austin Waters, Bryan Silverthorn, and Raymond J. Mooney. 2010. Spherical topic models. In Proc. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Michel Simard</author>
<author>Samuel Larkin</author>
<author>J Howard Johnson</author>
</authors>
<title>NRC’s PORTAGE system for WMT</title>
<date>2007</date>
<booktitle>In ACL-2007 2nd Workshop on SMT,</booktitle>
<pages>185--188</pages>
<contexts>
<context position="33544" citStr="Ueffing et al., 2007" startWordPosition="5517" endWordPosition="5520">ed, including fast machine translation of documents. Additionally, both discriminative projection methods outperformed their generative counterparts. 3.3 Cross-language text classification The second task is to train a text categorization system in one language, and test it with documents in another. To evaluate on this task, we use the Multilingual Reuters Collection, defined and provided by (Amini et al., 2009). We test the English/Spanish language pair. The collection has news articles in English and Spanish, each of which has been translated to the other by the Portage translation system (Ueffing et al., 2007). From the English news corpus, we take 13,131 documents as training, 1,875 documents as development, and 1,875 documents as test. We take the English training documents translated into Spanish as our comparable training data. For testing, we use the entire Spanish news corpus of 12,342 documents, ei259 ther mapped with cross-lingual projection, or translated by Portage. The data set was provided by (Amini et al., 2009) as already-processed document vectors, using BM25 weighting. Thus, we only test OPCA, CLLSI, and related methods: JPLSA and CPLSA require modeling the term counts directly. The</context>
</contexts>
<marker>Ueffing, Simard, Larkin, Johnson, 2007</marker>
<rawString>Nicola Ueffing, Michel Simard, Samuel Larkin, and J. Howard Johnson. 2007. NRC’s PORTAGE system for WMT 2007. In ACL-2007 2nd Workshop on SMT, pages 185–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexei Vinokourov</author>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Inferring a semantic representation of text via cross-language correlation analysis.</title>
<date>2003</date>
<booktitle>Advances in Neural Information Processing Systems 15,</booktitle>
<pages>1473--1480</pages>
<editor>In S. Thrun S. Becker and K. Obermayer, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5483" citStr="Vinokourov et al., 2003" startWordPosition="818" endWordPosition="821"> Gaussian models to term-wise generative models. Cross-language Latent Semantic Indexing (CL-LSI) (Dumais et al., 1997) applied LSA to concatenated comparable documents from multiple languages. Similarly, Polylingual Topic Models (PLTM) (Mimno et al., 2009) generalized LDA to tuples of documents from multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections for multiple languages whose results are maximally correlated with each other (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of parallel or comparable documents, using only knowledge from a translation dictionary to achieve sharing of topics across languages (Haghighi et al., 2008; Jagarlamudi and Daum´e, 2010; Zhang et al., 2010). Such work is complementary to ours and can be used to extend the models to domains lacking parallel documents. Outside of NLP, researchers have designed algorithms to find discriminative projections. We build on the Oriented Principal Component Analysis (OPCA) algorithm (Diamantaras and Kung, 1996), w</context>
<context position="13120" citStr="Vinokourov et al., 2003" startWordPosition="2107" endWordPosition="2110">e of comparable documents may not cover the entire space of translation noise the system will encounter in the test set. For safety, we add a regularizer that prevents the variance of a term from getting too small. We tuned γ on the development sets in section 3.2: for log(tf)- idf weighted vectors, C = 0.1 works well for the data sets and dimensionalities that we tried. We use C = 0.1 for all final tests. 2.3 Canonical Correlation Analysis Canonical Correlation Analysis (CCA) is a technique that is related to OPCA. CCA was kernelized and applied to creating cross-language document models by (Vinokourov et al., 2003). In CCA, a linear projection is found for each language, such that the projections of the corpus from each language are maximally correlated with each other. Similar to OPCA, this linear projection can be found by finding the top generalized eigenvectors of the system (7), where S is now a matrix of cross-correlations that the projection maximizes, &amp;quot; # 0 C12 S = ,(12) C21 0 and N is a matrix of autocorrelations that the projection minimizes, &amp;quot; # C11 + γI 0 N = .(13) 0 C22 + γI Here, Cij is the (cross-)covariance matrix, with dimension equal to the vocabulary size, that is computed between the</context>
</contexts>
<marker>Vinokourov, Shawe-Taylor, Cristianini, 2003</marker>
<rawString>Alexei Vinokourov, John Shawe-Taylor, and Nello Cristianini. 2003. Inferring a semantic representation of text via cross-language correlation analysis. In S. Thrun S. Becker and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, pages 1473–1480, Cambridge, MA. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fridolin Wild</author>
<author>Christina Stahl</author>
<author>Gerald Stermsek</author>
<author>Gustaf Neumann</author>
</authors>
<title>Parameters driving effectiveness of automated essay scoring with LSA.</title>
<date>2005</date>
<booktitle>In Proceedings 9th Internaional Computer-Assisted Assessment Conference,</booktitle>
<pages>485--494</pages>
<contexts>
<context position="8757" citStr="Wild et al., 2005" startWordPosition="1362" endWordPosition="1365">o the variance of the data when projected by the corresponding eigenvector ~vj. LSA simply uses top d eigenvectors as projections. LSA is very similar to Principal Components Analysis (PCA). The only difference is that the correlation matrix C is used, instead of the covariance matrix. In practice, the document-term matrix D is sparse, so the column means are close to zero, and the correlation matrix is close to the covariance matrix. There are a number of methods to form the document-term matrix D. One method that works well in practice is to compute the log(tf)-idf weighting: (Dumais, 1990; Wild et al., 2005) Dij = 1o92(fij + 1)1o92(n/dj), (4) where fij is the number of times term j occurs in document i, n is the total number of documents, and dj is the total number of documents that contain term j. Applying a logarthm to the term counts makes the distribution of matrix entries approach Gaussian, which makes the LSA model more valid. Cross-language LSI is an application of LSA where each row of D is formed by concatenating comparable or parallel documents in multiple languages. If a single term occurs in multiple languages, the term only has one slot in the concatenation, and the term count accumu</context>
</contexts>
<marker>Wild, Stahl, Stermsek, Neumann, 2005</marker>
<rawString>Fridolin Wild, Christina Stahl, Gerald Stermsek, and Gustaf Neumann. 2005. Parameters driving effectiveness of automated essay scoring with LSA. In Proceedings 9th Internaional Computer-Assisted Assessment Conference, pages 485–494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duo Zhang</author>
<author>Qiaozhu Mei</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Cross-lingual latent topic extraction.</title>
<date>2010</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1128--1137</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<contexts>
<context position="5779" citStr="Zhang et al., 2010" startWordPosition="865" endWordPosition="868"> multiple languages. The experiments in section 3 use CL-LSI and an algorithm similar to PLTM as benchmarks. The closest previous work to this paper is the use of Canonical Correlation Analysis (CCA) to find projections for multiple languages whose results are maximally correlated with each other (Vinokourov et al., 2003). PLSA-, LDA-, and CCA-based cross-lingual models have also been trained without the use of parallel or comparable documents, using only knowledge from a translation dictionary to achieve sharing of topics across languages (Haghighi et al., 2008; Jagarlamudi and Daum´e, 2010; Zhang et al., 2010). Such work is complementary to ours and can be used to extend the models to domains lacking parallel documents. Outside of NLP, researchers have designed algorithms to find discriminative projections. We build on the Oriented Principal Component Analysis (OPCA) algorithm (Diamantaras and Kung, 1996), which finds projections that maximize a signal-tonoise ratio (as defined by the user). OPCA has been used to create discriminative features for audio fingerprinting (Burges et al., 2003). 1.2 Structure of paper This paper now presents two algorithms for translingual document projection (in sectio</context>
</contexts>
<marker>Zhang, Mei, Zhai, 2010</marker>
<rawString>Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010. Cross-lingual latent topic extraction. In Proc. ACL, pages 1128–1137, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>