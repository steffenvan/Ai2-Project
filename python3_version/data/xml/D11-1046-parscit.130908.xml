<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998082">
Feature-Rich Language-Independent Syntax-Based Alignment for
Statistical Machine Translation
</title>
<author confidence="0.999187">
Jason Riesa&apos; Ann Irvine&apos; Daniel Marcus
</author>
<affiliation confidence="0.997607">
&apos;Information Sciences Institute
University of Southern California
</affiliation>
<address confidence="0.682183">
Marina del Rey, CA 90292
</address>
<email confidence="0.997457">
{riesa, marcu}@isi.edu
</email>
<sectionHeader confidence="0.994705" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9981325">
We present an accurate word alignment algo-
rithm that heavily exploits source and target-
language syntax. Using a discriminative frame-
work and an efficient bottom-up search algo-
rithm, we train a model of hundreds of thou-
sands of syntactic features. Our new model
(1) helps us to very accurately model syntac-
tic transformations between languages; (2) is
language-independent; and (3) with automatic
feature extraction, assists system developers
in obtaining good word-alignment performance
off-the-shelf when tackling new language pairs.
We analyze the impact of our features, describe
inference under the model, and demonstrate
significant alignment and translation quality
improvements over already-powerful baselines
trained on very large corpora. We observe
translation quality improvements correspond-
ing to 1.0 and 1.3 BLEU for Arabic-English and
Chinese-English, respectively.
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999746214285714">
In recent years, several state-of-the-art statistical ma-
chine translation (MT) systems have incorporated
both source and target syntax into the grammars that
they generate and use to translate. While some tree-
to-tree systems parse source and target sentences
separately (Galley et al., 2006; Zollman and Venu-
gopal, 2006; Huang and Mi, 2010), others project
syntactic parses across word alignments (Li et al.,
2009). In both approaches, as in largely all statistical
MT, the quality of the alignments used to generate
the rules of the grammar are critical to the success
of the system. However, to date, most word align-
ment systems have not considered the same degree
of syntactic information that MT systems have.
</bodyText>
<affiliation confidence="0.939986">
&apos;Department of Computer Science
Johns Hopkins University
</affiliation>
<address confidence="0.911213">
Baltimore, MD 21218
</address>
<email confidence="0.996419">
anni@jhu.edu
</email>
<bodyText confidence="0.99751524">
Extending unsupervised models, like the IBM
models (Brown et al., 1993), generally requires
changing the entire generative story. The additional
complexity would likely make training such mod-
els quite expensive. Already, with ubiquitous tools
like GIZA++ (Och and Ney, 2003), training accurate
models on large corpora takes upwards of 5 days.
Recent work in discriminative alignment has fo-
cused on incorporating features that are unavailable
or difficult to incorporate within other models, e.g.
(Moore, 2005; Ittycheriah and Roukos, 2005; Liu
et al., 2005; Taskar et al., 2005b; Blunsom and
Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al.,
2006). Even more recently, motivated by the rise of
syntax-based translation models, others have sought
to inform alignment decisions with syntactic infor-
mation (Fraser and Marcu, 2007; DeNero and Klein,
2007; May and Knight, 2007; Fossum et al., 2008;
Haghighi et al., 2009; Burkett et al., 2010; Pauls and
Klein, 2010; Riesa and Marcu, 2010).
Motivated by the wide modeling gap that still re-
mains between syntax-based translation and word-
alignment models, in this paper we expand on pre-
vious work in discriminative alignment, and move
forward in three key areas:
</bodyText>
<listItem confidence="0.822724888888889">
1. We heavily exploit both source and target syntax
in ways that most models can not. In addition,
during training we extract and learn hundreds
of thousands of features automatically, learning
both the structure and parameters for the model
at the same time.
2. Our model and inference support arbitrary fea-
tures, and easily scale to millions of features.
3. Having strengthened the synchronicity between
</listItem>
<page confidence="0.976592">
497
</page>
<note confidence="0.9578475">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 497–507,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9977364">
alignment and syntax-based translation mod-
els, we advance state-of-the-art performance in
terms of both alignment and translation quality
over already-powerful baselines on very large
corpora.
</bodyText>
<sectionHeader confidence="0.811632" genericHeader="introduction">
2 A Feature-Rich Syntax-Aware
Alignment Model
</sectionHeader>
<bodyText confidence="0.999975647058823">
We follow Riesa and Marcu (2010) for efficient in-
ference with arbitrary features, but do not rely upon
hand-crafted syntactic patterns; rather, we extract
syntactic features automatically from training data.
We also introduce, in Section 5, an iterative approx-
imate Viterbi inference procedure to deal with the
asymmetry of the model. We show that this boosts
both alignment and downstream translation quality
even further.
The model itself is a linear combination of fea-
tures, whose parameters are learned online via a
structured perceptron (Collins, 2002). However, as
we describe in Section 3, the features of the model
are not known a priori. In what follows, we describe
the search algorithm so that the reader has an under-
standing of the domain of locality before we begin
to describe features and how they are learned.
</bodyText>
<subsectionHeader confidence="0.994351">
2.1 Search Overview
</subsectionHeader>
<bodyText confidence="0.9822159">
We formulate the search for the best alignment as
bottom-up parsing. Given a syntactic parse tree on
one side of a parallel sentence, we use the structure
of the tree to guide the search process. The key idea
is that complex interactions between alignments are
less likely to cross constituents, so we search recur-
sively on the tree.
As an illustrative example, we point to the struc-
ture of the hypergraph search depicted in Figure 1.
Here we are aligning the sentence pair:
a flag hung from the stage
a � 41 V P9
tai shang gua zhe guoqi
The figure shows the search process for a small ex-
ample with beam size k. Each black square repre-
sents a partial alignment. Each partial alignment at
each node is ranked according to its model score. In
this figure, the 1-best hypothesis at the leftmost NP
node is constructed by composing the best hypothe-
sis at its child DT and the 2nd-best hypothesis at its
</bodyText>
<figureCaption confidence="0.703056">
Figure 1: Approximate search through a hypergraph
</figureCaption>
<bodyText confidence="0.9678389">
with beam size k = 5. Each black square repre-
sents a partial alignment; larger grey-shaded boxes
are links in an alignment. Each partial alignment
at each node is ranked according to its model score.
The root node, S, contains a k-best list of full align-
ments.
child NN. At the root node, we have a k-best list of
full alignments.
We continue with a procedural description of the
algorithm.
</bodyText>
<subsectionHeader confidence="0.576973">
2.1.1 Initialization
</subsectionHeader>
<bodyText confidence="0.998449466666667">
We begin by visiting each preterminal node in se-
quence. We enumerate and score all one-to-one links
as well as the unaligned link (aligned to null). Next,
for a given preterminal node, we use cube pruning
(Chiang, 2007) to find the top k one-to-two align-
ments, given the scores of the one-to-one links. We
perform additional iterations of cube pruning to find
top k sets of one-to-m links. In theory, we could in-
crease m to the length of the foreign sentence and
enumerate top k lists for each English word aligned
to between 0 and all foreign words. However, in
practice we set m to limit time spent here, while
maintaining acceptable recall. In our experiments
we set m = 2 for both English-Arabic and English-
Chinese.
</bodyText>
<figure confidence="0.994971728813559">
DT
stage
台
上
挂
a
台
上
挂
着
国旗
S
NP
VP
PP
NP
DT
NN
台
上
挂
S
VP
PP
NP
着
VBDIN DT NN
国旗
VP
台
上
挂
着
NP
PP
DT
NN
a Nag
台
上
挂
NP NP
国旗
着
DT
NN VBD IN DT NN
国旗
a Nag hung from the stage
NN
VBDIN DT NN
DT
a
着
国旗
台
上
挂
着
国旗
</figure>
<page confidence="0.990778">
498
</page>
<subsectionHeader confidence="0.685482">
2.1.2 Combination
</subsectionHeader>
<bodyText confidence="0.999921363636364">
We continue traversing the tree bottom-up. At
each nonterminal node, a k-best list of partial align-
ments from each of its child nodes are combined
into a larger span. We use cube pruning to do this
efficiently.1 Nodes in different subtrees are pro-
cessed independently of one another; i.e., for any
node, alignment information at that node&apos;s sister is
unavailable. For example, in Figure 1, alignment
information at the leftmost NP is unavailable to us
while we are constructing partial alignments at the
PP. Search continues recursively up the tree, until
we have reached the root node. The root node again
computes the top k alignments from its children, and
these comprise our final k-best list of full alignments.
In our experiments we only make use of the 1-
best alignment for evaluation and translation. Previ-
ous work has shown that only shallow k-best lists of
alignments may be beneficial, and that very deep k-
best lists are not especially useful in improving final
downstream translation grammar extraction due to
rapid degradation in quality (Venugopal et al., 2008;
Liu et al., 2009b); though they may have other uses.
</bodyText>
<sectionHeader confidence="0.681324" genericHeader="method">
3 Automatically Exploiting Syntactic
Features for Alignment
</sectionHeader>
<bodyText confidence="0.999966666666667">
Up to now, previous work in syntax-based alignment
has largely modeled alignments based on features
encoding target-side English syntactic and lexical in-
formation, but only lexical information on the source
side.
However, there is much more data waiting to be
exploited, and the flexible model and efficient and
modular learning framework of hierarchical discrim-
inative alignment afford us this possibility. Here,
we discuss our target-side features, source-side fea-
tures, and features that jointly take into account both
source- and target-side information.
</bodyText>
<subsectionHeader confidence="0.99908">
3.1 Target Syntax Features
</subsectionHeader>
<bodyText confidence="0.9997996">
Most alignment systems currently function without
explicit regard to the downstream translation model.
Some notable exceptions are May and Knight (2007)
who generate syntactic alignments by re-aligning
word-to-word alignments with a syntactic model;
</bodyText>
<footnote confidence="0.887915">
1Cube pruning is approximate when we have nonlocal com-
bination features, and most of our features are of this type.
</footnote>
<bodyText confidence="0.997543351351352">
and Pauls and Klein (2010) who generate syntactic
alignments with a synchronous ITG (Wu, 1997) ap-
proach. We depart from ITG-based models (Cherry
and Lin, 2006; Haghighi et al., 2009) because of their
complexity (O(n6) in the synchronous case), requir-
ing heavy pruning or the computation of outside cost
estimates (DeNero and Klein, 2010). Instead, we
use linguistically motivated target-side parse trees to
constrain search, as described above. These trees are
output from the Berkeley parser (Petrov and Klein,
2007) and fixed at alignment time. We use these trees
not only as a vehicle for search, but also for features.
A significant motivation for this work is the desire
to make the connection, at alignment time, between
translation rules used in decoding and the alignments
that yield such translation rules. To do this, we fold
the rule extraction process into the alignment search.
At each step in the search process, we can extract
translation rules from a given partial alignment and
encode them as binary features.
Importantly, the rule extraction process itself is not
directly tied to the alignment system, but rather to
the downstream translation model. We can drop in
any type of rule extraction we like into the alignment
system, though some may generalize better than oth-
ers to new data in a large corpus. This is key for
supervised training conditions with relatively small
amounts of annotated data.2 In this work we focus
on string-to-tree translation and the translation rule
space described in (Galley et al., 2004; Galley et al.,
2006).
During training and inference, we are constantly
scoring partial alignments. Every time we have a
partial alignment to score, we can extract all poten-
tial translation rules implied by that alignment, and
encode those rules as features. In this case, we are
doing two important things:
</bodyText>
<listItem confidence="0.9207762">
1. informing the alignment search with the rules of
the translation model, and
2. modeling actual translation rules — the model
parameters give us a way to quantify the rela-
tive importance of each rule.
</listItem>
<bodyText confidence="0.758616">
For example, we learn that:
</bodyText>
<footnote confidence="0.9904625">
2For example, fully lexicalized phrase-based rules are less
useful here than gapped phrases or hierarchical rules.
</footnote>
<page confidence="0.995981">
499
</page>
<listItem confidence="0.834214">
(1) Chinese VP and NP tend to be reordered around the
N particle when translating to English.
(2) When translating an Arabic NP as part of a VP, we
often insert &amp;quot;is&amp;quot;.
</listItem>
<bodyText confidence="0.994097333333333">
feature weight
0.67252
From this process we extract and learn 326,239
lexicalized and non-lexicalized translation rule fea-
tures in our Arabic-English model; 234,972 in our
Chinese-English model. Those features for which
a positive weight is learned tend to generalize well
over the training data; negatively weighted features
do not, and are generally learned from alignments
with mistakes during search. See Figure 2 for addi-
tional examples of rule features learned for Arabic-
English alignment.
Negative evidence Nearly 67% of the rule fea-
tures we learn for Chinese-English, and 55% of the
rule features we learn for Arabic-English are neg-
atively weighted. Early experiments involved only
firing indicator rule features when an extracted rule
at alignment-time matched in a set of rules extracted
offline from our hand-aligned data. However, cover-
age from such rules will always be limited; firing ev-
ery rule as a feature as it is encountered during search
gives us many more darts to throw. Using only rule
features extracted from gold data lowers F-measure
by close to 5 points.
</bodyText>
<subsectionHeader confidence="0.999893">
3.2 Source Syntax Features and Joint Features
</subsectionHeader>
<bodyText confidence="0.996593866666666">
Source syntactic trees have recently been shown to
be helpful in machine translation decoding (Zhang
et al., 2008; Liu et al., 2009a; Chiang, 2010), but
to our knowledge have not been used in alignment
models other than that of Burkett et al. (2010). We
parse the source side of our data using the Berkeley
parser (Petrov and Klein, 2007), and encode infor-
mation provided by the source syntax as features in
the model in two ways: (1) as tree-distance features3,
and (2) as joint source-target syntax features.
3These features parameterize the intuition that if two source
words align to a single target word, we prefer them to be mem-
bers of the same constituent, or having a short path through the
tree from one word to the other, e.g. (in, V...㺲), or the first and
last Chinese words in the examples in Figure 3.
</bodyText>
<subsectionHeader confidence="0.399343">
Extracted Rule Feature Weight
</subsectionHeader>
<bodyText confidence="0.855187833333333">
Figure 2: Translation rules as features extracted dur-
ing Arabic-English alignment. These rules show that
we learn to reorder adjectives and nouns inside noun
phrases, and that prepositions before sister NPs pre-
fer to be translated monotonically. For Chinese-
English, we learn the opposite.
</bodyText>
<subsectionHeader confidence="0.730803">
3.2.1 Source-Target Coordination Features
</subsectionHeader>
<bodyText confidence="0.995594214285714">
Drawing on work by Chiang (2010) in stochas-
tically rewriting syntactic constituents across lan-
guages in a translation model, we adapt the general
idea to alignment modeling. Chiang calls these fea-
tures fuzzy syntax features; here, we simply call them
coordination features in our adaptation for align-
ment, so as to avoid the implication that we are
rewriting.
This feature family is a set of binary features
that may fire at any nonterminal node in the tree
during bottom-up search. A feature fires for each
combination of two nonterminal source and target
nodes s and t, respectively, that match the following
conditions:
</bodyText>
<listItem confidence="0.9793084">
1. t is the label of the current target tree node in the
bottom-up search.
2. s is the label of the source tree node of maximal
depth (i.e. closest to leaf nodes) that spans all
links also spanned by t.
</listItem>
<bodyText confidence="0.98513025">
Figure 3 shows three examples of this joint fea-
ture over source and target trees. In Figure 3a,
the maximal-depth source tree node that spans ev-
ery link also spanned by the shaded target tree NP
</bodyText>
<figure confidence="0.99189734117647">
feature
weight
NP(NP 1 VP 2 ) H 2 N 1
1.01304
1.11908
–0.15417
[2] 1.15328
[1] –0.65943
NP
JJ[1] NN[2]
NP
JJ[1] NN[2]
PP
IN[1] NP[2]
PP
IN[1] NP[2]
[2]
[1]
VP((VBZ is) NP 1 ) H 1
500
PP
NP
NP
NNP POS JJ NN
IN
tL
��
中国
���
对外贸易
q&apos;
NR
NP
LC
NP
PP
LCP
P
PP
PP
NP
NP
IN
NP
NNP POS JJ NN
IN NNP PO J
IN�
NNP POS JJ NN
��
NP
� 在 P
rhK
N
X1 $NVO
中�L
���
对外贸易 � 对
q&apos;
tL
��
中国
NR
IVP
LC
P
NP
LCP
PP
P
NR
NP
LC
LC
NP
LCP
PP
(a) Source/target tree feature firing at
node NP, with value ( NP ; NP ). The
maximal-depth source tree node that
spans every link also spanned by the
shaded target tree NP is also labeled
NP.
(b) Source/target tree feature firing at
node IN, returning value ( IN ; PP ).
(c) 对外贸易
</figure>
<bodyText confidence="0.350973571428571">
In this figure, depicting an incor-
rect alignment, the
中 � �� same feature value
is fired as for the correct alignment in
3b: ( IN ; PP ). We need more con-
textual annotation to create more dis-
criminative power.
</bodyText>
<figureCaption confidence="0.971737">
Figure 3: Two examples of joint features over monolingual parse trees. The value of the feature depends on
the shaded areas.
</figureCaption>
<bodyText confidence="0.991689222222222">
is also labeled NP. So, the feature returns a value
of (NP; NP). In Figure 3b, PP is the label of the
maximal-depth source tree node that spans every link
also spanned by the shaded target tree IN node; the
feature fires a value (IN ; PP). We might expect this
pairing of IN with PP, or of IN with P, but we would
expect to learn a penalizing parameter weight for the
pairing of, say, IN with NP.
Adding more context Powerful as this feature is,
it is not quite discriminating enough; it may return
the same feature value for both a correct and incor-
rect alignment, as shown in Figure 3c. To over-
come this, we introduce additional features anno-
tated with the left-most and right-most tags in the
current span. For example, in this figure, we also
fire ( IN ; PP(P,NP) ), and learn a negative weight
of −0.638 denoting a poor choice of alignment. We
also find it helpful to keep the original unannotated
feature as a poor-man&apos;s backoff.
Some examples Table 1 shows some of the
maxmially and minimally-weighted features
learned. As the more highly weighted features
show, both models learn to prefer alignments that
result in the coordination of similar constituent
labels. For example, the Chinese model learns a
very high weight for aligning sets of English words
that form prepositional phrases to sets of Chinese
</bodyText>
<table confidence="0.9989455">
Ara-Eng Model Chi-Eng Model
eng ara w eng chi w
SBAR SBAR 6.40 PP PP 10.3
S S(CC,PU) 4.91 NP NP 9.38
PP PP 4.20 SBAR VP(VV,PU) 6.97
VP VP 3.90 NP NP(DT,NN) 6.67
SBAR PP 2.58 PP PP(P,LC) 6.38
NP S -2.80 NP PP -6.82
NP VP -3.01 S IP(PU,PU) -7.44
NP NP(NN,IN) -4.52 PP IP -7.33
PP VP -5.13 SBAR VP -7.72
PP S -7.37 NP IP -7.83
</table>
<tableCaption confidence="0.998089">
Table 1: This table shows a sampling of the highest
</tableCaption>
<bodyText confidence="0.994633090909091">
and lowest-weighted coordination features applied
when scoring partial alignments at nodes in the tree.
Preterminal tags inside parentheses indicate the POS
tags on the left and right edge of a given constituent.
words that also form prepositional phrases4.
Inversely, we learn high negative weights for
model features that fire for alignments that oblige
the firing of features of very dissimilar nonterminal
labels, and that often yield asynchronous bracket-
ing. For example, the Arabic model learns that En-
glish words that form prepositional phrases should
</bodyText>
<footnote confidence="0.920364">
4In Table 1, Chinese feature [1].
</footnote>
<page confidence="0.993459">
501
</page>
<bodyText confidence="0.9997422">
not align to sets of Arabic words that form entire sen-
tences or verb phrases5.
In total, we learn 127,932 syntactic coordination
features in our Arabic-English model; 59,239 for
Chinese-English.
</bodyText>
<sectionHeader confidence="0.992042" genericHeader="method">
4 Learning
</sectionHeader>
<bodyText confidence="0.999809818181818">
We learn feature weights using a parallelized imple-
mentation of online averaged perceptron (Collins,
2002). We distribute training examples to CPUs in a
cluster and essentially run several perceptron learn-
ers in parallel. We communicate and average the
weight vectors of each learner according to the It-
erative Parameter Mixing strategy described by Mc-
Donald et al. (2010).
Let yi be the correct output for input xi. Here, yi is
an alignment; xi is a sentence pair and parse tree. At
each iteration, our perceptron update is:
</bodyText>
<equation confidence="0.9850292">
w (-- w + h(yi) − h(ˆy) (3)
And we define:
yˆ = arg max f(yi, y) + w - h(y) (4)
yEY(xi)
f(yi, y) = 1 − F1(yi, y) (5)
</equation>
<bodyText confidence="0.999907714285714">
with w our weight vector, h(y) our sparse vector of
feature values, Y(xi) all possible outputs for input xi,
and F1(yi, y) balanced F-measure. The loss, f(yi, y),
is a measure of how bad it would be to guess yˆ instead
of y.
In selecting ˆy, we draw upon the loss-augmented
inference literature (Tsochantaridis et al., 2004;
Taskar et al., 2005a). Alignment yˆ is the output
candidate maximizing the sum of both the loss and
model score. This guess appears attractive to the
model, yet has low F-measure, and so is exactly the
sort of output we would like to update away from.
During training, we learn both the parameters and
model structure. Figure 4b shows how the size of
the model grows over time. As described in Sec-
tions 2 and 3, we automatically extract and fire fea-
tures given an alignment configuration and our cur-
rent position in the tree. We see a steep initial growth
in model size, and then begin to trail off as the num-
ber of new unique rules and negative evidence we
encounter diminishes.
</bodyText>
<footnote confidence="0.452053">
5In Table 1, Arabic features [6] and [7].
</footnote>
<bodyText confidence="0.9976092">
Model Selection Among models from the first it-
eration up to convergence, we choose the model pa-
rameters from the best performing model as mea-
sured by F-measure on a held-out development set
of alignments.
</bodyText>
<sectionHeader confidence="0.990618" genericHeader="method">
5 Iterative Approximate Viterbi Inference
</sectionHeader>
<bodyText confidence="0.9999269">
Though up to now we have described features that
fire during bottom-up search on the target-language
tree, we can also search bottom-up on the source-
language tree. The syntactic features we have de-
scribed are generic enough that they will still be ex-
tractable and applicable. Because our model and in-
ference procedure are asymmetric, a search on the
source-language tree will generate alignments from
a different space, and can provide a unique signal we
would not otherwise have. We can use the Viterbi
alignments from each model to inform the other. In
the following we describe a method for simultane-
ously training both target-tree and source-tree mod-
els but with features to enforce agreement, somewhat
similar to (Nivre and McDonald, 2008) in integrat-
ing two dependency parsing models.
We begin by training two models, one that oper-
ates on the target tree, and one that operates on the
source tree. Call the parameters learned from these
models wt1 and ws1, respectively. Then, performing
inference under these models yields alignments at1
and as1.
In the next iteration we learn parameters wt2 and
ws2, and introduce agreement features. In this step,
during training to find wt2, the target-tree model uses
as1 to fire indicator features. These fire for any align-
ment link that was also present in the previous itera-
tion&apos;s source-tree alignment, as1. Analogously, when
searching for the best ws2, we use at1 to fire indicator
features that fire for any alignment link also present
in the previous iteration&apos;s target-tree alignment, at1.
This process of using the alignment from the pre-
vious iteration&apos;s opposing tree continues until con-
vergence, i.e. until we no longer see improve-
ment in our 1-best source-tree and target-tree align-
ments. When we use these alignments for down-
stream translation, we symmetrize with the grow-
diag-�nal heuristic, which continues to work re-
markably well in practice. We also experiment with
the intersection of both final alignments.
</bodyText>
<page confidence="0.988288">
502
</page>
<figure confidence="0.991753341463415">
35
0 5 10 15 20 25 30
k=2
k=4
k=16
k=64
k=128
Model Size (number of features)
450,000
400,000
800,000
750,000
700,000
650,000
600,000
550,000
500,000
350,000
300,000
250,000
200,000
150,000
0.86
0.85
0.84
F-measure
0.83
0.87
k=128
k=64
k=16
0.82
k=4
0.81
k=2
0 5 10 15 20 25 30
35
0.8
0.79
Training Time (in Epochs)
(a) Learning curves (Arabic-English): F-measure accu-
</figure>
<figureCaption confidence="0.611789">
racy on heldout development data over time for five dif-
ferent beam settings, k=2, k=4, k=16, k=64 and k=128.
For Arabic-English, improvements are minimal with
beams larger than k=128; and for Chinese-English, with
beams larger than k=256.
</figureCaption>
<figure confidence="0.865945">
Training Time (in Epochs)
</figure>
<figureCaption confidence="0.9191516">
(b) Model size as a function of time for five different
beam settings (Arabic-English): We see a steep initial
growth, and then begin to trail off as the number of new
unique extractable features and negative evidence we en-
counter diminishes. Growth rate is higher for models
with narrower beams that make more mistakes.
Figure 4: Learning feature-rich alignment models. Figure 4a shows learning curves on heldout data for five
different beam sizes. Figure 4b shows how the models dynamically grow over time. In Figure 4b we notice
that less accurate models with narrower beams need to add more complexity in an attempt to make up for
their many more mistakes.
</figureCaption>
<sectionHeader confidence="0.99453" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999966">
6.1 Alignment Quality
</subsectionHeader>
<bodyText confidence="0.99999275">
From LDC2006E86 and LDC2006E83, we use as
training data 2,280 hand-aligned sentence pairs of
Arabic-English and 1,102 for Chinese-English. We
measure training convergence using a held-out de-
velopment set of 100 sentence pairs for each lan-
guage pair, and evaluate with F-measure on a held-
out test set of 184 sentences pairs for Chinese-
English and 364 sentence pairs for Arabic-English.
We use instances of the Berkeley parser (Petrov and
Klein, 2007) trained on the English Penn Treebank,
Chinese Treebank 6, and the Arabic Treebank parts
1-3; for each language, trees are fixed at alignment
time using the 1-best output from each parser.
We use Model-4 symmetrized with the grow-diag-
final heuristic, trained with GIZA++ as a baseline
alignment model. We train two GIZA++ models on
our largest available Chinese-English and Arabic-
English parallel corpora. These consist of 261M
and 223M English words,6 respectively. The size
of these corpora make for quite a powerful unsuper-
</bodyText>
<footnote confidence="0.998721">
6These counts correspond to 240M words of Chinese and
194M words of Arabic.
</footnote>
<bodyText confidence="0.990149125">
vised baseline.
In training our alignment model, we use the syn-
tactic features discussed in Section 3, plus word-
based lexical features t(e I f) and t(f I e) used dur-
ing initialization, extracted offline directly from the
translation-table of GIZA++. Using these features
alone results in an F-measure of 59.1 for Arabic-
English, and 55.6 for Chinese-English. Our auto-
matically extracted syntactic features and iterative
inference algorithm get us the rest of the way, bring-
ing performance up to 87.6 and 87.0, respectively.
Table 2 shows the results on our held-out 100-
sentence test set. In an intrinsic evaluation on an
alignment task, our F-measure scores are more than
15 points higher than the baseline for both language
pairs.
</bodyText>
<subsectionHeader confidence="0.999796">
6.2 Translation Quality
</subsectionHeader>
<bodyText confidence="0.999901142857143">
In evaluating downstream translation quality, we
build three translation systems each for Arabic-
English and Chinese-English: one with align-
ments from GIZA++, one with alignments from our
syntactically-informed discriminative model, and
one with alignments from our model with iterative
inference (Section 5). For each of these systems we
</bodyText>
<page confidence="0.997185">
503
</page>
<table confidence="0.9953698">
GIZA++ M4 grow-diag-final
Target-tree alignments only
with Iterative Inference (grow-diag-final)
with Iterative Inference (intersection)
Arabic-English Chinese-English
F P R F P R
72.5 74.5 70.5 71.7 71.4 72.0
86.8 89.1 84.6 84.4 89.4 80.0
87.6 89.7 85.6 87.0 90.0 84.1
83.4 93.1 75.6 83.1 95.4 73.6
</table>
<tableCaption confidence="0.995926">
Table 2: F-measure, Precision, Recall for GIZA++ Model-4, and for alignments from this work. GIZA++
</tableCaption>
<bodyText confidence="0.977306194444444">
was trained on 223M words for Arabic-English, and 261M words for Chinese-English. We observe very
large gains in accuracy of 15 points for both language pairs. Iterative inference with source and target-tree
alignments yields a large effect on Chinese-English recall, and a modest improvement in Arabic-English.
align our parallel training corpora described in Sec-
tion 6.1, and compute word-based lexical weighting
features (Koehn et al., 2003) based on these align-
ments.
Because of the number of experiments involved
in this research, we needed to accelerate our down-
stream experimental pipeline. While we align our
full training corpus, we extract translation rules from
a subset of our alignment training data; the quality of
the translation rules extracted is still a function of the
original alignment model.
We train a syntax-based string-to-tree translation
model (Galley et al., 2004; Galley et al., 2006) and
extract translation rules7 using alignments produced
by each system from 4.25+5.43M words for Arabic-
English and 31.8+37.7M words for Chinese-English.
For Arabic-English, we tune our MT system on a
held-out development corpus of 1,172 parallel sen-
tences, and test on a heldout set of 746 parallel
sentences with four references each. For Chinese-
English we tune our MT system on a held-out de-
velopment corpus of 4,089 parallel sentences, and
test on a set of 4,060 sentences with four references
each. We tune the translation models for these sys-
tems with MIRA (Watanabe et al., 2007; Chiang et
al., 2008). Our tuning and test corpora are drawn
from the NIST 2004 and 2006 evaluation data, dis-
joint from our rule-extraction data. All systems used
two language models; one trained on the combined
English sides of our Arabic-English and Chinese-
English data (480M words), and one trained on 4 bil-
lion words of English data.
MT results are shown in Table 3. We show a gain
</bodyText>
<footnote confidence="0.914142">
7We use the so-called composed rules of (Galley et al., 2006).
</footnote>
<table confidence="0.999543666666667">
Alignment model ara-eng chi-eng
BLEU BLEU
GIZA++ Model-4 47.6 26.2
Target-tree alignments only 48.3* 26.4+
+Iterative Inference (gdf) 48.4 27.0*
+Iterative Inference (intersection) 48.6+ 27.5*
</table>
<tableCaption confidence="0.99652">
Table 3: IBM BLEU scores using a syntax-based
</tableCaption>
<bodyText confidence="0.99461605">
MT system. We show statistically significant gains
in both language pairs over unsupervized GIZA++
Model 4 trained on very large corpora. An asterisk
(*) denotes a statistically significant improvement
with p &lt; 0.01 over the number immediately above;
a (+) denotes p &lt; 0.05.
of 1.0 and 1.3 BLEU points over GIZA++ Model-4.
Each is statistically significant over the baseline.
In the case of Chinese-English, we see a 1.1 BLEU
gain when using iterative inference over the standard
model which provides only target-tree alignments.
As measured by a bootstrap resampler, this improve-
ment is statistically significant, with p &lt; 0.01.
For Arabic-English, we see a BLEU gain of 0.7
with target-tree alignments alone, and a total 1.0
BLEU gain over the baseline with iterative inference
and our joint-agreement features.
We expect the limited improvement of iterative in-
ference for Arabic-English is due to at least two fac-
tors:
</bodyText>
<listItem confidence="0.968235">
1. the relative weakness of our Arabic parser, and
2. as shown in Table 2, our Arabic target-tree
alignments are already quite accurate.
</listItem>
<page confidence="0.997875">
504
</page>
<sectionHeader confidence="0.999096" genericHeader="evaluation">
7 Discussion
</sectionHeader>
<bodyText confidence="0.998277163934426">
We achieve our best downstream BLEU results when
using iterative inference with source-tree and target-
tree alignments, keeping the intersection.8 These
alignments have been shown to have recall in a sim-
ilar neighborhood as our unsupervised baseline, but
extremely high precision.
As DeNero and Klein (2010) and others have
observed, the relationship between word alignment
evaluation metrics and BLEU score remains tenu-
ous at best. While we are able to induce some of
the most accurate alignments we have seen to date,
it remains unclear, given our gold hand-aligned data,
whether we are optimizing for the right function ulti-
mately for the translation task. Related metrics, like
Rule F-measure (Fossum et al., 2008) and Transla-
tion Unit Error Rate (Sogaard and Kuhn, 2009), are
still functions of a given gold alignment. If the gold
alignment is not ideally annotated for the translation
task, it matters little what our alignment evaluation
metric is.
Why do grow-diag-final alignments (for our sys-
tem) not perform as well? We believe the answer lies
in the fact that these alignments too closely resemble
the gold alignments with word-alignment annotation
standards9 that do not handle function words ideally
for the translation task. Indeed, Hermjakob (2009)
reports improved BLEU with a hand-modified gold
standard.
Interestingly, the places in which our source-tree
and target-tree alignments most often disagree is in
the alignment of function words with no clear trans-
lation in the opposite language. For example, En-
glish the has no translation in Chinese. Our inter-
section alignments generally leave the unaligned to
Chinese words, whereas in our gold alignments the
is generally aligned to the same word as the head of
the NP in which it appears.10
We see our best translation performance with our
8Intersection symmetrization does not help GIZA++ because
the resulting recall is so low as to severely limit the usefulness
of direct translation rule extraction with such alignments (49.7
Recall for Chi-Eng; 47.2 Recall for Ara-Eng).
9We refer to those used for data used in this work,
LDC2006E86 and LDC2006E93, as well as the standards for
later hand-aligned data developed for the GALE program.
10E.g., ((the country , PJ⭨)); but not, ((the, 0); (coun-
try, PJ⭨))
intersection alignments because we believe it largely
leaves untranslated words and words without clear
translations in the opposite language unaligned; we
believe this may be the right thing to do.11 Con-
tinuing with the the example, our translation model
learns to insert words like the where appropriate,
and such insertion rules are validated by the lan-
guage model. We learn with good coverage accurate
high-precision translation rules for content words,
and general insertion rules for words like the, instead
of learning two unique lexicalized rules for a given
content word, one with and one without the. In this
way, we are learning a more general grammar that
explains the data.
</bodyText>
<sectionHeader confidence="0.998455" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999981388888889">
In this work we are closing the gap between trans-
lation and alignment models in terms of syntactic
sophistication. We have (1) shown how to effi-
ciently extract hundreds of thousands of language-
independent syntactic features useful for alignment,
(2) given a detailed analysis of the types of linguistic
phenomena these varied features generalize, and (3)
report significant gains not only on alignment quality
but also on downstream machine translation quality
(1.0+ BLEU) over very strong baselines across di-
verse language pairs.
We have also hinted at roadblocks to improved dis-
criminative alignment modeling for translation. We
expect that an accurate discriminative word align-
ment system, such as the one presented here, in con-
junction with better annotation standards for align-
ment will take us even farther beyond the advance-
ments in translation quality shown here.
</bodyText>
<sectionHeader confidence="0.994208" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999812">
The authors would like to thank David Chi-
ang, Steve DeNeefe, Liang Huang, Kevin Knight,
Jonathan May, and the anonymous reviewers for
their thoughtful comments. This work was sup-
ported in part by NSF IIS-0908532, DARPA con-
tract HR0011-06-C-0022 under subcontract to BBN
Technologies, and a USC CREATE Fellowship to
the first author.
</bodyText>
<footnote confidence="0.853881666666667">
11Naively leaving all function words unaligned is likely sub-
optimal, as many have seem to have direct translations in some
contexts; cf. (of, Ϧϣ) and (of, n).
</footnote>
<page confidence="0.996622">
505
</page>
<sectionHeader confidence="0.982713" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985857631067961">
Phil Blunsom and Trevor Cohn. 2006. Discriminative
word alignment with conditional random fields. In
Proceedings of COLING-ACL, pages 65-72, Sydney,
Australia.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and R. L. Mercer. 1993. The mathematics of
statistical machine translation: parameter estimation.
Computational Linguistics, 19(2):263-311.
David Burkett, John Blitzer, and Dan Klein. 2010.
Joint parsing and alignment with weakly synchronized
grammars. In Proceedings of NAACL HLT 2010, pages
127-135, Los Angeles, CA. USA.
Colin Cherry and Dekang Lin. 2006. Soft syntac-
tic constraints for word alignment through discrimina-
tive training. In Proceedings of COLING/ACL, pages
105-112, Sydney, Australia. Association for Computa-
tional Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and structural
translation features. In Proceedings of the Conference
on Empirical Methods in Natural Language Processing
(EMNLP), pages 224-233, Honolulu, HI. USA.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201-228.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of the 48th Annual
Meeting of the ACL, pages 1443-1452, Uppsala, Swe-
den.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP, pages 1-8, Philadelphia, PA. USA.
John DeNero and Dan Klein. 2007. Tailoring word align-
ments to syntactic machine translation. In Proceedings
of the 45th annual meeting of the ACL, pages 17-24,
Prague, Czech Republic.
John DeNero and Dan Klein. 2010. Discriminative mod-
eling of extraction sets for machine translation. In Pro-
ceedings of NAACL HLT 2010, pages 1453-1463, Los
Angeles, CA. USA.
Victoria Fossum, Kevin Knight, and Steven Abney. 2008.
Using syntax to improve word alignment for syntax-
based statistical machine translation. In Proceedings of
ACL MT Workshop, pages 44-52, Honolulu, HI. USA.
Alexander Fraser and Daniel Marcu. 2007. Getting the
structure right for word alignment: LEAF. In Proceed-
ings of EMNLP-CoNLL, pages 51-60, Prague, Czech
Republic.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What&apos;s in a translation rule? In Pro-
ceedings of HLT-NAACL, pages 273-280.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proceed-
ings of COLING-ACL, pages 961-968, Sydney, Aus-
tralia. Association for Computational Linguistics.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with supervised
itg models. In Proceedings of the Joint Conference of
the ACL and IJCNLP, pages 923-931, Singapore, Au-
gust.
Ulf Hermjakob. 2009. Improved word alignment with
statistics and linguistic heuristics. In Proceedings of
EMNLP, pages 229-237, Singapore.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings
of EMNLP 2010, pages 273-283, Boston, MA. USA.
Abraham Ittycheriah and Salim Roukos. 2005. A maxi-
mum entropy word aligner for Arabic-English machine
translation. In Proceedings of HLT-EMNLP, pages
89-96, Vancouver, Canada.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT-NAACL, pages 127-133, Edmonton, Canada.
Simon Lacoste-Julien, Dan Klein, Ben Taskar, and
Michael Jordan. 2006. Word alignment via quadratic
assignment. In Proceedings of HLT-NAACL, pages
112-119, New York, NY. USA.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-
itkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren
Thornton, Jonathan Weese, and Omar Zaidan. 2009.
Joshua: An open source toolkit for parsing-based
machine translation. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
135-139, Athens, Greece.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear
models for word alignment. In Proceedings of the 43rd
annual meeting of the ACL, pages 459-466, Ann Arbor,
MI.
Yang Liu, Yajuan La, and Qun Liu. 2009a. Improving
tree-to-tree translation with packed forests. In Pro-
ceedings of the 47th Annual Meeting of the ACL and
the 4th IJCNLP of the AFNLP, pages 558-566, Singa-
pore.
Yang Liu, Tian Xia, Xinyan Xiao, and Qun Liu.
2009b. Weighted alignment matrices for statistical ma-
chine translation. In Proceedings of EMNLP, pages
1017-1026, Singapore.
Jonathan May and Kevin Knight. 2007. Syntactic re-
alignment models for machine translation. In Proceed-
ings ofEMNLP, pages 360-368, Prague, Czech Repub-
lic.
</reference>
<page confidence="0.981944">
506
</page>
<reference confidence="0.999831567164179">
Ryan McDonald, Keith Hall, and Gideon Mann. 2010.
Distributed training strategies for the structured per-
ceptron. In Proceedings of NAACL HLT, pages
456-464, Los Angeles, CA. USA.
Robert C. Moore, Wen-Tau Yih, and Andreas Bode.
2006. Improved discriminative bilingual word align-
ment. In Proceedings of COLING-ACL, pages
513-520, Sydney, Australia.
Robert C. Moore. 2005. A discriminative framework
for bilingual word alignment. In Proceedings of HLT-
EMNLP, pages 81-88, Vancouver, Canada.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency parsers.
In Proceedings of the 46th Annual Meeting of the ACL,
pages 950-958, Columbus, OH. USA.
Franz J. Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19-51.
Adam Pauls and Dan Klein. 2010. Unsupervised syntac-
tic alignment with inversion transduction grammars. In
Proceedings of NAACL HLT 2010, pages 118-126, Los
Angeles, CA. USA.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of NAACL
HLT, pages 404-411, Rochester, NY. USA.
Jason Riesa and Daniel Marcu. 2010. Hierarchical search
for word alignment. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 157-166, Uppsala, Sweden.
Anders Sogaard and Jonas Kuhn. 2009. Empirical lower
bounds on alignment error rates in syntax-based ma-
chine translation. In SSST &apos;09: Proceedings of the
Third Workshop on Syntax and Structure in Statistical
Translation, pages 19-27. Association for Computa-
tional Linguistics.
Ben Taskar, Vassil Chatalbashev, Daphne Koller, and
Carlos Guestrin. 2005a. Learning structured predic-
tion models: A large margin approach. In Proceedings
of ICML, pages 896-903, Bonn, Germany.
Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
2005b. A discriminative matching approach to word
alignment. In Proceedings of HLT-EMNLP, pages
73-80, Vancouver, Canada.
Tsochantaridis, Thomas Hofmann, Thorsten Joachims,
and Yasemin Altun. 2004. Support vector ma-
chine learning for interdependent and structured output
spaces. In Proceedings of ICML, Banff, AB. Canada.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2008. Wider pipelines: N-best
alignments and parses in MT training. In Proceedings
of AMTA, pages 192-201, Honolulu, HI. USA.
Taro Watanabe, Jun Suzuki, Hajime Tsukuda, and Hideki
Isozaki. 2007. Online large-margin training for statis-
tical machine translation. In Proceedings of EMNLP,
pages 764-773.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377-403.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,
Chew Lim Tan, and Sheng Li. 2008. A tree sequence
alignment-based tree-to-tree translation model. In Pro-
ceedings of ACL-08: HLT, pages 559-567, Columbus,
OH. USA.
Andreas Zollman and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
NAACL 2006 Workshop on Statistical Machine Trans-
lation, pages 138-141, Rochester, NY. USA.
</reference>
<page confidence="0.997135">
507
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.146990">
<title confidence="0.795642333333333">Feature-Rich Language-Independent Syntax-Based Alignment Statistical Machine Translation Sciences</title>
<affiliation confidence="0.968258">University of Southern</affiliation>
<address confidence="0.617819">Marina del Rey, CA</address>
<abstract confidence="0.999641210526316">We present an accurate word alignment algorithm that heavily exploits source and targetlanguage syntax. Using a discriminative framework and an efficient bottom-up search algorithm, we train a model of hundreds of thousands of syntactic features. Our new model (1) helps us to very accurately model syntactic transformations between languages; (2) is language-independent; and (3) with automatic feature extraction, assists system developers in obtaining good word-alignment performance off-the-shelf when tackling new language pairs. We analyze the impact of our features, describe inference under the model, and demonstrate significant alignment and translation quality improvements over already-powerful baselines trained on very large corpora. We observe translation quality improvements correspond-</abstract>
<note confidence="0.6575315">ing to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
</authors>
<title>Discriminative word alignment with conditional random fields.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<pages>65--72</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2556" citStr="Blunsom and Cohn, 2006" startWordPosition="366" endWordPosition="369"> 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three k</context>
</contexts>
<marker>Blunsom, Cohn, 2006</marker>
<rawString>Phil Blunsom and Trevor Cohn. 2006. Discriminative word alignment with conditional random fields. In Proceedings of COLING-ACL, pages 65-72, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="2025" citStr="Brown et al., 1993" startWordPosition="286" endWordPosition="289">es separately (Galley et al., 2006; Zollman and Venugopal, 2006; Huang and Mi, 2010), others project syntactic parses across word alignments (Li et al., 2009). In both approaches, as in largely all statistical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recentl</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>John Blitzer</author>
<author>Dan Klein</author>
</authors>
<title>Joint parsing and alignment with weakly synchronized grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT 2010,</booktitle>
<pages>127--135</pages>
<publisher>USA.</publisher>
<location>Los Angeles, CA.</location>
<contexts>
<context position="2897" citStr="Burkett et al., 2010" startWordPosition="420" endWordPosition="423"> upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Our model and inference support arbitrary features, and easily scale</context>
<context position="13053" citStr="Burkett et al. (2010)" startWordPosition="2115" endWordPosition="2118">-time matched in a set of rules extracted offline from our hand-aligned data. However, coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one word to the other, e.g. (in, V...㺲), or the first and last Chinese words in the examples in Figure 3. Extracted Rule Feature Weight Figu</context>
</contexts>
<marker>Burkett, Blitzer, Klein, 2010</marker>
<rawString>David Burkett, John Blitzer, and Dan Klein. 2010. Joint parsing and alignment with weakly synchronized grammars. In Proceedings of NAACL HLT 2010, pages 127-135, Los Angeles, CA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>105--112</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="9471" citStr="Cherry and Lin, 2006" startWordPosition="1530" endWordPosition="1533"> jointly take into account both source- and target-side information. 3.1 Target Syntax Features Most alignment systems currently function without explicit regard to the downstream translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A significant motivation for this work is the desire to make the connection, at alignment time, between translation rules used in decod</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of COLING/ACL, pages 105-112, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>224--233</pages>
<location>Honolulu, HI. USA.</location>
<contexts>
<context position="27837" citStr="Chiang et al., 2008" startWordPosition="4643" endWordPosition="4646">t al., 2006) and extract translation rules7 using alignments produced by each system from 4.25+5.43M words for ArabicEnglish and 31.8+37.7M words for Chinese-English. For Arabic-English, we tune our MT system on a held-out development corpus of 1,172 parallel sentences, and test on a heldout set of 746 parallel sentences with four references each. For ChineseEnglish we tune our MT system on a held-out development corpus of 4,089 parallel sentences, and test on a set of 4,060 sentences with four references each. We tune the translation models for these systems with MIRA (Watanabe et al., 2007; Chiang et al., 2008). Our tuning and test corpora are drawn from the NIST 2004 and 2006 evaluation data, disjoint from our rule-extraction data. All systems used two language models; one trained on the combined English sides of our Arabic-English and ChineseEnglish data (480M words), and one trained on 4 billion words of English data. MT results are shown in Table 3. We show a gain 7We use the so-called composed rules of (Galley et al., 2006). Alignment model ara-eng chi-eng BLEU BLEU GIZA++ Model-4 47.6 26.2 Target-tree alignments only 48.3* 26.4+ +Iterative Inference (gdf) 48.4 27.0* +Iterative Inference (inter</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 224-233, Honolulu, HI. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<pages>33--2</pages>
<contexts>
<context position="6436" citStr="Chiang, 2007" startWordPosition="1006" endWordPosition="1007"> 5. Each black square represents a partial alignment; larger grey-shaded boxes are links in an alignment. Each partial alignment at each node is ranked according to its model score. The root node, S, contains a k-best list of full alignments. child NN. At the root node, we have a k-best list of full alignments. We continue with a procedural description of the algorithm. 2.1.1 Initialization We begin by visiting each preterminal node in sequence. We enumerate and score all one-to-one links as well as the unaligned link (aligned to null). Next, for a given preterminal node, we use cube pruning (Chiang, 2007) to find the top k one-to-two alignments, given the scores of the one-to-one links. We perform additional iterations of cube pruning to find top k sets of one-to-m links. In theory, we could increase m to the length of the foreign sentence and enumerate top k lists for each English word aligned to between 0 and all foreign words. However, in practice we set m to limit time spent here, while maintaining acceptable recall. In our experiments we set m = 2 for both English-Arabic and EnglishChinese. DT stage 台 上 挂 a 台 上 挂 着 国旗 S NP VP PP NP DT NN 台 上 挂 S VP PP NP 着 VBDIN DT NN 国旗 VP 台 上 挂 着 NP PP </context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201-228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Learning to translate with source and target syntax.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the ACL,</booktitle>
<pages>1443--1452</pages>
<location>Uppsala,</location>
<contexts>
<context position="12951" citStr="Chiang, 2010" startWordPosition="2098" endWordPosition="2099">y experiments involved only firing indicator rule features when an extracted rule at alignment-time matched in a set of rules extracted offline from our hand-aligned data. However, coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one word to the other, e.g. (in, V...㺲</context>
</contexts>
<marker>Chiang, 2010</marker>
<rawString>David Chiang. 2010. Learning to translate with source and target syntax. In Proceedings of the 48th Annual Meeting of the ACL, pages 1443-1452, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1--8</pages>
<location>Philadelphia, PA. USA.</location>
<contexts>
<context position="4567" citStr="Collins, 2002" startWordPosition="673" endWordPosition="674">e corpora. 2 A Feature-Rich Syntax-Aware Alignment Model We follow Riesa and Marcu (2010) for efficient inference with arbitrary features, but do not rely upon hand-crafted syntactic patterns; rather, we extract syntactic features automatically from training data. We also introduce, in Section 5, an iterative approximate Viterbi inference procedure to deal with the asymmetry of the model. We show that this boosts both alignment and downstream translation quality even further. The model itself is a linear combination of features, whose parameters are learned online via a structured perceptron (Collins, 2002). However, as we describe in Section 3, the features of the model are not known a priori. In what follows, we describe the search algorithm so that the reader has an understanding of the domain of locality before we begin to describe features and how they are learned. 2.1 Search Overview We formulate the search for the best alignment as bottom-up parsing. Given a syntactic parse tree on one side of a parallel sentence, we use the structure of the tree to guide the search process. The key idea is that complex interactions between alignments are less likely to cross constituents, so we search re</context>
<context position="18631" citStr="Collins, 2002" startWordPosition="3128" endWordPosition="3129">ghts for model features that fire for alignments that oblige the firing of features of very dissimilar nonterminal labels, and that often yield asynchronous bracketing. For example, the Arabic model learns that English words that form prepositional phrases should 4In Table 1, Chinese feature [1]. 501 not align to sets of Arabic words that form entire sentences or verb phrases5. In total, we learn 127,932 syntactic coordination features in our Arabic-English model; 59,239 for Chinese-English. 4 Learning We learn feature weights using a parallelized implementation of online averaged perceptron (Collins, 2002). We distribute training examples to CPUs in a cluster and essentially run several perceptron learners in parallel. We communicate and average the weight vectors of each learner according to the Iterative Parameter Mixing strategy described by McDonald et al. (2010). Let yi be the correct output for input xi. Here, yi is an alignment; xi is a sentence pair and parse tree. At each iteration, our perceptron update is: w (-- w + h(yi) − h(ˆy) (3) And we define: yˆ = arg max f(yi, y) + w - h(y) (4) yEY(xi) f(yi, y) = 1 − F1(yi, y) (5) with w our weight vector, h(y) our sparse vector of feature val</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of EMNLP, pages 1-8, Philadelphia, PA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th annual meeting of the ACL,</booktitle>
<pages>17--24</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2809" citStr="DeNero and Klein, 2007" startWordPosition="404" endWordPosition="407">ous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model a</context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In Proceedings of the 45th annual meeting of the ACL, pages 17-24, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Discriminative modeling of extraction sets for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT 2010,</booktitle>
<pages>1453--1463</pages>
<publisher>USA.</publisher>
<location>Los Angeles, CA.</location>
<contexts>
<context position="9650" citStr="DeNero and Klein, 2010" startWordPosition="1558" endWordPosition="1561">eam translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A significant motivation for this work is the desire to make the connection, at alignment time, between translation rules used in decoding and the alignments that yield such translation rules. To do this, we fold the rule extraction process into the alignment search. At each step in the search process, we can ext</context>
<context position="29886" citStr="DeNero and Klein (2010)" startWordPosition="4972" endWordPosition="4975"> iterative inference and our joint-agreement features. We expect the limited improvement of iterative inference for Arabic-English is due to at least two factors: 1. the relative weakness of our Arabic parser, and 2. as shown in Table 2, our Arabic target-tree alignments are already quite accurate. 504 7 Discussion We achieve our best downstream BLEU results when using iterative inference with source-tree and targettree alignments, keeping the intersection.8 These alignments have been shown to have recall in a similar neighborhood as our unsupervised baseline, but extremely high precision. As DeNero and Klein (2010) and others have observed, the relationship between word alignment evaluation metrics and BLEU score remains tenuous at best. While we are able to induce some of the most accurate alignments we have seen to date, it remains unclear, given our gold hand-aligned data, whether we are optimizing for the right function ultimately for the translation task. Related metrics, like Rule F-measure (Fossum et al., 2008) and Translation Unit Error Rate (Sogaard and Kuhn, 2009), are still functions of a given gold alignment. If the gold alignment is not ideally annotated for the translation task, it matters</context>
</contexts>
<marker>DeNero, Klein, 2010</marker>
<rawString>John DeNero and Dan Klein. 2010. Discriminative modeling of extraction sets for machine translation. In Proceedings of NAACL HLT 2010, pages 1453-1463, Los Angeles, CA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Fossum</author>
<author>Kevin Knight</author>
<author>Steven Abney</author>
</authors>
<title>Using syntax to improve word alignment for syntaxbased statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL MT Workshop,</booktitle>
<pages>44--52</pages>
<location>Honolulu, HI. USA.</location>
<contexts>
<context position="2852" citStr="Fossum et al., 2008" startWordPosition="412" endWordPosition="415">ining accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Our model and inference</context>
<context position="30297" citStr="Fossum et al., 2008" startWordPosition="5039" endWordPosition="5042">argettree alignments, keeping the intersection.8 These alignments have been shown to have recall in a similar neighborhood as our unsupervised baseline, but extremely high precision. As DeNero and Klein (2010) and others have observed, the relationship between word alignment evaluation metrics and BLEU score remains tenuous at best. While we are able to induce some of the most accurate alignments we have seen to date, it remains unclear, given our gold hand-aligned data, whether we are optimizing for the right function ultimately for the translation task. Related metrics, like Rule F-measure (Fossum et al., 2008) and Translation Unit Error Rate (Sogaard and Kuhn, 2009), are still functions of a given gold alignment. If the gold alignment is not ideally annotated for the translation task, it matters little what our alignment evaluation metric is. Why do grow-diag-final alignments (for our system) not perform as well? We believe the answer lies in the fact that these alignments too closely resemble the gold alignments with word-alignment annotation standards9 that do not handle function words ideally for the translation task. Indeed, Hermjakob (2009) reports improved BLEU with a hand-modified gold stand</context>
</contexts>
<marker>Fossum, Knight, Abney, 2008</marker>
<rawString>Victoria Fossum, Kevin Knight, and Steven Abney. 2008. Using syntax to improve word alignment for syntaxbased statistical machine translation. In Proceedings of ACL MT Workshop, pages 44-52, Honolulu, HI. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Getting the structure right for word alignment: LEAF.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>51--60</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2785" citStr="Fraser and Marcu, 2007" startWordPosition="400" endWordPosition="403">e. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and pa</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Getting the structure right for word alignment: LEAF. In Proceedings of EMNLP-CoNLL, pages 51-60, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What&apos;s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>273--280</pages>
<contexts>
<context position="10850" citStr="Galley et al., 2004" startWordPosition="1754" endWordPosition="1757">process, we can extract translation rules from a given partial alignment and encode them as binary features. Importantly, the rule extraction process itself is not directly tied to the alignment system, but rather to the downstream translation model. We can drop in any type of rule extraction we like into the alignment system, though some may generalize better than others to new data in a large corpus. This is key for supervised training conditions with relatively small amounts of annotated data.2 In this work we focus on string-to-tree translation and the translation rule space described in (Galley et al., 2004; Galley et al., 2006). During training and inference, we are constantly scoring partial alignments. Every time we have a partial alignment to score, we can extract all potential translation rules implied by that alignment, and encode those rules as features. In this case, we are doing two important things: 1. informing the alignment search with the rules of the translation model, and 2. modeling actual translation rules — the model parameters give us a way to quantify the relative importance of each rule. For example, we learn that: 2For example, fully lexicalized phrase-based rules are less </context>
<context position="27207" citStr="Galley et al., 2004" startWordPosition="4538" endWordPosition="4541">a modest improvement in Arabic-English. align our parallel training corpora described in Section 6.1, and compute word-based lexical weighting features (Koehn et al., 2003) based on these alignments. Because of the number of experiments involved in this research, we needed to accelerate our downstream experimental pipeline. While we align our full training corpus, we extract translation rules from a subset of our alignment training data; the quality of the translation rules extracted is still a function of the original alignment model. We train a syntax-based string-to-tree translation model (Galley et al., 2004; Galley et al., 2006) and extract translation rules7 using alignments produced by each system from 4.25+5.43M words for ArabicEnglish and 31.8+37.7M words for Chinese-English. For Arabic-English, we tune our MT system on a held-out development corpus of 1,172 parallel sentences, and test on a heldout set of 746 parallel sentences with four references each. For ChineseEnglish we tune our MT system on a held-out development corpus of 4,089 parallel sentences, and test on a set of 4,060 sentences with four references each. We tune the translation models for these systems with MIRA (Watanabe et a</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What&apos;s in a translation rule? In Proceedings of HLT-NAACL, pages 273-280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<pages>961--968</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia.</location>
<contexts>
<context position="1440" citStr="Galley et al., 2006" startWordPosition="193" endWordPosition="196">atures, describe inference under the model, and demonstrate significant alignment and translation quality improvements over already-powerful baselines trained on very large corpora. We observe translation quality improvements corresponding to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively. 1 Introduction In recent years, several state-of-the-art statistical machine translation (MT) systems have incorporated both source and target syntax into the grammars that they generate and use to translate. While some treeto-tree systems parse source and target sentences separately (Galley et al., 2006; Zollman and Venugopal, 2006; Huang and Mi, 2010), others project syntactic parses across word alignments (Li et al., 2009). In both approaches, as in largely all statistical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally req</context>
<context position="10872" citStr="Galley et al., 2006" startWordPosition="1758" endWordPosition="1761">ct translation rules from a given partial alignment and encode them as binary features. Importantly, the rule extraction process itself is not directly tied to the alignment system, but rather to the downstream translation model. We can drop in any type of rule extraction we like into the alignment system, though some may generalize better than others to new data in a large corpus. This is key for supervised training conditions with relatively small amounts of annotated data.2 In this work we focus on string-to-tree translation and the translation rule space described in (Galley et al., 2004; Galley et al., 2006). During training and inference, we are constantly scoring partial alignments. Every time we have a partial alignment to score, we can extract all potential translation rules implied by that alignment, and encode those rules as features. In this case, we are doing two important things: 1. informing the alignment search with the rules of the translation model, and 2. modeling actual translation rules — the model parameters give us a way to quantify the relative importance of each rule. For example, we learn that: 2For example, fully lexicalized phrase-based rules are less useful here than gappe</context>
<context position="27229" citStr="Galley et al., 2006" startWordPosition="4542" endWordPosition="4545">in Arabic-English. align our parallel training corpora described in Section 6.1, and compute word-based lexical weighting features (Koehn et al., 2003) based on these alignments. Because of the number of experiments involved in this research, we needed to accelerate our downstream experimental pipeline. While we align our full training corpus, we extract translation rules from a subset of our alignment training data; the quality of the translation rules extracted is still a function of the original alignment model. We train a syntax-based string-to-tree translation model (Galley et al., 2004; Galley et al., 2006) and extract translation rules7 using alignments produced by each system from 4.25+5.43M words for ArabicEnglish and 31.8+37.7M words for Chinese-English. For Arabic-English, we tune our MT system on a held-out development corpus of 1,172 parallel sentences, and test on a heldout set of 746 parallel sentences with four references each. For ChineseEnglish we tune our MT system on a held-out development corpus of 4,089 parallel sentences, and test on a set of 4,060 sentences with four references each. We tune the translation models for these systems with MIRA (Watanabe et al., 2007; Chiang et al</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of COLING-ACL, pages 961-968, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better word alignments with supervised itg models.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the ACL and IJCNLP,</booktitle>
<pages>923--931</pages>
<contexts>
<context position="2875" citStr="Haghighi et al., 2009" startWordPosition="416" endWordPosition="419"> on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Our model and inference support arbitrary feat</context>
<context position="9495" citStr="Haghighi et al., 2009" startWordPosition="1534" endWordPosition="1537">ount both source- and target-side information. 3.1 Target Syntax Features Most alignment systems currently function without explicit regard to the downstream translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A significant motivation for this work is the desire to make the connection, at alignment time, between translation rules used in decoding and the alignments t</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero, and Dan Klein. 2009. Better word alignments with supervised itg models. In Proceedings of the Joint Conference of the ACL and IJCNLP, pages 923-931, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
</authors>
<title>Improved word alignment with statistics and linguistic heuristics.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>229--237</pages>
<contexts>
<context position="30843" citStr="Hermjakob (2009)" startWordPosition="5127" endWordPosition="5128">ation task. Related metrics, like Rule F-measure (Fossum et al., 2008) and Translation Unit Error Rate (Sogaard and Kuhn, 2009), are still functions of a given gold alignment. If the gold alignment is not ideally annotated for the translation task, it matters little what our alignment evaluation metric is. Why do grow-diag-final alignments (for our system) not perform as well? We believe the answer lies in the fact that these alignments too closely resemble the gold alignments with word-alignment annotation standards9 that do not handle function words ideally for the translation task. Indeed, Hermjakob (2009) reports improved BLEU with a hand-modified gold standard. Interestingly, the places in which our source-tree and target-tree alignments most often disagree is in the alignment of function words with no clear translation in the opposite language. For example, English the has no translation in Chinese. Our intersection alignments generally leave the unaligned to Chinese words, whereas in our gold alignments the is generally aligned to the same word as the head of the NP in which it appears.10 We see our best translation performance with our 8Intersection symmetrization does not help GIZA++ beca</context>
</contexts>
<marker>Hermjakob, 2009</marker>
<rawString>Ulf Hermjakob. 2009. Improved word alignment with statistics and linguistic heuristics. In Proceedings of EMNLP, pages 229-237, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Haitao Mi</author>
</authors>
<title>Efficient incremental decoding for tree-to-string translation.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>273--283</pages>
<publisher>USA.</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="1490" citStr="Huang and Mi, 2010" startWordPosition="202" endWordPosition="205">monstrate significant alignment and translation quality improvements over already-powerful baselines trained on very large corpora. We observe translation quality improvements corresponding to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively. 1 Introduction In recent years, several state-of-the-art statistical machine translation (MT) systems have incorporated both source and target syntax into the grammars that they generate and use to translate. While some treeto-tree systems parse source and target sentences separately (Galley et al., 2006; Zollman and Venugopal, 2006; Huang and Mi, 2010), others project syntactic parses across word alignments (Li et al., 2009). In both approaches, as in largely all statistical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The ad</context>
</contexts>
<marker>Huang, Mi, 2010</marker>
<rawString>Liang Huang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string translation. In Proceedings of EMNLP 2010, pages 273-283, Boston, MA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy word aligner for Arabic-English machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>89--96</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2492" citStr="Ittycheriah and Roukos, 2005" startWordPosition="354" endWordPosition="357">&apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previo</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. 2005. A maximum entropy word aligner for Arabic-English machine translation. In Proceedings of HLT-EMNLP, pages 89-96, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>127--133</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="26760" citStr="Koehn et al., 2003" startWordPosition="4468" endWordPosition="4471">84.4 89.4 80.0 87.6 89.7 85.6 87.0 90.0 84.1 83.4 93.1 75.6 83.1 95.4 73.6 Table 2: F-measure, Precision, Recall for GIZA++ Model-4, and for alignments from this work. GIZA++ was trained on 223M words for Arabic-English, and 261M words for Chinese-English. We observe very large gains in accuracy of 15 points for both language pairs. Iterative inference with source and target-tree alignments yields a large effect on Chinese-English recall, and a modest improvement in Arabic-English. align our parallel training corpora described in Section 6.1, and compute word-based lexical weighting features (Koehn et al., 2003) based on these alignments. Because of the number of experiments involved in this research, we needed to accelerate our downstream experimental pipeline. While we align our full training corpus, we extract translation rules from a subset of our alignment training data; the quality of the translation rules extracted is still a function of the original alignment model. We train a syntax-based string-to-tree translation model (Galley et al., 2004; Galley et al., 2006) and extract translation rules7 using alignments produced by each system from 4.25+5.43M words for ArabicEnglish and 31.8+37.7M wor</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL, pages 127-133, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
<author>Michael Jordan</author>
</authors>
<title>Word alignment via quadratic assignment.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>112--119</pages>
<location>New York, NY. USA.</location>
<contexts>
<context position="2585" citStr="Lacoste-Julien et al., 2006" startWordPosition="370" endWordPosition="373">nding unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily explo</context>
</contexts>
<marker>Lacoste-Julien, Klein, Taskar, Jordan, 2006</marker>
<rawString>Simon Lacoste-Julien, Dan Klein, Ben Taskar, and Michael Jordan. 2006. Word alignment via quadratic assignment. In Proceedings of HLT-NAACL, pages 112-119, New York, NY. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Chris Callison-Burch</author>
<author>Chris Dyer</author>
<author>Juri Ganitkevitch</author>
<author>Sanjeev Khudanpur</author>
<author>Lane Schwartz</author>
<author>Wren Thornton</author>
<author>Jonathan Weese</author>
<author>Omar Zaidan</author>
</authors>
<title>Joshua: An open source toolkit for parsing-based machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>135--139</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="1564" citStr="Li et al., 2009" startWordPosition="213" endWordPosition="216">eady-powerful baselines trained on very large corpora. We observe translation quality improvements corresponding to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively. 1 Introduction In recent years, several state-of-the-art statistical machine translation (MT) systems have incorporated both source and target syntax into the grammars that they generate and use to translate. While some treeto-tree systems parse source and target sentences separately (Galley et al., 2006; Zollman and Venugopal, 2006; Huang and Mi, 2010), others project syntactic parses across word alignments (Li et al., 2009). In both approaches, as in largely all statistical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive</context>
</contexts>
<marker>Li, Callison-Burch, Dyer, Ganitkevitch, Khudanpur, Schwartz, Thornton, Weese, Zaidan, 2009</marker>
<rawString>Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren Thornton, Jonathan Weese, and Omar Zaidan. 2009. Joshua: An open source toolkit for parsing-based machine translation. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 135-139, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Log-linear models for word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd annual meeting of the ACL,</booktitle>
<pages>459--466</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="2510" citStr="Liu et al., 2005" startWordPosition="358" endWordPosition="361">e Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discrim</context>
</contexts>
<marker>Liu, Liu, Lin, 2005</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear models for word alignment. In Proceedings of the 43rd annual meeting of the ACL, pages 459-466, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Yajuan La</author>
<author>Qun Liu</author>
</authors>
<title>Improving tree-to-tree translation with packed forests.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP,</booktitle>
<pages>558--566</pages>
<contexts>
<context position="8264" citStr="Liu et al., 2009" startWordPosition="1353" endWordPosition="1356"> partial alignments at the PP. Search continues recursively up the tree, until we have reached the root node. The root node again computes the top k alignments from its children, and these comprise our final k-best list of full alignments. In our experiments we only make use of the 1- best alignment for evaluation and translation. Previous work has shown that only shallow k-best lists of alignments may be beneficial, and that very deep kbest lists are not especially useful in improving final downstream translation grammar extraction due to rapid degradation in quality (Venugopal et al., 2008; Liu et al., 2009b); though they may have other uses. 3 Automatically Exploiting Syntactic Features for Alignment Up to now, previous work in syntax-based alignment has largely modeled alignments based on features encoding target-side English syntactic and lexical information, but only lexical information on the source side. However, there is much more data waiting to be exploited, and the flexible model and efficient and modular learning framework of hierarchical discriminative alignment afford us this possibility. Here, we discuss our target-side features, source-side features, and features that jointly take</context>
<context position="12935" citStr="Liu et al., 2009" startWordPosition="2094" endWordPosition="2097">vely weighted. Early experiments involved only firing indicator rule features when an extracted rule at alignment-time matched in a set of rules extracted offline from our hand-aligned data. However, coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one word to the other,</context>
</contexts>
<marker>Liu, La, Liu, 2009</marker>
<rawString>Yang Liu, Yajuan La, and Qun Liu. 2009a. Improving tree-to-tree translation with packed forests. In Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 558-566, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Tian Xia</author>
<author>Xinyan Xiao</author>
<author>Qun Liu</author>
</authors>
<title>Weighted alignment matrices for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1017--1026</pages>
<contexts>
<context position="8264" citStr="Liu et al., 2009" startWordPosition="1353" endWordPosition="1356"> partial alignments at the PP. Search continues recursively up the tree, until we have reached the root node. The root node again computes the top k alignments from its children, and these comprise our final k-best list of full alignments. In our experiments we only make use of the 1- best alignment for evaluation and translation. Previous work has shown that only shallow k-best lists of alignments may be beneficial, and that very deep kbest lists are not especially useful in improving final downstream translation grammar extraction due to rapid degradation in quality (Venugopal et al., 2008; Liu et al., 2009b); though they may have other uses. 3 Automatically Exploiting Syntactic Features for Alignment Up to now, previous work in syntax-based alignment has largely modeled alignments based on features encoding target-side English syntactic and lexical information, but only lexical information on the source side. However, there is much more data waiting to be exploited, and the flexible model and efficient and modular learning framework of hierarchical discriminative alignment afford us this possibility. Here, we discuss our target-side features, source-side features, and features that jointly take</context>
<context position="12935" citStr="Liu et al., 2009" startWordPosition="2094" endWordPosition="2097">vely weighted. Early experiments involved only firing indicator rule features when an extracted rule at alignment-time matched in a set of rules extracted offline from our hand-aligned data. However, coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one word to the other,</context>
</contexts>
<marker>Liu, Xia, Xiao, Liu, 2009</marker>
<rawString>Yang Liu, Tian Xia, Xinyan Xiao, and Qun Liu. 2009b. Weighted alignment matrices for statistical machine translation. In Proceedings of EMNLP, pages 1017-1026, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
<author>Kevin Knight</author>
</authors>
<title>Syntactic realignment models for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings ofEMNLP,</booktitle>
<pages>360--368</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2831" citStr="May and Knight, 2007" startWordPosition="408" endWordPosition="411">ch and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Ou</context>
<context position="9099" citStr="May and Knight (2007)" startWordPosition="1472" endWordPosition="1475">ide English syntactic and lexical information, but only lexical information on the source side. However, there is much more data waiting to be exploited, and the flexible model and efficient and modular learning framework of hierarchical discriminative alignment afford us this possibility. Here, we discuss our target-side features, source-side features, and features that jointly take into account both source- and target-side information. 3.1 Target Syntax Features Most alignment systems currently function without explicit regard to the downstream translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target</context>
</contexts>
<marker>May, Knight, 2007</marker>
<rawString>Jonathan May and Kevin Knight. 2007. Syntactic realignment models for machine translation. In Proceedings ofEMNLP, pages 360-368, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Keith Hall</author>
<author>Gideon Mann</author>
</authors>
<title>Distributed training strategies for the structured perceptron.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<pages>456--464</pages>
<publisher>USA.</publisher>
<location>Los Angeles, CA.</location>
<contexts>
<context position="18897" citStr="McDonald et al. (2010)" startWordPosition="3168" endWordPosition="3172">hould 4In Table 1, Chinese feature [1]. 501 not align to sets of Arabic words that form entire sentences or verb phrases5. In total, we learn 127,932 syntactic coordination features in our Arabic-English model; 59,239 for Chinese-English. 4 Learning We learn feature weights using a parallelized implementation of online averaged perceptron (Collins, 2002). We distribute training examples to CPUs in a cluster and essentially run several perceptron learners in parallel. We communicate and average the weight vectors of each learner according to the Iterative Parameter Mixing strategy described by McDonald et al. (2010). Let yi be the correct output for input xi. Here, yi is an alignment; xi is a sentence pair and parse tree. At each iteration, our perceptron update is: w (-- w + h(yi) − h(ˆy) (3) And we define: yˆ = arg max f(yi, y) + w - h(y) (4) yEY(xi) f(yi, y) = 1 − F1(yi, y) (5) with w our weight vector, h(y) our sparse vector of feature values, Y(xi) all possible outputs for input xi, and F1(yi, y) balanced F-measure. The loss, f(yi, y), is a measure of how bad it would be to guess yˆ instead of y. In selecting ˆy, we draw upon the loss-augmented inference literature (Tsochantaridis et al., 2004; Task</context>
</contexts>
<marker>McDonald, Hall, Mann, 2010</marker>
<rawString>Ryan McDonald, Keith Hall, and Gideon Mann. 2010. Distributed training strategies for the structured perceptron. In Proceedings of NAACL HLT, pages 456-464, Los Angeles, CA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>Wen-Tau Yih</author>
<author>Andreas Bode</author>
</authors>
<title>Improved discriminative bilingual word alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<pages>513--520</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2606" citStr="Moore et al., 2006" startWordPosition="374" endWordPosition="377">ke the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and ta</context>
</contexts>
<marker>Moore, Yih, Bode, 2006</marker>
<rawString>Robert C. Moore, Wen-Tau Yih, and Andreas Bode. 2006. Improved discriminative bilingual word alignment. In Proceedings of COLING-ACL, pages 513-520, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A discriminative framework for bilingual word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of HLTEMNLP,</booktitle>
<pages>81--88</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2462" citStr="Moore, 2005" startWordPosition="352" endWordPosition="353">ystems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in </context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>Robert C. Moore. 2005. A discriminative framework for bilingual word alignment. In Proceedings of HLTEMNLP, pages 81-88, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL,</booktitle>
<pages>950--958</pages>
<location>Columbus, OH. USA.</location>
<contexts>
<context position="21206" citStr="Nivre and McDonald, 2008" startWordPosition="3580" endWordPosition="3583">search bottom-up on the sourcelanguage tree. The syntactic features we have described are generic enough that they will still be extractable and applicable. Because our model and inference procedure are asymmetric, a search on the source-language tree will generate alignments from a different space, and can provide a unique signal we would not otherwise have. We can use the Viterbi alignments from each model to inform the other. In the following we describe a method for simultaneously training both target-tree and source-tree models but with features to enforce agreement, somewhat similar to (Nivre and McDonald, 2008) in integrating two dependency parsing models. We begin by training two models, one that operates on the target tree, and one that operates on the source tree. Call the parameters learned from these models wt1 and ws1, respectively. Then, performing inference under these models yields alignments at1 and as1. In the next iteration we learn parameters wt2 and ws2, and introduce agreement features. In this step, during training to find wt2, the target-tree model uses as1 to fire indicator features. These fire for any alignment link that was also present in the previous iteration&apos;s source-tree ali</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings of the 46th Annual Meeting of the ACL, pages 950-958, Columbus, OH. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="2228" citStr="Och and Ney, 2003" startWordPosition="315" endWordPosition="318">tical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Unsupervised syntactic alignment with inversion transduction grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT 2010,</booktitle>
<pages>118--126</pages>
<publisher>USA.</publisher>
<location>Los Angeles, CA.</location>
<contexts>
<context position="2920" citStr="Pauls and Klein, 2010" startWordPosition="424" endWordPosition="427">cent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Our model and inference support arbitrary features, and easily scale to millions of feature</context>
<context position="9339" citStr="Pauls and Klein (2010)" startWordPosition="1509" endWordPosition="1512">iscriminative alignment afford us this possibility. Here, we discuss our target-side features, source-side features, and features that jointly take into account both source- and target-side information. 3.1 Target Syntax Features Most alignment systems currently function without explicit regard to the downstream translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A s</context>
</contexts>
<marker>Pauls, Klein, 2010</marker>
<rawString>Adam Pauls and Dan Klein. 2010. Unsupervised syntactic alignment with inversion transduction grammars. In Proceedings of NAACL HLT 2010, pages 118-126, Los Angeles, CA. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<pages>404--411</pages>
<location>Rochester, NY. USA.</location>
<contexts>
<context position="9830" citStr="Petrov and Klein, 2007" startWordPosition="1584" endWordPosition="1587">ing is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A significant motivation for this work is the desire to make the connection, at alignment time, between translation rules used in decoding and the alignments that yield such translation rules. To do this, we fold the rule extraction process into the alignment search. At each step in the search process, we can extract translation rules from a given partial alignment and encode them as binary features. Importantly, the rule extraction process itself is not directly tied to the alignment syst</context>
<context position="13142" citStr="Petrov and Klein, 2007" startWordPosition="2131" endWordPosition="2134">coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one word to the other, e.g. (in, V...㺲), or the first and last Chinese words in the examples in Figure 3. Extracted Rule Feature Weight Figure 2: Translation rules as features extracted during Arabic-English alignment. These rule</context>
<context position="24215" citStr="Petrov and Klein, 2007" startWordPosition="4073" endWordPosition="4076">we notice that less accurate models with narrower beams need to add more complexity in an attempt to make up for their many more mistakes. 6 Evaluation 6.1 Alignment Quality From LDC2006E86 and LDC2006E83, we use as training data 2,280 hand-aligned sentence pairs of Arabic-English and 1,102 for Chinese-English. We measure training convergence using a held-out development set of 100 sentence pairs for each language pair, and evaluate with F-measure on a heldout test set of 184 sentences pairs for ChineseEnglish and 364 sentence pairs for Arabic-English. We use instances of the Berkeley parser (Petrov and Klein, 2007) trained on the English Penn Treebank, Chinese Treebank 6, and the Arabic Treebank parts 1-3; for each language, trees are fixed at alignment time using the 1-best output from each parser. We use Model-4 symmetrized with the grow-diagfinal heuristic, trained with GIZA++ as a baseline alignment model. We train two GIZA++ models on our largest available Chinese-English and ArabicEnglish parallel corpora. These consist of 261M and 223M English words,6 respectively. The size of these corpora make for quite a powerful unsuper6These counts correspond to 240M words of Chinese and 194M words of Arabic</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of NAACL HLT, pages 404-411, Rochester, NY. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riesa</author>
<author>Daniel Marcu</author>
</authors>
<title>Hierarchical search for word alignment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>157--166</pages>
<location>Uppsala,</location>
<contexts>
<context position="2944" citStr="Riesa and Marcu, 2010" startWordPosition="428" endWordPosition="431">tive alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, and move forward in three key areas: 1. We heavily exploit both source and target syntax in ways that most models can not. In addition, during training we extract and learn hundreds of thousands of features automatically, learning both the structure and parameters for the model at the same time. 2. Our model and inference support arbitrary features, and easily scale to millions of features. 3. Having strengthene</context>
</contexts>
<marker>Riesa, Marcu, 2010</marker>
<rawString>Jason Riesa and Daniel Marcu. 2010. Hierarchical search for word alignment. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 157-166, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Sogaard</author>
<author>Jonas Kuhn</author>
</authors>
<title>Empirical lower bounds on alignment error rates in syntax-based machine translation.</title>
<date>2009</date>
<booktitle>In SSST &apos;09: Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>pages</pages>
<contexts>
<context position="30354" citStr="Sogaard and Kuhn, 2009" startWordPosition="5049" endWordPosition="5052"> alignments have been shown to have recall in a similar neighborhood as our unsupervised baseline, but extremely high precision. As DeNero and Klein (2010) and others have observed, the relationship between word alignment evaluation metrics and BLEU score remains tenuous at best. While we are able to induce some of the most accurate alignments we have seen to date, it remains unclear, given our gold hand-aligned data, whether we are optimizing for the right function ultimately for the translation task. Related metrics, like Rule F-measure (Fossum et al., 2008) and Translation Unit Error Rate (Sogaard and Kuhn, 2009), are still functions of a given gold alignment. If the gold alignment is not ideally annotated for the translation task, it matters little what our alignment evaluation metric is. Why do grow-diag-final alignments (for our system) not perform as well? We believe the answer lies in the fact that these alignments too closely resemble the gold alignments with word-alignment annotation standards9 that do not handle function words ideally for the translation task. Indeed, Hermjakob (2009) reports improved BLEU with a hand-modified gold standard. Interestingly, the places in which our source-tree a</context>
</contexts>
<marker>Sogaard, Kuhn, 2009</marker>
<rawString>Anders Sogaard and Jonas Kuhn. 2009. Empirical lower bounds on alignment error rates in syntax-based machine translation. In SSST &apos;09: Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation, pages 19-27. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Vassil Chatalbashev</author>
<author>Daphne Koller</author>
<author>Carlos Guestrin</author>
</authors>
<title>Learning structured prediction models: A large margin approach.</title>
<date>2005</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>896--903</pages>
<location>Bonn, Germany.</location>
<contexts>
<context position="2531" citStr="Taskar et al., 2005" startWordPosition="362" endWordPosition="365">iversity Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, an</context>
<context position="19512" citStr="Taskar et al., 2005" startWordPosition="3290" endWordPosition="3293">010). Let yi be the correct output for input xi. Here, yi is an alignment; xi is a sentence pair and parse tree. At each iteration, our perceptron update is: w (-- w + h(yi) − h(ˆy) (3) And we define: yˆ = arg max f(yi, y) + w - h(y) (4) yEY(xi) f(yi, y) = 1 − F1(yi, y) (5) with w our weight vector, h(y) our sparse vector of feature values, Y(xi) all possible outputs for input xi, and F1(yi, y) balanced F-measure. The loss, f(yi, y), is a measure of how bad it would be to guess yˆ instead of y. In selecting ˆy, we draw upon the loss-augmented inference literature (Tsochantaridis et al., 2004; Taskar et al., 2005a). Alignment yˆ is the output candidate maximizing the sum of both the loss and model score. This guess appears attractive to the model, yet has low F-measure, and so is exactly the sort of output we would like to update away from. During training, we learn both the parameters and model structure. Figure 4b shows how the size of the model grows over time. As described in Sections 2 and 3, we automatically extract and fire features given an alignment configuration and our current position in the tree. We see a steep initial growth in model size, and then begin to trail off as the number of new</context>
</contexts>
<marker>Taskar, Chatalbashev, Koller, Guestrin, 2005</marker>
<rawString>Ben Taskar, Vassil Chatalbashev, Daphne Koller, and Carlos Guestrin. 2005a. Learning structured prediction models: A large margin approach. In Proceedings of ICML, pages 896-903, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
</authors>
<title>A discriminative matching approach to word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>73--80</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2531" citStr="Taskar et al., 2005" startWordPosition="362" endWordPosition="365">iversity Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire generative story. The additional complexity would likely make training such models quite expensive. Already, with ubiquitous tools like GIZA++ (Och and Ney, 2003), training accurate models on large corpora takes upwards of 5 days. Recent work in discriminative alignment has focused on incorporating features that are unavailable or difficult to incorporate within other models, e.g. (Moore, 2005; Ittycheriah and Roukos, 2005; Liu et al., 2005; Taskar et al., 2005b; Blunsom and Cohn, 2006; Lacoste-Julien et al., 2006; Moore et al., 2006). Even more recently, motivated by the rise of syntax-based translation models, others have sought to inform alignment decisions with syntactic information (Fraser and Marcu, 2007; DeNero and Klein, 2007; May and Knight, 2007; Fossum et al., 2008; Haghighi et al., 2009; Burkett et al., 2010; Pauls and Klein, 2010; Riesa and Marcu, 2010). Motivated by the wide modeling gap that still remains between syntax-based translation and wordalignment models, in this paper we expand on previous work in discriminative alignment, an</context>
<context position="19512" citStr="Taskar et al., 2005" startWordPosition="3290" endWordPosition="3293">010). Let yi be the correct output for input xi. Here, yi is an alignment; xi is a sentence pair and parse tree. At each iteration, our perceptron update is: w (-- w + h(yi) − h(ˆy) (3) And we define: yˆ = arg max f(yi, y) + w - h(y) (4) yEY(xi) f(yi, y) = 1 − F1(yi, y) (5) with w our weight vector, h(y) our sparse vector of feature values, Y(xi) all possible outputs for input xi, and F1(yi, y) balanced F-measure. The loss, f(yi, y), is a measure of how bad it would be to guess yˆ instead of y. In selecting ˆy, we draw upon the loss-augmented inference literature (Tsochantaridis et al., 2004; Taskar et al., 2005a). Alignment yˆ is the output candidate maximizing the sum of both the loss and model score. This guess appears attractive to the model, yet has low F-measure, and so is exactly the sort of output we would like to update away from. During training, we learn both the parameters and model structure. Figure 4b shows how the size of the model grows over time. As described in Sections 2 and 3, we automatically extract and fire features given an alignment configuration and our current position in the tree. We see a steep initial growth in model size, and then begin to trail off as the number of new</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien, and Dan Klein. 2005b. A discriminative matching approach to word alignment. In Proceedings of HLT-EMNLP, pages 73-80, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann Tsochantaridis</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of ICML,</booktitle>
<publisher>Canada.</publisher>
<location>Banff, AB.</location>
<contexts>
<context position="19491" citStr="Tsochantaridis et al., 2004" startWordPosition="3286" endWordPosition="3289">scribed by McDonald et al. (2010). Let yi be the correct output for input xi. Here, yi is an alignment; xi is a sentence pair and parse tree. At each iteration, our perceptron update is: w (-- w + h(yi) − h(ˆy) (3) And we define: yˆ = arg max f(yi, y) + w - h(y) (4) yEY(xi) f(yi, y) = 1 − F1(yi, y) (5) with w our weight vector, h(y) our sparse vector of feature values, Y(xi) all possible outputs for input xi, and F1(yi, y) balanced F-measure. The loss, f(yi, y), is a measure of how bad it would be to guess yˆ instead of y. In selecting ˆy, we draw upon the loss-augmented inference literature (Tsochantaridis et al., 2004; Taskar et al., 2005a). Alignment yˆ is the output candidate maximizing the sum of both the loss and model score. This guess appears attractive to the model, yet has low F-measure, and so is exactly the sort of output we would like to update away from. During training, we learn both the parameters and model structure. Figure 4b shows how the size of the model grows over time. As described in Sections 2 and 3, we automatically extract and fire features given an alignment configuration and our current position in the tree. We see a steep initial growth in model size, and then begin to trail off</context>
</contexts>
<marker>Tsochantaridis, Joachims, Altun, 2004</marker>
<rawString>Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings of ICML, Banff, AB. Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Andreas Zollmann</author>
<author>Noah A Smith</author>
<author>Stephan Vogel</author>
</authors>
<title>Wider pipelines: N-best alignments and parses in MT training.</title>
<date>2008</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<pages>192--201</pages>
<location>Honolulu, HI. USA.</location>
<contexts>
<context position="8246" citStr="Venugopal et al., 2008" startWordPosition="1349" endWordPosition="1352">hile we are constructing partial alignments at the PP. Search continues recursively up the tree, until we have reached the root node. The root node again computes the top k alignments from its children, and these comprise our final k-best list of full alignments. In our experiments we only make use of the 1- best alignment for evaluation and translation. Previous work has shown that only shallow k-best lists of alignments may be beneficial, and that very deep kbest lists are not especially useful in improving final downstream translation grammar extraction due to rapid degradation in quality (Venugopal et al., 2008; Liu et al., 2009b); though they may have other uses. 3 Automatically Exploiting Syntactic Features for Alignment Up to now, previous work in syntax-based alignment has largely modeled alignments based on features encoding target-side English syntactic and lexical information, but only lexical information on the source side. However, there is much more data waiting to be exploited, and the flexible model and efficient and modular learning framework of hierarchical discriminative alignment afford us this possibility. Here, we discuss our target-side features, source-side features, and features</context>
</contexts>
<marker>Venugopal, Zollmann, Smith, Vogel, 2008</marker>
<rawString>Ashish Venugopal, Andreas Zollmann, Noah A. Smith, and Stephan Vogel. 2008. Wider pipelines: N-best alignments and parses in MT training. In Proceedings of AMTA, pages 192-201, Honolulu, HI. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukuda</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>764--773</pages>
<contexts>
<context position="27815" citStr="Watanabe et al., 2007" startWordPosition="4639" endWordPosition="4642"> et al., 2004; Galley et al., 2006) and extract translation rules7 using alignments produced by each system from 4.25+5.43M words for ArabicEnglish and 31.8+37.7M words for Chinese-English. For Arabic-English, we tune our MT system on a held-out development corpus of 1,172 parallel sentences, and test on a heldout set of 746 parallel sentences with four references each. For ChineseEnglish we tune our MT system on a held-out development corpus of 4,089 parallel sentences, and test on a set of 4,060 sentences with four references each. We tune the translation models for these systems with MIRA (Watanabe et al., 2007; Chiang et al., 2008). Our tuning and test corpora are drawn from the NIST 2004 and 2006 evaluation data, disjoint from our rule-extraction data. All systems used two language models; one trained on the combined English sides of our Arabic-English and ChineseEnglish data (480M words), and one trained on 4 billion words of English data. MT results are shown in Table 3. We show a gain 7We use the so-called composed rules of (Galley et al., 2006). Alignment model ara-eng chi-eng BLEU BLEU GIZA++ Model-4 47.6 26.2 Target-tree alignments only 48.3* 26.4+ +Iterative Inference (gdf) 48.4 27.0* +Iter</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukuda, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukuda, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In Proceedings of EMNLP, pages 764-773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--3</pages>
<contexts>
<context position="9407" citStr="Wu, 1997" startWordPosition="1521" endWordPosition="1522">ide features, source-side features, and features that jointly take into account both source- and target-side information. 3.1 Target Syntax Features Most alignment systems currently function without explicit regard to the downstream translation model. Some notable exceptions are May and Knight (2007) who generate syntactic alignments by re-aligning word-to-word alignments with a syntactic model; 1Cube pruning is approximate when we have nonlocal combination features, and most of our features are of this type. and Pauls and Klein (2010) who generate syntactic alignments with a synchronous ITG (Wu, 1997) approach. We depart from ITG-based models (Cherry and Lin, 2006; Haghighi et al., 2009) because of their complexity (O(n6) in the synchronous case), requiring heavy pruning or the computation of outside cost estimates (DeNero and Klein, 2010). Instead, we use linguistically motivated target-side parse trees to constrain search, as described above. These trees are output from the Berkeley parser (Petrov and Klein, 2007) and fixed at alignment time. We use these trees not only as a vehicle for search, but also for features. A significant motivation for this work is the desire to make the connec</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377-403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Hongfei Jiang</author>
<author>Aiti Aw</author>
<author>Haizhou Li</author>
<author>Chew Lim Tan</author>
<author>Sheng Li</author>
</authors>
<title>A tree sequence alignment-based tree-to-tree translation model.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>559--567</pages>
<location>Columbus, OH. USA.</location>
<contexts>
<context position="12917" citStr="Zhang et al., 2008" startWordPosition="2090" endWordPosition="2093">c-English are negatively weighted. Early experiments involved only firing indicator rule features when an extracted rule at alignment-time matched in a set of rules extracted offline from our hand-aligned data. However, coverage from such rules will always be limited; firing every rule as a feature as it is encountered during search gives us many more darts to throw. Using only rule features extracted from gold data lowers F-measure by close to 5 points. 3.2 Source Syntax Features and Joint Features Source syntactic trees have recently been shown to be helpful in machine translation decoding (Zhang et al., 2008; Liu et al., 2009a; Chiang, 2010), but to our knowledge have not been used in alignment models other than that of Burkett et al. (2010). We parse the source side of our data using the Berkeley parser (Petrov and Klein, 2007), and encode information provided by the source syntax as features in the model in two ways: (1) as tree-distance features3, and (2) as joint source-target syntax features. 3These features parameterize the intuition that if two source words align to a single target word, we prefer them to be members of the same constituent, or having a short path through the tree from one </context>
</contexts>
<marker>Zhang, Jiang, Aw, Li, Tan, Li, 2008</marker>
<rawString>Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim Tan, and Sheng Li. 2008. A tree sequence alignment-based tree-to-tree translation model. In Proceedings of ACL-08: HLT, pages 559-567, Columbus, OH. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollman</author>
<author>Ashish Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In NAACL 2006 Workshop on Statistical Machine Translation,</booktitle>
<pages>138--141</pages>
<location>Rochester, NY. USA.</location>
<contexts>
<context position="1469" citStr="Zollman and Venugopal, 2006" startWordPosition="197" endWordPosition="201">rence under the model, and demonstrate significant alignment and translation quality improvements over already-powerful baselines trained on very large corpora. We observe translation quality improvements corresponding to 1.0 and 1.3 BLEU for Arabic-English and Chinese-English, respectively. 1 Introduction In recent years, several state-of-the-art statistical machine translation (MT) systems have incorporated both source and target syntax into the grammars that they generate and use to translate. While some treeto-tree systems parse source and target sentences separately (Galley et al., 2006; Zollman and Venugopal, 2006; Huang and Mi, 2010), others project syntactic parses across word alignments (Li et al., 2009). In both approaches, as in largely all statistical MT, the quality of the alignments used to generate the rules of the grammar are critical to the success of the system. However, to date, most word alignment systems have not considered the same degree of syntactic information that MT systems have. &apos;Department of Computer Science Johns Hopkins University Baltimore, MD 21218 anni@jhu.edu Extending unsupervised models, like the IBM models (Brown et al., 1993), generally requires changing the entire gen</context>
</contexts>
<marker>Zollman, Venugopal, 2006</marker>
<rawString>Andreas Zollman and Ashish Venugopal. 2006. Syntax augmented machine translation via chart parsing. In NAACL 2006 Workshop on Statistical Machine Translation, pages 138-141, Rochester, NY. USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>