<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000356">
<title confidence="0.973467">
Knowledge-Based Multilingual Document Analysis
</title>
<author confidence="0.697166333333333">
R. Basili and R. Catizone and L. Padro and M.T. Pazienza
G. Rigau and A. Setzer and N. Webb
F. Zanzotto
</author>
<affiliation confidence="0.9954335">
Dept. of Computer Science, Systems and Production
University of Rome, Tor Vergata
</affiliation>
<address confidence="0.9142995">
Via di Tor Vergata
00133 Roma, Italy
</address>
<email confidence="0.992124">
basili, pazienza, zanzotto@info.uniroma2.it
</email>
<affiliation confidence="0.998846">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.829234">
Regent Court, 211 Portobello Street
Sheffield S1 4DP, UK
</address>
<email confidence="0.952015">
R.Catizone, A.Setzer, N.Webb@dcs.shef.ac.uk
</email>
<author confidence="0.419336">
Departament de Llenguatges i Sistemes Informatics
</author>
<affiliation confidence="0.466026">
Universitat Politecnica de Catalunya
Centre de Recerca TALP
</affiliation>
<address confidence="0.945225">
Jordi Girona Salgado 1-3
08034 Barcelona, Spain
</address>
<email confidence="0.997749">
l.padro, g.rigau@lsi.upc.es
</email>
<sectionHeader confidence="0.993073" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994795">
The growing availability of multilingual resources,
like EuroWordnet, has recently inspired the develop-
ment of large scale linguistic technologies, e.g. mul-
tilingual IE and Q&amp;A, that were considered infeasi-
ble until a few years ago. In this paper a system
for categorisation and automatic authoring of news
streams in different languages is presented. In our
system, a knowledge-based approach to Information
Extraction is adopted as a support for hyperlinking.
Authoring across documents in different languages
is triggered by Named Entities and event recogni-
tion. The matching of events in texts is carried out
by discourse processing driven by a large scale world
model. This kind of multilingual analysis relies on a
lexical knowledge base of nouns(i.e. the EuroWord-
net Base Concepts) shared among English, Spanish
and Italian lexicons. The impact of the design choices
on the language independence and the possibilities it
opens for automatic learning of the event hierarchy
will be discussed.
</bodyText>
<sectionHeader confidence="0.998903" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858206896552">
Modern information technologies are faced with the
problem of selecting, filtering, linking and manag-
ing growing amounts of multilingual information to
which access is usually critical. Our work is moti-
vated by the linking of multilingual information in a
wide range of domains. Although this problem ap-
pears to be directly related to the Information Re-
trieval task, we aimed to link articles, not in the broad
sense of clustering documents related to the same
topic, but rather more specifically linking particular
pieces of information together from different docu-
ments. Furthermore, we found that IE research, al-
though appropriate for our task, was not designed for
the scale/variety of different domains that we needed
to process. In general, creating the world model nec-
essary for the addition of a new domain to an IE sys-
tem is a time-consuming process. As such, we de-
signed an IE system that could be semi-automatically
and easily adapted to new domains - a process we will
refer to as large scale IE. The key to creating new
world models relied on incorporating large amounts
of domain knowledge. As a result we selected Eu-
roWordnet as our base knowledge source. EuroWord-
net has the advantages of 1) providing the foundation
for broad knowledge across many domains and 2) is
multilingual in nature. In this paper, we will explain
how our system works, how the knowledge base was
incorporated and a discussion of other applications
that could make use of the same technology.
</bodyText>
<sectionHeader confidence="0.954939" genericHeader="method">
2 The Application
</sectionHeader>
<bodyText confidence="0.9999151875">
In the 5th Framework NAMIC Project (News Agen-
cies Multilingual Information Categorisation), the de-
fined task of the system was to support the automatic
authoring of multilingual news agencies texts where
the chosen languages were English, Italian and Span-
ish. The goal was the Hypertextual linking of related
articles in one language as well as related articles in
the other project languages. One of the intermediate
goals of NAMIC was to categorise incoming news ar-
ticles, in one of the three target languages and use
Natural Language Technology to derive an ‘objec-
tive representation’ of the events and agents contained
within the news. This representation which is ini-
tially created once using representative news corpora
is stored in a repository and accessed in the authoring
process.
</bodyText>
<subsectionHeader confidence="0.991939">
2.1 Automatic Authoring
</subsectionHeader>
<bodyText confidence="0.994271342105263">
Automatic Authoring is the task of automatically de-
riving a hypertextual structure from a set of available
news articles (in three different languages English,
Spanish and Italian in our case). This relies on the ac-
tivity of event matching. Event matching is the pro-
cess of selecting the relevant facts in a news article
in terms of their general type (e.g. selling or buying
companies, winning a football match), their partici-
pants and their related roles (e.g. the company sold or
the winning football team) Authoring is the activity
of generating links between news articles according
to relationships established among facts detected in
the previous phase.
For instance, a company acquisition can be referred
to in one (or more) news items as:
Intel, the world’s largest chipmaker, bought a
unit of Danish cable maker NKT that designs
high-speed computer chips used in products that
direct traffic across the internet and corporate
networks.
The giant chip maker Intel said it acquired the
closely held ICP Vortex Computersysteme, a
German maker of systems for storing data on
computer networks, to enhance its array ofdata-
storage products.
Intel ha acquistato Xircom inc. per 748 milioni
di dollari.
Le dichiarazioni della Microsoft, infatti, sono
state precedute da un certo fermento, dovuto
all’interesse verso Linux di grandi ditte quali
Corel, Compaq e non ultima Intel (che ha ac-
quistato quote della Red Hat) ...
The hypothesis underlying Authoring is that all the
above news items deal with facts in the same area of
interest to a potential class of readers. They should be
thus linked and links should suggest to the user that
the underlying motivation is that they all refer to Intel
acquisitions.
</bodyText>
<sectionHeader confidence="0.996461" genericHeader="method">
3 The NAMIC Architecture
</sectionHeader>
<bodyText confidence="0.999824352941177">
The NAMIC system uses a modularised IE architec-
ture whose principal components, used to create the
IE repository, are morpho-syntactic analysis, cate-
gorisation and semantic analysis. During Morpho-
Syntactic analysis, a modular and lexicalised shal-
low morpho-syntactic parser (Basili et al., 2000b),
provides the extraction of dependency graphs from
source sentences. Ambiguity is controlled by part-
of-speech tagging and domain verb-subcategorisation
frames that guide the dependency recognition phase.
It is within the semantic analysis, which relies on the
output of this parser, that objects in the text, and their
relationships to key events are captured. This process
is explained in more detail in 4. In the next two sec-
tions, we will elaborate on the IE engine. For a full
description of the NAMIC Architecture see (Basili et
al., 2001).
</bodyText>
<subsectionHeader confidence="0.994827">
3.1 LaSIE
</subsectionHeader>
<bodyText confidence="0.999797285714286">
In NAMIC, we have integrated a key part of the Infor-
mation Extraction system called LaSIE (Large-scale
Information Extraction system, (Humphreys et al.,
1998)). Specifically, we have taken the Named Entity
Matcher and the Discourse Processor from the over-
all architecture of LaSIE. The roles of each of these
modules is outlined below.
</bodyText>
<subsectionHeader confidence="0.920665">
3.1.1 Named Entity Matcher
</subsectionHeader>
<bodyText confidence="0.999966538461538">
The Named Entity (NE) Matcher finds named enti-
ties (persons, organisations, locations, and dates, in
our case) through a secondary phase of parsing which
uses a NE grammar and a set of gazetteer lists. It takes
as input parsed text from the first phase of parsing and
the NE grammar which contains rules for finding a
predefined set of named entities and a set of gazetteer
lists containing proper nouns. The NE Matcher re-
turns the text with the Named Entities marked. The
NE grammar contains rules for coreferring abbrevia-
tions as well as different ways of expressing the same
named entity such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
</bodyText>
<subsectionHeader confidence="0.693446">
3.1.2 Discourse Processor
</subsectionHeader>
<bodyText confidence="0.999962205882353">
The Discourse Processor module translates the se-
mantic representation produced by the parser into a
representation of instances, their ontological classes
and their attributes, in the XI knowledge representa-
tion language (Gaizauskas and Humphreys, 1996).
XI allows a straightforward definition of cross-
classification hierarchies, the association of arbitrary
attributes with classes or instances, and a simple
mechanism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by the
parser for a single sentence is processed by adding
its instances, together with their attributes, to the dis-
course model which has been constructed for a text.
Following the addition of the instances mentioned
in the current sentence, together with any presuppo-
sitions that they inherit, the coreference algorithm is
applied to attempt to resolve, or in fact merge, each
of the newly added instances with instances currently
in the discourse model.
The merging of instances involves the removal of
the least specific instance (i.e. the highest in the on-
tology) and the addition of all its attributes to the other
instance. This results in a single instance with more
than one realisation attribute, which corresponds to a
single entity mentioned more than once in the text,
i.e. a coreference.
The mechanism described here is an extremely
powerful tool for accomplishing the IE task, however,
in common with all knowledge-based approaches,
and as highlighted in the introduction to this paper,
the significant overhead in terms of development and
deployment is in the creation of the world model rep-
resentation.
</bodyText>
<sectionHeader confidence="0.996932" genericHeader="method">
4 Large-Scale World Model Acquisition
</sectionHeader>
<bodyText confidence="0.999973909090909">
The traditional limitations of a knowledge-based in-
formation extraction system such as LaSIE have been
the need to hand-code information for the world
model - specifically relating to the event structure of
the domain. This is also valid for NAMIC. To aid the
development of the world model, a semi-automatic
boot-strapping process has been developed, which
creates the event type component of the world model.
To us, event descriptions can be categorised as a set
of regularly occurring verbs within our domain, com-
plete with their subcategorisation information.
</bodyText>
<subsectionHeader confidence="0.997394">
4.1 Event Hierarchy
</subsectionHeader>
<bodyText confidence="0.999895653846154">
The domain verbs can be selected according to sta-
tistical techniques and are, for the moment, subjected
to hand pruning. Once a list of verbs has been ex-
tracted, subcategorisation patterns can be generated
automatically using a combination of weakly super-
vised example-driven machine learning algorithms.
There are mainly three induction steps. First, syn-
tactic properties are derived for each verb, express-
ing the major subcategorisation information under-
lying those verbal senses which are more important
in the domain. Then, in a second phase, verb usage
examples are used to induce the semantic properties
of nouns in argumental positions. This information
relates to selectional constraints, independently as-
signed to each verb subcategorisation pattern. Thus,
different verb senses are derived, able to describe the
main properties of the domain events (e.g. Compa-
nies acquire companies). In a third and final phase
event types are derived by grouping verbs accord-
ing to their syntactic-semantic similarities. Here,
shared properties are used to generalise from the lex-
ical level, and generate verbal groups expressing spe-
cific semantic (and thus conceptual) aspects. These
types are then fed into the event hierarchy as required
for their straightforward application within the target
IE scenario.
</bodyText>
<subsectionHeader confidence="0.792347">
4.1.1 Acquisition of Subcategorisation Patterns
</subsectionHeader>
<bodyText confidence="0.995776595238095">
Each verb is separately processed. First, each local
context (extracted from sentences in the source cor-
pus) is mapped into a feature vector describing:
the verb of each vector (i.e. the lexical head of
the source clause);
the different grammatical relationships (e.g.
Subj and Obj for grammatical subject and ob-
jects respectively) as observed in the clause;
the lexical items, usually nouns, occurring in
specific grammatical positions, e.g. the subject
Named Entity, in the clause.
Then, vectors are clustered according to the set of
shared grammatical (not lexical) properties: Only the
clauses showing the same relationships (e.g. all the
Subj- -Obj triples) enter in the same subset .
Each cluster thus expresses a specific grammatical be-
haviour shared by several contexts (i.e. clauses) in the
corpus. The shared properties in characterise the
cluster, as they are necessary and sufficient member-
ship conditions for the grouped contexts.
As one context can enter in more than one cluster
(as it can share all (or part) of its relations with the
others), the inclusion property establishes a natural
partial order among clusters. A cluster is included
in another cluster if its set of properties is larger
(i.e. ) but it is shown only by a subset of the
contexts of the latter . The larger the set of mem-
bership constraints is, the smaller the resulting cluster
is. In this way, clusters are naturally organised into
a lattice (called Galois lattice). Complete properties
express for each cluster candidate subcategorisation
patterns for the target verb .
Finally, the lattice is traversed top-down and the
search stops at the more important clusters (i.e. those
showing a large set of members and characterised
by linguistically appealing properties): they are re-
tained and a lexicon of subcategorisation structures
(i.e. grammatical patterns describing different us-
ages of the same verb) is compiled for the target verb
. Forexample, (buy, [Subj:X, Obj:Y]) can
be used to describe the transitive usage of the verb
. More details can be found in (Basili et al., 1997).
</bodyText>
<subsubsectionHeader confidence="0.502562">
4.1.2 Corpus-driven Induction of Verb
</subsubsectionHeader>
<subsectionHeader confidence="0.866722">
Selectional Restrictions
</subsectionHeader>
<bodyText confidence="0.99826125">
The lattice can be further refined to express seman-
tic constraints over the syntactic patterns specified at
the previous stage. A technique proposed in (Basili
et al., 2000a) is adopted by deriving semantic con-
straints via synsets (i.e. synonymy sets) in the Word-
Net 1.6 base concepts (part of EuroWordNet). When
a given lattice node expresses a set of syntactic prop-
erties, then this suggests:
a set of grammatical relations necessary to ex-
press a given verb meaning, ; and
references to source corpus contexts where the
grammatical relations are realised in texts.
This information is used to generalise verb argu-
ments. For each node/pattern, the nouns appearing
in the same argumental position (in at least one
of the referred examples in the corpus) are grouped
together to form a noun set : a learning algorithm
based on EuroWordNet derives the most informa-
tive EuroWordNet synset(s) for each argument,
activated by the members. Most informative
synsets are those capable of (1) generalising as many
nouns as possible in , while (2) preserving their
specific semantic properties. A metric based on
conceptual density (Agirre and Rigau, 1995) is here
employed to detect the promising, most specific
generalisations of . Then the derived
sets for each argument are used to gen-
erate the minimal set of semantic patterns
capable of “covering” all the examples in , with
. The sequences express the most
promising generalisations of examples for the
subcategorisation . As an example, (buy,
[Agent:Company,Object:Company])
expresses the knowledge required for matching
sentences like ”Intel buys Vortex”. Full details on
the above process can be found in (Basili et al.,
2000a). Notice how Company is a base concept
in EuroWordNet and it is shared among the three
languages. It can thus be activated via the Inter-
Lingual-Index from lexical items of any language.
If included in the world model (as a concept in
the object hierarchy), these base concepts play
the role of a multilingual abstraction for the event
constraints.
</bodyText>
<subsectionHeader confidence="0.988547666666667">
4.1.3 Induction of Domain event Types via
Conceptual Clustering of Verb semantic
Patterns
</subsectionHeader>
<bodyText confidence="0.946775722222222">
The final phase in the development of a large scale
world model aims to link the event matching rules
valid for one verb to the suitable event hierarchy
nodes. The following semi-automatic process can be
applied:
First, a limited set of high level event types can
be defined by studying the corpus and via knowl-
edge engineering techniques (e.g. interactions
with experts of the domain);
then, semantic descriptions of verbs can be
grouped automatically, according to the similar-
ity among their corresponding patterns;
finally, the obtained verb groups can be mapped
to the high-level types, thus resulting in a flat
hierarchy.
An example of the target event hierarchy is given in
figure 1.
acquire buy send ... receive decide ... institute ... allow
</bodyText>
<figureCaption confidence="0.9786565">
Figure 1: Top levels in the event hierarchy vs. verb
clusters
</figureCaption>
<bodyText confidence="0.999752">
Currently, a set of event types ( main groupings
in a financial domain ranging from ”Company Ac-
quisitions” and ”Company Assets” to ”Regulation”)
have been defined. Within the eight event groupings,
we acquired more than 3000 lexicalisations of events.
The clustering step has been approached with a tech-
nique similar to the Galois lattices, where feature vec-
tors represent syntactic-semantic properties of the dif-
</bodyText>
<figure confidence="0.978436428571429">
Company
Acquisitions
...
Governmental
Activities
Event
Group 1 ... Group N
</figure>
<bodyText confidence="0.9809684">
ferent verbs (i.e. pattern derived in the pre-
vious phase). All verbs are considered&apos; and the ob-
tained clusters represent semantic abstractions valid
for more than one verb. The following is an example
of the grouping of the verbs acquire to win.
</bodyText>
<figure confidence="0.509353866666667">
cluster(141,[acquire,buy,catch,
contribute,earn,gain,hire,
issue,obtain,offer,order,
pay,reach,receive,refer,
secure,sell, serve,trade,
win]).
patt(141, [
arg(’Obj’,
(’measure quantity amount quantum’
,0),
’abstraction ’),
arg(’Subj’,
(’social_group’,0),
’entity something ’)
]).
</figure>
<bodyText confidence="0.995644">
The above cluster expresses a conceptual property
able to suggest a specific event subtype. Thus, manual
mapping to the correct high-level concept (”Company
acquisition” event type) is made possible and more
intuitive. As semantic constraints in event types
are given by base concepts, translations into Italian
and Spanish rules (for example: (acquistare,
[Agent:Company,Object:Company])) are
possible. They inherit the same topological position
in the event ontology. Accordingly, the world
model has a structure (i.e. the main object and
event hierarchies) which is essentially language
independent. Only the lowest levels are represen-
tative of each language. Here, a language specific
lexicalisation is required. The advantage is that most
of the groups derived for English can be retained for
other languages, and a simple translation suffices
for most of the patterns. Lexicalisations are thus
associated with the language independent abstrac-
tions (i.e. matching rules over parsed texts) which
control the behaviour of instances of these events in
the discourse processing.
The integrated adoption of EuroWordNet and the
automatic acquisition/translation of verb rules is thus
the key idea leading to a successful and quick devel-
opment of the large scale IE component required for
automatic authoring.
&apos;Initial partitions according to the Levin classification (Levin,
1993) are adopted. A partition of the verbs is built for each of
the Levin classes and conceptual clustering is applied internally
to each group.
</bodyText>
<subsectionHeader confidence="0.993118">
4.2 Object Hierarchy
</subsectionHeader>
<bodyText confidence="0.999939928571428">
In typical Information Extraction processing environ-
ments, the range of objects in the text is expected to
be as limited and constrained as the event types. For
example, when processing ’management succession’
events (MUC-6, 1995), the object types are the ob-
vious person, location, organisation, time and date.
Intuitively however, if the need was to process the en-
tire output of a news gathering organisation, it seems
clear that we must be able to capture a much wider
range of possible objects which interact with cen-
tral events. Rather than attempt to acquire all of this
object information from the corpus data, we instead
chose to use an existing multilingual lexical resource,
EuroWordNet.
</bodyText>
<subsectionHeader confidence="0.449333">
4.2.1 EuroWordNet
</subsectionHeader>
<bodyText confidence="0.99997796">
EuroWordNet (Vossen, 1998) is a multilingual lexi-
cal knowledge (KB) base comprised of hierarchical
representations of lexical items for several European
languages (Dutch, Italian, Spanish, German, French,
Czech and Estonian). The wordnets are structured in
the same way as the English WordNet developed at
Princeton (Miller, 1990) in terms of synsets (sets of
synonymous words) with basic semantic relations be-
tween them.
In addition, the wordnets are linked to an Inter-
Lingual-Index (ILI), based on the Princeton Word-
Net 1.5. (WordNet 1.6 is also connected to the ILI
as another English WordNet (Daude et al., 2000)).
Via this index, the languages are interconnected so
that it is possible to go from concepts in one lan-
guage to concepts in any other language having sim-
ilar meaning. Such an index also gives access to a
shared top-ontology and a subset of 1024 Base Con-
cepts (BC). The Base Concepts provide a common
semantic framework for all the languages, while lan-
guage specific properties are maintained in the indi-
vidual wordnets. The KB can be used, among oth-
ers, for monolingual and cross-lingual information re-
trieval, which was demonstrated by (Gonzalo et al.,
1998).
</bodyText>
<subsubsectionHeader confidence="0.813941">
4.2.2 EuroWordNet as the Object Ontology
</subsubsectionHeader>
<bodyText confidence="0.999838173076923">
The example rules shown in the previous section re-
late to Agents which conveniently belong to a class of
Named Entities as would be easily recognised under
the MUC competition rules (person, company and lo-
cation for example). However, a majority of the rules
extracted automatically from the corpus data involved
other kinds of semantic classes of information which
play key roles in the subcategorisation patterns of the
verbs.
In order to be able to work with these patterns,
it was necessary to extend the number of seman-
tic classes beyond the usual number of predefined
classes, across a variety of languages.
Representing the entirety of EWN in our object hi-
erarchy would be time consuming, and lead to inef-
ficient processing times. Instead we took advantage
of the Base Concepts (Rodriquez et al., 1998) within
EWN, a set of approximately 1000 nodes, with hier-
archical structure, that can be used to generalise the
rest of the EWN hierarchy.
These Base Concepts represent a core set of com-
mon concepts to be covered for every language that
has been defined in EWN. A concept is determined
as important (and is therefore a base concept) if it is
widely used, either directly or as a reference for other
widely used concepts. Importance is reflected in the
ability of a concept to function as an anchor to attach
other concepts.
The hierarchical representation of the base con-
cepts is added to the object hierarchy of the NAMIC
world model. Additionally, a concept lookup function
is added to the namematcher module of the NAMIC
architecture. This lookup takes all common nouns
in the input, and translates them into their respective
EWN Base Concept codes.
This process was reversed in the event rule acquisi-
tion stage, so that each occurrence of a object in a rule
was translated into a Base Concept code. This has
two effects. Firstly, the rules become more generic,
creating a more compact rule base. Secondly, given
the nature of the inter-lingual index which connects
EWN lexicons, the rules became language indepen-
dent at the object level. Links between the lexicali-
sations of events are still required, and at present are
hand-coded, but future development of the verb rep-
resentations of WN might eliminate this.
In summary, this new, expanded WM covers both
the domain specific events and a wide range of agents,
and can be acquired largely automatically from cor-
pus data, and used to process large amounts of text on
a spectrum of domains by leveraging existing multi-
lingual lexical resources.
</bodyText>
<sectionHeader confidence="0.998277" genericHeader="evaluation">
5 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999966273809524">
The NAMIC system was created to provide an envi-
ronment for automatic hypertextual authoring of mul-
tilingual news articles. In order to address that task,
we created language processors in three languages
(English, Italian and Spanish) which allows us to cre-
ate a database of conceptually analysed text. The abil-
ity to analyse text in this way is vital for the authoring
process, but is also applicable to a wide range of tech-
nologies, including Information Retrieval in general,
and Question-Answering in particular.
Information Retrieval (Spark Jones and Willett,
1997; Rijsbergen, 1979), or document retrieval as it
is in practice, is a well used, robust technology which
allows users to access some subset of documents by
means of a set of keywords. However, the retrieval of
answers to questions by keywords, whilst easy to im-
plement, suffers by their restrictive nature. For exam-
ple, a keyword based retrieval mechanism would be
unable to distinguish between the queries who killed
Lee Harvey Oswald? and who did Lee Harvey Os-
wald kill?, operating as they do by reducing these
queries to a bag of stemmed words. By accessing the
kind of knowledge base that we created in the Namic
project where events and their relations are explic-
itly represented, an IR system would be able to dis-
tinguish between the above two queries or any other
queries that require this kind of data mining.
One possible future extension of the NAMIC sce-
nario, is to move from only allowing users to browse
through a space of connected articles to a system that
supports journalists in the creation of news articles.
State of the art techniques for searching, analysing,
authoring and disseminating information in the news
domain originating from diverse language sources are
needed in order to support the working activities of
authors (i.e. the journalists) within a complex en-
vironment for searching, elaborating and delivering
news. The information so derived will enter the dis-
semination process (archives to the agencies and/or
Web channels) and enhanced presentation to the user
will be supported in a way that it can be readily un-
derstood, accepted, rejected or amended as necessary.
Reporters covering the early stages of a ”breaking”
story rely on a format of questions. Typically, these
questions include: What? Where? Who? When? But,
although definitions of a news story include the orig-
inality of the event (”Something that happened today
which did not happen yesterday”), coverage also re-
lies on archives. Checks made in the potentially mul-
tilingual archives - increasingly comprised of digital
resources - make up one of the most important phases
in reporting. If such a search path can be imitated
by a computer, this would greatly enhance the speed
and accuracy of archive searches. For example, in the
immediate aftermath of a crash involving a passenger
airliner, a number of simple questions and answers
may be addressed to the archive. Has this type of air-
craft crashed before? If so, what happened? How
many fatalities have there been in incidents involving
this type of aircraft? Has there been a crash before
at this airport? What are the main characteristics of
this aircraft? What are those of the airport? Answers
to these questions may prompt a series of subsidiary
questions.
The depth of interpretation which an experienced
and educated journalist can bring to events cannot
hope to be imitated by a computer, at least for some
considerable time. However, what does seem pos-
sible is that a computerised assistant, a sort of elec-
tronic cub reporter, could assist the human journal-
ist by finding and collating relevant archival mate-
rials in an intelligent fashion - i.e. without precise,
low-level instruction from the journalist. This multi-
lingual question-answering task would be aided by
the development the proposed system.
In conclusion, we believe that the creation of a
sophisticated knowledge base resource can benefit
many Information Technology applications - IR and
Question Answering to name two. We were able to
create such a resource in the NAMIC project by im-
plementing a scalable IE system containing a robust
world model based on EuroWordnet. We feel that this
kind of automatic resource building will play a signif-
icant part of future IT applications.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="conclusions">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9972625">
This research is funded by the European Union, grant
number IST-1999-12392. We would also like to thank
all of the partners in the NAMIC consortium espe-
cially Yorick Wilks.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999659388888889">
E. Agirre and G. Rigau. 1995. A Proposal for Word
Sense Disambiguation using Conceptual Distance.
In International Conference ”Recent Advances in
Natural Language Processing” RANLP’95, Tzigov
Chark, Bulgaria.
R. Basili, M.T. Pazienza, and M. Vindigni. 1997.
Corpus-driven unsupervised learning of verb sub-
categorization frames. In M. Lenzerini, editor,
AI*IA 97: Advances in Artificial Intelligence,
Lecture Notes in Artificial Intelligence n., 1321.
Springer Verlag, Berlin.
R. Basili, M.T. Pazienza, and M. Vindigni. 2000a.
Corpus-driven learning of Event Recognition
Rules. In Proceedings ofMachine Learning for In-
formation Extraction workshop, held jointly with
the ECAI2000, Berlin, Germany.
R. Basili, M.T. Pazienza, and F.M. Zanzotto. 2000b.
Customizable Modular Lexicalized Parsing. In
Proceedings of the 6th International Workshop on
Parsing Technology, IWPT2000, Trento, Italy.
R. Basili, R. Catizone, L. Padro, M.T. Pazienza,
R. Rigau, A. Setzer, N. Webb, Y. Wilks, and
F.M. Zanzotto. 2001. Multilingual Authoring: the
NAMIC Approach. In Proceedings of the Work-
shop on Human Language Technology and Knowl-
edge Management (at ACL-EACL 2001), Toulouse,
France.
J. Daude, L. Padro, and R. Rigau. 2000. Mapping
WordNets using Structural Information. In Pro-
ceedings of the 38th Annual Meeting of the Associ-
ation for Computational Linguistics ACL’00, Hong
Kong, China.
R. Gaizauskas and K. Humphreys. 1996. XI:
A Simple Prolog-based Language for Cross-
Classification and Inheritance. In Proceedings of
the 6th International Conference on Artificial In-
telligence: Methodologies, Systems, Applications
(AIMSA96), pages 86–95.
J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigarran.
1998. Indexing with WordNet Synsets can im-
prove Text Retrieval. In Proceedings of the COL-
ING/ACL’98 Workshop on Usage of WordNet for
NLP, Montreal, Canada.
K. Humphreys, R. Gaizauskas, S. Azzam, C. Huyck,
B. Mitchell, H. Cunningham, and Y. Wilks. 1998.
University of Sheffield: Description of the LaSIE-
II system as used for MUC-7. In Proceedings
of the Seventh Message Understanding Confer-
ences (MUC-7). Morgan Kaufman. Available at
http://www.saic.com.
B. Levin. 1993. English Verb Classes and Alterna-
tions. Chicago, Il.
G. Miller. 1990. Five Papers on WordNet. Interna-
tional Journal of Lexicography, 4(3).
MUC-6. 1995. Proceedings of the Sixth Mes-
sage Understanding Conference (MUC-6). Mor-
gan Kaufman. Available at http://www.saic.com.
C.J. Rijsbergen. 1979. Information Retrieval. But-
terworths, London.
H. Rodriquez, S. Climent, P. Vossen, L. Bloksma,
A. Roventini, F. Bertagna, A. Alonge, and W. Pe-
ters. 1998. The Top-Down Strategy for Building
EuroWordNet: Vocabulary Coverage, Base Con-
cepts and Top Ontology. Special Issue on Eu-
roWordNet. Computers and the Humanities, 32(2-
3):117–152.
K. Spark Jones and P. Willett, editors. 1997. Read-
ings in Information Retrieval. Morgan Kaufmann,
San Francisco, CA.
P. Vossen. 1998. EuroWordNet: A Multilin-
gual Database with Lexical Semantic Networks.
Kluwer Academic Publishers, Dordrecht.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.097781">
<title confidence="0.7893775">Knowledge-Based Multilingual Document Analysis Basili Catizone Padro</title>
<author confidence="0.9245555">Rigau Setzer Webb F Zanzotto</author>
<affiliation confidence="0.958802333333333">Dept. of Computer Science, Systems and Production University of Rome, Tor Vergata Via di Tor Vergata</affiliation>
<address confidence="0.999951">00133 Roma, Italy</address>
<email confidence="0.997395">basili,pazienza,zanzotto@info.uniroma2.it</email>
<affiliation confidence="0.993993">Department of Computer University of</affiliation>
<address confidence="0.5148835">Regent Court, 211 Portobello Sheffield S1 4DP,</address>
<email confidence="0.965992">R.Catizone,A.Setzer,</email>
<affiliation confidence="0.98552">Departament de Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya Centre de Recerca TALP</affiliation>
<address confidence="0.932447">Jordi Girona Salgado 1-3 08034 Barcelona, Spain</address>
<email confidence="0.986418">l.padro,g.rigau@lsi.upc.es</email>
<abstract confidence="0.998024047619048">The growing availability of multilingual resources, like EuroWordnet, has recently inspired the development of large scale linguistic technologies, e.g. multilingual IE and Q&amp;A, that were considered infeasible until a few years ago. In this paper a system for categorisation and automatic authoring of news streams in different languages is presented. In our system, a knowledge-based approach to Information Extraction is adopted as a support for hyperlinking. Authoring across documents in different languages is triggered by Named Entities and event recognition. The matching of events in texts is carried out by discourse processing driven by a large scale world model. This kind of multilingual analysis relies on a lexical knowledge base of nouns(i.e. the EuroWordnet Base Concepts) shared among English, Spanish and Italian lexicons. The impact of the design choices on the language independence and the possibilities it opens for automatic learning of the event hierarchy will be discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>G Rigau</author>
</authors>
<title>A Proposal for Word Sense Disambiguation using Conceptual Distance.</title>
<date>1995</date>
<booktitle>In International Conference ”Recent Advances in Natural Language Processing” RANLP’95, Tzigov Chark,</booktitle>
<contexts>
<context position="14548" citStr="Agirre and Rigau, 1995" startWordPosition="2292" endWordPosition="2295">rammatical relations are realised in texts. This information is used to generalise verb arguments. For each node/pattern, the nouns appearing in the same argumental position (in at least one of the referred examples in the corpus) are grouped together to form a noun set : a learning algorithm based on EuroWordNet derives the most informative EuroWordNet synset(s) for each argument, activated by the members. Most informative synsets are those capable of (1) generalising as many nouns as possible in , while (2) preserving their specific semantic properties. A metric based on conceptual density (Agirre and Rigau, 1995) is here employed to detect the promising, most specific generalisations of . Then the derived sets for each argument are used to generate the minimal set of semantic patterns capable of “covering” all the examples in , with . The sequences express the most promising generalisations of examples for the subcategorisation . As an example, (buy, [Agent:Company,Object:Company]) expresses the knowledge required for matching sentences like ”Intel buys Vortex”. Full details on the above process can be found in (Basili et al., 2000a). Notice how Company is a base concept in EuroWordNet and it is share</context>
</contexts>
<marker>Agirre, Rigau, 1995</marker>
<rawString>E. Agirre and G. Rigau. 1995. A Proposal for Word Sense Disambiguation using Conceptual Distance. In International Conference ”Recent Advances in Natural Language Processing” RANLP’95, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>M Vindigni</author>
</authors>
<title>Corpus-driven unsupervised learning of verb subcategorization frames.</title>
<date>1997</date>
<booktitle>AI*IA 97: Advances in Artificial Intelligence, Lecture Notes in Artificial Intelligence n.,</booktitle>
<pages>1321</pages>
<editor>In M. Lenzerini, editor,</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="13337" citStr="Basili et al., 1997" startWordPosition="2099" endWordPosition="2102">e). Complete properties express for each cluster candidate subcategorisation patterns for the target verb . Finally, the lattice is traversed top-down and the search stops at the more important clusters (i.e. those showing a large set of members and characterised by linguistically appealing properties): they are retained and a lexicon of subcategorisation structures (i.e. grammatical patterns describing different usages of the same verb) is compiled for the target verb . Forexample, (buy, [Subj:X, Obj:Y]) can be used to describe the transitive usage of the verb . More details can be found in (Basili et al., 1997). 4.1.2 Corpus-driven Induction of Verb Selectional Restrictions The lattice can be further refined to express semantic constraints over the syntactic patterns specified at the previous stage. A technique proposed in (Basili et al., 2000a) is adopted by deriving semantic constraints via synsets (i.e. synonymy sets) in the WordNet 1.6 base concepts (part of EuroWordNet). When a given lattice node expresses a set of syntactic properties, then this suggests: a set of grammatical relations necessary to express a given verb meaning, ; and references to source corpus contexts where the grammatical r</context>
</contexts>
<marker>Basili, Pazienza, Vindigni, 1997</marker>
<rawString>R. Basili, M.T. Pazienza, and M. Vindigni. 1997. Corpus-driven unsupervised learning of verb subcategorization frames. In M. Lenzerini, editor, AI*IA 97: Advances in Artificial Intelligence, Lecture Notes in Artificial Intelligence n., 1321. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>M Vindigni</author>
</authors>
<title>Corpus-driven learning of Event Recognition Rules.</title>
<date>2000</date>
<booktitle>In Proceedings ofMachine Learning for Information Extraction workshop, held jointly with the ECAI2000,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="6025" citStr="Basili et al., 2000" startWordPosition="946" endWordPosition="949">ed Hat) ... The hypothesis underlying Authoring is that all the above news items deal with facts in the same area of interest to a potential class of readers. They should be thus linked and links should suggest to the user that the underlying motivation is that they all refer to Intel acquisitions. 3 The NAMIC Architecture The NAMIC system uses a modularised IE architecture whose principal components, used to create the IE repository, are morpho-syntactic analysis, categorisation and semantic analysis. During MorphoSyntactic analysis, a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000b), provides the extraction of dependency graphs from source sentences. Ambiguity is controlled by partof-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. It is within the semantic analysis, which relies on the output of this parser, that objects in the text, and their relationships to key events are captured. This process is explained in more detail in 4. In the next two sections, we will elaborate on the IE engine. For a full description of the NAMIC Architecture see (Basili et al., 2001). 3.1 LaSIE In NAMIC, we have integrated a key part o</context>
<context position="13574" citStr="Basili et al., 2000" startWordPosition="2134" endWordPosition="2137">members and characterised by linguistically appealing properties): they are retained and a lexicon of subcategorisation structures (i.e. grammatical patterns describing different usages of the same verb) is compiled for the target verb . Forexample, (buy, [Subj:X, Obj:Y]) can be used to describe the transitive usage of the verb . More details can be found in (Basili et al., 1997). 4.1.2 Corpus-driven Induction of Verb Selectional Restrictions The lattice can be further refined to express semantic constraints over the syntactic patterns specified at the previous stage. A technique proposed in (Basili et al., 2000a) is adopted by deriving semantic constraints via synsets (i.e. synonymy sets) in the WordNet 1.6 base concepts (part of EuroWordNet). When a given lattice node expresses a set of syntactic properties, then this suggests: a set of grammatical relations necessary to express a given verb meaning, ; and references to source corpus contexts where the grammatical relations are realised in texts. This information is used to generalise verb arguments. For each node/pattern, the nouns appearing in the same argumental position (in at least one of the referred examples in the corpus) are grouped togeth</context>
<context position="15077" citStr="Basili et al., 2000" startWordPosition="2375" endWordPosition="2378">pecific semantic properties. A metric based on conceptual density (Agirre and Rigau, 1995) is here employed to detect the promising, most specific generalisations of . Then the derived sets for each argument are used to generate the minimal set of semantic patterns capable of “covering” all the examples in , with . The sequences express the most promising generalisations of examples for the subcategorisation . As an example, (buy, [Agent:Company,Object:Company]) expresses the knowledge required for matching sentences like ”Intel buys Vortex”. Full details on the above process can be found in (Basili et al., 2000a). Notice how Company is a base concept in EuroWordNet and it is shared among the three languages. It can thus be activated via the InterLingual-Index from lexical items of any language. If included in the world model (as a concept in the object hierarchy), these base concepts play the role of a multilingual abstraction for the event constraints. 4.1.3 Induction of Domain event Types via Conceptual Clustering of Verb semantic Patterns The final phase in the development of a large scale world model aims to link the event matching rules valid for one verb to the suitable event hierarchy nodes. </context>
</contexts>
<marker>Basili, Pazienza, Vindigni, 2000</marker>
<rawString>R. Basili, M.T. Pazienza, and M. Vindigni. 2000a. Corpus-driven learning of Event Recognition Rules. In Proceedings ofMachine Learning for Information Extraction workshop, held jointly with the ECAI2000, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>F M Zanzotto</author>
</authors>
<title>Customizable Modular Lexicalized Parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th International Workshop on Parsing Technology, IWPT2000,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="6025" citStr="Basili et al., 2000" startWordPosition="946" endWordPosition="949">ed Hat) ... The hypothesis underlying Authoring is that all the above news items deal with facts in the same area of interest to a potential class of readers. They should be thus linked and links should suggest to the user that the underlying motivation is that they all refer to Intel acquisitions. 3 The NAMIC Architecture The NAMIC system uses a modularised IE architecture whose principal components, used to create the IE repository, are morpho-syntactic analysis, categorisation and semantic analysis. During MorphoSyntactic analysis, a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000b), provides the extraction of dependency graphs from source sentences. Ambiguity is controlled by partof-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. It is within the semantic analysis, which relies on the output of this parser, that objects in the text, and their relationships to key events are captured. This process is explained in more detail in 4. In the next two sections, we will elaborate on the IE engine. For a full description of the NAMIC Architecture see (Basili et al., 2001). 3.1 LaSIE In NAMIC, we have integrated a key part o</context>
<context position="13574" citStr="Basili et al., 2000" startWordPosition="2134" endWordPosition="2137">members and characterised by linguistically appealing properties): they are retained and a lexicon of subcategorisation structures (i.e. grammatical patterns describing different usages of the same verb) is compiled for the target verb . Forexample, (buy, [Subj:X, Obj:Y]) can be used to describe the transitive usage of the verb . More details can be found in (Basili et al., 1997). 4.1.2 Corpus-driven Induction of Verb Selectional Restrictions The lattice can be further refined to express semantic constraints over the syntactic patterns specified at the previous stage. A technique proposed in (Basili et al., 2000a) is adopted by deriving semantic constraints via synsets (i.e. synonymy sets) in the WordNet 1.6 base concepts (part of EuroWordNet). When a given lattice node expresses a set of syntactic properties, then this suggests: a set of grammatical relations necessary to express a given verb meaning, ; and references to source corpus contexts where the grammatical relations are realised in texts. This information is used to generalise verb arguments. For each node/pattern, the nouns appearing in the same argumental position (in at least one of the referred examples in the corpus) are grouped togeth</context>
<context position="15077" citStr="Basili et al., 2000" startWordPosition="2375" endWordPosition="2378">pecific semantic properties. A metric based on conceptual density (Agirre and Rigau, 1995) is here employed to detect the promising, most specific generalisations of . Then the derived sets for each argument are used to generate the minimal set of semantic patterns capable of “covering” all the examples in , with . The sequences express the most promising generalisations of examples for the subcategorisation . As an example, (buy, [Agent:Company,Object:Company]) expresses the knowledge required for matching sentences like ”Intel buys Vortex”. Full details on the above process can be found in (Basili et al., 2000a). Notice how Company is a base concept in EuroWordNet and it is shared among the three languages. It can thus be activated via the InterLingual-Index from lexical items of any language. If included in the world model (as a concept in the object hierarchy), these base concepts play the role of a multilingual abstraction for the event constraints. 4.1.3 Induction of Domain event Types via Conceptual Clustering of Verb semantic Patterns The final phase in the development of a large scale world model aims to link the event matching rules valid for one verb to the suitable event hierarchy nodes. </context>
</contexts>
<marker>Basili, Pazienza, Zanzotto, 2000</marker>
<rawString>R. Basili, M.T. Pazienza, and F.M. Zanzotto. 2000b. Customizable Modular Lexicalized Parsing. In Proceedings of the 6th International Workshop on Parsing Technology, IWPT2000, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>R Catizone</author>
<author>L Padro</author>
<author>M T Pazienza</author>
<author>R Rigau</author>
<author>A Setzer</author>
<author>N Webb</author>
<author>Y Wilks</author>
<author>F M Zanzotto</author>
</authors>
<title>Multilingual Authoring: the NAMIC Approach.</title>
<date>2001</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology and Knowledge Management (at ACL-EACL</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="6572" citStr="Basili et al., 2001" startWordPosition="1034" endWordPosition="1037">ular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000b), provides the extraction of dependency graphs from source sentences. Ambiguity is controlled by partof-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. It is within the semantic analysis, which relies on the output of this parser, that objects in the text, and their relationships to key events are captured. This process is explained in more detail in 4. In the next two sections, we will elaborate on the IE engine. For a full description of the NAMIC Architecture see (Basili et al., 2001). 3.1 LaSIE In NAMIC, we have integrated a key part of the Information Extraction system called LaSIE (Large-scale Information Extraction system, (Humphreys et al., 1998)). Specifically, we have taken the Named Entity Matcher and the Discourse Processor from the overall architecture of LaSIE. The roles of each of these modules is outlined below. 3.1.1 Named Entity Matcher The Named Entity (NE) Matcher finds named entities (persons, organisations, locations, and dates, in our case) through a secondary phase of parsing which uses a NE grammar and a set of gazetteer lists. It takes as input parse</context>
</contexts>
<marker>Basili, Catizone, Padro, Pazienza, Rigau, Setzer, Webb, Wilks, Zanzotto, 2001</marker>
<rawString>R. Basili, R. Catizone, L. Padro, M.T. Pazienza, R. Rigau, A. Setzer, N. Webb, Y. Wilks, and F.M. Zanzotto. 2001. Multilingual Authoring: the NAMIC Approach. In Proceedings of the Workshop on Human Language Technology and Knowledge Management (at ACL-EACL 2001), Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daude</author>
<author>L Padro</author>
<author>R Rigau</author>
</authors>
<title>Mapping WordNets using Structural Information.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics ACL’00,</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="20216" citStr="Daude et al., 2000" startWordPosition="3160" endWordPosition="3163">et EuroWordNet (Vossen, 1998) is a multilingual lexical knowledge (KB) base comprised of hierarchical representations of lexical items for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the English WordNet developed at Princeton (Miller, 1990) in terms of synsets (sets of synonymous words) with basic semantic relations between them. In addition, the wordnets are linked to an InterLingual-Index (ILI), based on the Princeton WordNet 1.5. (WordNet 1.6 is also connected to the ILI as another English WordNet (Daude et al., 2000)). Via this index, the languages are interconnected so that it is possible to go from concepts in one language to concepts in any other language having similar meaning. Such an index also gives access to a shared top-ontology and a subset of 1024 Base Concepts (BC). The Base Concepts provide a common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets. The KB can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (Gonzalo et al., 1998). 4.2.2 EuroWordNet as the Object Ontol</context>
</contexts>
<marker>Daude, Padro, Rigau, 2000</marker>
<rawString>J. Daude, L. Padro, and R. Rigau. 2000. Mapping WordNets using Structural Information. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics ACL’00, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>K Humphreys</author>
</authors>
<title>XI: A Simple Prolog-based Language for CrossClassification and Inheritance.</title>
<date>1996</date>
<booktitle>In Proceedings of the 6th International Conference on Artificial Intelligence: Methodologies, Systems, Applications (AIMSA96),</booktitle>
<pages>86--95</pages>
<contexts>
<context position="7892" citStr="Gaizauskas and Humphreys, 1996" startWordPosition="1247" endWordPosition="1250">g a predefined set of named entities and a set of gazetteer lists containing proper nouns. The NE Matcher returns the text with the Named Entities marked. The NE grammar contains rules for coreferring abbreviations as well as different ways of expressing the same named entity such as Dr. Smith, John Smith and Mr. Smith occurring in the same article. 3.1.2 Discourse Processor The Discourse Processor module translates the semantic representation produced by the parser into a representation of instances, their ontological classes and their attributes, in the XI knowledge representation language (Gaizauskas and Humphreys, 1996). XI allows a straightforward definition of crossclassification hierarchies, the association of arbitrary attributes with classes or instances, and a simple mechanism to inherit attributes from classes or instances higher in the hierarchy. The semantic representation produced by the parser for a single sentence is processed by adding its instances, together with their attributes, to the discourse model which has been constructed for a text. Following the addition of the instances mentioned in the current sentence, together with any presuppositions that they inherit, the coreference algorithm i</context>
</contexts>
<marker>Gaizauskas, Humphreys, 1996</marker>
<rawString>R. Gaizauskas and K. Humphreys. 1996. XI: A Simple Prolog-based Language for CrossClassification and Inheritance. In Proceedings of the 6th International Conference on Artificial Intelligence: Methodologies, Systems, Applications (AIMSA96), pages 86–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejo</author>
<author>I Chugur</author>
<author>J Cigarran</author>
</authors>
<title>Indexing with WordNet Synsets can improve Text Retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL’98 Workshop on Usage of WordNet for NLP,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="20777" citStr="Gonzalo et al., 1998" startWordPosition="3256" endWordPosition="3259">d to the ILI as another English WordNet (Daude et al., 2000)). Via this index, the languages are interconnected so that it is possible to go from concepts in one language to concepts in any other language having similar meaning. Such an index also gives access to a shared top-ontology and a subset of 1024 Base Concepts (BC). The Base Concepts provide a common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets. The KB can be used, among others, for monolingual and cross-lingual information retrieval, which was demonstrated by (Gonzalo et al., 1998). 4.2.2 EuroWordNet as the Object Ontology The example rules shown in the previous section relate to Agents which conveniently belong to a class of Named Entities as would be easily recognised under the MUC competition rules (person, company and location for example). However, a majority of the rules extracted automatically from the corpus data involved other kinds of semantic classes of information which play key roles in the subcategorisation patterns of the verbs. In order to be able to work with these patterns, it was necessary to extend the number of semantic classes beyond the usual numb</context>
</contexts>
<marker>Gonzalo, Verdejo, Chugur, Cigarran, 1998</marker>
<rawString>J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigarran. 1998. Indexing with WordNet Synsets can improve Text Retrieval. In Proceedings of the COLING/ACL’98 Workshop on Usage of WordNet for NLP, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Humphreys</author>
<author>R Gaizauskas</author>
<author>S Azzam</author>
<author>C Huyck</author>
<author>B Mitchell</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>University of Sheffield: Description of the LaSIEII system as used for MUC-7.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conferences (MUC-7).</booktitle>
<publisher>Morgan</publisher>
<contexts>
<context position="6742" citStr="Humphreys et al., 1998" startWordPosition="1060" endWordPosition="1063">d by partof-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. It is within the semantic analysis, which relies on the output of this parser, that objects in the text, and their relationships to key events are captured. This process is explained in more detail in 4. In the next two sections, we will elaborate on the IE engine. For a full description of the NAMIC Architecture see (Basili et al., 2001). 3.1 LaSIE In NAMIC, we have integrated a key part of the Information Extraction system called LaSIE (Large-scale Information Extraction system, (Humphreys et al., 1998)). Specifically, we have taken the Named Entity Matcher and the Discourse Processor from the overall architecture of LaSIE. The roles of each of these modules is outlined below. 3.1.1 Named Entity Matcher The Named Entity (NE) Matcher finds named entities (persons, organisations, locations, and dates, in our case) through a secondary phase of parsing which uses a NE grammar and a set of gazetteer lists. It takes as input parsed text from the first phase of parsing and the NE grammar which contains rules for finding a predefined set of named entities and a set of gazetteer lists containing prop</context>
</contexts>
<marker>Humphreys, Gaizauskas, Azzam, Huyck, Mitchell, Cunningham, Wilks, 1998</marker>
<rawString>K. Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell, H. Cunningham, and Y. Wilks. 1998. University of Sheffield: Description of the LaSIEII system as used for MUC-7. In Proceedings of the Seventh Message Understanding Conferences (MUC-7). Morgan Kaufman. Available at http://www.saic.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<location>Chicago, Il.</location>
<contexts>
<context position="18722" citStr="Levin, 1993" startWordPosition="2924" endWordPosition="2925">or English can be retained for other languages, and a simple translation suffices for most of the patterns. Lexicalisations are thus associated with the language independent abstractions (i.e. matching rules over parsed texts) which control the behaviour of instances of these events in the discourse processing. The integrated adoption of EuroWordNet and the automatic acquisition/translation of verb rules is thus the key idea leading to a successful and quick development of the large scale IE component required for automatic authoring. &apos;Initial partitions according to the Levin classification (Levin, 1993) are adopted. A partition of the verbs is built for each of the Levin classes and conceptual clustering is applied internally to each group. 4.2 Object Hierarchy In typical Information Extraction processing environments, the range of objects in the text is expected to be as limited and constrained as the event types. For example, when processing ’management succession’ events (MUC-6, 1995), the object types are the obvious person, location, organisation, time and date. Intuitively however, if the need was to process the entire output of a news gathering organisation, it seems clear that we mus</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>B. Levin. 1993. English Verb Classes and Alternations. Chicago, Il.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>Five Papers on WordNet.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="19930" citStr="Miller, 1990" startWordPosition="3113" endWordPosition="3114">e must be able to capture a much wider range of possible objects which interact with central events. Rather than attempt to acquire all of this object information from the corpus data, we instead chose to use an existing multilingual lexical resource, EuroWordNet. 4.2.1 EuroWordNet EuroWordNet (Vossen, 1998) is a multilingual lexical knowledge (KB) base comprised of hierarchical representations of lexical items for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the English WordNet developed at Princeton (Miller, 1990) in terms of synsets (sets of synonymous words) with basic semantic relations between them. In addition, the wordnets are linked to an InterLingual-Index (ILI), based on the Princeton WordNet 1.5. (WordNet 1.6 is also connected to the ILI as another English WordNet (Daude et al., 2000)). Via this index, the languages are interconnected so that it is possible to go from concepts in one language to concepts in any other language having similar meaning. Such an index also gives access to a shared top-ontology and a subset of 1024 Base Concepts (BC). The Base Concepts provide a common semantic fra</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Five Papers on WordNet. International Journal of Lexicography, 4(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaufman</author>
</authors>
<date>1995</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference (MUC-6).</booktitle>
<publisher>Morgan</publisher>
<note>Available at http://www.saic.com.</note>
<marker>Kaufman, 1995</marker>
<rawString>MUC-6. 1995. Proceedings of the Sixth Message Understanding Conference (MUC-6). Morgan Kaufman. Available at http://www.saic.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<publisher>Butterworths,</publisher>
<location>London.</location>
<contexts>
<context position="23945" citStr="Rijsbergen, 1979" startWordPosition="3784" endWordPosition="3785">5 Discussion and Future Work The NAMIC system was created to provide an environment for automatic hypertextual authoring of multilingual news articles. In order to address that task, we created language processors in three languages (English, Italian and Spanish) which allows us to create a database of conceptually analysed text. The ability to analyse text in this way is vital for the authoring process, but is also applicable to a wide range of technologies, including Information Retrieval in general, and Question-Answering in particular. Information Retrieval (Spark Jones and Willett, 1997; Rijsbergen, 1979), or document retrieval as it is in practice, is a well used, robust technology which allows users to access some subset of documents by means of a set of keywords. However, the retrieval of answers to questions by keywords, whilst easy to implement, suffers by their restrictive nature. For example, a keyword based retrieval mechanism would be unable to distinguish between the queries who killed Lee Harvey Oswald? and who did Lee Harvey Oswald kill?, operating as they do by reducing these queries to a bag of stemmed words. By accessing the kind of knowledge base that we created in the Namic pr</context>
</contexts>
<marker>Rijsbergen, 1979</marker>
<rawString>C.J. Rijsbergen. 1979. Information Retrieval. Butterworths, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rodriquez</author>
<author>S Climent</author>
<author>P Vossen</author>
<author>L Bloksma</author>
<author>A Roventini</author>
<author>F Bertagna</author>
<author>A Alonge</author>
<author>W Peters</author>
</authors>
<title>The Top-Down Strategy for Building EuroWordNet: Vocabulary Coverage, Base Concepts and Top Ontology.</title>
<date>1998</date>
<booktitle>Special Issue on EuroWordNet. Computers and the Humanities,</booktitle>
<pages>32--2</pages>
<contexts>
<context position="21629" citStr="Rodriquez et al., 1998" startWordPosition="3397" endWordPosition="3400">son, company and location for example). However, a majority of the rules extracted automatically from the corpus data involved other kinds of semantic classes of information which play key roles in the subcategorisation patterns of the verbs. In order to be able to work with these patterns, it was necessary to extend the number of semantic classes beyond the usual number of predefined classes, across a variety of languages. Representing the entirety of EWN in our object hierarchy would be time consuming, and lead to inefficient processing times. Instead we took advantage of the Base Concepts (Rodriquez et al., 1998) within EWN, a set of approximately 1000 nodes, with hierarchical structure, that can be used to generalise the rest of the EWN hierarchy. These Base Concepts represent a core set of common concepts to be covered for every language that has been defined in EWN. A concept is determined as important (and is therefore a base concept) if it is widely used, either directly or as a reference for other widely used concepts. Importance is reflected in the ability of a concept to function as an anchor to attach other concepts. The hierarchical representation of the base concepts is added to the object </context>
</contexts>
<marker>Rodriquez, Climent, Vossen, Bloksma, Roventini, Bertagna, Alonge, Peters, 1998</marker>
<rawString>H. Rodriquez, S. Climent, P. Vossen, L. Bloksma, A. Roventini, F. Bertagna, A. Alonge, and W. Peters. 1998. The Top-Down Strategy for Building EuroWordNet: Vocabulary Coverage, Base Concepts and Top Ontology. Special Issue on EuroWordNet. Computers and the Humanities, 32(2-3):117–152.</rawString>
</citation>
<citation valid="true">
<date>1997</date>
<booktitle>Readings in Information Retrieval.</booktitle>
<editor>K. Spark Jones and P. Willett, editors.</editor>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA.</location>
<marker>1997</marker>
<rawString>K. Spark Jones and P. Willett, editors. 1997. Readings in Information Retrieval. Morgan Kaufmann, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="19626" citStr="Vossen, 1998" startWordPosition="3069" endWordPosition="3070">trained as the event types. For example, when processing ’management succession’ events (MUC-6, 1995), the object types are the obvious person, location, organisation, time and date. Intuitively however, if the need was to process the entire output of a news gathering organisation, it seems clear that we must be able to capture a much wider range of possible objects which interact with central events. Rather than attempt to acquire all of this object information from the corpus data, we instead chose to use an existing multilingual lexical resource, EuroWordNet. 4.2.1 EuroWordNet EuroWordNet (Vossen, 1998) is a multilingual lexical knowledge (KB) base comprised of hierarchical representations of lexical items for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the English WordNet developed at Princeton (Miller, 1990) in terms of synsets (sets of synonymous words) with basic semantic relations between them. In addition, the wordnets are linked to an InterLingual-Index (ILI), based on the Princeton WordNet 1.5. (WordNet 1.6 is also connected to the ILI as another English WordNet (Daude et al., 2000)). Via thi</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>P. Vossen. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>