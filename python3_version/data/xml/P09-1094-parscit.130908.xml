<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000129">
<title confidence="0.973147">
Application-driven Statistical Paraphrase Generation
</title>
<author confidence="0.998264">
Shiqi Zhao, Xiang Lan, Ting Liu, Sheng Li
</author>
<affiliation confidence="0.978774">
Information Retrieval Lab, Harbin Institute of Technology
</affiliation>
<address confidence="0.9158515">
6F Aoxiao Building, No.27 Jiaohua Street, Nangang District
Harbin, 150001, China
</address>
<email confidence="0.999109">
{zhaosq,xlan,tliu,lisheng}@ir.hit.edu.cn
</email>
<sectionHeader confidence="0.993898" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997336">
Paraphrase generation (PG) is important
in plenty of NLP applications. However,
the research of PG is far from enough. In
this paper, we propose a novel method for
statistical paraphrase generation (SPG),
which can (1) achieve various applications
based on a uniform statistical model, and
(2) naturally combine multiple resources
to enhance the PG performance. In our
experiments, we use the proposed method
to generate paraphrases for three differ-
ent applications. The results show that
the method can be easily transformed from
one application to another and generate
valuable and interesting paraphrases.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999846388888889">
Paraphrases are alternative ways that convey the
same meaning. There are two main threads in the
research of paraphrasing, i.e., paraphrase recogni-
tion and paraphrase generation (PG). Paraphrase
generation aims to generate a paraphrase for a
source sentence in a certain application. PG shows
its importance in many areas, such as question
expansion in question answering (QA) (Duboue
and Chu-Carroll, 2006), text polishing in natu-
ral language generation (NLG) (Iordanskaja et al.,
1991), text simplification in computer-aided read-
ing (Carroll et al., 1999), and sentence similarity
computation in the automatic evaluation of ma-
chine translation (MT) (Kauchak and Barzilay,
2006) and summarization (Zhou et al., 2006).
This paper presents a method for statistical
paraphrase generation (SPG). As far as we know,
this is the first statistical model specially designed
for paraphrase generation. It’s distinguishing fea-
ture is that it achieves various applications with a
uniform model. In addition, it exploits multiple
resources, including paraphrase phrases, patterns,
and collocations, to resolve the data shortage prob-
lem and generate more varied paraphrases.
We consider three paraphrase applications in
our experiments, including sentence compression,
sentence simplification, and sentence similarity
computation. The proposed method generates
paraphrases for the input sentences in each appli-
cation. The generated paraphrases are then man-
ually scored based on adequacy, fluency, and us-
ability. The results show that the proposed method
is promising, which generates useful paraphrases
for the given applications. In addition, comparison
experiments show that our method outperforms a
conventional SMT-based PG method.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9990714">
Conventional methods for paraphrase generation
can be classified as follows:
Rule-based methods: Rule-based PG methods
build on a set of paraphrase rules or patterns,
which are either hand crafted or automatically
collected. In the early rule-based PG research,
the paraphrase rules are generally manually writ-
ten (McKeown, 1979; Zong et al., 2001), which
is expensive and arduous. Some researchers then
tried to automatically extract paraphrase rules (Lin
and Pantel, 2001; Barzilay and Lee, 2003; Zhao
et al., 2008b), which facilitates the rule-based PG
methods. However, it has been shown that the
coverage of the paraphrase patterns is not high
enough, especially when the used paraphrase pat-
terns are long or complicated (Quirk et al., 2004).
Thesaurus-based methods: The thesaurus-based
methods generate a paraphrase t for a source sen-
tence s by substituting some words in s with
their synonyms (Bolshakov and Gelbukh, 2004;
</bodyText>
<page confidence="0.976751">
834
</page>
<note confidence="0.9996125">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999395239130435">
Kauchak and Barzilay, 2006). This kind of method
usually involves two phases, i.e., candidate extrac-
tion and paraphrase validation. In the first phase,
it extracts all synonyms from a thesaurus, such as
WordNet, for the words to be substituted. In the
second phase, it selects an optimal substitute for
each given word from the synonyms according to
the context in s. This kind of method is simple,
since the thesaurus synonyms are easy to access.
However, it cannot generate other types of para-
phrases but only synonym substitution.
NLG-based methods: NLG-based methods (Ko-
zlowski et al., 2003; Power and Scott, 2005) gen-
erally involve two stages. In the first one, the
source sentence s is transformed into its semantic
representation r by undertaking a series of NLP
processing, including morphology analyzing, syn-
tactic parsing, semantic role labeling, etc. In the
second stage, a NLG system is employed to gen-
erate a sentence t from r. s and t are paraphrases
as they are both derived from r. The NLG-based
methods simulate human paraphrasing behavior,
i.e., understanding a sentence and presenting the
meaning in another way. However, deep analysis
of sentences is a big challenge. Moreover, devel-
oping a NLG system is also not trivial.
SMT-based methods: SMT-based methods
viewed PG as monolingual MT, i.e., translating s
into t that are in the same language. Researchers
employ the existing SMT models for PG (Quirk
et al., 2004). Similar to typical SMT, a large
parallel corpus is needed as training data in the
SMT-based PG. However, such data are difficult
to acquire compared with the SMT data. There-
fore, data shortage becomes the major limitation
of the method. To address this problem, we have
tried combining multiple resources to improve the
SMT-based PG model (Zhao et al., 2008a).
There have been researchers trying to propose
uniform PG methods for multiple applications.
But they are either rule-based (Murata and Isa-
hara, 2001; Takahashi et al., 2001) or thesaurus-
based (Bolshakov and Gelbukh, 2004), thus they
have some limitations as stated above. Further-
more, few of them conducted formal experiments
to evaluate the proposed methods.
</bodyText>
<sectionHeader confidence="0.969849" genericHeader="method">
3 Statistical Paraphrase Generation
</sectionHeader>
<subsectionHeader confidence="0.996944">
3.1 Differences between SPG and SMT
</subsectionHeader>
<bodyText confidence="0.9887115">
Despite the similarity between PG and MT, the
statistical model used in SMT cannot be directly
</bodyText>
<listItem confidence="0.964834885714286">
applied in SPG, since there are some clear differ-
ences between them:
1. SMT has a unique purpose, i.e., producing
high-quality translations for the inputs. On
the contrary, SPG has distinct purposes in
different applications, such as sentence com-
pression, sentence simplification, etc. The
usability of the paraphrases have to be as-
sessed in each application.
2. In SMT, words of an input sentence should
be totally translated, whereas in SPG, not all
words of an input sentence need to be para-
phrased. Therefore, a SPG model should be
able to decide which part of a sentence needs
to be paraphrased.
3. The bilingual parallel data for SMT are easy
to collect. In contrast, the monolingual paral-
lel data for SPG are not so common (Quirk
et al., 2004). Thus the SPG model should
be able to easily combine different resources
and thereby solve the data shortage problem
(Zhao et al., 2008a).
4. Methods have been proposed for automatic
evaluation in MT (e.g., BLEU (Papineni et
al., 2002)). The basic idea is that a translation
should be scored based on their similarity to
the human references. However, they cannot
be adopted in SPG. The main reason is that it
is more difficult to provide human references
in SPG. Lin and Pantel (2001) have demon-
strated that the overlapping between the au-
tomatically acquired paraphrases and hand-
crafted ones is very small. Thus the human
references cannot properly assess the quality
of the generated paraphrases.
</listItem>
<subsectionHeader confidence="0.999964">
3.2 Method Overview
</subsectionHeader>
<bodyText confidence="0.9984465">
The SPG method proposed in this work contains
three components, i.e., sentence preprocessing,
paraphrase planning, and paraphrase generation
(Figure 1). Sentence preprocessing mainly in-
cludes POS tagging and dependency parsing for
the input sentences, as POS tags and dependency
information are necessary for matching the para-
phrase pattern and collocation resources in the
following stages. Paraphrase planning (Section
3.3) aims to select the units to be paraphrased
(called source units henceforth) in an input sen-
tence and the candidate paraphrases for the source
</bodyText>
<page confidence="0.998986">
835
</page>
<figureCaption confidence="0.999762">
Figure 1: Overview of the proposed SPG method.
</figureCaption>
<bodyText confidence="0.9978084">
units (called target units) from multiple resources
according to the given application A. Paraphrase
generation (Section 3.4) is designed to generate
paraphrases for the input sentences by selecting
the optimal target units with a statistical model.
</bodyText>
<figure confidence="0.874046961538461">
Input: source sentences
Input: paraphrase application A
t Input: paraphrase tables PTs
Output: set of source units SU
Output: set of target units TU
Extract source units of s from PTs: SU={sul, ..., su„}
For each source unit sui
Extract its target units TUi={tuil, ..., tuil.}
For each target unit tui�
If tui� cannot achieve the application A
Delete tui� from TUi
End If
End For
If TUi is empty
Delete sui from SU
End If
End for
Sentence
Preprocessing
PT1
Multiple Paraphrase Tables
PT2 °•••• PTn
Paraphrase
Planning
Paraphrase
Generation
</figure>
<figureCaption confidence="0.99991">
Figure 2: The paraphrase planning algorithm.
</figureCaption>
<subsectionHeader confidence="0.999167">
3.3 Paraphrase Planning
</subsectionHeader>
<bodyText confidence="0.99998062962963">
In this work, the multiple paraphrase resources are
stored in paraphrase tables (PTs). A paraphrase ta-
ble is similar to a phrase table in SMT, which con-
tains fine-grained paraphrases, such as paraphrase
phrases, patterns, or collocations. The PTs used in
this work are constructed using different corpora
and different score functions (Section 3.5).
If the applications are not considered, all units
of an input sentence that can be paraphrased us-
ing the PTs will be extracted as source units. Ac-
cordingly, all paraphrases for the source units will
be extracted as target units. However, when a cer-
tain application is given, only the source and target
units that can achieve the application will be kept.
We call this process paraphrase planning, which is
formally defined as in Figure 2.
An example is depicted in Figure 3. The ap-
plication in this example is sentence compression.
All source and target units are listed below the in-
put sentence, in which the first two source units
are phrases, while the third and fourth are a pattern
and a collocation, respectively. As can be seen, the
first and fourth source units are filtered in para-
phrase planning, since none of their paraphrases
achieve the application (i.e., shorter in bytes than
the source). The second and third source units are
kept, but some of their paraphrases are filtered.
</bodyText>
<subsectionHeader confidence="0.995353">
3.4 Paraphrase Generation
</subsectionHeader>
<bodyText confidence="0.997270583333333">
Our SPG model contains three sub-models: a
paraphrase model, a language model, and a usabil-
ity model, which control the adequacy, fluency,
and usability of the paraphrases, respectively1.
Paraphrase Model: Paraphrase generation is a
decoding process. The input sentence s is first
segmented into a sequence of I units sI1, which
are then paraphrased to a sequence of units �tI1.
Let (si, ti) be a pair of paraphrase units, their
paraphrase likelihood is computed using a score
function Opm(�si, ti). Thus the paraphrase score
ppm(9I1, �tI1) between s and t is decomposed into:
</bodyText>
<equation confidence="0.996264">
I
ppm(�sI1, �tI1) _ Opm(si, �ti)λp- (1)
i=1
</equation>
<bodyText confidence="0.9999585">
where Apm is the weight of the paraphrase model.
Actually, it is defined similarly to the translation
model in SMT (Koehn et al., 2003).
In practice, the units of a sentence may be para-
phrased using different PTs. Suppose we have K
PTs, (ski, tki) is a pair of paraphrase units from
the k-th PT with the score function Ok(ski, �tki),
then Equation (1) can be rewritten as:
</bodyText>
<equation confidence="0.65266">
Ok(Ski, �tki)λk) (2)
</equation>
<bodyText confidence="0.893972142857143">
where Ak is the weight for Ok(Ski, tki).
Equation (2) assumes that a pair of paraphrase
units is from only one paraphrase table. However,
1The SPG model applies monotone decoding, which does
not contain a reordering sub-model that is often used in SMT.
Instead, we use the paraphrase patterns to achieve word re-
ordering in paraphrase generation.
</bodyText>
<equation confidence="0.915383285714286">
ppm(-sI1, �tI1) _
K
H
k=1
�
(
ki
</equation>
<page confidence="0.934439">
836
</page>
<figure confidence="0.629103">
Paraphrase application: sentence compression
</figure>
<figureCaption confidence="0.964736">
Figure 3: An example of paraphrase planning.
</figureCaption>
<figure confidence="0.818375227272727">
&lt;promote, OBJ, trades&gt;
sanction! &amp;quot;#$! trades%
stimulate! &amp;quot;#$! trades%
strengthen! &amp;quot;#$! trades%
support! &amp;quot;#$! trades%
sustain! &amp;quot;#$! trades%
The US government should take the overall situation into consideration and actively promote bilateral high-tech trades.
overall situation
overall interest
overall picture
overview
��������� �� � �����
whole situation
The US government
The US administration
The US government on
take [NN�1] into consideration
consider [NN�1]
take into account [NN�I]
take account of [NN�1]
take [NN�I] into account
���� ���� ������������� ������
</figure>
<bodyText confidence="0.996922076923077">
we find that about 2% of the paraphrase units ap-
pear in two or more PTs. In this case, we only
count the PT that provides the largest paraphrase
score, i.e., kˆ = arg maxk{φk(¯si, ¯ti)λk}.
In addition, note that there may be some units
that cannot be paraphrased or prefer to keep un-
changed during paraphrasing. Therefore, we have
a self-paraphrase table in the K PTs, which para-
phrases any separate word w into itself with a con-
stant score c: φself(w, w) = c (we set c = e−1).
Language Model: We use a tri-gram language
model in this work. The language model based
score for the paraphrase t is computed as:
</bodyText>
<equation confidence="0.992497">
J
plm(�) = p(tj|tj−2tj−1)λ�— (3)
j=1
</equation>
<bodyText confidence="0.994278666666667">
where J is the length of t, tj is the j-th word of t,
and λlm is the weight for the language model.
Usability Model: The usability model prefers
paraphrase units that can better achieve the ap-
plication. The usability of t depends on para-
phrase units it contains. Hence the usability model
</bodyText>
<equation confidence="0.935914">
pum(¯sI1, ¯tI1) is decomposed into:
I
pum(¯sI 1, ¯tI 1) = pum(¯si, ¯ti)λu— (4)
i=1
</equation>
<bodyText confidence="0.999438">
where λum is the weight for the usability model
and pum(¯si, ¯ti) is defined as follows:
</bodyText>
<equation confidence="0.9866985">
µ(s ti)
pum(¯si, ti) = e z&apos; z (5)
</equation>
<bodyText confidence="0.998972666666667">
We consider three applications, including sentence
compression, simplification, and similarity com-
putation. µ(¯si, ¯ti) is defined separately for each:
</bodyText>
<listItem confidence="0.746781096774193">
• Sentence compression: Sentence compres-
sion2 is important for summarization, subti-
tle generation, and displaying texts in small
screens such as cell phones. In this appli-
cation, only the target units shorter than the
sources are kept in paraphrase planning. We
define µ(¯si, ¯ti) = len(¯si) − len(¯ti), where
len(·) denotes the length of a unit in bytes.
• Sentence simplification: Sentence simplifi-
cation requires using common expressions in
sentences so that readers can easily under-
stand the meaning. Therefore, only the target
units more frequent than the sources are kept
in paraphrase planning. Here, the frequency
of a unit is measured using the language
model mentioned above3. Specifically, the
langauge model assigns a score scorelm(·)
for each unit and the unit with larger score
is viewed as more frequent. We define
µ(¯si, ¯ti) = 1 iff scorelm(¯ti) &gt; scorelm(¯si).
• Sentence similarity computation: Given a
reference sentence s&apos;, this application aims to
paraphrase s into t, so that t is more similar
(closer in wording) with s&apos; than s. This ap-
plication is important for the automatic eval-
uation of machine translation and summa-
rization, since we can paraphrase the human
translations/summaries to make them more
similar to the system outputs, which can re-
fine the accuracy of the evaluation (Kauchak
and Barzilay, 2006). For this application,
</listItem>
<footnote confidence="0.9844374">
2This work defines compression as the shortening of sen-
tence length in bytes rather than in words.
3To compute the language model based score, the
matched patterns are instantiated and the matched colloca-
tions are connected with words between them.
</footnote>
<page confidence="0.993885">
837
</page>
<bodyText confidence="0.999814857142857">
only the target units that can enhance the sim-
ilarity to the reference sentence are kept in
planning. We define µ(si, ti) = sim(�ti, s&apos;)−
sim(si, s&apos;), where sim(·, ·) is simply com-
puted as the count of overlapping words.
We combine the three sub-models based on a
log-linear framework and get the SPG model:
</bodyText>
<equation confidence="0.999422428571429">
log φk(Ski, �tki))
J
+ λlm log p(tj|tj−2tj−1)
j=1
I
+ λum µ(si, ti) (6)
i=1
</equation>
<subsectionHeader confidence="0.856759">
3.5 Paraphrase Resources
</subsectionHeader>
<bodyText confidence="0.909302666666667">
We use five PTs in this work (except the self-
paraphrase table), in which each pair of paraphrase
units has a score assigned by the score function of
the corresponding method.
Paraphrase phrases (PT-1 to PT-3): Para-
phrase phrases are extracted from three corpora:
</bodyText>
<listItem confidence="0.99979425">
(1) Corp-1: bilingual parallel corpus, (2) Corp-
2: monolingual comparable corpus (comparable
news articles reporting on the same event), and
(3) Corp-3: monolingual parallel corpus (paral-
</listItem>
<bodyText confidence="0.990303947368421">
lel translations of the same foreign novel). The
details of the corpora, methods, and score func-
tions are presented in (Zhao et al., 2008a). In
our experiments, PT-1 is the largest, which con-
tains 3,041,822 pairs of paraphrase phrases. PT-2
and PT-3 contain 92,358, and 17,668 pairs of para-
phrase phrases, respectively.
Paraphrase patterns (PT-4): Paraphrase patterns
are also extracted from Corp-1. We applied the ap-
proach proposed in (Zhao et al., 2008b). Its basic
assumption is that if two English patterns e1 and e2
are aligned with the same foreign pattern f, then
e1 and e2 are possible paraphrases. One can refer
to (Zhao et al., 2008b) for the details. PT-4 con-
tains 1,018,371 pairs of paraphrase patterns.
Paraphrase collocations (PT-5): Collocations4
can cover long distance dependencies in sen-
tences. Thus paraphrase collocations are useful for
SPG. We extract collocations from a monolingual
</bodyText>
<footnote confidence="0.906142333333333">
4A collocation is a lexically restricted word pair with a
certain syntactic relation. This work only considers verb-
object collocations, e.g., &lt;promote, OBJ, trades&gt;.
</footnote>
<bodyText confidence="0.999915666666667">
corpus and use a binary classifier to recognize if
any two collocations are paraphrases. Due to the
space limit, we cannot introduce the detail of the
approach. We assign the score “1” for any pair
of paraphrase collocations. PT-5 contains 238,882
pairs of paraphrase collocations.
</bodyText>
<subsectionHeader confidence="0.985117">
3.6 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.998907108108108">
To estimate parameters λk(1 &lt; k &lt; K), λlm,
and λum, we adopt the approach of minimum error
rate training (MERT) that is popular in SMT (Och,
2003). In SMT, however, the optimization objec-
tive function in MERT is the MT evaluation cri-
teria, such as BLEU. As we analyzed above, the
BLEU-style criteria cannot be adapted in SPG. We
therefore introduce a new optimization objective
function in this paper. The basic assumption is that
a paraphrase should contain as many correct unit
replacements as possible. Accordingly, we design
the following criteria:
Replacement precision (rp): rp assesses the pre-
cision of the unit replacements, which is defined
as rp = cdev(+r)/cdev(r), where cdev(r) is the
total number of unit replacements in the generated
paraphrases on the development set. cdev(+r) is
the number of the correct replacements.
Replacement rate (rr): rr measures the para-
phrase degree on the development set, i.e., the per-
centage of words that are paraphrased. We define
rr as: rr = wdev(r)/wdev(s), where wdev(r) is
the total number of words in the replaced units on
the development set, and wdev(s) is the number of
words of all sentences on the development set.
Replacement f-measure (rf): We use rf as the
optimization objective function in MERT, which
is similar to the conventional f-measure and lever-
ages rp and rr: rf = (2 x rp x rr)/(rp + rr).
We estimate parameters for each paraphrase ap-
plication separately. For each application, we first
ask two raters to manually label all possible unit
replacements on the development set as correct or
incorrect, so that rp, rr, and rf can be automati-
cally computed under each set of parameters. The
parameters that result in the highest rf on the de-
velopment set are finally selected.
</bodyText>
<sectionHeader confidence="0.999141" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.998655">
Our SPG decoder is developed by remodeling
Moses that is widely used in SMT (Hoang and
Koehn, 2008). The POS tagger and depen-
dency parser for sentence preprocessing are SVM-
</bodyText>
<equation confidence="0.926043666666667">
p(L|s) = K 1:
k=1 (λk
ki
</equation>
<page confidence="0.989535">
838
</page>
<bodyText confidence="0.996797">
Tool (Gimenez and Marquez, 2004) and MST-
Parser (McDonald et al., 2006). The language
model is trained using a 9 GB English corpus.
</bodyText>
<subsectionHeader confidence="0.99259">
4.1 Experimental Data
</subsectionHeader>
<bodyText confidence="0.99995865">
Our method is not restricted in domain or sentence
style. Thus any sentence can be used in develop-
ment and test. However, for the sentence similarity
computation purpose in our experiments, we want
to evaluate if the method can enhance the string-
level similarity between two paraphrase sentences.
Therefore, for each input sentence s, we need a
reference sentence s&apos; for similarity computation.
Based on the above consideration, we acquire
experiment data from the human references of
the MT evaluation, which provide several human
translations for each foreign sentence. In detail,
we use the first translation of a foreign sentence
as the source s and the second translation as the
reference s&apos; for similarity computation. In our ex-
periments, the development set contains 200 sen-
tences and the test set contains 500 sentences, both
of which are randomly selected from the human
translations of 2008 NIST Open Machine Transla-
tion Evaluation: Chinese to English Task.
</bodyText>
<subsectionHeader confidence="0.978547">
4.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999982571428571">
The evaluation metrics for SPG are similar to the
human evaluation for MT (Callison-Burch et al.,
2007). The generated paraphrases are manually
evaluated based on three criteria, i.e., adequacy,
fluency, and usability, each of which has three
scales from 1 to 3. Here is a brief description of
the different scales for the criteria:
</bodyText>
<listItem confidence="0.923405">
Adequacy 1: The meaning is evidently changed.
2: The meaning is generally preserved.
3: The meaning is completely preserved.
Fluency 1: The paraphrase t is incomprehensible.
2: t is comprehensible.
3: t is a flawless sentence.
Usability 1: t is opposite to the application purpose.
2: t does not achieve the application.
3: t achieves the application.
</listItem>
<sectionHeader confidence="0.996664" genericHeader="evaluation">
5 Results and Analysis
</sectionHeader>
<bodyText confidence="0.999982222222222">
We use our method to generate paraphrases for the
three applications. Results show that the percent-
ages of test sentences that can be paraphrased are
97.2%, 95.4%, and 56.8% for the applications of
sentence compression, simplification, and similar-
ity computation, respectively. The reason why the
last percentage is much lower than the first two
is that, for sentence similarity computation, many
sentences cannot find unit replacements from the
PTs that improve the similarity to the reference
sentences. For the other applications, only some
very short sentences cannot be paraphrased.
Further results show that the average number of
unit replacements in each sentence is 5.36, 4.47,
and 1.87 for sentence compression, simplification,
and similarity computation. It also indicates that
sentence similarity computation is more difficult
than the other two applications.
</bodyText>
<subsectionHeader confidence="0.999609">
5.1 Evaluation of the Proposed Method
</subsectionHeader>
<bodyText confidence="0.999989648648648">
We ask two raters to label the paraphrases based
on the criteria defined in Section 4.2. The labeling
results are shown in the upper part of Table 1. We
can see that for adequacy and fluency, the para-
phrases in sentence similarity computation get the
highest scores. About 70% of the paraphrases are
labeled “3”. This is because in sentence similar-
ity computation, only the target units appearing
in the reference sentences are kept in paraphrase
planning. This constraint filters most of the noise.
The adequacy and fluency scores of the other two
applications are not high. The percentages of la-
bel “3” are around 30%. The main reason is that
the average numbers of unit replacements for these
two applications are much larger than sentence
similarity computation. It is thus more likely to
bring in incorrect unit replacements, which influ-
ence the quality of the generated paraphrases.
The usability is needed to be manually labeled
only for sentence simplification, since it can be
automatically labeled in the other two applica-
tions. As shown in Table 1, for sentence simplifi-
cation, most paraphrases are labeled “2” in usabil-
ity, while merely less than 20% are labeled “3”.
We conjecture that it is because the raters are not
sensitive to the slight change of the simplification
degree. Thus they labeled “2” in most cases.
We compute the kappa statistic between the
raters. Kappa is defined as K = P(A)−P(E) (Car-
1−P(E)letta, 1996), where P(A) is the proportion of times
that the labels agree, and P(E) is the proportion
of times that they may agree by chance. We define
P(E) = 13 , as the labeling is based on three point
scales. The results show that the kappa statistics
for adequacy and fluency are 0.6560 and 0.6500,
which indicates a substantial agreement (K: 0.61-
0.8) according to (Landis and Koch, 1977). The
</bodyText>
<page confidence="0.996122">
839
</page>
<table confidence="0.99991825">
Adequacy (%) Fluency (%) Usability (%)
1 2 3 1 2 3 1 2 3
Sentence rater1 32.92 44.44 22.63 21.60 47.53 30.86 0 0 100
compression rater2 40.54 34.98 24.49 25.51 43.83 30.66 0 0 100
Sentence rater1 29.77 44.03 26.21 22.01 42.77 35.22 25.37 61.84 12.79
simplification rater2 33.33 35.43 31.24 24.32 39.83 35.85 30.19 51.99 17.82
Sentence rater1 7.75 24.30 67.96 7.75 22.54 69.72 0 0 100
similarity rater2 7.75 19.01 73.24 6.69 21.48 71.83 0 0 100
Baseline-1 rater1 47.31 30.75 21.94 43.01 33.12 23.87 - - -
rater2 47.10 30.11 22.80 34.41 41.51 24.09 - - -
Baseline-2 rater1 29.45 52.76 17.79 25.15 52.76 22.09 - - -
rater2 33.95 46.01 20.04 27.61 48.06 24.34 - - -
</table>
<tableCaption confidence="0.999969">
Table 1: The evaluation results of the proposed method and two baseline methods.
</tableCaption>
<bodyText confidence="0.996158076923077">
kappa statistic for usability is 0.5849, which is
only moderate (K: 0.41-0.6).
Table 2 shows an example of the generated para-
phrases. A source sentence s is paraphrased in
each application and we can see that: (1) for sen-
tence compression, the paraphrase t is 8 bytes
shorter than s; (2) for sentence simplification, the
words wealth and part in t are easier than their
sources asset and proportion, especially for the
non-native speakers; (3) for sentence similarity
computation, the reference sentence s&apos; is listed be-
low t, in which the words appearing in t but not in
s are highlighted in blue.
</bodyText>
<subsectionHeader confidence="0.999949">
5.2 Comparison with Baseline Methods
</subsectionHeader>
<bodyText confidence="0.999969854166667">
In our experiments, we implement two baseline
methods for comparison:
Baseline-1: Baseline-1 follows the method pro-
posed in (Quirk et al., 2004), which generates
paraphrases using typical SMT tools. Similar to
Quirk et al.’s method, we extract a paraphrase ta-
ble for the SMT model from a monolingual com-
parable corpus (PT-2 described above). The SMT
decoder used in Baseline-1 is Moses.
Baseline-2: Baseline-2 extends Baseline-1 by
combining multiple resources. It exploits all PTs
introduced above in the same way as our pro-
posed method. The difference from our method is
that Baseline-2 does not take different applications
into consideration. Thus it contains no paraphrase
planning stage or the usability sub-model.
We tune the parameters for the two baselines
using the development data as described in Sec-
tion 3.6 and evaluate them with the test data. Since
paraphrase applications are not considered by the
baselines, each baseline method outputs a single
best paraphrase for each test sentence. The gener-
ation results show that 93% and 97.8% of the test
sentences can be paraphrased by Baseline-1 and
Baseline-2. The average number of unit replace-
ments per sentence is 4.23 and 5.95, respectively.
This result suggests that Baseline-1 is less capa-
ble than Baseline-2, which is mainly because its
paraphrase resource is limited.
The generated paraphrases are also labeled by
our two raters and the labeling results can be found
in the lower part of Table 1. As can be seen,
Baseline-1 performs poorly compared with our
method and Baseline-2, as the percentage of la-
bel “1” is the highest for both adequacy and flu-
ency. This result demonstrates that it is necessary
to combine multiple paraphrase resources to im-
prove the paraphrase generation performance.
Table 1 also shows that Baseline-2 performs
comparably with our method except that it does
not consider paraphrase applications. However,
we are interested how many paraphrases gener-
ated by Baseline-2 can achieve the given applica-
tions by chance. After analyzing the results, we
find that 24.95%, 8.79%, and 7.16% of the para-
phrases achieve sentence compression, simplifi-
cation, and similarity computation, respectively,
which are much lower than our method.
</bodyText>
<subsectionHeader confidence="0.669015">
5.3 Informal Comparison with Application
Specific Methods
</subsectionHeader>
<bodyText confidence="0.998816666666667">
Previous research regarded sentence compression,
simplification, and similarity computation as to-
tally different problems and proposed distinct
method for each one. Therefore, it is interesting
to compare our method to the application-specific
methods. However, it is really difficult for us to
</bodyText>
<page confidence="0.992442">
840
</page>
<table confidence="0.9991121">
Source Liu Lefei says that in the long term, in terms of asset allocation, overseas investment should occupy a
sentence certain proportion of an insurance company’s overall allocation.
Sentence Liu Lefei says that in [the long run]ph,., [in area of [asset allocation][n,n, 1]]pat, overseas investment
compression should occupy [a [certain][JJ 1] part of [an insurance company’s overall allocation][n,n, 1]]pat.
Sentence Liu Lefei says that in [the long run]ph,., in terms of [wealth]ph,. [distribution]ph,., overseas investment
simplification should occupy [a [certain][JJ 1] part of [an insurance company’s overall allocation][n,n, 1]]pat.
Sentence Liu Lefei says that in [the long run]ph,., in terms [of capital]ph,. allocation, overseas investment should
similarity occupy [the [certain][JJ 1] ratio of [an insurance company’s overall allocation][n,n, 1]]pat.
(reference sentence: Liu Lefei said that in terms of capital allocation, outbound investment should make
up a certain ratio of overall allocations for insurance companies in the long run .)
</table>
<tableCaption confidence="0.750899666666667">
Table 2: The generated paraphrases of a source sentence for different applications. The target units after
replacement are shown in blue and the pattern slot fillers are in cyan. Hphr denotes that the unit is a
phrase, while I·]pat denotes that the unit is a pattern. There is no collocation replacement in this example.
</tableCaption>
<bodyText confidence="0.990822613636364">
reimplement the methods purposely designed for
these applications. Thus here we just conduct an
informal comparison with these methods.
Sentence compression: Sentence compression
is widely studied, which is mostly reviewed as a
word deletion task. Different from prior research,
Cohn and Lapata (2008) achieved sentence com-
pression using a combination of several opera-
tions including word deletion, substitution, inser-
tion, and reordering based on a statistical model,
which is similar to our paraphrase generation pro-
cess. Besides, they also used paraphrase patterns
extracted from bilingual parallel corpora (like our
PT-4) as a kind of rewriting resource. However,
as most other sentence compression methods, their
method allows information loss after compression,
which means that the generated sentences are not
necessarily paraphrases of the source sentences.
Sentence Simplification: Carroll et al. (1999)
has proposed an automatic text simplification
method for language-impaired readers. Their
method contains two main parts, namely the lex-
ical simplifier and syntactic simplifier. The for-
mer one focuses on replacing words with simpler
synonyms, while the latter is designed to transfer
complex syntactic structures into easy ones (e.g.,
replacing passive sentences with active forms).
Our method is, to some extent, simpler than Car-
roll et al.’s, since our method does not contain syn-
tactic simplification strategies. We will try to ad-
dress sentence restructuring in our future work.
Sentence Similarity computation: Kauchak
and Barzilay (2006) have tried paraphrasing-based
sentence similarity computation. They paraphrase
a sentence s by replacing its words with Word-
Net synonyms, so that s can be more similar in
wording to another sentence s&apos;. A similar method
has also been proposed in (Zhou et al., 2006),
which uses paraphrase phrases like our PT-1 in-
stead of WordNet synonyms. These methods can
be roughly viewed as special cases of ours, which
only focus on the sentence similarity computation
application and only use one kind of paraphrase
resource.
</bodyText>
<sectionHeader confidence="0.998493" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999989714285714">
This paper proposes a method for statistical para-
phrase generation. The contributions are as fol-
lows. (1) It is the first statistical model spe-
cially designed for paraphrase generation, which
is based on the analysis of the differences between
paraphrase generation and other researches, espe-
cially machine translation. (2) It generates para-
phrases for different applications with a uniform
model, rather than presenting distinct methods for
each application. (3) It uses multiple resources,
including paraphrase phrases, patterns, and collo-
cations, to relieve data shortage and generate more
varied and interesting paraphrases.
Our future work will be carried out along two
directions. First, we will improve the components
of the method, especially the paraphrase planning
algorithm. The algorithm currently used is sim-
ple but greedy, which may miss some useful para-
phrase units. Second, we will extend the method to
other applications, We hope it can serve as a uni-
versal framework for most if not all applications.
</bodyText>
<sectionHeader confidence="0.99652" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9777996">
The research was supported by NSFC (60803093,
60675034) and 863 Program (2008AA01Z144).
Special thanks to Wanxiang Che, Ruifang He,
Yanyan Zhao, Yuhang Guo and the anonymous re-
viewers for insightful comments and suggestions.
</bodyText>
<page confidence="0.996723">
841
</page>
<sectionHeader confidence="0.99035" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999927676190476">
Regina Barzilay and Lillian Lee. 2003. Learning
to Paraphrase: An Unsupervised Approach Using
Multiple-Sequence Alignment. In Proceedings of
HLT-NAACL, pages 16-23.
Igor A. Bolshakov and Alexander Gelbukh. 2004.
Synonymous Paraphrasing Using WordNet and In-
ternet. In Proceedings of NLDB, pages 312-323.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-) Evaluation of Machine Translation. In Pro-
ceedings of ACL Workshop on Statistical Machine
Translation, pages 136-158.
Jean Carletta. 1996. Assessing Agreement on Clas-
sification Tasks: The Kappa Statistic. In Computa-
tional Linguistics, 22(2): 249-254.
John Carroll, Guido Minnen, Darren Pearce, Yvonne
Canning, Siobhan Devlin, John Tait. 1999. Simpli-
fying Text for Language-Impaired Readers. In Pro-
ceedings of EACL, pages 269-270.
Trevor Cohn and Mirella Lapata. 2008. Sentence
Compression Beyond Word Deletion In Proceed-
ings of COLING, pages 137-144.
Pablo Ariel Duboue and Jennifer Chu-Carroll. 2006.
Answering the Question You Wish They Had Asked:
The impact of paraphrasing for Question Answer-
ing. In Proceedings of HLT-NAACL, pages 33-36.
Jesus Gimenez and Lluis Marquez. 2004. SVMTool:
A general POS tagger generator based on Support
Vector Machines. In Proceedings of LREC, pages
43-46.
Hieu Hoang and Philipp Koehn. 2008. Design of the
Moses Decoder for Statistical Machine Translation.
In Proceedings of ACL Workshop on Software en-
gineering, testing, and quality assurance for NLP,
pages 58-65.
Lidija Iordanskaja, Richard Kittredge, and Alain
Polgu`ere. 1991. Lexical Selection and Paraphrase
in a Meaning-Text Generation Model. In C´ecile L.
Paris, William R. Swartout, and William C. Mann
(Eds.): Natural Language Generation in Artificial
Intelligence and Computational Linguistics, pages
293-312.
David Kauchak and Regina Barzilay. 2006. Paraphras-
ing for Automatic Evaluation. In Proceedings of
HLT-NAACL, pages 455-462.
Philipp Koehn, Franz Josef Och, Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proceed-
ings of HLT-NAACL, pages 127-133.
Raymond Kozlowski, Kathleen F. McCoy, and K.
Vijay-Shanker. 2003. Generation of single-sentence
paraphrases from predicate/argument structure us-
ing lexico-grammatical resources. In Proceedings
of IWP, pages 1-8.
J. R. Landis and G. G. Koch. 1977. The Measure-
ment of Observer Agreement for Categorical Data.
In Biometrics 33(1): 159-174.
De-Kang Lin and Patrick Pantel. 2001. Discovery of
Inference Rules for Question Answering. In Natural
Language Engineering 7(4): 343-360.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual Dependency Parsing with a
Two-Stage Discriminative Parser. In Proceedings of
CoNLL.
Kathleen R. McKeown. 1979. Paraphrasing Using
Given and New Information in a Question-Answer
System. In Proceedings of ACL, pages 67-72.
Masaki Murata and Hitoshi Isahara. 2001. Univer-
sal Model for Paraphrasing - Using Transformation
Based on a Defined Criteria. In Proceedings of NL-
PRS, pages 47-54.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
ofACL, pages 160-167.
Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing
Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of
ACL, pages 311-318.
Richard Power and Donia Scott. 2005. Automatic gen-
eration of large-scale paraphrases. In Proceedings of
IWP, pages 73-79.
Chris Quirk, Chris Brockett, and William Dolan. 2004.
Monolingual Machine Translation for Paraphrase
Generation. In Proceedings of EMNLP, pages 142-
149.
Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, At-
sushi Fujita, Kentaro Inui. 2001. KURA: A
Transfer-based Lexico-structural Paraphrasing En-
gine. In Proceedings of NLPRS, pages 37-46.
Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and
Sheng Li. 2008a. Combining Multiple Resources
to Improve SMT-based Paraphrasing Model. In Pro-
ceedings ofACL-08:HLT, pages 1021-1029.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008b. Pivot Approach for Extracting Paraphrase
Patterns from Bilingual Corpora. In Proceedings of
ACL-08:HLT, pages 780-788.
Liang Zhou, Chin-Yew Lin, Dragos Stefan Munteanu,
and Eduard Hovy. 2006. ParaEval: Using Para-
phrases to Evaluate Summaries Automatically. In
Proceedings of HLT-NAACL, pages 447-454.
Chengqing Zong, Yujie Zhang, Kazuhide Yamamoto,
Masashi Sakamoto, Satoshi Shirai. 2001. Approach
to Spoken Chinese Paraphrasing Based on Feature
Extraction. In Proceedings of NLPRS, pages 551-
556.
</reference>
<page confidence="0.998012">
842
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.847425">
<title confidence="0.999828">Application-driven Statistical Paraphrase Generation</title>
<author confidence="0.999223">Shiqi Zhao</author>
<author confidence="0.999223">Xiang Lan</author>
<author confidence="0.999223">Ting Liu</author>
<author confidence="0.999223">Sheng Li</author>
<affiliation confidence="0.999594">Information Retrieval Lab, Harbin Institute of Technology</affiliation>
<address confidence="0.927773">6F Aoxiao Building, No.27 Jiaohua Street, Nangang District Harbin, 150001, China</address>
<abstract confidence="0.999414875">Paraphrase generation (PG) is important in plenty of NLP applications. However, the research of PG is far from enough. In this paper, we propose a novel method for statistical paraphrase generation (SPG), which can (1) achieve various applications based on a uniform statistical model, and (2) naturally combine multiple resources to enhance the PG performance. In our experiments, we use the proposed method to generate paraphrases for three different applications. The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="3144" citStr="Barzilay and Lee, 2003" startWordPosition="445" endWordPosition="448">ons. In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment. In Proceedings of HLT-NAACL, pages 16-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Bolshakov</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Synonymous Paraphrasing Using WordNet and Internet.</title>
<date>2004</date>
<booktitle>In Proceedings of NLDB,</booktitle>
<pages>312--323</pages>
<contexts>
<context position="3576" citStr="Bolshakov and Gelbukh, 2004" startWordPosition="514" endWordPosition="517">lly written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006). This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation. In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted. In the second phase, it selects an optimal substitute for each given word from the synonyms according to the context in s. This kind of method is simple, since the thesaurus synonyms are easy to</context>
<context position="5758" citStr="Bolshakov and Gelbukh, 2004" startWordPosition="872" endWordPosition="875">sting SMT models for PG (Quirk et al., 2004). Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG. However, such data are difficult to acquire compared with the SMT data. Therefore, data shortage becomes the major limitation of the method. To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a). There have been researchers trying to propose uniform PG methods for multiple applications. But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have some limitations as stated above. Furthermore, few of them conducted formal experiments to evaluate the proposed methods. 3 Statistical Paraphrase Generation 3.1 Differences between SPG and SMT Despite the similarity between PG and MT, the statistical model used in SMT cannot be directly applied in SPG, since there are some clear differences between them: 1. SMT has a unique purpose, i.e., producing high-quality translations for the inputs. On the contrary, SPG has distinct purposes in different applications, such as sentence compression, sentence simplification, etc. The usab</context>
</contexts>
<marker>Bolshakov, Gelbukh, 2004</marker>
<rawString>Igor A. Bolshakov and Alexander Gelbukh. 2004. Synonymous Paraphrasing Using WordNet and Internet. In Proceedings of NLDB, pages 312-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>(Meta-) Evaluation of Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL Workshop on Statistical Machine Translation,</booktitle>
<pages>136--158</pages>
<contexts>
<context position="20792" citStr="Callison-Burch et al., 2007" startWordPosition="3338" endWordPosition="3341">uman references of the MT evaluation, which provide several human translations for each foreign sentence. In detail, we use the first translation of a foreign sentence as the source s and the second translation as the reference s&apos; for similarity computation. In our experiments, the development set contains 200 sentences and the test set contains 500 sentences, both of which are randomly selected from the human translations of 2008 NIST Open Machine Translation Evaluation: Chinese to English Task. 4.2 Evaluation Metrics The evaluation metrics for SPG are similar to the human evaluation for MT (Callison-Burch et al., 2007). The generated paraphrases are manually evaluated based on three criteria, i.e., adequacy, fluency, and usability, each of which has three scales from 1 to 3. Here is a brief description of the different scales for the criteria: Adequacy 1: The meaning is evidently changed. 2: The meaning is generally preserved. 3: The meaning is completely preserved. Fluency 1: The paraphrase t is incomprehensible. 2: t is comprehensible. 3: t is a flawless sentence. Usability 1: t is opposite to the application purpose. 2: t does not achieve the application. 3: t achieves the application. 5 Results and Anal</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2007</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) Evaluation of Machine Translation. In Proceedings of ACL Workshop on Statistical Machine Translation, pages 136-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing Agreement on Classification Tasks: The Kappa Statistic.</title>
<date>1996</date>
<journal>In Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>249--254</pages>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing Agreement on Classification Tasks: The Kappa Statistic. In Computational Linguistics, 22(2): 249-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Darren Pearce</author>
<author>Yvonne Canning</author>
<author>Siobhan Devlin</author>
<author>John Tait</author>
</authors>
<title>Simplifying Text for Language-Impaired Readers.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>269--270</pages>
<contexts>
<context position="1465" citStr="Carroll et al., 1999" startWordPosition="205" endWordPosition="208">d generate valuable and interesting paraphrases. 1 Introduction Paraphrases are alternative ways that convey the same meaning. There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG). Paraphrase generation aims to generate a paraphrase for a source sentence in a certain application. PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboue and Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al., 1991), text simplification in computer-aided reading (Carroll et al., 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al., 2006). This paper presents a method for statistical paraphrase generation (SPG). As far as we know, this is the first statistical model specially designed for paraphrase generation. It’s distinguishing feature is that it achieves various applications with a uniform model. In addition, it exploits multiple resources, including paraphrase phrases, patterns, and collocations, to resolve the data shortage problem and generate more varied paraphr</context>
<context position="30378" citStr="Carroll et al. (1999)" startWordPosition="4860" endWordPosition="4863">ata (2008) achieved sentence compression using a combination of several operations including word deletion, substitution, insertion, and reordering based on a statistical model, which is similar to our paraphrase generation process. Besides, they also used paraphrase patterns extracted from bilingual parallel corpora (like our PT-4) as a kind of rewriting resource. However, as most other sentence compression methods, their method allows information loss after compression, which means that the generated sentences are not necessarily paraphrases of the source sentences. Sentence Simplification: Carroll et al. (1999) has proposed an automatic text simplification method for language-impaired readers. Their method contains two main parts, namely the lexical simplifier and syntactic simplifier. The former one focuses on replacing words with simpler synonyms, while the latter is designed to transfer complex syntactic structures into easy ones (e.g., replacing passive sentences with active forms). Our method is, to some extent, simpler than Carroll et al.’s, since our method does not contain syntactic simplification strategies. We will try to address sentence restructuring in our future work. Sentence Similari</context>
</contexts>
<marker>Carroll, Minnen, Pearce, Canning, Devlin, Tait, 1999</marker>
<rawString>John Carroll, Guido Minnen, Darren Pearce, Yvonne Canning, Siobhan Devlin, John Tait. 1999. Simplifying Text for Language-Impaired Readers. In Proceedings of EACL, pages 269-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence Compression Beyond Word Deletion In</title>
<date>2008</date>
<booktitle>Proceedings of COLING,</booktitle>
<pages>137--144</pages>
<contexts>
<context position="29767" citStr="Cohn and Lapata (2008)" startWordPosition="4773" endWordPosition="4776">Table 2: The generated paraphrases of a source sentence for different applications. The target units after replacement are shown in blue and the pattern slot fillers are in cyan. Hphr denotes that the unit is a phrase, while I·]pat denotes that the unit is a pattern. There is no collocation replacement in this example. reimplement the methods purposely designed for these applications. Thus here we just conduct an informal comparison with these methods. Sentence compression: Sentence compression is widely studied, which is mostly reviewed as a word deletion task. Different from prior research, Cohn and Lapata (2008) achieved sentence compression using a combination of several operations including word deletion, substitution, insertion, and reordering based on a statistical model, which is similar to our paraphrase generation process. Besides, they also used paraphrase patterns extracted from bilingual parallel corpora (like our PT-4) as a kind of rewriting resource. However, as most other sentence compression methods, their method allows information loss after compression, which means that the generated sentences are not necessarily paraphrases of the source sentences. Sentence Simplification: Carroll et</context>
</contexts>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2008. Sentence Compression Beyond Word Deletion In Proceedings of COLING, pages 137-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Ariel Duboue</author>
<author>Jennifer Chu-Carroll</author>
</authors>
<title>Answering the Question You Wish They Had Asked: The impact of paraphrasing for Question Answering.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>33--36</pages>
<contexts>
<context position="1315" citStr="Duboue and Chu-Carroll, 2006" startWordPosition="183" endWordPosition="186">method to generate paraphrases for three different applications. The results show that the method can be easily transformed from one application to another and generate valuable and interesting paraphrases. 1 Introduction Paraphrases are alternative ways that convey the same meaning. There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG). Paraphrase generation aims to generate a paraphrase for a source sentence in a certain application. PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboue and Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al., 1991), text simplification in computer-aided reading (Carroll et al., 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al., 2006). This paper presents a method for statistical paraphrase generation (SPG). As far as we know, this is the first statistical model specially designed for paraphrase generation. It’s distinguishing feature is that it achieves various applications with a uniform model. In addition, it exploi</context>
</contexts>
<marker>Duboue, Chu-Carroll, 2006</marker>
<rawString>Pablo Ariel Duboue and Jennifer Chu-Carroll. 2006. Answering the Question You Wish They Had Asked: The impact of paraphrasing for Question Answering. In Proceedings of HLT-NAACL, pages 33-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesus Gimenez</author>
<author>Lluis Marquez</author>
</authors>
<title>SVMTool: A general POS tagger generator based on Support Vector Machines.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>43--46</pages>
<contexts>
<context position="19577" citStr="Gimenez and Marquez, 2004" startWordPosition="3142" endWordPosition="3145"> parameters for each paraphrase application separately. For each application, we first ask two raters to manually label all possible unit replacements on the development set as correct or incorrect, so that rp, rr, and rf can be automatically computed under each set of parameters. The parameters that result in the highest rf on the development set are finally selected. 4 Experimental Setup Our SPG decoder is developed by remodeling Moses that is widely used in SMT (Hoang and Koehn, 2008). The POS tagger and dependency parser for sentence preprocessing are SVMp(L|s) = K 1: k=1 (λk ki 838 Tool (Gimenez and Marquez, 2004) and MSTParser (McDonald et al., 2006). The language model is trained using a 9 GB English corpus. 4.1 Experimental Data Our method is not restricted in domain or sentence style. Thus any sentence can be used in development and test. However, for the sentence similarity computation purpose in our experiments, we want to evaluate if the method can enhance the stringlevel similarity between two paraphrase sentences. Therefore, for each input sentence s, we need a reference sentence s&apos; for similarity computation. Based on the above consideration, we acquire experiment data from the human referenc</context>
</contexts>
<marker>Gimenez, Marquez, 2004</marker>
<rawString>Jesus Gimenez and Lluis Marquez. 2004. SVMTool: A general POS tagger generator based on Support Vector Machines. In Proceedings of LREC, pages 43-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu Hoang</author>
<author>Philipp Koehn</author>
</authors>
<title>Design of the Moses Decoder for Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL Workshop on Software engineering, testing, and quality assurance for NLP,</booktitle>
<pages>58--65</pages>
<contexts>
<context position="19443" citStr="Hoang and Koehn, 2008" startWordPosition="3117" endWordPosition="3120">unction in MERT, which is similar to the conventional f-measure and leverages rp and rr: rf = (2 x rp x rr)/(rp + rr). We estimate parameters for each paraphrase application separately. For each application, we first ask two raters to manually label all possible unit replacements on the development set as correct or incorrect, so that rp, rr, and rf can be automatically computed under each set of parameters. The parameters that result in the highest rf on the development set are finally selected. 4 Experimental Setup Our SPG decoder is developed by remodeling Moses that is widely used in SMT (Hoang and Koehn, 2008). The POS tagger and dependency parser for sentence preprocessing are SVMp(L|s) = K 1: k=1 (λk ki 838 Tool (Gimenez and Marquez, 2004) and MSTParser (McDonald et al., 2006). The language model is trained using a 9 GB English corpus. 4.1 Experimental Data Our method is not restricted in domain or sentence style. Thus any sentence can be used in development and test. However, for the sentence similarity computation purpose in our experiments, we want to evaluate if the method can enhance the stringlevel similarity between two paraphrase sentences. Therefore, for each input sentence s, we need a </context>
</contexts>
<marker>Hoang, Koehn, 2008</marker>
<rawString>Hieu Hoang and Philipp Koehn. 2008. Design of the Moses Decoder for Statistical Machine Translation. In Proceedings of ACL Workshop on Software engineering, testing, and quality assurance for NLP, pages 58-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
<author>Richard Kittredge</author>
<author>Alain Polgu`ere</author>
</authors>
<title>Lexical Selection and Paraphrase in a Meaning-Text Generation Model. In C´ecile</title>
<date>1991</date>
<booktitle>Mann (Eds.): Natural Language Generation in Artificial Intelligence and Computational Linguistics,</booktitle>
<pages>293--312</pages>
<marker>Iordanskaja, Kittredge, Polgu`ere, 1991</marker>
<rawString>Lidija Iordanskaja, Richard Kittredge, and Alain Polgu`ere. 1991. Lexical Selection and Paraphrase in a Meaning-Text Generation Model. In C´ecile L. Paris, William R. Swartout, and William C. Mann (Eds.): Natural Language Generation in Artificial Intelligence and Computational Linguistics, pages 293-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
<author>Regina Barzilay</author>
</authors>
<title>Paraphrasing for Automatic Evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>455--462</pages>
<contexts>
<context position="1587" citStr="Kauchak and Barzilay, 2006" startWordPosition="222" endWordPosition="225">e meaning. There are two main threads in the research of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG). Paraphrase generation aims to generate a paraphrase for a source sentence in a certain application. PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboue and Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al., 1991), text simplification in computer-aided reading (Carroll et al., 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al., 2006). This paper presents a method for statistical paraphrase generation (SPG). As far as we know, this is the first statistical model specially designed for paraphrase generation. It’s distinguishing feature is that it achieves various applications with a uniform model. In addition, it exploits multiple resources, including paraphrase phrases, patterns, and collocations, to resolve the data shortage problem and generate more varied paraphrases. We consider three paraphrase applications in our experiments, including sentence compression, sentence simplificatio</context>
<context position="3764" citStr="Kauchak and Barzilay, 2006" startWordPosition="546" endWordPosition="549">e, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006). This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation. In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted. In the second phase, it selects an optimal substitute for each given word from the synonyms according to the context in s. This kind of method is simple, since the thesaurus synonyms are easy to access. However, it cannot generate other types of paraphrases but only synonym substitution. NLG-based methods: NLG-based methods (Kozlowski et al., 2003; Power and Scott, 2005) generall</context>
<context position="15066" citStr="Kauchak and Barzilay, 2006" startWordPosition="2398" endWordPosition="2401">auge model assigns a score scorelm(·) for each unit and the unit with larger score is viewed as more frequent. We define µ(¯si, ¯ti) = 1 iff scorelm(¯ti) &gt; scorelm(¯si). • Sentence similarity computation: Given a reference sentence s&apos;, this application aims to paraphrase s into t, so that t is more similar (closer in wording) with s&apos; than s. This application is important for the automatic evaluation of machine translation and summarization, since we can paraphrase the human translations/summaries to make them more similar to the system outputs, which can refine the accuracy of the evaluation (Kauchak and Barzilay, 2006). For this application, 2This work defines compression as the shortening of sentence length in bytes rather than in words. 3To compute the language model based score, the matched patterns are instantiated and the matched collocations are connected with words between them. 837 only the target units that can enhance the similarity to the reference sentence are kept in planning. We define µ(si, ti) = sim(�ti, s&apos;)− sim(si, s&apos;), where sim(·, ·) is simply computed as the count of overlapping words. We combine the three sub-models based on a log-linear framework and get the SPG model: log φk(Ski, �tk</context>
<context position="31021" citStr="Kauchak and Barzilay (2006)" startWordPosition="4956" endWordPosition="4959"> automatic text simplification method for language-impaired readers. Their method contains two main parts, namely the lexical simplifier and syntactic simplifier. The former one focuses on replacing words with simpler synonyms, while the latter is designed to transfer complex syntactic structures into easy ones (e.g., replacing passive sentences with active forms). Our method is, to some extent, simpler than Carroll et al.’s, since our method does not contain syntactic simplification strategies. We will try to address sentence restructuring in our future work. Sentence Similarity computation: Kauchak and Barzilay (2006) have tried paraphrasing-based sentence similarity computation. They paraphrase a sentence s by replacing its words with WordNet synonyms, so that s can be more similar in wording to another sentence s&apos;. A similar method has also been proposed in (Zhou et al., 2006), which uses paraphrase phrases like our PT-1 instead of WordNet synonyms. These methods can be roughly viewed as special cases of ours, which only focus on the sentence similarity computation application and only use one kind of paraphrase resource. 6 Conclusions and Future Work This paper proposes a method for statistical paraphra</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>David Kauchak and Regina Barzilay. 2006. Paraphrasing for Automatic Evaluation. In Proceedings of HLT-NAACL, pages 455-462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="11137" citStr="Koehn et al., 2003" startWordPosition="1747" endWordPosition="1750">, and usability of the paraphrases, respectively1. Paraphrase Model: Paraphrase generation is a decoding process. The input sentence s is first segmented into a sequence of I units sI1, which are then paraphrased to a sequence of units �tI1. Let (si, ti) be a pair of paraphrase units, their paraphrase likelihood is computed using a score function Opm(�si, ti). Thus the paraphrase score ppm(9I1, �tI1) between s and t is decomposed into: I ppm(�sI1, �tI1) _ Opm(si, �ti)λp- (1) i=1 where Apm is the weight of the paraphrase model. Actually, it is defined similarly to the translation model in SMT (Koehn et al., 2003). In practice, the units of a sentence may be paraphrased using different PTs. Suppose we have K PTs, (ski, tki) is a pair of paraphrase units from the k-th PT with the score function Ok(ski, �tki), then Equation (1) can be rewritten as: Ok(Ski, �tki)λk) (2) where Ak is the weight for Ok(Ski, tki). Equation (2) assumes that a pair of paraphrase units is from only one paraphrase table. However, 1The SPG model applies monotone decoding, which does not contain a reordering sub-model that is often used in SMT. Instead, we use the paraphrase patterns to achieve word reordering in paraphrase generat</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of HLT-NAACL, pages 127-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond Kozlowski</author>
<author>Kathleen F McCoy</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Generation of single-sentence paraphrases from predicate/argument structure using lexico-grammatical resources.</title>
<date>2003</date>
<booktitle>In Proceedings of IWP,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="4331" citStr="Kozlowski et al., 2003" startWordPosition="638" endWordPosition="642"> 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006). This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation. In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted. In the second phase, it selects an optimal substitute for each given word from the synonyms according to the context in s. This kind of method is simple, since the thesaurus synonyms are easy to access. However, it cannot generate other types of paraphrases but only synonym substitution. NLG-based methods: NLG-based methods (Kozlowski et al., 2003; Power and Scott, 2005) generally involve two stages. In the first one, the source sentence s is transformed into its semantic representation r by undertaking a series of NLP processing, including morphology analyzing, syntactic parsing, semantic role labeling, etc. In the second stage, a NLG system is employed to generate a sentence t from r. s and t are paraphrases as they are both derived from r. The NLG-based methods simulate human paraphrasing behavior, i.e., understanding a sentence and presenting the meaning in another way. However, deep analysis of sentences is a big challenge. Moreov</context>
</contexts>
<marker>Kozlowski, McCoy, Vijay-Shanker, 2003</marker>
<rawString>Raymond Kozlowski, Kathleen F. McCoy, and K. Vijay-Shanker. 2003. Generation of single-sentence paraphrases from predicate/argument structure using lexico-grammatical resources. In Proceedings of IWP, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Landis</author>
<author>G G Koch</author>
</authors>
<title>The Measurement of Observer Agreement for Categorical Data.</title>
<date>1977</date>
<journal>In Biometrics</journal>
<volume>33</volume>
<issue>1</issue>
<pages>159--174</pages>
<contexts>
<context position="24125" citStr="Landis and Koch, 1977" startWordPosition="3880" endWordPosition="3883">t it is because the raters are not sensitive to the slight change of the simplification degree. Thus they labeled “2” in most cases. We compute the kappa statistic between the raters. Kappa is defined as K = P(A)−P(E) (Car1−P(E)letta, 1996), where P(A) is the proportion of times that the labels agree, and P(E) is the proportion of times that they may agree by chance. We define P(E) = 13 , as the labeling is based on three point scales. The results show that the kappa statistics for adequacy and fluency are 0.6560 and 0.6500, which indicates a substantial agreement (K: 0.61- 0.8) according to (Landis and Koch, 1977). The 839 Adequacy (%) Fluency (%) Usability (%) 1 2 3 1 2 3 1 2 3 Sentence rater1 32.92 44.44 22.63 21.60 47.53 30.86 0 0 100 compression rater2 40.54 34.98 24.49 25.51 43.83 30.66 0 0 100 Sentence rater1 29.77 44.03 26.21 22.01 42.77 35.22 25.37 61.84 12.79 simplification rater2 33.33 35.43 31.24 24.32 39.83 35.85 30.19 51.99 17.82 Sentence rater1 7.75 24.30 67.96 7.75 22.54 69.72 0 0 100 similarity rater2 7.75 19.01 73.24 6.69 21.48 71.83 0 0 100 Baseline-1 rater1 47.31 30.75 21.94 43.01 33.12 23.87 - - - rater2 47.10 30.11 22.80 34.41 41.51 24.09 - - - Baseline-2 rater1 29.45 52.76 17.79 2</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>J. R. Landis and G. G. Koch. 1977. The Measurement of Observer Agreement for Categorical Data. In Biometrics 33(1): 159-174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>De-Kang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2001</date>
<journal>In Natural Language Engineering</journal>
<volume>7</volume>
<issue>4</issue>
<pages>343--360</pages>
<contexts>
<context position="3120" citStr="Lin and Pantel, 2001" startWordPosition="441" endWordPosition="444">or the given applications. In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�20</context>
<context position="7300" citStr="Lin and Pantel (2001)" startWordPosition="1131" endWordPosition="1134">al parallel data for SMT are easy to collect. In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004). Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a). 4. Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002)). The basic idea is that a translation should be scored based on their similarity to the human references. However, they cannot be adopted in SPG. The main reason is that it is more difficult to provide human references in SPG. Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is very small. Thus the human references cannot properly assess the quality of the generated paraphrases. 3.2 Method Overview The SPG method proposed in this work contains three components, i.e., sentence preprocessing, paraphrase planning, and paraphrase generation (Figure 1). Sentence preprocessing mainly includes POS tagging and dependency parsing for the input sentences, as POS tags and dependency information are necessary for matching the paraphrase pattern and collocation resources</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>De-Kang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for Question Answering. In Natural Language Engineering 7(4): 343-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual Dependency Parsing with a Two-Stage Discriminative Parser.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="19615" citStr="McDonald et al., 2006" startWordPosition="3149" endWordPosition="3152">n separately. For each application, we first ask two raters to manually label all possible unit replacements on the development set as correct or incorrect, so that rp, rr, and rf can be automatically computed under each set of parameters. The parameters that result in the highest rf on the development set are finally selected. 4 Experimental Setup Our SPG decoder is developed by remodeling Moses that is widely used in SMT (Hoang and Koehn, 2008). The POS tagger and dependency parser for sentence preprocessing are SVMp(L|s) = K 1: k=1 (λk ki 838 Tool (Gimenez and Marquez, 2004) and MSTParser (McDonald et al., 2006). The language model is trained using a 9 GB English corpus. 4.1 Experimental Data Our method is not restricted in domain or sentence style. Thus any sentence can be used in development and test. However, for the sentence similarity computation purpose in our experiments, we want to evaluate if the method can enhance the stringlevel similarity between two paraphrase sentences. Therefore, for each input sentence s, we need a reference sentence s&apos; for similarity computation. Based on the above consideration, we acquire experiment data from the human references of the MT evaluation, which provide</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual Dependency Parsing with a Two-Stage Discriminative Parser. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Paraphrasing Using Given and New Information in a Question-Answer System. In</title>
<date>1979</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>67--72</pages>
<contexts>
<context position="2975" citStr="McKeown, 1979" startWordPosition="421" endWordPosition="422">ed based on adequacy, fluency, and usability. The results show that the proposed method is promising, which generates useful paraphrases for the given applications. In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 200</context>
</contexts>
<marker>McKeown, 1979</marker>
<rawString>Kathleen R. McKeown. 1979. Paraphrasing Using Given and New Information in a Question-Answer System. In Proceedings of ACL, pages 67-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Universal Model for Paraphrasing - Using Transformation Based on a Defined Criteria.</title>
<date>2001</date>
<booktitle>In Proceedings of NLPRS,</booktitle>
<pages>47--54</pages>
<contexts>
<context position="5685" citStr="Murata and Isahara, 2001" startWordPosition="860" endWordPosition="864">ng s into t that are in the same language. Researchers employ the existing SMT models for PG (Quirk et al., 2004). Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG. However, such data are difficult to acquire compared with the SMT data. Therefore, data shortage becomes the major limitation of the method. To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a). There have been researchers trying to propose uniform PG methods for multiple applications. But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have some limitations as stated above. Furthermore, few of them conducted formal experiments to evaluate the proposed methods. 3 Statistical Paraphrase Generation 3.1 Differences between SPG and SMT Despite the similarity between PG and MT, the statistical model used in SMT cannot be directly applied in SPG, since there are some clear differences between them: 1. SMT has a unique purpose, i.e., producing high-quality translations for the inputs. On the contrary, SPG has distinct purposes in different applicati</context>
</contexts>
<marker>Murata, Isahara, 2001</marker>
<rawString>Masaki Murata and Hitoshi Isahara. 2001. Universal Model for Paraphrasing - Using Transformation Based on a Defined Criteria. In Proceedings of NLPRS, pages 47-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="17725" citStr="Och, 2003" startWordPosition="2832" endWordPosition="2833">ation is a lexically restricted word pair with a certain syntactic relation. This work only considers verbobject collocations, e.g., &lt;promote, OBJ, trades&gt;. corpus and use a binary classifier to recognize if any two collocations are paraphrases. Due to the space limit, we cannot introduce the detail of the approach. We assign the score “1” for any pair of paraphrase collocations. PT-5 contains 238,882 pairs of paraphrase collocations. 3.6 Parameter Estimation To estimate parameters λk(1 &lt; k &lt; K), λlm, and λum, we adopt the approach of minimum error rate training (MERT) that is popular in SMT (Och, 2003). In SMT, however, the optimization objective function in MERT is the MT evaluation criteria, such as BLEU. As we analyzed above, the BLEU-style criteria cannot be adapted in SPG. We therefore introduce a new optimization objective function in this paper. The basic assumption is that a paraphrase should contain as many correct unit replacements as possible. Accordingly, we design the following criteria: Replacement precision (rp): rp assesses the precision of the unit replacements, which is defined as rp = cdev(+r)/cdev(r), where cdev(r) is the total number of unit replacements in the generate</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings ofACL, pages 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="7050" citStr="Papineni et al., 2002" startWordPosition="1087" endWordPosition="1090">n SMT, words of an input sentence should be totally translated, whereas in SPG, not all words of an input sentence need to be paraphrased. Therefore, a SPG model should be able to decide which part of a sentence needs to be paraphrased. 3. The bilingual parallel data for SMT are easy to collect. In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004). Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a). 4. Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002)). The basic idea is that a translation should be scored based on their similarity to the human references. However, they cannot be adopted in SPG. The main reason is that it is more difficult to provide human references in SPG. Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is very small. Thus the human references cannot properly assess the quality of the generated paraphrases. 3.2 Method Overview The SPG method proposed in this work contains three components, i.e., sentence preprocessing, paraphrase planning, a</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of ACL, pages 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Power</author>
<author>Donia Scott</author>
</authors>
<title>Automatic generation of large-scale paraphrases.</title>
<date>2005</date>
<booktitle>In Proceedings of IWP,</booktitle>
<pages>73--79</pages>
<contexts>
<context position="4355" citStr="Power and Scott, 2005" startWordPosition="643" endWordPosition="646">NLP Kauchak and Barzilay, 2006). This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation. In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted. In the second phase, it selects an optimal substitute for each given word from the synonyms according to the context in s. This kind of method is simple, since the thesaurus synonyms are easy to access. However, it cannot generate other types of paraphrases but only synonym substitution. NLG-based methods: NLG-based methods (Kozlowski et al., 2003; Power and Scott, 2005) generally involve two stages. In the first one, the source sentence s is transformed into its semantic representation r by undertaking a series of NLP processing, including morphology analyzing, syntactic parsing, semantic role labeling, etc. In the second stage, a NLG system is employed to generate a sentence t from r. s and t are paraphrases as they are both derived from r. The NLG-based methods simulate human paraphrasing behavior, i.e., understanding a sentence and presenting the meaning in another way. However, deep analysis of sentences is a big challenge. Moreover, developing a NLG sys</context>
</contexts>
<marker>Power, Scott, 2005</marker>
<rawString>Richard Power and Donia Scott. 2005. Automatic generation of large-scale paraphrases. In Proceedings of IWP, pages 73-79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
<author>William Dolan</author>
</authors>
<title>Monolingual Machine Translation for Paraphrase Generation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>142--149</pages>
<contexts>
<context position="3393" citStr="Quirk et al., 2004" startWordPosition="486" endWordPosition="489"> a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006). This kind of method usually involves two phases, i.e., candidate extraction and paraphrase validation. In the first phase, it extracts all synonyms from a thesaurus, such as WordNet, for the words to be substituted. In the seco</context>
<context position="5174" citStr="Quirk et al., 2004" startWordPosition="778" endWordPosition="781">actic parsing, semantic role labeling, etc. In the second stage, a NLG system is employed to generate a sentence t from r. s and t are paraphrases as they are both derived from r. The NLG-based methods simulate human paraphrasing behavior, i.e., understanding a sentence and presenting the meaning in another way. However, deep analysis of sentences is a big challenge. Moreover, developing a NLG system is also not trivial. SMT-based methods: SMT-based methods viewed PG as monolingual MT, i.e., translating s into t that are in the same language. Researchers employ the existing SMT models for PG (Quirk et al., 2004). Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG. However, such data are difficult to acquire compared with the SMT data. Therefore, data shortage becomes the major limitation of the method. To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a). There have been researchers trying to propose uniform PG methods for multiple applications. But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have</context>
<context position="6814" citStr="Quirk et al., 2004" startWordPosition="1048" endWordPosition="1051">slations for the inputs. On the contrary, SPG has distinct purposes in different applications, such as sentence compression, sentence simplification, etc. The usability of the paraphrases have to be assessed in each application. 2. In SMT, words of an input sentence should be totally translated, whereas in SPG, not all words of an input sentence need to be paraphrased. Therefore, a SPG model should be able to decide which part of a sentence needs to be paraphrased. 3. The bilingual parallel data for SMT are easy to collect. In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004). Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a). 4. Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002)). The basic idea is that a translation should be scored based on their similarity to the human references. However, they cannot be adopted in SPG. The main reason is that it is more difficult to provide human references in SPG. Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is ver</context>
<context position="25657" citStr="Quirk et al., 2004" startWordPosition="4148" endWordPosition="4151">aphrased in each application and we can see that: (1) for sentence compression, the paraphrase t is 8 bytes shorter than s; (2) for sentence simplification, the words wealth and part in t are easier than their sources asset and proportion, especially for the non-native speakers; (3) for sentence similarity computation, the reference sentence s&apos; is listed below t, in which the words appearing in t but not in s are highlighted in blue. 5.2 Comparison with Baseline Methods In our experiments, we implement two baseline methods for comparison: Baseline-1: Baseline-1 follows the method proposed in (Quirk et al., 2004), which generates paraphrases using typical SMT tools. Similar to Quirk et al.’s method, we extract a paraphrase table for the SMT model from a monolingual comparable corpus (PT-2 described above). The SMT decoder used in Baseline-1 is Moses. Baseline-2: Baseline-2 extends Baseline-1 by combining multiple resources. It exploits all PTs introduced above in the same way as our proposed method. The difference from our method is that Baseline-2 does not take different applications into consideration. Thus it contains no paraphrase planning stage or the usability sub-model. We tune the parameters f</context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>Chris Quirk, Chris Brockett, and William Dolan. 2004. Monolingual Machine Translation for Paraphrase Generation. In Proceedings of EMNLP, pages 142-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuro Takahashi</author>
</authors>
<title>Tomoyam Iwakura, Ryu Iida, Atsushi Fujita, Kentaro Inui.</title>
<date>2001</date>
<booktitle>In Proceedings of NLPRS,</booktitle>
<pages>37--46</pages>
<marker>Takahashi, 2001</marker>
<rawString>Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, Atsushi Fujita, Kentaro Inui. 2001. KURA: A Transfer-based Lexico-structural Paraphrasing Engine. In Proceedings of NLPRS, pages 37-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Cheng Niu</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Combining Multiple Resources to Improve SMT-based Paraphrasing Model.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08:HLT,</booktitle>
<pages>1021--1029</pages>
<contexts>
<context position="3163" citStr="Zhao et al., 2008" startWordPosition="449" endWordPosition="452">ison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006</context>
<context position="5533" citStr="Zhao et al., 2008" startWordPosition="838" endWordPosition="841">allenge. Moreover, developing a NLG system is also not trivial. SMT-based methods: SMT-based methods viewed PG as monolingual MT, i.e., translating s into t that are in the same language. Researchers employ the existing SMT models for PG (Quirk et al., 2004). Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG. However, such data are difficult to acquire compared with the SMT data. Therefore, data shortage becomes the major limitation of the method. To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a). There have been researchers trying to propose uniform PG methods for multiple applications. But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have some limitations as stated above. Furthermore, few of them conducted formal experiments to evaluate the proposed methods. 3 Statistical Paraphrase Generation 3.1 Differences between SPG and SMT Despite the similarity between PG and MT, the statistical model used in SMT cannot be directly applied in SPG, since there are some clear differences between them: </context>
<context position="6950" citStr="Zhao et al., 2008" startWordPosition="1071" endWordPosition="1074">lification, etc. The usability of the paraphrases have to be assessed in each application. 2. In SMT, words of an input sentence should be totally translated, whereas in SPG, not all words of an input sentence need to be paraphrased. Therefore, a SPG model should be able to decide which part of a sentence needs to be paraphrased. 3. The bilingual parallel data for SMT are easy to collect. In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004). Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a). 4. Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002)). The basic idea is that a translation should be scored based on their similarity to the human references. However, they cannot be adopted in SPG. The main reason is that it is more difficult to provide human references in SPG. Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is very small. Thus the human references cannot properly assess the quality of the generated paraphrases. 3.2 Method Overview The SPG method p</context>
<context position="16338" citStr="Zhao et al., 2008" startWordPosition="2610" endWordPosition="2613">) i=1 3.5 Paraphrase Resources We use five PTs in this work (except the selfparaphrase table), in which each pair of paraphrase units has a score assigned by the score function of the corresponding method. Paraphrase phrases (PT-1 to PT-3): Paraphrase phrases are extracted from three corpora: (1) Corp-1: bilingual parallel corpus, (2) Corp2: monolingual comparable corpus (comparable news articles reporting on the same event), and (3) Corp-3: monolingual parallel corpus (parallel translations of the same foreign novel). The details of the corpora, methods, and score functions are presented in (Zhao et al., 2008a). In our experiments, PT-1 is the largest, which contains 3,041,822 pairs of paraphrase phrases. PT-2 and PT-3 contain 92,358, and 17,668 pairs of paraphrase phrases, respectively. Paraphrase patterns (PT-4): Paraphrase patterns are also extracted from Corp-1. We applied the approach proposed in (Zhao et al., 2008b). Its basic assumption is that if two English patterns e1 and e2 are aligned with the same foreign pattern f, then e1 and e2 are possible paraphrases. One can refer to (Zhao et al., 2008b) for the details. PT-4 contains 1,018,371 pairs of paraphrase patterns. Paraphrase collocatio</context>
</contexts>
<marker>Zhao, Niu, Zhou, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and Sheng Li. 2008a. Combining Multiple Resources to Improve SMT-based Paraphrasing Model. In Proceedings ofACL-08:HLT, pages 1021-1029.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08:HLT,</booktitle>
<pages>780--788</pages>
<contexts>
<context position="3163" citStr="Zhao et al., 2008" startWordPosition="449" endWordPosition="452">ison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 834–842, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP Kauchak and Barzilay, 2006</context>
<context position="5533" citStr="Zhao et al., 2008" startWordPosition="838" endWordPosition="841">allenge. Moreover, developing a NLG system is also not trivial. SMT-based methods: SMT-based methods viewed PG as monolingual MT, i.e., translating s into t that are in the same language. Researchers employ the existing SMT models for PG (Quirk et al., 2004). Similar to typical SMT, a large parallel corpus is needed as training data in the SMT-based PG. However, such data are difficult to acquire compared with the SMT data. Therefore, data shortage becomes the major limitation of the method. To address this problem, we have tried combining multiple resources to improve the SMT-based PG model (Zhao et al., 2008a). There have been researchers trying to propose uniform PG methods for multiple applications. But they are either rule-based (Murata and Isahara, 2001; Takahashi et al., 2001) or thesaurusbased (Bolshakov and Gelbukh, 2004), thus they have some limitations as stated above. Furthermore, few of them conducted formal experiments to evaluate the proposed methods. 3 Statistical Paraphrase Generation 3.1 Differences between SPG and SMT Despite the similarity between PG and MT, the statistical model used in SMT cannot be directly applied in SPG, since there are some clear differences between them: </context>
<context position="6950" citStr="Zhao et al., 2008" startWordPosition="1071" endWordPosition="1074">lification, etc. The usability of the paraphrases have to be assessed in each application. 2. In SMT, words of an input sentence should be totally translated, whereas in SPG, not all words of an input sentence need to be paraphrased. Therefore, a SPG model should be able to decide which part of a sentence needs to be paraphrased. 3. The bilingual parallel data for SMT are easy to collect. In contrast, the monolingual parallel data for SPG are not so common (Quirk et al., 2004). Thus the SPG model should be able to easily combine different resources and thereby solve the data shortage problem (Zhao et al., 2008a). 4. Methods have been proposed for automatic evaluation in MT (e.g., BLEU (Papineni et al., 2002)). The basic idea is that a translation should be scored based on their similarity to the human references. However, they cannot be adopted in SPG. The main reason is that it is more difficult to provide human references in SPG. Lin and Pantel (2001) have demonstrated that the overlapping between the automatically acquired paraphrases and handcrafted ones is very small. Thus the human references cannot properly assess the quality of the generated paraphrases. 3.2 Method Overview The SPG method p</context>
<context position="16338" citStr="Zhao et al., 2008" startWordPosition="2610" endWordPosition="2613">) i=1 3.5 Paraphrase Resources We use five PTs in this work (except the selfparaphrase table), in which each pair of paraphrase units has a score assigned by the score function of the corresponding method. Paraphrase phrases (PT-1 to PT-3): Paraphrase phrases are extracted from three corpora: (1) Corp-1: bilingual parallel corpus, (2) Corp2: monolingual comparable corpus (comparable news articles reporting on the same event), and (3) Corp-3: monolingual parallel corpus (parallel translations of the same foreign novel). The details of the corpora, methods, and score functions are presented in (Zhao et al., 2008a). In our experiments, PT-1 is the largest, which contains 3,041,822 pairs of paraphrase phrases. PT-2 and PT-3 contain 92,358, and 17,668 pairs of paraphrase phrases, respectively. Paraphrase patterns (PT-4): Paraphrase patterns are also extracted from Corp-1. We applied the approach proposed in (Zhao et al., 2008b). Its basic assumption is that if two English patterns e1 and e2 are aligned with the same foreign pattern f, then e1 and e2 are possible paraphrases. One can refer to (Zhao et al., 2008b) for the details. PT-4 contains 1,018,371 pairs of paraphrase patterns. Paraphrase collocatio</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008b. Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora. In Proceedings of ACL-08:HLT, pages 780-788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Chin-Yew Lin</author>
<author>Dragos Stefan Munteanu</author>
<author>Eduard Hovy</author>
</authors>
<title>ParaEval: Using Paraphrases to Evaluate Summaries Automatically.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>447--454</pages>
<contexts>
<context position="1625" citStr="Zhou et al., 2006" startWordPosition="228" endWordPosition="231">search of paraphrasing, i.e., paraphrase recognition and paraphrase generation (PG). Paraphrase generation aims to generate a paraphrase for a source sentence in a certain application. PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboue and Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al., 1991), text simplification in computer-aided reading (Carroll et al., 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al., 2006). This paper presents a method for statistical paraphrase generation (SPG). As far as we know, this is the first statistical model specially designed for paraphrase generation. It’s distinguishing feature is that it achieves various applications with a uniform model. In addition, it exploits multiple resources, including paraphrase phrases, patterns, and collocations, to resolve the data shortage problem and generate more varied paraphrases. We consider three paraphrase applications in our experiments, including sentence compression, sentence simplification, and sentence similarity computation</context>
<context position="31287" citStr="Zhou et al., 2006" startWordPosition="5000" endWordPosition="5003">x syntactic structures into easy ones (e.g., replacing passive sentences with active forms). Our method is, to some extent, simpler than Carroll et al.’s, since our method does not contain syntactic simplification strategies. We will try to address sentence restructuring in our future work. Sentence Similarity computation: Kauchak and Barzilay (2006) have tried paraphrasing-based sentence similarity computation. They paraphrase a sentence s by replacing its words with WordNet synonyms, so that s can be more similar in wording to another sentence s&apos;. A similar method has also been proposed in (Zhou et al., 2006), which uses paraphrase phrases like our PT-1 instead of WordNet synonyms. These methods can be roughly viewed as special cases of ours, which only focus on the sentence similarity computation application and only use one kind of paraphrase resource. 6 Conclusions and Future Work This paper proposes a method for statistical paraphrase generation. The contributions are as follows. (1) It is the first statistical model specially designed for paraphrase generation, which is based on the analysis of the differences between paraphrase generation and other researches, especially machine translation.</context>
</contexts>
<marker>Zhou, Lin, Munteanu, Hovy, 2006</marker>
<rawString>Liang Zhou, Chin-Yew Lin, Dragos Stefan Munteanu, and Eduard Hovy. 2006. ParaEval: Using Paraphrases to Evaluate Summaries Automatically. In Proceedings of HLT-NAACL, pages 447-454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengqing Zong</author>
<author>Yujie Zhang</author>
<author>Kazuhide Yamamoto</author>
<author>Masashi Sakamoto</author>
<author>Satoshi Shirai</author>
</authors>
<title>Approach to Spoken Chinese Paraphrasing Based on Feature Extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of NLPRS,</booktitle>
<pages>551--556</pages>
<contexts>
<context position="2995" citStr="Zong et al., 2001" startWordPosition="423" endWordPosition="426">quacy, fluency, and usability. The results show that the proposed method is promising, which generates useful paraphrases for the given applications. In addition, comparison experiments show that our method outperforms a conventional SMT-based PG method. 2 Related Work Conventional methods for paraphrase generation can be classified as follows: Rule-based methods: Rule-based PG methods build on a set of paraphrase rules or patterns, which are either hand crafted or automatically collected. In the early rule-based PG research, the paraphrase rules are generally manually written (McKeown, 1979; Zong et al., 2001), which is expensive and arduous. Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods. However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase patterns are long or complicated (Quirk et al., 2004). Thesaurus-based methods: The thesaurus-based methods generate a paraphrase t for a source sentence s by substituting some words in s with their synonyms (Bolshakov and Gelbukh, 2004; 834 Proceedings o</context>
</contexts>
<marker>Zong, Zhang, Yamamoto, Sakamoto, Shirai, 2001</marker>
<rawString>Chengqing Zong, Yujie Zhang, Kazuhide Yamamoto, Masashi Sakamoto, Satoshi Shirai. 2001. Approach to Spoken Chinese Paraphrasing Based on Feature Extraction. In Proceedings of NLPRS, pages 551-556.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>