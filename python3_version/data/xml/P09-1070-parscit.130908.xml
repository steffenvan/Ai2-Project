<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000095">
<title confidence="0.991001">
Latent Variable Models of Concept-Attribute Attachment
</title>
<author confidence="0.999507">
Joseph Reisinger*
</author>
<affiliation confidence="0.9985795">
Department of Computer Sciences
The University of Texas at Austin
</affiliation>
<address confidence="0.547974">
Austin, Texas 78712
</address>
<email confidence="0.995896">
joeraii@cs.utexas.edu
</email>
<author confidence="0.859532">
Marius Pas¸ca
</author>
<affiliation confidence="0.826384">
Google Inc.
</affiliation>
<address confidence="0.6626255">
1600 Amphitheatre Parkway
Mountain View, California 94043
</address>
<email confidence="0.998478">
mars@google.com
</email>
<sectionHeader confidence="0.993881" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995676">
This paper presents a set of Bayesian
methods for automatically extending the
WORDNET ontology with new concepts
and annotating existing concepts with
generic property fields, or attributes. We
base our approach on Latent Dirichlet Al-
location and evaluate along two dimen-
sions: (1) the precision of the ranked
lists of attributes, and (2) the quality of
the attribute assignments to WORDNET
concepts. In all cases we find that the
principled LDA-based approaches outper-
form previously proposed heuristic meth-
ods, greatly improving the specificity of
attributes at each concept.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994198865671642">
We present a Bayesian approach for simultane-
ously extending Is-A hierarchies such as those
found in WORDNET (WN) (Fellbaum, 1998) with
additional concepts, and annotating the resulting
concept graph with attributes, i.e., generic prop-
erty fields shared by instances of that concept. Ex-
amples of attributes include “height” and “eye-
color” for the concept Person or “gdp” and “pres-
ident” for Country. Identifying and extracting
such attributes relative to a set of flat (i.e., non-
hierarchically organized) labeled classes of in-
stances has been extensively studied, using a vari-
ety of data, e.g., Web search query logs (Pas¸ca and
Van Durme, 2008), Web documents (Yoshinaga
and Torisawa, 2007), and Wikipedia (Suchanek et
al., 2007; Wu and Weld, 2008).
Building on the current state of the art in at-
tribute extraction, we propose a model-based ap-
proach for mapping flat sets of attributes anno-
tated with class labels into an existing ontology.
This inference problem is divided into two main
components: (1) identifying the appropriate par-
ent concept for each labeled class and (2) learning
*Contributions made during an internship at Google.
the correct level of abstraction for each attribute in
the extended ontology. For example, consider the
task of annotating WN with the labeled class re-
naissance painters containing the class instances
Pisanello, Hieronymus Bosch, and Jan van Eyck
and associated with the attributes “famous works”
and “style.” Since there is no WN concept for
renaissance painters, the latter would need to be
mapped into WN under, e.g., Painter. Further-
more, since “famous works” and “style” are not
specific to renaissance painters (or even the WN
concept Painter), they should be placed at the
most appropriate level of abstraction, e.g., Artist.
In this paper, we show that both of these goals
can be realized jointly using a probabilistic topic
model, namely hierarchical Latent Dirichlet Allo-
cation (LDA) (Blei et al., 2003b).
There are three main advantages to using a topic
model as the annotation procedure: (1) Unlike hi-
erarchical clustering (Duda et al., 2000), the at-
tribute distribution at a concept node is not com-
posed of the distributions of its children; attributes
found specific to the concept Painter would not
need to appear in the distribution of attributes for
Person, making the internal distributions at each
concept more meaningful as attributes specific to
that concept; (2) Since LDA is fully Bayesian, its
model semantics allow additional prior informa-
tion to be included, unlike standard models such as
Latent Semantic Analysis (Hofmann, 1999), im-
proving annotation precision; (3) Attributes with
multiple related meanings (i.e., polysemous at-
tributes) are modeled implicitly: if an attribute
(e.g., “style”) occurs in two separate input classes
(e.g., poets and car models), then that attribute
might attach at two different concepts in the ontol-
ogy, which is better than attaching it at their most
specific common ancestor (Whole) if that ancestor
is too general to be useful. However, there is also
a pressure for these two occurrences to attach to a
single concept.
We use WORDNET 3.0 as the specific test on-
tology for our annotation procedure, and evalu-
</bodyText>
<page confidence="0.967243">
620
</page>
<note confidence="0.999617">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 620–628,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.910765">
anticancer drugs: mechanism of action, uses, extrava-
sation, solubility, contraindications, side effects, chem-
istry, molecular weight, history, mode of action
bollywood actors: biography, filmography, age, bio-
data, height, profile, autobiography, new wallpapers, lat-
est photos, family pictures
</bodyText>
<figureCaption confidence="0.686896375">
citrus fruits: nutrition, health benefits, nutritional value,
nutritional information, calories, nutrition facts, history
european countries: population, flag, climate, presi-
dent, economy, geography, currency, population density,
topography, vegetation, religion, natural resources
london boroughs: population, taxis, local newspapers,
mp, lb, street map, renault connexions, local history
microorganisms: cell structure, taxonomy, life cycle,
reproduction, colony morphology, scientific name, vir-
ulence factors, gram stain, clipart
renaissance painters: early life, bibliography, short bi-
ography, the david, bio, painting, techniques, homosexu-
ality, birthplace, anatomical drawings, famous paintings
Figure 1: Examples of labeled attribute sets ex-
tracted using the method from (Pas¸ca and Van
Durme, 2008).
</figureCaption>
<bodyText confidence="0.999547846153846">
ate three variants: (1) a fixed structure approach
where each flat class is attached to WN using
a simple string-matching heuristic, and concept
nodes are annotated using LDA, (2) an extension
of LDA allowing for sense selection in addition to
annotation, and (3) an approach employing a non-
parametric prior over tree structures capable of in-
ferring arbitrary ontologies.
The remainder of this paper is organized as fol-
lows: §2 describes the full ontology annotation
framework, §3 introduces the LDA-based topic
models, §4 gives the experimental setup, §5 gives
results, §6 gives related work and §7 concludes.
</bodyText>
<sectionHeader confidence="0.992532" genericHeader="method">
2 Ontology Annotation
</sectionHeader>
<bodyText confidence="0.999976611111111">
Input to our ontology annotation procedure con-
sists of sets of class instances (e.g., Pisanello,
Hieronymus Bosch) associated with class labels
(e.g., renaissance painters) and attributes (e.g.,
“birthplace”, “famous works”, “style” and “early
life”). Clusters of noun phrases (instances) are
constructed using distributional similarity (Lin
and Pantel, 2002; Hearst, 1992) and are labeled
by applying “such-as” surface patterns to raw Web
text (e.g., “renaissance painters such as Hierony-
mous Bosch”), yielding 870K instances in more
than 4500 classes (Pas¸ca and Van Durme, 2008).
Attributes for each flat labeled class are ex-
tracted from anonymized Web search query
logs using the minimally supervised procedure
in (Pas¸ca, 2008)1. Candidate attributes are ranked
based on their weighted Jaccard similarity to a
set of 5 manually provided seed attributes for the
</bodyText>
<footnote confidence="0.9979065">
1Similar query data, including query strings and fre-
quency counts, is available from, e.g., (Gao et al., 2007)
</footnote>
<figureCaption confidence="0.8029955">
Figure 2: Graphical models for the LDA variants;
shaded nodes indicate observed quantities.
</figureCaption>
<bodyText confidence="0.984112875">
class european countries. Figure 1 illustrates sev-
eral such labeled attribute sets (the underlying in-
stances are not depicted). Naturally, the attributes
extracted are not perfect, e.g., “lb” and “renault
connexions” as attributes for london boroughs.
We propose a set of Bayesian generative models
based on LDA that take as input labeled attribute
sets generated using an extraction procedure such
as the above and organize the attributes in WN ac-
cording to their level of generality. Annotating
WN with attributes proceeds in three steps: (1)
attaching labeled attribute sets to leaf concepts in
WN using string distance, (2) inferring an attribute
model using one of the LDA variants discussed in
§ 3, and (3) generating ranked lists of attributes for
each concept using the model probabilities (§ 4.3).
</bodyText>
<sectionHeader confidence="0.970721" genericHeader="method">
3 Hierarchical Topic Models
</sectionHeader>
<subsectionHeader confidence="0.99868">
3.1 Latent Dirichlet Allocation
</subsectionHeader>
<bodyText confidence="0.9992">
The underlying mechanism for our annotation
procedure is LDA (Blei et al., 2003b), a fully
Bayesian extension of probabilistic Latent Seman-
tic Analysis (Hofmann, 1999). Given D labeled
attribute sets wd, d E D, LDA infers an unstruc-
tured set of T latent annotated concepts over
which attribute sets decompose as mixtures.2 The
latent annotated concepts represent semantically
coherent groups of attributes expressed in the data,
as shown in Example 1.
The generative model for LDA is given by
</bodyText>
<equation confidence="0.9975378">
θd|α — Dir(α), d E 1... D
βt|η — Dir(η), t E 1... T
zi,d|θd — Mult(θd), i E 1 ... |wd|
wi,d|βzi,d — Mult(βzi,d), i E 1... |wd|
(1)
</equation>
<bodyText confidence="0.9988204">
where α and q are hyperparameters smoothing
the per-attribute set distribution over concepts and
per-concept attribute distribution respectively (see
Figure 2 for the graphical model). We are inter-
ested in the case where w is known and we want
</bodyText>
<footnote confidence="0.9214885">
2In topic modeling literature, attributes are words and at-
tribute sets are documents.
</footnote>
<figure confidence="0.968601575757576">
T
n
�
LDA
D
w
w � w
T
IX
0
z
Fixed Structure LDA
n
D
w
IX
0
z
T
c
W
n
0
D
w
nCRP
w
IX
0
z
c
Y
T
</figure>
<page confidence="0.99568">
621
</page>
<bodyText confidence="0.9999462">
to compute the conditional posterior of the remain-
ing random variables p(z,,3, 0|w). This distribu-
tion can be approximated efficiently using Gibbs
sampling. See (Blei et al., 2003b) and (Griffiths
and Steyvers, 2002) for more details.
</bodyText>
<subsectionHeader confidence="0.997451">
3.2 Fixed-Structure LDA
</subsectionHeader>
<bodyText confidence="0.999850482758621">
In this paper, we extend LDA to model structural
dependencies between latent annotated concepts
(cf. (Li and McCallum, 2006; Sivic et al., 2008));
In particular, we fix the concept structure to cor-
respond to the WN Is-A hierarchy. Each labeled
attribute set is assigned to a leaf concept in WN
based on the edit distance between the concept la-
bel and the attribute set label. Possible latent con-
cepts for this set include the concepts along all
paths from its attachment point to the WN root,
following Is-A relation edges. Therefore, any two
labeled attribute sets share a number of latent con-
cepts based on their similarity in WN: all labeled
attribute sets share at least the root concept, and
may share more concepts depending on their most
specific, common ancestor. Under such a model,
more general attributes naturally attach to latent
concept nodes closer to the root, and more specific
attributes attach lower (Example 2).
Formally, we introduce into LDA an extra set of
random variables cd identifying the subset of con-
cepts in T available to attribute set d, as shown
in the diagram at the middle of Figure 2.3 For
example, with a tree structure, cd would be con-
strained to correspond to the concept nodes in T
on the path from the root to the leaf containing d.
Equation 1 can be adapted to this case if the in-
dex t is taken to range over concepts applicable to
attribute set d.
</bodyText>
<footnote confidence="0.687016">
3Abusing notation, we use T to refer to a structured set of
concepts and to refer to the number of concepts in flat LDA
</footnote>
<subsectionHeader confidence="0.994614">
3.3 Sense-Selective LDA
</subsectionHeader>
<bodyText confidence="0.99930225">
For each labeled attribute set, determining the ap-
propriate parent concept in WN is difficult since a
single class label may be found in many different
synsets (for example, the class bollywood actors
might attach to the “thespian” sense of Actor or
the “doer” sense). Fixed-hierarchy LDA can be
extended to perform automatic sense selection by
placing a distribution over the leaf concepts c, de-
scribing the prior probability of each possible path
through the concept tree. For WN, this amounts
to fixing the set of concepts to which a labeled at-
tribute set can attach (e.g., restricting it to a seman-
tically similar subset) and assigning a probability
to each concept (e.g., using the relative WN con-
cept frequencies). The probability for each sense
attachment cd becomes
</bodyText>
<equation confidence="0.932858">
p(cd|w, c−d, z) ∝ p(wd|c, w−d, z)p(cd|c−d),
</equation>
<bodyText confidence="0.999188666666667">
i.e., the complete conditionals for sense selection.
p(cd|c−d) is the conditional probability for attach-
ing attribute set d at cd (e.g., simply the prior
p(cd|c−d) def � p(cd) in the WN case). A closed
form expression for p(wd|c, w−d, z) is derived
in (Blei et al., 2003a).
</bodyText>
<subsectionHeader confidence="0.946212">
3.4 Nested Chinese Restaurant Process
</subsectionHeader>
<bodyText confidence="0.900710125">
In the final model, shown in the diagram on the
right side of Figure 2, LDA is extended hierarchi-
cally to infer arbitrary fixed-depth tree structures
(Example 1) Given 26 labeled attribute sets falling into
three broad semantic categories: philosophers, writers
and actors (e.g., sets for contemporary philosophers,
women writers, bollywood actors), LDA is able to infer
a meaningful set of latent annotated concepts:
</bodyText>
<figure confidence="0.998849285714286">
(philosopher)
quotations
teachings
virtue ethics
philosophies
biography
sayings
writing style
influences
achievements
bibliography
family tree
short biography
(writer)
new movies
filmography
official website
biography
email address
autobiography
(actor)
</figure>
<bodyText confidence="0.975753933333333">
(concept labels manually added for the latent annotated
concepts are shown in parentheses). Note that with a flat
concept structure, attributes can only be separated into
broad clusters, so the generality/specificity of attributes
cannot be inferred. Parameters were α=1, 71=0.1, T=3.
(Example 2 ) Fixing the latent concept structure to cor-
respond to WN (dark/purple nodes), and attaching each
labeled attribute set (examples depicted by light/orange
nodes) yields the annotated hierarchy:
Attribute distributions for the small nodes are not shown.
Dotted lines indicate multiple paths from the root, which
can be inferred using sense selection. Unlike with the flat
annotated concept structure, with a hierarchical concept
structure, attributes can be separated by their generality.
Parameters were set at α=1 and 71=0.1.
</bodyText>
<figure confidence="0.994992361111111">
philosophy
natural rights
criticism
ethics
law
philosopher
intellectual
works
picture
writings
history
biography
scholar
contemporary
philosophers
literary criticism
books
essays
short stories
novels
communicator
writer
person
women
writers
literate
tattoos
funeral
filmography
biographies
net worth
entertainer
performer
actor
bollywood
actors
</figure>
<page confidence="0.98673">
622
</page>
<bodyText confidence="0.999979277777778">
from data. Unlike the fixed-structure and sense-
selective approaches which use the WN hierarchy
directly, the nCRP generates its own annotated hi-
erarchy whose concept nodes do not necessarily
correspond to WN concepts (Example 3). Each
node in the tree instead corresponds to a latent an-
notated concept with an arbitrary number of sub-
concepts, distributed according to a Dirichlet Pro-
cess (Ferguson, 1973). Due to its recursive struc-
ture, the underlying model is called the nested Chi-
nese Restaurant Process (nCRP). The model in
Equation 1 is extended with cdJ-y — nCRP(-y, L),
d E D i.e., latent concepts for each attribute set are
drawn from an nCRP. The hyperparameter -y con-
trols the probability of branching via the per-node
Dirichlet Process, and L is the fixed tree depth.
An efficient Gibbs sampling procedure is given
in (Blei et al., 2003a).
</bodyText>
<sectionHeader confidence="0.995208" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.997875">
4.1 Data Analysis
</subsectionHeader>
<bodyText confidence="0.999687789473684">
We employ two data sets derived using the pro-
cedure in (Pas¸ca and Van Durme, 2008): the full
set of automatic extractions generated in § 2, and a
subset consisting of all attribute sets that fall under
the hierarchies rooted at the WN concepts living
thing#1 (i.e., the first sense of living thing), sub-
stance#7, location#1, person#1, organization#1
and food#1, manually selected to cover a high-
precision subset of labeled attribute sets. By com-
paring the results across the two datasets we can
measure each model’s robustness to noise.
In the full dataset, there are 4502 input attribute
sets with a total of 225K attributes (24K unique),
of which 8121 occur only once. The 10 attributes
occurring in the most sets (history, definition, pic-
ture(s), images, photos, clipart, timeline, clip art,
types) account for 6% of the total. For the subset,
there are 1510 attribute sets with 76K attributes
(11K unique), of which 4479 occur only once.
</bodyText>
<subsectionHeader confidence="0.998909">
4.2 Model Settings
</subsectionHeader>
<bodyText confidence="0.994535392156863">
Baseline: Each labeled attribute set is mapped to
the most common WN concept with the closest la-
bel string distance (Pas¸ca, 2008). Attributes are
propagated up the tree, attaching to node c if they
are contained in a majority of c’s children.
LDA: LDA is used to infer a flat set of T = 300
latent annotated concepts describing the data. The
concept selection smoothing parameter is set as
α=100. The smoother for the per-concept multi-
nomial over words is set as q=0.1.4 The effects of
concept structure on attribute precision can be iso-
lated by comparing the structured models to LDA.
Fixed-Structure LDA (fsLDA): The latent con-
cept hierarchy is fixed based on WN (§ 3.2), and
labeled attribute sets are mapped into it as in base-
line. The concept graph for each labeled attribute
set wd is decomposed into (possibly overlapping)
chains, one for each unique path from the WN root
to wd’s attachment point. Each path is assigned a
copy wd, reducing the bias in attribute sets with
many unique ancestor concepts.5 The final mod-
els contain 6566 annotated concepts on average.
Sense-Selective LDA (ssLDA): For the sense se-
lective approach (§ 3.3), the set of possible sense
attachments for each attribute set is taken to be all
WN concepts with the lowest edit distance to its
label, and the conditional probability of each sense
attachment p(cd) is set proportional to its relative
frequency. This procedure results in 2 to 3 senses
per attribute set on average, yielding models with
7108 annotated concepts.
Arbitrary hierarchy (nCRP): For the arbitrary
hierarchy model (§ 3.4), we set the maximum
tree depth L=5, per-concept attribute smoother
q=0.05, concept assignment smoother α=10 and
nCRP branching proportion -y=1.0. The resulting
4(Parameter setting) Across all models, the main results
in this paper are robust to changes in α. For nCRP, changes
in rl and 7 affect the size of the learned model but have less
effect on the final precision. Larger values for L give the
model more flexibility, but take longer to train.
5Reducing the directed-acyclic graph to a tree ontology
did not significantly affect precision.
(Example 3) Applying nCRP to the same three semantic
categories: philosophers, writers and actors, yields the
model:
(manually added labels are shown in parentheses). Un-
like in WN, the inferred structure naturally places
philosopher and writer under the same subconcept,
which is also separate from actor. Hyperparameters were
α=0.1, rl=0.1, 7=1.0.
</bodyText>
<figure confidence="0.990736282051282">
teachings
virtue ethics
structuralism
philosophies
political theory
(philosopher) (writer)
biography
date of birth
childhood
picture
family
works
books
quotations
critics
poems
contemporary
philosophers
criticism
short stories
style
poems
complete works
(root)
women
writers
accomplishments
official website
profile
life story
achievements
filmography
pictures
new movies
official site
works
bollywood
actors
(actor)
</figure>
<page confidence="0.989753">
623
</page>
<bodyText confidence="0.948459">
models span 380 annotated concepts on average.
</bodyText>
<subsectionHeader confidence="0.998782">
4.3 Constructing Ranked Lists of Attributes
</subsectionHeader>
<bodyText confidence="0.999678">
Given an inferred model, there are several ways to
construct ranked lists of attributes:
Per-Node Distribution: In fsLDA and ssLDA,
attribute rankings can be constructed directly for
each WN concept c, by computing the likelihood
of attribute w attaching to c, L(c|w) = p(w|c) av-
eraged over all Gibbs samples (discarding a fixed
number of samples for burn-in). Since c’s attribute
distribution is not dependent on the distributions
of its children, the resulting distribution is biased
towards more specific attributes.
Class-Entropy (CE): In all models, the inferred
latent annotated concepts can be used to smooth
the attribute rankings for each labeled attribute set.
Each sample from the posterior is composed of
two components: (1) a multinomial distribution
over a set of WN nodes, p(c|wd,α) for each at-
tribute set wd, where the (discrete) values of c are
WN concepts, and (2) a multinomial distribution
over attributes p(w|c, η) for each WN concept c.
To compute an attribute ranking for wd, we have
</bodyText>
<equation confidence="0.99259">
p(w|wd) = � p(w|c, η)p(c|wd, α).
c
</equation>
<bodyText confidence="0.999954666666667">
Given this new ranking for each attribute set, we
can compute new rankings for each WN concept
c by averaging again over all the wd that appear
as (possible indirect) descendants of c. Thus, this
method uses LDA to first perform reranking on the
raw extractions before applying the baseline ontol-
ogy induction procedure (§ 4.2).6
CE ranking exhibits a “conservation of entropy”
effect, whereby the proportion of general to spe-
cific attributes in each attribute set wd remains the
same in the posterior. If set A contains 10 specific
attributes and 30 generic ones, then the latter will
be favored over the former in the resulting distri-
bution 3 to 1. Conservation of entropy is a strong
assumption, and in particular it hinders improving
the specificity of attribute rankings.
Class-Entropy+Prior: The LDA-based models
do not inherently make use of any ranking infor-
mation contained in the original extractions. How-
ever, such information can be incorporated in the
form of a prior. The final ranking method com-
bines CE with an exponential prior over the at-
tribute rank in the baseline extraction. For each
attribute set, we compute the probability of each
</bodyText>
<footnote confidence="0.763210666666667">
6One simple extension is to run LDA again on the CE
ranked output, yielding an iterative procedure; however, this
was not found to significantly affect precision.
</footnote>
<equation confidence="0.367818">
attribute p(w|wd) = plda(w|wd)pbase(w|wd), as-
</equation>
<bodyText confidence="0.99791">
suming a parametric form for pbase(w|wd) def =
θ1(1,Wd). Here, r(w, wd) is the rank of w in at-
tribute set d. In all experiments reported, θ=0.9.
</bodyText>
<subsectionHeader confidence="0.99356">
4.4 Evaluating Attribute Attachment
</subsectionHeader>
<bodyText confidence="0.999968714285714">
For the WN-based models, in addition to mea-
suring the average precision of the reranked at-
tributes, it is also useful to evaluate the assign-
ment of attributes to WN concepts. For this eval-
uation, human annotators were asked to determine
the most appropriate WN synset(s) for a set of gold
attributes, taking into account polysemous usage.
For each model, ranked lists of possible concept
assignments C(w) are generated for each attribute
w, using L(c|w) for ranking. The accuracy of a list
C(w) for an attribute w is measured by a scoring
metric that corresponds to a modification (Pas¸ca
and Alfonseca, 2009) of the mean reciprocal rank
score (Voorhees and Tice, 2000):
</bodyText>
<equation confidence="0.986293">
1
DRR = max
rank(c) x (1 + PathToGold)
</equation>
<bodyText confidence="0.999906625">
where rank(c) is the rank (from 1 up to 10) of a
concept c in C(w), and PathToGold is the length
of the minimum path along Is-A edges in the con-
ceptual hierarchies between the concept c, on one
hand, and any of the gold-standard concepts man-
ually identified for the attribute w, on the other
hand. The length PathToGold is 0, if the returned
concept is the same as the gold-standard concept.
Conversely, a gold-standard attribute receives no
credit (that is, DRR is 0) if no path is found in
the hierarchies between the top 10 concepts of
C(w) and any of the gold-standard concepts, or if
C(w) is empty. The overalll precision of a given
model is the average of the DRR scores of individ-
ual attributes, computed over the gold assignment
set (Pas¸ca and Alfonseca, 2009).
</bodyText>
<sectionHeader confidence="0.999988" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.997053">
5.1 Attribute Precision
</subsectionHeader>
<bodyText confidence="0.824385">
Precision was manually evaluated relative to 23
concepts chosen for broad coverage.7 Table 1
shows precision at n and the Mean Average Preci-
sion (MAP); In all LDA-based models, the Bayes
average posterior is taken over all Gibbs samples
7(Precision evaluation) Attributes were hand annotated
using the procedure in (Pas¸ca and Van Durme, 2008) and nu-
merical precision scores (1.0 for vital, 0.5 for okay and 0.0 for
incorrect) were assigned for the top 50 attributes per concept.
25 reference concepts were originally chosen, but 2 were not
populated with attributes in any method, and hence were ex-
cluded from the comparison.
</bodyText>
<page confidence="0.987753">
624
</page>
<table confidence="0.997096658536586">
Precision @ MAP
10 20 50
0.48 0.47 0.44 0.46
0.77 0.69 0.58 0.67
-24 · 105
0.53 0.52 0.56 0.55
0.73 0.74 0.58 0.69
Model 5
Base (unranked) 0.45
Base (ranked) 0.77
LDA†
CE 0.64
CE+Prior 0.80
Per-Node 0.37 0.44 0.42 0.41 0.42
CE 0.69 0.68 0.65 0.58 0.64
CE+Prior 0.81 0.80 0.72 0.60 0.70
nCRP† -14 · 105
CE 0.74 0.76 0.73 0.65 0.72
CE+Prior 0.88 0.85 0.81 0.68 0.78
Subset only
Base (unranked) 0.61 0.62 0.62 0.60 0.62
Base (ranked) 0.79 0.82 0.72 0.65 0.72
–WN living thing 0.73 0.80 0.71 0.65 0.69
–WN substance 0.80 0.80 0.69 0.53 0.68
–WN location 0.95 0.93 0.84 0.75 0.84
–WN person 0.75 0.83 0.75 0.77 0.77
–WN organization 0.60 0.70 0.60 0.68 0.63
–WNfood 0.90 0.85 0.58 0.45 0.64
Per-Node 0.64 0.58 0.52 0.56 0.55
CE 0.90 0.83 0.78 0.73 0.78
CE+Prior 0.88 0.86 0.80 0.66 0.78
–WN living thing 0.83 0.88 0.78 0.63 0.77
–WN substance 0.85 0.83 0.78 0.66 0.76
–WN location 0.95 0.95 0.88 0.75 0.85
–WN person 1.00 0.93 0.91 0.76 0.87
–WN organization 0.80 0.70 0.80 0.76 0.75
–WNfood 0.80 0.70 0.63 0.40 0.59
nCRP† · 104
-45
CE 0.88 0.88 0.78 0.71 0.79
CE+Prior 0.90 0.88 0.83 0.67 0.79
</table>
<tableCaption confidence="0.998998">
Table 1: Precision at n and mean-average preci-
</tableCaption>
<bodyText confidence="0.99107385">
sion for all models and data sets. Inset plots show
log-likelihood of each Gibbs sample, indicating
convergence except in the case of nCRP. † indi-
cates models that do not generate annotated con-
cepts corresponding to WN nodes and hence have
no per-node scores.
after burn-in.8 The improvements in average pre-
cision are important, given the amount of noise in
the raw extracted data.
When prior attribute rank information (Per-
Node and CE scores) from the baseline extractions
is not incorporated, all LDA-based models outper-
form the unranked baseline (Table 1). In particu-
lar, LDA yields a 17% reduction in error (MAP)
8(Bayes average vs. maximum a-posteriori) The full
Bayesian average posterior consistently yielded higher preci-
sion than the maximum a-posteriori model. For the per-node
distributions, the fsLDA Bayes average model exhibits a 17%
reduction in relative error over the maximum a-posteriori es-
timate and for ssLDA there was a 26% reduction.
</bodyText>
<table confidence="0.99983676">
Model all DRR Scores (n)
(n) found
Base (unranked) 0.14 (150) 0.24 (91)
Base (ranked) 0.17 (150) 0.21 (123)
Fixed-structure 0.31 (150) 0.37 (128)
(fsLDA)
Sense-selective 0.31 (150) 0.37 (128)
(ssLDA)
Subset only
Base (unranked) 0.15 (97) 0.27 (54)
Base (ranked) 0.18 (97) 0.24 (74)
WN living thing 0.29 (27) 0.35 (22)
WN substance 0.21 (12) 0.32 (8)
WN location 0.12 0.17 (20)
WNperson 0.37 (18) 0.44 (15)
WN organization 0.15 0.17 (27)
WNfood 0.15 (6) 0.22 (4)
Fixed-structure 0.37 (97) 0.47 (77)
(fsLDA)
WN living thing 0.45 (27) 0.55 (22)
WN substance 0.48 (12) 0.64 (9)
WN location 0.34 (30) 0.44 (23)
WNperson 0.44 (18) 0.52 (15)
WN organization 0.44 (31) 0.71 (19)
WNfood 0.60 (6) 0.72 (5)
</table>
<tableCaption confidence="0.983154">
Table 2: All measures the DRR score relative to
</tableCaption>
<bodyText confidence="0.991982096774193">
the entire gold assignment set; found measures
DRR only for attributes with DRR(w)&gt;0; n is the
number of scores averaged.
over the baseline, fsLDA yields a 31% reduction,
ssLDA yields a 33% reduction and nCRP yields
a 48% reduction (24% reduction over fsLDA).
Performance also improves relative to the ranked
baseline when prior ranking information is incor-
porated in the LDA-based models, as indicated
by CE+Prior scores in Table 1. LDA and fsLDA
reduce relative error by 6%, ssLDA by 9% and
nCRP by 33%. Furthermore, nCRP precision
without ranking information surpasses the base-
line with ranking information, indicating robust-
ness to extraction noise. Precision curves for indi-
vidual attribute sets are shown in Figure 3. Over-
all, learning unconstrained hierarchies (nCRP) in-
creases precision, but as the inferred node distri-
butions do not correspond to WN concepts they
cannot be used for annotation.
One benefit to using an admixture model like
LDA is that each concept node in the resulting
model contains a distribution over attributes spe-
cific only to that node (in contrast to, e.g., hierar-
chical agglomerative clustering). Although abso-
lute precision is lower as more general attributes
have higher average precision (Per-Node scores
in Table 1), these distributions are semantically
meaningful in many cases (Figure 4) and further-
more can be used to calculate concept assignment
precision for each attribute.9
</bodyText>
<footnote confidence="0.395645">
9Per-node distributions (and hence DRR) were not evalu-
</footnote>
<figure confidence="0.99534325">
Fixed-structure (fsLDA)
Per-Node 0.43
CE 0.75
CE+Prior 0.78
Sense-selective (ssLDA)
-22 · 105
0.41 0.42 0.41 0.42
0.68 0.63 0.55 0.63
0.77 0.71 0.59 0.69
-18 · 105
Fixed-structure (fsLDA)
-77 · 104
</figure>
<page confidence="0.866533">
625
</page>
<figureCaption confidence="0.998897">
Figure 3: Precision (%) vs. rank plots (log scale) of attributes broken down across 18 labeled test attribute
sets. Ranked lists of attributes are generated using the CE+Prior method.
</figureCaption>
<subsectionHeader confidence="0.99518">
5.2 Concept Assignment Precision
</subsectionHeader>
<bodyText confidence="0.999692181818182">
The precision of assigning attributes to various
concepts is summarized in Table 2. Two scores are
given: all measures DRR relative to the entire gold
assignment set, and found measures DRR only for
attributes with DRR(w)&gt;0. Comparing the scores
gives an estimate of whether coverage or precision
is responsible for differences in scores. fsLDA and
ssLDA both yield a 20% reduction in relative er-
ror (17.2% increase in absolute DRR) over the un-
ranked baseline and a 17.2% reduction (14.2% ab-
solute increase) over the ranked baseline.
</bodyText>
<subsectionHeader confidence="0.997688">
5.3 Subset Precision and DRR
</subsectionHeader>
<bodyText confidence="0.988914863636364">
Precision scores for the manually selected subset
of extractions are given in the second half of Ta-
ble 1. Relative to the unranked baseline, fsLDA
and nCRP yield 42% and 44% reductions in er-
ror respectively, and relative to the ranked base-
line they both yield a 21.4% reduction. In terms of
absolute precision, there is no benefit to adding in
prior ranking knowledge to fsLDA or nCRP, in-
dicating diminishing returns as average baseline
precision increases (Baseline vs. fsLDA/nCRP CE
scores). Broken down across each of the subhier-
archies, LDA helps in all cases except food.
DRR scores for the subset are given in the lower
half of Table 2. Averaged over all gold test at-
tributes, DRR scores double when using fsLDA.
These results can be misleading, however, due
to artificially low coverage. Hence, Table 2 also
shows DRR scores broken down over each sub-
hierarchy, In this case fsLDA more than doubles
the DRR relative to the baseline for substance and
location, and triples it for organization and food.
ated for LDA or nCRP, because they are not mapped to WN.
</bodyText>
<sectionHeader confidence="0.999844" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999992470588235">
A large body of previous work exists on extend-
ing WORDNET with additional concepts and in-
stances (Snow et al., 2006; Suchanek et al., 2007);
these methods do not address attributes directly.
Previous literature in attribute extraction takes ad-
vantage of a range of data sources and extraction
procedures (Chklovski and Gil, 2005; Tokunaga
et al., 2005; Pas¸ca and Van Durme, 2008; Yoshi-
naga and Torisawa, 2007; Probst et al., 2007; Van
Durme et al., 2008; Wu and Weld, 2008). How-
ever these methods do not address the task of de-
termining the level of specificity for each attribute.
The closest studies to ours are (Pas¸ca, 2008), im-
plemented as the baseline method in this paper;
and (Pas¸ca and Alfonseca, 2009), which relies on
heuristics rather than formal models to estimate
the specificity of each attribute.
</bodyText>
<sectionHeader confidence="0.990778" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999956357142857">
This paper introduced a set of methods based on
Latent Dirichlet Allocation (LDA) for jointly ex-
tending the WORDNET ontology and annotating
its concepts with attributes (see Figure 4 for the
end result). LDA significantly outperformed a pre-
vious approach both in terms of the concept as-
signment precision (i.e., determining the correct
level of generality for an attribute) and the mean-
average precision of attribute lists at each concept
(i.e., filtering out noisy attributes from the base ex-
traction set). Also, relative precision of the attach-
ment models was shown to improve significantly
when the raw extraction quality increased, show-
ing the long-term viability of the approach.
</bodyText>
<page confidence="0.99365">
626
</page>
<figure confidence="0.997839857651245">
municipality
¥
¥
¥
population
nightlife
street map
temperature
ancient cities
registry office
school term dates
local history
renault
citizens advice bureau
leisure centres
sights
weather forecast
culture
tourist spots
state map
sightseeing
weather forecast
tourist guide
american school
zoo
hospitals
traditional dress
per capita income
tourist spot
cuisine
folk dances
industrial policy
borough
city
london
boroughs
administrative
district
port
cost of living
canadian embassy
city
air pollution
cheap hotels
region
district
filmography
new movies
schedule
new pictures
new pics
european
countries
recreation
national costume
prime minister
political parties
royal family
national parks
pathogen
phobia
mortality rate
symptoms
treatment
European
country
performer
country
bollywood
actors
actor
climate
tourist attractions
geography
weather
tourism
economy
photos
taxonomy
scientific name
reproduction
life cycle
habitat
location
parasites
new wallpapers
upcoming movies
baby pictures
latest wallpapers
entertainer
self portrait
paintings
famous works
self portraits
painting techniques
famous paintings
parasite
influenced
impressionist
the life
&apos;s paintings
style of
watercolor
bio
autobiography
childhood
bibliography
accomplishments
timeline
state codes
zipcodes
country profile
currencies
national anthem
telephone codes
hairstyle
hairstyles
music videos
songs
new pictures
sexy pictures
living thing
organism
object
whole
renaissance
painters
person
painter
creator
artist
pharmacokinetics
mechanism of action
long term effects
pharmacology
contraindications
mode of action
influences
artwork
style
work
art
technique
physical entity
drink mixes
apparitions
pitchers
existence
fantasy art
advertisements
sugar content
adverts
brand
nutrition information
storage temperature
carbohydrates
carbs
calories
alcohol content
pronunciation
glass
causal agent
drug
drug of abuse beverage
liquor
liquors
agent
danger
half life
ingredients
side effects
withdrawal symptoms
sexual side effects
alcohol
grape
vintage chart
grapes
city
food pairings
cheese
entity
recepies
gift baskets
receipes
rdi
daily allowance
fondue recipes
history
pictures
images
picture
photos
timeline
substance
food
matter
red wines
wine
sugar content
alcohol content
caffeine content
serving temperature
alcohol percentage
shelf life
chemistry
ingredients
chemical structure
dangers
chemical formula
msds
fiber
electricity
potassium
nutritional values
nutrition value
dna extraction
abstraction
substance
pests
nutritional values
music store
essential oil
nutrition value
dna extraction
liquid
fluid
solid
vegetable
produce
shelf life
nutritional facts
nutrition information
flavors
nutrition
nutritional information
vegetables
density
uses
physical properties
melting point
chemical properties
chemical structure
jobs
website
logo
address
mission statement
president
group
careers
ceo
phone number
annual report
london
company
material properties
refractive index
thermal properties
phase diagram
thermal expansion
aneurysm
dvorak
recordings
conductor
instrument
broadcasts
hall
recordings
broadcasts
recording
christmas
ticket
conductor
organization
musical
organization
food
orchestra
orchestras
social
group
</figure>
<figureCaption confidence="0.994245">
Figure 4: Example per-node attribute distribution generated by fsLDA. Light/orange nodes represent
</figureCaption>
<bodyText confidence="0.909209142857143">
labeled attribute sets attached to WN, and the full hypernym graph is given for each in dark/purple
nodes. White nodes depict the top attributes predicted for each WN concept. These inferred annotations
exhibit a high degree of concept specificity, naturally becoming more general at higher levels of the
ontology. Some annotations, such as for the concepts Agent, Substance, Living Thing and Person have
high precision and specificity while others, such as Liquor and Actor need improvement. Overall, the
more general concepts yield better annotations as they are averaged over many labeled attribute sets,
reducing noise. 627
</bodyText>
<sectionHeader confidence="0.995382" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999928612068965">
D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.
2003a. Hierarchical topic models and the nested
Chinese restaurant process. In Proceedings of the
17th Conference on Neural Information Process-
ing Systems (NIPS-2003), pages 17–24, Vancouver,
British Columbia.
D. Blei, A. Ng, and M. Jordan. 2003b. Latent dirich-
let allocation. Machine Learning Research, 3:993–
1022.
T. Chklovski and Y. Gil. 2005. An analysis of knowl-
edge collected from volunteer contributors. In Pro-
ceedings of the 20th National Conference on Arti-
ficial Intelligence (AAAI-05), pages 564–571, Pitts-
burgh, Pennsylvania.
R. Duda, P. Hart, and D. Stork. 2000. Pattern Classifi-
cation. John Wiley and Sons.
C. Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database and Some of its Applications. MIT
Press.
T. Ferguson. 1973. A bayesian analysis of some non-
parametric problems. Annals of Statistics, 1(2):209–
230.
W. Gao, C. Niu, J. Nie, M. Zhou, J. Hu, K. Wong, and
H. Hon. 2007. Cross-lingual query suggestion using
query logs of different languages. In Proceedings of
the 30th ACM Conference on Research and Devel-
opment in Information Retrieval (SIGIR-07), pages
463–470, Amsterdam, The Netherlands.
T. Griffiths and M. Steyvers. 2002. A probabilistic ap-
proach to semantic representation. In Proceedings
of the 24th Conference of the Cognitive Science So-
ciety (CogSci02), pages 381–386, Fairfax, Virginia.
M. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th International Conference on Computational
Linguistics (COLING-92), pages 539–545, Nantes,
France.
T. Hofmann. 1999. Probabilistic latent semantic in-
dexing. In Proceedings of the 22nd ACM Confer-
ence on Research and Development in Information
Retrieval (SIGIR-99), pages 50–57, Berkeley, Cali-
fornia.
W. Li and A. McCallum. 2006. Pachinko alloca-
tion: DAG-structured mixture models of topic cor-
relations. In Proceedings of the 23rd International
Conference on Machine Learning (ICML-06), pages
577–584, Pittsburgh, Pennsylvania.
D. Lin and P. Pantel. 2002. Concept discovery from
text. In Proceedings of the 19th International Con-
ference on Computational linguistics (COLING-02),
pages 1–7, Taipei, Taiwan.
M. Pas¸ca and E. Alfonseca. 2009. Web-derived re-
sources for Web Information Retrieval: From con-
ceptual hierarchies to attribute hierarchies. In Pro-
ceedings of the 32nd International Conference on
Research and Development in Information Retrieval
(SIGIR-09), Boston, Massachusetts.
M. Pas¸ca and B. Van Durme. 2008. Weakly-
supervised acquisition of open-domain classes and
class attributes from web documents and query logs.
In Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics (ACL-08),
pages 19–27, Columbus, Ohio.
M. Pas¸ca. 2008. Turning Web text and search
queries into factual knowledge: Hierarchical class
attribute extraction. In Proceedings of the 23rd Na-
tional Conference on Artificial Intelligence (AAAI-
08), pages 1225–1230, Chicago, Illinois.
K. Probst, R. Ghani, M. Krema, A. Fano, and Y. Liu.
2007. Semi-supervised learning of attribute-value
pairs from product descriptions. In Proceedings of
the 20th International Joint Conference on Artificial
Intelligence (IJCAI-07), pages 2838–2843, Hyder-
abad, India.
J. Sivic, B. Russell, A. Zisserman, W. Freeman, and
A. Efros. 2008. Unsupervised discovery of visual
object class hierarchies. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recog-
nition (CVPR-08), pages 1–8, Anchorage, Alaska.
R. Snow, D. Jurafsky, and A. Ng. 2006. Semantic tax-
onomy induction from heterogenous evidence. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL-06), pages 801–808, Sydney, Aus-
tralia.
F. Suchanek, G. Kasneci, and G. Weikum. 2007. Yago:
a core of semantic knowledge unifying WordNet and
Wikipedia. In Proceedings of the 16th World Wide
Web Conference (WWW-07), pages 697–706, Banff,
Canada.
K. Tokunaga, J. Kazama, and K. Torisawa. 2005. Au-
tomatic discovery of attribute words from Web doc-
uments. In Proceedings of the 2nd International
Joint Conference on Natural Language Processing
(IJCNLP-05), pages 106–118, Jeju Island, Korea.
B. Van Durme, T. Qian, and L. Schubert. 2008.
Class-driven attribute extraction. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics (COLING-2008), pages 921–928,
Manchester, United Kingdom.
E.M. Voorhees and D.M. Tice. 2000. Building a
question-answering test collection. In Proceedings
of the 23rd International Conference on Research
and Development in Information Retrieval (SIGIR-
00), pages 200–207, Athens, Greece.
F. Wu and D. Weld. 2008. Automatically refining the
Wikipedia infobox ontology. In Proceedings of the
17th World Wide Web Conference (WWW-08), pages
635–644, Beijing, China.
N. Yoshinaga and K. Torisawa. 2007. Open-domain
attribute-value acquisition from semi-structured
texts. In Proceedings of the 6th International Se-
mantic Web Conference (ISWC-07), Workshop on
Text to Knowledge: The Lexicon/Ontology Interface
(OntoLex-2007), pages 55–66, Busan, South Korea.
</reference>
<page confidence="0.997345">
628
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.787810">
<title confidence="0.825278">Latent Variable Models of Concept-Attribute Attachment</title>
<affiliation confidence="0.996202">Department of Computer Sciences The University of Texas at Austin</affiliation>
<address confidence="0.99971">Austin, Texas 78712</address>
<email confidence="0.99979">joeraii@cs.utexas.edu</email>
<affiliation confidence="0.998685">Google Inc.</affiliation>
<address confidence="0.998747">1600 Amphitheatre Parkway Mountain View, California 94043</address>
<email confidence="0.999166">mars@google.com</email>
<abstract confidence="0.9979275">This paper presents a set of Bayesian methods for automatically extending the with new concepts and annotating existing concepts with property fields, or We base our approach on Latent Dirichlet Allocation and evaluate along two dimensions: (1) the precision of the ranked lists of attributes, and (2) the quality of attribute assignments to concepts. In all cases we find that the principled LDA-based approaches outperform previously proposed heuristic methods, greatly improving the specificity of attributes at each concept.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>T Griffiths</author>
<author>M Jordan</author>
<author>J Tenenbaum</author>
</authors>
<title>Hierarchical topic models and the nested Chinese restaurant process.</title>
<date>2003</date>
<booktitle>In Proceedings of the 17th Conference on Neural Information Processing Systems (NIPS-2003),</booktitle>
<pages>17--24</pages>
<location>Vancouver, British Columbia.</location>
<contexts>
<context position="2835" citStr="Blei et al., 2003" startWordPosition="432" endWordPosition="435">ances Pisanello, Hieronymus Bosch, and Jan van Eyck and associated with the attributes “famous works” and “style.” Since there is no WN concept for renaissance painters, the latter would need to be mapped into WN under, e.g., Painter. Furthermore, since “famous works” and “style” are not specific to renaissance painters (or even the WN concept Painter), they should be placed at the most appropriate level of abstraction, e.g., Artist. In this paper, we show that both of these goals can be realized jointly using a probabilistic topic model, namely hierarchical Latent Dirichlet Allocation (LDA) (Blei et al., 2003b). There are three main advantages to using a topic model as the annotation procedure: (1) Unlike hierarchical clustering (Duda et al., 2000), the attribute distribution at a concept node is not composed of the distributions of its children; attributes found specific to the concept Painter would not need to appear in the distribution of attributes for Person, making the internal distributions at each concept more meaningful as attributes specific to that concept; (2) Since LDA is fully Bayesian, its model semantics allow additional prior information to be included, unlike standard models such</context>
<context position="8002" citStr="Blei et al., 2003" startWordPosition="1205" endWordPosition="1208">t labeled attribute sets generated using an extraction procedure such as the above and organize the attributes in WN according to their level of generality. Annotating WN with attributes proceeds in three steps: (1) attaching labeled attribute sets to leaf concepts in WN using string distance, (2) inferring an attribute model using one of the LDA variants discussed in § 3, and (3) generating ranked lists of attributes for each concept using the model probabilities (§ 4.3). 3 Hierarchical Topic Models 3.1 Latent Dirichlet Allocation The underlying mechanism for our annotation procedure is LDA (Blei et al., 2003b), a fully Bayesian extension of probabilistic Latent Semantic Analysis (Hofmann, 1999). Given D labeled attribute sets wd, d E D, LDA infers an unstructured set of T latent annotated concepts over which attribute sets decompose as mixtures.2 The latent annotated concepts represent semantically coherent groups of attributes expressed in the data, as shown in Example 1. The generative model for LDA is given by θd|α — Dir(α), d E 1... D βt|η — Dir(η), t E 1... T zi,d|θd — Mult(θd), i E 1 ... |wd| wi,d|βzi,d — Mult(βzi,d), i E 1... |wd| (1) where α and q are hyperparameters smoothing the per-att</context>
<context position="11859" citStr="Blei et al., 2003" startWordPosition="1885" endWordPosition="1888">ee. For WN, this amounts to fixing the set of concepts to which a labeled attribute set can attach (e.g., restricting it to a semantically similar subset) and assigning a probability to each concept (e.g., using the relative WN concept frequencies). The probability for each sense attachment cd becomes p(cd|w, c−d, z) ∝ p(wd|c, w−d, z)p(cd|c−d), i.e., the complete conditionals for sense selection. p(cd|c−d) is the conditional probability for attaching attribute set d at cd (e.g., simply the prior p(cd|c−d) def � p(cd) in the WN case). A closed form expression for p(wd|c, w−d, z) is derived in (Blei et al., 2003a). 3.4 Nested Chinese Restaurant Process In the final model, shown in the diagram on the right side of Figure 2, LDA is extended hierarchically to infer arbitrary fixed-depth tree structures (Example 1) Given 26 labeled attribute sets falling into three broad semantic categories: philosophers, writers and actors (e.g., sets for contemporary philosophers, women writers, bollywood actors), LDA is able to infer a meaningful set of latent annotated concepts: (philosopher) quotations teachings virtue ethics philosophies biography sayings writing style influences achievements bibliography family tr</context>
<context position="14592" citStr="Blei et al., 2003" startWordPosition="2286" endWordPosition="2289">Each node in the tree instead corresponds to a latent annotated concept with an arbitrary number of subconcepts, distributed according to a Dirichlet Process (Ferguson, 1973). Due to its recursive structure, the underlying model is called the nested Chinese Restaurant Process (nCRP). The model in Equation 1 is extended with cdJ-y — nCRP(-y, L), d E D i.e., latent concepts for each attribute set are drawn from an nCRP. The hyperparameter -y controls the probability of branching via the per-node Dirichlet Process, and L is the fixed tree depth. An efficient Gibbs sampling procedure is given in (Blei et al., 2003a). 4 Experimental Setup 4.1 Data Analysis We employ two data sets derived using the procedure in (Pas¸ca and Van Durme, 2008): the full set of automatic extractions generated in § 2, and a subset consisting of all attribute sets that fall under the hierarchies rooted at the WN concepts living thing#1 (i.e., the first sense of living thing), substance#7, location#1, person#1, organization#1 and food#1, manually selected to cover a highprecision subset of labeled attribute sets. By comparing the results across the two datasets we can measure each model’s robustness to noise. In the full dataset</context>
</contexts>
<marker>Blei, Griffiths, Jordan, Tenenbaum, 2003</marker>
<rawString>D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum. 2003a. Hierarchical topic models and the nested Chinese restaurant process. In Proceedings of the 17th Conference on Neural Information Processing Systems (NIPS-2003), pages 17–24, Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>A Ng</author>
<author>M Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Machine Learning Research,</journal>
<volume>3</volume>
<pages>1022</pages>
<contexts>
<context position="2835" citStr="Blei et al., 2003" startWordPosition="432" endWordPosition="435">ances Pisanello, Hieronymus Bosch, and Jan van Eyck and associated with the attributes “famous works” and “style.” Since there is no WN concept for renaissance painters, the latter would need to be mapped into WN under, e.g., Painter. Furthermore, since “famous works” and “style” are not specific to renaissance painters (or even the WN concept Painter), they should be placed at the most appropriate level of abstraction, e.g., Artist. In this paper, we show that both of these goals can be realized jointly using a probabilistic topic model, namely hierarchical Latent Dirichlet Allocation (LDA) (Blei et al., 2003b). There are three main advantages to using a topic model as the annotation procedure: (1) Unlike hierarchical clustering (Duda et al., 2000), the attribute distribution at a concept node is not composed of the distributions of its children; attributes found specific to the concept Painter would not need to appear in the distribution of attributes for Person, making the internal distributions at each concept more meaningful as attributes specific to that concept; (2) Since LDA is fully Bayesian, its model semantics allow additional prior information to be included, unlike standard models such</context>
<context position="8002" citStr="Blei et al., 2003" startWordPosition="1205" endWordPosition="1208">t labeled attribute sets generated using an extraction procedure such as the above and organize the attributes in WN according to their level of generality. Annotating WN with attributes proceeds in three steps: (1) attaching labeled attribute sets to leaf concepts in WN using string distance, (2) inferring an attribute model using one of the LDA variants discussed in § 3, and (3) generating ranked lists of attributes for each concept using the model probabilities (§ 4.3). 3 Hierarchical Topic Models 3.1 Latent Dirichlet Allocation The underlying mechanism for our annotation procedure is LDA (Blei et al., 2003b), a fully Bayesian extension of probabilistic Latent Semantic Analysis (Hofmann, 1999). Given D labeled attribute sets wd, d E D, LDA infers an unstructured set of T latent annotated concepts over which attribute sets decompose as mixtures.2 The latent annotated concepts represent semantically coherent groups of attributes expressed in the data, as shown in Example 1. The generative model for LDA is given by θd|α — Dir(α), d E 1... D βt|η — Dir(η), t E 1... T zi,d|θd — Mult(θd), i E 1 ... |wd| wi,d|βzi,d — Mult(βzi,d), i E 1... |wd| (1) where α and q are hyperparameters smoothing the per-att</context>
<context position="11859" citStr="Blei et al., 2003" startWordPosition="1885" endWordPosition="1888">ee. For WN, this amounts to fixing the set of concepts to which a labeled attribute set can attach (e.g., restricting it to a semantically similar subset) and assigning a probability to each concept (e.g., using the relative WN concept frequencies). The probability for each sense attachment cd becomes p(cd|w, c−d, z) ∝ p(wd|c, w−d, z)p(cd|c−d), i.e., the complete conditionals for sense selection. p(cd|c−d) is the conditional probability for attaching attribute set d at cd (e.g., simply the prior p(cd|c−d) def � p(cd) in the WN case). A closed form expression for p(wd|c, w−d, z) is derived in (Blei et al., 2003a). 3.4 Nested Chinese Restaurant Process In the final model, shown in the diagram on the right side of Figure 2, LDA is extended hierarchically to infer arbitrary fixed-depth tree structures (Example 1) Given 26 labeled attribute sets falling into three broad semantic categories: philosophers, writers and actors (e.g., sets for contemporary philosophers, women writers, bollywood actors), LDA is able to infer a meaningful set of latent annotated concepts: (philosopher) quotations teachings virtue ethics philosophies biography sayings writing style influences achievements bibliography family tr</context>
<context position="14592" citStr="Blei et al., 2003" startWordPosition="2286" endWordPosition="2289">Each node in the tree instead corresponds to a latent annotated concept with an arbitrary number of subconcepts, distributed according to a Dirichlet Process (Ferguson, 1973). Due to its recursive structure, the underlying model is called the nested Chinese Restaurant Process (nCRP). The model in Equation 1 is extended with cdJ-y — nCRP(-y, L), d E D i.e., latent concepts for each attribute set are drawn from an nCRP. The hyperparameter -y controls the probability of branching via the per-node Dirichlet Process, and L is the fixed tree depth. An efficient Gibbs sampling procedure is given in (Blei et al., 2003a). 4 Experimental Setup 4.1 Data Analysis We employ two data sets derived using the procedure in (Pas¸ca and Van Durme, 2008): the full set of automatic extractions generated in § 2, and a subset consisting of all attribute sets that fall under the hierarchies rooted at the WN concepts living thing#1 (i.e., the first sense of living thing), substance#7, location#1, person#1, organization#1 and food#1, manually selected to cover a highprecision subset of labeled attribute sets. By comparing the results across the two datasets we can measure each model’s robustness to noise. In the full dataset</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D. Blei, A. Ng, and M. Jordan. 2003b. Latent dirichlet allocation. Machine Learning Research, 3:993– 1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovski</author>
<author>Y Gil</author>
</authors>
<title>An analysis of knowledge collected from volunteer contributors.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05),</booktitle>
<pages>564--571</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="30013" citStr="Chklovski and Gil, 2005" startWordPosition="4837" endWordPosition="4840">coverage. Hence, Table 2 also shows DRR scores broken down over each subhierarchy, In this case fsLDA more than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristics rather than formal models to estimate the specificity of each attribute. 7 Conclusion This paper introduced a set of methods based on Latent Dirichlet Allocation (LDA) for jointly extendi</context>
</contexts>
<marker>Chklovski, Gil, 2005</marker>
<rawString>T. Chklovski and Y. Gil. 2005. An analysis of knowledge collected from volunteer contributors. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05), pages 564–571, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Duda</author>
<author>P Hart</author>
<author>D Stork</author>
</authors>
<title>Pattern Classification.</title>
<date>2000</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="2977" citStr="Duda et al., 2000" startWordPosition="455" endWordPosition="458">pt for renaissance painters, the latter would need to be mapped into WN under, e.g., Painter. Furthermore, since “famous works” and “style” are not specific to renaissance painters (or even the WN concept Painter), they should be placed at the most appropriate level of abstraction, e.g., Artist. In this paper, we show that both of these goals can be realized jointly using a probabilistic topic model, namely hierarchical Latent Dirichlet Allocation (LDA) (Blei et al., 2003b). There are three main advantages to using a topic model as the annotation procedure: (1) Unlike hierarchical clustering (Duda et al., 2000), the attribute distribution at a concept node is not composed of the distributions of its children; attributes found specific to the concept Painter would not need to appear in the distribution of attributes for Person, making the internal distributions at each concept more meaningful as attributes specific to that concept; (2) Since LDA is fully Bayesian, its model semantics allow additional prior information to be included, unlike standard models such as Latent Semantic Analysis (Hofmann, 1999), improving annotation precision; (3) Attributes with multiple related meanings (i.e., polysemous </context>
</contexts>
<marker>Duda, Hart, Stork, 2000</marker>
<rawString>R. Duda, P. Hart, and D. Stork. 2000. Pattern Classification. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database and Some of its Applications.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database and Some of its Applications. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ferguson</author>
</authors>
<title>A bayesian analysis of some nonparametric problems.</title>
<date>1973</date>
<journal>Annals of Statistics,</journal>
<volume>1</volume>
<issue>2</issue>
<pages>230</pages>
<contexts>
<context position="14149" citStr="Ferguson, 1973" startWordPosition="2210" endWordPosition="2211">osophers literary criticism books essays short stories novels communicator writer person women writers literate tattoos funeral filmography biographies net worth entertainer performer actor bollywood actors 622 from data. Unlike the fixed-structure and senseselective approaches which use the WN hierarchy directly, the nCRP generates its own annotated hierarchy whose concept nodes do not necessarily correspond to WN concepts (Example 3). Each node in the tree instead corresponds to a latent annotated concept with an arbitrary number of subconcepts, distributed according to a Dirichlet Process (Ferguson, 1973). Due to its recursive structure, the underlying model is called the nested Chinese Restaurant Process (nCRP). The model in Equation 1 is extended with cdJ-y — nCRP(-y, L), d E D i.e., latent concepts for each attribute set are drawn from an nCRP. The hyperparameter -y controls the probability of branching via the per-node Dirichlet Process, and L is the fixed tree depth. An efficient Gibbs sampling procedure is given in (Blei et al., 2003a). 4 Experimental Setup 4.1 Data Analysis We employ two data sets derived using the procedure in (Pas¸ca and Van Durme, 2008): the full set of automatic ext</context>
</contexts>
<marker>Ferguson, 1973</marker>
<rawString>T. Ferguson. 1973. A bayesian analysis of some nonparametric problems. Annals of Statistics, 1(2):209– 230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gao</author>
<author>C Niu</author>
<author>J Nie</author>
<author>M Zhou</author>
<author>J Hu</author>
<author>K Wong</author>
<author>H Hon</author>
</authors>
<title>Cross-lingual query suggestion using query logs of different languages.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th ACM Conference on Research and Development in Information Retrieval (SIGIR-07),</booktitle>
<pages>463--470</pages>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="6963" citStr="Gao et al., 2007" startWordPosition="1043" endWordPosition="1046"> Hearst, 1992) and are labeled by applying “such-as” surface patterns to raw Web text (e.g., “renaissance painters such as Hieronymous Bosch”), yielding 870K instances in more than 4500 classes (Pas¸ca and Van Durme, 2008). Attributes for each flat labeled class are extracted from anonymized Web search query logs using the minimally supervised procedure in (Pas¸ca, 2008)1. Candidate attributes are ranked based on their weighted Jaccard similarity to a set of 5 manually provided seed attributes for the 1Similar query data, including query strings and frequency counts, is available from, e.g., (Gao et al., 2007) Figure 2: Graphical models for the LDA variants; shaded nodes indicate observed quantities. class european countries. Figure 1 illustrates several such labeled attribute sets (the underlying instances are not depicted). Naturally, the attributes extracted are not perfect, e.g., “lb” and “renault connexions” as attributes for london boroughs. We propose a set of Bayesian generative models based on LDA that take as input labeled attribute sets generated using an extraction procedure such as the above and organize the attributes in WN according to their level of generality. Annotating WN with at</context>
</contexts>
<marker>Gao, Niu, Nie, Zhou, Hu, Wong, Hon, 2007</marker>
<rawString>W. Gao, C. Niu, J. Nie, M. Zhou, J. Hu, K. Wong, and H. Hon. 2007. Cross-lingual query suggestion using query logs of different languages. In Proceedings of the 30th ACM Conference on Research and Development in Information Retrieval (SIGIR-07), pages 463–470, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Griffiths</author>
<author>M Steyvers</author>
</authors>
<title>A probabilistic approach to semantic representation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 24th Conference of the Cognitive Science Society (CogSci02),</booktitle>
<pages>381--386</pages>
<location>Fairfax, Virginia.</location>
<contexts>
<context position="9193" citStr="Griffiths and Steyvers, 2002" startWordPosition="1424" endWordPosition="1427"> hyperparameters smoothing the per-attribute set distribution over concepts and per-concept attribute distribution respectively (see Figure 2 for the graphical model). We are interested in the case where w is known and we want 2In topic modeling literature, attributes are words and attribute sets are documents. T n � LDA D w w � w T IX 0 z Fixed Structure LDA n D w IX 0 z T c W n 0 D w nCRP w IX 0 z c Y T 621 to compute the conditional posterior of the remaining random variables p(z,,3, 0|w). This distribution can be approximated efficiently using Gibbs sampling. See (Blei et al., 2003b) and (Griffiths and Steyvers, 2002) for more details. 3.2 Fixed-Structure LDA In this paper, we extend LDA to model structural dependencies between latent annotated concepts (cf. (Li and McCallum, 2006; Sivic et al., 2008)); In particular, we fix the concept structure to correspond to the WN Is-A hierarchy. Each labeled attribute set is assigned to a leaf concept in WN based on the edit distance between the concept label and the attribute set label. Possible latent concepts for this set include the concepts along all paths from its attachment point to the WN root, following Is-A relation edges. Therefore, any two labeled attrib</context>
</contexts>
<marker>Griffiths, Steyvers, 2002</marker>
<rawString>T. Griffiths and M. Steyvers. 2002. A probabilistic approach to semantic representation. In Proceedings of the 24th Conference of the Cognitive Science Society (CogSci02), pages 381–386, Fairfax, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92),</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="6360" citStr="Hearst, 1992" startWordPosition="950" endWordPosition="951"> paper is organized as follows: §2 describes the full ontology annotation framework, §3 introduces the LDA-based topic models, §4 gives the experimental setup, §5 gives results, §6 gives related work and §7 concludes. 2 Ontology Annotation Input to our ontology annotation procedure consists of sets of class instances (e.g., Pisanello, Hieronymus Bosch) associated with class labels (e.g., renaissance painters) and attributes (e.g., “birthplace”, “famous works”, “style” and “early life”). Clusters of noun phrases (instances) are constructed using distributional similarity (Lin and Pantel, 2002; Hearst, 1992) and are labeled by applying “such-as” surface patterns to raw Web text (e.g., “renaissance painters such as Hieronymous Bosch”), yielding 870K instances in more than 4500 classes (Pas¸ca and Van Durme, 2008). Attributes for each flat labeled class are extracted from anonymized Web search query logs using the minimally supervised procedure in (Pas¸ca, 2008)1. Candidate attributes are ranked based on their weighted Jaccard similarity to a set of 5 manually provided seed attributes for the 1Similar query data, including query strings and frequency counts, is available from, e.g., (Gao et al., 20</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th International Conference on Computational Linguistics (COLING-92), pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd ACM Conference on Research and Development in Information Retrieval (SIGIR-99),</booktitle>
<pages>50--57</pages>
<location>Berkeley, California.</location>
<contexts>
<context position="3479" citStr="Hofmann, 1999" startWordPosition="536" endWordPosition="537">tages to using a topic model as the annotation procedure: (1) Unlike hierarchical clustering (Duda et al., 2000), the attribute distribution at a concept node is not composed of the distributions of its children; attributes found specific to the concept Painter would not need to appear in the distribution of attributes for Person, making the internal distributions at each concept more meaningful as attributes specific to that concept; (2) Since LDA is fully Bayesian, its model semantics allow additional prior information to be included, unlike standard models such as Latent Semantic Analysis (Hofmann, 1999), improving annotation precision; (3) Attributes with multiple related meanings (i.e., polysemous attributes) are modeled implicitly: if an attribute (e.g., “style”) occurs in two separate input classes (e.g., poets and car models), then that attribute might attach at two different concepts in the ontology, which is better than attaching it at their most specific common ancestor (Whole) if that ancestor is too general to be useful. However, there is also a pressure for these two occurrences to attach to a single concept. We use WORDNET 3.0 as the specific test ontology for our annotation proce</context>
<context position="8090" citStr="Hofmann, 1999" startWordPosition="1219" endWordPosition="1220">nize the attributes in WN according to their level of generality. Annotating WN with attributes proceeds in three steps: (1) attaching labeled attribute sets to leaf concepts in WN using string distance, (2) inferring an attribute model using one of the LDA variants discussed in § 3, and (3) generating ranked lists of attributes for each concept using the model probabilities (§ 4.3). 3 Hierarchical Topic Models 3.1 Latent Dirichlet Allocation The underlying mechanism for our annotation procedure is LDA (Blei et al., 2003b), a fully Bayesian extension of probabilistic Latent Semantic Analysis (Hofmann, 1999). Given D labeled attribute sets wd, d E D, LDA infers an unstructured set of T latent annotated concepts over which attribute sets decompose as mixtures.2 The latent annotated concepts represent semantically coherent groups of attributes expressed in the data, as shown in Example 1. The generative model for LDA is given by θd|α — Dir(α), d E 1... D βt|η — Dir(η), t E 1... T zi,d|θd — Mult(θd), i E 1 ... |wd| wi,d|βzi,d — Mult(βzi,d), i E 1... |wd| (1) where α and q are hyperparameters smoothing the per-attribute set distribution over concepts and per-concept attribute distribution respectivel</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the 22nd ACM Conference on Research and Development in Information Retrieval (SIGIR-99), pages 50–57, Berkeley, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>A McCallum</author>
</authors>
<title>Pachinko allocation: DAG-structured mixture models of topic correlations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 23rd International Conference on Machine Learning (ICML-06),</booktitle>
<pages>577--584</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="9359" citStr="Li and McCallum, 2006" startWordPosition="1449" endWordPosition="1452"> interested in the case where w is known and we want 2In topic modeling literature, attributes are words and attribute sets are documents. T n � LDA D w w � w T IX 0 z Fixed Structure LDA n D w IX 0 z T c W n 0 D w nCRP w IX 0 z c Y T 621 to compute the conditional posterior of the remaining random variables p(z,,3, 0|w). This distribution can be approximated efficiently using Gibbs sampling. See (Blei et al., 2003b) and (Griffiths and Steyvers, 2002) for more details. 3.2 Fixed-Structure LDA In this paper, we extend LDA to model structural dependencies between latent annotated concepts (cf. (Li and McCallum, 2006; Sivic et al., 2008)); In particular, we fix the concept structure to correspond to the WN Is-A hierarchy. Each labeled attribute set is assigned to a leaf concept in WN based on the edit distance between the concept label and the attribute set label. Possible latent concepts for this set include the concepts along all paths from its attachment point to the WN root, following Is-A relation edges. Therefore, any two labeled attribute sets share a number of latent concepts based on their similarity in WN: all labeled attribute sets share at least the root concept, and may share more concepts de</context>
</contexts>
<marker>Li, McCallum, 2006</marker>
<rawString>W. Li and A. McCallum. 2006. Pachinko allocation: DAG-structured mixture models of topic correlations. In Proceedings of the 23rd International Conference on Machine Learning (ICML-06), pages 577–584, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational linguistics (COLING-02),</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="6345" citStr="Lin and Pantel, 2002" startWordPosition="946" endWordPosition="949"> The remainder of this paper is organized as follows: §2 describes the full ontology annotation framework, §3 introduces the LDA-based topic models, §4 gives the experimental setup, §5 gives results, §6 gives related work and §7 concludes. 2 Ontology Annotation Input to our ontology annotation procedure consists of sets of class instances (e.g., Pisanello, Hieronymus Bosch) associated with class labels (e.g., renaissance painters) and attributes (e.g., “birthplace”, “famous works”, “style” and “early life”). Clusters of noun phrases (instances) are constructed using distributional similarity (Lin and Pantel, 2002; Hearst, 1992) and are labeled by applying “such-as” surface patterns to raw Web text (e.g., “renaissance painters such as Hieronymous Bosch”), yielding 870K instances in more than 4500 classes (Pas¸ca and Van Durme, 2008). Attributes for each flat labeled class are extracted from anonymized Web search query logs using the minimally supervised procedure in (Pas¸ca, 2008)1. Candidate attributes are ranked based on their weighted Jaccard similarity to a set of 5 manually provided seed attributes for the 1Similar query data, including query strings and frequency counts, is available from, e.g., </context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>D. Lin and P. Pantel. 2002. Concept discovery from text. In Proceedings of the 19th International Conference on Computational linguistics (COLING-02), pages 1–7, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>E Alfonseca</author>
</authors>
<title>Web-derived resources for Web Information Retrieval: From conceptual hierarchies to attribute hierarchies.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd International Conference on Research and Development in Information Retrieval (SIGIR-09),</booktitle>
<location>Boston, Massachusetts.</location>
<marker>Pas¸ca, Alfonseca, 2009</marker>
<rawString>M. Pas¸ca and E. Alfonseca. 2009. Web-derived resources for Web Information Retrieval: From conceptual hierarchies to attribute hierarchies. In Proceedings of the 32nd International Conference on Research and Development in Information Retrieval (SIGIR-09), Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
<author>B Van Durme</author>
</authors>
<title>Weaklysupervised acquisition of open-domain classes and class attributes from web documents and query logs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08),</booktitle>
<pages>pages</pages>
<location>Columbus, Ohio.</location>
<marker>Pas¸ca, Van Durme, 2008</marker>
<rawString>M. Pas¸ca and B. Van Durme. 2008. Weaklysupervised acquisition of open-domain classes and class attributes from web documents and query logs. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08), pages 19–27, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
</authors>
<title>Turning Web text and search queries into factual knowledge: Hierarchical class attribute extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI08),</booktitle>
<pages>1225--1230</pages>
<location>Chicago, Illinois.</location>
<marker>Pas¸ca, 2008</marker>
<rawString>M. Pas¸ca. 2008. Turning Web text and search queries into factual knowledge: Hierarchical class attribute extraction. In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI08), pages 1225–1230, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Probst</author>
<author>R Ghani</author>
<author>M Krema</author>
<author>A Fano</author>
<author>Y Liu</author>
</authors>
<title>Semi-supervised learning of attribute-value pairs from product descriptions.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07),</booktitle>
<pages>2838--2843</pages>
<location>Hyderabad, India.</location>
<contexts>
<context position="30115" citStr="Probst et al., 2007" startWordPosition="4855" endWordPosition="4858"> than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristics rather than formal models to estimate the specificity of each attribute. 7 Conclusion This paper introduced a set of methods based on Latent Dirichlet Allocation (LDA) for jointly extending the WORDNET ontology and annotating its concepts with attributes (see Figure 4 for the end result).</context>
</contexts>
<marker>Probst, Ghani, Krema, Fano, Liu, 2007</marker>
<rawString>K. Probst, R. Ghani, M. Krema, A. Fano, and Y. Liu. 2007. Semi-supervised learning of attribute-value pairs from product descriptions. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07), pages 2838–2843, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sivic</author>
<author>B Russell</author>
<author>A Zisserman</author>
<author>W Freeman</author>
<author>A Efros</author>
</authors>
<title>Unsupervised discovery of visual object class hierarchies.</title>
<date>2008</date>
<booktitle>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR-08),</booktitle>
<pages>1--8</pages>
<location>Anchorage, Alaska.</location>
<contexts>
<context position="9380" citStr="Sivic et al., 2008" startWordPosition="1453" endWordPosition="1456"> where w is known and we want 2In topic modeling literature, attributes are words and attribute sets are documents. T n � LDA D w w � w T IX 0 z Fixed Structure LDA n D w IX 0 z T c W n 0 D w nCRP w IX 0 z c Y T 621 to compute the conditional posterior of the remaining random variables p(z,,3, 0|w). This distribution can be approximated efficiently using Gibbs sampling. See (Blei et al., 2003b) and (Griffiths and Steyvers, 2002) for more details. 3.2 Fixed-Structure LDA In this paper, we extend LDA to model structural dependencies between latent annotated concepts (cf. (Li and McCallum, 2006; Sivic et al., 2008)); In particular, we fix the concept structure to correspond to the WN Is-A hierarchy. Each labeled attribute set is assigned to a leaf concept in WN based on the edit distance between the concept label and the attribute set label. Possible latent concepts for this set include the concepts along all paths from its attachment point to the WN root, following Is-A relation edges. Therefore, any two labeled attribute sets share a number of latent concepts based on their similarity in WN: all labeled attribute sets share at least the root concept, and may share more concepts depending on their most</context>
</contexts>
<marker>Sivic, Russell, Zisserman, Freeman, Efros, 2008</marker>
<rawString>J. Sivic, B. Russell, A. Zisserman, W. Freeman, and A. Efros. 2008. Unsupervised discovery of visual object class hierarchies. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR-08), pages 1–8, Anchorage, Alaska.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-06),</booktitle>
<pages>801--808</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="29800" citStr="Snow et al., 2006" startWordPosition="4805" endWordPosition="4808">RR scores for the subset are given in the lower half of Table 2. Averaged over all gold test attributes, DRR scores double when using fsLDA. These results can be misleading, however, due to artificially low coverage. Hence, Table 2 also shows DRR scores broken down over each subhierarchy, In this case fsLDA more than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), w</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>R. Snow, D. Jurafsky, and A. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-06), pages 801–808, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge unifying WordNet and Wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th World Wide Web Conference (WWW-07),</booktitle>
<pages>697--706</pages>
<location>Banff, Canada.</location>
<contexts>
<context position="1611" citStr="Suchanek et al., 2007" startWordPosition="235" endWordPosition="238"> (WN) (Fellbaum, 1998) with additional concepts, and annotating the resulting concept graph with attributes, i.e., generic property fields shared by instances of that concept. Examples of attributes include “height” and “eyecolor” for the concept Person or “gdp” and “president” for Country. Identifying and extracting such attributes relative to a set of flat (i.e., nonhierarchically organized) labeled classes of instances has been extensively studied, using a variety of data, e.g., Web search query logs (Pas¸ca and Van Durme, 2008), Web documents (Yoshinaga and Torisawa, 2007), and Wikipedia (Suchanek et al., 2007; Wu and Weld, 2008). Building on the current state of the art in attribute extraction, we propose a model-based approach for mapping flat sets of attributes annotated with class labels into an existing ontology. This inference problem is divided into two main components: (1) identifying the appropriate parent concept for each labeled class and (2) learning *Contributions made during an internship at Google. the correct level of abstraction for each attribute in the extended ontology. For example, consider the task of annotating WN with the labeled class renaissance painters containing the cla</context>
<context position="29824" citStr="Suchanek et al., 2007" startWordPosition="4809" endWordPosition="4812">ubset are given in the lower half of Table 2. Averaged over all gold test attributes, DRR scores double when using fsLDA. These results can be misleading, however, due to artificially low coverage. Hence, Table 2 also shows DRR scores broken down over each subhierarchy, In this case fsLDA more than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristic</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>F. Suchanek, G. Kasneci, and G. Weikum. 2007. Yago: a core of semantic knowledge unifying WordNet and Wikipedia. In Proceedings of the 16th World Wide Web Conference (WWW-07), pages 697–706, Banff, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tokunaga</author>
<author>J Kazama</author>
<author>K Torisawa</author>
</authors>
<title>Automatic discovery of attribute words from Web documents.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05),</booktitle>
<pages>106--118</pages>
<location>Jeju Island,</location>
<contexts>
<context position="30036" citStr="Tokunaga et al., 2005" startWordPosition="4841" endWordPosition="4844">also shows DRR scores broken down over each subhierarchy, In this case fsLDA more than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristics rather than formal models to estimate the specificity of each attribute. 7 Conclusion This paper introduced a set of methods based on Latent Dirichlet Allocation (LDA) for jointly extending the WORDNET ontology</context>
</contexts>
<marker>Tokunaga, Kazama, Torisawa, 2005</marker>
<rawString>K. Tokunaga, J. Kazama, and K. Torisawa. 2005. Automatic discovery of attribute words from Web documents. In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05), pages 106–118, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Van Durme</author>
<author>T Qian</author>
<author>L Schubert</author>
</authors>
<title>Class-driven attribute extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-2008),</booktitle>
<pages>921--928</pages>
<location>Manchester, United Kingdom.</location>
<marker>Van Durme, Qian, Schubert, 2008</marker>
<rawString>B. Van Durme, T. Qian, and L. Schubert. 2008. Class-driven attribute extraction. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-2008), pages 921–928, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
<author>D M Tice</author>
</authors>
<title>Building a question-answering test collection.</title>
<date>2000</date>
<booktitle>In Proceedings of the 23rd International Conference on Research and Development in Information Retrieval (SIGIR00),</booktitle>
<pages>200--207</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="21837" citStr="Voorhees and Tice, 2000" startWordPosition="3456" endWordPosition="3459">ring the average precision of the reranked attributes, it is also useful to evaluate the assignment of attributes to WN concepts. For this evaluation, human annotators were asked to determine the most appropriate WN synset(s) for a set of gold attributes, taking into account polysemous usage. For each model, ranked lists of possible concept assignments C(w) are generated for each attribute w, using L(c|w) for ranking. The accuracy of a list C(w) for an attribute w is measured by a scoring metric that corresponds to a modification (Pas¸ca and Alfonseca, 2009) of the mean reciprocal rank score (Voorhees and Tice, 2000): 1 DRR = max rank(c) x (1 + PathToGold) where rank(c) is the rank (from 1 up to 10) of a concept c in C(w), and PathToGold is the length of the minimum path along Is-A edges in the conceptual hierarchies between the concept c, on one hand, and any of the gold-standard concepts manually identified for the attribute w, on the other hand. The length PathToGold is 0, if the returned concept is the same as the gold-standard concept. Conversely, a gold-standard attribute receives no credit (that is, DRR is 0) if no path is found in the hierarchies between the top 10 concepts of C(w) and any of the </context>
</contexts>
<marker>Voorhees, Tice, 2000</marker>
<rawString>E.M. Voorhees and D.M. Tice. 2000. Building a question-answering test collection. In Proceedings of the 23rd International Conference on Research and Development in Information Retrieval (SIGIR00), pages 200–207, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wu</author>
<author>D Weld</author>
</authors>
<title>Automatically refining the Wikipedia infobox ontology.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th World Wide Web Conference (WWW-08),</booktitle>
<pages>635--644</pages>
<location>Beijing, China.</location>
<contexts>
<context position="1631" citStr="Wu and Weld, 2008" startWordPosition="239" endWordPosition="242">with additional concepts, and annotating the resulting concept graph with attributes, i.e., generic property fields shared by instances of that concept. Examples of attributes include “height” and “eyecolor” for the concept Person or “gdp” and “president” for Country. Identifying and extracting such attributes relative to a set of flat (i.e., nonhierarchically organized) labeled classes of instances has been extensively studied, using a variety of data, e.g., Web search query logs (Pas¸ca and Van Durme, 2008), Web documents (Yoshinaga and Torisawa, 2007), and Wikipedia (Suchanek et al., 2007; Wu and Weld, 2008). Building on the current state of the art in attribute extraction, we propose a model-based approach for mapping flat sets of attributes annotated with class labels into an existing ontology. This inference problem is divided into two main components: (1) identifying the appropriate parent concept for each labeled class and (2) learning *Contributions made during an internship at Google. the correct level of abstraction for each attribute in the extended ontology. For example, consider the task of annotating WN with the labeled class renaissance painters containing the class instances Pisanel</context>
<context position="30159" citStr="Wu and Weld, 2008" startWordPosition="4864" endWordPosition="4867">e for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristics rather than formal models to estimate the specificity of each attribute. 7 Conclusion This paper introduced a set of methods based on Latent Dirichlet Allocation (LDA) for jointly extending the WORDNET ontology and annotating its concepts with attributes (see Figure 4 for the end result). LDA significantly outperformed a previous a</context>
</contexts>
<marker>Wu, Weld, 2008</marker>
<rawString>F. Wu and D. Weld. 2008. Automatically refining the Wikipedia infobox ontology. In Proceedings of the 17th World Wide Web Conference (WWW-08), pages 635–644, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Yoshinaga</author>
<author>K Torisawa</author>
</authors>
<title>Open-domain attribute-value acquisition from semi-structured texts.</title>
<date>2007</date>
<booktitle>In Proceedings of the 6th International Semantic Web Conference (ISWC-07), Workshop on Text to Knowledge: The Lexicon/Ontology Interface (OntoLex-2007),</booktitle>
<pages>55--66</pages>
<location>Busan, South</location>
<contexts>
<context position="1573" citStr="Yoshinaga and Torisawa, 2007" startWordPosition="229" endWordPosition="232">s-A hierarchies such as those found in WORDNET (WN) (Fellbaum, 1998) with additional concepts, and annotating the resulting concept graph with attributes, i.e., generic property fields shared by instances of that concept. Examples of attributes include “height” and “eyecolor” for the concept Person or “gdp” and “president” for Country. Identifying and extracting such attributes relative to a set of flat (i.e., nonhierarchically organized) labeled classes of instances has been extensively studied, using a variety of data, e.g., Web search query logs (Pas¸ca and Van Durme, 2008), Web documents (Yoshinaga and Torisawa, 2007), and Wikipedia (Suchanek et al., 2007; Wu and Weld, 2008). Building on the current state of the art in attribute extraction, we propose a model-based approach for mapping flat sets of attributes annotated with class labels into an existing ontology. This inference problem is divided into two main components: (1) identifying the appropriate parent concept for each labeled class and (2) learning *Contributions made during an internship at Google. the correct level of abstraction for each attribute in the extended ontology. For example, consider the task of annotating WN with the labeled class r</context>
<context position="30094" citStr="Yoshinaga and Torisawa, 2007" startWordPosition="4850" endWordPosition="4854">archy, In this case fsLDA more than doubles the DRR relative to the baseline for substance and location, and triples it for organization and food. ated for LDA or nCRP, because they are not mapped to WN. 6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly. Previous literature in attribute extraction takes advantage of a range of data sources and extraction procedures (Chklovski and Gil, 2005; Tokunaga et al., 2005; Pas¸ca and Van Durme, 2008; Yoshinaga and Torisawa, 2007; Probst et al., 2007; Van Durme et al., 2008; Wu and Weld, 2008). However these methods do not address the task of determining the level of specificity for each attribute. The closest studies to ours are (Pas¸ca, 2008), implemented as the baseline method in this paper; and (Pas¸ca and Alfonseca, 2009), which relies on heuristics rather than formal models to estimate the specificity of each attribute. 7 Conclusion This paper introduced a set of methods based on Latent Dirichlet Allocation (LDA) for jointly extending the WORDNET ontology and annotating its concepts with attributes (see Figure 4</context>
</contexts>
<marker>Yoshinaga, Torisawa, 2007</marker>
<rawString>N. Yoshinaga and K. Torisawa. 2007. Open-domain attribute-value acquisition from semi-structured texts. In Proceedings of the 6th International Semantic Web Conference (ISWC-07), Workshop on Text to Knowledge: The Lexicon/Ontology Interface (OntoLex-2007), pages 55–66, Busan, South Korea.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>