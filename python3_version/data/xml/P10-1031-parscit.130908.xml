<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000139">
<title confidence="0.935079">
Unsupervised Ontology Induction from Text
</title>
<author confidence="0.992319">
Hoifung Poon and Pedro Domingos
</author>
<affiliation confidence="0.9980775">
Department of Computer Science &amp; Engineering
University of Washington
</affiliation>
<email confidence="0.998371">
hoifung,pedrod@cs.washington.edu
</email>
<sectionHeader confidence="0.994794" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999851541666667">
Extracting knowledge from unstructured
text is a long-standing goal of NLP. Al-
though learning approaches to many of its
subtasks have been developed (e.g., pars-
ing, taxonomy induction, information ex-
traction), all end-to-end solutions to date
require heavy supervision and/or manual
engineering, limiting their scope and scal-
ability. We present OntoUSP, a system that
induces and populates a probabilistic on-
tology using only dependency-parsed text
as input. OntoUSP builds on the USP
unsupervised semantic parser by jointly
forming ISA and IS-PART hierarchies of
lambda-form clusters. The ISA hierar-
chy allows more general knowledge to
be learned, and the use of smoothing for
parameter estimation. We evaluate On-
toUSP by using it to extract a knowledge
base from biomedical abstracts and an-
swer questions. OntoUSP improves on
the recall of USP by 47% and greatly
outperforms previous state-of-the-art ap-
proaches.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982208333333">
Knowledge acquisition has been a major goal of
NLP since its early days. We would like comput-
ers to be able to read text and express the knowl-
edge it contains in a formal representation, suit-
able for answering questions and solving prob-
lems. However, progress has been difficult. The
earliest approaches were manual, but the sheer
amount of coding and knowledge engineering
needed makes them very costly and limits them to
well-circumscribed domains. More recently, ma-
chine learning approaches to a number of key sub-
problems have been developed (e.g., Snow et al.
(2006)), but to date there is no sufficiently auto-
matic end-to-end solution. Most saliently, super-
vised learning requires labeled data, which itself is
costly and infeasible for large-scale, open-domain
knowledge acquisition.
Ideally, we would like to have an end-to-end un-
supervised (or lightly supervised) solution to the
problem of knowledge acquisition from text. The
TextRunner system (Banko et al., 2007) can ex-
tract a large number of ground atoms from the
Web using only a small number of seed patterns
as guidance, but it is unable to extract non-atomic
formulas, and the mass of facts it extracts is un-
structured and very noisy. The USP system (Poon
and Domingos, 2009) can extract formulas and ap-
pears to be fairly robust to noise. However, it is
still limited to extractions for which there is sub-
stantial evidence in the corpus, and in most cor-
pora most pieces of knowledge are stated only
once or a few times, making them very difficult to
extract without supervision. Also, the knowledge
extracted is simply a large set of formulas with-
out ontological structure, and the latter is essential
for compact representation and efficient reasoning
(Staab and Studer, 2004).
We propose OntoUSP (Ontological USP), a sys-
tem that learns an ISA hierarchy over clusters of
logical expressions, and populates it by translat-
ing sentences to logical form. OntoUSP is en-
coded in a few formulas of higher-order Markov
logic (Domingos and Lowd, 2009), and can be
viewed as extending USP with the capability to
perform hierarchical (as opposed to flat) cluster-
ing. This clustering is then used to perform hier-
archical smoothing (a.k.a. shrinkage), greatly in-
creasing the system’s capability to generalize from
</bodyText>
<page confidence="0.974859">
296
</page>
<note confidence="0.944055">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 296–305,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.997309625">
sparse data.
We begin by reviewing the necessary back-
ground. We then present the OntoUSP Markov
logic network and the inference and learning al-
gorithms used with it. Finally, experiments on
a biomedical knowledge acquisition and question
answering task show that OntoUSP can greatly
outperform USP and previous systems.
</bodyText>
<sectionHeader confidence="0.997432" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.994703">
2.1 Ontology Learning
</subsectionHeader>
<bodyText confidence="0.99984017948718">
In general, ontology induction (constructing an
ontology) and ontology population (mapping tex-
tual expressions to concepts and relations in the
ontology) remain difficult open problems (Staab
and Studer, 2004). Recently, ontology learn-
ing has attracted increasing interest in both NLP
and semantic Web communities (Cimiano, 2006;
Maedche, 2002), and a number of machine learn-
ing approaches have been developed (e.g., Snow
et al. (2006), Cimiano (2006), Suchanek et al.
(2008,2009), Wu &amp; Weld (2008)). However, they
are still limited in several aspects. Most ap-
proaches induce and populate a deterministic on-
tology, which does not capture the inherent un-
certainty among the entities and relations. Be-
sides, many of them either bootstrap from heuris-
tic patterns (e.g., Hearst patterns (Hearst, 1992))
or build on existing structured or semi-structured
knowledge bases (e.g., WordNet (Fellbaum, 1998)
and Wikipedia1), thus are limited in coverage.
Moreover, they often focus on inducing ontology
over individual words rather than arbitrarily large
meaning units (e.g., idioms, phrasal verbs, etc.).
Most importantly, existing approaches typically
separate ontology induction from population and
knowledge extraction, and pursue each task in a
standalone fashion. While computationally effi-
cient, this is suboptimal. The resulted ontology
is disconnected from text and requires additional
effort to map between the two (Tsujii, 2004). In
addition, this fails to leverage the intimate connec-
tions between the three tasks for joint inference
and mutual disambiguiation.
Our approach differs from existing ones in two
main aspects: we induce a probabilistic ontology
from text, and we do so by jointly conducting on-
tology induction, population, and knowledge ex-
traction. Probabilistic modeling handles uncer-
tainty and noise. A joint approach propagates in-
</bodyText>
<footnote confidence="0.948018">
1http : //www.wikipedia.org
</footnote>
<bodyText confidence="0.99996">
formation among the three tasks, uncovers more
implicit information from text, and can potentially
work well even in domains not well covered by
existing resources like WordNet and Wikipedia.
Furthermore, we leverage the ontology for hierar-
chical smoothing and incorporate this smoothing
into the induction process. This facilitates more
accurate parameter estimation and better general-
ization.
Our approach can also leverage existing on-
tologies and knowledge bases to conduct semi-
supervised ontology induction (e.g., by incorpo-
rating existing structures as hard constraints or pe-
nalizing deviation from them).
</bodyText>
<subsectionHeader confidence="0.998931">
2.2 Markov Logic
</subsectionHeader>
<bodyText confidence="0.999840153846154">
Combining uncertainty handling and joint infer-
ence is the hallmark of the emerging field of statis-
tical relational learning (a.k.a. structured predic-
tion), where a plethora of approaches have been
developed (Getoor and Taskar, 2007; Bakir et al.,
2007). In this paper, we use Markov logic (Domin-
gos and Lowd, 2009), which is the leading unify-
ing framework, but other approaches can be used
as well. Markov logic is a probabilistic exten-
sion of first-order logic and can compactly specify
probability distributions over complex relational
domains. It has been successfully applied to un-
supervised learning for various NLP tasks such
as coreference resolution (Poon and Domingos,
2008) and semantic parsing (Poon and Domingos,
2009). A Markov logic network (MLN) is a set of
weighted first-order clauses. Together with a set
of constants, it defines a Markov network with one
node per ground atom and one feature per ground
clause. The weight of a feature is the weight of the
first-order clause that originated it. The probabil-
ity of a state x in such a network is given by the
log-linear model P(x) = 1Z exp (Ei wini(x)),
where Z is a normalization constant, wi is the
weight of the ith formula, and ni is the number
of satisfied groundings.
</bodyText>
<subsectionHeader confidence="0.998962">
2.3 Unsupervised Semantic Parsing
</subsectionHeader>
<bodyText confidence="0.99993975">
Semantic parsing aims to obtain a complete canon-
ical meaning representation for input sentences. It
can be viewed as a structured prediction problem,
where a semantic parse is formed by partitioning
the input sentence (or a syntactic analysis such as
a dependency tree) into meaning units and assign-
ing each unit to the logical form representing an
entity or relation (Figure 1). In effect, a semantic
</bodyText>
<page confidence="0.997635">
297
</page>
<figureCaption confidence="0.979133">
Figure 1: An example of semantic parsing. Top:
semantic parsing converts an input sentence into
logical form in Davidsonian semantics. Bottom: a
semantic parse consists of a partition of the depen-
dency tree and an assignment of its parts.
</figureCaption>
<bodyText confidence="0.998949931034483">
parser extracts knowledge from input text and con-
verts them into logical form (the semantic parse),
which can then be used in logical and probabilistic
inference and support end tasks such as question
answering.
A major challenge to semantic parsing is syn-
tactic and lexical variations of the same mean-
ing, which abound in natural languages. For ex-
ample, the fact that IL-4 protein induces CD11b
can be expressed in a variety of ways, such
as, “Interleukin-4 enhances the expression of
CD11b”, “CD11b is upregulated by IL-4”, etc.
Past approaches either manually construct a gram-
mar or require example sentences with meaning
annotation, and do not scale beyond restricted do-
mains.
Recently, we developed the USP system (Poon
and Domingos, 2009), the first unsupervised ap-
proach for semantic parsing.2 USP inputs de-
pendency trees of sentences and first transforms
them into quasi-logical forms (QLFs) by convert-
ing each node to a unary atom and each depen-
dency edge to a binary atom (e.g., the node for
“induces” becomes induces(e1) and the subject
dependency becomes nsubj(e1, e2), where ei’s
are Skolem constants indexed by the nodes.).3
For each sentence, a semantic parse comprises of
a partition of its QLF into subexpressions, each
of which has a naturally corresponding lambda
</bodyText>
<footnote confidence="0.9964866">
2In this paper, we use a slightly different formulation of
USP and its MLN to facilitate the exposition of OntoUSP.
3We call these QLFs because they are not true logical
form (the ambiguities are not yet resolved). This is related
to but not identical with the definition in Alshawi (1990).
</footnote>
<figureCaption confidence="0.945914333333333">
Figure 2: An example of object/property clusters:
INDUCE contains the core-form property cluster
and others, such as the agent argument INDUCER.
</figureCaption>
<bodyText confidence="0.991990314285714">
form,4 and an assignment of each subexpression
to a lambda-form cluster.
The lambda-form clusters naturally form an IS-
PART hierarchy (Figure 2). An object cluster cor-
responds to semantic concepts or relations such as
INDUCE, and contains a variable number of prop-
erty clusters. A special property cluster of core
forms maintains a distribution over variations in
lambda forms for expressing this concept or rela-
tion. Other property clusters correspond to modi-
fiers or arguments such as INDUCER (the agent ar-
gument of INDUCE), each of which in turn con-
tains three subclusters of property values: the
argument-object subcluster maintains a distribu-
tion over object clusters that may occur in this
argument (e.g., IL − 4), the argument-form sub-
cluster maintains a distribution over lambda forms
that corresponds to syntactic variations for this ar-
gument (e.g., nsubj in active voice and agent in
passive voice), and the argument-number subclus-
ter maintains a distribution over total numbers of
this argument that may occur in a sentence (e.g.,
zero if the argument is not mentioned).
Effectively, USP simultaneously discovers the
lambda-form clusters and an IS-PART hierarchy
among them. It does so by recursively combining
subexpressions that are composed with or by sim-
ilar subexpressions. The partition breaks a sen-
tence into subexpressions that are meaning units,
and the clustering abstracts away syntactic and
lexical variations for the same meaning. This
novel form of relational clustering is governed by
a joint probability distribution P(T, L) defined in
higher-order5 Markov logic, where T are the input
dependency trees, and L the semantic parses. The
</bodyText>
<footnote confidence="0.995805166666667">
4The lambda form is derived by replacing every Skolem
constant ei that does not appear in any unary atom in the
subexpression with a lambda variable xi that is uniquely in-
dexed by the corresponding node i. For example, the lambda
form for nsubj(e1, e2) is ax1ax2.nsubj(x1, x2).
5Variables can range over arbitrary lambda forms.
</footnote>
<figure confidence="0.998532027777778">
IL-4 protein
induces CD11b
INDUCE(e1)
INDUCER(e1,e2) INDUCED(e1,e3)
IL-4(e2) CD11B(e3)
induces
induces
INDUCE
nsubj dobj
protein CD11b
protein CD11b
CD11B
nn
nn
IL-4
IL-4
IL-4
Structured prediction: Partition + Assignment
INDUCER nsubj dobj INDUCED
induces 0.1
enhances 0.4
Core Form
...
nsubj
agent
Object Cluster: INDUCE
...
Property Cluster: INDUCER
0.5
0.4
IL-8 0.1
IL-4 0.2
...
None 0.1
One 0.8
...
</figure>
<page confidence="0.987343">
298
</page>
<bodyText confidence="0.97882379245283">
main predicates are:
e E c: expression e is assigned to cluster c;
SubExpr(s, e): s is a subexpression of e;
HasValue(s, v): s is of value v;
IsPart(c, i, p): p is the property cluster in ob-
ject cluster c uniquely indexed by i.
In USP, property clusters in different object clus-
ters use distinct index i’s. As we will see later,
in OntoUSP, property clusters with ISA relation
share the same index i, which corresponds to a
generic semantic frame such as agent and patient.
The probability model of USP can be captured
by two formulas:
x E +p n HasValue(x, +v)
e E c n SubExpr(x, e) n x E p
==&gt;. 11i.IsPart(c,i,p).
All free variables are implicitly universally
quantified. The “+” notation signifies that the
MLN contains an instance of the formula, with
a separate weight, for each value combination of
the variables with a plus sign. The first formula is
the core of the model and represents the mixture
of property values given the cluster. The second
formula ensures that a property cluster must be a
part in the corresponding object cluster; it is a hard
constraint, as signified by the period at the end.
To encourage clustering, USP imposes an expo-
nential prior over the number of parameters.
To parse a new sentence, USP starts by parti-
tioning the QLF into atomic forms, and then hill-
climbs on the probability using a search operator
based on lambda reduction until it finds the max-
imum a posteriori (MAP) parse. During learn-
ing, USP starts with clusters of atomic forms,
maintains the optimal semantic parses according
to current parameters, and hill-climbs on the log-
likelihood of observed QLFs using two search op-
erators:
MERGE(c1, c2) merges clusters c1, c2 into a larger
cluster c by merging the core-form clusters
and argument clusters of c1, c2, respectively.
E.g., c1 = {“induce”}, c2 = {“enhance”},
and c = {“induce”, “enhance”}.
COMPOSE(c1, c2) creates a new lambda-form
cluster c formed by composing the lambda
forms in c1, c2 into larger ones. E.g., c1 =
{“amino”}, c2 = {“acid”}, and c =
{“amino acid”}.
Each time, USP executes the highest-scored op-
erator and reparses affected sentences using the
new parameters. The output contains the optimal
lambda-form clusters and parameters, as well as
the MAP semantic parses of input sentences.
</bodyText>
<sectionHeader confidence="0.7753875" genericHeader="method">
3 Unsupervised Ontology Induction with
Markov Logic
</sectionHeader>
<bodyText confidence="0.999950651162791">
A major limitation of USP is that it either merges
two object clusters into one, or leaves them sepa-
rate. This is suboptimal, because different object
clusters may still possess substantial commonali-
ties. Modeling these can help extract more gen-
eral knowledge and answer many more questions.
The best way to capture such commonalities is
by forming an ISA hierarchy among the clusters.
For example, INDUCE and INHIBIT are both sub-
concepts of REGULATE. Learning these ISA rela-
tions helps answer questions like “What regulates
CD11b?”, when the text states that “IL-4 induces
CD11b” or “AP-1 suppresses CD11b”.
For parameter learning, this is also undesirable.
Without the hierarchical structure, each cluster es-
timates its parameters solely based on its own ob-
servations, which can be extremely sparse. The
better solution is to leverage the hierarchical struc-
ture for smoothing (a.k.a. shrinkage (McCallum et
al., 1998; Gelman and Hill, 2006)). For example,
if we learn that “super-induce” is a verb and that in
general verbs have active and passive voices, then
even though “super-induce” only shows up once
in the corpus as in “AP-1 is super-induced by IL-
4”, by smoothing we can still infer that this proba-
bly means the same as “IL-4 super-induces AP-1”,
which in turn helps answer questions like “What
super-induces AP-1”.
OntoUSP overcomes the limitations of USP by
replacing the flat clustering process with a hier-
archical clustering one, and learns an ISA hier-
archy of lambda-form clusters in addition to the
IS-PART one. The output of OntoUSP consists
of an ontology, a semantic parser, and the MAP
parses. In effect, OntoUSP conducts ontology in-
duction, population, and knowledge extraction in a
single integrated process. Specifically, given clus-
ters c1, c2, in addition to merge vs. separate, On-
toUSP evaluates a third option called abstraction,
in which a new object cluster c is created, and ISA
links are added from ci to c; the argument clusters
in c are formed by merging that of ci’s.
In the remainder of the section, we describe the
</bodyText>
<page confidence="0.991299">
299
</page>
<bodyText confidence="0.989578833333333">
details of OntoUSP. We start by presenting the
OntoUSP MLN. We then describe our inference
algorithm and how to parse a new sentence us-
ing OntoUSP. Finally, we describe the learning al-
gorithm and how OntoUSP induces the ontology
while learning the semantic parser.
</bodyText>
<subsectionHeader confidence="0.995482">
3.1 The OntoUSP MLN
</subsectionHeader>
<bodyText confidence="0.999956714285714">
The OntoUSP MLN can be obtained by modifying
the USP MLN with three simple changes. First,
we introduce a new predicate IsA(c1, c2), which
is true if cluster c1 is a subconcept of c2. For con-
venience, we stipulate that IsA is reflexive (i.e.,
IsA(c, c) is true for any c). Second, we add two
formulas to the MLN:
</bodyText>
<equation confidence="0.998342666666667">
IsA(c1, c2) n IsA(c2, c3) ==&gt; IsA(c1, c3).
IsPart(c1, i1, p1) n IsPart(c2, i2, p2)
n IsA(c1, c2) ==&gt; (i1 = i2 &apos;#? IsA(p1, p2)).
</equation>
<bodyText confidence="0.993768956521739">
The first formula simply enforces the transitivity
of ISA relation. The second formula states that if
the ISA relation holds for a pair of object clusters,
it also holds between their corresponding property
clusters. Both are hard constraints. Third, we in-
troduce hierarchical smoothing into the model by
replacing the USP mixture formula
x E +p n HasValue(x, +v)
with a new formula
ISA(p1, +p2) n x E p1 n HasValue(x, +v)
Intuitively, for each p2, the weight corresponds to
the delta in log-probability of v comparing to the
prediction according to all ancestors of p2. The
effect of this change is that now the value v of
a subexpression x is not solely determined by its
property cluster p1, but is also smoothed by statis-
tics of all p2 that are super clusters of p1.
Shrinkage takes place via interaction among the
weights of the ISA mixture formula. In particular,
if the weights for some property cluster p are all
zero, it means that values in p are completely pre-
dicted by p’s ancestors. In effect, p is backed off
to its parent.
</bodyText>
<subsectionHeader confidence="0.877298">
3.2 Inference
</subsectionHeader>
<bodyText confidence="0.9995755">
Given the dependency tree T of a sentence, the
conditional probability of a semantic parse L is
given by Pr(L|T) a exp (&amp; wini(T, L)).
The MAP semantic parse is simply
</bodyText>
<figure confidence="0.7473175">
Algorithm 1 OntoUSP-Parse(MLN, T)
Initialize semantic parse L with individual
atoms in the QLF of T
repeat
for all subexpressions e in L do
Evaluate all semantic parses that are
lambda-reducible from e
end for
L +— the new semantic parse with the highest
gain in probability
until none of these improve the probability
return L
�
arg maxL i wini(T, L). Directly enumer-
</figure>
<bodyText confidence="0.968338">
ating all L’s is intractable. OntoUSP uses the
same inference algorithm as USP by hill-climbing
on the probability of L; in each step, OntoUSP
evaluates the alternative semantic parses that
can be formed by lambda-reducing a current
subexpression with one of its arguments. The only
difference is that OntoUSP uses a different MLN
and so the probabilities and resulting semantic
parses may be different. Algorithm 1 gives
pseudo-code for OntoUSP’s inference algorithm.
</bodyText>
<subsectionHeader confidence="0.997458">
3.3 Learning
</subsectionHeader>
<bodyText confidence="0.99999125">
OntoUSP uses the same learning objective as USP,
i.e., to find parameters 0 that maximizes the log-
likelihood of observing the dependency trees T,
summing out the unobserved semantic parses L:
</bodyText>
<equation confidence="0.995898">
Lθ(T) = log Pθ(L)
= log EL Pθ(T, L)
</equation>
<bodyText confidence="0.999969833333333">
However, the learning problem in OntoUSP is
distinct in two important aspects. First, OntoUSP
learns in addition an ISA hierarchy among the
lambda-form clusters. Second and more impor-
tantly, OntoUSP leverages this hierarchy during
learning to smooth the parameter estimation of in-
dividual clusters, as embodied by the new ISA
mixture formula in the OntoUSP MLN.
OntoUSP faces several new challenges unseen
in previous hierarchical-smoothing approaches.
The ISA hierarchy in OntoUSP is not known in
advance, but needs to be learned as well. Simi-
larly, OntoUSP has no known examples of pop-
ulated facts and rules in the ontology, but has to
infer that in the same joint learning process. Fi-
nally, OntoUSP does not start from well-formed
structured input like relational tuples, but rather
directly from raw text. In sum, OntoUSP tackles a
</bodyText>
<page confidence="0.98124">
300
</page>
<figure confidence="0.927983666666667">
Algorithm 2 OntoUSP-Learn(MLN, T’s)
Initialize with a flat ontology, along with clus-
ters and semantic parses
Merge clusters with the same core form
Agenda 0
repeat
for all candidate operations O do
Score O by log-likelihood improvement
if score is above a threshold then
Add O to agenda
end if
end for
Execute the highest scoring operation O* in
the agenda
Regenerate MAP parses for affected trees and
</figure>
<bodyText confidence="0.915408588235294">
update agenda and candidate operations
until agenda is empty
return the learned ontology and MLN, and the
semantic parses
very hard problem with exceedingly little aid from
user supervision.
To combat these challenges, OntoUSP adopts
a novel form of hierarchical smoothing by inte-
grating it with the search process for identify-
ing the hierarchy. Algorithm 2 gives pseudo-
code for OntoUSP’s learning algorithm. Like
USP, OntoUSP approximates the sum over all
semantic parses with the most probable parse,
and searches for both 0 and the MAP semantic
parses L that maximize P0(T,L). In addition to
MERGE and COMPOSE, OntoUSP uses a new opera-
tor ABSTRACT(ci, c2), which does the following:
</bodyText>
<listItem confidence="0.711749375">
1. Create an abstract cluster c;
2. Create ISA links from ci, c2 to c;
3. Align property clusters of ci and c2; for each
aligned pair pi and p2, either merge them
into a single property cluster, or create an ab-
stract property cluster p in c and create ISA
links from pi to p, so as to maximize log-
likelihood.
</listItem>
<bodyText confidence="0.9915984">
Intuitively, c corresponds to a more abstract con-
cept that summarizes similar properties in ci’s.
To add a child cluster c2 to an existing ab-
stract cluster ci, OntoUSP also uses an operator
ADDCHILD(ci, c2) that does the following:
</bodyText>
<listItem confidence="0.973479333333333">
1. Create an ISA link from c2 to cl;
2. For each property cluster of c2, maximize the
log-likelihood by doing one of the following:
</listItem>
<bodyText confidence="0.999820470588235">
merge it with a property cluster in an exist-
ing child of ci; create ISA link from it to
an abstract property cluster in c; leave it un-
changed.
For efficiency, in both operators, the best option
is chosen greedily for each property cluster in c2,
in descending order of cluster size.
Notice that once an abstract cluster is created,
it could be merged with an existing cluster using
MERGE. Thus with the new operators, OntoUSP
is capable of inducing any ISA hierarchy among
abstract and existing clusters. (Of course, the ISA
hierarchy it actually induces depends on the data.)
Learning the shrinkage weights has been ap-
proached in a variety of ways; examples include
EM and cross-validation (McCallum et al., 1998),
hierarchical Bayesian methods (Gelman and Hill,
2006), and maximum entropy with Li priors
(Dudik et al., 2007). The past methods either only
learn parameters with one or two levels (e.g., in
hierarchical Bayes), or requires significant amount
of computation (e.g., in EM and in Li-regularized
maxent), while also typically assuming a given
hierarchy. In contrast, OntoUSP has to both in-
duce the hierarchy and populate it, with potentially
many levels in the induced hierarchy, starting from
raw text with little user supervision.
Therefore, OntoUSP simplifies the weight
learning problem by adopting standard m-
estimation for smoothing. Namely, the weights
for cluster c are set by counting its observations
plus m fractional samples from its parent distribu-
tion. When c has few observations, its unreliable
statistics can be significantly augmented via the
smoothing by its parent (and in turn to a gradually
smaller degree by its ancestors). m is a hyperpa-
rameter that can be used to trade off bias towards
statistics for parent vs oneself.
OntoUSP also needs to balance between two
conflicting aspects during learning. On one hand,
it should encourage creating abstract clusters to
summarize intrinsic commonalities among the
children. On the other hand, this needs to be heav-
ily regularized to avoid mistaking noise for the sig-
nal. OntoUSP does this by a combination of priors
and thresholding. To encourage the induction of
higher-level nodes and inheritance, OntoUSP im-
poses an exponential prior Q on the number of pa-
rameter slots. Each slot corresponds to a distinct
property value. A child cluster inherits its parent’s
slots (and thus avoids the penalty on them). On-
</bodyText>
<page confidence="0.997605">
301
</page>
<bodyText confidence="0.999874125">
toUSP also stipulates that, in an ABSTRACT opera-
tion, a new property cluster can be created either as
a concrete cluster with full parameterization, or as
an abstract cluster that merely serves for smooth-
ing purposes. To discourage overproposing clus-
ters and ISA links, OntoUSP imposes a large ex-
ponential prior -y on the number of concrete clus-
ters created by ABSTRACT. For abstract cluster, it
sets a cut-off tp and only allows storing a probabil-
ity value no less than tp. Like USP, it also rejects
MERGE and COMPOSE operations that improve log-
likelihood by less than to. These priors and cut-off
values can be tuned to control the granularity of
the induced ontology and clusters.
Concretely, given semantic parses L, OntoUSP
computes the optimal parameters and evaluates
the regularized log-likelihood as follows. Let
wp,,v denote the weight of the ISA mixture for-
mula ISA(p1, +p2) n x E p1 n HasValue(x, +v).
For convenience, for each pair of property clus-
ter c and value v, OntoUSP instead computes
and stores w&apos;c,v = EISA(c, a) wa,v, which sums
over all weights for c and its ancestors. (Thus
wc,v = w&apos;c,v − w&apos;p,v, where p is the parent of
c.) Like USP, OntoUSP imposes local normal-
ization constraints that enable closed-form esti-
mation of the optimal parameters and likelihood.
Specifically, using m-estimation, the optimal w&apos;c,v
is log((m ew�p,v +nc,v)/(m+nc)), where p is the
parent of c and n is the count. The log-likelihood
is Ec,v w&apos;c,v nc,v, which is then augmented by the
priors.
</bodyText>
<sectionHeader confidence="0.998372" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.978199">
4.1 Methodology
</subsectionHeader>
<bodyText confidence="0.995944923076923">
Evaluating unsupervised ontology induction is dif-
ficult, because there is no gold ontology for com-
parison. Moreover, our ultimate goal is to aid
knowledge acquisition, rather than just inducing
an ontology for its own sake. Therefore, we
used the same methodology and dataset as the
USP paper to evaluate OntoUSP on its capabil-
ity in knowledge acquisition. Specifically, we ap-
plied OntoUSP to extract knowledge from the GE-
NIA dataset (Kim et al., 2003) and answer ques-
tions, and we evaluated it on the number of ex-
tracted answers and accuracy. GENIA contains
1999 PubMed abstracts.6 The question set con-
</bodyText>
<footnote confidence="0.716522">
6http://www-tsujii.is.s.u-tokyo-
.ac.jp/GENIA/home/wiki.cgi.
</footnote>
<bodyText confidence="0.999469875">
tains 2000 questions which were created by sam-
pling verbs and entities according to their frequen-
cies in GENIA. Sample questions include “What
regulates MIP-1alpha?”, “What does anti-STAT 1
inhibit?”. These simple question types were used
to focus the evaluation on the knowledge extrac-
tion aspect, rather than engineering for handling
special question types and/or reasoning.
</bodyText>
<subsectionHeader confidence="0.991001">
4.2 Systems
</subsectionHeader>
<bodyText confidence="0.998466634146341">
OntoUSP is the first unsupervised approach that
synergistically conducts ontology induction, pop-
ulation, and knowledge extraction. The system
closest in aim and capability is USP. We thus com-
pared OntoUSP with USP and all other systems
evaluated in the USP paper (Poon and Domingos,
2009). Below is a brief description of the systems.
(For more details, see Poon &amp; Domingos (2009).)
Keyword is a baseline system based on keyword
matching. It directly matches the question sub-
string containing the verb and the available argu-
ment with the input text, ignoring case and mor-
phology. Given a match, two ways to derive the
answer were considered: KW simply returns the
rest of sentence on the other side of the verb,
whereas KW-SYN is informed by syntax and ex-
tracts the answer from the subject or object of the
verb, depending on the question (if the expected
argument is absent, the sentence is ignored).
TextRunner (Banko et al., 2007) is the state-of-
the-art system for open-domain information ex-
traction. It inputs text and outputs relational triples
in the form (R, A1, A2), where R is the relation
string, and A1, A2 the argument strings. To an-
swer questions, each triple-question pair is consid-
ered in turn by first matching their relation strings,
and then the available argument strings. If both
match, the remaining argument string in the triple
is returned as an answer. Results were reported
when exact match is used (TR-EXACT), or when
the triple strings may contain the question ones as
substrings (TR-SUB).
RESOLVER (Yates and Etzioni, 2009) inputs
TextRunner triples and collectively resolves coref-
erent relation and argument strings. To answer
questions, the only difference from TextRunner is
that a question string can match any string in its
cluster. As in TextRunner, results were reported
for both exact match (RS-EXACT) and substring
(RS-SUB).
DIRT (Lin and Pantel, 2001) resolves binary rela-
</bodyText>
<page confidence="0.998136">
302
</page>
<tableCaption confidence="0.85724525">
Table 1: Comparison of question answering re-
sults on the GENIA dataset. Results for systems
other than OntoUSP are from Poon &amp; Domingos
(2009).
</tableCaption>
<table confidence="0.9998029">
# Total # Correct Accuracy
KW 150 67 45%
KW-SYN 87 67 77%
TR-EXACT 29 23 79%
TR-SUB 152 81 53%
RS-EXACT 53 24 45%
RS-SUB 196 81 41%
DIRT 159 94 59%
USP 334 295 88%
OntoUSP 480 435 91%
</table>
<bodyText confidence="0.999570083333333">
tions by inputting a dependency path that signifies
the relation and returns a set of similar paths. To
use DIRT in question answering, it was queried to
obtain similar paths for the relation of the ques-
tion, which were then used to match sentences.
USP (Poon and Domingos, 2009) parses the in-
put text using the Stanford dependency parser
(Klein and Manning, 2003; de Marneffe et al.,
2006), learns an MLN for semantic parsing from
the dependency trees, and outputs this MLN and
the MAP semantic parses of the input sentences.
These MAP parses formed the knowledge base
(KB). To answer questions, USP first parses the
questions (with the question slot replaced by a
dummy word), and then matches the question
parse to parses in the KB by testing subsumption.
OntoUSP uses a similar procedure as USP for ex-
tracting knowledge and answering questions, ex-
cept for two changes. First, USP’s learning and
parsing algorithms are replaced with OntoUSP-
Learn and OntoUSP-Parse, respectively. Second,
when OntoUSP matches a question to its KB, it
not only considers the lambda-form cluster of the
question relation, but also all its sub-clusters.7
</bodyText>
<subsectionHeader confidence="0.949185">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999830571428571">
Table 1 shows the results comparing OntoUSP
with other systems. While USP already greatly
outperformed other systems in both precision and
recall, OntoUSP further substantially improved on
the recall of USP, without any loss in precision.
In particular, OntoUSP extracted 140 more correct
answers than USP, for a gain of 47% in absolute
</bodyText>
<footnote confidence="0.8934375">
7Additional details are available at
http : //alchemy.cs.washington.edu/papers/poonl0.
</footnote>
<note confidence="0.788137">
REGULATE
</note>
<figureCaption confidence="0.997672">
Figure 3: A fragment of the induced ISA hierar-
</figureCaption>
<bodyText confidence="0.957930317073171">
chy, showing the core forms for each cluster (the
cluster labels are added by the authors for illustra-
tion purpose).
recall. Compared to TextRunner (TR-SUB), On-
toUSP gained on precision by 38 points and ex-
tracted more than five times of correct answers.
Manual inspection shows that the induced ISA
hierarchy is the key for the recall gain. Like
USP, OntoUSP discovered the following clusters
(in core forms) that represent some of the core
concepts in biomedical research:
{regulate, control, govern, modulate}
{induce, enhance, trigger, augment, up-
regulate}
{inhibit, block, suppress, prevent, abolish, ab-
rogate, down-regulate}
However, USP formed these as separate clusters,
whereas OntoUSP in addition induces ISA rela-
tions from the INDUCE and INHIBIT clusters to
the REGULATE cluster (Figure 3). This allows
OntoUSP to answer many more questions that
are asked about general regulation events, even
though the text states them with specific regula-
tion directions like “induce” or “inhibit”. Below
is an example question-answer pair output by On-
toUSP; neither USP nor any other system were
able to extract the necessary knowledge.
Q: What does IL-2 control?
A: The DEX-mediated IkappaBalpha induc-
tion.
Sentence: Interestingly, the DEX-mediated
IkappaBalpha induction was completely inhibited
by IL-2, but not IL-4, in Th1 cells, while the re-
verse profile was seen in Th2 cells.
OntoUSP also discovered other interesting
commonalities among the clusters. For exam-
ple, both USP and OntoUSP formed a singleton
cluster with core form “activate”. Although this
cluster may appear similar to the INDUCE clus-
ter, the data in GENIA does not support merg-
ing the two. However, OntoUSP discovered that
</bodyText>
<figure confidence="0.994708583333333">
ISA
ISA
ISA
regulate, control, govern, modulate
induce, enhance,
trigger, augment,
up-regulate
inhibit, block, suppress,
abrogate, down-regulate
prevent, abolish, ACTIVATE
activate
INDUCE INHIBIT
</figure>
<page confidence="0.997974">
303
</page>
<bodyText confidence="0.999971736842105">
the ACTIVATE cluster, while not completely resol-
vent with INDUCE, shared very similar distribu-
tions in their agent arguments. In fact, they are
so similar that OntoUSP merges them into a sin-
gle property cluster. It found that the patient ar-
guments of INDUCE and INHIBIT are very similar
and merged them. In turn, OntoUSP formed ISA
links from these three object clusters to REGULATE,
as well as among their property clusters. In-
tuitively, this makes sense. The positive- and
negative-regulation events, as signified by INDUCE
and INHIBIT, often target similar object entities
or processes. However, their agents tend to differ
since in one case they are inducers, and in the other
they are inhibitors. On the other hand, ACTIVATE
and INDUCE share similar agents since they both
signify positive regulation. However, “activate”
tends to be used more often when the patient ar-
gument is a concrete entity (e.g., cells, genes, pro-
teins), whereas “induce” and others are also used
with processes and events (e.g., expressions, inhi-
bition, pathways).
USP was able to resolve common syntactic dif-
ferences such as active vs. passive voice. How-
ever, it does so on the basis of individual verbs,
and there is no generalization beyond their clus-
ters. OntoUSP, on the other hand, formed a high-
level cluster with two abstract property clusters,
corresponding to general agent argument and pa-
tient argument. The active-passive alternation is
captured in these clusters, and is inherited by all
descendant clusters, including many rare verbs
like “super-induce” which only occur once in GE-
NIA and for which there is no way that USP
could have learned about their active-passive al-
ternations. This illustrates the importance of dis-
covering ISA relations and performing hierarchi-
cal smoothing.
</bodyText>
<subsectionHeader confidence="0.954914">
4.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999974875">
OntoUSP is a first step towards joint ontology in-
duction and knowledge extraction. The experi-
mental results demonstrate the promise in this di-
rection. However, we also notice some limitations
in the current system. While OntoUSP induced
meaningful ISA relations among relation clusters
like REGULATE, INDUCE, etc., it was less success-
ful in inducing ISA relations among entity clus-
ters such as specific genes and proteins. This is
probably due to the fact that our model only con-
siders local features such as the parent and argu-
ments. A relation is often manifested as verbs and
has several arguments, whereas an entity typically
appears as an argument of others and has few ar-
guments of its own. As a result, in average, there
is less information available for entities than rela-
tions. Presumably, we can address this limitation
by modeling longer-ranged dependencies such as
grandparents, siblings, etc. This is straightforward
to do in Markov logic.
OntoUSP also uses a rather elaborate scheme
for regularization. We hypothesize that this can
be much simplified and improved by adopting a
principled framework such as Dudik et al. (2007).
</bodyText>
<sectionHeader confidence="0.999504" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999607">
This paper introduced OntoUSP, the first unsuper-
vised end-to-end system for ontology induction
and knowledge extraction from text. OntoUSP
builds on the USP semantic parser by adding the
capability to form hierarchical clusterings of logi-
cal expressions, linked by ISA relations, and us-
ing them for hierarchical smoothing. OntoUSP
greatly outperformed USP and other state-of-the-
art systems in a biomedical knowledge acquisition
task.
Directions for future work include: exploiting
the ontological structure for principled handling of
antonyms and (more generally) expressions with
opposite meanings; developing and testing alter-
nate methods for hierarchical modeling in On-
toUSP; scaling up learning and inference to larger
corpora; investigating the theoretical properties of
OntoUSP’s learning approach and generalizing it
to other tasks; answering questions that require in-
ference over multiple extractions; etc.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999936818181818">
We give warm thanks to the anonymous reviewers for
their comments. This research was partly funded by ARO
grant W911NF-08-1-0242, AFRL contract FA8750-09-C-
0181, DARPA contracts FA8750-05-2-0283, FA8750-07-D-
0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-
D030010, NSF grants IIS-0534881 and IIS-0803481, and
ONR grant N00014-08-1-0670. The views and conclusions
contained in this document are those of the authors and
should not be interpreted as necessarily representing the offi-
cial policies, either expressed or implied, of ARO, DARPA,
NSF, ONR, or the United States Government.
</bodyText>
<sectionHeader confidence="0.999269" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998467333333333">
Hiyan Alshawi. 1990. Resolving quasi logical forms. Com-
putational Linguistics, 16:133–144.
G. Bakir, T. Hofmann, B. B. Sch¨olkopf, A. Smola, B. Taskar,
</reference>
<page confidence="0.992731">
304
</page>
<reference confidence="0.999801421686747">
S. Vishwanathan, and (eds.). 2007. Predicting Structured
Data. MIT Press, Cambridge, MA.
Michele Banko, Michael J. Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open informa-
tion extraction from the web. In Proceedings of the Twen-
tieth International Joint Conference on Artificial Intelli-
gence, pages 2670–2676, Hyderabad, India. AAAI Press.
Philipp Cimiano. 2006. Ontology learning and population
from text. Springer.
Marie-Catherine de Marneffe, Bill MacCartney, and Christo-
pher D. Manning. 2006. Generating typed dependency
parses from phrase structure parses. In Proceedings of the
Fifth International Conference on Language Resources
and Evaluation, pages 449–454, Genoa, Italy. ELRA.
Pedro Domingos and Daniel Lowd. 2009. Markov Logic:
An Interface Layer for Artificial Intelligence. Morgan &amp;
Claypool, San Rafael, CA.
Miroslav Dudik, David Blei, and Robert Schapire. 2007. Hi-
erarchical maximum entropy density estimation. In Pro-
ceedings of the Twenty Fourth International Conference
on Machine Learning.
Christiane Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA.
Andrew Gelman and Jennifer Hill. 2006. Data Analysis Us-
ing Regression and Multilevel/Hierarchical Models. Cam-
bridge University Press.
Lise Getoor and Ben Taskar, editors. 2007. Introduction to
Statistical Relational Learning. MIT Press, Cambridge,
MA.
Marti Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proceedings of the 14th In-
ternational Conference on Computational Linguistics.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun’ichi Tsu-
jii. 2003. GENIA corpus - a semantically annotated cor-
pus for bio-textmining. Bioinformatics, 19:180–82.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of the Forty First
Annual Meeting of the Association for Computational Lin-
guistics, pages 423–430.
Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of
inference rules from text. In Proceedings of the Seventh
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 323–328, San Fran-
cisco, CA. ACM Press.
Alexander Maedche. 2002. Ontology learning for the se-
mantic Web. Kluwer Academic Publishers, Boston, Mas-
sachusetts.
Andrew McCallum, Ronald Rosenfeld, Tom Mitchell, and
Andrew Ng. 1998. Improving text classification by
shrinkage in a hierarchy of classes. In Proceedings of the
Fifteenth International Conference on Machine Learning.
Hoifung Poon and Pedro Domingos. 2008. Joint unsuper-
vised coreference resolution with Markov logic. In Pro-
ceedings of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 649–658, Honolulu,
HI. ACL.
Hoifung Poon and Pedro Domingos. 2009. Unsupervised
semantic parsing. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Processing,
pages 1–10, Singapore. ACL.
Rion Snow, Daniel Jurafsky, and Andrew Ng. 2006. Seman-
tic taxonomy induction from heterogenous evidence. In
Proceedings of COLING/ACL 2006.
S. Staab and R. Studer. 2004. Handbook on ontologies.
Springer.
Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.
2008. Yago - a large ontology from Wikipedia and Word-
Net. Journal of Web Semantics.
Fabian Suchanek, Mauro Sozio, and Gerhard Weikum. 2009.
Sofie: A self-organizing framework for information ex-
traction. In Proceedings of the Eighteenth International
Conference on World Wide Web.
Jun-ichi Tsujii. 2004. Thesaurus or logical ontology, which
do we need for mining text? In Proceedings of the Lan-
guage Resources and Evaluation Conference.
Fei Wu and Daniel S. Weld. 2008. Automatically refining the
wikipedia infobox ontology. In Proceedings of the Seven-
teenth International Conference on World Wide Web, Bei-
jing, China.
Alexander Yates and Oren Etzioni. 2009. Unsupervised
methods for determining object and relation synonyms
on the web. Journal of Artificial Intelligence Research,
34:255–296.
</reference>
<page confidence="0.999237">
305
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.839024">
<title confidence="0.998898">Unsupervised Ontology Induction from Text</title>
<author confidence="0.992707">Poon Domingos</author>
<affiliation confidence="0.9999085">Department of Computer Science &amp; Engineering University of Washington</affiliation>
<email confidence="0.999571">hoifung,pedrod@cs.washington.edu</email>
<abstract confidence="0.99380836">Extracting knowledge from unstructured text is a long-standing goal of NLP. Although learning approaches to many of its subtasks have been developed (e.g., parsing, taxonomy induction, information extraction), all end-to-end solutions to date require heavy supervision and/or manual engineering, limiting their scope and scalability. We present OntoUSP, a system that induces and populates a probabilistic ontology using only dependency-parsed text as input. OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters. The ISA hierarchy allows more general knowledge to be learned, and the use of smoothing for parameter estimation. We evaluate OntoUSP by using it to extract a knowledge base from biomedical abstracts and answer questions. OntoUSP improves on the recall of USP by 47% and greatly outperforms previous state-of-the-art approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>Resolving quasi logical forms.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--133</pages>
<contexts>
<context position="9928" citStr="Alshawi (1990)" startWordPosition="1554" endWordPosition="1555">y edge to a binary atom (e.g., the node for “induces” becomes induces(e1) and the subject dependency becomes nsubj(e1, e2), where ei’s are Skolem constants indexed by the nodes.).3 For each sentence, a semantic parse comprises of a partition of its QLF into subexpressions, each of which has a naturally corresponding lambda 2In this paper, we use a slightly different formulation of USP and its MLN to facilitate the exposition of OntoUSP. 3We call these QLFs because they are not true logical form (the ambiguities are not yet resolved). This is related to but not identical with the definition in Alshawi (1990). Figure 2: An example of object/property clusters: INDUCE contains the core-form property cluster and others, such as the agent argument INDUCER. form,4 and an assignment of each subexpression to a lambda-form cluster. The lambda-form clusters naturally form an ISPART hierarchy (Figure 2). An object cluster corresponds to semantic concepts or relations such as INDUCE, and contains a variable number of property clusters. A special property cluster of core forms maintains a distribution over variations in lambda forms for expressing this concept or relation. Other property clusters correspond t</context>
</contexts>
<marker>Alshawi, 1990</marker>
<rawString>Hiyan Alshawi. 1990. Resolving quasi logical forms. Computational Linguistics, 16:133–144.</rawString>
</citation>
<citation valid="true">
<title>Predicting Structured Data.</title>
<date>2007</date>
<editor>G. Bakir, T. Hofmann, B. B. Sch¨olkopf, A. Smola, B. Taskar, S. Vishwanathan, and (eds.).</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="36130" citStr="(2007)" startWordPosition="5863" endWordPosition="5863"> A relation is often manifested as verbs and has several arguments, whereas an entity typically appears as an argument of others and has few arguments of its own. As a result, in average, there is less information available for entities than relations. Presumably, we can address this limitation by modeling longer-ranged dependencies such as grandparents, siblings, etc. This is straightforward to do in Markov logic. OntoUSP also uses a rather elaborate scheme for regularization. We hypothesize that this can be much simplified and improved by adopting a principled framework such as Dudik et al. (2007). 5 Conclusion This paper introduced OntoUSP, the first unsupervised end-to-end system for ontology induction and knowledge extraction from text. OntoUSP builds on the USP semantic parser by adding the capability to form hierarchical clusterings of logical expressions, linked by ISA relations, and using them for hierarchical smoothing. OntoUSP greatly outperformed USP and other state-of-theart systems in a biomedical knowledge acquisition task. Directions for future work include: exploiting the ontological structure for principled handling of antonyms and (more generally) expressions with oppo</context>
</contexts>
<marker>2007</marker>
<rawString>G. Bakir, T. Hofmann, B. B. Sch¨olkopf, A. Smola, B. Taskar, S. Vishwanathan, and (eds.). 2007. Predicting Structured Data. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2670--2676</pages>
<publisher>AAAI Press.</publisher>
<location>Hyderabad,</location>
<contexts>
<context position="2090" citStr="Banko et al., 2007" startWordPosition="312" endWordPosition="315">wledge engineering needed makes them very costly and limits them to well-circumscribed domains. More recently, machine learning approaches to a number of key subproblems have been developed (e.g., Snow et al. (2006)), but to date there is no sufficiently automatic end-to-end solution. Most saliently, supervised learning requires labeled data, which itself is costly and infeasible for large-scale, open-domain knowledge acquisition. Ideally, we would like to have an end-to-end unsupervised (or lightly supervised) solution to the problem of knowledge acquisition from text. The TextRunner system (Banko et al., 2007) can extract a large number of ground atoms from the Web using only a small number of seed patterns as guidance, but it is unable to extract non-atomic formulas, and the mass of facts it extracts is unstructured and very noisy. The USP system (Poon and Domingos, 2009) can extract formulas and appears to be fairly robust to noise. However, it is still limited to extractions for which there is substantial evidence in the corpus, and in most corpora most pieces of knowledge are stated only once or a few times, making them very difficult to extract without supervision. Also, the knowledge extracte</context>
<context position="28366" citStr="Banko et al., 2007" startWordPosition="4616" endWordPosition="4619">tion of the systems. (For more details, see Poon &amp; Domingos (2009).) Keyword is a baseline system based on keyword matching. It directly matches the question substring containing the verb and the available argument with the input text, ignoring case and morphology. Given a match, two ways to derive the answer were considered: KW simply returns the rest of sentence on the other side of the verb, whereas KW-SYN is informed by syntax and extracts the answer from the subject or object of the verb, depending on the question (if the expected argument is absent, the sentence is ignored). TextRunner (Banko et al., 2007) is the state-ofthe-art system for open-domain information extraction. It inputs text and outputs relational triples in the form (R, A1, A2), where R is the relation string, and A1, A2 the argument strings. To answer questions, each triple-question pair is considered in turn by first matching their relation strings, and then the available argument strings. If both match, the remaining argument string in the triple is returned as an answer. Results were reported when exact match is used (TR-EXACT), or when the triple strings may contain the question ones as substrings (TR-SUB). RESOLVER (Yates </context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, pages 2670–2676, Hyderabad, India. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
</authors>
<title>Ontology learning and population from text.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="4259" citStr="Cimiano, 2006" startWordPosition="657" endWordPosition="658">resent the OntoUSP Markov logic network and the inference and learning algorithms used with it. Finally, experiments on a biomedical knowledge acquisition and question answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limi</context>
</contexts>
<marker>Cimiano, 2006</marker>
<rawString>Philipp Cimiano. 2006. Ontology learning and population from text. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation,</booktitle>
<pages>449--454</pages>
<location>Genoa, Italy. ELRA.</location>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the Fifth International Conference on Language Resources and Evaluation, pages 449–454, Genoa, Italy. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro Domingos</author>
<author>Daniel Lowd</author>
</authors>
<title>Markov Logic: An Interface Layer for Artificial Intelligence. Morgan &amp; Claypool,</title>
<date>2009</date>
<location>San Rafael, CA.</location>
<contexts>
<context position="3126" citStr="Domingos and Lowd, 2009" startWordPosition="490" endWordPosition="493">nce in the corpus, and in most corpora most pieces of knowledge are stated only once or a few times, making them very difficult to extract without supervision. Also, the knowledge extracted is simply a large set of formulas without ontological structure, and the latter is essential for compact representation and efficient reasoning (Staab and Studer, 2004). We propose OntoUSP (Ontological USP), a system that learns an ISA hierarchy over clusters of logical expressions, and populates it by translating sentences to logical form. OntoUSP is encoded in a few formulas of higher-order Markov logic (Domingos and Lowd, 2009), and can be viewed as extending USP with the capability to perform hierarchical (as opposed to flat) clustering. This clustering is then used to perform hierarchical smoothing (a.k.a. shrinkage), greatly increasing the system’s capability to generalize from 296 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 296–305, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics sparse data. We begin by reviewing the necessary background. We then present the OntoUSP Markov logic network and the inference and learning algorithm</context>
<context position="6749" citStr="Domingos and Lowd, 2009" startWordPosition="1025" endWordPosition="1029">is facilitates more accurate parameter estimation and better generalization. Our approach can also leverage existing ontologies and knowledge bases to conduct semisupervised ontology induction (e.g., by incorporating existing structures as hard constraints or penalizing deviation from them). 2.2 Markov Logic Combining uncertainty handling and joint inference is the hallmark of the emerging field of statistical relational learning (a.k.a. structured prediction), where a plethora of approaches have been developed (Getoor and Taskar, 2007; Bakir et al., 2007). In this paper, we use Markov logic (Domingos and Lowd, 2009), which is the leading unifying framework, but other approaches can be used as well. Markov logic is a probabilistic extension of first-order logic and can compactly specify probability distributions over complex relational domains. It has been successfully applied to unsupervised learning for various NLP tasks such as coreference resolution (Poon and Domingos, 2008) and semantic parsing (Poon and Domingos, 2009). A Markov logic network (MLN) is a set of weighted first-order clauses. Together with a set of constants, it defines a Markov network with one node per ground atom and one feature per</context>
</contexts>
<marker>Domingos, Lowd, 2009</marker>
<rawString>Pedro Domingos and Daniel Lowd. 2009. Markov Logic: An Interface Layer for Artificial Intelligence. Morgan &amp; Claypool, San Rafael, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miroslav Dudik</author>
<author>David Blei</author>
<author>Robert Schapire</author>
</authors>
<title>Hierarchical maximum entropy density estimation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twenty Fourth International Conference on Machine Learning.</booktitle>
<contexts>
<context position="23288" citStr="Dudik et al., 2007" startWordPosition="3790" endWordPosition="3793">edily for each property cluster in c2, in descending order of cluster size. Notice that once an abstract cluster is created, it could be merged with an existing cluster using MERGE. Thus with the new operators, OntoUSP is capable of inducing any ISA hierarchy among abstract and existing clusters. (Of course, the ISA hierarchy it actually induces depends on the data.) Learning the shrinkage weights has been approached in a variety of ways; examples include EM and cross-validation (McCallum et al., 1998), hierarchical Bayesian methods (Gelman and Hill, 2006), and maximum entropy with Li priors (Dudik et al., 2007). The past methods either only learn parameters with one or two levels (e.g., in hierarchical Bayes), or requires significant amount of computation (e.g., in EM and in Li-regularized maxent), while also typically assuming a given hierarchy. In contrast, OntoUSP has to both induce the hierarchy and populate it, with potentially many levels in the induced hierarchy, starting from raw text with little user supervision. Therefore, OntoUSP simplifies the weight learning problem by adopting standard mestimation for smoothing. Namely, the weights for cluster c are set by counting its observations plu</context>
<context position="36130" citStr="Dudik et al. (2007)" startWordPosition="5860" endWordPosition="5863">nd arguments. A relation is often manifested as verbs and has several arguments, whereas an entity typically appears as an argument of others and has few arguments of its own. As a result, in average, there is less information available for entities than relations. Presumably, we can address this limitation by modeling longer-ranged dependencies such as grandparents, siblings, etc. This is straightforward to do in Markov logic. OntoUSP also uses a rather elaborate scheme for regularization. We hypothesize that this can be much simplified and improved by adopting a principled framework such as Dudik et al. (2007). 5 Conclusion This paper introduced OntoUSP, the first unsupervised end-to-end system for ontology induction and knowledge extraction from text. OntoUSP builds on the USP semantic parser by adding the capability to form hierarchical clusterings of logical expressions, linked by ISA relations, and using them for hierarchical smoothing. OntoUSP greatly outperformed USP and other state-of-theart systems in a biomedical knowledge acquisition task. Directions for future work include: exploiting the ontological structure for principled handling of antonyms and (more generally) expressions with oppo</context>
</contexts>
<marker>Dudik, Blei, Schapire, 2007</marker>
<rawString>Miroslav Dudik, David Blei, and Robert Schapire. 2007. Hierarchical maximum entropy density estimation. In Proceedings of the Twenty Fourth International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Gelman</author>
<author>Jennifer Hill</author>
</authors>
<title>Data Analysis Using Regression and Multilevel/Hierarchical Models.</title>
<date>2006</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="15725" citStr="Gelman and Hill, 2006" startWordPosition="2495" endWordPosition="2498"> commonalities is by forming an ISA hierarchy among the clusters. For example, INDUCE and INHIBIT are both subconcepts of REGULATE. Learning these ISA relations helps answer questions like “What regulates CD11b?”, when the text states that “IL-4 induces CD11b” or “AP-1 suppresses CD11b”. For parameter learning, this is also undesirable. Without the hierarchical structure, each cluster estimates its parameters solely based on its own observations, which can be extremely sparse. The better solution is to leverage the hierarchical structure for smoothing (a.k.a. shrinkage (McCallum et al., 1998; Gelman and Hill, 2006)). For example, if we learn that “super-induce” is a verb and that in general verbs have active and passive voices, then even though “super-induce” only shows up once in the corpus as in “AP-1 is super-induced by IL4”, by smoothing we can still infer that this probably means the same as “IL-4 super-induces AP-1”, which in turn helps answer questions like “What super-induces AP-1”. OntoUSP overcomes the limitations of USP by replacing the flat clustering process with a hierarchical clustering one, and learns an ISA hierarchy of lambda-form clusters in addition to the IS-PART one. The output of </context>
<context position="23231" citStr="Gelman and Hill, 2006" startWordPosition="3780" endWordPosition="3783">efficiency, in both operators, the best option is chosen greedily for each property cluster in c2, in descending order of cluster size. Notice that once an abstract cluster is created, it could be merged with an existing cluster using MERGE. Thus with the new operators, OntoUSP is capable of inducing any ISA hierarchy among abstract and existing clusters. (Of course, the ISA hierarchy it actually induces depends on the data.) Learning the shrinkage weights has been approached in a variety of ways; examples include EM and cross-validation (McCallum et al., 1998), hierarchical Bayesian methods (Gelman and Hill, 2006), and maximum entropy with Li priors (Dudik et al., 2007). The past methods either only learn parameters with one or two levels (e.g., in hierarchical Bayes), or requires significant amount of computation (e.g., in EM and in Li-regularized maxent), while also typically assuming a given hierarchy. In contrast, OntoUSP has to both induce the hierarchy and populate it, with potentially many levels in the induced hierarchy, starting from raw text with little user supervision. Therefore, OntoUSP simplifies the weight learning problem by adopting standard mestimation for smoothing. Namely, the weigh</context>
</contexts>
<marker>Gelman, Hill, 2006</marker>
<rawString>Andrew Gelman and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<title>Introduction to Statistical Relational Learning.</title>
<date>2007</date>
<editor>Lise Getoor and Ben Taskar, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="36130" citStr="(2007)" startWordPosition="5863" endWordPosition="5863"> A relation is often manifested as verbs and has several arguments, whereas an entity typically appears as an argument of others and has few arguments of its own. As a result, in average, there is less information available for entities than relations. Presumably, we can address this limitation by modeling longer-ranged dependencies such as grandparents, siblings, etc. This is straightforward to do in Markov logic. OntoUSP also uses a rather elaborate scheme for regularization. We hypothesize that this can be much simplified and improved by adopting a principled framework such as Dudik et al. (2007). 5 Conclusion This paper introduced OntoUSP, the first unsupervised end-to-end system for ontology induction and knowledge extraction from text. OntoUSP builds on the USP semantic parser by adding the capability to form hierarchical clusterings of logical expressions, linked by ISA relations, and using them for hierarchical smoothing. OntoUSP greatly outperformed USP and other state-of-theart systems in a biomedical knowledge acquisition task. Directions for future work include: exploiting the ontological structure for principled handling of antonyms and (more generally) expressions with oppo</context>
</contexts>
<marker>2007</marker>
<rawString>Lise Getoor and Ben Taskar, editors. 2007. Introduction to Statistical Relational Learning. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="4728" citStr="Hearst, 1992" startWordPosition="732" endWordPosition="733"> (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage. Moreover, they often focus on inducing ontology over individual words rather than arbitrarily large meaning units (e.g., idioms, phrasal verbs, etc.). Most importantly, existing approaches typically separate ontology induction from population and knowledge extraction, and pursue each task in a standalone fashion. While computationally efficient, this is suboptimal. The resulted ontology is disconnected from text and requires additional effort to ma</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Yuka Tateisi</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>GENIA corpus - a semantically annotated corpus for bio-textmining.</title>
<date>2003</date>
<journal>Bioinformatics,</journal>
<pages>19--180</pages>
<contexts>
<context position="26834" citStr="Kim et al., 2003" startWordPosition="4373" endWordPosition="4376">/(m+nc)), where p is the parent of c and n is the count. The log-likelihood is Ec,v w&apos;c,v nc,v, which is then augmented by the priors. 4 Experiments 4.1 Methodology Evaluating unsupervised ontology induction is difficult, because there is no gold ontology for comparison. Moreover, our ultimate goal is to aid knowledge acquisition, rather than just inducing an ontology for its own sake. Therefore, we used the same methodology and dataset as the USP paper to evaluate OntoUSP on its capability in knowledge acquisition. Specifically, we applied OntoUSP to extract knowledge from the GENIA dataset (Kim et al., 2003) and answer questions, and we evaluated it on the number of extracted answers and accuracy. GENIA contains 1999 PubMed abstracts.6 The question set con6http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/home/wiki.cgi. tains 2000 questions which were created by sampling verbs and entities according to their frequencies in GENIA. Sample questions include “What regulates MIP-1alpha?”, “What does anti-STAT 1 inhibit?”. These simple question types were used to focus the evaluation on the knowledge extraction aspect, rather than engineering for handling special question types and/or reasoning. 4.2 Systems O</context>
</contexts>
<marker>Kim, Ohta, Tateisi, Tsujii, 2003</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, and Jun’ichi Tsujii. 2003. GENIA corpus - a semantically annotated corpus for bio-textmining. Bioinformatics, 19:180–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the Forty First Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="30038" citStr="Klein and Manning, 2003" startWordPosition="4900" endWordPosition="4903">et. Results for systems other than OntoUSP are from Poon &amp; Domingos (2009). # Total # Correct Accuracy KW 150 67 45% KW-SYN 87 67 77% TR-EXACT 29 23 79% TR-SUB 152 81 53% RS-EXACT 53 24 45% RS-SUB 196 81 41% DIRT 159 94 59% USP 334 295 88% OntoUSP 480 435 91% tions by inputting a dependency path that signifies the relation and returns a set of similar paths. To use DIRT in question answering, it was queried to obtain similar paths for the relation of the question, which were then used to match sentences. USP (Poon and Domingos, 2009) parses the input text using the Stanford dependency parser (Klein and Manning, 2003; de Marneffe et al., 2006), learns an MLN for semantic parsing from the dependency trees, and outputs this MLN and the MAP semantic parses of the input sentences. These MAP parses formed the knowledge base (KB). To answer questions, USP first parses the questions (with the question slot replaced by a dummy word), and then matches the question parse to parses in the KB by testing subsumption. OntoUSP uses a similar procedure as USP for extracting knowledge and answering questions, except for two changes. First, USP’s learning and parsing algorithms are replaced with OntoUSPLearn and OntoUSP-Pa</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the Forty First Annual Meeting of the Association for Computational Linguistics, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>323--328</pages>
<publisher>ACM Press.</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="29322" citStr="Lin and Pantel, 2001" startWordPosition="4768" endWordPosition="4771">lable argument strings. If both match, the remaining argument string in the triple is returned as an answer. Results were reported when exact match is used (TR-EXACT), or when the triple strings may contain the question ones as substrings (TR-SUB). RESOLVER (Yates and Etzioni, 2009) inputs TextRunner triples and collectively resolves coreferent relation and argument strings. To answer questions, the only difference from TextRunner is that a question string can match any string in its cluster. As in TextRunner, results were reported for both exact match (RS-EXACT) and substring (RS-SUB). DIRT (Lin and Pantel, 2001) resolves binary rela302 Table 1: Comparison of question answering results on the GENIA dataset. Results for systems other than OntoUSP are from Poon &amp; Domingos (2009). # Total # Correct Accuracy KW 150 67 45% KW-SYN 87 67 77% TR-EXACT 29 23 79% TR-SUB 152 81 53% RS-EXACT 53 24 45% RS-SUB 196 81 41% DIRT 159 94 59% USP 334 295 88% OntoUSP 480 435 91% tions by inputting a dependency path that signifies the relation and returns a set of similar paths. To use DIRT in question answering, it was queried to obtain similar paths for the relation of the question, which were then used to match sentence</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 323–328, San Francisco, CA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Maedche</author>
</authors>
<title>Ontology learning for the semantic Web.</title>
<date>2002</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston, Massachusetts.</location>
<contexts>
<context position="4275" citStr="Maedche, 2002" startWordPosition="659" endWordPosition="660">USP Markov logic network and the inference and learning algorithms used with it. Finally, experiments on a biomedical knowledge acquisition and question answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage.</context>
</contexts>
<marker>Maedche, 2002</marker>
<rawString>Alexander Maedche. 2002. Ontology learning for the semantic Web. Kluwer Academic Publishers, Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Ronald Rosenfeld</author>
<author>Tom Mitchell</author>
<author>Andrew Ng</author>
</authors>
<title>Improving text classification by shrinkage in a hierarchy of classes.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fifteenth International Conference on Machine Learning.</booktitle>
<contexts>
<context position="15701" citStr="McCallum et al., 1998" startWordPosition="2491" endWordPosition="2494">est way to capture such commonalities is by forming an ISA hierarchy among the clusters. For example, INDUCE and INHIBIT are both subconcepts of REGULATE. Learning these ISA relations helps answer questions like “What regulates CD11b?”, when the text states that “IL-4 induces CD11b” or “AP-1 suppresses CD11b”. For parameter learning, this is also undesirable. Without the hierarchical structure, each cluster estimates its parameters solely based on its own observations, which can be extremely sparse. The better solution is to leverage the hierarchical structure for smoothing (a.k.a. shrinkage (McCallum et al., 1998; Gelman and Hill, 2006)). For example, if we learn that “super-induce” is a verb and that in general verbs have active and passive voices, then even though “super-induce” only shows up once in the corpus as in “AP-1 is super-induced by IL4”, by smoothing we can still infer that this probably means the same as “IL-4 super-induces AP-1”, which in turn helps answer questions like “What super-induces AP-1”. OntoUSP overcomes the limitations of USP by replacing the flat clustering process with a hierarchical clustering one, and learns an ISA hierarchy of lambda-form clusters in addition to the IS-</context>
<context position="23176" citStr="McCallum et al., 1998" startWordPosition="3773" endWordPosition="3776">bstract property cluster in c; leave it unchanged. For efficiency, in both operators, the best option is chosen greedily for each property cluster in c2, in descending order of cluster size. Notice that once an abstract cluster is created, it could be merged with an existing cluster using MERGE. Thus with the new operators, OntoUSP is capable of inducing any ISA hierarchy among abstract and existing clusters. (Of course, the ISA hierarchy it actually induces depends on the data.) Learning the shrinkage weights has been approached in a variety of ways; examples include EM and cross-validation (McCallum et al., 1998), hierarchical Bayesian methods (Gelman and Hill, 2006), and maximum entropy with Li priors (Dudik et al., 2007). The past methods either only learn parameters with one or two levels (e.g., in hierarchical Bayes), or requires significant amount of computation (e.g., in EM and in Li-regularized maxent), while also typically assuming a given hierarchy. In contrast, OntoUSP has to both induce the hierarchy and populate it, with potentially many levels in the induced hierarchy, starting from raw text with little user supervision. Therefore, OntoUSP simplifies the weight learning problem by adoptin</context>
</contexts>
<marker>McCallum, Rosenfeld, Mitchell, Ng, 1998</marker>
<rawString>Andrew McCallum, Ronald Rosenfeld, Tom Mitchell, and Andrew Ng. 1998. Improving text classification by shrinkage in a hierarchy of classes. In Proceedings of the Fifteenth International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>649--658</pages>
<publisher>ACL.</publisher>
<location>Honolulu, HI.</location>
<contexts>
<context position="7118" citStr="Poon and Domingos, 2008" startWordPosition="1082" endWordPosition="1085">allmark of the emerging field of statistical relational learning (a.k.a. structured prediction), where a plethora of approaches have been developed (Getoor and Taskar, 2007; Bakir et al., 2007). In this paper, we use Markov logic (Domingos and Lowd, 2009), which is the leading unifying framework, but other approaches can be used as well. Markov logic is a probabilistic extension of first-order logic and can compactly specify probability distributions over complex relational domains. It has been successfully applied to unsupervised learning for various NLP tasks such as coreference resolution (Poon and Domingos, 2008) and semantic parsing (Poon and Domingos, 2009). A Markov logic network (MLN) is a set of weighted first-order clauses. Together with a set of constants, it defines a Markov network with one node per ground atom and one feature per ground clause. The weight of a feature is the weight of the first-order clause that originated it. The probability of a state x in such a network is given by the log-linear model P(x) = 1Z exp (Ei wini(x)), where Z is a normalization constant, wi is the weight of the ith formula, and ni is the number of satisfied groundings. 2.3 Unsupervised Semantic Parsing Semanti</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2008. Joint unsupervised coreference resolution with Markov logic. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 649–658, Honolulu, HI. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--10</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2358" citStr="Poon and Domingos, 2009" startWordPosition="362" endWordPosition="365">c end-to-end solution. Most saliently, supervised learning requires labeled data, which itself is costly and infeasible for large-scale, open-domain knowledge acquisition. Ideally, we would like to have an end-to-end unsupervised (or lightly supervised) solution to the problem of knowledge acquisition from text. The TextRunner system (Banko et al., 2007) can extract a large number of ground atoms from the Web using only a small number of seed patterns as guidance, but it is unable to extract non-atomic formulas, and the mass of facts it extracts is unstructured and very noisy. The USP system (Poon and Domingos, 2009) can extract formulas and appears to be fairly robust to noise. However, it is still limited to extractions for which there is substantial evidence in the corpus, and in most corpora most pieces of knowledge are stated only once or a few times, making them very difficult to extract without supervision. Also, the knowledge extracted is simply a large set of formulas without ontological structure, and the latter is essential for compact representation and efficient reasoning (Staab and Studer, 2004). We propose OntoUSP (Ontological USP), a system that learns an ISA hierarchy over clusters of log</context>
<context position="7165" citStr="Poon and Domingos, 2009" startWordPosition="1089" endWordPosition="1092">lational learning (a.k.a. structured prediction), where a plethora of approaches have been developed (Getoor and Taskar, 2007; Bakir et al., 2007). In this paper, we use Markov logic (Domingos and Lowd, 2009), which is the leading unifying framework, but other approaches can be used as well. Markov logic is a probabilistic extension of first-order logic and can compactly specify probability distributions over complex relational domains. It has been successfully applied to unsupervised learning for various NLP tasks such as coreference resolution (Poon and Domingos, 2008) and semantic parsing (Poon and Domingos, 2009). A Markov logic network (MLN) is a set of weighted first-order clauses. Together with a set of constants, it defines a Markov network with one node per ground atom and one feature per ground clause. The weight of a feature is the weight of the first-order clause that originated it. The probability of a state x in such a network is given by the log-linear model P(x) = 1Z exp (Ei wini(x)), where Z is a normalization constant, wi is the weight of the ith formula, and ni is the number of satisfied groundings. 2.3 Unsupervised Semantic Parsing Semantic parsing aims to obtain a complete canonical m</context>
<context position="9100" citStr="Poon and Domingos, 2009" startWordPosition="1415" endWordPosition="1418">ed in logical and probabilistic inference and support end tasks such as question answering. A major challenge to semantic parsing is syntactic and lexical variations of the same meaning, which abound in natural languages. For example, the fact that IL-4 protein induces CD11b can be expressed in a variety of ways, such as, “Interleukin-4 enhances the expression of CD11b”, “CD11b is upregulated by IL-4”, etc. Past approaches either manually construct a grammar or require example sentences with meaning annotation, and do not scale beyond restricted domains. Recently, we developed the USP system (Poon and Domingos, 2009), the first unsupervised approach for semantic parsing.2 USP inputs dependency trees of sentences and first transforms them into quasi-logical forms (QLFs) by converting each node to a unary atom and each dependency edge to a binary atom (e.g., the node for “induces” becomes induces(e1) and the subject dependency becomes nsubj(e1, e2), where ei’s are Skolem constants indexed by the nodes.).3 For each sentence, a semantic parse comprises of a partition of its QLF into subexpressions, each of which has a naturally corresponding lambda 2In this paper, we use a slightly different formulation of US</context>
<context position="27721" citStr="Poon and Domingos, 2009" startWordPosition="4504" endWordPosition="4507">erbs and entities according to their frequencies in GENIA. Sample questions include “What regulates MIP-1alpha?”, “What does anti-STAT 1 inhibit?”. These simple question types were used to focus the evaluation on the knowledge extraction aspect, rather than engineering for handling special question types and/or reasoning. 4.2 Systems OntoUSP is the first unsupervised approach that synergistically conducts ontology induction, population, and knowledge extraction. The system closest in aim and capability is USP. We thus compared OntoUSP with USP and all other systems evaluated in the USP paper (Poon and Domingos, 2009). Below is a brief description of the systems. (For more details, see Poon &amp; Domingos (2009).) Keyword is a baseline system based on keyword matching. It directly matches the question substring containing the verb and the available argument with the input text, ignoring case and morphology. Given a match, two ways to derive the answer were considered: KW simply returns the rest of sentence on the other side of the verb, whereas KW-SYN is informed by syntax and extracts the answer from the subject or object of the verb, depending on the question (if the expected argument is absent, the sentence</context>
<context position="29954" citStr="Poon and Domingos, 2009" startWordPosition="4886" endWordPosition="4889">s binary rela302 Table 1: Comparison of question answering results on the GENIA dataset. Results for systems other than OntoUSP are from Poon &amp; Domingos (2009). # Total # Correct Accuracy KW 150 67 45% KW-SYN 87 67 77% TR-EXACT 29 23 79% TR-SUB 152 81 53% RS-EXACT 53 24 45% RS-SUB 196 81 41% DIRT 159 94 59% USP 334 295 88% OntoUSP 480 435 91% tions by inputting a dependency path that signifies the relation and returns a set of similar paths. To use DIRT in question answering, it was queried to obtain similar paths for the relation of the question, which were then used to match sentences. USP (Poon and Domingos, 2009) parses the input text using the Stanford dependency parser (Klein and Manning, 2003; de Marneffe et al., 2006), learns an MLN for semantic parsing from the dependency trees, and outputs this MLN and the MAP semantic parses of the input sentences. These MAP parses formed the knowledge base (KB). To answer questions, USP first parses the questions (with the question slot replaced by a dummy word), and then matches the question parse to parses in the KB by testing subsumption. OntoUSP uses a similar procedure as USP for extracting knowledge and answering questions, except for two changes. First,</context>
<context position="27813" citStr="Poon &amp; Domingos (2009)" startWordPosition="4520" endWordPosition="4523">lates MIP-1alpha?”, “What does anti-STAT 1 inhibit?”. These simple question types were used to focus the evaluation on the knowledge extraction aspect, rather than engineering for handling special question types and/or reasoning. 4.2 Systems OntoUSP is the first unsupervised approach that synergistically conducts ontology induction, population, and knowledge extraction. The system closest in aim and capability is USP. We thus compared OntoUSP with USP and all other systems evaluated in the USP paper (Poon and Domingos, 2009). Below is a brief description of the systems. (For more details, see Poon &amp; Domingos (2009).) Keyword is a baseline system based on keyword matching. It directly matches the question substring containing the verb and the available argument with the input text, ignoring case and morphology. Given a match, two ways to derive the answer were considered: KW simply returns the rest of sentence on the other side of the verb, whereas KW-SYN is informed by syntax and extracts the answer from the subject or object of the verb, depending on the question (if the expected argument is absent, the sentence is ignored). TextRunner (Banko et al., 2007) is the state-ofthe-art system for open-domain </context>
<context position="29489" citStr="Poon &amp; Domingos (2009)" startWordPosition="4796" endWordPosition="4799">, or when the triple strings may contain the question ones as substrings (TR-SUB). RESOLVER (Yates and Etzioni, 2009) inputs TextRunner triples and collectively resolves coreferent relation and argument strings. To answer questions, the only difference from TextRunner is that a question string can match any string in its cluster. As in TextRunner, results were reported for both exact match (RS-EXACT) and substring (RS-SUB). DIRT (Lin and Pantel, 2001) resolves binary rela302 Table 1: Comparison of question answering results on the GENIA dataset. Results for systems other than OntoUSP are from Poon &amp; Domingos (2009). # Total # Correct Accuracy KW 150 67 45% KW-SYN 87 67 77% TR-EXACT 29 23 79% TR-SUB 152 81 53% RS-EXACT 53 24 45% RS-SUB 196 81 41% DIRT 159 94 59% USP 334 295 88% OntoUSP 480 435 91% tions by inputting a dependency path that signifies the relation and returns a set of similar paths. To use DIRT in question answering, it was queried to obtain similar paths for the relation of the question, which were then used to match sentences. USP (Poon and Domingos, 2009) parses the input text using the Stanford dependency parser (Klein and Manning, 2003; de Marneffe et al., 2006), learns an MLN for sema</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised semantic parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1–10, Singapore. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL</booktitle>
<contexts>
<context position="1686" citStr="Snow et al. (2006)" startWordPosition="253" endWordPosition="256">ous state-of-the-art approaches. 1 Introduction Knowledge acquisition has been a major goal of NLP since its early days. We would like computers to be able to read text and express the knowledge it contains in a formal representation, suitable for answering questions and solving problems. However, progress has been difficult. The earliest approaches were manual, but the sheer amount of coding and knowledge engineering needed makes them very costly and limits them to well-circumscribed domains. More recently, machine learning approaches to a number of key subproblems have been developed (e.g., Snow et al. (2006)), but to date there is no sufficiently automatic end-to-end solution. Most saliently, supervised learning requires labeled data, which itself is costly and infeasible for large-scale, open-domain knowledge acquisition. Ideally, we would like to have an end-to-end unsupervised (or lightly supervised) solution to the problem of knowledge acquisition from text. The TextRunner system (Banko et al., 2007) can extract a large number of ground atoms from the Web using only a small number of seed patterns as guidance, but it is unable to extract non-atomic formulas, and the mass of facts it extracts </context>
<context position="4366" citStr="Snow et al. (2006)" startWordPosition="673" endWordPosition="676">y, experiments on a biomedical knowledge acquisition and question answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage. Moreover, they often focus on inducing ontology over individual words rather than arbitrar</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Staab</author>
<author>R Studer</author>
</authors>
<title>Handbook on ontologies.</title>
<date>2004</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2860" citStr="Staab and Studer, 2004" startWordPosition="446" endWordPosition="449">omic formulas, and the mass of facts it extracts is unstructured and very noisy. The USP system (Poon and Domingos, 2009) can extract formulas and appears to be fairly robust to noise. However, it is still limited to extractions for which there is substantial evidence in the corpus, and in most corpora most pieces of knowledge are stated only once or a few times, making them very difficult to extract without supervision. Also, the knowledge extracted is simply a large set of formulas without ontological structure, and the latter is essential for compact representation and efficient reasoning (Staab and Studer, 2004). We propose OntoUSP (Ontological USP), a system that learns an ISA hierarchy over clusters of logical expressions, and populates it by translating sentences to logical form. OntoUSP is encoded in a few formulas of higher-order Markov logic (Domingos and Lowd, 2009), and can be viewed as extending USP with the capability to perform hierarchical (as opposed to flat) clustering. This clustering is then used to perform hierarchical smoothing (a.k.a. shrinkage), greatly increasing the system’s capability to generalize from 296 Proceedings of the 48th Annual Meeting of the Association for Computati</context>
<context position="4140" citStr="Staab and Studer, 2004" startWordPosition="638" endWordPosition="641">uly 2010. c�2010 Association for Computational Linguistics sparse data. We begin by reviewing the necessary background. We then present the OntoUSP Markov logic network and the inference and learning algorithms used with it. Finally, experiments on a biomedical knowledge acquisition and question answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build o</context>
</contexts>
<marker>Staab, Studer, 2004</marker>
<rawString>S. Staab and R. Studer. 2004. Handbook on ontologies. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago - a large ontology from Wikipedia and WordNet.</title>
<date>2008</date>
<journal>Journal of Web Semantics.</journal>
<contexts>
<context position="4405" citStr="Suchanek et al. (2008" startWordPosition="679" endWordPosition="682">edge acquisition and question answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage. Moreover, they often focus on inducing ontology over individual words rather than arbitrarily large meaning units (e.g., idioms, </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2008</marker>
<rawString>Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2008. Yago - a large ontology from Wikipedia and WordNet. Journal of Web Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Suchanek</author>
<author>Mauro Sozio</author>
<author>Gerhard Weikum</author>
</authors>
<title>Sofie: A self-organizing framework for information extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Eighteenth International Conference on World Wide Web.</booktitle>
<marker>Suchanek, Sozio, Weikum, 2009</marker>
<rawString>Fabian Suchanek, Mauro Sozio, and Gerhard Weikum. 2009. Sofie: A self-organizing framework for information extraction. In Proceedings of the Eighteenth International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-ichi Tsujii</author>
</authors>
<title>Thesaurus or logical ontology, which do we need for mining text?</title>
<date>2004</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference.</booktitle>
<contexts>
<context position="5360" citStr="Tsujii, 2004" startWordPosition="819" endWordPosition="820">ing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage. Moreover, they often focus on inducing ontology over individual words rather than arbitrarily large meaning units (e.g., idioms, phrasal verbs, etc.). Most importantly, existing approaches typically separate ontology induction from population and knowledge extraction, and pursue each task in a standalone fashion. While computationally efficient, this is suboptimal. The resulted ontology is disconnected from text and requires additional effort to map between the two (Tsujii, 2004). In addition, this fails to leverage the intimate connections between the three tasks for joint inference and mutual disambiguiation. Our approach differs from existing ones in two main aspects: we induce a probabilistic ontology from text, and we do so by jointly conducting ontology induction, population, and knowledge extraction. Probabilistic modeling handles uncertainty and noise. A joint approach propagates in1http : //www.wikipedia.org formation among the three tasks, uncovers more implicit information from text, and can potentially work well even in domains not well covered by existing</context>
</contexts>
<marker>Tsujii, 2004</marker>
<rawString>Jun-ichi Tsujii. 2004. Thesaurus or logical ontology, which do we need for mining text? In Proceedings of the Language Resources and Evaluation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Automatically refining the wikipedia infobox ontology.</title>
<date>2008</date>
<booktitle>In Proceedings of the Seventeenth International Conference on World Wide Web,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="4429" citStr="Wu &amp; Weld (2008)" startWordPosition="683" endWordPosition="686"> answering task show that OntoUSP can greatly outperform USP and previous systems. 2 Background 2.1 Ontology Learning In general, ontology induction (constructing an ontology) and ontology population (mapping textual expressions to concepts and relations in the ontology) remain difficult open problems (Staab and Studer, 2004). Recently, ontology learning has attracted increasing interest in both NLP and semantic Web communities (Cimiano, 2006; Maedche, 2002), and a number of machine learning approaches have been developed (e.g., Snow et al. (2006), Cimiano (2006), Suchanek et al. (2008,2009), Wu &amp; Weld (2008)). However, they are still limited in several aspects. Most approaches induce and populate a deterministic ontology, which does not capture the inherent uncertainty among the entities and relations. Besides, many of them either bootstrap from heuristic patterns (e.g., Hearst patterns (Hearst, 1992)) or build on existing structured or semi-structured knowledge bases (e.g., WordNet (Fellbaum, 1998) and Wikipedia1), thus are limited in coverage. Moreover, they often focus on inducing ontology over individual words rather than arbitrarily large meaning units (e.g., idioms, phrasal verbs, etc.). Mo</context>
</contexts>
<marker>Wu, Weld, 2008</marker>
<rawString>Fei Wu and Daniel S. Weld. 2008. Automatically refining the wikipedia infobox ontology. In Proceedings of the Seventeenth International Conference on World Wide Web, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>34--255</pages>
<contexts>
<context position="28984" citStr="Yates and Etzioni, 2009" startWordPosition="4717" endWordPosition="4720"> 2007) is the state-ofthe-art system for open-domain information extraction. It inputs text and outputs relational triples in the form (R, A1, A2), where R is the relation string, and A1, A2 the argument strings. To answer questions, each triple-question pair is considered in turn by first matching their relation strings, and then the available argument strings. If both match, the remaining argument string in the triple is returned as an answer. Results were reported when exact match is used (TR-EXACT), or when the triple strings may contain the question ones as substrings (TR-SUB). RESOLVER (Yates and Etzioni, 2009) inputs TextRunner triples and collectively resolves coreferent relation and argument strings. To answer questions, the only difference from TextRunner is that a question string can match any string in its cluster. As in TextRunner, results were reported for both exact match (RS-EXACT) and substring (RS-SUB). DIRT (Lin and Pantel, 2001) resolves binary rela302 Table 1: Comparison of question answering results on the GENIA dataset. Results for systems other than OntoUSP are from Poon &amp; Domingos (2009). # Total # Correct Accuracy KW 150 67 45% KW-SYN 87 67 77% TR-EXACT 29 23 79% TR-SUB 152 81 53</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal of Artificial Intelligence Research, 34:255–296.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>