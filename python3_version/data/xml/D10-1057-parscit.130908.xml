<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019819">
<title confidence="0.980924">
We’re Not in Kansas Anymore: Detecting Domain Changes in Streams
</title>
<author confidence="0.981728">
†*Mark Dredze and †*Tim Oates and †$Christine Piatko
</author>
<affiliation confidence="0.988289">
†Human Language Technology Center of Excellence,
*Center for Language and Speech Processing,
$Applied Physics Lab
Johns Hopkins University
*University of Maryland, Baltimore County
</affiliation>
<email confidence="0.998209">
mdredze@cs.jhu.edu, oates@umbc.edu, christine.piatko@jhuapl.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999773666666667">
Domain adaptation, the problem of adapting
a natural language processing system trained
in one domain to perform well in a differ-
ent domain, has received significant attention.
This paper addresses an important problem for
deployed systems that has received little at-
tention – detecting when such adaptation is
needed by a system operating in the wild,
i.e., performing classification over a stream
of unlabeled examples. Our method uses A-
distance, a metric for detecting shifts in data
streams, combined with classification margins
to detect domain shifts. We empirically show
effective domain shift detection on a variety of
data sets and shift conditions.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995072">
Consider a named entity recognition system trained
on newswire stories. Given annotated documents
containing sentences like “Tony Hayward has faced
fresh criticism for taking time off to go sailing ...”
we would like to learn a model that will allow us to
recognize that “Obama” and “BP” are named enti-
ties in a sentence like “Obama summoned BP ex-
ecutives ...”. When all of the documents come
from one data distribution, like newswire articles,
this tends to work well. However, the sentence
“OBAMA SUMMONED BP EXECUTIVES ...”
from transcribed broadcast news, and others like it,
will probably lead to poor results because the fea-
tures it relies on have changed. For example, capi-
talization patterns are no longer a good indicator of
the presence of a named entity and appositives are
not indicated by punctuation. This problem of do-
main shift is a pervasive problem in NLP in which
any kind of model – a parser, a POS tagger, a senti-
ment classifier – is tested on data that do not match
the training data.
Given a model and a stream of unlabeled in-
stances, we are interested in automatically detecting
changes in the feature distribution that negatively
impact classification accuracy. For example, a senti-
ment classification model trained on book reviews
may heavily weight n-grams features like “uplift-
ing” and “page turner”. Those features may never
occur in reviews of kitchen appliances that get mixed
in at test time, and useful features in this new do-
main like “efficient” and “noisy compressor” will
have never been seen during training and therefore
not be in the model. Furthermore, we do not assume
labeled instances are available to help detect these
harmful changes. Other tasks related to changes
in data distributions, like detecting concept drift in
which the labeling function changes, may require la-
beled instances, but that is not the focus of this paper.
There is significant work on the related problem
of adapting a classifier for a known domain shift.
Versions of this problem include adapting using only
unlabeled target domain data (Blitzer et al., 2006;
Blitzer et al., 2007; Jiang and Zhai, 2007), adapt-
ing using a limited amount of target domain labeled
data (Daum´e, 2007; Finkel and Manning, 2009), and
learning across multiple domains simultaneously in
an online setting (Dredze and Crammer, 2008b).
However, in practical settings, we do not know if
the data distribution will change, and certainly not
when. Additionally, we will not know to what do-
</bodyText>
<page confidence="0.980243">
585
</page>
<note confidence="0.8176485">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999964951219512">
main the shift will happen. A discussion forum de-
voted to science fiction books may change over time
to focus more on fantasy and then narrow to discus-
sions of vampire fiction. Maybe this shift is harm-
less and it is possible to identify the sentiment of the
discussants with the original model with no loss in
accuracy. If not, we seek methods that detect this
shift and trigger the use of an adaptation method.
Our domain shift detection problem can be de-
composed into two subproblems: detecting distribu-
tional changes in streams of real numbers, and rep-
resenting a stream of examples as a stream of real
numbers informative for distribution change detec-
tion. We select the A-distance metric (Kifer et al.,
2004) to solve the first subproblem since it has been
previously used in other domain adaptation work
(Blitzer et al., 2006; Blitzer et al., 2007). Our main
contribution is towards the second problem, repre-
senting examples as real numbers for this task. We
demonstrate that classification margins, which in-
corporate information about features that most im-
pact system accuracy, can effectively solve the sec-
ond subproblem. Furthermore, we show that the pre-
viously proposed Confidence Weighted learning al-
gorithm (Dredze et al., 2008) can provide a more
informative measure than a simple margin for this
task. Our experiments include evaluations on com-
monly used domain adaptation data and false change
scenarios, as well as comparisons to supervised de-
tection methods that observe label values, or have
knowledge of the target domain.
We begin with a description of our task and pre-
vious applications to language data. After describ-
ing the data used in this paper, we discuss the A-
distance metric and how it has previously been used
for adaptation. We then show that margin based
methods effectively capture information to detect
domain shifts, and propose an alternate way of gen-
erating informative margin values. Finally, we com-
pare our results to settings with supervised knowl-
edge, and close with a survey of related work.
</bodyText>
<sectionHeader confidence="0.903834" genericHeader="introduction">
2 Domain Shifts in Language Data
</sectionHeader>
<bodyText confidence="0.999778538461539">
The study of domain shifts in language data has been
the purview of domain adaptation and transfer learn-
ing, which seek to adapt or transfer a model learned
on one source domain with labeled data to another
target domain with few or no labeled examples. For-
mally, errors from such transfers have two sources:
differences in feature distributions and changes to la-
beling functions (annotation standards) (Ben-David
et al., 2006; Ben-David et al., 2009). Empirical work
on NLP domain shifts has focused on the former.
For example, Blitzer et al. (2007) learned correspon-
dences between features across domains and Jiang
and Zhai (2007) weighted source domain examples
by their similarity to the target distribution.
We continue in this tradition by making two as-
sumptions about our setting. First, a change in do-
main will be signaled by a change in the feature
distributions. That is, new words, phrases, syntac-
tic structures, etc. signal that the system has shifted
to a new domain. Second, while there may be a
change in the labeling function, i.e., features have a
different meaning in each domain, this will be a sec-
ondary concern. For example, both Daum´e (2007)
and Dredze and Crammer (2008b) assume that do-
mains are more similar than different.
A similar problem to the one we consider is that
of concept drift, where a stream of examples are
labeled with a shifting labeling function (concept)
(Nishida and Yamauchi, 2007; Widmer and Kubat,
1996). While concept drift is similar there are two
important differences. First, concept drift can be
measured using a stream of labeled examples, so
system accuracy is directly measured. For exam-
ple, Klinkenberg and Joachims (2000) detect con-
cept drift with support vector machines, using es-
timates of leave-one-out performance to adaptively
adjust and maintain a training window that mini-
mizes estimated generalization error. This is pos-
sible only because class labels arrive with the exam-
ples in the stream. Another concept drift detection
algorithm, STEPD, uses a statistical test to continu-
ally monitor the possibly changing stream, measur-
ing system accuracy directly, again using the labels
it receives for each example (Nishida, 2008). Ob-
viously, no such labels are available in our unsuper-
vised setting. Second, concept drift assumes only
changes in the labeling function, whereas domain
adaptation relies on feature distribution changes.
Several properties of detecting domain shifts in
natural language streams distinguish it from tradi-
tional domain adaptation, concept drift, and other
related tasks:
</bodyText>
<page confidence="0.994862">
586
</page>
<listItem confidence="0.9984562">
• No Target Distribution Examples Blitzer et
al. (2007) estimate the loss in accuracy from
domain shift by discriminating between two
data distributions. In our setting, we have no
knowledge of the target distribution.
• No Labeled Target Data Some approaches to
domain adaptation assume a limited number of
labeled examples (Daum´e, 2007; Dredze and
Crammer, 2008b; Finkel and Manning, 2009).
We assume no labels in our setting.
• Online Setting Domain adaptation typically
assumes a batch transfer between two domains.
We consider a purely stream (online) setting.
• Computationally Constrained Our approach
must be fast, as we expect to run our domain
shift detector alongside a deployed NLP sys-
tem. This limits both computation and storage.
• Unknown Adaptation A critical assumption
of previous work is that a domain change has
occurred. We must ascertain this ourselves.
</listItem>
<bodyText confidence="0.998614125">
Despite these challenges, we show unsupervised
stream-based methods that effectively identify shifts
in domain in language data. Furthermore, our meth-
ods are tied directly to the learning task so are sen-
sitive to changes in actual task accuracy. Our meth-
ods have low false positive rates of change detection,
which is important since examples within a single
domain display a large amount of variance, which
could be mistaken for a domain change.
Once a change is detected, any number of actions
may be appropriate. The maintainer of the system
may be notified that performance is suffering, la-
bels can be obtained for a sample of instances from
the stream for retraining, or large volumes of unla-
beled instances can be used for instance reweighting
(Jiang and Zhai, 2007).
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="method">
3 Datasets
</sectionHeader>
<bodyText confidence="0.999952071428571">
We begin the presentation of our methods by de-
scribing the data used in our experiments. We se-
lected three data sets commonly used in domain
adaptation: spam (Jiang and Zhai, 2007), ACE 2005
named entity recognition (Jiang and Zhai, 2007),
and sentiment (Blitzer et al., 2007). Sentiment and
spam are binary and ACE is multi-class. Note that
in all experiments, a shift in the domain yields a de-
crease in system accuracy.
The goal of the spam data is to classify an email
(bag-of-words) as either spam or ham (not-spam).
Each email user may have different preferences and
features. We used unigram and bigram features, fol-
lowing Dredze and Crammer (2008b) for feature ex-
traction, and used the three task A users as three
domains. The ACE 2005 named entity recognition
dataset includes 7 named entity class labels (person,
organization, location, geopolitical entity, facility,
vehicle, weapon) for 5 text genres (newswire, broad-
cast news, broadcast conversations, conversational
telephone speech, weblogs). We use 4000 examples
from each genre and used Jiang and Zhai’s feature-
extracted data.1 The sentiment data contains reviews
from Amazon for four product types: books, dvds,
electronics, and kitchen. We include an additional
two types (music and video from Dredze and Cram-
mer) in our false shift experiments and use unigram
and bigram features, following Blitzer et al.
</bodyText>
<sectionHeader confidence="0.995468" genericHeader="method">
4 The A-Distance
</sectionHeader>
<bodyText confidence="0.999841545454546">
Our approach to detecting domain shifts in data
streams that negatively impact system accuracy is
based on the ability to (1) detect distributional
changes in streams of real numbers and (2) con-
vert document streams to streams of informative real
numbers. This section describes how we achieve the
former, and the next section describes the latter.
Theoretical work on domain adaptation showed
that the A-distance (Kifer et al., 2004), a stream
based measure of difference between two arbitrary
probability distributions P and P�, can be used to
evaluate the difference between two domain distri-
butions (Ben-David et al., 2006). In a batch set-
ting this corresponds to learning a linear classi-
fier to discriminate the domains, and Blitzer et al.
(2007) showed correlations with the error from do-
main adaptation. Given our interest in streaming
data we return to the original stream formulation of
A-distance.
The A-distance detects differences between two
arbitrary probability distributions by dividing the
range of a random variable into a set of (possibly
</bodyText>
<footnote confidence="0.939285">
1We thank Jing Jiang for the feature-extracted ACE data.
</footnote>
<page confidence="0.992486">
587
</page>
<figureCaption confidence="0.727423">
Figure 1: The A-distance is computed between two win-
dows (P and P&apos; in a stream of real-valued data. The sam-
ples in each window are divided into intervals, and the
A-distance measures the change in the distributions over
these intervals between the two windows.
</figureCaption>
<bodyText confidence="0.9991792">
overlapping) intervals, and then measures changes
in the probability that a value drawn for that variable
falls into any one of the intervals. If such a change is
large, a change in the underlying distribution is de-
clared. Let A be a set of real intervals and let A E A
be one such interval. For that interval, P(A) is the
probability that a value drawn from some unknown
distribution falls in A. The A-distance between P
and P0, i.e. the difference between two distributions
over the intervals, is defined as follows:
</bodyText>
<equation confidence="0.510238">
dA(P, P0) = 2 sup A∈A|P(A) − P0(A)|�
</equation>
<bodyText confidence="0.999926835820896">
Two distributions are said to be different when, for
a user-specified threshold c, dA(P, P0) &gt; c. The
A-distance is distribution independent. That is, it
makes no assumptions about the form of the under-
lying distribution nor about the form of the change
that might occur, either algorithmically or in the un-
derlying theory. Unlike the Li norm, the A-distance
can be shown to require finitely many samples to de-
tect distribution differences, a property that is crucial
for streaming, sample-based approaches.
Since the A-distance processes a stream of real
numbers, we need to represent an example using a
real number, such as the classification margin for
that example. The first n of these numbers in the
stream are a sample from P, and the most recent
n are a sample from P0. We signal a domain shift
when the A-distance between P and P0 is large
(greater than c). Larger values of n result in more
accurate estimates of P(A) and slower detection of
changes.
The two windows of samples of size n are shown
graphically in Fig. 1. Each increment on the hori-
zontal axis represents the arrival of a new document.
The vertical axis is some value computed from each
document, such as its classification margin. To com-
pute P and P0, one needs to specify A and n, which
are shown as two stacks of boxes that are identical
except for their position. The width of each box is
n, the number of examples used to estimate P(A)
and P(A0) for A E A, where the real interval A cor-
responds to the vertical span of the box. The value
P(A) is simply the number of documents whose real
value falls inside that interval A divided by n. Note
that the first n documents in the stream are used to
compute P, and as each new document arrives the
location of the stack of boxes used to compute P0 is
shifted to the right by one.
In Fig. 1, the number of examples whose real
value falls in the top two intervals for P is approxi-
mately the same, with no example’s value falling in
the lower two intervals. For P0, almost every one
of the n document values falls in the second interval
from the top, virtually assuring that dA(P, P0) will
be large. Though the intervals in the figure do not
overlap, they typically do.
Given n and intervals A, the value of c is chosen
by randomization testing. Because the A-distance is
distribution independent, a sample of size m » n is
drawn from any distribution that spans A. This sam-
ple is treated as a stream as described above, and
the largest value of dA(P, P0) is stored. The sam-
ple is permuted and this process is repeated l times.
Note that any change detection would be a false pos-
itive because all values were sampled from the same
distribution. The values dA(P, P0) are sorted from
largest to smallest, and c is chosen to be the Lαl]th
such value where parameter α is a user specified
false positive probability.
Both the time and space complexity of our ap-
proach based on the A-distance are small. Given
n and A, n instances must be stored in the sliding
window and 2|A |counters are required to represent
P and P0. Note that both values are constants based
on user specified parameters, not on the size of the
stream. Processing a new instance involves comput-
ing its margin and updating P and P0, all of which
can occur in constant time.
</bodyText>
<page confidence="0.995938">
588
</page>
<figureCaption confidence="0.889250428571429">
Figure 2: Each column of plots is a representative result using an SVM on a single run over a sentiment data shift:
dvds → electronics, electronics → books, and kitchen → books, from left to right. The horizontal axis is the number
of instances from the stream processed by the classifier. The top plot is the accuracy of the classifier on the last 100
instances. The bottom plot is the absolute value of the SVM classification margin. The vertical line at 500 instances
marks the point of domain shift. Horizontal dotted lines indicate the mean of the accuracy/margin before and after the
domain shift. Note that in all cases, the mean accuracy drops, as do the mean margin values, demonstrating that both
can indicate domain shifts.
</figureCaption>
<sectionHeader confidence="0.896498" genericHeader="method">
5 A-Distance Over Margins
</sectionHeader>
<bodyText confidence="0.999915590909091">
Since shifts in domains correlate with changes in
distributions, it is natural to begin by considering the
observed features in each example. When we shift
from a source domain (e.g., book reviews) to a target
domain (e.g., dvd reviews) we expect a change in the
distribution for common source words (“author” and
“plot” become less common). Since the A-distance
assumes a stream of single values, we can apply an
A-distance detector to each feature (e.g., unigram
and bigram count) individually. However, our exten-
sive experiments with this approach (omitted here)
show that it suffers from a number of flaws, such as
a high false positive rate if all features are tracked,
the difficult problem of identifying an informative
subset of features for tracking, and deciding how
many such features need to change before a shift has
occurred, which turns out to be highly variable be-
tween shifts.
Therefore, our goal is to use a single A-distance
tracker by collapsing each example to a single value.
One way of doing this is to consider the classifica-
tion margin produced by the classifier. The mar-
gin weighs features by their importance in classi-
fication. When more important features disappear,
we expect the magnitude of the margin to decrease.
Additionally, features that change but do not in-
fluence system performance are effectively ignored
since they do not influence the margin. This ap-
proach has the advantage of task sensitivity, only
tracking changes that impact task accuracy. Initial
experiments showed effectiveness with the unsigned
(absolute value of the) margin, which we use in all
experiments.
We begin by examining visually the information
content of the margin with regards to predicting a
domain shift. The caption of Fig. 2 describes the
setup, and the first row of the figure illustrates the
effects of the shift on the source domain classifier’s
empirical accuracy, measured on a window of the
previous 100 examples. The horizontal dashed lines
indicate the average accuracy before and after the
shift. Note that in each case, average classification
accuracy drops after the shift. However, at any one
point the accuracy displays considerable variance.
Thus, while classification accuracy clearly suffers, it
is difficult to measure this even in a supervised set-
ting with labeled examples when considering a small
portion of the stream.
The second row of Fig. 2 shows the average un-
signed margin value of an SVM classifier computed
over the previous 100 examples in the stream. The
two dashed horizontal lines indicate the average
margin value over source and target examples. There
is a clear drop in the average margin value after the
shift. This difference suggests that the margin can
be examined directly to detect a domain shift. How-
ever, these values vary considerably so extracting
useful information is not trivial.
We evaluated the ability of A-distance trackers to
detect such changes in margin values by simulat-
ing domain shifts using each domain pair in a task
(books to dvds, weblogs to newswire, etc.). For
each domain shift setting, we first trained a classi-
fier on 1000 source domain instances. In our ex-
periments, we used three different classification al-
gorithms: Support Vector Machines (SVM) (Chang
</bodyText>
<page confidence="0.981975">
589
</page>
<figure confidence="0.999673576271186">
1200
1000
800
600
400
200
00 200 400 600 800 1000 1200
CWPM
1400
1200
1000
800
600
400
200
00 200 400 600 800 1000 1200 1400
CWPM
CW
SVM
1400
1200
1000
400
800
600
200
00 200 400 600 800 1000 1200 1400
CWPM
spam
ace2005
sentiment
MIRA
300
250
200
150
100
50
00 50 100 150 200 250 300
CWPM
300
250
200
150
100
50
00 50 100 150 200 250 300
CWPM
300
250
200
150
100
50
00 50 100 150 200 250 300
CWPM
SVM
MIRA
CW
</figure>
<figureCaption confidence="0.93953075">
Figure 3: The mean number of instances after a domain change at which the A-distance tracker detects a change. Each
point represents the mean number of instances for CWPM (x-axis) and the SVM, MIRA and CW methods (y-axis).
Datasets are indicated by different markers. The second row zooms each plot to the bottom left corner of the first row.
Points above the diagonal indicate SVM, MIRA or CW took longer to detect a change than CWPM.
</figureCaption>
<bodyText confidence="0.999839911111111">
and Lin, 2001), MIRA (Crammer et al., 2006) and
Confidence Weighted (CW) learning (Dredze et al.,
2008). We evaluated each trained classifier on 500
test examples to measure accuracy on the source do-
main, and then used it to label examples in a stream.
The first 500 examples in the stream were used for
calibrating our change detection methods. The next
500 examples were from the source domain, fol-
lowed by 1500 examples from the target domain.
Over these 2000 examples we ran each of our de-
tection methods. Experiments were repeated over
10 fixed random data permutations.
We automatically select A-distance intervals as
follows. First, we computed the mean and variance
of the 500 calibration margins and then added inter-
vals for .5 standard deviations away from the mean
in each direction, .5 to 1 standard deviation in each
direction, and intervals for 1 standard deviation to
foo. We also added three evenly spaced overlap-
ping intervals. To calibrate a FP rate of 0.05 we
sampled from a Gaussian with the above mean and
variance and used n = 200, m = 10000 and l = 50.
The results for each experiment (38 shifts re-
peated averaged over 10 runs each) are shown in
Fig. 3.2 Each plot represents one of the three classi-
fiers (SVM, MIRA, CW) plotted on the vertical axis,
where each point’s y-value indicates the number of
examples observed after a shift occurred before the
A-distance detector registered a change. Smaller
values (lower points) are preferred. The second row
of plots highlights the 0 to 300 region of the first
row. (The x-axis will be discussed in the next sec-
tion.) Notice that in many cases, a change was reg-
istered within 300 examples, showing that domain
shifts can be reasonably detected using the margin
values alone.
Equally important to detecting changes is robust-
ness to false changes. We evaluated the margin de-
tector for false positives in two ways. First, we
logged any incorrectly detected changes before the
shift. For all three algorithms, there were very few
false positives (Table 1). The highest false positive
rate was about 1% (CW), while for the SVM experi-
ments, not a single detector fired prematurely in any
experiment.
</bodyText>
<footnote confidence="0.695556">
2The method plotted on the x-axis will be introduced in
the next section. To evaluate the three methods in this section
(SVM, MIRA, CW) compare the y-values.
</footnote>
<page confidence="0.995312">
590
</page>
<bodyText confidence="0.999996272727273">
Second, we sought to test the robustness of the
method over a long stream of examples where no
change occurred. In this experiment, we selected 11
domains that had a sufficient number of examples
to consider a long stream of source domain exam-
ples.3 Rather than use 500 source domain examples
followed by 1500 target domain examples, all 2000
examples were from the source domain. All other
settings were the same. For the SVM detector, out
of 110 runs we detected 6 false positives, 3 of which
were for the same data set (kitchen) (see Table 1.)
</bodyText>
<sectionHeader confidence="0.975754" genericHeader="method">
6 Confidence Weighted Margins
</sectionHeader>
<bodyText confidence="0.990063936507937">
In the previous section, we showed that margin val-
ues could be used to detect domain shifts. We now
explore ways to reduce the number of target domain
examples needed to detect domain shift by improv-
ing the margin values.
Margin values are often taken as a measure of
prediction confidence. From this perspective, the
A-distance margin tracker identifies when predic-
tion confidence drops. Another task that relies on
margins as measures of confidence is active learn-
ing, where uncertainty sampling for margin based
systems is determined based on the magnitude of
the predicted margin. Dredze and Crammer (2008a)
showed how Confidence Weighted (CW) learning
could be used to generate a more informative mea-
sure of confidence for active learning.
CW is an online algorithm inspired by the MIRA
update (Crammer et al., 2006), which ensures a pos-
itive margin while minimizing parameter change.
CW replaces the Euclidean distance used in the
MIRA update with the KL divergence over Gaussian
distributions. CW learning maintains a Gaussian
distribution over linear weight vectors with mean
µ E ][8�&apos; and diagonal covariance E E ][8�&apos;x�&apos;.
Maintaining a distribution over prediction func-
tions is appropriate for our task where we con-
sider margin values as confidence. We re-
place the margin |w · x|, where w is a stan-
dard linear classifier, with a probabilistic margin
 |(Prw_N(µi,Ei) [sign(w · z) = 1])−1�|. Dredze and
Crammer showed that this probabilistic margin can
be translated into a corrected geometric margin,
3ACE: bc, bn, cts, nw, wl; Sentiment: books, dvd, electron-
ics, kitchen, music, video
which is computed as the normalized margin as M =
M/-/V , where M is the mean M = µ·x and V the
variance V = xTEx of a univariate Gaussian dis-
tribution over the unsigned-margin M = w · x. We
call this method CWPM, for Confidence Weighted
Probabilistic Margin.
We compared using CWPM to the standard mar-
gins produced by an SVM, MIRA and CW classifier
in the last section. Fig. 3 shows the results of these
comparisons. In each plot, CWPM (normalized mar-
gin) is plotted on the x-axis, indicating how many
examples from the target domain were observed be-
fore the detector identified a change. The y-axis in
each plot is the number of instances observed for
the SVM, MIRA and CW methods. As before, each
point is the average of the 10 randomized runs used
above (assuming that detectors that did not fire do so
at the end of the stream.) Points above the diagonal
indicate that CWPM detected a change sooner than
the comparative method. Of the 38 shifts, CWPM
detected domain shifts faster than an SVM 34 times,
MIRA 26 times and CW 27 times.
We repeated the experiments to detect false posi-
tives for each margin based method. Table 1 shows
the false positives for the 38 domain shifts consid-
ered as well as the 11 false shift domain shifts. The
false positive rates are among the lowest for CWPM.
This shows that CWPM is a more useful indicator
for detecting domain changes.
</bodyText>
<sectionHeader confidence="0.993315" genericHeader="method">
7 Gradual Shifts
</sectionHeader>
<bodyText confidence="0.999895">
We have shown detection of sudden shifts between
the source and target domains. However, some shifts
may happen gradually over time. We evaluate this
by modifying the stream as follows: the first 500
instances come from the source domain, and the re-
maining 1500 are sampled randomly from the source
and target domains. The probability of an instance
being drawn from the target domain at time i is
A(x = target)= �
1500, where i counts from the start
of the shift at index 500. The probability of sam-
pling target domain data increases uniformly over
the stream. At index 750 after the start of the shift
each domain is equally likely. The ACE and Sen-
timent datasets had sufficient data to be evaluated
in this setting. Fig. 4 shows CWPM still performs
best, but results are close (SVM: 22 of 32, MIRA &amp;
</bodyText>
<page confidence="0.987991">
591
</page>
<figure confidence="0.998670171428571">
1600
1400
1200
1000
800
600
400
200
00 200 400 600 800 1000 1200 1400 1600
CWPM
1600
1400
1200
1000
800
600
400
200
00 200 400 600 800 1000 1200 1400 1600
CWPM
CW
1600
1400
1200
1000
800
600
400
ace2005
sentiment
00 200 400 600 800 1000 1200 1400 1600
CWPM
SVM
200
MIRA
</figure>
<figureCaption confidence="0.999318">
Figure 4: Gradual shift detection with SVM, MIRA or CW vs. CWPM. There were no false positives.
</figureCaption>
<table confidence="0.999790142857143">
Algorithm Domain Shift FPs
True Shift False Shift
Sec. 5: SVM 0 6
Sec. 6: MIRA 2 13
Sec. 6: CW 5 10
Sec. 6: CWPM 1 6
Total tests 380 110
</table>
<tableCaption confidence="0.9535">
Table 1: False positives (FPs) observed in true domain
shift and false domain shift experiments for methods in
corresponding sections. Each setting was run 10 times,
resulting in 380 true domain shifts and 110 false shifts.
</tableCaption>
<bodyText confidence="0.999550142857143">
CW: 17 of 32). As expected, detections happen later
in the stream. The closer results are likely due to
the increased difficulty of the task. With less clear
information, there it is more difficult for all the al-
gorithms to recognize a change, and performance
across the methods begins to equalize. Even in this
more difficult setting, CWPM is the best performer.
</bodyText>
<sectionHeader confidence="0.805385" genericHeader="method">
8 Comparison to Supervised Information
</sectionHeader>
<bodyText confidence="0.99992725">
So far we have considered applying A-distance
tracking to information freely available in a real
world system: the classification margins. As a use-
ful baseline for comparison, we can measure using
supervised sources of information, where additional
information is provided that is not normally avail-
able. In particular, we investigate two types of su-
pervised knowledge: the labels of examples in the
stream and knowledge of the target domain. In each
case, we compare using the A-distance and CWPM
versus applying the A-distance to supervised infor-
mation.
</bodyText>
<subsectionHeader confidence="0.998421">
8.1 Classifier Accuracy
</subsectionHeader>
<bodyText confidence="0.999980642857143">
In Sec. 4 we showed that both the margin and recent
classifier accuracy indicate when shifts in domains
occur (Fig. 2). We developed techniques based on
the margin, which is available at test time. We now
consider knowledge of the true labels for these test
examples, which allows for tracking classifier accu-
racy. We can use the A-distance to detect when un-
expected changes in accuracy occur.
For each test example classified by the system,
we evaluated whether the system was correct in its
prediction by examining the label. If the classifier
was correct, we output a 1; otherwise, we output a
0. Over this 1/0 stream produced by checking clas-
sifier accuracy we ran an A-distance detector, with
intervals set for 1s and 0s (10,000 uniform samples
to calibrate the threshold for a false positive rate of
0.05.) If an unusual number of 0s or 1s occur –
more or less mistakes than on the source domain – a
change is detected.4 Results on this accuracy stream
are compared to CWPM (Fig. 5.) Despite this su-
pervised information, CWPM still detects domain
changes faster than with labeled examples. Consider
again Fig. 2, which shows both accuracy and margin
values over time. While the average accuracy drops,
the instantaneous value is very noisy, suggesting that
even this additional information may not yield bet-
ter domain shift detection. This will be interesting
to explore in future work.
</bodyText>
<footnote confidence="0.916856333333333">
4An alternate approach would be to measure accuracy di-
rectly as a real valued number. However, our experiments
showed the discrete approach to be more effective.
</footnote>
<page confidence="0.993633">
592
</page>
<figure confidence="0.993367380952381">
300
250
200
150
100
50
00 50 100 150 200 250 300
CWPM
1600
1400
1200
1000
800
600
400
200
0
0 200 400 600 800 1000 1200 1400 1600
CWPM
Accuracy Detector
Accuracy Detector
</figure>
<figureCaption confidence="0.990782666666667">
Figure 5: An A-distance accuracy detector, run over a stream of 1s and 0s indicating correct and incorrect predictions
of the classifier on examples in a stream. The bulk of points above the line indicate that CWPM is more effective at
detecting domain change. CWPM had a single false positive and the accuracy detector had no false positives.
</figureCaption>
<subsectionHeader confidence="0.991268">
8.2 Domain Classification
</subsectionHeader>
<bodyText confidence="0.9999720625">
Next, we consider another source of supervision:
a selection of examples known to be from the tar-
get domain. In this setting, we know that a shift
will occur and we know to which domain it will oc-
cur. This requires a sample of (unlabeled) target do-
main examples when the target domain is not known
ahead of time. Using a common approach to detect-
ing domain differences when data is available from
both domains (Ben-David et al., 2009; Blitzer et al.,
2007; Rai et al., 2010), we train a binary classifier
to differentiate between the source and target do-
main. We learn a CW classifier on 1000 examples
(500 from each domain) that do not appear in the
test stream. We then label each example as either
“source” or “target” and output a 1 or 0 accordingly.
Over this 0/1 stream, we run an A-distance detector
with two intervals, one for 1s and one for 0s. The
remaining setup is identical to the A-distance exper-
iments above.
Fig. 6 shows the detection rate of CWPM versus
A-distance over the domain classifier stream. As ex-
pected, the detection rate for the domain classifier
is very fast, in almost every case (save 1) less than
400 examples after the shift happens. When CWPM
is slow to detect a change (over 400 examples), the
domain classifier is the clear winner. However, in
the majority of experiments, especially for ACE and
spam data, both detectors register a change quickly.
These results suggest that while a sample of target
domain examples is very helpful, our CWPM ap-
proach can also be effective when such samples are
not available.
</bodyText>
<sectionHeader confidence="0.999903" genericHeader="related work">
9 Related Work
</sectionHeader>
<bodyText confidence="0.9999063125">
Early NLP work in the unsupervised setting moni-
tored classification confidence values, setting a con-
fidence threshold based on a break-even heuristic,
monitoring the rate of (presumed) irrelevant exam-
ples based on this threshold, and signaling a change
when this rate increased (Lanquillon, 1999).
Confidence estimation has been used for specific
NLP components such as information extraction.
The correctness of fields extracted via a conditional
random field extractor has been shown to corre-
late well to an estimate obtained by a constrained
forward-backward technique (Culotta and McCal-
lum, 2004). EM-based confidence estimation has
been used to estimate the confidence of patterns
derived from partially supervised relation extrac-
tion (Agichtein, 2006). Confidence estimation has
also been used to improve the overall effectiveness
of NLP systems. Confidence estimates obtained via
neural networks have shown gains for speech recog-
nition, spoken language understanding, and machine
translation (Gandrabur et al., 2006). Pipeline models
using confidence estimates at one stage as weights
for further downstream stages improve over base-
line dependency parsing and named entity recogni-
tion pipeline models (Bunescu, 2008).
An alternative formulation of domain adaptation
trains on different corpora from many different do-
mains, then uses linear combinations of models
trained on the different corpora(McClosky et al.,
2010).
Work in novelty detection is relevant to the task
of detecting domain shifts (Scholkopf et al., 2000),
</bodyText>
<page confidence="0.994138">
593
</page>
<figure confidence="0.999583">
400 600 800 1000 1200
CWPM
300
250
200
150
100
50
00 50 100 150 200 250 300
CWPM
Domain Classifier
0
0 200
1200
1000
800
600
400
200
Domain Classifier
</figure>
<figureCaption confidence="0.993099">
Figure 6: A-distance over a stream of is and Os produced by a supervised classifier trained to differentiate between
the source and target domain. Samples from the unseen target domain is very effective. However, for many shifts, the
margin based A-distance detector is still competitive. CWPM had a single false positive while the domain classifier
stream had 2 false positives in these experiments.
</figureCaption>
<bodyText confidence="0.999907925925926">
though the rate of occurrence of novel instances is
more informative in our setting than the mere fact
that novel instances are observed.
We are also motivated by the problem of detect-
ing genre shift in addition to domain shift, as in the
ACE 2005 data set shifts from newswire to tran-
scripts and blogs. Different text genres occur in tra-
ditional settings, such as broadcast news transcripts
and newswire, and have begun to proliferate with
the variety of social media technologies now avail-
able including weblogs. Static genre classification
has been explored using a variety of techniques, in-
cluding exploiting punctuation (Kessler et al., 1997;
Dewdney et al., 2001), TF-IDF statistics (Lee and
Myaeng, 2002), and part-of-speech statistics and
histograms (Finn and Kushmerick, 2006; Feldman
et al., 2009).
Finally, statistical estimation in a streaming con-
text has been considered in data mining applica-
tions (Muthukrishnan, 2005). Change detection
via sequential hypothesis testing has been effective
for streaming applications such as network intrusion
detection (Muthukrishnan et al., 2007). Detecting
new events in a stream of Twitter posts can be done
using constant time and space similarity measures
based on a modification of locality sensitive hash-
ing (Petrovi´c et al., 2010).
</bodyText>
<sectionHeader confidence="0.995526" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.99997325">
While there are a number of methods for domain
adaptation, a system first needs to determine that a
domain shift has occurred. We have presented meth-
ods for automatically detecting such domain shifts
from a stream of (unlabeled) examples that require
limited computation and memory by virtue of op-
erating on fixed-size windows of data. Our meth-
ods were evaluated empirically on a variety of do-
main shifts using NLP data sets and are shown to
be sensitive to shifts while maintaining a low rate of
false positives. Additionally, we showed improved
detection results using a probabilistic margin based
on Confidence Weighted learning. Comparisons to
detection with supervised information show that our
results are effective even in unlabeled settings. Our
methods are promising as tools to accompany the de-
ployment of domain adaptation algorithms, so that a
complete system can first identify when a domain
shift has occurred before automatically adapting to
the new domain.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999635">
Thanks to the HLTCOE text processing group for
many helpful discussions.
</bodyText>
<sectionHeader confidence="0.99925" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993573">
Eugene Agichtein. 2006. Confidence estimation meth-
ods for partially supervised information extraction. In
SDM.
Shai Ben-David, John Blitzer, Koby Crammer, and Fer-
nando Pereira. 2006. Analysis of representations for
domain adaptation. In NIPS.
Shai Ben-David, John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Jennifer Vaughan.
2009. A theory of learning from different domains.
Machine Learning.
</reference>
<page confidence="0.985219">
594
</page>
<reference confidence="0.999796886597938">
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In EMNLP.
John Blitzer, Mark Dredze, and Fernando Pereira. 2007.
Biographies, Bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classification. In As-
sociation for Computational Linguistics (ACL).
Razvan C. Bunescu. 2008. Learning with probabilistic
features for improved pipeline models. In EMNLP.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/˜cjlin/libsvm.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research (JMLR).
Aron Culotta and Andrew McCallum. 2004. Confidence
estimation for information extraction. In North Amer-
ican Chapter of the Association for Computational
Linguistics - Human Language Technologies (NAACL-
HLT).
Hal Daum´e. 2007. Frustratingly easy domain adaptation.
In Association for Computational Linguistics (ACL).
Nigel Dewdney, Carol VanEss-Dykema, and Richard
MacMillan. 2001. The form is the substance: clas-
sification of genres in text. In Workshop on Human
Language Technology and Knowledge Management.
Mark Dredze and Koby Crammer. 2008a. Active learn-
ing with confidence. In Association for Computational
Linguistics (ACL).
Mark Dredze and Koby Crammer. 2008b. Online meth-
ods for multi-domain learning and adaptation. In
EMNLP.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
ICML.
S. Feldman, M. A. Marin, M. Ostendorf, and M. R.
Gupta. 2009. Part-of-speech histograms for genre
classification of text. In International Conference on
Acoustics, Speech, and Signal Processing (ICASSP).
Jenny Rose Finkel and Christopher D. Manning. 2009.
Hierarchical Bayesian domain adaptation. In NAACL-
HLT.
Aidan Finn and Nicholas Kushmerick. 2006. Learning to
classify documents according to genre: Special topic
section on computational analysis of style. J. Am. Soc.
Inf. Sci. Technol., 57(11):1506–1518.
Simona Gandrabur, George Foster, and Guy Lapalme.
2006. Confidence estimation for NLP applications.
ACM Trans. Speech Lang. Process., 3(3):1–29.
Jing Jiang and ChengXiang Zhai. 2007. Instance weight-
ing for domain adaptation in NLP. In Association for
Computational Linguistics (ACL).
Brett Kessler, Geoffrey Numberg, and Hinrich Sch¨utze.
1997. Automatic detection of text genre. In Associa-
tion for Computational Linguistics (ACL).
Daniel Kifer, Shai Ben-David, and Johannes Gehrke.
2004. Detecting change in data streams. In Very Large
Data Bases (VLDB).
Ralf Klinkenberg and Thorsten Joachims. 2000. Detect-
ing concept drift with support vector machines. In In-
ternational Conference on Machine Learning (ICML).
C. Lanquillon. 1999. Information filtering in changing
domains. In IJCAI.
Yong-Bae Lee and Sung Hyon Myaeng. 2002. Text
genre classification with genre-revealing and subject-
revealing features. In SIGIR.
David McClosky, Eugene Charniak, and Mark Johnson.
2010. Automatic domain adaptation for parsing. In
NAACL-HLT, pages 28–36, Los Angeles, California,
June. Association for Computational Linguistics.
S. Muthukrishnan, Eric van den Berg, and Yihua Wu.
2007. Sequential change detection on data streams. In
IEEE International Conference on Data Mining Work-
shops (ICDMW).
S. Muthukrishnan. 2005. Data streams: Algorithms and
applications. Foundations and Trends in Theoretical
Computer Science, 1(2).
Kyosuke Nishida and Koichiro Yamauchi. 2007. Detect-
ing concept drift using statistical testing. In Discovery
Science.
Kyosuke Nishida. 2008. Learning and Detecting Con-
cept Drift. Ph.D. thesis, Hokkaido University, Japan.
Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko.
2010. Streaming first story detection with application
to twitter. In NAACL-HLT, pages 181–189, June.
P. Rai, A. Saha, H. Daum´e III, and S. Venkatasubrama-
nian. 2010. Domain Adaptation meets Active Learn-
ing. In Workshop on Active Learning for Natural Lan-
guage Processing (ALNLP), page 27.
Bernhard Scholkopf, Robert Williamson, Alex Smola,
John Shawe-Taylor, and John Platt. 2000. Support
vector method for novelty detection. In NIPS.
Gerhard Widmer and Miroslav Kubat. 1996. Learning
in the presence of concept drift and hidden contexts.
Machine Learning, 23:69–101.
</reference>
<page confidence="0.998669">
595
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.325292">
<title confidence="0.8140024">We’re Not in Kansas Anymore: Detecting Domain Changes in Streams Dredze Oates Language Technology Center of *Center for Language and Speech Physics</title>
<author confidence="0.647566">Johns Hopkins of Maryland</author>
<author confidence="0.647566">Baltimore</author>
<email confidence="0.999858">mdredze@cs.jhu.edu,oates@umbc.edu,christine.piatko@jhuapl.edu</email>
<abstract confidence="0.9997481875">Domain adaptation, the problem of adapting a natural language processing system trained in one domain to perform well in a different domain, has received significant attention. This paper addresses an important problem for deployed systems that has received little attention – detecting when such adaptation is needed by a system operating in the wild, i.e., performing classification over a stream unlabeled examples. Our method uses distance, a metric for detecting shifts in data streams, combined with classification margins to detect domain shifts. We empirically show effective domain shift detection on a variety of data sets and shift conditions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
</authors>
<title>Confidence estimation methods for partially supervised information extraction.</title>
<date>2006</date>
<booktitle>In SDM.</booktitle>
<contexts>
<context position="34289" citStr="Agichtein, 2006" startWordPosition="5787" endWordPosition="5788">euristic, monitoring the rate of (presumed) irrelevant examples based on this threshold, and signaling a change when this rate increased (Lanquillon, 1999). Confidence estimation has been used for specific NLP components such as information extraction. The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique (Culotta and McCallum, 2004). EM-based confidence estimation has been used to estimate the confidence of patterns derived from partially supervised relation extraction (Agichtein, 2006). Confidence estimation has also been used to improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural networks have shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline models (Bunescu, 2008). An alternative formulation of domain adaptation trains on different corpora from many different domains, then uses linear combinatio</context>
</contexts>
<marker>Agichtein, 2006</marker>
<rawString>Eugene Agichtein. 2006. Confidence estimation methods for partially supervised information extraction. In SDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shai Ben-David</author>
<author>John Blitzer</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Analysis of representations for domain adaptation.</title>
<date>2006</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="6221" citStr="Ben-David et al., 2006" startWordPosition="997" endWordPosition="1000">rnate way of generating informative margin values. Finally, we compare our results to settings with supervised knowledge, and close with a survey of related work. 2 Domain Shifts in Language Data The study of domain shifts in language data has been the purview of domain adaptation and transfer learning, which seek to adapt or transfer a model learned on one source domain with labeled data to another target domain with few or no labeled examples. Formally, errors from such transfers have two sources: differences in feature distributions and changes to labeling functions (annotation standards) (Ben-David et al., 2006; Ben-David et al., 2009). Empirical work on NLP domain shifts has focused on the former. For example, Blitzer et al. (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the la</context>
<context position="12039" citStr="Ben-David et al., 2006" startWordPosition="1927" endWordPosition="1930">approach to detecting domain shifts in data streams that negatively impact system accuracy is based on the ability to (1) detect distributional changes in streams of real numbers and (2) convert document streams to streams of informative real numbers. This section describes how we achieve the former, and the next section describes the latter. Theoretical work on domain adaptation showed that the A-distance (Kifer et al., 2004), a stream based measure of difference between two arbitrary probability distributions P and P�, can be used to evaluate the difference between two domain distributions (Ben-David et al., 2006). In a batch setting this corresponds to learning a linear classifier to discriminate the domains, and Blitzer et al. (2007) showed correlations with the error from domain adaptation. Given our interest in streaming data we return to the original stream formulation of A-distance. The A-distance detects differences between two arbitrary probability distributions by dividing the range of a random variable into a set of (possibly 1We thank Jing Jiang for the feature-extracted ACE data. 587 Figure 1: The A-distance is computed between two windows (P and P&apos; in a stream of real-valued data. The samp</context>
</contexts>
<marker>Ben-David, Blitzer, Crammer, Pereira, 2006</marker>
<rawString>Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. 2006. Analysis of representations for domain adaptation. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shai Ben-David</author>
<author>John Blitzer</author>
<author>Koby Crammer</author>
<author>Alex Kulesza</author>
<author>Fernando Pereira</author>
<author>Jennifer Vaughan</author>
</authors>
<title>A theory of learning from different domains.</title>
<date>2009</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="6246" citStr="Ben-David et al., 2009" startWordPosition="1001" endWordPosition="1004">informative margin values. Finally, we compare our results to settings with supervised knowledge, and close with a survey of related work. 2 Domain Shifts in Language Data The study of domain shifts in language data has been the purview of domain adaptation and transfer learning, which seek to adapt or transfer a model learned on one source domain with labeled data to another target domain with few or no labeled examples. Formally, errors from such transfers have two sources: differences in feature distributions and changes to labeling functions (annotation standards) (Ben-David et al., 2006; Ben-David et al., 2009). Empirical work on NLP domain shifts has focused on the former. For example, Blitzer et al. (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., fe</context>
<context position="32403" citStr="Ben-David et al., 2009" startWordPosition="5477" endWordPosition="5480">above the line indicate that CWPM is more effective at detecting domain change. CWPM had a single false positive and the accuracy detector had no false positives. 8.2 Domain Classification Next, we consider another source of supervision: a selection of examples known to be from the target domain. In this setting, we know that a shift will occur and we know to which domain it will occur. This requires a sample of (unlabeled) target domain examples when the target domain is not known ahead of time. Using a common approach to detecting domain differences when data is available from both domains (Ben-David et al., 2009; Blitzer et al., 2007; Rai et al., 2010), we train a binary classifier to differentiate between the source and target domain. We learn a CW classifier on 1000 examples (500 from each domain) that do not appear in the test stream. We then label each example as either “source” or “target” and output a 1 or 0 accordingly. Over this 0/1 stream, we run an A-distance detector with two intervals, one for 1s and one for 0s. The remaining setup is identical to the A-distance experiments above. Fig. 6 shows the detection rate of CWPM versus A-distance over the domain classifier stream. As expected, the</context>
</contexts>
<marker>Ben-David, Blitzer, Crammer, Kulesza, Pereira, Vaughan, 2009</marker>
<rawString>Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Vaughan. 2009. A theory of learning from different domains. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="3125" citStr="Blitzer et al., 2006" startWordPosition="492" endWordPosition="495">main like “efficient” and “noisy compressor” will have never been seen during training and therefore not be in the model. Furthermore, we do not assume labeled instances are available to help detect these harmful changes. Other tasks related to changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguisti</context>
<context position="4559" citStr="Blitzer et al., 2006" startWordPosition="727" endWordPosition="730">t is possible to identify the sentiment of the discussants with the original model with no loss in accuracy. If not, we seek methods that detect this shift and trigger the use of an adaptation method. Our domain shift detection problem can be decomposed into two subproblems: detecting distributional changes in streams of real numbers, and representing a stream of examples as a stream of real numbers informative for distribution change detection. We select the A-distance metric (Kifer et al., 2004) to solve the first subproblem since it has been previously used in other domain adaptation work (Blitzer et al., 2006; Blitzer et al., 2007). Our main contribution is towards the second problem, representing examples as real numbers for this task. We demonstrate that classification margins, which incorporate information about features that most impact system accuracy, can effectively solve the second subproblem. Furthermore, we show that the previously proposed Confidence Weighted learning algorithm (Dredze et al., 2008) can provide a more informative measure than a simple margin for this task. Our experiments include evaluations on commonly used domain adaptation data and false change scenarios, as well as </context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3147" citStr="Blitzer et al., 2007" startWordPosition="496" endWordPosition="499">and “noisy compressor” will have never been seen during training and therefore not be in the model. Furthermore, we do not assume labeled instances are available to help detect these harmful changes. Other tasks related to changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics main the shift will</context>
<context position="4582" citStr="Blitzer et al., 2007" startWordPosition="731" endWordPosition="734">ify the sentiment of the discussants with the original model with no loss in accuracy. If not, we seek methods that detect this shift and trigger the use of an adaptation method. Our domain shift detection problem can be decomposed into two subproblems: detecting distributional changes in streams of real numbers, and representing a stream of examples as a stream of real numbers informative for distribution change detection. We select the A-distance metric (Kifer et al., 2004) to solve the first subproblem since it has been previously used in other domain adaptation work (Blitzer et al., 2006; Blitzer et al., 2007). Our main contribution is towards the second problem, representing examples as real numbers for this task. We demonstrate that classification margins, which incorporate information about features that most impact system accuracy, can effectively solve the second subproblem. Furthermore, we show that the previously proposed Confidence Weighted learning algorithm (Dredze et al., 2008) can provide a more informative measure than a simple margin for this task. Our experiments include evaluations on commonly used domain adaptation data and false change scenarios, as well as comparisons to supervis</context>
<context position="6345" citStr="Blitzer et al. (2007)" startWordPosition="1018" endWordPosition="1021"> close with a survey of related work. 2 Domain Shifts in Language Data The study of domain shifts in language data has been the purview of domain adaptation and transfer learning, which seek to adapt or transfer a model learned on one source domain with labeled data to another target domain with few or no labeled examples. Formally, errors from such transfers have two sources: differences in feature distributions and changes to labeling functions (annotation standards) (Ben-David et al., 2006; Ben-David et al., 2009). Empirical work on NLP domain shifts has focused on the former. For example, Blitzer et al. (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both</context>
<context position="8413" citStr="Blitzer et al. (2007)" startWordPosition="1345" endWordPosition="1348">hm, STEPD, uses a statistical test to continually monitor the possibly changing stream, measuring system accuracy directly, again using the labels it receives for each example (Nishida, 2008). Obviously, no such labels are available in our unsupervised setting. Second, concept drift assumes only changes in the labeling function, whereas domain adaptation relies on feature distribution changes. Several properties of detecting domain shifts in natural language streams distinguish it from traditional domain adaptation, concept drift, and other related tasks: 586 • No Target Distribution Examples Blitzer et al. (2007) estimate the loss in accuracy from domain shift by discriminating between two data distributions. In our setting, we have no knowledge of the target distribution. • No Labeled Target Data Some approaches to domain adaptation assume a limited number of labeled examples (Daum´e, 2007; Dredze and Crammer, 2008b; Finkel and Manning, 2009). We assume no labels in our setting. • Online Setting Domain adaptation typically assumes a batch transfer between two domains. We consider a purely stream (online) setting. • Computationally Constrained Our approach must be fast, as we expect to run our domain </context>
<context position="10296" citStr="Blitzer et al., 2007" startWordPosition="1651" endWordPosition="1654">hange. Once a change is detected, any number of actions may be appropriate. The maintainer of the system may be notified that performance is suffering, labels can be obtained for a sample of instances from the stream for retraining, or large volumes of unlabeled instances can be used for instance reweighting (Jiang and Zhai, 2007). 3 Datasets We begin the presentation of our methods by describing the data used in our experiments. We selected three data sets commonly used in domain adaptation: spam (Jiang and Zhai, 2007), ACE 2005 named entity recognition (Jiang and Zhai, 2007), and sentiment (Blitzer et al., 2007). Sentiment and spam are binary and ACE is multi-class. Note that in all experiments, a shift in the domain yields a decrease in system accuracy. The goal of the spam data is to classify an email (bag-of-words) as either spam or ham (not-spam). Each email user may have different preferences and features. We used unigram and bigram features, following Dredze and Crammer (2008b) for feature extraction, and used the three task A users as three domains. The ACE 2005 named entity recognition dataset includes 7 named entity class labels (person, organization, location, geopolitical entity, facility,</context>
<context position="12163" citStr="Blitzer et al. (2007)" startWordPosition="1949" endWordPosition="1952">ct distributional changes in streams of real numbers and (2) convert document streams to streams of informative real numbers. This section describes how we achieve the former, and the next section describes the latter. Theoretical work on domain adaptation showed that the A-distance (Kifer et al., 2004), a stream based measure of difference between two arbitrary probability distributions P and P�, can be used to evaluate the difference between two domain distributions (Ben-David et al., 2006). In a batch setting this corresponds to learning a linear classifier to discriminate the domains, and Blitzer et al. (2007) showed correlations with the error from domain adaptation. Given our interest in streaming data we return to the original stream formulation of A-distance. The A-distance detects differences between two arbitrary probability distributions by dividing the range of a random variable into a set of (possibly 1We thank Jing Jiang for the feature-extracted ACE data. 587 Figure 1: The A-distance is computed between two windows (P and P&apos; in a stream of real-valued data. The samples in each window are divided into intervals, and the A-distance measures the change in the distributions over these interv</context>
<context position="32425" citStr="Blitzer et al., 2007" startWordPosition="5481" endWordPosition="5484">that CWPM is more effective at detecting domain change. CWPM had a single false positive and the accuracy detector had no false positives. 8.2 Domain Classification Next, we consider another source of supervision: a selection of examples known to be from the target domain. In this setting, we know that a shift will occur and we know to which domain it will occur. This requires a sample of (unlabeled) target domain examples when the target domain is not known ahead of time. Using a common approach to detecting domain differences when data is available from both domains (Ben-David et al., 2009; Blitzer et al., 2007; Rai et al., 2010), we train a binary classifier to differentiate between the source and target domain. We learn a CW classifier on 1000 examples (500 from each domain) that do not appear in the test stream. We then label each example as either “source” or “target” and output a 1 or 0 accordingly. Over this 0/1 stream, we run an A-distance detector with two intervals, one for 1s and one for 0s. The remaining setup is identical to the A-distance experiments above. Fig. 6 shows the detection rate of CWPM versus A-distance over the domain classifier stream. As expected, the detection rate for th</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
</authors>
<title>Learning with probabilistic features for improved pipeline models.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="34755" citStr="Bunescu, 2008" startWordPosition="5853" endWordPosition="5854">d confidence estimation has been used to estimate the confidence of patterns derived from partially supervised relation extraction (Agichtein, 2006). Confidence estimation has also been used to improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural networks have shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline models (Bunescu, 2008). An alternative formulation of domain adaptation trains on different corpora from many different domains, then uses linear combinations of models trained on the different corpora(McClosky et al., 2010). Work in novelty detection is relevant to the task of detecting domain shifts (Scholkopf et al., 2000), 593 400 600 800 1000 1200 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM Domain Classifier 0 0 200 1200 1000 800 600 400 200 Domain Classifier Figure 6: A-distance over a stream of is and Os produced by a supervised classifier trained to differentiate between the source and target</context>
</contexts>
<marker>Bunescu, 2008</marker>
<rawString>Razvan C. Bunescu. 2008. Learning with probabilistic features for improved pipeline models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.</title>
<date>2001</date>
<tech>tw/˜cjlin/libsvm.</tech>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu. tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research (JMLR).</journal>
<contexts>
<context position="21510" citStr="Crammer et al., 2006" startWordPosition="3587" endWordPosition="3590"> 150 200 250 300 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM SVM MIRA CW Figure 3: The mean number of instances after a domain change at which the A-distance tracker detects a change. Each point represents the mean number of instances for CWPM (x-axis) and the SVM, MIRA and CW methods (y-axis). Datasets are indicated by different markers. The second row zooms each plot to the bottom left corner of the first row. Points above the diagonal indicate SVM, MIRA or CW took longer to detect a change than CWPM. and Lin, 2001), MIRA (Crammer et al., 2006) and Confidence Weighted (CW) learning (Dredze et al., 2008). We evaluated each trained classifier on 500 test examples to measure accuracy on the source domain, and then used it to label examples in a stream. The first 500 examples in the stream were used for calibrating our change detection methods. The next 500 examples were from the source domain, followed by 1500 examples from the target domain. Over these 2000 examples we ran each of our detection methods. Experiments were repeated over 10 fixed random data permutations. We automatically select A-distance intervals as follows. First, we </context>
<context position="25191" citStr="Crammer et al., 2006" startWordPosition="4213" endWordPosition="4216">ng the margin values. Margin values are often taken as a measure of prediction confidence. From this perspective, the A-distance margin tracker identifies when prediction confidence drops. Another task that relies on margins as measures of confidence is active learning, where uncertainty sampling for margin based systems is determined based on the magnitude of the predicted margin. Dredze and Crammer (2008a) showed how Confidence Weighted (CW) learning could be used to generate a more informative measure of confidence for active learning. CW is an online algorithm inspired by the MIRA update (Crammer et al., 2006), which ensures a positive margin while minimizing parameter change. CW replaces the Euclidean distance used in the MIRA update with the KL divergence over Gaussian distributions. CW learning maintains a Gaussian distribution over linear weight vectors with mean µ E ][8�&apos; and diagonal covariance E E ][8�&apos;x�&apos;. Maintaining a distribution over prediction functions is appropriate for our task where we consider margin values as confidence. We replace the margin |w · x|, where w is a standard linear classifier, with a probabilistic margin |(Prw_N(µi,Ei) [sign(w · z) = 1])−1�|. Dredze and Crammer sho</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. Journal of Machine Learning Research (JMLR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Confidence estimation for information extraction.</title>
<date>2004</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACLHLT).</booktitle>
<contexts>
<context position="34132" citStr="Culotta and McCallum, 2004" startWordPosition="5763" endWordPosition="5767"> available. 9 Related Work Early NLP work in the unsupervised setting monitored classification confidence values, setting a confidence threshold based on a break-even heuristic, monitoring the rate of (presumed) irrelevant examples based on this threshold, and signaling a change when this rate increased (Lanquillon, 1999). Confidence estimation has been used for specific NLP components such as information extraction. The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique (Culotta and McCallum, 2004). EM-based confidence estimation has been used to estimate the confidence of patterns derived from partially supervised relation extraction (Agichtein, 2006). Confidence estimation has also been used to improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural networks have shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline</context>
</contexts>
<marker>Culotta, McCallum, 2004</marker>
<rawString>Aron Culotta and Andrew McCallum. 2004. Confidence estimation for information extraction. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACLHLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e. 2007. Frustratingly easy domain adaptation. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nigel Dewdney</author>
<author>Carol VanEss-Dykema</author>
<author>Richard MacMillan</author>
</authors>
<title>The form is the substance: classification of genres in text.</title>
<date>2001</date>
<booktitle>In Workshop on Human Language Technology and Knowledge Management.</booktitle>
<contexts>
<context position="36287" citStr="Dewdney et al., 2001" startWordPosition="6104" endWordPosition="6107"> is more informative in our setting than the mere fact that novel instances are observed. We are also motivated by the problem of detecting genre shift in addition to domain shift, as in the ACE 2005 data set shifts from newswire to transcripts and blogs. Different text genres occur in traditional settings, such as broadcast news transcripts and newswire, and have begun to proliferate with the variety of social media technologies now available including weblogs. Static genre classification has been explored using a variety of techniques, including exploiting punctuation (Kessler et al., 1997; Dewdney et al., 2001), TF-IDF statistics (Lee and Myaeng, 2002), and part-of-speech statistics and histograms (Finn and Kushmerick, 2006; Feldman et al., 2009). Finally, statistical estimation in a streaming context has been considered in data mining applications (Muthukrishnan, 2005). Change detection via sequential hypothesis testing has been effective for streaming applications such as network intrusion detection (Muthukrishnan et al., 2007). Detecting new events in a stream of Twitter posts can be done using constant time and space similarity measures based on a modification of locality sensitive hashing (Petr</context>
</contexts>
<marker>Dewdney, VanEss-Dykema, MacMillan, 2001</marker>
<rawString>Nigel Dewdney, Carol VanEss-Dykema, and Richard MacMillan. 2001. The form is the substance: classification of genres in text. In Workshop on Human Language Technology and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
</authors>
<title>Active learning with confidence.</title>
<date>2008</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3374" citStr="Dredze and Crammer, 2008" startWordPosition="531" endWordPosition="534">changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics main the shift will happen. A discussion forum devoted to science fiction books may change over time to focus more on fantasy and then narrow to discussions of vampire fiction. Maybe this shift is harmless and it is possible to identify the senti</context>
<context position="6988" citStr="Dredze and Crammer (2008" startWordPosition="1126" endWordPosition="1129">ences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar than different. A similar problem to the one we consider is that of concept drift, where a stream of examples are labeled with a shifting labeling function (concept) (Nishida and Yamauchi, 2007; Widmer and Kubat, 1996). While concept drift is similar there are two important differences. First, concept drift can be measured using a stream of labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adj</context>
<context position="8722" citStr="Dredze and Crammer, 2008" startWordPosition="1393" endWordPosition="1396">n the labeling function, whereas domain adaptation relies on feature distribution changes. Several properties of detecting domain shifts in natural language streams distinguish it from traditional domain adaptation, concept drift, and other related tasks: 586 • No Target Distribution Examples Blitzer et al. (2007) estimate the loss in accuracy from domain shift by discriminating between two data distributions. In our setting, we have no knowledge of the target distribution. • No Labeled Target Data Some approaches to domain adaptation assume a limited number of labeled examples (Daum´e, 2007; Dredze and Crammer, 2008b; Finkel and Manning, 2009). We assume no labels in our setting. • Online Setting Domain adaptation typically assumes a batch transfer between two domains. We consider a purely stream (online) setting. • Computationally Constrained Our approach must be fast, as we expect to run our domain shift detector alongside a deployed NLP system. This limits both computation and storage. • Unknown Adaptation A critical assumption of previous work is that a domain change has occurred. We must ascertain this ourselves. Despite these challenges, we show unsupervised stream-based methods that effectively id</context>
<context position="10673" citStr="Dredze and Crammer (2008" startWordPosition="1716" endWordPosition="1719">our methods by describing the data used in our experiments. We selected three data sets commonly used in domain adaptation: spam (Jiang and Zhai, 2007), ACE 2005 named entity recognition (Jiang and Zhai, 2007), and sentiment (Blitzer et al., 2007). Sentiment and spam are binary and ACE is multi-class. Note that in all experiments, a shift in the domain yields a decrease in system accuracy. The goal of the spam data is to classify an email (bag-of-words) as either spam or ham (not-spam). Each email user may have different preferences and features. We used unigram and bigram features, following Dredze and Crammer (2008b) for feature extraction, and used the three task A users as three domains. The ACE 2005 named entity recognition dataset includes 7 named entity class labels (person, organization, location, geopolitical entity, facility, vehicle, weapon) for 5 text genres (newswire, broadcast news, broadcast conversations, conversational telephone speech, weblogs). We use 4000 examples from each genre and used Jiang and Zhai’s featureextracted data.1 The sentiment data contains reviews from Amazon for four product types: books, dvds, electronics, and kitchen. We include an additional two types (music and vi</context>
<context position="24979" citStr="Dredze and Crammer (2008" startWordPosition="4178" endWordPosition="4181">ighted Margins In the previous section, we showed that margin values could be used to detect domain shifts. We now explore ways to reduce the number of target domain examples needed to detect domain shift by improving the margin values. Margin values are often taken as a measure of prediction confidence. From this perspective, the A-distance margin tracker identifies when prediction confidence drops. Another task that relies on margins as measures of confidence is active learning, where uncertainty sampling for margin based systems is determined based on the magnitude of the predicted margin. Dredze and Crammer (2008a) showed how Confidence Weighted (CW) learning could be used to generate a more informative measure of confidence for active learning. CW is an online algorithm inspired by the MIRA update (Crammer et al., 2006), which ensures a positive margin while minimizing parameter change. CW replaces the Euclidean distance used in the MIRA update with the KL divergence over Gaussian distributions. CW learning maintains a Gaussian distribution over linear weight vectors with mean µ E ][8�&apos; and diagonal covariance E E ][8�&apos;x�&apos;. Maintaining a distribution over prediction functions is appropriate for our t</context>
</contexts>
<marker>Dredze, Crammer, 2008</marker>
<rawString>Mark Dredze and Koby Crammer. 2008a. Active learning with confidence. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
</authors>
<title>Online methods for multi-domain learning and adaptation.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="3374" citStr="Dredze and Crammer, 2008" startWordPosition="531" endWordPosition="534">changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics main the shift will happen. A discussion forum devoted to science fiction books may change over time to focus more on fantasy and then narrow to discussions of vampire fiction. Maybe this shift is harmless and it is possible to identify the senti</context>
<context position="6988" citStr="Dredze and Crammer (2008" startWordPosition="1126" endWordPosition="1129">ences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar than different. A similar problem to the one we consider is that of concept drift, where a stream of examples are labeled with a shifting labeling function (concept) (Nishida and Yamauchi, 2007; Widmer and Kubat, 1996). While concept drift is similar there are two important differences. First, concept drift can be measured using a stream of labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adj</context>
<context position="8722" citStr="Dredze and Crammer, 2008" startWordPosition="1393" endWordPosition="1396">n the labeling function, whereas domain adaptation relies on feature distribution changes. Several properties of detecting domain shifts in natural language streams distinguish it from traditional domain adaptation, concept drift, and other related tasks: 586 • No Target Distribution Examples Blitzer et al. (2007) estimate the loss in accuracy from domain shift by discriminating between two data distributions. In our setting, we have no knowledge of the target distribution. • No Labeled Target Data Some approaches to domain adaptation assume a limited number of labeled examples (Daum´e, 2007; Dredze and Crammer, 2008b; Finkel and Manning, 2009). We assume no labels in our setting. • Online Setting Domain adaptation typically assumes a batch transfer between two domains. We consider a purely stream (online) setting. • Computationally Constrained Our approach must be fast, as we expect to run our domain shift detector alongside a deployed NLP system. This limits both computation and storage. • Unknown Adaptation A critical assumption of previous work is that a domain change has occurred. We must ascertain this ourselves. Despite these challenges, we show unsupervised stream-based methods that effectively id</context>
<context position="10673" citStr="Dredze and Crammer (2008" startWordPosition="1716" endWordPosition="1719">our methods by describing the data used in our experiments. We selected three data sets commonly used in domain adaptation: spam (Jiang and Zhai, 2007), ACE 2005 named entity recognition (Jiang and Zhai, 2007), and sentiment (Blitzer et al., 2007). Sentiment and spam are binary and ACE is multi-class. Note that in all experiments, a shift in the domain yields a decrease in system accuracy. The goal of the spam data is to classify an email (bag-of-words) as either spam or ham (not-spam). Each email user may have different preferences and features. We used unigram and bigram features, following Dredze and Crammer (2008b) for feature extraction, and used the three task A users as three domains. The ACE 2005 named entity recognition dataset includes 7 named entity class labels (person, organization, location, geopolitical entity, facility, vehicle, weapon) for 5 text genres (newswire, broadcast news, broadcast conversations, conversational telephone speech, weblogs). We use 4000 examples from each genre and used Jiang and Zhai’s featureextracted data.1 The sentiment data contains reviews from Amazon for four product types: books, dvds, electronics, and kitchen. We include an additional two types (music and vi</context>
<context position="24979" citStr="Dredze and Crammer (2008" startWordPosition="4178" endWordPosition="4181">ighted Margins In the previous section, we showed that margin values could be used to detect domain shifts. We now explore ways to reduce the number of target domain examples needed to detect domain shift by improving the margin values. Margin values are often taken as a measure of prediction confidence. From this perspective, the A-distance margin tracker identifies when prediction confidence drops. Another task that relies on margins as measures of confidence is active learning, where uncertainty sampling for margin based systems is determined based on the magnitude of the predicted margin. Dredze and Crammer (2008a) showed how Confidence Weighted (CW) learning could be used to generate a more informative measure of confidence for active learning. CW is an online algorithm inspired by the MIRA update (Crammer et al., 2006), which ensures a positive margin while minimizing parameter change. CW replaces the Euclidean distance used in the MIRA update with the KL divergence over Gaussian distributions. CW learning maintains a Gaussian distribution over linear weight vectors with mean µ E ][8�&apos; and diagonal covariance E E ][8�&apos;x�&apos;. Maintaining a distribution over prediction functions is appropriate for our t</context>
</contexts>
<marker>Dredze, Crammer, 2008</marker>
<rawString>Mark Dredze and Koby Crammer. 2008b. Online methods for multi-domain learning and adaptation. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="4968" citStr="Dredze et al., 2008" startWordPosition="789" endWordPosition="792">ative for distribution change detection. We select the A-distance metric (Kifer et al., 2004) to solve the first subproblem since it has been previously used in other domain adaptation work (Blitzer et al., 2006; Blitzer et al., 2007). Our main contribution is towards the second problem, representing examples as real numbers for this task. We demonstrate that classification margins, which incorporate information about features that most impact system accuracy, can effectively solve the second subproblem. Furthermore, we show that the previously proposed Confidence Weighted learning algorithm (Dredze et al., 2008) can provide a more informative measure than a simple margin for this task. Our experiments include evaluations on commonly used domain adaptation data and false change scenarios, as well as comparisons to supervised detection methods that observe label values, or have knowledge of the target domain. We begin with a description of our task and previous applications to language data. After describing the data used in this paper, we discuss the Adistance metric and how it has previously been used for adaptation. We then show that margin based methods effectively capture information to detect dom</context>
<context position="21570" citStr="Dredze et al., 2008" startWordPosition="3596" endWordPosition="3599">0 250 300 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM SVM MIRA CW Figure 3: The mean number of instances after a domain change at which the A-distance tracker detects a change. Each point represents the mean number of instances for CWPM (x-axis) and the SVM, MIRA and CW methods (y-axis). Datasets are indicated by different markers. The second row zooms each plot to the bottom left corner of the first row. Points above the diagonal indicate SVM, MIRA or CW took longer to detect a change than CWPM. and Lin, 2001), MIRA (Crammer et al., 2006) and Confidence Weighted (CW) learning (Dredze et al., 2008). We evaluated each trained classifier on 500 test examples to measure accuracy on the source domain, and then used it to label examples in a stream. The first 500 examples in the stream were used for calibrating our change detection methods. The next 500 examples were from the source domain, followed by 1500 examples from the target domain. Over these 2000 examples we ran each of our detection methods. Experiments were repeated over 10 fixed random data permutations. We automatically select A-distance intervals as follows. First, we computed the mean and variance of the 500 calibration margin</context>
</contexts>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Feldman</author>
<author>M A Marin</author>
<author>M Ostendorf</author>
<author>M R Gupta</author>
</authors>
<title>Part-of-speech histograms for genre classification of text.</title>
<date>2009</date>
<booktitle>In International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="36425" citStr="Feldman et al., 2009" startWordPosition="6123" endWordPosition="6126">g genre shift in addition to domain shift, as in the ACE 2005 data set shifts from newswire to transcripts and blogs. Different text genres occur in traditional settings, such as broadcast news transcripts and newswire, and have begun to proliferate with the variety of social media technologies now available including weblogs. Static genre classification has been explored using a variety of techniques, including exploiting punctuation (Kessler et al., 1997; Dewdney et al., 2001), TF-IDF statistics (Lee and Myaeng, 2002), and part-of-speech statistics and histograms (Finn and Kushmerick, 2006; Feldman et al., 2009). Finally, statistical estimation in a streaming context has been considered in data mining applications (Muthukrishnan, 2005). Change detection via sequential hypothesis testing has been effective for streaming applications such as network intrusion detection (Muthukrishnan et al., 2007). Detecting new events in a stream of Twitter posts can be done using constant time and space similarity measures based on a modification of locality sensitive hashing (Petrovi´c et al., 2010). 10 Conclusion While there are a number of methods for domain adaptation, a system first needs to determine that a dom</context>
</contexts>
<marker>Feldman, Marin, Ostendorf, Gupta, 2009</marker>
<rawString>S. Feldman, M. A. Marin, M. Ostendorf, and M. R. Gupta. 2009. Part-of-speech histograms for genre classification of text. In International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Hierarchical Bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In NAACLHLT.</booktitle>
<contexts>
<context position="3274" citStr="Finkel and Manning, 2009" startWordPosition="517" endWordPosition="520"> assume labeled instances are available to help detect these harmful changes. Other tasks related to changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics main the shift will happen. A discussion forum devoted to science fiction books may change over time to focus more on fantasy and then narrow to d</context>
<context position="8750" citStr="Finkel and Manning, 2009" startWordPosition="1397" endWordPosition="1400">ereas domain adaptation relies on feature distribution changes. Several properties of detecting domain shifts in natural language streams distinguish it from traditional domain adaptation, concept drift, and other related tasks: 586 • No Target Distribution Examples Blitzer et al. (2007) estimate the loss in accuracy from domain shift by discriminating between two data distributions. In our setting, we have no knowledge of the target distribution. • No Labeled Target Data Some approaches to domain adaptation assume a limited number of labeled examples (Daum´e, 2007; Dredze and Crammer, 2008b; Finkel and Manning, 2009). We assume no labels in our setting. • Online Setting Domain adaptation typically assumes a batch transfer between two domains. We consider a purely stream (online) setting. • Computationally Constrained Our approach must be fast, as we expect to run our domain shift detector alongside a deployed NLP system. This limits both computation and storage. • Unknown Adaptation A critical assumption of previous work is that a domain change has occurred. We must ascertain this ourselves. Despite these challenges, we show unsupervised stream-based methods that effectively identify shifts in domain in l</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Hierarchical Bayesian domain adaptation. In NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aidan Finn</author>
<author>Nicholas Kushmerick</author>
</authors>
<title>Learning to classify documents according to genre: Special topic section on computational analysis of style.</title>
<date>2006</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>57</volume>
<issue>11</issue>
<contexts>
<context position="36402" citStr="Finn and Kushmerick, 2006" startWordPosition="6119" endWordPosition="6122"> by the problem of detecting genre shift in addition to domain shift, as in the ACE 2005 data set shifts from newswire to transcripts and blogs. Different text genres occur in traditional settings, such as broadcast news transcripts and newswire, and have begun to proliferate with the variety of social media technologies now available including weblogs. Static genre classification has been explored using a variety of techniques, including exploiting punctuation (Kessler et al., 1997; Dewdney et al., 2001), TF-IDF statistics (Lee and Myaeng, 2002), and part-of-speech statistics and histograms (Finn and Kushmerick, 2006; Feldman et al., 2009). Finally, statistical estimation in a streaming context has been considered in data mining applications (Muthukrishnan, 2005). Change detection via sequential hypothesis testing has been effective for streaming applications such as network intrusion detection (Muthukrishnan et al., 2007). Detecting new events in a stream of Twitter posts can be done using constant time and space similarity measures based on a modification of locality sensitive hashing (Petrovi´c et al., 2010). 10 Conclusion While there are a number of methods for domain adaptation, a system first needs </context>
</contexts>
<marker>Finn, Kushmerick, 2006</marker>
<rawString>Aidan Finn and Nicholas Kushmerick. 2006. Learning to classify documents according to genre: Special topic section on computational analysis of style. J. Am. Soc. Inf. Sci. Technol., 57(11):1506–1518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simona Gandrabur</author>
<author>George Foster</author>
<author>Guy Lapalme</author>
</authors>
<title>Confidence estimation for NLP applications.</title>
<date>2006</date>
<journal>ACM Trans. Speech Lang. Process.,</journal>
<volume>3</volume>
<issue>3</issue>
<contexts>
<context position="34555" citStr="Gandrabur et al., 2006" startWordPosition="5822" endWordPosition="5825">rrectness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique (Culotta and McCallum, 2004). EM-based confidence estimation has been used to estimate the confidence of patterns derived from partially supervised relation extraction (Agichtein, 2006). Confidence estimation has also been used to improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural networks have shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline models (Bunescu, 2008). An alternative formulation of domain adaptation trains on different corpora from many different domains, then uses linear combinations of models trained on the different corpora(McClosky et al., 2010). Work in novelty detection is relevant to the task of detecting domain shifts (Scholkopf et al., 2000), 593 400 600 800 1000 1200 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM Domain C</context>
</contexts>
<marker>Gandrabur, Foster, Lapalme, 2006</marker>
<rawString>Simona Gandrabur, George Foster, and Guy Lapalme. 2006. Confidence estimation for NLP applications. ACM Trans. Speech Lang. Process., 3(3):1–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Instance weighting for domain adaptation in NLP.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3170" citStr="Jiang and Zhai, 2007" startWordPosition="500" endWordPosition="503"> will have never been seen during training and therefore not be in the model. Furthermore, we do not assume labeled instances are available to help detect these harmful changes. Other tasks related to changes in data distributions, like detecting concept drift in which the labeling function changes, may require labeled instances, but that is not the focus of this paper. There is significant work on the related problem of adapting a classifier for a known domain shift. Versions of this problem include adapting using only unlabeled target domain data (Blitzer et al., 2006; Blitzer et al., 2007; Jiang and Zhai, 2007), adapting using a limited amount of target domain labeled data (Daum´e, 2007; Finkel and Manning, 2009), and learning across multiple domains simultaneously in an online setting (Dredze and Crammer, 2008b). However, in practical settings, we do not know if the data distribution will change, and certainly not when. Additionally, we will not know to what do585 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585–595, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics main the shift will happen. A discussion f</context>
<context position="6427" citStr="Jiang and Zhai (2007)" startWordPosition="1030" endWordPosition="1033">f domain shifts in language data has been the purview of domain adaptation and transfer learning, which seek to adapt or transfer a model learned on one source domain with labeled data to another target domain with few or no labeled examples. Formally, errors from such transfers have two sources: differences in feature distributions and changes to labeling functions (annotation standards) (Ben-David et al., 2006; Ben-David et al., 2009). Empirical work on NLP domain shifts has focused on the former. For example, Blitzer et al. (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting. First, a change in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar</context>
<context position="10007" citStr="Jiang and Zhai, 2007" startWordPosition="1602" endWordPosition="1605">ds are tied directly to the learning task so are sensitive to changes in actual task accuracy. Our methods have low false positive rates of change detection, which is important since examples within a single domain display a large amount of variance, which could be mistaken for a domain change. Once a change is detected, any number of actions may be appropriate. The maintainer of the system may be notified that performance is suffering, labels can be obtained for a sample of instances from the stream for retraining, or large volumes of unlabeled instances can be used for instance reweighting (Jiang and Zhai, 2007). 3 Datasets We begin the presentation of our methods by describing the data used in our experiments. We selected three data sets commonly used in domain adaptation: spam (Jiang and Zhai, 2007), ACE 2005 named entity recognition (Jiang and Zhai, 2007), and sentiment (Blitzer et al., 2007). Sentiment and spam are binary and ACE is multi-class. Note that in all experiments, a shift in the domain yields a decrease in system accuracy. The goal of the spam data is to classify an email (bag-of-words) as either spam or ham (not-spam). Each email user may have different preferences and features. We us</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007. Instance weighting for domain adaptation in NLP. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brett Kessler</author>
<author>Geoffrey Numberg</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic detection of text genre.</title>
<date>1997</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<marker>Kessler, Numberg, Sch¨utze, 1997</marker>
<rawString>Brett Kessler, Geoffrey Numberg, and Hinrich Sch¨utze. 1997. Automatic detection of text genre. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Kifer</author>
<author>Shai Ben-David</author>
<author>Johannes Gehrke</author>
</authors>
<title>Detecting change in data streams.</title>
<date>2004</date>
<booktitle>In Very Large Data Bases (VLDB).</booktitle>
<contexts>
<context position="4441" citStr="Kifer et al., 2004" startWordPosition="707" endWordPosition="710">r time to focus more on fantasy and then narrow to discussions of vampire fiction. Maybe this shift is harmless and it is possible to identify the sentiment of the discussants with the original model with no loss in accuracy. If not, we seek methods that detect this shift and trigger the use of an adaptation method. Our domain shift detection problem can be decomposed into two subproblems: detecting distributional changes in streams of real numbers, and representing a stream of examples as a stream of real numbers informative for distribution change detection. We select the A-distance metric (Kifer et al., 2004) to solve the first subproblem since it has been previously used in other domain adaptation work (Blitzer et al., 2006; Blitzer et al., 2007). Our main contribution is towards the second problem, representing examples as real numbers for this task. We demonstrate that classification margins, which incorporate information about features that most impact system accuracy, can effectively solve the second subproblem. Furthermore, we show that the previously proposed Confidence Weighted learning algorithm (Dredze et al., 2008) can provide a more informative measure than a simple margin for this tas</context>
<context position="11846" citStr="Kifer et al., 2004" startWordPosition="1897" endWordPosition="1900"> include an additional two types (music and video from Dredze and Crammer) in our false shift experiments and use unigram and bigram features, following Blitzer et al. 4 The A-Distance Our approach to detecting domain shifts in data streams that negatively impact system accuracy is based on the ability to (1) detect distributional changes in streams of real numbers and (2) convert document streams to streams of informative real numbers. This section describes how we achieve the former, and the next section describes the latter. Theoretical work on domain adaptation showed that the A-distance (Kifer et al., 2004), a stream based measure of difference between two arbitrary probability distributions P and P�, can be used to evaluate the difference between two domain distributions (Ben-David et al., 2006). In a batch setting this corresponds to learning a linear classifier to discriminate the domains, and Blitzer et al. (2007) showed correlations with the error from domain adaptation. Given our interest in streaming data we return to the original stream formulation of A-distance. The A-distance detects differences between two arbitrary probability distributions by dividing the range of a random variable </context>
</contexts>
<marker>Kifer, Ben-David, Gehrke, 2004</marker>
<rawString>Daniel Kifer, Shai Ben-David, and Johannes Gehrke. 2004. Detecting change in data streams. In Very Large Data Bases (VLDB).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Klinkenberg</author>
<author>Thorsten Joachims</author>
</authors>
<title>Detecting concept drift with support vector machines.</title>
<date>2000</date>
<booktitle>In International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="7474" citStr="Klinkenberg and Joachims (2000)" startWordPosition="1204" endWordPosition="1207"> features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar than different. A similar problem to the one we consider is that of concept drift, where a stream of examples are labeled with a shifting labeling function (concept) (Nishida and Yamauchi, 2007; Widmer and Kubat, 1996). While concept drift is similar there are two important differences. First, concept drift can be measured using a stream of labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adjust and maintain a training window that minimizes estimated generalization error. This is possible only because class labels arrive with the examples in the stream. Another concept drift detection algorithm, STEPD, uses a statistical test to continually monitor the possibly changing stream, measuring system accuracy directly, again using the labels it receives for each example (Nishida, 2008). Obviously, no such labels are available in our unsupervised setting. Second, concept drif</context>
</contexts>
<marker>Klinkenberg, Joachims, 2000</marker>
<rawString>Ralf Klinkenberg and Thorsten Joachims. 2000. Detecting concept drift with support vector machines. In International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lanquillon</author>
</authors>
<title>Information filtering in changing domains.</title>
<date>1999</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="33828" citStr="Lanquillon, 1999" startWordPosition="5721" endWordPosition="5722">ifier is the clear winner. However, in the majority of experiments, especially for ACE and spam data, both detectors register a change quickly. These results suggest that while a sample of target domain examples is very helpful, our CWPM approach can also be effective when such samples are not available. 9 Related Work Early NLP work in the unsupervised setting monitored classification confidence values, setting a confidence threshold based on a break-even heuristic, monitoring the rate of (presumed) irrelevant examples based on this threshold, and signaling a change when this rate increased (Lanquillon, 1999). Confidence estimation has been used for specific NLP components such as information extraction. The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique (Culotta and McCallum, 2004). EM-based confidence estimation has been used to estimate the confidence of patterns derived from partially supervised relation extraction (Agichtein, 2006). Confidence estimation has also been used to improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural ne</context>
</contexts>
<marker>Lanquillon, 1999</marker>
<rawString>C. Lanquillon. 1999. Information filtering in changing domains. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yong-Bae Lee</author>
<author>Sung Hyon Myaeng</author>
</authors>
<title>Text genre classification with genre-revealing and subjectrevealing features.</title>
<date>2002</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="36329" citStr="Lee and Myaeng, 2002" startWordPosition="6110" endWordPosition="6113">he mere fact that novel instances are observed. We are also motivated by the problem of detecting genre shift in addition to domain shift, as in the ACE 2005 data set shifts from newswire to transcripts and blogs. Different text genres occur in traditional settings, such as broadcast news transcripts and newswire, and have begun to proliferate with the variety of social media technologies now available including weblogs. Static genre classification has been explored using a variety of techniques, including exploiting punctuation (Kessler et al., 1997; Dewdney et al., 2001), TF-IDF statistics (Lee and Myaeng, 2002), and part-of-speech statistics and histograms (Finn and Kushmerick, 2006; Feldman et al., 2009). Finally, statistical estimation in a streaming context has been considered in data mining applications (Muthukrishnan, 2005). Change detection via sequential hypothesis testing has been effective for streaming applications such as network intrusion detection (Muthukrishnan et al., 2007). Detecting new events in a stream of Twitter posts can be done using constant time and space similarity measures based on a modification of locality sensitive hashing (Petrovi´c et al., 2010). 10 Conclusion While t</context>
</contexts>
<marker>Lee, Myaeng, 2002</marker>
<rawString>Yong-Bae Lee and Sung Hyon Myaeng. 2002. Text genre classification with genre-revealing and subjectrevealing features. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Automatic domain adaptation for parsing.</title>
<date>2010</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="34957" citStr="McClosky et al., 2010" startWordPosition="5880" endWordPosition="5883">improve the overall effectiveness of NLP systems. Confidence estimates obtained via neural networks have shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline models (Bunescu, 2008). An alternative formulation of domain adaptation trains on different corpora from many different domains, then uses linear combinations of models trained on the different corpora(McClosky et al., 2010). Work in novelty detection is relevant to the task of detecting domain shifts (Scholkopf et al., 2000), 593 400 600 800 1000 1200 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM Domain Classifier 0 0 200 1200 1000 800 600 400 200 Domain Classifier Figure 6: A-distance over a stream of is and Os produced by a supervised classifier trained to differentiate between the source and target domain. Samples from the unseen target domain is very effective. However, for many shifts, the margin based A-distance detector is still competitive. CWPM had a single false positive while the domain c</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2010</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2010. Automatic domain adaptation for parsing. In NAACL-HLT, pages 28–36, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muthukrishnan</author>
<author>Eric van den Berg</author>
<author>Yihua Wu</author>
</authors>
<title>Sequential change detection on data streams.</title>
<date>2007</date>
<booktitle>In IEEE International Conference on Data Mining Workshops (ICDMW).</booktitle>
<marker>Muthukrishnan, van den Berg, Wu, 2007</marker>
<rawString>S. Muthukrishnan, Eric van den Berg, and Yihua Wu. 2007. Sequential change detection on data streams. In IEEE International Conference on Data Mining Workshops (ICDMW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muthukrishnan</author>
</authors>
<title>Data streams: Algorithms and applications. Foundations and Trends in</title>
<date>2005</date>
<journal>Theoretical Computer Science,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="36551" citStr="Muthukrishnan, 2005" startWordPosition="6143" endWordPosition="6144"> text genres occur in traditional settings, such as broadcast news transcripts and newswire, and have begun to proliferate with the variety of social media technologies now available including weblogs. Static genre classification has been explored using a variety of techniques, including exploiting punctuation (Kessler et al., 1997; Dewdney et al., 2001), TF-IDF statistics (Lee and Myaeng, 2002), and part-of-speech statistics and histograms (Finn and Kushmerick, 2006; Feldman et al., 2009). Finally, statistical estimation in a streaming context has been considered in data mining applications (Muthukrishnan, 2005). Change detection via sequential hypothesis testing has been effective for streaming applications such as network intrusion detection (Muthukrishnan et al., 2007). Detecting new events in a stream of Twitter posts can be done using constant time and space similarity measures based on a modification of locality sensitive hashing (Petrovi´c et al., 2010). 10 Conclusion While there are a number of methods for domain adaptation, a system first needs to determine that a domain shift has occurred. We have presented methods for automatically detecting such domain shifts from a stream of (unlabeled) </context>
</contexts>
<marker>Muthukrishnan, 2005</marker>
<rawString>S. Muthukrishnan. 2005. Data streams: Algorithms and applications. Foundations and Trends in Theoretical Computer Science, 1(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyosuke Nishida</author>
<author>Koichiro Yamauchi</author>
</authors>
<title>Detecting concept drift using statistical testing.</title>
<date>2007</date>
<booktitle>In Discovery Science.</booktitle>
<contexts>
<context position="7221" citStr="Nishida and Yamauchi, 2007" startWordPosition="1165" endWordPosition="1168">nge in domain will be signaled by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar than different. A similar problem to the one we consider is that of concept drift, where a stream of examples are labeled with a shifting labeling function (concept) (Nishida and Yamauchi, 2007; Widmer and Kubat, 1996). While concept drift is similar there are two important differences. First, concept drift can be measured using a stream of labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adjust and maintain a training window that minimizes estimated generalization error. This is possible only because class labels arrive with the examples in the stream. Another concept drift detection algorithm, STEPD, uses a statistical</context>
</contexts>
<marker>Nishida, Yamauchi, 2007</marker>
<rawString>Kyosuke Nishida and Koichiro Yamauchi. 2007. Detecting concept drift using statistical testing. In Discovery Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyosuke Nishida</author>
</authors>
<title>Learning and Detecting Concept Drift.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Hokkaido University,</institution>
<contexts>
<context position="7983" citStr="Nishida, 2008" startWordPosition="1284" endWordPosition="1285">f labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adjust and maintain a training window that minimizes estimated generalization error. This is possible only because class labels arrive with the examples in the stream. Another concept drift detection algorithm, STEPD, uses a statistical test to continually monitor the possibly changing stream, measuring system accuracy directly, again using the labels it receives for each example (Nishida, 2008). Obviously, no such labels are available in our unsupervised setting. Second, concept drift assumes only changes in the labeling function, whereas domain adaptation relies on feature distribution changes. Several properties of detecting domain shifts in natural language streams distinguish it from traditional domain adaptation, concept drift, and other related tasks: 586 • No Target Distribution Examples Blitzer et al. (2007) estimate the loss in accuracy from domain shift by discriminating between two data distributions. In our setting, we have no knowledge of the target distribution. • No L</context>
</contexts>
<marker>Nishida, 2008</marker>
<rawString>Kyosuke Nishida. 2008. Learning and Detecting Concept Drift. Ph.D. thesis, Hokkaido University, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇsa Petrovi´c</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>Streaming first story detection with application to twitter.</title>
<date>2010</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>181--189</pages>
<marker>Petrovi´c, Osborne, Lavrenko, 2010</marker>
<rawString>Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko. 2010. Streaming first story detection with application to twitter. In NAACL-HLT, pages 181–189, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rai</author>
<author>A Saha</author>
<author>H Daum´e</author>
<author>S Venkatasubramanian</author>
</authors>
<title>Domain Adaptation meets Active Learning.</title>
<date>2010</date>
<booktitle>In Workshop on Active Learning for Natural Language Processing (ALNLP),</booktitle>
<pages>27</pages>
<marker>Rai, Saha, Daum´e, Venkatasubramanian, 2010</marker>
<rawString>P. Rai, A. Saha, H. Daum´e III, and S. Venkatasubramanian. 2010. Domain Adaptation meets Active Learning. In Workshop on Active Learning for Natural Language Processing (ALNLP), page 27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Scholkopf</author>
<author>Robert Williamson</author>
<author>Alex Smola</author>
<author>John Shawe-Taylor</author>
<author>John Platt</author>
</authors>
<title>Support vector method for novelty detection.</title>
<date>2000</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="35060" citStr="Scholkopf et al., 2000" startWordPosition="5897" endWordPosition="5900">ve shown gains for speech recognition, spoken language understanding, and machine translation (Gandrabur et al., 2006). Pipeline models using confidence estimates at one stage as weights for further downstream stages improve over baseline dependency parsing and named entity recognition pipeline models (Bunescu, 2008). An alternative formulation of domain adaptation trains on different corpora from many different domains, then uses linear combinations of models trained on the different corpora(McClosky et al., 2010). Work in novelty detection is relevant to the task of detecting domain shifts (Scholkopf et al., 2000), 593 400 600 800 1000 1200 CWPM 300 250 200 150 100 50 00 50 100 150 200 250 300 CWPM Domain Classifier 0 0 200 1200 1000 800 600 400 200 Domain Classifier Figure 6: A-distance over a stream of is and Os produced by a supervised classifier trained to differentiate between the source and target domain. Samples from the unseen target domain is very effective. However, for many shifts, the margin based A-distance detector is still competitive. CWPM had a single false positive while the domain classifier stream had 2 false positives in these experiments. though the rate of occurrence of novel ins</context>
</contexts>
<marker>Scholkopf, Williamson, Smola, Shawe-Taylor, Platt, 2000</marker>
<rawString>Bernhard Scholkopf, Robert Williamson, Alex Smola, John Shawe-Taylor, and John Platt. 2000. Support vector method for novelty detection. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Widmer</author>
<author>Miroslav Kubat</author>
</authors>
<title>Learning in the presence of concept drift and hidden contexts.</title>
<date>1996</date>
<booktitle>Machine Learning,</booktitle>
<pages>23--69</pages>
<contexts>
<context position="7246" citStr="Widmer and Kubat, 1996" startWordPosition="1169" endWordPosition="1172">ed by a change in the feature distributions. That is, new words, phrases, syntactic structures, etc. signal that the system has shifted to a new domain. Second, while there may be a change in the labeling function, i.e., features have a different meaning in each domain, this will be a secondary concern. For example, both Daum´e (2007) and Dredze and Crammer (2008b) assume that domains are more similar than different. A similar problem to the one we consider is that of concept drift, where a stream of examples are labeled with a shifting labeling function (concept) (Nishida and Yamauchi, 2007; Widmer and Kubat, 1996). While concept drift is similar there are two important differences. First, concept drift can be measured using a stream of labeled examples, so system accuracy is directly measured. For example, Klinkenberg and Joachims (2000) detect concept drift with support vector machines, using estimates of leave-one-out performance to adaptively adjust and maintain a training window that minimizes estimated generalization error. This is possible only because class labels arrive with the examples in the stream. Another concept drift detection algorithm, STEPD, uses a statistical test to continually moni</context>
</contexts>
<marker>Widmer, Kubat, 1996</marker>
<rawString>Gerhard Widmer and Miroslav Kubat. 1996. Learning in the presence of concept drift and hidden contexts. Machine Learning, 23:69–101.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>