<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998652">
Statistical Machine Translation Improves Question Retrieval in
Community Question Answering via Matrix Factorization
</title>
<author confidence="0.999509">
Guangyou Zhou, Fang Liu, Yang Liu, Shizhu He, and Jun Zhao
</author>
<affiliation confidence="0.9972455">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
</affiliation>
<address confidence="0.967">
95 Zhongguancun East Road, Beijing 100190, China
</address>
<email confidence="0.998711">
{gyzhou,fliu,liuyang09,shizhu.he,jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999751129032258">
Community question answering (CQA)
has become an increasingly popular re-
search topic. In this paper, we focus on the
problem of question retrieval. Question
retrieval in CQA can automatically find
the most relevant and recent questions that
have been solved by other users. However,
the word ambiguity and word mismatch
problems bring about new challenges for
question retrieval in CQA. State-of-the-art
approaches address these issues by implic-
itly expanding the queried questions with
additional words or phrases using mono-
lingual translation models. While use-
ful, the effectiveness of these models is
highly dependent on the availability of
quality parallel monolingual corpora (e.g.,
question-answer pairs) in the absence of
which they are troubled by noise issue.
In this work, we propose an alternative
way to address the word ambiguity and
word mismatch problems by taking advan-
tage of potentially rich semantic informa-
tion drawn from other languages. Our pro-
posed method employs statistical machine
translation to improve question retrieval
and enriches the question representation
with the translated words from other lan-
guages via matrix factorization. Experi-
ments conducted on a real CQA data show
that our proposed approach is promising.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999936675675676">
With the development of Web 2.0, community
question answering (CQA) services like Yahoo!
Answers,1 Baidu Zhidao2 and WkiAnswers3 have
attracted great attention from both academia and
industry (Jeon et al., 2005; Xue et al., 2008;
Adamic et al., 2008; Wang et al., 2009; Cao et al.,
2010). In CQA, anyone can ask and answer ques-
tions on any topic, and people seeking information
are connected to those who know the answers. As
answers are usually explicitly provided by human,
they can be helpful in answering real world ques-
tions.
In this paper, we focus on the task of question
retrieval. Question retrieval in CQA can automati-
cally find the most relevant and recent questions
(historical questions) that have been solved by
other users, and then the best answers of these his-
torical questions will be used to answer the users’
queried questions. However, question retrieval is
challenging partly due to the word ambiguity and
word mismatch between the queried questions
and the historical questions in the archives. Word
ambiguity often causes the retrieval models to re-
trieve many historical questions that do not match
the users’ intent. This problem is also amplified
by the high diversity of questions and users. For
example, depending on different users, the word
“interest” may refer to “curiosity”, or “a charge
for borrowing money”.
Another challenge is word mismatch between
the queried questions and the historical questions.
The queried questions may contain words that are
different from, but related to, the words in the rele-
vant historical questions. For example, if a queried
question contains the word “company” but a rele-
vant historical question instead contains the word
“firm”, then there is a mismatch and the historical
</bodyText>
<footnote confidence="0.999956666666667">
1http://answers.yahoo.com/
2http://zhidao.baidu.com/
3http://wiki.answers.com/
</footnote>
<page confidence="0.911691">
852
</page>
<note confidence="0.982430727272727">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 852–861,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
English Chinese
word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng)
from a bank? Wff(yinhbng) �rk(daikudn) ?
How to reach the �PPj(ruhe) �#-(qibnwdng)
bank of the river? NPV(hean) ?
word mismatch company o (gongs!)
firm o (g�ngs!)
rheum ,q�(g6nm6o)
catarrh ,q�(g6nm6o)
</note>
<tableCaption confidence="0.999417">
Table 1: Google translate: some illustrative examples.
</tableCaption>
<bodyText confidence="0.998831116883117">
question may not be easily distinguished from an
irrelevant one.
Researchers have proposed the use of word-
based translation models (Berger et al., 2000;
Jeon et al., 2005; Xue et al., 2008; Lee et al.,
2008; Bernhard and Gurevych, 2009) to solve
the word mismatch problem. As a principle ap-
proach to capture semantic word relations, word-
based translation models are built by using the
IBM model 1 (Brown et al., 1993) and have
been shown to outperform traditional models (e.g.,
VSM, BM25, LM) for question retrieval. Be-
sides, Riezler et al. (2007) and Zhou et al. (2011)
proposed the phrase-based translation models for
question and answer retrieval. The basic idea is
to capture the contextual information in model-
ing the translation of phrases as a whole, thus
the word ambiguity problem is somewhat allevi-
ated. However, all these existing studies in the
literature are basically monolingual approaches
which are restricted to the use of original language
of questions. While useful, the effectiveness of
these models is highly dependent on the availabil-
ity of quality parallel monolingual corpora (e.g.,
question-answer pairs) in the absence of which
they are troubled by noise issue. In this work,
we propose an alternative way to address the word
ambiguity and word mismatch problems by taking
advantage of potentially rich semantic information
drawn from other languages. Through other lan-
guages, various ways of adding semantic informa-
tion to a question could be available, thereby lead-
ing to potentially more improvements than using
the original language only.
Taking a step toward using other languages, we
propose the use of translated representation by al-
ternatively enriching the original questions with
the words from other languages. The idea of im-
proving question retrieval with statistical machine
translation is based on the following two observa-
tions: (1) Contextual information is exploited dur-
ing the translation from one language to another.
For example in Table 1, English words “interest”
and “bank” that have multiple meanings under
different contexts are correctly addressed by us-
ing the state-of-the-art translation tool −−Google
Translate.4 Thus, word ambiguity based on con-
textual information is naturally involved when
questions are translated. (2) Multiple words that
have similar meanings in one language may be
translated into an unique word or a few words in a
foreign language. For example in Table 1, English
words such as “company” and “firm” are trans-
lated into “ o (gongs!)”, “rheum” and “catarrh”
are translated into “,qN(g6nmao)” in Chinese.
Thus, word mismatch problem can be somewhat
alleviated by using other languages.
Although Zhou et al. (2012) exploited bilin-
gual translation for question retrieval and obtained
the better performance than traditional monolin-
gual translation models. However, there are two
problems with this enrichment: (1) enriching
the original questions with the translated words
from other languages increases the dimensionality
and makes the question representation even more
sparse; (2) statistical machine translation may in-
troduce noise, which can harm the performance of
question retrieval. To solve these two problems,
we propose to leverage statistical machine transla-
tion to improve question retrieval via matrix fac-
torization.
The remainder of this paper is organized as fol-
lows. Section 2 describes the proposed method
by leveraging statistical machine translation to im-
prove question retrieval via matrix factorization.
Section 3 presents the experimental results. In sec-
tion 4, we conclude with ideas for future research.
</bodyText>
<footnote confidence="0.998929">
4http://translate.google.com/translate t
</footnote>
<page confidence="0.999291">
853
</page>
<sectionHeader confidence="0.995377" genericHeader="method">
2 Our Approach
</sectionHeader>
<subsectionHeader confidence="0.99982">
2.1 Problem Statement
</subsectionHeader>
<bodyText confidence="0.988210357142857">
This paper aims to leverage statistical machine
translation to enrich the question representation.
In order to address the word ambiguity and word
mismatch problems, we expand a question by
adding its translation counterparts. Statistical ma-
chine translation (e.g., Google Translate) can uti-
lize contextual information during the question
translation, so it can solve the word ambiguity and
word mismatch problems to some extent.
Let L = {l1, l2, ... , lP} denote the language
set, where P is the number of languages con-
sidered in the paper, l1 denotes the original lan-
guage (e.g., English) while l2 to lP are the for-
eign languages. Let D1 = {d(1)
</bodyText>
<equation confidence="0.989925">
1 , d(1)
</equation>
<bodyText confidence="0.964260545454545">
2 , ... , d(1) N}
be the set of historical question collection in origi-
nal language, where N is the number of historical
questions in D1 with vocabulary size M1. Now
we first translate each original historical question
from language l1 into other languages lp (p ∈
[2,P]) by Google Translate. Thus, we can ob-
tain D2, ... , DP in different languages, and Mp is
the vocabulary size of Dp. A question d(p)
i in Dp
is simply represented as a Mp dimensional vector
</bodyText>
<equation confidence="0.657944">
d(p)
</equation>
<bodyText confidence="0.9207065">
i , in which each entry is calculated by tf-idf.
The N historical questions in Dp are then repre-
sented in a Mp × N term-question matrix Dp =
{d(p)
</bodyText>
<equation confidence="0.7282455">
1 , d(p)
2 , ... , d(p)
</equation>
<bodyText confidence="0.9915024">
N }, in which each row corre-
sponds to a term and each column corresponds to
a question.
Intuitively, we can enrich the original ques-
tion representation by adding the translated words
from language l2 to lP, the original vocabu-
lary size is increased from M1 to EPp=1 Mp.
Thus, the term-question matrix becomes D =
{D1, D2, ... , DP} and D ∈ R(∑P p�1 Mp)xN.
However, there are two problems with this enrich-
ment: (1) enriching the original questions with the
translated words from other languages makes the
question representation even more sparse; (2) sta-
tistical machine translation may introduce noise.5
To solve these two problems, we propose to
leverage statistical machine translation to improve
question retrieval via matrix factorization. Figure
1 presents the framework of our proposed method,
where qi represents a queried question, and qi is a
vector representation of qi.
</bodyText>
<footnote confidence="0.8938045">
5Statistical machine translation quality is far from satis-
factory in real applications.
</footnote>
<figure confidence="0.726674">
Query
Representation
</figure>
<figureCaption confidence="0.959779">
Figure 1: Framework of our proposed approach
for question retrieval.
</figureCaption>
<subsectionHeader confidence="0.999285">
2.2 Model Formulation
</subsectionHeader>
<bodyText confidence="0.999954238095238">
To tackle the data sparseness of question represen-
tation with the translated words, we hope to find
two or more lower dimensional matrices whose
product provides a good approximate to the orig-
inal one via matrix factorization. Previous stud-
ies have shown that there is psychological and
physiological evidence for parts-based representa-
tion in the human brain (Wachsmuth et al., 1994).
The non-negative matrix factorization (NMF) is
proposed to learn the parts of objects like text
documents (Lee and Seung, 2001). NMF aims
to find two non-negative matrices whose product
provides a good approximation to the original ma-
trix and has been shown to be superior to SVD in
document clustering (Xu et al., 2003; Tang et al.,
2012).
In this paper, NMF is used to induce the reduced
representation Vp of Dp, Dp is independent on
{D1, D2, ... , Dp_1, Dp+1, ... , DP}. When ig-
noring the coupling between Vp, it can be solved
by minimizing the objective function as follows:
</bodyText>
<equation confidence="0.996295">
O1(Up,Vp) = min ∥Dp − UpVp∥2F (1)
Up&gt;0,Vp&gt;0
</equation>
<bodyText confidence="0.891200818181818">
where ∥ · ∥F denotes Frobenius norm of a matrix.
Matrices Up ∈ RMpxK and Vp ∈ RKxN are the
reduced representation for terms and questions in
the K dimensional space, respectively.
To reduce the noise introduced by statistical ma-
chine translation, we assume that Vp from lan-
guage Dp (p ∈ [2, P]) should be close to V1
Historical
Question
Collection
Representation
</bodyText>
<page confidence="0.994746">
854
</page>
<bodyText confidence="0.987329666666667">
from the original language D1. Based on this as-
sumption, we minimize the distance between Vp
(p ∈ [2, P]) and V1 as follows:
∥Vp − V1∥2 F (2)
Combining equations (1) and (2), we get the fol-
lowing objective function:
</bodyText>
<equation confidence="0.997868">
O(U1, ... , UP; V1, ... , VP) (3)
P P
= ∥Dp − UpVp∥2F + λp∥Vp − V1∥2 F
p=1 p=2
</equation>
<bodyText confidence="0.999861272727273">
where parameter λp (p ∈ [2, P]) is used to adjust
the relative importance of these two components.
If we set a small value for λp, the objective func-
tion behaves like the traditional NMF and the im-
portance of data sparseness is emphasized; while a
big value of λp indicates Vp should be very closed
to V1, and equation (3) aims to remove the noise
introduced by statistical machine translation.
By solving the optimization problem in equa-
tion (4), we can get the reduced representation of
terms and questions.
</bodyText>
<figure confidence="0.321462045454545">
Algorithm 1 Optimization framework
Input: Dp ∈ RmpxN, p ∈ [1, P]
1:forp=1:Pdo
2: V(0)
p ∈ RKxN ← random matrix
3: for t = 1 : T do D T is iteration times
4: U(t)
p ← UpdateU(Dp, V(t�1)
p )
5: V(t)
p ← UpdateV(Dp, U(t)
p )
6: end for
7: return U(T )
p , V(T)
p
8: end for
Algorithm 2 Update Up
Input: Dp ∈ RMpxN, Vp ∈ RKxN
1: for i = 1 : Mp do
2: i(p)*
i = (VpVT)-1Vpa(p)
</figure>
<listItem confidence="0.6651935">
3: end for l /
4: return Up
</listItem>
<equation confidence="0.963675">
Let a(p) i= (d(p)
i1 , ... , d(p)
iK)T and i(p) i=
(u(p)
i1 , ... , u(p)
</equation>
<bodyText confidence="0.999927">
iK)T be the column vectors whose en-
tries are those of the ith row of Dp and Up re-
spectively. Thus, the optimization of equation (5)
can be decomposed into Mp optimization prob-
lems that can be solved independently, with each
corresponding to one row of Up:
</bodyText>
<equation confidence="0.9688465">
O2(Vp) = min
Vp&gt;0
P
p=2
</equation>
<bodyText confidence="0.963734333333333">
min O(U1, ... , UP; V1,..., VP) (4) min ∥ v) i− VTp i(p) i∥2 (6)
subject to : Up ≥ 0, Vp ≥ 0, p ∈ [1, P] ���p) 2
i �0
</bodyText>
<subsectionHeader confidence="0.995092">
2.3 Optimization
</subsectionHeader>
<bodyText confidence="0.993516692307692">
The objective function O defined in equation (4)
performs data sparseness and noise removing si-
multaneously. There are 2P coupling components
in O, and O is not convex in both U and V to-
gether. Therefore it is unrealistic to expect an al-
gorithm to find the global minima. In the follow-
ing, we introduce an iterative algorithm which can
achieve local minima. In our optimization frame-
work, we optimize the objective function in equa-
tion (4) by alternatively minimizing each compo-
nent when the remaining 2P − 1 components are
fixed. This procedure is summarized in Algorithm
1.
</bodyText>
<subsectionHeader confidence="0.777414">
2.3.1 Update of Matrix Up
</subsectionHeader>
<bodyText confidence="0.993293">
Holding V1,..., VP and U1, ... , Up-1, Up+1,
..., UP fixed, the update of Up amounts to the
following optimization problem:
</bodyText>
<equation confidence="0.913470375">
U n0∥Dp − UpVp∥F (5)
p-
for i = 1,...,Mp.
Equation (6) is a standard least squares prob-
lems in statistics and the solution is:
i(p)*
i = (VpVTp )-1Vpa(p) (7)
i
</equation>
<bodyText confidence="0.706576">
Algorithm 2 shows the procedure.
</bodyText>
<subsectionHeader confidence="0.85499">
2.3.2 Update of Matrix Vp
</subsectionHeader>
<bodyText confidence="0.9913058">
Holding U1, ... , UP and V1, ... , Vp-1, Vp+1,
..., VP fixed, the update of Vp amounts to the
optimization problem divided into two categories.
if p ∈ [2, P], the objective function can be writ-
ten as:
</bodyText>
<equation confidence="0.986163333333333">
V n0∥Dp − UpVp∥2F + λp∥Vp − V1∥2 (8)
(8)
P_
</equation>
<bodyText confidence="0.858863">
if p = 1, the objective function can be written
as:
</bodyText>
<equation confidence="0.942963333333333">
min0∥Dp − UpVp∥2F + λp∥Vp∥2 (9)
V
p-
</equation>
<page confidence="0.9419">
855
</page>
<bodyText confidence="0.9046678">
Let d(p)
j be the jth column vector of Dp, and
vj be the jth column vector of Vp, respectively.
(p)
Thus, equation (8) can be rewritten as:
</bodyText>
<equation confidence="0.88728075">
f min N ∥d(p) N Ap∥v(P)−v;1)∥22
1VjP)&gt;0J j=1 j −Upv(p) j=1
j ∥2 2+
(10)
</equation>
<bodyText confidence="0.968173">
which can be decomposed into N optimization
problems that can be solved independently, with
each corresponding to one column of Vp:
for j = 1, ... , N.
Equation (12) is a least square problem with L2
norm regularization. Now we rewrite the objective
function in equation (12) as
</bodyText>
<equation confidence="0.84344">
L(v(p)j) = ∥d(p) − Upv�) ∥22 + Ap∥vpj − v( ∥2
1)2
where L(v(1)
</equation>
<bodyText confidence="0.7499115">
j ) is convex, and hence has a unique
solution. Taking derivatives, we obtain:
</bodyText>
<equation confidence="0.820930375">
�L(v(p)
j ) = −2UTp (d;p)−Upv(p)j)+2Ap(vjp)−vj1))
av(p)
j
Forcing the partial derivative to be zero leads to
(p)* p Up + ApI)−1(UTp d(p)
j + Apv(1)
vj = (UT j )
</equation>
<bodyText confidence="0.999362333333333">
where p ∈ [2, P] denotes the foreign language rep-
resentation.
Similarly, the solution of equation (9) is:
</bodyText>
<equation confidence="0.998094">
(p)* p Up + ApI)−1UTp d(p) (15)
vj = (UT j
</equation>
<bodyText confidence="0.999201">
where p = 1 denotes the original language repre-
sentation.
Algorithm 3 shows the procedure.
</bodyText>
<subsectionHeader confidence="0.994615">
2.4 Time Complexity Analysis
</subsectionHeader>
<bodyText confidence="0.971753818181818">
In this subsection, we discuss the time complex-
ity of our proposed method. The optimization
¯u(p) iusing Algorithm 2 should calculate VpVTp
and Vp¯d(p)
i , which takes O(NK2 + NK) op-
erations. Therefore, the optimization Up takes
O(NK2 + MpNK) operations. Similarly, the
time complexity of optimization Vi using Algo-
rithm 3 is O(MpK2 + MpNK).
Another time complexity is the iteration times
T used in Algorithm 1 and the total number of
</bodyText>
<figure confidence="0.620038421052632">
Algorithm 3 Update Vp
Input: Dp ∈ RMPxN, Up ∈ RMPxK
1: Σ ← (UTp Up + ApI)−1
2: Φ ←UT p Dp
3: if p = 1 then
4: for j = 1 : N do
5: v(p)
j ← Σϕj, ϕj is the jth column of Φ
6: end for
7: end if
8: return V1
9: if p ∈ [2, P] then
10: for j = 1 : N do
11: v(p)
j ← Σ(ϕj + Apv(1)
j )
12: end for
13: end if
14: return Vp
</figure>
<figureCaption confidence="0.7979145">
languages P, the overall time complexity of our
proposed method is:
</figureCaption>
<equation confidence="0.995782666666667">
P
T × O(NK2 + MpK2 + 2MpNK) (16)
p=1
</equation>
<bodyText confidence="0.987523">
For each language Dp, the size of vocabulary
Mp is almost constant as the number of questions
increases. Besides, K ≪ min(Mp, N), theoreti-
cally, the computational time is almost linear with
the number of questions N and the number of lan-
guages P considered in the paper. Thus, the pro-
posed method can be easily adapted to the large-
scale information retrieval task.
</bodyText>
<subsectionHeader confidence="0.976653">
2.5 Relevance Ranking
</subsectionHeader>
<bodyText confidence="0.999970363636364">
The advantage of incorporating statistical machine
translation in relevance ranking is to reduce “word
ambiguity” and “word mismatch” problems. To
do so, given a queried question q and a historical
question d from Yahoo! Answers, we first trans-
late q and d into other foreign languages (e.g., Chi-
nese, French etc.) and get the corresponding trans-
lated representation qi and di (i ∈ [2, P]), where
P is the number of languages considered in the pa-
per. For queried question q = q1, we represent it
in the reduced space:
</bodyText>
<equation confidence="0.9687565">
vq1 = arg min ∥q1 − U1v∥2 2 + A1∥v∥2 2 (17)
v&gt;0
</equation>
<bodyText confidence="0.9998816">
where vector q1 is the tf-idf representation of
queried question q1 in the term space. Similarly,
for historical question d = d1 (and its tf-idf repre-
sentation d1 in the term space) we represent it in
the reduced space as vd1.
</bodyText>
<equation confidence="0.945159666666667">
min ∥d(jp)−Upv�p)∥22+Ap∥vjp)−vj1)∥22 (11)
v�P)
� &gt;0
</equation>
<page confidence="0.987002">
856
</page>
<bodyText confidence="0.99994625">
The relevance score between the queried ques-
tion q1 and the historical question d1 in the re-
duced space is, then, calculated as the cosine sim-
ilarity between vq1 and vd1:
</bodyText>
<equation confidence="0.996614">
&lt; vq1, vd1 &gt;
s(q1, d1) = (18)
∥vq1∥2 · ∥vd1∥2
</equation>
<bodyText confidence="0.866015">
For translated representation qi (i ∈ [2, P]), we
also represent it in the reduced space:
</bodyText>
<equation confidence="0.9834655">
vqi = arg min ∥qi−Uiv∥2 2+λi∥v−vq1∥2 2 (19)
��0
</equation>
<bodyText confidence="0.987669578947368">
where vector qi is the tf-idf representation of qi
in the term space. Similarly, for translated rep-
resentation di (and its tf-idf representation di in
the term space) we also represent it in the reduced
space as vdi. The relevance score s(qi, di) be-
tween qi and di in the reduced space can be cal-
culated as the cosine similarity between vqi and
vdi.
Finally, we consider learning a relevance func-
tion of the following general, linear form:
Score(q, d) = θT · 4)(q, d) (20)
where feature vector 4)(q, d) �
(sV SM(q, d), s(q1, d1), s(q2, d2), ... , s(qP, dP)),
and θ is the corresponding weight vector, we
optimize this parameter for our evaluation metrics
directly using the Powell Search algorithm (Paul
et al., 1992) via cross-validation. sV SM(q, d) is
the relevance score in the term space and can be
calculated using Vector Space Model (VSM).
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999994">
3.1 Data Set and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999849857142857">
We collect the data set from Yahoo! Answers and
use the getByCategory function provided in Ya-
hoo! Answers API6 to obtain CQA threads from
the Yahoo! site. More specifically, we utilize
the resolved questions and the resulting question
repository that we use for question retrieval con-
tains 2,288,607 questions. Each resolved ques-
tion consists of four parts: “question title”, “ques-
tion description”, “question answers” and “ques-
tion category”. For question retrieval, we only use
the “question title” part. It is assumed that ques-
tion title already provides enough semantic infor-
mation for understanding the users’ information
needs (Duan et al., 2008). There are 26 categories
</bodyText>
<footnote confidence="0.923836">
6http://developer.yahoo.com/answers
</footnote>
<table confidence="0.999874214285714">
Category #Size Category # Size
Arts &amp; Humanities 86,744 Home &amp; Garden 35,029
Business &amp; Finance 105,453 Beauty &amp; Style 37,350
Cars &amp; Transportation 145,515 Pet 54,158
Education &amp; Reference 80,782 Travel 305,283
Entertainment &amp; Music 152,769 Health 132,716
Family &amp; Relationships 34,743 Sports 214,317
Politics &amp; Government 59,787 Social Science 46,415
Pregnancy &amp; Parenting 43,103 Ding out 46,933
Science &amp; Mathematics 89,856 Food &amp; Drink 45,055
Computers &amp; Internet 90,546 News &amp; Events 20,300
Games &amp; Recreation 53,458 Environment 21,276
Consumer Electronics 90,553 Local Businesses 51,551
Society &amp; Culture 94,470 Yahoo! Products 150,445
</table>
<tableCaption confidence="0.9335">
Table 2: Number of questions in each first-level
category.
</tableCaption>
<bodyText confidence="0.992607685714286">
at the first level and 1,262 categories at the leaf
level. Each question belongs to a unique leaf cat-
egory. Table 2 shows the distribution across first-
level categories of the questions in the archives.
We use the same test set in previous work (Cao
et al., 2009; Cao et al., 2010). This set contains
252 queried questions and can be freely down-
loaded for research communities.7
The original language of the above data set is
English (l1) and then they are translated into four
other languages (Chinese (l2), French (l3), Ger-
man (l4), Italian (l5)), thus the number of language
considered is P = 5) by using the state-of-the-art
translation tool −−Google Translate.
Evaluation Metrics: We evaluate the perfor-
mance of question retrieval using the following
metrics: Mean Average Precision (MAP) and
Precision@N (P@N). MAP rewards methods that
return relevant questions early and also rewards
correct ranking of the results. P@N reports the
fraction of the top-N questions retrieved that are
relevant. We perform a significant test, i.e., a t-
test with a default significant level of 0.05.
We tune the parameters on a small development
set of 50 questions. This development set is also
extracted from Yahoo! Answers, and it is not in-
cluded in the test set. For parameter K, we do an
experiment on the development set to determine
the optimal values among 50, 100, 150, · · · , 300 in
terms of MAP. Finally, we set K = 100 in the ex-
periments empirically as this setting yields the best
performance. For parameter λ1, we set λ1 = 1
empirically, while for parameter λi (i ∈ [2, P]),
we set λi = 0.25 empirically and ensure that
Ei λi = 1.
</bodyText>
<footnote confidence="0.972203">
7http://homepages.inf.ed.ac.uk/gcong/qa/
</footnote>
<page confidence="0.987137">
857
</page>
<table confidence="0.985836333333333">
# Methods MAP P@10
1 VSM 0.242 0.226
2 LM 0.385 0.242
</table>
<note confidence="0.983118">
3 Jeon et al. (2005) 0.405 0.247
4 Xue et al. (2008) 0.436 0.261
5 Zhou et al. (2011) 0.452 0.268
6 Singh (2012) 0.450 0.267
7 Zhou et al. (2012) 0.483 0.275
8 SMT + MF (P = 2, l1, l2) 0.527 0.284
9 SMT + MF (P = 5) 0.564 0.291
</note>
<tableCaption confidence="0.9942635">
Table 3: Comparison with different methods for
question retrieval.
</tableCaption>
<subsectionHeader confidence="0.999949">
3.2 Question Retrieval Results
</subsectionHeader>
<bodyText confidence="0.999828054054054">
Table 3 presents the main retrieval performance.
Row 1 and row 2 are two baseline systems, which
model the relevance score using VSM (Cao et al.,
2010) and language model (LM) (Zhai and Laf-
ferty, 2001; Cao et al., 2010) in the term space.
Row 3 and row 6 are monolingual translation mod-
els to address the word mismatch problem and
obtain the state-of-the-art performance in previ-
ous work. Row 3 is the word-based translation
model (Jeon et al., 2005), and row 4 is the word-
based translation language model, which linearly
combines the word-based translation model and
language model into a unified framework (Xue et
al., 2008). Row 5 is the phrase-based translation
model, which translates a sequence of words as
whole (Zhou et al., 2011). Row 6 is the entity-
based translation model, which extends the word-
based translation model and explores strategies to
learn the translation probabilities between words
and the concepts using the CQA archives and a
popular entity catalog (Singh, 2012). Row 7 is
the bilingual translation model, which translates
the English questions from Yahoo! Answers into
Chinese questions using Google Translate and ex-
pands the English words with the translated Chi-
nese words (Zhou et al., 2012). For these previ-
ous work, we use the same parameter settings in
the original papers. Row 8 and row 9 are our pro-
posed method, which leverages statistical machine
translation to improve question retrieval via ma-
trix factorization. In row 8, we only consider two
languages (English and Chinese) and translate En-
glish questions into Chinese using Google Trans-
late in order to compare with Zhou et al. (2012).
In row 9, we translate English questions into other
four languages. There are some clear trends in the
result of Table 3:
</bodyText>
<listItem confidence="0.97429805">
(1) Monolingual translation models signifi-
cantly outperform the VSM and LM (row 1 and
row 2 vs. row 3, row 4, row 5 and row 6).
(2) Taking advantage of potentially rich seman-
tic information drawn from other languages via
statistical machine translation, question retrieval
performance can be significantly improved (row 3,
row 4, row 5 and row 6 vs. row 7, row 8 and row 9,
all these comparisons are statistically significant at
p &lt; 0.05).
(3) Our proposed method (leveraging statisti-
cal machine translation via matrix factorization,
SMT + MF) significantly outperforms the bilin-
gual translation model of Zhou et al. (2012) (row
7 vs. row 8, the comparison is statistically signifi-
cant at p &lt; 0.05). The reason is that matrix factor-
ization used in the paper can effectively solve the
data sparseness and noise introduced by the ma-
chine translator simultaneously.
(4) When considering more languages, ques-
</listItem>
<bodyText confidence="0.953756">
tion retrieval performance can be further improved
(row 8 vs. row 9).
Note that Wang et al. (2009) also addressed the
word mismatch problem for question retrieval by
using syntactic tree matching. We do not compare
with Wang et al. (2009) in Table 3 because pre-
vious work (Ming et al., 2010) demonstrated that
word-based translation language model (Xue et
al., 2008) obtained the superior performance than
the syntactic tree matching (Wang et al., 2009).
Besides, some other studies attempt to improve
question retrieval with category information (Cao
et al., 2009; Cao et al., 2010), label ranking (Li et
al., 2011) or world knowledge (Zhou et al., 2012).
However, their methods are orthogonal to ours,
and we suspect that combining the category infor-
mation or label ranking into our proposed method
might get even better performance. We leave it for
future research.
</bodyText>
<subsectionHeader confidence="0.999856">
3.3 Impact of the Matrix Factorization
</subsectionHeader>
<bodyText confidence="0.999913083333333">
Our proposed method (SMT + MF) can effectively
solve the data sparseness and noise via matrix fac-
torization. To further investigate the impact of
the matrix factorization, one intuitive way is to
expand the original questions with the translated
words from other four languages, without consid-
ering the data sparseness and noise introduced by
machine translator. We compare our SMT + MF
with this intuitive enriching method (SMT + IEM).
Besides, we also employ our proposed matrix fac-
torization to the original question representation
(VSM + MF). Table 4 shows the comparison.
</bodyText>
<page confidence="0.995004">
858
</page>
<table confidence="0.9998264">
# Methods MAP P@10
1 VSM 0.242 0.226
2 VSM + MF 0.411 0.253
3 SMT + IEM (P = 5) 0.495 0.280
4 SMT + MF (P = 5) 0.564 0.291
</table>
<tableCaption confidence="0.99966">
Table 4: The impact of matrix factorization.
</tableCaption>
<listItem confidence="0.648835736842105">
(1) Our proposed matrix factorization can sig-
nificantly improve the performance of question re-
trieval (row 1 vs. row2; row3 vs. row4, the
improvements are statistically significant at p &lt;
0.05). The results indicate that our proposed ma-
trix factorization can effectively address the issues
of data spareness and noise introduced by statisti-
cal machine translation.
(2) Compared to the relative improvements of
row 3 and row 4, the relative improvements of row
1 and row 2 is much larger. The reason may be
that although matrix factorization can be used to
reduce dimension, it may impair the meaningful
terms.
(3) Compared to VSM, the performance of
SMT + IEM is significantly improved (row 1
vs. row 3), which supports the motivation that
the word ambiguity and word mismatch problems
could be partially addressed by Google Translate.
</listItem>
<subsectionHeader confidence="0.988761">
3.4 Impact of the Translation Language
</subsectionHeader>
<bodyText confidence="0.999380565217391">
One of the success of this paper is to take ad-
vantage of potentially rich semantic information
drawn from other languages to solve the word am-
biguity and word mismatch problems. So we con-
struct a dummy translator (DT) that translates an
English word to itself. Thus, through this trans-
lation, we do not add any semantic information
into the original questions. The comparison is pre-
sented in Table 5. Row 1 (DT + MF) represents
integrating two copies of English questions with
our proposed matrix factorization. From Table 5,
we have several different findings:
(1) Taking advantage of potentially rich seman-
tic information drawn from other languages can
significantly improve the performance of question
retrieval (row 1 vs. row 2, row 3, row 4 and row 5,
the improvements relative to DT + MF are statisti-
cally significant at p &lt; 0.05).
(2) Different languages contribute unevenly for
question retrieval (e.g., row 2 vs. row 3). The
reason may be that the improvements of leverag-
ing different other languages depend on the qual-
ity of machine translation. For example, row 3
</bodyText>
<table confidence="0.996281">
# Methods MAP
1 DT + MF (l1, l1) 0.352
2 SMT + MF (P = 2, l1, l2) 0.527
3 SMT + MF (P = 2, l1, l3) 0.553
4 SMT + MF (P = 2, l1, l4) 0.536
5 SMT + MF (P = 2, l1, l5) 0.545
6 SMT + MF (P = 3, l1, l2, l3) 0.559
7 SMT + MF (P = 4, l1, l2, l3, l4) 0.563
8 SMT + MF (P = 5, l1, l2, l3, l4, l5) 0.564
</table>
<tableCaption confidence="0.998714">
Table 5: The impact of translation language.
</tableCaption>
<table confidence="0.99872225">
Method Translation MAP
Dict 0.468
SMT + MF (P = 2, l1, l2)
GTrans 0.527
</table>
<tableCaption confidence="0.999117">
Table 6: Impact of the contextual information.
</tableCaption>
<bodyText confidence="0.999013">
is better than row 2 because the translation qual-
ity of English-French is much better than English-
Chinese.
(3) Using much more languages does not seem
to produce significantly better performance (row 6
and row 7 vs. row 8). The reason may be that in-
consistency between different languages may exist
due to statistical machine translation.
</bodyText>
<subsectionHeader confidence="0.983233">
3.5 Impact of the Contextual Information
</subsectionHeader>
<bodyText confidence="0.999994666666667">
In this paper, we translate the English questions
into other four languages using Google Translate
(GTrans), which takes into account contextual in-
formation during translation. If we translate a
question word by word, it discards the contextual
information. We would expect that such a transla-
tion would not be able to solve the word ambiguity
problem.
To investigate the impact of contextual infor-
mation for question retrieval, we only consider
two languages and translate English questions
into Chinese using an English to Chinese lexicon
(Dict) in StarDict8. Table 6 shows the experi-
mental results, we can see that the performance is
degraded when the contextual information is not
considered for the translation of questions. The
reason is that GTrans is context-dependent and
thus produces different translated Chinese words
depending on the context of an English word.
Therefore, the word ambiguity problem can be
solved during the English-Chinese translation.
</bodyText>
<sectionHeader confidence="0.999376" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99668">
In this paper, we propose to employ statistical ma-
chine translation to improve question retrieval and
</bodyText>
<footnote confidence="0.999816">
8StarDict is an open source dictionary software, available
at http://stardict.sourceforge.net/.
</footnote>
<page confidence="0.998062">
859
</page>
<bodyText confidence="0.999971565217391">
enrich the question representation with the trans-
lated words from other languages via matrix fac-
torization. Experiments conducted on a real CQA
data show some promising findings: (1) the pro-
posed method significantly outperforms the pre-
vious work for question retrieval; (2) the pro-
posed matrix factorization can significantly im-
prove the performance of question retrieval, no
matter whether considering the translation lan-
guages or not; (3) considering more languages can
further improve the performance but it does not
seem to produce significantly better performance;
(4) different languages contribute unevenly for
question retrieval; (5) our proposed method can
be easily adapted to the large-scale information re-
trieval task.
As future work, we plan to incorporate the ques-
tion structure (e.g., question topic and question fo-
cus (Duan et al., 2008)) into the question represen-
tation for question retrieval. We also want to fur-
ther investigate the use of the proposed method for
other kinds of data set, such as categorized ques-
tions from forum sites and FAQ sites.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996031">
This work was supported by the National Natural
Science Foundation of China (No. 61070106, No.
61272332 and No. 61202329), the National High
Technology Development 863 Program of China
(No. 2012AA011102), the National Basic Re-
search Program of China (No. 2012CB316300),
We thank the anonymous reviewers for their in-
sightful comments. We also thank Dr. Gao Cong
for providing the data set and Dr. Li Cai for some
discussion.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99997316923077">
L. Adamic, J. Zhang, E. Bakshy, and M. Ackerman.
2008. Knowledge sharing and yahoo answers: ev-
eryone knows and something. In Proceedings of
WWW.
A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mit-
tal. 2000. Bridging the lexical chasm: statistical ap-
proach to answer-finding. In Proceedings of SIGIR,
pages 192-199.
D. Bernhard and I. Gurevych. 2009. Combining
lexical semantic resources with question &amp; answer
archives for translation-based answer finding. In
Proceedings of ACL, pages 728-736.
P. F. Brown, V. J. D. Pietra, S. A. D. Pietra, and R. L.
Mercer. 1993. The mathematics of statistical ma-
chine translation: parameter estimation. Computa-
tional Linguistics, 19(2):263-311.
X. Cao, G. Cong, B. Cui, C. Jensen, and C. Zhang.
2009. The use of categorization information in lan-
guage models for question retrieval. In Proceedings
of CIKM, pages 265-274.
X. Cao, G. Cong, B. Cui, and C. Jensen. 2010. A
generalized framework of exploring category infor-
mation for question retrieval in community question
answer archives. In Proceedings of WWW, pages
201-210.
H. Duan, Y. Cao, C. Y. Lin, and Y. Yu. 2008. Searching
questions by identifying questions topics and ques-
tion focus. In Proceedings ofACL, pages 156-164.
C. L. Lawson and R. J. Hanson. 1974. Solving least
squares problems. Prentice-Hall.
J. -T. Lee, S. -B. Kim, Y. -I. Song, and H. -C. Rim.
2008. Bridging lexical gaps between queries and
questions on large online Q&amp;A collections with
compact translation models. In Proceedings of
EMNLP, pages 410-418.
W. Wang, B. Li, and I. King. 2011. Improving ques-
tion retrieval in community question answering with
label ranking. In Proceedings of IJCNN, pages 349-
356.
D. D. Lee and H. S. Seung. 2001. Algorithms for
non-negative matrix factorization. In Proceedings
of NIPS.
Z. Ming, K. Wang, and T. -S. Chua. 2010. Prototype
hierarchy based clustering for the categorization and
navigation of web collections. In Proceedings of SI-
GIR, pages 2-9.
J. Jeon, W. Croft, and J. Lee. 2005. Finding similar
questions in large question and answer archives. In
Proceedings of CIKM, pages 84-90.
C. Paige and M. Saunders. 1982. LSQR: an algo-
rithm for sparse linear equations and sparse least
squares. ACM Transaction on Mathematical Soft-
ware, 8(1):43-71.
W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B.
P. Flannery. 1992. Numerical Recipes In C. Cam-
bridge Univ. Press.
S. Riezler, A. Vasserman, I. Tsochantaridis, V. Mittal,
and Y. Liu. 2007. Statistical machine translation for
query expansion in answer retrieval. In Proceedings
ofACL, pages 464-471.
A. Singh. 2012. Entity based q&amp;a retrieval. In Pro-
ceedings of EMNLP-CoNLL, pages 1266-1277.
J. Tang, X. Wang, H. Gao, X. Hu, and H. Liu. 2012.
Enriching short text representation in microblog for
clustering. Front. Comput., 6(1):88-101.
</reference>
<page confidence="0.971921">
860
</page>
<reference confidence="0.999935529411764">
E. Wachsmuth, M. W. Oram, and D. I. Perrett. 1994.
Recognition of objects and their component parts:
responses of single units in the temporal cortex of
teh macaque. Cerebral Cortex, 4:509-522.
K. Wang, Z. Ming, and T-S. Chua. 2009. A syntac-
tic tree matching approach to find similar questions
in community-based qa services. In Proceedings of
SIGIR, pages 187-194.
B. Wang, X. Wang, C. Sun, B. Liu, and L. Sun. 2010.
Modeling semantic relevance for question-answer
pairs in web social communities. In Proceedings of
ACL, pages 1230-1238.
W. Xu, X. Liu, and Y. Gong. 2003. Document cluster-
ing based on non-negative matrix factorization. In
Proceedings of SIGIR, pages 267-273.
X. Xue, J. Jeon, and W. B. Croft. 2008. Retrieval mod-
els for question and answer archives. In Proceedings
of SIGIR, pages 475-482.
C. Zhai and J. Lafferty. 2001. A study of smooth meth-
ods for language models applied to ad hoc informa-
tion retrieval. In Proceedings of SIGIR, pages 334-
342.
G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrase-
based translation model for question retrieval in
community question answer archives. In Proceed-
ings of ACL, pages 653-662.
G. Zhou, K. Liu, and J. Zhao. 2012. Exploiting bilin-
gual translation for question retrieval in community-
based question answering. In Proceedings of COL-
ING, pages 3153-3170.
G. Zhou, Y. Liu, F. Liu, D. Zeng, and J. Zhao. 2013.
Improving Question Retrieval in Community Ques-
tion Answering Using World Knowledge. In Pro-
ceedings of IJCAI.
</reference>
<page confidence="0.998374">
861
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.810665">
<title confidence="0.9942535">Statistical Machine Translation Improves Question Retrieval Community Question Answering via Matrix Factorization</title>
<author confidence="0.979155">Guangyou Zhou</author>
<author confidence="0.979155">Fang Liu</author>
<author confidence="0.979155">Yang Liu</author>
<author confidence="0.979155">Shizhu He</author>
<author confidence="0.979155">Jun</author>
<affiliation confidence="0.9868135">National Laboratory of Pattern Institute of Automation, Chinese Academy of</affiliation>
<address confidence="0.864133">95 Zhongguancun East Road, Beijing 100190,</address>
<abstract confidence="0.99942053125">Community question answering (CQA) has become an increasingly popular research topic. In this paper, we focus on the problem of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions that have been solved by other users. However, the word ambiguity and word mismatch problems bring about new challenges for question retrieval in CQA. State-of-the-art approaches address these issues by implicitly expanding the queried questions with additional words or phrases using monolingual translation models. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue. In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Adamic</author>
<author>J Zhang</author>
<author>E Bakshy</author>
<author>M Ackerman</author>
</authors>
<title>Knowledge sharing and yahoo answers: everyone knows and something.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW.</booktitle>
<contexts>
<context position="1898" citStr="Adamic et al., 2008" startWordPosition="271" endWordPosition="274">tentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising. 1 Introduction With the development of Web 2.0, community question answering (CQA) services like Yahoo! Answers,1 Baidu Zhidao2 and WkiAnswers3 have attracted great attention from both academia and industry (Jeon et al., 2005; Xue et al., 2008; Adamic et al., 2008; Wang et al., 2009; Cao et al., 2010). In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions. In this paper, we focus on the task of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to answer the users’ queried questions. H</context>
</contexts>
<marker>Adamic, Zhang, Bakshy, Ackerman, 2008</marker>
<rawString>L. Adamic, J. Zhang, E. Bakshy, and M. Ackerman. 2008. Knowledge sharing and yahoo answers: everyone knows and something. In Proceedings of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>R Caruana</author>
<author>D Cohn</author>
<author>D Freitag</author>
<author>V Mittal</author>
</authors>
<title>Bridging the lexical chasm: statistical approach to answer-finding.</title>
<date>2000</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="4146" citStr="Berger et al., 2000" startWordPosition="616" endWordPosition="619">ation for Computational Linguistics, pages 852–861, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics English Chinese word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng) from a bank? Wff(yinhbng) �rk(daikudn) ? How to reach the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a </context>
</contexts>
<marker>Berger, Caruana, Cohn, Freitag, Mittal, 2000</marker>
<rawString>A. Berger, R. Caruana, D. Cohn, D. Freitag, and V. Mittal. 2000. Bridging the lexical chasm: statistical approach to answer-finding. In Proceedings of SIGIR, pages 192-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bernhard</author>
<author>I Gurevych</author>
</authors>
<title>Combining lexical semantic resources with question &amp; answer archives for translation-based answer finding.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>728--736</pages>
<contexts>
<context position="4231" citStr="Bernhard and Gurevych, 2009" startWordPosition="632" endWordPosition="635">4-9 2013. c�2013 Association for Computational Linguistics English Chinese word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng) from a bank? Wff(yinhbng) �rk(daikudn) ? How to reach the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alleviated. However, all these exi</context>
</contexts>
<marker>Bernhard, Gurevych, 2009</marker>
<rawString>D. Bernhard and I. Gurevych. 2009. Combining lexical semantic resources with question &amp; answer archives for translation-based answer finding. In Proceedings of ACL, pages 728-736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J D Pietra</author>
<author>S A D Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="4412" citStr="Brown et al., 1993" startWordPosition="664" endWordPosition="667">the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alleviated. However, all these existing studies in the literature are basically monolingual approaches which are restricted to the use of original language of questions. While useful, the effectiveness of these mode</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, V. J. D. Pietra, S. A. D. Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Cao</author>
<author>G Cong</author>
<author>B Cui</author>
<author>C Jensen</author>
<author>C Zhang</author>
</authors>
<title>The use of categorization information in language models for question retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>265--274</pages>
<contexts>
<context position="20482" citStr="Cao et al., 2009" startWordPosition="3482" endWordPosition="3485">46,415 Pregnancy &amp; Parenting 43,103 Ding out 46,933 Science &amp; Mathematics 89,856 Food &amp; Drink 45,055 Computers &amp; Internet 90,546 News &amp; Events 20,300 Games &amp; Recreation 53,458 Environment 21,276 Consumer Electronics 90,553 Local Businesses 51,551 Society &amp; Culture 94,470 Yahoo! Products 150,445 Table 2: Number of questions in each first-level category. at the first level and 1,262 categories at the leaf level. Each question belongs to a unique leaf category. Table 2 shows the distribution across firstlevel categories of the questions in the archives. We use the same test set in previous work (Cao et al., 2009; Cao et al., 2010). This set contains 252 queried questions and can be freely downloaded for research communities.7 The original language of the above data set is English (l1) and then they are translated into four other languages (Chinese (l2), French (l3), German (l4), Italian (l5)), thus the number of language considered is P = 5) by using the state-of-the-art translation tool −−Google Translate. Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and Precision@N (P@N). MAP rewards methods that return relevant ques</context>
<context position="25496" citStr="Cao et al., 2009" startWordPosition="4337" endWordPosition="4340">taneously. (4) When considering more languages, question retrieval performance can be further improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to ours, and we suspect that combining the category information or label ranking into our proposed method might get even better performance. We leave it for future research. 3.3 Impact of the Matrix Factorization Our proposed method (SMT + MF) can effectively solve the data sparseness and noise via matrix factorization. To further investigate the impact of the matrix factorization, one intuitive way is to expand the original questions with the translated words from</context>
</contexts>
<marker>Cao, Cong, Cui, Jensen, Zhang, 2009</marker>
<rawString>X. Cao, G. Cong, B. Cui, C. Jensen, and C. Zhang. 2009. The use of categorization information in language models for question retrieval. In Proceedings of CIKM, pages 265-274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Cao</author>
<author>G Cong</author>
<author>B Cui</author>
<author>C Jensen</author>
</authors>
<title>A generalized framework of exploring category information for question retrieval in community question answer archives.</title>
<date>2010</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>201--210</pages>
<contexts>
<context position="1936" citStr="Cao et al., 2010" startWordPosition="279" endWordPosition="282">n from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising. 1 Introduction With the development of Web 2.0, community question answering (CQA) services like Yahoo! Answers,1 Baidu Zhidao2 and WkiAnswers3 have attracted great attention from both academia and industry (Jeon et al., 2005; Xue et al., 2008; Adamic et al., 2008; Wang et al., 2009; Cao et al., 2010). In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions. In this paper, we focus on the task of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to answer the users’ queried questions. However, question retrieval is challeng</context>
<context position="20501" citStr="Cao et al., 2010" startWordPosition="3486" endWordPosition="3489"> Parenting 43,103 Ding out 46,933 Science &amp; Mathematics 89,856 Food &amp; Drink 45,055 Computers &amp; Internet 90,546 News &amp; Events 20,300 Games &amp; Recreation 53,458 Environment 21,276 Consumer Electronics 90,553 Local Businesses 51,551 Society &amp; Culture 94,470 Yahoo! Products 150,445 Table 2: Number of questions in each first-level category. at the first level and 1,262 categories at the leaf level. Each question belongs to a unique leaf category. Table 2 shows the distribution across firstlevel categories of the questions in the archives. We use the same test set in previous work (Cao et al., 2009; Cao et al., 2010). This set contains 252 queried questions and can be freely downloaded for research communities.7 The original language of the above data set is English (l1) and then they are translated into four other languages (Chinese (l2), French (l3), German (l4), Italian (l5)), thus the number of language considered is P = 5) by using the state-of-the-art translation tool −−Google Translate. Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and Precision@N (P@N). MAP rewards methods that return relevant questions early and als</context>
<context position="22429" citStr="Cao et al., 2010" startWordPosition="3828" endWordPosition="3831">5 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art performance in previous work. Row 3 is the word-based translation model (Jeon et al., 2005), and row 4 is the wordbased translation language model, which linearly combines the word-based translation model and language model into a unified framework (Xue et al., 2008). Row 5 is the phrase-based translation model, which translates a sequence of words as whole (Zhou et al., 2011). Row 6 is th</context>
<context position="25515" citStr="Cao et al., 2010" startWordPosition="4341" endWordPosition="4344">n considering more languages, question retrieval performance can be further improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to ours, and we suspect that combining the category information or label ranking into our proposed method might get even better performance. We leave it for future research. 3.3 Impact of the Matrix Factorization Our proposed method (SMT + MF) can effectively solve the data sparseness and noise via matrix factorization. To further investigate the impact of the matrix factorization, one intuitive way is to expand the original questions with the translated words from other four languag</context>
</contexts>
<marker>Cao, Cong, Cui, Jensen, 2010</marker>
<rawString>X. Cao, G. Cong, B. Cui, and C. Jensen. 2010. A generalized framework of exploring category information for question retrieval in community question answer archives. In Proceedings of WWW, pages 201-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Duan</author>
<author>Y Cao</author>
<author>C Y Lin</author>
<author>Y Yu</author>
</authors>
<title>Searching questions by identifying questions topics and question focus.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>156--164</pages>
<contexts>
<context position="19459" citStr="Duan et al., 2008" startWordPosition="3326" endWordPosition="3329">! Answers and use the getByCategory function provided in Yahoo! Answers API6 to obtain CQA threads from the Yahoo! site. More specifically, we utilize the resolved questions and the resulting question repository that we use for question retrieval contains 2,288,607 questions. Each resolved question consists of four parts: “question title”, “question description”, “question answers” and “question category”. For question retrieval, we only use the “question title” part. It is assumed that question title already provides enough semantic information for understanding the users’ information needs (Duan et al., 2008). There are 26 categories 6http://developer.yahoo.com/answers Category #Size Category # Size Arts &amp; Humanities 86,744 Home &amp; Garden 35,029 Business &amp; Finance 105,453 Beauty &amp; Style 37,350 Cars &amp; Transportation 145,515 Pet 54,158 Education &amp; Reference 80,782 Travel 305,283 Entertainment &amp; Music 152,769 Health 132,716 Family &amp; Relationships 34,743 Sports 214,317 Politics &amp; Government 59,787 Social Science 46,415 Pregnancy &amp; Parenting 43,103 Ding out 46,933 Science &amp; Mathematics 89,856 Food &amp; Drink 45,055 Computers &amp; Internet 90,546 News &amp; Events 20,300 Games &amp; Recreation 53,458 Environment 21,27</context>
<context position="31430" citStr="Duan et al., 2008" startWordPosition="5338" endWordPosition="5341">vious work for question retrieval; (2) the proposed matrix factorization can significantly improve the performance of question retrieval, no matter whether considering the translation languages or not; (3) considering more languages can further improve the performance but it does not seem to produce significantly better performance; (4) different languages contribute unevenly for question retrieval; (5) our proposed method can be easily adapted to the large-scale information retrieval task. As future work, we plan to incorporate the question structure (e.g., question topic and question focus (Duan et al., 2008)) into the question representation for question retrieval. We also want to further investigate the use of the proposed method for other kinds of data set, such as categorized questions from forum sites and FAQ sites. Acknowledgments This work was supported by the National Natural Science Foundation of China (No. 61070106, No. 61272332 and No. 61202329), the National High Technology Development 863 Program of China (No. 2012AA011102), the National Basic Research Program of China (No. 2012CB316300), We thank the anonymous reviewers for their insightful comments. We also thank Dr. Gao Cong for pr</context>
</contexts>
<marker>Duan, Cao, Lin, Yu, 2008</marker>
<rawString>H. Duan, Y. Cao, C. Y. Lin, and Y. Yu. 2008. Searching questions by identifying questions topics and question focus. In Proceedings ofACL, pages 156-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Lawson</author>
<author>R J Hanson</author>
</authors>
<title>Solving least squares problems.</title>
<date>1974</date>
<publisher>Prentice-Hall.</publisher>
<marker>Lawson, Hanson, 1974</marker>
<rawString>C. L. Lawson and R. J. Hanson. 1974. Solving least squares problems. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J -T Lee</author>
<author>S -B Kim</author>
<author>Y -I Song</author>
<author>H -C Rim</author>
</authors>
<title>Bridging lexical gaps between queries and questions on large online Q&amp;A collections with compact translation models.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>410--418</pages>
<contexts>
<context position="4201" citStr="Lee et al., 2008" startWordPosition="628" endWordPosition="631"> Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics English Chinese word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng) from a bank? Wff(yinhbng) �rk(daikudn) ? How to reach the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alle</context>
</contexts>
<marker>Lee, Kim, Song, Rim, 2008</marker>
<rawString>J. -T. Lee, S. -B. Kim, Y. -I. Song, and H. -C. Rim. 2008. Bridging lexical gaps between queries and questions on large online Q&amp;A collections with compact translation models. In Proceedings of EMNLP, pages 410-418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>B Li</author>
<author>I King</author>
</authors>
<title>Improving question retrieval in community question answering with label ranking.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNN,</booktitle>
<pages>349--356</pages>
<marker>Wang, Li, King, 2011</marker>
<rawString>W. Wang, B. Li, and I. King. 2011. Improving question retrieval in community question answering with label ranking. In Proceedings of IJCNN, pages 349-356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lee</author>
<author>H S Seung</author>
</authors>
<title>Algorithms for non-negative matrix factorization.</title>
<date>2001</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="10567" citStr="Lee and Seung, 2001" startWordPosition="1647" endWordPosition="1650"> Representation Figure 1: Framework of our proposed approach for question retrieval. 2.2 Model Formulation To tackle the data sparseness of question representation with the translated words, we hope to find two or more lower dimensional matrices whose product provides a good approximate to the original one via matrix factorization. Previous studies have shown that there is psychological and physiological evidence for parts-based representation in the human brain (Wachsmuth et al., 1994). The non-negative matrix factorization (NMF) is proposed to learn the parts of objects like text documents (Lee and Seung, 2001). NMF aims to find two non-negative matrices whose product provides a good approximation to the original matrix and has been shown to be superior to SVD in document clustering (Xu et al., 2003; Tang et al., 2012). In this paper, NMF is used to induce the reduced representation Vp of Dp, Dp is independent on {D1, D2, ... , Dp_1, Dp+1, ... , DP}. When ignoring the coupling between Vp, it can be solved by minimizing the objective function as follows: O1(Up,Vp) = min ∥Dp − UpVp∥2F (1) Up&gt;0,Vp&gt;0 where ∥ · ∥F denotes Frobenius norm of a matrix. Matrices Up ∈ RMpxK and Vp ∈ RKxN are the reduced repre</context>
</contexts>
<marker>Lee, Seung, 2001</marker>
<rawString>D. D. Lee and H. S. Seung. 2001. Algorithms for non-negative matrix factorization. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Ming</author>
<author>K Wang</author>
<author>T -S Chua</author>
</authors>
<title>Prototype hierarchy based clustering for the categorization and navigation of web collections.</title>
<date>2010</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>2--9</pages>
<contexts>
<context position="25223" citStr="Ming et al., 2010" startWordPosition="4298" endWordPosition="4301">ingual translation model of Zhou et al. (2012) (row 7 vs. row 8, the comparison is statistically significant at p &lt; 0.05). The reason is that matrix factorization used in the paper can effectively solve the data sparseness and noise introduced by the machine translator simultaneously. (4) When considering more languages, question retrieval performance can be further improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to ours, and we suspect that combining the category information or label ranking into our proposed method might get even better performance. We leave it for future research. 3.3 Impact of the Matr</context>
</contexts>
<marker>Ming, Wang, Chua, 2010</marker>
<rawString>Z. Ming, K. Wang, and T. -S. Chua. 2010. Prototype hierarchy based clustering for the categorization and navigation of web collections. In Proceedings of SIGIR, pages 2-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jeon</author>
<author>W Croft</author>
<author>J Lee</author>
</authors>
<title>Finding similar questions in large question and answer archives.</title>
<date>2005</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>84--90</pages>
<contexts>
<context position="1859" citStr="Jeon et al., 2005" startWordPosition="263" endWordPosition="266">ch problems by taking advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising. 1 Introduction With the development of Web 2.0, community question answering (CQA) services like Yahoo! Answers,1 Baidu Zhidao2 and WkiAnswers3 have attracted great attention from both academia and industry (Jeon et al., 2005; Xue et al., 2008; Adamic et al., 2008; Wang et al., 2009; Cao et al., 2010). In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions. In this paper, we focus on the task of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to</context>
<context position="4165" citStr="Jeon et al., 2005" startWordPosition="620" endWordPosition="623">al Linguistics, pages 852–861, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics English Chinese word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng) from a bank? Wff(yinhbng) �rk(daikudn) ? How to reach the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the wor</context>
<context position="21972" citStr="Jeon et al. (2005)" startWordPosition="3740" endWordPosition="3743">et of 50 questions. This development set is also extracted from Yahoo! Answers, and it is not included in the test set. For parameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, · · · , 300 in terms of MAP. Finally, we set K = 100 in the experiments empirically as this setting yields the best performance. For parameter λ1, we set λ1 = 1 empirically, while for parameter λi (i ∈ [2, P]), we set λi = 0.25 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to a</context>
</contexts>
<marker>Jeon, Croft, Lee, 2005</marker>
<rawString>J. Jeon, W. Croft, and J. Lee. 2005. Finding similar questions in large question and answer archives. In Proceedings of CIKM, pages 84-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Paige</author>
<author>M Saunders</author>
</authors>
<title>LSQR: an algorithm for sparse linear equations and sparse least squares.</title>
<date>1982</date>
<journal>ACM Transaction on Mathematical Software,</journal>
<pages>8--1</pages>
<marker>Paige, Saunders, 1982</marker>
<rawString>C. Paige and M. Saunders. 1982. LSQR: an algorithm for sparse linear equations and sparse least squares. ACM Transaction on Mathematical Software, 8(1):43-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W H Press</author>
<author>S A Teukolsky</author>
<author>W T Vetterling</author>
<author>B P Flannery</author>
</authors>
<title>Numerical Recipes In C.</title>
<date>1992</date>
<publisher>Cambridge Univ. Press.</publisher>
<marker>Press, Teukolsky, Vetterling, Flannery, 1992</marker>
<rawString>W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. 1992. Numerical Recipes In C. Cambridge Univ. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>A Vasserman</author>
<author>I Tsochantaridis</author>
<author>V Mittal</author>
<author>Y Liu</author>
</authors>
<title>Statistical machine translation for query expansion in answer retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>464--471</pages>
<contexts>
<context position="4542" citStr="Riezler et al. (2007)" startWordPosition="685" endWordPosition="688">atarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alleviated. However, all these existing studies in the literature are basically monolingual approaches which are restricted to the use of original language of questions. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of</context>
</contexts>
<marker>Riezler, Vasserman, Tsochantaridis, Mittal, Liu, 2007</marker>
<rawString>S. Riezler, A. Vasserman, I. Tsochantaridis, V. Mittal, and Y. Liu. 2007. Statistical machine translation for query expansion in answer retrieval. In Proceedings ofACL, pages 464-471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Singh</author>
</authors>
<title>Entity based q&amp;a retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>1266--1277</pages>
<contexts>
<context position="22064" citStr="Singh (2012)" startWordPosition="3761" endWordPosition="3762">uded in the test set. For parameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, · · · , 300 in terms of MAP. Finally, we set K = 100 in the experiments empirically as this setting yields the best performance. For parameter λ1, we set λ1 = 1 empirically, while for parameter λi (i ∈ [2, P]), we set λi = 0.25 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art performance in previous wor</context>
</contexts>
<marker>Singh, 2012</marker>
<rawString>A. Singh. 2012. Entity based q&amp;a retrieval. In Proceedings of EMNLP-CoNLL, pages 1266-1277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tang</author>
<author>X Wang</author>
<author>H Gao</author>
<author>X Hu</author>
<author>H Liu</author>
</authors>
<title>Enriching short text representation in microblog for clustering.</title>
<date>2012</date>
<journal>Front. Comput.,</journal>
<pages>6--1</pages>
<contexts>
<context position="10779" citStr="Tang et al., 2012" startWordPosition="1685" endWordPosition="1688">more lower dimensional matrices whose product provides a good approximate to the original one via matrix factorization. Previous studies have shown that there is psychological and physiological evidence for parts-based representation in the human brain (Wachsmuth et al., 1994). The non-negative matrix factorization (NMF) is proposed to learn the parts of objects like text documents (Lee and Seung, 2001). NMF aims to find two non-negative matrices whose product provides a good approximation to the original matrix and has been shown to be superior to SVD in document clustering (Xu et al., 2003; Tang et al., 2012). In this paper, NMF is used to induce the reduced representation Vp of Dp, Dp is independent on {D1, D2, ... , Dp_1, Dp+1, ... , DP}. When ignoring the coupling between Vp, it can be solved by minimizing the objective function as follows: O1(Up,Vp) = min ∥Dp − UpVp∥2F (1) Up&gt;0,Vp&gt;0 where ∥ · ∥F denotes Frobenius norm of a matrix. Matrices Up ∈ RMpxK and Vp ∈ RKxN are the reduced representation for terms and questions in the K dimensional space, respectively. To reduce the noise introduced by statistical machine translation, we assume that Vp from language Dp (p ∈ [2, P]) should be close to V1</context>
</contexts>
<marker>Tang, Wang, Gao, Hu, Liu, 2012</marker>
<rawString>J. Tang, X. Wang, H. Gao, X. Hu, and H. Liu. 2012. Enriching short text representation in microblog for clustering. Front. Comput., 6(1):88-101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Wachsmuth</author>
<author>M W Oram</author>
<author>D I Perrett</author>
</authors>
<title>Recognition of objects and their component parts: responses of single units in the temporal cortex of teh macaque.</title>
<date>1994</date>
<journal>Cerebral Cortex,</journal>
<pages>4--509</pages>
<contexts>
<context position="10438" citStr="Wachsmuth et al., 1994" startWordPosition="1627" endWordPosition="1630">d qi is a vector representation of qi. 5Statistical machine translation quality is far from satisfactory in real applications. Query Representation Figure 1: Framework of our proposed approach for question retrieval. 2.2 Model Formulation To tackle the data sparseness of question representation with the translated words, we hope to find two or more lower dimensional matrices whose product provides a good approximate to the original one via matrix factorization. Previous studies have shown that there is psychological and physiological evidence for parts-based representation in the human brain (Wachsmuth et al., 1994). The non-negative matrix factorization (NMF) is proposed to learn the parts of objects like text documents (Lee and Seung, 2001). NMF aims to find two non-negative matrices whose product provides a good approximation to the original matrix and has been shown to be superior to SVD in document clustering (Xu et al., 2003; Tang et al., 2012). In this paper, NMF is used to induce the reduced representation Vp of Dp, Dp is independent on {D1, D2, ... , Dp_1, Dp+1, ... , DP}. When ignoring the coupling between Vp, it can be solved by minimizing the objective function as follows: O1(Up,Vp) = min ∥Dp</context>
</contexts>
<marker>Wachsmuth, Oram, Perrett, 1994</marker>
<rawString>E. Wachsmuth, M. W. Oram, and D. I. Perrett. 1994. Recognition of objects and their component parts: responses of single units in the temporal cortex of teh macaque. Cerebral Cortex, 4:509-522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Wang</author>
<author>Z Ming</author>
<author>T-S Chua</author>
</authors>
<title>A syntactic tree matching approach to find similar questions in community-based qa services.</title>
<date>2009</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="1917" citStr="Wang et al., 2009" startWordPosition="275" endWordPosition="278">ic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising. 1 Introduction With the development of Web 2.0, community question answering (CQA) services like Yahoo! Answers,1 Baidu Zhidao2 and WkiAnswers3 have attracted great attention from both academia and industry (Jeon et al., 2005; Xue et al., 2008; Adamic et al., 2008; Wang et al., 2009; Cao et al., 2010). In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions. In this paper, we focus on the task of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to answer the users’ queried questions. However, question re</context>
<context position="25030" citStr="Wang et al. (2009)" startWordPosition="4264" endWordPosition="4267">comparisons are statistically significant at p &lt; 0.05). (3) Our proposed method (leveraging statistical machine translation via matrix factorization, SMT + MF) significantly outperforms the bilingual translation model of Zhou et al. (2012) (row 7 vs. row 8, the comparison is statistically significant at p &lt; 0.05). The reason is that matrix factorization used in the paper can effectively solve the data sparseness and noise introduced by the machine translator simultaneously. (4) When considering more languages, question retrieval performance can be further improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to </context>
</contexts>
<marker>Wang, Ming, Chua, 2009</marker>
<rawString>K. Wang, Z. Ming, and T-S. Chua. 2009. A syntactic tree matching approach to find similar questions in community-based qa services. In Proceedings of SIGIR, pages 187-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wang</author>
<author>X Wang</author>
<author>C Sun</author>
<author>B Liu</author>
<author>L Sun</author>
</authors>
<title>Modeling semantic relevance for question-answer pairs in web social communities.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1230--1238</pages>
<marker>Wang, Wang, Sun, Liu, Sun, 2010</marker>
<rawString>B. Wang, X. Wang, C. Sun, B. Liu, and L. Sun. 2010. Modeling semantic relevance for question-answer pairs in web social communities. In Proceedings of ACL, pages 1230-1238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Xu</author>
<author>X Liu</author>
<author>Y Gong</author>
</authors>
<title>Document clustering based on non-negative matrix factorization.</title>
<date>2003</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>267--273</pages>
<contexts>
<context position="10759" citStr="Xu et al., 2003" startWordPosition="1681" endWordPosition="1684">e to find two or more lower dimensional matrices whose product provides a good approximate to the original one via matrix factorization. Previous studies have shown that there is psychological and physiological evidence for parts-based representation in the human brain (Wachsmuth et al., 1994). The non-negative matrix factorization (NMF) is proposed to learn the parts of objects like text documents (Lee and Seung, 2001). NMF aims to find two non-negative matrices whose product provides a good approximation to the original matrix and has been shown to be superior to SVD in document clustering (Xu et al., 2003; Tang et al., 2012). In this paper, NMF is used to induce the reduced representation Vp of Dp, Dp is independent on {D1, D2, ... , Dp_1, Dp+1, ... , DP}. When ignoring the coupling between Vp, it can be solved by minimizing the objective function as follows: O1(Up,Vp) = min ∥Dp − UpVp∥2F (1) Up&gt;0,Vp&gt;0 where ∥ · ∥F denotes Frobenius norm of a matrix. Matrices Up ∈ RMpxK and Vp ∈ RKxN are the reduced representation for terms and questions in the K dimensional space, respectively. To reduce the noise introduced by statistical machine translation, we assume that Vp from language Dp (p ∈ [2, P]) s</context>
</contexts>
<marker>Xu, Liu, Gong, 2003</marker>
<rawString>W. Xu, X. Liu, and Y. Gong. 2003. Document clustering based on non-negative matrix factorization. In Proceedings of SIGIR, pages 267-273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Xue</author>
<author>J Jeon</author>
<author>W B Croft</author>
</authors>
<title>Retrieval models for question and answer archives.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="1877" citStr="Xue et al., 2008" startWordPosition="267" endWordPosition="270">ng advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising. 1 Introduction With the development of Web 2.0, community question answering (CQA) services like Yahoo! Answers,1 Baidu Zhidao2 and WkiAnswers3 have attracted great attention from both academia and industry (Jeon et al., 2005; Xue et al., 2008; Adamic et al., 2008; Wang et al., 2009; Cao et al., 2010). In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers. As answers are usually explicitly provided by human, they can be helpful in answering real world questions. In this paper, we focus on the task of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to answer the users’</context>
<context position="4183" citStr="Xue et al., 2008" startWordPosition="624" endWordPosition="627">es 852–861, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics English Chinese word ambiguity How do I get a loan R(w6) �PPj(ruhe) ;k(c6ng) from a bank? Wff(yinhbng) �rk(daikudn) ? How to reach the �PPj(ruhe) �#-(qibnwdng) bank of the river? NPV(hean) ? word mismatch company o (gongs!) firm o (g�ngs!) rheum ,q�(g6nm6o) catarrh ,q�(g6nm6o) Table 1: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity proble</context>
<context position="22004" citStr="Xue et al. (2008)" startWordPosition="3747" endWordPosition="3750">ent set is also extracted from Yahoo! Answers, and it is not included in the test set. For parameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, · · · , 300 in terms of MAP. Finally, we set K = 100 in the experiments empirically as this setting yields the best performance. For parameter λ1, we set λ1 = 1 empirically, while for parameter λi (i ∈ [2, P]), we set λi = 0.25 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem</context>
<context position="25298" citStr="Xue et al., 2008" startWordPosition="4308" endWordPosition="4311">son is statistically significant at p &lt; 0.05). The reason is that matrix factorization used in the paper can effectively solve the data sparseness and noise introduced by the machine translator simultaneously. (4) When considering more languages, question retrieval performance can be further improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to ours, and we suspect that combining the category information or label ranking into our proposed method might get even better performance. We leave it for future research. 3.3 Impact of the Matrix Factorization Our proposed method (SMT + MF) can effectively solve the d</context>
</contexts>
<marker>Xue, Jeon, Croft, 2008</marker>
<rawString>X. Xue, J. Jeon, and W. B. Croft. 2008. Retrieval models for question and answer archives. In Proceedings of SIGIR, pages 475-482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Zhai</author>
<author>J Lafferty</author>
</authors>
<title>A study of smooth methods for language models applied to ad hoc information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>334--342</pages>
<contexts>
<context position="22478" citStr="Zhai and Lafferty, 2001" startWordPosition="3836" endWordPosition="3840">ttp://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art performance in previous work. Row 3 is the word-based translation model (Jeon et al., 2005), and row 4 is the wordbased translation language model, which linearly combines the word-based translation model and language model into a unified framework (Xue et al., 2008). Row 5 is the phrase-based translation model, which translates a sequence of words as whole (Zhou et al., 2011). Row 6 is the entitybased translation model, which extends th</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>C. Zhai and J. Lafferty. 2001. A study of smooth methods for language models applied to ad hoc information retrieval. In Proceedings of SIGIR, pages 334-342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>L Cai</author>
<author>J Zhao</author>
<author>K Liu</author>
</authors>
<title>Phrasebased translation model for question retrieval in community question answer archives.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>653--662</pages>
<contexts>
<context position="4565" citStr="Zhou et al. (2011)" startWordPosition="690" endWordPosition="693">: Google translate: some illustrative examples. question may not be easily distinguished from an irrelevant one. Researchers have proposed the use of wordbased translation models (Berger et al., 2000; Jeon et al., 2005; Xue et al., 2008; Lee et al., 2008; Bernhard and Gurevych, 2009) to solve the word mismatch problem. As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval. Besides, Riezler et al. (2007) and Zhou et al. (2011) proposed the phrase-based translation models for question and answer retrieval. The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alleviated. However, all these existing studies in the literature are basically monolingual approaches which are restricted to the use of original language of questions. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are trouble</context>
<context position="22037" citStr="Zhou et al. (2011)" startWordPosition="3754" endWordPosition="3757">ahoo! Answers, and it is not included in the test set. For parameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, · · · , 300 in terms of MAP. Finally, we set K = 100 in the experiments empirically as this setting yields the best performance. For parameter λ1, we set λ1 = 1 empirically, while for parameter λi (i ∈ [2, P]), we set λi = 0.25 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art </context>
</contexts>
<marker>Zhou, Cai, Zhao, Liu, 2011</marker>
<rawString>G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrasebased translation model for question retrieval in community question answer archives. In Proceedings of ACL, pages 653-662.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>K Liu</author>
<author>J Zhao</author>
</authors>
<title>Exploiting bilingual translation for question retrieval in communitybased question answering.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>3153--3170</pages>
<contexts>
<context position="6685" citStr="Zhou et al. (2012)" startWordPosition="1017" endWordPosition="1020">xts are correctly addressed by using the state-of-the-art translation tool −−Google Translate.4 Thus, word ambiguity based on contextual information is naturally involved when questions are translated. (2) Multiple words that have similar meanings in one language may be translated into an unique word or a few words in a foreign language. For example in Table 1, English words such as “company” and “firm” are translated into “ o (gongs!)”, “rheum” and “catarrh” are translated into “,qN(g6nmao)” in Chinese. Thus, word mismatch problem can be somewhat alleviated by using other languages. Although Zhou et al. (2012) exploited bilingual translation for question retrieval and obtained the better performance than traditional monolingual translation models. However, there are two problems with this enrichment: (1) enriching the original questions with the translated words from other languages increases the dimensionality and makes the question representation even more sparse; (2) statistical machine translation may introduce noise, which can harm the performance of question retrieval. To solve these two problems, we propose to leverage statistical machine translation to improve question retrieval via matrix </context>
<context position="22097" citStr="Zhou et al. (2012)" startWordPosition="3766" endWordPosition="3769">arameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, · · · , 300 in terms of MAP. Finally, we set K = 100 in the experiments empirically as this setting yields the best performance. For parameter λ1, we set λ1 = 1 empirically, while for parameter λi (i ∈ [2, P]), we set λi = 0.25 empirically and ensure that Ei λi = 1. 7http://homepages.inf.ed.ac.uk/gcong/qa/ 857 # Methods MAP P@10 1 VSM 0.242 0.226 2 LM 0.385 0.242 3 Jeon et al. (2005) 0.405 0.247 4 Xue et al. (2008) 0.436 0.261 5 Zhou et al. (2011) 0.452 0.268 6 Singh (2012) 0.450 0.267 7 Zhou et al. (2012) 0.483 0.275 8 SMT + MF (P = 2, l1, l2) 0.527 0.284 9 SMT + MF (P = 5) 0.564 0.291 Table 3: Comparison with different methods for question retrieval. 3.2 Question Retrieval Results Table 3 presents the main retrieval performance. Row 1 and row 2 are two baseline systems, which model the relevance score using VSM (Cao et al., 2010) and language model (LM) (Zhai and Lafferty, 2001; Cao et al., 2010) in the term space. Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art performance in previous work. Row 3 is the word-based transl</context>
<context position="23499" citStr="Zhou et al., 2012" startWordPosition="4004" endWordPosition="4007">work (Xue et al., 2008). Row 5 is the phrase-based translation model, which translates a sequence of words as whole (Zhou et al., 2011). Row 6 is the entitybased translation model, which extends the wordbased translation model and explores strategies to learn the translation probabilities between words and the concepts using the CQA archives and a popular entity catalog (Singh, 2012). Row 7 is the bilingual translation model, which translates the English questions from Yahoo! Answers into Chinese questions using Google Translate and expands the English words with the translated Chinese words (Zhou et al., 2012). For these previous work, we use the same parameter settings in the original papers. Row 8 and row 9 are our proposed method, which leverages statistical machine translation to improve question retrieval via matrix factorization. In row 8, we only consider two languages (English and Chinese) and translate English questions into Chinese using Google Translate in order to compare with Zhou et al. (2012). In row 9, we translate English questions into other four languages. There are some clear trends in the result of Table 3: (1) Monolingual translation models significantly outperform the VSM and</context>
<context position="25587" citStr="Zhou et al., 2012" startWordPosition="4354" endWordPosition="4357">ther improved (row 8 vs. row 9). Note that Wang et al. (2009) also addressed the word mismatch problem for question retrieval by using syntactic tree matching. We do not compare with Wang et al. (2009) in Table 3 because previous work (Ming et al., 2010) demonstrated that word-based translation language model (Xue et al., 2008) obtained the superior performance than the syntactic tree matching (Wang et al., 2009). Besides, some other studies attempt to improve question retrieval with category information (Cao et al., 2009; Cao et al., 2010), label ranking (Li et al., 2011) or world knowledge (Zhou et al., 2012). However, their methods are orthogonal to ours, and we suspect that combining the category information or label ranking into our proposed method might get even better performance. We leave it for future research. 3.3 Impact of the Matrix Factorization Our proposed method (SMT + MF) can effectively solve the data sparseness and noise via matrix factorization. To further investigate the impact of the matrix factorization, one intuitive way is to expand the original questions with the translated words from other four languages, without considering the data sparseness and noise introduced by mach</context>
</contexts>
<marker>Zhou, Liu, Zhao, 2012</marker>
<rawString>G. Zhou, K. Liu, and J. Zhao. 2012. Exploiting bilingual translation for question retrieval in communitybased question answering. In Proceedings of COLING, pages 3153-3170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>Y Liu</author>
<author>F Liu</author>
<author>D Zeng</author>
<author>J Zhao</author>
</authors>
<title>Improving Question Retrieval in Community Question Answering Using World Knowledge.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<marker>Zhou, Liu, Liu, Zeng, Zhao, 2013</marker>
<rawString>G. Zhou, Y. Liu, F. Liu, D. Zeng, and J. Zhao. 2013. Improving Question Retrieval in Community Question Answering Using World Knowledge. In Proceedings of IJCAI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>