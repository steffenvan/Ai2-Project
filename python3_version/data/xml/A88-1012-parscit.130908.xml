<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<note confidence="0.601860666666667">
CREATING AND QUERYING LEXICAL DATA BASES
Mary S. Neff, Roy J. Byrd, and Omneya A. Rizk
IBM T. J. Watson Research Center
</note>
<author confidence="0.5026225">
P. 0. Box 704
Yorktown Heights, New York 10598
</author>
<sectionHeader confidence="0.573343" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999443375">
Users of computerized dictionaries require powerful and
flexible tools for analyzing and manipulating the informa-
tion in them. This paper discusses a system for grammat-
ically describing and parsing entries from machine-readable
dictionary tapes and a lexical data base representation for
storing the dictionary information. It also describes a lan-
guage for querying, formatting, and maintaining diction-
aries and other lexical data stored with that representation.
</bodyText>
<sectionHeader confidence="0.990393" genericHeader="keywords">
1. Introduction.
</sectionHeader>
<bodyText confidence="0.999968727272727">
Computer resident lexical information is required in a large
variety of applications, including on-line dictionary refer-
ence systems (Neff and Byrd(1987)), lexicographic sys-
tems for creating new dictionaries (Tompa(1986)),
systems for performing lexicological analyses of existing
dictionaries (Zampolli and Calzolari(1985), Chodorow et
al.(1985)), and various natural language processing sys-
tems (Byrd(1986)). Establishment of standard represent-
ations and access mechanisms for lexical information will
help us to better meet these requirements.
The Lexical Systems project at the IBM T. J. Watson Re-
search Center has defined a lexical data base representation
(LDB) for lexical information, a set of tools and grammars
for converting machine readable dictionary (MRD) type-
setting tapes to the LDB representation, and a Lexical
Query Language (LQL) for specifying storage and retrieval
operations on LDBs. This paper briefly discusses the LDB
structure, the tools and grammar for creating LDBs from
existing sources, and then describes the facilities and im-
plementation of LQL.
Of the many machine-readable dictionary (MRD) re-
sources available, current research concerns exploitation
of the information from one dictionary (for example,
Michiels (1982), Ahlswede, et. al. (1986)) or, in the case
of multiple dictionaries, a limited subset of information
from each (cf. Chodorow, et. al. (1985)). This exploitation
is usually via a special extraction program which gets only
the information needed by the project or application. Al-
though in some cases the literature mentions the term &amp;quot;data
base&amp;quot;, the term is frequently not used in any strict sense,
as it is here.
The work reported in the present paper is related to work
reported by Calzolari ( I 984a, 1984b) and Calzolari and
Picchi(1986). Some of it, particularly the development of
tools and grammars for parsing entries in MRD tapes to
LDB format, is most related in spirit to some of the work
reported by the New Oxford English Dictionary project
(Tompa (1986a), Gonnet and Tompa( 1986),
Benbow(1986)). Whereas the new OED project has de-
fined a markup language for dictionary entries before data
entry and a grammar based on that markup language, this
work attempts to parse and convert to a standard form a
number of different raw type-setting tapes without any
pre-editing.
</bodyText>
<sectionHeader confidence="0.98071" genericHeader="introduction">
2. Lexical Data Bases.
</sectionHeader>
<bodyText confidence="0.999728">
Dictionary entries are typically organized as shallow hier-
archies of information with a variable number of instances
of certain items at each level, e.g. multiple homographs
within an entry or multiple senses within a homograph.
More formally, they can be characterized as finite depth
hierarchies of attribute-value pairs with a variable number
of instances of specific nodes at each level. At at each node
there is an attribute name and a value, which can be a sim-
ple value, a list of attribute-value pairs, or an entire subtree.
A node may have an arbitrary number of daughter nodes
of the same attribute type, just as a dictionary entry can
have an arbitrary number of senses per homograph, for
example. Thus, in the entry for quack from the Collins
English-Italian dictionary, shown in Figure 1, the &apos;&apos;entry&amp;quot;
node has two &amp;quot;superhom&amp;quot; (superscript homograph) nodes
as daughters; the first of these, in turn, dominates two
&amp;quot;homograph&apos;&apos; nodes, one for a noun and the other for an
intransitive verb. Lexicographers are familiar with the
notion of hierarchically structured entries of this type.
It is important to distinguish between the type of hierar-
chies found in dictionary entries and those, for example,
that characterize the syntactic structure of English sen-
tences. Both types of hierarchy are, in principle, of un-
</bodyText>
<page confidence="0.994459">
84
</page>
<figure confidence="0.995843888888889">
entry
+-hdw quack
+-superhom
I +-hum 1
1 +-pron &gt;u71&lt;kw&gt;u43&lt;k&gt;u72&lt;
I +-hom
1 +-hnum 1
1 +-pos n
+-sens
1
+-xlat
+-spel qua qua
+-gnd m inv
+-hom
+-hnum 2
+-pos vi
1
+-sens
1
+-xlat
+-spel fare qua qua
+-superhom
+-hum 2
+-pron &gt;u71&lt;kw&gt;u43&lt;k&gt;u72&lt;
+-hom
+-pos n
1
+-sens
1
+-xlat
+-note pe j
+-spel ciarlatano/a
1
+-xlat
+-note fam: doctor
+-spel dottore/essa
</figure>
<figureCaption confidence="0.999967">
Figure 1. Collins English-Italian entry for quack.
</figureCaption>
<bodyText confidence="0.998213656716418">
bounded size. Dictionary entries achieve their
unboundedness by iteration: a dictionary entry may have
any number of homographs, which may, in turn, have an
arbitrary number of senses, and so forth. Syntax trees
achieve their unboundedness both by iteration (e.g., coor-
dination) and by recursion (e.g., self-embedding). In fact,
while the nodes of a dictionary entry hierarchy may only
iterate, the data values contained in the tree may have their
own--possibly recursive--structures. This is the case for
definition text in monolingual dictionaries, or for
etymologies (as was pointed out by Martin Chodorow).
The observation that dictionary entry hierarchies may only
iterate is useful for defining lexical data bases. All entries
in an LDB can be characterized by a &amp;quot;design&apos;&apos; or &amp;quot;tem-
plate&amp;quot; which is stored once for that data base. The design
is a single hierarchy which serves as a grammar for any in-
stance of an entry by naming the possible parents, siblings,
and children of each node type that may occur. Figure 2
shows a simplified design for an LDB containing the
Collins English-Italian bilingual dictionary. Comments are
given to describe the lexicographic functions of the various
nodes. The entry for quack shown in Figure 1 is an in-
stance of the design shown in Figure 2. Different diction-
aries may have different structures and hence different
designs. The notion of representing dictionary entries as
instances of a hierarchical design derived from a grammar
is not unique to our work; Gonnet and Tompa (1987) use
the same notion when they create hierarchical &amp;quot;p-strings&amp;quot;
over the strings that they analyze with their grammatical
formalism.
Actual LDBs are created by storing hierarchically format-
ted entries in a direct access file with the design stored as
control information (the creation of these formatted entries
is the subject of the next section). The files are managed
by the Dictionary Access Method (DAM), described in
Byrd (1986) and Byrd, et al.(1986b). Each entry is stored
with its headword as the key. Alternate access paths can
be established by building indexes on attributes other than
the headword.
It may be useful to point out reasons for not using tradi-
tional data base mechanisms for storing and accessing
LDBs. We believe that lexical data bases cannot be cor-
rectly viewed as relational data bases. Within the
taxonomy of &amp;quot;normal forms&amp;quot; defined by relational data
base theory, dictionary entries are &amp;quot;unnormalized re-
lations&amp;quot; in which attributes can contain other relations,
rather than simple scalar values. As a result, no efficient
data base tools or attractive languages have been developed
for accessing unnormalized relations. In order to use ex-
isting relational tools to store and access dictionary entries,
we should first re-cast the entries into one of the normal
forms defined by the theory. This could be achieved by
defining relations over sets of siblings in our LDB designs,
creating or selecting unique key attributes among those
siblings, and performing join operations on those attri-
butes. However, to do so would force us to sacrifice the
intuitive advantage that hierarchically organized dictionary
entries offer. We have therefore chosen not to.
Similarly, traditional hierarchical data bases do not provide
an appropriate model for lexical data. In those systems, as
typified by IBM&apos;s IMS (Date (1986)), hierarchical re-
lationships are represented among separate entities which
are stored as &amp;quot;segments&amp;quot;. This metaphor of separate enti-
ties does not apply to lexical data. There is no sense, for
example, in which a translation in the Collins English-
Italian dictionary is a separate entity to be related to other
entities. Rather, each lexical entry is itself a complex entity
</bodyText>
<page confidence="0.999477">
85
</page>
<bodyText confidence="0.9551818">
entry /*root of the tree*/
+-hdw /*English headword; key to the DAM file*/
+-superhom
+-hum
+-pron
</bodyText>
<figure confidence="0.7398296875">
+-altspel /*alternate spelling*/
I +-note /*e.g.&amp;quot;U.S. English&amp;quot;*/
I +-spel /*the alternate spelling string*/
+-hom /*homograph*/
+-hnum /*homograph number*/
+-pos /*part-of-speech*/
+-morph /*irregular inflections, etc.*/
+-sens /*sense*/
+-snum /*sense number*/
/*superscript homograph*/
/*superscript number from printed dictionary*/
/*encoded pronunciations*/
+-xlat
I +-note
I +-spel
I +-gnd
</figure>
<bodyText confidence="0.987408111111111">
+-xmp
+-note
+-gloss
+-pos
+-expl
+-tran
+-gnd
/*translation information for headword*/
/*usage note for the English term*/
/*the Italian translation*/
/*grammatical information about the Italian*/
/*&amp;quot;example&amp;quot; phrases containing headword*/
/*usage note for the English phrase*/
/*the English phrase*/
/*part-of-speech*/
/*more usage information*/
/*Italian translation of phrase*/
/*grammatical information about the Italian*/
</bodyText>
<figureCaption confidence="0.995576">
Figure 2. LDB design for the Collins English-Italian dictionary.
</figureCaption>
<bodyText confidence="0.951098">
with a hierarchical relationship among its internal compo-
nents. Our LDB strategy preserves this intuition.
</bodyText>
<listItem confidence="0.400747">
3. From typesetting tape to data base.
</listItem>
<bodyText confidence="0.975052674418605">
Among the resources available for making lexical data
bases, we have typesetting tapes of Webster&apos;s Seventh,
Longman&apos;s Dictionary of Contemporary English
(LDOCE), several Collins bilingual dictionaries, and two
synonym dictionaries. Creation of lexical data bases began
from a number of direct access b-tree (DAM) files which
had been created from the tapes for the WordSmith on-line
dictionary reference system (Neff and Byrd(1987)). These
files, keyed on headword and containing the otherwise un-
normalized body of the entry, complete with original font
codes, were the result of a by-entry segmentation program,
an idiosyncratic process reflecting the diverse origin and
formatting conventions of the source dictionaries. To meet
the requirements of computerized random access, some
entries (e.g., those with superscripted homograph numbers)
were combined into one entry; words with alternate
spellings (such as &amp;quot;whisk(e)y&amp;quot;) became multiple entries
with cross references; still others (compound entries from
the German-English bilingual dictionary) were broken up
so that each compound word listed could be accessed by its
own key.
The dictionary entry parser. The hierarchical structure of a
dictionary entry is implicit in its syntax. Major signposts
are the homograph numbers, the sense numbers, and the
consistent alternation of fonts; also useful are punctuation,
position of swung dashes (indicating repetition of the head
word in a collocation or example), and membership of an
item in a closed set (part of speech, for example). By way
of illustration, we reproduce here for the entry quack --
both the raw version from the tape of the Collins English-
Italian dictionary and the formatted entry as it appears in
the printed dictionary.
&gt;u1&lt;quack &gt;u123&lt;1 &gt;u155&lt;&gt;u71&lt;kw&gt;u43&lt;k&gt;u72&lt;
&gt;u2&lt;1 &gt;u6&lt;n &gt;u5&lt;qua qua &gt;u6&lt;m inv. &gt;u2&lt;2
&gt;u6&lt;vi &gt;u5&lt;fare qua qua. &gt;u1&lt;quack &gt;u123&lt;2
&gt;u155&lt;&gt;u71&lt;kw&gt;u43&lt;k&gt;u72&lt; &gt;u6&lt;n &gt;u6&lt;(pe3)
&gt;u5&lt;ciarlatano/a; &gt;u6&lt;(fam; doctor)
&gt;u5&lt;dottore/essa.
quackl [kwaek] 1 n qua qua m inv. 2 vi fare qua qua.
quack2 [kwaelc] n (pej) ciarlatano/a; (fain: doctor)
dottore/essa.
To parse the dictionary entries, we constructed a general
parsing engine and a specific grammar for each one of se-
</bodyText>
<page confidence="0.979969">
86
</page>
<bodyText confidence="0.998533159090909">
veral MRD&apos;s. Because dictionary entries may only iterate.
the level of sophistication required of an entry parser is not
as high as that required for a sentence parser. Neverthe-
less, two technologies for sentence parsers were readily
available to us: a bottom-up, all-paths strategy offered by
PLNLP (Langendoen and Barnett(1986)), and a top-down
depth-first approach offered by logic grammars in Prolog
(McCord(1986)). Using either would significantly reduce
the effort required to parse our more than a dozen diction-
aries, because each new dictionary would only require a
new grammar. Preliminary versions in PLNLP and Prolog
were both adequate and contribute nothing to the theore-
tical issues surrounding parsing strategies. The choice of
Prolog for continued development was largely due to the
somewhat deterministic nature of parsing dictionary entries
vis-a-vis the extravagance of the bottom-up, all-paths
strategy. Nevertheless, we are studying the possibility of
implementing a partial bottom-up strategy analogous to
parse-fitting (cf. Jensen, et al.(1983)) when it becomes
necessary to process input with missing or corrupt font
codes, there being few recovery strategies available to a
top-down parser.
Grammars for entries and grammars for sentences differ in
three important ways: (1) entries can be huge: some are
longer than 5000 bytes; (2) tokens, the smallest unit han-
dled by the grammar are larger and defined differently; and
(3) a dictionary grammar does not have to produce recur-
sive structures, so can be to a large extent deterministic.
A consequence of (1) is that it takes a large amount of
storage to parse an entry. To process extremely long en-
tries, we use an 8-megabyte virtual machine under
VM/CMS. The motivation for (2) comes from the fact
that the entries consist of text interspersed with font codes,
which are not required to be delimited with blanks. The
token string for an entry is therefore usually an alternating
string of font codes and characters, with some semicolons
or periods also defined as tokens.
The grammar is a formal description of the structure of
entries for a particular dictionary; its formalism is a mod-
ification and extension of McCord&apos;s (1986) modular logic
grammar (MLG), which is in turn derived from the definite
clause grammar (DCG) of Pereira and Warren (1980).
We illustrate with some sample rules from the grammar of
the Collins English-German dictionary.
</bodyText>
<listItem confidence="0.98823325">
(1) body ==&gt; opt(prehom) : opt(homlist(*)).
(2) body ==&gt; alt.
(3) prehom ==&gt; opt(alt) :
opt(pronunc) : opt(vbmorph) :
opt(note) : opt(abb).
(4) homlist(num) ==&gt; hom(num) :
opt(opt(-sc) : homlist(num)).
(5) homlist(nonum) ==&gt; hom(nonum).
</listItem>
<bodyText confidence="0.9943848125">
Rule (1) says that the body of an entry consists of optional
prehomograph material (prehom) and an optional
homograph list of any type(*). A significant addition to the
MLG formalism was a mechanism for treatment of large
numbers of optional elements in a single rule to prevent
proliferation of rules. Tests added by the compiler enforce
the convention that to succeed, a rule consisting solely of
optional elements must contain at least one. Rule (2) says
that the body of an entry consists of an alternate spelling.
This rule is an alternate to (1); normal Prolog backtracking
conventions apply. Rule (3) says that the prehomograph
may contain any of the following, in this order: alternate
spelling, pronunciation, verb morphology, a usage note, a
long form of which this is an abbreviation. Rule (4) says
that a numbered homograph list consists of a numbered
homograph followed optionally by a semicolon (to be dis-
carded from the resulting structure) and a numbered
homograph list. This rule illustrates the mechanism for
defining multiple sister nodes of the same type by means
of a recursive rule. Though it appears that each successive
homograph node is one level deeper in the tree, the use of
McCord&apos;s definition of some nodes as weak nonte-
rminals&amp;quot; ensures that nodes so defined (like horn/is!, and,
incidentally, prehom) disappear from the final structure,
thus flattening the tree and eliminating recursion. Rule (5)
handles the case of a single unnumbered homograph.
Leaf node rules are more numerous than those that de-
scribe higher structures, and these may contain Prolog-like
tests. Unlike syntax parsers, dictionary entry parsers dis-
card some segments (e.g. font codes) after use in parsing;
the &amp;quot;-&amp;quot; operator, added to the original rule formalism, al-
lows any segment to disappear from the resulting tree.
</bodyText>
<equation confidence="0.796847">
(6) pos ==&gt; -font(ital) : +Seg :
$not(stconc(&amp;quot;(&amp;quot;,*,Seg)) : opt(-sc).
</equation>
<bodyText confidence="0.9944353125">
This rule, one of four handling part of speech segments,
says that the pos segment (Seg) is preceded by an italic font
code (discarded), does not begin with a left parenthesis,
and is followed optionally by a semicolon (also discarded).
Font code definition rules and retokenization rules are
needed before parsing rules are applied. Font code defi-
nition rules are simply Prolog unit clauses, which define
font codes and delimiters, as in the following simple exam-
ple, where the string &amp;quot;&gt;u4&lt;&amp;quot; is both a boldface font token
and a delimiter.
delim(&amp;quot;&gt;u4&lt;&amp;quot;,font(bold)).
Delimiters and strings between delimiters are the tokens.
After initial tokenization, retokenization rules in a
formalism similar to that of the grammar rules make ad-
justments to the token string because of the inexact map-
ping of font changes to segments, as in
</bodyText>
<footnote confidence="0.440497">
...&gt;u5&lt;(&gt;u4&lt;word&gt;u5&lt;) something ...
</footnote>
<page confidence="0.897164">
87
</page>
<bodyText confidence="0.691874">
which is tokenized as
</bodyText>
<equation confidence="0.68311">
font(roman).&amp;quot;(&amp;quot;.font(bold).&amp;quot;word&amp;quot;.
font(roman).&amp;quot;) something&amp;quot;...
but which is modified to:
font(bold).&amp;quot;(word)&amp;quot;.font(roman).
&amp;quot;something&amp;quot; ...
</equation>
<bodyText confidence="0.999988785714286">
The grammar and retokenization rules are compiled into
Prolog clauses with a compiler that is a modification and
extension of McCord&apos;s (1986) MLG rule compiler. Ex-
tensions include the &amp;quot;opt&amp;quot; operator, the &amp;quot;-II operator, and
the &amp;quot;++&amp;quot; operator, which allows rules to insert tokens into
the string during parsing, thus allowing for breakup and
analysis of two different data items not separated by a font
code.
The compiler and rules are supported by a Prolog shell
which offers the rule developer a variety of tools for trac-
ing, debugging, and selecting among a large number of
options, including input and output data and file formats,
thus supporting both development and batch processing.
Tools for analyzing failures assist in the often tedious
process of combing through a long entry to determine why
it failed; in particular, there is a mechanism optionally
compiled into the rules which marks the right-most frontier
(RMF) reached in the parsing process. Other tools analyze
the RMF environments resulting from a batch run to help
the developer determine which rule modifications are re-
quired by the largest number of entries.
The parse trees are compacted and encoded in LDB format
and stored in a DAM file for access by analysis programs,
such as the Lexical Query Language (LQL), described in
the next section. The rule compiler, as part of the compi-
lation process, produces the entry design for the dictionary
that is required by LQL and encodes it as control informa-
tion with the LDB.
</bodyText>
<sectionHeader confidence="0.95585" genericHeader="method">
4. The Lexical Query Language.
</sectionHeader>
<bodyText confidence="0.9999146">
The LQL programming language must satisfy several re-
quirements. First, it must be possible to formulate an un-
restricted variety of queries against any LDB. Second, it
must be possible to flexibly format the answers to queries,
either for display or for use in creating other computer files.
Third, LQL must allow users to specify modification oper-
ations on LDBs; this will allow for LDB maintenance. The
style of LQL programs must be natural and easy to re-
member. See Byrd(1986) for a discussion of these re-
quirements on computerized dictionaries.
Data base query. The Lexical Query Language allows the
user to specify conditions on the attributes of LDB entries.
Only those entries which satisfy all conditions become part
of the query answer. Further, the user specifies which at-
tributes of the successful entries are part of the answer and
what their output format will be. The query is stated as
entries in the nodes of a two-dimensional representation
of an LDB&apos;s design (see Figure 2), using a syntax remi-
niscent of the Query-by-Example (QBE) data base query
language (Zloof(1974)). Example-elements, denoted by a
leading underscore, are used to relate values of attributes
in a query tree to conditions in a condition box, to display
positions in an output box, and to values in other dictionary
entry trees (for &amp;quot;join&amp;quot; operations).
Part (a) of Figure 3 shows a query which will list all words
which are both nouns and verbs in English together with
their translations in the Collins English-Italian dictionary.
The condition on the noun part-of-speech attribute is sim-
ple (it must be &apos;&apos;n&amp;quot; for this data base) and is entered di-
rectly in the tree. The condition on the verb part of speech
is more complex, and the example-element VPOS is used
to relate those attribute values to the condition box, where
they are tested for equality with either &amp;quot;vi&amp;quot; or &amp;quot;vt&amp;quot;. The
example-elements WORD. NTRAN, and VTRAN
are used to map answers from the hierarchy into the output
box where their eventual output format is schematically
represented. Part (b) of Figure 5 shows sample entries
from the answer to this query when applied to the Collins
English-Italian dictionary. Such a query might be useful,
for example, in a study of the relation between homography
in English and derivational morphology in Italian.
As in the query tree itself, the output box may contain both
constants and example-elements. The constants define
boilerplate material used to label the variable instantiations
of the example-elements, as in Figure 3. Such labelling is
perhaps more useful when dictionary entries are presented
one at a time, as in the WordSmith on-line dictionary sys-
tem (Neff and Byrd(1987)). Alternately, a p. (for
&amp;quot;print&amp;quot;) operator can be user&apos;. in the terminal or non-
terminal nodes of the query tree to specify which data
should be given in a hierarchically formatted display of the
query answers. Figure Figure 4(c) illustrates the use of the
p. operator.
LQL conditions specify tests to be performed on the values
of attributes in the data tree to which nodes in the query
tree may be mapped during query processing. Terminal
nodes may be tested using a variety of string and arithmetic
operations. The current prototype implementation includes
the built-in functions of the REXX programming language
(IBM (1984)). Non-terminal nodes may only be tested for
equality or inequality with other nodes having the same at-
tribute name. All nodes may have aggregate functions
(e.g., count, maximum, minimum, etc.) applied to them
and the results may either be tested in conditions or be
output as part of the query answer. Nodes may also be
</bodyText>
<page confidence="0.995689">
88
</page>
<figure confidence="0.937454696969697">
(a) Query
entry I OUTPUT
+-hdw WORD WORD: WORD
+-superhom
I NOUNS VERBS I
+-hom I _NTRAN VTRAN I
+-pos n
+-sens
+-xlat
+-spel NTRAN
+-hom
+-pos _VPOS
+-sens
+-xlat
+-spel VTRAN
(b) Answer:
CONDITIONS
I VPOS = vi I _VPOS = vt I
I —
WORD: force
NOUNS
forza
VERBS
forzare
costringere
WORD: quack
NOUNS VERBS
qua qua fare qua qua
WORD: scream VERBS
NOUNS gridare
grido urlare
strillo
urlo
</figure>
<figureCaption confidence="0.991991">
Figure 3. An LQL query.
</figureCaption>
<bodyText confidence="0.99955635">
tested for a null value (i.e., non-occurrence in a particular
entry).
In addition to producing the formatted output specified in
the output box, the process of answering a query also
yields, as a by-product, an answer LDB. This is a new LDB
containing just those entries from the original LDB which
satisfied all conditions, and containing just those attributes
which were either part of the conditions or the output
specification. The design for the answer LDB is derived
from the query tree and is a subset of the design for the
original LDB.
Data base modification. A realistic data base system must
provide facilities for creating and maintaining data bases.
LDB creation is usually a bulk operation and has been dis-
cussed in section 3. LDB maintenance, on the other hand,
can benefit from the flexibility provided by combining a
powerful query processor with the capability to insert, de-
lete, and update parts of the LDB entries. LQL offers this
flexibility by providing the operators i. (for &amp;quot;insert&amp;quot;), d.
(for &amp;quot;delete), and u. (for &amp;quot;update&amp;quot;). These are also famil-
iar QBE operators and are described (in a relational con-
text) in IBM(1978).
Figure 4 shows three examples of how these operators
might be used to modify an LDB containing the Collins
English-Italian dictionary. In (a), a new entry for the term
&amp;quot;lexical data base&amp;quot; is added to the dictionary; notice that
the i. operator applies to the entire hierarchy, so that a new
record will be added to the DAM file containing the LDB.
Similarly, program (b) will delete entire entries, if any have
headwords which satisfy the condition that they not be al-
phabetic (determined by using the REXX datatype func-
tion, which - in this case - checks whether the value consists
of entirely mixed case alphabetic characters). Finally, (c)
locates entries where a &amp;quot;superhom&amp;quot; (superscript
homograph) node dominates exactly one &amp;quot;horn&amp;quot;
(homograph) node (as determined by the cnt. operator).
The headwords of such entries are printed by the p. opera-
tor and the &amp;quot;horn&amp;quot; nodes receive a new &amp;quot;hno&amp;quot; (homograph
number) attribute with the value &amp;quot;1&amp;quot; as a result of the i.
operator.
</bodyText>
<page confidence="0.998787">
89
</page>
<figure confidence="0.579325285714286">
(a) Add a new entry. headwords.
entry i.
+-hdw lexical data base
+-superhom
+-hum 1
+-hom
+-pos n
+-sens
+-xlat
+-note technical
+-spel dizinario macchina
+-gnd m
(b) Delete entries with non-alphabetic
entry d.
+-hdw _WORD
(c) Assign homograph numbers to
entry
+-hdw p.
+-superhom
+-hom _HNODE
+hno 1.1
</figure>
<figureCaption confidence="0.99773">
Figure 4. LQL programs for modifying an LDB.
</figureCaption>
<equation confidence="0.8725826">
CONDITIONS
I datatype(_WORD,W) =
single homographs.
CONDITIONS
I cnt._HNODE = 1
</equation>
<bodyText confidence="0.999472">
Figure 5 shows how an initial attempt to build an Italian
synonym dictionary from an English synonym dictionary
and an English-Italian bilingual dictionary might be pro-
grammed using LQL. This program creates the Italian
synonym dictionary by simply translating the English syn-
onym dictionary into Italian while retaining the English
sense numbers. The program uses example elements (e.g.,
ESYN which maps English synonyms to headwords in
the English Italian dictionary) to specify join operations
among the input dictionaries and to map results into the
output dictionary. Clearly, this procedure is
lexicographically naive and inadequate; the point of the
example is to show the ease which which lexical exploration
can be performed using LQL.
</bodyText>
<sectionHeader confidence="0.797573" genericHeader="method">
5. Status and Plans.
</sectionHeader>
<bodyText confidence="0.999961862068965">
The entire Collins English-German dictionary, consisting
of 46,600 entries, was recently submitted to the parser and
E-G grammar with a parsing rate of 80% of the entries.
Parts of the Collins Italian-English and English-Italian dic-
tionary were parsed with their respective grammars with a
success rate of about 95%; some of the entries were quite
large. The high success rate on the Italian dictionaries is
partly due to the consistency in the formatting of these
dictionaries and the integrity of the tapes. The rules for
both grammars are still being improved to account for the
residue. Among the remaining problems are the following:
some contiguous data items appear in the same font with-
out an intervening font code, some discrete data items use
more than one font, some kinds of data items are discon-
tiguous, and some new lower level structures used in only
a few entries remain to be discovered.
Unfortunately, the residue often contains long entries as-
sociated with high-frequency words, making partial results
less immediately usable. However, unparsable entries of-
ten have large sections of parsable material, which could
be made available in LDB format for analysis or applica-
tions in spite of its partial nature, if only the top-down
parser wouldn&apos;t fail. Because a dictionary eutry has iden-
tifiable signposts like homograph numbers and sense num-
bers that can be possible recovery points, we plan to
implement and constrain a &amp;quot;junk collecting&amp;quot; rule in the
English-German grammar that will pick up and blandly la-
bel everything at or just before the failure point up to the
next recovery point.
</bodyText>
<page confidence="0.978624">
90
</page>
<figure confidence="0.99901834375">
+-English-Italian
entry
+-hdw EWRD
+-superhom
+-hom
+-sens
+-xlat
+-spel I WRD
+-English Synonyms
1 entry
I +-hdw _EWRD
I I
1 +-sense
+-num _SNUM
+-synonym
+-spel _ESYN
+-English-Italian
entry
+-hdw _ESYN
+-superhom
+-hom
+-sens
+-xlat •
+-spel ISYN
+-Italian Synonyms
1 entry i.
I +-hdw _IWRD
I I
+-sense
+-num _SNUM
+-synonym
+-spel _ISYN
</figure>
<figureCaption confidence="0.999717">
Figure 5. LQL program to create an Italian synonym dictionary.
</figureCaption>
<bodyText confidence="0.999980841269841">
Recently we parsed a small random sample from the
Collins French-English dictionary using a slightly modified
English-German grammar, including some junk collection.
The success rate was about 50%. The time required to
modify the English-German grammar for the French dic-
tionary was less than an hour, confirming our belief in the
efficacy of our approach to dealing with multiple diction-
aries.
We intend to build grammars and LDBs for all our dic-
tionary resources. The uses to which these LDBs can be
put are numerous; we have identified the following initial
projects. Analysis of the English-Italian and Italian-
English dictionaries has allowed us to transfer semantic in-
formation from an English monolingual dictionary to an
Italian one (see Byrd, et al.(1986)). The English-German
LDB will soon be used for analysis as part of the develop-
ment of LMT, an English-German machine translation
system (McCord (1986)). The English-French and
French-English dictionaries will be used as part of a study
of asymmetrical references in bilingual dictionaries (see
Byrd, et al.(1986)).
Many other kinds of applications and analyses will be pos-
sible with the LDBs created from printed dictionaries. One
could easily imagine a lexical data base as the common
source for several different variants of printed dictionaries.
Indeed, publishers are beginning to use the notion of an
LDB for maintenance and enhancement of their products
(cf. New OED, Gonnet and Tompa(1986)). On-line ref-
erence systems need not be limited to the information
available in printed dictionaries, as they are today: users
of such systems can define their own views of the on-line
data. Natural language processing systems can use parts
of a common LDB, extracted for their requirements. Fur-
ther exciting possibilities include more inter-dictionary in-
vestigations or even the creation of a combined LDB and
dealing with the so-called &amp;quot;mapping&amp;quot; problem: how to map
information from one dictionary onto another.
A prototype LQL query processor and output formatter
have been built at IBM Research. The prototype processes
single dictionary queries with conditions and produces for-
matted and hierarchical output as well as answer LDBs.
Current work is aimed at implementing the full language
(including joins, updates, and aggregate operations) and
improving performance in order to make LQL attractive
for use in a wide variety of applications. The first large
scale applications will be a stand-alone query processor for
use in lexicological research and an entry storage, filtering,
and formatting mechanism for the WordSmith on-line dic-
tionary system.
LQL queries would be tedious and difficult to create if they
had to be entered all by hand. Fortunately, the LDB design
can be used to build a user interface which presents a query
tree template to be filled in by the terminal user. The pro-
totype implementation does this and provides further facil-
ities for moving, copying, and deleting subtrees during
query preparation. A new one-dimensional representation
must be defined for use in storing LQL programs and to
provide a mechanism for issuing LQL requests from other
programming languages.
Beyond dictionaries. The tools described here can be used
for parsing and querying other kinds of data. The notion
of creating a data base from data parsed from text (&amp;quot;text-
dominated databases,&amp;quot; cf. Gonnet and Tompa(1987)) can
</bodyText>
<page confidence="0.995529">
91
</page>
<bodyText confidence="0.997422166666667">
Gonnet, Gaston H. and Frank Wm. Tompa (1986) &amp;quot;Status Re-
port on University of Waterloo Technical Activities for the New
OED Project&amp;quot;, University of Waterloo, unpublished.
be applied to other collections of structured data, such as
almanacs, encyclopedias, abstracts, legal documents, or
bibliographies.
</bodyText>
<sectionHeader confidence="0.974167" genericHeader="method">
References.
</sectionHeader>
<reference confidence="0.999911808219178">
Ahlswede, Thomas, Martha Evens. Kay Rossi. and Judith
Markowitz (1986) &amp;quot;Building a Lexical Database by Parsing
Webster&apos;s Seventh New Collegiate Dictionary,&amp;quot; Advances in
Lexicology. Second Annual Conference of the UW Centre for the
New Oxford English Dictionary, 65-78.
Benbow, Tim (1986) &amp;quot;Status Report on the New OED Project&amp;quot;.
Oxford University Press, unpublished.
Byrd. Roy J. (1986) &amp;quot;Dictionary Systems for Office Practice,&amp;quot;
Proceedings of the Grosseto Workshop &amp;quot;On Automating the
Lexicon&amp;quot;, also available as IBM Research Report RC 11872.
Byrd, Roy J., Nicoletta Calzolari, Martin S. Chodorow, Judith
L. Klavans, Mary S. Neff. Omneya A. Rizk (1987) &amp;quot;Tools and
Methods for Computational Lexicology,&amp;quot; Computational Lin-
guistics.
Byrd. Roy J.. Gustaf Neumann, and Karl Seved B. Andersson
(1986b) &amp;quot;DAM - A Dictionary Access Method,&amp;quot; IBM Research
Report, in preparation.
Calzolari, Nicoletta (1984a) &amp;quot;Detecting patterns in a lexical data
base,&amp;quot; Proceedings of COLING 84, 170-173.
Calzolari, Nicoletta (1984b) &amp;quot;Machine-readable dictionaries,
lexical data bases, and the lexical system,&amp;quot; Proceedings of
COLING 84, 460.
Calzolari, Nicoletta and Eugenio Picchi, (1986) &amp;quot;A Project for
a Bilingual Lexical Database System&amp;quot;, Advances in Lexicology,
Second Annual Conference of the UW Centre for the New
Oxford English Dictionary, 79-92.
Chodorow, Martin S., Roy J. Byrd, and George E. Heidorn
(1985) &amp;quot;Extracting Semantic Hierarchies from a Large On-line
Dictionary,&amp;quot; Proceedings of the Association for Computational
Linguistics, 299-304.
Collins (1980) Collins German Dictionary: German-English.
English-German, Collins Publishers, Glasgow.
Collins (1980) Collins Sansoni Italian Dictionary: Italian-
English, English-Italian, Collins Publishers, Glasgow.
Date, Christopher J. (1986) At Introduction to Data Base
Systems, Addison-Wesley.
Gonnet, Gaston H. and Frank Wm. Tompa (1987) &amp;quot;Mind Your
Grammar: a New Approach to Modelling Text,&amp;quot; University of
Waterloo Centre for the New Oxford English Dictionary, Report
OED-87-0 I.
IBM (1978) Query-by-Example: Terminal Users Guide, IBM
form no. SH20-2078.
IBM (1984) System Product Interpreter (REXX) Reference Man-
ual, IBM form no. SC24-5239.
Jensen. Karen, George E. Heidorn. Lance A. Miller, and Yael
Ravin (1983) &amp;quot;Parse Fitting and prose Fixing: Getting a Hold
on III-formedness,&amp;quot; AJCL 9.3-4.123-36.
Langendoen, D. Terence and H. Michael Barnett (1986)
&amp;quot;PLNLP: A Linguist&apos;s Introduction.&amp;quot; IBM Research Report.
Longman(1978) Longman Dictionary of Contemporary English,
Longman Group, London.
McCord, Michael C. (1986) &amp;quot;Design of a Prolog-Based Machine
Translation System&amp;quot;, Proc. Third International Conference on
Logic Programming, Springer-Verlag, 350-374.
McCord, Michael C. (1987) &amp;quot;Natural language processing and
Prolog,&amp;quot; Knowledge Systems and Prolog. in Adrian Walker.
Michael McCord, John Sowa. and Walter Wilson, ed. Addison-
Wesley. Waltham, Massachusetts.
Michiels, Archibal (1982) Exploiting a Large Dictionary Data
Base. Unpublished PhD Dissertation. University of Liege, Liege.
Holland.
Neff, Mary S. and Roy J. Byrd (1987) &amp;quot;WordSmith Users
Guide,&amp;quot; IBM Research Report, in preparation.
Pereira, Fernando, and David Warren (1980) &amp;quot;Definite clause
grammars for language analysis - a survey of the formalism and
a comparison with augmented transition networks&amp;quot;, Artificial
Intelligence, 13, 231-178.
Tompa, Frank (1986) &amp;quot;Database design for a dictionary of the
future,&amp;quot; University of Waterloo, unpublished.
Zampolli, Antonio and Nicoletta Calzolari (1985) &amp;quot;Computa-
tional Lexicography and Lexicology,&amp;quot; AILA Bulletin, pp. 59-78.
Zloof, Moshe M. (1974) &amp;quot;Query by Example,&amp;quot; IBM Research
Report RC 4917.
</reference>
<page confidence="0.996007">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.852374">
<title confidence="0.998582">CREATING AND QUERYING LEXICAL DATA BASES</title>
<author confidence="1">Mary S Neff</author>
<author confidence="1">Roy J Byrd</author>
<author confidence="1">Omneya A Rizk</author>
<affiliation confidence="0.999907">IBM T. J. Watson Research Center</affiliation>
<address confidence="0.9590575">704 Yorktown Heights, New York 10598</address>
<abstract confidence="0.991807">Users of computerized dictionaries require powerful and flexible tools for analyzing and manipulating the information in them. This paper discusses a system for grammatically describing and parsing entries from machine-readable dictionary tapes and a lexical data base representation for storing the dictionary information. It also describes a language for querying, formatting, and maintaining dictionaries and other lexical data stored with that representation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kay Rossi</author>
<author>Judith Markowitz</author>
</authors>
<title>Building a Lexical Database by Parsing Webster&apos;s Seventh New Collegiate Dictionary,&amp;quot;</title>
<date>1986</date>
<booktitle>Advances in Lexicology. Second Annual Conference of the UW Centre for the New Oxford English Dictionary,</booktitle>
<pages>65--78</pages>
<marker>Rossi, Markowitz, 1986</marker>
<rawString>Ahlswede, Thomas, Martha Evens. Kay Rossi. and Judith Markowitz (1986) &amp;quot;Building a Lexical Database by Parsing Webster&apos;s Seventh New Collegiate Dictionary,&amp;quot; Advances in Lexicology. Second Annual Conference of the UW Centre for the New Oxford English Dictionary, 65-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Benbow</author>
</authors>
<title>Status Report on the New OED Project&amp;quot;.</title>
<date>1986</date>
<pages>unpublished.</pages>
<publisher>Oxford University Press,</publisher>
<marker>Benbow, 1986</marker>
<rawString>Benbow, Tim (1986) &amp;quot;Status Report on the New OED Project&amp;quot;. Oxford University Press, unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Roy</author>
</authors>
<title>Dictionary Systems for Office Practice,&amp;quot; Proceedings of the Grosseto Workshop &amp;quot;On Automating the Lexicon&amp;quot;, also available as IBM</title>
<date>1986</date>
<tech>Research Report RC 11872.</tech>
<marker>Roy, 1986</marker>
<rawString>Byrd. Roy J. (1986) &amp;quot;Dictionary Systems for Office Practice,&amp;quot; Proceedings of the Grosseto Workshop &amp;quot;On Automating the Lexicon&amp;quot;, also available as IBM Research Report RC 11872.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omneya A Rizk</author>
</authors>
<title>Tools and Methods for Computational Lexicology,&amp;quot; Computational Linguistics.</title>
<date>1987</date>
<marker>Rizk, 1987</marker>
<rawString>Byrd, Roy J., Nicoletta Calzolari, Martin S. Chodorow, Judith L. Klavans, Mary S. Neff. Omneya A. Rizk (1987) &amp;quot;Tools and Methods for Computational Lexicology,&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Roy J Gustaf Neumann</author>
<author>Karl Seved B</author>
</authors>
<title>Andersson (1986b) &amp;quot;DAM - A Dictionary Access Method,&amp;quot; IBM Research Report,</title>
<note>in preparation.</note>
<marker>Neumann, B, </marker>
<rawString>Byrd. Roy J.. Gustaf Neumann, and Karl Seved B. Andersson (1986b) &amp;quot;DAM - A Dictionary Access Method,&amp;quot; IBM Research Report, in preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
</authors>
<title>Detecting patterns in a lexical data base,&amp;quot;</title>
<date>1984</date>
<journal>Proceedings of COLING</journal>
<volume>84</volume>
<pages>170--173</pages>
<marker>Calzolari, 1984</marker>
<rawString>Calzolari, Nicoletta (1984a) &amp;quot;Detecting patterns in a lexical data base,&amp;quot; Proceedings of COLING 84, 170-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
</authors>
<title>Machine-readable dictionaries, lexical data bases, and the lexical system,&amp;quot;</title>
<date>1984</date>
<booktitle>Proceedings of COLING 84,</booktitle>
<pages>460</pages>
<marker>Calzolari, 1984</marker>
<rawString>Calzolari, Nicoletta (1984b) &amp;quot;Machine-readable dictionaries, lexical data bases, and the lexical system,&amp;quot; Proceedings of COLING 84, 460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
<author>Eugenio Picchi</author>
</authors>
<title>A Project for a Bilingual Lexical Database System&amp;quot;,</title>
<date>1986</date>
<booktitle>Advances in Lexicology, Second Annual Conference of the UW Centre for the New Oxford English Dictionary,</booktitle>
<pages>79--92</pages>
<marker>Calzolari, Picchi, 1986</marker>
<rawString>Calzolari, Nicoletta and Eugenio Picchi, (1986) &amp;quot;A Project for a Bilingual Lexical Database System&amp;quot;, Advances in Lexicology, Second Annual Conference of the UW Centre for the New Oxford English Dictionary, 79-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin S Chodorow</author>
<author>Roy J Byrd</author>
<author>George E Heidorn</author>
</authors>
<title>Extracting Semantic Hierarchies from a Large On-line Dictionary,&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>299--304</pages>
<marker>Chodorow, Byrd, Heidorn, 1985</marker>
<rawString>Chodorow, Martin S., Roy J. Byrd, and George E. Heidorn (1985) &amp;quot;Extracting Semantic Hierarchies from a Large On-line Dictionary,&amp;quot; Proceedings of the Association for Computational Linguistics, 299-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collins</author>
</authors>
<title>Collins German Dictionary: German-English.</title>
<date>1980</date>
<publisher>English-German, Collins Publishers,</publisher>
<location>Glasgow.</location>
<marker>Collins, 1980</marker>
<rawString>Collins (1980) Collins German Dictionary: German-English. English-German, Collins Publishers, Glasgow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collins</author>
</authors>
<title>Collins Sansoni Italian Dictionary: ItalianEnglish, English-Italian, Collins Publishers,</title>
<date>1980</date>
<location>Glasgow.</location>
<marker>Collins, 1980</marker>
<rawString>Collins (1980) Collins Sansoni Italian Dictionary: ItalianEnglish, English-Italian, Collins Publishers, Glasgow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher J Date</author>
</authors>
<title>At Introduction to Data Base Systems,</title>
<date>1986</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="8112" citStr="Date (1986)" startWordPosition="1285" endWordPosition="1286">s, we should first re-cast the entries into one of the normal forms defined by the theory. This could be achieved by defining relations over sets of siblings in our LDB designs, creating or selecting unique key attributes among those siblings, and performing join operations on those attributes. However, to do so would force us to sacrifice the intuitive advantage that hierarchically organized dictionary entries offer. We have therefore chosen not to. Similarly, traditional hierarchical data bases do not provide an appropriate model for lexical data. In those systems, as typified by IBM&apos;s IMS (Date (1986)), hierarchical relationships are represented among separate entities which are stored as &amp;quot;segments&amp;quot;. This metaphor of separate entities does not apply to lexical data. There is no sense, for example, in which a translation in the Collins EnglishItalian dictionary is a separate entity to be related to other entities. Rather, each lexical entry is itself a complex entity 85 entry /*root of the tree*/ +-hdw /*English headword; key to the DAM file*/ +-superhom +-hum +-pron +-altspel /*alternate spelling*/ I +-note /*e.g.&amp;quot;U.S. English&amp;quot;*/ I +-spel /*the alternate spelling string*/ +-hom /*homograph</context>
</contexts>
<marker>Date, 1986</marker>
<rawString>Date, Christopher J. (1986) At Introduction to Data Base Systems, Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gaston H Gonnet</author>
<author>Frank Wm</author>
</authors>
<title>Mind Your Grammar: a New Approach to Modelling Text,&amp;quot;</title>
<date>1987</date>
<tech>Report OED-87-0 I.</tech>
<institution>University of Waterloo Centre for the New Oxford English Dictionary,</institution>
<location>Tompa</location>
<marker>Gonnet, Wm, 1987</marker>
<rawString>Gonnet, Gaston H. and Frank Wm. Tompa (1987) &amp;quot;Mind Your Grammar: a New Approach to Modelling Text,&amp;quot; University of Waterloo Centre for the New Oxford English Dictionary, Report OED-87-0 I.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IBM</author>
</authors>
<title>Query-by-Example: Terminal Users Guide,</title>
<date>1978</date>
<journal>IBM form</journal>
<pages>20--2078</pages>
<marker>IBM, 1978</marker>
<rawString>IBM (1978) Query-by-Example: Terminal Users Guide, IBM form no. SH20-2078.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IBM</author>
</authors>
<title>System Product Interpreter (REXX) Reference Manual,</title>
<date>1984</date>
<journal>IBM form</journal>
<pages>24--5239</pages>
<contexts>
<context position="22236" citStr="IBM (1984)" startWordPosition="3490" endWordPosition="3491"> p. (for &amp;quot;print&amp;quot;) operator can be user&apos;. in the terminal or nonterminal nodes of the query tree to specify which data should be given in a hierarchically formatted display of the query answers. Figure Figure 4(c) illustrates the use of the p. operator. LQL conditions specify tests to be performed on the values of attributes in the data tree to which nodes in the query tree may be mapped during query processing. Terminal nodes may be tested using a variety of string and arithmetic operations. The current prototype implementation includes the built-in functions of the REXX programming language (IBM (1984)). Non-terminal nodes may only be tested for equality or inequality with other nodes having the same attribute name. All nodes may have aggregate functions (e.g., count, maximum, minimum, etc.) applied to them and the results may either be tested in conditions or be output as part of the query answer. Nodes may also be 88 (a) Query entry I OUTPUT +-hdw WORD WORD: WORD +-superhom I NOUNS VERBS I +-hom I _NTRAN VTRAN I +-pos n +-sens +-xlat +-spel NTRAN +-hom +-pos _VPOS +-sens +-xlat +-spel VTRAN (b) Answer: CONDITIONS I VPOS = vi I _VPOS = vt I I — WORD: force NOUNS forza VERBS forzare costrin</context>
</contexts>
<marker>IBM, 1984</marker>
<rawString>IBM (1984) System Product Interpreter (REXX) Reference Manual, IBM form no. SC24-5239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn Lance A Miller Karen</author>
</authors>
<title>and Yael Ravin</title>
<date>1983</date>
<journal>AJCL</journal>
<pages>9--3</pages>
<marker>Karen, 1983</marker>
<rawString>Jensen. Karen, George E. Heidorn. Lance A. Miller, and Yael Ravin (1983) &amp;quot;Parse Fitting and prose Fixing: Getting a Hold on III-formedness,&amp;quot; AJCL 9.3-4.123-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Terence Langendoen</author>
<author>H Michael Barnett</author>
</authors>
<title>PLNLP: A Linguist&apos;s Introduction.&amp;quot;</title>
<date>1986</date>
<journal>IBM Research Report.</journal>
<marker>Langendoen, Barnett, 1986</marker>
<rawString>Langendoen, D. Terence and H. Michael Barnett (1986) &amp;quot;PLNLP: A Linguist&apos;s Introduction.&amp;quot; IBM Research Report.</rawString>
</citation>
<citation valid="false">
<title>Longman(1978) Longman Dictionary of Contemporary English,</title>
<publisher>Longman Group,</publisher>
<location>London.</location>
<marker></marker>
<rawString>Longman(1978) Longman Dictionary of Contemporary English, Longman Group, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
</authors>
<title>Design of a Prolog-Based Machine Translation System&amp;quot;,</title>
<date>1986</date>
<booktitle>Proc. Third International Conference on Logic Programming,</booktitle>
<pages>350--374</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="29213" citStr="McCord (1986)" startWordPosition="4637" endWordPosition="4638"> confirming our belief in the efficacy of our approach to dealing with multiple dictionaries. We intend to build grammars and LDBs for all our dictionary resources. The uses to which these LDBs can be put are numerous; we have identified the following initial projects. Analysis of the English-Italian and ItalianEnglish dictionaries has allowed us to transfer semantic information from an English monolingual dictionary to an Italian one (see Byrd, et al.(1986)). The English-German LDB will soon be used for analysis as part of the development of LMT, an English-German machine translation system (McCord (1986)). The English-French and French-English dictionaries will be used as part of a study of asymmetrical references in bilingual dictionaries (see Byrd, et al.(1986)). Many other kinds of applications and analyses will be possible with the LDBs created from printed dictionaries. One could easily imagine a lexical data base as the common source for several different variants of printed dictionaries. Indeed, publishers are beginning to use the notion of an LDB for maintenance and enhancement of their products (cf. New OED, Gonnet and Tompa(1986)). On-line reference systems need not be limited to th</context>
</contexts>
<marker>McCord, 1986</marker>
<rawString>McCord, Michael C. (1986) &amp;quot;Design of a Prolog-Based Machine Translation System&amp;quot;, Proc. Third International Conference on Logic Programming, Springer-Verlag, 350-374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
</authors>
<title>Natural language processing and Prolog,&amp;quot; Knowledge Systems and Prolog.</title>
<date>1987</date>
<editor>in Adrian Walker. Michael McCord, John Sowa. and Walter Wilson, ed.</editor>
<publisher>AddisonWesley.</publisher>
<location>Waltham, Massachusetts.</location>
<marker>McCord, 1987</marker>
<rawString>McCord, Michael C. (1987) &amp;quot;Natural language processing and Prolog,&amp;quot; Knowledge Systems and Prolog. in Adrian Walker. Michael McCord, John Sowa. and Walter Wilson, ed. AddisonWesley. Waltham, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Archibal Michiels</author>
</authors>
<title>Exploiting a Large Dictionary Data Base.</title>
<date>1982</date>
<institution>Unpublished PhD Dissertation. University of Liege,</institution>
<location>Liege. Holland.</location>
<contexts>
<context position="1910" citStr="Michiels (1982)" startWordPosition="275" endWordPosition="276">ata base representation (LDB) for lexical information, a set of tools and grammars for converting machine readable dictionary (MRD) typesetting tapes to the LDB representation, and a Lexical Query Language (LQL) for specifying storage and retrieval operations on LDBs. This paper briefly discusses the LDB structure, the tools and grammar for creating LDBs from existing sources, and then describes the facilities and implementation of LQL. Of the many machine-readable dictionary (MRD) resources available, current research concerns exploitation of the information from one dictionary (for example, Michiels (1982), Ahlswede, et. al. (1986)) or, in the case of multiple dictionaries, a limited subset of information from each (cf. Chodorow, et. al. (1985)). This exploitation is usually via a special extraction program which gets only the information needed by the project or application. Although in some cases the literature mentions the term &amp;quot;data base&amp;quot;, the term is frequently not used in any strict sense, as it is here. The work reported in the present paper is related to work reported by Calzolari ( I 984a, 1984b) and Calzolari and Picchi(1986). Some of it, particularly the development of tools and gram</context>
</contexts>
<marker>Michiels, 1982</marker>
<rawString>Michiels, Archibal (1982) Exploiting a Large Dictionary Data Base. Unpublished PhD Dissertation. University of Liege, Liege. Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary S Neff</author>
<author>Roy J Byrd</author>
</authors>
<title>WordSmith Users Guide,&amp;quot;</title>
<date>1987</date>
<note>IBM Research Report, in preparation.</note>
<marker>Neff, Byrd, 1987</marker>
<rawString>Neff, Mary S. and Roy J. Byrd (1987) &amp;quot;WordSmith Users Guide,&amp;quot; IBM Research Report, in preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>David Warren</author>
</authors>
<title>Definite clause grammars for language analysis - a survey of the formalism and a comparison with augmented transition networks&amp;quot;,</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<volume>13</volume>
<pages>231--178</pages>
<contexts>
<context position="14150" citStr="Pereira and Warren (1980)" startWordPosition="2182" endWordPosition="2185">irtual machine under VM/CMS. The motivation for (2) comes from the fact that the entries consist of text interspersed with font codes, which are not required to be delimited with blanks. The token string for an entry is therefore usually an alternating string of font codes and characters, with some semicolons or periods also defined as tokens. The grammar is a formal description of the structure of entries for a particular dictionary; its formalism is a modification and extension of McCord&apos;s (1986) modular logic grammar (MLG), which is in turn derived from the definite clause grammar (DCG) of Pereira and Warren (1980). We illustrate with some sample rules from the grammar of the Collins English-German dictionary. (1) body ==&gt; opt(prehom) : opt(homlist(*)). (2) body ==&gt; alt. (3) prehom ==&gt; opt(alt) : opt(pronunc) : opt(vbmorph) : opt(note) : opt(abb). (4) homlist(num) ==&gt; hom(num) : opt(opt(-sc) : homlist(num)). (5) homlist(nonum) ==&gt; hom(nonum). Rule (1) says that the body of an entry consists of optional prehomograph material (prehom) and an optional homograph list of any type(*). A significant addition to the MLG formalism was a mechanism for treatment of large numbers of optional elements in a single ru</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, Fernando, and David Warren (1980) &amp;quot;Definite clause grammars for language analysis - a survey of the formalism and a comparison with augmented transition networks&amp;quot;, Artificial Intelligence, 13, 231-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Tompa</author>
</authors>
<title>Database design for a dictionary of the future,&amp;quot;</title>
<date>1986</date>
<institution>University of Waterloo, unpublished.</institution>
<contexts>
<context position="2675" citStr="Tompa (1986" startWordPosition="405" endWordPosition="406">itation is usually via a special extraction program which gets only the information needed by the project or application. Although in some cases the literature mentions the term &amp;quot;data base&amp;quot;, the term is frequently not used in any strict sense, as it is here. The work reported in the present paper is related to work reported by Calzolari ( I 984a, 1984b) and Calzolari and Picchi(1986). Some of it, particularly the development of tools and grammars for parsing entries in MRD tapes to LDB format, is most related in spirit to some of the work reported by the New Oxford English Dictionary project (Tompa (1986a), Gonnet and Tompa( 1986), Benbow(1986)). Whereas the new OED project has defined a markup language for dictionary entries before data entry and a grammar based on that markup language, this work attempts to parse and convert to a standard form a number of different raw type-setting tapes without any pre-editing. 2. Lexical Data Bases. Dictionary entries are typically organized as shallow hierarchies of information with a variable number of instances of certain items at each level, e.g. multiple homographs within an entry or multiple senses within a homograph. More formally, they can be char</context>
</contexts>
<marker>Tompa, 1986</marker>
<rawString>Tompa, Frank (1986) &amp;quot;Database design for a dictionary of the future,&amp;quot; University of Waterloo, unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Zampolli</author>
<author>Nicoletta Calzolari</author>
</authors>
<title>Computational Lexicography and Lexicology,&amp;quot;</title>
<date>1985</date>
<journal>AILA Bulletin,</journal>
<pages>59--78</pages>
<marker>Zampolli, Calzolari, 1985</marker>
<rawString>Zampolli, Antonio and Nicoletta Calzolari (1985) &amp;quot;Computational Lexicography and Lexicology,&amp;quot; AILA Bulletin, pp. 59-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe M Zloof</author>
</authors>
<title>Query by Example,&amp;quot;</title>
<date>1974</date>
<journal>IBM Research Report RC</journal>
<pages>4917</pages>
<marker>Zloof, 1974</marker>
<rawString>Zloof, Moshe M. (1974) &amp;quot;Query by Example,&amp;quot; IBM Research Report RC 4917.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>