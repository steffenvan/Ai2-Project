<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.081826">
<title confidence="0.991664">
Language Independent Named Entity Classification by modified
Transformation-based Learning and by Decision Tree Induction
</title>
<author confidence="0.996764">
William J. Black Argyrios Vasilakopoulos
</author>
<affiliation confidence="0.996453">
Department of Computation, UMIST Department of Computation, UMIST
</affiliation>
<address confidence="0.924891">
P.O. Box 88, Sackville Street P.O. Box 88, Sackville Street
Manchester M60 1QD, UK Manchester M60 1QD, UK
</address>
<email confidence="0.99697">
wjb@co.umist.ac.uk A.Vassilakopoulos@postgrad.umist.ac.uk
</email>
<sectionHeader confidence="0.995552" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933857142857">
We describe our last results at the CoNLL2002
shared task of Named Entity Recognition and
Classification using two approaches that we
first applied to other NLL problems. We have
been developing our own modified TBL learner
initially to tackle the Part-of-Speech tagging
problem, for integration in a hybrid NLL and
rule- based system for information extraction
(Ciravegna et al., 1999). After encouraging
results in applying decision tree induction to
the CoNLL2001 task of chunking, Jones (2002),
where we attained an overall F- measure of
92.90 at this task, we have applied the same
set-up to the NER task.
</bodyText>
<sectionHeader confidence="0.998485" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999741791666667">
Named Entity Classification (NEC) is the pro-
cess of identifying and classifying names in text
and is a crucial task for several natural lan-
guage processing areas such as information re-
trieval, information extraction, machine trans-
lation and language understanding. From 1995
when the NE task was first introduced as part of
the Message Understanding Conference (MUC-
6) most systems that have attempted this task
are based in lists of common names in order
to provide some clues. These lists are, in most
cases, very large and can provide an efficient
way of dealing with NEC but it is still a nave
method for recognizing names. About the size
of the lists, Krupke and Hausman (1998) found
that the good quality of a name list is quite more
important than its total size, while Mikheev et
al. (1999) concluded that small but well elab-
orated lists can be as effective as the larger
ones. Except from name lists many of the NEC
systems also use a number of other NLP tools
such as hand-crafted rules, morphological dis-
ambiguators, chunkers and parsers taking ad-
vantage of what McDonald (1996) defines as in-
ternal and external evidence in the NEC. While
many systems tend to recognize the names in
text very efficiently - Zhou and Su (2002) report
F-measures of 96.8% and 94.2% on the MUC6
and MUC7 datasets - most of them are designed
for specific domains and specific languages.
Our aim has been to build a language in-
dependent system for dealing with the NEC
task. We have attempted two different ap-
proaches using only the data provided for the
CoNLL2002 shared task of NEC. The first ap-
proach is based on the Transformation- Based
Learning method, a very efficient method which
has been successfully attempted for other NLP
tasks like PP-attachment disambiguation (Brill
and Resnik, 1994), part-of-speech tagging (Brill,
1995), text chunking (Ramshaw and Marcus,
1995), dialog act tagging (Samuel et al., 1988)
ellipsis resolution (Hardt, 1998) and spelling
correction (Magnu and Brill, 1997). Our sec-
ond approach is a simple decision tree induction
scheme. In the next two sections we describe
our approaches in more detail and in section 3
we present our results so far.
</bodyText>
<sectionHeader confidence="0.966476" genericHeader="method">
2 Modified TBL Approach
</sectionHeader>
<bodyText confidence="0.999947894736842">
The learner we used in our first experiment dif-
fers from Brill&apos;s TBL Learner (Brill, 1995) in
that it produces a set of transformation rules in
a single pass without basing each learning cycle
on a new initial state. We were motivated to do
this after noticing how little the revision stage
contributes to the final precision of the tag-
ger, having found that improved unknown- word
guessing contributes more than is lost by aban-
doning the multi-pass patch acquisition step.
The approach followed here consists of two
main stages for both the learner and the tagger:
(i) In the first stage we try just to recognize all
the named entities (NE&apos;s) in the training or test
data by taking into account only the orthogra-
phy feature of the NE&apos;s.
(ii) In the second stage we classify the NE&apos;s
found during the stage (i) by using a corpus
derived lexicon and contextual rules.
</bodyText>
<subsectionHeader confidence="0.984831">
2.1 Learning
</subsectionHeader>
<bodyText confidence="0.999899625">
The learning process consists of the induction
of two sets of rules and a lexicon. The first set
of rules is induced in the first stage and results
in a binary classification between the &apos;0&apos; of the
training corpus to &apos;NE&apos; which generalizes over
the remaining tags. This stage creates an ini-
tially annotated version of the text. An example
of a rule at this phase of analysis is:
</bodyText>
<construct confidence="0.738465">
Change tag 0 to NE of the current
word if the preceding and following
words are both Capitalized and the cur-
rent word is &amp;quot;de&amp;quot;
</construct>
<bodyText confidence="0.988102263157895">
which would result in the correction of
Rio/NE de/0 Janeiro/NE to Rio/NE de/NE
Janeiro/NE. In the second stage we firstly cre-
ate the lexicon from the training corpus in the
way that Brill does in (Brill, 1995). The lexicon
then is applied on the initially annotated text
and the result is the initial state for the TBL
algorithm. The initial state is afterwards com-
pared to the original training corpus, according
to a set of user defined templates and a second
set of transformation rules is induced. The dif-
ference with Brill&apos;s original TBL is that in our
case we keep all the rules which satisfy the ac-
curacy and score thresholds, instead of keeping
the best one and iterate the process until no
more rule is found. We finally rank these rules.
At this point it is essential to note that only
the word sequences tagged as &apos;NE&apos;s at the first
stage, are subject to stage (ii).
</bodyText>
<subsectionHeader confidence="0.964214">
2.2 Tagger
</subsectionHeader>
<bodyText confidence="0.999937">
For tagging an unknown corpus, we firstly cre-
ate the initial state of the corpus as described
in the previous section, and we then apply all
the ranked rules sequentially.
</bodyText>
<sectionHeader confidence="0.947854" genericHeader="method">
3 Decision Tree Induction
</sectionHeader>
<bodyText confidence="0.999766777777778">
As with our modified TBL approach, we use no
data outside of the training corpus for the deci-
sion tree experiment. We used an of-the- shelf
system (Weka&apos;s J4.8 variant of C4.5 - Weka 3
(2001)) for this experiment. The training data
is converted into a 49-attribute table, covering
12 attributes of the current token, its two prede-
cessors and its successor. There are 46 nominal
and 3 numeric features. These features are:
</bodyText>
<listItem confidence="0.995020545454545">
• The token itself if it is one of the 150 most
frequent tokens, otherwise `miskTok&apos;.
• The orthography. Each token can only
belong in one of the next 17 categories
which are distinguished via regular expres-
sions: { null, lowercase, capitalized, ca-
phyphenated, lowerhyphenated, uppercase,
multicap, upperdotted, initial, initialdot,
punct, doublequote, apostrophe, number,
numberrange, bracket, other } (Hopefully
most of these are self- evident in meaning)
• &apos;True&apos; if the token is a frequent word &apos;false&apos;
otherwise.
• &apos;True&apos; if the suffix of the token is a frequent
one &apos;false&apos; otherwise.
• The most frequent category in the training
data, or if not found in the training data
&apos;0&apos; for lowercase tokens and &apos;I-PER&apos; for all
the others.
• The total number of occurrences of the to-
ken in the training data.
• Six more features indicating &apos;True&apos; or
</listItem>
<bodyText confidence="0.964693">
&apos;False&apos; if the token appears as 13-`, &apos;I- &apos;,
&apos;PER&apos;, &apos;LOC&apos;, &apos;ORG&apos; and `MISC&apos; some-
where in the training data.
The decision tree induced from the training
data by using these attributes is then used in
order to predict the NE class of the unknown
words of the test corpus. Finally, a filter is
applied to the result, aiming at removing any
discrepancies which refer to the patterns of the
NE sequences. So, this filter corrects the follow-
ing mistakes: a) it changes the following label
sequence from &amp;quot;&lt;B-X&gt; &lt;B-X&gt; ...&amp;quot; to &amp;quot;&lt;B-
X&gt; &lt;I-X&gt;...&amp;quot; and b) it changes the following
label sequence from &amp;quot;&lt;B-X&gt; or &lt;I-X&gt; &lt;I-Y&gt;
&lt;I-X&gt;...&amp;quot; to &amp;quot;&lt;B-X&gt; or &lt;I-X&gt; &lt;I-X&gt; &lt;I-
X&gt;...&amp;quot; if &lt;I-Y&gt; is the classification label of
a functional word. In the above, the X and Y
variables can take one of the following values:
LOC, PER, ORG, MISC.
</bodyText>
<sectionHeader confidence="0.999507" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999969545454545">
We have tested only our modified TBL approach
with all the data available from the CoNLL2002.
Especially, for the Dutch data we used only the
NE tags of the tokens of the training corpus,
as we did for the Spanish data. In the case of
the decision tree induction, having spent most
of our time on the data conversion and prepara-
tion, we have only conducted a run only for the
Spanish data by using only the first 100,000 to-
kens of the training corpus. The overall results
are as shown in the Tables 1, 2, 3 and 4.
</bodyText>
<table confidence="0.999070833333333">
Spanish train Precision Recall F0-1
LOC 87.47% 69.99% 77.76
MISC 80.39% 55.41% 65.60
ORG 74.51% 84.83% 79.34
PER 94.63% 93.18% 93.90
Overall 82.65% 79.02% 80.79
</table>
<tableCaption confidence="0.9274165">
Table 1: NER task results from the modified
TBL approach on the Spanish training data.
</tableCaption>
<table confidence="0.999847">
Dutch train Precision Recall F0-1
LOC 94.10% 84.99% 89.31
MISC 82.57% 72.04% 76.95
ORG 86.08% 34.94% 49.70
PER 93.98% 90.75% 92.34
Overall 90.44% 75.59% 82.35
</table>
<tableCaption confidence="0.8668425">
Table 2: NER task results from the modified
TBL approach on the Dutch training data.
</tableCaption>
<sectionHeader confidence="0.977823" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999810933333333">
This paper has presented two different ap-
proaches for solving the named entity classifica-
tion task using supervised learning. Our target
has been to use the least resources for creat-
ing our rules, for the modified Transformation-
Based approach, and inducing our decision tree
for the Decision Tree Induction approach. So
far, it seems that the modified TBL approach
gives better results on Spanish data than our
second approach. After developing our modi-
fied TBL learner using the Spanish data and
trained them using both the Spanish and the
Dutch training corpora we observed the fact
that our approach works better with the Span-
ish test texts. Our both systems seem to per-
</bodyText>
<table confidence="0.999592666666667">
Spanish train Precision Recall F0-1
LOC 74.61% 76.82% 75.70
MISC 78.60% 56.96% 66.05
ORG 86.81% 70.39% 77.74
PER 80.57% 77.90% 79.21
Overall 81.03% 71.52% 75.98
Spanish dev. Precision Recall F0-1
LOC 58.48% 71.54% 64.35
MISC 52.95% 31.79% 39.73
ORG 74.20% 49.09% 59.09
PER 60.06% 76.11% 67.14
Overall 63.18% 58.21% 60.60
Spanish test Precision Recall F0-1
LOC 63.04% 60.04% 61.50
MISC 48.85% 31.36% 38.20
ORG 73.15% 58.04% 64.72
PER 60.11% 79.93% 68.62
overall 64.31% 59.87% 62.01
</table>
<tableCaption confidence="0.944563">
Table 3: NER task results from the Decision
Tree Induction on Spanish data.
</tableCaption>
<bodyText confidence="0.999546888888889">
form better on &apos;persons&apos; regarding the recall,
while the precision values look better for the &apos;lo-
cations&apos; and the &apos;organizations&apos;. Our best result
is an F-measure value of 68.21. This is not high
enough but the result is encouraging if we take
into consideration that both our approaches are
very simple and they do not make use of any
extended resource except from the information
contained in the training text.
</bodyText>
<sectionHeader confidence="0.997547" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99701784">
Weka 3. 2001. Machine learning software in java
2001. http://www.cs.waikato.ac.nz/ml/weka.
E. Brill and P. Resnik. 1994. A transformation-
based approach to prepositional phrase attach-
ment. In Proceedings of COLING&apos;94. Kyoto,
Japan.
E. Brill. 1995. Error-driven learning and natural
language processing: A case study in part of
speech tagging. Computational Linguistics, De-
cember 1995.
F. Ciravegna, A. Lavelli, M. Mana, L. Gilardoni,
S. Mazza, M. Ferraro, J. Matiasek, W. J. Black,
F. Rinaldi, and D. Mowatt. 1999. Facile: Classi-
fying texts integrating pattern matching and in-
formation extraction. In Proceedings of IJCAI99.
Stockholm, Sweden.
D. Hardt. 1998. Improving ellipsis resolution with
transformation-based learning. AAAI Fall Sym-
posium 1998.
D. Jones. 2002. Machine Learning for Natural Lan-
guage Analysis.
G Krupke and K. Hausman. 1998. Isoquest inc: de-
scription of the netowl(tm) extractor system as
used for muc-7. In Message Understanding Con-
ference Proceedings: MUC 7.
L. Magnu and E. Brill. 1997. Automatic rule ac-
quisition for spelling correction. In Proceedings of
The Fourteenth International Conference on Ma-
chine Learning ICML&apos;97. Morgan Kaufmann.
D McDonald. 1996. Internal and external evidence
in the identification and semantic categorization
of proper names. In Corpus Processing for Lexical
Acquisition, pages 21-39. MIT Press, Cambridge,
MA. ch. 2.
A. Mikheev, M. Moens, and C Grover. 1999. Named
entity recognition without gazetteers. In Pro-
ceedings of the ninth Conference of the Euro-
pean Chapter of the Association for Computa-
tional Linguistics, pages 1-8.
L. A. Ramshaw and M. P. Marcus. 1995. Text
chunking using transformation-based learning. In
Proceedings of the ACL Third Workshop on Very
Large Corpora, June 1995.
K. Samuel, S. Carberry, and K. Vijay-Shanker.
1988. Dialog act tagging with transformation-
based learning. In Proceedings of COL-
ING/ACL&apos;98.
G. Zhou and J. Su. 2002. Named entity
recognition using an hmm-based chunk tagger.
http://citeseer.nj.nec.com/zhou02named.html.
</reference>
<table confidence="0.994485958333334">
Spanish dev. Precision Recall F0-1
LOC 67.54% 64.42% 65.94
MISC 63.16% 38.22% 47.62
ORG 73.29% 60.76% 66.44
PER 70.65% 90.10% 79.20
Overall 70.34% 66.20% 68.21
Spanish test Precision Recall F0-1
LOC 76.78% 54.22% 63.56
MISC 61.78% 30.13% 40.51
ORG 68.40% 71.57% 69.95
PER 66.74% 92.48% 77.53
overall 68.78% 66.24% 67.49
Dutch devel. Precision Recall F0-1
LOC 76.41% 40.26% 52.73
MISC 71.59% 39.58% 50.98
ORG 84.51% 17.98% 29.65
PER 50.13% 87.81% 63.82
Overall 58.88% 48.35% 53.10
Dutch test Precision Recall F0-1
LOC 76.02% 54.51% 63.49
MISC 70.61% 37.19% 48.72
ORG 76.79% 18.09% 29.28
PER 55.43% 87.60% 67.90
Overall 62.12% 51.69% 56.43
</table>
<tableCaption confidence="0.9615565">
Table 4: NER task results from the modified
TBL approach on Spanish and Dutch data sets.
</tableCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902356">
<title confidence="0.9995015">Language Independent Named Entity Classification by modified Transformation-based Learning and by Decision Tree Induction</title>
<author confidence="0.999856">William J Black Argyrios Vasilakopoulos</author>
<affiliation confidence="0.985012">Department of Computation, UMIST Department of Computation, UMIST</affiliation>
<address confidence="0.9860065">P.O. Box 88, Sackville Street P.O. Box 88, Sackville Street Manchester M60 1QD, UK Manchester M60 1QD, UK</address>
<email confidence="0.97236">wjb@co.umist.ac.ukA.Vassilakopoulos@postgrad.umist.ac.uk</email>
<abstract confidence="0.997847533333333">We describe our last results at the CoNLL2002 shared task of Named Entity Recognition and Classification using two approaches that we first applied to other NLL problems. We have been developing our own modified TBL learner initially to tackle the Part-of-Speech tagging problem, for integration in a hybrid NLL and rulebased system for information extraction (Ciravegna et al., 1999). After encouraging results in applying decision tree induction to the CoNLL2001 task of chunking, Jones (2002), where we attained an overall Fmeasure of 92.90 at this task, we have applied the same set-up to the NER task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Weka</author>
</authors>
<title>Machine learning software in java</title>
<date>2001</date>
<note>http://www.cs.waikato.ac.nz/ml/weka.</note>
<marker>Weka, 2001</marker>
<rawString>Weka 3. 2001. Machine learning software in java 2001. http://www.cs.waikato.ac.nz/ml/weka.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>P Resnik</author>
</authors>
<title>A transformationbased approach to prepositional phrase attachment.</title>
<date>1994</date>
<booktitle>In Proceedings of COLING&apos;94. Kyoto,</booktitle>
<contexts>
<context position="2815" citStr="Brill and Resnik, 1994" startWordPosition="451" endWordPosition="454">nd to recognize the names in text very efficiently - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycl</context>
</contexts>
<marker>Brill, Resnik, 1994</marker>
<rawString>E. Brill and P. Resnik. 1994. A transformationbased approach to prepositional phrase attachment. In Proceedings of COLING&apos;94. Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics,</title>
<date>1995</date>
<contexts>
<context position="2853" citStr="Brill, 1995" startWordPosition="457" endWordPosition="458">y - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycle on a new initial state. We were moti</context>
<context position="4818" citStr="Brill, 1995" startWordPosition="804" endWordPosition="805">les is induced in the first stage and results in a binary classification between the &apos;0&apos; of the training corpus to &apos;NE&apos; which generalizes over the remaining tags. This stage creates an initially annotated version of the text. An example of a rule at this phase of analysis is: Change tag 0 to NE of the current word if the preceding and following words are both Capitalized and the current word is &amp;quot;de&amp;quot; which would result in the correction of Rio/NE de/0 Janeiro/NE to Rio/NE de/NE Janeiro/NE. In the second stage we firstly create the lexicon from the training corpus in the way that Brill does in (Brill, 1995). The lexicon then is applied on the initially annotated text and the result is the initial state for the TBL algorithm. The initial state is afterwards compared to the original training corpus, according to a set of user defined templates and a second set of transformation rules is induced. The difference with Brill&apos;s original TBL is that in our case we keep all the rules which satisfy the accuracy and score thresholds, instead of keeping the best one and iterate the process until no more rule is found. We finally rank these rules. At this point it is essential to note that only the word sequ</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics, December 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ciravegna</author>
<author>A Lavelli</author>
<author>M Mana</author>
<author>L Gilardoni</author>
<author>S Mazza</author>
<author>M Ferraro</author>
<author>J Matiasek</author>
<author>W J Black</author>
<author>F Rinaldi</author>
<author>D Mowatt</author>
</authors>
<title>Facile: Classifying texts integrating pattern matching and information extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of IJCAI99.</booktitle>
<location>Stockholm,</location>
<contexts>
<context position="788" citStr="Ciravegna et al., 1999" startWordPosition="104" endWordPosition="107">partment of Computation, UMIST Department of Computation, UMIST P.O. Box 88, Sackville Street P.O. Box 88, Sackville Street Manchester M60 1QD, UK Manchester M60 1QD, UK wjb@co.umist.ac.uk A.Vassilakopoulos@postgrad.umist.ac.uk Abstract We describe our last results at the CoNLL2002 shared task of Named Entity Recognition and Classification using two approaches that we first applied to other NLL problems. We have been developing our own modified TBL learner initially to tackle the Part-of-Speech tagging problem, for integration in a hybrid NLL and rule- based system for information extraction (Ciravegna et al., 1999). After encouraging results in applying decision tree induction to the CoNLL2001 task of chunking, Jones (2002), where we attained an overall F- measure of 92.90 at this task, we have applied the same set-up to the NER task. 1 Introduction Named Entity Classification (NEC) is the process of identifying and classifying names in text and is a crucial task for several natural language processing areas such as information retrieval, information extraction, machine translation and language understanding. From 1995 when the NE task was first introduced as part of the Message Understanding Conference</context>
</contexts>
<marker>Ciravegna, Lavelli, Mana, Gilardoni, Mazza, Ferraro, Matiasek, Black, Rinaldi, Mowatt, 1999</marker>
<rawString>F. Ciravegna, A. Lavelli, M. Mana, L. Gilardoni, S. Mazza, M. Ferraro, J. Matiasek, W. J. Black, F. Rinaldi, and D. Mowatt. 1999. Facile: Classifying texts integrating pattern matching and information extraction. In Proceedings of IJCAI99. Stockholm, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hardt</author>
</authors>
<title>Improving ellipsis resolution with transformation-based learning. AAAI Fall Symposium</title>
<date>1998</date>
<contexts>
<context position="2971" citStr="Hardt, 1998" startWordPosition="474" endWordPosition="475">for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycle on a new initial state. We were motivated to do this after noticing how little the revision stage contributes to the final precision of the tagger, having</context>
</contexts>
<marker>Hardt, 1998</marker>
<rawString>D. Hardt. 1998. Improving ellipsis resolution with transformation-based learning. AAAI Fall Symposium 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jones</author>
</authors>
<title>Machine Learning for Natural Language Analysis.</title>
<date>2002</date>
<contexts>
<context position="899" citStr="Jones (2002)" startWordPosition="122" endWordPosition="123">t Manchester M60 1QD, UK Manchester M60 1QD, UK wjb@co.umist.ac.uk A.Vassilakopoulos@postgrad.umist.ac.uk Abstract We describe our last results at the CoNLL2002 shared task of Named Entity Recognition and Classification using two approaches that we first applied to other NLL problems. We have been developing our own modified TBL learner initially to tackle the Part-of-Speech tagging problem, for integration in a hybrid NLL and rule- based system for information extraction (Ciravegna et al., 1999). After encouraging results in applying decision tree induction to the CoNLL2001 task of chunking, Jones (2002), where we attained an overall F- measure of 92.90 at this task, we have applied the same set-up to the NER task. 1 Introduction Named Entity Classification (NEC) is the process of identifying and classifying names in text and is a crucial task for several natural language processing areas such as information retrieval, information extraction, machine translation and language understanding. From 1995 when the NE task was first introduced as part of the Message Understanding Conference (MUC6) most systems that have attempted this task are based in lists of common names in order to provide some </context>
</contexts>
<marker>Jones, 2002</marker>
<rawString>D. Jones. 2002. Machine Learning for Natural Language Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Krupke</author>
<author>K Hausman</author>
</authors>
<title>Isoquest inc: description of the netowl(tm) extractor system as used for muc-7.</title>
<date>1998</date>
<booktitle>In Message Understanding Conference Proceedings: MUC 7.</booktitle>
<contexts>
<context position="1709" citStr="Krupke and Hausman (1998)" startWordPosition="260" endWordPosition="263">tifying and classifying names in text and is a crucial task for several natural language processing areas such as information retrieval, information extraction, machine translation and language understanding. From 1995 when the NE task was first introduced as part of the Message Understanding Conference (MUC6) most systems that have attempted this task are based in lists of common names in order to provide some clues. These lists are, in most cases, very large and can provide an efficient way of dealing with NEC but it is still a nave method for recognizing names. About the size of the lists, Krupke and Hausman (1998) found that the good quality of a name list is quite more important than its total size, while Mikheev et al. (1999) concluded that small but well elaborated lists can be as effective as the larger ones. Except from name lists many of the NEC systems also use a number of other NLP tools such as hand-crafted rules, morphological disambiguators, chunkers and parsers taking advantage of what McDonald (1996) defines as internal and external evidence in the NEC. While many systems tend to recognize the names in text very efficiently - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the M</context>
</contexts>
<marker>Krupke, Hausman, 1998</marker>
<rawString>G Krupke and K. Hausman. 1998. Isoquest inc: description of the netowl(tm) extractor system as used for muc-7. In Message Understanding Conference Proceedings: MUC 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Magnu</author>
<author>E Brill</author>
</authors>
<title>Automatic rule acquisition for spelling correction.</title>
<date>1997</date>
<booktitle>In Proceedings of The Fourteenth International Conference on Machine Learning ICML&apos;97.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3019" citStr="Magnu and Brill, 1997" startWordPosition="479" endWordPosition="482">uages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycle on a new initial state. We were motivated to do this after noticing how little the revision stage contributes to the final precision of the tagger, having found that improved unknown- word guessing cont</context>
</contexts>
<marker>Magnu, Brill, 1997</marker>
<rawString>L. Magnu and E. Brill. 1997. Automatic rule acquisition for spelling correction. In Proceedings of The Fourteenth International Conference on Machine Learning ICML&apos;97. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McDonald</author>
</authors>
<title>Internal and external evidence in the identification and semantic categorization of proper names.</title>
<date>1996</date>
<booktitle>In Corpus Processing for Lexical Acquisition,</booktitle>
<pages>21--39</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<note>ch. 2.</note>
<contexts>
<context position="2116" citStr="McDonald (1996)" startWordPosition="334" endWordPosition="335">ues. These lists are, in most cases, very large and can provide an efficient way of dealing with NEC but it is still a nave method for recognizing names. About the size of the lists, Krupke and Hausman (1998) found that the good quality of a name list is quite more important than its total size, while Mikheev et al. (1999) concluded that small but well elaborated lists can be as effective as the larger ones. Except from name lists many of the NEC systems also use a number of other NLP tools such as hand-crafted rules, morphological disambiguators, chunkers and parsers taking advantage of what McDonald (1996) defines as internal and external evidence in the NEC. While many systems tend to recognize the names in text very efficiently - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been su</context>
</contexts>
<marker>McDonald, 1996</marker>
<rawString>D McDonald. 1996. Internal and external evidence in the identification and semantic categorization of proper names. In Corpus Processing for Lexical Acquisition, pages 21-39. MIT Press, Cambridge, MA. ch. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mikheev</author>
<author>M Moens</author>
<author>C Grover</author>
</authors>
<title>Named entity recognition without gazetteers.</title>
<date>1999</date>
<booktitle>In Proceedings of the ninth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="1825" citStr="Mikheev et al. (1999)" startWordPosition="282" endWordPosition="285">ation retrieval, information extraction, machine translation and language understanding. From 1995 when the NE task was first introduced as part of the Message Understanding Conference (MUC6) most systems that have attempted this task are based in lists of common names in order to provide some clues. These lists are, in most cases, very large and can provide an efficient way of dealing with NEC but it is still a nave method for recognizing names. About the size of the lists, Krupke and Hausman (1998) found that the good quality of a name list is quite more important than its total size, while Mikheev et al. (1999) concluded that small but well elaborated lists can be as effective as the larger ones. Except from name lists many of the NEC systems also use a number of other NLP tools such as hand-crafted rules, morphological disambiguators, chunkers and parsers taking advantage of what McDonald (1996) defines as internal and external evidence in the NEC. While many systems tend to recognize the names in text very efficiently - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to b</context>
</contexts>
<marker>Mikheev, Moens, Grover, 1999</marker>
<rawString>A. Mikheev, M. Moens, and C Grover. 1999. Named entity recognition without gazetteers. In Proceedings of the ninth Conference of the European Chapter of the Association for Computational Linguistics, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACL Third Workshop on Very Large Corpora,</booktitle>
<contexts>
<context position="2895" citStr="Ramshaw and Marcus, 1995" startWordPosition="461" endWordPosition="464"> F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycle on a new initial state. We were motivated to do this after noticing how little</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. P. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the ACL Third Workshop on Very Large Corpora, June 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Samuel</author>
<author>S Carberry</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Dialog act tagging with transformationbased learning.</title>
<date>1988</date>
<booktitle>In Proceedings of COLING/ACL&apos;98.</booktitle>
<contexts>
<context position="2937" citStr="Samuel et al., 1988" startWordPosition="468" endWordPosition="471">MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chunking (Ramshaw and Marcus, 1995), dialog act tagging (Samuel et al., 1988) ellipsis resolution (Hardt, 1998) and spelling correction (Magnu and Brill, 1997). Our second approach is a simple decision tree induction scheme. In the next two sections we describe our approaches in more detail and in section 3 we present our results so far. 2 Modified TBL Approach The learner we used in our first experiment differs from Brill&apos;s TBL Learner (Brill, 1995) in that it produces a set of transformation rules in a single pass without basing each learning cycle on a new initial state. We were motivated to do this after noticing how little the revision stage contributes to the fin</context>
</contexts>
<marker>Samuel, Carberry, Vijay-Shanker, 1988</marker>
<rawString>K. Samuel, S. Carberry, and K. Vijay-Shanker. 1988. Dialog act tagging with transformationbased learning. In Proceedings of COLING/ACL&apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>J Su</author>
</authors>
<title>Named entity recognition using an hmm-based chunk tagger.</title>
<date>2002</date>
<note>http://citeseer.nj.nec.com/zhou02named.html.</note>
<contexts>
<context position="2263" citStr="Zhou and Su (2002)" startWordPosition="359" endWordPosition="362">ng names. About the size of the lists, Krupke and Hausman (1998) found that the good quality of a name list is quite more important than its total size, while Mikheev et al. (1999) concluded that small but well elaborated lists can be as effective as the larger ones. Except from name lists many of the NEC systems also use a number of other NLP tools such as hand-crafted rules, morphological disambiguators, chunkers and parsers taking advantage of what McDonald (1996) defines as internal and external evidence in the NEC. While many systems tend to recognize the names in text very efficiently - Zhou and Su (2002) report F-measures of 96.8% and 94.2% on the MUC6 and MUC7 datasets - most of them are designed for specific domains and specific languages. Our aim has been to build a language independent system for dealing with the NEC task. We have attempted two different approaches using only the data provided for the CoNLL2002 shared task of NEC. The first approach is based on the Transformation- Based Learning method, a very efficient method which has been successfully attempted for other NLP tasks like PP-attachment disambiguation (Brill and Resnik, 1994), part-of-speech tagging (Brill, 1995), text chu</context>
</contexts>
<marker>Zhou, Su, 2002</marker>
<rawString>G. Zhou and J. Su. 2002. Named entity recognition using an hmm-based chunk tagger. http://citeseer.nj.nec.com/zhou02named.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>