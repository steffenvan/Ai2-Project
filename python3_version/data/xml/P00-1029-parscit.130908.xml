<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001821">
<title confidence="0.9958745">
Inducing Probabilistic Syllable Classes
Using Multivariate Clustering
</title>
<author confidence="0.998674">
Karin Müller, Bernd Möbius, and Detlef Prescher
</author>
<affiliation confidence="0.987831">
Institut fur Maschinelle Sprachverarbeitung
University of Stuttgart, Germany
</affiliation>
<email confidence="0.997789">
{karin.muellerlbernd.moebiusldetlef.prescher}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.982096" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999841666666667">
An approach to automatic detection
of syllable structure is presented. We
demonstrate a novel application of
EM-based clustering to multivariate
data, exemplified by the induction
of 3- and 5-dimensional probabilis-
tic syllable classes. The qualitative
evaluation shows that the method
yields phonologically meaningful syl-
lable classes. We then propose a
novel approach to grapheme-to-pho-
neme conversion and show that syl-
lable structure represents valuable
information for pronunciation sys-
tems.
</bodyText>
<sectionHeader confidence="0.996328" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999763649122807">
In this paper we present an approach to un-
supervised learning and automatic detection
of syllable structure. The primary goal of
the paper is to demonstrate the application
of EM-based clustering to multivariate data.
The suitability of this approach is exemplified
by the induction of 3- and 5-dimensional prob-
abilistic syllable classes. A secondary goal is
to outline a novel approach to the conversion
of graphemes to phonemes (g2p) which uses a
context-free grammar (cfg) to generate all se-
quences of phonemes corresponding to a given
orthographic input word and then ranks the
hypotheses according to the probabilistic in-
formation coded in the syllable classes.
Our approach builds on two resources. The
first resource is a cfg for g2p conversion that
was constructed manually by a linguistic ex-
pert (Müller, 2000). The grammar describes
how words are composed of syllables and how
syllables consist of parts that are convention-
ally called onset, nucleus and coda, which in
turn are composed of phonemes, and corre-
sponding graphemes. The second resource
consists of a multivariate clustering algorithm
that is used to reveal syllable structure hid-
den in unannotated training data. In a first
step, we collect syllables by going through a
large text corpus, looking up the words and
their syllabifications in a pronunciation dictio-
nary and counting the occurrence frequencies
of the syllable types. Probabilistic syllable
classes are then computed by applying max-
imum likelihood estimation from incomplete
data via the EM algorithm. Two-dimensional
EM-based clustering has been applied to tasks
in syntax (Rooth et al., 1999), but so far this
approach has not been used to derive models
of higher dimensionality and, to the best of
our knowledge, this is the first time that it
is being applied to speech. Accordingly, we
have trained 3- and 5-dimensional models for
English and German syllable structure.
The obtained models of syllable struc-
ture were evaluated in three ways. Firstly,
the 3-dimensional models were subjected to
a pseudo-disambiguation task, the result of
which shows that the onset is the most vari-
able part of the syllable. Secondly, the re-
sulting syllable classes were qualitatively eval-
uated from a phonological and phonotactic
point of view. Thirdly, a 5-dimensional syl-
lable model for German was tested in a g2p
conversion task. The results compare well
with the best currently available data-driven
approaches to g2p conversion (e.g., (Damper
et al., 1999)) and suggest that syllable struc-
</bodyText>
<table confidence="0.490558142857143">
class 0 0.212 NOP[I] 0.282 I 0.999 NOP[I] 0.460
t 0.107 n 0.121
l 0.074 N 0.096
d 0.071 z 0.079
b 0.065 t 0.042
s 0.060 ts 0.013
f 0.012
</table>
<figureCaption confidence="0.924981">
Figure 1: Class #0 of a 3-dimensional English model with 12 classes
</figureCaption>
<bodyText confidence="0.8221752">
class 46 0.007 NOP[E] 0.630 E 0.990 nt 0.602 INI 0.627 STR 0.596
ts 0.256 t 0.128 FIN 0.331 USTR 0.403
d 0.074 n 0.092 MED 0.040
n 0.001 pt 0.010
ks 0.004
</bodyText>
<figureCaption confidence="0.950649">
Figure 2: Class #46 of a 5-dimensional German model with 50 classes
</figureCaption>
<equation confidence="0.998153090909091">
p(c)p(yIc)
p(c; y) = X
c2C
p(c)
Yd
i=1
p(y) = X
c2C
X
c2C
p(yiIc)
</equation>
<bodyText confidence="0.999988153846154">
ture represents valuable information for pro-
nunciation systems. Such systems are critical
components in text-to-speech (TTS) conver-
sion systems, and they are also increasingly
used to generate pronunciation variants in au-
tomatic speech recognition.
The rest of the paper is organized as fol-
lows. In Section 2 we introduce the multi-
variate clustering algorithm. In Section 3 we
present four experiments based on 3- and 5-
dimensional data for German and English.
Section 4 is dedicated to evaluation and in
Section 5 we discuss our results.
</bodyText>
<sectionHeader confidence="0.860623" genericHeader="method">
2 Multivariate Syllable Clustering
</sectionHeader>
<bodyText confidence="0.999934807692308">
EM-based clustering has been derived and ap-
plied to syntax (Rooth et al., 1999). Unfor-
tunately, this approach is not applicable to
multivariate data with more than two dimen-
sions. However, we consider syllables to con-
sist of at least three dimensions correspond-
ing to parts of the internal syllable structure:
onset, nucleus and coda. We have also experi-
mented with 5-dimensional models by adding
two more dimensions: position of the sylla-
ble in the word and stress status. In our
multivariate clustering approach, classes cor-
responding to syllables are viewed as hidden
data in the context of maximum likelihood es-
timation from incomplete data via the EM al-
gorithm. The two main tasks of EM-based
clustering are (i) the induction of a smooth
probability model on the data, and (ii) the
automatic discovery of class structure in the
data. Both aspects are considered in our ap-
plication. We aim to derive a probability
distribution p(y) on syllables y from a large
sample. The key idea is to view y as condi-
tioned on an unobserved class c 2 C, where
the classes are given no prior interpretation.
The probability of a syllable y = (y1; ::; yd) 2
</bodyText>
<equation confidence="0.590639">
Y1 x :: x Yd; d &gt; 3; is defined as:
</equation>
<bodyText confidence="0.957889956521739">
Note that conditioning of yi on each other is
solely made through the classes c via the in-
dependence assumption p(yIc) = Qdi=1 p(yiIc).
This assumption makes clustering feasible in
the first place; later on (in Section 4.1) we
will experimentally determine the number ICI
of classes such that the assumption is opti-
mally met. The EM algorithm (Dempster et
al., 1977) is directed at maximizing the incom-
plete data log-likelihood L = Py ~p(y) lnp(y)
as a function of the probability distribution
p for a given empirical probability distribu-
tion ~p. Our application is an instance of the
EM-algorithm for context-free models (Baum
et al., 1970), from which simple re-estimation
formulae can be derived. Let f(y) the fre-
quency of syllable y, and If I = Py2Y f(y)
the total frequency of the sample (i.e. ~p(y) =
f�y)
jfj ), and fc(y) = f(y)p(cIy) the estimated
frequency of y annotated with c. Parameter
updates ^p(c); ^p(yiIc) can thus be computed by
(c 2 C; yi 2 Yi; i = 1; ::; d):
</bodyText>
<equation confidence="0.982368">
Py2Y fc(y)
^p(c) =; and
</equation>
<sectionHeader confidence="0.460227" genericHeader="method">
If I
</sectionHeader>
<table confidence="0.992808285714285">
class 0 0.071 D 0.745 @ 1 ONE 0.999 STR 1
NOP[@] 0.166 NOP[@] 0.877
m 0.0792
class 1 0.049 NOP[I] 0.914 I 1 n 0.387 ONE 0.916 STR 1
h 0.071 z 0.360 INI 0.069
b 0.010 t 0.180
f 0.042
ts 0.02
class 3 0.040 t 0.206 I 0.993 0.466 FIN 0.997 USTR 0.999
s 0.106 N 0.167
d 0.104 d 0.152
NOP[I] 0.101 z 0.012
n 0.052 Nz
class 4 0.037 t 0.211 @ 0.978 r* 0.597 0.057 0.996 USTR 0.999
v 0.115 O: 0.009 z 0.115 FIN 0.003
D 0.102 d 0.054 MED
d 0.095 l 0.045
NOP[@] 0.072 n
class 10 0.028 S 0.257 @ 0.063 n 0.388 FIN 0.999 USTR 0.999
m 0.227 I 0.926 nt 0.191
d 0.059 I@ 0.031 nz 0.088
t 0.007 E 0.015 l 0.066
NOP[@] 0.005 nts 0.049
ns 0.048
class 14 0.026 m 0.116 pl 0.052 eI 0.426 0.165 0.162 ONE 0.696 STR 0.984
p 0.108 A: 0.140 t 0.131 FIN 0.276
k 0.090 E 0.110 s 0.088
g 0.088 O: n 0.079
t 0.080 d 0.079
st 0.051 k 0.052
nd 0.037
ts
class 17 0.023 NOP[@] 0.973 @ 1 ONE 0.944 STR 1
NOP[@] 0.325 INI 0.050
r* 0.317
</table>
<figureCaption confidence="0.996771">
Figure 3: Classes #0, #1, #3, #4, #10, #14, #17 of the 5-dimensional English model
</figureCaption>
<bodyText confidence="0.9999485">
As shown by Baum et al. (1970), every such
maximization step increases the log-likelihood
function L, and a sequence of re-estimates
eventually converges to a (local) maximum.
</bodyText>
<sectionHeader confidence="0.998409" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999919461538461">
A sample of syllables serves as input to the
multivariate clustering algorithm. The Ger-
man data were extracted from the Stuttgarter
Zeitung (STZ), a newspaper corpus of about
31 million words. The English data came from
the British National Corpus (BNC), a col-
lection of written and spoken language con-
taining about 100 million words. For both
languages, syllables were collected by going
through the corpus, looking up the words and
their syllabifications in a pronunciation dictio-
nary (Baayen et al., 1993)1 and counting the
occurrence frequencies of the syllable types�.
</bodyText>
<footnote confidence="0.686849142857143">
1We slightly modified the English pronunciation
lexicon to obtain non-empty nuclei, e.g. /ideal-
ism/ [aI][dI@][lIzm,] was modified to [aI][dI@][lI][z@m]
(SAMPA transcription).
2Subsequent experiments on syllable types (Müller
et al., 2000) have shown that frequency counts repre-
sent valuable information for our clustering task.
</footnote>
<bodyText confidence="0.999966321428571">
In two experiments, we induced 3-dimensional
models based on syllable onset, nucleus, and
coda. We collected 9327 distinct German syl-
lables and 13,598 distinct English syllables.
The number of syllable classes was system-
atically varied in iterated training runs and
ranged from 1 to 200.
Figure 1 shows a selected segment of class
#0 from a 3-dimensional English model with
12 classes. The first column displays the class
index 0 and the class probability p(0). The
most probable onsets and their probabilities
are listed in descending order in the second
column, as are nucleus and coda in the third
and fourth columns, respectively. Empty on-
sets and codas were labeled &amp;quot;NOP[nucleus]&amp;quot;.
Class #0 contains the highly frequent func-
tion words in, is, it, its as well as the suffixes
-ing ,-ting, -ling. Notice that these function
words and suffixes appear to be separated in
the 5-dimensional model (classes #1 and #3
in Figure 3).
In two further experiments, we induced 5-
dimensional models, augmented by the addi-
tional parameters of position of the syllable in
the word and stress status. Syllable position
has four values: monosyllabic (ONE), initial
(INI), medial (MED), and final (FIN). Stress
</bodyText>
<figure confidence="0.95529488">
�p(yijc) = Py2Y f�(y)
Py2Y1x..XYi-1xfyigxYi+1x..xYd f�(y)
95
90
85
80
75
70
65
60
onset
nucleus
coda
onset
nucleus
coda
90
85
80
75
70
65
55
0 20 40 60 80 100 120 140 160 180 200
0 20 40 60 80 100 120 140 160 180 200
</figure>
<figureCaption confidence="0.999993">
Figure 4: Evaluation on pseudo-disambiguation task for English (left) and German (right)
</figureCaption>
<bodyText confidence="0.999985">
has two values: stressed (STR) and unstressed
(USTR). We collected 16,595 distinct German
syllables and 24,365 distinct English syllables.
The number of syllable classes ranged from 1
to 200. Figure 2 illustrates (part of) class #46
from a 5-dimensional German model with 50
classes. Syllable position and stress are dis-
played in the last two columns.
</bodyText>
<sectionHeader confidence="0.996769" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999934833333333">
In the following sections, (i) the 3-dimen-
sional models are subjected to a pseudo-
disambiguation task (4.1); (ii) the syllable
classes are qualitatively evaluated (4.2); and
(iii) the 5-dimensional syllable model for Ger-
man is tested in a g2p task (4.3).
</bodyText>
<subsectionHeader confidence="0.993643">
4.1 Pseudo-Disambiguation
</subsectionHeader>
<bodyText confidence="0.999979789473684">
We evaluated our 3-dimensional cluster-
ing models on a pseudo-disambiguation
task similar to the one described by
Rooth et al. (1999), but specified to onset,
nucleus, and coda ambiguity. The first task
is to judge which of two onsets on and on&apos;
is more likely to appear in the context of a
given nucleus n and a given coda cod. For this
purpose, we constructed an evaluation cor-
pus of 3000 syllables (on, n, cod) selected from
the original data. Then, randomly chosen on-
sets on&apos; were attached to all syllables in the
evaluation corpus, with the resulting syllables
(on&apos;, n, cod) appearing neither in the training
nor in the evaluation corpus. Furthermore,
the elements on, n, cod, and on&apos; were required
to be part of the training corpus.
Clustering models were parameterized in
(up to 10) starting values of EM-training, in
the number of classes of the model (up to
200), resulting in a sequence of 10 x 20 mod-
els. Accuracy was calculated as the number
of times the model decided p(on, n, cod) &gt;
p(on&apos;, n, cod) for all choices made. Two simi-
lar tasks were designed for nucleus and coda.
Results for the best starting values are
shown in Figure 4. Models of 12 classes
show the highest accuracy rates. For German
we reached accuracy rates of 88-90% (nucleus
and coda) and 77% (onset). For English we
achieved accuracy rates of 92% (coda), 84%
(nucleus), and 76% (onset). The results of
the pseudo-disambiguation agree with intu-
ition: in both languages (i) the onset is the
most variable part of the syllable, as it is easy
to find minimal pairs that vary in the onset,
(ii) it is easier to predict the coda and nucleus,
as their choice is more restricted.
</bodyText>
<subsectionHeader confidence="0.977449">
4.2 Qualitative Evaluation
</subsectionHeader>
<bodyText confidence="0.998901714285714">
The following discussion is restricted to the 5-
dimensional syllable models, as the quality of
the output increased when more dimensions
were added. We can look at the results from
different angles. For instance, we can verify
if any of the classes are mainly representa-
tives of a syllable class pertinent to a par-
ticular nucleus (as it is the case with the 3-
dimensional models). Another interesting as-
pect is whether there are syllable classes that
represent parts of lexical content words, as op-
posed to high-frequency function words. Fi-
nally, some syllable classes may correspond to
productive affixes.
</bodyText>
<table confidence="0.9991584">
class 4 0.032 NOP[aI] 0.624 aI 1 NOP[aI] 0.689 INI 0.755 STR 0.999
z 0.163 n 0.303 ONE 0.226
k 0.043 nst 0.002
v 0.029 ns 0.001
fR 0.021
m 0.016
class 7 0.029 NOP[I] 0.730 I 1 n 0.533 ONE 0.867 STR 0.915
z 0.259 x 0.204 INI 0.128 USTR 0.084
st 0.150
nt 0.067
ns 0.007
m 0.003
class 26 0.017 f 0.573 E 0.987 R 0.983 INI 0.906 USTR 0.994
NOP[E] 0.351 o: 0.007 MED 0.093
ts 0.009 O 0.001
h 0.006
class 34 0.011 l 0.408 I 0.905 x 0.690 FIN 0.936 USTR 0.999
t 0.175 xt 0.108 MED 0.063
d 0.133 k 0.047
class 40 0.009 b 0.144 aI 0.999 NOP[aI] 0.706 MED 0.876 USTR 0.596
R 0.128 n 0.103 FIN 0.119 STR 0.403
t 0.119 x 0.077
v 0.095 ts 0.057
ts 0.090 s 0.016
gl 0.022 l 0.015
</table>
<figureCaption confidence="0.997941">
Figure 5: Classes #4, #7, #26, #34, #40 of the 5-dimensional German model
</figureCaption>
<bodyText confidence="0.999067109375">
German. The majority of syllable classes
obtained for German is dominated by one par-
ticular nucleus per syllable class. In 24 out of
50 classes the probability of the dominant nu-
cleus is greater than 99%, and in 9 cases it is
indeed 100%. The only syllable nuclei that do
not dominate any class are the front rounded
vowels /y:, Y, 2:, 9/, the front vowel /E:/ and
the diphthong /OY/, all of which are among
the least frequently occurring nuclei in the lex-
icon of German. Figure 5 depicts the classes
that will be discussed now.
Almost one third (28%) of the 50 classes
are representatives of high-frequency function
words. For example, class #7 is dominated by
the function words in, ich, ist, im, sind, sich,
all of which contain the short vowel /I/.
Another 32% of the 50 classes represents
syllables that are most likely to occur in ini-
tial, medial and final positions in the open
word classes of the lexicon, i.e. nouns, ad-
jectives, and verbs. Class #4 covers several
lexical entries involving the diphthong /aI/
mostly in stressed word-initial syllables. Class
#40 provides complimentary information, as
it also includes syllables containing /aI/, but
here mostly in word-medial position.
We also observe syllable classes that repre-
sent productive prefixes (e.g., ver-, er-, zer-,
vor-, her- in class #26) and suffixes (e.g.,
-lich, -ig in class #34). Finally, there are
two syllable classes (not displayed) that cover
the most common inflectional suffixes involv-
ing the vowel /@/ (schwa).
Class numbers are informative insofar as
the classes are ranked by decreasing proba-
bility. Lower-ranked classes tend (i) not to
be dominated by one nucleus; (ii) to contain
vowels with relatively low frequency of occur-
rence; and (iii) to yield less clear patterns in
terms of word class or stress or position. For
illustration, class #46 (Figure 2) represents
the syllable ent [Ent], both as a prefix (INI)
and as a suffix (FIN), the former being un-
stressed (as in Entwurf &amp;quot;design&amp;quot;) and the lat-
ter stressed (as in Dirigent &amp;quot;conductor&amp;quot;).
English. In 24 out of the 50 syllable classes
obtained for English one dominant nucleus per
syllable class is observed. In all of these cases
the probability of the nucleus is larger than
99% and in 7 classes the nucleus probability is
100%. Besides several diphthongs only the rel-
atively infrequent vowels /V/, /A:/ and /3:/
do not dominate any class. Figure 3 shows
the classes that are described as follows.
High-frequency function words are repre-
sented by 10 syllable classes. For example,
class #0 and #17 and are dominated by the
determiners the and a, respectively, and class
#1 contains function words that involve the
short vowel /I/, such as in, is, it, his, if, its.
Productive word-forming suffixes are found
in class #3 (-ing), and common inflectional
suffixes in class #4 (-er, -es, -ed). Class #10
</bodyText>
<figureCaption confidence="0.985619">
Figure 6: An incorrect (left) and a correct (right) cfg analysis of Lotzinn
</figureCaption>
<figure confidence="0.99902686">
Onset
Liquid
Syl
Nucleus
LVowel
Nucleus
LVowel
Syl
Coda
Nasal
Onset
Liquid
Syl
Nucleus
LVowel
Coda
Plosiv
Word
Onset
Affricate
Syl
Nucleus
SVowel
Coda
Nasal
Word
Coda
Affricate
phon=2:
grph=o
phon=ts
grph=t grph=z
phon=2:
grph=o
phon=ts
grph=z
phon=i:
grph=i
grph=n grph=n
phon=n
phon=I
phon=n
grph=i
grph=n grph=n
phon=l
grph=L
phon=l
grph=L
phon=t
grph=t
</figure>
<bodyText confidence="0.9755885">
is particularly interesting in that it represents
a comparably large number of common suf-
fixes, such as -tion, -ment, -al, -ant, -ent, -
ence and others.
The majority of syllable classes, viz. 31 out
of 50, contains syllables that are likely to be
found in initial, medial and final positions in
the open word classes of the lexicon. For ex-
ample, class #14 represents mostly stressed
syllables involving the vowels /eI, A:, e:, O:/
and others, in a variety of syllable positions in
nouns, adjectives or verbs.
</bodyText>
<subsectionHeader confidence="0.988623">
4.3 Evaluation by g2p Conversion
</subsectionHeader>
<bodyText confidence="0.998355827586207">
In this section, we present a novel method
of g2p conversion (i) using a cfg to produce
all possible phonemic correspondences of a
given grapheme string, (ii) applying a prob-
abilistic syllable model to rank the pronunci-
ation hypotheses, and (iii) predicting pronun-
ciation by choosing the most probable anal-
ysis. We used a cfg for generating transcrip-
tions, because grammars are expressive and
writing grammar-rules is easy and intuitive.
Our grammar describes how words are com-
posed of syllables and syllables branch into
onset, nucleus and coda. These syllable parts
are re-written by the grammar as sequences
of natural phone classes, e.g. stops, frica-
tives, nasals, liquids, as well as long and
short vowels, and diphthongs. The phone
classes are then re-interpreted as the individ-
ual phonemes that they are made up of. Fi-
nally, for each phoneme all possible graphemic
correspondences are listed.
Figure 6 illustrates two analyses (out of
100) of the German word Lotzinn (tin sol-
der). The phoneme strings (represented by
non-terminals named &amp;quot;phon...&amp;quot;) and the
syllable boundaries (represented by the non-
terminal &amp;quot;Syl&amp;quot;) can be extracted from these
analyses. Figure 6 depicts both an incor-
rect analysis [l2:ts][i:n] and its correct coun-
terpart [l2:t][tsIn]. The next step is to rank
these transcriptions by assigning probabilities
to them. The key idea is to take the prod-
uct of the syllable probabilities. Using the 5-
dimensional3 German syllable model yields a
probability of 7.5.10-7 .3.1.10-7 = 2.3.10-13
for the incorrect analysis and a probability of
1.5.10-7 .6.5.10-6 = 9.8.10-13 for the correct
one. Thus we achieve the desired result of as-
signing the higher probability to the correct
transcription.
We evaluated our g2p system on a test set
of 1835 unseen words. The ambiguity ex-
pressed as the average number of analyses per
word was 289. The test set was constructed
by collecting 295,102 words from the German
Celex dictionary (Baayen et al., 1993) that
were not seen in the STZ corpus. From this
set we manually eliminated (i) foreign words,
(ii) acronyms, (iii) proper names, (iv) verbs,
and (v) words with more than three syllables.
The resulting test set is available on the World
Wide Web4.
Figure 7 shows the performance of four g2p
systems. The second and fourth columns show
the accuracy of two baseline systems: g2p con-
version using the 3- and 5-dimensional em-
pirical distributions (Section 2), respectively.
The third and fifth columns show the word
</bodyText>
<footnote confidence="0.99950375">
3Position can be derived from the cfg analyses,
stress placement is controlled by the most likely dis-
tribution.
4http://www.ims.uni-stuttgart.de/phonetik/g2p/
</footnote>
<note confidence="0.7486855">
g2p system 3-dim baseline 3-dim classes 5-dim baseline 5-dim classes
word accuracy 66.8 % 67.4 % 72.5 % 75.3 %
</note>
<figureCaption confidence="0.999851">
Figure 7: Evaluation of g2p systems using probabilistic syllable models
</figureCaption>
<bodyText confidence="0.99992125">
accuracy of two g2p systems using 3- and 5-
dimensional syllable models, respectively.
The g2p system using 5-dimensional sylla-
ble models achieved the highest performance
(75.3%), which is a gain of 3% over the per-
formance of the 5-dimensional baseline system
and a gain of 8% over the performance of the
3-dimensional models5.
</bodyText>
<sectionHeader confidence="0.999179" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99933857936508">
We have presented an approach to unsuper-
vised learning and automatic detection of syl-
lable structure, using EM-based multivariate
clustering. The method yields phonologically
meaningful syllable classes. These classes are
shown to represent valuable input information
in a g2p conversion task.
In contrast to the application of two-
dimensional EM-based clustering to syntax
(Rooth et al., 1999), where semantic rela-
tions were revealed between verbs and objects,
the syllable models cannot a priori be ex-
pected to yield similarly meaningful proper-
ties. This is because the syllable constituents
(or phones) represent an inventory with a
small number of units which can be combined
to form meaningful larger units, viz. mor-
phemes and words, but which do not them-
selves carry meaning. Thus, there is no reason
why certain syllable types should occur signif-
icantly more often than others, except for the
fact that certain morphemes and words have a
higher frequency count than others in a given
text corpus. As discussed in Section 4.2, how-
ever, we do find some interesting properties
of syllable classes, some of which apparently
represent high-frequency function words and
productive affixes, while others are typically
found in lexical content words. Subjected to
545 resp. 95 words could not be disambiguated
by the 3- resp. 5-dimensional empirical distributions.
The reported relatively small gains can be explained
by the fact that our syllable models were applied only
to this small number of ambiguous words.
a pseudo-disambiguation task (Section 4.1),
the 3-dimensional models confirm the intu-
ition that the onset is the most variable part
of the syllable.
In a feasibility study we applied the 5-
dimensional syllable model obtained for Ger-
man to a g2p conversion task. Automatic
conversion of a string of characters, i.e. a
word, into a string of phonemes, i.e. its pro-
nunciation, is essential for applications such
as speech synthesis from unrestricted text in-
put, which can be expected to contain words
that are not in the system&apos;s pronunciation
dictionary or otherwise unknown to the sys-
tem. The main purpose of the feasibility
study was to demonstrate the relevance of the
phonological information on syllable structure
for g2p conversion. Therefore, information
and probabilities derived from an alignment
of grapheme and phoneme strings, i.e. the
lowest two levels in the trees displayed in Fig-
ure 6, was deliberately ignored. Data-driven
pronunciation systems usually rely on training
data that include an alignment of graphemes
and phonemes. Damper et al. (1999) have
shown that the use of unaligned training data
significantly reduces the performance of g2p
systems. In our experiment, with training
on unannotated text corpora and without an
alignment of graphemes and phonemes, we ob-
tained a word accuracy rate of 75.3% for the
5-dimensional German syllable model.
Comparison of this performance with other
systems is difficult: (i) hardly any quantita-
tive g2p performance data are available for
German; (ii) comparisons across languages are
hard to interpret; (iii) comparisons across dif-
ferent approaches require cautious interpreta-
tions. The most direct point of comparison
is the method presented by Müller (2000). In
one of her experiments, the standard prob-
ability model was applied to the hand-crafted
cfg presented in this paper, yielding 42% word
accuracy as evaluated on our test set. Run-
ning the test set through the pronunciation
rule system of the IMS German Festival TTS
system (Mohler, 1999) resulted in 55% word
accuracy. The Bell Labs German TTS sys-
tem (Möbius, 1999) performed at better than
94% word accuracy on our test set. This TTS
system relies on an annotation of morpho-
logical structure for the words in its lexicon
and it performs a morphological analysis of
unknown words (Möbius, 1998); the pronun-
ciation rules draw on this structural infor-
mation. These comparative results emphasize
the value of phonotactic knowledge and infor-
mation on syllable structure and morphologi-
cal structure for g2p conversion.
In a comparison across languages, a word
accuracy rate of 75.3% for our 5-dimensional
German syllable model is slightly higher than
the best data-driven method for English with
72% (Damper et al., 1999). Recently, Bouma
(2000) has reported a word accuracy of 92.6%
for Dutch, using a `lazy&apos; training strategy on
data aligned with the correct phoneme string,
and a hand-crafted system that relied on a
large set of rule templates and a many-to-one
mapping of characters to graphemes preceding
the actual g2p conversion.
We are confident that a judicious combina-
tion of phonological information of the type
employed in our feasibility study with stan-
dard techniques such as g2p alignment of
training data will produce a pronunciation
system with a word accuracy that matches
the one reported by Bouma (2000). We be-
lieve, however, that for an optimally perform-
ing system as is desired for TTS, an even
more complex design will have to be adopted.
In many languages, including English, Ger-
man and Dutch, access to morphological and
phonological information is required to reli-
ably predict the pronunciation of words; this
view is further evidenced by the performance
of the Bell Labs system, which relies on pre-
cisely this type of information. We agree with
Sproat (1998, p. 77) that it is unrealistic to ex-
pect optimal results from a system that has no
access to this type of information or is trained
on data that are insufficient for the task.
</bodyText>
<sectionHeader confidence="0.992067" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99974993877551">
Harald R. Baayen, Richard Piepenbrock, and
H. van Rijn. 1993. The CELEx lexical
database Dutch, English, German. (Re-
lease 1)[CD-ROM]. Philadelphia, PA: Linguis-
tic Data Consortium, Univ. Pennsylvania.
Leonard E. Baum, Ted Petrie, George Soules, and
Norman Weiss. 1970. A maximization tech-
nique occurring in the statistical analysis of
probabilistic functions of Markov chains. The
Annals of Math. Statistics, 41(1):164-171.
Gosse Bouma. 2000. A finite state and data-
oriented method for grapheme to phoneme con-
version. In Proc. 1st Conf. North American
Chapter of the ACL (NAACL), Seattle, WA.
Robert I. Damper, Y. Marchand, M. J. Adam-
son, and Kjell Gustafson. 1999. Evaluating
the pronunciation component of text-to-speech
systems for English: a performance comparison
of different approaches. Computer Speech and
Language, 13:155-176.
A. P. Dempster, N. M. Laird, and D. B. Rubin.
1977. Maximum likelihood from incomplete
data via the EM algorithm. J. Royal Statistical
Soc., 39(B):1-38.
Bernd Möbius. 1998. Word and syllable mod-
els for German text-to-speech synthesis. In
Proc. 3rd ESCA Workshop on Speech Synthe-
sis (Jenolan Caves), pages 59-64.
Bernd Möbius. 1999. The Bell Labs German text-
to-speech system. Computer Speech and Lan-
guage, 13:319-358.
Gregor Mohler. 1999. IMS Festival.
[http://www.ims.uni-stuttgart.de/phonetik/
synthesis/index.html].
Karin Müller, Bernd Möbius, and Detlef Prescher.
2000. Inducing probabilistic syllable classes us-
ing multivariate clustering - GOLD. In AIMS
Report 6(2), IMS, Univ. Stuttgart.
Karin Müller. 2000. PCFGs for syllabification
and g2p conversion. In AIMS Report 6(2), IMS,
Univ. Stuttgart.
Mats Rooth, Stefan Riezler, Detlef Prescher,
Glenn Carroll, and Franz Beil. 1999. Inducing
a semantically annotated lexicon via EM-based
clustering. In Proc. 37th Ann. Meeting of the
ACL, College Park, MD.
Richard Sproat, editor. 1998. Multilingual Text-
to-Speech Synthesis: The Bell Labs Approach.
Kluwer Academic, Dordrecht.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.685518">
<title confidence="0.999712">Inducing Probabilistic Syllable Classes Using Multivariate Clustering</title>
<author confidence="0.946744">Karin Müller</author>
<author confidence="0.946744">Bernd Möbius</author>
<author confidence="0.946744">Detlef Prescher</author>
<affiliation confidence="0.9129205">Institut fur Maschinelle Sprachverarbeitung University of Stuttgart, Germany</affiliation>
<abstract confidence="0.9910939375">An approach to automatic detection of syllable structure is presented. We demonstrate a novel application of EM-based clustering to multivariate data, exemplified by the induction of 3and 5-dimensional probabilistic syllable classes. The qualitative evaluation shows that the method yields phonologically meaningful syllable classes. We then propose a novel approach to grapheme-to-phoneme conversion and show that syllable structure represents valuable information for pronunciation systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Harald R Baayen</author>
<author>Richard Piepenbrock</author>
<author>H van Rijn</author>
</authors>
<date>1993</date>
<booktitle>The CELEx lexical database Dutch, English, German. (Release 1)[CD-ROM].</booktitle>
<institution>Linguistic Data Consortium, Univ. Pennsylvania.</institution>
<location>Philadelphia, PA:</location>
<marker>Baayen, Piepenbrock, van Rijn, 1993</marker>
<rawString>Harald R. Baayen, Richard Piepenbrock, and H. van Rijn. 1993. The CELEx lexical database Dutch, English, German. (Release 1)[CD-ROM]. Philadelphia, PA: Linguistic Data Consortium, Univ. Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard E Baum</author>
<author>Ted Petrie</author>
<author>George Soules</author>
<author>Norman Weiss</author>
</authors>
<title>A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains.</title>
<date>1970</date>
<journal>The Annals of Math. Statistics,</journal>
<pages>41--1</pages>
<contexts>
<context position="6190" citStr="Baum et al., 1970" startWordPosition="1002" endWordPosition="1005">of yi on each other is solely made through the classes c via the independence assumption p(yIc) = Qdi=1 p(yiIc). This assumption makes clustering feasible in the first place; later on (in Section 4.1) we will experimentally determine the number ICI of classes such that the assumption is optimally met. The EM algorithm (Dempster et al., 1977) is directed at maximizing the incomplete data log-likelihood L = Py ~p(y) lnp(y) as a function of the probability distribution p for a given empirical probability distribution ~p. Our application is an instance of the EM-algorithm for context-free models (Baum et al., 1970), from which simple re-estimation formulae can be derived. Let f(y) the frequency of syllable y, and If I = Py2Y f(y) the total frequency of the sample (i.e. ~p(y) = f�y) jfj ), and fc(y) = f(y)p(cIy) the estimated frequency of y annotated with c. Parameter updates ^p(c); ^p(yiIc) can thus be computed by (c 2 C; yi 2 Yi; i = 1; ::; d): Py2Y fc(y) ^p(c) =; and If I class 0 0.071 D 0.745 @ 1 ONE 0.999 STR 1 NOP[@] 0.166 NOP[@] 0.877 m 0.0792 class 1 0.049 NOP[I] 0.914 I 1 n 0.387 ONE 0.916 STR 1 h 0.071 z 0.360 INI 0.069 b 0.010 t 0.180 f 0.042 ts 0.02 class 3 0.040 t 0.206 I 0.993 0.466 FIN 0.9</context>
<context position="7572" citStr="Baum et al. (1970)" startWordPosition="1300" endWordPosition="1303"> FIN 0.003 D 0.102 d 0.054 MED d 0.095 l 0.045 NOP[@] 0.072 n class 10 0.028 S 0.257 @ 0.063 n 0.388 FIN 0.999 USTR 0.999 m 0.227 I 0.926 nt 0.191 d 0.059 I@ 0.031 nz 0.088 t 0.007 E 0.015 l 0.066 NOP[@] 0.005 nts 0.049 ns 0.048 class 14 0.026 m 0.116 pl 0.052 eI 0.426 0.165 0.162 ONE 0.696 STR 0.984 p 0.108 A: 0.140 t 0.131 FIN 0.276 k 0.090 E 0.110 s 0.088 g 0.088 O: n 0.079 t 0.080 d 0.079 st 0.051 k 0.052 nd 0.037 ts class 17 0.023 NOP[@] 0.973 @ 1 ONE 0.944 STR 1 NOP[@] 0.325 INI 0.050 r* 0.317 Figure 3: Classes #0, #1, #3, #4, #10, #14, #17 of the 5-dimensional English model As shown by Baum et al. (1970), every such maximization step increases the log-likelihood function L, and a sequence of re-estimates eventually converges to a (local) maximum. 3 Experiments A sample of syllables serves as input to the multivariate clustering algorithm. The German data were extracted from the Stuttgarter Zeitung (STZ), a newspaper corpus of about 31 million words. The English data came from the British National Corpus (BNC), a collection of written and spoken language containing about 100 million words. For both languages, syllables were collected by going through the corpus, looking up the words and their </context>
</contexts>
<marker>Baum, Petrie, Soules, Weiss, 1970</marker>
<rawString>Leonard E. Baum, Ted Petrie, George Soules, and Norman Weiss. 1970. A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. The Annals of Math. Statistics, 41(1):164-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
</authors>
<title>A finite state and dataoriented method for grapheme to phoneme conversion.</title>
<date>2000</date>
<booktitle>In Proc. 1st Conf. North American Chapter of the ACL (NAACL),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="25069" citStr="Bouma (2000)" startWordPosition="4191" endWordPosition="4192">is TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); the pronunciation rules draw on this structural information. These comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion. In a comparison across languages, a word accuracy rate of 75.3% for our 5-dimensional German syllable model is slightly higher than the best data-driven method for English with 72% (Damper et al., 1999). Recently, Bouma (2000) has reported a word accuracy of 92.6% for Dutch, using a `lazy&apos; training strategy on data aligned with the correct phoneme string, and a hand-crafted system that relied on a large set of rule templates and a many-to-one mapping of characters to graphemes preceding the actual g2p conversion. We are confident that a judicious combination of phonological information of the type employed in our feasibility study with standard techniques such as g2p alignment of training data will produce a pronunciation system with a word accuracy that matches the one reported by Bouma (2000). We believe, however</context>
</contexts>
<marker>Bouma, 2000</marker>
<rawString>Gosse Bouma. 2000. A finite state and dataoriented method for grapheme to phoneme conversion. In Proc. 1st Conf. North American Chapter of the ACL (NAACL), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert I Damper</author>
<author>Y Marchand</author>
<author>M J Adamson</author>
<author>Kjell Gustafson</author>
</authors>
<title>Evaluating the pronunciation component of text-to-speech systems for English: a performance comparison of different approaches.</title>
<date>1999</date>
<journal>Computer Speech and Language,</journal>
<pages>13--155</pages>
<contexts>
<context position="3266" citStr="Damper et al., 1999" startWordPosition="486" endWordPosition="489">s for English and German syllable structure. The obtained models of syllable structure were evaluated in three ways. Firstly, the 3-dimensional models were subjected to a pseudo-disambiguation task, the result of which shows that the onset is the most variable part of the syllable. Secondly, the resulting syllable classes were qualitatively evaluated from a phonological and phonotactic point of view. Thirdly, a 5-dimensional syllable model for German was tested in a g2p conversion task. The results compare well with the best currently available data-driven approaches to g2p conversion (e.g., (Damper et al., 1999)) and suggest that syllable strucclass 0 0.212 NOP[I] 0.282 I 0.999 NOP[I] 0.460 t 0.107 n 0.121 l 0.074 N 0.096 d 0.071 z 0.079 b 0.065 t 0.042 s 0.060 ts 0.013 f 0.012 Figure 1: Class #0 of a 3-dimensional English model with 12 classes class 46 0.007 NOP[E] 0.630 E 0.990 nt 0.602 INI 0.627 STR 0.596 ts 0.256 t 0.128 FIN 0.331 USTR 0.403 d 0.074 n 0.092 MED 0.040 n 0.001 pt 0.010 ks 0.004 Figure 2: Class #46 of a 5-dimensional German model with 50 classes p(c)p(yIc) p(c; y) = X c2C p(c) Yd i=1 p(y) = X c2C X c2C p(yiIc) ture represents valuable information for pronunciation systems. Such syst</context>
<context position="23369" citStr="Damper et al. (1999)" startWordPosition="3919" endWordPosition="3922">ted text input, which can be expected to contain words that are not in the system&apos;s pronunciation dictionary or otherwise unknown to the system. The main purpose of the feasibility study was to demonstrate the relevance of the phonological information on syllable structure for g2p conversion. Therefore, information and probabilities derived from an alignment of grapheme and phoneme strings, i.e. the lowest two levels in the trees displayed in Figure 6, was deliberately ignored. Data-driven pronunciation systems usually rely on training data that include an alignment of graphemes and phonemes. Damper et al. (1999) have shown that the use of unaligned training data significantly reduces the performance of g2p systems. In our experiment, with training on unannotated text corpora and without an alignment of graphemes and phonemes, we obtained a word accuracy rate of 75.3% for the 5-dimensional German syllable model. Comparison of this performance with other systems is difficult: (i) hardly any quantitative g2p performance data are available for German; (ii) comparisons across languages are hard to interpret; (iii) comparisons across different approaches require cautious interpretations. The most direct po</context>
<context position="25045" citStr="Damper et al., 1999" startWordPosition="4186" endWordPosition="4189">ord accuracy on our test set. This TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); the pronunciation rules draw on this structural information. These comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion. In a comparison across languages, a word accuracy rate of 75.3% for our 5-dimensional German syllable model is slightly higher than the best data-driven method for English with 72% (Damper et al., 1999). Recently, Bouma (2000) has reported a word accuracy of 92.6% for Dutch, using a `lazy&apos; training strategy on data aligned with the correct phoneme string, and a hand-crafted system that relied on a large set of rule templates and a many-to-one mapping of characters to graphemes preceding the actual g2p conversion. We are confident that a judicious combination of phonological information of the type employed in our feasibility study with standard techniques such as g2p alignment of training data will produce a pronunciation system with a word accuracy that matches the one reported by Bouma (20</context>
</contexts>
<marker>Damper, Marchand, Adamson, Gustafson, 1999</marker>
<rawString>Robert I. Damper, Y. Marchand, M. J. Adamson, and Kjell Gustafson. 1999. Evaluating the pronunciation component of text-to-speech systems for English: a performance comparison of different approaches. Computer Speech and Language, 13:155-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>J. Royal Statistical Soc.,</journal>
<pages>39--1</pages>
<contexts>
<context position="5915" citStr="Dempster et al., 1977" startWordPosition="957" endWordPosition="960">ution p(y) on syllables y from a large sample. The key idea is to view y as conditioned on an unobserved class c 2 C, where the classes are given no prior interpretation. The probability of a syllable y = (y1; ::; yd) 2 Y1 x :: x Yd; d &gt; 3; is defined as: Note that conditioning of yi on each other is solely made through the classes c via the independence assumption p(yIc) = Qdi=1 p(yiIc). This assumption makes clustering feasible in the first place; later on (in Section 4.1) we will experimentally determine the number ICI of classes such that the assumption is optimally met. The EM algorithm (Dempster et al., 1977) is directed at maximizing the incomplete data log-likelihood L = Py ~p(y) lnp(y) as a function of the probability distribution p for a given empirical probability distribution ~p. Our application is an instance of the EM-algorithm for context-free models (Baum et al., 1970), from which simple re-estimation formulae can be derived. Let f(y) the frequency of syllable y, and If I = Py2Y f(y) the total frequency of the sample (i.e. ~p(y) = f�y) jfj ), and fc(y) = f(y)p(cIy) the estimated frequency of y annotated with c. Parameter updates ^p(c); ^p(yiIc) can thus be computed by (c 2 C; yi 2 Yi; i </context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statistical Soc., 39(B):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Möbius</author>
</authors>
<title>Word and syllable models for German text-to-speech synthesis.</title>
<date>1998</date>
<booktitle>In Proc. 3rd ESCA Workshop on Speech Synthesis (Jenolan Caves),</booktitle>
<pages>59--64</pages>
<contexts>
<context position="24623" citStr="Möbius, 1998" startWordPosition="4123" endWordPosition="4124"> by Müller (2000). In one of her experiments, the standard probability model was applied to the hand-crafted cfg presented in this paper, yielding 42% word accuracy as evaluated on our test set. Running the test set through the pronunciation rule system of the IMS German Festival TTS system (Mohler, 1999) resulted in 55% word accuracy. The Bell Labs German TTS system (Möbius, 1999) performed at better than 94% word accuracy on our test set. This TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); the pronunciation rules draw on this structural information. These comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion. In a comparison across languages, a word accuracy rate of 75.3% for our 5-dimensional German syllable model is slightly higher than the best data-driven method for English with 72% (Damper et al., 1999). Recently, Bouma (2000) has reported a word accuracy of 92.6% for Dutch, using a `lazy&apos; training strategy on data aligned with the correct phoneme string, and a hand-crafted sys</context>
</contexts>
<marker>Möbius, 1998</marker>
<rawString>Bernd Möbius. 1998. Word and syllable models for German text-to-speech synthesis. In Proc. 3rd ESCA Workshop on Speech Synthesis (Jenolan Caves), pages 59-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Möbius</author>
</authors>
<title>The Bell Labs German textto-speech system.</title>
<date>1999</date>
<journal>Computer Speech and Language,</journal>
<pages>13--319</pages>
<contexts>
<context position="24394" citStr="Möbius, 1999" startWordPosition="4084" endWordPosition="4085">e data are available for German; (ii) comparisons across languages are hard to interpret; (iii) comparisons across different approaches require cautious interpretations. The most direct point of comparison is the method presented by Müller (2000). In one of her experiments, the standard probability model was applied to the hand-crafted cfg presented in this paper, yielding 42% word accuracy as evaluated on our test set. Running the test set through the pronunciation rule system of the IMS German Festival TTS system (Mohler, 1999) resulted in 55% word accuracy. The Bell Labs German TTS system (Möbius, 1999) performed at better than 94% word accuracy on our test set. This TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); the pronunciation rules draw on this structural information. These comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion. In a comparison across languages, a word accuracy rate of 75.3% for our 5-dimensional German syllable model is slightly higher than the best data-drive</context>
</contexts>
<marker>Möbius, 1999</marker>
<rawString>Bernd Möbius. 1999. The Bell Labs German textto-speech system. Computer Speech and Language, 13:319-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Mohler</author>
</authors>
<date>1999</date>
<note>IMS Festival. [http://www.ims.uni-stuttgart.de/phonetik/ synthesis/index.html].</note>
<contexts>
<context position="24316" citStr="Mohler, 1999" startWordPosition="4070" endWordPosition="4071">ce with other systems is difficult: (i) hardly any quantitative g2p performance data are available for German; (ii) comparisons across languages are hard to interpret; (iii) comparisons across different approaches require cautious interpretations. The most direct point of comparison is the method presented by Müller (2000). In one of her experiments, the standard probability model was applied to the hand-crafted cfg presented in this paper, yielding 42% word accuracy as evaluated on our test set. Running the test set through the pronunciation rule system of the IMS German Festival TTS system (Mohler, 1999) resulted in 55% word accuracy. The Bell Labs German TTS system (Möbius, 1999) performed at better than 94% word accuracy on our test set. This TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); the pronunciation rules draw on this structural information. These comparative results emphasize the value of phonotactic knowledge and information on syllable structure and morphological structure for g2p conversion. In a comparison across languages, a word accuracy rate of 75.3% for our 5</context>
</contexts>
<marker>Mohler, 1999</marker>
<rawString>Gregor Mohler. 1999. IMS Festival. [http://www.ims.uni-stuttgart.de/phonetik/ synthesis/index.html].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Müller</author>
<author>Bernd Möbius</author>
<author>Detlef Prescher</author>
</authors>
<title>Inducing probabilistic syllable classes using multivariate clustering - GOLD.</title>
<date>2000</date>
<booktitle>In AIMS Report 6(2), IMS, Univ.</booktitle>
<location>Stuttgart.</location>
<contexts>
<context position="8544" citStr="Müller et al., 2000" startWordPosition="1443" endWordPosition="1446"> The English data came from the British National Corpus (BNC), a collection of written and spoken language containing about 100 million words. For both languages, syllables were collected by going through the corpus, looking up the words and their syllabifications in a pronunciation dictionary (Baayen et al., 1993)1 and counting the occurrence frequencies of the syllable types�. 1We slightly modified the English pronunciation lexicon to obtain non-empty nuclei, e.g. /idealism/ [aI][dI@][lIzm,] was modified to [aI][dI@][lI][z@m] (SAMPA transcription). 2Subsequent experiments on syllable types (Müller et al., 2000) have shown that frequency counts represent valuable information for our clustering task. In two experiments, we induced 3-dimensional models based on syllable onset, nucleus, and coda. We collected 9327 distinct German syllables and 13,598 distinct English syllables. The number of syllable classes was systematically varied in iterated training runs and ranged from 1 to 200. Figure 1 shows a selected segment of class #0 from a 3-dimensional English model with 12 classes. The first column displays the class index 0 and the class probability p(0). The most probable onsets and their probabilities</context>
</contexts>
<marker>Müller, Möbius, Prescher, 2000</marker>
<rawString>Karin Müller, Bernd Möbius, and Detlef Prescher. 2000. Inducing probabilistic syllable classes using multivariate clustering - GOLD. In AIMS Report 6(2), IMS, Univ. Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Müller</author>
</authors>
<title>PCFGs for syllabification and g2p conversion.</title>
<date>2000</date>
<booktitle>In AIMS Report 6(2), IMS, Univ.</booktitle>
<location>Stuttgart.</location>
<contexts>
<context position="1600" citStr="Müller, 2000" startWordPosition="224" endWordPosition="225">riate data. The suitability of this approach is exemplified by the induction of 3- and 5-dimensional probabilistic syllable classes. A secondary goal is to outline a novel approach to the conversion of graphemes to phonemes (g2p) which uses a context-free grammar (cfg) to generate all sequences of phonemes corresponding to a given orthographic input word and then ranks the hypotheses according to the probabilistic information coded in the syllable classes. Our approach builds on two resources. The first resource is a cfg for g2p conversion that was constructed manually by a linguistic expert (Müller, 2000). The grammar describes how words are composed of syllables and how syllables consist of parts that are conventionally called onset, nucleus and coda, which in turn are composed of phonemes, and corresponding graphemes. The second resource consists of a multivariate clustering algorithm that is used to reveal syllable structure hidden in unannotated training data. In a first step, we collect syllables by going through a large text corpus, looking up the words and their syllabifications in a pronunciation dictionary and counting the occurrence frequencies of the syllable types. Probabilistic sy</context>
<context position="24027" citStr="Müller (2000)" startWordPosition="4021" endWordPosition="4022">g data significantly reduces the performance of g2p systems. In our experiment, with training on unannotated text corpora and without an alignment of graphemes and phonemes, we obtained a word accuracy rate of 75.3% for the 5-dimensional German syllable model. Comparison of this performance with other systems is difficult: (i) hardly any quantitative g2p performance data are available for German; (ii) comparisons across languages are hard to interpret; (iii) comparisons across different approaches require cautious interpretations. The most direct point of comparison is the method presented by Müller (2000). In one of her experiments, the standard probability model was applied to the hand-crafted cfg presented in this paper, yielding 42% word accuracy as evaluated on our test set. Running the test set through the pronunciation rule system of the IMS German Festival TTS system (Mohler, 1999) resulted in 55% word accuracy. The Bell Labs German TTS system (Möbius, 1999) performed at better than 94% word accuracy on our test set. This TTS system relies on an annotation of morphological structure for the words in its lexicon and it performs a morphological analysis of unknown words (Möbius, 1998); th</context>
</contexts>
<marker>Müller, 2000</marker>
<rawString>Karin Müller. 2000. PCFGs for syllabification and g2p conversion. In AIMS Report 6(2), IMS, Univ. Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proc. 37th Ann. Meeting of the ACL,</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="2410" citStr="Rooth et al., 1999" startWordPosition="347" endWordPosition="350">and corresponding graphemes. The second resource consists of a multivariate clustering algorithm that is used to reveal syllable structure hidden in unannotated training data. In a first step, we collect syllables by going through a large text corpus, looking up the words and their syllabifications in a pronunciation dictionary and counting the occurrence frequencies of the syllable types. Probabilistic syllable classes are then computed by applying maximum likelihood estimation from incomplete data via the EM algorithm. Two-dimensional EM-based clustering has been applied to tasks in syntax (Rooth et al., 1999), but so far this approach has not been used to derive models of higher dimensionality and, to the best of our knowledge, this is the first time that it is being applied to speech. Accordingly, we have trained 3- and 5-dimensional models for English and German syllable structure. The obtained models of syllable structure were evaluated in three ways. Firstly, the 3-dimensional models were subjected to a pseudo-disambiguation task, the result of which shows that the onset is the most variable part of the syllable. Secondly, the resulting syllable classes were qualitatively evaluated from a phon</context>
<context position="4447" citStr="Rooth et al., 1999" startWordPosition="699" endWordPosition="702">n for pronunciation systems. Such systems are critical components in text-to-speech (TTS) conversion systems, and they are also increasingly used to generate pronunciation variants in automatic speech recognition. The rest of the paper is organized as follows. In Section 2 we introduce the multivariate clustering algorithm. In Section 3 we present four experiments based on 3- and 5- dimensional data for German and English. Section 4 is dedicated to evaluation and in Section 5 we discuss our results. 2 Multivariate Syllable Clustering EM-based clustering has been derived and applied to syntax (Rooth et al., 1999). Unfortunately, this approach is not applicable to multivariate data with more than two dimensions. However, we consider syllables to consist of at least three dimensions corresponding to parts of the internal syllable structure: onset, nucleus and coda. We have also experimented with 5-dimensional models by adding two more dimensions: position of the syllable in the word and stress status. In our multivariate clustering approach, classes corresponding to syllables are viewed as hidden data in the context of maximum likelihood estimation from incomplete data via the EM algorithm. The two main</context>
<context position="10914" citStr="Rooth et al. (1999)" startWordPosition="1834" endWordPosition="1837">ble classes ranged from 1 to 200. Figure 2 illustrates (part of) class #46 from a 5-dimensional German model with 50 classes. Syllable position and stress are displayed in the last two columns. 4 Evaluation In the following sections, (i) the 3-dimensional models are subjected to a pseudodisambiguation task (4.1); (ii) the syllable classes are qualitatively evaluated (4.2); and (iii) the 5-dimensional syllable model for German is tested in a g2p task (4.3). 4.1 Pseudo-Disambiguation We evaluated our 3-dimensional clustering models on a pseudo-disambiguation task similar to the one described by Rooth et al. (1999), but specified to onset, nucleus, and coda ambiguity. The first task is to judge which of two onsets on and on&apos; is more likely to appear in the context of a given nucleus n and a given coda cod. For this purpose, we constructed an evaluation corpus of 3000 syllables (on, n, cod) selected from the original data. Then, randomly chosen onsets on&apos; were attached to all syllables in the evaluation corpus, with the resulting syllables (on&apos;, n, cod) appearing neither in the training nor in the evaluation corpus. Furthermore, the elements on, n, cod, and on&apos; were required to be part of the training co</context>
<context position="21186" citStr="Rooth et al., 1999" startWordPosition="3571" endWordPosition="3574">sional syllable models achieved the highest performance (75.3%), which is a gain of 3% over the performance of the 5-dimensional baseline system and a gain of 8% over the performance of the 3-dimensional models5. 5 Discussion We have presented an approach to unsupervised learning and automatic detection of syllable structure, using EM-based multivariate clustering. The method yields phonologically meaningful syllable classes. These classes are shown to represent valuable input information in a g2p conversion task. In contrast to the application of twodimensional EM-based clustering to syntax (Rooth et al., 1999), where semantic relations were revealed between verbs and objects, the syllable models cannot a priori be expected to yield similarly meaningful properties. This is because the syllable constituents (or phones) represent an inventory with a small number of units which can be combined to form meaningful larger units, viz. morphemes and words, but which do not themselves carry meaning. Thus, there is no reason why certain syllable types should occur significantly more often than others, except for the fact that certain morphemes and words have a higher frequency count than others in a given tex</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via EM-based clustering. In Proc. 37th Ann. Meeting of the ACL, College Park, MD.</rawString>
</citation>
<citation valid="true">
<title>Multilingual Textto-Speech Synthesis: The Bell Labs Approach.</title>
<date>1998</date>
<editor>Richard Sproat, editor.</editor>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht.</location>
<marker>1998</marker>
<rawString>Richard Sproat, editor. 1998. Multilingual Textto-Speech Synthesis: The Bell Labs Approach. Kluwer Academic, Dordrecht.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>