<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.982616">
The Delphi Natural Language Understanding System
</title>
<author confidence="0.985789">
Madeleine Bates, Robert Bobrow, Robert Ingria and David Stallard
</author>
<affiliation confidence="0.864547">
BBN Systems and Technologies, Inc.
</affiliation>
<address confidence="0.878423">
70 Fawcett St.
Cambridge, MA 02138
</address>
<sectionHeader confidence="0.931389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995105">
This paper presents Delphi, the natural
language component of the BBN Spoken
Language System. Delphi is a domain-
independent natural language question an-
swering system that is solidly based on
linguistic principles, yet which is also ro-
bust to ungrammatical input. It includes
a domain-independent, broad-coverage gram-
mar of English. Analysis components include
an agenda-based best-first parser and a fall-
back component for partial understanding that
works by fragment combination. Delphi has
been formally evaluated in the ARPA Spoken
Language program&apos;s ATIS (Airline Travel In-
formation System) domain, and has performed
well. Delphi has also been ported to a spo-
ken language demonstration system in an Air
Force Resource Management domain. We dis-
cuss results of the evaluation as well as the
porting process.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999596">
Delphi is a natural language understanding system based
on general linguistic principles which is adaptable to any
question-answering domain. It incorporates a number of
domain-independent knowledge bases, including a gen-
eral, broad-coverage grammar of English with a pow-
erful and flexible handling of complementation. Unlike
most other linguistically motivated systems, however,
Delphi is also highly robust, allowing for partial under-
standing when an input is ungrammatical, disfluent, or
not properly transcribed by a speech recognizer. Thus,
Delphi can be used for a spoken language application
as readily as for a written one. Furthermore, Delphi&apos;s
partial understanding component, called the Semantic
Linker, is driven off the same system of semantic rules
as Delphi&apos;s regular best-first parser. Building a robust
application therefore requires no additional effort.
There are several components of the system, which
is diagrammed in Figure 1. First are the parser and
Semantic Linker, which output an intermediate repre-
sentation we call a &amp;quot;semantic graph&amp;quot;. The semantic
</bodyText>
<figureCaption confidence="0.999523">
Figure 1: System Diagram
</figureCaption>
<bodyText confidence="0.999915681818182">
graph is passed to a quantification stage which pro-
duces a fully scoped logical form from it. The logical
form is then passed to the discourse stage, which re-
solves pronominal references and performs other types
of task-dependent constraint resolution to produce the
final logical form. The final logical form is then passed
to the backend translator, and then to the application
system which produces the response. Several knowl-
edge bases are employed by these analysis components,
including grammar, &amp;quot;realization rules&amp;quot; and the domain
model, which represents the set of classes and binary
relations of the given application domain.
Delphi differs from most other linguistically moti-
vated systems in the role that is played by syntax.
The primary function of Delphi&apos;s parser and syntac-
tic knowledge bases is not to produce a parse tree, but
rather to constrain the search for an appropriate semantic
graph interpretation of the utterance. Semantic graphs
are produced not by rule-to-rule compositionality, but
by what might be called &amp;quot;relation-to-relation&amp;quot; compo-
sitionality — the association of grammatical relations in
the syntactic structure with semantic relations in the se-
</bodyText>
<sectionHeader confidence="0.924634" genericHeader="introduction">
QUANTIFICATION
AND DISCOURSE
</sectionHeader>
<page confidence="0.996484">
132
</page>
<bodyText confidence="0.988336428571428">
mantic graph.
This more incremental view of the syntax/semantics
interface has three crucial advantages. First, there is
much more flexibility with respect to ordering and op-
tionality of constituents. Second, because relation-to-
relation translations are simple, the task of porting the
system is greatly simplified. Third and finally, partial
or fragmentary analyses can be represented, and a com-
plete semantic graph interpretation for the utterance pro-
duced even when a complete syntactic analyses is not
available.
In the remainder of the paper, we describe Del-
phi&apos;s main processing components, representational for-
malisms, and knowledge bases.
</bodyText>
<sectionHeader confidence="0.993048" genericHeader="method">
2 Grammar And The Syntax/Semantics
Interface
</sectionHeader>
<bodyText confidence="0.999353857142857">
The Delphi grammar is a broad coverage, domain inde-
pendent grammar of English written in a version of the
Definite Clause Grammar formalism (Pereira and War-
ren, 1980) that has been extended to include labeling of
right-hand side elements with the grammatical relations
they bear to the head of the construction. An example
is:
</bodyText>
<subsectionHeader confidence="0.533951">
(S ?arg ?mood)
</subsectionHeader>
<bodyText confidence="0.98979403125">
-&gt;
subject: (NP ?arg ?mood etc.)
head: (VP ?agr ?mood etc.)
In this rule, there is a head VP and an NP which
bears the SUBJECT relation to it. Other grammati-
cal relations include the familar DIRECT-OBJECT and
INDIRECT-OBJECT as well as the prepositions, such
as TO, FROM, WITH and so on.
Annotating sub-constituents with grammatical rela-
tions regularizes the syntactic structure with respect to
particular grammatical rules, and allows a &amp;quot;relation-to-
relation&amp;quot; form of compositionality, as opposed to the
more traditional &amp;quot;rule-to-rule&amp;quot; version that is exempli-
fied by such systems as Gemini (Dowding et al, 1993)
and the Core Language Engine (Alsbawi, 1992). In
relation-to-relation compositionality, each grammatical
relation in the syntactic structure corresponds to a se-
mantic relation in a parallel semantic structure we call
a &amp;quot;semantic graph&amp;quot;. The terminal nodes of the seman-
tic graph are the word meanings, corresponding to the
lexical heads of syntactic structure.
An example of a semantic graph, representing the
meaning of &amp;quot;What flights fly from Boston to Denver&amp;quot;,
may be seen in Figure 2. The semantic graph is not a
fully quantified formula; rather it may be thought of as
a form of predicate-argument representation, with quan-
tifiers in place, from which a fully quantified formula
can be generated. The allowed class and relation labels
come from the domain model.
This view of the syntax/semantics interface has
marked advantages. For one thing, because the syn-
tactic/semantic structure is built up one argument at a
</bodyText>
<figure confidence="0.986418285714286">
flight-of
quant
FLIGHT- WH
BOSTON
orig-of
DENVER
dest-of
</figure>
<figureCaption confidence="0.999793">
Figure 2: Semantic Graph
</figureCaption>
<bodyText confidence="0.983809">
time, it becomes much easier to accomodate such phe-
nomena as order-variation and optionality of arguments
that are difficult for other approaches
The importance of this feature may be seen in the
examples of argument order-variation and optionality
that abound in real data. Consider the following from
the ATIS domain, in which complements can vary freely
in order:
</bodyText>
<subsectionHeader confidence="0.323273">
What flights fly from Boston to Denver?
What flights fly to Denver from Boston?
</subsectionHeader>
<bodyText confidence="0.795102">
or be separated from the head by a modifier typically
regarded as an adjunct:
What flights fly at 3 pm from Boston to Denver?
In some cases, modifiers can be omitted, as in:
</bodyText>
<subsectionHeader confidence="0.441677">
What flights fly from Boston?
What flights fly to Denver?
</subsectionHeader>
<bodyText confidence="0.8017145">
and sometimes the omission of an argument can have
anaphoric consequences, as in:
</bodyText>
<subsectionHeader confidence="0.968776">
What restrictions apply?
</subsectionHeader>
<bodyText confidence="0.97930232">
which cannot be felicitously uttered except in a con-
text where there is something in the discourse that a
restriction could &amp;quot;apply&amp;quot; to.
Conventional approaches to subcategorization, such
as Definite Clause Grammar (Pereira and Warren,
1980), Categorial Grarmnar (Ades and Steedman, 1982),
PATR-II (Shieber, 1986), and lexicalized TAG (Schabes
et al, 1988) all deal with complementation by includ-
ing in one form or another a notion of &amp;quot;subcategoriza-
tion frame&amp;quot; that specifies a sequence of complement
phrases and constraints on them. Handling all the pos-
sible variations in complement distribution in such for-
malisms inevitably leads to an explosion in the number
of such frames, and a correspondingly more difficult
task in porting to a new domain.
In our approach, on the other hand, it becomes pos-
sible to view subcategorization of a lexical item as a
set of constraints on the outgoing arcs of its semantic
graph node. Different types of constraints — order of ar-
guments, optionality of arguments, semantic-class con-
straints and semantic effects of arguments — can all be
represented separately, instead of enumerating all pos-
sible argument sequences in a set of alternative subcat-
egorization frames.
FLY
</bodyText>
<page confidence="0.995613">
133
</page>
<bodyText confidence="0.999458">
Subcategorization constraints in Delphi are encoded
in lexical entries using a structure called a &amp;quot;map&amp;quot; (Stal-
lard and Bobrow, 1991). Below is part of the lexical
entry for &amp;quot;fly&amp;quot; in the ATIS domain:
</bodyText>
<sectionHeader confidence="0.5214014" genericHeader="method">
FLY
subject: FLIGHT-OF
to: DEST-OF
from: ORIG-OF
completion: (and (filled flight-of)
</sectionHeader>
<bodyText confidence="0.989329676470588">
(or (filled dest-of)
(filled orig-of))
Map entries have &amp;quot;translation&amp;quot;, &amp;quot;realization&amp;quot; and &amp;quot;com-
pletion&amp;quot; components. The translation part of this entry
specifies that the lexical head &amp;quot;fly&amp;quot; is to correspond to a
semantic-graph node labeled with event-class FLY. The
realization part of the entry specifies what grammati-
cal relations the lexical item takes, and what semantic
relations these correspond to, or &amp;quot;realize&amp;quot;, in the se-
mantic graph. Here, the entry specifies that &amp;quot;fly&amp;quot; takes
SUBJECT, TO, and FROM complements, and that these
grammatical relations correspond to the semantic rela-
tions FLIGHT-OF, DEST-OF, and ORIG-OF respec-
tively. Semantic selectional restrictions in these argu-
ment positions — that the filler of DEST-OF be a city,
for example — are implicit from the declarations of the
relations in the domain model.
The &amp;quot;completion&amp;quot; part of the entry specifies what out-
going arcs are required for the node. Here, the entry re-
quires that the FLIGHT-OF role be filled, and that either
the DEST-OF or ORIG-OF roles be filled (forbidding
the intransitive &amp;quot;the flight flies&amp;quot;). More complex op-
tionality cases are encoded with other completion pred-
icates. For example, the case where an anaphor must
be present (&amp;quot;What restrictions apply&amp;quot;) is encoded by the
predicate FILLED-OR-ANAPHOR.
Some realization rules are tied to semantic classes
rather than lexical translations, and require for their ap-
plication only that semantic class restrictions implicit
from the domain and range of the realized relation be
satisfied. Typical examples are the rules governing noun
modifier meanings, such as &amp;quot;Delta flights&amp;quot;, &amp;quot;Delta&apos;s
flights&amp;quot;, &amp;quot;the flights on/aboard Delta&amp;quot;. These would all
be handled by the global realization rule:
</bodyText>
<equation confidence="0.293698">
{NOM-COMP POSS ABOARD ON ...}
—1
AIRLINE-OF
</equation>
<bodyText confidence="0.999654818181818">
Determining what semantic relation a given grammat-
ical relation instance corresponds to is most generally
viewed as a form of goal-solving in Delphi, in which
a chain of rules can be invoked. For example, syntac-
tic constructions such as &amp;quot;X with Y&amp;quot;, &amp;quot;X has Y&amp;quot; and
&amp;quot;X&apos;s Y&amp;quot; are interpreted by first appealing to a rule map-
ping them to a pseudo-relation called GENERALIZED-
POSSESSION, and then seeking a realization for it that
is compatible with the classes of X and Y. This avoids
having to write three different versions of the same re-
alization rule.
</bodyText>
<figure confidence="0.984931571428571">
BOSTON:TO
DENVER
airline-of
DELTA
FLI
MONDAY:ON
day-of-week
</figure>
<figureCaption confidence="0.99972">
Figure 3: Fragment Graphs
</figureCaption>
<bodyText confidence="0.9993098">
An important advantage of the realization rule for-
mulation, apart from its its power and flexibility, is its
simplicity. Realization rules are very simple to write,
and make maximal use both of knowledge about the
domain and general knowledge of language.
</bodyText>
<sectionHeader confidence="0.875385" genericHeader="method">
3 Ill-Formedness Handling: The
Semantic Linker
</sectionHeader>
<bodyText confidence="0.999936783783784">
When an utterance cannot be parsed with Delphi&apos;s best-
first parser (Bobrow, 1991) — either because it is ill-
formed, mis-recognized by the speech system, or sim-
ply because it is outside the coverage of the grammar —
it can still be partially understood by the system, often
well enough to give the correct response. The compo-
nent responsible for partial understanding in the Delphi
system is called the Semantic Linker (Stallard and Bo-
brow, 1993).
After a parse fails there is a set of fragmentary con-
stituents left over in the chart, corresponding to a set of
semantic graphs. The Semantic Linker seeks to connect
these sub-graphs into a single connected one by adding
links between nodes in the different sub-graphs.
At top-level, this is the same thing that the parser
and grammar do. The difference is that the parser and
grammar have an idea of what the grammatical rela-
tionship between constituents is, based on requirements
of their proximity in the string and other syntactic ev-
idence. The Semantic Linker does not have these re-
quirements, being a looser form of combination that
can ignore fragment order and skip over intervening,
unanalyzable material with ease.
Although it is a very different algorithm, the Seman-
tic Linker uses the same set of realization rules that
drives the regular parser. Using the realization rules,
the Linker determines for each pair of nodes in dif-
ferent semantic graphs the set of all links which can
connect them. It then uses an A* search to find the
most plausible set of links which produce a complete
graph.
Suppose for example, we have the three fragments
&amp;quot;to Boston&amp;quot;, &amp;quot;Denver&amp;quot; and &amp;quot;Delta flights on Mon-
day&amp;quot;. Then the three corresponding sub-graphs are
those shown in Figure 3 where a PP is treated as its
NP object with the preposition as a tag. For this set of
fragmentary sub-graphs, the possible links are:
</bodyText>
<note confidence="0.59431">
La. FLIGHTS1--- DEST-OF -&gt; BOSTON:TO
</note>
<page confidence="0.965438">
134
</page>
<table confidence="0.53014625">
lb. FLIGHTS1--- ORIG-OF -&gt; BOSTON:TO
FLIGHTS1--- DEST-OF -&gt; DENVER
FLIGHTS1--- ORIG-OF -&gt; DENVER
3a. DENVER--- NEARBY-TO -&gt; BOSTON:TO
</table>
<bodyText confidence="0.999866416666667">
where the links are grouped together in a ordered list
according to the fragment-pairs they connect.
The plausibility of a given link is a function of a
number of different features, including penalities from
assumptions made in its computation (e.g. that a given
preposition can be ignored or assumed) and empirically
determined probabilities for the given link (e.g. that
given an AIRLINE and a FLIGHT they are most prob-
ably linked by the relation AIRLINE-OF).
The semantic linker may also &amp;quot;hallucinate&amp;quot; a new
node to bridge two fragments between whom no links
can otherwise be computed. For example, for the utter-
ance &amp;quot;from Boston to Denver&amp;quot;, which has no explicit
FLIGHT-object, a FLIGHT node can be inserted be-
tween the fragments to make sense of the utterance.
Because the Semantic Linker uses the same set of
realization rules as the rest of the system, when the
system is ported to a new domain the Semantic Linker
can be used immediately - a distinct advantage over
some other approaches to fallback understanding, such
as (Stallard and Bobrow, 1992) or (Jackson et al, 1991).
In formal experiments (as we discuss subsequently)
the Semantic Linker has been show to dramatically im-
prove Delphi&apos;s performance.
</bodyText>
<sectionHeader confidence="0.997283" genericHeader="method">
4 Quantification
</sectionHeader>
<bodyText confidence="0.999902363636364">
The quantifier scoping module in Delphi takes a se-
mantic graph and produces a fully-scoped expression
in the logical language FMRL. The basic strategy for
quantifier scoping is a descendant of that used in the
LUNAR system (Woods et al, 1978). This is made
possible by the use of the semantic graph as a com-
mon underlying representation for both the grammatical
and ill-formed parts of fragmentary utterances. Delphi&apos;s
scoping module traps quantifiers from relative clauses,
makes the quantifiers from PPs etc. outscope the NP
quantifier, and resolves the scope of quantifiers from
parallel constituents in terms of left-to-right order in
the input. These general rules are modified to take into
account differing strengths of quantifiers such as EACH.
Left-to-right ordering and syntactic structure for
grammatical portions of the utterance are recovered
from the semantic graph by backpointers to the lexical
items and grammatical relations from which the graph
was produced. Links established by the semantic linker
are treated by the quantification mechanism as if the
constituency is indeterminate, so that only left-to-right
scoping rules and individual quantifier preferences take
effect.
The resulting mechanism is robust, and quantifica-
tional scoping has been an insignificant source of error
in the official ARPA blind-test evaluations of the ATIS
system. More complex strategies have been proposed
and implemented in the last two decades, and could in
principle be modified to work with ill-formed input, but
the simple and robust LUNAR approach handles essen-
tially all the phenomena seen in the tens of thousands of
sentences of ATIS training collected during experiments
with non-linguist users.
</bodyText>
<sectionHeader confidence="0.999057" genericHeader="method">
5 Discourse
</sectionHeader>
<bodyText confidence="0.998827346938776">
The discourse mechanism of Delphi consists of several
components: resolution of local ambiguities, pronomi-
nal and deictic antecedent resolution, ellipsis handling
and discourse constraint propagation.
The most common case of local ambiguity in the
ATIS domain involves temporal phrases as in &amp;quot;the nine
o&apos;clock flight&amp;quot;. The resolution mechanism searches
both for linguistic information in the current and previ-
ous sentences, as well as properties of entities in previ-
ous answers, to resolve whether &amp;quot;nine o&apos;clock&amp;quot; is AM
or PM.
The pronoun/deictic resolution mechanism used in
Delphi makes use of locally expressed or implied se-
mantic constraints to search through a set of candidate
antecedents. The current mechanism ignores syntac-
tic number as a cue, because empirically in the ATIS
corpus (and we suspect in other spontaneous speech ap-
plications) it is often in error. A simple-minded focus
component is used, primarily based on recency, and sec-
ondarily based on grammatical relations within an utter-
ance. Because of the strength of semantic cues and the
prevalence of ill-formed input, the use of syntactic cues
for focus is limited.
The interpretation of later sentences often must in-
clude information from previous sentences, without ex-
plicit linguistic cues. This is especially true in &amp;quot;design
dialogues&amp;quot;, where the goal is to find a description of
a set of objects that will meet some set of implicit or
explicit constraints. Consider for example the following
discourse from the ATIS domain.
Show Delta flights from Boston to Dallas tomorrow.
Can I leave in the morning?
Is there a nonstop flight?
Show me the American flights.
I want to go from Dallas to Chicago on Wednesday
Note that the constraints of prior sentences (such as on
airline, origin, destination etc.) are implicit for subse-
quent sentences unless contradicted by information in
the current sentence (e.g. &amp;quot;American&amp;quot; overrides the
&amp;quot;Delta&amp;quot; from the first sentence) or until there is evidence
that a new problem is being solved (the new origin and
destination in the last sentence indicates that all previ-
ous constraints can be dropped). Delphi has a &amp;quot;context
tracker&amp;quot; that maintains a stack of the constraints from
previous utterances, and has a set of rules for when
constraints are to be modified or deleted before being
merged with the current sentence.
Finally, we handle ellipsis as a special case of seman-
tic linking. If we have the two utterances:
</bodyText>
<page confidence="0.99758">
135
</page>
<bodyText confidence="0.999579555555556">
Show me the meals on the morning flight.
on American at 12:30
We can treat these as if they were one run-on ill-
formed input and link &amp;quot;American&amp;quot; to &amp;quot;flight&amp;quot;, and re-
place &amp;quot;morning&amp;quot; with &amp;quot;12:30&amp;quot;, using a minor variant of
the Semantic Linker linker which allows for later con-
straints to overwrite earlier ones of the same type. This
strategy has been very effective, and covers a large class
of elliptical constructions.
</bodyText>
<sectionHeader confidence="0.964233" genericHeader="method">
6 Backend Mapping
</sectionHeader>
<bodyText confidence="0.939376694444445">
In order to get a response to a user query, the complete
FMRL interpretation of an utterance must be translated
to an expression of a target query language which can be
evaluated directly against the tabular database to retrieve
the answer.
A key step is bridging the gap in conceptual vo-
cabulary between the two representations. For exam-
ple, the FMRL interpretation of the query &amp;quot;How many
flights on Delta serve meals&amp;quot; has one-place predicates
like FLIGHT and AIRLINE, and two-place predicates
like AIRLINE-OF and MEAL-OF. The database for the
ATIS domain, on the other hand, only has a single table
FLIGHT with fields containing airline and meal infor-
mation. Delphi bridges this gap between representations
with a system of local mapping rules which translate
the one- and two-place predicates of the FMRL into ex-
pressions of a relational algebra target language which
retrieve the extensions of these predicates.
Sometimes, however, some combination of FMRL
predicates has a correspondence in the database but the
individual predicates themselves do not. For example,
in the database for the SPLINT domain a table relating
aircraft-types to their physical characteristics has a field
for the number of engines the aircraft has, but no rep-
resentation for the engines themselves. If we now ask
&amp;quot;How many engines does an F-16 have?&amp;quot;, there is no
local translation of the FMRL predicate ENGINE.
To deal with this, Delphi has a system of global trans-
formations that are applied first, rewriting subsets of the
FMRL clauses to a form that can be handled with local
translation. The rule that handles this example is:
(is-a :e engine number)
(aircraft-engine-of :a :e)
—■
(is-a *count* number)
(eq (number-engines-of :a) *count*)
</bodyText>
<sectionHeader confidence="0.989349" genericHeader="method">
7 Interface To A Speech Recognizer
</sectionHeader>
<bodyText confidence="0.9998908">
In spoken language applications, Delphi is interfaced
to the output of the Byblos speech recognition system
(Bates et al, 1993). The N-best paradigm is used, in
which the recognizer outputs in order its top N guesses
at the transcription of the sentence, for some value of N
(usually 5). Delphi then runs over these transcriptions in
the order they have been ranked, first with the Semantic
Linker disabled so that only grammatical utterances are
allowed, and if none is found, runs over them again
with the Semantic Linker enabled.
</bodyText>
<sectionHeader confidence="0.99561" genericHeader="method">
8 Results Of Formal Evaluation On ATIS
</sectionHeader>
<bodyText confidence="0.99995628">
Our complete system including the Semantic Linker was
evaluated in the December 1993 ARPA ATIS evalua-
tion. Prior to evaluation, ATIS versions of the system&apos;s
domain model, lexicon and realization rules had been
developed using several thousand utterances of training
data collected from users of ATIS. An approximately
1000-utterance set was held aside as a blind test set on
which all participating sites were evaluated.
Error rate in this evaluation was defined as F+NA,
where F was the percentage of queries answered incor-
rectly, and NA the percentage of queries not answered
at all. There were two evaluations on the same corpus
using this metric: one of NL text understanding alone,
and the other of a complete spoken language system
(SLS) comprised of Delphi and the Byblos recognizer.
Our system achieved an official result of 14.7% on the
NL test, which was the third-lowest error rate achieved.
The SLS error rate was 17.5%.
Our own experiments show that using the Semantic
Linker reduced our system&apos;s error rate on the NL test by
43%. This was largely achieved by dramatically low-
ering the no-answer rate NA from 18.7% to 2.3%. Just
over 80% of this increment of sentences answered were
answered correctly, so the Linker showed considerable
accuracy.
</bodyText>
<sectionHeader confidence="0.94931" genericHeader="method">
9 Porting Delphi to the SPLINT Domain
</sectionHeader>
<bodyText confidence="0.99804244">
The SPLINT (Speech and Language Integration) do-
main is concerned with Air Force units and their com-
ponent aircraft, weaponry and other physical attributes
of aircraft, ordnance, and facilities (such as air bases,
runways, bunkers, etc.). The SPLINT database has 106
fields in 23 tables.
Some example utterances in the SPLINT domain are:
What aircraft types are assigned to the 32nd?
Which base has a unit carrying mavericks?
Can a Stealth use Langley&apos;s runway 1?
In order to port Delphi to the SPLINT domain,
SPLINT-specific versions of the domain model, lexicon,
realization rules and db-mapping rules were needed. For
the speech-understanding part of the application, word
pronunciations were also neccesary, as well as word-
class membership for a statistical n-gram class gram-
mar. Delphi includes &amp;quot;core&amp;quot; versions of some of these
knowledge bases: a core domain model with common
classes like NUMBER and TIME-OF-DAY and rela-
tions like GREATER, a core lexicon with closed-class
items such as prepositions as well as words appropri-
ate to question-answering in general such as &amp;quot;show&amp;quot;, to
which domain-specific items have to be added.
In porting to SPLINT, 60 classes and 65 relations
were added to the domain model. 400 words were added
</bodyText>
<page confidence="0.996365">
136
</page>
<bodyText confidence="0.99983185">
to the lexicon. Of these, approximately half were de-
rived from database field values. 118 realization rules
were added.
The grammar did not need to be modified, with the
exception of adding one rule (for constructions such as
&amp;quot;Mach 1&amp;quot;).
The entire process took about a person month to get
90% coverage on a 1400 sentence corpus, developed in-
dependently by a non-NL person. An additional person
week was required to develop the speech-related knowl-
edge bases. A complete spoken language system with
Delphi as the understanding component, plus a Motif-
based user interface, was succesfully demonstrated at
the 1994 ARPA Human Language Technology meeting,
and at Rome Labs in New York. The porting process is
described in more detail in (Bates, 1994).
This effort demonstrates that, given an appropriate
system design, it is possible to build a complete spoken
language system that is robust to speech and production
errors, and to do so rapidly and straightforwardly.
</bodyText>
<sectionHeader confidence="0.988969" genericHeader="conclusions">
10 Conclusion And Summary
</sectionHeader>
<bodyText confidence="0.99997225">
In conclusion, we have developed a technology that
makes maximal use of general linguistic knowledge to
improve portability, while at the same time maintaining
robustness in the face of the type of input one can ex-
pect from a real-life spoken language application. The
system has been shown to reach high levels of perfor-
mance in objective blind-test evaluation on the ATIS
domain. The system has also been shown to be rapidly
portable to a new domain, SPLINT. This did not re-
quire any changes in the underlying system code, and
was done with a relatively small effort.
This work shows that computational linguistic meth-
ods, based on general knowledge of language, can be
used in large, robust spoken language systems, and that
special-purpose NL understanding systems do not have
to be built for each new task.
</bodyText>
<sectionHeader confidence="0.991566" genericHeader="acknowledgments">
11 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999568666666667">
The work reported here was supported by the Advanced
Research Projects Agency and was monitored by the
Office of Naval Research under Contract No. N00014-
92-C-0035. The views and conclusions contained in this
document are those of the authors and should not be in-
terpreted as necessarily representing the official policies,
either expressed or implied, of the Defense Advanced
Research Projects Agency or the United States Govern-
ment.
</bodyText>
<sectionHeader confidence="0.999632" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999651714285714">
Ades, A. E. and Steedman, M. J. 1982. On the Order
of Words. In Linguistics and Philosophy 44.3, 1982,
pp. 517-558.
Alshawi, Hiyan (ed). 1992. The Core Language Engine,
MIT Press, Cambridge.
Bates, Madeleine et al. 1993. The BBN/HARC Spoken
Language Understanding System. In Proceedings of
IEEE ICASSP-93 Minneapolis, MN, April 1993, pp.
111-114, vol. II.
Bates, M. Beginning to Port a Spoken Language
Database Interface In 4th Annual Dual Use Tech-
nologies and Applications Conference, Utica NY May
1994
Bobrow, Robert. 1991. Statistical Agenda Parsing
In Proceedings 4th DARPA Workshop on Speech and
Natural Language
Dowding, John et al. Gemini: A Natural Language
Understanding System for Spoken Language Under-
standing. In Proceedings of the 31st Annual Meet-
ing of the Association for Computational Linguistics,
Columbus, OH
Jackson, Eric, Appelt, Douglas, Bear, John, Moore,
Robert, and A. Podlozny. A Template Matcher for
Robust NL Interpretation. In Proceedings Speech and
Natural Language Workshop February 1991
Pereira, F. C. N. and Warren, D. H. D. 1980. Definite
Clause Grammars for Language Analysis—A Survey
of the Formalism and a Comparison with Augmented
Transition Networks. In Artificial Intelligence 13,
1980, pp. 231-278.
Schabes, Y., Abeille, A., and Joshi, A. K. Parsing
Strategies with `Lexicalized&apos; Grammars&apos;: Applica-
tion to Tree Adjoining Grammars. 1988 In COLING
Budapest: PROCEEDINGS of the 12th International
Conference on Computational Linguistics, Associa-
tion for Computational Linguistics, Morristown, NJ,
1988, pp. 578-583.
Shieber, S. M. 1986. An Introduction to Unification-
Based Approaches to Grammar. Center for the Study
of Language and Information, Stanford, CA, 1986.
Stallard, David and Bobrow, Robert. 1991. The
Mapping Unit Approach to Subcategorization. In
Proceedings Speech and Natural Language Workshop
March 1991
Stallard, David and Bobrow, Robert. 1992. Fragment
Processing in the DELPHI System. In Proceedings
Speech and Natural Language Workshop February
1992
Stallard, David and Bobrow, Robert. 1993. The Seman-
tic Linker – a New Fragment Combining Method. In
Proceedings Human Language Technology Workshop
March 1993
Woods, William A., Kaplan, Robert A., and Nash-
Webber, B. 1978. The Lunar Sciences Natural Lan-
guage Information System: Final Report. Report
2378, Bolt, Beranek and Newman, Cambridge, MA.
</reference>
<page confidence="0.997827">
137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.989796">
<title confidence="0.999907">The Delphi Natural Language Understanding System</title>
<author confidence="0.999939">Madeleine Bates</author>
<author confidence="0.999939">Robert Bobrow</author>
<author confidence="0.999939">Robert Ingria</author>
<author confidence="0.999939">David Stallard</author>
<affiliation confidence="0.999563">BBN Systems and Technologies, Inc.</affiliation>
<address confidence="0.999251">70 Fawcett St. Cambridge, MA 02138</address>
<abstract confidence="0.999581333333334">This paper presents Delphi, the natural language component of the BBN Spoken Language System. Delphi is a domainindependent natural language question answering system that is solidly based on linguistic principles, yet which is also robust to ungrammatical input. It includes a domain-independent, broad-coverage grammar of English. Analysis components include an agenda-based best-first parser and a fallback component for partial understanding that works by fragment combination. Delphi has been formally evaluated in the ARPA Spoken Language program&apos;s ATIS (Airline Travel Information System) domain, and has performed well. Delphi has also been ported to a spoken language demonstration system in an Air Force Resource Management domain. We discuss results of the evaluation as well as the porting process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the Order of Words.</title>
<date>1982</date>
<journal>In Linguistics and Philosophy</journal>
<volume>44</volume>
<pages>517--558</pages>
<contexts>
<context position="7052" citStr="Ades and Steedman, 1982" startWordPosition="1082" endWordPosition="1085"> be separated from the head by a modifier typically regarded as an adjunct: What flights fly at 3 pm from Boston to Denver? In some cases, modifiers can be omitted, as in: What flights fly from Boston? What flights fly to Denver? and sometimes the omission of an argument can have anaphoric consequences, as in: What restrictions apply? which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could &amp;quot;apply&amp;quot; to. Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980), Categorial Grarmnar (Ades and Steedman, 1982), PATR-II (Shieber, 1986), and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of &amp;quot;subcategorization frame&amp;quot; that specifies a sequence of complement phrases and constraints on them. Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoin</context>
</contexts>
<marker>Ades, Steedman, 1982</marker>
<rawString>Ades, A. E. and Steedman, M. J. 1982. On the Order of Words. In Linguistics and Philosophy 44.3, 1982, pp. 517-558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>The Core Language Engine,</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, Hiyan (ed). 1992. The Core Language Engine, MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Madeleine Bates</author>
</authors>
<title>The BBN/HARC Spoken Language Understanding System. In</title>
<date>1993</date>
<booktitle>Proceedings of IEEE ICASSP-93</booktitle>
<pages>111--114</pages>
<publisher>II.</publisher>
<location>Minneapolis, MN,</location>
<marker>Bates, 1993</marker>
<rawString>Bates, Madeleine et al. 1993. The BBN/HARC Spoken Language Understanding System. In Proceedings of IEEE ICASSP-93 Minneapolis, MN, April 1993, pp. 111-114, vol. II.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bates</author>
</authors>
<title>Beginning to Port a Spoken Language Database Interface</title>
<date>1994</date>
<booktitle>In 4th Annual Dual Use Technologies and Applications Conference,</booktitle>
<location>Utica NY</location>
<contexts>
<context position="24433" citStr="Bates, 1994" startWordPosition="3899" endWordPosition="3900">d not need to be modified, with the exception of adding one rule (for constructions such as &amp;quot;Mach 1&amp;quot;). The entire process took about a person month to get 90% coverage on a 1400 sentence corpus, developed independently by a non-NL person. An additional person week was required to develop the speech-related knowledge bases. A complete spoken language system with Delphi as the understanding component, plus a Motifbased user interface, was succesfully demonstrated at the 1994 ARPA Human Language Technology meeting, and at Rome Labs in New York. The porting process is described in more detail in (Bates, 1994). This effort demonstrates that, given an appropriate system design, it is possible to build a complete spoken language system that is robust to speech and production errors, and to do so rapidly and straightforwardly. 10 Conclusion And Summary In conclusion, we have developed a technology that makes maximal use of general linguistic knowledge to improve portability, while at the same time maintaining robustness in the face of the type of input one can expect from a real-life spoken language application. The system has been shown to reach high levels of performance in objective blind-test eval</context>
</contexts>
<marker>Bates, 1994</marker>
<rawString>Bates, M. Beginning to Port a Spoken Language Database Interface In 4th Annual Dual Use Technologies and Applications Conference, Utica NY May 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Bobrow</author>
</authors>
<title>Statistical Agenda Parsing</title>
<date>1991</date>
<booktitle>In Proceedings 4th DARPA Workshop on Speech and Natural Language</booktitle>
<contexts>
<context position="8108" citStr="Bobrow, 1991" startWordPosition="1255" endWordPosition="1256">g to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic graph node. Different types of constraints — order of arguments, optionality of arguments, semantic-class constraints and semantic effects of arguments — can all be represented separately, instead of enumerating all possible argument sequences in a set of alternative subcategorization frames. FLY 133 Subcategorization constraints in Delphi are encoded in lexical entries using a structure called a &amp;quot;map&amp;quot; (Stallard and Bobrow, 1991). Below is part of the lexical entry for &amp;quot;fly&amp;quot; in the ATIS domain: FLY subject: FLIGHT-OF to: DEST-OF from: ORIG-OF completion: (and (filled flight-of) (or (filled dest-of) (filled orig-of)) Map entries have &amp;quot;translation&amp;quot;, &amp;quot;realization&amp;quot; and &amp;quot;completion&amp;quot; components. The translation part of this entry specifies that the lexical head &amp;quot;fly&amp;quot; is to correspond to a semantic-graph node labeled with event-class FLY. The realization part of the entry specifies what grammatical relations the lexical item takes, and what semantic relations these correspond to, or &amp;quot;realize&amp;quot;, in the semantic graph. Here, th</context>
<context position="11043" citStr="Bobrow, 1991" startWordPosition="1718" endWordPosition="1719">ation for it that is compatible with the classes of X and Y. This avoids having to write three different versions of the same realization rule. BOSTON:TO DENVER airline-of DELTA FLI MONDAY:ON day-of-week Figure 3: Fragment Graphs An important advantage of the realization rule formulation, apart from its its power and flexibility, is its simplicity. Realization rules are very simple to write, and make maximal use both of knowledge about the domain and general knowledge of language. 3 Ill-Formedness Handling: The Semantic Linker When an utterance cannot be parsed with Delphi&apos;s bestfirst parser (Bobrow, 1991) — either because it is illformed, mis-recognized by the speech system, or simply because it is outside the coverage of the grammar — it can still be partially understood by the system, often well enough to give the correct response. The component responsible for partial understanding in the Delphi system is called the Semantic Linker (Stallard and Bobrow, 1993). After a parse fails there is a set of fragmentary constituents left over in the chart, corresponding to a set of semantic graphs. The Semantic Linker seeks to connect these sub-graphs into a single connected one by adding links betwee</context>
</contexts>
<marker>Bobrow, 1991</marker>
<rawString>Bobrow, Robert. 1991. Statistical Agenda Parsing In Proceedings 4th DARPA Workshop on Speech and Natural Language</rawString>
</citation>
<citation valid="false">
<authors>
<author>John Dowding</author>
</authors>
<title>Gemini: A Natural Language Understanding System for Spoken Language Understanding.</title>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Columbus, OH</location>
<marker>Dowding, </marker>
<rawString>Dowding, John et al. Gemini: A Natural Language Understanding System for Spoken Language Understanding. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, Columbus, OH</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Jackson</author>
<author>Douglas Appelt</author>
<author>John Bear</author>
<author>Robert Moore</author>
<author>A Podlozny</author>
</authors>
<title>A Template Matcher for Robust NL Interpretation.</title>
<date>1991</date>
<booktitle>In Proceedings Speech and Natural Language Workshop</booktitle>
<contexts>
<context position="14078" citStr="Jackson et al, 1991" startWordPosition="2227" endWordPosition="2230">he semantic linker may also &amp;quot;hallucinate&amp;quot; a new node to bridge two fragments between whom no links can otherwise be computed. For example, for the utterance &amp;quot;from Boston to Denver&amp;quot;, which has no explicit FLIGHT-object, a FLIGHT node can be inserted between the fragments to make sense of the utterance. Because the Semantic Linker uses the same set of realization rules as the rest of the system, when the system is ported to a new domain the Semantic Linker can be used immediately - a distinct advantage over some other approaches to fallback understanding, such as (Stallard and Bobrow, 1992) or (Jackson et al, 1991). In formal experiments (as we discuss subsequently) the Semantic Linker has been show to dramatically improve Delphi&apos;s performance. 4 Quantification The quantifier scoping module in Delphi takes a semantic graph and produces a fully-scoped expression in the logical language FMRL. The basic strategy for quantifier scoping is a descendant of that used in the LUNAR system (Woods et al, 1978). This is made possible by the use of the semantic graph as a common underlying representation for both the grammatical and ill-formed parts of fragmentary utterances. Delphi&apos;s scoping module traps quantifier</context>
</contexts>
<marker>Jackson, Appelt, Bear, Moore, Podlozny, 1991</marker>
<rawString>Jackson, Eric, Appelt, Douglas, Bear, John, Moore, Robert, and A. Podlozny. A Template Matcher for Robust NL Interpretation. In Proceedings Speech and Natural Language Workshop February 1991</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
<author>D H D Warren</author>
</authors>
<title>Definite Clause Grammars for Language Analysis—A Survey of the Formalism and a Comparison with Augmented Transition Networks.</title>
<date>1980</date>
<journal>In Artificial Intelligence</journal>
<volume>13</volume>
<pages>231--278</pages>
<contexts>
<context position="4190" citStr="Pereira and Warren, 1980" startWordPosition="624" endWordPosition="628">ion translations are simple, the task of porting the system is greatly simplified. Third and finally, partial or fragmentary analyses can be represented, and a complete semantic graph interpretation for the utterance produced even when a complete syntactic analyses is not available. In the remainder of the paper, we describe Delphi&apos;s main processing components, representational formalisms, and knowledge bases. 2 Grammar And The Syntax/Semantics Interface The Delphi grammar is a broad coverage, domain independent grammar of English written in a version of the Definite Clause Grammar formalism (Pereira and Warren, 1980) that has been extended to include labeling of right-hand side elements with the grammatical relations they bear to the head of the construction. An example is: (S ?arg ?mood) -&gt; subject: (NP ?arg ?mood etc.) head: (VP ?agr ?mood etc.) In this rule, there is a head VP and an NP which bears the SUBJECT relation to it. Other grammatical relations include the familar DIRECT-OBJECT and INDIRECT-OBJECT as well as the prepositions, such as TO, FROM, WITH and so on. Annotating sub-constituents with grammatical relations regularizes the syntactic structure with respect to particular grammatical rules,</context>
<context position="7005" citStr="Pereira and Warren, 1980" startWordPosition="1076" endWordPosition="1079">nver? What flights fly to Denver from Boston? or be separated from the head by a modifier typically regarded as an adjunct: What flights fly at 3 pm from Boston to Denver? In some cases, modifiers can be omitted, as in: What flights fly from Boston? What flights fly to Denver? and sometimes the omission of an argument can have anaphoric consequences, as in: What restrictions apply? which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could &amp;quot;apply&amp;quot; to. Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980), Categorial Grarmnar (Ades and Steedman, 1982), PATR-II (Shieber, 1986), and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of &amp;quot;subcategorization frame&amp;quot; that specifies a sequence of complement phrases and constraints on them. Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexi</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, F. C. N. and Warren, D. H. D. 1980. Definite Clause Grammars for Language Analysis—A Survey of the Formalism and a Comparison with Augmented Transition Networks. In Artificial Intelligence 13, 1980, pp. 231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A Abeille</author>
<author>A K Joshi</author>
</authors>
<title>Parsing Strategies with `Lexicalized&apos; Grammars&apos;: Application to Tree Adjoining Grammars.</title>
<date>1988</date>
<booktitle>In COLING Budapest: PROCEEDINGS of the 12th International Conference on Computational Linguistics, Association for Computational Linguistics,</booktitle>
<pages>578--583</pages>
<location>Morristown, NJ,</location>
<contexts>
<context position="7120" citStr="Schabes et al, 1988" startWordPosition="1092" endWordPosition="1095">ct: What flights fly at 3 pm from Boston to Denver? In some cases, modifiers can be omitted, as in: What flights fly from Boston? What flights fly to Denver? and sometimes the omission of an argument can have anaphoric consequences, as in: What restrictions apply? which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could &amp;quot;apply&amp;quot; to. Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980), Categorial Grarmnar (Ades and Steedman, 1982), PATR-II (Shieber, 1986), and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of &amp;quot;subcategorization frame&amp;quot; that specifies a sequence of complement phrases and constraints on them. Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic graph node. Different types of constraints — </context>
</contexts>
<marker>Schabes, Abeille, Joshi, 1988</marker>
<rawString>Schabes, Y., Abeille, A., and Joshi, A. K. Parsing Strategies with `Lexicalized&apos; Grammars&apos;: Application to Tree Adjoining Grammars. 1988 In COLING Budapest: PROCEEDINGS of the 12th International Conference on Computational Linguistics, Association for Computational Linguistics, Morristown, NJ, 1988, pp. 578-583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>An Introduction to UnificationBased Approaches to Grammar. Center for the Study of Language and Information,</title>
<date>1986</date>
<location>Stanford, CA,</location>
<contexts>
<context position="7077" citStr="Shieber, 1986" startWordPosition="1087" endWordPosition="1088">difier typically regarded as an adjunct: What flights fly at 3 pm from Boston to Denver? In some cases, modifiers can be omitted, as in: What flights fly from Boston? What flights fly to Denver? and sometimes the omission of an argument can have anaphoric consequences, as in: What restrictions apply? which cannot be felicitously uttered except in a context where there is something in the discourse that a restriction could &amp;quot;apply&amp;quot; to. Conventional approaches to subcategorization, such as Definite Clause Grammar (Pereira and Warren, 1980), Categorial Grarmnar (Ades and Steedman, 1982), PATR-II (Shieber, 1986), and lexicalized TAG (Schabes et al, 1988) all deal with complementation by including in one form or another a notion of &amp;quot;subcategorization frame&amp;quot; that specifies a sequence of complement phrases and constraints on them. Handling all the possible variations in complement distribution in such formalisms inevitably leads to an explosion in the number of such frames, and a correspondingly more difficult task in porting to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic gr</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, S. M. 1986. An Introduction to UnificationBased Approaches to Grammar. Center for the Study of Language and Information, Stanford, CA, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Stallard</author>
<author>Robert Bobrow</author>
</authors>
<title>The Mapping Unit Approach to Subcategorization.</title>
<date>1991</date>
<booktitle>In Proceedings Speech and Natural Language Workshop</booktitle>
<contexts>
<context position="8108" citStr="Stallard and Bobrow, 1991" startWordPosition="1252" endWordPosition="1256">ask in porting to a new domain. In our approach, on the other hand, it becomes possible to view subcategorization of a lexical item as a set of constraints on the outgoing arcs of its semantic graph node. Different types of constraints — order of arguments, optionality of arguments, semantic-class constraints and semantic effects of arguments — can all be represented separately, instead of enumerating all possible argument sequences in a set of alternative subcategorization frames. FLY 133 Subcategorization constraints in Delphi are encoded in lexical entries using a structure called a &amp;quot;map&amp;quot; (Stallard and Bobrow, 1991). Below is part of the lexical entry for &amp;quot;fly&amp;quot; in the ATIS domain: FLY subject: FLIGHT-OF to: DEST-OF from: ORIG-OF completion: (and (filled flight-of) (or (filled dest-of) (filled orig-of)) Map entries have &amp;quot;translation&amp;quot;, &amp;quot;realization&amp;quot; and &amp;quot;completion&amp;quot; components. The translation part of this entry specifies that the lexical head &amp;quot;fly&amp;quot; is to correspond to a semantic-graph node labeled with event-class FLY. The realization part of the entry specifies what grammatical relations the lexical item takes, and what semantic relations these correspond to, or &amp;quot;realize&amp;quot;, in the semantic graph. Here, th</context>
</contexts>
<marker>Stallard, Bobrow, 1991</marker>
<rawString>Stallard, David and Bobrow, Robert. 1991. The Mapping Unit Approach to Subcategorization. In Proceedings Speech and Natural Language Workshop March 1991</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Stallard</author>
<author>Robert Bobrow</author>
</authors>
<title>Fragment Processing in the DELPHI System.</title>
<date>1992</date>
<booktitle>In Proceedings Speech and Natural Language Workshop</booktitle>
<contexts>
<context position="14053" citStr="Stallard and Bobrow, 1992" startWordPosition="2222" endWordPosition="2225"> by the relation AIRLINE-OF). The semantic linker may also &amp;quot;hallucinate&amp;quot; a new node to bridge two fragments between whom no links can otherwise be computed. For example, for the utterance &amp;quot;from Boston to Denver&amp;quot;, which has no explicit FLIGHT-object, a FLIGHT node can be inserted between the fragments to make sense of the utterance. Because the Semantic Linker uses the same set of realization rules as the rest of the system, when the system is ported to a new domain the Semantic Linker can be used immediately - a distinct advantage over some other approaches to fallback understanding, such as (Stallard and Bobrow, 1992) or (Jackson et al, 1991). In formal experiments (as we discuss subsequently) the Semantic Linker has been show to dramatically improve Delphi&apos;s performance. 4 Quantification The quantifier scoping module in Delphi takes a semantic graph and produces a fully-scoped expression in the logical language FMRL. The basic strategy for quantifier scoping is a descendant of that used in the LUNAR system (Woods et al, 1978). This is made possible by the use of the semantic graph as a common underlying representation for both the grammatical and ill-formed parts of fragmentary utterances. Delphi&apos;s scopin</context>
</contexts>
<marker>Stallard, Bobrow, 1992</marker>
<rawString>Stallard, David and Bobrow, Robert. 1992. Fragment Processing in the DELPHI System. In Proceedings Speech and Natural Language Workshop February 1992</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Stallard</author>
<author>Robert Bobrow</author>
</authors>
<title>The Semantic Linker – a New Fragment Combining Method.</title>
<date>1993</date>
<booktitle>In Proceedings Human Language Technology Workshop</booktitle>
<contexts>
<context position="11407" citStr="Stallard and Bobrow, 1993" startWordPosition="1778" endWordPosition="1782">Realization rules are very simple to write, and make maximal use both of knowledge about the domain and general knowledge of language. 3 Ill-Formedness Handling: The Semantic Linker When an utterance cannot be parsed with Delphi&apos;s bestfirst parser (Bobrow, 1991) — either because it is illformed, mis-recognized by the speech system, or simply because it is outside the coverage of the grammar — it can still be partially understood by the system, often well enough to give the correct response. The component responsible for partial understanding in the Delphi system is called the Semantic Linker (Stallard and Bobrow, 1993). After a parse fails there is a set of fragmentary constituents left over in the chart, corresponding to a set of semantic graphs. The Semantic Linker seeks to connect these sub-graphs into a single connected one by adding links between nodes in the different sub-graphs. At top-level, this is the same thing that the parser and grammar do. The difference is that the parser and grammar have an idea of what the grammatical relationship between constituents is, based on requirements of their proximity in the string and other syntactic evidence. The Semantic Linker does not have these requirements</context>
</contexts>
<marker>Stallard, Bobrow, 1993</marker>
<rawString>Stallard, David and Bobrow, Robert. 1993. The Semantic Linker – a New Fragment Combining Method. In Proceedings Human Language Technology Workshop March 1993</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
<author>Robert A Kaplan</author>
<author>B NashWebber</author>
</authors>
<title>The Lunar Sciences Natural Language Information System: Final Report.</title>
<date>1978</date>
<tech>Report 2378,</tech>
<location>Bolt, Beranek and Newman, Cambridge, MA.</location>
<contexts>
<context position="14470" citStr="Woods et al, 1978" startWordPosition="2289" endWordPosition="2292">m, when the system is ported to a new domain the Semantic Linker can be used immediately - a distinct advantage over some other approaches to fallback understanding, such as (Stallard and Bobrow, 1992) or (Jackson et al, 1991). In formal experiments (as we discuss subsequently) the Semantic Linker has been show to dramatically improve Delphi&apos;s performance. 4 Quantification The quantifier scoping module in Delphi takes a semantic graph and produces a fully-scoped expression in the logical language FMRL. The basic strategy for quantifier scoping is a descendant of that used in the LUNAR system (Woods et al, 1978). This is made possible by the use of the semantic graph as a common underlying representation for both the grammatical and ill-formed parts of fragmentary utterances. Delphi&apos;s scoping module traps quantifiers from relative clauses, makes the quantifiers from PPs etc. outscope the NP quantifier, and resolves the scope of quantifiers from parallel constituents in terms of left-to-right order in the input. These general rules are modified to take into account differing strengths of quantifiers such as EACH. Left-to-right ordering and syntactic structure for grammatical portions of the utterance </context>
</contexts>
<marker>Woods, Kaplan, NashWebber, 1978</marker>
<rawString>Woods, William A., Kaplan, Robert A., and NashWebber, B. 1978. The Lunar Sciences Natural Language Information System: Final Report. Report 2378, Bolt, Beranek and Newman, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>