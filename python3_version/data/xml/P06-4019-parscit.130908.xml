<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.125829">
<title confidence="0.990883">
Outilex, a Linguistic Platform for Text Processing
</title>
<author confidence="0.997042">
Olivier Blanc
</author>
<affiliation confidence="0.993387">
IGM, University of Marne-la-Vall´ee
</affiliation>
<address confidence="0.8707415">
5, bd Descartes - Champs/Marne
77454 Marne-la-Vall´ee, France
</address>
<email confidence="0.911584">
oblanc@univ-mlv.fr
</email>
<author confidence="0.977558">
Matthieu Constant
</author>
<affiliation confidence="0.982023">
IGM, University of Marne-la-Vall´ee
</affiliation>
<address confidence="0.910296">
5, bd Descartes - Champs/Marne
77 454 Marne-la-Vall´ee, france
</address>
<email confidence="0.944582">
mconstan@univ-mlv.fr
</email>
<sectionHeader confidence="0.991647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998715">
We present Outilex, a generalist linguis-
tic platform for text processing. The plat-
form includes several modules implement-
ing the main operations for text processing
and is designed to use large-coverage Lan-
guage Resources. These resources (dictio-
naries, grammars, annotated texts) are for-
matted into XML, in accordance with cur-
rent standards. Evaluations on efficiency
are given.
</bodyText>
<sectionHeader confidence="0.993447" genericHeader="keywords">
1 Credits
</sectionHeader>
<bodyText confidence="0.98876">
This project has been supported by the French
Ministry of Industry and the CNRS. Thanks to Sky
and Francesca Sigal for their linguistic expertise.
</bodyText>
<sectionHeader confidence="0.998282" genericHeader="introduction">
2 Introduction
</sectionHeader>
<bodyText confidence="0.999924770833333">
The Outilex Project (Blanc et al., 2006) aims to de-
velop an open-linguistic platform, including tools,
electronic dictionaries and grammars, dedicated to
text processing. It is the result of the collaboration
of ten French partners, composed of 4 universities
and 6 industrial organizations. The project started
in 2002 and will end in 2006. The platform which
will be made freely available to research, develop-
ment and industry in April 2007, comprises soft-
ware components implementing all the fundamen-
tal operations of written text processing: text seg-
mentation, morphosyntactic tagging, parsing with
grammars and language resource management.
All Language Resources are structured in XML
formats, as well as binary formats more adequate
to efficient processing; the required format con-
verters are included in the platform. The grammar
formalism allows for the combination of statis-
tical approaches with resource-based approaches.
Manually constructed lexicons of substantial cov-
erage for French and English, originating from the
former LADL1, will be distributed with the plat-
form under LGPL-LR2 license.
The platform aims to be a generalist base for di-
verse processings on text corpora. Furthermore, it
uses portable formats and format converters that
would allow for combining several software com-
ponents. There exist a lot of platforms dedicated
to NLP, but none are fully satisfactory for various
reasons. Intex (Silberztein, 1993), FSM (Mohri et
al., 1998) and Xelda3 are closed source. Unitex
(Paumier, 2003), inspired by Intex has its source
code under LGPL license4 but it does not support
standard formats for Language Resources (LR).
Systems like NLTK (Loper and Bird, 2002) and
Gate (Cunningham, 2002) do not offer functional-
ity for Lexical Resource Management.
All the operations described below are imple-
mented in C++ independent modules which in-
teract with each others through XML streams.
Each functionality is accessible by programmers
through a specified API and by end users through
binary programs. Programs can be invoked by
a Graphical User Interface implemented in Java.
This interface allows the user to define his own
processing flow as well as to work on several
projects with specific texts, dictionaries and gram-
mars.
</bodyText>
<footnote confidence="0.999509857142857">
1French Laboratory for Linguistics and Information Re-
trieval
2Lesser General Public License for Language Resources,
http://infolingu.univ-mlv.fr/lgpllr.html.
3http://www.dcs.shef.ac.uk/ hamish/dalr/baslow/xelda.pdf.
4Lesser General Public License,
http://www.gnu.org/copyleft/lesser.html.
</footnote>
<page confidence="0.991308">
73
</page>
<bodyText confidence="0.5595">
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 73–76,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.974395" genericHeader="method">
3 Text segmentation
</sectionHeader>
<bodyText confidence="0.999951578947369">
The segmentation module takes raw texts or
HTML documents as input. It outputs a text
segmented into paragraphs, sentences and tokens
in an XML format. The HTML tags are kept
enclosed in XML elements, which distinguishes
them from actual textual data. It is therefore pos-
sible to rebuild at any point the original docu-
ment or a modified version with its original layout.
Rules of segmentation in tokens and sentences are
based on the categorization of characters defined
by the Unicode norm. Each token is associated
with information such as its type (word, number,
punctuation, ...), its alphabet (Latin, Greek), its
case (lowercase word, capitalized word, ...), and
other information for the other symbols (opening
or closing punctuation symbol, ...). When applied
to a corpus of journalistic telegrams of 352,464
tokens, our tokenizer processes 22,185 words per
second5.
</bodyText>
<sectionHeader confidence="0.968388" genericHeader="method">
4 Morphosyntactic tagging
</sectionHeader>
<bodyText confidence="0.999929608695652">
By using lexicons and grammars, our platform in-
cludes the notion of multiword units, and allows
for the handling of several types of morphosyntac-
tic ambiguities. Usually, stochastic morphosyn-
tactic taggers (Schmid, 1994; Brill, 1995) do not
handle well such notions. However, the use of lex-
icons by companies working in the domain has
much developed over the past few years. That
is why Outilex provides a complete set of soft-
ware components handling operations on lexicons.
IGM also contributed to this project by freely dis-
tributing a large amount of the LADL lexicons6
with fine-grained tagsets7: for French, 109,912
simple lemmas and 86,337 compound lemmas; for
English, 166,150 simple lemmas and 13,361 com-
pound lemmas. These resources are available un-
der LGPL-LR license. Outilex programs are com-
patible with all European languages using inflec-
tion by suffix. Extensions will be necessary for
the other types of languages.
Our morphosyntactic tagger takes a segmented
text as an input; each form (simple or compound)
is assigned a set of possible tags, extracted from
</bodyText>
<footnote confidence="0.946830285714286">
5This test and further tests have been carried out on a PC
with a 2.8 GHz Intel Pentium Processor and a 512 Mb RAM.
6http://infolingu.univ-mlv.fr/english/, follow links Lin-
guistic data then Dictionnaries.
7For instance, for French, the tagset combines 13 part-of-
speech tags, 18 morphological features and several syntactic
and semantic features.
</footnote>
<bodyText confidence="0.99988162962963">
indexed lexicons (cf. section 6). Several lexicons
can be applied at the same time. A system of pri-
ority allows for the blocking of analyses extracted
from lexicons with low priority if the considered
form is also present in a lexicon with a higher pri-
ority. Therefore, we provide by default a general
lexicon proposing a large set of analyses for stan-
dard language. The user can, for a specific appli-
cation, enrich it by means of complementary lexi-
cons and/or filter it with a specialized lexicon for
his/her domain. The dictionary look-up can be pa-
rameterized to ignore case and diacritics, which
can assist the tagger to adapt to the type of pro-
cessed text (academic papers, web pages, emails,
...). Applied to a corpus of AFP journalistic tele-
grams with the above mentioned dictionaries, Out-
ilex tags about 6,650 words per second8.
The result of this operation is an acyclic au-
tomaton (sometimes, called word lattice in this
context), that represents segmentation and tag-
ging ambiguities. This tagged text can be serial-
ized in an XML format, compatible with the draft
model MAF (Morphosyntactic Annotation Frame-
work)(Cl´ement and de la Clergerie, 2005).
All further processing described in the next sec-
tion will be run on this automaton, possibly modi-
fying it.
</bodyText>
<sectionHeader confidence="0.991956" genericHeader="method">
5 Text Parsing
</sectionHeader>
<bodyText confidence="0.995794304347826">
Grammatical formalisms are very numerous in
NLP. Outilex uses a minimal formalism: Recur-
sive Transition Network (RTN)(Woods, 1970) that
are represented in the form of recursive automata
(automata that call other automata). The termi-
nal symbols are lexical masks (Blanc and Dister,
2004), which are underspecified word tags i.e. that
represent a set of tagged words matching with the
specified features (e.g. noun in the plural). Trans-
ductions can be put in our RTNs. This can be used,
for instance, to insert tags in texts and therefore
formalize relations between identified segments.
This formalism allows for the construction of
local grammars in the sense of (Gross, 1993).
It has been successfully used in different types
of applications: information extraction (Poibeau,
84.7 % of the token occurrences were not found in the dic-
tionary; This value falls to 0.4 % if we remove the capitalized
occurrences.
The processing time could appear rather slow; but, this task
involves not so trivial computations such as conversion be-
tween different charsets or approximated look-up using Uni-
code character properties.
</bodyText>
<page confidence="0.993626">
74
</page>
<bodyText confidence="0.999808487179487">
2001; Nakamura, 2005), named entity localization
(Krstev et al., 2005), grammatical structure iden-
tification (Mason, 2004; Danlos, 2005)). All of
these experiments resulted in recall and precision
rates equaling the state-of-the-art.
This formalism has been enhanced with weights
that are assigned to the automata transitions. Thus,
grammars can be integrated into hybrid systems
using both statistical methods and methods based
on linguistic resources. We call the obtained for-
malism Weighted Recursive Transition Network
(WRTN). These grammars are constructed in the
form of graphs with an editor and are saved in an
XML format (Sastre, 2005).
Each graph (or automaton) is optimized with
epsilon transition removal, determinization and
minimization operations. It is also possible to
transform a grammar in an equivalent or approx-
imate finite state transducer, by copying the sub-
graphs into the main automaton. The result gen-
erally requires more memory space but can highly
accelerate processing.
Our parser is based on Earley algorithm (Earley,
1970) that has been adapted to deal with WRTN
(instead of context-free grammar) and a text in the
form of an acyclic finite state automaton (instead
of a word sequence). The result of the parsing
consists of a shared forest of weighted syntactic
trees for each sentence. The nodes of the trees
are decorated by the possible outputs of the gram-
mar. This shared forest can be processed to get
different types of results, such as a list of con-
cordances, an annotated text or a modified text
automaton. By applying a noun phrase grammar
(Paumier, 2003) on a corpus of AFP journalistic
telegrams, our parser processed 12,466 words per
second and found 39,468 occurrences.
The platform includes a concordancer that al-
lows for listing in their occurring context differ-
ent occurrences of the patterns described in the
grammar. Concordances can be sorted according
to the text order or lexicographic order. The con-
cordancer is a valuable tool for linguists who are
interested in finding the different uses of linguis-
tic forms in corpora. It is also of great interest to
improve grammars during their construction.
Also included is a module to apply a transducer
on a text. It produces a text with the outputs of the
grammar inserted in the text or with recognized
segments replaced by the outputs. In the case of
a weighted grammar, weights are criteria to select
between several concurrent analyses. A criterion
on the length of the recognized sequences can also
be used.
For more complex processes, a variant of this
functionality produces an automaton correspond-
ing to the original text automaton with new transi-
tions tagged with the grammar outputs. This pro-
cess is easily iterable and can then be used for
incremental recognition and annotation of longer
and longer segments. It can also complete the mor-
phosyntactic tagging for the recognition of semi-
frozen lexical units, whose variations are too com-
plex to be enumerated in dictionaries, but can be
easily described in local grammars.
Also included is a deep syntactic parser based
on unification grammars in the decorated WRTN
formalism (Blanc and Constant, 2005). This for-
malism combines WRTN formalism with func-
tional equations on feature structures. Therefore,
complex syntactic phenomena, such as the extrac-
tion of a grammatical element or the resolution of
some co-references, can be formalized. In addi-
tion, the result of the parsing is also a shared for-
est of syntactic trees. Each tree is associated with a
feature structure where are represented grammati-
cal relations between syntactical constituents that
have been identified during parsing.
</bodyText>
<sectionHeader confidence="0.988197" genericHeader="method">
6 Linguistic Resource Management
</sectionHeader>
<bodyText confidence="0.99927565">
The reuse of LRs requires flexibility: a lexicon or a
grammar is not a static resource. The management
of lexicons and grammars implies manual con-
struction and maintenance of resources in a read-
able format, and compilation of these resources in
an operational format. These techniques require
strong collaborations between computer scientists
and linguists; few systems provide such function-
ality (Xelda, Intex, Unitex). The Outilex platform
provides a complete set of management tools for
LRs. For instance, the platform offers an inflection
module. This module takes a lexicon of lemmas
with syntactic tags as input associated with inflec-
tion rules. It produces a lexicon of inflected words
associated with morphosyntactic features. In order
to accelerate word tagging, these lexicons are then
indexed on their inflected forms by using a mini-
mal finite state automaton representation (Revuz,
1991) that allows for both fast look-up procedure
and dictionary compression.
</bodyText>
<page confidence="0.998853">
75
</page>
<sectionHeader confidence="0.991476" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999943266666667">
The Outilex platform in its current version pro-
vides all fundamental operations for text pro-
cessing: processing without lexicon, lexicon and
grammar exploitation and LR management. Data
are structured both in standard XML formats and
in more compact ones. Format converters are in-
cluded in the platform. The WRTN formalism al-
lows for combining statistical methods with meth-
ods based on LRs. The development of the plat-
form required expertise both in computer science
and in linguistics. It took into account both needs
in fundamental research and applications. In the
future, we hope the platform will be extended to
other languages and will be enriched with new
functionality.
</bodyText>
<sectionHeader confidence="0.998927" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.978175341176471">
Olivier Blanc and Matthieu Constant. 2005. Lexi-
calization of grammars with parameterized graphs.
In Proc. of RANLP 2005, pages 117–121, Borovets,
Bulgarie, September. INCOMA Ltd.
Olivier Blanc and Anne Dister. 2004. Automates lexi-
caux avec structure de traits. In Actes de RECITAL,
pages 23–32.
Olivier Blanc, Matthieu Constant, and ´Eric Laporte.
2006. Outilex, plate-forme logicielle de traitements
de textes ´ecrits. In C´edrick Fairon and Piet Mertens,
editors, Actes de TALN 2006 (Traitement automa-
tique des langues naturelles), page to appear, Leu-
ven. ATALA.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational Lin-
guistics, 21(4):543–565.
Lionel Cl´ement and ´Eric de la Clergerie. 2005. MAF:
a morphosyntactic annotation framework. In Proc.
of the Language and Technology Conference, Poz-
nan, Poland, pages 90–94.
Hamish Cunningham. 2002. GATE, a general archi-
tecture for text engineering. Computers and the Hu-
manities, 36:223–254.
Laurence Danlos. 2005. Automatic recognition of
French expletive pronoun occurrences. In Compan-
ion Volume of the International Joint Conference
on Natural Language Processing, Jeju, Korea, page
2013.
Jay Earley. 1970. An efficient context-free parsing al-
gorithm. Comm. ACM, 13(2):94–102.
Maurice Gross. 1993. Local grammars and their rep-
resentation by finite automata. In M. Hoey, editor,
Data, Description, Discourse, Papers on the English
Language in honour of John McH Sinclair, pages
26–38. Harper-Collins, London.
Cvetana Krstev, Duˇsko Vitas, Denis Maurel, and
Micka¨el Tran. 2005. Multilingual ontology of
proper names. In Proc. of the Language and Tech-
nology Conference, Poznan, Poland, pages 116–119.
Edward Loper and Steven Bird. 2002. NLTK: the nat-
ural language toolkit. In Proc. of the ACL Workshop
on Effective Tools and Methodologies for Teaching
Natural Language Processing and Computational
Linguistics, Philadelphia.
Oliver Mason. 2004. Automatic processing of lo-
cal grammar patterns. In Proc. of the 7th Annual
CLUK (the UK special-interest group for computa-
tional linguistics) Research Colloquium.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
1998. A rational design for a weighted finite-state
transducer library. Lecture Notes in Computer Sci-
ence, 1436.
Takuya Nakamura. 2005. Analysing texts in a specific
domain with local grammars: The case of stock ex-
change market reports. In Linguistic Informatics -
State of the Art and the Future, pages 76–98. Ben-
jamins, Amsterdam/Philadelphia.
S´ebastien Paumier. 2003. De la reconnaissance de
formes linguistiques a` l’analyse syntaxique. Volume
2, Manuel d’Unitex. Ph.D. thesis, IGM, Universit´e
de Marne-la-Vall´ee.
Thierry Poibeau. 2001. Extraction d’information dans
les bases de donn´ees textuelles en g´enomique au
moyen de transducteurs a` ´etats finis. In Denis Mau-
rel, editor, Actes de TALN2001 (Traitement automa-
tique des langues naturelles), pages 295–304, Tours,
July. ATALA, Universit´e de Tours.
Dominique Revuz. 1991. Dictionnaires et lexiques:
m´ethodes et algorithmes. Ph.D. thesis, Universit´e
Paris 7.
Javier M. Sastre. 2005. XML-based representation
formats of local grammars for NLP. In Proc. of
the Language and Technology Conference, Poznan,
Poland, pages 314–317.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. Proceedings of the
International Conference on New Methods in Lan-
guage Processing.
Max Silberztein. 1993. Dictionnaires ´electroniques et
analyse automatique de textes. Le syst`eme INTEX.
Masson, Paris. 234 p.
William A. Woods. 1970. Transition network gram-
mars for natural language analysis. Communica-
tions of the ACM, 13(10):591–606.
</reference>
<page confidence="0.991738">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.600591">
<title confidence="0.999878">Outilex, a Linguistic Platform for Text Processing</title>
<author confidence="0.999603">Olivier Blanc</author>
<affiliation confidence="0.999728">IGM, University of Marne-la-Vall´ee</affiliation>
<address confidence="0.9678405">5, bd Descartes - Champs/Marne 77454 Marne-la-Vall´ee, France</address>
<email confidence="0.994218">oblanc@univ-mlv.fr</email>
<author confidence="0.997485">Matthieu Constant</author>
<affiliation confidence="0.999657">IGM, University of Marne-la-Vall´ee</affiliation>
<address confidence="0.9366885">5, bd Descartes - Champs/Marne 77 454 Marne-la-Vall´ee, france</address>
<email confidence="0.988171">mconstan@univ-mlv.fr</email>
<abstract confidence="0.944722">We present Outilex, a generalist linguistic platform for text processing. The platform includes several modules implementing the main operations for text processing and is designed to use large-coverage Language Resources. These resources (dictionaries, grammars, annotated texts) are formatted into XML, in accordance with current standards. Evaluations on efficiency are given. 1 Credits This project has been supported by the French Ministry of Industry and the CNRS. Thanks to Sky and Francesca Sigal for their linguistic expertise.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Olivier Blanc</author>
<author>Matthieu Constant</author>
</authors>
<title>Lexicalization of grammars with parameterized graphs.</title>
<date>2005</date>
<booktitle>In Proc. of RANLP</booktitle>
<pages>117--121</pages>
<publisher>INCOMA Ltd.</publisher>
<location>Borovets, Bulgarie,</location>
<contexts>
<context position="11471" citStr="Blanc and Constant, 2005" startWordPosition="1777" endWordPosition="1780">es, a variant of this functionality produces an automaton corresponding to the original text automaton with new transitions tagged with the grammar outputs. This process is easily iterable and can then be used for incremental recognition and annotation of longer and longer segments. It can also complete the morphosyntactic tagging for the recognition of semifrozen lexical units, whose variations are too complex to be enumerated in dictionaries, but can be easily described in local grammars. Also included is a deep syntactic parser based on unification grammars in the decorated WRTN formalism (Blanc and Constant, 2005). This formalism combines WRTN formalism with functional equations on feature structures. Therefore, complex syntactic phenomena, such as the extraction of a grammatical element or the resolution of some co-references, can be formalized. In addition, the result of the parsing is also a shared forest of syntactic trees. Each tree is associated with a feature structure where are represented grammatical relations between syntactical constituents that have been identified during parsing. 6 Linguistic Resource Management The reuse of LRs requires flexibility: a lexicon or a grammar is not a static </context>
</contexts>
<marker>Blanc, Constant, 2005</marker>
<rawString>Olivier Blanc and Matthieu Constant. 2005. Lexicalization of grammars with parameterized graphs. In Proc. of RANLP 2005, pages 117–121, Borovets, Bulgarie, September. INCOMA Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Blanc</author>
<author>Anne Dister</author>
</authors>
<title>Automates lexicaux avec structure de traits.</title>
<date>2004</date>
<booktitle>In Actes de RECITAL,</booktitle>
<pages>23--32</pages>
<contexts>
<context position="7478" citStr="Blanc and Dister, 2004" startWordPosition="1135" endWordPosition="1138"> represents segmentation and tagging ambiguities. This tagged text can be serialized in an XML format, compatible with the draft model MAF (Morphosyntactic Annotation Framework)(Cl´ement and de la Clergerie, 2005). All further processing described in the next section will be run on this automaton, possibly modifying it. 5 Text Parsing Grammatical formalisms are very numerous in NLP. Outilex uses a minimal formalism: Recursive Transition Network (RTN)(Woods, 1970) that are represented in the form of recursive automata (automata that call other automata). The terminal symbols are lexical masks (Blanc and Dister, 2004), which are underspecified word tags i.e. that represent a set of tagged words matching with the specified features (e.g. noun in the plural). Transductions can be put in our RTNs. This can be used, for instance, to insert tags in texts and therefore formalize relations between identified segments. This formalism allows for the construction of local grammars in the sense of (Gross, 1993). It has been successfully used in different types of applications: information extraction (Poibeau, 84.7 % of the token occurrences were not found in the dictionary; This value falls to 0.4 % if we remove the </context>
</contexts>
<marker>Blanc, Dister, 2004</marker>
<rawString>Olivier Blanc and Anne Dister. 2004. Automates lexicaux avec structure de traits. In Actes de RECITAL, pages 23–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Blanc</author>
<author>Matthieu Constant</author>
<author>´Eric Laporte</author>
</authors>
<title>Outilex, plate-forme logicielle de traitements de textes ´ecrits.</title>
<date>2006</date>
<booktitle>In C´edrick Fairon and Piet Mertens, editors, Actes de TALN 2006 (Traitement automatique des langues naturelles),</booktitle>
<pages>page</pages>
<location>Leuven. ATALA.</location>
<contexts>
<context position="921" citStr="Blanc et al., 2006" startWordPosition="127" endWordPosition="130">nstan@univ-mlv.fr Abstract We present Outilex, a generalist linguistic platform for text processing. The platform includes several modules implementing the main operations for text processing and is designed to use large-coverage Language Resources. These resources (dictionaries, grammars, annotated texts) are formatted into XML, in accordance with current standards. Evaluations on efficiency are given. 1 Credits This project has been supported by the French Ministry of Industry and the CNRS. Thanks to Sky and Francesca Sigal for their linguistic expertise. 2 Introduction The Outilex Project (Blanc et al., 2006) aims to develop an open-linguistic platform, including tools, electronic dictionaries and grammars, dedicated to text processing. It is the result of the collaboration of ten French partners, composed of 4 universities and 6 industrial organizations. The project started in 2002 and will end in 2006. The platform which will be made freely available to research, development and industry in April 2007, comprises software components implementing all the fundamental operations of written text processing: text segmentation, morphosyntactic tagging, parsing with grammars and language resource manage</context>
</contexts>
<marker>Blanc, Constant, Laporte, 2006</marker>
<rawString>Olivier Blanc, Matthieu Constant, and ´Eric Laporte. 2006. Outilex, plate-forme logicielle de traitements de textes ´ecrits. In C´edrick Fairon and Piet Mertens, editors, Actes de TALN 2006 (Traitement automatique des langues naturelles), page to appear, Leuven. ATALA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="4725" citStr="Brill, 1995" startWordPosition="689" endWordPosition="690"> information such as its type (word, number, punctuation, ...), its alphabet (Latin, Greek), its case (lowercase word, capitalized word, ...), and other information for the other symbols (opening or closing punctuation symbol, ...). When applied to a corpus of journalistic telegrams of 352,464 tokens, our tokenizer processes 22,185 words per second5. 4 Morphosyntactic tagging By using lexicons and grammars, our platform includes the notion of multiword units, and allows for the handling of several types of morphosyntactic ambiguities. Usually, stochastic morphosyntactic taggers (Schmid, 1994; Brill, 1995) do not handle well such notions. However, the use of lexicons by companies working in the domain has much developed over the past few years. That is why Outilex provides a complete set of software components handling operations on lexicons. IGM also contributed to this project by freely distributing a large amount of the LADL lexicons6 with fine-grained tagsets7: for French, 109,912 simple lemmas and 86,337 compound lemmas; for English, 166,150 simple lemmas and 13,361 compound lemmas. These resources are available under LGPL-LR license. Outilex programs are compatible with all European langu</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lionel Cl´ement</author>
<author>´Eric de la Clergerie</author>
</authors>
<title>MAF: a morphosyntactic annotation framework.</title>
<date>2005</date>
<booktitle>In Proc. of the Language and Technology Conference,</booktitle>
<pages>90--94</pages>
<location>Poznan, Poland,</location>
<marker>Cl´ement, Clergerie, 2005</marker>
<rawString>Lionel Cl´ement and ´Eric de la Clergerie. 2005. MAF: a morphosyntactic annotation framework. In Proc. of the Language and Technology Conference, Poznan, Poland, pages 90–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
</authors>
<title>GATE, a general architecture for text engineering. Computers and the Humanities,</title>
<date>2002</date>
<pages>36--223</pages>
<contexts>
<context position="2596" citStr="Cunningham, 2002" startWordPosition="383" endWordPosition="384"> license. The platform aims to be a generalist base for diverse processings on text corpora. Furthermore, it uses portable formats and format converters that would allow for combining several software components. There exist a lot of platforms dedicated to NLP, but none are fully satisfactory for various reasons. Intex (Silberztein, 1993), FSM (Mohri et al., 1998) and Xelda3 are closed source. Unitex (Paumier, 2003), inspired by Intex has its source code under LGPL license4 but it does not support standard formats for Language Resources (LR). Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. All the operations described below are implemented in C++ independent modules which interact with each others through XML streams. Each functionality is accessible by programmers through a specified API and by end users through binary programs. Programs can be invoked by a Graphical User Interface implemented in Java. This interface allows the user to define his own processing flow as well as to work on several projects with specific texts, dictionaries and grammars. 1French Laboratory for Linguistics and Information Retrieval 2Lesse</context>
</contexts>
<marker>Cunningham, 2002</marker>
<rawString>Hamish Cunningham. 2002. GATE, a general architecture for text engineering. Computers and the Humanities, 36:223–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence Danlos</author>
</authors>
<title>Automatic recognition of French expletive pronoun occurrences.</title>
<date>2005</date>
<booktitle>In Companion Volume of the International Joint Conference on Natural Language Processing,</booktitle>
<location>Jeju, Korea, page</location>
<contexts>
<context position="8446" citStr="Danlos, 2005" startWordPosition="1288" endWordPosition="1289">mmars in the sense of (Gross, 1993). It has been successfully used in different types of applications: information extraction (Poibeau, 84.7 % of the token occurrences were not found in the dictionary; This value falls to 0.4 % if we remove the capitalized occurrences. The processing time could appear rather slow; but, this task involves not so trivial computations such as conversion between different charsets or approximated look-up using Unicode character properties. 74 2001; Nakamura, 2005), named entity localization (Krstev et al., 2005), grammatical structure identification (Mason, 2004; Danlos, 2005)). All of these experiments resulted in recall and precision rates equaling the state-of-the-art. This formalism has been enhanced with weights that are assigned to the automata transitions. Thus, grammars can be integrated into hybrid systems using both statistical methods and methods based on linguistic resources. We call the obtained formalism Weighted Recursive Transition Network (WRTN). These grammars are constructed in the form of graphs with an editor and are saved in an XML format (Sastre, 2005). Each graph (or automaton) is optimized with epsilon transition removal, determinization an</context>
</contexts>
<marker>Danlos, 2005</marker>
<rawString>Laurence Danlos. 2005. Automatic recognition of French expletive pronoun occurrences. In Companion Volume of the International Joint Conference on Natural Language Processing, Jeju, Korea, page 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Comm. ACM,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="9363" citStr="Earley, 1970" startWordPosition="1427" endWordPosition="1428">ic resources. We call the obtained formalism Weighted Recursive Transition Network (WRTN). These grammars are constructed in the form of graphs with an editor and are saved in an XML format (Sastre, 2005). Each graph (or automaton) is optimized with epsilon transition removal, determinization and minimization operations. It is also possible to transform a grammar in an equivalent or approximate finite state transducer, by copying the subgraphs into the main automaton. The result generally requires more memory space but can highly accelerate processing. Our parser is based on Earley algorithm (Earley, 1970) that has been adapted to deal with WRTN (instead of context-free grammar) and a text in the form of an acyclic finite state automaton (instead of a word sequence). The result of the parsing consists of a shared forest of weighted syntactic trees for each sentence. The nodes of the trees are decorated by the possible outputs of the grammar. This shared forest can be processed to get different types of results, such as a list of concordances, an annotated text or a modified text automaton. By applying a noun phrase grammar (Paumier, 2003) on a corpus of AFP journalistic telegrams, our parser pr</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Jay Earley. 1970. An efficient context-free parsing algorithm. Comm. ACM, 13(2):94–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Gross</author>
</authors>
<title>Local grammars and their representation by finite automata.</title>
<date>1993</date>
<booktitle>Data, Description, Discourse, Papers on the English Language in honour of John McH Sinclair,</booktitle>
<pages>26--38</pages>
<editor>In M. Hoey, editor,</editor>
<publisher>Harper-Collins,</publisher>
<location>London.</location>
<contexts>
<context position="7868" citStr="Gross, 1993" startWordPosition="1201" endWordPosition="1202">minimal formalism: Recursive Transition Network (RTN)(Woods, 1970) that are represented in the form of recursive automata (automata that call other automata). The terminal symbols are lexical masks (Blanc and Dister, 2004), which are underspecified word tags i.e. that represent a set of tagged words matching with the specified features (e.g. noun in the plural). Transductions can be put in our RTNs. This can be used, for instance, to insert tags in texts and therefore formalize relations between identified segments. This formalism allows for the construction of local grammars in the sense of (Gross, 1993). It has been successfully used in different types of applications: information extraction (Poibeau, 84.7 % of the token occurrences were not found in the dictionary; This value falls to 0.4 % if we remove the capitalized occurrences. The processing time could appear rather slow; but, this task involves not so trivial computations such as conversion between different charsets or approximated look-up using Unicode character properties. 74 2001; Nakamura, 2005), named entity localization (Krstev et al., 2005), grammatical structure identification (Mason, 2004; Danlos, 2005)). All of these experi</context>
</contexts>
<marker>Gross, 1993</marker>
<rawString>Maurice Gross. 1993. Local grammars and their representation by finite automata. In M. Hoey, editor, Data, Description, Discourse, Papers on the English Language in honour of John McH Sinclair, pages 26–38. Harper-Collins, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cvetana Krstev</author>
<author>Duˇsko Vitas</author>
<author>Denis Maurel</author>
<author>Micka¨el Tran</author>
</authors>
<title>Multilingual ontology of proper names.</title>
<date>2005</date>
<booktitle>In Proc. of the Language and Technology Conference,</booktitle>
<pages>116--119</pages>
<location>Poznan, Poland,</location>
<marker>Krstev, Vitas, Maurel, Micka¨el Tran, 2005</marker>
<rawString>Cvetana Krstev, Duˇsko Vitas, Denis Maurel, and Micka¨el Tran. 2005. Multilingual ontology of proper names. In Proc. of the Language and Technology Conference, Poznan, Poland, pages 116–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>NLTK: the natural language toolkit.</title>
<date>2002</date>
<booktitle>In Proc. of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="2568" citStr="Loper and Bird, 2002" startWordPosition="377" endWordPosition="380">with the platform under LGPL-LR2 license. The platform aims to be a generalist base for diverse processings on text corpora. Furthermore, it uses portable formats and format converters that would allow for combining several software components. There exist a lot of platforms dedicated to NLP, but none are fully satisfactory for various reasons. Intex (Silberztein, 1993), FSM (Mohri et al., 1998) and Xelda3 are closed source. Unitex (Paumier, 2003), inspired by Intex has its source code under LGPL license4 but it does not support standard formats for Language Resources (LR). Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. All the operations described below are implemented in C++ independent modules which interact with each others through XML streams. Each functionality is accessible by programmers through a specified API and by end users through binary programs. Programs can be invoked by a Graphical User Interface implemented in Java. This interface allows the user to define his own processing flow as well as to work on several projects with specific texts, dictionaries and grammars. 1French Laboratory for Linguistics and </context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. NLTK: the natural language toolkit. In Proc. of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Mason</author>
</authors>
<title>Automatic processing of local grammar patterns.</title>
<date>2004</date>
<booktitle>In Proc. of the 7th Annual CLUK (the UK special-interest group for computational linguistics) Research Colloquium.</booktitle>
<contexts>
<context position="8431" citStr="Mason, 2004" startWordPosition="1286" endWordPosition="1287"> of local grammars in the sense of (Gross, 1993). It has been successfully used in different types of applications: information extraction (Poibeau, 84.7 % of the token occurrences were not found in the dictionary; This value falls to 0.4 % if we remove the capitalized occurrences. The processing time could appear rather slow; but, this task involves not so trivial computations such as conversion between different charsets or approximated look-up using Unicode character properties. 74 2001; Nakamura, 2005), named entity localization (Krstev et al., 2005), grammatical structure identification (Mason, 2004; Danlos, 2005)). All of these experiments resulted in recall and precision rates equaling the state-of-the-art. This formalism has been enhanced with weights that are assigned to the automata transitions. Thus, grammars can be integrated into hybrid systems using both statistical methods and methods based on linguistic resources. We call the obtained formalism Weighted Recursive Transition Network (WRTN). These grammars are constructed in the form of graphs with an editor and are saved in an XML format (Sastre, 2005). Each graph (or automaton) is optimized with epsilon transition removal, det</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Oliver Mason. 2004. Automatic processing of local grammar patterns. In Proc. of the 7th Annual CLUK (the UK special-interest group for computational linguistics) Research Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>A rational design for a weighted finite-state transducer library.</title>
<date>1998</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>1436</pages>
<contexts>
<context position="2345" citStr="Mohri et al., 1998" startWordPosition="341" endWordPosition="344">sm allows for the combination of statistical approaches with resource-based approaches. Manually constructed lexicons of substantial coverage for French and English, originating from the former LADL1, will be distributed with the platform under LGPL-LR2 license. The platform aims to be a generalist base for diverse processings on text corpora. Furthermore, it uses portable formats and format converters that would allow for combining several software components. There exist a lot of platforms dedicated to NLP, but none are fully satisfactory for various reasons. Intex (Silberztein, 1993), FSM (Mohri et al., 1998) and Xelda3 are closed source. Unitex (Paumier, 2003), inspired by Intex has its source code under LGPL license4 but it does not support standard formats for Language Resources (LR). Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. All the operations described below are implemented in C++ independent modules which interact with each others through XML streams. Each functionality is accessible by programmers through a specified API and by end users through binary programs. Programs can be invoked by a Graphical User</context>
</contexts>
<marker>Mohri, Pereira, Riley, 1998</marker>
<rawString>Mehryar Mohri, Fernando Pereira, and Michael Riley. 1998. A rational design for a weighted finite-state transducer library. Lecture Notes in Computer Science, 1436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Nakamura</author>
</authors>
<title>Analysing texts in a specific domain with local grammars: The case of stock exchange market reports.</title>
<date>2005</date>
<booktitle>In Linguistic Informatics -State of the Art and the Future,</booktitle>
<pages>76--98</pages>
<location>Benjamins, Amsterdam/Philadelphia.</location>
<contexts>
<context position="8331" citStr="Nakamura, 2005" startWordPosition="1273" endWordPosition="1274">nd therefore formalize relations between identified segments. This formalism allows for the construction of local grammars in the sense of (Gross, 1993). It has been successfully used in different types of applications: information extraction (Poibeau, 84.7 % of the token occurrences were not found in the dictionary; This value falls to 0.4 % if we remove the capitalized occurrences. The processing time could appear rather slow; but, this task involves not so trivial computations such as conversion between different charsets or approximated look-up using Unicode character properties. 74 2001; Nakamura, 2005), named entity localization (Krstev et al., 2005), grammatical structure identification (Mason, 2004; Danlos, 2005)). All of these experiments resulted in recall and precision rates equaling the state-of-the-art. This formalism has been enhanced with weights that are assigned to the automata transitions. Thus, grammars can be integrated into hybrid systems using both statistical methods and methods based on linguistic resources. We call the obtained formalism Weighted Recursive Transition Network (WRTN). These grammars are constructed in the form of graphs with an editor and are saved in an XM</context>
</contexts>
<marker>Nakamura, 2005</marker>
<rawString>Takuya Nakamura. 2005. Analysing texts in a specific domain with local grammars: The case of stock exchange market reports. In Linguistic Informatics -State of the Art and the Future, pages 76–98. Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S´ebastien Paumier</author>
</authors>
<title>De la reconnaissance de formes linguistiques a` l’analyse syntaxique.</title>
<date>2003</date>
<booktitle>Volume 2, Manuel d’Unitex. Ph.D. thesis, IGM, Universit´e de Marne-la-Vall´ee.</booktitle>
<contexts>
<context position="2398" citStr="Paumier, 2003" startWordPosition="351" endWordPosition="352">th resource-based approaches. Manually constructed lexicons of substantial coverage for French and English, originating from the former LADL1, will be distributed with the platform under LGPL-LR2 license. The platform aims to be a generalist base for diverse processings on text corpora. Furthermore, it uses portable formats and format converters that would allow for combining several software components. There exist a lot of platforms dedicated to NLP, but none are fully satisfactory for various reasons. Intex (Silberztein, 1993), FSM (Mohri et al., 1998) and Xelda3 are closed source. Unitex (Paumier, 2003), inspired by Intex has its source code under LGPL license4 but it does not support standard formats for Language Resources (LR). Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. All the operations described below are implemented in C++ independent modules which interact with each others through XML streams. Each functionality is accessible by programmers through a specified API and by end users through binary programs. Programs can be invoked by a Graphical User Interface implemented in Java. This interface allows</context>
<context position="9906" citStr="Paumier, 2003" startWordPosition="1523" endWordPosition="1524">rate processing. Our parser is based on Earley algorithm (Earley, 1970) that has been adapted to deal with WRTN (instead of context-free grammar) and a text in the form of an acyclic finite state automaton (instead of a word sequence). The result of the parsing consists of a shared forest of weighted syntactic trees for each sentence. The nodes of the trees are decorated by the possible outputs of the grammar. This shared forest can be processed to get different types of results, such as a list of concordances, an annotated text or a modified text automaton. By applying a noun phrase grammar (Paumier, 2003) on a corpus of AFP journalistic telegrams, our parser processed 12,466 words per second and found 39,468 occurrences. The platform includes a concordancer that allows for listing in their occurring context different occurrences of the patterns described in the grammar. Concordances can be sorted according to the text order or lexicographic order. The concordancer is a valuable tool for linguists who are interested in finding the different uses of linguistic forms in corpora. It is also of great interest to improve grammars during their construction. Also included is a module to apply a transd</context>
</contexts>
<marker>Paumier, 2003</marker>
<rawString>S´ebastien Paumier. 2003. De la reconnaissance de formes linguistiques a` l’analyse syntaxique. Volume 2, Manuel d’Unitex. Ph.D. thesis, IGM, Universit´e de Marne-la-Vall´ee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Poibeau</author>
</authors>
<title>Extraction d’information dans les bases de donn´ees textuelles en g´enomique au moyen de transducteurs a` ´etats finis.</title>
<date>2001</date>
<booktitle>Actes de TALN2001 (Traitement automatique des langues naturelles),</booktitle>
<pages>295--304</pages>
<editor>In Denis Maurel, editor,</editor>
<institution>Universit´e de Tours.</institution>
<marker>Poibeau, 2001</marker>
<rawString>Thierry Poibeau. 2001. Extraction d’information dans les bases de donn´ees textuelles en g´enomique au moyen de transducteurs a` ´etats finis. In Denis Maurel, editor, Actes de TALN2001 (Traitement automatique des langues naturelles), pages 295–304, Tours, July. ATALA, Universit´e de Tours.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Revuz</author>
</authors>
<title>Dictionnaires et lexiques: m´ethodes et algorithmes.</title>
<date>1991</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e Paris</institution>
<contexts>
<context position="12892" citStr="Revuz, 1991" startWordPosition="1995" endWordPosition="1996">quire strong collaborations between computer scientists and linguists; few systems provide such functionality (Xelda, Intex, Unitex). The Outilex platform provides a complete set of management tools for LRs. For instance, the platform offers an inflection module. This module takes a lexicon of lemmas with syntactic tags as input associated with inflection rules. It produces a lexicon of inflected words associated with morphosyntactic features. In order to accelerate word tagging, these lexicons are then indexed on their inflected forms by using a minimal finite state automaton representation (Revuz, 1991) that allows for both fast look-up procedure and dictionary compression. 75 7 Conclusion The Outilex platform in its current version provides all fundamental operations for text processing: processing without lexicon, lexicon and grammar exploitation and LR management. Data are structured both in standard XML formats and in more compact ones. Format converters are included in the platform. The WRTN formalism allows for combining statistical methods with methods based on LRs. The development of the platform required expertise both in computer science and in linguistics. It took into account bot</context>
</contexts>
<marker>Revuz, 1991</marker>
<rawString>Dominique Revuz. 1991. Dictionnaires et lexiques: m´ethodes et algorithmes. Ph.D. thesis, Universit´e Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier M Sastre</author>
</authors>
<title>XML-based representation formats of local grammars for NLP.</title>
<date>2005</date>
<booktitle>In Proc. of the Language and Technology Conference,</booktitle>
<pages>314--317</pages>
<location>Poznan, Poland,</location>
<contexts>
<context position="8954" citStr="Sastre, 2005" startWordPosition="1365" endWordPosition="1366">tity localization (Krstev et al., 2005), grammatical structure identification (Mason, 2004; Danlos, 2005)). All of these experiments resulted in recall and precision rates equaling the state-of-the-art. This formalism has been enhanced with weights that are assigned to the automata transitions. Thus, grammars can be integrated into hybrid systems using both statistical methods and methods based on linguistic resources. We call the obtained formalism Weighted Recursive Transition Network (WRTN). These grammars are constructed in the form of graphs with an editor and are saved in an XML format (Sastre, 2005). Each graph (or automaton) is optimized with epsilon transition removal, determinization and minimization operations. It is also possible to transform a grammar in an equivalent or approximate finite state transducer, by copying the subgraphs into the main automaton. The result generally requires more memory space but can highly accelerate processing. Our parser is based on Earley algorithm (Earley, 1970) that has been adapted to deal with WRTN (instead of context-free grammar) and a text in the form of an acyclic finite state automaton (instead of a word sequence). The result of the parsing </context>
</contexts>
<marker>Sastre, 2005</marker>
<rawString>Javier M. Sastre. 2005. XML-based representation formats of local grammars for NLP. In Proc. of the Language and Technology Conference, Poznan, Poland, pages 314–317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>Proceedings of the International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="4711" citStr="Schmid, 1994" startWordPosition="687" endWordPosition="688">ssociated with information such as its type (word, number, punctuation, ...), its alphabet (Latin, Greek), its case (lowercase word, capitalized word, ...), and other information for the other symbols (opening or closing punctuation symbol, ...). When applied to a corpus of journalistic telegrams of 352,464 tokens, our tokenizer processes 22,185 words per second5. 4 Morphosyntactic tagging By using lexicons and grammars, our platform includes the notion of multiword units, and allows for the handling of several types of morphosyntactic ambiguities. Usually, stochastic morphosyntactic taggers (Schmid, 1994; Brill, 1995) do not handle well such notions. However, the use of lexicons by companies working in the domain has much developed over the past few years. That is why Outilex provides a complete set of software components handling operations on lexicons. IGM also contributed to this project by freely distributing a large amount of the LADL lexicons6 with fine-grained tagsets7: for French, 109,912 simple lemmas and 86,337 compound lemmas; for English, 166,150 simple lemmas and 13,361 compound lemmas. These resources are available under LGPL-LR license. Outilex programs are compatible with all </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. Proceedings of the International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Silberztein</author>
</authors>
<title>Dictionnaires ´electroniques et analyse automatique de textes.</title>
<date>1993</date>
<booktitle>Le syst`eme INTEX. Masson,</booktitle>
<volume>234</volume>
<pages>p.</pages>
<location>Paris.</location>
<contexts>
<context position="2319" citStr="Silberztein, 1993" startWordPosition="338" endWordPosition="339">form. The grammar formalism allows for the combination of statistical approaches with resource-based approaches. Manually constructed lexicons of substantial coverage for French and English, originating from the former LADL1, will be distributed with the platform under LGPL-LR2 license. The platform aims to be a generalist base for diverse processings on text corpora. Furthermore, it uses portable formats and format converters that would allow for combining several software components. There exist a lot of platforms dedicated to NLP, but none are fully satisfactory for various reasons. Intex (Silberztein, 1993), FSM (Mohri et al., 1998) and Xelda3 are closed source. Unitex (Paumier, 2003), inspired by Intex has its source code under LGPL license4 but it does not support standard formats for Language Resources (LR). Systems like NLTK (Loper and Bird, 2002) and Gate (Cunningham, 2002) do not offer functionality for Lexical Resource Management. All the operations described below are implemented in C++ independent modules which interact with each others through XML streams. Each functionality is accessible by programmers through a specified API and by end users through binary programs. Programs can be i</context>
</contexts>
<marker>Silberztein, 1993</marker>
<rawString>Max Silberztein. 1993. Dictionnaires ´electroniques et analyse automatique de textes. Le syst`eme INTEX. Masson, Paris. 234 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
</authors>
<title>Transition network grammars for natural language analysis.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<volume>13</volume>
<issue>10</issue>
<contexts>
<context position="7322" citStr="Woods, 1970" startWordPosition="1112" endWordPosition="1113">x tags about 6,650 words per second8. The result of this operation is an acyclic automaton (sometimes, called word lattice in this context), that represents segmentation and tagging ambiguities. This tagged text can be serialized in an XML format, compatible with the draft model MAF (Morphosyntactic Annotation Framework)(Cl´ement and de la Clergerie, 2005). All further processing described in the next section will be run on this automaton, possibly modifying it. 5 Text Parsing Grammatical formalisms are very numerous in NLP. Outilex uses a minimal formalism: Recursive Transition Network (RTN)(Woods, 1970) that are represented in the form of recursive automata (automata that call other automata). The terminal symbols are lexical masks (Blanc and Dister, 2004), which are underspecified word tags i.e. that represent a set of tagged words matching with the specified features (e.g. noun in the plural). Transductions can be put in our RTNs. This can be used, for instance, to insert tags in texts and therefore formalize relations between identified segments. This formalism allows for the construction of local grammars in the sense of (Gross, 1993). It has been successfully used in different types of </context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>William A. Woods. 1970. Transition network grammars for natural language analysis. Communications of the ACM, 13(10):591–606.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>