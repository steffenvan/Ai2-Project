<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.990144">
Multilingual Structural Projection across Interlinear Text
</title>
<author confidence="0.996888">
Fei Xia
</author>
<affiliation confidence="0.994151">
Department of Linguistics
University of Washington
</affiliation>
<address confidence="0.949564">
Seattle, WA 98195
</address>
<email confidence="0.99895">
fxia@u.washington.edu
</email>
<author confidence="0.99194">
William D. Lewis
</author>
<affiliation confidence="0.992216">
Department of Linguistics
University of Washington
</affiliation>
<address confidence="0.948437">
Seattle, WA 98195
</address>
<email confidence="0.998288">
wlewis2@u.washington.edu
</email>
<sectionHeader confidence="0.995632" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998406857142857">
This paper explores the potential for an-
notating and enriching data for low-density
languages via the alignment and projec-
tion of syntactic structure from parsed data
for resource-rich languages such as English.
We seek to develop enriched resources for a
large number of the world’s languages, most
of which have no significant digital pres-
ence. We do this by tapping the body of
Web-based linguistic data, most of which
exists in small, analyzed chunks embedded
in scholarly papers, journal articles, Web
pages, and other online documents. By har-
vesting and enriching these data, we can
provide the means for knowledge discovery
across the resulting corpus that can lead
to building computational resources such
as grammars and transfer rules, which, in
turn, can be used as bootstraps for build-
ing additional tools and resources for the
languages represented.&apos;
</bodyText>
<sectionHeader confidence="0.999126" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999624470588235">
Developing natural language applications is generally
dependent on the availability of annotated corpora.
Building annotated resources, however, is a signif-
icantly time consuming process involving consider-
able human effort. Although a number of projects
have been undertaken to develop annotated resources
for non-English languages, e.g., treebanks, the devel-
opment of these resources has been no small feat, and
to date have been limited to a very small number of
&apos;We would like to thank Dan Jinguji for creating the
word alignment and source dependency structure gold
standards. Our thanks also go to three anonymous re-
viewers for their helpful comments and suggestions.
the world’s languages (e.g., Chinese, German, Ara-
bic, Korean, etc.). Some notable efforts have been
undertaken to develop automated means for creating
annotated corpora through the projection of annota-
tions (Yarowksy and Ngai, 2001; Xi and Hwa, 2005).
The resulting methods, however, can only be applied
to a small number of language pairs due mostly to
the need for sizeable parallel corpora. Unfortunately,
most languages do not have parallel corpora of suffi-
cient size, making these methods inapplicable for the
vast majority of the world’s languages.
We describe a method for bootstrapping resource
creation by tapping the wealth of multilingual data
on the Web that has been created by linguists. Of
particular note is the linguistic presentation format
of “interlinear text”, a common format used for pre-
senting language data and analysis relevant to a par-
ticular argument or investigation. Since interlin-
ear examples consist of orthographically or phoneti-
cally encoded language data aligned with an English
translation, the “database” of interlinear examples
found on the Web, when taken together, constitute a
significant multilingual, parallel corpus covering hun-
dreds to thousands of the world’s languages.
We do not propose that a database of interlin-
ear text alone is sufficient to create NLP resources
and tools, but rather that it may act as a means for
more rapidly developing such tools using less data.
We contend that such a resource allows one to de-
velop computational artifacts, such as grammars and
transfer rules, which can be used as “seed” knowledge
for building larger resources. In particular, knowing
a little about the structure of a language can help
in developing annotated corpora and tools, since a
little knowledge can go a long way in inducing accu-
rate structure and annotations (Haghighi and Klein,
2006).
Of particular relevance to MT is the issue of struc-
</bodyText>
<page confidence="0.959984">
452
</page>
<note confidence="0.747551111111111">
Proceedings of NAACL HLT 2007, pages 452–459,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
tural divergence (Dorr, 1994). Many MT models im-
plicitly make the so-called direct correspondence as-
sumption (DCA) as defined in (Hwa et al., 2002).
However, to what extent that assumption holds is
tested only on a small number of language pairs us-
ing hand aligned data (Fox, 2002; Hwa et al., 2002;
Wellington et al., 2006). A larger sample of typo-
</note>
<bodyText confidence="0.976347121951219">
logically diverse language data can help test the as-
sumption for hundreds of languages.
We contend that the knowledge garnered from
structural projections applied to interlinear text can
bootstrap the development of resources and tools
across parallel corpora, where such corpora could be
of smaller size and the resulting tools more robust,
opening the door to the development of tools and re-
sources for a larger number of the world’s languages.
Given the imminent death of half of the world’s 6,000
languages (Krauss, 1992), the development of any
language specific tools for a larger percentage of the
world’s languages than is currently possible can aid
in both their documentation and preservation.
Although IGT is usually embedded in linguistics
documents as part of a larger analysis, in and of
itself it contains analysis and interesting informa-
tion about the source language. In particular, the
gloss line, which is word and morpheme aligned with
the source, contains word and morpheme transla-
tions for the source language data, and can even con-
tain grammatically salient annotations (e.g., 3sg for
Third Person Singular). Further, the reader will note
2 A pointed out by a reviewer, there is a long tradi-
tion in the classical languages for using interlinear trans-
lations. So, too, in other literature bases. Our focus here
is strictly limited to IGT, the interlinear form used in the
field of linguistics.
that many words are shared between the gloss and
translation lines, allowing for the alignment between
these two lines as a intermediate step in the align-
ment between the translation and the source.
An effort is underway to collect these interlinear
snippets into an online searchable database, the pri-
mary purpose of which is to help linguists find ana-
lyzed data for languages they are interested in. We
use this resource, called ODIN, the Online Database
of INterlinear text (Lewis, 2006)3, as our primary
data source. At the time of this writing, ODIN con-
tains 36,439 instances of interlinear data for 725 of
the world’s languages.
</bodyText>
<sectionHeader confidence="0.974087" genericHeader="method">
3 The Enrichment Algorithm
</sectionHeader>
<bodyText confidence="0.999434714285714">
Our algorithm enriches the original IGT examples by
building syntactic structures over the English data
and then projects these onto the source language
data via word alignment. The term syntactic struc-
ture in this paper refers to both phrase structure (PS)
and dependency structure (DS). The enrichment pro-
cess has three steps:
</bodyText>
<listItem confidence="0.995781714285714">
1. Parse the English translation using an off-the-
shelf parser.
2. Align the source sentence and English transla-
tion with the help of the gloss line.
3. Project the English syntactic structures to ob-
tain the source syntactic structures using word
alignment.
</listItem>
<subsectionHeader confidence="0.999923">
3.1 Parsing English sentences
</subsectionHeader>
<bodyText confidence="0.9988897">
There are many English parsers available to the pub-
lic, and in this experiment we used Charniak&apos;s parser
(Charniak, 1997), which was trained on the English
Penn Treebank (Marcus et al., 1994). Figure 1(a)
shows a parse tree (in the Penn Treebank style) for
the English translation in Ex (1). Given a parse tree,
we use a head percolation table (Magerman, 1995)
to create the corresponding dependency structure.
Figure 2(a) shows the dependency structure derived
from the parse tree in Figure 1(a).
</bodyText>
<subsectionHeader confidence="0.999913">
3.2 Word alignment
</subsectionHeader>
<bodyText confidence="0.9990428">
Because most of the 700+ languages in ODIN are
low-density languages with no on-line bilingual dic-
tionaries or large parallel corpora, aligning the source
sentence and its English translation directly would
not work well. To take advantage of the unique lay-
out of IGT examples, we propose using the gloss line
as a bridge between the other two lines; that is, we
first align the source sentence and the gloss line, and
then align the gloss line and the English translation.
The process is illustrated in Figure 3.
</bodyText>
<footnote confidence="0.64274">
3The url of ODIN is http://www.csufresno.edu/odin
2 Background
</footnote>
<bodyText confidence="0.999897916666667">
The practice of presenting language data in interlin-
ear form has a long history in the field of linguistics,
going back at least to the time of the structuralists
(see (Swanton, 1912) for early examples). The mod-
ern form of interlinear data presentation started to
gel in the mid-1960s, resulting in the canonical three
line form shown in Ex (1), which we will refer to
as Interlinear Glossed Text, or IGT. The canonical
form consists of three lines: a line for the language
in question (often a sentence, which we will refer to
here as the source sentence), an English gloss line,
and an English translation.2
</bodyText>
<equation confidence="0.491358">
(1) Rhoddodd yr athro lyfr i&apos;r bachgen ddoe
gave-3sg the teacher book to-the boy yesterday
“The teacher gave a book to the boy yesterday”
(Bailyn, 2001)
</equation>
<page confidence="0.993906">
453
</page>
<figureCaption confidence="0.998794">
Figure 1: English PS produced by Charniak&apos;s parser, and source PS projected from the English PS
</figureCaption>
<figure confidence="0.999902171717172">
(b) Source PS after Step 2
(c) Final source PS
S
S
NP
NP1 VP
VBD
NP PP NP
VBD
DT
NN
NP2 PP NP4
NN
DT
IN+DT
NN
NP3
IN
NN
rhoddodd
(gave)
yr
(the)
NN
NN
athro
NN
i’r
(to-the)
(teacher)
DT
NN
i’r
(to-the)
ddoe
(yesterday)
athro
(teacher)
lyfr
(book)
lyfr
(book)
i’r
bachogen
(boy)
rhoddodd
(gave) yr
(the)
bachogen
(boy) ddoe
(yesterday)
(a) English PS
S
NP1 VP
the
boy
DT
VBD
NN
NP4
PP
The
NP3
IN
gave
NN
teacher
NN
NP2
DT
to
yesterday
a
book
DT
NN
lyfr
i’r
ddoe
(a) English DS
gave
to yesterday athro
teacher
book
the
a boy
bachgen
yr
(b) Source DS after Step 2
Rhoddodd
(c) Final source DS
Rhoddodd
yr
bachgen
athro
i’r
lyfr
ddoe
the i’r
</figure>
<figureCaption confidence="0.997758333333333">
Figure 2: English DS derived from English PS, and source DS projected from the English DS
Figure 3: Aligning source sentence and English
translation with help of the gloss line
</figureCaption>
<bodyText confidence="0.9999867">
The alignment between the source sentence and
the gloss line is trivial and our preliminary exper-
iments showed that simply using whitespace and
dashes as delimiters, and assuming a one-to-one
alignment produces almost perfect results. In con-
trast, the alignment between the gloss line and the
English translation is more complicated since align-
ment links can cross and words on one side can link
to zero or more words on the other side. We built
two aligners for this stage, as described below.
</bodyText>
<subsectionHeader confidence="0.904863">
3.2.1 Statistical word aligner
</subsectionHeader>
<bodyText confidence="0.9998138">
We create a parallel corpus by using the gloss lines
and the translation lines of all the IGT examples for
all the languages in ODIN. We then train IBM mod-
els (Brown et al., 1993) using the GIZA++ package
(Och and Ney, 2000). In addition to the common
practice of lowercasing words and combining word
alignments from both directions, we adopt the fol-
lowing strategies to improve word alignment:
Breaking words into morphemes: Since a
multi-morpheme word in a gloss line often corre-
sponds to multiple words in the translation line, we
split each word on the gloss line into morphemes us-
ing the standard IGT morpheme delimiters (e.g., “-
&amp;quot;). For instance, the seven words in the gloss line of
Ex (1) become nine morphemes.
Adding (x,x) pairs: If a word x appears in the
gloss and the translation lines of the same IGT ex-
ample, it is highly likely that the two copies of the
same word should be aligned to each other. To help
GIZA++ recognize this property, we first identify
and collect all such words and then add single word
pairs (x,x) to the training data. For instance, from
Ex (1), we would add a sentence pair for each mor-
pheme (excepting -3sg which does not appear in the
translation line).
</bodyText>
<subsectionHeader confidence="0.589316">
3.2.2 Heuristic word aligner
</subsectionHeader>
<bodyText confidence="0.999978666666667">
Our second word aligner is based on the assump-
tion that if two words (one on the gloss line, the other
on the translation line) have the same root form, they
are likely to be aligned to one other.We built a sim-
ple English morphological analyzer and ran it on the
two lines, and then linked the words with the same
</bodyText>
<figure confidence="0.756967833333333">
Rhoddodd yr athro lyfr i’r bachgen ddoe
gave-3sg the teacher book to-the boy yesterday
The teacher gave a book to the boy yesterday
Source:
Gloss:
Transatlion:
</figure>
<page confidence="0.958901">
454
</page>
<bodyText confidence="0.62523">
root form.4
</bodyText>
<subsectionHeader confidence="0.996276">
3.3 Tree projection
</subsectionHeader>
<bodyText confidence="0.999609333333333">
We designed two projection algorithms: one which
projects PS and the other which projects DS, both
from the English to the source language.5
</bodyText>
<subsectionHeader confidence="0.653242">
3.3.1 Projecting dependency structure
</subsectionHeader>
<bodyText confidence="0.744608222222222">
Our DS projection algorithm is similar to the pro-
jection algorithms described in (Hwa et al., 2002) and
(Quirk et al., 2005). It has four steps: First, we copy
the English DS, and remove all the unaligned English
words from the DS.&apos; Second, we replace each English
word in the DS with the corresponding source words.
If an English word x aligns to several source words,
we will make several copies of the node for x, one
copy for each such source word. The copies will all
be siblings in the DS.
If a source word aligns to multiple English words,
after Step 2 the source word will have several copies
in the resulting DS. In the third step, we keep only
the copy that is closest to the root and remove all the
other copies.&apos; In Step 4, we attach unaligned source
words to the DS using the heuristics described in
(Quirk et al., 2005). Figure 2 shows the English DS,
the source DS after Step 2, and the final DS.
</bodyText>
<subsectionHeader confidence="0.976578">
3.3.2 Projecting phrase structure
</subsectionHeader>
<bodyText confidence="0.997691">
Our PS projection algorithm also has four steps,
the first two being the same as those for projecting
DS. In the third step, starting from the root of the
current source PS and for each node x with more
than one child, we reorder each pair of x&apos;s children
until they are in the same order as dictated by the
source sentence. Let yi and yj be two children of
x, and their spans be Si = [ai, bi] and Sj = [aj, bj].
When we reorder yi and yj, there are four possible
scenarios:
</bodyText>
<listItem confidence="0.820433">
(1) Si and Sj don’t overlap: we put yi before yj
if ai &lt; aj or the opposity if ai &gt; aj.
</listItem>
<bodyText confidence="0.785272588235294">
4When a word is repeated in both the gloss and trans-
lation, the individual occurrences are aligned individually
in left-to-right order.
5The DS projection algorithm as described does not
guarantee that the yield of the resulting source DS has
the same word order as the source sentence; however, if
needed, the algorithm can be easily modified (by mak-
ing its Step 3 similar to the Step 3 of the PS projection
algorithm) to ensure the correct word order.
6Every time we remove an internal node x from a DS,
we make x&apos;s children depend on x&apos;s parent directly.
7The heuristic is not as arbitrary as it sounds because
very often when a source word aligns to multiple English
words, one of the English words dominates the rest in
the DS (e.g., the node for to in Figure 2(a) dominates
the node for the). We are using the dominant word to
represent the whole set.
</bodyText>
<listItem confidence="0.8608831">
(2) Si is a strict subset of Sj: we remove yj
from the PS and promote its children: yj&apos;s
children will become children of yj&apos;s parent.
(3) Sj is a strict subset of Si: we remove yi and
promote its children.
(4) Si and Sj overlap but neither is a strict
subset of the other: we remove both yi and
yj and promote their children. If both yi and
yj are leaf nodes with the same span, we will
merge the two nodes.8
</listItem>
<bodyText confidence="0.9748785">
The last step is to insert unaligned source words
into the source PS. For each unaligned source word
x, we will find its closest left and right neighbors that
are aligned to some English words, and then attach x
to the lowest common ancestor of the two neighbors.
Figure 1 shows the English PS, the source PS after
Step 2, and the final source PS. The three boxes in
1(b) mark the nodes that are removed in Step 3.
</bodyText>
<sectionHeader confidence="0.999757" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999301142857143">
We tested the feasibility of our approach on a small
set of IGT examples for seven languages: Ger-
man (GER), Korean (KKN), Hausa (HUA), Mala-
gasy (MEX), Welsh (WLS), Irish (GLI), and Yaqui
(YAQ). This set of languages was chosen because of
its typological diversity: GER and HUA are SVO
languages, KKN and YAQ are SOV, GLI and WLS
are VSO, and MEX is VOS. In addition, while Ger-
man and Korean are well-studied and have readily
accessible resources that we could use to test the ef-
fectiveness and accuracy of our methods, Yaqui, with
about 16,000 speakers, is a highly endangered lan-
guage and serves as a demonstration of our methods
for resource-poor and endangered languages.
</bodyText>
<subsectionHeader confidence="0.9905755">
4.1 Creating the gold standard for the test
set
</subsectionHeader>
<bodyText confidence="0.780858933333333">
The number of IGT examples in ODIN varies greatly
across the seven languages, ranging from less than
one hundred for Welsh to over seventeen hundred for
German. For each language, we randomly picked 50-
150 IGT examples from the available examples whose
English translations had at least five words.9 The
examples were manually checked and corrupted ex-
amples were thrown away. The remaining examples
8 W will keep one copy and merge the POS tag of
the words. For instance, the tag IN+DT in Figure 1(c)
was created when two copies of Vr in Figure 1(b) were
merged.
9We skipped examples with very short English trans-
lations because they are unlikely to contain much in the
way of syntactic structures.
</bodyText>
<page confidence="0.999357">
455
</page>
<tableCaption confidence="0.999946">
Table 1: The size and average sentence length of the test data
</tableCaption>
<table confidence="0.998915285714286">
GER KKN HUA MEX WLS GLI YAQ Total
# of IGT examples 104 103 77 87 53 46 68 538
# of src words 739 526 441 498 313 252 404 3173
Ave src sent leng 7.11 5.11 5.73 5.72 5.91 5.48 5.94 5.90
# of Eng words 711 735 520 646 329 278 544 3823
Ave Eng sent leng 7.41 7.14 6.75 7.43 6.21 6.04 8.01 7.11
# of speakers 128M 78M 39M 9.4M 580K 260K 16K 255.3M
</table>
<bodyText confidence="0.9966105">
formed our test data. Table 1 shows the size and av-
erage sentence lengths of the test data by language.10
The languages are sorted by number of speakers (as
derived from the Ethnologue (Gordon, 2005)).
We ran our algorithm on the test data, and the
system produced the following: an English PS, En-
glish DS, word alignment, projected source PS, and
projected source DS. We asked human annotators to
manually check the output and correct the English
DS, word alignments and projected DS structures
where necessary.11 12 In order to calculate inter-
annotator agreement, the Yaqui data and half of the
German data were each checked by two annotators,
and the disagreement between the annotators was
adjudicated and a gold standard was created. The
inter-annotator agreement (a.k.a. the F-measure of
dependency or alignment links) on English DS, gloss-
translation alignment, and projected source DS are
96.34%, 96.35%, and 91.09%, respectively. The rest
of the data were annotated by one annotator.
</bodyText>
<subsectionHeader confidence="0.997186">
4.2 Word alignment results
</subsectionHeader>
<bodyText confidence="0.999978666666667">
We tested our word aligners on 70% (374 examples)
of the whole test set (538 examples), while reserving
the remaining 30% for future use.
</bodyText>
<subsectionHeader confidence="0.540278">
4.2.1 Statistical word aligner
</subsectionHeader>
<bodyText confidence="0.9757375">
As indicated earlier, the ODIN database contains
36,439 IGT examples. We removed duplicates13 and
</bodyText>
<tableCaption confidence="0.72261452631579">
10There are three reasons why the sentences are so
short. First, since IGT is used to present particular lin-
guistically salient morphological or syntactic material,
sentences in IGT are only as long as needed for the
given expose. Second, space constraints often dictate us-
ing shorter examples (i.e., they must fit on one line).
Third, the IGT extraction algorithm currently used in
ODIN does not search for the less common multi-line
(i.e., greater than three line) examples.
11The English PS and source PS were not corrected;
without a thorough linguistic study of the source lan-
guages, it is impossible to devise appropriate gold stan-
dards for their phrase structures.
12The DS structures for the English and source lan-
guage in the gold standard can be non-isomorphic.
13Duplicates are common since it is standard practice
in linguistics to copy and cite language examples from
other papers.
Table 2: The training data for GIZA++
</tableCaption>
<table confidence="0.999266">
# of sentences 28,902
# of words in gloss lines 174,765
# of morphemes in gloss lines 251,465
# of words in translation lines 217,022
Size of gloss word vocabulary 16360
Size of gloss morpheme vocabulary 14050
Size of translation word vocabulary 14029
</table>
<tableCaption confidence="0.9952135">
Table 3: The word alignment results when gloss
words are not split into morphemes
</tableCaption>
<table confidence="0.9990685">
Precision Recall F-measure
Gloss trans 0.674 0.689 0.681
Trans gloss 0.721 0.823 0.769
Intersection 0.948 0.620 0.750
Union 0.590 0.892 0.711
Refined 0.846 0.780 0.812
</table>
<bodyText confidence="0.994782">
examples with missing lines, and used the remain-
ing 28,902 examples for GIZA++ training.14 Table
2 shows the statistics of the training data with all
words lowercased. Tables 3–5 show the performance
of the word aligner under three settings:
</bodyText>
<listItem confidence="0.6830185">
(1): Not splitting words in the gloss lines into mor-
phemes.
(2): Splitting words in gloss lines into morphemes.
(3): Doing (2) plus adding (x,x) sentence pairs into
</listItem>
<bodyText confidence="0.7330764">
the training data, where x is a word that appears
in both the gloss and translation lines of the
same IGT example.
For each setting, we trained in both directions and
combined the two alignments by taking the intersec-
tion, union, and refined as defined in (Och and Ney,
2000). The best F-score for each setting is in bold-
face. From the tables, it is clear that the third set-
ting works the best, and combining the alignments
14Interestingly, although the IGT examples in the
training data come from hundreds of languages in ODIN,
IBM Model 4 performs significantly better than Models
1 and 2 (by at least two percent points for F-measure);
therefore, all the GIZA++ results reported in the paper
are based on Model 4.
</bodyText>
<page confidence="0.998969">
456
</page>
<tableCaption confidence="0.977904">
Table 4: The word alignment results when gloss
words are split into morphemes
</tableCaption>
<table confidence="0.999969">
Precision Recall F-measure
Gloss trans 0.746 0.889 0.811
Trans gloss 0.797 0.863 0.829
Intersection 0.958 0.811 0.878
Union 0.659 0.941 0.775
Refined 0.918 0.900 0.909
</table>
<tableCaption confidence="0.9965915">
Table 5: The word alignment results when (x,x) pairs
are added
</tableCaption>
<table confidence="0.915673">
Precision Recall F-measure
Gloss trans 0.759 0.922 0.833
Trans gloss 0.801 0.924 0.858
Intersection 0.956 0.885 0.919
Union 0.666 0.961 0.787
Refined 0.908 0.921 0.915
from both directions works better than either direc-
tion alone.15
</table>
<subsubsectionHeader confidence="0.598936">
4.2.2 Heuristic word aligner
</subsubsectionHeader>
<bodyText confidence="0.980309285714286">
The word aligner has two settings. In the first
one, the aligner aligns two words if and only if they
have the same orthographic form. In the second, it
aligns two words if and only if they have the same
root form.1s The results are shown in the first and
second rows of Table 6.
We experimented with various methods of com-
bining the two aligners, and the best one is an aug-
15For languages with hundreds of IGT examples, one
may wonder whether training GIZA++ with the data for
that language alone would outperform the system trained
with IGT examples from all the languages in ODIN. To
answer this question, we ran three experiments on the
German data (for which there are 1757 IGT examples
in ODIN after removing duplicates): (a) trained on the
(gloss, translation) pairs for all IGT data, (b) trained on
the (gloss, translation) pairs of the German data alone,
and (c) trained on the (source, translation) pairs of the
German data. The test was run against 58 IGT examples,
a subset of the German test data in Table 1. It turns out
that (a) performs much better than (b) and (c), which
justifies the approach we proposed in Section 3.2. For
instance, the F-measures for the refined alignment for
(a)-(c) are 92.5%, 90.2%, and 85.6%, respectively.
16For the second setting, we wrote a 90-line Perl appli-
cation that finds the root for each English word by using
a dozen regular expression patterns combined with a list
of 163 irregular verbs with their inflected forms.
</bodyText>
<tableCaption confidence="0.999283">
Table 6: The performance of heuristic word aligner
</tableCaption>
<table confidence="0.97028425">
Precision Recall F-measure
No morphing 0.983 0.742 0.846
With morphing 0.983 0.854 0.914
Augmented aligner 0.981 0.881 0.928
</table>
<bodyText confidence="0.749271">
mented heuristic word aligner which links two words
if and only if they have the same root form or they
are good translations of each other according to the
translation model built by GIZA++.17 The result
is shown in the last row of Table 6. We used this
aligner for the structural projection experiment.
</bodyText>
<subsectionHeader confidence="0.999756">
4.3 Projection results
</subsectionHeader>
<bodyText confidence="0.980951833333333">
We evaluated the results of the major steps in our al-
gorithm: the English DS derived from the parse trees
produced by the English parser, the word alignment
between the gloss and translation lines, and the pro-
jected source DS. We calculated the precision, recall,
and F-score of the dependency links and word align-
ment links. The F-scores are shown in Table 7.18
Both the English parser and the word aligner work
reasonably well with most F-scores well above 90%.
The F-scores for dependency links in the source DS
are lower partly due to errors in early parts of the
process (e.g., English DS and word alignment), which
propagates to this step. When we replace the auto-
matically generated English DS and word alignment
with the ones in gold standard, the F-measure of
source DS increases significantly, as shown in Table
8.
To identify the causes of the remaining errors in
the oracle results, we manually checked and classified
one third of the errors in the German data. Among
the 43 errors in the source DS, 26 (60.5%) are due
to language divergence (e.g., head switching), eight
(18.6%) are errors made by the projection heuristics,
and nine (20.9%) are due to non-exact translations
such as the one shown in Ex (2). Because language
divergence can reveal interesting typological distinc-
tions between languages, the first type of error may,
in fact, identify examples that could be of great value
to linguists and computational linguists.
(2) der Antrag des oder der Dozenten
</bodyText>
<subsectionHeader confidence="0.790953">
the petition of-the.SG or of-the.PL docent.MSC
</subsectionHeader>
<bodyText confidence="0.838694">
“the petition of the docent.” (Daniels, 2001)
</bodyText>
<sectionHeader confidence="0.999768" genericHeader="method">
5 Discussion
</sectionHeader>
<subsectionHeader confidence="0.9231445">
5.1 The IGT bias and knowledge discovery
from enriched data
</subsectionHeader>
<bodyText confidence="0.997917">
From the enriched data, various kinds of informa-
tion can be extracted, such as grammars and transfer
rules. We extracted CFGs for the seven languages by
reading off the context-free rules from the projected
</bodyText>
<footnote confidence="0.9364882">
17We treat a word pair, (e,f), as a good translation if
and only if both P(e|f) and P(f|e) are high.
18The Total word alignment F-measure is higher than
0.928 as mentioned in Table 6 because the test set used
here is the superset of the one used in that section.
</footnote>
<page confidence="0.997157">
457
</page>
<tableCaption confidence="0.999755">
Table 7: The system performance on the seven languages
</tableCaption>
<table confidence="0.9994455">
GER KKN HUA MEX WLS GLI YAQ Total
English DS 94.25 89.78 96.15 95.51 91.49 93.53 93.57 93.48
Word alignment 94.91 94.20 94.71 94.26 95.65 88.11 93.64 94.03
Source DS 78.14 82.16 84.71 84.22 84.39 78.17 79.36 81.45
</table>
<tableCaption confidence="0.995861">
Table 8: The F-measure of source dependency links with perfect English DS and/or word alignment
</tableCaption>
<table confidence="0.999633">
GER KKN HUA MEX WLS GLI YAQ Total
With gold Eng DS 82.21 87.67 88.46 85.23 91.72 80.16 83.81 85.42
With gold alignment 85.77 86.15 86.07 88.44 84.98 82.40 86.27 86.00
With both 91.21 91.67 89.82 89.65 94.25 85.77 90.68 90.64
</table>
<tableCaption confidence="0.988382">
Table 9: Extracted CFGs and evidence of word order
</tableCaption>
<table confidence="0.9987435">
HUA MEX GLI YAQ
Word order SVO VOS VSO SOV
# of rule types 102 129 86 115
# of rule tokens 384 466 202 295
</table>
<bodyText confidence="0.998064255813954">
source PS. The numbers of rule types and rule tokens
for four of the languages are listed in Table 9.
It is important to note that IGT data is somewhat
biased: examples tend to be short and are selected
for the purposes of a particular rhetorical context.
They, therefore, deviate from the “normal” usage
that one might normally expect to find in a corpus of
language data. As such, one might question whether
the information extracted from IGT would also be
skewed due to these biases.
To test the usefulness of the data for answering
typological questions, we wrote a tool that predicted
the canonical word order (e.g., SOV, SVO) of a lan-
guage using simple heuristics. It was able to pro-
duce the correct answers for all seven languages in
our sample.19 20 We suspect that the number of
IGT instances and their diversity (i.e., from multiple
documents) is crucial to overcoming the IGT bias,
and feel that the same heuristics could be applied
to a much larger sample of languages. These could
be further adapted to additional typological param-
eters beyond word order (e.g., orders of heads and
modifiers in PS). We leave this to future work.
Given syntactically enriched data, it is also possi-
ble to search for patterns that are linguistically in-
teresting. For instance, we wrote a piece of code
that automatically identified examples with crossing
19Our code simply went through all the rules in the
extracted CFGs and checked the position of the verb with
respect to its subject and object. The -SBJ and -OBJ
function tags were added to the English parse trees using
simple heuristics and were carried over to the source PS
via the projection algorithm.
20There is disagreement among linguists about Ger-
man’s underlying word order, being either SVO or SOV.
Our heuristics returned SOV.
dependencies (i.e., the ones whose DS have crossing
links). One such example from the Yaqui data is in
Ex (3), where the coordinated noun phrase kow-ta
into mis-ta “the pig and the cat” is separated by the
verb bwuise-k “grasp”. Note that the crossing depen-
dencies can only be discovered in the Yaqui data and
not in the English since none exist in the English.
</bodyText>
<figure confidence="0.562802">
(3) inepo kow-ta bwuise-k into mis-ta
1SG pig-NNOM.SG grasp-PST and cat-NNOM.SG
“I caught the pig and the cat.&amp;quot; (Martinez Fabian,
2006)
</figure>
<bodyText confidence="0.999622285714286">
So far, we have examined linguistically interesting
information in the source. In the future, we plan to
examine structures in both the source and English.
For instance, we plan to extract transfer rules from
the aligned source and English structures and also
calculate head/modifier crossings between languages
similar to those described in (Fox, 2002).
</bodyText>
<subsectionHeader confidence="0.99767">
5.2 Tools and resource building
</subsectionHeader>
<bodyText confidence="0.999969727272727">
The information that we discover about a language
can help with the development of tools for the lan-
guage. The order of constituents, for instance, can
be used to inform prototype-driven learning strate-
gies (Haghighi and Klein, 2006), which can then
be applied to raw corpora. It is also possible that
small samples of data showing the alignment inter-
actions between source language structures and those
of English can provide essential bootstrap informa-
tion for informing machine translation systems (cf
(Quirk and Corston-Oliver, 2006)).
Proof of the utility of an enriched corpus built over
ODIN will depend crucially on its evaluation, and we
feel that an important part of our future work will be
the development of parsers that have been trained on
projected structures. These parsers can be evaluated
against human built corpora such as treebanks (obvi-
ously, only for those languages that have treebanks).
Proof will also come from linguists who will be able
to use the corpus to search for constructions of in-
terest (e.g., passives, relative clauses, etc.), and will
likely be able to do so using standard tools such as
</bodyText>
<page confidence="0.99622">
458
</page>
<bodyText confidence="0.994716">
tgrep.21 Crucially, linguists would be able to conduct
such searches over a very large number of languages.
Raymond G. Gordon, editor. 2005. Ethnologue: Lan-
guages of the World. SIL International, Dallas, TX,
fifteenth edition.
</bodyText>
<sectionHeader confidence="0.999081" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999055608695652">
In this paper we demonstrate a methodology for pro-
jecting structure from annotated English data onto
source language data. Because each IGT instance
provides an English translation and an intermedi-
ary gloss line, we are able to project full syntac-
tic structures from the automatically parsed trans-
lation. The fact that our basic methodology and
code were applied to a typologically diverse sample
of seven languages without modification suggests the
potential for application to a much larger sample,
perhaps numbering into the hundreds of languages.
The resulting enriched structures could be of great
importance to the fields of linguistics and compu-
tational linguistics. For the former, search facili-
ties could be built over the data that would allow
linguists to find syntactically marked up data for a
large variety of languages, and could even accommo-
date cross-linguistic comparisons and analyses. For
the latter, we could automatically discern grammars
and transfer rules from the aligned and marked up
data, where these computational artifacts could act
as bootstraps for the development of additional tools
and resources.
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999950148648649">
John Frederick Bailyn. 2001. Inversion, dislocation and
optionality in russian. In Gerhild Zybatow, editor,
Current Issues in Formal Slavic Linguistics.
Peter Brown, Vincent Pietra, Stephen Pietra, and Robert
Mercer. 1993. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation. Computa-
tional Linguistics, 19(2):263–311.
Eugene Charniak. 1997. Statistical Parsing with a
Context-Free Grammar and Word Statistics. In Proc.
of AAAI-1997.
Michael W. Daniels. 2001. On a type-based analysis
of feature neutrality and the coordination of unlikes.
In Proceedings of the 8th International HPSG Confer-
ence. CSLI Publications.
Bonnie J. Dorr. 1994. Machine translation divergences:
a formal description and proposed solution. Computa-
tional Linguistics, 20(4):597–635.
Heidi Fox. 2002. Phrasal cohesion and statistical ma-
chine translation. In Proceedings of EMNLP 2002,
Philadelphia, Pennsylvania.
21This kind of search is reminiscent of Resnik&apos;s Lin-
guists Search Engine (http://lse.umiacs.umd.edu), which
allows structural search across text found on the Web.
Aria Haghighi and Dan Klein. 2006. Protoype-driven
sequence models. In Proceedings of HLT-NAACL, New
York City, NY.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan
Kolak. 2002. Evaluating translational correspondence
using annotation projection. In Proceedings of the 40th
Annual Meeting of the ACL, Philadelphia, Pennsylva-
nia.
Michael Krauss. 1992. The World’s Languages in Crisis.
Language, 68(1):4–10.
William D. Lewis. 2006. ODIN: A Model for Adapting
and Enriching Legacy Infrastructure. In Proceedings
of the e-Humanities Workshop, Amsterdam. Held in
cooperation with e-Science 2006: 2nd IEEE Interna-
tional Conference on e-Science and Grid Computing.
David M. Magerman. 1995. Statistical Decision-Tree
Models for Parsing. In Proc. of the 33rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL-1995), Cambridge, Massachusetts, USA.
Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,
et al. 1994. The Penn Treebank: Annotating Pred-
icate Argument Structure. In Proc of ARPA Speech
and Natural Language Workshop.
Constantino Martinez Fabian. 2006. Yaqui Coordina-
tion. Ph.D. thesis, University of Arizona.
Franz-Josef Och and Hermann Ney. 2000. Improved Sta-
tistical Alignment Models. In the 38th Annual Confer-
ence of the Association for Computational Linguistics
(ACL-2000), pages 440–447.
Chris Quirk and Simon Corston-Oliver. 2006. The im-
pact of parse quality on syntactically-informed statis-
tical machine translation. In Proceedings of EMNLP
2006.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency tree translation: Syntactically informed
phrasal smt. In Proceedings of ACL 2005.
John R. Swanton. 1912. Haida songs. In Franz Boas,
editor, Publications of the American Ethnological So-
ciety, Volume III. E. J. Brill.
Benjamin Wellington, Sonjia Waxmonsky, and I. Dan
Melamed. 2006. Empirical lower bounds on the com-
plexity of translation equivalence. In Proceedings of
ACL 2006.
Chenhai Xi and Rebecca Hwa. 2005. A backoff model
for bootstrapping resources for non-English languages.
In Proceedings of HLT-EMNLP, pages 851–858, Van-
couver, British Columbia, Canada.
David Yarowksy and Grace Ngai. 2001. Inducing Mul-
tilingual POS taggers and NP Bracketers via robust
projection across aligned corpora. In Proceedings of
NAACL-2001, pages 377–404.
</reference>
<page confidence="0.999128">
459
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.502512">
<title confidence="0.999234">Multilingual Structural Projection across Interlinear Text</title>
<author confidence="0.991275">Fei</author>
<affiliation confidence="0.9996865">Department of University of</affiliation>
<address confidence="0.971322">Seattle, WA</address>
<email confidence="0.9999">fxia@u.washington.edu</email>
<author confidence="0.998357">D William</author>
<affiliation confidence="0.999766">Department of University of</affiliation>
<address confidence="0.949135">Seattle, WA</address>
<email confidence="0.998887">wlewis2@u.washington.edu</email>
<abstract confidence="0.99954755">This paper explores the potential for annotating and enriching data for low-density languages via the alignment and projection of syntactic structure from parsed data for resource-rich languages such as English. We seek to develop enriched resources for a large number of the world’s languages, most of which have no significant digital presence. We do this by tapping the body of Web-based linguistic data, most of which exists in small, analyzed chunks embedded in scholarly papers, journal articles, Web pages, and other online documents. By harvesting and enriching these data, we can provide the means for knowledge discovery across the resulting corpus that can lead to building computational resources such as grammars and transfer rules, which, in turn, can be used as bootstraps for build-</abstract>
<intro confidence="0.554413">ing additional tools and resources for the</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Frederick Bailyn</author>
</authors>
<title>Inversion, dislocation and optionality in russian.</title>
<date>2001</date>
<booktitle>In Gerhild Zybatow, editor, Current Issues in Formal Slavic Linguistics.</booktitle>
<contexts>
<context position="8748" citStr="Bailyn, 2001" startWordPosition="1401" endWordPosition="1402">ructuralists (see (Swanton, 1912) for early examples). The modern form of interlinear data presentation started to gel in the mid-1960s, resulting in the canonical three line form shown in Ex (1), which we will refer to as Interlinear Glossed Text, or IGT. The canonical form consists of three lines: a line for the language in question (often a sentence, which we will refer to here as the source sentence), an English gloss line, and an English translation.2 (1) Rhoddodd yr athro lyfr i&apos;r bachgen ddoe gave-3sg the teacher book to-the boy yesterday “The teacher gave a book to the boy yesterday” (Bailyn, 2001) 453 Figure 1: English PS produced by Charniak&apos;s parser, and source PS projected from the English PS (b) Source PS after Step 2 (c) Final source PS S S NP NP1 VP VBD NP PP NP VBD DT NN NP2 PP NP4 NN DT IN+DT NN NP3 IN NN rhoddodd (gave) yr (the) NN NN athro NN i’r (to-the) (teacher) DT NN i’r (to-the) ddoe (yesterday) athro (teacher) lyfr (book) lyfr (book) i’r bachogen (boy) rhoddodd (gave) yr (the) bachogen (boy) ddoe (yesterday) (a) English PS S NP1 VP the boy DT VBD NN NP4 PP The NP3 IN gave NN teacher NN NP2 DT to yesterday a book DT NN lyfr i’r ddoe (a) English DS gave to yesterday athro</context>
</contexts>
<marker>Bailyn, 2001</marker>
<rawString>John Frederick Bailyn. 2001. Inversion, dislocation and optionality in russian. In Gerhild Zybatow, editor, Current Issues in Formal Slavic Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>Vincent Pietra</author>
<author>Stephen Pietra</author>
<author>Robert Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="10369" citStr="Brown et al., 1993" startWordPosition="1699" endWordPosition="1702">inary experiments showed that simply using whitespace and dashes as delimiters, and assuming a one-to-one alignment produces almost perfect results. In contrast, the alignment between the gloss line and the English translation is more complicated since alignment links can cross and words on one side can link to zero or more words on the other side. We built two aligners for this stage, as described below. 3.2.1 Statistical word aligner We create a parallel corpus by using the gloss lines and the translation lines of all the IGT examples for all the languages in ODIN. We then train IBM models (Brown et al., 1993) using the GIZA++ package (Och and Ney, 2000). In addition to the common practice of lowercasing words and combining word alignments from both directions, we adopt the following strategies to improve word alignment: Breaking words into morphemes: Since a multi-morpheme word in a gloss line often corresponds to multiple words in the translation line, we split each word on the gloss line into morphemes using the standard IGT morpheme delimiters (e.g., “- &amp;quot;). For instance, the seven words in the gloss line of Ex (1) become nine morphemes. Adding (x,x) pairs: If a word x appears in the gloss and t</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter Brown, Vincent Pietra, Stephen Pietra, and Robert Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical Parsing with a Context-Free Grammar and Word Statistics.</title>
<date>1997</date>
<booktitle>In Proc. of AAAI-1997.</booktitle>
<contexts>
<context position="7012" citStr="Charniak, 1997" startWordPosition="1108" endWordPosition="1109">these onto the source language data via word alignment. The term syntactic structure in this paper refers to both phrase structure (PS) and dependency structure (DS). The enrichment process has three steps: 1. Parse the English translation using an off-theshelf parser. 2. Align the source sentence and English translation with the help of the gloss line. 3. Project the English syntactic structures to obtain the source syntactic structures using word alignment. 3.1 Parsing English sentences There are many English parsers available to the public, and in this experiment we used Charniak&apos;s parser (Charniak, 1997), which was trained on the English Penn Treebank (Marcus et al., 1994). Figure 1(a) shows a parse tree (in the Penn Treebank style) for the English translation in Ex (1). Given a parse tree, we use a head percolation table (Magerman, 1995) to create the corresponding dependency structure. Figure 2(a) shows the dependency structure derived from the parse tree in Figure 1(a). 3.2 Word alignment Because most of the 700+ languages in ODIN are low-density languages with no on-line bilingual dictionaries or large parallel corpora, aligning the source sentence and its English translation directly wou</context>
</contexts>
<marker>Charniak, 1997</marker>
<rawString>Eugene Charniak. 1997. Statistical Parsing with a Context-Free Grammar and Word Statistics. In Proc. of AAAI-1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael W Daniels</author>
</authors>
<title>On a type-based analysis of feature neutrality and the coordination of unlikes.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th International HPSG Conference.</booktitle>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="25113" citStr="Daniels, 2001" startWordPosition="4282" endWordPosition="4283">e German data. Among the 43 errors in the source DS, 26 (60.5%) are due to language divergence (e.g., head switching), eight (18.6%) are errors made by the projection heuristics, and nine (20.9%) are due to non-exact translations such as the one shown in Ex (2). Because language divergence can reveal interesting typological distinctions between languages, the first type of error may, in fact, identify examples that could be of great value to linguists and computational linguists. (2) der Antrag des oder der Dozenten the petition of-the.SG or of-the.PL docent.MSC “the petition of the docent.” (Daniels, 2001) 5 Discussion 5.1 The IGT bias and knowledge discovery from enriched data From the enriched data, various kinds of information can be extracted, such as grammars and transfer rules. We extracted CFGs for the seven languages by reading off the context-free rules from the projected 17We treat a word pair, (e,f), as a good translation if and only if both P(e|f) and P(f|e) are high. 18The Total word alignment F-measure is higher than 0.928 as mentioned in Table 6 because the test set used here is the superset of the one used in that section. 457 Table 7: The system performance on the seven languag</context>
</contexts>
<marker>Daniels, 2001</marker>
<rawString>Michael W. Daniels. 2001. On a type-based analysis of feature neutrality and the coordination of unlikes. In Proceedings of the 8th International HPSG Conference. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Machine translation divergences: a formal description and proposed solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="3877" citStr="Dorr, 1994" startWordPosition="594" endWordPosition="595">such a resource allows one to develop computational artifacts, such as grammars and transfer rules, which can be used as “seed” knowledge for building larger resources. In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006). Of particular relevance to MT is the issue of struc452 Proceedings of NAACL HLT 2007, pages 452–459, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics tural divergence (Dorr, 1994). Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al., 2002). However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundreds of languages. We contend that the knowledge garnered from structural projections applied to interlinear text can bootstrap the development of resources and tools across parallel corpora, where such corpora </context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Bonnie J. Dorr. 1994. Machine translation divergences: a formal description and proposed solution. Computational Linguistics, 20(4):597–635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heidi Fox</author>
</authors>
<title>Phrasal cohesion and statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP 2002,</booktitle>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="4128" citStr="Fox, 2002" startWordPosition="638" endWordPosition="639">ping annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006). Of particular relevance to MT is the issue of struc452 Proceedings of NAACL HLT 2007, pages 452–459, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics tural divergence (Dorr, 1994). Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al., 2002). However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundreds of languages. We contend that the knowledge garnered from structural projections applied to interlinear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust, opening the door to the development of tools and resources for a larger number of the world’s languages. Given the imminent death of half of the world’s 6,000 languages (Krauss, 1992), the </context>
<context position="29049" citStr="Fox, 2002" startWordPosition="4962" endWordPosition="4963">e crossing dependencies can only be discovered in the Yaqui data and not in the English since none exist in the English. (3) inepo kow-ta bwuise-k into mis-ta 1SG pig-NNOM.SG grasp-PST and cat-NNOM.SG “I caught the pig and the cat.&amp;quot; (Martinez Fabian, 2006) So far, we have examined linguistically interesting information in the source. In the future, we plan to examine structures in both the source and English. For instance, we plan to extract transfer rules from the aligned source and English structures and also calculate head/modifier crossings between languages similar to those described in (Fox, 2002). 5.2 Tools and resource building The information that we discover about a language can help with the development of tools for the language. The order of constituents, for instance, can be used to inform prototype-driven learning strategies (Haghighi and Klein, 2006), which can then be applied to raw corpora. It is also possible that small samples of data showing the alignment interactions between source language structures and those of English can provide essential bootstrap information for informing machine translation systems (cf (Quirk and Corston-Oliver, 2006)). Proof of the utility of an</context>
</contexts>
<marker>Fox, 2002</marker>
<rawString>Heidi Fox. 2002. Phrasal cohesion and statistical machine translation. In Proceedings of EMNLP 2002, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="false">
<title>21This kind of search is reminiscent of Resnik&apos;s Linguists Search Engine (http://lse.umiacs.umd.edu), which allows structural search across text found on the Web.</title>
<marker></marker>
<rawString>21This kind of search is reminiscent of Resnik&apos;s Linguists Search Engine (http://lse.umiacs.umd.edu), which allows structural search across text found on the Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Protoype-driven sequence models.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<location>New York City, NY.</location>
<contexts>
<context position="3669" citStr="Haghighi and Klein, 2006" startWordPosition="561" endWordPosition="564">s. We do not propose that a database of interlinear text alone is sufficient to create NLP resources and tools, but rather that it may act as a means for more rapidly developing such tools using less data. We contend that such a resource allows one to develop computational artifacts, such as grammars and transfer rules, which can be used as “seed” knowledge for building larger resources. In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006). Of particular relevance to MT is the issue of struc452 Proceedings of NAACL HLT 2007, pages 452–459, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics tural divergence (Dorr, 1994). Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al., 2002). However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundred</context>
<context position="29316" citStr="Haghighi and Klein, 2006" startWordPosition="5003" endWordPosition="5006">006) So far, we have examined linguistically interesting information in the source. In the future, we plan to examine structures in both the source and English. For instance, we plan to extract transfer rules from the aligned source and English structures and also calculate head/modifier crossings between languages similar to those described in (Fox, 2002). 5.2 Tools and resource building The information that we discover about a language can help with the development of tools for the language. The order of constituents, for instance, can be used to inform prototype-driven learning strategies (Haghighi and Klein, 2006), which can then be applied to raw corpora. It is also possible that small samples of data showing the alignment interactions between source language structures and those of English can provide essential bootstrap information for informing machine translation systems (cf (Quirk and Corston-Oliver, 2006)). Proof of the utility of an enriched corpus built over ODIN will depend crucially on its evaluation, and we feel that an important part of our future work will be the development of parsers that have been trained on projected structures. These parsers can be evaluated against human built corpo</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Protoype-driven sequence models. In Proceedings of HLT-NAACL, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Okan Kolak</author>
</authors>
<title>Evaluating translational correspondence using annotation projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the ACL,</booktitle>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="3995" citStr="Hwa et al., 2002" startWordPosition="612" endWordPosition="615"> used as “seed” knowledge for building larger resources. In particular, knowing a little about the structure of a language can help in developing annotated corpora and tools, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006). Of particular relevance to MT is the issue of struc452 Proceedings of NAACL HLT 2007, pages 452–459, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics tural divergence (Dorr, 1994). Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al., 2002). However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundreds of languages. We contend that the knowledge garnered from structural projections applied to interlinear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust, opening the door to the development of tools and resourc</context>
<context position="12204" citStr="Hwa et al., 2002" startWordPosition="2020" endWordPosition="2023"> be aligned to one other.We built a simple English morphological analyzer and ran it on the two lines, and then linked the words with the same Rhoddodd yr athro lyfr i’r bachgen ddoe gave-3sg the teacher book to-the boy yesterday The teacher gave a book to the boy yesterday Source: Gloss: Transatlion: 454 root form.4 3.3 Tree projection We designed two projection algorithms: one which projects PS and the other which projects DS, both from the English to the source language.5 3.3.1 Projecting dependency structure Our DS projection algorithm is similar to the projection algorithms described in (Hwa et al., 2002) and (Quirk et al., 2005). It has four steps: First, we copy the English DS, and remove all the unaligned English words from the DS.&apos; Second, we replace each English word in the DS with the corresponding source words. If an English word x aligns to several source words, we will make several copies of the node for x, one copy for each such source word. The copies will all be siblings in the DS. If a source word aligns to multiple English words, after Step 2 the source word will have several copies in the resulting DS. In the third step, we keep only the copy that is closest to the root and remo</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2002</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2002. Evaluating translational correspondence using annotation projection. In Proceedings of the 40th Annual Meeting of the ACL, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Krauss</author>
</authors>
<title>The World’s Languages in Crisis.</title>
<date>1992</date>
<journal>Language,</journal>
<volume>68</volume>
<issue>1</issue>
<contexts>
<context position="4722" citStr="Krauss, 1992" startWordPosition="735" endWordPosition="736">ned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundreds of languages. We contend that the knowledge garnered from structural projections applied to interlinear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust, opening the door to the development of tools and resources for a larger number of the world’s languages. Given the imminent death of half of the world’s 6,000 languages (Krauss, 1992), the development of any language specific tools for a larger percentage of the world’s languages than is currently possible can aid in both their documentation and preservation. Although IGT is usually embedded in linguistics documents as part of a larger analysis, in and of itself it contains analysis and interesting information about the source language. In particular, the gloss line, which is word and morpheme aligned with the source, contains word and morpheme translations for the source language data, and can even contain grammatically salient annotations (e.g., 3sg for Third Person Sing</context>
</contexts>
<marker>Krauss, 1992</marker>
<rawString>Michael Krauss. 1992. The World’s Languages in Crisis. Language, 68(1):4–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William D Lewis</author>
</authors>
<title>ODIN: A Model for Adapting and Enriching Legacy Infrastructure.</title>
<date>2006</date>
<booktitle>In Proceedings of the e-Humanities Workshop,</booktitle>
<location>Amsterdam. Held</location>
<contexts>
<context position="6103" citStr="Lewis, 2006" startWordPosition="961" endWordPosition="962">other literature bases. Our focus here is strictly limited to IGT, the interlinear form used in the field of linguistics. that many words are shared between the gloss and translation lines, allowing for the alignment between these two lines as a intermediate step in the alignment between the translation and the source. An effort is underway to collect these interlinear snippets into an online searchable database, the primary purpose of which is to help linguists find analyzed data for languages they are interested in. We use this resource, called ODIN, the Online Database of INterlinear text (Lewis, 2006)3, as our primary data source. At the time of this writing, ODIN contains 36,439 instances of interlinear data for 725 of the world’s languages. 3 The Enrichment Algorithm Our algorithm enriches the original IGT examples by building syntactic structures over the English data and then projects these onto the source language data via word alignment. The term syntactic structure in this paper refers to both phrase structure (PS) and dependency structure (DS). The enrichment process has three steps: 1. Parse the English translation using an off-theshelf parser. 2. Align the source sentence and Eng</context>
</contexts>
<marker>Lewis, 2006</marker>
<rawString>William D. Lewis. 2006. ODIN: A Model for Adapting and Enriching Legacy Infrastructure. In Proceedings of the e-Humanities Workshop, Amsterdam. Held in cooperation with e-Science 2006: 2nd IEEE International Conference on e-Science and Grid Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
</authors>
<title>Statistical Decision-Tree Models for Parsing.</title>
<date>1995</date>
<booktitle>In Proc. of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL-1995),</booktitle>
<location>Cambridge, Massachusetts, USA.</location>
<contexts>
<context position="7251" citStr="Magerman, 1995" startWordPosition="1150" endWordPosition="1151"> using an off-theshelf parser. 2. Align the source sentence and English translation with the help of the gloss line. 3. Project the English syntactic structures to obtain the source syntactic structures using word alignment. 3.1 Parsing English sentences There are many English parsers available to the public, and in this experiment we used Charniak&apos;s parser (Charniak, 1997), which was trained on the English Penn Treebank (Marcus et al., 1994). Figure 1(a) shows a parse tree (in the Penn Treebank style) for the English translation in Ex (1). Given a parse tree, we use a head percolation table (Magerman, 1995) to create the corresponding dependency structure. Figure 2(a) shows the dependency structure derived from the parse tree in Figure 1(a). 3.2 Word alignment Because most of the 700+ languages in ODIN are low-density languages with no on-line bilingual dictionaries or large parallel corpora, aligning the source sentence and its English translation directly would not work well. To take advantage of the unique layout of IGT examples, we propose using the gloss line as a bridge between the other two lines; that is, we first align the source sentence and the gloss line, and then align the gloss lin</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>David M. Magerman. 1995. Statistical Decision-Tree Models for Parsing. In Proc. of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL-1995), Cambridge, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>The Penn Treebank: Annotating Predicate Argument Structure.</title>
<date>1994</date>
<booktitle>In Proc of ARPA Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="7082" citStr="Marcus et al., 1994" startWordPosition="1118" endWordPosition="1121">syntactic structure in this paper refers to both phrase structure (PS) and dependency structure (DS). The enrichment process has three steps: 1. Parse the English translation using an off-theshelf parser. 2. Align the source sentence and English translation with the help of the gloss line. 3. Project the English syntactic structures to obtain the source syntactic structures using word alignment. 3.1 Parsing English sentences There are many English parsers available to the public, and in this experiment we used Charniak&apos;s parser (Charniak, 1997), which was trained on the English Penn Treebank (Marcus et al., 1994). Figure 1(a) shows a parse tree (in the Penn Treebank style) for the English translation in Ex (1). Given a parse tree, we use a head percolation table (Magerman, 1995) to create the corresponding dependency structure. Figure 2(a) shows the dependency structure derived from the parse tree in Figure 1(a). 3.2 Word alignment Because most of the 700+ languages in ODIN are low-density languages with no on-line bilingual dictionaries or large parallel corpora, aligning the source sentence and its English translation directly would not work well. To take advantage of the unique layout of IGT exampl</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, et al. 1994. The Penn Treebank: Annotating Predicate Argument Structure. In Proc of ARPA Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantino Martinez Fabian</author>
</authors>
<title>Yaqui Coordination.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Arizona.</institution>
<contexts>
<context position="28695" citStr="Fabian, 2006" startWordPosition="4908" endWordPosition="4909">reement among linguists about German’s underlying word order, being either SVO or SOV. Our heuristics returned SOV. dependencies (i.e., the ones whose DS have crossing links). One such example from the Yaqui data is in Ex (3), where the coordinated noun phrase kow-ta into mis-ta “the pig and the cat” is separated by the verb bwuise-k “grasp”. Note that the crossing dependencies can only be discovered in the Yaqui data and not in the English since none exist in the English. (3) inepo kow-ta bwuise-k into mis-ta 1SG pig-NNOM.SG grasp-PST and cat-NNOM.SG “I caught the pig and the cat.&amp;quot; (Martinez Fabian, 2006) So far, we have examined linguistically interesting information in the source. In the future, we plan to examine structures in both the source and English. For instance, we plan to extract transfer rules from the aligned source and English structures and also calculate head/modifier crossings between languages similar to those described in (Fox, 2002). 5.2 Tools and resource building The information that we discover about a language can help with the development of tools for the language. The order of constituents, for instance, can be used to inform prototype-driven learning strategies (Hagh</context>
</contexts>
<marker>Fabian, 2006</marker>
<rawString>Constantino Martinez Fabian. 2006. Yaqui Coordination. Ph.D. thesis, University of Arizona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz-Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In the 38th Annual Conference of the Association for Computational Linguistics (ACL-2000),</booktitle>
<pages>440--447</pages>
<contexts>
<context position="10414" citStr="Och and Ney, 2000" startWordPosition="1707" endWordPosition="1710">tespace and dashes as delimiters, and assuming a one-to-one alignment produces almost perfect results. In contrast, the alignment between the gloss line and the English translation is more complicated since alignment links can cross and words on one side can link to zero or more words on the other side. We built two aligners for this stage, as described below. 3.2.1 Statistical word aligner We create a parallel corpus by using the gloss lines and the translation lines of all the IGT examples for all the languages in ODIN. We then train IBM models (Brown et al., 1993) using the GIZA++ package (Och and Ney, 2000). In addition to the common practice of lowercasing words and combining word alignments from both directions, we adopt the following strategies to improve word alignment: Breaking words into morphemes: Since a multi-morpheme word in a gloss line often corresponds to multiple words in the translation line, we split each word on the gloss line into morphemes using the standard IGT morpheme delimiters (e.g., “- &amp;quot;). For instance, the seven words in the gloss line of Ex (1) become nine morphemes. Adding (x,x) pairs: If a word x appears in the gloss and the translation lines of the same IGT example,</context>
<context position="20548" citStr="Och and Ney, 2000" startWordPosition="3509" endWordPosition="3512">les for GIZA++ training.14 Table 2 shows the statistics of the training data with all words lowercased. Tables 3–5 show the performance of the word aligner under three settings: (1): Not splitting words in the gloss lines into morphemes. (2): Splitting words in gloss lines into morphemes. (3): Doing (2) plus adding (x,x) sentence pairs into the training data, where x is a word that appears in both the gloss and translation lines of the same IGT example. For each setting, we trained in both directions and combined the two alignments by taking the intersection, union, and refined as defined in (Och and Ney, 2000). The best F-score for each setting is in boldface. From the tables, it is clear that the third setting works the best, and combining the alignments 14Interestingly, although the IGT examples in the training data come from hundreds of languages in ODIN, IBM Model 4 performs significantly better than Models 1 and 2 (by at least two percent points for F-measure); therefore, all the GIZA++ results reported in the paper are based on Model 4. 456 Table 4: The word alignment results when gloss words are split into morphemes Precision Recall F-measure Gloss trans 0.746 0.889 0.811 Trans gloss 0.797 0</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz-Josef Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In the 38th Annual Conference of the Association for Computational Linguistics (ACL-2000), pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Simon Corston-Oliver</author>
</authors>
<title>The impact of parse quality on syntactically-informed statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="29620" citStr="Quirk and Corston-Oliver, 2006" startWordPosition="5049" endWordPosition="5052"> between languages similar to those described in (Fox, 2002). 5.2 Tools and resource building The information that we discover about a language can help with the development of tools for the language. The order of constituents, for instance, can be used to inform prototype-driven learning strategies (Haghighi and Klein, 2006), which can then be applied to raw corpora. It is also possible that small samples of data showing the alignment interactions between source language structures and those of English can provide essential bootstrap information for informing machine translation systems (cf (Quirk and Corston-Oliver, 2006)). Proof of the utility of an enriched corpus built over ODIN will depend crucially on its evaluation, and we feel that an important part of our future work will be the development of parsers that have been trained on projected structures. These parsers can be evaluated against human built corpora such as treebanks (obviously, only for those languages that have treebanks). Proof will also come from linguists who will be able to use the corpus to search for constructions of interest (e.g., passives, relative clauses, etc.), and will likely be able to do so using standard tools such as 458 tgrep</context>
</contexts>
<marker>Quirk, Corston-Oliver, 2006</marker>
<rawString>Chris Quirk and Simon Corston-Oliver. 2006. The impact of parse quality on syntactically-informed statistical machine translation. In Proceedings of EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency tree translation: Syntactically informed phrasal smt.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="12229" citStr="Quirk et al., 2005" startWordPosition="2025" endWordPosition="2028">r.We built a simple English morphological analyzer and ran it on the two lines, and then linked the words with the same Rhoddodd yr athro lyfr i’r bachgen ddoe gave-3sg the teacher book to-the boy yesterday The teacher gave a book to the boy yesterday Source: Gloss: Transatlion: 454 root form.4 3.3 Tree projection We designed two projection algorithms: one which projects PS and the other which projects DS, both from the English to the source language.5 3.3.1 Projecting dependency structure Our DS projection algorithm is similar to the projection algorithms described in (Hwa et al., 2002) and (Quirk et al., 2005). It has four steps: First, we copy the English DS, and remove all the unaligned English words from the DS.&apos; Second, we replace each English word in the DS with the corresponding source words. If an English word x aligns to several source words, we will make several copies of the node for x, one copy for each such source word. The copies will all be siblings in the DS. If a source word aligns to multiple English words, after Step 2 the source word will have several copies in the resulting DS. In the third step, we keep only the copy that is closest to the root and remove all the other copies.&apos;</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency tree translation: Syntactically informed phrasal smt. In Proceedings of ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Swanton</author>
</authors>
<title>Haida songs.</title>
<date>1912</date>
<booktitle>Publications of the American Ethnological Society, Volume III.</booktitle>
<editor>In Franz Boas, editor,</editor>
<publisher>E. J. Brill.</publisher>
<contexts>
<context position="8168" citStr="Swanton, 1912" startWordPosition="1301" endWordPosition="1302">e source sentence and its English translation directly would not work well. To take advantage of the unique layout of IGT examples, we propose using the gloss line as a bridge between the other two lines; that is, we first align the source sentence and the gloss line, and then align the gloss line and the English translation. The process is illustrated in Figure 3. 3The url of ODIN is http://www.csufresno.edu/odin 2 Background The practice of presenting language data in interlinear form has a long history in the field of linguistics, going back at least to the time of the structuralists (see (Swanton, 1912) for early examples). The modern form of interlinear data presentation started to gel in the mid-1960s, resulting in the canonical three line form shown in Ex (1), which we will refer to as Interlinear Glossed Text, or IGT. The canonical form consists of three lines: a line for the language in question (often a sentence, which we will refer to here as the source sentence), an English gloss line, and an English translation.2 (1) Rhoddodd yr athro lyfr i&apos;r bachgen ddoe gave-3sg the teacher book to-the boy yesterday “The teacher gave a book to the boy yesterday” (Bailyn, 2001) 453 Figure 1: Engli</context>
</contexts>
<marker>Swanton, 1912</marker>
<rawString>John R. Swanton. 1912. Haida songs. In Franz Boas, editor, Publications of the American Ethnological Society, Volume III. E. J. Brill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Wellington</author>
<author>Sonjia Waxmonsky</author>
<author>I Dan Melamed</author>
</authors>
<title>Empirical lower bounds on the complexity of translation equivalence.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="4172" citStr="Wellington et al., 2006" startWordPosition="644" endWordPosition="647">ols, since a little knowledge can go a long way in inducing accurate structure and annotations (Haghighi and Klein, 2006). Of particular relevance to MT is the issue of struc452 Proceedings of NAACL HLT 2007, pages 452–459, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics tural divergence (Dorr, 1994). Many MT models implicitly make the so-called direct correspondence assumption (DCA) as defined in (Hwa et al., 2002). However, to what extent that assumption holds is tested only on a small number of language pairs using hand aligned data (Fox, 2002; Hwa et al., 2002; Wellington et al., 2006). A larger sample of typologically diverse language data can help test the assumption for hundreds of languages. We contend that the knowledge garnered from structural projections applied to interlinear text can bootstrap the development of resources and tools across parallel corpora, where such corpora could be of smaller size and the resulting tools more robust, opening the door to the development of tools and resources for a larger number of the world’s languages. Given the imminent death of half of the world’s 6,000 languages (Krauss, 1992), the development of any language specific tools f</context>
</contexts>
<marker>Wellington, Waxmonsky, Melamed, 2006</marker>
<rawString>Benjamin Wellington, Sonjia Waxmonsky, and I. Dan Melamed. 2006. Empirical lower bounds on the complexity of translation equivalence. In Proceedings of ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-English languages.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP,</booktitle>
<pages>851--858</pages>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="2080" citStr="Xi and Hwa, 2005" startWordPosition="307" endWordPosition="310">for non-English languages, e.g., treebanks, the development of these resources has been no small feat, and to date have been limited to a very small number of &apos;We would like to thank Dan Jinguji for creating the word alignment and source dependency structure gold standards. Our thanks also go to three anonymous reviewers for their helpful comments and suggestions. the world’s languages (e.g., Chinese, German, Arabic, Korean, etc.). Some notable efforts have been undertaken to develop automated means for creating annotated corpora through the projection of annotations (Yarowksy and Ngai, 2001; Xi and Hwa, 2005). The resulting methods, however, can only be applied to a small number of language pairs due mostly to the need for sizeable parallel corpora. Unfortunately, most languages do not have parallel corpora of sufficient size, making these methods inapplicable for the vast majority of the world’s languages. We describe a method for bootstrapping resource creation by tapping the wealth of multilingual data on the Web that has been created by linguists. Of particular note is the linguistic presentation format of “interlinear text”, a common format used for presenting language data and analysis relev</context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-English languages. In Proceedings of HLT-EMNLP, pages 851–858, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowksy</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing Multilingual POS taggers and NP Bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL-2001,</booktitle>
<pages>377--404</pages>
<contexts>
<context position="2061" citStr="Yarowksy and Ngai, 2001" startWordPosition="303" endWordPosition="306">elop annotated resources for non-English languages, e.g., treebanks, the development of these resources has been no small feat, and to date have been limited to a very small number of &apos;We would like to thank Dan Jinguji for creating the word alignment and source dependency structure gold standards. Our thanks also go to three anonymous reviewers for their helpful comments and suggestions. the world’s languages (e.g., Chinese, German, Arabic, Korean, etc.). Some notable efforts have been undertaken to develop automated means for creating annotated corpora through the projection of annotations (Yarowksy and Ngai, 2001; Xi and Hwa, 2005). The resulting methods, however, can only be applied to a small number of language pairs due mostly to the need for sizeable parallel corpora. Unfortunately, most languages do not have parallel corpora of sufficient size, making these methods inapplicable for the vast majority of the world’s languages. We describe a method for bootstrapping resource creation by tapping the wealth of multilingual data on the Web that has been created by linguists. Of particular note is the linguistic presentation format of “interlinear text”, a common format used for presenting language data</context>
</contexts>
<marker>Yarowksy, Ngai, 2001</marker>
<rawString>David Yarowksy and Grace Ngai. 2001. Inducing Multilingual POS taggers and NP Bracketers via robust projection across aligned corpora. In Proceedings of NAACL-2001, pages 377–404.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>