<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002435">
<title confidence="0.988404">
Automatic Metaphor Interpretation as a Paraphrasing Task
</title>
<author confidence="0.991733">
Ekaterina Shutova
</author>
<affiliation confidence="0.992076">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.989957">
15 JJ Thomson Avenue
Cambridge CB3 0FD, UK
</address>
<email confidence="0.999009">
Ekaterina.Shutova@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999915153846154">
We present a novel approach to metaphor in-
terpretation and a system that produces lit-
eral paraphrases for metaphorical expressions.
Such a representation is directly transferable
to other applications that can benefit from a
metaphor processing component. Our method
is distinguished from the previous work in that
it does not rely on any hand-crafted knowl-
edge about metaphor, but in contrast employs
automatically induced selectional preferences.
Being the first of its kind, our system is capa-
ble of paraphrasing metaphorical expressions
with a high accuracy (0.81).
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994476">
Metaphors arise when one concept is viewed in
terms of the properties of the other. In other words
it is based on similarity between the concepts. Sim-
ilarity is a kind of association implying the presence
of characteristics in common. Here are some exam-
ples of metaphor.
</bodyText>
<listItem confidence="0.977408">
(1) News travels fast. (Lakoff and Johnson, 1980)
(2) How can I kill a process? (Martin, 1988)
(3) And then my heart with pleasure fills,
And dances with the daffodils.1
</listItem>
<bodyText confidence="0.931266">
In metaphorical expressions seemingly unrelated
features of one concept are associated with another
</bodyText>
<footnote confidence="0.742863">
1taken from the verse “I wandered lonely as a cloud” written
by William Wordsworth in 1804.
</footnote>
<bodyText confidence="0.999446848484848">
concept. In the example (2) the computational pro-
cess is viewed as something alive and, therefore,
its forced termination is associated with the act of
killing.
Metaphorical expressions represent a great vari-
ety, ranging from conventional metaphors, which we
reproduce and comprehend every day, e.g. those in
(1) and (2), to poetic and largely novel ones, such
as (3). The use of metaphor is ubiquitous in natural
language text and it is a serious bottleneck in auto-
matic text understanding. In order to estimate the
frequency of the phenomenon, we conducted a cor-
pus study on a subset of the British National Corpus
(BNC) (Burnard, 2007) representing various genres.
We manually annotated metaphorical expressions in
this data and found that 241 out of 761 sentences
contained a metaphor or (rarely) an idiom. Due to
such a high frequency of their use, a system capa-
ble of interpreting metaphorical expressions in unre-
stricted text would become an invaluable component
of any semantics-oriented NLP application.
Automatic processing of metaphor can be clearly
divided into two subtasks: metaphor recognition
(distinguishing between literal and metaphorical
language in text) and metaphor interpretation (iden-
tifying the intended literal meaning of a metaphori-
cal expression). Both of them have been repeatedly
addressed in NLP.
To date the most influential account of metaphor
recognition has been that of Wilks (1978). Accord-
ing to Wilks, metaphors represent a violation of se-
lectional restrictions in a given context. Consider the
following example.
</bodyText>
<listItem confidence="0.69178">
(4) My car drinks gasoline. (Wilks, 1978)
</listItem>
<page confidence="0.970027">
1029
</page>
<note confidence="0.7508655">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999814611111111">
The verb drink normally takes an animate subject
and a liquid object. Therefore, drink taking a car as
a subject is an anomaly, which may as well indicate
metaphorical use of drink.
Most approaches to metaphor interpretation rely
on task-specific hand-coded knowledge (Fass, 1991;
Martin, 1990; Narayanan, 1997; Narayanan, 1999;
Feldman and Narayanan, 2004; Barnden and Lee,
2002; Agerri et al., 2007) and produce interpreta-
tions in a non-textual format. However, the ultimate
objective of automatic metaphor processing is a type
of interpretation that can be directly embedded into
other systems to enhance their performance. Thus,
we define metaphor interpretation as a paraphrasing
task and build a system that automatically derives
literal paraphrases for metaphorical expressions in
unrestricted text.
In summary, our system (1) produces a list of
all possible paraphrases for a metaphorical expres-
sion (induced automatically from a large corpus);
(2) ranks the paraphrases according to their likeli-
hood derived from the corpus; (3) discriminates be-
tween literal and figurative paraphrases by detect-
ing selectional preference violation and outputs the
literal ones; and (4) disambiguates the sense of the
paraphrases using WordNet (Fellbaum, 1998) inven-
tory of senses.
We tested our system on a collection of metaphor-
ical expressions representing verb-subject and verb-
object constructions, where the verb is used
metaphorically. To compile this dataset we manually
annotated such phrases in a subset of the BNC using
the metaphor identification procedure (MIP) (Prag-
glejaz Group, 2007). We then evaluated the quality
of paraphrasing with the help of human annotators
and created a gold standard for this task.
</bodyText>
<sectionHeader confidence="0.98615" genericHeader="method">
2 Experimental Data
</sectionHeader>
<bodyText confidence="0.9921649">
Since we focus on single-word metaphors expressed
by a verb, our annotation task can be viewed as
verb classification according to whether the verbs
are used metaphorically or literally. However, some
verbs have weak or no potential of being a metaphor
and, thus, our study is not concerned with them. We
excluded the following verb classes: (1) auxiliary
verbs; (2) modal verbs; (3) aspectual verbs (e.g. be-
gin, start, finish); (4) light verbs (e.g. take, give, put,
get, make).
</bodyText>
<subsectionHeader confidence="0.992724">
2.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.999783166666667">
Our corpus is a subset of the BNC. We sampled
texts representing various genres: literature, news-
paper/journal articles, essays on politics, interna-
tional relations and history, radio broadcast (tran-
scribed speech). The corpus contains 761 sentences
and 13642 words.
</bodyText>
<subsectionHeader confidence="0.999942">
2.2 Annotation Scheme
</subsectionHeader>
<bodyText confidence="0.9978656">
The annotation scheme we use is based on the
principles of the metaphor identification procedure
(MIP) developed by Pragglejaz Group (2007). We
adopt their definition of basic sense of a word and
their approach to distinguishing basic senses from
the metaphorical ones. MIP involves metaphor an-
notation at the word level as opposed to identifying
metaphorical relations (between words) or source–
target domain mappings (between concepts or do-
mains). Such annotation can be viewed as a form
of word sense disambiguation with an emphasis on
metaphoricity.
In order to discriminate between the verbs used
metaphorically and literally we use the following
procedure as part of our guidelines:
</bodyText>
<listItem confidence="0.735821363636364">
1. For each verb establish its meaning in context
and try to imagine a more basic meaning of this
verb on other contexts. As defined in the frame-
work of MIP (Pragglejaz Group, 2007) basic
meanings normally are: (1) more concrete; (2)
related to bodily action; (3) more precise (as
opposed to vague); (4) historically older.
2. If you can establish the basic meaning that is
distinct from the meaning of the verb in this
context, the verb is likely to be used metaphor-
ically.
</listItem>
<bodyText confidence="0.984151">
Consider the following example sentence:
(5) If he asked her to post a letter or buy some razor
blades from the chemist, she was transported
with pleasure.
In this sentence one needs to annotate four verbs that
are underlined. The first 3 verbs are used in their ba-
sic sense, i.e. literally (ask in the context of “a per-
son asking another person a question or a favour”;
</bodyText>
<page confidence="0.986789">
1030
</page>
<bodyText confidence="0.999858272727273">
post in the context of “a person posting/sending a
letter”; buy in the sense of “making a purchase”).
Thus, they are tagged as literal. The verb trans-
port, however, in its basic sense is used in the con-
text of “goods being transported/carried by a vehi-
cle”. The context in this sentence involves “a per-
son being transported by a feeling”, which contrasts
the basic sense in that the agent of transporting is
an EMOTION as opposed to a VEHICLE. Thus, we
can infer that the use of transport in this sentence is
metaphorical.
</bodyText>
<subsectionHeader confidence="0.999857">
2.3 Annotation Reliability
</subsectionHeader>
<bodyText confidence="0.99988016">
We tested reliability of this annotation scheme using
multiple annotators on a subset of the corpus. The
rest of the annotation was done by a single annota-
tor.
Annotators We had three independent volunteer an-
notators, who were all native speakers of English
and had some linguistics background.
Material and Task All of them received the same
text taken from the BNC containing 142 verbs to
annotate. They were asked to classify verbs as
metaphorical or literal.
Guidelines and Training The annotators received
written guidelines (2 pages) and were asked to do a
small annotation exercise (2 sentences containing 8
verbs in total). The goal of the exercise was to en-
sure they were at ease with the annotation format.
Interannotator Agreement We evaluate reliability
of our annotation scheme by assessing interannota-
tor agreement in terms of n (Siegel and Castellan,
1988). The classification was performed with the
agreement of 0.64 (n), which is considered reliable.
The main source of disagreement was the high con-
ventionality of some expressions, i.e. cases where
the metaphorical etymology could be clearly traced,
but the senses are highly lexicalized.
</bodyText>
<subsectionHeader confidence="0.997393">
2.4 Phrase Selection
</subsectionHeader>
<bodyText confidence="0.990219">
Only the phrases that were tagged as metaphorical
by all of the annotators were included in the test set.
Here are some examples of such phrases: memo-
ries were slipping away; hold the truth back; stirred
an unfathomable excitement; factors shape results;
mending their marriage; brushed aside the accusa-
tions etc. In order to avoid extra noise we placed
some additional criteria to select the test phrases:
(1) exclude phrases where subject or object referent
is unknown, e.g. containing pronouns such as in in
which they [changes] operated; (2) exclude phrases
whose metaphorical meaning is realised solely in
passive constructions (e.g. sociologists have been
inclined to [..]); (3) exclude phrases where the sub-
ject or object of interest are represented by a named
entity (e.g. Then Hillary leapt into the conversa-
tion); (4) exclude multiword metaphors (e.g. go on
pilgrimage with Raleigh or put out to sea with Ten-
nyson). The resulting test set contains 62 metaphor-
ical expressions.
</bodyText>
<sectionHeader confidence="0.99527" genericHeader="method">
3 The Method
</sectionHeader>
<bodyText confidence="0.999985916666667">
The system takes phrases containing annotated
single-word metaphors (where a verb is used
metaphorically, its context is used literally) as in-
put. It generates a list of possible paraphrases that
can occur in the same context and ranks them ac-
cording to their likelihood derived from the cor-
pus. Subsequently it identifies shared features of the
paraphrases and the metaphorical verb using Word-
Net hierarchy of concepts and removes the unrelated
concepts. Among the related paraphrases it then
identifies the literal ones given the context relying on
the automatically induced selectional preferences.
</bodyText>
<subsectionHeader confidence="0.985531">
3.1 The Model for Paraphrase Ranking
</subsectionHeader>
<bodyText confidence="0.966878">
We model the likelihood of a particular paraphrase
as a joint probability of the following events: the
interpretation (another term to replace the one used
metaphorically) i co-occurring with the other lexi-
cal items from its context w1, ..., wN in the relations
r1, ..., rN respectively.
</bodyText>
<equation confidence="0.929681">
Li = P(i, (w1, r1), (w2, r2), ..., (wN, rN)), (1)
</equation>
<bodyText confidence="0.999875090909091">
where w1, ..., wN and r1, ..., rN represent the fixed
context of the term used metaphorically in the sen-
tence. This context will be kept as part of the para-
phrase, and the term used metaphorically will be re-
placed.
We take each relation of the term in a phrase to be
independent from the other relations of this term in
this phrase. E.g. for a verb in the presence of both
the subject and the object the Verb-Subject and
Verb-Object relations would be considered to
be independent events within the model. This yields
</bodyText>
<page confidence="0.911296">
1031
</page>
<bodyText confidence="0.796664">
the following approximation:
</bodyText>
<equation confidence="0.9622565">
P(i, (w1, r1), (w2, r2), ..., (wN, rN)) =
(2)
P(i) · P((w1, r1)|i) · ... · P((wN, rN)|i).
We can calculate the probabilities using maximum
likelihood estimation
P(i) = f(i) (3)
Ek f(ik
P(wn, rn|i) = f(wn, rn, i) f(i) , (4)
</equation>
<bodyText confidence="0.999941857142857">
where f(i) is the frequency of the interpretation on
its own, Ek f(ik) is the number of times this part
of speech is attested in the corpus and f(wn, rn, i)
- the frequency of the co-occurrence of the interpre-
tation with the context word wn in the relation rn.
By performing appropriate substitutions into (2) we
obtain
</bodyText>
<equation confidence="0.998339833333333">
P(i, (w1, r1), (w2, r2), ..., (wN, rN)) =
f(i) f(w1, r1, i) f(wN, rN, i)
Ek f(ik) · f(i) · ... · f(i) =
HN
11n=1 f(wn, rn, i)
(f(i))N−1 · Ek f(ik)
</equation>
<bodyText confidence="0.98805425">
(5)
This model is then used to rank the possible re-
placements of the term used metaphorically in the
fixed context according to the data.
</bodyText>
<subsectionHeader confidence="0.999214">
3.2 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.9998854">
The parameters of the model were estimated from
the British National Corpus that was parsed using
the RASP parser of Briscoe et al. (2006). We used
the grammatical relations (GRs) output of RASP
for BNC created by Andersen et al. (2008). The
same output of RASP was used to identify the GRs
in the metaphorical expressions themselves, as the
metaphor corpus from which they were extracted
is a subset of the BNC. To obtain the counts for
f(wn, rn, i) we extracted all the terms appearing in
the corpus in the relation rn with wn for each lexical
item - relation pair. The initial list of replacements
for the metaphorical term was constructed by taking
an overlap of the lists of terms for each lexical item
- relation pair.
</bodyText>
<subsectionHeader confidence="0.999277">
3.3 Identifying Shared Meanings in WordNet
</subsectionHeader>
<bodyText confidence="0.999971185185185">
It should be noted that the context-based model
described in 3.1 overgenerates and hence there is
a need to further narrow the search space. It
is acknowledged in the linguistics community that
metaphor is to a great extent based on similarity be-
tween the concepts involved. We exploit this fact to
refine paraphrasing. After obtaining the initial list
of possible substitutes for the metaphorical term, we
filter out the terms whose meaning does not share
any common features with that of the metaphorical
term. Consider a Computer Science metaphor kill a
process, which stands for terminate a process. The
basic sense of kill implies an end or termination of
life. Thus, termination is the shared element of the
metaphorical verb and its literal interpretation.
Such overlap of features can be identified using
the hyponymy relations in the WordNet taxonomy.
Within the initial list of paraphrases we select the
terms that are a hypernym of the metaphorical term
or share a common hypernym with it2. To maxi-
mize the accuracy we restrict the hypernym search
to three level distance in the taxomomy. The filtered
lists of metaphorical verb replacements for some of
the phrases from our dataset together with their log-
likelihood are demonstrated in Table 1. Selecting
the highest ranked paraphrase from this list as a lit-
eral interpretation will serve as a baseline.
</bodyText>
<subsectionHeader confidence="0.994777">
3.4 Filtering Based on Selectional Preferences
</subsectionHeader>
<bodyText confidence="0.999979615384615">
The obtained lists contain some irrelevant para-
phrases (e.g. contain the truth for hold back the
truth) and some paraphrases where the substitute is
used metaphorically again (e.g. suppress the truth).
However, the task is to identify the literal interpreta-
tion, therefore, these need to be removed.
One way of dealing with both problems at once
is to take into account selectional preferences of the
verbs in our list. The verbs used metaphorically are
likely to demonstrate strong semantic preference for
the source domain, e.g. suppress would select for
movements (political) rather than ideas, or truth, (the
target domain), whereas the ones used literally (e.g.,
</bodyText>
<footnote confidence="0.99224375">
2We excluded the expressions containing a term whose
metaphorical sense is included in WordNet from the test set,
to ensure that the system does not rely on this extra hand-coded
knowledge about metaphor.
</footnote>
<page confidence="0.93635">
1032
</page>
<table confidence="0.992992037037037">
Log-likelihood Replacement
Verb-DirectObject
hold back truth:
-13.09 contain
-14.15 conceal
-14.62 suppress
-15.13 hold
-16.23 keep
-16.24 defend
stir excitement:
-14.28 create
-14.84 provoke
-15.53 make
-15.53 elicit
-15.53 arouse
-16.23 stimulate
-16.23 raise
-16.23 excite
-16.23 conjure
Subject-Verb
report leak:
-11.78 reveal
-12.59 issue
-13.18 disclose
-13.28 emerge
-14.84 expose
-16.23 discover
</table>
<tableCaption confidence="0.999687">
Table 1: The list of paraphrases with the initial ranking
</tableCaption>
<table confidence="0.998210814814815">
Association Replacement
Verb-DirectObject
hold back truth:
0.1161 conceal
0.0214 keep
0.0070 suppress
0.0022 contain
0.0018 defend
0.0006 hold
stir excitement:
0.0696 provoke
0.0245 elicit
0.0194 arouse
0.0061 conjure
0.0028 create
0.0001 stimulate
� 0 raise
� 0 make
Pz�0 excite
Subject-Verb
report leak:
0.1492 disclose
0.1463 discover
0.0674 reveal
0.0597 issue
� 0 emerge
Pz�0 expose
</table>
<tableCaption confidence="0.9941015">
Table 2: The list of paraphrases reranked using selec-
tional preferences
</tableCaption>
<bodyText confidence="0.998903260869565">
conceal) would select for truth. This would poten-
tially allow us to filter out non-literalness, as well as
unrelated verbs, by selecting the verbs that the noun
in the metaphorical expression matches best.
We automatically acquired selectional preference
distributions of the verbs in the paraphrase lists
(for Verb-Subject and Verb-Object rela-
tions) from the BNC parsed by RASP. We first clus-
tered 2000 most frequent nouns in the BNC into 200
clusters using the algorithm of Sun and Korhonen
(2009). The obtained clusters formed our selectional
preference classes. We adopted the association mea-
sure proposed by Resnik (1993) and successfully ap-
plied to a number of tasks in NLP including word
sense disambiguation (Resnik, 1997). Resnik mod-
els selectional preference of a verb in probabilistic
terms as the difference between the posterior distri-
bution of noun classes in a particular relation with
the verb and their prior distribution in that syntac-
tic position regardless of the identity of the predi-
cate. He quantifies this difference using the relative
entropy (or Kullback-Leibler distance), defining the
selectional preference strength as follows.
</bodyText>
<equation confidence="0.999876333333333">
SR(v) = D(P(c|v)||P(c)) =
EP
cP(c|v) log P(C|V), (6)
</equation>
<bodyText confidence="0.99982675">
where P(c) is the prior probability of the noun class,
P(c|v) is the posterior probability of the noun class
given the verb and R is the grammatical relation in
question. Selectional preference strength measures
how strongly the predicate constrains its arguments.
In order to quantify how well a particular argument
class fits the verb, Resnik defines another measure
called selectional association:
</bodyText>
<equation confidence="0.9931235">
1 P (c|v)
AR(v, c) = SR(v)P(c|v) log P (c) . (7)
</equation>
<bodyText confidence="0.9999012">
We use this measure to rerank the paraphrases and
filter out those not well suited or used metaphor-
ically. The new ranking is demonstrated in Table
2. The expectation is that the paraphrase in the first
rank (i.e. the verb with which the noun in question
</bodyText>
<page confidence="0.980266">
1033
</page>
<bodyText confidence="0.998359">
has the highest association) represents the literal in-
terpretation.
</bodyText>
<subsectionHeader confidence="0.952018">
3.5 Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.991544">
Another feature of our system is that having identi-
fied literal interpretations, it is capable to perform
their word sense disambiguation (WSD). Disam-
biguated metaphorical interpretations are potentially
a useful source of information for NLP applications
dealing with word senses.
We adopt WordNet representation of a sense.
Disambiguation is performed by selecting WordNet
nodes containing those verbs that share a common
hypernym with the metaphorical verb. The list of
disambiguated interpretations for a random selection
of phrases from our dataset is demonstrated in Table
3. However, we did not evaluate the WSD of the
paraphrases at this stage.
</bodyText>
<sectionHeader confidence="0.994695" genericHeader="evaluation">
4 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.999910733333334">
We evaluated the paraphrases with the help of hu-
man annotators in two different experimental set-
tings.
Setting 1: the annotators were presented with a set
of sentences containing metaphorical expressions
and their rank 1 paraphrases produced by the system
and by the baseline. They were asked to mark the
ones that have the same meaning as the term used
metaphorically and are used literally in the context
of the paraphrase expression as correct.
We had 7 volunteer annotators who were all na-
tive speakers of English (one bilingual) and had no
or sparse linguistic expertise. Their agreement on
the task was 0.62 (n), whereby the main source
of disagreement was the presence of highly lexi-
calised metaphorical paraphrases. We then evalu-
ated the system performance against their judgments
in terms of accuracy. Accuracy measures the pro-
portion of correct literal interpretations among the
paraphrases in rank 1. The results are demonstrated
in Table 4, the final systems identifies literal para-
phrases with the accuracy of 0.81.
Setting 2: the annotators were presented with a set
of sentences containing metaphorical expressions
and asked to write down all suitable literal para-
phrases for the highlighted metaphorical verbs. We
had 5 volunteer subjects for this experiment (note
that these were people not employed in the previ-
ous setting); they were all native speakers of En-
glish and had some linguistics background. We then
compiled a gold standard by incorporating all of the
annotations. E.g. the gold standard for the phrase
brushed aside the accusations contains the verbs re-
jected, ignored, disregarded, dismissed, overlooked,
discarded.
We compared the system output against the gold
standard using mean reciprocal rank (MRR) as a
measure. MRR is traditionally used to evaluate the
performance of Question-Answering systems. We
adapted this measure in order to be able to assess
ranking quality beyond rank 1 and the recall of our
system. An individual metaphorical expression re-
ceives a score equal to the reciprocal of the rank at
which the first correct literal interpretation (accord-
ing to the human gold standard) is found among the
top five paraphrases, or 0 if none of the five para-
phrases contains a correct interpretation. Once the
individual reciprocal ranks of metaphorical expres-
sions are estimated their mean is computed across
the dataset. The MRR of our system equals 0.63
and that of the baseline is 0.55. However, it should
be noted that given that our task is open-ended, it
is hard to construct a comprehensive gold standard.
For example, for the phrase stir excitement most an-
notators suggested only one paraphrase create ex-
citement, which is found in rank 3. However, the top
ranks of the system output are occupied by provoke
and stimulate, which are more precise paraphrases,
although they have not occurred to the annotators.
Such examples result in the system’s MRR being
significantly lower than its accuracy at rank 1.
The obtained results are promising, the selec-
tional preference-based reranking yields a consider-
able improvement in accuracy (26%) over the base-
line. However, for one of the phrases in the dataset,
mend marriage, the new ranking overruns the cor-
rect top suggestion of the baseline, improve mar-
riage, and outputs repair marriage as the most likely
literal interpretation. This is due to both the conven-
tionality of some metaphorical senses (in this case
repair) and to the fact that some verbs, e.g. improve,
expose a moderate selectional preference strength,
i.e. they are equally associated with a large number
of classes. This demonstrates potential drawbacks of
the selectional preference-based solutions. Another
</bodyText>
<page confidence="0.993465">
1034
</page>
<note confidence="0.411867">
Met. Expression Top Int. Its WordNet Sense
</note>
<subsectionHeader confidence="0.93994">
Verb-DirectObject
</subsectionHeader>
<bodyText confidence="0.992382">
stir excitement provoke (arouse-1 elicit-1 enkindle-2 kindle-3 evoke-1 fire-7 raise-10 provoke-1) - call forth
(emotions, feelings, and responses): ”arouse pity”; ”raise a smile”; ”evoke sympathy”
inherit state acquire (get-1 acquire-1) - come into the possession of something concrete or abstract: ”She got
a lot of paintings from her uncle”; ”They acquired a new pet”
reflect concern manifest (attest-1 certify-1 manifest-1 demonstrate-3 evidence-1) - provide evidence for; stand
as proof of; show by one’s behavior, attitude, or external attributes: ”The buildings in
Rome manifest a high level of architectural sophistication”; ”This decision demonstrates
his sense of fairness”
brush aside accusation reject (reject-1) - refuse to accept or acknowledge: ”we reject the idea of starting a war”; ”The
journal rejected the student’s paper”
</bodyText>
<subsectionHeader confidence="0.990449">
Verb-Subject
</subsectionHeader>
<bodyText confidence="0.88925">
campaign surged improve (better-3 improve-2 ameliorate-2 meliorate-2) - to make better: ”The editor improved
the manuscript with his changes”
report leaked disclose (unwrap-2 disclose-1 let on-1 bring out-9 reveal-2 discover-6 expose-2 divulge-1
break-15 give away-2 let out-2) - make known to the public information that was pre-
viously known only to a few people or that was meant to be kept a secret: ”The auction
house would not disclose the price at which the van Gogh had sold”; ”The actress won’t
reveal how old she is”
tension mounted lift (rise-1 lift-4 arise-5 move up-2 go up-1 come up-6 uprise-6) - move upward: ”The fog
lifted”; ”The smoke arose from the forest fire”; ”The mist uprose from the meadows”
</bodyText>
<tableCaption confidence="0.99287">
Table 3: Disambiguated paraphrases produced by the system
</tableCaption>
<table confidence="0.99921725">
Relation Baseline System
Verb-DirectObject 0.52 0.79
Verb-Subject 0.57 0.83
Average 0.55 0.81
</table>
<tableCaption confidence="0.999966">
Table 4: Accuracy with the evaluation setting 1
</tableCaption>
<bodyText confidence="0.999960285714286">
controvertial example was the metaphorical expres-
sion tension mounted, for which the system pro-
duced a paraphrase tension lifted with the opposite
meaning. This error is likely to have been triggered
by the feature similarity component, whereby one of
the senses of lift would stem from the same node in
WordNet as the metaphorical sense of mount.
</bodyText>
<sectionHeader confidence="0.999925" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.996891027027027">
According to Conceptual Metaphor Theory (Lakoff
and Johnson, 1980) metaphor can be viewed as an
analogy between two distinct domains - the target
and the source. Consider the following example:
(6) He shot down all of my arguments. (Lakoff and
Johnson, 1980)
A mapping of a concept of argument (target) to
that of war (source) is employed here. The idea of
such interconceptual mappings has been exploited in
some NLP systems.
One of the first attempts to identify and inter-
pret metaphorical expressions in text automatically
is the approach of Fass (1991). It originates in
the work of Wilks (1978) and utilizes hand-coded
knowledge. Fass (1991) developed a system called
met*, capable of discriminating between literal-
ness, metonymy, metaphor and anomaly. It does
this in three stages. First, literalness is distin-
guished from non-literalness using selectional pref-
erence violation as an indicator. In the case that non-
literalness is detected, the respective phrase is tested
for being a metonymic relation using hand-coded
patterns (such as CONTAINER-for-CONTENT). If
the system fails to recognize metonymy, it pro-
ceeds to search the knowledge base for a relevant
analogy in order to discriminate metaphorical re-
lations from anomalous ones. E.g., the sentence
in (4) would be represented in this framework as
(car,drink,gasoline), which does not satisfy the pref-
erence (animal,drink,liquid), as car is not a hy-
ponym of animal. met* then searches its knowl-
edge base for a triple containing a hypernym of
both the actual argument and the desired argument
and finds (thing,use,energy source), which repre-
sents the metaphorical interpretation.
Almost simultaneously with the work of Fass
(1991), Martin (1990) presents a Metaphor Inter-
</bodyText>
<page confidence="0.980046">
1035
</page>
<bodyText confidence="0.991924538461539">
pretation, Denotation and Acquisition System (MI-
DAS). The idea behind this work is that the more
specific conventional metaphors descend from the
general ones. Given an example of a metaphor-
ical expression, MIDAS searches its database for
a corresponding metaphor that would explain the
anomaly. If it does not find any, it abstracts from
the example to more general concepts and repeats
the search. If it finds a suitable general metaphor, it
creates a mapping for its descendant, a more specific
metaphor, based on this example. This is also how
novel metaphors are acquired. MIDAS has been in-
tegrated with the Unix Consultant (UC), the system
that answers users questions about Unix.
Another cohort of approaches relies on perform-
ing inferences about entities and events in the source
and target domains for metaphor interpretation.
These include the KARMA system (Narayanan,
1997; Narayanan, 1999; Feldman and Narayanan,
2004) and the ATT-Meta project (Barnden and Lee,
2002; Agerri et al., 2007). Within both systems
the authors developed a metaphor-based reasoning
framework in accordance with the theory of concep-
tual metaphor. The reasoning process relies on man-
ually coded knowledge about the world and operates
mainly in the source domain. The results are then
projected onto the target domain using the concep-
tual mapping representation. The ATT-Meta project
concerns metaphorical and metonymic description
of mental states and reasoning about mental states
using first order logic. Their system, however, does
not take natural language sentences as input, but
logical expressions that are representations of small
discourse fragments. KARMA in turn deals with a
broad range of abstract actions and events and takes
parsed text as input.
Veale and Hao (2008) derive a “fluid knowledge
representation for metaphor interpretation and gen-
eration”, called Talking Points. Talking Points are a
set of characteristics of concepts belonging to source
and target domains and related facts about the world
which the authors acquire automatically from Word-
Net and from the web. Talking Points are then orga-
nized in Slipnet, a framework that allows for a num-
ber of insertions, deletions and substitutions in def-
initions of such characteristics in order to establish
a connection between the target and the source con-
cepts. This work builds on the idea of slippage in
knowledge representation for understanding analo-
gies in abstract domains (Hofstadter and Mitchell,
1994; Hofstadter, 1995). Consider the metaphor
Make-up is a Western burqa:
Make-up =&gt;
� typically worn by women
� expected to be worn by women
� must be worn by women
� must be worn by Muslim women
Burqa &lt;=
By doing insertions and substitutions the system ar-
rives from the definition typically worn by women to
that of must be worn by Muslim women, and thus es-
tablish a link between the concepts of make-up and
burqa. Veale and Hao (2008), however, did not eval-
uate to which extent their method is useful to inter-
pret metaphorical expressions occurring in text.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999965789473684">
We presented a novel approach to metaphor interpre-
tation and a system that produces literal paraphrases
for metaphorical expressions. Such a representation
is directly transferable to other applications that can
benefit from a metaphor processing component. Our
method is distinguished from the previous work in
that it does not rely on any hand-crafted knowledge,
other than WordNet, but in contrast employs auto-
matically induced selectional preferences.
Our system is the first of its kind and it is capa-
ble of paraphrasing metaphorical expressions with a
high accuracy (0.81). Although we reported results
on a test set consisting of verb-subject and verb-
object metaphors only, we are convinced that the
described interpretation techniques can be similarly
applied to other parts of speech and a wider range
of syntactic constructions. Extending the system to
deal with more types of phrases is part of our future
work.
</bodyText>
<sectionHeader confidence="0.999333" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997872833333333">
I am very grateful to Anna Korhonen, Simone
Teufel, Ann Copestake and the reviewers for their
helpful feedback on this work, Lin Sun for sharing
his noun clustering data and the volunteer annota-
tors. My studies and, thus, this research are funded
by generosity of Cambridge Overseas Trust.
</bodyText>
<page confidence="0.992873">
1036
</page>
<sectionHeader confidence="0.99834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999903987654321">
R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Wallington.
2007. Metaphor, inference and domain-independent
mappings. In Proceedings of International Confer-
ence on Recent Advances in Natural Language Pro-
cessing (RANLP-2007), pages 17–23, Borovets, Bul-
garia.
O. E. Andersen, J. Nioche, E. Briscoe, and J. Carroll.
2008. The BNC parsed with RASP4UIMA. In
Proceedings of the Sixth International Language Re-
sources and Evaluation Conference (LREC’08), Mar-
rakech, Morocco.
J.A. Barnden and M.G. Lee. 2002. An artificial intelli-
gence approach to metaphor understanding. Theoria
etHistoria Scientiarum, 6(1):399–412.
E. Briscoe, J. Carroll, and R. Watson. 2006. The second
release of the rasp system. In Proceedings of the COL-
ING/ACL on Interactive presentation sessions, pages
77–80.
L. Burnard. 2007. Reference Guide for the
British National Corpus (XML Edition).
URL=http://www.natcorp.ox.ac.uk/XMLedition/URG/.
D. Fass. 1991. met*: A method for discriminating
metonymy and metaphor by computer. Computational
Linguistics, 17(1):49–90.
J. Feldman and S. Narayanan. 2004. Embodied meaning
in a neural theory of language. Brain and Language,
89(2):385–392.
C. Fellbaum, editor. 1998. WordNet: An Electronic Lexi-
cal Database (ISBN: 0-262-06197-X). MIT Press, first
edition.
D. Hofstadter and M. Mitchell. 1994. The Copy-
cat Project: A model of mental fluidity and analogy-
making. In K.J. Holyoak and J. A. Barnden, editors,
Advances in Connectionist and Neural Computation
Theory, Ablex, New Jersey.
D. Hofstadter. 1995. Fluid Concepts and Creative
Analogies: Computer Models of the Fundamental
Mechanisms of Thought. HarperCollins Publishers.
G. Lakoff and M. Johnson. 1980. Metaphors We Live By.
University of Chicago Press, Chicago.
J. H. Martin. 1988. Representing regularities in the
metaphoric lexicon. In Proceedings of the 12th con-
ference on Computational linguistics, pages 396–401.
J. H. Martin. 1990. A Computational Model of Metaphor
Interpretation. Academic Press Professional, Inc., San
Diego, CA, USA.
S. Narayanan. 1997. Knowledge-based action represen-
tations for metaphor and aspect (KARMA). Technical
report, PhD thesis, University of California at Berke-
ley.
S. Narayanan. 1999. Moving right along: A computa-
tional model of metaphoric reasoning about events. In
In Proceedings of the National Conference on Artifi-
cial Intelligence (AAAI 99), pages 121–128, Orlando,
Florida.
Pragglejaz Group (P. Crisp, R. Gibbs, A. Cienki, G.
Low, G. Steen, L. Cameron, E. Semino, J. Grady, A.
Deignan and Z. Kovecses). 2007. MIP: A method for
identifying metaphorically used words in discourse.
Metaphor and Symbol, 22:1–39.
P. Resnik. 1993. Selection and Information: A Class-
based Approach to Lexical Relationships. Ph.D. the-
sis, Philadelphia, PA, USA.
P. Resnik. 1997. Selectional preference and sense disam-
biguation. In ACL SIGLEX Workshop on Tagging Text
with Lexical Semantics, Washington, D.C.
S. Siegel and N. J. Castellan. 1988. Nonparametric
statistics for the behavioral sciences. McGraw-Hill
Book Company, New York, USA.
L. Sun and A. Korhonen. 2009. Improving verb clus-
tering with automatically acquired selectional prefer-
ences. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
pages 638–647, Singapore, August.
T. Veale and Y. Hao. 2008. A fluid knowledge rep-
resentation for understanding and generating creative
metaphors. In Proceedings of the 22nd Interna-
tional Conference on Computational Linguistics (Col-
ing 2008), pages 945–952, Manchester, UK.
Y. Wilks. 1978. Making preferences more active. Artifi-
cialIntelligence, 11(3):197–223.
</reference>
<page confidence="0.993922">
1037
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.639119">
<title confidence="0.999749">Automatic Metaphor Interpretation as a Paraphrasing Task</title>
<author confidence="0.974787">Ekaterina</author>
<affiliation confidence="0.9833865">Computer University of</affiliation>
<address confidence="0.897138">15 JJ Thomson Cambridge CB3 0FD, UK</address>
<email confidence="0.983916">Ekaterina.Shutova@cl.cam.ac.uk</email>
<abstract confidence="0.989563714285714">We present a novel approach to metaphor interpretation and a system that produces literal paraphrases for metaphorical expressions. Such a representation is directly transferable to other applications that can benefit from a metaphor processing component. Our method is distinguished from the previous work in that it does not rely on any hand-crafted knowledge about metaphor, but in contrast employs automatically induced selectional preferences. Being the first of its kind, our system is capable of paraphrasing metaphorical expressions with a high accuracy (0.81).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agerri</author>
<author>J A Barnden</author>
<author>M G Lee</author>
<author>A M Wallington</author>
</authors>
<title>Metaphor, inference and domain-independent mappings.</title>
<date>2007</date>
<booktitle>In Proceedings of International Conference on Recent Advances in Natural Language Processing (RANLP-2007),</booktitle>
<pages>17--23</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="3621" citStr="Agerri et al., 2007" startWordPosition="553" endWordPosition="556">(Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphorical expression (induced automatically from a large corpus); (2) ranks the paraphrases according to their lik</context>
<context position="27679" citStr="Agerri et al., 2007" startWordPosition="4417" endWordPosition="4420">repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are</context>
</contexts>
<marker>Agerri, Barnden, Lee, Wallington, 2007</marker>
<rawString>R. Agerri, J.A. Barnden, M.G. Lee, and A.M. Wallington. 2007. Metaphor, inference and domain-independent mappings. In Proceedings of International Conference on Recent Advances in Natural Language Processing (RANLP-2007), pages 17–23, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O E Andersen</author>
<author>J Nioche</author>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>The BNC parsed with RASP4UIMA.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation Conference (LREC’08),</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="12627" citStr="Andersen et al. (2008)" startWordPosition="2044" endWordPosition="2047">the relation rn. By performing appropriate substitutions into (2) we obtain P(i, (w1, r1), (w2, r2), ..., (wN, rN)) = f(i) f(w1, r1, i) f(wN, rN, i) Ek f(ik) · f(i) · ... · f(i) = HN 11n=1 f(wn, rn, i) (f(i))N−1 · Ek f(ik) (5) This model is then used to rank the possible replacements of the term used metaphorically in the fixed context according to the data. 3.2 Parameter Estimation The parameters of the model were estimated from the British National Corpus that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations (GRs) output of RASP for BNC created by Andersen et al. (2008). The same output of RASP was used to identify the GRs in the metaphorical expressions themselves, as the metaphor corpus from which they were extracted is a subset of the BNC. To obtain the counts for f(wn, rn, i) we extracted all the terms appearing in the corpus in the relation rn with wn for each lexical item - relation pair. The initial list of replacements for the metaphorical term was constructed by taking an overlap of the lists of terms for each lexical item - relation pair. 3.3 Identifying Shared Meanings in WordNet It should be noted that the context-based model described in 3.1 ove</context>
</contexts>
<marker>Andersen, Nioche, Briscoe, Carroll, 2008</marker>
<rawString>O. E. Andersen, J. Nioche, E. Briscoe, and J. Carroll. 2008. The BNC parsed with RASP4UIMA. In Proceedings of the Sixth International Language Resources and Evaluation Conference (LREC’08), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Barnden</author>
<author>M G Lee</author>
</authors>
<title>An artificial intelligence approach to metaphor understanding. Theoria etHistoria</title>
<date>2002</date>
<journal>Scientiarum,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3599" citStr="Barnden and Lee, 2002" startWordPosition="549" endWordPosition="552">y car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphorical expression (induced automatically from a large corpus); (2) ranks the paraphrases </context>
<context position="27657" citStr="Barnden and Lee, 2002" startWordPosition="4413" endWordPosition="4416">e general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logica</context>
</contexts>
<marker>Barnden, Lee, 2002</marker>
<rawString>J.A. Barnden and M.G. Lee. 2002. An artificial intelligence approach to metaphor understanding. Theoria etHistoria Scientiarum, 6(1):399–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="12529" citStr="Briscoe et al. (2006)" startWordPosition="2027" endWordPosition="2030">n, rn, i) - the frequency of the co-occurrence of the interpretation with the context word wn in the relation rn. By performing appropriate substitutions into (2) we obtain P(i, (w1, r1), (w2, r2), ..., (wN, rN)) = f(i) f(w1, r1, i) f(wN, rN, i) Ek f(ik) · f(i) · ... · f(i) = HN 11n=1 f(wn, rn, i) (f(i))N−1 · Ek f(ik) (5) This model is then used to rank the possible replacements of the term used metaphorically in the fixed context according to the data. 3.2 Parameter Estimation The parameters of the model were estimated from the British National Corpus that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations (GRs) output of RASP for BNC created by Andersen et al. (2008). The same output of RASP was used to identify the GRs in the metaphorical expressions themselves, as the metaphor corpus from which they were extracted is a subset of the BNC. To obtain the counts for f(wn, rn, i) we extracted all the terms appearing in the corpus in the relation rn with wn for each lexical item - relation pair. The initial list of replacements for the metaphorical term was constructed by taking an overlap of the lists of terms for each lexical item - relation pair. 3.3 Identifyi</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>E. Briscoe, J. Carroll, and R. Watson. 2006. The second release of the rasp system. In Proceedings of the COLING/ACL on Interactive presentation sessions, pages 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
</authors>
<date>2007</date>
<booktitle>Reference Guide for the British National Corpus (XML Edition). URL=http://www.natcorp.ox.ac.uk/XMLedition/URG/.</booktitle>
<contexts>
<context position="2058" citStr="Burnard, 2007" startWordPosition="322" endWordPosition="323">(2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (1) and (2), to poetic and largely novel ones, such as (3). The use of metaphor is ubiquitous in natural language text and it is a serious bottleneck in automatic text understanding. In order to estimate the frequency of the phenomenon, we conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various genres. We manually annotated metaphorical expressions in this data and found that 241 out of 761 sentences contained a metaphor or (rarely) an idiom. Due to such a high frequency of their use, a system capable of interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal </context>
</contexts>
<marker>Burnard, 2007</marker>
<rawString>L. Burnard. 2007. Reference Guide for the British National Corpus (XML Edition). URL=http://www.natcorp.ox.ac.uk/XMLedition/URG/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Fass</author>
</authors>
<title>met*: A method for discriminating metonymy and metaphor by computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="3499" citStr="Fass, 1991" startWordPosition="537" endWordPosition="538">ion of selectional restrictions in a given context. Consider the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases f</context>
<context position="25496" citStr="Fass (1991)" startWordPosition="4080" endWordPosition="4081">Net as the metaphorical sense of mount. 5 Related Work According to Conceptual Metaphor Theory (Lakoff and Johnson, 1980) metaphor can be viewed as an analogy between two distinct domains - the target and the source. Consider the following example: (6) He shot down all of my arguments. (Lakoff and Johnson, 1980) A mapping of a concept of argument (target) to that of war (source) is employed here. The idea of such interconceptual mappings has been exploited in some NLP systems. One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes hand-coded knowledge. Fass (1991) developed a system called met*, capable of discriminating between literalness, metonymy, metaphor and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selectional preference violation as an indicator. In the case that nonliteralness is detected, the respective phrase is tested for being a metonymic relation using hand-coded patterns (such as CONTAINER-for-CONTENT). If the system fails to recognize metonymy, it proceeds to search the knowledge base for </context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>D. Fass. 1991. met*: A method for discriminating metonymy and metaphor by computer. Computational Linguistics, 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Feldman</author>
<author>S Narayanan</author>
</authors>
<title>Embodied meaning in a neural theory of language.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="3576" citStr="Feldman and Narayanan, 2004" startWordPosition="545" endWordPosition="548"> the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphorical expression (induced automatically from a large corpus); (2)</context>
<context position="27609" citStr="Feldman and Narayanan, 2004" startWordPosition="4405" endWordPosition="4408">does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take</context>
</contexts>
<marker>Feldman, Narayanan, 2004</marker>
<rawString>J. Feldman and S. Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385–392.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database (ISBN:</booktitle>
<pages>0--262</pages>
<editor>C. Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<note>first edition.</note>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (ISBN: 0-262-06197-X). MIT Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hofstadter</author>
<author>M Mitchell</author>
</authors>
<title>The Copycat Project: A model of mental fluidity and analogymaking.</title>
<date>1994</date>
<booktitle>Advances in Connectionist and Neural Computation Theory,</booktitle>
<editor>In K.J. Holyoak and J. A. Barnden, editors,</editor>
<location>Ablex, New Jersey.</location>
<contexts>
<context position="29149" citStr="Hofstadter and Mitchell, 1994" startWordPosition="4644" endWordPosition="4647">d generation”, called Talking Points. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source concepts. This work builds on the idea of slippage in knowledge representation for understanding analogies in abstract domains (Hofstadter and Mitchell, 1994; Hofstadter, 1995). Consider the metaphor Make-up is a Western burqa: Make-up =&gt; � typically worn by women � expected to be worn by women � must be worn by women � must be worn by Muslim women Burqa &lt;= By doing insertions and substitutions the system arrives from the definition typically worn by women to that of must be worn by Muslim women, and thus establish a link between the concepts of make-up and burqa. Veale and Hao (2008), however, did not evaluate to which extent their method is useful to interpret metaphorical expressions occurring in text. 6 Conclusions We presented a novel approac</context>
</contexts>
<marker>Hofstadter, Mitchell, 1994</marker>
<rawString>D. Hofstadter and M. Mitchell. 1994. The Copycat Project: A model of mental fluidity and analogymaking. In K.J. Holyoak and J. A. Barnden, editors, Advances in Connectionist and Neural Computation Theory, Ablex, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hofstadter</author>
</authors>
<title>Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought.</title>
<date>1995</date>
<publisher>HarperCollins Publishers.</publisher>
<contexts>
<context position="29168" citStr="Hofstadter, 1995" startWordPosition="4648" endWordPosition="4649">oints. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source concepts. This work builds on the idea of slippage in knowledge representation for understanding analogies in abstract domains (Hofstadter and Mitchell, 1994; Hofstadter, 1995). Consider the metaphor Make-up is a Western burqa: Make-up =&gt; � typically worn by women � expected to be worn by women � must be worn by women � must be worn by Muslim women Burqa &lt;= By doing insertions and substitutions the system arrives from the definition typically worn by women to that of must be worn by Muslim women, and thus establish a link between the concepts of make-up and burqa. Veale and Hao (2008), however, did not evaluate to which extent their method is useful to interpret metaphorical expressions occurring in text. 6 Conclusions We presented a novel approach to metaphor inter</context>
</contexts>
<marker>Hofstadter, 1995</marker>
<rawString>D. Hofstadter. 1995. Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought. HarperCollins Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
<author>M Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="1107" citStr="Lakoff and Johnson, 1980" startWordPosition="163" endWordPosition="166">hed from the previous work in that it does not rely on any hand-crafted knowledge about metaphor, but in contrast employs automatically induced selectional preferences. Being the first of its kind, our system is capable of paraphrasing metaphorical expressions with a high accuracy (0.81). 1 Introduction Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concepts. Similarity is a kind of association implying the presence of characteristics in common. Here are some examples of metaphor. (1) News travels fast. (Lakoff and Johnson, 1980) (2) How can I kill a process? (Martin, 1988) (3) And then my heart with pleasure fills, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another 1taken from the verse “I wandered lonely as a cloud” written by William Wordsworth in 1804. concept. In the example (2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend eve</context>
<context position="25006" citStr="Lakoff and Johnson, 1980" startWordPosition="3995" endWordPosition="3998">e 3: Disambiguated paraphrases produced by the system Relation Baseline System Verb-DirectObject 0.52 0.79 Verb-Subject 0.57 0.83 Average 0.55 0.81 Table 4: Accuracy with the evaluation setting 1 controvertial example was the metaphorical expression tension mounted, for which the system produced a paraphrase tension lifted with the opposite meaning. This error is likely to have been triggered by the feature similarity component, whereby one of the senses of lift would stem from the same node in WordNet as the metaphorical sense of mount. 5 Related Work According to Conceptual Metaphor Theory (Lakoff and Johnson, 1980) metaphor can be viewed as an analogy between two distinct domains - the target and the source. Consider the following example: (6) He shot down all of my arguments. (Lakoff and Johnson, 1980) A mapping of a concept of argument (target) to that of war (source) is employed here. The idea of such interconceptual mappings has been exploited in some NLP systems. One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes hand-coded knowledge. Fass (1991) developed a system </context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>G. Lakoff and M. Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>Representing regularities in the metaphoric lexicon.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th conference on Computational linguistics,</booktitle>
<pages>396--401</pages>
<contexts>
<context position="1152" citStr="Martin, 1988" startWordPosition="174" endWordPosition="175">y hand-crafted knowledge about metaphor, but in contrast employs automatically induced selectional preferences. Being the first of its kind, our system is capable of paraphrasing metaphorical expressions with a high accuracy (0.81). 1 Introduction Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concepts. Similarity is a kind of association implying the presence of characteristics in common. Here are some examples of metaphor. (1) News travels fast. (Lakoff and Johnson, 1980) (2) How can I kill a process? (Martin, 1988) (3) And then my heart with pleasure fills, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another 1taken from the verse “I wandered lonely as a cloud” written by William Wordsworth in 1804. concept. In the example (2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (1) and (2), to poetic </context>
</contexts>
<marker>Martin, 1988</marker>
<rawString>J. H. Martin. 1988. Representing regularities in the metaphoric lexicon. In Proceedings of the 12th conference on Computational linguistics, pages 396–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>A Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press Professional, Inc.,</publisher>
<location>San Diego, CA, USA.</location>
<contexts>
<context position="3513" citStr="Martin, 1990" startWordPosition="539" endWordPosition="540">tional restrictions in a given context. Consider the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphori</context>
<context position="26648" citStr="Martin (1990)" startWordPosition="4255" endWordPosition="4256">gnize metonymy, it proceeds to search the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. E.g., the sentence in (4) would be represented in this framework as (car,drink,gasoline), which does not satisfy the preference (animal,drink,liquid), as car is not a hyponym of animal. met* then searches its knowledge base for a triple containing a hypernym of both the actual argument and the desired argument and finds (thing,use,energy source), which represents the metaphorical interpretation. Almost simultaneously with the work of Fass (1991), Martin (1990) presents a Metaphor Inter1035 pretation, Denotation and Acquisition System (MIDAS). The idea behind this work is that the more specific conventional metaphors descend from the general ones. Given an example of a metaphorical expression, MIDAS searches its database for a corresponding metaphor that would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are a</context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>J. H. Martin. 1990. A Computational Model of Metaphor Interpretation. Academic Press Professional, Inc., San Diego, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
</authors>
<title>Knowledge-based action representations for metaphor and aspect (KARMA).</title>
<date>1997</date>
<tech>Technical report, PhD thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="3530" citStr="Narayanan, 1997" startWordPosition="541" endWordPosition="542">tions in a given context. Consider the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphorical expression (i</context>
<context position="27562" citStr="Narayanan, 1997" startWordPosition="4401" endWordPosition="4402"> would explain the anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first or</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>S. Narayanan. 1997. Knowledge-based action representations for metaphor and aspect (KARMA). Technical report, PhD thesis, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
</authors>
<title>Moving right along: A computational model of metaphoric reasoning about events. In</title>
<date>1999</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI 99),</booktitle>
<pages>121--128</pages>
<location>Orlando, Florida.</location>
<contexts>
<context position="3547" citStr="Narayanan, 1999" startWordPosition="543" endWordPosition="544">context. Consider the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpretation rely on task-specific hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007) and produce interpretations in a non-textual format. However, the ultimate objective of automatic metaphor processing is a type of interpretation that can be directly embedded into other systems to enhance their performance. Thus, we define metaphor interpretation as a paraphrasing task and build a system that automatically derives literal paraphrases for metaphorical expressions in unrestricted text. In summary, our system (1) produces a list of all possible paraphrases for a metaphorical expression (induced automatica</context>
<context position="27579" citStr="Narayanan, 1999" startWordPosition="4403" endWordPosition="4404">e anomaly. If it does not find any, it abstracts from the example to more general concepts and repeats the search. If it finds a suitable general metaphor, it creates a mapping for its descendant, a more specific metaphor, based on this example. This is also how novel metaphors are acquired. MIDAS has been integrated with the Unix Consultant (UC), the system that answers users questions about Unix. Another cohort of approaches relies on performing inferences about entities and events in the source and target domains for metaphor interpretation. These include the KARMA system (Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004) and the ATT-Meta project (Barnden and Lee, 2002; Agerri et al., 2007). Within both systems the authors developed a metaphor-based reasoning framework in accordance with the theory of conceptual metaphor. The reasoning process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their </context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>S. Narayanan. 1999. Moving right along: A computational model of metaphoric reasoning about events. In In Proceedings of the National Conference on Artificial Intelligence (AAAI 99), pages 121–128, Orlando, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pragglejaz Group</author>
</authors>
<title>MIP: A method for identifying metaphorically used words in discourse. Metaphor and Symbol,</title>
<date>2007</date>
<pages>22--1</pages>
<contexts>
<context position="4810" citStr="Group, 2007" startWordPosition="731" endWordPosition="732"> according to their likelihood derived from the corpus; (3) discriminates between literal and figurative paraphrases by detecting selectional preference violation and outputs the literal ones; and (4) disambiguates the sense of the paraphrases using WordNet (Fellbaum, 1998) inventory of senses. We tested our system on a collection of metaphorical expressions representing verb-subject and verbobject constructions, where the verb is used metaphorically. To compile this dataset we manually annotated such phrases in a subset of the BNC using the metaphor identification procedure (MIP) (Pragglejaz Group, 2007). We then evaluated the quality of paraphrasing with the help of human annotators and created a gold standard for this task. 2 Experimental Data Since we focus on single-word metaphors expressed by a verb, our annotation task can be viewed as verb classification according to whether the verbs are used metaphorically or literally. However, some verbs have weak or no potential of being a metaphor and, thus, our study is not concerned with them. We excluded the following verb classes: (1) auxiliary verbs; (2) modal verbs; (3) aspectual verbs (e.g. begin, start, finish); (4) light verbs (e.g. take</context>
<context position="6610" citStr="Group, 2007" startWordPosition="1020" endWordPosition="1021">ical ones. MIP involves metaphor annotation at the word level as opposed to identifying metaphorical relations (between words) or source– target domain mappings (between concepts or domains). Such annotation can be viewed as a form of word sense disambiguation with an emphasis on metaphoricity. In order to discriminate between the verbs used metaphorically and literally we use the following procedure as part of our guidelines: 1. For each verb establish its meaning in context and try to imagine a more basic meaning of this verb on other contexts. As defined in the framework of MIP (Pragglejaz Group, 2007) basic meanings normally are: (1) more concrete; (2) related to bodily action; (3) more precise (as opposed to vague); (4) historically older. 2. If you can establish the basic meaning that is distinct from the meaning of the verb in this context, the verb is likely to be used metaphorically. Consider the following example sentence: (5) If he asked her to post a letter or buy some razor blades from the chemist, she was transported with pleasure. In this sentence one needs to annotate four verbs that are underlined. The first 3 verbs are used in their basic sense, i.e. literally (ask in the con</context>
</contexts>
<marker>Group, 2007</marker>
<rawString>Pragglejaz Group (P. Crisp, R. Gibbs, A. Cienki, G. Low, G. Steen, L. Cameron, E. Semino, J. Grady, A. Deignan and Z. Kovecses). 2007. MIP: A method for identifying metaphorically used words in discourse. Metaphor and Symbol, 22:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selection and Information: A Classbased Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="16998" citStr="Resnik (1993)" startWordPosition="2737" endWordPosition="2738">d select for truth. This would potentially allow us to filter out non-literalness, as well as unrelated verbs, by selecting the verbs that the noun in the metaphorical expression matches best. We automatically acquired selectional preference distributions of the verbs in the paraphrase lists (for Verb-Subject and Verb-Object relations) from the BNC parsed by RASP. We first clustered 2000 most frequent nouns in the BNC into 200 clusters using the algorithm of Sun and Korhonen (2009). The obtained clusters formed our selectional preference classes. We adopted the association measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). Resnik models selectional preference of a verb in probabilistic terms as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position regardless of the identity of the predicate. He quantifies this difference using the relative entropy (or Kullback-Leibler distance), defining the selectional preference strength as follows. SR(v) = D(P(c|v)||P(c)) = EP cP(c|v) log P(C|V), (6) where P(c) is th</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>P. Resnik. 1993. Selection and Information: A Classbased Approach to Lexical Relationships. Ph.D. thesis, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selectional preference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In ACL SIGLEX Workshop on Tagging Text with Lexical Semantics,</booktitle>
<location>Washington, D.C.</location>
<contexts>
<context position="17102" citStr="Resnik, 1997" startWordPosition="2754" endWordPosition="2755">verbs, by selecting the verbs that the noun in the metaphorical expression matches best. We automatically acquired selectional preference distributions of the verbs in the paraphrase lists (for Verb-Subject and Verb-Object relations) from the BNC parsed by RASP. We first clustered 2000 most frequent nouns in the BNC into 200 clusters using the algorithm of Sun and Korhonen (2009). The obtained clusters formed our selectional preference classes. We adopted the association measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). Resnik models selectional preference of a verb in probabilistic terms as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position regardless of the identity of the predicate. He quantifies this difference using the relative entropy (or Kullback-Leibler distance), defining the selectional preference strength as follows. SR(v) = D(P(c|v)||P(c)) = EP cP(c|v) log P(C|V), (6) where P(c) is the prior probability of the noun class, P(c|v) is the posterior probability of the noun class given the v</context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>P. Resnik. 1997. Selectional preference and sense disambiguation. In ACL SIGLEX Workshop on Tagging Text with Lexical Semantics, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Nonparametric statistics for the behavioral sciences.</title>
<date>1988</date>
<publisher>McGraw-Hill Book Company,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="8701" citStr="Siegel and Castellan, 1988" startWordPosition="1377" endWordPosition="1380">rs of English and had some linguistics background. Material and Task All of them received the same text taken from the BNC containing 142 verbs to annotate. They were asked to classify verbs as metaphorical or literal. Guidelines and Training The annotators received written guidelines (2 pages) and were asked to do a small annotation exercise (2 sentences containing 8 verbs in total). The goal of the exercise was to ensure they were at ease with the annotation format. Interannotator Agreement We evaluate reliability of our annotation scheme by assessing interannotator agreement in terms of n (Siegel and Castellan, 1988). The classification was performed with the agreement of 0.64 (n), which is considered reliable. The main source of disagreement was the high conventionality of some expressions, i.e. cases where the metaphorical etymology could be clearly traced, but the senses are highly lexicalized. 2.4 Phrase Selection Only the phrases that were tagged as metaphorical by all of the annotators were included in the test set. Here are some examples of such phrases: memories were slipping away; hold the truth back; stirred an unfathomable excitement; factors shape results; mending their marriage; brushed aside</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and N. J. Castellan. 1988. Nonparametric statistics for the behavioral sciences. McGraw-Hill Book Company, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Sun</author>
<author>A Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>638--647</pages>
<location>Singapore,</location>
<contexts>
<context position="16871" citStr="Sun and Korhonen (2009)" startWordPosition="2717" endWordPosition="2720">r 0.0674 reveal 0.0597 issue � 0 emerge Pz�0 expose Table 2: The list of paraphrases reranked using selectional preferences conceal) would select for truth. This would potentially allow us to filter out non-literalness, as well as unrelated verbs, by selecting the verbs that the noun in the metaphorical expression matches best. We automatically acquired selectional preference distributions of the verbs in the paraphrase lists (for Verb-Subject and Verb-Object relations) from the BNC parsed by RASP. We first clustered 2000 most frequent nouns in the BNC into 200 clusters using the algorithm of Sun and Korhonen (2009). The obtained clusters formed our selectional preference classes. We adopted the association measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). Resnik models selectional preference of a verb in probabilistic terms as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position regardless of the identity of the predicate. He quantifies this difference using the relative entropy (or Kullback-Leibler distance),</context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>L. Sun and A. Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 638–647, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>A fluid knowledge representation for understanding and generating creative metaphors.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>945--952</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="28448" citStr="Veale and Hao (2008)" startWordPosition="4534" endWordPosition="4537">process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are representations of small discourse fragments. KARMA in turn deals with a broad range of abstract actions and events and takes parsed text as input. Veale and Hao (2008) derive a “fluid knowledge representation for metaphor interpretation and generation”, called Talking Points. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source concepts. This work builds on the idea of slippage in kn</context>
</contexts>
<marker>Veale, Hao, 2008</marker>
<rawString>T. Veale and Y. Hao. 2008. A fluid knowledge representation for understanding and generating creative metaphors. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 945–952, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Making preferences more active.</title>
<date>1978</date>
<journal>ArtificialIntelligence,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="2839" citStr="Wilks (1978)" startWordPosition="438" endWordPosition="439">om. Due to such a high frequency of their use, a system capable of interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. To date the most influential account of metaphor recognition has been that of Wilks (1978). According to Wilks, metaphors represent a violation of selectional restrictions in a given context. Consider the following example. (4) My car drinks gasoline. (Wilks, 1978) 1029 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1029–1037, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. Most approaches to metaphor interpret</context>
<context position="25539" citStr="Wilks (1978)" startWordPosition="4088" endWordPosition="4089">Related Work According to Conceptual Metaphor Theory (Lakoff and Johnson, 1980) metaphor can be viewed as an analogy between two distinct domains - the target and the source. Consider the following example: (6) He shot down all of my arguments. (Lakoff and Johnson, 1980) A mapping of a concept of argument (target) to that of war (source) is employed here. The idea of such interconceptual mappings has been exploited in some NLP systems. One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes hand-coded knowledge. Fass (1991) developed a system called met*, capable of discriminating between literalness, metonymy, metaphor and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selectional preference violation as an indicator. In the case that nonliteralness is detected, the respective phrase is tested for being a metonymic relation using hand-coded patterns (such as CONTAINER-for-CONTENT). If the system fails to recognize metonymy, it proceeds to search the knowledge base for a relevant analogy in order to discriminate</context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Y. Wilks. 1978. Making preferences more active. ArtificialIntelligence, 11(3):197–223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>