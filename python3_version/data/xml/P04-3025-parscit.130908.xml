<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.120750">
<title confidence="0.980542">
Incorporating topic information into sentiment analysis models
</title>
<author confidence="0.995302">
Tony Mullen
</author>
<affiliation confidence="0.979148">
National Institute of Informatics (NII)
</affiliation>
<address confidence="0.714919666666667">
Hitotsubashi 2-1-2, Chiyoda-ku
Tokyo 101-8430,
Japan,
</address>
<email confidence="0.997324">
mullen@nii.ac.jp
</email>
<author confidence="0.91487">
Nigel Collier
</author>
<affiliation confidence="0.905973">
National Institute of Informatics (NII)
</affiliation>
<address confidence="0.676615333333333">
Hitotsubashi 2-1-2, Chiyoda-ku
Tokyo 101-8430,
Japan,
</address>
<email confidence="0.988608">
collier@nii.ac.jp
</email>
<sectionHeader confidence="0.993534" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99946875">
This paper reports experiments in classifying texts based upon their favorability towards the subject of the
text using a feature set enriched with topic information on a small dataset of music reviews hand-annotated
for topic. The results of these experiments suggest ways in which incorporating topic information into such
models may yield improvement over models which do not use topic information.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999987333333333">
There are a number of challenging aspects in recognizing the favorability of opinion-based texts, the task
known as sentiment analysis. Opinions in natural language are very often expressed in subtle and complex
ways, presenting challenges which may not be easily addressed by simple text categorization approaches
such as n-gram or keyword identification approaches. Although such approaches have been employed ef-
fectively (Pang et al., 2002), there appears to remain considerable room for improvement. Moving beyond
these approaches can involve addressing the task at several levels. Negative reviews may contain many ap-
parently positive phrases even while maintaining a strongly negative tone, and the opposite is also common.
This paper attempts to address this issue using Support Vector Machines (SVMs), a well-known and
powerful tool for classification of vectors of real-valued features (Vapnik, 1998). The present approach
emphasizes the use of a variety of diverse information sources. In particular, several classes of features based
upon the proximity of the topic with phrases which have been assigned favorability values are described in
order to take advantage of situations in which the topic of the text may be explicitly identified.
</bodyText>
<sectionHeader confidence="0.978001" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999861222222222">
In the past, work has been done in the area of characterizing words and phrases according to their emotive
tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000;
Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual
phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment
of the task as analogous to topic-classification underscores the difference between the two tasks. A number
of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or ex-
pectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse
domains, create challenges for these approaches. It is hoped that incorporating topic information along the
lines suggested in this paper will be a step towards solving some of these problems.
</bodyText>
<sectionHeader confidence="0.99978" genericHeader="method">
3 Methods
</sectionHeader>
<subsectionHeader confidence="0.999624">
3.1 Semantic orientation with PMI
</subsectionHeader>
<bodyText confidence="0.999986571428572">
Here, the term semantic orientation (SO) (Hatzivassiloglou and McKeown, 2002) refers to a real number
measure of the positive or negative sentiment expressed by a word or phrase. In the present work, the
approach taken by Turney (2002) is used to derive such values for selected phrases in the text. For the
purposes of this paper, these phrases will be referred to as value phrases, since they will be the sources of
SO values. Once the desired value phrases have been extracted from the text, each one is assigned an SO
value. The SO of a phrase is determined based upon the phrase’s pointwise mutual information (PMI) with
the words “excellent” and “poor”. PMI is defined by Church and Hanks (1989) as follows:
</bodyText>
<equation confidence="0.960599">
(1)
</equation>
<bodyText confidence="0.9999099">
where is the probability that and co-occur.
The SO for a is the difference between its PMI with the word “excellent” and its PMI with the
word “poor.” The method used to derive these values takes advantage of the possibility of using the World
Wide Web as a corpus, similarly to work such as (Keller and Lapata, 2003). The probabilities are estimated
by querying the AltaVista Advanced Search engine&apos; for counts. The search engine’s “NEAR” operator,
representing occurrences of the two queried words within ten words of each other in a text, is used to define
co-occurrence. The final SO equation is
Intuitively, this yields values above zero for phrases with greater PMI with the word “excellent” and
below zero for greater PMI with “poor”. A SO value of zero would indicate a completely neutral semantic
orientation.
</bodyText>
<subsectionHeader confidence="0.999622">
3.2 Osgood semantic differentiation with WordNet
</subsectionHeader>
<bodyText confidence="0.9999855">
Further feature types are derived using the method of Kamps and Marx (2002) of using WordNet relation-
ships to derive three values pertinent to the emotive meaning of adjectives. The three values correspond to
the potency (strong or weak), activity (active or passive) and the evaluative (good or bad) factors introduced
in Charles Osgood’s Theory of Semantic Differentiation (Osgood et al., 1957).
These values are derived by measuring the relative minimal path length (MPL) in WordNet between the
adjective in question and the pair of words appropriate for the given factor. In the case of the evaluative
factor (EVA) for example, the comparison is between the MPL between the adjective and “good” and the
MPL between the adjective and “bad”.
Only adjectives connected by synonymy to each of the opposites are considered. The method results in
a list of 5410 adjectives, each of which is given a value for each of the three factors referred to as EVA,
POT, and ACT. Each of these factors’ values are averaged over all the adjectives in a text, yielding three
real-valued feature values for the text, which will be added to the SVM model.
</bodyText>
<subsectionHeader confidence="0.999902">
3.3 Topic proximity and syntactic-relation features
</subsectionHeader>
<bodyText confidence="0.989516179487179">
In some application domains, it is known in advance what the topic is toward which sentiment is to be
evaluated. Incorporating this information is done by creating several classes of features based upon the
semantic orientation values of phrases given their position in relation to the topic of the text. The approach
allows secondary information to be incorporated where available, in this case, the primary information is
the specific record being reviewed and the secondary information identified is the artist.
Texts were annotated by hand using the Open Ontology Forge annotation tool (Collier et al., 2003).
In each record review, references (including co-reference) to the record being reviewed were tagged as
THIS WORK and references to the artist under review were tagged as THIS ARTIST.
With these entities tagged, a number of classes of features may be extracted, representing various relation-
ships between topic entities and value phrases similar to those described in section 3.1. The classes looked
at in this work are as follows:
Turney Value The average value of all value phrases’ SO values for the text. Classification by this feature
alone is not the equivalent of Turney’s approach, since the present approach involves retraining in a
supervised model.
In sentence with THIS WORK The average value of all value phrases which occur in the same sentence
as a reference to the work being reviewed.
lwww.altavista.com
Following THIS WORK The average value of all value phrases which follow a reference to the work being
reviewed directly, or separated only by the copula or a preposition.
Preceding THIS WORK The average value of all value phrases which precede a reference to the work
being reviewed directly, or separated only by the copula or a preposition.
In sentence with THIS ARTIST As above, but with reference to the artist.
Following THIS ARTIST As above, but with reference to the artist.
Preceding THIS ARTIST As above, but with reference to the artist.
The features used which make use of adjectives with WordNet derived Osgood values include the follow-
ing:
Text-wide EVA The average EVA value of all adjectives in a text.
Text-wide POT The average POT value of all adjectives in a text.
Text-wide ACT The average ACT value of all adjectives in a text.
TOPIC-sentence EVA The average EVA value of all adjectives which share a sentence with the topic of
the text.
TOPIC-sentence POT The average POT value of all adjectives which share a sentence with the topic of
the text.
TOPIC-sentence ACT The average ACT value of all adjectives which share a sentence with the topic of
the text.
The grouping of these classes should reflect some common degree of reliability of features within a given
class, but due to data sparseness what might have been more natural class groupings—for example including
value-phrase preposition topic-entity as a distinct class—often had to be conflated in order to get features
with enough occurrences to be representative.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999818285714286">
The dataset consists of 100 record reviews from the Pitchfork Media online record review publication,2
topic-annotated by hand. Features used include word unigrams and lemmatized unigrams3 as well as the
features described in 3.3 which make use of topic information, namely the broader PMI derived SO values
and the topic-sentence Osgood values. Due to the relatively small size of this dataset, test suites were created
using 100, 20, 10, and 5-fold cross validation, to maximize the amount of data available for training and the
accuracy of the results.
SVMs were built using Kudo’s TinySVM software implementation.4
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.982896">
Experimental results may be seen in figure 1. It must be noted that this dataset is very small,and although the
results are not conclusive they are promising insofar as they suggest that the use of incorporating PMI values
towards the topic yields some improvement in modeling. They also suggest that the best way to incorporate
such features is in the form of a separate SVM which may then be combined with the lemma-based model
to create a hybrid.
</bodyText>
<footnote confidence="0.999870666666667">
2http://www.pitchforkmedia.com
3We employ the Conexor FDG parser (Tapanainen and J¨arvinen, 1997) for POS tagging and lemmatization
4http://cl.aist-nara.ac.jp/˜taku-ku/software/TinySVM
</footnote>
<table confidence="0.996806214285714">
Model 5 folds 10 folds 20 folds 100 folds
All (THIS WORK and THIS ARTIST) PMI 70% 70% 68% 69%
THIS WORK PMI 72% 69% 70% 71%
All Osgood 64% 64% 65% 64%
All PMI and Osgood 74% 71% 74% 72%
Unigrams 79% 80% 78% 82%
Unigrams, PMI, Osgood 81% 80% 82% 82%
Lemmas 83% 85% 84% 84%
Lemmas and Osgood 83% 84% 84% 84%
Lemmas and Turney 84% 85% 84% 84%
Lemmas, Turney, text-wide Osgood 84% 85% 84% 84%
Lemmas, PMI, Osgood 84% 85% 84% 86%
Lemmas and PMI 84% 85% 85% 86%
Hybrid SVM (PMI/Osgood and Lemmas) 86% 87% 84% 89%
</table>
<figureCaption confidence="0.995952">
Figure 1: Accuracy results (percent of texts correctly classed) for 5, 10, 20 and 100-fold cross-validation
tests with Pitchforkmedia.com record review data, hand-annotated for topic.
</figureCaption>
<subsectionHeader confidence="0.922666">
5.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999934791666667">
At the level of the phrasal SO assignment, it would seem that some improvement could be gained by adding
domain context to the AltaVista Search. Many—perhaps most—terms’ favorability content depends to some
extent on their context. As Turney notes, “unpredictable,” is generally positive when describing a movie plot,
and negative when describing an automobile or a politician. Likewise, such terms as “devastating” might be
generally negative, but in the context of music or art may imply an emotional engagement which is usually
seen as positive. Likewise, using “excellent” and “poor” as the poles in assessing this value seems somewhat
arbitrary, especially given the potentially misleading economic meaning of “poor.” Nevertheless, cursory
experiments in adjusting the search have not yielded improvements. One problem with limiting the domain
(such as adding “AND music” or some disjunction of such constraints to the query) is that the resultant hit
count is greatly diminished. The data sparseness which results from added restrictions appears to cancel out
any potential gain. It is to be hoped that in the future, as search engines continue to improve and the Internet
continues to grow, more possibilities will open up in this regard. As it is, Google returns more hits than
AltaVista, but its query syntax lacks a “NEAR” operator, making it unsuitable for this task. As to why using
“excellent” and “poor” works better than, for example “good” and “bad,” it is not entirely clear. Again,
cursory investigations have thus far supported Turney’s conclusion that the former are the appropriate terms
to use for this task.
It also seems likely that the topic-relations aspect of the present research only scratches the surface of
what should be possible. Although performance in the mid-80s is not bad, there is still considerable room
for improvement. The present models may also be further expanded with features representing other infor-
mation sources, which may include other types of semantic annotation (Wiebe, 2002; Wiebe et al., 2002), or
features based on more sophisticated grammatical or dependency relations, or perhaps upon such things as
zoning (e.g. do opinions become more clearly stated towards the end of a text?). In any case, it is hoped that
the present work may help to indicate how various information sources pertinent to the task may be brought
together.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999855">
Further investigation using larger datasets is necessary for the purposes of fully exploiting topic information
where it is available, but the present results suggest that this is a worthwhile direction to investigate.
</bodyText>
<sectionHeader confidence="0.997937" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992995852941177">
K.W. Church and P. Hanks. 1989. Word association norms, mutual information and lexicography. In Pro-
ceedings of the 27th Annual Conference of the ACL, New Brunswick, NJ.
N. Collier, K. Takeuchi, A. Kawazoe, T. Mullen, and T. Wattarujeekrit. 2003. A framework for integrat-
ing deep and shallow semantic structures in text mining. In Proceedings of the Seventh International
Conference on Knowledge-based Intelligent Information and Engineering Systems. Springer-Verlag.
V. Hatzivassiloglou and K.R. McKeown. 2002. Predicting the semantic orientation of adjectives. In Pro-
ceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Con-
ference of the European Chapter of the ACL.
V. Hatzivassiloglou and J. Wiebe. 2000. Effects of adjective orientation and gradability on sentence subjec-
tivity.
Jaap Kamps, Maarten Marx, Robert J. Mokken, and Marten de Rijke. 2002. Words with attitude. In In
Proceedings of the 1st International Conference on Global WordNet, Mysore, India.
Frank Keller and Mirella Lapata. 2003. Using the web to obtain freqeuncies for unseen bigrams. Compu-
tational Linguistics, 29(3). Special Issue on the Web as Corpus.
Charles E. Osgood, George J. Succi, and Percy H. Tannenbaum. 1957. The Measurement of Meaning.
University of Illinois.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using
machine learning techniques. In Empirical Methods in Natural Language Processing [and Very Large
Corpora].
P. Tapanainen and T. J¨arvinen. 1997. A non-projective dependency parser. In Proceedings of the 5th Con-
ference on Applied Natural Language Processing, Washington D.C., Association of Computational Lin-
guistics.
P.D. Turney and M.L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation
from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346.
P.D. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification
of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,
Philadelphia.
Vladimir Vapnik. 1998. Statistical Learning Theory. Wiley, Chichester, GB.
J. Wiebe, T. Wilson, R. Bruce, M. Bell, and M. Martin. 2002. Learning subjective language. Technical
Report TR-02-100, University of Pittsburgh, Pittsburgh, PA.
Janyce Wiebe. 2000. Learning subjective adjectives from corpora. In Proc. 17th National Conference on
Artificial Intelligence (AAAI-2000), Austin, Texas, July.
J Wiebe. 2002. Instructions for annotating opinions in newspaper articles. Technical Report TR-02-101,
University of Pittsburgh, Pittsburgh, PA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341373">
<title confidence="0.998034">Incorporating topic information into sentiment analysis models</title>
<author confidence="0.999995">Tony Mullen</author>
<affiliation confidence="0.999745">National Institute of Informatics (NII)</affiliation>
<address confidence="0.76179">Hitotsubashi 2-1-2, Chiyoda-ku Tokyo 101-8430, Japan,</address>
<email confidence="0.987896">mullen@nii.ac.jp</email>
<author confidence="0.949826">Nigel Collier</author>
<affiliation confidence="0.999668">National Institute of Informatics (NII)</affiliation>
<address confidence="0.876617">Hitotsubashi 2-1-2, Chiyoda-ku Tokyo 101-8430, Japan,</address>
<email confidence="0.99072">collier@nii.ac.jp</email>
<abstract confidence="0.9989016">This paper reports experiments in classifying texts based upon their favorability towards the subject of the text using a feature set enriched with topic information on a small dataset of music reviews hand-annotated for topic. The results of these experiments suggest ways in which incorporating topic information into such models may yield improvement over models which do not use topic information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Conference of the ACL,</booktitle>
<location>New Brunswick, NJ.</location>
<contexts>
<context position="3686" citStr="Church and Hanks (1989)" startWordPosition="559" endWordPosition="562">refers to a real number measure of the positive or negative sentiment expressed by a word or phrase. In the present work, the approach taken by Turney (2002) is used to derive such values for selected phrases in the text. For the purposes of this paper, these phrases will be referred to as value phrases, since they will be the sources of SO values. Once the desired value phrases have been extracted from the text, each one is assigned an SO value. The SO of a phrase is determined based upon the phrase’s pointwise mutual information (PMI) with the words “excellent” and “poor”. PMI is defined by Church and Hanks (1989) as follows: (1) where is the probability that and co-occur. The SO for a is the difference between its PMI with the word “excellent” and its PMI with the word “poor.” The method used to derive these values takes advantage of the possibility of using the World Wide Web as a corpus, similarly to work such as (Keller and Lapata, 2003). The probabilities are estimated by querying the AltaVista Advanced Search engine&apos; for counts. The search engine’s “NEAR” operator, representing occurrences of the two queried words within ten words of each other in a text, is used to define co-occurrence. The fina</context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>K.W. Church and P. Hanks. 1989. Word association norms, mutual information and lexicography. In Proceedings of the 27th Annual Conference of the ACL, New Brunswick, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Collier</author>
<author>K Takeuchi</author>
<author>A Kawazoe</author>
<author>T Mullen</author>
<author>T Wattarujeekrit</author>
</authors>
<title>A framework for integrating deep and shallow semantic structures in text mining.</title>
<date>2003</date>
<booktitle>In Proceedings of the Seventh International Conference on Knowledge-based Intelligent Information and Engineering Systems.</booktitle>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="6374" citStr="Collier et al., 2003" startWordPosition="998" endWordPosition="1001">features In some application domains, it is known in advance what the topic is toward which sentiment is to be evaluated. Incorporating this information is done by creating several classes of features based upon the semantic orientation values of phrases given their position in relation to the topic of the text. The approach allows secondary information to be incorporated where available, in this case, the primary information is the specific record being reviewed and the secondary information identified is the artist. Texts were annotated by hand using the Open Ontology Forge annotation tool (Collier et al., 2003). In each record review, references (including co-reference) to the record being reviewed were tagged as THIS WORK and references to the artist under review were tagged as THIS ARTIST. With these entities tagged, a number of classes of features may be extracted, representing various relationships between topic entities and value phrases similar to those described in section 3.1. The classes looked at in this work are as follows: Turney Value The average value of all value phrases’ SO values for the text. Classification by this feature alone is not the equivalent of Turney’s approach, since the</context>
</contexts>
<marker>Collier, Takeuchi, Kawazoe, Mullen, Wattarujeekrit, 2003</marker>
<rawString>N. Collier, K. Takeuchi, A. Kawazoe, T. Mullen, and T. Wattarujeekrit. 2003. A framework for integrating deep and shallow semantic structures in text mining. In Proceedings of the Seventh International Conference on Knowledge-based Intelligent Information and Engineering Systems. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>2002</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the ACL.</booktitle>
<contexts>
<context position="2243" citStr="Hatzivassiloglou and McKeown, 2002" startWordPosition="322" endWordPosition="325">of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse domains, create challenges for these approaches. It is hoped that incorporating topic informati</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 2002</marker>
<rawString>V. Hatzivassiloglou and K.R. McKeown. 2002. Predicting the semantic orientation of adjectives. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>J Wiebe</author>
</authors>
<title>Effects of adjective orientation and gradability on sentence subjectivity.</title>
<date>2000</date>
<contexts>
<context position="2207" citStr="Hatzivassiloglou and Wiebe, 2000" startWordPosition="318" endWordPosition="321">ool for classification of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse domains, create challenges for these approaches. It is hope</context>
</contexts>
<marker>Hatzivassiloglou, Wiebe, 2000</marker>
<rawString>V. Hatzivassiloglou and J. Wiebe. 2000. Effects of adjective orientation and gradability on sentence subjectivity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert J Mokken</author>
<author>Marten de Rijke</author>
</authors>
<title>Words with attitude. In</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st International Conference on Global WordNet, Mysore,</booktitle>
<marker>Kamps, Marx, Mokken, de Rijke, 2002</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert J. Mokken, and Marten de Rijke. 2002. Words with attitude. In In Proceedings of the 1st International Conference on Global WordNet, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
<author>Mirella Lapata</author>
</authors>
<title>Using the web to obtain freqeuncies for unseen bigrams.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<note>Special Issue on the Web as Corpus.</note>
<contexts>
<context position="4020" citStr="Keller and Lapata, 2003" startWordPosition="620" endWordPosition="623">ces of SO values. Once the desired value phrases have been extracted from the text, each one is assigned an SO value. The SO of a phrase is determined based upon the phrase’s pointwise mutual information (PMI) with the words “excellent” and “poor”. PMI is defined by Church and Hanks (1989) as follows: (1) where is the probability that and co-occur. The SO for a is the difference between its PMI with the word “excellent” and its PMI with the word “poor.” The method used to derive these values takes advantage of the possibility of using the World Wide Web as a corpus, similarly to work such as (Keller and Lapata, 2003). The probabilities are estimated by querying the AltaVista Advanced Search engine&apos; for counts. The search engine’s “NEAR” operator, representing occurrences of the two queried words within ten words of each other in a text, is used to define co-occurrence. The final SO equation is Intuitively, this yields values above zero for phrases with greater PMI with the word “excellent” and below zero for greater PMI with “poor”. A SO value of zero would indicate a completely neutral semantic orientation. 3.2 Osgood semantic differentiation with WordNet Further feature types are derived using the metho</context>
</contexts>
<marker>Keller, Lapata, 2003</marker>
<rawString>Frank Keller and Mirella Lapata. 2003. Using the web to obtain freqeuncies for unseen bigrams. Computational Linguistics, 29(3). Special Issue on the Web as Corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles E Osgood</author>
<author>George J Succi</author>
<author>Percy H Tannenbaum</author>
</authors>
<title>The Measurement of Meaning.</title>
<date>1957</date>
<institution>University of Illinois.</institution>
<contexts>
<context position="4967" citStr="Osgood et al., 1957" startWordPosition="767" endWordPosition="770">or phrases with greater PMI with the word “excellent” and below zero for greater PMI with “poor”. A SO value of zero would indicate a completely neutral semantic orientation. 3.2 Osgood semantic differentiation with WordNet Further feature types are derived using the method of Kamps and Marx (2002) of using WordNet relationships to derive three values pertinent to the emotive meaning of adjectives. The three values correspond to the potency (strong or weak), activity (active or passive) and the evaluative (good or bad) factors introduced in Charles Osgood’s Theory of Semantic Differentiation (Osgood et al., 1957). These values are derived by measuring the relative minimal path length (MPL) in WordNet between the adjective in question and the pair of words appropriate for the given factor. In the case of the evaluative factor (EVA) for example, the comparison is between the MPL between the adjective and “good” and the MPL between the adjective and “bad”. Only adjectives connected by synonymy to each of the opposites are considered. The method results in a list of 5410 adjectives, each of which is given a value for each of the three factors referred to as EVA, POT, and ACT. Each of these factors’ values</context>
</contexts>
<marker>Osgood, Succi, Tannenbaum, 1957</marker>
<rawString>Charles E. Osgood, George J. Succi, and Percy H. Tannenbaum. 1957. The Measurement of Meaning. University of Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Empirical Methods in Natural Language Processing [and Very Large Corpora].</booktitle>
<contexts>
<context position="1181" citStr="Pang et al., 2002" startWordPosition="160" endWordPosition="163"> these experiments suggest ways in which incorporating topic information into such models may yield improvement over models which do not use topic information. 1 Introduction There are a number of challenging aspects in recognizing the favorability of opinion-based texts, the task known as sentiment analysis. Opinions in natural language are very often expressed in subtle and complex ways, presenting challenges which may not be easily addressed by simple text categorization approaches such as n-gram or keyword identification approaches. Although such approaches have been employed effectively (Pang et al., 2002), there appears to remain considerable room for improvement. Moving beyond these approaches can involve addressing the task at several levels. Negative reviews may contain many apparently positive phrases even while maintaining a strongly negative tone, and the opposite is also common. This paper attempts to address this issue using Support Vector Machines (SVMs), a well-known and powerful tool for classification of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features base</context>
<context position="2412" citStr="Pang et al. (2002)" startWordPosition="351" endWordPosition="354">oximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse domains, create challenges for these approaches. It is hoped that incorporating topic information along the lines suggested in this paper will be a step towards solving some of these problems. 3 Methods 3.1 Semantic orientation with PMI Here, the term semantic ori</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Empirical Methods in Natural Language Processing [and Very Large Corpora].</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>T J¨arvinen</author>
</authors>
<title>A non-projective dependency parser.</title>
<date>1997</date>
<journal>D.C., Association of Computational Linguistics.</journal>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing,</booktitle>
<location>Washington</location>
<marker>Tapanainen, J¨arvinen, 1997</marker>
<rawString>P. Tapanainen and T. J¨arvinen. 1997. A non-projective dependency parser. In Proceedings of the 5th Conference on Applied Natural Language Processing, Washington D.C., Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
<author>M L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="2139" citStr="Turney and Littman, 2003" startWordPosition="308" endWordPosition="311"> Support Vector Machines (SVMs), a well-known and powerful tool for classification of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many d</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>P.D. Turney and M.L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="2153" citStr="Turney, 2002" startWordPosition="312" endWordPosition="313">SVMs), a well-known and powerful tool for classification of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse domai</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P.D. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley,</publisher>
<location>Chichester, GB.</location>
<contexts>
<context position="1647" citStr="Vapnik, 1998" startWordPosition="230" endWordPosition="231">ization approaches such as n-gram or keyword identification approaches. Although such approaches have been employed effectively (Pang et al., 2002), there appears to remain considerable room for improvement. Moving beyond these approaches can involve addressing the task at several levels. Negative reviews may contain many apparently positive phrases even while maintaining a strongly negative tone, and the opposite is also common. This paper attempts to address this issue using Support Vector Machines (SVMs), a well-known and powerful tool for classification of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wi</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir Vapnik. 1998. Statistical Learning Theory. Wiley, Chichester, GB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>R Bruce</author>
<author>M Bell</author>
<author>M Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2002</date>
<tech>Technical Report TR-02-100,</tech>
<institution>University of Pittsburgh,</institution>
<location>Pittsburgh, PA.</location>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2002</marker>
<rawString>J. Wiebe, T. Wilson, R. Bruce, M. Bell, and M. Martin. 2002. Learning subjective language. Technical Report TR-02-100, University of Pittsburgh, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Learning subjective adjectives from corpora.</title>
<date>2000</date>
<booktitle>In Proc. 17th National Conference on Artificial Intelligence (AAAI-2000),</booktitle>
<location>Austin, Texas,</location>
<contexts>
<context position="2207" citStr="Wiebe, 2000" startWordPosition="320" endWordPosition="321">n of vectors of real-valued features (Vapnik, 1998). The present approach emphasizes the use of a variety of diverse information sources. In particular, several classes of features based upon the proximity of the topic with phrases which have been assigned favorability values are described in order to take advantage of situations in which the topic of the text may be explicitly identified. 2 Motivation In the past, work has been done in the area of characterizing words and phrases according to their emotive tone (Turney and Littman, 2003; Turney, 2002; Kamps et al., 2002; Hatzivassiloglou and Wiebe, 2000; Hatzivassiloglou and McKeown, 2002; Wiebe, 2000), but in many domains of text, the values of individual phrases may bear little relation to the overall sentiment expressed by the text. Pang et al. (2002)’s treatment of the task as analogous to topic-classification underscores the difference between the two tasks. A number of rhetorical devices, such as the drawing of contrasts between the reviewed entity and other entities or expectations, sarcasm, understatement, and digressions, all of which are used in abundance in many discourse domains, create challenges for these approaches. It is hope</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Janyce Wiebe. 2000. Learning subjective adjectives from corpora. In Proc. 17th National Conference on Artificial Intelligence (AAAI-2000), Austin, Texas, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
</authors>
<title>Instructions for annotating opinions in newspaper articles.</title>
<date>2002</date>
<tech>Technical Report TR-02-101,</tech>
<institution>University of Pittsburgh,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="12753" citStr="Wiebe, 2002" startWordPosition="2033" endWordPosition="2034"> works better than, for example “good” and “bad,” it is not entirely clear. Again, cursory investigations have thus far supported Turney’s conclusion that the former are the appropriate terms to use for this task. It also seems likely that the topic-relations aspect of the present research only scratches the surface of what should be possible. Although performance in the mid-80s is not bad, there is still considerable room for improvement. The present models may also be further expanded with features representing other information sources, which may include other types of semantic annotation (Wiebe, 2002; Wiebe et al., 2002), or features based on more sophisticated grammatical or dependency relations, or perhaps upon such things as zoning (e.g. do opinions become more clearly stated towards the end of a text?). In any case, it is hoped that the present work may help to indicate how various information sources pertinent to the task may be brought together. 6 Conclusion Further investigation using larger datasets is necessary for the purposes of fully exploiting topic information where it is available, but the present results suggest that this is a worthwhile direction to investigate. Reference</context>
</contexts>
<marker>Wiebe, 2002</marker>
<rawString>J Wiebe. 2002. Instructions for annotating opinions in newspaper articles. Technical Report TR-02-101, University of Pittsburgh, Pittsburgh, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>