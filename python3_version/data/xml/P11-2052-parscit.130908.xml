<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.104311">
<title confidence="0.989686">
Scaling up Automatic Cross-Lingual Semantic Role Annotation
</title>
<author confidence="0.949926">
Lonneke van der Plas Paola Merlo James Henderson
</author>
<affiliation confidence="0.983421">
Department of Linguistics Department of Linguistics Department of Computer Science
University of Geneva University of Geneva University of Geneva
Geneva, Switzerland Geneva, Switzerland Geneva, Switzerland
</affiliation>
<email confidence="0.996971">
{Lonneke.vanderPlas,Paola.Merlo,James.Henderson}@unige.ch
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999283526315789">
Broad-coverage semantic annotations for
training statistical learners are only available
for a handful of languages. Previous ap-
proaches to cross-lingual transfer of seman-
tic annotations have addressed this problem
with encouraging results on a small scale. In
this paper, we scale up previous efforts by us-
ing an automatic approach to semantic anno-
tation that does not rely on a semantic on-
tology for the target language. Moreover,
we improve the quality of the transferred se-
mantic annotations by using a joint syntactic-
semantic parser that learns the correlations be-
tween syntax and semantics of the target lan-
guage and smooths out the errors from auto-
matic transfer. We reach a labelled F-measure
for predicates and arguments of only 4% and
9% points, respectively, lower than the upper
bound from manual annotations.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999937063829787">
As data-driven techniques tackle more and more
complex natural language processing tasks, it be-
comes increasingly unfeasible to use complete, ac-
curate, hand-annotated data on a large scale for
training models in all languages. One approach to
addressing this problem is to develop methods that
automatically generate annotated data by transfer-
ring annotations in parallel corpora from languages
for which this information is available to languages
for which these data are not available (Yarowsky et
al., 2001; Fung et al., 2007; Pad´o and Lapata, 2009).
Previous work on the cross-lingual transfer of se-
mantic annotations (Pad´o, 2007; Basili et al., 2009)
has produced annotations of good quality for test
sets that were carefully selected based on seman-
tic ontologies on the source and target side. It has
been suggested that these annotations could be used
to train semantic role labellers (Basili et al., 2009).
In this paper, we generate high-quality broad-
coverage semantic annotations using an automatic
approach that does not rely on a semantic ontol-
ogy for the target language. Furthermore, to our
knowledge, we report the first results on using joint
syntactic-semantic learning to improve the quality
of the semantic annotations from automatic cross-
lingual transfer. Results on correlations between
syntax and semantics found in previous work (Merlo
and van der Plas, 2009; Lang and Lapata, 2010) have
led us to make use of the available syntactic anno-
tations on the target language. We use the seman-
tic annotations resulting from cross-lingual transfer
combined with syntactic annotations to train a joint
syntactic-semantic parser for the target language,
which, in turn, re-annotates the corpus (See Fig-
ure 1). We show that the semantic annotations pro-
duced by this parser are of higher quality than the
data on which it was trained.
Given our goal of producing broad-coverage an-
notations in a setting based on an aligned corpus,
our choices of formal representation and of labelling
scheme differ from previous work (Pad´o, 2007;
Basili et al., 2009). We choose a dependency repre-
sentation both for the syntax and semantics because
relations are expressed as direct arcs between words.
This representation allows cross-lingual transfer to
use word-based alignments directly, eschewing the
need for complex constituent-alignment algorithms.
</bodyText>
<page confidence="0.987344">
299
</page>
<note confidence="0.8928865">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 299–304,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999948">
Figure 1: System overview
</figureCaption>
<bodyText confidence="0.999970555555556">
We choose the semantic annotation scheme defined
by Propbank, because it has broad coverage and in-
cludes an annotated corpus, contrary to other avail-
able resources such as FrameNet (Fillmore et al.,
2003) and is the preferred annotation scheme for a
joint syntactic-semantic setting (Merlo and van der
Plas, 2009). Furthermore, Monachesi et al. (2007)
showed that the PropBank annotation scheme can be
used for languages other than English directly.
</bodyText>
<sectionHeader confidence="0.893884" genericHeader="method">
2 Cross-lingual semantic transfer
</sectionHeader>
<bodyText confidence="0.999515230769231">
Data-driven induction of semantic annotation based
on parallel corpora is a well-defined and feasible
task, and it has been argued to be particularly suit-
able to semantic role label annotation because cross-
lingual parallelism improves as one moves to more
abstract linguistic levels of representation. While
Hwa et al. (2002; 2005) find that direct syntactic de-
pendency parallelism between English and Spanish
concerns 37% of dependency links, Pad´o (2007) re-
ports an upper-bound mapping correspondence cal-
culated on gold data of 88% F-measure for in-
dividual semantic roles, and 69% F-measure for
whole scenario-like semantic frames. Recently, Wu
and Fung (2009a; 2009b) also show that semantic
roles help in statistical machine translation, capi-
talising on a study of the correspondence between
English and Chinese which indicates that 84% of
roles transfer directly, for PropBank-style annota-
tions. These results indicate high correspondence
across languages at a shallow semantic level.
Based on these results, our transfer of semantic
annotations from English sentences to their French
translations is based on a very strong mapping hy-
pothesis, adapted from the Direct Correspondence
Assumption for syntactic dependency trees by Hwa
et al. (2005).
</bodyText>
<subsectionHeader confidence="0.465792">
Direct Semantic Transfer (DST) For any
</subsectionHeader>
<bodyText confidence="0.999919074074074">
pair of sentences E and F that are transla-
tions of each other, we transfer the seman-
tic relationship R(xE, YE) to R(xF, YF) if
and only if there exists a word-alignment
between xE and xF and between YE and
YF, and we transfer the semantic property
P(xE) to P(xF) if and only if there exists
a word-alignment between xE and xF.
The relationships which we transfer are semantic
role dependencies and the properties are predicate
senses. We introduce one constraint to the direct se-
mantic transfer. Because the semantic annotations in
the target language are limited to verbal predicates,
we only transfer predicates to words the syntactic
parser has tagged as a verb.
As reported by Hwa et al. (2005), the direct cor-
respondence assumption is a strong hypothesis that
is useful to trigger a projection process, but will not
work correctly for several cases.
We used a filter to remove obviously incomplete
annotations. We know from the annotation guide-
lines used to annotate the French gold sentences that
all verbs, except modals and realisations of the verb
ˆetre, should receive a predicate label. We define a
filter that removes sentences with missing predicate
labels based on PoS-information in the French sen-
tence.
</bodyText>
<subsectionHeader confidence="0.9972705">
2.1 Learning joint syntactic-semantic
structures
</subsectionHeader>
<bodyText confidence="0.999991846153846">
We know from previous work that there is a strong
correlation between syntax and semantics (Merlo
and van der Plas, 2009), and that this correla-
tion has been successfully applied for the unsuper-
vised induction of semantic roles (Lang and Lap-
ata, 2010). However, previous work in machine
translation leads us to believe that transferring the
correlations between syntax and semantics across
languages would be problematic due to argument-
structure divergences (Dorr, 1994). For example,
the English verb like and the French verb plaire do
not share correlations between syntax and seman-
tics. The verb like takes an A0 subject and an A1
</bodyText>
<figure confidence="0.994071696969697">
Train a French
syntactic
parser
FR
syntactic
annotations
EN
syntactic-
semantic
annotations
EN-FR
word-
aligned
data
Transfer semantic
annotations
from EN to FR
using word
alignments
FR
semantic
annotations
Train French
joint syntactic-
semantic parser
evaluation
FR
syntactic
annotations
FR
semantic
annotations
evaluation
</figure>
<page confidence="0.977502">
300
</page>
<bodyText confidence="0.999863066666667">
direct object, whereas the verb plaire licences an A1
subject and an A0 indirect object.
We therefore transfer semantic roles cross-
lingually based only on lexical alignments and add
syntactic information after transfer. In Figure 1, we
see that cross-lingual transfer takes place at the se-
mantic level, a level that is more abstract and known
to port relatively well across languages, while the
correlations with syntax, that are known to diverge
cross-lingually, are learnt on the target language
only. We train a joint syntactic-semantic parser
on the combination of the two linguistic levels that
learns the correlations between these structures in
the target language and is able to smooth out errors
from automatic transfer.
</bodyText>
<sectionHeader confidence="0.999696" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9998328">
We used two statistical parsers in our transfer of
semantic annotations from English to French, one
for syntactic parsing and one for joint syntactic-
semantic parsing. In addition, we used several cor-
pora.
</bodyText>
<subsectionHeader confidence="0.999607">
3.1 The statistical parsers
</subsectionHeader>
<bodyText confidence="0.999959769230769">
For our syntactic-semantic parsing model, we use
a freely-available parser (Henderson et al., 2008;
Titov et al., 2009). The probabilistic model is a joint
generative model of syntactic and semantic depen-
dencies that maximises the joint probability of the
syntactic and semantic dependencies, while building
two separate structures.
For the French syntactic parser, we used the de-
pendency parser described in Titov and Hender-
son (2007). We train the parser on the dependency
version of the French Paris treebank (Candito et al.,
2009), achieving 87.2% labelled accuracy on this
data set.
</bodyText>
<subsectionHeader confidence="0.997592">
3.2 Data
</subsectionHeader>
<bodyText confidence="0.988715633333334">
To transfer semantic annotation from English to
French, we used the Europarl corpus (Koehn,
2003)1. We word-align the English sentences to the
French sentences automatically using GIZA++ (Och
1As is usual practice in preprocessing for automatic align-
ment, the datasets were tokenised and lowercased and only sen-
tence pairs corresponding to a one-to-one sentence alignment
with lengths ranging from one to 40 tokens on both French and
English sides were considered.
and Ney, 2003) and include only intersective align-
ments. Furthermore, because translation shifts are
known to pose problems for the automatic projection
of semantic roles across languages (Pad´o, 2007), we
select only those parallel sentences in Europarl that
are direct translations from English to French, or
vice versa. In the end, we have a word-aligned par-
allel corpus of 276-thousand sentence pairs.
Syntactic annotation is available for French. The
French Treebank (Abeill´e et al., 2003) is a treebank
of 21,564 sentences annotated with constituency an-
notation. We use the automatic dependency conver-
sion of the French Treebank into dependency format
provided to us by Candito and Crabb´e and described
in Candito et al. (2009).
The Penn Treebank corpus (Marcus et al., 1993)
merged with PropBank labels (Palmer et al., 2005)
and NomBank labels (Meyers, 2007) is used to train
the syntactic-semantic parser described in Subsec-
tion 3.1 to annotate the English part of the parallel
corpus.
</bodyText>
<subsectionHeader confidence="0.999906">
3.3 Test sets
</subsectionHeader>
<bodyText confidence="0.999409375">
For testing, we used the hand-annotated data de-
scribed in (van der Plas et al., 2010). One-thousand
French sentences are extracted randomly from our
parallel corpus without any constraints on the se-
mantic parallelism of the sentences, unlike much
previous work. We randomly split those 1000 sen-
tences into test and development set containing 500
sentences each.
</bodyText>
<sectionHeader confidence="0.999979" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.999970583333333">
We evaluate our methods for automatic annotation
generation twice: once after the transfer step, and
once after joint syntactic-semantic learning. The
comparison of these two steps will tell us whether
the joint syntactic-semantic parser is able to improve
semantic annotations by learning from the syntactic
annotations available. We evaluate the models on
unrestricted test sets2 to determine if our methods
scale up.
Table 1 shows the results of automatically an-
notating French sentences with semantic role an-
notation. The first set of columns of results re-
</bodyText>
<footnote confidence="0.9657585">
2Due to filtering, the test set for the transfer (filter) model is
smaller and not directly comparable to the other three models.
</footnote>
<page confidence="0.993771">
301
</page>
<table confidence="0.99942025">
Predicates Unlabelled Arguments (given predicate)
Labelled Labelled Unlabelled
Prec Rec F Prec Rec F Prec Rec F Prec Rec F
1 Transfer (no filter) 50 31 38 91 55 69 61 48 54 72 57 64
2 Transfer (filter) 51 46 49 92 84 88 65 51 57 76 59 67
3 Transfer+parsing (no filter) 71 29 42 97 40 57 77 57 65 87 64 74
4 Transfer+parsing (filter) 61 50 55 95 78 85 71 52 60 83 61 70
5 Inter-annotator agreement 61 57 59 97 89 93 73 75 74 88 91 89
</table>
<tableCaption confidence="0.988657">
Table 1: Percent recall, precision, and F-measure for predicates and for arguments given the predicate, for the four
automatic annotation models and the manual annotation.
</tableCaption>
<bodyText confidence="0.999979111111111">
ports labelling and identification of predicates and
the second set of columns reports labelling and iden-
tification of arguments, respectively, for the predi-
cates that are identified. The first two rows show
the results when applying direct semantic transfer.
Rows three and four show results when using the
joint syntactic-semantic parser to re-annotate the
sentences. For both annotation models we show re-
sults when using the filter described in Section 2 and
without the filter.
The most striking result that we can read from
Table 1 is that the joint syntactic-semantic learning
step results in large improvements, especially for
argument labelling, where the F-measure increases
from 54% to 65% for the unfiltered data. The parser
is able to outperform the quality of the semantic
data on which it was trained by using the infor-
mation contained in the syntax. This result is in
accordance with results reported in Merlo and Van
der Plas (2009) and Lang and Lapata (2010), where
the authors find a high correlation between syntactic
functions and PropBank semantic roles.
Filtering improves the quality of the transferred
annotations. However, when training a parser on the
annotations we see that filtering only results in better
recall scores for predicate labelling. This is not sur-
prising given that the filters apply to completeness in
predicate labelling specifically. The improvements
from joint syntactic-semantic learning for argument
labelling are largest for the unfiltered setting, be-
cause the parser has access to larger amounts of data.
The filter removes 61% of the data.
As an upper bound we take the inter-annotator
agreement for manual annotation on a random set
of 100 sentences (van der Plas et al., 2010), given
in the last row of Table 1. The parser reaches an
F-measure on predicate labelling of 55% when us-
ing filtered data, which is very close to the up-
per bound (59%). The upper bound for argument
inter-annotator agreement is an F-measure of 74%.
The parser trained on unfiltered data reaches an
F-measure of 65%. These results on unrestricted
test sets and their comparison to manual annotation
show that we are able to scale up cross-lingual se-
mantic role annotation.
</bodyText>
<sectionHeader confidence="0.994597" genericHeader="evaluation">
5 Discussion and error analysis
</sectionHeader>
<bodyText confidence="0.99999804">
A more detailed analysis of the distribution of im-
provements over the types of roles further strength-
ens the conclusion that the parser learns the corre-
lations between syntax and semantics. It is a well-
known fact that there exists a strong correlation be-
tween syntactic function and semantic role for the
A0 and A1 arguments: A0s are commonly mapped
onto subjects and A1s are often realised as direct ob-
jects (Lang and Lapata, 2010). It is therefore not
surprising that the F-measure on these types of ar-
guments increases by 12% and 15%, respectively,
after joint-syntactic semantic learning. Since these
arguments make up 65% of the roles, this introduces
a large improvement. In addition, we find improve-
ments of more than 10% on the following adjuncts:
AM-CAU, AM-LOC, AM-MNR, and AM-MOD that to-
gether comprise 9% of the data.
With respect to predicate labelling, comparison
of the output after transfer with the output after
parsing (on the development set) shows how the
parser smooths out transfer errors and how inter-
lingual divergences can be solved by making use
of the variations we find intra-lingually. An exam-
ple is given in Figure 2. The first line shows the
predicate-argument structure given by the English
</bodyText>
<page confidence="0.99316">
302
</page>
<figure confidence="0.567256666666667">
EN (source) Postal [A1 services] [AM-MOD must] [CONTINUE.01 continue] [C-A1 to] be public services.
FR (transfer) Les [A1services] postaux [AM-MOD doivent] [CONTINUE.01rester] des services publics.
FR (parsed) Les [A1 services] postaux [AM-MOD doivent] [REMAIN.01rester] des [A3 services] publics.
</figure>
<figureCaption confidence="0.995999">
Figure 2: Differences in predicate-argument labelling after transfer and after parsing
</figureCaption>
<bodyText confidence="0.999980566037736">
syntactic-semantic parser to the English sentence.
The second line shows the French translation and
the predicate-argument structure as it is transferred
cross-lingually following the method described in
Section 2. Transfer maps the English predicate la-
bel CONTINUE.01 onto the French verb rester, be-
cause these two verbs are aligned. The first oc-
currence of services is aligned to the first occur-
rence of services in the English sentence and gets
the A1 label. The second occurrence of services
gets no argument label, because there is no align-
ment between the C-A1 argument to, the head of
the infinitival clause, and the French word services.
The third line shows the analysis resulting from the
syntactic-semantic parser that has been trained on a
corpus of French sentences labelled with automat-
ically transferred annotations and syntactic annota-
tions. The parser has access to several labelled ex-
amples of the predicate-argument structure of rester,
which in many other cases is translated with remain
and has the same predicate-argument structure as
rester. Consequently, the parser re-labels the verb
with REMAIN.01 and labels the argument with A3.
Because the languages and annotation framework
adopted in previous work are not directly compara-
ble to ours, and their methods have been evaluated
on restricted test sets, results are not strictly com-
parable. But for completeness, recall that our best
result for predicate identification is an F-measure
of 55% accompanied with an F-measure of 60%
for argument labelling. Pad´o (2007) reports a 56%
F-measure on transferring FrameNet roles, know-
ing the predicate, from an automatically parsed and
semantically annotated English corpus. Pad´o and
Pitel (2007), transferring semantic annotation to
French, report a best result of 57% F-measure for
argument labelling given the predicate. Basili et
al. (2009), in an approach based on phrase-based
machine translation to transfer FrameNet-like anno-
tation from English to Italian, report 42% recall in
identifying predicates and an aggregated 73% recall
of identifying predicates and roles given these pred-
icates. They do not report an unaggregated number
that can be compared to our 60% argument labelling.
In a recent paper, Annesi and Basili (2010) improve
the results from Basili et al. (2009) by 11% using
Hidden Markov Models to support the automatic
semantic transfer. Johansson and Nugues (2006)
trained a FrameNet-based semantic role labeller for
Swedish on annotations transferred cross-lingually
from English parallel data. They report 55% F-
measure for argument labelling given the frame on
150 translated example sentences.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999983266666667">
In this paper, we have scaled up previous efforts of
annotation by using an automatic approach to se-
mantic annotation transfer in combination with a
joint syntactic-semantic parsing architecture. We
propose a direct transfer method that requires nei-
ther manual intervention nor a semantic ontology for
the target language. This method leads to semanti-
cally annotated data of sufficient quality to train a
syntactic-semantic parser that further improves the
quality of the semantic annotation by joint learning
of syntactic-semantic structures on the target lan-
guage. The labelled F-measure of the resulting an-
notations for predicates is only 4% point lower than
the upper bound and the resulting annotations for ar-
guments only 9%.
</bodyText>
<sectionHeader confidence="0.99649" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999031">
The research leading to these results has received
funding from the EU FP7 programme (FP7/2007-
2013) under grant agreement nr 216594 (CLAS-
SIC project: www.classic-project.org), and from the
Swiss NSF under grant 122643.
</bodyText>
<sectionHeader confidence="0.997099" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.85161">
A. Abeill´e, L. Cl´ement, and F. Toussenel. 2003. Building
a treebank for French. In Treebanks: Building and
Using Parsed Corpora. Kluwer Academic Publishers.
</reference>
<page confidence="0.996933">
303
</page>
<reference confidence="0.99963319047619">
P. Annesi and R. Basili. 2010. Cross-lingual alignment
of FrameNet annotations through Hidden Markov
Models. In Proceedings of CICLing.
R. Basili, D. De Cao, D. Croce, B. Coppola, and A. Mos-
chitti, 2009. Computational Linguistics and Intelli-
gent Text Processing, chapter Cross-Language Frame
Semantics Transfer in Bilingual Corpora, pages 332–
345. Springer Berlin / Heidelberg.
M.-H. Candito, B. Crabb´e, P. Denis, and F. Gu´erin. 2009.
Analyse syntaxique du franc¸ais : des constituants
aux d´ependances. In Proceedings of la Conf´erence
sur le TraitementAutomatique des Langues Naturelles
(TALN’09), Senlis, France.
B. Dorr. 1994. Machine translation divergences: A for-
mal description and proposed solution. Computational
Linguistics, 20(4):597–633.
C. J. Fillmore, R. Johnson, and M.R.L. Petruck. 2003.
Background to FrameNet. International journal of
lexicography, 16.3:235–250.
P. Fung, Z. Wu, Y. Yang, and D. Wu. 2007. Learn-
ing bilingual semantic frames: Shallow semantic pars-
ing vs. semantic role projection. In 11th Conference
on Theoretical and Methodological Issues in Machine
Translation (TMI 2007).
J. Henderson, P. Merlo, G. Musillo, and I. Titov. 2008. A
latent variable model of synchronous parsing for syn-
tactic and semantic dependencies. In Proceedings of
CONLL 2008, pages 178–182.
R. Hwa, P. Resnik, A. Weinberg, and O. Kolak. 2002.
Evaluating translational correspondence using anno-
tation projection. In Proceedings of the 40th Annual
Meeting of the ACL.
R. Hwa, P. Resnik, A.Weinberg, C. Cabezas, and O. Ko-
lak. 2005. Bootstrapping parsers via syntactic projec-
tion accross parallel texts. Natural language engineer-
ing, 11:311–325.
R. Johansson and P. Nugues. 2006. A FrameNet-based
semantic role labeler for Swedish. In Proceedings of
the annual Meeting of the Association for Computa-
tional Linguistics (ACL).
P. Koehn. 2003. Europarl: A multilingual corpus for
evaluation of machine translation.
J. Lang and M. Lapata. 2010. Unsupervised induction
of semantic roles. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics, pages 939–947, Los Angeles, California, June.
Association for Computational Linguistics.
M. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1993. Building a large annotated corpus of English:
the Penn Treebank. Comp. Ling., 19:313–330.
P. Merlo and L. van der Plas. 2009. Abstraction and gen-
eralisation in semantic role labels: PropBank, VerbNet
or both? In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP, pages 288–296, Suntec, Singapore.
A. Meyers. 2007. Annotation guidelines for NomBank
- noun argument structure for PropBank. Technical
report, New York University.
P. Monachesi, G. Stevens, and J. Trapman. 2007. Adding
semantic role annotation to a corpus of written Dutch.
In Proceedings of the Linguistic Annotation Workshop
(LAW), pages 77–84, Prague, Czech republic.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29:19–51.
Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual
annotation projection of semantic roles. Journal ofAr-
tificial Intelligence Research, 36:307–340.
S. Pad´o and G. Pitel. 2007. Annotation pr´ecise du
franc¸ais en s´emantique de rˆoles par projection cross-
linguistique. In Proceedings of TALN.
S. Pad´o. 2007. Cross-lingual Annotation Projection
Models for Role-Semantic Information. Ph.D. thesis,
Saarland University.
M. Palmer, D. Gildea, and P. Kingsbury. 2005. The
Proposition Bank: An annotated corpus of semantic
roles. Computational Linguistics, 31:71–105.
I. Titov and J. Henderson. 2007. A latent variable model
for generative dependency parsing. In Proceedings of
the International Conference on Parsing Technologies
(IWPT-07), pages 144–155, Prague, Czech Republic.
I. Titov, J. Henderson, P. Merlo, and G. Musillo. 2009.
Online graph planarisation for synchronous parsing of
semantic and syntactic dependencies. In Proceedings
of the twenty-first international joint conference on ar-
tificial intelligence (IJCAI-09), Pasadena, California,
July.
L. van der Plas, T. Samard˘zi´c, and P. Merlo. 2010. Cross-
lingual validity of PropBank in the manual annotation
of French. In In Proceedings of the 4th Linguistic An-
notation Workshop (The LAW IV), Uppsala, Sweden.
D. Wu and P. Fung. 2009a. Can semantic role labeling
improve SMT? In Proceedings of the Annual Confer-
ence of European Association of Machine Translation.
D. Wu and P. Fung. 2009b. Semantic roles for SMT:
A hybrid two-pass model. In Proceedings of the
Joint Conference of the North American Chapter of
ACL/Human Language Technology.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings of the
International Conference on Human Language Tech-
nology (HLT).
</reference>
<page confidence="0.999313">
304
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966483">
<title confidence="0.999835">Scaling up Automatic Cross-Lingual Semantic Role Annotation</title>
<author confidence="0.999792">Lonneke van_der_Plas Paola Merlo James Henderson</author>
<affiliation confidence="0.9999675">Department of Linguistics Department of Linguistics Department of Computer Science University of Geneva University of Geneva University of Geneva</affiliation>
<address confidence="0.995195">Geneva, Switzerland Geneva, Switzerland Geneva, Switzerland</address>
<abstract confidence="0.9980225">Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeill´e</author>
<author>L Cl´ement</author>
<author>F Toussenel</author>
</authors>
<title>Building a treebank for French. In Treebanks: Building and Using Parsed Corpora.</title>
<date>2003</date>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>A. Abeill´e, L. Cl´ement, and F. Toussenel. 2003. Building a treebank for French. In Treebanks: Building and Using Parsed Corpora. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Annesi</author>
<author>R Basili</author>
</authors>
<title>Cross-lingual alignment of FrameNet annotations through Hidden Markov Models.</title>
<date>2010</date>
<booktitle>In Proceedings of CICLing.</booktitle>
<contexts>
<context position="18623" citStr="Annesi and Basili (2010)" startWordPosition="2922" endWordPosition="2925">utomatically parsed and semantically annotated English corpus. Pad´o and Pitel (2007), transferring semantic annotation to French, report a best result of 57% F-measure for argument labelling given the predicate. Basili et al. (2009), in an approach based on phrase-based machine translation to transfer FrameNet-like annotation from English to Italian, report 42% recall in identifying predicates and an aggregated 73% recall of identifying predicates and roles given these predicates. They do not report an unaggregated number that can be compared to our 60% argument labelling. In a recent paper, Annesi and Basili (2010) improve the results from Basili et al. (2009) by 11% using Hidden Markov Models to support the automatic semantic transfer. Johansson and Nugues (2006) trained a FrameNet-based semantic role labeller for Swedish on annotations transferred cross-lingually from English parallel data. They report 55% Fmeasure for argument labelling given the frame on 150 translated example sentences. 6 Conclusions In this paper, we have scaled up previous efforts of annotation by using an automatic approach to semantic annotation transfer in combination with a joint syntactic-semantic parsing architecture. We pr</context>
</contexts>
<marker>Annesi, Basili, 2010</marker>
<rawString>P. Annesi and R. Basili. 2010. Cross-lingual alignment of FrameNet annotations through Hidden Markov Models. In Proceedings of CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>D De Cao</author>
<author>D Croce</author>
<author>B Coppola</author>
<author>A Moschitti</author>
</authors>
<date>2009</date>
<booktitle>Computational Linguistics and Intelligent Text Processing, chapter Cross-Language Frame Semantics Transfer in Bilingual Corpora,</booktitle>
<pages>332--345</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<marker>Basili, De Cao, Croce, Coppola, Moschitti, 2009</marker>
<rawString>R. Basili, D. De Cao, D. Croce, B. Coppola, and A. Moschitti, 2009. Computational Linguistics and Intelligent Text Processing, chapter Cross-Language Frame Semantics Transfer in Bilingual Corpora, pages 332– 345. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-H Candito</author>
<author>B Crabb´e</author>
<author>P Denis</author>
<author>F Gu´erin</author>
</authors>
<title>Analyse syntaxique du franc¸ais : des constituants aux d´ependances.</title>
<date>2009</date>
<booktitle>In Proceedings of la Conf´erence sur le TraitementAutomatique des Langues Naturelles (TALN’09),</booktitle>
<location>Senlis, France.</location>
<marker>Candito, Crabb´e, Denis, Gu´erin, 2009</marker>
<rawString>M.-H. Candito, B. Crabb´e, P. Denis, and F. Gu´erin. 2009. Analyse syntaxique du franc¸ais : des constituants aux d´ependances. In Proceedings of la Conf´erence sur le TraitementAutomatique des Langues Naturelles (TALN’09), Senlis, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
</authors>
<title>Machine translation divergences: A formal description and proposed solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="7318" citStr="Dorr, 1994" startWordPosition="1118" endWordPosition="1119">es sentences with missing predicate labels based on PoS-information in the French sentence. 2.1 Learning joint syntactic-semantic structures We know from previous work that there is a strong correlation between syntax and semantics (Merlo and van der Plas, 2009), and that this correlation has been successfully applied for the unsupervised induction of semantic roles (Lang and Lapata, 2010). However, previous work in machine translation leads us to believe that transferring the correlations between syntax and semantics across languages would be problematic due to argumentstructure divergences (Dorr, 1994). For example, the English verb like and the French verb plaire do not share correlations between syntax and semantics. The verb like takes an A0 subject and an A1 Train a French syntactic parser FR syntactic annotations EN syntacticsemantic annotations EN-FR wordaligned data Transfer semantic annotations from EN to FR using word alignments FR semantic annotations Train French joint syntacticsemantic parser evaluation FR syntactic annotations FR semantic annotations evaluation 300 direct object, whereas the verb plaire licences an A1 subject and an A0 indirect object. We therefore transfer sem</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>B. Dorr. 1994. Machine translation divergences: A formal description and proposed solution. Computational Linguistics, 20(4):597–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>R Johnson</author>
<author>M R L Petruck</author>
</authors>
<title>Background to FrameNet. International journal of lexicography,</title>
<date>2003</date>
<pages>16--3</pages>
<contexts>
<context position="4009" citStr="Fillmore et al., 2003" startWordPosition="599" endWordPosition="602">ed as direct arcs between words. This representation allows cross-lingual transfer to use word-based alignments directly, eschewing the need for complex constituent-alignment algorithms. 299 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 299–304, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: System overview We choose the semantic annotation scheme defined by Propbank, because it has broad coverage and includes an annotated corpus, contrary to other available resources such as FrameNet (Fillmore et al., 2003) and is the preferred annotation scheme for a joint syntactic-semantic setting (Merlo and van der Plas, 2009). Furthermore, Monachesi et al. (2007) showed that the PropBank annotation scheme can be used for languages other than English directly. 2 Cross-lingual semantic transfer Data-driven induction of semantic annotation based on parallel corpora is a well-defined and feasible task, and it has been argued to be particularly suitable to semantic role label annotation because crosslingual parallelism improves as one moves to more abstract linguistic levels of representation. While Hwa et al. (</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>C. J. Fillmore, R. Johnson, and M.R.L. Petruck. 2003. Background to FrameNet. International journal of lexicography, 16.3:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>Z Wu</author>
<author>Y Yang</author>
<author>D Wu</author>
</authors>
<title>Learning bilingual semantic frames: Shallow semantic parsing vs. semantic role projection.</title>
<date>2007</date>
<booktitle>In 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI</booktitle>
<contexts>
<context position="1747" citStr="Fung et al., 2007" startWordPosition="253" endWordPosition="256">points, respectively, lower than the upper bound from manual annotations. 1 Introduction As data-driven techniques tackle more and more complex natural language processing tasks, it becomes increasingly unfeasible to use complete, accurate, hand-annotated data on a large scale for training models in all languages. One approach to addressing this problem is to develop methods that automatically generate annotated data by transferring annotations in parallel corpora from languages for which this information is available to languages for which these data are not available (Yarowsky et al., 2001; Fung et al., 2007; Pad´o and Lapata, 2009). Previous work on the cross-lingual transfer of semantic annotations (Pad´o, 2007; Basili et al., 2009) has produced annotations of good quality for test sets that were carefully selected based on semantic ontologies on the source and target side. It has been suggested that these annotations could be used to train semantic role labellers (Basili et al., 2009). In this paper, we generate high-quality broadcoverage semantic annotations using an automatic approach that does not rely on a semantic ontology for the target language. Furthermore, to our knowledge, we report </context>
</contexts>
<marker>Fung, Wu, Yang, Wu, 2007</marker>
<rawString>P. Fung, Z. Wu, Y. Yang, and D. Wu. 2007. Learning bilingual semantic frames: Shallow semantic parsing vs. semantic role projection. In 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Henderson</author>
<author>P Merlo</author>
<author>G Musillo</author>
<author>I Titov</author>
</authors>
<title>A latent variable model of synchronous parsing for syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of CONLL</booktitle>
<pages>178--182</pages>
<contexts>
<context position="8879" citStr="Henderson et al., 2008" startWordPosition="1358" endWordPosition="1361">lingually, are learnt on the target language only. We train a joint syntactic-semantic parser on the combination of the two linguistic levels that learns the correlations between these structures in the target language and is able to smooth out errors from automatic transfer. 3 Experiments We used two statistical parsers in our transfer of semantic annotations from English to French, one for syntactic parsing and one for joint syntacticsemantic parsing. In addition, we used several corpora. 3.1 The statistical parsers For our syntactic-semantic parsing model, we use a freely-available parser (Henderson et al., 2008; Titov et al., 2009). The probabilistic model is a joint generative model of syntactic and semantic dependencies that maximises the joint probability of the syntactic and semantic dependencies, while building two separate structures. For the French syntactic parser, we used the dependency parser described in Titov and Henderson (2007). We train the parser on the dependency version of the French Paris treebank (Candito et al., 2009), achieving 87.2% labelled accuracy on this data set. 3.2 Data To transfer semantic annotation from English to French, we used the Europarl corpus (Koehn, 2003)1. W</context>
</contexts>
<marker>Henderson, Merlo, Musillo, Titov, 2008</marker>
<rawString>J. Henderson, P. Merlo, G. Musillo, and I. Titov. 2008. A latent variable model of synchronous parsing for syntactic and semantic dependencies. In Proceedings of CONLL 2008, pages 178–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>O Kolak</author>
</authors>
<title>Evaluating translational correspondence using annotation projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="4613" citStr="Hwa et al. (2002" startWordPosition="690" endWordPosition="693">t al., 2003) and is the preferred annotation scheme for a joint syntactic-semantic setting (Merlo and van der Plas, 2009). Furthermore, Monachesi et al. (2007) showed that the PropBank annotation scheme can be used for languages other than English directly. 2 Cross-lingual semantic transfer Data-driven induction of semantic annotation based on parallel corpora is a well-defined and feasible task, and it has been argued to be particularly suitable to semantic role label annotation because crosslingual parallelism improves as one moves to more abstract linguistic levels of representation. While Hwa et al. (2002; 2005) find that direct syntactic dependency parallelism between English and Spanish concerns 37% of dependency links, Pad´o (2007) reports an upper-bound mapping correspondence calculated on gold data of 88% F-measure for individual semantic roles, and 69% F-measure for whole scenario-like semantic frames. Recently, Wu and Fung (2009a; 2009b) also show that semantic roles help in statistical machine translation, capitalising on a study of the correspondence between English and Chinese which indicates that 84% of roles transfer directly, for PropBank-style annotations. These results indicate </context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2002</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, and O. Kolak. 2002. Evaluating translational correspondence using annotation projection. In Proceedings of the 40th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>C Cabezas A Weinberg</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection accross parallel texts. Natural language engineering,</title>
<date>2005</date>
<pages>11--311</pages>
<contexts>
<context position="5539" citStr="Hwa et al. (2005)" startWordPosition="828" endWordPosition="831"> Recently, Wu and Fung (2009a; 2009b) also show that semantic roles help in statistical machine translation, capitalising on a study of the correspondence between English and Chinese which indicates that 84% of roles transfer directly, for PropBank-style annotations. These results indicate high correspondence across languages at a shallow semantic level. Based on these results, our transfer of semantic annotations from English sentences to their French translations is based on a very strong mapping hypothesis, adapted from the Direct Correspondence Assumption for syntactic dependency trees by Hwa et al. (2005). Direct Semantic Transfer (DST) For any pair of sentences E and F that are translations of each other, we transfer the semantic relationship R(xE, YE) to R(xF, YF) if and only if there exists a word-alignment between xE and xF and between YE and YF, and we transfer the semantic property P(xE) to P(xF) if and only if there exists a word-alignment between xE and xF. The relationships which we transfer are semantic role dependencies and the properties are predicate senses. We introduce one constraint to the direct semantic transfer. Because the semantic annotations in the target language are lim</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A.Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection accross parallel texts. Natural language engineering, 11:311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johansson</author>
<author>P Nugues</author>
</authors>
<title>A FrameNet-based semantic role labeler for Swedish.</title>
<date>2006</date>
<booktitle>In Proceedings of the annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18775" citStr="Johansson and Nugues (2006)" startWordPosition="2946" endWordPosition="2949">lt of 57% F-measure for argument labelling given the predicate. Basili et al. (2009), in an approach based on phrase-based machine translation to transfer FrameNet-like annotation from English to Italian, report 42% recall in identifying predicates and an aggregated 73% recall of identifying predicates and roles given these predicates. They do not report an unaggregated number that can be compared to our 60% argument labelling. In a recent paper, Annesi and Basili (2010) improve the results from Basili et al. (2009) by 11% using Hidden Markov Models to support the automatic semantic transfer. Johansson and Nugues (2006) trained a FrameNet-based semantic role labeller for Swedish on annotations transferred cross-lingually from English parallel data. They report 55% Fmeasure for argument labelling given the frame on 150 translated example sentences. 6 Conclusions In this paper, we have scaled up previous efforts of annotation by using an automatic approach to semantic annotation transfer in combination with a joint syntactic-semantic parsing architecture. We propose a direct transfer method that requires neither manual intervention nor a semantic ontology for the target language. This method leads to semantica</context>
</contexts>
<marker>Johansson, Nugues, 2006</marker>
<rawString>R. Johansson and P. Nugues. 2006. A FrameNet-based semantic role labeler for Swedish. In Proceedings of the annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A multilingual corpus for evaluation of machine translation.</title>
<date>2003</date>
<contexts>
<context position="9475" citStr="Koehn, 2003" startWordPosition="1454" endWordPosition="1455">son et al., 2008; Titov et al., 2009). The probabilistic model is a joint generative model of syntactic and semantic dependencies that maximises the joint probability of the syntactic and semantic dependencies, while building two separate structures. For the French syntactic parser, we used the dependency parser described in Titov and Henderson (2007). We train the parser on the dependency version of the French Paris treebank (Candito et al., 2009), achieving 87.2% labelled accuracy on this data set. 3.2 Data To transfer semantic annotation from English to French, we used the Europarl corpus (Koehn, 2003)1. We word-align the English sentences to the French sentences automatically using GIZA++ (Och 1As is usual practice in preprocessing for automatic alignment, the datasets were tokenised and lowercased and only sentence pairs corresponding to a one-to-one sentence alignment with lengths ranging from one to 40 tokens on both French and English sides were considered. and Ney, 2003) and include only intersective alignments. Furthermore, because translation shifts are known to pose problems for the automatic projection of semantic roles across languages (Pad´o, 2007), we select only those parallel</context>
</contexts>
<marker>Koehn, 2003</marker>
<rawString>P. Koehn. 2003. Europarl: A multilingual corpus for evaluation of machine translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lang</author>
<author>M Lapata</author>
</authors>
<title>Unsupervised induction of semantic roles.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>939--947</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="2626" citStr="Lang and Lapata, 2010" startWordPosition="391" endWordPosition="394">and target side. It has been suggested that these annotations could be used to train semantic role labellers (Basili et al., 2009). In this paper, we generate high-quality broadcoverage semantic annotations using an automatic approach that does not rely on a semantic ontology for the target language. Furthermore, to our knowledge, we report the first results on using joint syntactic-semantic learning to improve the quality of the semantic annotations from automatic crosslingual transfer. Results on correlations between syntax and semantics found in previous work (Merlo and van der Plas, 2009; Lang and Lapata, 2010) have led us to make use of the available syntactic annotations on the target language. We use the semantic annotations resulting from cross-lingual transfer combined with syntactic annotations to train a joint syntactic-semantic parser for the target language, which, in turn, re-annotates the corpus (See Figure 1). We show that the semantic annotations produced by this parser are of higher quality than the data on which it was trained. Given our goal of producing broad-coverage annotations in a setting based on an aligned corpus, our choices of formal representation and of labelling scheme di</context>
<context position="7099" citStr="Lang and Lapata, 2010" startWordPosition="1085" endWordPosition="1089">plete annotations. We know from the annotation guidelines used to annotate the French gold sentences that all verbs, except modals and realisations of the verb ˆetre, should receive a predicate label. We define a filter that removes sentences with missing predicate labels based on PoS-information in the French sentence. 2.1 Learning joint syntactic-semantic structures We know from previous work that there is a strong correlation between syntax and semantics (Merlo and van der Plas, 2009), and that this correlation has been successfully applied for the unsupervised induction of semantic roles (Lang and Lapata, 2010). However, previous work in machine translation leads us to believe that transferring the correlations between syntax and semantics across languages would be problematic due to argumentstructure divergences (Dorr, 1994). For example, the English verb like and the French verb plaire do not share correlations between syntax and semantics. The verb like takes an A0 subject and an A1 Train a French syntactic parser FR syntactic annotations EN syntacticsemantic annotations EN-FR wordaligned data Transfer semantic annotations from EN to FR using word alignments FR semantic annotations Train French j</context>
<context position="13499" citStr="Lang and Lapata (2010)" startWordPosition="2116" endWordPosition="2119">e the sentences. For both annotation models we show results when using the filter described in Section 2 and without the filter. The most striking result that we can read from Table 1 is that the joint syntactic-semantic learning step results in large improvements, especially for argument labelling, where the F-measure increases from 54% to 65% for the unfiltered data. The parser is able to outperform the quality of the semantic data on which it was trained by using the information contained in the syntax. This result is in accordance with results reported in Merlo and Van der Plas (2009) and Lang and Lapata (2010), where the authors find a high correlation between syntactic functions and PropBank semantic roles. Filtering improves the quality of the transferred annotations. However, when training a parser on the annotations we see that filtering only results in better recall scores for predicate labelling. This is not surprising given that the filters apply to completeness in predicate labelling specifically. The improvements from joint syntactic-semantic learning for argument labelling are largest for the unfiltered setting, because the parser has access to larger amounts of data. The filter removes 6</context>
<context position="15189" citStr="Lang and Lapata, 2010" startWordPosition="2394" endWordPosition="2397">. These results on unrestricted test sets and their comparison to manual annotation show that we are able to scale up cross-lingual semantic role annotation. 5 Discussion and error analysis A more detailed analysis of the distribution of improvements over the types of roles further strengthens the conclusion that the parser learns the correlations between syntax and semantics. It is a wellknown fact that there exists a strong correlation between syntactic function and semantic role for the A0 and A1 arguments: A0s are commonly mapped onto subjects and A1s are often realised as direct objects (Lang and Lapata, 2010). It is therefore not surprising that the F-measure on these types of arguments increases by 12% and 15%, respectively, after joint-syntactic semantic learning. Since these arguments make up 65% of the roles, this introduces a large improvement. In addition, we find improvements of more than 10% on the following adjuncts: AM-CAU, AM-LOC, AM-MNR, and AM-MOD that together comprise 9% of the data. With respect to predicate labelling, comparison of the output after transfer with the output after parsing (on the development set) shows how the parser smooths out transfer errors and how interlingual </context>
</contexts>
<marker>Lang, Lapata, 2010</marker>
<rawString>J. Lang and M. Lapata. 2010. Unsupervised induction of semantic roles. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 939–947, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<location>Comp. Ling.,</location>
<contexts>
<context position="10626" citStr="Marcus et al., 1993" startWordPosition="1630" endWordPosition="1633">c roles across languages (Pad´o, 2007), we select only those parallel sentences in Europarl that are direct translations from English to French, or vice versa. In the end, we have a word-aligned parallel corpus of 276-thousand sentence pairs. Syntactic annotation is available for French. The French Treebank (Abeill´e et al., 2003) is a treebank of 21,564 sentences annotated with constituency annotation. We use the automatic dependency conversion of the French Treebank into dependency format provided to us by Candito and Crabb´e and described in Candito et al. (2009). The Penn Treebank corpus (Marcus et al., 1993) merged with PropBank labels (Palmer et al., 2005) and NomBank labels (Meyers, 2007) is used to train the syntactic-semantic parser described in Subsection 3.1 to annotate the English part of the parallel corpus. 3.3 Test sets For testing, we used the hand-annotated data described in (van der Plas et al., 2010). One-thousand French sentences are extracted randomly from our parallel corpus without any constraints on the semantic parallelism of the sentences, unlike much previous work. We randomly split those 1000 sentences into test and development set containing 500 sentences each. 4 Results W</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Comp. Ling., 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
<author>L van der Plas</author>
</authors>
<title>Abstraction and generalisation in semantic role labels: PropBank, VerbNet or both?</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>288--296</pages>
<location>Suntec, Singapore.</location>
<marker>Merlo, van der Plas, 2009</marker>
<rawString>P. Merlo and L. van der Plas. 2009. Abstraction and generalisation in semantic role labels: PropBank, VerbNet or both? In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 288–296, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
</authors>
<title>Annotation guidelines for NomBank - noun argument structure for PropBank.</title>
<date>2007</date>
<tech>Technical report,</tech>
<location>New York University.</location>
<contexts>
<context position="10710" citStr="Meyers, 2007" startWordPosition="1645" endWordPosition="1646"> that are direct translations from English to French, or vice versa. In the end, we have a word-aligned parallel corpus of 276-thousand sentence pairs. Syntactic annotation is available for French. The French Treebank (Abeill´e et al., 2003) is a treebank of 21,564 sentences annotated with constituency annotation. We use the automatic dependency conversion of the French Treebank into dependency format provided to us by Candito and Crabb´e and described in Candito et al. (2009). The Penn Treebank corpus (Marcus et al., 1993) merged with PropBank labels (Palmer et al., 2005) and NomBank labels (Meyers, 2007) is used to train the syntactic-semantic parser described in Subsection 3.1 to annotate the English part of the parallel corpus. 3.3 Test sets For testing, we used the hand-annotated data described in (van der Plas et al., 2010). One-thousand French sentences are extracted randomly from our parallel corpus without any constraints on the semantic parallelism of the sentences, unlike much previous work. We randomly split those 1000 sentences into test and development set containing 500 sentences each. 4 Results We evaluate our methods for automatic annotation generation twice: once after the tra</context>
</contexts>
<marker>Meyers, 2007</marker>
<rawString>A. Meyers. 2007. Annotation guidelines for NomBank - noun argument structure for PropBank. Technical report, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Monachesi</author>
<author>G Stevens</author>
<author>J Trapman</author>
</authors>
<title>Adding semantic role annotation to a corpus of written Dutch.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop (LAW),</booktitle>
<pages>77--84</pages>
<location>Prague, Czech republic.</location>
<contexts>
<context position="4156" citStr="Monachesi et al. (2007)" startWordPosition="621" endWordPosition="624">omplex constituent-alignment algorithms. 299 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 299–304, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: System overview We choose the semantic annotation scheme defined by Propbank, because it has broad coverage and includes an annotated corpus, contrary to other available resources such as FrameNet (Fillmore et al., 2003) and is the preferred annotation scheme for a joint syntactic-semantic setting (Merlo and van der Plas, 2009). Furthermore, Monachesi et al. (2007) showed that the PropBank annotation scheme can be used for languages other than English directly. 2 Cross-lingual semantic transfer Data-driven induction of semantic annotation based on parallel corpora is a well-defined and feasible task, and it has been argued to be particularly suitable to semantic role label annotation because crosslingual parallelism improves as one moves to more abstract linguistic levels of representation. While Hwa et al. (2002; 2005) find that direct syntactic dependency parallelism between English and Spanish concerns 37% of dependency links, Pad´o (2007) reports an</context>
</contexts>
<marker>Monachesi, Stevens, Trapman, 2007</marker>
<rawString>P. Monachesi, G. Stevens, and J. Trapman. 2007. Adding semantic role annotation to a corpus of written Dutch. In Proceedings of the Linguistic Annotation Workshop (LAW), pages 77–84, Prague, Czech republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--19</pages>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29:19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Cross-lingual annotation projection of semantic roles.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>36--307</pages>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual annotation projection of semantic roles. Journal ofArtificial Intelligence Research, 36:307–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>G Pitel</author>
</authors>
<title>Annotation pr´ecise du franc¸ais en s´emantique de rˆoles par projection crosslinguistique.</title>
<date>2007</date>
<booktitle>In Proceedings of TALN.</booktitle>
<marker>Pad´o, Pitel, 2007</marker>
<rawString>S. Pad´o and G. Pitel. 2007. Annotation pr´ecise du franc¸ais en s´emantique de rˆoles par projection crosslinguistique. In Proceedings of TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
</authors>
<title>Cross-lingual Annotation Projection Models for Role-Semantic Information.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Saarland University.</institution>
<marker>Pad´o, 2007</marker>
<rawString>S. Pad´o. 2007. Cross-lingual Annotation Projection Models for Role-Semantic Information. Ph.D. thesis, Saarland University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<pages>31--71</pages>
<contexts>
<context position="10676" citStr="Palmer et al., 2005" startWordPosition="1638" endWordPosition="1641">only those parallel sentences in Europarl that are direct translations from English to French, or vice versa. In the end, we have a word-aligned parallel corpus of 276-thousand sentence pairs. Syntactic annotation is available for French. The French Treebank (Abeill´e et al., 2003) is a treebank of 21,564 sentences annotated with constituency annotation. We use the automatic dependency conversion of the French Treebank into dependency format provided to us by Candito and Crabb´e and described in Candito et al. (2009). The Penn Treebank corpus (Marcus et al., 1993) merged with PropBank labels (Palmer et al., 2005) and NomBank labels (Meyers, 2007) is used to train the syntactic-semantic parser described in Subsection 3.1 to annotate the English part of the parallel corpus. 3.3 Test sets For testing, we used the hand-annotated data described in (van der Plas et al., 2010). One-thousand French sentences are extracted randomly from our parallel corpus without any constraints on the semantic parallelism of the sentences, unlike much previous work. We randomly split those 1000 sentences into test and development set containing 500 sentences each. 4 Results We evaluate our methods for automatic annotation ge</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, and P. Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31:71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>A latent variable model for generative dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Parsing Technologies (IWPT-07),</booktitle>
<pages>144--155</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="9216" citStr="Titov and Henderson (2007)" startWordPosition="1409" endWordPosition="1413">nsfer of semantic annotations from English to French, one for syntactic parsing and one for joint syntacticsemantic parsing. In addition, we used several corpora. 3.1 The statistical parsers For our syntactic-semantic parsing model, we use a freely-available parser (Henderson et al., 2008; Titov et al., 2009). The probabilistic model is a joint generative model of syntactic and semantic dependencies that maximises the joint probability of the syntactic and semantic dependencies, while building two separate structures. For the French syntactic parser, we used the dependency parser described in Titov and Henderson (2007). We train the parser on the dependency version of the French Paris treebank (Candito et al., 2009), achieving 87.2% labelled accuracy on this data set. 3.2 Data To transfer semantic annotation from English to French, we used the Europarl corpus (Koehn, 2003)1. We word-align the English sentences to the French sentences automatically using GIZA++ (Och 1As is usual practice in preprocessing for automatic alignment, the datasets were tokenised and lowercased and only sentence pairs corresponding to a one-to-one sentence alignment with lengths ranging from one to 40 tokens on both French and Engl</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>I. Titov and J. Henderson. 2007. A latent variable model for generative dependency parsing. In Proceedings of the International Conference on Parsing Technologies (IWPT-07), pages 144–155, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
<author>P Merlo</author>
<author>G Musillo</author>
</authors>
<title>Online graph planarisation for synchronous parsing of semantic and syntactic dependencies.</title>
<date>2009</date>
<booktitle>In Proceedings of the twenty-first international joint conference on artificial intelligence (IJCAI-09),</booktitle>
<location>Pasadena, California,</location>
<contexts>
<context position="8900" citStr="Titov et al., 2009" startWordPosition="1362" endWordPosition="1365"> the target language only. We train a joint syntactic-semantic parser on the combination of the two linguistic levels that learns the correlations between these structures in the target language and is able to smooth out errors from automatic transfer. 3 Experiments We used two statistical parsers in our transfer of semantic annotations from English to French, one for syntactic parsing and one for joint syntacticsemantic parsing. In addition, we used several corpora. 3.1 The statistical parsers For our syntactic-semantic parsing model, we use a freely-available parser (Henderson et al., 2008; Titov et al., 2009). The probabilistic model is a joint generative model of syntactic and semantic dependencies that maximises the joint probability of the syntactic and semantic dependencies, while building two separate structures. For the French syntactic parser, we used the dependency parser described in Titov and Henderson (2007). We train the parser on the dependency version of the French Paris treebank (Candito et al., 2009), achieving 87.2% labelled accuracy on this data set. 3.2 Data To transfer semantic annotation from English to French, we used the Europarl corpus (Koehn, 2003)1. We word-align the Engl</context>
</contexts>
<marker>Titov, Henderson, Merlo, Musillo, 2009</marker>
<rawString>I. Titov, J. Henderson, P. Merlo, and G. Musillo. 2009. Online graph planarisation for synchronous parsing of semantic and syntactic dependencies. In Proceedings of the twenty-first international joint conference on artificial intelligence (IJCAI-09), Pasadena, California, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L van der Plas</author>
<author>T Samard˘zi´c</author>
<author>P Merlo</author>
</authors>
<title>Crosslingual validity of PropBank in the manual annotation of French. In</title>
<date>2010</date>
<booktitle>In Proceedings of the 4th Linguistic Annotation Workshop (The LAW IV),</booktitle>
<location>Uppsala,</location>
<marker>van der Plas, Samard˘zi´c, Merlo, 2010</marker>
<rawString>L. van der Plas, T. Samard˘zi´c, and P. Merlo. 2010. Crosslingual validity of PropBank in the manual annotation of French. In In Proceedings of the 4th Linguistic Annotation Workshop (The LAW IV), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>P Fung</author>
</authors>
<title>Can semantic role labeling improve SMT?</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of European Association of Machine Translation.</booktitle>
<contexts>
<context position="4950" citStr="Wu and Fung (2009" startWordPosition="741" endWordPosition="744"> based on parallel corpora is a well-defined and feasible task, and it has been argued to be particularly suitable to semantic role label annotation because crosslingual parallelism improves as one moves to more abstract linguistic levels of representation. While Hwa et al. (2002; 2005) find that direct syntactic dependency parallelism between English and Spanish concerns 37% of dependency links, Pad´o (2007) reports an upper-bound mapping correspondence calculated on gold data of 88% F-measure for individual semantic roles, and 69% F-measure for whole scenario-like semantic frames. Recently, Wu and Fung (2009a; 2009b) also show that semantic roles help in statistical machine translation, capitalising on a study of the correspondence between English and Chinese which indicates that 84% of roles transfer directly, for PropBank-style annotations. These results indicate high correspondence across languages at a shallow semantic level. Based on these results, our transfer of semantic annotations from English sentences to their French translations is based on a very strong mapping hypothesis, adapted from the Direct Correspondence Assumption for syntactic dependency trees by Hwa et al. (2005). Direct Se</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>D. Wu and P. Fung. 2009a. Can semantic role labeling improve SMT? In Proceedings of the Annual Conference of European Association of Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>P Fung</author>
</authors>
<title>Semantic roles for SMT: A hybrid two-pass model.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the North American Chapter of ACL/Human Language Technology.</booktitle>
<contexts>
<context position="4950" citStr="Wu and Fung (2009" startWordPosition="741" endWordPosition="744"> based on parallel corpora is a well-defined and feasible task, and it has been argued to be particularly suitable to semantic role label annotation because crosslingual parallelism improves as one moves to more abstract linguistic levels of representation. While Hwa et al. (2002; 2005) find that direct syntactic dependency parallelism between English and Spanish concerns 37% of dependency links, Pad´o (2007) reports an upper-bound mapping correspondence calculated on gold data of 88% F-measure for individual semantic roles, and 69% F-measure for whole scenario-like semantic frames. Recently, Wu and Fung (2009a; 2009b) also show that semantic roles help in statistical machine translation, capitalising on a study of the correspondence between English and Chinese which indicates that 84% of roles transfer directly, for PropBank-style annotations. These results indicate high correspondence across languages at a shallow semantic level. Based on these results, our transfer of semantic annotations from English sentences to their French translations is based on a very strong mapping hypothesis, adapted from the Direct Correspondence Assumption for syntactic dependency trees by Hwa et al. (2005). Direct Se</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>D. Wu and P. Fung. 2009b. Semantic roles for SMT: A hybrid two-pass model. In Proceedings of the Joint Conference of the North American Chapter of ACL/Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Human Language Technology (HLT).</booktitle>
<contexts>
<context position="1728" citStr="Yarowsky et al., 2001" startWordPosition="249" endWordPosition="252">ents of only 4% and 9% points, respectively, lower than the upper bound from manual annotations. 1 Introduction As data-driven techniques tackle more and more complex natural language processing tasks, it becomes increasingly unfeasible to use complete, accurate, hand-annotated data on a large scale for training models in all languages. One approach to addressing this problem is to develop methods that automatically generate annotated data by transferring annotations in parallel corpora from languages for which this information is available to languages for which these data are not available (Yarowsky et al., 2001; Fung et al., 2007; Pad´o and Lapata, 2009). Previous work on the cross-lingual transfer of semantic annotations (Pad´o, 2007; Basili et al., 2009) has produced annotations of good quality for test sets that were carefully selected based on semantic ontologies on the source and target side. It has been suggested that these annotations could be used to train semantic role labellers (Basili et al., 2009). In this paper, we generate high-quality broadcoverage semantic annotations using an automatic approach that does not rely on a semantic ontology for the target language. Furthermore, to our kn</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the International Conference on Human Language Technology (HLT).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>