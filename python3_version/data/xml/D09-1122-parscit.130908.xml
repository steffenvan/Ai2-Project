<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.739487">
Large-Scale Verb Entailment Acquisition from the Web
Chikara Hashimoto* Kentaro Torisawa† Kow Kurodaf
</title>
<author confidence="0.955332">
Stijn De Saeger§ Masaki Muratalf Jun’ichi Kazamall
</author>
<affiliation confidence="0.993838">
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.884839">
Sorakugun, Kyoto, 619-0289, JAPAN
</address>
<email confidence="0.984835">
I* ch,† torisawa,f kuroda,§ stijn,lfmurata,ll kazamal@nict.go.jp
</email>
<sectionHeader confidence="0.997121" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997955">
Textual entailment recognition plays a
fundamental role in tasks that require in-
depth natural language understanding. In
order to use entailment recognition tech-
nologies for real-world applications, a
large-scale entailment knowledge base is
indispensable. This paper proposes a con-
ditional probability based directional sim-
ilarity measure to acquire verb entailment
pairs on a large scale. We targeted 52,562
verb types that were derived from 108
Japanese Web documents, without regard
for whether they were used in daily life
or only in specific fields. In an evaluation
of the top 20,000 verb entailment pairs ac-
quired by previous methods and ours, we
found that our similarity measure outper-
formed the previous ones. Our method
also worked well for the top 100,000 re-
sults.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999199076923077">
We all know that if you snored, you must have
been sleeping, that if you are divorced, you must
have been married, and that if you won a lawsuit,
you must have sued somebody. These relation-
ships between events where one is the logical con-
sequence of the other are called entailment. Such
knowledge plays a fundamental role in tasks that
require in-depth natural language understanding,
e.g., answering questions and using natural lan-
guage interfaces.
This paper proposes a novel method for verb
entailment acquisition. Using a Japanese Web
corpus (Kawahara and Kurohashi, 2006a) derived
from 108 Japanese Web documents, we automat-
ically acquired such verb pairs as snore —* sleep
and divorce —* marry, where entailment holds be-
tween the verbs in the pair.1 Our definition of “en-
tailment” is the same as that in WordNet3.0; v1
entails v2 if v1 cannot be done unless v2 is, or has
been, done.2
Our method follows the distributional similar-
ity hypothesis, i.e., words that occur in the same
context tend to have similar meanings. Just as in
the methods of Lin and Pantel (2001) and Szpek-
tor and Dagan (2008), we regard the arguments
of verbs as the context in the hypothesis. How-
ever, unlike the previous methods, ours is based
on conditional probability and is augmented with
a simple trick that improves the accuracy of verb
entailment acquisition. In an evaluation of the top
20,000 verb entailment pairs acquired by the pre-
vious methods and ours, we found that our similar-
ity measure outperformed the previous ones. Our
method also worked well for the top 100,000 re-
sults,
Since the scope of Natural Language Process-
ing (NLP) has advanced from a formal writing
style to a colloquial style and from restricted to
open domains, it is necessary for the language re-
sources for NLP, including verb entailment knowl-
edge bases, to cover a broad range of expressions,
regardless of whether they are used in daily life
or only in specific fields that are highly techni-
cal. As we will discuss later, our method can ac-
quire, with reasonable accuracy, verb entailment
pairs that deal not only with common and familiar
verbs but also with technical and unfamiliar ones
like podcast —* download and jibe —* sail.
Note that previous researches on entailment ac-
quisition focused on templates with variables or
word-lattices (Lin and Pantel, 2001; Szpektor and
Dagan, 2008; Barzilay and Lee, 2003; Shinyama
</bodyText>
<footnote confidence="0.8702262">
1Verb entailment pairs are described as v1 → v2 (v1 is
the entailing verb and v2 is the entailed one) henceforth.
2WordNet3.0 provides entailment relationships between
synsets like divorce, split up → marry, get married, wed, con-
join, hook up with, get hitched with, espouse.
</footnote>
<page confidence="0.885132">
1172
</page>
<note confidence="0.9966195">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1172–1181,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999755">
et al., 2002). Certainly these templates or word
lattices are more useful in such NLP applications
as Q&amp;A than simple entailment relations between
verbs. However, our contention is that entailment
certainly holds for some verb pairs (like snore →
sleep) by themselves, and that such pairs consti-
tute the core of a future entailment rule database.
Although we focused on verb entailment, our
method can also acquire template-level entailment
pairs with a reasonable accuracy.
The rest of this paper is organized as follows.
In §2, related works are described. §3 presents our
proposed method. After this, an evaluation of our
method and the existing methods is presented in
Section 4. Finally, we conclude the paper in §5.
</bodyText>
<sectionHeader confidence="0.999938" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997758857142857">
Previous studies on entailment, inference rules,
and paraphrase acquisition are roughly classi-
fied into those that require comparable corpora
(Shinyama et al., 2002; Barzilay and Lee, 2003;
Ibrahim et al., 2003) and those that do not (Lin
and Pantel, 2001; Weeds and Weir, 2003; Geffet
and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007;
Szpektor and Dagan, 2008).
Shinyama et al. (2002) regarded newspaper arti-
cles that describe the same event as a pool of para-
phrases, and acquired them by exploiting named
entity recognition. They assumed that named en-
tities are preserved across paraphrases, and that
text fragments in the articles that share several
comparable named entities should be paraphrases.
Barzilay and Lee (2003) also used newspaper ar-
ticles on the same event as comparable corpora
to acquire paraphrases. They induced paraphras-
ing patterns by sentence clustering. Ibrahim et al.
(2003) relied on multiple English translations of
foreign novels and sentence alignment to acquire
paraphrases. We decided not to take this approach
since using comparable corpora limits the scale
of the acquired paraphrases or entailment knowl-
edge bases. Although obtaining comparable cor-
pora has been simplified by the recent explosion
of the Web, the availability of plain texts is incom-
parably better.
Entailment acquisition methods that do not re-
quire comparable corpora are mostly based on the
distributional similarity hypothesis and use plain
texts with a syntactic parser. Basically, they parse
texts to obtain pairs of predicate phrases and their
arguments, which are regarded as features of the
predicates with appropriately assigned weights.
Lin and Pantel (2001) proposed a paraphrase ac-
quisition method (non-directional similarity mea-
sure) called DIRT which acquires pairs of binary-
templates (predicate phrases with two argument
slots) that are paraphrases of each other. DIRT em-
ploys the following similarity measure proposed
by Lin (1998):
</bodyText>
<equation confidence="0.9987735">
Lin (l, r) = Ef∈Fl∩Fr [wl (f ) + wr(f )]
Ef∈Fl wl(f) + Ef∈Fr wr(f)
</equation>
<bodyText confidence="0.99974716">
where l and r are the corresponding slots of two
binary templates, Fs is s’s feature vector (argu-
ment nouns), and ws(f) is the weight of f E Fs
(PMI between s and f). The intuition behind this
is that the more nouns two templates share, the
more semantically similar they are. Since we ac-
quire verb entailment pairs based on unary tem-
plates (Szpektor and Dagan, 2008) we used the
Lin formula to acquire unary templates directly
rather than using the DIRT formula, which is the
arithmetic-geometric mean of Lin’s similarities for
two slots in a binary template.
Bhagat et al. (2007) developed an algorithm
called LEDIR for learning the directionality of
non-directional inference rules like those pro-
duced by DIRT. LEDIR implements a Direction-
ality Hypothesis: when two binary semantic re-
lations tend to occur in similar contexts and the
first one occurs in significantly more contexts than
the second, then the second most likely implies the
first and not vice versa.
Weeds and Weir (2003) proposed a general
framework for distributional similarity that mainly
consists of the notions of what they call Precision
(defined below) and Recall:
</bodyText>
<equation confidence="0.749751">
Precision(l, r) = EE f∈Fl wi F (f) )
</equation>
<bodyText confidence="0.9998461">
where l and r are the targets of a similarity mea-
surement, Fs is s’s feature vector, and ws(f) is the
weight of f E Fs. The best performing weight is
PMI. Precision is a directional similarity measure
that examines the coverage of l’s features by those
of r’s, with more coverage indicating more simi-
larity.
Szpektor and Dagan (2008) proposed a direc-
tional similarity measure called BInc (Balanced-
Inclusion) that consists of Lin and Precision, as
</bodyText>
<equation confidence="0.8085475">
�
BInc(l, r) = Lin(l, r) x Precision(l, r)
</equation>
<page confidence="0.878206">
1173
</page>
<bodyText confidence="0.9999774">
where l and r are the target templates. For weight-
ing features, they used PMI. Szpektor and Dagan
(2008) also proposed a unary template, which is
defined as a template consisting of one argument
slot and one predicate phrase. For example, X take
a nap —* X sleep is an entailment pair consisting
of two unary templates. Note that the slot X must
be shared between templates. Though most of the
previous entailment acquisition studies focused on
binary templates, unary templates have an obvi-
ous advantage over binary ones; they can handle
intransitive predicate phrases and those that have
omitted arguments. The Japanese language, which
we deal with here, often omits arguments, and thus
the advantage of unary templates is obvious.
As shown in §4, our method outperforms Lin,
Precision, and BInc in accuracy.
Szpector et al. (2004) addressed broad coverage
entailment acquisition. But their method requires
an existing lexicon to start, while ours does not.
Apart from the dichotomy of the compara-
ble corpora and the distributional similarity ap-
proaches, Torisawa (2006) exploited the structure
of Japanese coordinated sentences to acquire verb
entailment pairs. Pekar (2006) used the local
structure of coherent text by identifying related
clauses within a local discourse. Zanzotto et al.
(2006) exploited agentive nouns. For example,
they acquired win —*play from “the player wins.”
Geffet and Dagan (2005) proposed the Distribu-
tional Inclusion Hypotheses, which claimed that if
a word v entails another word w, then all the char-
acteristic features of v are expected to appear with
w, and vice versa. They applied this to noun en-
tailment pair acquisition, rather than verb pairs.
</bodyText>
<sectionHeader confidence="0.992321" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.999975888888889">
This section presents our method of verb entail-
ment acquisition. First, the basics of Japanese are
described. Then, we present the directional sim-
ilarity measure that we developed in §3.2. §3.3
describes the structure and acquisition of the web-
based data from which entailment pairs are de-
rived. Finally, we show how we acquire verb en-
tailment pairs using our proposed similarity mea-
sure and the web-based data in §3.4.
</bodyText>
<subsectionHeader confidence="0.999953">
3.1 Basics of Japanese
</subsectionHeader>
<bodyText confidence="0.999888928571429">
Japanese explicitly marks arguments including the
subject and object by postpositions, and is a head-
final language. Thus, a verb phrase consisting of
an object hon (book) and a verb yomu (read), for
example, is expressed as hon-wo yomu (book-ACC
read) “read a book” with the accusative postpo-
sition wo marking the object.3 Accordingly, we
refer to a unary template as (p, v) hereafter, with
p and v referring to the postposition and a verb.
Also, we abbreviate a template-level entailment
(pl, vl) —* (pr, vr) as l —* r for simplicity. We
define a unary template as a template consisting
of one argument slot and one predicate, following
Szpektor and Dagan (2008).
</bodyText>
<subsectionHeader confidence="0.999499">
3.2 Directional Similarity Measure based on
Conditional Probability
</subsectionHeader>
<bodyText confidence="0.93165">
The directional similarity measure that we devel-
oped and called Score is defined as follows:
Score(l, r) = Scorebase(l, r) x Scoretrick(l, r)
where l and r are unary templates, and Score in-
dicates the probability of l —* r. Scorebase, which
is the base of Score, is defined as follows:
</bodyText>
<equation confidence="0.948764">
�Scorebase(l, r) = P(r|f)P(f|l)
fEFlnFr
</equation>
<bodyText confidence="0.980209217391304">
where Fs is s’s feature vector (nouns including
compounds). The intention behind the definition
of Scorebase is to emulate the conditional proba-
bility P(vr|vl)4 in a distributional similarity style
function. Note that P(vr|vl) should be 1 when en-
tailment vl —* vr holds (i.e., vr is observed when-
ever vl is observed) and we have reliable proba-
bility values. Then, if we can directly estimate
P(vr|vl), it is reasonable to assume vl —* vr if
P(vr|vl) is large enough. However, we cannot es-
timate P(vr|vl) directly since it is unlikely that we
will observe the verbs vr and vl at the same time.
(People do not usually repeat vr and vl in the same
document to avoid redundancy.) Thus, instead of
a direct estimation, we substitute Scorebase(l, r)
as defined above. In other words, we assume
P(vr|vl) Pz P(r|l) Pz ΣfEFlnFrP(f|l)P(r|f).
Actually, Scorebase originally had another mo-
tivation, inspired by Torisawa (2005), for which no
postposition but the instrumental postposition de
was relevant. In this discussion, all of the nouns
(fs) that are marked by the instrumental postposi-
tion are seen as “tools,” and P(f|l) is interpreted
</bodyText>
<footnote confidence="0.926408">
3ACC represents an accusative postposition in Japanese.
Likewise, NOM, DAT, INS, and TOP are the symbols for the
nominative, dative, instrumental, and topic postpositions.
4Remember that vl and vr are the verbs of unary tem-
plates l and r.
</footnote>
<page confidence="0.993967">
1174
</page>
<bodyText confidence="0.971585166666667">
as a measure of how typically the tool f is used
to perform the action denoted by (the vl of) l; if
P(f|l) is large enough, f is a typical tool used in
l. On the other hand, P(r|f) indicates the proba-
bility of (the vr of) r being the purpose for using
the tool f. See (1) for an example.
</bodyText>
<equation confidence="0.870068">
(1) konro-de chouri-suru
cooking.stove-INS cook
‘cook (something) using a cooking stove.’
</equation>
<bodyText confidence="0.999862156862745">
The purpose of using a cooking stove is to cook.
Torisawa (2005) has pointed out that when r ex-
presses the purpose of using a tool f, P(r|f) tends
to be large. This predicts that P(r|cooking stove)
is large, where r is (de, cook).
According to this observation, if f is a single
purpose tool and P(f|l), the probability of f be-
ing the tool by which l is performed, and P(r|f),
the probability of r being the purpose of using the
tool f, are large enough, then the typical perfor-
mance of the action vl should contain some ac-
tions that can be described by vr, i.e., the pur-
pose of using f. Moreover, if all the typical tools
(fs) used in vl are also used for vr, most perfor-
mances of the action vl should contain a part de-
scribed by the action vr. In summary, this means
that when EfEFlnFrP(r|f)P(f|l), Scorebase, has
a large value, we can expect vl —* vr.
For example, let vl be deep-fry and vr be cook.
Note that vl —* vr holds for this example. There
are many tools that are used for deep-frying,
such as cooking stove, pot, or pan. This means
that P(cooking stove|l), P(pot|l), or P(pan|l) are
large. On the other hand, the purpose of using all
of these tools is cooking, based on common sense.
Thus, probabilities such as P(r|cooking stove)
and P(r|pan) should have large values. Accord-
ingly, EfEFlnFrP(f|l)P(r|f), Scorebase, should
be relatively large for deep-fry —* cook,
Actually, we defined Scorebase based on the
above assumption However, through a series of
preliminary experiments, we found that the same
score could be applied without losing the preci-
sion to the other postpositions. Thus, we gener-
alized the framework so that it could deal with
most postpositions, namely ga (NOM), wo (ACC),
ni (DAT), de (INS), and wa (TOP). Note that this
is a variation of the distributional inclusion hy-
pothesis (Geffet and Dagan, 2005), but that we do
not use mutual information as in previous works,
based on the hypothesis discussed above. Actu-
ally, as shown in §4, our conditional probability
based method outperformed the mutual informa-
tion based metrics in our experiments.
On the other hand, Scoretrick implements an-
other assumption that if only one feature con-
tributes to Scorebase and the contribution of the
other nouns is negligible, if any, the similarity is
unreliable. Accordingly, for Scoretrick, we uni-
formly ignore the contribution of the most domi-
nant feature from the similarity measurement.
</bodyText>
<equation confidence="0.963584">
Scoretrick(l, r)
= Scorebase(l, r) − max
fEFlnFr
</equation>
<bodyText confidence="0.99920805">
As shown in §4, this trick actually improved the
entailment acquisition accuracy.
We used maximum likelihood estimation to ob-
tain P(r|f) and P(f|l) in the above discussion.
Bannard and Callison-Burch (2005) and Fujita
and Sato (2008) also proposed directional simi-
larity measures based on conditional probability,
which are very similar to Scorebase, although ei-
ther their method’s prerequisites or the targets of
the similarity measurements were different from
ours. The method of Bannard and Callison-Burch
(2005) requires bilingual parallel corpora, and
uses the translations of expressions as its feature.
Fujita and Sato (2008) dealt with productive pred-
icate phrases, while our target is non-productive
lexical units, i.e., verbs. Thus, this is the first
attempt to apply a conditional probability based
similarity measure to verb entailment acquisition.
In addition, the trick implemented in Scoretrick is
novel.
</bodyText>
<subsectionHeader confidence="0.999916">
3.3 Preparing Template-Feature Tuples
</subsectionHeader>
<bodyText confidence="0.9971586">
Our method starts from a dataset called template-
feature tuples, which was derived from the Web
in the following way: 1) Parse the Japanese Web
corpus (Kawahara and Kurohashi, 2006a) derived
from 108 Japanese Web documents with Japanese
dependency parser KNP (Kawahara and Kuro-
hashi, 2006b). 2) Extract triples (n, p, v) consist-
ing of nouns (n), postpositions (p), and verbs (v),
where an n marked by a p depends on a v from
the parsed Web text. 3) From the triple database,
construct template-feature tuples (n, (p, v)) by re-
garding (p, v) as a unary template and n as one of
its features. 4) Convert the verbs into their canon-
ical forms as defined by KNP. 5) Filter out tuples
that fall into one of the following categories: 5-
</bodyText>
<equation confidence="0.7129745">
1) Freq((p, v)) &lt; 20. 5-2) Its verb is passivized,
P(r|f)P(f|l)
</equation>
<page confidence="0.924818">
1175
</page>
<bodyText confidence="0.9996938">
causativized, or negated. 5-3) Its verb is semanti-
cally vague like be, do, or become. 5-4) Its post-
position is something other than ga (NOM), wo
(ACC), ni (DAT), de (INS), or wa (TOP).
The resulting unary template-feature tuples in-
cluded 127,808 kinds of templates that consisted
of 52,562 verb types and five kinds of postpo-
sitions. The verbs included compound words
like bosi-kansen-suru (mother.to.child-infection-
do) “infect from mothers to infants.”
</bodyText>
<subsectionHeader confidence="0.996135">
3.4 Acquiring Entailment Pairs
</subsectionHeader>
<bodyText confidence="0.999921769230769">
We acquired verb entailment pairs using the fol-
lowing procedure: i) From the template-feature
tuples mentioned in §3.3, acquire unary template
pairs that exhibit an entailment relation between
them using the directional similarity measure in
§3.2. ii) Convert the acquired unary templates
(p, v) into naked verbs v by stripping the postpo-
sitions p. iii) Remove the duplicated verb pairs
resulting from stripping ps. To be precise, when
we removed the duplicated pairs, we left the high-
est ranked one. iv) Retrieve N-best verb pairs as
the final output from the result of iii). That is, we
first acquired unary template pairs and then trans-
formed them into verb pairs.
Although this paper focuses on verb entailment
acquisition, we also evaluated the accuracy of
template-level entailment acquisition, in order to
show that our similarity measure works well, not
only for verb entailment acquisition, but also for
template entailment acquisition (See §4.4). we
created two kinds of unary templates: the “Scoring
Slots” template and the “Nom(inative) Slots” tem-
plate. The first is simply the result of the procedure
i); all of the templates have slots that are used for
similarity scoring. The second one was obtained
in the following way: 1) Only templates whose p
is not a nominative are sampled from the result of
the procedure i). 2) Their ps are all changed to a
nominative. Templates of the second kind are used
to show that the corresponding slots between tem-
plates (nominative, in this case) that are not used
for similarity scoring can be incorporated to re-
sulting template-level entailment pairs if the scor-
ing function really captures the semantic similarity
between templates.
Note that, for unary template entailment pairs
like (2) to be well-formed, the two unary slots (X-
wo) between templates must share the same noun
as the index i indicates. This is relevant in §4.4.
</bodyText>
<listItem confidence="0.4582875">
(2) XZ-wo musaborikuu → XZ-wo taberu
XZ-ACC gobble XZ-ACC eat
</listItem>
<sectionHeader confidence="0.982104" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999987444444444">
We compare the accuracy of our method with that
of the alternative methods in §4.1. §4.2 shows
the effectiveness of the trick. We examine the en-
tailment acquisition accuracy for frequent verbs in
§4.3, and evaluate the performance of our method
when applied to template-level entailment acquisi-
tion in §4.4. Finally, by showing the accuracy for
verb pairs obtained from the top 100,000 results,
we claim that our method provides a good start-
ing point from which a large-scale verb entailment
resource can be constructed in §4.5.
For the evaluation, three human annotators (not
the authors) checked whether each acquired entail-
ment pair was correct. The average of the three
Kappa values for each annotator pair was 0.579
for verb entailment pairs and 0.568 for template
entailment pairs, both of which indicate the mid-
dling stability of this evaluation annotation.
</bodyText>
<subsectionHeader confidence="0.991325">
4.1 Experiment 1: Verb Pairs
</subsectionHeader>
<bodyText confidence="0.995420142857143">
We applied Score, BInc, Lin, and Precision to the
template-feature tuples (§3.3), obtained template
entailment pairs, and finally obtained verb entail-
ment pairs by removing the postpositions from the
templates as described in §3. As a baseline, we
created pairs from randomly chosen verbs.
Since we targeted all of the verbs that ap-
peared on the Web (under the condition of
Freq((p, v)) ≥ 20), the annotators were con-
fronted with technical terms and slang that they
did not know. In such cases, they consulted dic-
tionaries (either printed or machine readable ones)
and the Web. If they still could not find the mean-
ing of a verb, they labeled the pair containing the
unknown verb as incorrect.
We used the accuracy = # of correct pairs as
# of acquired pairs
an evaluation measure. We regarded a pair as cor-
rect if it was judged correct by one (Accuracy-1),
two (Accuracy-2), or three (Accuracy-3) annota-
tors.
We evaluated 200 entailment pairs sampled
from the top 20,000 for each method (# of ac-
quired pairs = 200). For fairness, the evaluation
samples for each method were shuffled and placed
in one file from which the annotators worked. In
this way, they were unable to know which entail-
ment pair came from which method.
</bodyText>
<page confidence="0.986713">
1176
</page>
<figure confidence="0.999291583333334">
Accuracy-1
1
0.8
0.6
0.4
0.2
0
Score
BInc
Precision
Lin
0 5000 10000 15000 20000
Accuracy-2
1
0.8
0.6
0.4
0.2
0
Score
BInc
Precision
Lin
0 5000 10000 15000 20000
</figure>
<bodyText confidence="0.993951">
Note that the verb entailment pairs produced
by Lin do not provide the directionality of en-
tailment. Thus, the annotators decided the direc-
tionality of these entailment pairs as follows: i)
Copy 200 original samples and reverse the order
of v1 and v2. ii) Shuffle the 400 Lin samples
(the original and reversed samples) with the other
ones. iii) Evaluate all of the shuffled pairs. Each
Lin pair was regarded as correct if either direction
was judged correct. In other words, we evaluated
the upper bound performance of the LEDIR algo-
rithm.
Table 1 shows the accuracy of the acquired
verb entailment pairs for each method. Figure 1
</bodyText>
<table confidence="0.999719666666667">
Method Acc-1 Acc-2 Acc-3
Score 0.770 0.660 0.460
BInc 0.450 0.255 0.125
Precision 0.725 0.545 0.385
Lin 0.590 0.370 0.160
Random 0.050 0.010 0.005
</table>
<tableCaption confidence="0.999753">
Table 1: Accuracy of verb entailment pairs.
</tableCaption>
<bodyText confidence="0.954278285714286">
Accuracy-3
shows the accuracy figures for the N-best entail-
ment pairs for each method, with N being 1,000,
2,000, ..., or 20,000. We observed the following
points from the results. First, Score outperformed
all the other methods. Second, Score and Pre-
cision, which are directional similarity measures,
worked well, while Lin, which is a symmetric one,
performed poorly even though the directionality of
its output was determined manually.
Looking at the evaluated samples, Score suc-
cessfully acquired pairs in which the entailed
verbs generalized entailing verbs that were techni-
cal terms. (3) shows examples of Score’s outputs.
</bodyText>
<listItem confidence="0.92626125">
(3) a. RSS-haisin-suru → todokeru
RSS-feed-do deliver
“feed the RSS data”
b. middosippu-maunto-suru → tumu
</listItem>
<bodyText confidence="0.773758">
midship-mounting-do mount
“have (engine) midship-mounted”
The errors made by DIRT (4) and BInc (5) in-
cluded pairs consisting of technical terms.
</bodyText>
<figure confidence="0.877595857142857">
(4) kurakkingu-suru
software.cracking-do
‘crack a (security) system’
→ koutiku-hosyu-suru
building-maintenance-do
“build and maintain a system”
0 5000 10000 15000 20000
</figure>
<figureCaption confidence="0.999969">
Figure 1: Accuracy of verb entailment pairs.
</figureCaption>
<equation confidence="0.714259833333333">
(5) suisou-siiku-suru
tank-raising-do
“raise (fish) in a tank”
→ siken-houryuu-suru
test-discharge-do
“stock (with fish) experimentally”
</equation>
<bodyText confidence="0.9998215">
These terms are related in some sense, but they
are not entailment pairs.
</bodyText>
<subsectionHeader confidence="0.993949">
4.2 Experiment 2: Effectiveness of the Trick
</subsectionHeader>
<bodyText confidence="0.9999412">
Next, we investigated the effectiveness of the trick
described in §3. We evaluated Score, ScoretTick,
and Scorebase. Table 2 shows the accuracy figures
for each method. Figure 2 shows the accuracy fig-
ures for the N-best outputs for each method. The
</bodyText>
<figure confidence="0.9970504">
1
0.8
0.6
0.4
0.2
0
Score
BInc
Precision
Lin
</figure>
<page confidence="0.975944">
1177
</page>
<table confidence="0.99929275">
Method Acc-1 Acc-2 Acc-3
Score 0.770 0.660 0.460
Scoretrick 0.725 0.610 0.395
Scorebase 0.590 0.465 0.315
</table>
<tableCaption confidence="0.999436">
Table 2: Effectiveness of the trick.
</tableCaption>
<bodyText confidence="0.998418">
results illustrate that introducing the trick signif-
icantly improved the performance of Scorebase,
and so did multiplying Scoretrick and Scorebase,
which is our proposal Score.
</bodyText>
<listItem confidence="0.91735">
(6) shows an example of Scorebase’s errors.
(6) gazou-sakusei-suru —* henkou-suru
</listItem>
<bodyText confidence="0.9803075">
image-making-do change-do
“make an image” “change”
This pair has only two shared nouns (f E Fl nFr),
and more than 99.99% of the pair’s similarity re-
flects only one of the two. Clearly, the trick would
have prevented the pair from being highly ranked.
</bodyText>
<subsectionHeader confidence="0.99842">
4.3 Experiment 3: Pairs of Frequent Verbs
</subsectionHeader>
<bodyText confidence="0.999922818181818">
We found that the errors made by Lin and BInc
in Experiment 1 were mostly pairs of infrequent
verbs such as technical terms. Thus, we con-
ducted the acquisition of entailment pairs targeting
more frequent verbs to see how their performance
changed. The experimental conditions were the
same as in Experiment 1, except that the templates
((p, v)) used were all Freq((p, v)) &gt; 200.
Table 3 shows the accuracy figures for each
method with the changes in accuracy from those
of the original methods in parentheses. The re-
</bodyText>
<table confidence="0.999828666666667">
Method Acc-1 Acc-2 Acc-3
Score 0.690 0.520 0.335
(−0.080) (−0.140) (−0.125)
BInc 0.455 0.295 0.160
(+0.005) (+0.040) (+0.035)
Precision 0.450 0.355 0.205
(−0.275) (−0.190) (−0.180)
Lin 0.635 0.385 0.205
(+0.045) (+0.015) (+0.045)
</table>
<tableCaption confidence="0.99991">
Table 3: Accuracy of frequent verb pairs.
</tableCaption>
<bodyText confidence="0.999896">
sults show that the accuracies of Score and Pre-
cision (the two best methods in Experiment 1) de-
graded, while the other two improved a little. We
suspect that the performance difference between
these methods would get smaller if we further re-
stricted the target verbs to more frequent ones.
</bodyText>
<figure confidence="0.987001833333333">
Accuracy-1
0 5000 10000 15000 20000
Accuracy-2
0 5000 10000 15000 20000
Accuracy-3
0 5000 10000 15000 20000
</figure>
<figureCaption confidence="0.9928095">
Figure 2: Accuracy of verb entailment pairs ac-
quired by Score, Scoretrick, and Scorebase.
</figureCaption>
<bodyText confidence="0.999982571428571">
However, we believe that dealing with verbs com-
prehensively, including infrequent ones, is impor-
tant, since, in the era of information explosion, the
impact on applications is determined not only by
frequent verbs but also infrequent ones that consti-
tute the long tail of a verb-frequency graph. Thus,
this tendency does not matter for our purpose.
</bodyText>
<subsectionHeader confidence="0.996076">
4.4 Experiment 4: Template Pairs
</subsectionHeader>
<bodyText confidence="0.9999008">
This section presents the entailment acquisition
accuracy for template pairs to show that our
method can also perform the entailment acqui-
sition of unary templates. We presented pairs
of unary templates, obtained by the procedure in
</bodyText>
<figure confidence="0.999196407407407">
1
0.8
0.6
0.4
0.2
0
Score
Scoretrick
Scorebase
1
0.8
0.6
0.4
0.2
0
Score
Scoretrick
Scorebase
1
0.8
0.6
0.4
0.2
0
Score
Scoretrick
Scorebase
</figure>
<page confidence="0.983673">
1178
</page>
<bodyText confidence="0.984953125">
§3.4, to the annotators. In doing so, we restricted
the correct entailment pairs to those for which en-
tailment always held regardless of what argument
filled the two unary slots, and the two slots had to
be filled with the same argument, as exemplified
in (2). We evaluated Score and Precision.
Table 4 shows the accuracy of the acquired pairs
of unary templates. Compared to verb entailment
</bodyText>
<table confidence="0.99983">
Method Acc-1 Acc-2 Acc-3
Scoring Score 0.655 0.510 0.300
Slots (−0.115) (−0.150) (−0.160)
Precision 0.565 0.430 0.265
(−0.160) (−0.115) (−0.120)
Nom Score 0.665 0.515 0.315
Slots (−0.105) (−0.145) (−0.145)
Precision 0.490 0.325 0.215
(−0.235) (−0.220) (−0.170)
</table>
<tableCaption confidence="0.876628">
Table 4: Accuracy of entailment pairs of templates
whose slots were used for scoring.
</tableCaption>
<bodyText confidence="0.988631818181818">
acquisition, the accuracy of both methods dropped
by about 10%. This was mainly due to the evalua-
tion restriction exemplified in (2) which was not
introduced in the previous experiments; the an-
notators ignored the argument correspondence be-
tween the verb pairs in Experiment 1. Also note
that Score outperformed Precision in this experi-
ment, too.
(7) and (8) are examples of the Scoring Slots
template entailment pairs and (9) is that of the
Nom Slots acquired by our method.
</bodyText>
<figure confidence="0.536615214285714">
(7) X-wo tatigui-suru — X-wo taberu
X-ACC standing.up.eating-do X-ACC eat
“eat X standing up” “eat X”
(8) X-de marineedo-suru — X-wo ireru
X-INS marinade-do X-ACC pour
“marinate with X” “pour X”
(9) X-ga NBA-iri-suru · · · (was X-de (INS))
X-NOM NBA-entering-do
‘X joins an NBA team’
— X-ga nyuudan-suru · · · (was X-de)
X-NOM enrollment-do
“X joins a team”
4.5 Experiment 5: Verb Pairs form the Top
100,000
</figure>
<bodyText confidence="0.993806666666667">
Finally, we examined the accuracy of the top
100,000 verb pairs acquired by Score and Preci-
sion. As Table 5 shows, Score outperformed Pre-
</bodyText>
<table confidence="0.998659666666667">
Method Acc-1 Acc-2 Acc-3
Score 0.610 0.480 0.300
Precision 0.470 0.295 0.190
</table>
<tableCaption confidence="0.999724">
Table 5: Accuracy of the top 100,000 verb pairs.
</tableCaption>
<bodyText confidence="0.9995565">
cision. Note also that Score kept a reasonable ac-
curacy for the top 100,000 results (Acc-2: 48%).
The accuracy is encouraging enough to consider
human annotation for the top 100,000 results to
produce a language resource for verb entailment,
which we actually plan to do.
Below are correct verb entailment examples
from the top 100,000 results of our method.
</bodyText>
<figure confidence="0.867075954545454">
(10) The 121th pair
kaado-kessai-suru — siharau
card-payment-do pay
“pay by card” “pay”
(11) The 6,081th pair
saitei-suru sadameru
adjudicate-do settle
“adjudicate” “settle”
(12) The 15,464th pair
eraa-syuuryou-suru jikkou-suru
error-termination-do perform-do
“abend” “execute”
(13) The 30,044th pair
ribuuto-suru — kidou-suru
reboot-do start-do
“reboot” “boot”
(14) The 57,653th pair
rinin-suru syuunin-suru
resignation-do accession-do
“resign” “accede”
(15) The 70,103th pair
sijou-tounyuu-suru happyou-suru
</figure>
<bodyText confidence="0.924976777777778">
market-input-do publication-do
“bring to the market” “publicize”
Below are examples of erroneous pairs from our
results. (16) is a causal relation but not an entail-
ment. (17) is a contradictory pair.
(16) The 5,475th pair
juken-suru goukaku-suru
take.an.exam-do acceptance-do
“take an exam” “gain admission”
</bodyText>
<page confidence="0.989208">
1179
</page>
<bodyText confidence="0.96288975">
(17) The 40,504th pair
ketujou-suru → syutujou-suru
not.take.part-do take.part-do
“not take part” “take part”
</bodyText>
<sectionHeader confidence="0.997472" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999993285714286">
This paper addressed verb entailment acquisition
from the Web, and proposed a novel directional
similarity measure Score. Through a series of ex-
periments, we showed i) that Score outperforms
the previously proposed measures, Lin, Precision,
and BInc in large scale verb entailment acquisi-
tion, ii) that our proposed trick implemented in
Scoretrick significantly improves the accuracy of
verb entailment acquisition despite its simplicity,
iii) that Score worked better than the others even
when we restricted the target verbs to more fre-
quent ones, iv) that our method is also moder-
ately successful at producing template-level en-
tailment pairs, and v) that our method maintained
reasonable accuracy (in terms of human annota-
tion) for the top 100,000 results. As examples of
the acquired verb entailment pairs illustrated, our
method can acquire from an ocean of information,
namely the Web, a variety of verb entailment pairs
ranging from those that are used in daily life to
those that are used in very specific fields.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99965275">
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Pro-
ceedings of the 43rd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL2005),
pages 597–604.
Regina Barzilay and Lillian Lee. 2003. Learn-
ing to paraphrase: An unsupervised approach us-
ing multiple-sequence alignment. In Proceedings of
HLT-NAACL 2003, pages 16–23.
Rahul Bhagat, Patrick Pantel, and Eduard Hovy. 2007.
Ledir: An unsupervised algorithm for learning di-
rectionality of inference rules. In Proceedings of
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP2007), pages 161–170.
Atsushi Fujita and Satoshi Sato. 2008. A probabilis-
tic model for measuring grammaticality and similar-
ity of automatically generated paraphrases of pred-
icate phrases. In Proceedings of the 22nd Inter-
national Conference on Computational Linguistics
(COLING2008), pages 225–232.
Maayan Geffet and Ido Dagan. 2005. The dis-
tributional inclusion hypotheses and lexical entail-
ment. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL2005), pages 107–114.
Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Ex-
tracting structural paraphrases from aligned mono-
lingual corpora. In Proceedings of the 2nd Interna-
tional Workshop on Paraphrasing (IWP2003), pages
57–64.
Daisuke Kawahara and Sadao Kurohashi. 2006a.
Case Frame Compilation from the Web using High-
Performance Computing. In Proceedings of The 5th
International Conference on Language Resources
and Evaluation (LREC-06), pages 1344–1347.
Daisuke Kawahara and Sadao Kurohashi. 2006b. A
Fully-Lexicalized Probabilistic Model for Japanese
Syntactic and Case Structure Analysis. In Pro-
ceedings of the Human Language Technology Con-
ference of the North American Chapter of the
Association for Computational Linguistics (HLT-
NAACL2006), pages 176–183.
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 7(4):343–360.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics (COLING-ACL1998), pages
768–774.
Viktor Pekar. 2006. Acquisition of verb entailment
from text. In Proceedings of the main confer-
ence on Human Language Technology Conference
of the North American Chapter of the Association
of Computational Linguistics (HLT-NAACL2006),
pages 49–56.
Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.
2002. Automatic paraphrase acquisition from news
articles. In Proceedings of the 2nd international
Conference on Human Language Technology Re-
search (HLT2002), pages 313–318.
Idan Szpector, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP2004), pages 41–48.
Idan Szpektor and Ido Dagan. 2008. Learning en-
tailment rules for unary template. In Proceedings
of the 22nd International Conference on Computa-
tional Linguistics (COLING2008), pages 849–856.
Kentaro Torisawa. 2005. Automatic acquisition of ex-
pressions representing preparation and utilization of
an object. In Proceedings of the Recent Advances
in Natural Language Processing (RANLP05), pages
556–560.
</reference>
<page confidence="0.835572">
1180
</page>
<reference confidence="0.983215944444444">
Kentaro Torisawa. 2006. Acquiring inference rules
with temporal constraints by using japanese cood-
inated sentences and noun-verb co-occurences. In
Proceedings of the Human Language Technology
Conference of the Norh American Chapter of the
ACL (HLT-NAACL2006), pages 57–64.
Julie Weeds and David Weir. 2003. A general frame-
work for distributional similarity. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP2003), pages 81–88.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using se-
lectional preferences. In Proceedings of the 44th
Annual Meeting of the Association for Computa-
tional Linguistics and 21th International Conference
on Computational Linguistics (COLING-ACL2006),
pages 849–856.
</reference>
<page confidence="0.994538">
1181
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.589557">
<title confidence="0.992156">Large-Scale Verb Entailment Acquisition from the Web</title>
<author confidence="0.785881">Kentaro</author>
<affiliation confidence="0.8580275">De National Institute of Information and Communications</affiliation>
<address confidence="0.916736">Sorakugun, Kyoto, 619-0289,</address>
<abstract confidence="0.993817142857143">Textual entailment recognition plays a fundamental role in tasks that require indepth natural language understanding. In order to use entailment recognition technologies for real-world applications, a large-scale entailment knowledge base is indispensable. This paper proposes a conditional probability based directional similarity measure to acquire verb entailment pairs on a large scale. We targeted 52,562 types that were derived from Japanese Web documents, without regard for whether they were used in daily life or only in specific fields. In an evaluation of the top 20,000 verb entailment pairs acquired by previous methods and ours, we found that our similarity measure outperformed the previous ones. Our method also worked well for the top 100,000 results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005),</booktitle>
<pages>597--604</pages>
<contexts>
<context position="15995" citStr="Bannard and Callison-Burch (2005)" startWordPosition="2631" endWordPosition="2634"> information based metrics in our experiments. On the other hand, Scoretrick implements another assumption that if only one feature contributes to Scorebase and the contribution of the other nouns is negligible, if any, the similarity is unreliable. Accordingly, for Scoretrick, we uniformly ignore the contribution of the most dominant feature from the similarity measurement. Scoretrick(l, r) = Scorebase(l, r) − max fEFlnFr As shown in §4, this trick actually improved the entailment acquisition accuracy. We used maximum likelihood estimation to obtain P(r|f) and P(f|l) in the above discussion. Bannard and Callison-Burch (2005) and Fujita and Sato (2008) also proposed directional similarity measures based on conditional probability, which are very similar to Scorebase, although either their method’s prerequisites or the targets of the similarity measurements were different from ours. The method of Bannard and Callison-Burch (2005) requires bilingual parallel corpora, and uses the translations of expressions as its feature. Fujita and Sato (2008) dealt with productive predicate phrases, while our target is non-productive lexical units, i.e., verbs. Thus, this is the first attempt to apply a conditional probability ba</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005), pages 597–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>16--23</pages>
<contexts>
<context position="3498" citStr="Barzilay and Lee, 2003" startWordPosition="561" endWordPosition="564">e resources for NLP, including verb entailment knowledge bases, to cover a broad range of expressions, regardless of whether they are used in daily life or only in specific fields that are highly technical. As we will discuss later, our method can acquire, with reasonable accuracy, verb entailment pairs that deal not only with common and familiar verbs but also with technical and unfamiliar ones like podcast —* download and jibe —* sail. Note that previous researches on entailment acquisition focused on templates with variables or word-lattices (Lin and Pantel, 2001; Szpektor and Dagan, 2008; Barzilay and Lee, 2003; Shinyama 1Verb entailment pairs are described as v1 → v2 (v1 is the entailing verb and v2 is the entailed one) henceforth. 2WordNet3.0 provides entailment relationships between synsets like divorce, split up → marry, get married, wed, conjoin, hook up with, get hitched with, espouse. 1172 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1172–1181, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP et al., 2002). Certainly these templates or word lattices are more useful in such NLP applications as Q&amp;A than simple entailment relations between verbs. </context>
<context position="4869" citStr="Barzilay and Lee, 2003" startWordPosition="777" endWordPosition="780"> core of a future entailment rule database. Although we focused on verb entailment, our method can also acquire template-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable </context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In Proceedings of HLT-NAACL 2003, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Patrick Pantel</author>
<author>Eduard Hovy</author>
</authors>
<title>Ledir: An unsupervised algorithm for learning directionality of inference rules.</title>
<date>2007</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP2007),</booktitle>
<pages>161--170</pages>
<contexts>
<context position="5016" citStr="Bhagat et al., 2007" startWordPosition="804" endWordPosition="807"> reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns by sentence clustering. Ibrahim et al. (2003) relied on multiple English transla</context>
<context position="7279" citStr="Bhagat et al. (2007)" startWordPosition="1168" endWordPosition="1171"> ) + wr(f )] Ef∈Fl wl(f) + Ef∈Fr wr(f) where l and r are the corresponding slots of two binary templates, Fs is s’s feature vector (argument nouns), and ws(f) is the weight of f E Fs (PMI between s and f). The intuition behind this is that the more nouns two templates share, the more semantically similar they are. Since we acquire verb entailment pairs based on unary templates (Szpektor and Dagan, 2008) we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lin’s similarities for two slots in a binary template. Bhagat et al. (2007) developed an algorithm called LEDIR for learning the directionality of non-directional inference rules like those produced by DIRT. LEDIR implements a Directionality Hypothesis: when two binary semantic relations tend to occur in similar contexts and the first one occurs in significantly more contexts than the second, then the second most likely implies the first and not vice versa. Weeds and Weir (2003) proposed a general framework for distributional similarity that mainly consists of the notions of what they call Precision (defined below) and Recall: Precision(l, r) = EE f∈Fl wi F (f) ) whe</context>
</contexts>
<marker>Bhagat, Pantel, Hovy, 2007</marker>
<rawString>Rahul Bhagat, Patrick Pantel, and Eduard Hovy. 2007. Ledir: An unsupervised algorithm for learning directionality of inference rules. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP2007), pages 161–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujita</author>
<author>Satoshi Sato</author>
</authors>
<title>A probabilistic model for measuring grammaticality and similarity of automatically generated paraphrases of predicate phrases.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008),</booktitle>
<pages>225--232</pages>
<contexts>
<context position="16022" citStr="Fujita and Sato (2008)" startWordPosition="2636" endWordPosition="2639">riments. On the other hand, Scoretrick implements another assumption that if only one feature contributes to Scorebase and the contribution of the other nouns is negligible, if any, the similarity is unreliable. Accordingly, for Scoretrick, we uniformly ignore the contribution of the most dominant feature from the similarity measurement. Scoretrick(l, r) = Scorebase(l, r) − max fEFlnFr As shown in §4, this trick actually improved the entailment acquisition accuracy. We used maximum likelihood estimation to obtain P(r|f) and P(f|l) in the above discussion. Bannard and Callison-Burch (2005) and Fujita and Sato (2008) also proposed directional similarity measures based on conditional probability, which are very similar to Scorebase, although either their method’s prerequisites or the targets of the similarity measurements were different from ours. The method of Bannard and Callison-Burch (2005) requires bilingual parallel corpora, and uses the translations of expressions as its feature. Fujita and Sato (2008) dealt with productive predicate phrases, while our target is non-productive lexical units, i.e., verbs. Thus, this is the first attempt to apply a conditional probability based similarity measure to v</context>
</contexts>
<marker>Fujita, Sato, 2008</marker>
<rawString>Atsushi Fujita and Satoshi Sato. 2008. A probabilistic model for measuring grammaticality and similarity of automatically generated paraphrases of predicate phrases. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008), pages 225–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maayan Geffet</author>
<author>Ido Dagan</author>
</authors>
<title>The distributional inclusion hypotheses and lexical entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005),</booktitle>
<pages>107--114</pages>
<contexts>
<context position="4982" citStr="Geffet and Dagan, 2005" startWordPosition="798" endWordPosition="801">emplate-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns by sentence clustering. Ibrahim et al. (2003) </context>
<context position="9782" citStr="Geffet and Dagan (2005)" startWordPosition="1574" endWordPosition="1577"> and BInc in accuracy. Szpector et al. (2004) addressed broad coverage entailment acquisition. But their method requires an existing lexicon to start, while ours does not. Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs. Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse. Zanzotto et al. (2006) exploited agentive nouns. For example, they acquired win —*play from “the player wins.” Geffet and Dagan (2005) proposed the Distributional Inclusion Hypotheses, which claimed that if a word v entails another word w, then all the characteristic features of v are expected to appear with w, and vice versa. They applied this to noun entailment pair acquisition, rather than verb pairs. 3 Proposed Method This section presents our method of verb entailment acquisition. First, the basics of Japanese are described. Then, we present the directional similarity measure that we developed in §3.2. §3.3 describes the structure and acquisition of the webbased data from which entailment pairs are derived. Finally, we </context>
<context position="15165" citStr="Geffet and Dagan, 2005" startWordPosition="2501" endWordPosition="2504">ies such as P(r|cooking stove) and P(r|pan) should have large values. Accordingly, EfEFlnFrP(f|l)P(r|f), Scorebase, should be relatively large for deep-fry —* cook, Actually, we defined Scorebase based on the above assumption However, through a series of preliminary experiments, we found that the same score could be applied without losing the precision to the other postpositions. Thus, we generalized the framework so that it could deal with most postpositions, namely ga (NOM), wo (ACC), ni (DAT), de (INS), and wa (TOP). Note that this is a variation of the distributional inclusion hypothesis (Geffet and Dagan, 2005), but that we do not use mutual information as in previous works, based on the hypothesis discussed above. Actually, as shown in §4, our conditional probability based method outperformed the mutual information based metrics in our experiments. On the other hand, Scoretrick implements another assumption that if only one feature contributes to Scorebase and the contribution of the other nouns is negligible, if any, the similarity is unreliable. Accordingly, for Scoretrick, we uniformly ignore the contribution of the most dominant feature from the similarity measurement. Scoretrick(l, r) = Scoreb</context>
</contexts>
<marker>Geffet, Dagan, 2005</marker>
<rawString>Maayan Geffet and Ido Dagan. 2005. The distributional inclusion hypotheses and lexical entailment. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005), pages 107–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali Ibrahim</author>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd International Workshop on Paraphrasing (IWP2003),</booktitle>
<pages>57--64</pages>
<contexts>
<context position="4892" citStr="Ibrahim et al., 2003" startWordPosition="781" endWordPosition="784">ment rule database. Although we focused on verb entailment, our method can also acquire template-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire para</context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Proceedings of the 2nd International Workshop on Paraphrasing (IWP2003), pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Case Frame Compilation from the Web using HighPerformance Computing.</title>
<date>2006</date>
<booktitle>In Proceedings of The 5th International Conference on Language Resources and Evaluation (LREC-06),</booktitle>
<pages>1344--1347</pages>
<contexts>
<context position="1694" citStr="Kawahara and Kurohashi, 2006" startWordPosition="252" endWordPosition="255">ed well for the top 100,000 results. 1 Introduction We all know that if you snored, you must have been sleeping, that if you are divorced, you must have been married, and that if you won a lawsuit, you must have sued somebody. These relationships between events where one is the logical consequence of the other are called entailment. Such knowledge plays a fundamental role in tasks that require in-depth natural language understanding, e.g., answering questions and using natural language interfaces. This paper proposes a novel method for verb entailment acquisition. Using a Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents, we automatically acquired such verb pairs as snore —* sleep and divorce —* marry, where entailment holds between the verbs in the pair.1 Our definition of “entailment” is the same as that in WordNet3.0; v1 entails v2 if v1 cannot be done unless v2 is, or has been, done.2 Our method follows the distributional similarity hypothesis, i.e., words that occur in the same context tend to have similar meanings. Just as in the methods of Lin and Pantel (2001) and Szpektor and Dagan (2008), we regard the arguments of verbs as the context in the hypothesis. How</context>
<context position="16926" citStr="Kawahara and Kurohashi, 2006" startWordPosition="2769" endWordPosition="2772">(2005) requires bilingual parallel corpora, and uses the translations of expressions as its feature. Fujita and Sato (2008) dealt with productive predicate phrases, while our target is non-productive lexical units, i.e., verbs. Thus, this is the first attempt to apply a conditional probability based similarity measure to verb entailment acquisition. In addition, the trick implemented in Scoretrick is novel. 3.3 Preparing Template-Feature Tuples Our method starts from a dataset called templatefeature tuples, which was derived from the Web in the following way: 1) Parse the Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents with Japanese dependency parser KNP (Kawahara and Kurohashi, 2006b). 2) Extract triples (n, p, v) consisting of nouns (n), postpositions (p), and verbs (v), where an n marked by a p depends on a v from the parsed Web text. 3) From the triple database, construct template-feature tuples (n, (p, v)) by regarding (p, v) as a unary template and n as one of its features. 4) Convert the verbs into their canonical forms as defined by KNP. 5) Filter out tuples that fall into one of the following categories: 5- 1) Freq((p, v)) &lt; 20. 5-2) Its verb is passivized,</context>
</contexts>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006a. Case Frame Compilation from the Web using HighPerformance Computing. In Proceedings of The 5th International Conference on Language Resources and Evaluation (LREC-06), pages 1344–1347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>A Fully-Lexicalized Probabilistic Model for Japanese Syntactic and Case Structure Analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL2006),</booktitle>
<pages>176--183</pages>
<contexts>
<context position="1694" citStr="Kawahara and Kurohashi, 2006" startWordPosition="252" endWordPosition="255">ed well for the top 100,000 results. 1 Introduction We all know that if you snored, you must have been sleeping, that if you are divorced, you must have been married, and that if you won a lawsuit, you must have sued somebody. These relationships between events where one is the logical consequence of the other are called entailment. Such knowledge plays a fundamental role in tasks that require in-depth natural language understanding, e.g., answering questions and using natural language interfaces. This paper proposes a novel method for verb entailment acquisition. Using a Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents, we automatically acquired such verb pairs as snore —* sleep and divorce —* marry, where entailment holds between the verbs in the pair.1 Our definition of “entailment” is the same as that in WordNet3.0; v1 entails v2 if v1 cannot be done unless v2 is, or has been, done.2 Our method follows the distributional similarity hypothesis, i.e., words that occur in the same context tend to have similar meanings. Just as in the methods of Lin and Pantel (2001) and Szpektor and Dagan (2008), we regard the arguments of verbs as the context in the hypothesis. How</context>
<context position="16926" citStr="Kawahara and Kurohashi, 2006" startWordPosition="2769" endWordPosition="2772">(2005) requires bilingual parallel corpora, and uses the translations of expressions as its feature. Fujita and Sato (2008) dealt with productive predicate phrases, while our target is non-productive lexical units, i.e., verbs. Thus, this is the first attempt to apply a conditional probability based similarity measure to verb entailment acquisition. In addition, the trick implemented in Scoretrick is novel. 3.3 Preparing Template-Feature Tuples Our method starts from a dataset called templatefeature tuples, which was derived from the Web in the following way: 1) Parse the Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents with Japanese dependency parser KNP (Kawahara and Kurohashi, 2006b). 2) Extract triples (n, p, v) consisting of nouns (n), postpositions (p), and verbs (v), where an n marked by a p depends on a v from the parsed Web text. 3) From the triple database, construct template-feature tuples (n, (p, v)) by regarding (p, v) as a unary template and n as one of its features. 4) Convert the verbs into their canonical forms as defined by KNP. 5) Filter out tuples that fall into one of the following categories: 5- 1) Freq((p, v)) &lt; 20. 5-2) Its verb is passivized,</context>
</contexts>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006b. A Fully-Lexicalized Probabilistic Model for Japanese Syntactic and Case Structure Analysis. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL2006), pages 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="2192" citStr="Lin and Pantel (2001)" startWordPosition="341" endWordPosition="344">is paper proposes a novel method for verb entailment acquisition. Using a Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents, we automatically acquired such verb pairs as snore —* sleep and divorce —* marry, where entailment holds between the verbs in the pair.1 Our definition of “entailment” is the same as that in WordNet3.0; v1 entails v2 if v1 cannot be done unless v2 is, or has been, done.2 Our method follows the distributional similarity hypothesis, i.e., words that occur in the same context tend to have similar meanings. Just as in the methods of Lin and Pantel (2001) and Szpektor and Dagan (2008), we regard the arguments of verbs as the context in the hypothesis. However, unlike the previous methods, ours is based on conditional probability and is augmented with a simple trick that improves the accuracy of verb entailment acquisition. In an evaluation of the top 20,000 verb entailment pairs acquired by the previous methods and ours, we found that our similarity measure outperformed the previous ones. Our method also worked well for the top 100,000 results, Since the scope of Natural Language Processing (NLP) has advanced from a formal writing style to a c</context>
<context position="3448" citStr="Lin and Pantel, 2001" startWordPosition="553" endWordPosition="556">to open domains, it is necessary for the language resources for NLP, including verb entailment knowledge bases, to cover a broad range of expressions, regardless of whether they are used in daily life or only in specific fields that are highly technical. As we will discuss later, our method can acquire, with reasonable accuracy, verb entailment pairs that deal not only with common and familiar verbs but also with technical and unfamiliar ones like podcast —* download and jibe —* sail. Note that previous researches on entailment acquisition focused on templates with variables or word-lattices (Lin and Pantel, 2001; Szpektor and Dagan, 2008; Barzilay and Lee, 2003; Shinyama 1Verb entailment pairs are described as v1 → v2 (v1 is the entailing verb and v2 is the entailed one) henceforth. 2WordNet3.0 provides entailment relationships between synsets like divorce, split up → marry, get married, wed, conjoin, hook up with, get hitched with, espouse. 1172 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1172–1181, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP et al., 2002). Certainly these templates or word lattices are more useful in such NLP applications as Q&amp;</context>
<context position="4936" citStr="Lin and Pantel, 2001" startWordPosition="790" endWordPosition="793">rb entailment, our method can also acquire template-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns </context>
<context position="6350" citStr="Lin and Pantel (2001)" startWordPosition="1008" endWordPosition="1011"> using comparable corpora limits the scale of the acquired paraphrases or entailment knowledge bases. Although obtaining comparable corpora has been simplified by the recent explosion of the Web, the availability of plain texts is incomparably better. Entailment acquisition methods that do not require comparable corpora are mostly based on the distributional similarity hypothesis and use plain texts with a syntactic parser. Basically, they parse texts to obtain pairs of predicate phrases and their arguments, which are regarded as features of the predicates with appropriately assigned weights. Lin and Pantel (2001) proposed a paraphrase acquisition method (non-directional similarity measure) called DIRT which acquires pairs of binarytemplates (predicate phrases with two argument slots) that are paraphrases of each other. DIRT employs the following similarity measure proposed by Lin (1998): Lin (l, r) = Ef∈Fl∩Fr [wl (f ) + wr(f )] Ef∈Fl wl(f) + Ef∈Fr wr(f) where l and r are the corresponding slots of two binary templates, Fs is s’s feature vector (argument nouns), and ws(f) is the weight of f E Fs (PMI between s and f). The intuition behind this is that the more nouns two templates share, the more semant</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLING-ACL1998),</booktitle>
<pages>768--774</pages>
<contexts>
<context position="6629" citStr="Lin (1998)" startWordPosition="1051" endWordPosition="1052"> not require comparable corpora are mostly based on the distributional similarity hypothesis and use plain texts with a syntactic parser. Basically, they parse texts to obtain pairs of predicate phrases and their arguments, which are regarded as features of the predicates with appropriately assigned weights. Lin and Pantel (2001) proposed a paraphrase acquisition method (non-directional similarity measure) called DIRT which acquires pairs of binarytemplates (predicate phrases with two argument slots) that are paraphrases of each other. DIRT employs the following similarity measure proposed by Lin (1998): Lin (l, r) = Ef∈Fl∩Fr [wl (f ) + wr(f )] Ef∈Fl wl(f) + Ef∈Fr wr(f) where l and r are the corresponding slots of two binary templates, Fs is s’s feature vector (argument nouns), and ws(f) is the weight of f E Fs (PMI between s and f). The intuition behind this is that the more nouns two templates share, the more semantically similar they are. Since we acquire verb entailment pairs based on unary templates (Szpektor and Dagan, 2008) we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lin’s similarities for tw</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLING-ACL1998), pages 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viktor Pekar</author>
</authors>
<title>Acquisition of verb entailment from text.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL2006),</booktitle>
<pages>49--56</pages>
<contexts>
<context position="4995" citStr="Pekar, 2006" startWordPosition="802" endWordPosition="803"> pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns by sentence clustering. Ibrahim et al. (2003) relied on mul</context>
<context position="9548" citStr="Pekar (2006)" startWordPosition="1540" endWordPosition="1541">ases and those that have omitted arguments. The Japanese language, which we deal with here, often omits arguments, and thus the advantage of unary templates is obvious. As shown in §4, our method outperforms Lin, Precision, and BInc in accuracy. Szpector et al. (2004) addressed broad coverage entailment acquisition. But their method requires an existing lexicon to start, while ours does not. Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs. Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse. Zanzotto et al. (2006) exploited agentive nouns. For example, they acquired win —*play from “the player wins.” Geffet and Dagan (2005) proposed the Distributional Inclusion Hypotheses, which claimed that if a word v entails another word w, then all the characteristic features of v are expected to appear with w, and vice versa. They applied this to noun entailment pair acquisition, rather than verb pairs. 3 Proposed Method This section presents our method of verb entailment acquisition. First, th</context>
</contexts>
<marker>Pekar, 2006</marker>
<rawString>Viktor Pekar. 2006. Acquisition of verb entailment from text. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL2006), pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
</authors>
<title>Automatic paraphrase acquisition from news articles.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd international Conference on Human Language Technology Research (HLT2002),</booktitle>
<pages>313--318</pages>
<contexts>
<context position="4845" citStr="Shinyama et al., 2002" startWordPosition="773" endWordPosition="776">ch pairs constitute the core of a future entailment rule database. Although we focused on verb entailment, our method can also acquire template-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the s</context>
</contexts>
<marker>Shinyama, Sekine, Sudo, 2002</marker>
<rawString>Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo. 2002. Automatic paraphrase acquisition from news articles. In Proceedings of the 2nd international Conference on Human Language Technology Research (HLT2002), pages 313–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpector</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2004),</booktitle>
<pages>41--48</pages>
<contexts>
<context position="9204" citStr="Szpector et al. (2004)" startWordPosition="1489" endWordPosition="1492">dicate phrase. For example, X take a nap —* X sleep is an entailment pair consisting of two unary templates. Note that the slot X must be shared between templates. Though most of the previous entailment acquisition studies focused on binary templates, unary templates have an obvious advantage over binary ones; they can handle intransitive predicate phrases and those that have omitted arguments. The Japanese language, which we deal with here, often omits arguments, and thus the advantage of unary templates is obvious. As shown in §4, our method outperforms Lin, Precision, and BInc in accuracy. Szpector et al. (2004) addressed broad coverage entailment acquisition. But their method requires an existing lexicon to start, while ours does not. Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs. Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse. Zanzotto et al. (2006) exploited agentive nouns. For example, they acquired win —*play from “the player wins.” Geffet and Dagan (2005) proposed the Distribu</context>
</contexts>
<marker>Szpector, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpector, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2004), pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary template.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008),</booktitle>
<pages>849--856</pages>
<contexts>
<context position="2222" citStr="Szpektor and Dagan (2008)" startWordPosition="346" endWordPosition="350">method for verb entailment acquisition. Using a Japanese Web corpus (Kawahara and Kurohashi, 2006a) derived from 108 Japanese Web documents, we automatically acquired such verb pairs as snore —* sleep and divorce —* marry, where entailment holds between the verbs in the pair.1 Our definition of “entailment” is the same as that in WordNet3.0; v1 entails v2 if v1 cannot be done unless v2 is, or has been, done.2 Our method follows the distributional similarity hypothesis, i.e., words that occur in the same context tend to have similar meanings. Just as in the methods of Lin and Pantel (2001) and Szpektor and Dagan (2008), we regard the arguments of verbs as the context in the hypothesis. However, unlike the previous methods, ours is based on conditional probability and is augmented with a simple trick that improves the accuracy of verb entailment acquisition. In an evaluation of the top 20,000 verb entailment pairs acquired by the previous methods and ours, we found that our similarity measure outperformed the previous ones. Our method also worked well for the top 100,000 results, Since the scope of Natural Language Processing (NLP) has advanced from a formal writing style to a colloquial style and from restr</context>
<context position="3474" citStr="Szpektor and Dagan, 2008" startWordPosition="557" endWordPosition="560"> necessary for the language resources for NLP, including verb entailment knowledge bases, to cover a broad range of expressions, regardless of whether they are used in daily life or only in specific fields that are highly technical. As we will discuss later, our method can acquire, with reasonable accuracy, verb entailment pairs that deal not only with common and familiar verbs but also with technical and unfamiliar ones like podcast —* download and jibe —* sail. Note that previous researches on entailment acquisition focused on templates with variables or word-lattices (Lin and Pantel, 2001; Szpektor and Dagan, 2008; Barzilay and Lee, 2003; Shinyama 1Verb entailment pairs are described as v1 → v2 (v1 is the entailing verb and v2 is the entailed one) henceforth. 2WordNet3.0 provides entailment relationships between synsets like divorce, split up → marry, get married, wed, conjoin, hook up with, get hitched with, espouse. 1172 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1172–1181, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP et al., 2002). Certainly these templates or word lattices are more useful in such NLP applications as Q&amp;A than simple entailment r</context>
<context position="5043" citStr="Szpektor and Dagan, 2008" startWordPosition="808" endWordPosition="811"> The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns by sentence clustering. Ibrahim et al. (2003) relied on multiple English translations of foreign novels and</context>
<context position="7065" citStr="Szpektor and Dagan, 2008" startWordPosition="1133" endWordPosition="1136"> which acquires pairs of binarytemplates (predicate phrases with two argument slots) that are paraphrases of each other. DIRT employs the following similarity measure proposed by Lin (1998): Lin (l, r) = Ef∈Fl∩Fr [wl (f ) + wr(f )] Ef∈Fl wl(f) + Ef∈Fr wr(f) where l and r are the corresponding slots of two binary templates, Fs is s’s feature vector (argument nouns), and ws(f) is the weight of f E Fs (PMI between s and f). The intuition behind this is that the more nouns two templates share, the more semantically similar they are. Since we acquire verb entailment pairs based on unary templates (Szpektor and Dagan, 2008) we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lin’s similarities for two slots in a binary template. Bhagat et al. (2007) developed an algorithm called LEDIR for learning the directionality of non-directional inference rules like those produced by DIRT. LEDIR implements a Directionality Hypothesis: when two binary semantic relations tend to occur in similar contexts and the first one occurs in significantly more contexts than the second, then the second most likely implies the first and not vice versa.</context>
<context position="8475" citStr="Szpektor and Dagan (2008)" startWordPosition="1370" endWordPosition="1373">, r) = EE f∈Fl wi F (f) ) where l and r are the targets of a similarity measurement, Fs is s’s feature vector, and ws(f) is the weight of f E Fs. The best performing weight is PMI. Precision is a directional similarity measure that examines the coverage of l’s features by those of r’s, with more coverage indicating more similarity. Szpektor and Dagan (2008) proposed a directional similarity measure called BInc (BalancedInclusion) that consists of Lin and Precision, as � BInc(l, r) = Lin(l, r) x Precision(l, r) 1173 where l and r are the target templates. For weighting features, they used PMI. Szpektor and Dagan (2008) also proposed a unary template, which is defined as a template consisting of one argument slot and one predicate phrase. For example, X take a nap —* X sleep is an entailment pair consisting of two unary templates. Note that the slot X must be shared between templates. Though most of the previous entailment acquisition studies focused on binary templates, unary templates have an obvious advantage over binary ones; they can handle intransitive predicate phrases and those that have omitted arguments. The Japanese language, which we deal with here, often omits arguments, and thus the advantage o</context>
<context position="11180" citStr="Szpektor and Dagan (2008)" startWordPosition="1811" endWordPosition="1814">cluding the subject and object by postpositions, and is a headfinal language. Thus, a verb phrase consisting of an object hon (book) and a verb yomu (read), for example, is expressed as hon-wo yomu (book-ACC read) “read a book” with the accusative postposition wo marking the object.3 Accordingly, we refer to a unary template as (p, v) hereafter, with p and v referring to the postposition and a verb. Also, we abbreviate a template-level entailment (pl, vl) —* (pr, vr) as l —* r for simplicity. We define a unary template as a template consisting of one argument slot and one predicate, following Szpektor and Dagan (2008). 3.2 Directional Similarity Measure based on Conditional Probability The directional similarity measure that we developed and called Score is defined as follows: Score(l, r) = Scorebase(l, r) x Scoretrick(l, r) where l and r are unary templates, and Score indicates the probability of l —* r. Scorebase, which is the base of Score, is defined as follows: �Scorebase(l, r) = P(r|f)P(f|l) fEFlnFr where Fs is s’s feature vector (nouns including compounds). The intention behind the definition of Scorebase is to emulate the conditional probability P(vr|vl)4 in a distributional similarity style functi</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary template. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008), pages 849–856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
</authors>
<title>Automatic acquisition of expressions representing preparation and utilization of an object.</title>
<date>2005</date>
<booktitle>In Proceedings of the Recent Advances in Natural Language Processing (RANLP05),</booktitle>
<pages>556--560</pages>
<contexts>
<context position="12490" citStr="Torisawa (2005)" startWordPosition="2029" endWordPosition="2030">r vl is observed) and we have reliable probability values. Then, if we can directly estimate P(vr|vl), it is reasonable to assume vl —* vr if P(vr|vl) is large enough. However, we cannot estimate P(vr|vl) directly since it is unlikely that we will observe the verbs vr and vl at the same time. (People do not usually repeat vr and vl in the same document to avoid redundancy.) Thus, instead of a direct estimation, we substitute Scorebase(l, r) as defined above. In other words, we assume P(vr|vl) Pz P(r|l) Pz ΣfEFlnFrP(f|l)P(r|f). Actually, Scorebase originally had another motivation, inspired by Torisawa (2005), for which no postposition but the instrumental postposition de was relevant. In this discussion, all of the nouns (fs) that are marked by the instrumental postposition are seen as “tools,” and P(f|l) is interpreted 3ACC represents an accusative postposition in Japanese. Likewise, NOM, DAT, INS, and TOP are the symbols for the nominative, dative, instrumental, and topic postpositions. 4Remember that vl and vr are the verbs of unary templates l and r. 1174 as a measure of how typically the tool f is used to perform the action denoted by (the vl of) l; if P(f|l) is large enough, f is a typical </context>
</contexts>
<marker>Torisawa, 2005</marker>
<rawString>Kentaro Torisawa. 2005. Automatic acquisition of expressions representing preparation and utilization of an object. In Proceedings of the Recent Advances in Natural Language Processing (RANLP05), pages 556–560.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
</authors>
<title>Acquiring inference rules with temporal constraints by using japanese coodinated sentences and noun-verb co-occurences.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the Norh American Chapter of the ACL (HLT-NAACL2006),</booktitle>
<pages>57--64</pages>
<contexts>
<context position="9443" citStr="Torisawa (2006)" startWordPosition="1526" endWordPosition="1527">ates, unary templates have an obvious advantage over binary ones; they can handle intransitive predicate phrases and those that have omitted arguments. The Japanese language, which we deal with here, often omits arguments, and thus the advantage of unary templates is obvious. As shown in §4, our method outperforms Lin, Precision, and BInc in accuracy. Szpector et al. (2004) addressed broad coverage entailment acquisition. But their method requires an existing lexicon to start, while ours does not. Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs. Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse. Zanzotto et al. (2006) exploited agentive nouns. For example, they acquired win —*play from “the player wins.” Geffet and Dagan (2005) proposed the Distributional Inclusion Hypotheses, which claimed that if a word v entails another word w, then all the characteristic features of v are expected to appear with w, and vice versa. They applied this to noun entailment pair acquisition, rather than</context>
</contexts>
<marker>Torisawa, 2006</marker>
<rawString>Kentaro Torisawa. 2006. Acquiring inference rules with temporal constraints by using japanese coodinated sentences and noun-verb co-occurences. In Proceedings of the Human Language Technology Conference of the Norh American Chapter of the ACL (HLT-NAACL2006), pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2003),</booktitle>
<pages>81--88</pages>
<contexts>
<context position="4958" citStr="Weeds and Weir, 2003" startWordPosition="794" endWordPosition="797">hod can also acquire template-level entailment pairs with a reasonable accuracy. The rest of this paper is organized as follows. In §2, related works are described. §3 presents our proposed method. After this, an evaluation of our method and the existing methods is presented in Section 4. Finally, we conclude the paper in §5. 2 Related Work Previous studies on entailment, inference rules, and paraphrase acquisition are roughly classified into those that require comparable corpora (Shinyama et al., 2002; Barzilay and Lee, 2003; Ibrahim et al., 2003) and those that do not (Lin and Pantel, 2001; Weeds and Weir, 2003; Geffet and Dagan, 2005; Pekar, 2006; Bhagat et al., 2007; Szpektor and Dagan, 2008). Shinyama et al. (2002) regarded newspaper articles that describe the same event as a pool of paraphrases, and acquired them by exploiting named entity recognition. They assumed that named entities are preserved across paraphrases, and that text fragments in the articles that share several comparable named entities should be paraphrases. Barzilay and Lee (2003) also used newspaper articles on the same event as comparable corpora to acquire paraphrases. They induced paraphrasing patterns by sentence clustering</context>
<context position="7687" citStr="Weeds and Weir (2003)" startWordPosition="1233" endWordPosition="1236">we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lin’s similarities for two slots in a binary template. Bhagat et al. (2007) developed an algorithm called LEDIR for learning the directionality of non-directional inference rules like those produced by DIRT. LEDIR implements a Directionality Hypothesis: when two binary semantic relations tend to occur in similar contexts and the first one occurs in significantly more contexts than the second, then the second most likely implies the first and not vice versa. Weeds and Weir (2003) proposed a general framework for distributional similarity that mainly consists of the notions of what they call Precision (defined below) and Recall: Precision(l, r) = EE f∈Fl wi F (f) ) where l and r are the targets of a similarity measurement, Fs is s’s feature vector, and ws(f) is the weight of f E Fs. The best performing weight is PMI. Precision is a directional similarity measure that examines the coverage of l’s features by those of r’s, with more coverage indicating more similarity. Szpektor and Dagan (2008) proposed a directional similarity measure called BInc (BalancedInclusion) tha</context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2003), pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Maria Teresa Pazienza</author>
</authors>
<title>Discovering asymmetric entailment relations between verbs using selectional preferences.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics and 21th International Conference on Computational Linguistics (COLING-ACL2006),</booktitle>
<pages>849--856</pages>
<contexts>
<context position="9670" citStr="Zanzotto et al. (2006)" startWordPosition="1557" endWordPosition="1560">s, and thus the advantage of unary templates is obvious. As shown in §4, our method outperforms Lin, Precision, and BInc in accuracy. Szpector et al. (2004) addressed broad coverage entailment acquisition. But their method requires an existing lexicon to start, while ours does not. Apart from the dichotomy of the comparable corpora and the distributional similarity approaches, Torisawa (2006) exploited the structure of Japanese coordinated sentences to acquire verb entailment pairs. Pekar (2006) used the local structure of coherent text by identifying related clauses within a local discourse. Zanzotto et al. (2006) exploited agentive nouns. For example, they acquired win —*play from “the player wins.” Geffet and Dagan (2005) proposed the Distributional Inclusion Hypotheses, which claimed that if a word v entails another word w, then all the characteristic features of v are expected to appear with w, and vice versa. They applied this to noun entailment pair acquisition, rather than verb pairs. 3 Proposed Method This section presents our method of verb entailment acquisition. First, the basics of Japanese are described. Then, we present the directional similarity measure that we developed in §3.2. §3.3 de</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Pazienza, 2006</marker>
<rawString>Fabio Massimo Zanzotto, Marco Pennacchiotti, and Maria Teresa Pazienza. 2006. Discovering asymmetric entailment relations between verbs using selectional preferences. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics and 21th International Conference on Computational Linguistics (COLING-ACL2006), pages 849–856.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>