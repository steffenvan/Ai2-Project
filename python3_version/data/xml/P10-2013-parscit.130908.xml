<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003160">
<title confidence="0.9958145">
The Manually Annotated Sub-Corpus:
A Community Resource For and By the People
</title>
<author confidence="0.998176">
Nancy Ide
</author>
<affiliation confidence="0.83984">
Department of Computer Science
Vassar College
</affiliation>
<address confidence="0.78088">
Poughkeepsie, NY, USA
</address>
<email confidence="0.995997">
ide@cs.vassar.edu
</email>
<author confidence="0.990451">
Christiane Fellbaum
</author>
<affiliation confidence="0.9475605">
Princeton University
Princeton, New Jersey USA
</affiliation>
<email confidence="0.998382">
fellbaum@princeton.edu
</email>
<sectionHeader confidence="0.99384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999764173913044">
The Manually Annotated Sub-Corpus
(MASC) project provides data and annota-
tions to serve as the base for a community-
wide annotation effort of a subset of the
American National Corpus. The MASC
infrastructure enables the incorporation of
contributed annotations into a single, us-
able format that can then be analyzed as
it is or ported to any of a variety of other
formats. MASC includes data from a
much wider variety of genres than exist-
ing multiply-annotated corpora of English,
and the project is committed to a fully
open model of distribution, without re-
striction, for all data and annotations pro-
duced or contributed. As such, MASC
is the first large-scale, open, community-
based effort to create much needed lan-
guage resources for NLP. This paper de-
scribes the MASC project, its corpus and
annotations, and serves as a call for con-
tributions of data and annotations from the
language processing community.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923333333333">
The need for corpora annotated for multiple phe-
nomena across a variety of linguistic layers is
keenly recognized in the computational linguistics
community. Several multiply-annotated corpora
exist, especially for Western European languages
and for spoken data, but, interestingly, broad-
based English language corpora with robust anno-
tation for diverse linguistic phenomena are rela-
tively rare. The most widely-used corpus of En-
glish, the British National Corpus, contains only
part-of-speech annotation; and although it con-
tains a wider range of annotation types, the fif-
</bodyText>
<note confidence="0.629855333333333">
Collin Baker
International Computer Science Institute
Berkeley, California USA
</note>
<email confidence="0.882047">
collinb@icsi.berkeley.edu
</email>
<author confidence="0.898686">
Rebecca Passonneau
</author>
<affiliation confidence="0.958154">
Columbia University
</affiliation>
<address confidence="0.869894">
New York, New York USA
</address>
<email confidence="0.99605">
becky@cs.columbia.edu
</email>
<bodyText confidence="0.999884947368421">
teen million word Open American National Cor-
pus annotations are largely unvalidated. The most
well-known multiply-annotated and validated cor-
pus of English is the one million word Wall Street
Journal corpus known as the Penn Treebank (Mar-
cus et al., 1993), which over the years has been
fully or partially annotated for several phenomena
over and above the original part-of-speech tagging
and phrase structure annotation. The usability of
these annotations is limited, however, by the fact
that many of them were produced by independent
projects using their own tools and formats, mak-
ing it difficult to combine them in order to study
their inter-relations. More recently, the OntoNotes
project (Pradhan et al., 2007) released a one mil-
lion word English corpus of newswire, broadcast
news, and broadcast conversation that is annotated
for Penn Treebank syntax, PropBank predicate ar-
gument structures, coreference, and named enti-
ties. OntoNotes comes closest to providing a cor-
pus with multiple layers of annotation that can be
analyzed as a unit via its representation of the an-
notations in a “normal form”. However, like the
Wall Street Journal corpus, OntoNotes is limited
in the range of genres it includes. It is also limited
to only those annotations that may be produced by
members of the OntoNotes project. In addition,
use of the data and annotations with software other
than the OntoNotes database API is not necessar-
ily straightforward.
The sparseness of reliable multiply-annotated
corpora can be attributed to several factors. The
greatest obstacle is the high cost of manual pro-
duction and validation of linguistic annotations.
Furthermore, the production and annotation of
corpora, even when they involve significant scien-
tific research, often do not, per se, lead to publish-
able research results. It is therefore understand-
</bodyText>
<page confidence="0.993047">
68
</page>
<note confidence="0.506114">
Proceedings of the ACL 2010 Conference Short Papers, pages 68–73,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.998668119047619">
able that many research groups are unwilling to
get involved in such a massive undertaking for rel-
atively little reward.
The Manually Annotated Sub-Corpus
(MASC) (Ide et al., 2008) project has been
established to address many of these obstacles
to the creation of large-scale, robust, multiply-
annotated corpora. The project is providing
appropriate data and annotations to serve as the
base for a community-wide annotation effort,
together with an infrastructure that enables the
representation of internally-produced and con-
tributed annotations in a single, usable format
that can then be analyzed as it is or ported to any
of a variety of other formats, thus enabling its
immediate use with many common annotation
platforms as well as off-the-shelf concordance
and analysis software. The MASC project’s aim is
to offset some of the high costs of producing high
quality linguistic annotations via a distribution of
effort, and to solve some of the usability problems
for annotations produced at different sites by
harmonizing their representation formats.
The MASC project provides a resource that is
significantly different from OntoNotes and simi-
lar corpora. It provides data from a much wider
variety of genres than existing multiply-annotated
corpora of English, and all of the data in the cor-
pus are drawn from current American English so
as to be most useful for NLP applications. Per-
haps most importantly, the MASC project is com-
mitted to a fully open model of distribution, with-
out restriction, for all data and annotations. It is
also committed to incorporating diverse annota-
tions contributed by the community, regardless of
format, into the corpus. As such, MASC is the
first large-scale, open, community-based effort to
create a much-needed language resource for NLP.
This paper describes the MASC project, its corpus
and annotations, and serves as a call for contribu-
tions of data and annotations from the language
processing community.
</bodyText>
<sectionHeader confidence="0.987663" genericHeader="method">
2 MASC: The Corpus
</sectionHeader>
<bodyText confidence="0.996931166666667">
MASC is a balanced subset of 500K words of
written texts and transcribed speech drawn pri-
marily from the Open American National Corpus
(OANC)1. The OANC is a 15 million word (and
growing) corpus of American English produced
since 1990, all of which is in the public domain
</bodyText>
<footnote confidence="0.99446">
1http://www.anc.org
</footnote>
<table confidence="0.999750133333334">
Genre No. texts Total words
Email 2 468
Essay 4 17516
Fiction 4 20413
Gov’t documents 1 6064
Journal 10 25635
Letters 31 10518
Newspaper/newswire 41 17951
Non-fiction 4 17118
Spoken 11 25783
Debate transcript 2 32325
Court transcript 1 20817
Technical 3 15417
Travel guides 4 12463
Total 118 222488
</table>
<tableCaption confidence="0.999321">
Table 1: MASC Composition (first 220K)
</tableCaption>
<bodyText confidence="0.999887592592593">
or otherwise free of usage and redistribution re-
strictions.
Where licensing permits, data for inclusion in
MASC is drawn from sources that have already
been heavily annotated by others. So far, the
first 80K increment of MASC data includes a
40K subset consisting of OANC data that has
been previously annotated for PropBank predi-
cate argument structures, Pittsburgh Opinion an-
notation (opinions, evaluations, sentiments, etc.),
TimeML time and events2, and several other lin-
guistic phenomena. It also includes a handful of
small texts from the so-called Language Under-
standing (LU) Corpus3 that has been annotated by
multiple groups for a wide variety of phenomena,
including events and committed belief. All of the
first 80K increment is annotated for Penn Tree-
bank syntax. The second 120K increment includes
5.5K words of Wall Street Journal texts that have
been annotated by several projects, including Penn
Treebank, PropBank, Penn Discourse Treebank,
TimeML, and the Pittsburgh Opinion project. The
composition of the 220K portion of the corpus an-
notated so far is shown in Table 1. The remain-
ing 280K of the corpus fills out the genres that are
under-represented in the first portion and includes
a few additional genres such as blogs and tweets.
</bodyText>
<sectionHeader confidence="0.998148" genericHeader="method">
3 MASC Annotations
</sectionHeader>
<bodyText confidence="0.997157">
Annotations for a variety of linguistic phenomena,
either manually produced or corrected from output
of automatic annotation systems, are being added
</bodyText>
<footnote confidence="0.9906748">
2The TimeML annotations of the data are not yet com-
pleted.
3MASC contains about 2K words of the 10K LU corpus,
eliminating non-English and translated LU texts as well as
texts that are not free of usage and redistribution restrictions.
</footnote>
<page confidence="0.995221">
69
</page>
<table confidence="0.999912411764706">
Annotation type Method No. texts No. words
Token Validated 118 222472
Sentence Validated 118 222472
POS/lemma Validated 118 222472
Noun chunks Validated 118 222472
Verb chunks Validated 118 222472
Named entities Validated 118 222472
FrameNet frames Manual 21 17829
HSPG Validated 40* 30106
Discourse Manual 40* 30106
Penn Treebank Validated 97 87383
PropBank Validated 92 50165
Opinion Manual 97 47583
TimeBank Validated 34 5434
Committed belief Manual 13 4614
Event Manual 13 4614
Coreference Manual 2 1877
</table>
<tableCaption confidence="0.999565">
Table 2: Current MASC Annotations (* projected)
</tableCaption>
<bodyText confidence="0.959526387096774">
to MASC data in increments of roughly 100K
words. To date, validated or manually produced
annotations for 222K words have been made avail-
able.
The MASC project is itself producing annota-
tions for portions of the corpus for WordNet senses
and FrameNet frames and frame elements. To de-
rive maximal benefit from the semantic informa-
tion provided by these resources, the entire cor-
pus is also annotated and manually validated for
shallow parses (noun and verb chunks) and named
entities (person, location, organization, date and
time). Several additional types of annotation have
either been contracted by the MASC project or
contributed from other sources. The 220K words
of MASC I and II include seventeen different types
of linguistic annotation4, shown in Table 2.
All MASC annotations, whether contributed or
produced in-house, are transduced to the Graph
Annotation Framework (GrAF) (Ide and Suder-
man, 2007) defined by ISO TC37 SC4’s Linguistic
Annotation Framework (LAF) (Ide and Romary,
2004). GrAF is an XML serialization of the LAF
abstract model of annotations, which consists of
a directed graph decorated with feature structures
providing the annotation content. GrAF’s primary
role is to serve as a “pivot” format for transducing
among annotations represented in different for-
mats. However, because the underlying data struc-
ture is a graph, the GrAF representation itself can
serve as the basis for analysis via application of
</bodyText>
<footnote confidence="0.9763225">
4This includes WordNet sense annotations, which are not
listed in Table 2 because they are not applied to full texts; see
Section 3.1 for a description of the WordNet sense annota-
tions in MASC.
</footnote>
<bodyText confidence="0.99946572">
graph-analytic algorithms such as common sub-
tree detection.
The layering of annotations over MASC texts
dictates the use of a stand-off annotation repre-
sentation format, in which each annotation is con-
tained in a separate document linked to the pri-
mary data. Each text in the corpus is provided in
UTF-8 character encoding in a separate file, which
includes no annotation or markup of any kind.
Each file is associated with a set of GrAF standoff
files, one for each annotation type, containing the
annotations for that text. In addition to the anno-
tation types listed in Table 2, a document contain-
ing annotation for logical structure (titles, head-
ings, sections, etc. down to the level of paragraph)
is included. Each text is also associated with
(1) a header document that provides appropriate
metadata together with machine-processable in-
formation about associated annotations and inter-
relations among the annotation layers; and (2) a
segmentation of the primary data into minimal re-
gions, which enables the definition of different to-
kenizations over the text. Contributed annotations
are also included in their original format, where
available.
</bodyText>
<subsectionHeader confidence="0.997701">
3.1 WordNet Sense Annotations
</subsectionHeader>
<bodyText confidence="0.9999715">
A focus of the MASC project is to provide corpus
evidence to support an effort to harmonize sense
distinctions in WordNet and FrameNet (Baker and
Fellbaum, 2009), (Fellbaum and Baker, to appear).
The WordNet and FrameNet teams have selected
for this purpose 100 common polysemous words
whose senses they will study in detail, and the
MASC team is annotating occurrences of these
words in the MASC. As a first step, fifty oc-
currences of each word are annotated using the
WordNet 3.0 inventory and analyzed for prob-
lems in sense assignment, after which the Word-
Net team may make modifications to the inven-
tory if needed. The revised inventory (which will
be released as part of WordNet 3.1) is then used to
annotate 1000 occurrences. Because of its small
size, MASC typically contains less than 1000 oc-
currences of a given word; the remaining occur-
rences are therefore drawn from the 15 million
words of the OANC. Furthermore, the FrameNet
team is also annotating one hundred of the 1000
sentences for each word with FrameNet frames
and frame elements, providing direct comparisons
of WordNet and FrameNet sense assignments in
</bodyText>
<page confidence="0.975026">
70
</page>
<bodyText confidence="0.95508475">
attested sentences.5
For convenience, the annotated sentences are
provided as a stand-alone corpus, with the Word-
Net and FrameNet annotations represented in
standoff files. Each sentence in this corpus is
linked to its occurrence in the original text, so that
the context and other annotations associated with
the sentence may be retrieved.
</bodyText>
<subsectionHeader confidence="0.998958">
3.2 Validation
</subsectionHeader>
<bodyText confidence="0.999938611111111">
Automatically-produced annotations for sentence,
token, part of speech, shallow parses (noun and
verb chunks), and named entities (person, lo-
cation, organization, date and time) are hand-
validated by a team of students. Each annotation
set is first corrected by one student, after which it
is checked (and corrected where necessary) by a
second student, and finally checked by both auto-
matic extraction of the annotated data and a third
pass over the annotations by a graduate student
or senior researcher. We have performed inter-
annotator agreement studies for shallow parses in
order to establish the number of passes required to
achieve near-100% accuracy.
Annotations produced by other projects and
the FrameNet and Penn Treebank annotations
produced specifically for MASC are semi-
automatically and/or manually produced by those
projects and subjected to their internal quality con-
trols. No additional validation is performed by the
ANC project.
The WordNet sense annotations are being used
as a base for an extensive inter-annotator agree-
ment study, which is described in detail in (Pas-
sonneau et al., 2009), (Passonneau et al., 2010).
All inter-annotator agreement data and statistics
are published along with the sense tags. The re-
lease also includes documentation on the words
annotated in each round, the sense labels for each
word, the sentences for each word, and the anno-
tator or annotators for each sense assignment to
each word in context. For the multiply annotated
data in rounds 2-4, we include raw tables for each
word in the form expected by Ron Artstein’s cal-
culate alpha.pl perl script6, so that the agreement
numbers can be regenerated.
</bodyText>
<footnote confidence="0.99848325">
5Note that several MASC texts have been fully annotated
for FrameNet frames and frame elements, in addition to the
WordNet-tagged sentences.
6http://ron.artstein.org/resources/calculate-alpha.perl
</footnote>
<sectionHeader confidence="0.636374" genericHeader="method">
4 MASC Availability and Distribution
</sectionHeader>
<bodyText confidence="0.999914875">
Like the OANC, MASC is distributed without
license or other restrictions from the American
National Corpus website7. It is also available
from the Linguistic Data Consortium (LDC)8 for
a nominal processing fee.
In addition to enabling download of the entire
MASC, we provide a web application that allows
users to select some or all parts of the corpus and
choose among the available annotations via a web
interface (Ide et al., 2010). Once generated, the
corpus and annotation bundle is made available to
the user for download. Thus, the MASC user need
never deal directly with or see the underlying rep-
resentation of the stand-off annotations, but gains
all the advantages that representation offers. The
following output formats are currently available:
</bodyText>
<listItem confidence="0.977032272727273">
1. in-line XML (XCES9), suitable for use with
the BNCs XAIRA search and access inter-
face and other XML-aware software;
2. token / part of speech, a common input for-
mat for general-purpose concordance soft-
ware such as MonoConc10, as well as the
Natural Language Toolkit (NLTK) (Bird et
al., 2009);
3. CONLL IOB format, used in the Confer-
ence on Natural Language Learning shared
tasks.11
</listItem>
<sectionHeader confidence="0.971002" genericHeader="method">
5 Tools
</sectionHeader>
<bodyText confidence="0.999925846153846">
The ANC project provides an API for GrAF an-
notations that can be used to access and manip-
ulate GrAF annotations directly from Java pro-
grams and render GrAF annotations in a format
suitable for input to the open source GraphViz12
graph visualization application.13 Beyond this, the
ANC project does not provide specific tools for
use of the corpus, but rather provides the data in
formats suitable for use with a variety of available
applications, as described in section 4, together
with means to import GrAF annotations into ma-
jor annotation software platforms. In particular,
the ANC project provides plugins for the General
</bodyText>
<footnote confidence="0.999923571428571">
7http://www.anc.org
8http://www.ldc.upenn.edu
9XML Corpus Encoding Standard, http://www.xces.org
10http://www.athel.com/mono.html
11http://ifarm.nl/signll/conll
12http://www.graphviz.org/
13http://www.anc.org/graf-api
</footnote>
<page confidence="0.998847">
71
</page>
<bodyText confidence="0.99996824137931">
Architecture for Text Engineering (GATE) (Cun-
ningham et al., 2002) to input and/or output an-
notations in GrAF format; a “CAS Consumer”
to enable using GrAF annotations in the Un-
structured Information Management Architecture
(UIMA) (Ferrucci and Lally, 2004); and a corpus
reader for importing MASC data and annotations
into NLTK14.
Because the GrAF format is isomorphic to in-
put to many graph-analytic tools, existing graph-
analytic software can also be exploited to search
and manipulate MASC annotations. Trivial merg-
ing of GrAF-based annotations involves simply
combining the graphs for each annotation, after
which graph minimization algorithms15 can be ap-
plied to collapse nodes with edges to common
subgraphs to identify commonly annotated com-
ponents. Graph-traversal and graph-coloring al-
gorithms can also be applied in order to iden-
tify and generate statistics that could reveal in-
teractions among linguistic phenomena that may
have previously been difficult to observe. Other
graph-analytic algorithms — including common
sub-graph analysis, shortest paths, minimum span-
ning trees, connectedness, identification of artic-
ulation vertices, topological sort, graph partition-
ing, etc. — may also prove to be useful for mining
information from a graph of annotations at multi-
ple linguistic levels.
</bodyText>
<sectionHeader confidence="0.998777" genericHeader="method">
6 Community Contributions
</sectionHeader>
<bodyText confidence="0.999890823529412">
The ANC project solicits contributions of anno-
tations of any kind, applied to any part or all of
the MASC data. Annotations may be contributed
in any format, either inline or standoff. All con-
tributed annotations are ported to GrAF standoff
format so that they may be used with other MASC
annotations and rendered in the various formats
the ANC tools generate. To accomplish this, the
ANC project has developed a suite of internal tools
and methods for automatically transducing other
annotation formats to GrAF and for rapid adapta-
tion of previously unseen formats.
Contributions may be emailed to
anc@cs.vassar.edu or uploaded via the
ANC website16. The validity of annotations
and supplemental documentation (if appropriate)
are the responsibility of the contributor. MASC
</bodyText>
<footnote confidence="0.922705">
14Available in September, 2010.
15Efficient algorithms for graph merging exist; see,
e.g., (Habib et al., 2000).
16http://www.anc.org/contributions.html
</footnote>
<bodyText confidence="0.998261454545455">
users may contribute evaluations and error reports
for the various annotations on the ANC/MASC
wiki17.
Contributions of unvalidated annotations for
MASC and OANC data are also welcomed and are
distributed separately. Contributions of unencum-
bered texts in any genre, including stories, papers,
student essays, poetry, blogs, and email, are also
solicited via the ANC web site and the ANC Face-
Book page18, and may be uploaded at the contri-
bution page cited above.
</bodyText>
<sectionHeader confidence="0.99837" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999940181818182">
MASC is already the most richly annotated corpus
of English available for widespread use. Because
the MASC is an open resource that the commu-
nity can continually enhance with additional an-
notations and modifications, the project serves as a
model for community-wide resource development
in the future. Past experience with corpora such
as the Wall Street Journal shows that the commu-
nity is eager to annotate available language data,
and we anticipate even greater interest in MASC,
which includes language data covering a range of
genres that no existing resource provides. There-
fore, we expect that as MASC evolves, more and
more annotations will be contributed, thus creat-
ing a massive, inter-linked linguistic infrastructure
for the study and processing of current American
English in its many genres and varieties. In addi-
tion, by virtue of its WordNet and FrameNet anno-
tations, MASC will be linked to parallel WordNets
and FrameNets in languages other than English,
thus creating a global resource for multi-lingual
technologies, including machine translation.
</bodyText>
<sectionHeader confidence="0.997501" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99265875">
The MASC project is supported by National
Science Foundation grant CRI-0708952. The
WordNet-FrameNet alignment work is supported
by NSF grant IIS 0705155.
</bodyText>
<sectionHeader confidence="0.995047" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.762055666666667">
Collin F. Baker and Christiane Fellbaum. 2009. Word-
Net and FrameNet as complementary resources for
annotation. In Proceedings of the Third Linguistic
</reference>
<footnote confidence="0.682947666666667">
17http://www.anc.org/masc-wiki
18http://www.facebook.com/pages/American-National-
Corpus/42474226671
</footnote>
<page confidence="0.990925">
72
</page>
<reference confidence="0.999686606060606">
Annotation Workshop, pages 125–129, Suntec, Sin-
gapore, August. Association for Computational Lin-
guistics.
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python.
O’Reilly Media, 1st edition.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. GATE: A
framework and graphical development environment
for robust nlp tools and applications. In Proceedings
of ACL’02.
Christiane Fellbaum and Collin Baker. to appear.
Aligning verbs in WordNet and FrameNet. Linguis-
tics.
David Ferrucci and Adam Lally. 2004. UIMA: An
architectural approach to unstructured information
processing in the corporate research environment.
Natural Language Engineering, 10(3-4):327–348.
Michel Habib, Christophe Paul, and Laurent Viennot.
2000. Partition refinement techniques: an interest-
ing algorithmic tool kit. International Journal of
Foundations of Computer Science, 175.
Nancy Ide and Laurent Romary. 2004. International
standard for a linguistic annotation framework. Nat-
ural Language Engineering, 10(3-4):211–225.
Nancy Ide and Keith Suderman. 2007. GrAF: A graph-
based format for linguistic annotations. In Proceed-
ings of the Linguistic Annotation Workshop, pages
1–8, Prague, Czech Republic, June. Association for
Computational Linguistics.
Nancy Ide, Collin Baker, Christiane Fellbaum, Charles
Fillmore, and Rebecca Passonneau. 2008. MASC:
The Manually Annotated Sub-Corpus of American
English. In Proceedings of the Sixth International
Conference on Language Resources and Evaluation
(LREC), Marrakech, Morocco.
Nancy Ide, Keith Suderman, and Brian Simms. 2010.
ANC2Go: A web application for customized cor-
pus creation. In Proceedings of the Seventh Interna-
tional Conference on Language Resources and Eval-
uation (LREC), Valletta, Malta, May. European Lan-
guage Resources Association.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of English: the Penn Treebank. Com-
putational Linguistics, 19(2):313–330.
Rebecca J. Passonneau, Ansaf Salleb-Aouissi, and
Nancy Ide. 2009. Making sense of word sense
variation. In SEW ’09: Proceedings of the Work-
shop on Semantic Evaluations: Recent Achieve-
ments and Future Directions, pages 2–9, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Rebecca Passonneau, Ansaf Salleb-Aouissi, Vikas
Bhardwaj, and Nancy Ide. 2010. Word sense an-
notation of polysemous words by multiple annota-
tors. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC), Valletta, Malta.
Sameer S. Pradhan, Eduard Hovy, Mitch Mar-
cus, Martha Palmer, Lance Ramshaw, and Ralph
Weischedel. 2007. OntoNotes: A unified relational
semantic representation. In ICSC ’07: Proceed-
ings of the International Conference on Semantic
Computing, pages 517–526, Washington, DC, USA.
IEEE Computer Society.
</reference>
<page confidence="0.99929">
73
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912351">
<title confidence="0.9987425">The Manually Annotated Sub-Corpus: A Community Resource For and By the People</title>
<author confidence="0.999451">Nancy Ide</author>
<affiliation confidence="0.994615">Department of Computer Science Vassar College</affiliation>
<address confidence="0.980802">Poughkeepsie, NY, USA</address>
<email confidence="0.99937">ide@cs.vassar.edu</email>
<author confidence="0.96648">Christiane Fellbaum</author>
<affiliation confidence="0.999975">Princeton University</affiliation>
<address confidence="0.982965">Princeton, New Jersey USA</address>
<email confidence="0.999922">fellbaum@princeton.edu</email>
<abstract confidence="0.999712833333333">The Manually Annotated Sub-Corpus (MASC) project provides data and annotations to serve as the base for a communitywide annotation effort of a subset of the American National Corpus. The MASC infrastructure enables the incorporation of contributed annotations into a single, usable format that can then be analyzed as it is or ported to any of a variety of other formats. MASC includes data from a much wider variety of genres than existing multiply-annotated corpora of English, and the project is committed to a fully open model of distribution, without restriction, for all data and annotations produced or contributed. As such, MASC is the first large-scale, open, communitybased effort to create much needed language resources for NLP. This paper describes the MASC project, its corpus and annotations, and serves as a call for contributions of data and annotations from the language processing community.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet and FrameNet as complementary resources for annotation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop,</booktitle>
<pages>125--129</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="11741" citStr="Baker and Fellbaum, 2009" startWordPosition="1840" endWordPosition="1843">ach text is also associated with (1) a header document that provides appropriate metadata together with machine-processable information about associated annotations and interrelations among the annotation layers; and (2) a segmentation of the primary data into minimal regions, which enables the definition of different tokenizations over the text. Contributed annotations are also included in their original format, where available. 3.1 WordNet Sense Annotations A focus of the MASC project is to provide corpus evidence to support an effort to harmonize sense distinctions in WordNet and FrameNet (Baker and Fellbaum, 2009), (Fellbaum and Baker, to appear). The WordNet and FrameNet teams have selected for this purpose 100 common polysemous words whose senses they will study in detail, and the MASC team is annotating occurrences of these words in the MASC. As a first step, fifty occurrences of each word are annotated using the WordNet 3.0 inventory and analyzed for problems in sense assignment, after which the WordNet team may make modifications to the inventory if needed. The revised inventory (which will be released as part of WordNet 3.1) is then used to annotate 1000 occurrences. Because of its small size, MA</context>
</contexts>
<marker>Baker, Fellbaum, 2009</marker>
<rawString>Collin F. Baker and Christiane Fellbaum. 2009. WordNet and FrameNet as complementary resources for annotation. In Proceedings of the Third Linguistic Annotation Workshop, pages 125–129, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media, 1st edition.</booktitle>
<contexts>
<context position="16008" citStr="Bird et al., 2009" startWordPosition="2520" endWordPosition="2523">. Once generated, the corpus and annotation bundle is made available to the user for download. Thus, the MASC user need never deal directly with or see the underlying representation of the stand-off annotations, but gains all the advantages that representation offers. The following output formats are currently available: 1. in-line XML (XCES9), suitable for use with the BNCs XAIRA search and access interface and other XML-aware software; 2. token / part of speech, a common input format for general-purpose concordance software such as MonoConc10, as well as the Natural Language Toolkit (NLTK) (Bird et al., 2009); 3. CONLL IOB format, used in the Conference on Natural Language Learning shared tasks.11 5 Tools The ANC project provides an API for GrAF annotations that can be used to access and manipulate GrAF annotations directly from Java programs and render GrAF annotations in a format suitable for input to the open source GraphViz12 graph visualization application.13 Beyond this, the ANC project does not provide specific tools for use of the corpus, but rather provides the data in formats suitable for use with a variety of available applications, as described in section 4, together with means to impo</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. O’Reilly Media, 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
</authors>
<title>GATE: A framework and graphical development environment for robust nlp tools and applications.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02.</booktitle>
<contexts>
<context position="17021" citStr="Cunningham et al., 2002" startWordPosition="2661" endWordPosition="2665">ct does not provide specific tools for use of the corpus, but rather provides the data in formats suitable for use with a variety of available applications, as described in section 4, together with means to import GrAF annotations into major annotation software platforms. In particular, the ANC project provides plugins for the General 7http://www.anc.org 8http://www.ldc.upenn.edu 9XML Corpus Encoding Standard, http://www.xces.org 10http://www.athel.com/mono.html 11http://ifarm.nl/signll/conll 12http://www.graphviz.org/ 13http://www.anc.org/graf-api 71 Architecture for Text Engineering (GATE) (Cunningham et al., 2002) to input and/or output annotations in GrAF format; a “CAS Consumer” to enable using GrAF annotations in the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004); and a corpus reader for importing MASC data and annotations into NLTK14. Because the GrAF format is isomorphic to input to many graph-analytic tools, existing graphanalytic software can also be exploited to search and manipulate MASC annotations. Trivial merging of GrAF-based annotations involves simply combining the graphs for each annotation, after which graph minimization algorithms15 can be applied t</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: A framework and graphical development environment for robust nlp tools and applications. In Proceedings of ACL’02.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Christiane Fellbaum</author>
<author>Collin Baker</author>
</authors>
<title>to appear. Aligning verbs in WordNet and FrameNet.</title>
<publisher>Linguistics.</publisher>
<marker>Fellbaum, Baker, </marker>
<rawString>Christiane Fellbaum and Collin Baker. to appear. Aligning verbs in WordNet and FrameNet. Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>UIMA: An architectural approach to unstructured information processing in the corporate research environment.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--3</pages>
<contexts>
<context position="17212" citStr="Ferrucci and Lally, 2004" startWordPosition="2691" endWordPosition="2694">er with means to import GrAF annotations into major annotation software platforms. In particular, the ANC project provides plugins for the General 7http://www.anc.org 8http://www.ldc.upenn.edu 9XML Corpus Encoding Standard, http://www.xces.org 10http://www.athel.com/mono.html 11http://ifarm.nl/signll/conll 12http://www.graphviz.org/ 13http://www.anc.org/graf-api 71 Architecture for Text Engineering (GATE) (Cunningham et al., 2002) to input and/or output annotations in GrAF format; a “CAS Consumer” to enable using GrAF annotations in the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004); and a corpus reader for importing MASC data and annotations into NLTK14. Because the GrAF format is isomorphic to input to many graph-analytic tools, existing graphanalytic software can also be exploited to search and manipulate MASC annotations. Trivial merging of GrAF-based annotations involves simply combining the graphs for each annotation, after which graph minimization algorithms15 can be applied to collapse nodes with edges to common subgraphs to identify commonly annotated components. Graph-traversal and graph-coloring algorithms can also be applied in order to identify and generate </context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>David Ferrucci and Adam Lally. 2004. UIMA: An architectural approach to unstructured information processing in the corporate research environment. Natural Language Engineering, 10(3-4):327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Habib</author>
<author>Christophe Paul</author>
<author>Laurent Viennot</author>
</authors>
<title>Partition refinement techniques: an interesting algorithmic tool kit.</title>
<date>2000</date>
<journal>International Journal of Foundations of Computer Science,</journal>
<volume>175</volume>
<contexts>
<context position="19168" citStr="Habib et al., 2000" startWordPosition="2987" endWordPosition="2990">used with other MASC annotations and rendered in the various formats the ANC tools generate. To accomplish this, the ANC project has developed a suite of internal tools and methods for automatically transducing other annotation formats to GrAF and for rapid adaptation of previously unseen formats. Contributions may be emailed to anc@cs.vassar.edu or uploaded via the ANC website16. The validity of annotations and supplemental documentation (if appropriate) are the responsibility of the contributor. MASC 14Available in September, 2010. 15Efficient algorithms for graph merging exist; see, e.g., (Habib et al., 2000). 16http://www.anc.org/contributions.html users may contribute evaluations and error reports for the various annotations on the ANC/MASC wiki17. Contributions of unvalidated annotations for MASC and OANC data are also welcomed and are distributed separately. Contributions of unencumbered texts in any genre, including stories, papers, student essays, poetry, blogs, and email, are also solicited via the ANC web site and the ANC FaceBook page18, and may be uploaded at the contribution page cited above. 7 Conclusion MASC is already the most richly annotated corpus of English available for widespre</context>
</contexts>
<marker>Habib, Paul, Viennot, 2000</marker>
<rawString>Michel Habib, Christophe Paul, and Laurent Viennot. 2000. Partition refinement techniques: an interesting algorithmic tool kit. International Journal of Foundations of Computer Science, 175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Laurent Romary</author>
</authors>
<title>International standard for a linguistic annotation framework.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--3</pages>
<contexts>
<context position="9765" citStr="Ide and Romary, 2004" startWordPosition="1523" endWordPosition="1526">orpus is also annotated and manually validated for shallow parses (noun and verb chunks) and named entities (person, location, organization, date and time). Several additional types of annotation have either been contracted by the MASC project or contributed from other sources. The 220K words of MASC I and II include seventeen different types of linguistic annotation4, shown in Table 2. All MASC annotations, whether contributed or produced in-house, are transduced to the Graph Annotation Framework (GrAF) (Ide and Suderman, 2007) defined by ISO TC37 SC4’s Linguistic Annotation Framework (LAF) (Ide and Romary, 2004). GrAF is an XML serialization of the LAF abstract model of annotations, which consists of a directed graph decorated with feature structures providing the annotation content. GrAF’s primary role is to serve as a “pivot” format for transducing among annotations represented in different formats. However, because the underlying data structure is a graph, the GrAF representation itself can serve as the basis for analysis via application of 4This includes WordNet sense annotations, which are not listed in Table 2 because they are not applied to full texts; see Section 3.1 for a description of the </context>
</contexts>
<marker>Ide, Romary, 2004</marker>
<rawString>Nancy Ide and Laurent Romary. 2004. International standard for a linguistic annotation framework. Natural Language Engineering, 10(3-4):211–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Keith Suderman</author>
</authors>
<title>GrAF: A graphbased format for linguistic annotations.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="9678" citStr="Ide and Suderman, 2007" startWordPosition="1509" endWordPosition="1513">e maximal benefit from the semantic information provided by these resources, the entire corpus is also annotated and manually validated for shallow parses (noun and verb chunks) and named entities (person, location, organization, date and time). Several additional types of annotation have either been contracted by the MASC project or contributed from other sources. The 220K words of MASC I and II include seventeen different types of linguistic annotation4, shown in Table 2. All MASC annotations, whether contributed or produced in-house, are transduced to the Graph Annotation Framework (GrAF) (Ide and Suderman, 2007) defined by ISO TC37 SC4’s Linguistic Annotation Framework (LAF) (Ide and Romary, 2004). GrAF is an XML serialization of the LAF abstract model of annotations, which consists of a directed graph decorated with feature structures providing the annotation content. GrAF’s primary role is to serve as a “pivot” format for transducing among annotations represented in different formats. However, because the underlying data structure is a graph, the GrAF representation itself can serve as the basis for analysis via application of 4This includes WordNet sense annotations, which are not listed in Table </context>
</contexts>
<marker>Ide, Suderman, 2007</marker>
<rawString>Nancy Ide and Keith Suderman. 2007. GrAF: A graphbased format for linguistic annotations. In Proceedings of the Linguistic Annotation Workshop, pages 1–8, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Collin Baker</author>
<author>Christiane Fellbaum</author>
<author>Charles Fillmore</author>
<author>Rebecca Passonneau</author>
</authors>
<title>MASC: The Manually Annotated Sub-Corpus of American English.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="4130" citStr="Ide et al., 2008" startWordPosition="627" endWordPosition="630">bstacle is the high cost of manual production and validation of linguistic annotations. Furthermore, the production and annotation of corpora, even when they involve significant scientific research, often do not, per se, lead to publishable research results. It is therefore understand68 Proceedings of the ACL 2010 Conference Short Papers, pages 68–73, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics able that many research groups are unwilling to get involved in such a massive undertaking for relatively little reward. The Manually Annotated Sub-Corpus (MASC) (Ide et al., 2008) project has been established to address many of these obstacles to the creation of large-scale, robust, multiplyannotated corpora. The project is providing appropriate data and annotations to serve as the base for a community-wide annotation effort, together with an infrastructure that enables the representation of internally-produced and contributed annotations in a single, usable format that can then be analyzed as it is or ported to any of a variety of other formats, thus enabling its immediate use with many common annotation platforms as well as off-the-shelf concordance and analysis soft</context>
</contexts>
<marker>Ide, Baker, Fellbaum, Fillmore, Passonneau, 2008</marker>
<rawString>Nancy Ide, Collin Baker, Christiane Fellbaum, Charles Fillmore, and Rebecca Passonneau. 2008. MASC: The Manually Annotated Sub-Corpus of American English. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Keith Suderman</author>
<author>Brian Simms</author>
</authors>
<title>ANC2Go: A web application for customized corpus creation.</title>
<date>2010</date>
<journal>European Language Resources Association.</journal>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Valletta, Malta,</location>
<contexts>
<context position="15390" citStr="Ide et al., 2010" startWordPosition="2420" endWordPosition="2423">ated for FrameNet frames and frame elements, in addition to the WordNet-tagged sentences. 6http://ron.artstein.org/resources/calculate-alpha.perl 4 MASC Availability and Distribution Like the OANC, MASC is distributed without license or other restrictions from the American National Corpus website7. It is also available from the Linguistic Data Consortium (LDC)8 for a nominal processing fee. In addition to enabling download of the entire MASC, we provide a web application that allows users to select some or all parts of the corpus and choose among the available annotations via a web interface (Ide et al., 2010). Once generated, the corpus and annotation bundle is made available to the user for download. Thus, the MASC user need never deal directly with or see the underlying representation of the stand-off annotations, but gains all the advantages that representation offers. The following output formats are currently available: 1. in-line XML (XCES9), suitable for use with the BNCs XAIRA search and access interface and other XML-aware software; 2. token / part of speech, a common input format for general-purpose concordance software such as MonoConc10, as well as the Natural Language Toolkit (NLTK) (</context>
</contexts>
<marker>Ide, Suderman, Simms, 2010</marker>
<rawString>Nancy Ide, Keith Suderman, and Brian Simms. 2010. ANC2Go: A web application for customized corpus creation. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC), Valletta, Malta, May. European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="2215" citStr="Marcus et al., 1993" startWordPosition="327" endWordPosition="331">he most widely-used corpus of English, the British National Corpus, contains only part-of-speech annotation; and although it contains a wider range of annotation types, the fifCollin Baker International Computer Science Institute Berkeley, California USA collinb@icsi.berkeley.edu Rebecca Passonneau Columbia University New York, New York USA becky@cs.columbia.edu teen million word Open American National Corpus annotations are largely unvalidated. The most well-known multiply-annotated and validated corpus of English is the one million word Wall Street Journal corpus known as the Penn Treebank (Marcus et al., 1993), which over the years has been fully or partially annotated for several phenomena over and above the original part-of-speech tagging and phrase structure annotation. The usability of these annotations is limited, however, by the fact that many of them were produced by independent projects using their own tools and formats, making it difficult to combine them in order to study their inter-relations. More recently, the OntoNotes project (Pradhan et al., 2007) released a one million word English corpus of newswire, broadcast news, and broadcast conversation that is annotated for Penn Treebank sy</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passonneau</author>
<author>Ansaf Salleb-Aouissi</author>
<author>Nancy Ide</author>
</authors>
<title>Making sense of word sense variation.</title>
<date>2009</date>
<booktitle>In SEW ’09: Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions,</booktitle>
<pages>2--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="14175" citStr="Passonneau et al., 2009" startWordPosition="2229" endWordPosition="2233">senior researcher. We have performed interannotator agreement studies for shallow parses in order to establish the number of passes required to achieve near-100% accuracy. Annotations produced by other projects and the FrameNet and Penn Treebank annotations produced specifically for MASC are semiautomatically and/or manually produced by those projects and subjected to their internal quality controls. No additional validation is performed by the ANC project. The WordNet sense annotations are being used as a base for an extensive inter-annotator agreement study, which is described in detail in (Passonneau et al., 2009), (Passonneau et al., 2010). All inter-annotator agreement data and statistics are published along with the sense tags. The release also includes documentation on the words annotated in each round, the sense labels for each word, the sentences for each word, and the annotator or annotators for each sense assignment to each word in context. For the multiply annotated data in rounds 2-4, we include raw tables for each word in the form expected by Ron Artstein’s calculate alpha.pl perl script6, so that the agreement numbers can be regenerated. 5Note that several MASC texts have been fully annotat</context>
</contexts>
<marker>Passonneau, Salleb-Aouissi, Ide, 2009</marker>
<rawString>Rebecca J. Passonneau, Ansaf Salleb-Aouissi, and Nancy Ide. 2009. Making sense of word sense variation. In SEW ’09: Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 2–9, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Passonneau</author>
<author>Ansaf Salleb-Aouissi</author>
<author>Vikas Bhardwaj</author>
<author>Nancy Ide</author>
</authors>
<title>Word sense annotation of polysemous words by multiple annotators.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="14202" citStr="Passonneau et al., 2010" startWordPosition="2234" endWordPosition="2237">performed interannotator agreement studies for shallow parses in order to establish the number of passes required to achieve near-100% accuracy. Annotations produced by other projects and the FrameNet and Penn Treebank annotations produced specifically for MASC are semiautomatically and/or manually produced by those projects and subjected to their internal quality controls. No additional validation is performed by the ANC project. The WordNet sense annotations are being used as a base for an extensive inter-annotator agreement study, which is described in detail in (Passonneau et al., 2009), (Passonneau et al., 2010). All inter-annotator agreement data and statistics are published along with the sense tags. The release also includes documentation on the words annotated in each round, the sense labels for each word, the sentences for each word, and the annotator or annotators for each sense assignment to each word in context. For the multiply annotated data in rounds 2-4, we include raw tables for each word in the form expected by Ron Artstein’s calculate alpha.pl perl script6, so that the agreement numbers can be regenerated. 5Note that several MASC texts have been fully annotated for FrameNet frames and </context>
</contexts>
<marker>Passonneau, Salleb-Aouissi, Bhardwaj, Ide, 2010</marker>
<rawString>Rebecca Passonneau, Ansaf Salleb-Aouissi, Vikas Bhardwaj, and Nancy Ide. 2010. Word sense annotation of polysemous words by multiple annotators. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer S Pradhan</author>
<author>Eduard Hovy</author>
<author>Mitch Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: A unified relational semantic representation.</title>
<date>2007</date>
<booktitle>In ICSC ’07: Proceedings of the International Conference on Semantic Computing,</booktitle>
<pages>517--526</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="2677" citStr="Pradhan et al., 2007" startWordPosition="400" endWordPosition="403">ll-known multiply-annotated and validated corpus of English is the one million word Wall Street Journal corpus known as the Penn Treebank (Marcus et al., 1993), which over the years has been fully or partially annotated for several phenomena over and above the original part-of-speech tagging and phrase structure annotation. The usability of these annotations is limited, however, by the fact that many of them were produced by independent projects using their own tools and formats, making it difficult to combine them in order to study their inter-relations. More recently, the OntoNotes project (Pradhan et al., 2007) released a one million word English corpus of newswire, broadcast news, and broadcast conversation that is annotated for Penn Treebank syntax, PropBank predicate argument structures, coreference, and named entities. OntoNotes comes closest to providing a corpus with multiple layers of annotation that can be analyzed as a unit via its representation of the annotations in a “normal form”. However, like the Wall Street Journal corpus, OntoNotes is limited in the range of genres it includes. It is also limited to only those annotations that may be produced by members of the OntoNotes project. In </context>
</contexts>
<marker>Pradhan, Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2007</marker>
<rawString>Sameer S. Pradhan, Eduard Hovy, Mitch Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2007. OntoNotes: A unified relational semantic representation. In ICSC ’07: Proceedings of the International Conference on Semantic Computing, pages 517–526, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>