<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000059">
<title confidence="0.987904">
Recycling Terms into a Partial Parser
</title>
<author confidence="0.963612">
Christian Jacquemin
</author>
<affiliation confidence="0.545125">
Institut de Recherche en Informatique de Nantes (IRIN)
JUT de Nantes
</affiliation>
<address confidence="0.57058">
3, rue du Marechal Joffre
F-44041 NANTES Cedex 01 — FRANCE
</address>
<email confidence="0.991973">
jacquemin@irin.iut-nantes.univ-nantes.fr
</email>
<sectionHeader confidence="0.99368" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999919407407407">
Both full-text information retrieval and large scale
parsing require text preprocessing to identify
strong lexical associations in textual databases. In
order to associate linguistic felicity with
computational efficiency, we have conceived
FASTR a unification-based parser supporting
large textual and grammatical databases. The
grammar is composed of term rules obtained by
tagging and lemmatizing term lists with an on-
line dictionary. Through FASTR, large
terminological data can be recycled for text
processing purposes. Great stress is placed on the
handling of term variations through metarules
which relate basic terms to their semantically
close morphosyntactic variants.
The quality of terminological extraction and
the computational efficiency of FASTR are
evaluated through a joint experiment with an
industrial documentation center. The processing
of two large technical corpora shows that the
application is scalable to such industrial data and
that accounting for term variants results in an
increase of recall by 20%.
Although automatic indexing is the most
straightforward application of FASTR, it can be
extended fruitfully to terminological acquisition
and compound interpretation.
</bodyText>
<sectionHeader confidence="0.960928" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99922626984127">
Large terminological databases are now available and can
be used as lexicons in Natural Language Processing
(NLP) systems aimed at terminology extraction. In
FASTR term lists are transformed into large lexicalized
grammars and are parsed with a robust and
computationally tractable unification-based parser. Our
method contrasts with pattern-matching techniques by
offering an expressive and convenient descriptive
framework. It also differs from a general multipurpose
parser by an ability to recycle linguistic knowledge
embodied in terminological data. Higher quality in
terminological extraction is achieved thanks to a
description of term variations.
Areas of application using such a tool for
terminology extraction include automatic indexing
through an assignment of text pointers to thesaurus
entries, knowledge acquisition form textual databases,
noun phrase structural disambiguation and machine
translation with a specific concern for the translation of
idioms, compounds and terms.
When designing any NLP system with large
linguistic resources, there is tension between tractability
and descriptive power. Finite state automata are efficient
tools for lexical extraction. But their lack of convenience
for information description makes the testing of different
methodological choices difficult. Such a limitation is
specifically problematic during the development stage.
Symmetrically, unification-based parsers offer rich and
conceptually tractable formalisms, but their
computational cost is very high. The approach taken in
FASTR is to use a convenient grammatical description
stemming from PATR-II (Shieber 1986) associated with
an optimized computational engine. Efficiency and
constraint-based grammar formalism have motivated the
acronym of the application (FAST + PATR-II) that
stands for FAST TERM RECOGNIZER.
When terminology extraction is applied to automatic
indexing, two measures are important: recall and
precision. Precision is crucial for applications using
acquisition methods which are subject to an excessive
recall, blurring terminological entries with syntactic
recurrences or semantic preferences. Conversely, in a
knowledge-based method like FASTR, recall is a
decisive evaluation of the coverage of the extraction. The
recall rate mainly depends on the ability of the processor
to extract term occurrences which differ from their
description in the terminological base. With the purpose
of enhancing the recall rate, FASTR includes a
metagrammar used to generate term variant rules from
term rules. Such an addition of robustness does not
entail a degradation of precision because variations are
restricted to a &amp;quot;safe&amp;quot; window bordered by the term
components.
The formalism of FASTR is organized into three
levels: a single word lexicon, a terminological grammar
and a metagrammar for term variations. The
initialization of FASTR consists of the description of
the inflectional system of the language under study, the
generation of a lexicon and a grammar from a list of
terms with an on-line lexicon and the handcrafted
creation of a set of paradigmatic metarules (about a
hundred) which are refmed according to the experimental
results.
</bodyText>
<page confidence="0.998676">
113
</page>
<bodyText confidence="0.998265153846154">
Processing in FASTR starts with segmentation and
stemming. During stemming, a few term rules are
activated through a bottom-up filtering. Then, metarules
are applied to these rules and yield transformed rules used
to extract terms and their variants. For example, from
the preceding sentence and from a grammar including
term variant, the sequence terms and their variants would
be extracted as a variation of term variant. The data
required by FASTR consist of a declension file, an
initial terminological database and an on-line dictionary
to transform terms into compilable linguistic data. As
far as human time is concerned, only a slight
experimental tuning of the metarules is necessary.
</bodyText>
<subsectionHeader confidence="0.559555">
A Three-tier Formalism
</subsectionHeader>
<bodyText confidence="0.998073785714286">
The formalism of FASTR stems from PATR-H (Shieber
1986). Rules are composed of a context-free portion
describing the concatenation of the constituents and a set
of equations constraining information of these
constituents.
The description of a single word includes minimally
the string of the word stem, a part-of-speech category and
its inflection number. These three values are used to
dynamically rebuild the different inflections of the word.
They are automatically extracted from an on-line
dictionary with morphological information. We currently
use the DELAS dictionary of LADL laboratory
(University of Paris 7). For example, rule (1) describes
the noun ray, plural rays.
</bodyText>
<listItem confidence="0.987216666666667">
(1) Word: &apos;ray&apos;
&lt;cat&gt; = &apos;N&apos;
&lt;inflection&gt; = 1.
</listItem>
<bodyText confidence="0.999130727272727">
Terms are described by grammar rules. The
formalism of PATR-II has been extended to support such
additional facilities as rules with an extended domain of
locality, structure disjunction and negative atomic
values. Rule (2) represents the term [X ray] diffraction.
This rule localizes the embedded structure X ray. Lexical
anchors, indicated by the value of the feature
lexicalization, are used prior to the parsing phase for a
selective bottom-up activation of the rules. For example,
rule (2) is anchored to diffraction and is activated when
this word is encountered in the input sentence.
</bodyText>
<listItem confidence="0.886136">
(2) Rule : --&gt; (N2 --&gt; N3 N4) N5
&lt;N1 label&gt; = &apos;XRD&apos;
</listItem>
<equation confidence="0.9977365">
&lt;N1 metaLabel&gt; = &apos;XX&apos;
&lt;N1 lexicalization&gt; = &apos;N5&apos;
&lt;N3 lemma&gt; = &apos;X&apos;
&lt;N3 inflection&gt; = 7
&lt;N4 lemma&gt; = &apos;ray&apos;
&lt;N4 inflection&gt; -= 1
&lt;N5 lemma&gt; = &apos;diffraction&apos;
&lt;N5 inflection&gt; = 1.
</equation>
<bodyText confidence="0.978655272727273">
The third level of the formalism consists of a
metagrammar. Metarules are composed of two context-
free descriptions: the source and the target and a set of
equations constraining them. Information shared by the
source and the target is embodied by identical symbols.
For example, metarule (3) describes a coordination of a
two-constituent term inserting a conjunction (except but)
and a word (except a definite or indefinite determiner)
between both constituents. When applied to rule (2), it
outputs a novel rule which accepts X ray or neutron
diffraction as a variant of X ray diffraction.
</bodyText>
<listItem confidence="0.845384">
(3) Metarule : Coor(Xi ----&gt; X2 X3)
</listItem>
<equation confidence="0.8711726">
= xl —3 X2 C3 X4 X3 &amp;quot;C&apos; = conjunction&amp;quot;
&lt;X1 metaLabel&gt; =
&lt;C3 lemma&gt; I &apos;but&apos; &amp;quot; ! denotes inequality&amp;quot;
&lt;X4 cat&gt; &apos;Dd&apos; &amp;quot;Dd&apos;= definite determiner&amp;quot;
&lt;X4 cat&gt; I &apos;Di&apos;. &amp;quot;Dl&apos;= indefinite determiner&amp;quot;
</equation>
<bodyText confidence="0.409599">
Parsing
</bodyText>
<subsectionHeader confidence="0.720924">
Morphology
</subsectionHeader>
<bodyText confidence="0.999283">
FASTR has been applied to the French and the English
languages and can be easily extended to any language
without word agglutination thanks to an external
description of morphology. The suffix stripping
operation precedes syntactic analysis and requires a
dictionary of lemmas and a declension file (Savoy 1993).
Each entry in the dictionary has a basic stem and words
with an irregular inflectional morphology such as
mouse/mice have one or more auxiliary stems.
Derivational links such as synapse/ synaptic can also be
accounted for through multi-valued part-of-speech
categories such as noun-adjective. The declension file is
illustrated by formulae (4) and (5). A set of features is
provided for each inflectional case of each inflected
category (e.g. (4) for nouns). A list of suffixes
corresponds to each declension class (e.g. (5) for the first
two classes of nouns). ?1 indicates the first auxiliary
stem. The inflection class of a word is denoted by the
value of the feature inflection in word rule (1) and term
rule (2).
</bodyText>
<equation confidence="0.848560571428571">
&amp;quot;The two cases of nouns&amp;quot;
(4) NT[ 1] &lt;number&gt; = &apos;singular&apos;.
NI 2] &lt;number&gt; = &apos;plural&apos;.
&amp;quot; dogl dog-s (stem dog) &amp;quot;
(5) 1\1) 1 ] 0 s
&amp;quot;mouse! mice (stem mouse, aux. stem mice) &amp;quot;
N[ 2J 0 71
</equation>
<bodyText confidence="0.999725181818182">
In order to prepare suffix stripping, a generalized
lexicographic tree is built form the whole set of the
reversed suffixes of the current language. Each inflected
word is also reversed and all its endings corresponding to
an actual suffix are removed. The corresponding stems
are looked for in the dictionary. If one of their inflections
is equal to the current inflected word, the features
associated with the declension case are unified with the
features of the lemma and attached to the inflected word.
Thus, the morphological stemmer associates all its
homographic inflections to an inflected word.
</bodyText>
<page confidence="0.993501">
114
</page>
<bodyText confidence="0.966609047619048">
The term rules whose lexical anchor is equal to one
of the lemmas in the input are activated and processed by
a top-down algorithm. In order to ensure short parsing
times, unification is delayed until rewriting is achieved.
Whenever a rule fails to be parsed, it is repeatedly tried
again on its variants generated by metarules.
Term syntax and local syntax
Metarules can be straightforwardly described by
embedding the formalism into a logical framework where
rule generation by metarules is calculated through
unification. With this aim in mind, the definitions of
term rules and metarules given in the preceding part can
be transformed into logical (in)equations by using the
formulae of Kasper and Rounds (1986). As in (Vijay-
Shanker 1992), type variables whose denotations are sets
of structures derived from non-terminals can be replaced
by monoadic predicates. Individual variables that stand
for individual feature structures are used to capture
reentrance. For example, rule (2) is translated into
formula (6). A monoadic predicate arity is added to
restrict the application of metarules.
</bodyText>
<equation confidence="0.988998125">
(6) XRD(x) &lt;=&gt; cat(x) = &apos;N&apos; A arity(x) = 2
lexicalization(x) x4 A metaLabel(x)
A i(X) = X1 A cat(x1) = &apos;N&apos; A arity(xi) = 2
A 1(x1) = X2 A 2(x1) = X3 A cat(x2) &apos;N&apos;
A lemma(x2) &apos;X&apos; A inflection(x2) 1
cat(x3) &apos;N&apos; A lemma(x3) = &apos;ray&apos;
inflection(x3) =, 1 A 2(4 = x4 A cat(x4) &apos;N&apos;
lemma(x4) = &apos;diffraction&apos; A inflection(x4) 1
</equation>
<bodyText confidence="0.987773083333333">
Standard fixed-point semantics is associated to this syn-
tax which is used to calculate the interpretation of such
formulae. The denotation of a formula is an automaton
calculated through an inductive interpretation of the
terms it contains (Rounds and Manaster-Ramer 1987).
As a consequence of this mathematical formulation, the
metarules are expressed as couples of monoadic
predicates with shared variables. For example, the
metarule of coordination (3) is described by formula (7).
The syntax of both sides of the metarule is identical to
the syntax of rules except for the monoadic rule predicate
p which is a variable. stands for negation.
</bodyText>
<equation confidence="0.9609234">
(7) Coor(p(y) &lt;=&gt; arity(y)-2 A 1(y) yi A 2(y) = y2)
= (Coor(p) (y) &lt;=&gt; arity(y) = 4 A 1(y) = 111
A 2(Y) = Y3 A 3(y) =-&amp;quot;&amp;quot;. Y4 A 4(Y) = Y2
cat(y3) &apos;C&apos; A-,(1emma(y4) &apos;but&apos;)
--,(cat(y4) = &apos;Di&apos;) A -,(cat(y4) &apos;Dd&apos;) )
</equation>
<bodyText confidence="0.991258583333333">
The result of the application of a metarule to a rule is
calculated in two steps. Firstly, the left-hand-side of the
metarule is unified with the rule. If unification fails, no
output rule is generated. Otherwise, let a be the
substitution providing the unification. Then, the formula
of the transformed rule is equal to the right-hand-side of
the metarule, where the variables are substituted
according to a. The computational implementation is
straightforwardly derived from this calculus. For
example, metarule (7) applies to rule (6) with the
substitution a (8) and yields the transformed rule (9)
whose PATR-II expression is (10).
</bodyText>
<listItem confidence="0.905506">
(8) a Ey = x, XRD/p, = yi, x4 = y2]
(9) Coor(XRD)(x) &lt;=&gt; cat(x) = &apos;N&apos; A arity(x) = 4
</listItem>
<equation confidence="0.999689833333333">
lexicalization(x) = x4 A metaLabel(x) =XX&apos;
A 1(x) X1 A cat(xi) &apos;N&apos; A arity(xi) = 2
A 1(x1) X2 A 2(x1) X3 A cat(x2) = &apos;N&apos;
lemma(x2) = &apos;X&apos; A inflection(x2) = 1
• cat(x3) = &apos;N&apos; A lemma(x3) = &apos;ray&apos;
inflection(x3) = 1 A 4(4 = x4 A cat(x4) &apos;N&apos;
• lemma(x4) = &apos;diffraction&apos; A inflection(x4) --- 1
A 2(y) = y3 A 3(y) — y4 A cat(y3) = &apos;C&apos;
(10) Rule : ---&gt; (N2 --&gt; N3 N4) C6 N7 N5
&lt;N1 label&gt; = &apos;Coor(XRD)&apos;
&lt;N1 metarabel&gt; = &apos;XX&apos;
&lt;N1 lexicati7ation&gt; = &apos;N5&apos;
&lt;N3 lemma&gt; = &apos;X
&lt;N3 inflection&gt; = 1
&lt;N4 lemma&gt; = &apos;ray&apos;
&lt;N4 inflection&gt; = 1
&lt;N5 lemma&gt; = &apos;diffraction&apos;
&lt;N5 inflection&gt; = 1.
</equation>
<bodyText confidence="0.999076">
The mapping performed by the metarules in FASTR
differs from the definition of metarules in GPSG (Gazdar
et al. 1985) on the following points:
</bodyText>
<listItem confidence="0.967195545454545">
• The matching of the input rule and the source is
replaced by their unification. The correspondence
between source and target is achieved by identical
variables shared by both sides of the metarule.
• In GPSG, when input rule and target disagree about
the value of some feature, the target always wins. In
FASTR, the target wins if its value for this feature is
independent of its source. Conversely, if source and
target share this value, the unification of the source
and the rule fails and no output is provided.
• The metavariable W used in GPSG and standing for a
</listItem>
<bodyText confidence="0.949975090909091">
set of categories is not available in FASTR.
However, an empty category in the context-free
skeleton can stand for any subtree of the original
rule. Thus, variable yi from metarule (7), associated
to X2 in formula (3), stands for the subterm X ray
when applied to rule (6).
When implementing metarules in a grammar parser,
there are two possibilities for the time to apply the
metarules to a rule. The compile-time application
calculates all the images of all the rules in the grammar
prior to parsing. In the run-time approach, metarules are
dynamically applied to the active rules during parsing.
Weisweber and Preull (1992) demonstrate that there is no
difference in complexity between both approaches.
Moreover, in the compile-time approach, metarules
generate a huge set of transformed rules which may make
the parsing process totally inefficient. Due to the very
large size of our grammar, we have opted for the
dynamic approach. The computational performances of
the application reported in (Jacquemin 1994a) indicate
that the parser only spends 10% of its time in generating
metarules and fully justify the run-time approach.
</bodyText>
<page confidence="0.997707">
115
</page>
<subsectionHeader confidence="0.890155">
Computational Lexicalization
</subsectionHeader>
<bodyText confidence="0.997286026315789">
The keystone of the computational tractability is
lexicalization which allows for a bottom-up filtering of
the rules before parsing. It is completed by fast
mechanisms for data access such as a B-Tree (for the disk
resident lexicon of single words) and a Hash-Code table
(for the memory resident stop words).
The formalism of FASTR is lexicalized in the sense
of Schabes and Joshi (1990) because it is composed of
rules associated with each lexical item which is the
anchor of the corresponding rules. The parsing algorithm
for lexicalizecl grammars takes advantage of lexicalization
through a two-step strategy. The first step is a selection
of the rules linked to the lexical items in the input. The
second step parses the input with a grammar restricted to
the filtered rules. In case of rules with multiple lexical
items such as the rules representing multi-word terms,
the anchor can be any of the lexical items. For example,
the term aortic disease can be anchored either to aortic or
to disease. In Jacquemin (1994b), an algorithm for
optimizing the determination of computational anchors
is described. It yields a uniform distribution of the rules
on to the lexical items with respect to a given weighting
function. A comparison between the &amp;quot;natural&amp;quot;
lexicalization on the head nouns and the optimized one
has been made with FASTR. It shows that the rules
filtered by the optimized lexicalization represent only
57% of the rules selected by the natural lexicalization
and ensure a 2.6-time higher parsing speed.
The computational performances of parsing with
FASTR mainly depend on the size of the grammar (see
Figure 1). The parsing speed with a 71,623-rule
teiminological grammar, a 38,536-word lexicon and 110
metarules is 2,562 words/minute on a Sparc 2
workstation (real time), As 71,623 terms is a reasonable
size for a real-word multi-domain list of terms (for
example WordNet currently includes 35,155 synonyms
sets), a workstation is well-suited for processing large
corpora with such terminological databases.
</bodyText>
<figure confidence="0.960110666666667">
100,000
20,000 40,000 60,000 80,000
Number of terms (in the grammar)
</figure>
<figureCaption confidence="0.99933">
Figure 1. Parsing speed of FASTR (Sparc 2, real time)
</figureCaption>
<sectionHeader confidence="0.612076" genericHeader="method">
Application to Automatic Indexing
</sectionHeader>
<bodyText confidence="0.9924615">
A list of 71,623 multi-domain terms and two corpora of
scientific abstracts have been provided by the
documentation center INIST/CNRS : a 118,563-word
corpus on metallurgy [METAL] and a 1.5-million word
medical corpus [MEDIC]. The laboratory of
INIST/CNRS has achieved tagging and lemmatization of
terms and has evaluated the results of the indexing
provided by FASTR.
In this experiment, the metagrammar consists of
positive paradigmatic metarules (e.g. (11)) and filtering
negative metarules rejecting the spurious variations
extracted by the positive ones (e.g. (12)). Examples of
variations from [MEDIC] accepted by (11) or rejected by
(12) are shown in Figure 2.
</bodyText>
<listItem confidence="0.68879025">
(11) Metarule Coor( X1 —&gt; X2 X3)
= x1 —&gt; X2 C3 X4 X3
&lt;X1 metaLabel&gt; = &apos;XX&apos;.
(12) Metartde NegCoor( X1 —&gt; X2 X3)
</listItem>
<equation confidence="0.99091">
= x1 —) X2 C3 X4 X3
&lt;X1 metaLabel&gt; = &apos;XX&apos;
&lt;X4 cat&gt; = &apos;P&apos; = preposition&amp;quot;
&lt;X4 cat&gt; = &apos;Dd&apos;
&lt;X4 cat&gt; = &apos;Di&apos;.
</equation>
<bodyText confidence="0.509611">
Variations accepted by (11)
</bodyText>
<figure confidence="0.5194994">
mechanical and enzymatic methods
Down and Williams syndromes
amplitude and frequency modulations
Northern and Western blotting
Variations rejected by (12)
</figure>
<figureCaption confidence="0.914252">
relaxation and the time
satellite and whole chromosome
cells or after culture
tissue or a factor
Figure 2. Antagonist description of variations
</figureCaption>
<bodyText confidence="0.999880666666667">
Negative metarules are used instead of negative
constraints such as the ones stated in (3) to keep a trace
of the rejected variations. More details about this
description are reported in (Jacquemin and Royaute
1994). An evaluation of terminology extraction on
corpus [METAL] indicates that term variations represent
16.7% of multi-word term occurrences extracted by
FASTR (an account for term variants increases recall by
20%). The three kinds of variants retrieved through
metarules are coordinations (2%), modifier insertions
(8.3%) and permutations (6.4%). See Figure 3 for
examples. Elisions such as Kerrr magnetooptical effect
—&gt; Kerr effect are not accounted for because our local
approach to variation is not appropriate to elliptic
references. In this framework, FASTR retrieves 74.9%
of the term variants with a precision of 86.7%. These
results confirm the substantial gain in recall obtained by
accounting for term variants in automatic indexing. A
</bodyText>
<figure confidence="0.991040090909091">
-0 30,000
cl) 4)
a) 0) 20,000
(a.
° 10,000
0, e
.s E
3,000
o_ 2,000
0
1,000 -0
</figure>
<bodyText confidence="0.99612">
better precision could be reached through a more accurate
description of permutation. An improvement in term
variant recall requires the handling of elision.
</bodyText>
<subsectionHeader confidence="0.908542">
Related Work
</subsectionHeader>
<bodyText confidence="0.999943774193549">
Firstly, our formalism is inspired by two fields of
lexicalized and logical tree formalisms. The first one is
the general framework of Lexicalized Tree Adjoining
Grammar (LTAG) which has shown to be fruitful for the
description of idioms (Abeille and Schabes 1989). The
second one is the important extension of Tree Adjoining
Grammar (TAG) to a logical framework (Vijay-Shanker
1992) which contrasts with the traditional approach that
operations in a TAG combine trees. From these works,
we have adopted the constraint of LTAG which states
that rules must have at least one lexical frontier node
together with the logical representation of Vijay-Shanker
(1992) where rules are not restricted to immediate
dependency. The lexicalized tree grammar is motivated
by the domain to be described: terms mainly consist of
compounds with an internal structure and lexical
constituents. The logical formalism provides us with a
straightforward extension to metarules.
Secondly, our approach to text processing is a form
of partial parsing. A current trend in large scale NLP
system (Jacobs 1992) refuses to consider parsing as an
exhaustive derivation of a very large grammar which
would process any encountered sentence. To alleviate
these problems parsing should be planned as the
cooperation of several methods such as text
preprocessing, parsing by chunks, multiple-step partial
parsing, shallow parsing... etc. The scope of the
preprocessing task is &amp;quot;abstract[ing] idiosyncrasies,
highlight[ing] regularities, and, in general feed[ing]
digested text into the unification parser&amp;quot; (Zemik 1992).
With this aim in mind FASTR brings forth occurrences
of complex lexical entries and their local variations. It is
adapted to integration in a multi-step parsing strategy. It
takes as input a raw corpus and yields chunks
corresponding to partial parses. This output can be fed
into a following module or reprocessed with more
precise metarules.
Thirdly, our research on term extraction places great
stress on term variations. The most direct precursors of
the use of term variation in information retrieval are
Sparck Jones and Tait (1984). These authors advocate the
systematic generation of syntactic term variants in query
processing. Their approach, however, makes the
assumption that only semantic equivalent variant should
be generated and that each of the words in a variant
should be given instead of allowing paradigmatic places.
They only account for restricted associations such as
information retrieval/retrieval of information.
Strzalkowski and Vauthey (1992) follow the way
suggested by Sparck Jones and Tait (1984) at the end of
their paper. Instead of generating term variants in a
query, they look for different term occurrences in text
documents analyzed by a general multipurpose parser.
Their parse trees are composed of head/modifier relations
of four categories. These four classes account for most of
the syntactic variants of two-word terms into pairs with
compatible semantic content such as information
retrieval/information retrieval system/retrieval of
information from databases... We think however that
most of these variants can be extracted without parsing
the whole sentence. They can be detected safely through
a local parse with a noun-phrase micro-syntax.
</bodyText>
<sectionHeader confidence="0.851622" genericHeader="method">
Extensions and Conclusion
</sectionHeader>
<bodyText confidence="0.995396125">
Although applied straightforwardly to automatic
indexing, FASTR can be extended to terminology
acquisition through a bootstrapping method where new
terms are acquired by observing the variations of
controlled terms in corpora. Figure 3 reports four
occurrences of term variants retrieved through three
metarules belonging to three different families. Each of
these occurrences yields a novel candidate term which
either already belongs to the terminology or can be added
after validation.
A second extension of FASTR concerns acquisition
of noun phrase interpretation from a corpus. Observation
of variation is an opportunity to find objective linguistic
clues which denote the semantic relation between both
words of a binominal compound. For example, cell into
a metastatic tumor is a permutation of tumor cell
involving the preposition into. Figure 4 lists four N
cell terms for which more than four permutations cell
Prep X N have been encountered in corpus [MEDIC].
The prepositions found in more than one permutation are
followed by their number of occurrences. For example,
the prepositions encountered in the permutations of
blood cell are from, in, into and on. These four
prepositions denote a relation of spatial inclusion of a
trajector cell into a landmark blood (Langacker 1987).
Term Variation Candidate term
water absorption water and sodium absorption (coordination) sodium absorption
Central Africa Central and West Africa (coordination) West Africa
controlled delivery controlled drug delivery (insertion) drug delivery
magnetic coupling magnetic transcutaneous coupling (insertion) transcutaneous coupling
information access access to lexical information (permutation) lexical information
wave effect effect of short wave (permutation) short wave
</bodyText>
<figureCaption confidence="0.995997">
Figure 3. Acquisition of candidate terms through variation
</figureCaption>
<page confidence="0.945918">
117
</page>
<table confidence="0.9676362">
Term Prepositions
Membrane cell in [4], into, to
Myeloid cell of [3], from
Blood cell from [8], in [13], into, on
Tumor cell in [3], from [4], into, with, of
</table>
<figureCaption confidence="0.974537">
Figure 4. Noun phrase interpretation through variation
</figureCaption>
<bodyText confidence="0.999981210526316">
Although initially devised for automatic indexing,
FASTR can play a crucial role in other text-based
intelligent tasks. This part has sketched out a picture of
incremental terminological acquisition and noun-phrase
understanding through the analysis of term variants.
As Resnik (1993) points out, large-scale knowledge
sources can be used as a source of lexical information.
Similarly, our approach to corpus linguistics makes a
extensive use of terminological data and investigates
systematically and precisely the variations of terms in
technical corpora. The next natural step in term and
compound processing is to provide FASTR with a
learning ability. With this aim in mind, we are currently
investigating two novel research directions: firstly, a
hybridisation of FASTR with a connectionist model
dedicated to nominal composition (Jacquemin 1993) and,
secondly, a cooperation between FASTR and LEXTER
(Bourigault 1993) a tool for term acquisition through the
filtering of part-of-speech patterns.
</bodyText>
<sectionHeader confidence="0.959494" genericHeader="method">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.99994625">
I would like to thank Jean Royaute from INIST/CNRS
for his helpful and friendly collaboration on this project.
Many thanks also to Benoit Habert from ENS Fontenay
for numerous constructive discussions.
</bodyText>
<sectionHeader confidence="0.99855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999818278481013">
Abeille, Anne and Yves Schabes. 1989. Parsing Idioms
in Lexicalized Tags. In Proceedings, 4th Conference of
the European Chapter of the Association for
Computational Linguistics (EACL&apos; 89), Manchester, June
1989, 1-9.
Bourigault, Didier. 1993. An Endogeneous Corpus-
Based Method for Structural Noun Phrase
Disambiguation. In Proceedings, 6th European Chapter of
the Association for Computational Linguistics
(EACL&apos;93), Utrecht, June 1993.
Gazdar, Gerald, Ewan Klein, Geoffrey Pullum, Ivan
Sag. 1985. Generalized Phrase Structure Grammar,
Oxford: Blackwell.
Jacobs, Paul S. (edt). 1992. Text-based Intelligent
systems, Current Research and Practice in Information
Extraction and Retrieval. Hillsdale : Lawrence Erlbaum.
Jacquemin, Christian. 1993. A Coincidence Detection
Network for Spatio-Temporal Coding: Application to
Nominal Composition. In Proceedings, 13th International
Joint Conference on Artificial Intelligence (IJCAI&apos;93),
Chambery, August 1993, 1346-1351.
Jacquemin, Christian. 1994a. FASTR: A unification
grammar and a parser for terminology extraction from
large corpora. In Proceedings, IA-94, Paris, June 1994.
Jacquemin, Christian. 1994b. Optimizing the
computational lexicalization of large grammars. In
Proceedings, 32nd Annual Meeting of the Association for
Computational Linguistics, Las Cruces, June 1994.
Jacquemin, Christian and Jean Royaute. 1994.
Retrieving terms and their variants in a lexicalized
unification-based framework. In Proceedings, 17th Annual
International ACM SIGIR Conference (SIGIR&apos;94),
Dublin, July 1994.
Kasper, Robert T. and William C. Rounds. 1986. A
logical semantics for feature structures. In Proceedings,
24th Annual Meeting of the Association for
Computational Linguistics, NY, June 1986, 257-266.
Langacker Ronald W. 1987. Foundations of Cognitive
Grammar. Vol I. Theoretical Prerequisites. Stanford:
Stanford University Press.
Resnik, Philip S. 1993. Selection and Information:
A Class-Based Approach to Lexical Relationships. Ph D
diss in Computer Science, University of Pennsylvania.
Rounds, William C. and Alexis Manaster-Ramer.
1987. A logical version of functional grammar. In
Proceedings, 24th Annual Meeting of the Association for
Computational Linguistics, Stanford CA, July 1987,
257-266.
Savoy, Jacques. 1993. Stemming of French words
based on grammatical categories. 1993. Journal of the
American Society for Information Science, Vol. 44,
No 1, January 1993, 1-10.
Schabes, Yves and Aravind K. Joshi. 1990. Parsing
with Lexicalized Tree Adjoining Grammar. In Current
Issues in Parsing Technologies, Masaru Tomita (edt),
Dordrecht: Kluwer Academic Publishers.
Shieber, Stuart N. 1986. An Introduction to
Unification-Based Approaches to Grammar. CSLI Lecture
Notes 4, Stanford, CA: CSLI.
Sparck Jones, Karen and J. I. Tait. 1984. Automatic
Search Term Variant Generation. Journal of
Documentation, Vol. 40, No. 1, March 1984, 50-66.
Strzalkowski, Tomek and Barbara Vauthey. 1992.
Information Retrieval Using Robust Natural Language
Processing. In Proceedings, 30th Annual Meeting of the
Association for Computational Linguistics (ACL&apos;92),
Newark, DE, June 1992, 104-111.
Vijay-Shanker, K. 1992. Using Description of Trees
in a Tree Adjoining Grammar. Computational
Linguistics, Vol. 18, No. 4, December 1992, 481-518.
Weisweber, Willielm and Susanne Preull. 1992. Direct
Parsing with Metarules. In Proceedings, 14th
International Conference on Computational Linguistics
(COLING&apos;92), Nantes, July 1992, 1111-1115.
Zernik, Uri. 1992. Shipping Departments vs.
Shipping Pacemakers : Using Thematic Analysis to
Improve Tagging Accuracy. In Proceedings, Annual
Meeting of the American Association for Artificial
Intelligence (AAAI-92), 335-342.
</reference>
<page confidence="0.996173">
118
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.764285">
<title confidence="0.973777">Recycling Terms into a Partial Parser</title>
<affiliation confidence="0.950842">Institut de Recherche en Informatique de Nantes (IRIN) JUT de Nantes</affiliation>
<address confidence="0.9344205">3, rue du Marechal Joffre F-44041 NANTES Cedex 01 — FRANCE</address>
<abstract confidence="0.999560321428571">Both full-text information retrieval and large scale parsing require text preprocessing to identify strong lexical associations in textual databases. In order to associate linguistic felicity with computational efficiency, we have conceived unification-based parser supporting large textual and grammatical databases. The grammar is composed of term rules obtained by tagging and lemmatizing term lists with an ondictionary. Through terminological data can be recycled for text processing purposes. Great stress is placed on the handling of term variations through metarules which relate basic terms to their semantically close morphosyntactic variants. The quality of terminological extraction and computational efficiency of evaluated through a joint experiment with an industrial documentation center. The processing of two large technical corpora shows that the application is scalable to such industrial data and that accounting for term variants results in an increase of recall by 20%. Although automatic indexing is the most application of can be extended fruitfully to terminological acquisition and compound interpretation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Yves Schabes</author>
</authors>
<title>Parsing Idioms in Lexicalized Tags.</title>
<date>1989</date>
<booktitle>In Proceedings, 4th Conference of the European Chapter of the Association for Computational Linguistics (EACL&apos; 89),</booktitle>
<pages>1--9</pages>
<location>Manchester,</location>
<contexts>
<context position="19855" citStr="Abeille and Schabes 1989" startWordPosition="3157" endWordPosition="3160">sults confirm the substantial gain in recall obtained by accounting for term variants in automatic indexing. A -0 30,000 cl) 4) a) 0) 20,000 (a. ° 10,000 0, e .s E 3,000 o_ 2,000 0 1,000 -0 better precision could be reached through a more accurate description of permutation. An improvement in term variant recall requires the handling of elision. Related Work Firstly, our formalism is inspired by two fields of lexicalized and logical tree formalisms. The first one is the general framework of Lexicalized Tree Adjoining Grammar (LTAG) which has shown to be fruitful for the description of idioms (Abeille and Schabes 1989). The second one is the important extension of Tree Adjoining Grammar (TAG) to a logical framework (Vijay-Shanker 1992) which contrasts with the traditional approach that operations in a TAG combine trees. From these works, we have adopted the constraint of LTAG which states that rules must have at least one lexical frontier node together with the logical representation of Vijay-Shanker (1992) where rules are not restricted to immediate dependency. The lexicalized tree grammar is motivated by the domain to be described: terms mainly consist of compounds with an internal structure and lexical c</context>
</contexts>
<marker>Abeille, Schabes, 1989</marker>
<rawString>Abeille, Anne and Yves Schabes. 1989. Parsing Idioms in Lexicalized Tags. In Proceedings, 4th Conference of the European Chapter of the Association for Computational Linguistics (EACL&apos; 89), Manchester, June 1989, 1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Didier Bourigault</author>
</authors>
<title>An Endogeneous CorpusBased Method for Structural Noun Phrase Disambiguation.</title>
<date>1993</date>
<booktitle>In Proceedings, 6th European Chapter of the Association for Computational Linguistics (EACL&apos;93),</booktitle>
<location>Utrecht,</location>
<marker>Bourigault, 1993</marker>
<rawString>Bourigault, Didier. 1993. An Endogeneous CorpusBased Method for Structural Noun Phrase Disambiguation. In Proceedings, 6th European Chapter of the Association for Computational Linguistics (EACL&apos;93), Utrecht, June 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Ewan Klein</author>
<author>Geoffrey Pullum</author>
<author>Ivan Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar,</title>
<date>1985</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="13221" citStr="Gazdar et al. 1985" startWordPosition="2091" endWordPosition="2094">&apos; A arity(xi) = 2 A 1(x1) X2 A 2(x1) X3 A cat(x2) = &apos;N&apos; lemma(x2) = &apos;X&apos; A inflection(x2) = 1 • cat(x3) = &apos;N&apos; A lemma(x3) = &apos;ray&apos; inflection(x3) = 1 A 4(4 = x4 A cat(x4) &apos;N&apos; • lemma(x4) = &apos;diffraction&apos; A inflection(x4) --- 1 A 2(y) = y3 A 3(y) — y4 A cat(y3) = &apos;C&apos; (10) Rule : ---&gt; (N2 --&gt; N3 N4) C6 N7 N5 &lt;N1 label&gt; = &apos;Coor(XRD)&apos; &lt;N1 metarabel&gt; = &apos;XX&apos; &lt;N1 lexicati7ation&gt; = &apos;N5&apos; &lt;N3 lemma&gt; = &apos;X &lt;N3 inflection&gt; = 1 &lt;N4 lemma&gt; = &apos;ray&apos; &lt;N4 inflection&gt; = 1 &lt;N5 lemma&gt; = &apos;diffraction&apos; &lt;N5 inflection&gt; = 1. The mapping performed by the metarules in FASTR differs from the definition of metarules in GPSG (Gazdar et al. 1985) on the following points: • The matching of the input rule and the source is replaced by their unification. The correspondence between source and target is achieved by identical variables shared by both sides of the metarule. • In GPSG, when input rule and target disagree about the value of some feature, the target always wins. In FASTR, the target wins if its value for this feature is independent of its source. Conversely, if source and target share this value, the unification of the source and the rule fails and no output is provided. • The metavariable W used in GPSG and standing for a set </context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, Gerald, Ewan Klein, Geoffrey Pullum, Ivan Sag. 1985. Generalized Phrase Structure Grammar, Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul S Jacobs</author>
</authors>
<title>Text-based Intelligent systems, Current Research and Practice in Information Extraction and Retrieval. Hillsdale : Lawrence Erlbaum.</title>
<date>1992</date>
<contexts>
<context position="20676" citStr="Jacobs 1992" startWordPosition="3285" endWordPosition="3286">m these works, we have adopted the constraint of LTAG which states that rules must have at least one lexical frontier node together with the logical representation of Vijay-Shanker (1992) where rules are not restricted to immediate dependency. The lexicalized tree grammar is motivated by the domain to be described: terms mainly consist of compounds with an internal structure and lexical constituents. The logical formalism provides us with a straightforward extension to metarules. Secondly, our approach to text processing is a form of partial parsing. A current trend in large scale NLP system (Jacobs 1992) refuses to consider parsing as an exhaustive derivation of a very large grammar which would process any encountered sentence. To alleviate these problems parsing should be planned as the cooperation of several methods such as text preprocessing, parsing by chunks, multiple-step partial parsing, shallow parsing... etc. The scope of the preprocessing task is &amp;quot;abstract[ing] idiosyncrasies, highlight[ing] regularities, and, in general feed[ing] digested text into the unification parser&amp;quot; (Zemik 1992). With this aim in mind FASTR brings forth occurrences of complex lexical entries and their local v</context>
</contexts>
<marker>Jacobs, 1992</marker>
<rawString>Jacobs, Paul S. (edt). 1992. Text-based Intelligent systems, Current Research and Practice in Information Extraction and Retrieval. Hillsdale : Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>A Coincidence Detection Network for Spatio-Temporal Coding: Application to Nominal Composition. In</title>
<date>1993</date>
<booktitle>Proceedings, 13th International Joint Conference on Artificial Intelligence (IJCAI&apos;93), Chambery,</booktitle>
<pages>1346--1351</pages>
<marker>Jacquemin, 1993</marker>
<rawString>Jacquemin, Christian. 1993. A Coincidence Detection Network for Spatio-Temporal Coding: Application to Nominal Composition. In Proceedings, 13th International Joint Conference on Artificial Intelligence (IJCAI&apos;93), Chambery, August 1993, 1346-1351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>FASTR: A unification grammar and a parser for terminology extraction from large corpora.</title>
<date>1994</date>
<booktitle>In Proceedings, IA-94,</booktitle>
<location>Paris,</location>
<contexts>
<context position="14830" citStr="Jacquemin 1994" startWordPosition="2360" endWordPosition="2361">he compile-time application calculates all the images of all the rules in the grammar prior to parsing. In the run-time approach, metarules are dynamically applied to the active rules during parsing. Weisweber and Preull (1992) demonstrate that there is no difference in complexity between both approaches. Moreover, in the compile-time approach, metarules generate a huge set of transformed rules which may make the parsing process totally inefficient. Due to the very large size of our grammar, we have opted for the dynamic approach. The computational performances of the application reported in (Jacquemin 1994a) indicate that the parser only spends 10% of its time in generating metarules and fully justify the run-time approach. 115 Computational Lexicalization The keystone of the computational tractability is lexicalization which allows for a bottom-up filtering of the rules before parsing. It is completed by fast mechanisms for data access such as a B-Tree (for the disk resident lexicon of single words) and a Hash-Code table (for the memory resident stop words). The formalism of FASTR is lexicalized in the sense of Schabes and Joshi (1990) because it is composed of rules associated with each lexic</context>
</contexts>
<marker>Jacquemin, 1994</marker>
<rawString>Jacquemin, Christian. 1994a. FASTR: A unification grammar and a parser for terminology extraction from large corpora. In Proceedings, IA-94, Paris, June 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Optimizing the computational lexicalization of large grammars.</title>
<date>1994</date>
<booktitle>In Proceedings, 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Las Cruces,</location>
<contexts>
<context position="14830" citStr="Jacquemin 1994" startWordPosition="2360" endWordPosition="2361">he compile-time application calculates all the images of all the rules in the grammar prior to parsing. In the run-time approach, metarules are dynamically applied to the active rules during parsing. Weisweber and Preull (1992) demonstrate that there is no difference in complexity between both approaches. Moreover, in the compile-time approach, metarules generate a huge set of transformed rules which may make the parsing process totally inefficient. Due to the very large size of our grammar, we have opted for the dynamic approach. The computational performances of the application reported in (Jacquemin 1994a) indicate that the parser only spends 10% of its time in generating metarules and fully justify the run-time approach. 115 Computational Lexicalization The keystone of the computational tractability is lexicalization which allows for a bottom-up filtering of the rules before parsing. It is completed by fast mechanisms for data access such as a B-Tree (for the disk resident lexicon of single words) and a Hash-Code table (for the memory resident stop words). The formalism of FASTR is lexicalized in the sense of Schabes and Joshi (1990) because it is composed of rules associated with each lexic</context>
</contexts>
<marker>Jacquemin, 1994</marker>
<rawString>Jacquemin, Christian. 1994b. Optimizing the computational lexicalization of large grammars. In Proceedings, 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, June 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
<author>Jean Royaute</author>
</authors>
<title>Retrieving terms and their variants in a lexicalized unification-based framework.</title>
<date>1994</date>
<booktitle>In Proceedings, 17th Annual International ACM SIGIR Conference (SIGIR&apos;94),</booktitle>
<location>Dublin,</location>
<contexts>
<context position="18596" citStr="Jacquemin and Royaute 1994" startWordPosition="2960" endWordPosition="2963">&lt;X1 metaLabel&gt; = &apos;XX&apos; &lt;X4 cat&gt; = &apos;P&apos; = preposition&amp;quot; &lt;X4 cat&gt; = &apos;Dd&apos; &lt;X4 cat&gt; = &apos;Di&apos;. Variations accepted by (11) mechanical and enzymatic methods Down and Williams syndromes amplitude and frequency modulations Northern and Western blotting Variations rejected by (12) relaxation and the time satellite and whole chromosome cells or after culture tissue or a factor Figure 2. Antagonist description of variations Negative metarules are used instead of negative constraints such as the ones stated in (3) to keep a trace of the rejected variations. More details about this description are reported in (Jacquemin and Royaute 1994). An evaluation of terminology extraction on corpus [METAL] indicates that term variations represent 16.7% of multi-word term occurrences extracted by FASTR (an account for term variants increases recall by 20%). The three kinds of variants retrieved through metarules are coordinations (2%), modifier insertions (8.3%) and permutations (6.4%). See Figure 3 for examples. Elisions such as Kerrr magnetooptical effect —&gt; Kerr effect are not accounted for because our local approach to variation is not appropriate to elliptic references. In this framework, FASTR retrieves 74.9% of the term variants w</context>
</contexts>
<marker>Jacquemin, Royaute, 1994</marker>
<rawString>Jacquemin, Christian and Jean Royaute. 1994. Retrieving terms and their variants in a lexicalized unification-based framework. In Proceedings, 17th Annual International ACM SIGIR Conference (SIGIR&apos;94), Dublin, July 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
<author>William C Rounds</author>
</authors>
<title>A logical semantics for feature structures.</title>
<date>1986</date>
<booktitle>In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>257--266</pages>
<location>NY,</location>
<contexts>
<context position="10258" citStr="Kasper and Rounds (1986)" startWordPosition="1565" endWordPosition="1568">d and processed by a top-down algorithm. In order to ensure short parsing times, unification is delayed until rewriting is achieved. Whenever a rule fails to be parsed, it is repeatedly tried again on its variants generated by metarules. Term syntax and local syntax Metarules can be straightforwardly described by embedding the formalism into a logical framework where rule generation by metarules is calculated through unification. With this aim in mind, the definitions of term rules and metarules given in the preceding part can be transformed into logical (in)equations by using the formulae of Kasper and Rounds (1986). As in (VijayShanker 1992), type variables whose denotations are sets of structures derived from non-terminals can be replaced by monoadic predicates. Individual variables that stand for individual feature structures are used to capture reentrance. For example, rule (2) is translated into formula (6). A monoadic predicate arity is added to restrict the application of metarules. (6) XRD(x) &lt;=&gt; cat(x) = &apos;N&apos; A arity(x) = 2 lexicalization(x) x4 A metaLabel(x) A i(X) = X1 A cat(x1) = &apos;N&apos; A arity(xi) = 2 A 1(x1) = X2 A 2(x1) = X3 A cat(x2) &apos;N&apos; A lemma(x2) &apos;X&apos; A inflection(x2) 1 cat(x3) &apos;N&apos; A lemma(</context>
</contexts>
<marker>Kasper, Rounds, 1986</marker>
<rawString>Kasper, Robert T. and William C. Rounds. 1986. A logical semantics for feature structures. In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics, NY, June 1986, 257-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Langacker Ronald W</author>
</authors>
<title>Foundations of Cognitive Grammar. Vol I. Theoretical Prerequisites. Stanford:</title>
<date>1987</date>
<publisher>Stanford University Press.</publisher>
<marker>W, 1987</marker>
<rawString>Langacker Ronald W. 1987. Foundations of Cognitive Grammar. Vol I. Theoretical Prerequisites. Stanford: Stanford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip S Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships. Ph D diss in Computer Science,</title>
<date>1993</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="25223" citStr="Resnik (1993)" startWordPosition="3952" endWordPosition="3953">effect effect of short wave (permutation) short wave Figure 3. Acquisition of candidate terms through variation 117 Term Prepositions Membrane cell in [4], into, to Myeloid cell of [3], from Blood cell from [8], in [13], into, on Tumor cell in [3], from [4], into, with, of Figure 4. Noun phrase interpretation through variation Although initially devised for automatic indexing, FASTR can play a crucial role in other text-based intelligent tasks. This part has sketched out a picture of incremental terminological acquisition and noun-phrase understanding through the analysis of term variants. As Resnik (1993) points out, large-scale knowledge sources can be used as a source of lexical information. Similarly, our approach to corpus linguistics makes a extensive use of terminological data and investigates systematically and precisely the variations of terms in technical corpora. The next natural step in term and compound processing is to provide FASTR with a learning ability. With this aim in mind, we are currently investigating two novel research directions: firstly, a hybridisation of FASTR with a connectionist model dedicated to nominal composition (Jacquemin 1993) and, secondly, a cooperation be</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Resnik, Philip S. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph D diss in Computer Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
<author>Alexis Manaster-Ramer</author>
</authors>
<title>A logical version of functional grammar.</title>
<date>1987</date>
<booktitle>In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>257--266</pages>
<location>Stanford CA,</location>
<contexts>
<context position="11232" citStr="Rounds and Manaster-Ramer 1987" startWordPosition="1727" endWordPosition="1730">restrict the application of metarules. (6) XRD(x) &lt;=&gt; cat(x) = &apos;N&apos; A arity(x) = 2 lexicalization(x) x4 A metaLabel(x) A i(X) = X1 A cat(x1) = &apos;N&apos; A arity(xi) = 2 A 1(x1) = X2 A 2(x1) = X3 A cat(x2) &apos;N&apos; A lemma(x2) &apos;X&apos; A inflection(x2) 1 cat(x3) &apos;N&apos; A lemma(x3) = &apos;ray&apos; inflection(x3) =, 1 A 2(4 = x4 A cat(x4) &apos;N&apos; lemma(x4) = &apos;diffraction&apos; A inflection(x4) 1 Standard fixed-point semantics is associated to this syntax which is used to calculate the interpretation of such formulae. The denotation of a formula is an automaton calculated through an inductive interpretation of the terms it contains (Rounds and Manaster-Ramer 1987). As a consequence of this mathematical formulation, the metarules are expressed as couples of monoadic predicates with shared variables. For example, the metarule of coordination (3) is described by formula (7). The syntax of both sides of the metarule is identical to the syntax of rules except for the monoadic rule predicate p which is a variable. stands for negation. (7) Coor(p(y) &lt;=&gt; arity(y)-2 A 1(y) yi A 2(y) = y2) = (Coor(p) (y) &lt;=&gt; arity(y) = 4 A 1(y) = 111 A 2(Y) = Y3 A 3(y) =-&amp;quot;&amp;quot;. Y4 A 4(Y) = Y2 cat(y3) &apos;C&apos; A-,(1emma(y4) &apos;but&apos;) --,(cat(y4) = &apos;Di&apos;) A -,(cat(y4) &apos;Dd&apos;) ) The result of th</context>
</contexts>
<marker>Rounds, Manaster-Ramer, 1987</marker>
<rawString>Rounds, William C. and Alexis Manaster-Ramer. 1987. A logical version of functional grammar. In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics, Stanford CA, July 1987, 257-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Savoy</author>
</authors>
<title>Stemming of French words based on grammatical categories.</title>
<date>1993</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>44</volume>
<pages>1--10</pages>
<contexts>
<context position="8031" citStr="Savoy 1993" startWordPosition="1197" endWordPosition="1198"> or neutron diffraction as a variant of X ray diffraction. (3) Metarule : Coor(Xi ----&gt; X2 X3) = xl —3 X2 C3 X4 X3 &amp;quot;C&apos; = conjunction&amp;quot; &lt;X1 metaLabel&gt; = &lt;C3 lemma&gt; I &apos;but&apos; &amp;quot; ! denotes inequality&amp;quot; &lt;X4 cat&gt; &apos;Dd&apos; &amp;quot;Dd&apos;= definite determiner&amp;quot; &lt;X4 cat&gt; I &apos;Di&apos;. &amp;quot;Dl&apos;= indefinite determiner&amp;quot; Parsing Morphology FASTR has been applied to the French and the English languages and can be easily extended to any language without word agglutination thanks to an external description of morphology. The suffix stripping operation precedes syntactic analysis and requires a dictionary of lemmas and a declension file (Savoy 1993). Each entry in the dictionary has a basic stem and words with an irregular inflectional morphology such as mouse/mice have one or more auxiliary stems. Derivational links such as synapse/ synaptic can also be accounted for through multi-valued part-of-speech categories such as noun-adjective. The declension file is illustrated by formulae (4) and (5). A set of features is provided for each inflectional case of each inflected category (e.g. (4) for nouns). A list of suffixes corresponds to each declension class (e.g. (5) for the first two classes of nouns). ?1 indicates the first auxiliary ste</context>
</contexts>
<marker>Savoy, 1993</marker>
<rawString>Savoy, Jacques. 1993. Stemming of French words based on grammatical categories. 1993. Journal of the American Society for Information Science, Vol. 44, No 1, January 1993, 1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing with Lexicalized Tree Adjoining Grammar.</title>
<date>1990</date>
<booktitle>In Current Issues in Parsing Technologies, Masaru Tomita (edt),</booktitle>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="15371" citStr="Schabes and Joshi (1990)" startWordPosition="2444" endWordPosition="2447">oach. The computational performances of the application reported in (Jacquemin 1994a) indicate that the parser only spends 10% of its time in generating metarules and fully justify the run-time approach. 115 Computational Lexicalization The keystone of the computational tractability is lexicalization which allows for a bottom-up filtering of the rules before parsing. It is completed by fast mechanisms for data access such as a B-Tree (for the disk resident lexicon of single words) and a Hash-Code table (for the memory resident stop words). The formalism of FASTR is lexicalized in the sense of Schabes and Joshi (1990) because it is composed of rules associated with each lexical item which is the anchor of the corresponding rules. The parsing algorithm for lexicalizecl grammars takes advantage of lexicalization through a two-step strategy. The first step is a selection of the rules linked to the lexical items in the input. The second step parses the input with a grammar restricted to the filtered rules. In case of rules with multiple lexical items such as the rules representing multi-word terms, the anchor can be any of the lexical items. For example, the term aortic disease can be anchored either to aortic</context>
</contexts>
<marker>Schabes, Joshi, 1990</marker>
<rawString>Schabes, Yves and Aravind K. Joshi. 1990. Parsing with Lexicalized Tree Adjoining Grammar. In Current Issues in Parsing Technologies, Masaru Tomita (edt), Dordrecht: Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart N Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar.</title>
<date>1986</date>
<booktitle>CSLI Lecture Notes 4,</booktitle>
<publisher>CSLI.</publisher>
<location>Stanford, CA:</location>
<contexts>
<context position="3077" citStr="Shieber 1986" startWordPosition="420" endWordPosition="421">P system with large linguistic resources, there is tension between tractability and descriptive power. Finite state automata are efficient tools for lexical extraction. But their lack of convenience for information description makes the testing of different methodological choices difficult. Such a limitation is specifically problematic during the development stage. Symmetrically, unification-based parsers offer rich and conceptually tractable formalisms, but their computational cost is very high. The approach taken in FASTR is to use a convenient grammatical description stemming from PATR-II (Shieber 1986) associated with an optimized computational engine. Efficiency and constraint-based grammar formalism have motivated the acronym of the application (FAST + PATR-II) that stands for FAST TERM RECOGNIZER. When terminology extraction is applied to automatic indexing, two measures are important: recall and precision. Precision is crucial for applications using acquisition methods which are subject to an excessive recall, blurring terminological entries with syntactic recurrences or semantic preferences. Conversely, in a knowledge-based method like FASTR, recall is a decisive evaluation of the cove</context>
<context position="5400" citStr="Shieber 1986" startWordPosition="772" endWordPosition="773">pplied to these rules and yield transformed rules used to extract terms and their variants. For example, from the preceding sentence and from a grammar including term variant, the sequence terms and their variants would be extracted as a variation of term variant. The data required by FASTR consist of a declension file, an initial terminological database and an on-line dictionary to transform terms into compilable linguistic data. As far as human time is concerned, only a slight experimental tuning of the metarules is necessary. A Three-tier Formalism The formalism of FASTR stems from PATR-H (Shieber 1986). Rules are composed of a context-free portion describing the concatenation of the constituents and a set of equations constraining information of these constituents. The description of a single word includes minimally the string of the word stem, a part-of-speech category and its inflection number. These three values are used to dynamically rebuild the different inflections of the word. They are automatically extracted from an on-line dictionary with morphological information. We currently use the DELAS dictionary of LADL laboratory (University of Paris 7). For example, rule (1) describes the</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart N. 1986. An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes 4, Stanford, CA: CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>Karen</author>
<author>J I Tait</author>
</authors>
<title>Automatic Search Term Variant Generation.</title>
<date>1984</date>
<journal>Journal of Documentation,</journal>
<volume>40</volume>
<pages>50--66</pages>
<marker>Jones, Karen, Tait, 1984</marker>
<rawString>Sparck Jones, Karen and J. I. Tait. 1984. Automatic Search Term Variant Generation. Journal of Documentation, Vol. 40, No. 1, March 1984, 50-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Barbara Vauthey</author>
</authors>
<title>Information Retrieval Using Robust Natural Language Processing.</title>
<date>1992</date>
<booktitle>In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics (ACL&apos;92),</booktitle>
<pages>104--111</pages>
<location>Newark, DE,</location>
<contexts>
<context position="22150" citStr="Strzalkowski and Vauthey (1992)" startWordPosition="3499" endWordPosition="3502">es. Thirdly, our research on term extraction places great stress on term variations. The most direct precursors of the use of term variation in information retrieval are Sparck Jones and Tait (1984). These authors advocate the systematic generation of syntactic term variants in query processing. Their approach, however, makes the assumption that only semantic equivalent variant should be generated and that each of the words in a variant should be given instead of allowing paradigmatic places. They only account for restricted associations such as information retrieval/retrieval of information. Strzalkowski and Vauthey (1992) follow the way suggested by Sparck Jones and Tait (1984) at the end of their paper. Instead of generating term variants in a query, they look for different term occurrences in text documents analyzed by a general multipurpose parser. Their parse trees are composed of head/modifier relations of four categories. These four classes account for most of the syntactic variants of two-word terms into pairs with compatible semantic content such as information retrieval/information retrieval system/retrieval of information from databases... We think however that most of these variants can be extracted</context>
</contexts>
<marker>Strzalkowski, Vauthey, 1992</marker>
<rawString>Strzalkowski, Tomek and Barbara Vauthey. 1992. Information Retrieval Using Robust Natural Language Processing. In Proceedings, 30th Annual Meeting of the Association for Computational Linguistics (ACL&apos;92), Newark, DE, June 1992, 104-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
</authors>
<title>Using Description of Trees in a Tree Adjoining Grammar.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<pages>481--518</pages>
<contexts>
<context position="19974" citStr="Vijay-Shanker 1992" startWordPosition="3177" endWordPosition="3178">4) a) 0) 20,000 (a. ° 10,000 0, e .s E 3,000 o_ 2,000 0 1,000 -0 better precision could be reached through a more accurate description of permutation. An improvement in term variant recall requires the handling of elision. Related Work Firstly, our formalism is inspired by two fields of lexicalized and logical tree formalisms. The first one is the general framework of Lexicalized Tree Adjoining Grammar (LTAG) which has shown to be fruitful for the description of idioms (Abeille and Schabes 1989). The second one is the important extension of Tree Adjoining Grammar (TAG) to a logical framework (Vijay-Shanker 1992) which contrasts with the traditional approach that operations in a TAG combine trees. From these works, we have adopted the constraint of LTAG which states that rules must have at least one lexical frontier node together with the logical representation of Vijay-Shanker (1992) where rules are not restricted to immediate dependency. The lexicalized tree grammar is motivated by the domain to be described: terms mainly consist of compounds with an internal structure and lexical constituents. The logical formalism provides us with a straightforward extension to metarules. Secondly, our approach to</context>
</contexts>
<marker>Vijay-Shanker, 1992</marker>
<rawString>Vijay-Shanker, K. 1992. Using Description of Trees in a Tree Adjoining Grammar. Computational Linguistics, Vol. 18, No. 4, December 1992, 481-518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willielm Weisweber</author>
<author>Susanne Preull</author>
</authors>
<title>Direct Parsing with Metarules. In</title>
<date>1992</date>
<booktitle>Proceedings, 14th International Conference on Computational Linguistics (COLING&apos;92),</booktitle>
<pages>1111--1115</pages>
<location>Nantes,</location>
<contexts>
<context position="14443" citStr="Weisweber and Preull (1992)" startWordPosition="2300" endWordPosition="2303"> set of categories is not available in FASTR. However, an empty category in the context-free skeleton can stand for any subtree of the original rule. Thus, variable yi from metarule (7), associated to X2 in formula (3), stands for the subterm X ray when applied to rule (6). When implementing metarules in a grammar parser, there are two possibilities for the time to apply the metarules to a rule. The compile-time application calculates all the images of all the rules in the grammar prior to parsing. In the run-time approach, metarules are dynamically applied to the active rules during parsing. Weisweber and Preull (1992) demonstrate that there is no difference in complexity between both approaches. Moreover, in the compile-time approach, metarules generate a huge set of transformed rules which may make the parsing process totally inefficient. Due to the very large size of our grammar, we have opted for the dynamic approach. The computational performances of the application reported in (Jacquemin 1994a) indicate that the parser only spends 10% of its time in generating metarules and fully justify the run-time approach. 115 Computational Lexicalization The keystone of the computational tractability is lexicaliz</context>
</contexts>
<marker>Weisweber, Preull, 1992</marker>
<rawString>Weisweber, Willielm and Susanne Preull. 1992. Direct Parsing with Metarules. In Proceedings, 14th International Conference on Computational Linguistics (COLING&apos;92), Nantes, July 1992, 1111-1115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uri Zernik</author>
</authors>
<title>Shipping Departments vs. Shipping Pacemakers : Using Thematic Analysis to Improve Tagging Accuracy.</title>
<date>1992</date>
<booktitle>In Proceedings, Annual Meeting of the American Association for Artificial Intelligence (AAAI-92),</booktitle>
<pages>335--342</pages>
<marker>Zernik, 1992</marker>
<rawString>Zernik, Uri. 1992. Shipping Departments vs. Shipping Pacemakers : Using Thematic Analysis to Improve Tagging Accuracy. In Proceedings, Annual Meeting of the American Association for Artificial Intelligence (AAAI-92), 335-342.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>