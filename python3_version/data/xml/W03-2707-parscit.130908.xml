<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.998194">
Automating Hinting in Mathematical Tutorial Dialogue
</title>
<author confidence="0.992445">
Armin Fiedler Dimitra Tsovaltzi
</author>
<affiliation confidence="0.999837">
Department of Computer Science Department of Computational Linguistics
Saarland University Saarland University
</affiliation>
<email confidence="0.893901">
afiedler@cs.uni—sb.de dimitra@coli.uni—sb.de
</email>
<keyword confidence="0.4614">
Thematic Session: Adaptation and learning in
spoken dialogue systems
</keyword>
<sectionHeader confidence="0.995064" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962571428571">
In spite of psychological substantia-
tion of hinting, most intelligent tutoring
systems do not systematically produce
hints. In this paper we present a taxon-
omy of hints for tutoring mathematics.
Based on this taxonomy, we suggest an
algorithm for the production of hints.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977818181818">
Although there has been psychological evidence
(Chi et al., 1994; Rosé et al., 2001) for the high
educational effect of hinting, most intelligent tu-
toring systems do not take advantage of the find-
ings. Only little systematic research in automating
hinting has been done (Hume et al., 1996b; Fiedler
and Horacek, 2001; Tsovaltzi, 2001).
In the DIALOG project, we undertake the goal
of tackling some problems of mathematical tutor-
ing dialogue systems in the domain of naive set
theory (Pinkal et al., 2001). More specifically, DI-
ALOG aims at providing a mathematical knowl-
edge base that would serve as the basis for the
study material, a user-adaptive dialogue system
modelling tutorial dialogues and an advanced the-
orem prover fitting the needs of planning for tuto-
rials. In this framework, we have been investigat-
ing the automation of the hinting process.
A mathematical tutoring system must be able to
tutor proofs in a way that not only helps the student
understand the current proof, but also allows for a
high learning effect. What is meant by the latter is
the ability of the students not only to better under-
stand the problem at hand, but also to generalise
and apply the taught strategies on their own later
on. We propose to establish those tutoring aims by
making use of the Socratic tutoring method (Per-
son et al., 2000; Rosé et al., 2001). The decisive
characteristic of the socratic method is the use of
hints in order to achieve self-explanation, as op-
posed to answers and explanations being provided
constantly by the tutor, which is characteristic of
the didactic method (Rosé et al., 2001; Tsovaltzi
and Matheson, 2002).
Hinting is a method that aims at encouraging
active learning. It can take the form of eliciting in-
formation that the student is unable to access with-
out the aid of prompts, or information which he
can access but whose relevance he is unaware of
with respect to the problem at hand. Alternatively,
a hint can point to an inference that the student is
expected to make based on knowledge available to
him, which helps the general reasoning needed to
deal with a problem (Hume et al., 1996b).
In this paper, we shall first give in Section 2 a
taxonomy of hints that we developed for the do-
main of mathematics tutoring. Next, in Section 3,
we shall propose an algorithm for producing hints
based on that taxonomy. This hinting algorithm
is envisaged as part of a dialogue manager, which
accounts also for other types of dialogues, such as
clarification sub-dialogues and question answer-
ing. Then, in Section 4, the algorithm will be sup-
plemented with an example, before we conclude
the paper.
</bodyText>
<sectionHeader confidence="0.985646" genericHeader="method">
2 A Taxonomy of Hints
</sectionHeader>
<bodyText confidence="0.997838">
In this section we shall explain the philosophy
and the structure of our hint taxonomy. We shall
also look into the most representative hints that
are used in the algorithm. The names of the cate-
gories are intended to be as descriptive of the con-
</bodyText>
<page confidence="0.998687">
45
</page>
<bodyText confidence="0.999992571428571">
tent as possible, and should in some cases be self-
explanatory. Our taxonomy includes more than
the hint categories mentioned in this section. The
full taxonomy is given in Table 1. Some of the
strategies are not real hints (e.g., point-to-lesson),
but they have been included in the taxonomy be-
cause they are part of the general hinting process.
</bodyText>
<subsectionHeader confidence="0.956955">
2.1 Philosophy and Structure
</subsectionHeader>
<bodyText confidence="0.99998765">
Our hint taxonomy was derived with regard to the
underlying function that can be common for differ-
ent surface realisations. The underlying function
is mainly responsible for the educational effect of
hints. The surface structure, which undoubtedly
plays its own significant role in teaching, is yet to
be examined in the naive set theory domain.
We defined our hint categories based on the
needs in the domain. In order to estimate those
needs we defined the relations between the ob-
jects in the domain. More specifically, we defined
the inter-relations between mathematical concepts
as well as between concepts and inference rules,
which are used in proving. An additional guide
for deriving hint categories that are useful for tu-
toring in our domain was a previous hint taxon-
omy, which was derived from the BE&amp;E corpus
(Tsovaltzi, 2001).
The structure of the hint taxonomy reflects the
function of the hints with respect to the informa-
tion that the hint addresses or is meant to trigger.
In order to capture different functions of a hint we
define hint categories across two dimensions.
Before we introduce the dimensions, let us clar-
ify some terminology. In the following, we dis-
tinguish performable steps from meta-reasoning.
Performable steps are the steps that can be found
in the formal proof. These include premises,
conclusion and inference methods such as lem-
mata, theorems, definitions of concepts, or calcu-
lus level rules (e.g., proof by contradiction). Meta-
reasoning steps consist of everything that leads to
the performable step, but cannot be found in the
formal proof. To be more specific, meta-reasoning
consists of everything that could potentially be ap-
plied to any particular proof. It involves general
proving techniques. As soon as a general tech-
nique is instantiated for the particular proof, it be-
longs to the performable step level.
The two hint dimensions consist of the follow-
</bodyText>
<listItem confidence="0.970068">
ing classes:
1. active vs. passive hints
2. domain-relation vs. domain-object vs.
inference-rule vs. substitution vs. meta-
reasoning vs. performable-step hints
</listItem>
<bodyText confidence="0.999819875">
In the second dimension, we ordered the classes
with respect to their subordination relation. We
say, that a class is subordinate to another one if it
reveals more information. In addition, the class of
pragmatic hints belongs to the second dimension
as well, but we define it so that it is not subordinate
to any other class and no other class is subordinate
to it.
</bodyText>
<subsectionHeader confidence="0.996703">
2.2 First Dimension
</subsectionHeader>
<bodyText confidence="0.999991318181818">
The first dimension distinguishes between the ac-
tive and passive function of hints. The difference
lies in the way the information to which the tu-
tor wants to refer is approached. The idea be-
hind this distinction resembles that of backward-
vs. forward-looking function of dialogue acts in
DAMSL (Core and Allen, 1993). The active func-
tion of hints looks forward and seeks to help the
student in accessing a further bit of information,
by means of eliciting, that will bring him closer
to the solution. The student has to think of and
produce the answer that is hinted at.
The passive function of hints refers to the small
piece of information that is provided each time in
order to bring the student closer to some answer.
The tutor gives away some information, which he
has normally unsuccessfully tried to elicit previ-
ously. Due to that relation between the active and
passive function of hints, the passive function of
one hint class in the second dimension consists of
hint categories that are included in the active func-
tion in its subordinate class.
</bodyText>
<subsectionHeader confidence="0.999105">
2.3 Second Dimension
</subsectionHeader>
<bodyText confidence="0.999782">
Domain-relation hints address the relations be-
tween mathematical concepts in the domain. An
example of a relation that we have defined is an-
tithesis, which captures that two concepts are op-
posites. For example, the element relation E is in
antithesis to its opposite V. The passive function
of domain-relation hints is the active function of
domain-object hints, that is, they are used to elicit
domain objects.
</bodyText>
<page confidence="0.999003">
46
</page>
<table confidence="0.979014">
active passive
domain-relation elicit-antithesis give-away-antithesis
elicit-duality give-away-duality
elicit-junction give-away-junction
elicit-hypotaxis give-away-hypotaxis
elicit-specialisation give-away-specialisation
elicit-generalisation give-away-generalisation
domain-object give-away-antithesis give-away-relevant-concept
give-away-duality give-away-hypotactical-concept
give-away-junction give-away-primitive-concept
give-away-hypotaxis
give-away-specialisation
give-away-generalisation
inference rule give-away-relevant-concept give-away-inference-rule
give-away-hypotactical-concept
give-away-primitive-concept
elaborate-domain-object
substitution give-away-inference-rule spell-out-substitution
elicit-substitution
meta-reasoning spell-out-substitution explain-meta-reasoning
performable-step explain-meta-reasoning give-away-performable-step
confer-to-lesson
pragmatic ordered-list take-for-granted
unordered-list point-to-lesson
elicit-discrepancy
</table>
<tableCaption confidence="0.999782">
Table 1: The taxonomy of hints.
</tableCaption>
<bodyText confidence="0.999933288461538">
Domain-object hints address an object in the
domain. The hint give-away-relevant-concept
names the most prominent concept in the propo-
sition or formula under consideration. This might
be, for instance, the concept whose definition
the student needs to use in order to proceed
with the proof, or the concept that will in gen-
eral lead the student to understand which infer-
ence rule he has to apply. Other examples in
the class are give-away-hypotactical-concept and
give-away-primitive-concept. The terms hypotac-
tical and primitive concept refer to the relation,
based on the domain hierarchy, between the ad-
dressed concept and the original relevant concept,
which the tutor is trying to elicit. The passive
function of domain-object hints is used to elicit the
applicable inference rule, and, therefore, is part of
the active function of the respective class.
Inference-rule hints refer to the inference rules
in the domain that need to be applied in the cur-
rent proof. An additional active inference rule
hint is elaborate-domain-object. It asks the stu-
dent to elaborate on the domain object at hand
in order to elicit the inference rule. The passive
function, give-away-inference-rule, names the in-
ference rule to be used. It is used to elicit the sub-
stitution of the rule for the problem at hand.
The active function of substitution hints consists
of the passive function of the inference-rule hint
plus the hint elicit-substitution. The latter asks the
student to bind variables of the inference rule. The
passive function spell-out-substitution explains to
the student the way the substitution is done.
The active function of meta-reasoning hints is
spell-out-substitution. It is, thus, the last hint that
leads to the completion of the hints about the meta-
reasoning employed. Therefore, its passive func-
tion explains the meta-reasoning employed so far.
The active function of performable-step hints
consists of the passive function of meta-reasoning
hints plus the hint confer-to-lesson, which points
the student to the section in the study material
where the answer can be found. Since there is
no meta-reasoning left to be explained, the passive
function is give-away-performable step.
Finally, the class of pragmatic hints is some-
what different from other classes in that it makes
use of minimal domain knowledge. It rather refers
to pragmatic attributes of the expected answer.
The active function hints are ordered-list, which
specifically refers to the order in which the parts of
the expected answer appear, unordered-list, which
</bodyText>
<page confidence="0.99604">
47
</page>
<bodyText confidence="0.9999763125">
only refers to the number of the parts, and elicit-
discrepancy, which points out that there is a dis-
crepancy between the student&apos;s answer and the ex-
pected answer. The latter can be used in place of
all other active hint categories. Take-for-granted
asks the student to just accept something as a fact
either when the student cannot understand the ex-
planation or when the explanation would require
making use of formal logic. Point-to-lesson points
the student to the lesson in general and asks him
to read it again when it appears that he cannot be
helped by tutoring because he does not remember
the study material. There is no one-to-one cor-
respondence between the active and passive prag-
matic hints. Some pragmatic hints can be used in
combination with hints from other classes.
</bodyText>
<sectionHeader confidence="0.980361" genericHeader="method">
3 A Hinting Algorithm
</sectionHeader>
<bodyText confidence="0.999983739130435">
A tutorial system ideally aims at having the stu-
dent find the solution to a problem by himself.
Only if the student gets stuck should the system
intervene. There is pedagogical evidence (Chi et
al., 1994; Rosé et al., 2001) that students learn
better if the tutor does not give away the answer
but instead gives hints that prompt the student for
self-explanations. Accordingly, based on the work
by Tsovaltzi (2001) we have derived an algorithm
that implements an eliciting strategy that is user-
adaptive by choosing hints tailored to the students.
Only if hints appear not to help does the algorithm
switch to an explaining strategy, where it gives
away the answer and explains it. We shall fol-
low Person and colleagues (2000) and Rosé and
colleagues (2001) in calling the eliciting strategy
socratic and the explaining strategy didactic.
To determine which parts of the solution need to
be addressed the algorithm has to examine the stu-
dent&apos;s answer. Therefore, we shall briefly present
the student answer categories we use in the algo-
rithm in Section 3.1 before we introduce the hint-
ing algorithm in more detail in Section 3.2.
</bodyText>
<subsectionHeader confidence="0.998951">
3.1 Student Answer Categories
</subsectionHeader>
<bodyText confidence="0.999888">
The algorithm that determines if a hint is to be pro-
duced and chooses the hint takes into account the
last answer the student has given. In particular, we
need to categorise the student&apos;s answer in terms of
its completeness and accuracy with respect to the
expected answer. We say that an answer is COM-
plete if and only if all desired parts of the answer
are mentioned. We say that a part of an answer
is accurate if and only if the propositional content
of the part is the true and desired one. Based on
these notions, we define the following student an-
swer categories:
Correct: The answer is complete and all parts are
accurate.
Incomplete-Accurate: The answer is incom-
plete, but all parts that are there are accurate.
Inaccurate: The answer is complete or incom-
plete, but some parts of the answer are inac-
curate.]
Wrong: The answer is incomplete and all parts
are inaccurate.
We consider over-answering as several distinct
answers, that is, if the student&apos;s answer has more
parts than needed, these parts are considered as an-
other answer, which can be categorised in turn.
</bodyText>
<subsectionHeader confidence="0.994029">
3.2 The Algorithm
</subsectionHeader>
<bodyText confidence="0.9999853">
We shall now present an algorithm that imple-
ments the socratic strategy. In intuitive terms, the
algorithm aims at having the student find the proof
by himself. If the student does not know how to
proceed or makes a mistake, the algorithm prefers
hinting at the right solution in order to elicit the
problem solving instead of giving away the an-
swer. An implicit student model makes the algo-
rithm sensitive to students of a different level by
providing increasingly informative hints. Only if
the hinting does not effect correct student answers
after several hints does the algorithm switch to a
didactic strategy, and, without hinting, explains
the steps that the student cannot find himself. Nev-
ertheless, the algorithm continues to ask the stu-
dent for the subsequent step. If the student gives
correct answers again and, thus, the tutor need not
explain anymore, the algorithm switches back to
the socratic strategy. In effect, hints are provided
again to elicit the step under consideration.
</bodyText>
<footnote confidence="0.988807">
1Note that this category is in fact an aggregation of several
categories, which we need not distinguish for the purposes of
this paper.
</footnote>
<page confidence="0.996579">
48
</page>
<subsectionHeader confidence="0.477955">
The Main Algorithm
</subsectionHeader>
<bodyText confidence="0.999332333333333">
The algorithm takes into account not only current
and previous student answers and the number of
wrong answers, but also the previous hints it pro-
duced both with respect to the hint category and
the number of hints produced. The essentials of
the algorithm are as follows:
</bodyText>
<listItem confidence="0.986475">
1. if the proof is not completed
then prompt for the next step
else stop
2. analyse the student answer
3. if the student&apos;s answer is correct
then accept the answer and go to step 1.
else call the function socratic on the
</listItem>
<bodyText confidence="0.938150052631579">
inaccurate and missing parts of the
student&apos;s answer
The Function socratic
The bulk of the work is done by the function so-
cratic, which we only outline here. The function
takes as an argument the category C of the stu-
dent&apos;s current answer. If the origin of the student&apos;s
mistake is not clear, a clarification dialogue is initi-
ated, which we shall not describe here. Note, how-
ever, that the function stops if the student gives the
correct answer during that clarification dialogue,
as that means that the student corrected himself.
Otherwise, the function produces a hint in a user-
adaptive manner.
The function socratic calls several other func-
tions, which we shall explain subsequently.
Let H denote the number of hints produced so
far and the category of the student&apos;s previous
answer. The hint is then produced as follows:
</bodyText>
<figure confidence="0.906372194444444">
Case H = 0
if C is wrong or inaccurate then call elicit
if C is incomplete-accurate
then produce an active pragmatic hint
{that is, ordered-list or unordered-list}
Case H = 1
if C is wrong
then if C_1 is wrong or incomplete-accurate
then call up-to-inference-rule
if C_1 is inaccurate
then call elicit-give-away
if C_1 is correct
then call elicit
else call elicit
Case H = 2
if C is wrong
then if this is the third wrong answer
then produce explain-meta-reasoning
else if previous hint was an active
substitution hint
then produce spell-out-substitution
else if previous hint was
spell-out-substitution
then produce
give-away-performable-step
else call up-to-inference-rule
else call elicit-give-away
Case H = 3
if C is wrong and it is at least the third wrong
answer
then produce point-to-lesson and stop
{The student is asked to read the lesson
again. Afterwards, the algorithm starts
anew. }
else produce explain-meta-reasoning
Case H &gt; 4
</figure>
<bodyText confidence="0.9535433125">
give away the answer and switch to didactic
strategy; switch back after three consecutive cor-
rect answers with all counters reset
{After four hints, the algorithm starts to guide the student
more than before to avoid frustration. If the student is able
to follow again the tutor&apos;s plan for addressing the task, the
algorithm switches back to the socratic strategy again and
lets the student take over. If the student carries on giving
correct answers the main algorithm guarantees that the tu-
tor just accepts the answer and does not intervene further.
Only if the student makes a mistake again will the hinting
start anew with all counters reset. }
After having produced a hint the function So-
cratic analyses the student&apos;s answer to that hint.
If the student&apos;s answer is still not right the func-
tion socratic is recursively called. However,
if the student answers correctly and at least two
hints have been produced the algorithm re-visits
the produced hints in the reverse order to recapitu-
late the proof step and to make sure the student un-
derstands the reasoning so far. This is done by pro-
ducing a sequence of active meta-reasoning hints,
one for each hint that have addressed the current
step of the proof, in the reverse order. If the active
meta-reasoning hints get the student to say any-
thing but the right answer, the algorithm produces
an explain-meta-reasoning hint. This is done to
avoid frustrating the student as his performance is
poor.
The function socratic calls several functions,
which we shall present now. The functions are
self-explanatory.
</bodyText>
<subsectionHeader confidence="0.707469">
Function elicit
</subsectionHeader>
<bodyText confidence="0.5225726">
if the student knows the relevant concept
then if the student knows the inference rule
then call up-to-substitution
else call up-to-inference-rule
else call elicit-relevant-concept
</bodyText>
<subsectionHeader confidence="0.380272">
Function elicit—give—away
</subsectionHeader>
<bodyText confidence="0.73184">
if previous hint was an active domain-object
hint
then call up-to-inference-rule
else if previous hint was a passive
</bodyText>
<page confidence="0.996913">
49
</page>
<figure confidence="0.973572629629629">
domain-object hint
then produce elaborate-domain-object
else if previous hint was
elaborate-domain-object
then call up-to-substitution
else produce give-away-performable-step
and spell-out-substitution
{this is to explain the substitution}
Function up-to-inference-rule
if previous hint was
give-away-hypotactical-concept
then produce give-away-inference-rule
else if previous hint was
give-away-relevant-concept
then produce elaborate-domain-object
else if previous hint was
elaborate-domain-object
then produce
give-away-hypotactical-concept
else produce
give-away-relevant-concept
Function up-to-substitution
if previous hint was elicit-substitution
then produce spell-out-substitution
else if right inference rule known
then produce elicit-substitution
else produce give-away-inference-rule
</figure>
<subsectionHeader confidence="0.591301">
Function elicit-relevant-concept
</subsectionHeader>
<bodyText confidence="0.964479">
if the student knows a concept that is related
to the relevant concept
then produce an active domain-object hint
else produce give-away-relevant-concept
</bodyText>
<sectionHeader confidence="0.954733" genericHeader="method">
4 An Example Dialogue
</sectionHeader>
<bodyText confidence="0.958152365384616">
To elucidate how the algorithm for the socratic tu-
toring strategy proceeds, let us consider the fol-
lowing dialogue as it might occur between a tu-
toring system and a student. The tutoring sys-
tem, denoted as tutor in the following, is supposed
to teach the proof of the proposition AnB E
P(A U B), where P(X) stands for the powerset
of the set X, that is, the set of all subsets of X,
including the empty set and X itself. The proof is
as follows: Obviously, AnB C AU B. Thus, the
proposition follows by the definition of powerset.
When the algorithm starts, the counter H for the
hints produced so far is initialised to 0. Since the
proof is not completed, the tutor prompts for the
first step by introducing the task.
Tutor (1): Prove that AnB e P(A U B).
The expected answer is that by the application
of the definition of powerset it suffices to show that
AnBcAuB. However, the student answers:
Student (2): I don&apos;t know how to prove that.
This utterance is categorised as a wrong answer,
since it does not contain any accurate part. Thus
the algorithm calls the function socratic. Since
H = 0, it calls the functions elicit and, thus,
elicit-relevant-concept and eventually pro-
duces a hint of type give-away-relevant-concept
(where powerset is the relevant concept) to elicit
the inference rule (namely, the application of a
definition).
Tutor (3): Think of using powerset.
With the production of this hint, the counter H
is incremented by 1. However, this hint is not suf-
ficient to help the student:
Student (4): How can I use it?
This again is categorised as a wrong answer.
Thus, the function socratic is called recursively.
Since H = 1, the function up-to-inference-
rule is called, which produces a hint of type
elaborate-domain-object to elicit the inference
rule.
Tutor (5): What are the properties of powerset?
Again, the counter H is incremented by 1. The
student answers:
Student (6): I don&apos;t know.
This answer is also considered as wrong. Since
this is the third wrong answer and H = 2, the al-
gorithm now produces an explain-meta-reasoning
hint and explains the reasoning behind this step.
Tutor (7): You can start by applying the definition of
powerset, which connects powerset to subset.
This will simplify the problem.
The counter H is again incremented by 1.
</bodyText>
<subsectionHeader confidence="0.575795">
Student (8): I don&apos;t understand.
</subsectionHeader>
<bodyText confidence="0.988345875">
This is again a wrong answer. Since H = 4, the
algorithm produces a give-away-performable-step
hint:
Tutor (9): According to the definition, the powerset of
a set X is the set of all subsets Y of X. That
is, if Y C X then Y E P(X). Now, you need to
substitute X and Y with the right formulae from
the proposition you want to prove.
</bodyText>
<page confidence="0.990141">
50
</page>
<bodyText confidence="0.977282551724138">
Subsequently, the system switches to the didac-
tic strategy, which we will not pursue in this pa-
per. After having completed the explanation of
this proof step, the system re-visits all hints pro-
duced by the socratic strategy while explaining the
step, and makes the student aware of why they
were produced. However, we will not go into such
detail here, since it is not in the focus of this paper.
Instead, let us examine what happens if the stu-
dent gives partial answers. Let us assume that the
first hint uttered in (3) leads the student into the
right direction:
Student (4&apos;): I can try to apply the definition of power-
set.
Since the student names the correct inference
rule, but does not give the instantiation, this is con-
sidered as an incomplete-accurate answer. Hence,
the algorithm calls the function elicit. Since the
student already knows both the right relevant con-
cept and the right inference rule, the tutor produces
an elicit-substitution hint:
Tutor (5&apos;): Can you spell out the application?
Student (6&apos;): From the definition of the powerset fol-
lows that if AnB c AuB then AnB E P(AuB).
That is, all I have to do is prove that AnB c AuB.
This is the correct answer, which also completes
the first proof step. Since only one hint was pro-
duced, the recapitulation is omitted. Thus the al-
gorithm proceeds with prompting for the next step.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="related work">
5 Related Work and Discussion
</sectionHeader>
<bodyText confidence="0.999873904761905">
Several other tutorial systems tackle hinting strate-
gies as well. The BE&amp;E project (Core et al., 2000)
investigated multi-turn tutorial strategies in basic
electricity and electronics. Some of these strate-
gies are motivated by similar theoretical interests
to the ones presented here. However, the number
of strategies is small and no emphasis is given to
the way information is made salient, which is the
aim of our taxonomy. Moreover, there are no crite-
ria, equivalent to our algorithm, for choosing one
strategy over another.
Ms. Lindquist (Heffernan and Koedinger,
2000), a tutorial system for high-school algebra,
also has some domain specific types of questions
that resemble the BE&amp;E strategies in form. Al-
though there is some mention of hints, and the no-
tion of gradually revealing information by rephras-
ing the question is prominent, there is no taxon-
omy of hints or any suggestions for dynamically
producing them.
An analysis of hints can also be found in the
CIRCSIM-Tutor (Hume et al., 1996a; Hume et al.,
1996b), an intelligent tutoring system for blood
circulation. Our work has been largely inspired by
the CIRCSIM project both for the general plan-
ning of the hinting process and for the taxonomy
of hints. CIRCSIM-Tutor uses domain specific
hint tactics that are applied locally, but does not
include a global hinting strategy that models the
cognitive reasoning behind the choice of hints.
We, instead, make use of the hinting history in
a more structured manner. Our algorithm takes
into account the kind of hints produced previ-
ously as well as the necessary pedagogical knowl-
edge, and follows a smooth transition from less
to more informative hints. Furthermore, we have
defined a structured hint taxonomy with refined
definition of classes and categories based on the
passive vs. active distinction, which is similar to
active-passive continuum in CIRCSIM. We have
distinguished these from functions, which resem-
ble CIRCSIM tactics, but are again more detailed
and more clearly defined. All this facilitates the
automation of the hint production.
AutoTutor (Person et al., 2000) uses curriculum
scripts on which the tutoring of computer literacy
is based. There is mention of hints that are used
by every script. Although it is not clear exactly
what those hints are, they seem to be static. More
emphasis seems to be put on the pedagogically ori-
ented choice of dialogue moves, prosodic features
and facial expression features, but not on hints. In
contrast, we have presented in this paper a hint tax-
onomy (cf. Section 2) and a tutoring algorithm (cf.
Section 3) that models the dynamic generation of
hints according to the needs of the student.
AutoTutor also uses a cycle of prompting-
hinting-elaborating. This structure relies on the
different role of the dialogue moves involved to
capture the fact that the tutor provides more and
more information if the student cannot follow the
tutoring well. However, it does not provide hints
that themselves reveal more information as the tu-
</bodyText>
<page confidence="0.994809">
51
</page>
<bodyText confidence="0.999963">
toring process progresses, which we have mod-
elled in our algorithm for the Socratic teaching
method (cf. Section 3). Thus, the student is not
merely made to articulate the expected answers, as
is the case in AutoTutor, but he is also encouraged
to actively produce the content of the answer itself.
Furthermore, the separation of the study material
and the tutoring session facilitates the production
of the answers by the student, since the tutor does
not have to present the material and re-elicit it in
one and the same session. The student is guided
through making use of the study material that he
has already read in order to solve the problem.
</bodyText>
<sectionHeader confidence="0.990659" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999994045454546">
There is psychological evidence that hinting in tu-
torial dialogue has a positive effect on the student&apos;s
learning (Chi et al., 1994; Rosé et al., 2001). To
take advantage of this effect, we have been devel-
oping a taxonomy of hints and a socratic algorithm
for hint production in tutorial dialogues in mathe-
matics. This algorithm should be easily adaptable
to other tutoring domains as well.
Before we implement the algorithm in an intel-
ligent system for tutorial dialogues, we chose to
perform Wizard-of-Oz experiments to test the ade-
quacy of the taxonomy and the effectiveness of the
socratic algorithm. The experiments have already
been completed and are currently being evaluated.
The socratic algorithm presented in this paper
does not deal with the realisation of the hints. We
are currently investigating the surface structure of
hints and their generation. Moreover, the pro-
duced hints do not necessarily complete the tutor&apos;s
dialogue turn. Further examination is needed to
suggest a model of dialogue moves and dialogue
specifications in our domain.
</bodyText>
<sectionHeader confidence="0.99882" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997931593220339">
Michelene T. H. Chi, Nicholas de Leeuw, Mei-Hung
Chiu, and Christian Lavancher. 1994. Eliciting self-
explanation improves understanding. Cognitive Sci-
ence, 18:439-477.
Mark G. Core and James F. Allen. 1993. Coding dia-
logues with DAMSL annotation scheme. In AAAI
Fall Symposium on Communicative Action in Hu-
mans and Machines, pages 28-35, Boston, MA.
Mark G. Core, Johanna D. Moore, and Claus Zinn.
2000. Supporting constructive learning with a feed-
back planner. In Proceedings of the AAAI Fall Sym-
posium: Building Dialogue Systems for Tutorial Ap-
plications, Falmouth, MA. AAAI Press.
Armin Fiedler and Helmut Horacek. 2001. Towards
understanding the role of hints in tutorial dialogues.
In BI-DIALOG: 5th Workshop on Formal Semantics
and Pragmatics in Dialogue, pages 40-44, Biele-
feld, Germany.
Neil T. Heffernan and Kenneth R. Koedinger. 2000.
Building a 3rd generation ITS for symbolization:
Adding a tutorial model with multiple tutorial strate-
gies. In Proceedings of the ITS 2000 Workshop on
Algebra Learning, Montréal, Canada.
Gregory Hume, Joel Michael, Allen Rovick, and
Martha Evens. 1996a. Student responses and fol-
low up tutorial tactics in an ITS. In Proceedings of
the 9th Florida Artificial Intelligence Research Sym-
posium, pages 168-172, Key West, FL.
Gregory D. Hume, Michael A. Joel, Rovick A. Allen,
and Martha W. Evens. 1996b. Hinting as a tactic
in one-on-one tutoring. Journal of the Learning Sci-
ences, 5(1):23-47.
Natalie K. Person, Arthur C. Graesser, Derek Harter,
Eric Mathews, and the Tutoring Research Group.
2000. Dialog move generation and conversation
management in AutoTutor. In Proceedings of the
AAAI Fall Symposium: Building Dialogue Systems
for Tutorial Applications, pages 45-51, Falmouth,
MA. AAAI Press.
Manfred Pinkal, Jorg Siekmann, and Christoph
Benzmiiller. 2001. Projektantrag Teilprojekt MI3
— DIALOG: Tutorieller Dialog mit einem mathe-
matischen Assistenzsystem. In Fortsetzungsantrag
SFB 378 — Ressourcenadaptive kognitve Prozesse,
Universitat des Saarlandes, Saarbriicken, Germany.
Carolyn P. Rosé, Johanna D. Moore, Kurt VanLehn,
and David Allbritton. 2001. A comparative eval-
uation of socratic versus didactic tutoring. In Jo-
hanna Moore and Keith Stenning, editors, Proceed-
ings 23rd Annual Conference of the Cognitive Sci-
ence Society, University of Edinburgh, Scotland,
UK.
Dimitra Tsovaltzi and Colin Matheson. 2002. Formal-
ising hinting in tutorial dialogues. In EDILOG: 6th
workshop on the semantics and pragmatics of dia-
logue, pages 185-192, Edinburgh, Scotland, UK.
Dimitra Tsovaltzi. 2001. Formalising hinting in tu-
torial dialogues. Master&apos;s thesis, Division of Infor-
matics, University of Edinburgh, Scotland, UK.
</reference>
<page confidence="0.998911">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909058">
<title confidence="0.999944">Automating Hinting in Mathematical Tutorial Dialogue</title>
<author confidence="0.998539">Armin Fiedler Dimitra Tsovaltzi</author>
<affiliation confidence="0.999945">Department of Computer Science Department of Computational Linguistics Saarland University Saarland University</affiliation>
<abstract confidence="0.988002636363636">afiedler@cs.uni—sb.de dimitra@coli.uni—sb.de Thematic Session: Adaptation and learning in spoken dialogue systems Abstract In spite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michelene T H Chi</author>
<author>Nicholas de Leeuw</author>
<author>Mei-Hung Chiu</author>
<author>Christian Lavancher</author>
</authors>
<title>Eliciting selfexplanation improves understanding.</title>
<date>1994</date>
<journal>Cognitive Science,</journal>
<pages>18--439</pages>
<marker>Chi, de Leeuw, Chiu, Lavancher, 1994</marker>
<rawString>Michelene T. H. Chi, Nicholas de Leeuw, Mei-Hung Chiu, and Christian Lavancher. 1994. Eliciting selfexplanation improves understanding. Cognitive Science, 18:439-477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark G Core</author>
<author>James F Allen</author>
</authors>
<title>Coding dialogues with DAMSL annotation scheme.</title>
<date>1993</date>
<booktitle>In AAAI Fall Symposium on Communicative Action in Humans and Machines,</booktitle>
<pages>28--35</pages>
<location>Boston, MA.</location>
<contexts>
<context position="6643" citStr="Core and Allen, 1993" startWordPosition="1090" endWordPosition="1093">n relation. We say, that a class is subordinate to another one if it reveals more information. In addition, the class of pragmatic hints belongs to the second dimension as well, but we define it so that it is not subordinate to any other class and no other class is subordinate to it. 2.2 First Dimension The first dimension distinguishes between the active and passive function of hints. The difference lies in the way the information to which the tutor wants to refer is approached. The idea behind this distinction resembles that of backwardvs. forward-looking function of dialogue acts in DAMSL (Core and Allen, 1993). The active function of hints looks forward and seeks to help the student in accessing a further bit of information, by means of eliciting, that will bring him closer to the solution. The student has to think of and produce the answer that is hinted at. The passive function of hints refers to the small piece of information that is provided each time in order to bring the student closer to some answer. The tutor gives away some information, which he has normally unsuccessfully tried to elicit previously. Due to that relation between the active and passive function of hints, the passive functio</context>
</contexts>
<marker>Core, Allen, 1993</marker>
<rawString>Mark G. Core and James F. Allen. 1993. Coding dialogues with DAMSL annotation scheme. In AAAI Fall Symposium on Communicative Action in Humans and Machines, pages 28-35, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark G Core</author>
<author>Johanna D Moore</author>
<author>Claus Zinn</author>
</authors>
<title>Supporting constructive learning with a feedback planner.</title>
<date>2000</date>
<booktitle>In Proceedings of the AAAI Fall Symposium: Building Dialogue Systems for Tutorial Applications,</booktitle>
<publisher>AAAI Press.</publisher>
<location>Falmouth, MA.</location>
<contexts>
<context position="24863" citStr="Core et al., 2000" startWordPosition="3986" endWordPosition="3989">relevant concept and the right inference rule, the tutor produces an elicit-substitution hint: Tutor (5&apos;): Can you spell out the application? Student (6&apos;): From the definition of the powerset follows that if AnB c AuB then AnB E P(AuB). That is, all I have to do is prove that AnB c AuB. This is the correct answer, which also completes the first proof step. Since only one hint was produced, the recapitulation is omitted. Thus the algorithm proceeds with prompting for the next step. 5 Related Work and Discussion Several other tutorial systems tackle hinting strategies as well. The BE&amp;E project (Core et al., 2000) investigated multi-turn tutorial strategies in basic electricity and electronics. Some of these strategies are motivated by similar theoretical interests to the ones presented here. However, the number of strategies is small and no emphasis is given to the way information is made salient, which is the aim of our taxonomy. Moreover, there are no criteria, equivalent to our algorithm, for choosing one strategy over another. Ms. Lindquist (Heffernan and Koedinger, 2000), a tutorial system for high-school algebra, also has some domain specific types of questions that resemble the BE&amp;E strategies </context>
</contexts>
<marker>Core, Moore, Zinn, 2000</marker>
<rawString>Mark G. Core, Johanna D. Moore, and Claus Zinn. 2000. Supporting constructive learning with a feedback planner. In Proceedings of the AAAI Fall Symposium: Building Dialogue Systems for Tutorial Applications, Falmouth, MA. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Armin Fiedler</author>
<author>Helmut Horacek</author>
</authors>
<title>Towards understanding the role of hints in tutorial dialogues.</title>
<date>2001</date>
<booktitle>In BI-DIALOG: 5th Workshop on Formal Semantics and Pragmatics in Dialogue,</booktitle>
<pages>40--44</pages>
<location>Bielefeld, Germany.</location>
<contexts>
<context position="922" citStr="Fiedler and Horacek, 2001" startWordPosition="127" endWordPosition="130">ogue systems Abstract In spite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial dialogues and an advanced theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system must be able to tutor proofs </context>
</contexts>
<marker>Fiedler, Horacek, 2001</marker>
<rawString>Armin Fiedler and Helmut Horacek. 2001. Towards understanding the role of hints in tutorial dialogues. In BI-DIALOG: 5th Workshop on Formal Semantics and Pragmatics in Dialogue, pages 40-44, Bielefeld, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil T Heffernan</author>
<author>Kenneth R Koedinger</author>
</authors>
<title>Building a 3rd generation ITS for symbolization: Adding a tutorial model with multiple tutorial strategies.</title>
<date>2000</date>
<booktitle>In Proceedings of the ITS 2000 Workshop on Algebra Learning,</booktitle>
<location>Montréal, Canada.</location>
<contexts>
<context position="25335" citStr="Heffernan and Koedinger, 2000" startWordPosition="4059" endWordPosition="4062">mpting for the next step. 5 Related Work and Discussion Several other tutorial systems tackle hinting strategies as well. The BE&amp;E project (Core et al., 2000) investigated multi-turn tutorial strategies in basic electricity and electronics. Some of these strategies are motivated by similar theoretical interests to the ones presented here. However, the number of strategies is small and no emphasis is given to the way information is made salient, which is the aim of our taxonomy. Moreover, there are no criteria, equivalent to our algorithm, for choosing one strategy over another. Ms. Lindquist (Heffernan and Koedinger, 2000), a tutorial system for high-school algebra, also has some domain specific types of questions that resemble the BE&amp;E strategies in form. Although there is some mention of hints, and the notion of gradually revealing information by rephrasing the question is prominent, there is no taxonomy of hints or any suggestions for dynamically producing them. An analysis of hints can also be found in the CIRCSIM-Tutor (Hume et al., 1996a; Hume et al., 1996b), an intelligent tutoring system for blood circulation. Our work has been largely inspired by the CIRCSIM project both for the general planning of the</context>
</contexts>
<marker>Heffernan, Koedinger, 2000</marker>
<rawString>Neil T. Heffernan and Kenneth R. Koedinger. 2000. Building a 3rd generation ITS for symbolization: Adding a tutorial model with multiple tutorial strategies. In Proceedings of the ITS 2000 Workshop on Algebra Learning, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Hume</author>
<author>Joel Michael</author>
<author>Allen Rovick</author>
<author>Martha Evens</author>
</authors>
<title>Student responses and follow up tutorial tactics in an ITS.</title>
<date>1996</date>
<booktitle>In Proceedings of the 9th Florida Artificial Intelligence Research Symposium,</booktitle>
<pages>168--172</pages>
<location>Key West, FL.</location>
<contexts>
<context position="894" citStr="Hume et al., 1996" startWordPosition="123" endWordPosition="126">rning in spoken dialogue systems Abstract In spite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial dialogues and an advanced theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system m</context>
<context position="2729" citStr="Hume et al., 1996" startWordPosition="439" endWordPosition="442">rovided constantly by the tutor, which is characteristic of the didactic method (Rosé et al., 2001; Tsovaltzi and Matheson, 2002). Hinting is a method that aims at encouraging active learning. It can take the form of eliciting information that the student is unable to access without the aid of prompts, or information which he can access but whose relevance he is unaware of with respect to the problem at hand. Alternatively, a hint can point to an inference that the student is expected to make based on knowledge available to him, which helps the general reasoning needed to deal with a problem (Hume et al., 1996b). In this paper, we shall first give in Section 2 a taxonomy of hints that we developed for the domain of mathematics tutoring. Next, in Section 3, we shall propose an algorithm for producing hints based on that taxonomy. This hinting algorithm is envisaged as part of a dialogue manager, which accounts also for other types of dialogues, such as clarification sub-dialogues and question answering. Then, in Section 4, the algorithm will be supplemented with an example, before we conclude the paper. 2 A Taxonomy of Hints In this section we shall explain the philosophy and the structure of our hi</context>
<context position="25763" citStr="Hume et al., 1996" startWordPosition="4132" endWordPosition="4135">alient, which is the aim of our taxonomy. Moreover, there are no criteria, equivalent to our algorithm, for choosing one strategy over another. Ms. Lindquist (Heffernan and Koedinger, 2000), a tutorial system for high-school algebra, also has some domain specific types of questions that resemble the BE&amp;E strategies in form. Although there is some mention of hints, and the notion of gradually revealing information by rephrasing the question is prominent, there is no taxonomy of hints or any suggestions for dynamically producing them. An analysis of hints can also be found in the CIRCSIM-Tutor (Hume et al., 1996a; Hume et al., 1996b), an intelligent tutoring system for blood circulation. Our work has been largely inspired by the CIRCSIM project both for the general planning of the hinting process and for the taxonomy of hints. CIRCSIM-Tutor uses domain specific hint tactics that are applied locally, but does not include a global hinting strategy that models the cognitive reasoning behind the choice of hints. We, instead, make use of the hinting history in a more structured manner. Our algorithm takes into account the kind of hints produced previously as well as the necessary pedagogical knowledge, an</context>
</contexts>
<marker>Hume, Michael, Rovick, Evens, 1996</marker>
<rawString>Gregory Hume, Joel Michael, Allen Rovick, and Martha Evens. 1996a. Student responses and follow up tutorial tactics in an ITS. In Proceedings of the 9th Florida Artificial Intelligence Research Symposium, pages 168-172, Key West, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory D Hume</author>
<author>Michael A Joel</author>
<author>Rovick A Allen</author>
<author>Martha W Evens</author>
</authors>
<title>Hinting as a tactic in one-on-one tutoring.</title>
<date>1996</date>
<journal>Journal of the Learning Sciences,</journal>
<pages>5--1</pages>
<contexts>
<context position="894" citStr="Hume et al., 1996" startWordPosition="123" endWordPosition="126">rning in spoken dialogue systems Abstract In spite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial dialogues and an advanced theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system m</context>
<context position="2729" citStr="Hume et al., 1996" startWordPosition="439" endWordPosition="442">rovided constantly by the tutor, which is characteristic of the didactic method (Rosé et al., 2001; Tsovaltzi and Matheson, 2002). Hinting is a method that aims at encouraging active learning. It can take the form of eliciting information that the student is unable to access without the aid of prompts, or information which he can access but whose relevance he is unaware of with respect to the problem at hand. Alternatively, a hint can point to an inference that the student is expected to make based on knowledge available to him, which helps the general reasoning needed to deal with a problem (Hume et al., 1996b). In this paper, we shall first give in Section 2 a taxonomy of hints that we developed for the domain of mathematics tutoring. Next, in Section 3, we shall propose an algorithm for producing hints based on that taxonomy. This hinting algorithm is envisaged as part of a dialogue manager, which accounts also for other types of dialogues, such as clarification sub-dialogues and question answering. Then, in Section 4, the algorithm will be supplemented with an example, before we conclude the paper. 2 A Taxonomy of Hints In this section we shall explain the philosophy and the structure of our hi</context>
<context position="25763" citStr="Hume et al., 1996" startWordPosition="4132" endWordPosition="4135">alient, which is the aim of our taxonomy. Moreover, there are no criteria, equivalent to our algorithm, for choosing one strategy over another. Ms. Lindquist (Heffernan and Koedinger, 2000), a tutorial system for high-school algebra, also has some domain specific types of questions that resemble the BE&amp;E strategies in form. Although there is some mention of hints, and the notion of gradually revealing information by rephrasing the question is prominent, there is no taxonomy of hints or any suggestions for dynamically producing them. An analysis of hints can also be found in the CIRCSIM-Tutor (Hume et al., 1996a; Hume et al., 1996b), an intelligent tutoring system for blood circulation. Our work has been largely inspired by the CIRCSIM project both for the general planning of the hinting process and for the taxonomy of hints. CIRCSIM-Tutor uses domain specific hint tactics that are applied locally, but does not include a global hinting strategy that models the cognitive reasoning behind the choice of hints. We, instead, make use of the hinting history in a more structured manner. Our algorithm takes into account the kind of hints produced previously as well as the necessary pedagogical knowledge, an</context>
</contexts>
<marker>Hume, Joel, Allen, Evens, 1996</marker>
<rawString>Gregory D. Hume, Michael A. Joel, Rovick A. Allen, and Martha W. Evens. 1996b. Hinting as a tactic in one-on-one tutoring. Journal of the Learning Sciences, 5(1):23-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie K Person</author>
<author>Arthur C Graesser</author>
<author>Derek Harter</author>
</authors>
<title>Eric Mathews, and the Tutoring Research Group.</title>
<date>2000</date>
<booktitle>In Proceedings of the AAAI Fall Symposium: Building Dialogue Systems for Tutorial Applications,</booktitle>
<pages>45--51</pages>
<publisher>AAAI Press.</publisher>
<location>Falmouth, MA.</location>
<contexts>
<context position="1935" citStr="Person et al., 2000" startWordPosition="301" endWordPosition="305"> theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system must be able to tutor proofs in a way that not only helps the student understand the current proof, but also allows for a high learning effect. What is meant by the latter is the ability of the students not only to better understand the problem at hand, but also to generalise and apply the taught strategies on their own later on. We propose to establish those tutoring aims by making use of the Socratic tutoring method (Person et al., 2000; Rosé et al., 2001). The decisive characteristic of the socratic method is the use of hints in order to achieve self-explanation, as opposed to answers and explanations being provided constantly by the tutor, which is characteristic of the didactic method (Rosé et al., 2001; Tsovaltzi and Matheson, 2002). Hinting is a method that aims at encouraging active learning. It can take the form of eliciting information that the student is unable to access without the aid of prompts, or information which he can access but whose relevance he is unaware of with respect to the problem at hand. Alternativ</context>
<context position="26859" citStr="Person et al., 2000" startWordPosition="4305" endWordPosition="4308">r. Our algorithm takes into account the kind of hints produced previously as well as the necessary pedagogical knowledge, and follows a smooth transition from less to more informative hints. Furthermore, we have defined a structured hint taxonomy with refined definition of classes and categories based on the passive vs. active distinction, which is similar to active-passive continuum in CIRCSIM. We have distinguished these from functions, which resemble CIRCSIM tactics, but are again more detailed and more clearly defined. All this facilitates the automation of the hint production. AutoTutor (Person et al., 2000) uses curriculum scripts on which the tutoring of computer literacy is based. There is mention of hints that are used by every script. Although it is not clear exactly what those hints are, they seem to be static. More emphasis seems to be put on the pedagogically oriented choice of dialogue moves, prosodic features and facial expression features, but not on hints. In contrast, we have presented in this paper a hint taxonomy (cf. Section 2) and a tutoring algorithm (cf. Section 3) that models the dynamic generation of hints according to the needs of the student. AutoTutor also uses a cycle of </context>
</contexts>
<marker>Person, Graesser, Harter, 2000</marker>
<rawString>Natalie K. Person, Arthur C. Graesser, Derek Harter, Eric Mathews, and the Tutoring Research Group. 2000. Dialog move generation and conversation management in AutoTutor. In Proceedings of the AAAI Fall Symposium: Building Dialogue Systems for Tutorial Applications, pages 45-51, Falmouth, MA. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Pinkal</author>
<author>Jorg Siekmann</author>
<author>Christoph Benzmiiller</author>
</authors>
<date>2001</date>
<booktitle>Projektantrag Teilprojekt MI3 — DIALOG: Tutorieller Dialog mit einem mathematischen Assistenzsystem. In Fortsetzungsantrag SFB 378 — Ressourcenadaptive kognitve Prozesse, Universitat des Saarlandes,</booktitle>
<location>Saarbriicken, Germany.</location>
<contexts>
<context position="1110" citStr="Pinkal et al., 2001" startWordPosition="158" endWordPosition="161">r tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial dialogues and an advanced theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system must be able to tutor proofs in a way that not only helps the student understand the current proof, but also allows for a high learning effect. What is meant by the latter is the ability of the students not only to be</context>
</contexts>
<marker>Pinkal, Siekmann, Benzmiiller, 2001</marker>
<rawString>Manfred Pinkal, Jorg Siekmann, and Christoph Benzmiiller. 2001. Projektantrag Teilprojekt MI3 — DIALOG: Tutorieller Dialog mit einem mathematischen Assistenzsystem. In Fortsetzungsantrag SFB 378 — Ressourcenadaptive kognitve Prozesse, Universitat des Saarlandes, Saarbriicken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn P Rosé</author>
<author>Johanna D Moore</author>
<author>Kurt VanLehn</author>
<author>David Allbritton</author>
</authors>
<title>A comparative evaluation of socratic versus didactic tutoring.</title>
<date>2001</date>
<booktitle>In Johanna Moore and Keith Stenning, editors, Proceedings 23rd Annual Conference of the Cognitive</booktitle>
<institution>Science Society, University of Edinburgh,</institution>
<location>Scotland, UK.</location>
<contexts>
<context position="690" citStr="Rosé et al., 2001" startWordPosition="89" endWordPosition="92">ra Tsovaltzi Department of Computer Science Department of Computational Linguistics Saarland University Saarland University afiedler@cs.uni—sb.de dimitra@coli.uni—sb.de Thematic Session: Adaptation and learning in spoken dialogue systems Abstract In spite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial</context>
<context position="1955" citStr="Rosé et al., 2001" startWordPosition="306" endWordPosition="309">ng the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system must be able to tutor proofs in a way that not only helps the student understand the current proof, but also allows for a high learning effect. What is meant by the latter is the ability of the students not only to better understand the problem at hand, but also to generalise and apply the taught strategies on their own later on. We propose to establish those tutoring aims by making use of the Socratic tutoring method (Person et al., 2000; Rosé et al., 2001). The decisive characteristic of the socratic method is the use of hints in order to achieve self-explanation, as opposed to answers and explanations being provided constantly by the tutor, which is characteristic of the didactic method (Rosé et al., 2001; Tsovaltzi and Matheson, 2002). Hinting is a method that aims at encouraging active learning. It can take the form of eliciting information that the student is unable to access without the aid of prompts, or information which he can access but whose relevance he is unaware of with respect to the problem at hand. Alternatively, a hint can poin</context>
<context position="12384" citStr="Rosé et al., 2001" startWordPosition="1922" endWordPosition="1925">f formal logic. Point-to-lesson points the student to the lesson in general and asks him to read it again when it appears that he cannot be helped by tutoring because he does not remember the study material. There is no one-to-one correspondence between the active and passive pragmatic hints. Some pragmatic hints can be used in combination with hints from other classes. 3 A Hinting Algorithm A tutorial system ideally aims at having the student find the solution to a problem by himself. Only if the student gets stuck should the system intervene. There is pedagogical evidence (Chi et al., 1994; Rosé et al., 2001) that students learn better if the tutor does not give away the answer but instead gives hints that prompt the student for self-explanations. Accordingly, based on the work by Tsovaltzi (2001) we have derived an algorithm that implements an eliciting strategy that is useradaptive by choosing hints tailored to the students. Only if hints appear not to help does the algorithm switch to an explaining strategy, where it gives away the answer and explains it. We shall follow Person and colleagues (2000) and Rosé and colleagues (2001) in calling the eliciting strategy socratic and the explaining str</context>
<context position="28600" citStr="Rosé et al., 2001" startWordPosition="4602" endWordPosition="4605">utor, but he is also encouraged to actively produce the content of the answer itself. Furthermore, the separation of the study material and the tutoring session facilitates the production of the answers by the student, since the tutor does not have to present the material and re-elicit it in one and the same session. The student is guided through making use of the study material that he has already read in order to solve the problem. 6 Conclusion and Future Work There is psychological evidence that hinting in tutorial dialogue has a positive effect on the student&apos;s learning (Chi et al., 1994; Rosé et al., 2001). To take advantage of this effect, we have been developing a taxonomy of hints and a socratic algorithm for hint production in tutorial dialogues in mathematics. This algorithm should be easily adaptable to other tutoring domains as well. Before we implement the algorithm in an intelligent system for tutorial dialogues, we chose to perform Wizard-of-Oz experiments to test the adequacy of the taxonomy and the effectiveness of the socratic algorithm. The experiments have already been completed and are currently being evaluated. The socratic algorithm presented in this paper does not deal with t</context>
</contexts>
<marker>Rosé, Moore, VanLehn, Allbritton, 2001</marker>
<rawString>Carolyn P. Rosé, Johanna D. Moore, Kurt VanLehn, and David Allbritton. 2001. A comparative evaluation of socratic versus didactic tutoring. In Johanna Moore and Keith Stenning, editors, Proceedings 23rd Annual Conference of the Cognitive Science Society, University of Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Tsovaltzi</author>
<author>Colin Matheson</author>
</authors>
<title>Formalising hinting in tutorial dialogues.</title>
<date>2002</date>
<booktitle>In EDILOG: 6th workshop on the</booktitle>
<pages>185--192</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="2241" citStr="Tsovaltzi and Matheson, 2002" startWordPosition="351" endWordPosition="354"> a high learning effect. What is meant by the latter is the ability of the students not only to better understand the problem at hand, but also to generalise and apply the taught strategies on their own later on. We propose to establish those tutoring aims by making use of the Socratic tutoring method (Person et al., 2000; Rosé et al., 2001). The decisive characteristic of the socratic method is the use of hints in order to achieve self-explanation, as opposed to answers and explanations being provided constantly by the tutor, which is characteristic of the didactic method (Rosé et al., 2001; Tsovaltzi and Matheson, 2002). Hinting is a method that aims at encouraging active learning. It can take the form of eliciting information that the student is unable to access without the aid of prompts, or information which he can access but whose relevance he is unaware of with respect to the problem at hand. Alternatively, a hint can point to an inference that the student is expected to make based on knowledge available to him, which helps the general reasoning needed to deal with a problem (Hume et al., 1996b). In this paper, we shall first give in Section 2 a taxonomy of hints that we developed for the domain of math</context>
</contexts>
<marker>Tsovaltzi, Matheson, 2002</marker>
<rawString>Dimitra Tsovaltzi and Colin Matheson. 2002. Formalising hinting in tutorial dialogues. In EDILOG: 6th workshop on the semantics and pragmatics of dialogue, pages 185-192, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Tsovaltzi</author>
</authors>
<title>Formalising hinting in tutorial dialogues.</title>
<date>2001</date>
<tech>Master&apos;s thesis,</tech>
<institution>Division of Informatics, University of Edinburgh,</institution>
<location>Scotland, UK.</location>
<contexts>
<context position="940" citStr="Tsovaltzi, 2001" startWordPosition="131" endWordPosition="132">ite of psychological substantiation of hinting, most intelligent tutoring systems do not systematically produce hints. In this paper we present a taxonomy of hints for tutoring mathematics. Based on this taxonomy, we suggest an algorithm for the production of hints. 1 Introduction Although there has been psychological evidence (Chi et al., 1994; Rosé et al., 2001) for the high educational effect of hinting, most intelligent tutoring systems do not take advantage of the findings. Only little systematic research in automating hinting has been done (Hume et al., 1996b; Fiedler and Horacek, 2001; Tsovaltzi, 2001). In the DIALOG project, we undertake the goal of tackling some problems of mathematical tutoring dialogue systems in the domain of naive set theory (Pinkal et al., 2001). More specifically, DIALOG aims at providing a mathematical knowledge base that would serve as the basis for the study material, a user-adaptive dialogue system modelling tutorial dialogues and an advanced theorem prover fitting the needs of planning for tutorials. In this framework, we have been investigating the automation of the hinting process. A mathematical tutoring system must be able to tutor proofs in a way that not </context>
<context position="4716" citStr="Tsovaltzi, 2001" startWordPosition="777" endWordPosition="778">ucture, which undoubtedly plays its own significant role in teaching, is yet to be examined in the naive set theory domain. We defined our hint categories based on the needs in the domain. In order to estimate those needs we defined the relations between the objects in the domain. More specifically, we defined the inter-relations between mathematical concepts as well as between concepts and inference rules, which are used in proving. An additional guide for deriving hint categories that are useful for tutoring in our domain was a previous hint taxonomy, which was derived from the BE&amp;E corpus (Tsovaltzi, 2001). The structure of the hint taxonomy reflects the function of the hints with respect to the information that the hint addresses or is meant to trigger. In order to capture different functions of a hint we define hint categories across two dimensions. Before we introduce the dimensions, let us clarify some terminology. In the following, we distinguish performable steps from meta-reasoning. Performable steps are the steps that can be found in the formal proof. These include premises, conclusion and inference methods such as lemmata, theorems, definitions of concepts, or calculus level rules (e.g</context>
<context position="12576" citStr="Tsovaltzi (2001)" startWordPosition="1955" endWordPosition="1956">udy material. There is no one-to-one correspondence between the active and passive pragmatic hints. Some pragmatic hints can be used in combination with hints from other classes. 3 A Hinting Algorithm A tutorial system ideally aims at having the student find the solution to a problem by himself. Only if the student gets stuck should the system intervene. There is pedagogical evidence (Chi et al., 1994; Rosé et al., 2001) that students learn better if the tutor does not give away the answer but instead gives hints that prompt the student for self-explanations. Accordingly, based on the work by Tsovaltzi (2001) we have derived an algorithm that implements an eliciting strategy that is useradaptive by choosing hints tailored to the students. Only if hints appear not to help does the algorithm switch to an explaining strategy, where it gives away the answer and explains it. We shall follow Person and colleagues (2000) and Rosé and colleagues (2001) in calling the eliciting strategy socratic and the explaining strategy didactic. To determine which parts of the solution need to be addressed the algorithm has to examine the student&apos;s answer. Therefore, we shall briefly present the student answer categori</context>
</contexts>
<marker>Tsovaltzi, 2001</marker>
<rawString>Dimitra Tsovaltzi. 2001. Formalising hinting in tutorial dialogues. Master&apos;s thesis, Division of Informatics, University of Edinburgh, Scotland, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>