<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.873102">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<title confidence="0.562894">
Abstracts of Current Literature
</title>
<note confidence="0.6161385">
Interestingness: Controlling Inferences
Roger C. Schank
</note>
<subsectionHeader confidence="0.376646">
Department of Computer Science
Yale University
New Haven, Connecticut 06520
</subsectionHeader>
<bodyText confidence="0.897766857142857">
Artificial Intelligence 12, 3 (Nov. 1979), 273-297.
One of the central issues in natural language under-
standing for the last few years has been the problem
of making inferences and controlling those inferences.
In this paper I will discuss an overall method for con-
trolling inferences that has effects on parsing, script
application and the tracking of goals and plans.
</bodyText>
<note confidence="0.6795995">
Reminding and Memory Organization:
An Introduction to MOPs
</note>
<author confidence="0.876821">
Roger C. Schank
</author>
<affiliation confidence="0.9315505">
Department of Computer Science
Yale University
</affiliation>
<address confidence="0.840302">
New Haven, Connecticut 06520
</address>
<subsectionHeader confidence="0.360144">
Research Report 170, Dec. 1979.
</subsectionHeader>
<bodyText confidence="0.999762785714286">
A key question for researchers in Cognitive Science
is the problem of how human memory is organized.
The solution to this problem is fundamental to Cogni-
tive Scientists regardless of whether their basic orien-
tation is towards Artificial Intelligence or Cognitive
Psychology. The theories that we test by means of
psychological experiments ought to have some ramifi-
cations on how we build computer models of the proc-
esses tested by those experiments, and the computer
models that we build ought to supply testable hy-
potheses for psychologists. This paper discusses some
issues in memory organization that are fundamental to
an understanding system, and thus to Cognitive Sci-
ence.
</bodyText>
<subsectionHeader confidence="0.856797333333333">
Knowledge-Based Parsing
Anatole V. Gershman
Department of Computer Science
Yale University
New Haven, Connecticut 06520
Research Report 156, April 1979.
</subsectionHeader>
<bodyText confidence="0.999967709677419">
A model for knowledge-based natural language
analysis is described. The model is applied to parsing
English into Conceptual Dependency representations.
The model processes sentences from left to right, one
word at a time, using linguistic and non-linguistic
knowledge to find the meaning of the input. It oper-
ates in three modes: structure-driven, position-driven,
and situation-driven. The first two modes are
expectation-based. In structure-driven mode concepts
underlying new input are expected to fill slots in the
previously built conceptual structures. Noun groups
are handled in position-driven mode which uses
position-based pooling of expectations. When the first
two modes fail to account for a new input, the parser
goes into the third, situation-driven mode which tries
to handle a situation by applying a series of appropri-
ate experts.
Four general kinds of knowledge are identified as
necessary for language understanding: lexical knowl-
edge, world knowledge, linguistic knowledge, and con-
textual knowledge. The concrete knowledge structures
and representational mechanisms necessary for under-
standing are examined using examples of English con-
structions involving the preposition &amp;quot;by&amp;quot;. These in-
clude passives, instrumental constructions, construc-
tions introducing physical settings, role-frame charac-
terizations, and authorship expressions. It is shown
that the parsing framework outlined in this thesis is
adequate for the integration of the first three kinds of
knowledge but difficulties with the integration of con-
textual knowledge still remain.
</bodyText>
<title confidence="0.6965695">
Skimming Stories in Real Time:
An Experiment in Integrated Understanding
</title>
<author confidence="0.501256">
Gerald Francis DeJong II
</author>
<affiliation confidence="0.692099">
Department of Computer Science
Yale University
</affiliation>
<address confidence="0.710646">
New Haven, Connecticut 06520
</address>
<subsectionHeader confidence="0.729775">
Research Report 158, May 1979.
</subsectionHeader>
<bodyText confidence="0.999957862068965">
This dissertation describes a new method of auto-
mated text analysis. FRUMP (Fast Reading Under-
standing and Memory Program) is a working natural
language processing system that has been implemented
to demonstrate the viability of this new approach.
The system skims news stories directly from the Unit-
ed Press International news wire and produces a sum-
mary of what it understands. FRUMP is able to cor-
rectly process news articles it has never before seen.
The process of interpreting input text words can be
greatly simplified if it is viewed as one component of a
highly integrated understanding process. In FRUMP
the text analyzer is embedded in a predictive under-
stander. This embedding is the key to FRUMP&apos;s ro-
bustness. FRUMP&apos;s integration makes all of the world
knowledge and top-down predictions of the understan-
der available to the text analyzer. FRUMP uses a
data construct called a sketchy script to store its world
knowledge. There is one sketchy script for each real
world &amp;quot;situation&amp;quot; FRUMP knows about. The system
uses this knowledge to make predictions about what
might happen next in a given situation. FRUMP con-
tinually jumps to conclusions about what the text
means and generates predictions about what might
occur next. The text analysis process then is reduced
to finding a reading of the text that satisfies these
predictions. The process of looking for readings in the
text is much simpler than the process of generating a
conceptual structure from an arbitrary input. Thus
</bodyText>
<page confidence="0.582264">
196 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<note confidence="0.905808">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.81916735">
there is no need in FRUMP for an extremely powerful
English parser.
Given a new input FRUMP must be able to decide
which of its sketchy scripts contains the knowledge
needed to process the input. This is the process of
&amp;quot;script selection&amp;quot; which is a major problem for an
approach such as FRUMP&apos;s. A workable solution to
the script selection problem must be computationally
manageable. The process must not be significantly
slowed down by the addition of more world knowledge
in the form of more sketchy scripts. That is, the com-
putational complexity of script selection must not de-
pend significantly on the number of scripts in the sys-
tem. Furthermore, the script selection process must
often be completely bottom-up; most news stories
cannot be anticipated before they are seen. Yet dur-
ing this process, the FRUMP text analyzer must still
be supplied with adequate top-down guidance. This
problem is addressed and a general solution for
FRUMP&apos;s purposes is given.
</bodyText>
<sectionHeader confidence="0.326263" genericHeader="method">
A Process Model of Language Acquisition
</sectionHeader>
<subsectionHeader confidence="0.4207926">
Mallory Gordon Richard Selfridge
Department of Computer Science
Yale University
New Haven, Connecticut 06520
Research Report 172, Jan. 1980.
</subsectionHeader>
<bodyText confidence="0.998427972972973">
How do children acquire language? This thesis
approaches this problem by studying how children
between the ages of 1 and 2 years learn to understand
commands containing action words, object words, and
relation words. It presents observations of one child
made during language development and presents rules
which account for this development. A computer pro-
gram model of this child&apos;s development, incorporating
the observations and rules, was written and tested in
learning a subset of English and Japanese.
There are four components to the problem of learn-
ing to understand commands involving action, object,
and relation words. The first is that of knowledge
which the child brought to language learning. The
second is a characterization of his developed compre-
hension abilities at age 2. The third is that of his ex-
periences with language -- the various situations in
which people said things to him. The fourth is the
rules which can account for his learning the compre-
hension skills based on his initial knowledge and his
experience with language.
This thesis presents a characterization of this
child&apos;s knowledge prior to learning language at age 1,
describes his comprehension skills at age 2, examines
his experiences with language between these times,
and proposes a set of rules which can account for the
development of these skills from his prior knowledge
and his language experiences. It also presents a com-
puter program which embodies this model.
The results of this work suggest that language
learning is dependent upon situational understanding
and world knowledge to a greater degree than realized.
They suggest that notions of adult language under-
standing, in particular the nature and role of language
structure in understanding, should perhaps be modified
in light of what appears both to be easily learnable
and also is sufficient to account for the observations.
</bodyText>
<subsectionHeader confidence="0.423255">
Affect Units and Narrative Summarization
</subsectionHeader>
<affiliation confidence="0.777442333333333">
Wendy G. Lehnert
Department of Computer Science
Yale University
</affiliation>
<address confidence="0.772341">
New Haven, Connecticut 06520
</address>
<subsectionHeader confidence="0.582768">
Research Report 179, May 1980.
</subsectionHeader>
<bodyText confidence="0.999921740740741">
The analysis of narrative text involves various lev-
els of description. On the lowest level are word mean-
ings and syntactic structure within single sentences.
On a higher level there are problems of generating
inferences and integrating information into memory.
At the highest level is the notion of a macro-structure
or narrative plot. The identification of high-level nar-
rative structures is central to the problem of narrative
summarization. But the intuitive notion of a plot is
useless for a process model of summarization unless
we can specify the hierarchical representations that
allow us to analyze input and produce plots as output.
A representational strategy has been developed for
high-level structural analysis in conjunction with the
BORIS system (a narrative text understanding system).
The structures produced effectively encode plot lines
in terms of connected graph structures where graph
nodes correspond to specific affect units. An affect
unit is an abstraction of affective causality which is
recognized in a bottom-up manner at the time of un-
derstanding. Simple manipulations of these graph
structures yield the conceptual basis for narrative sum-
maries, but the actual process of summarization de-
pends on certain connectivity properties in the graph
structure. Summarization techniques for the general
case are presented, and a specific algorithm for one
class of graphs is proposed.
</bodyText>
<subsectionHeader confidence="0.941981">
VEGE: Variable Processing in a
Natural Language Query System
Wendy G. Lehnert and William M. Bain
Department of Computer Science
Yale University
New Haven, Connecticut 06520
Research Report 183, April 1980.
</subsectionHeader>
<bodyText confidence="0.990042181818182">
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 197
The FINITE STRING Newsletter Abstracts of Current Literature
VEGE (VEgetable Gardening Expert) is a natural
language query system designed to answer questions
about vegetable gardening by employing a strategy of
variable-depth sentence analysis. Each time an input
question is encountered, VEGE can rely on one of
three analysis strategies varying from superficial key-
concept recognition to fully predictive conceptual
analysis. The system determines which analysis is
sufficient as it moves through the question in a one-
pass left-to-right parsing procedure. A taxonomy of
question types then determines what retrieval heuris-
tics to execute in searching for an appropriate answer
to the question. By expending no more processing
effort than is absolutely necessary, VEGE implements
a question analysis technique that is both semantically
efficient and relatively robust in the range of sentence
constructions it can handle. The processing techniques
outlined in this report appear to be specific to the task
orientation of an expert query system, but independent
of vegetable gardening as a knowledge domain.
</bodyText>
<subsectionHeader confidence="0.9957766">
Inferring Conceptual Graphs
Sharon C. Salveter
Department of Computer Science
State University of New York
Stony Brook, New York 11794
</subsectionHeader>
<bodyText confidence="0.976572722222222">
Cognitive Science 3, 2 (April-June 1979), 141-166.
This paper investigates the mechanisms a program
may use to learn conceptual structures that represent
natural language meaning. A computer program
named Moran is described that infers conceptual struc-
tures from pictorial input data. Moran is presented
with &amp;quot;snapshots&amp;quot; of an environment and an English
sentence describing the action that takes place be-
tween the snapshots. The learning task is to associate
each root verb with a conceptual structure that repre-
sents the types of objects that participate in the action
and the changes the objects undergo during the action.
Four learning mechanisms are shown to be adequate to
accomplish this learning task. The learning mecha-
nisms are described along with the conditions under
which each is invoked and the effect each has on ex-
isting memory structures. The conceptual structure
Moran inferred for one root verb is shown.
</bodyText>
<subsectionHeader confidence="0.821911222222222">
Elements of a Plan-Based Theory
of Speech Acts
Philip R. Cohen
Bolt Beranek and Newman, Inc.
50 Moulton Street
Cambridge, Massachusetts 02138
C. Raymond Perrault
Department of Computer Science
University of Toronto
</subsectionHeader>
<bodyText confidence="0.561487">
Toronto, Ontario M5S 1A7 CANADA
</bodyText>
<subsubsectionHeader confidence="0.773173">
Cognitive Science 3, 3 (July-Sept. 1979), 177-212.
</subsubsectionHeader>
<bodyText confidence="0.999903714285714">
This paper explores the truism that people think
about what they say. It proposes that, to satisfy their
own goals, people often plan their speech acts to af-
fect their listeners&apos; beliefs, goals, and emotional states.
Such language use can be modelled by viewing speech
acts as operators in a planning system, thus allowing
both physical and speech acts to be integrated into
plans.
Methodological issues of how speech acts should be
defined in a plan-based theory are illustrated by defin-
ing operators for requesting and informing. Plans
containing those operators are presented and compari-
sons are drawn with Searle&apos;s formulation. The opera-
tors are shown to be inadequate since they cannot be
composed to form questions (requests to inform) and
multiparty requests (requests to request). By refining
the operator definitions and by identifying some of the
side effects of requesting, compositional adequacy is
achieved. The solution leads to a metatheoretical
principle for modelling speech acts as planning opera-
tors.
</bodyText>
<subsectionHeader confidence="0.969779727272727">
An Evaluation of Story Grammars
John B. Black
Department of Psychology
Yale University
Box 11A Yale Station
New Haven, Connecticut 06520
Robert Wilensky
Computer Science Division
Department of EECS
University of California, Berkeley
Berkeley, California 94720
</subsectionHeader>
<subsubsectionHeader confidence="0.509081">
Cognitive Science 3, 3 (July-Sept. 1979), 213-230.
</subsubsectionHeader>
<bodyText confidence="0.999975071428571">
We evaluate the &amp;quot;story grammar&amp;quot; approach to story
understanding from three perspectives. We first exam-
ine the formal properties of the grammars and find
only one to be formally adequate. We next evaluate
the grammars empirically by asking whether they gen-
erate all simple stories and whether they generate only
stories. We find many stories that they do not gener-
ate and one major class of nonstory that they do gen-
erate. We also evaluate the grammars&apos; potential as
comprehension models and find that they would add
nothing to semantic models that focus on the story
content. Hence we advocate a story content oriented
approach to studying story understanding instead of
the structural story grammar approach.
</bodyText>
<subsectionHeader confidence="0.8807245">
Prediction and Substantiation: A New
Approach to Natural Language Processing
Gerald DeJong
Department of Computer Science
Yale University
New Haven, Connecticut 06520
</subsectionHeader>
<subsubsectionHeader confidence="0.334599">
Cognitive Science 3, 3 (July-Sept. 1979), 251-273.
</subsubsectionHeader>
<page confidence="0.782776">
198 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<note confidence="0.41545">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.999965529411765">
This paper describes a new approach to natural
language processing which results in a very robust and
efficient system. The approach taken is to integrate
the parser with the rest of the system. This enables
the parser to benefit from predictions that the rest of
the system makes in the course of its processing.
These predictions can be invaluable as guides to the
parser in such difficult problem areas as resolving re-
ferents and selecting meanings of ambiguous words. A
program, called FRUMP for Fast Reading Understand-
ing and Memory Program, employs this approach to
parsing. FRUMP skims articles rather than reading
them for detail. The program works on the relatively
unconstrained domain of news articles. It routinely
understands stories it has never before seen. The
program&apos;s success is largely due to its radically differ-
ent approach to parsing.
</bodyText>
<subsectionHeader confidence="0.986579166666667">
Points: A Theory of Story Content
Robert Wilensky
Computer Science Division
Department of, EECS
University of California, Berkeley
Berkeley, California 94720
</subsectionHeader>
<bodyText confidence="0.978399074074074">
Memorandum No. UCBIERL M80117, April 1980.
Attempts to produce computer story understanding
systems have generated a number of interesting ideas,
particularly in the areas of knowledge representation
and organization. However, many basic questions still
remain largely unaddressed. In particular, the idea of
what actually constitutes a story has never been clearly
delineated.
A theory of story points has been developed that
attempts to characterize those texts that describe situ-
ations that constitute stories. Unlike previous at-
tempts at such a characterization, points are based not
on the structure or form of a text, but on its content.
Points describe those situations that generate reader
interest and therefore give a text some poignancy.
The theory of stories proposed here is intimately
connected with basic issues of language understanding,
language generation, cognition and memory. In addi-
tion to characterizing stories, knowledge about poig-
nancy is as necessary for the construction of intelligent
story understanding programs as are theories of infer-
ence and knowledge representation. A story under-
standing system (PAM - Plan Applier Mechanism) has
been given some of this knowledge about points, and
as a result, its language processing capabilities have
been extended to facilitate summarization and intelli-
gent forgetting.
</bodyText>
<subsectionHeader confidence="0.926744888888889">
Meta-Planning: Representing and Using
Knowledge About Planning in Problem Solving
and Natural Language Understanding
Robert Wilensky
Computer Science Division
Department of EECS
University of California, Berkeley
Berkeley, California 94720
Memorandum No. UCBIERL M80133, Aug. 1980.
</subsectionHeader>
<bodyText confidence="0.99995084375">
This paper is concerned with those elements of
planning knowledge that are common to both under-
standing someone else&apos;s plan and creating a plan for
one&apos;s own use. This planning knowledge can be divid-
ed into two bodies: knowledge about the world, and
knowledge about the planning process itself. Our
interest here is primarily with the latter corpus. The
central thesis is that much of the knowledge about the
planning process itself can be formulated in terms of
higher-level goals and plans called meta-goals and
meta-plans. These entities can then be used by the
same understanding and planning mechanisms that
process ordinary goals and plans; however, the metal-
planning knowledge now enables these mechanisms to
handle much more complicated situations, and in a
quite uniform manner.
Systems based on meta-planning would have a
number of advantages over existing problem solving
and understanding systems. The same knowledge
could be shared by both a planner and understander,
and both would be able to handle complex situations
elegantly. In addition, in planning, the use of meta-
planning has several advantages over more traditional
methods involving constraints or critics. Meta-
planning allows the full power of a problem solver to
be applied to situations that are generally amenable
only to special purpose processing. In addition, meta-
planning facilitates the representation of some situa-
tions that are difficult to express otherwise. We have
begun to introduce meta-planning knowledge into two
systems: PAM, a story understanding program, and
PANDORA, a problem solving and planning system.
</bodyText>
<subsectionHeader confidence="0.932720285714286">
PHRAN: A Knowledge-Based Approach to
Natural Language Analysis
Robert Wilensky and Yigal Arens
Computer Science Division
Department of EECS
University of California, Berkeley
Berkeley, California 94720
</subsectionHeader>
<bodyText confidence="0.980431157894737">
Memorandum No. UCBIERL M80134, Aug. 1980.
We have developed an approach to natural lan-
guage processing in which the natural language proc-
essor is viewed as a knowledge-based system whose
knowledge is about the meanings of the utterances of
its language. The approach is oriented around the
phrase rather than the word as the basic unit. We
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 199
The FINITE STRING Newsletter Abstracts of Current Literature
believe that this paradigm for language processing not
only extends the capabilities of natural language sys-
tems, but handles those tasks that previous systems
could perform in a more systematic and extensible
manner.
We have constructed a natural language analysis
program called PHRAN (PHRasal ANalyzer) based in
this approach. PHRAN reads texts in English and
produces structures representing their meanings.
PHRAN&apos;s knowledge of English is not confined to the
word level. Instead, the system has knowledge about
language constructs of varying levels of specificity,
from canned literal phrases to general verb-oriented
patterns. Associated with each language pattern is a
corresponding meaning component. As PHRAN reads
a sentence, it searches its data base for the language
patterns that best interpret the incoming text. Then
the associated meaning components of those patterns
are used to create a meaning representation for that
utterance.
This model has a number of advantages over exist-
ing systems, including the ability to understand a wider
variety of language utterances, increased processing
speed in some cases, a clear separation of control
structure from data structure, a knowledge base that
could be shared by a language production mechanism,
greater ease of extensibility, and the ability to store
some useful forms of knowledge that cannot readily be
added to other systems.
</bodyText>
<subsectionHeader confidence="0.995227">
Computational Interpretation of
English Spacial Prepositions
Lois Carolyn Boggess
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<bodyText confidence="0.986254">
Technical Report T-75, Feb. 1979.
It seems clear to anyone who pays attention to the
use of prepositions in language that any one preposi-
tion, when used to describe the spatial relationship
between different objects can produce strikingly dif-
ferent mental models for different objects. The men-
tal model produced by the description &amp;quot;a bowl on a
table&amp;quot; seems to be somewhat different from that prod-
uced by &amp;quot;a poster on a wall&amp;quot; which in turn is some-
what different from &amp;quot;a shelf on a wall&amp;quot; which again is
different from &amp;quot;a fly on a ceiling&amp;quot;.
It is the contention of this paper that the preposi-
tion in conjunction with a small set of features of the
objects (mostly perceptual features) can account for
such variations in spatial relations. The thesis discuss-
es a means of taking English-language descriptions
involving prepositions and their semantic subjects and
objects and deriving a three-dimensional model of the
spatial relationships of the subject and object.
The relationship of some of the spatial prepositions
to a coordinate system is explored, as well as canoni-
cal definitions for prepositions based on analyses of
descriptions using &amp;quot;neutral&amp;quot; subjects and/or objects
(lwhatchamacallit&amp;quot;, &amp;quot;you-know-what&amp;quot;, and so on).
Examples are taken from a simple program which
accompanies the theory. The program is supplied with
approximate descriptions of the shapes of a variety of
objects. Each preposition in the program has one defi-
nition (e.g., there is only one procedure for on, rather
than several--ON1, 0N2, 0N3, and so on); in general
the definition is made up of several components, each
of which is responsive to a perceptual characteristic of
the semantic subject or object.
The program takes extended descriptions involving
many objects, each of which is incorporated into the
overall model. Once an object has been described, it
is possible to interrogate the model about the relation
of that object to any other in the model, without re-
course to inference rules of the following kind: &amp;quot;if A
is on B and B is in C then A is (probably) in C.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.988313166666667">
Experience with the Evaluation of Natural
Language Question Answerers
Harry Tennant
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<bodyText confidence="0.956802636363636">
Working Paper WP-18, Feb. 1979.
Research in natural language processing could be
facilitated by thorough and critical evaluations of nat-
ural language systems. Two measurements, conceptual
and linguistic completeness, are defined and discussed
in this paper. Testing done on two natural language
question answerers demonstrated that the conceptual
coverage of such systems should be extended to better
satisfy the needs and expectations of users. Three
heuristics are presented that describe how conceptual
coverage of question answerers should be extended.
</bodyText>
<subsectionHeader confidence="0.865378333333333">
JETS: Achieving Completeness through
Coverage and Closure
Tim Finin, Brad Goodman, and Harry Tennant
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<bodyText confidence="0.950207">
Working Paper WP-19, Feb. 1979.
Work in progress on JETS, the successor to
PLANES, is described. JETS is a natural language
question answering system that is intended to interface
users to a large relational data base. The architecture
is designed to extend the conceptual coverage of JETS
to better meet the conversational and data base usage
requirements of users. The implementation of JETS is
designed to gain a high degree of closure over concept
200 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
The FINITE STRING Newsletter Abstracts of Current Literature
manipulation, contributing to a solution to the prob-
lems of perspicuity and scale. Specific examples are
given on concept manipulation through the implied
relationships of modification and of an approach to
problem-solving through the use of frames.
</bodyText>
<subsectionHeader confidence="0.9923095">
Visual Analog Representation for
Natural Language Understanding
David L. Waltz and Lois Boggess
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<subsubsectionHeader confidence="0.588143">
Working Paper WP-20, Feb. 1979.
</subsubsectionHeader>
<bodyText confidence="0.999981285714286">
In order for a natural language system to truly
&amp;quot;know what it is talking about,&amp;quot; it must have a con-
nection to the real world correlates of language. For
language describing physical objects and their relations
in a scene, a visual analog representation of the scene
can provide a useful target structure to be shared by a
language understanding system and a computer vision
system. This paper discusses the generation of visual
analog representations from input English sentences.
It also describes the operation of a LISP program
which generates such a representation from simple
English sentences describing a scene. A sequence of
sentences can result in a fairly elaborate model. The
program can then answer questions about relationships
between the objects, even though the relationships
between the objects may not have been explicit in the
original scene description. Results suggest that the
direct testing of visual analog representations may be
an important way to bypass long chains of reasoning
and to thus avoid the combinatorial problems inherent
in such reasoning methods.
</bodyText>
<subsectionHeader confidence="0.993892333333333">
Problem Solving in a Natural Language
Environment
Bradley A. Goodman
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<bodyText confidence="0.9657323125">
Working Paper WP-22, July 1979.
The kinds of requests that can be currently handled
by natural language data base systems are constrained
mainly to simple queries to retrieve information from
the data base. The requests must be completely speci-
fied by the user (though certain information can be
assumed from past context). This paper is a proposal
for a Ph.D. thesis that explores requests of a more
complicated nature. The goal is to take vague and
complex requests from users and turn them into well-
defined problems. Missing information will be filled in
through world knowledge or from the current dialog
context. The transformation of the request into a
well-defined problem and the generation of a plan to
solve the problem will be guided by a set of problem
solving frames.
</bodyText>
<subsectionHeader confidence="0.754856833333333">
Relating Images, Concepts and Words
David L. Waltz
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
Working Paper WP-23, May 1979.
</subsectionHeader>
<bodyText confidence="0.995281882352941">
Examination of verbal descriptions of objects sug-
gests that we use hierarchical structures for shape de-
scription; the highest levels of the hierarchy provide a
general object framework or breakdown into compo-
nent parts and a description of each part by analogy to
a well-understood set of shapes called prototypes.
Lower levels of the hierarchy provide refinement of
the analogies and ways in which shapes deviate from
the prototypes. The set of prototypes on which the
analogies are based contains many common objects,
especially natural objects and the parts of the human
body, plus certain shapes with special symmetry prop-
erties. It is argued that no single 3-D representation
scheme is natural for all members of this set of proto-
types, and that since unfamiliar objects are described
with respect to the basic set of shapes, these objects
will have varying shape representation schemes also.
</bodyText>
<subsectionHeader confidence="0.885337">
Generating and Understanding
Scene Descriptions
David L. Waltz
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
</subsectionHeader>
<bodyText confidence="0.963077666666667">
Working Paper WP-24, March 1980.
This paper explores design issues for a system
which has both vision and language, in particular, a
system which addresses both the problem of selecting
appropriate words and sentences to describe a particu-
lar perceptual event, and the related problem of mak-
ing appropriate inferences about a natural language
description of a perceptual event. It argues that per-
ception is basically a description-budding process, and
that the understanding of scene descriptions is ulti-
mately based on our ability to first use scene descrip-
tions to drive processes of &amp;quot;picture-building&amp;quot;, and then
to drive processes of &amp;quot;event-simulation&amp;quot; which cause
the &amp;quot;pictures&amp;quot; we build to mimic the dynamics of the
world.
</bodyText>
<table confidence="0.350674125">
Syntactic Analysis in JETS
Harry Tennant
Coordinated Science Laboratory
University of Illinois
Urbana, Illinois 61801
Working Paper WP-26, May 1980.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 201
The FINITE STRING Newsletter Abstracts of Current Literature
</table>
<bodyText confidence="0.995082625">
Our experience with PLANES has lent evidence to
the opinion that syntactic rules ought to be included in
a natural language processing system. They were not
explicitly included in PLANES, with desirable and
undesirable results. The desirable result was that
PLANES was quite capable at interpreting elliptical
and non-grammatical utterances, which occur fairly
frequently in user interactions. The undesirable result
was that PLANES could not interpret many grammati-
cal utterances whose interpretation would have been
greatly facilitated by using syntactic information. This
report is the result of an investigation and experiments
into using an extension of the LUNAR grammar for
JETS, the successor to PLANES. The goal is to gain
the regularities of syntactic analysis, but still allow for
elliptical and &amp;quot;non-grammatical&amp;quot; utterances.
</bodyText>
<subsectionHeader confidence="0.741142571428571">
The Semantic Interpretation of
Noun-Noun Modification
Timothy W. Finin
Department of Computer and Information Science
Moore School of Electrical Engineering
University of Pennsylvania
Philadelphia, Pennsylvania 19104
</subsectionHeader>
<subsubsectionHeader confidence="0.878505">
Illinois CSL Working Paper WP-21, May 1979.
</subsubsectionHeader>
<bodyText confidence="0.999976916666667">
This paper is a proposal for a Ph.D. thesis con-
cerned with the semantic interpretation of noun-noun
modification. The study of this topic is being coordi-
nated with the development of the JETS natural lan-
guage question answering system. One of the goals of
this research is a computer program which will inter-
pret instances of noun-noun modification within the
domain of discourse of JETS. Related work on noun-
noun modification in the disciplines of Linguistics and
Artificial Intelligence is described and contrasted to
the proposed research. The basic approach being take
is described and the scope of the work is outlined.
</bodyText>
<subsectionHeader confidence="0.898747857142857">
The Semantic Interpretation of
Nominal Compounds
Timothy W. Finin
Department of Computer and Information Science
Moore School of Electrical Engineering
University of Pennsylvania
Philadelphia, Pennsylvania 19104
</subsectionHeader>
<subsubsectionHeader confidence="0.914989">
Illinois CSL Working Paper WP-25, April 1980.
</subsubsectionHeader>
<bodyText confidence="0.999939857142857">
This paper briefly introduces an approach to the
problem of building semantic interpretations of nomi-
nal compounds, i.e. sequences of two or more nouns
related through modification. Examples of the kinds
of nominal compounds dealt with are: &amp;quot;engine re-
pairs&amp;quot;, &amp;quot;aircraft flight arrival&amp;quot;, &amp;quot;aluminum water
pump&amp;quot;, and &amp;quot;noun noun modification&amp;quot;.
</bodyText>
<table confidence="0.448133">
The Semantic Interpretation of
Nominal Compounds
Timothy W. Finin
Department of Computer and Information Science
Moore School of Electrical Engineering
University of Pennsylvania
Philadelphia, Pennsylvania 19104
</table>
<subsubsectionHeader confidence="0.717388">
Illinois CSL Technical Report T-96, March 1980.
</subsubsectionHeader>
<bodyText confidence="0.999902888888889">
This report deals with one aspect of enabling ma-
chines to communicate with people in a natural lan-
guage. The particular problem which is the focus of
this work is the interpretation of nominal compounds,
i.e. sequences of two or more nouns related through
modification. Examples of the kinds of nominal com-
pounds dealt with are: &amp;quot;engine repairs&amp;quot;, &amp;quot;aircraft
flight arrival&amp;quot;, &amp;quot;aluminum water pump&amp;quot;, and &amp;quot;noun
noun modification&amp;quot;.
The interpretation of nominal compounds can be
divided into three intertwined subproblems: lexical
interpretation (mapping words into concepts), modifier
parsing (discovering the structure of strings with more
than two nominals) and concept modification (assigning
an interpretation to the modification of one concept
by another). This last problem is the central one.
The essential feature of this form of modification is
that the underlying semantic relationship which exists
between the two concepts is not explicit. Moreover, a
large number of relationships might, in principal, exist
between the two concepts. The selection of the most
appropriate one depends on a host of semantic, prag-
matic and contextual factors.
As a part of this research a computer program was
written to build an appropriate semantic interpretation
when given a string of nouns. This program has been
designed as one component of the natural language
question answering system JETS. The interpretation is
done by a set of semantic interpretation rules. Some
of the rules are very specific, capturing the meaning of
idioms and canned-phrases. Other rules are very gen-
eral, representing fundamental case-like relationships
which can hold between concepts. A strong attempt
has been made to handle as much as possible with the
more general, highly productive interpretation rules.
The approach has been built around a frame-based
representational system which represents concepts and
the relationships between them. The concepts are
organized into an abstraction hierarchy which supports
inheritance of attributes. The same representational
system is used to encode the semantic interpretation
rules. An important part of the system is the concept
matcher which, given two concepts, determines wheth-
er the first describes the second and, if it does, how
well.
</bodyText>
<page confidence="0.493828">
202 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<table confidence="0.697549571428571">
The FINITE STRING Newsletter Abstracts of Current Literature
Cooperative Responses from a Portable Natural
Language Data Base Query System
S. Jerrold Kaplan
Department of Computer Science
Stanford University
Stanford, California 94305
</table>
<subsubsectionHeader confidence="0.523234">
Univ. of Penn. Ph.D. Thesis, 1979.
</subsubsectionHeader>
<bodyText confidence="0.999928583333333">
This work describes the design and implementation
of a Natural Language (NL) Data Base (DB) query
system (named CO-OP) that provides cooperative
responses to NL requests for data retrieval and oper-
ates with a CODASYL DB management system. Co-
operative responses to questions address a questioner&apos;s
goals and intentions beyond a literal, direct response
while observing the conventions normally associated
with discourse. For example, if a course CIS500 was
not given in the Spring, &apos;77 semester, the indirect re-
sponse R1 to question Q is more cooperative than the
direct, correct response R2.
</bodyText>
<listItem confidence="0.517978">
Q: How many students failed CIS500
in Spring, &apos;77?
It 1: CIS500 was not given in Spring &apos;77.
R2: Zero.
</listItem>
<bodyText confidence="0.992839">
Providing cooperative responses in a computational
setting requires a systematic approach to pragmatic
issues - those aspects of the meaning of utterances
that arise from the fact or context of use. A limited
theory of cooperative behavior in question-answering
is presented, and applied in a query system that is
capable of various types of direct and indirect respon-
ses.
This work also explores problems in the representa-
tion of the knowledge required to produce such re-
sponses. The implementation of CO-OP illustrates
that a DB, a DB schema and a suitably encoded lexi-
con are sufficient sources of domain specific knowl-
edge to provide appropriate responses to a habitable
class of simple NL questions. As a result, the system
achieves a high degree of portability to new DB do-
mains. Transcripts of the program&apos;s behavior on two
radically different DB&apos;s are presented and analyzed.
In addition, issues in the production of useful para-
phrases, effective error handling, transparency of DB
update, and efficient path finding in DB schemas are
discussed.
</bodyText>
<table confidence="0.231515714285714">
Premier Bilan D&apos;Une Experience de
Comprehension du Langage Nature!
D. Coulon, D. Kayser, J. Fuss, F. Jakob, M. Monfils
Laboratoire de Recherche en Informatique
Batiment 490
Universal, de Paris - Sud
F-91405 Orsay, FRANCE
</table>
<subsubsectionHeader confidence="0.587073">
Research Report No. 40, 1979.
</subsubsectionHeader>
<bodyText confidence="0.99985025">
After a brief presentation of our hypotheses on the
understanding process, we describe how they are im-
plemented in the experimental system of our mecha-
nisms and the problem unsolved yet.
</bodyText>
<figure confidence="0.769115555555555">
Acquisition de Connaissances a Partir de
Textes: Une Experimentation en
Documentation Automatique
J.C. Bassano
Laboratoire de Recherche en Informatique
Batiment 490
Universite de Paris - Sud
F-91405 Orsay, FRANCE
Research Report No. 41, 1979.
</figure>
<bodyText confidence="0.999854090909091">
The proposed syntactic interference matching me-
thod induces abstractions in a powerful prototype in-
formation retrieval system implemented with data-base
software. During the retrieval process the initial term
assignment of the incoming information request might
be automatically improved by adding synonymous or
related terms and new term combinations or phrases in
the query. Heuristics enable us to keep the search
space to a manageable size and provide the search
with direction by indicating which of the unused in-
stances are to be used in a cycle of construction.
</bodyText>
<subsectionHeader confidence="0.724">
Les Grammaires Semantiques,
</subsectionHeader>
<bodyText confidence="0.3719555">
Outil Puissant Pour Interroger les Bases
de Donnees en Langage Nature!
</bodyText>
<figure confidence="0.6709444">
A. Bonnet
Laboratoire de Recherche en Informatique
Batiment 490
Universit6 de Paris - Sud
F-91405 Orsay, FRANCE
</figure>
<subsubsectionHeader confidence="0.39138">
Research Report No. 52, 1979.
</subsubsectionHeader>
<bodyText confidence="0.9987318125">
Data bases usually provide a framework in which
the relations between objects are sufficiently precise
that there is no need for a complete analysis (i.e. syn-
tactic) in order to interpret the requests of the user.
Semantic grammars take into account the structures of
the questions without explicitly using conventional
syntactic categories such as nouns, verbs .... Instead,
the categories intervening in the rules emphasize the
domain of application. The use of semantics in the
grammar makes the parsing process deterministic and
therefore very efficient. Furthermore, such grammars
can be rapidly implemented. This is because writing
the formal clause resulting from the request (syntactic
pattern/response expression correspondence) is fairly
straightforward, even for those queries which have a
relatively complex structure.
</bodyText>
<figure confidence="0.4339001">
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 203
The FINITE STRING Newsletter Abstracts of Current Literature
Ober Dialogkoharenz in Naturlichsprachlichen
Al-Systemen.
Walther v. Hahn
Universitat Hamburg
Germanisches Seminar
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
HAM-RPM Report No. 8, Oct. 1979.
</figure>
<bodyText confidence="0.999646785714286">
It is pointed out that dialogue coherence involves
the intentions of the speakers, not just particular fea-
tures of the text. Aspects of coherence involving three
areas of research are then discussed using the dialogue
system HAM-RPM as an example: The cognitive capa-
bilities of the natural language system (in particular,
linguistic and metalinguistic capabilities, knowledge,
and adaptive strategies), the coherence-supporting
behaviour of the natural language partner (in particu-
lar, cooperation, metacommunication, and goal-
directed action) and the text indices (in particular,
anaphora and lexical contingency). The interdepen-
dencies among these three areas can be seen clearly in
natural language Al systems.
</bodyText>
<subsectionHeader confidence="0.9614506">
Analysis by Means of Sentence Patterns:
Examples for Which- and How Many- Questions
Wolfgang Hoeppner
Universitat Hamburg
Germanisches Seminar
</subsectionHeader>
<footnote confidence="0.51454">
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
</footnote>
<note confidence="0.534861">
Memo 10, Dec. 1979, (In German).
</note>
<bodyText confidence="0.999968">
This memo gives a short introduction into the com-
ponent called &apos;Analysis by means of sentence patterns&apos;
in HAM-RPM. The main part contains examples of
WHICH- and HOW MANY- questions. Running the
system in the &apos;protocol mode&apos; the internal processing
of these questions is described in detail.
</bodyText>
<subsectionHeader confidence="0.7786942">
Dialogue Sequences with the System
HAM-RPM in Protocol Mode
Wolfgang Hoeppner and Wolfgang Wahlster
Universitat Hamburg
Germanisches Seminar
</subsectionHeader>
<footnote confidence="0.818834">
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
</footnote>
<note confidence="0.687446">
Memo 11, Jan. 1980, (In German).
</note>
<bodyText confidence="0.999331285714286">
This memo describes the highly flexible tracing and
backtracing mechanisms for internal processing phases
(&apos;protocol mode&apos;) of the system HAM-RPM and sum-
marizes its new linguistic, communicative and cognitive
capabilities. A dialogue sequence about a living-room
scene illustrates both the tracing facilities and the new
capabilities.
</bodyText>
<figure confidence="0.897869375">
Composite Objects:
Representation and Inferences
Wolfgang Hoeppner
Universitat Hamburg
Germanisches Seminar
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
Report 15, March 1980, (In German).
</figure>
<bodyText confidence="0.999807764705882">
This report addresses problems concerning the con-
ceptual representation of composite physical objects.
To define part-whole relations in the framework of an
associative semantic network a simple set of primitive
arcs and simple inference rules are introduced. Inten-
sional and extensional arcs provide the natural lan-
guage dialogue system HAM-RPM with general and
specific knowledge about objects, respectively. The
main disadvantage of these simple constructs appears
to be the unrestricted transitivity of the part-whole
relation. The approach taken in HAM-RPM is dis-
cussed together with proposals concerning related
problems. Examples illustrate the way the system uses
its knowledge when answering HOW MANY- ques-
tions. Finally extensions to the existing representation
structures concerning composite physical objects are
proposed.
</bodyText>
<subsectionHeader confidence="0.8802588">
Towards a Computational Model for
the Semantics of Why-questions
Wolfgang Wahlster
Universitat Hamburg
Germanisches Seminar
</subsectionHeader>
<footnote confidence="0.2568015">
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
</footnote>
<subsubsectionHeader confidence="0.375154">
HAM-RPM Report No. 16, June 1980.
</subsubsectionHeader>
<bodyText confidence="0.999976476190476">
This paper discusses aspects of a computational
model for the semantics of why-questions which are
relevant to the implementation of an explanation com-
ponent in a natural language dialogue system. After a
brief survey of all of the explanation components
which have been implemented to date, some of the
distinguishing features of the explanation component
designed and implemented by the author are listed. In
the first part of the paper the major types of signals
which, like the word &apos;why&apos;, can be used to set the
explanation component into action are listed, and
some ways of recognizing them are considered. In
addition to these linguistic signals, communicative and
cognitive conditions which can have the same effect
are discussed. In the second part the various schemata
for argumentative dialogue sequences which can be
handled by the explanation component in question are
examined. Particular attention is paid to the problems
arising in connection with the iteration of why-
questions and the verbalization of multiple justifica-
tions. Finally schemata for metacommunicative why-
</bodyText>
<page confidence="0.691737">
204 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<note confidence="0.550902">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.9770655">
questions and for why-questions asked by the user are
investigated.
</bodyText>
<subsectionHeader confidence="0.960081666666667">
The Natural Language System HAM-RPM
as a Hotel Manager:
Some Representational Prerequisites
</subsectionHeader>
<author confidence="0.420885">
Anthony Jameson, Wolfgang Hoeppner, and
</author>
<figure confidence="0.4368495">
Wolfgang Wahlster
Universitat Hamburg
Germanisches Seminar
Von-Melle-Park 6
D-2000 Hamburg 13 WEST GERMANY
HAM-RPM Report No. 17, Aug. 1980.
</figure>
<bodyText confidence="0.9999235625">
The dialogue system HAM-RPM simulates a per-
son conversing about one of several interchangeable
scenes in colloquial German. Attention is currently
being focused on a hotel reservation situation in which
the system is required to construct and make use of a
model of its dialogue partner&apos;s goals and beliefs. This
situation calls for a semantic representation language
which is declarative and which permits the representa-
tion, among other things, of various numerical and
natural language quantifiers, conjoined noun phrases
and belief modifiers. This paper describes this lan-
guage and sketches the processes in the course of
which expressions of the language are analysed, con-
structed, transformed, or evaluated. The system&apos;s
behavior is described in detail to illustrate the relation-
ships among these processes.
</bodyText>
<subsectionHeader confidence="0.8967565">
SWYSS - A Natural Language
Question-Answering System for Scene-Analysis
Peter Schefe and Bernd Pretschner
Fachbereich Informatik
Universitat Hamburg
Schliiterstr. 70
D-2000 Hamburg 13 WEST GERMANY
Technical Report, 1979.
</subsectionHeader>
<bodyText confidence="0.999979466666667">
The adequate representation of a universe of dis-
course in a computational system may be tested by
introducing a sensory channel to the &amp;quot;real world&amp;quot;.
SWYSS (&amp;quot;Say-what-you-see-system&amp;quot;) is a natural
language system connected to a TV-camera gathering
snapshots analysed by a scene analysis component.
Since there is a continuum of object shapes and other
property values, the uncertainty of definitions becomes
a main problem of communication. It is described
how representations of natural language inputs and
pictorial input are computed and tied together. At
present, the system is focused on the processing of
natural language queries containing vague descriptors
and imprecise quantifiers. The answers of SWYSS are
in elaborate German as well as the questions.
</bodyText>
<subsectionHeader confidence="0.615550857142857">
On Foundations of Reasoning with Uncertain
Facts and Vague Concepts
Peter Schefe
Fachbereich lnformatik
Universitat Hamburg
Schliiterstr. 70
D-2000 Hamburg 13 WEST GERMANY
</subsectionHeader>
<bodyText confidence="0.983638">
Report No. 56, 1979.
&amp;quot;Fuzzy sets theory&amp;quot; and &amp;quot;fuzzy logic&amp;quot; based on
the former have become of rapidly increasing interest.
The foundations, however, are still disputed. Especial-
ly the definitions of some set operations and logical
connectives appear to be somewhat arbitrary. The
relations of &amp;quot;fuzziness&amp;quot; to &amp;quot;probability&amp;quot; and
&amp;quot;possibility&amp;quot; are not yet clear. This paper contains an
outline of a probabilistic foundation of multi-valued
(&amp;quot;fuzzy&amp;quot;) reasoning. The fundamental concept is
&amp;quot;agreement probability&amp;quot;. It is shown that some unde-
sirable consequences of &amp;quot;fuzzy logic&amp;quot;, e.g., that tautol-
ogies of propositional calculus are not preserved, can
be avoided. A proposal for alternative definitions of
&amp;quot;degree of membership&amp;quot; and operations on
membership-graded sets are given.
&amp;quot;Fuzziness&amp;quot; is interpreted as a subjectivistic con-
cept, i.e., subjective uncertainty pertaining to the truth
of a proposition. An important consequence thereof is
that, from a graded agreement associated with a con-
jecture, an agreement degree pertaining to its negation
cannot be computed.
According to this foundation Shortliffe&apos;s model of
medical diagnosis is reviewed as an application para-
digm. There is no fundamental disagreement with
Shortliffe&apos;s interpretation. However, Zadeh&apos;s &amp;quot;lin-
guistic modelling&amp;quot; is shown to be inadequate.
&amp;quot;Fuzziness&amp;quot; of linguistic concepts is interpreted as
uncertainty of the applicability of a predicate in a
given situation. This leads to the conclusion that the
definition of derived concepts, especially, of hedged
expressions referring to continuous scales cannot be
modelled using Zadeh&apos;s fuzzy set operations. Experi-
mental findings of Hersh and Caramazza support an
alternative interpretation. Particularly, Zadeh&apos;s con-
jecture that truth values can be equated with member-
ship degrees is shown to be inadequate. Alternative
interpretations of linguistic phenomena considered and
of the sorites paradox are given. Especially the meta-
linguistic character of the phenomena is emphasized.
It is argued that &amp;quot;vagueness&amp;quot; and &amp;quot;uncertainty&amp;quot; should
be clearly distinguished, as well as &amp;quot;possibility&amp;quot; and
&amp;quot;applicability&amp;quot;. Suggestions are made how underlying
measuring scales and orderings of objects are used in
reasoning processes involving vague concepts.
</bodyText>
<table confidence="0.608230777777778">
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 205
The FINITE STRING Newsletter Abstracts of Current Literature
On Representing Uncertainty in AI-Systems
Peter Schefe
Fachbereich Informatik
Universitiat Hamburg
Schliiterstr. 70
D-2000 Hamburg 13 WEST GERMANY
Note 69, 1979.
</table>
<bodyText confidence="0.999240666666667">
Al systems dealing with natural environments and
texts have to cope with &amp;quot;fuzziness&amp;quot;, i.e., factual uncer-
tainty and uncertainty of meaning. A formal model of
&amp;quot;fuzzy reasoning&amp;quot; is proposed. It is based on the
notion of &amp;quot;agreement probability&amp;quot; of a proposition.
Combining and inference rules are defined similar to,
but definitely deviating from, those in probability the-
ory. Epistemologically, &amp;quot;agreement probability&amp;quot; is
interpreted as subjective certainty or uncertainty of
belief in the truth (or falsehood) of a proposition.
According to this, some theories and theoretical
assumptions underlying AI systems are reviewed. Es-
pecially, MYCIN&apos;s inference rules conceived of on a
purely intuitive base are shown to be valid in general.
However, systems of language and story understanding
do not cope with uncertain inferences adequately as
yet. Suggestions are made how Schank&apos;s &amp;quot;conceptual
inference&amp;quot; and some aspects of Wilks&apos; &amp;quot;preference
semantics&amp;quot; can be reinterpreted and provided with a
more coherent model of inference making under un-
certainty.
</bodyText>
<subsectionHeader confidence="0.920666142857143">
Arten von Wissen und lnferenzen in
Natiirlichsprachlichen Systemen
Peter Schefe
Fachbereich Informatik
Universitat Hamburg
Schliiterstr. 70
D-2000 Hamburg 13 WEST GERMANY
</subsectionHeader>
<bodyText confidence="0.973426888888889">
Note 73, 1979.
Since &amp;quot;intelligent&amp;quot; information systems using natu-
ral language interfaces have to be considered formal
systems, philosophically, there is no point to ascribe to
these systems natural capabilities corresponding to
human understanding, intelligence, and knowledge. Of
course, the implementability of a formal system does
not support the contrary. On the other hand, the pos-
sible usefulness of such systems should not be doubted
in general. There are problems of formal representa-
tions of knowledge and belief pertaining to an ade-
quate epistemological taxonomy. Different kinds of
knowledge and belief require different formal systems
for representation and inference making. Definiteness
- undefiniteness, preciseness - unpreciseness, and com-
pleteness - uncompleteness are the main dimensions
pertaining to the epistemological state of the knowl-
edge base. Models available so far are discussed. Be-
yond that, knowledge may be given in vague terms,
such that there is a tolerance space for a set of com-
patible assertions. The notions of &amp;quot;definitional uncer-
tainty&amp;quot; and &amp;quot;prototype&amp;quot; can be accounted for by a
probabilistic model of &amp;quot;tolerant&amp;quot; knowledge. For all
kinds of knowledge addressed, conditions of inference
making are given, and implementability is demonstrat-
ed using the programming languages FUZZY and
AMORD.
</bodyText>
<subsectionHeader confidence="0.837811714285714">
Sprachliche Bildinterpretation
fiir em n Frage-Antwort-System
Karl-Jiirgen Han(&amp;mann
Fachbereich Informatik
Universitat Hamburg
Schliiterstr. 70
D-2000 Hamburg 13 WEST GERMANY
</subsectionHeader>
<subsubsectionHeader confidence="0.48194">
Note 74, 1980.
</subsubsectionHeader>
<bodyText confidence="0.997461866666667">
A component of a system (SWYSS - &apos;Say what you
see system&apos;) is described that generates a linguistic
representation of a two-dimensional scene from the
output of a scene analysis component which recognizes
objects by use of prototypes. Most of the linguistical-
ly possible spatial relations holding among the objects
are computed. These computations are triggered by
natural-language queries, using a knowledge base,
except for relations pertaining to gravitation. Most of
the relations are vague, i.e., their applicability can be
graded. For these relations, a numerical degree of
applicability is computed which can be reflected in
natural language expressions. The procedures for
computing the spatial relations are implemented in
FUZZY and LISP.
</bodyText>
<subsectionHeader confidence="0.891918">
KNET: An Extended SI-Net Formalism for
Knowledge Representation Systems
Michael W. Freeman
ADO/FSSG
Burroughs Corporation
P.O. Box 517
Paoli, Pennsylvania 19301
Technical Report TR 80-1, Jan. 1980.
</subsectionHeader>
<bodyText confidence="0.999983571428571">
We discuss in this paper four areas where we feel
additional epistemological primitives should be intro-
duced into Brachman&apos;s Structured Inheritance Network
formalism. These concern respectively: definitional vs.
descriptive concepts, generic vs. individuated descrip-
tion, coreference vs. denotation, and the representa-
tion of dynamic attributes as event logs and monitors.
</bodyText>
<subsectionHeader confidence="0.7633588">
Representing Type Hierarchies
Freeman Rawson
IBM General Systems Division
Boca Raton, Florida 33432
IBM SRI Technical Report TR 73-006, Jan. 1980.
</subsectionHeader>
<bodyText confidence="0.595109">
Symbol mapping is the problem of associating
properties with an object based upon typed informa-
</bodyText>
<page confidence="0.611864">
206 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
<note confidence="0.730811">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.999863333333333">
tion about the object so that the properties can be
inherited from general class to specific instances. The
reference window problem is the problem of finding
an individual object given a description of the object.
Both of these problems cannot be solved efficiently
using the standard methods of procedural inference
found in PLANNER and CONNIVER. However, by
using conceptual graph theory and organizing the data
base using type information, both of these problems
can be handled with reasonable efficiency.
The conceptual graph search algorithms and the
methods available in PLANNER and CONNIVER are
of equal power in the sense that they both derive the
same inferences. Using some methods from concrete
complexity theory, the efficiency of both the PLAN-
NER approach and the conceptual graph approach are
analyzed, and formulas are derived for the average
number of nodes searched.
</bodyText>
<subsectionHeader confidence="0.434284666666667">
An English Parser
Jonathan L. Handel
IBM Systems Research Institute
205 East 42nd Street
New York, New York 10017
Technical Report TR 73-005, Jan. 1980.
</subsectionHeader>
<bodyText confidence="0.999016125">
ENGLISH is a purely syntactic parser for English
sentences. It was originally designed as an illustrative
program for a course in linguistics at the IBM Systems
Research Institute. The program has the following
features: high speed, generation of all parses in the
grammar, interactive execution, and good coverage
with a small grammar. This report is a user&apos;s guide
and reference source for the ENGLISH program.
</bodyText>
<subsectionHeader confidence="0.81339075">
An Ideational Parser
Alan L. Tharp
Computer Science Department
North Carolina State University
Raleigh, North Carolina 27650
Jeffrey F. Eastman
Hewlett-Packard Corporation
Loveland, Colorado
</subsectionHeader>
<bodyText confidence="0.983878833333333">
SIGLASH Newsletter 12, 1 (March 1979), 17-36.
Recent parsers have extended the variety and diffi-
culty of natural language constructs recognizable by a
computer. However, one shortcoming of existing par-
sers is that as the complexity of the sentences recog-
nized increases, the computational complexity increas-
es quadratically. One reason for this computational
explosion is that much if not most of the control infor-
mation is embedded in the parser.
A different approach, referred to as an ideational
parser, is proposed. Although the design for this par-
ser was motivated by the manner in which people
might use language, it is not necessarily intended to be
a model for human cognition. The control informa-
tion, for the most part, is removed to the lexicon, and
the words are considered operators in the information
of a mental picture rather than as operands to the par-
ser. The parser mechanism is detailed with an exam-
ple parse and a typical conversation is given in the
appendix.
Two primary benefits of the ideational parser are
1) an improved, simpler control mechanism and 2) the
ability to acquire new knowledge which is automatical-
ly stored in the same format as the given knowledge.
</bodyText>
<subsectionHeader confidence="0.486383833333333">
Automatic Resolution of Linguistic Ambiguities
B.K. Boguraev
Computer Laboratory
University of Cambridge
Corn Exchange Street
Cambridge, CB2 3QG ENGLAND
</subsectionHeader>
<subsubsectionHeader confidence="0.526351">
Technical Report No. 11, 1979.
</subsubsectionHeader>
<bodyText confidence="0.985176428571429">
The thesis describes the design, implementation and
testing of a natural language analysis system capable
of performing the task of generating paraphrases in a
highly ambiguous environment. The emphasis is on
incorporating strong semantic judgement in an aug-
mented transition network grammar: the system pro-
vides a framework for examining the relationship be-
tween syntax and semantics in the process of text
analysis, especially while treating the related phenome-
na of lexical and structural ambiguity. Word-sense
selection is based on global analysis of context within
a semantically well-formed unit, with primary emphasis
on the verb choice. In building structures representing
text meaning, the analyser relies not on screening
through many alternative structures - intermediate
syntactic, or partial semantic - but on dynamically
constructing only the valid ones. The two tasks of
sense selection and structure building are procedurally
linked by the application of semantic routines derived
from Y. Wilks&apos; preference semantics, which are in-
voked at certain well chosen points of the syntactic
constituent analysis - this delimits the scope of their
action and provides context for a particular disambigu-
ation technique. The hierarchical process of sentence
analysis is reflected in the hierarchical organization of
application of these semantic routines - this allows the
efficient coordination of various disambiguation tech-
niques, and the reduction of syntactic backtracking,
non-determinism in the grammar, and semantic paral-
lelism. The final result of the analysis process is a
dependency structure providing a meaning representa-
tion of the input text with labelled components cen-
tered on the main verb element, each characterized in
terms of semantic primitives and expressing both the
meaning of a constituent and its function in the overall
textual unit. The representation serves as an input to
the generator, organized around the same underlying
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 207
The FINITE STRING Newsletter Abstracts of Current Literature
principle as the analyser - the verb is central to the
clause. Currently the generator works in paraphrase
mode, but is specially designed so that with minimum
effort and virtually no change in the program control
structure and code it could be switched over to per-
form translation.
The thesis discusses the rationale for the approach
adopted, comparing it with others, describes the sys-
tem and its machine implementation, and presents
experimental results.
</bodyText>
<table confidence="0.415873">
Definite Clause Grammars for Language
Analysis - A Survey of the Formalism
and a Comparison with ATN&apos;s
Fernando C. N. Pereira and David H. D. Warren
Artificial Intelligence Department
University of Edinburgh
Forrest Hill
Edinburgh EH1 2QL, SCOTLAND
Artificial Intelligence 13, 3 (May 1980), 231-278.
</table>
<bodyText confidence="0.9987961">
A clear and powerful formalism for describing lan-
guages, both natural and artificial, follows from a me-
thod for expressing grammars in logic due to Colmer-
auer and Kowalski. This formalism, which is a natural
extension of context-free grammars, we call &amp;quot;definite
clause grammars&amp;quot; (DCG&apos;s).
A DCG provides not only a description of a lan-
guage, but also an effective means for analysing
strings of that language, since the DCG, as it stands, is
an executable program of the programming language
PROLOG. Using a standard PROLOG compiler, the
DCG can be compiled into efficient code, making it
feasible to implement practical language analysers
directly as DCG&apos;s.
This paper compares DCG&apos;s with the successful
and widely used augmented transition network (ATN)
formalism, and indicates how ATN&apos;s can be translated
into DCG&apos;s. It is argued that DCG&apos;s can be at least as
efficient as ATN&apos;s, whilst the DCG formalism is clear-
er, more concise and in practice more powerful.
</bodyText>
<sectionHeader confidence="0.430753" genericHeader="method">
Toward A PROLOG Text Grammar
</sectionHeader>
<reference confidence="0.6868318">
Georgette Silva and Don Dwiggins
Operating Systems, Inc.
21031 Ventura Blvd., Suite 1200
Woodland Hills, California 91364
SIGART Newsletter 73 (Oct. 1980), 20-25.
</reference>
<bodyText confidence="0.999910909090909">
This paper focuses on the syntactic and semantic
processing components -- the Text Grammar -- of an
application-oriented experimental natural language
understanding system, called MATRES, currently un-
der development at Operating Systems Inc. The pri-
mary application for this system is the automated gen-
eration and update of data bases from natural lan-
guage text. The current version of the Text Grammar
is implemented in the programming language PRO-
LOG, which provides a unified and powerful environ-
ment capable of representing the structures and proc-
esses required for the analysis of natural language
text.
Our methodological approach combines concepts
from Text Grammar theory with Artificial Intelligence
techniques for discourse analysis. We subscribe to the
hypothesis that as people read and understand text,
they construct a multi-level mental representation of
its content, with the most concrete level at the bottom
of the conceptual structure. Thus, at the lowest level
of this mental structure are the sentences and phrases
of the text, while the representation becomes more
concise and abstract at higher levels. This concept of
understanding text is embodied in our PROLOG text
grammar.
Our approach is centered around the notion of
event, and utilizes two major knowledge sources: (1)
a model of the sublanguage that characterizes the do-
main of application and (2), a model of the entities
and relations characteristic of this domain. These
knowledge sources are used by our text grammar to
derive content representations approximating a
human&apos;s understanding of a text.
</bodyText>
<subsectionHeader confidence="0.9706568">
Logic Programming and Compiler Writing
David Warren
Artificial Intelligence Department
University of Edinburgh
Forrest Hill
</subsectionHeader>
<bodyText confidence="0.705392">
Edinburgh EH1 2QL, SCOTLAND
</bodyText>
<subsubsectionHeader confidence="0.898594">
Softw. Pract. Exper. 10, 2 (Feb. 1980), 97-125.
</subsubsectionHeader>
<bodyText confidence="0.999991">
The concept of &amp;quot;logic programming,&amp;quot; and its prac-
tical application in the programming language PRO-
LOG, are explained from first principles. The ideas
are illustrated by describing in detail one sizable PRO-
LOG program which implements a simple compiler.
The advantages and practicability of using PROLOG
for &amp;quot;real&amp;quot; compiler implementation are discussed.
</bodyText>
<subsectionHeader confidence="0.895192">
Translation of Phrase Structured
Programming Languages
William Butte!mann
</subsectionHeader>
<affiliation confidence="0.522871666666667">
Computer and Information Science
Ohio State University
Columbus, Ohio 43210
</affiliation>
<subsubsectionHeader confidence="0.237896">
Technical Report AFOSR-TR-80-0088, Dec. 1979.
</subsubsectionHeader>
<bodyText confidence="0.965381269230769">
An integrated formal theory of phrase structure
linguistic descriptions has been developed, based on
classical phrase linguistic theory and on a new formal
theory of phrase structure semantics developed by this
research project. The theory provides for both
context-sensitive syntax and semantic structure, inter-
pretations, the meaning of certain linguistic entities
208 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
The FINITE STRING Newsletter Abstracts of Current Literature
such as morphemes, phrases, sentences, and state-
ments, and specifies the nature of and relationship
between syntactic and semantic ambiguity. The theo-
retical model of syntax and semantics was developed
in order to study computational aspects of semantic
interpreters and language translators. Based on the
model, a theory of interpretation and translation was
constructed, and a number of results in these two are-
as have been developed. It was shown how linguistic
properties can be treated either as context-sensitive or
context-free and either as semantic or syntactic infor-
mation. This theory establishes the basis for further
research into the computational complexity of seman-
tic interpreters and especially into the problem of min-
imizing the complexity of interpreters by proper trade-
offs between syntax and semantics and/or &apos;context-
sensitive&apos;-ness and &apos;context-free&apos;-ness.
</bodyText>
<sectionHeader confidence="0.794305" genericHeader="method">
A System for Natural Language Computation
</sectionHeader>
<reference confidence="0.783969666666667">
Alan W. Biermann, Bruce W. Ballard,
and Anne M. Holler
Department of Computer Science
Duke University
Durham, North Carolina 27706
SIGLASH Newsletter 12, 1 (March 1979), 6-16.
</reference>
<bodyText confidence="0.999076730769231">
This paper briefly describes a natural language pro-
gramming system called NLC which allows users to
type commands in English and watch the resulting
actions carried out on a computer display screen. The
data entities appear on the screen at all times, so that
the user can observe the effect of each input before
proceeding to the next one. Should some input ever
be incorrectly processed, a backup facility allows re-
quests to be clarified after restoring the previous con-
text and data values. The user may identify a se-
quence of natural language commands as a procedure
which, when given a name, acts as a new imperative
verb and may be used to define further customiza-
tions.
The design of NLC stresses reliability and depth of
linguistic coverage, so that the facilities provided can
be employed arbitrarily. For the purpose of testing a
prototype version of the system, the domain of matrix
elements and scalar variables was selected. For in-
stance, in a recent test of the system, a paid subject
was asked to use NLC to compute the final averages
for a hypothetical class of six students using a speci-
fied formula. The subject requested of the system that
a matrix be displayed and that the columns be labeled.
He then labeled the rows of the matrix with the
students&apos; names and entered their grades.
</bodyText>
<sectionHeader confidence="0.6196575" genericHeader="method">
Statistical Techniques for
Free-Text Processing
</sectionHeader>
<reference confidence="0.87767816">
John M. Morris
PAR Corporation
228 Liberty Plaza
Rome, New York 13440
SIGLASH Newsletter 13, 2 (June 1980), 14-32.
Over the past eight years we have developed statis-
tical methods for characterizing, classifying, and re-
trieving brief natural-language messages. Our goal
was to provide a tool for people who had to deal with
enormous numbers of heterogeneous documents, using
ill-defined criteria of relevance and interest. Initially,
we worked with a large, general-purpose system, the
On-Line Pattern Analysis and Recognition System
(OLPARS). More recently, we have developed a sys-
tem called Message Extraction Through Estimation of
Relevance (METER). Our present aim is the con-
struction of a Testbed system for further studies and
the development of more complex systems.
Anaphora in Natural Language Understanding:
A Survey
Graeme Hirst
Department of Computer Science
Box 1910, Brown University
Providence, Rhode Island 02912
UBC Technical Report 79-2, May 1979.
</reference>
<bodyText confidence="0.95123168">
A problem that all computer-based natural lan-
guage understanding systems encounter is that of lin-
guistic reference, and in particular anaphora
(abbreviated reference). This report is an extensive
review of the reference and anaphor problem, and the
approaches to it that natural language understanding
systems have taken, from early systems such as STU-
DENT through to current discourse-oriented ones such
as PAL.
The problem is first examined in detail, and exam-
ples are given of many different types of anaphor,
some of which have been overlooked by previous au-
thors. The approaches taken in traditional systems are
then described and abstracted and it is shown why
they were inadequate, and why discourse theme and
anaphoric focus need to be taken into account. The
strengths and weaknesses of current anaphora theories
and approaches are evaluated. The report closes with
a list of some remaining research problems.
The report has been written so as to be as compre-
hensible as possible to both Al workers who know no
linguistics, and linguists who have not studied artificial
intelligence.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 209
The FINITE STRING Newsletter Abstracts of Current Literature
</bodyText>
<reference confidence="0.925225666666667">
An Artificial Intelligence Approach to
Natural Language Teaching
Larry H. Reeker
University of Queensland
St. Lucia, Queensland, AUSTRALIA
Aust. Comput. Sci. Commun. 2, 1 (Jan. 1980), 97-106.
</reference>
<bodyText confidence="0.964915333333333">
This paper develops the rationale and outlines the
structure of a program, LANGLAB, for computer-
aided instruction in a second language. Although the
first stage of the program is based on conventional
teaching principles, the second stage uses an
&amp;quot;intelligent&amp;quot; tutor to guide the student into more ad-
vanced structures of the language. Essentially, the
program mimics situations that appear to be important
in a first language acquisition situation, providing a
rich, structured environment without overly restricting
the student&apos;s ability to move forward into new materi-
al.
</bodyText>
<reference confidence="0.670845833333333">
Dylan Thomas, the Craftsman: Computer
Analysis of the Composition of a Poem
Mary Dee Harris Fosberg
Central State University
Edmond, Oklahoma
ALLC Bulletin 7, 3 (1979), 295-300.
</reference>
<bodyText confidence="0.9842423">
Over 400 pages of manuscript exist of Dylan
Thomas&apos;s &amp;quot;Poem on His Birthday,&amp;quot; published in its
final form with 108 lines. These manuscripts provide
evidence of the poet&apos;s work while composing the
poem. Computer analysis of this material first re-
quired designing an encoding scheme to capture the
two dimensionality of the manuscript page and trans-
late it into a linear string of characters. When the
information from the pages had been transcribed into
computer readable form, several collations were made
using the published version of the poem as copy text.
These collations produced a history of the composition
process. Thomas&apos;s use of Roget&apos;s Thesaurus was ana-
lyzed to reveal some of his methods of choosing
words. The data from the manuscripts has been or-
ganized into a database on disk for convenient access
to the poetry to facilitate further research. Later
study will include statistical analysis of metric and
sound patterns to learn more about Thomas&apos;s method
of composing the poem.
</bodyText>
<reference confidence="0.5719844">
Tolvukonnun a Tidni Orda og
Stafa i Islenskum Texta
Baldur Jonsson, Bjorn Ellertsson,
and Sven P. Sigurosson
Raunvisindastofnun Haskolans
Science Institute
University of Iceland
Dunhaga 3
Reykjavik ICELAND
Report RH-80-12, Oct. 1980.
</reference>
<bodyText confidence="0.998799736842105">
In 1972, on the initiative of the first author, the
Science Institute and the Institute of Nordic Linguis-
tics (both at the University of Iceland) began working
together on a project in linguistic computing. The
main purpose was to establish the feasibility of carry-
ing out such a project in Iceland. It was decided to try
to make a frequency study at the graphic level of the
novel Hreiorio by Olafur Johann Sigurosson, published
in 1972, and to aim at producing the following: (1)
Word-frequency lists in alphabetic order, reverse or-
der, and order of decreasing frequency. (2) A com-
plete concordance to the text. (3) A report whose
objective was in turn threefold: a) to account for the
execution of the project, b) to include results in tabu-
lar form on frequencies of letters, word-structures, and
related matters, c) to serve as an introductory guide to
anybody wishing to carry out a similar study.
The word-frequency lists have been published in
ten copies (Baldur Jonsson 1975). The concordance
was line-printed in three copies in 1976 and later on
made available for public use with the addition of a
preface and a title page (Baldur Jonsson 1978). The
publication of the present report has - for various per-
sonal reasons - been considerably delayed. In this
summary we mainly cover the second objective of the
report.
Chapter 1 describes the general progress of the
project. Chapter 2 refers to previously published fre-
quency counts of Icelandic texts. Chapter 3 accounts
for some linguistic concepts and terms used in the
succeeding chapters. Chapter 4 describes the key-
punching rules used in this project. Chapter 5 con-
tains a description of the programs used and some
efficiency considerations. Chapter 6 contains samples
from the published word-frequency lists. The main
tabular information is contained in Chapter 7. In
Chapter 8 the concordance is discussed and samples
from it are shown.
</bodyText>
<page confidence="0.90844">
210 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.325104">
<title confidence="0.998890666666667">The FINITE STRING Newsletter Abstracts of Current Literature Abstracts of Current Literature Interestingness: Controlling Inferences</title>
<author confidence="0.999985">Roger C Schank</author>
<affiliation confidence="0.9821075">Department of Computer Science Yale University</affiliation>
<address confidence="0.990654">New Haven, Connecticut 06520</address>
<abstract confidence="0.944197571428571">Artificial Intelligence 12, 3 (Nov. 1979), 273-297. One of the central issues in natural language understanding for the last few years has been the problem of making inferences and controlling those inferences. In this paper I will discuss an overall method for controlling inferences that has effects on parsing, script application and the tracking of goals and plans.</abstract>
<intro confidence="0.523207">Reminding and Memory Organization:</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<institution>Georgette Silva and Don Dwiggins Operating Systems, Inc.</institution>
<marker></marker>
<rawString>Georgette Silva and Don Dwiggins Operating Systems, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ventura Blvd</author>
</authors>
<title>Suite 1200</title>
<date></date>
<journal>SIGART Newsletter</journal>
<volume>73</volume>
<location>Woodland Hills, California</location>
<marker>Blvd, </marker>
<rawString>21031 Ventura Blvd., Suite 1200 Woodland Hills, California 91364 SIGART Newsletter 73 (Oct. 1980), 20-25.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Alan W Biermann</author>
<author>Bruce W Ballard</author>
<author>M Anne</author>
</authors>
<institution>Holler Department of Computer Science Duke University</institution>
<marker>Biermann, Ballard, Anne, </marker>
<rawString>Alan W. Biermann, Bruce W. Ballard, and Anne M. Holler Department of Computer Science Duke University</rawString>
</citation>
<citation valid="true">
<authors>
<author>North Durham</author>
</authors>
<title>Carolina 27706</title>
<date>1979</date>
<journal>SIGLASH Newsletter</journal>
<volume>12</volume>
<pages>6--16</pages>
<marker>Durham, 1979</marker>
<rawString>Durham, North Carolina 27706 SIGLASH Newsletter 12, 1 (March 1979), 6-16.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M John</author>
</authors>
<title>Morris PAR Corporation 228</title>
<location>Liberty Plaza</location>
<marker>John, </marker>
<rawString>John M. Morris PAR Corporation 228 Liberty Plaza</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rome</author>
</authors>
<date>1344</date>
<journal>SIGLASH Newsletter</journal>
<volume>13</volume>
<pages>14--32</pages>
<location>New York</location>
<marker>Rome, 1344</marker>
<rawString>Rome, New York 13440 SIGLASH Newsletter 13, 2 (June 1980), 14-32.</rawString>
</citation>
<citation valid="false">
<title>Over the past eight years we have developed statistical methods for characterizing, classifying, and retrieving brief natural-language messages. Our goal was to provide a tool for people who had to deal with enormous numbers of heterogeneous documents, using ill-defined criteria of relevance and interest. Initially, we worked with a large, general-purpose system, the On-Line Pattern Analysis and Recognition System (OLPARS). More recently, we have developed a system called Message Extraction Through Estimation of Relevance (METER). Our present aim is the construction of a Testbed system for further studies and the development of more complex systems.</title>
<marker></marker>
<rawString>Over the past eight years we have developed statistical methods for characterizing, classifying, and retrieving brief natural-language messages. Our goal was to provide a tool for people who had to deal with enormous numbers of heterogeneous documents, using ill-defined criteria of relevance and interest. Initially, we worked with a large, general-purpose system, the On-Line Pattern Analysis and Recognition System (OLPARS). More recently, we have developed a system called Message Extraction Through Estimation of Relevance (METER). Our present aim is the construction of a Testbed system for further studies and the development of more complex systems.</rawString>
</citation>
<citation valid="false">
<title>Anaphora in Natural Language Understanding: A Survey</title>
<marker></marker>
<rawString>Anaphora in Natural Language Understanding: A Survey</rawString>
</citation>
<citation valid="false">
<date>1910</date>
<tech>02912 UBC Technical Report 79-2,</tech>
<institution>Graeme Hirst Department of Computer Science Box</institution>
<marker>1910</marker>
<rawString>Graeme Hirst Department of Computer Science Box 1910, Brown University Providence, Rhode Island 02912 UBC Technical Report 79-2, May 1979.</rawString>
</citation>
<citation valid="false">
<title>An Artificial Intelligence Approach to Natural Language Teaching</title>
<marker></marker>
<rawString>An Artificial Intelligence Approach to Natural Language Teaching</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Larry</author>
</authors>
<date>1980</date>
<journal>AUSTRALIA Aust. Comput. Sci. Commun.</journal>
<volume>2</volume>
<pages>97--106</pages>
<institution>Reeker University of Queensland St.</institution>
<location>Lucia, Queensland,</location>
<marker>Larry, 1980</marker>
<rawString>Larry H. Reeker University of Queensland St. Lucia, Queensland, AUSTRALIA Aust. Comput. Sci. Commun. 2, 1 (Jan. 1980), 97-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dylan Thomas</author>
</authors>
<title>the Craftsman: Computer Analysis of the Composition of a</title>
<date>1979</date>
<journal>ALLC Bulletin</journal>
<volume>7</volume>
<pages>295--300</pages>
<institution>Poem Mary Dee Harris Fosberg Central State University Edmond,</institution>
<location>Oklahoma</location>
<marker>Thomas, 1979</marker>
<rawString>Dylan Thomas, the Craftsman: Computer Analysis of the Composition of a Poem Mary Dee Harris Fosberg Central State University Edmond, Oklahoma ALLC Bulletin 7, 3 (1979), 295-300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bjorn Ellertsson Jonsson</author>
<author>P Sven</author>
</authors>
<title>Tolvukonnun a Tidni Orda og Stafa i Islenskum Texta Baldur</title>
<date>1980</date>
<tech>3 Reykjavik ICELAND Report RH-80-12,</tech>
<institution>Sigurosson Raunvisindastofnun Haskolans Science Institute University of Iceland Dunhaga</institution>
<marker>Jonsson, Sven, 1980</marker>
<rawString>Tolvukonnun a Tidni Orda og Stafa i Islenskum Texta Baldur Jonsson, Bjorn Ellertsson, and Sven P. Sigurosson Raunvisindastofnun Haskolans Science Institute University of Iceland Dunhaga 3 Reykjavik ICELAND Report RH-80-12, Oct. 1980.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>