<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.999544">
Domain Adaptation with Latent Semantic Association
for Named Entity Recognition
</title>
<author confidence="0.994313">
Honglei Guo Huijia Zhu Zhili Guo Xiaoxun Zhang Xian Wu and Zhong Su
</author>
<affiliation confidence="0.991879">
IBM China Research Laboratory
</affiliation>
<address confidence="0.89945">
Beijing, P. R. China
</address>
<email confidence="0.986718">
{guohl, zhuhuiji, guozhili, zhangxx, wuxian, suzhong}@cn.ibm.com
</email>
<sectionHeader confidence="0.994482" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9145353">
Domain adaptation is an important problem in
named entity recognition (NER). NER classi-
fiers usually lose accuracy in the domain trans-
fer due to the different data distribution be-
tween the source and the target domains. The
major reason for performance degrading is
that each entity type often has lots of domain-
specific term representations in the different
domains. The existing approaches usually
need an amount of labeled target domain data
for tuning the original model. However, it
is a labor-intensive and time-consuming task
to build annotated training data set for every
target domain. We present a domain adapta-
tion method with latent semantic association
(LaSA). This method effectively overcomes
the data distribution difference without lever-
aging any labeled target domain data. LaSA
model is constructed to capture latent seman-
tic association among words from the unla-
beled corpus. It groups words into a set of
concepts according to the related context snip-
pets. In the domain transfer, the original term
spaces of both domains are projected to a con-
cept space using LaSA model at first, then the
original NER model is tuned based on the se-
mantic association features. Experimental re-
sults on English and Chinese corpus show that
LaSA-based domain adaptation significantly
enhances the performance of NER.
</bodyText>
<sectionHeader confidence="0.998767" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99689575">
Named entities (NE) are phrases that contain names
of persons, organizations, locations, etc. NER is an
important task in information extraction and natu-
ral language processing (NLP) applications. Super-
vised learning methods can effectively solve NER
problem by learning a model from manually labeled
data (Borthwick, 1999; Sang and Meulder, 2003;
Gao et al., 2005; Florian et al., 2003). However, em-
pirical study shows that NE types have different dis-
tribution across domains (Guo et al., 2006). Trained
NER classifiers in the source domain usually lose
accuracy in a new target domain when the data dis-
tribution is different between both domains.
Domain adaptation is a challenge for NER and
other NLP applications. In the domain transfer,
the reason for accuracy loss is that each NE type
often has various specific term representations and
context clues in the different domains. For ex-
ample, {“economist”, “singer”, “dancer”, “athlete”,
“player”, “philosopher”, ...} are used as context
clues for NER. However, the distribution of these
representations are varied with domains. We expect
to do better domain adaptation for NER by exploit-
ing latent semantic association among words from
different domains. Some approaches have been pro-
posed to group words into “topics” to capture im-
portant relationships between words, such as Latent
Semantic Indexing (LSI) (Deerwester et al., 1990),
probabilistic Latent Semantic Indexing (pLSI) (Hof-
mann, 1999), Latent Dirichlet Allocation (LDA)
(Blei et al., 2003). These models have been success-
fully employed in topic modeling, dimensionality
reduction for text categorization (Blei et al., 2003),
ad hoc IR (Wei and Croft., 2006), and so on.
In this paper, we present a domain adaptation
method with latent semantic association. We focus
</bodyText>
<page confidence="0.965124">
281
</page>
<note confidence="0.8902355">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 281–289,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99996496875">
on capturing the hidden semantic association among
words in the domain adaptation. We introduce the
LaSA model to overcome the distribution difference
between the source domain and the target domain.
LaSA model is constructed from the unlabeled cor-
pus at first. It learns latent semantic association
among words from their related context snippets.
In the domain transfer, words in the corpus are as-
sociated with a low-dimension concept space using
LaSA model, then the original NER model is tuned
using these generated semantic association features.
The intuition behind our method is that words in one
concept set will have similar semantic features or
latent semantic association, and share syntactic and
semantic context in the corpus. They can be consid-
ered as behaving in the same way for discriminative
learning in the source and target domains. The pro-
posed method associates words from different do-
mains on a semantic level rather than by lexical oc-
currence. It can better bridge the domain distribu-
tion gap without any labeled target domain samples.
Experimental results on English and Chinese corpus
show that LaSA-based adaptation significantly en-
hances NER performance across domains.
The rest of this paper is organized as follows. Sec-
tion 2 briefly describes the related works. Section 3
presents a domain adaptation method based on latent
semantic association. Section 4 illustrates how to
learn LaSA model from the unlabeled corpus. Sec-
tion 5 shows experimental results on large-scale En-
glish and Chinese corpus across domains, respec-
tively. The conclusion is given in Section 6.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999962348837209">
Some domain adaptation techniques have been em-
ployed in NLP in recent years. Some of them
focus on quantifying the generalizability of cer-
tain features across domains. Roark and Bacchiani
(2003) use maximum a posteriori (MAP) estimation
to combine training data from the source and target
domains. Chelba and Acero (2004) use the param-
eters of the source domain maximum entropy clas-
sifier as the means of a Gaussian prior when train-
ing a new model on the target data. Daume III and
Marcu (2006) use an empirical Bayes model to esti-
mate a latent variable model grouping instances into
domain-specific or common across both domains.
Daume III (2007) further augments the feature space
on the instances of both domains. Jiang and Zhai
(2006) exploit the domain structure contained in the
training examples to avoid over-fitting the training
domains. Arnold et al. (2008) exploit feature hier-
archy for transfer learning in NER. Instance weight-
ing (Jiang and Zhai, 2007) and active learning (Chan
and Ng, 2007) are also employed in domain adap-
tation. Most of these approaches need the labeled
target domain samples for the model estimation in
the domain transfer. Obviously, they require much
efforts for labeling the target domain samples.
Some approaches exploit the common structure of
related problems. Ando et al. (2005) learn pred-
icative structures from multiple tasks and unlabeled
data. Blitzer et al. (2006, 2007) employ structural
corresponding learning (SCL) to infer a good fea-
ture representation from unlabeled source and target
data sets in the domain transfer. We present LaSA
model to overcome the data gap across domains by
capturing latent semantic association among words
from unlabeled source and target data.
In addition, Miller et al. (2004) and Freitag
(2004) employ distributional and hierarchical clus-
tering methods to improve the performance of NER
within a single domain. Li and McCallum (2005)
present a semi-supervised sequence modeling with
syntactic topic models. In this paper, we focus on
capturing hidden semantic association among words
in the domain adaptation.
</bodyText>
<sectionHeader confidence="0.958245" genericHeader="method">
3 Domain Adaptation Based on Latent
</sectionHeader>
<subsectionHeader confidence="0.906302">
Semantic Association
</subsectionHeader>
<bodyText confidence="0.993674357142857">
The challenge in domain adaptation is how to cap-
ture latent semantic association from the source and
target domain data. We present a LaSA-based do-
main adaptation method in this section.
NER can be considered as a classification prob-
lem. Let X be a feature space to represent the ob-
served word instances, and let Y be the set of class
labels. Let ps(x, y) and pt(x, y) be the true under-
lying distributions for the source and the target do-
mains, respectively. In order to minimize the efforts
required in the domain transfer, we often expect to
use ps(x, y) to approximate pt(x, y).
However, data distribution are often varied with
the domains. For example, in the economics-to-
</bodyText>
<page confidence="0.994291">
282
</page>
<bodyText confidence="0.999976804878049">
entertainment domain transfer, although many NE
triggers (e.g. “company” and “Mr.”) are used in
both domains, some are totally new, like “dancer”,
“singer”. Moreover, many useful words (e.g.
“economist”) in the economics NER are useless in
the entertainment domain. The above examples
show that features could change behavior across do-
mains. Some useful predictive features from one do-
main are not predictive or do not appear in another
domain. Although some triggers (e.g. “singer”,
“economist”) are completely distinct for each do-
main, they often appear in the similar syntactic and
semantic context. For example, triggers of per-
son entity often appear as the subject of “visited”,
“said”, etc, or are modified by “excellent”, “popu-
lar”, “famous” etc. Such latent semantic association
among words provides useful hints for overcoming
the data distribution gap of both domains.
Hence, we present a LaSA model Bs,t to cap-
ture latent semantic association among words in the
domain adaptation. Bs,t is learned from the unla-
beled source and target domain data. Each instance
is characterized by its co-occurred context distribu-
tion in the learning. Semantic association feature
in Bs,t is a hidden random variable that is inferred
from data. In the domain adaptation, we transfer the
problem of semantic association mapping to a pos-
terior inference task using LaSA model. Latent se-
mantic concept association set of a word instance x
(denoted by 5A(x)) is generated by Bs,t. Instances
in the same concept set are considered as behaving
in the same way for discriminative learning in both
domains. Even though word instances do not ap-
pear in a training corpus (or appear rarely) but are in
similar context, they still might have relatively high
probability in the same semantic concept set. Obvi-
ously, 5A(x) can better bridge the gap between the
two distributions ps(y|x) and pt(y|x). Hence, LaSA
model can enhance the estimate of the source do-
main distribution ps(y|x; Bs,t) to better approximate
the target domain distribution pt(y|x; Bs,t).
</bodyText>
<sectionHeader confidence="0.919095" genericHeader="method">
4 Learning LaSA Model from Virtual
Context Documents
</sectionHeader>
<bodyText confidence="0.9999645">
In the domain adaptation, LaSA model is employed
to find the latent semantic association structures of
“words” in a text corpus. We will illustrate how
to build LaSA model from words and their context
snippets in this section. LaSA model actually can
be considered as a general probabilistic topic model.
It can be learned on the unlabeled corpus using the
popular hidden topic models such as LDA or pLSI.
</bodyText>
<subsectionHeader confidence="0.842673">
4.1 Virtual Context Document
</subsectionHeader>
<bodyText confidence="0.999811">
The distribution of content words (e.g. nouns, adjec-
tives) is usually varied with domains. Hence, in the
domain adaptation, we focus on capturing the latent
semantic association among content words. In or-
der to learn latent relationships among words from
the unlabeled corpus, each content word is charac-
terized by a virtual context document as follows.
Given a content word xi, the virtual context docu-
ment of xi (denoted by vdxi) consists of all the con-
text units around xi in the corpus. Let n be the total
number of the sentences which contain xi in the cor-
pus. vdxi is constructed as follows.
</bodyText>
<equation confidence="0.9946115">
vdx&amp;quot; = {F(xs1
i ), ..., F(xsk
i ), ..., F(xsn
i )}
</equation>
<bodyText confidence="0.986801714285714">
where, F(xsk
i ) denotes the context feature set of
xi in the sentence sk, 1 ≤ k ≤ n.
Given the context window size {-t, t} (i.e. pre-
vious t words and next t words around xi in sk).
F (xsk
i ) usually consists of the following features.
</bodyText>
<listItem confidence="0.991675333333333">
1. Anchor unit Ax&amp;quot;C : the current focused word unit xi.
2. Left adjacent unit Ax&amp;quot;L : The nearest left adjacent
unit xi−1 around xi, denoted by AL(xi−1).
3. Right adjacent unit Ax&amp;quot;R : The nearest right adjacent
unit xi+1 around xi, denoted by AR(xi+1).
4. Left context set Cx&amp;quot;
L : the other left adjacent units
{xi−t, ..., xi−j, ..., xi−2} (2 ≤ j ≤ t) around xi, de-
noted by {CL(xi−t), ..., CL(xi−j),..., CL(xi−2)}.
5. Right context set Cx&amp;quot;R : the other right adjacent units
{xi+2, ..., xi+j, ..., xi+t} (2 ≤ j ≤ t ) around xi, de-
noted by {CR(xi+2), ..., CR(xi+j), ..., CR(xi+t)}.
</listItem>
<bodyText confidence="0.809652444444445">
For example, given xi=“singer”, sk=“This popu-
lar new singer attended the new year party”. Let
the context window size be {-3,3}. F(singer)
= {singer, AL(new), AR(attend(ed)), CL(this),
CL(popular), CR(the), CR(new) }.
vdxi actually describes the semantic and syntac-
tic feature distribution of xi in the domains. We
construct the feature vector of xi with all the ob-
served context features in vdxi. Given vdxi =
</bodyText>
<page confidence="0.98944">
283
</page>
<bodyText confidence="0.7579092">
{f,, ..., fj, ..., fm}, fj denotes jth context feature
around xi, 1 &lt; j &lt; m, m denotes the total num-
ber of features in vdxz. The value of fj is calculated
by Mutual Information (Church and Hanks, 1990)
between xi and fj.
</bodyText>
<equation confidence="0.9632475">
Weight(fj, xi) = log2 P(h)P�)z) (1)
j
</equation>
<bodyText confidence="0.9997965">
where, P(fj, xi) is the joint probability of xi and
fj co-occurred in the corpus, P(fj) is the probabil-
ity of fj occurred in the corpus. P(xi) is the proba-
bility of xi occurred in the corpus.
</bodyText>
<subsectionHeader confidence="0.988098">
4.2 Learning LaSA Model
</subsectionHeader>
<bodyText confidence="0.999982029411765">
Topic models are statistical models of text that posit
a hidden space of topics in which the corpus is em-
bedded (Blei et al., 2003). LDA (Blei et al., 2003) is
a probabilistic model that can be used to model and
discover underlying topic structures of documents.
LDA assumes that there are K “topics”, multinomial
distributions over words, which describes a collec-
tion. Each document exhibits multiple topics, and
each word in each document is associated with one
of them. LDA imposes a Dirichlet distribution on
the topic mixture weights corresponding to the doc-
uments in the corpus. The topics derived by LDA
seem to possess semantic coherence. Those words
with similar semantics are likely to occur in the same
topic. Since the number of LDA model parameters
depends only on the number of topic mixtures and
vocabulary size, LDA is less prone to over-fitting
and is capable of estimating the probability of un-
observed test documents. LDA is already success-
fully applied to enhance document representations
in text classification (Blei et al., 2003), information
retrieval (Wei and Croft., 2006).
In the following, we illustrate how to construct
LDA-style LaSA model 03,t on the virtual con-
text documents. Algorithm 1 describes LaSA
model training method in detail, where, Function
AddTo(data, Set) denotes that data is added to
Set. Given a large-scale unlabeled data set Du
which consists of the source and target domain data,
virtual context document for each candidate content
word is extracted from Du at first, then the value of
each feature in a virtual context document is calcu-
lated using its Mutual Information ( see Equation 1
in Section 4.1) instead of the counts when running
</bodyText>
<sectionHeader confidence="0.412474" genericHeader="method">
Algorithm 1: LaSA Model Training
</sectionHeader>
<bodyText confidence="0.994771857142857">
LDA. LaSA model 03,t with Dirichlet distribution is
generated on the virtual context document set V D3,t
using the algorithm presented by Blei et al (2003).
1 2 3 4 5
customer theater company Beijing music
president showplace government Hongkong film
singer courtyard university China arts
manager center community Japan concert
economist city team Singapore party
policeman gymnasium enterprise New York Ballet
reporter airport bank Vienna dance
director square market America song
consumer park organization Korea band
dancer building agency international opera
</bodyText>
<tableCaption confidence="0.978672">
Table 1: Top 10 nouns from 5 randomly selected topics
computed on the economics and entertainment domains
</tableCaption>
<bodyText confidence="0.99904975">
LaSA model learns the posterior distribution to
decompose words and their corresponding virtual
context documents into topics. Table 1 lists top 10
nouns from a random selection of 5 topics computed
on the unlabeled economics and entertainment do-
main data. As shown, words in the same topic are
representative nouns. They actually are grouped into
broad concept sets. For example, set 1, 3 and 4
correspond to nominal person, nominal organization
and location, respectively. With a large-scale unla-
beled corpus, we will have enough words assigned
to each topic concept to better approximate the un-
derlying semantic association distribution.
In LDA-style LaSA model, the topic mixture
is drawn from a conjugate Dirichlet prior that re-
mains the same for all the virtual context docu-
</bodyText>
<figure confidence="0.992430323529411">
11
12
13
14
15
16
17
18
1 Inputs:
2 • Unlabeled data set: Du;
3 Outputs:
4 • LaSA model: Bs,t;
5 Initialization:
6 • Virtual context document set: V Ds,t = 0;
7 • Candidate content word set: Xs,t = 0;
8Steps:
9 begin
10
if Frequency(xi)&gt; the predefined threshold then
AddTo(xi, Xs,t);
foreach xk E Xs,t do
foreach sentence Si E Du do
if xk E Si then
F(xSi)
k ��
{xk, Axk
L , Axk R , Cxk
L , CxkR };
AddTo(F(xSi
k ), vdxk );
foreach content word xi E Du do
AddTo(vdxk , V Ds,t);
• Generate LaSA model Bs,t with Dirichlet distribution on V Ds,t.
19 end
</figure>
<page confidence="0.992289">
284
</page>
<bodyText confidence="0.999006071428571">
ments. Hence, given a word xi in the corpus, we
may perform posterior inference to determine the
conditional distribution of the hidden topic feature
variables associated with xi. Latent semantic asso-
ciation set of xi (denoted by SA(xi)) is generated
using Algorithm 2. Here, Multinomial(Os,t(vdxi))
refers to sample from the posterior distribution over
topics given a virtual document vdxi. In the domain
adaptation, we do semantic association inference on
the source domain training data using LaSA model
at first, then the original source domain NER model
is tuned on the source domain training data set by
incorporating these generated semantic association
features.
</bodyText>
<figure confidence="0.724889272727273">
Algorithm 2: Generate Latent Semantic As-
sociation Set of Word xi Using K-topic
LaSA Model
1 Inputs:
2 • Bs,t: LaSA model with multinomial distribution;
3 • Dirichlet(α): Dirichlet distribution with parameter α;
4 • xi: Content word;
5 Outputs:
6 • SA(xi): Latent semantic association set of xi;
7 Steps:
8 begin
</figure>
<listItem confidence="0.936932">
• Extract vdxi from the corpus.
• Draw topic weights Bs,t(vdxi ) from Dirichlet(α);
</listItem>
<bodyText confidence="0.999842727272727">
LaSA model better models latent semantic asso-
ciation distribution in the source and the target do-
mains. By grouping words into concepts, we effec-
tively overcome the data distribution difference of
both domains. Thus, we may reduce the number
of parameters required to model the target domain
data, and improve the quality of the estimated pa-
rameters in the domain transfer. LaSA model ex-
tends the traditional bag-of-words topic models to
context-dependence concept association model. It
has potential use for concept grouping.
</bodyText>
<sectionHeader confidence="0.999711" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999834833333333">
We evaluate LaSA-based domain adaptation method
on both English and Chinese corpus in this section.
In the experiments, we focus on recognizing person
(PER), location (LOC) and organization (ORG) in
the given four domains, including economics (Eco),
entertainment (Ent), politics (Pol) and sports (Spo).
</bodyText>
<subsectionHeader confidence="0.9777">
5.1 Experimental setting
</subsectionHeader>
<bodyText confidence="0.9998608">
In the NER domain adaptation, nouns and adjectives
make a significant impact on the performance. Thus,
we focus on capturing latent semantic association
for high-frequency nouns and adjectives (i.e. occur-
rence count &gt; 50 ) in the unlabeled corpus. LaSA
models for nouns and adjectives are learned from
the unlabeled corpus using Algorithm 1 (see section
4.2), respectively. Our empirical study shows that
better adaptation is obtained with a 50-topic LaSA
model. Therefore, we set the number of topics N as
50, and define the context view window size as {-
3,3} (i.e. previous 3 words and next 3 words) in the
LaSA model learning. LaSA features for other irre-
spective words (e.g. token unit “the”) are assigned
with a default topic value N+1.
All the basic NER models are trained on the
domain-specific training data using RRM classifier
(Guo et al., 2005). RRM is a generalization Winnow
learning algorithm (Zhang et al., 2002). We set the
context view window size as {-2,2} in NER. Given a
word instance x, we employ local linguistic features
(e.g. word unit, part of speech) of x and its context
units ( i.e. previous 2 words and next 2 words ) in
NER. All Chinese texts in the experiments are auto-
matically segmented into words using HMM.
In LaSA-based domain adaptation, the semantic
association features of each unit in the observation
window {-2,2} are generated by LaSA model at first,
then the basic source domain NER model is tuned on
the original source domain training data set by incor-
porating the semantic association features. For ex-
ample, given the sentence “This popular new singer
attended the new year party”, Figure 1 illustrates
various features and views at the current word wi=
“singer” in LaSA-based adaptation.
</bodyText>
<figure confidence="0.832892166666667">
—. Tagging —.
Position wi−2 wi−1 wi wi+1 wi+2
Word popular new singer attend the
POS adj adj noun verb article
SA SA(popular) SA(new) SA(singer) SA(attend) SA(the)
Tag ti−2 ti−1 ti
</figure>
<figureCaption confidence="0.5759032">
Figure 1: Feature window in LaSA-based adaptation
In the viewing window at the word “singer” (see
Figure 1), each word unit around “singer” is codi-
fied with a set of primitive features (e.g. POS, SA,
Tag), together with its relative position to “singer”.
</figureCaption>
<figure confidence="0.987763384615385">
• foreach fj in vdxi do
draw a topic zj ∈{ 1,...,K} from Multinomial(Bs,t(vdxi ));
AddTo(zj , Topics(vdxi ));
• Rank all the topics in T opics(vdxi );
• SA(xi) r− top n topics in T opics(vdxi );
9
10
11
12
13
14
15
16 end
</figure>
<page confidence="0.996385">
285
</page>
<bodyText confidence="0.964764142857143">
Here, “SA” denotes semantic association feature set
which is generated by LaSA model. “Tag” denotes
NE tags labeled in the data set.
Given the input vector constructed with the above
features, RRM method is then applied to train linear
weight vectors, one for each possible class-label. In
the decoding stage, the class with the maximum con-
fidence is then selected for each token unit.
In our evaluation, only NEs with correct bound-
aries and correct class labels are considered as the
correct recognition. We use the standard Precision
(P), Recall (R), and F-measure (F = 2P R
P +R) to mea-
sure the performance of NER models.
</bodyText>
<subsectionHeader confidence="0.984443">
5.2 Data
</subsectionHeader>
<bodyText confidence="0.9997398">
We built large-scale English and Chinese anno-
tated corpus. English corpus are generated from
wikipedia while Chinese corpus are selected from
Chinese newspapers. Moreover, test data do not
overlap with training data and unlabeled data.
</bodyText>
<sectionHeader confidence="0.732541" genericHeader="method">
5.2.1 Generate English Annotated Corpus
from Wikipedia
</sectionHeader>
<bodyText confidence="0.999899566666667">
Wikipedia provides a variety of data resources for
NER and other NLP research (Richman and Schone,
2008). We generate all the annotated English corpus
from wikipedia. With the limitation of efforts, only
PER NEs in the corpus are automatically tagged us-
ing an English person gazetteer. We automatically
extract an English Person gazetteer from wikipedia
at first. Then we select the articles from wikipedia
and tag them using this gazetteer.
In order to build the English Person gazetteer
from wikipdedia, we manually selected several key
phrases, including “births”, “deaths”, “surname”,
“given names” and “human names” at first. For
each article title of interest, we extracted the cate-
gories to which that entry was assigned. The en-
try is considered as a person name if its related
explicit category links contain any one of the key
phrases, such as “Category: human names”. We to-
tally extracted 25,219 person name candidates from
204,882 wikipedia articles. And we expanded this
gazetteer by adding the other available common
person names. Finally, we obtained a large-scale
gazetteer of 51,253 person names.
All the articles selected from wikipedia are further
tagged using the above large-scale gazetteer. Since
human annotated set were not available, we held out
more than 100,000 words of text from the automat-
ically tagged corpus to as a test set in each domain.
Table 2 shows the data distribution of the training
and test data sets.
</bodyText>
<table confidence="0.999456166666667">
Domains Training Data Set Test Data Set
Size PERs Size PERs
Pol 0.45M 9,383 0.23M 6,067
Eco 1.06M 21,023 0.34M 6,951
Spo 0.47M 17,727 0.20M 6,075
Ent 0.36M 12,821 0.15M 5,395
</table>
<tableCaption confidence="0.999623">
Table 2: English training and test data sets
</tableCaption>
<bodyText confidence="0.936832333333333">
We also randomly select 17M unlabeled English
data (see Table 3) from Wikipedia. These unlabeled
data are used to build the English LaSA model.
</bodyText>
<tableCaption confidence="0.983926">
Table 3: Domain distribution in the unlabeled English
data set
</tableCaption>
<subsectionHeader confidence="0.752455">
5.2.2 Chinese Data
</subsectionHeader>
<bodyText confidence="0.997569666666667">
We built a large-scale high-quality Chinese NE
annotated corpus. All the data are news articles from
several Chinese newspapers in 2001 and 2002. All
the NEs (i.e. PER, LOC and ORG) in the corpus are
manually tagged. Cross-validation checking is em-
ployed to ensure the quality of the annotated corpus.
</bodyText>
<table confidence="0.9997995">
Domain Size NEs in the training data set
(M)
PER ORG LOC Total
Pol 0.90 11,388 6,618 14,350 32,356
Eco 1.40 6,821 18,827 14,332 39,980
Spo 0.60 11,647 8,105 7,468 27,220
Ent 0.60 12,954 2,823 4,665 20,442
Domain Size NEs in the test data set
(M)
PER ORG LOC Total
Pol 0.20 2,470 1,528 2,540 6,538
Eco 0.26 1,098 2,971 2,362 6,431
Spo 0.10 1,802 1,323 1,246 4,371
Ent 0.10 2,458 526 738 3,722
</table>
<tableCaption confidence="0.999876">
Table 4: Chinese training and test data sets
</tableCaption>
<bodyText confidence="0.9995288">
All the domain-specific training and test data are
selected from this annotated corpus according to the
domain categories (see Table 4). 8.46M unlabeled
Chinese data (see Table 5) are randomly selected
from this corpus to build the Chinese LaSA model.
</bodyText>
<subsectionHeader confidence="0.997342">
5.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.993952666666667">
All the experiments are conducted on the above
large-scale English and Chinese corpus. The overall
performance enhancement of NER by LaSA-based
</bodyText>
<figure confidence="0.998642583333333">
Data Size(M)
All
17.06
Domain
Pol
7.36
2.59
Eco
3.65
Spo
3.46
Ent
</figure>
<page confidence="0.99675">
286
</page>
<tableCaption confidence="0.9651415">
Table 5: Domain distribution in the unlabeled Chinese
data set
</tableCaption>
<bodyText confidence="0.999791">
domain adaptation is evaluated at first. Since the
distribution of each NE type is different across do-
mains, we also analyze the performance enhance-
ment on each entity type by LaSA-based adaptation.
</bodyText>
<subsectionHeader confidence="0.675087">
5.3.1 Performance Enhancement of NER by
LaSA-based Domain Adaptation
</subsectionHeader>
<bodyText confidence="0.9593506875">
Table 6 and 7 show the experimental results for
all pairs of domain adaptation on both English and
Chinese corpus, respectively. In the experiment,
the basic source domain NER model Ms is learned
from the specific domain training data set Ddom
(see Table 2 and 4 in Section 5.2). Here, dom E
{Eco, Ent, Pol, Spo}. Fin
dom denotes the top-line
F-measure of Ms in the source trained domain dom.
When Ms is directly applied in a new target do-
main, its F-measure in this basic transfer is consid-
ered as baseline (denoted by FBase). FLaSA de-
notes F-measure of Ms achieved in the target do-
main with LaSA-based domain adaptation. 6(F) =
FLaSA−FBase which denotes the relative F-measure
FBase
</bodyText>
<table confidence="0.993716583333333">
enhancement by LaSA-based domain adaptation.
Source -. Performance in the domain transfer
Target
FBase FLaSA 6(F) 6(loss) FT op
Eco-.Ent 57.61% 59.22% +2.79% 17.87% Fin
Ent=66.62%
Pol-.Ent 57.5 % 59.83% +4.05% 25.55% Fin
Ent=66.62%
Spo-.Ent 58.66% 62.46% +6.48% 47.74% Fin Ent=66.62%
Ent-.Eco 70.56 % 72.46% +2.69% 19.33% Fin
Eco=80.39%
Pol-.Eco 63.62% 68.1% +7.04% 26.71% FinEco=80.39%
Spo-.Eco 70.35% 72.85% +3.55% 24.90% Fin
Eco=80.39%
Eco-.Pol 50.59% 52.7% +4.17% 15.81% FPinol=63.94%
Ent-.Pol 56.12% 59.82% +6.59% 47.31% Fin
P ol=63.94%
Spo-.Pol 60.22% 62.6% +3.95% 63.98% FPinol=63.94%
Eco-.Spo 60.28% 61.21% +1.54% 9.93% Fin
Spo=69.65%
Ent-.Spo 60.28% 62.68% +3.98% 25.61% Fin
Spo=69.65%
Pol-.Spo 56.94% 60.48% +6.22% 27.85% Fin
Spo=69.65%
</table>
<tableCaption confidence="0.999375">
Table 6: Experimental results on English corpus
</tableCaption>
<bodyText confidence="0.995044555555556">
Experimental results on English and Chinese cor-
pus indicate that the performance of Ms signifi-
cantly degrades in each basic domain transfer with-
out using LaSA model (see Table 6 and 7). For ex-
ample, in the “Eco→Ent” transfer on Chinese cor-
pus (see Table 7), Fin
eco of Ms is 82.28% while FBase
of Ms is 60.45% in the entertainment domain. F-
measure of Ms significantly degrades by 21.83 per-
</bodyText>
<table confidence="0.9991373">
Source -. Performance in the domain transfer
Target
FBase FLaSA 6(F) 6(loss) FT op
Eco-.Ent 60.45% 66.42% +9.88% 26.29% FinEnt=83.16%
Pol-.Ent 69.89% 73.07% +4.55% 23.96% FinEnt =83.16%
Spo-.Ent 68.66% 70.89% +3.25% 15.38% Fin
Ent =83.16%
Ent-.Eco 58.50% 61.35% +4.87% 11.98% Fin Eco=82.28%
Pol-.Eco 62.89% 64.93% +3.24% 10.52% Fin
Eco=82.28%
Spo-.Eco 60.44% 63.20% + 4.57 % 12.64% Fin
Eco=82.28%
Eco-.Pol 67.03% 70.90% +5.77% 27.78% FPinol=80.96%
Ent-.Pol 66.64% 68.94% +3.45% 16.06% FPinol=80.96%
Spo-.Pol 65.40% 67.20% +2.75% 11.57% Fin
P ol=80.96%
Eco-.Spo 67.20% 70.77% +5.31% 15.47% FinSpo=90.24%
Ent-.Spo 70.05% 72.20% +3.07% 10.64% Fin
Spo=90.24%
Pol-.Spo 70.99% 73.86% +4.04% 14.91% FinSpo=90.24%
</table>
<tableCaption confidence="0.999731">
Table 7: Experimental results on Chinese corpus
</tableCaption>
<bodyText confidence="0.979596378378378">
cent points in this basic transfer. Significant perfor-
mance degrading of Ms is observed in all the basic
transfer. It shows that the data distribution of both
domains is very different in each possible transfer.
Experimental results on English corpus show that
LaSA-based adaptation effectively enhances the per-
formance in each domain transfer (see Table 6).
For example, in the “Pol→Eco” transfer, FBase is
63.62% while FLaSA achieves 68.10%. Compared
with FBase, LaSA-based method significantly en-
hances F-measure by 7.04%. We perform t-tests on
F-measure of all the comparison experiments on En-
glish corpus. The p-value is 2.44E-06, which shows
that the improvement is statistically significant.
Table 6 also gives the accuracy loss due to transfer
in each domain adaptation on English corpus. The
accuracy loss is defined as loss = 1 _ F
F in . And
dom
the relative reduction in error is defined as S(loss)=
|1 _ lossLaSA  |Experimental results indicate that
lossBase
the relative reduction in error is above 9.93% with
LaSA-based transfer in each test on English cor-
pus. LaSA model significantly decreases the ac-
curacy loss by 29.38% in average. Especially for
“Spo→Pol” transfer, δ(loss) achieves 63.98% with
LaSA-based adaptation. All the above results show
that LaSA-based adaptation significantly reduces the
accuracy loss in the domain transfer for English
NER without any labeled target domain samples.
Experimental results on Chinese corpus also show
that LaSA-based adaptation effectively increases the
accuracy in all the tests (see Table 7). For example,
in the “Eco→Ent” transfer, compared with FBase,
LaSA-based adaptation significantly increases F-
measure by 9.88%. We also perform t-tests on F-
</bodyText>
<figure confidence="0.99857275">
Data Size(M)
Domain
Pol
2.34
All
8.46
Eco
1.99
2.08
Spo
2.05
Ent
</figure>
<page confidence="0.985653">
287
</page>
<bodyText confidence="0.999956">
measure of 12 comparison experiments on Chinese
corpus. The p-value is 1.99E-06, which shows that
the enhancement is statistically significant. More-
over, the relative reduction in error is above 10%
with LaSA-based method in each test. LaSA model
decreases the accuracy loss by 16.43% in average.
Especially for the “Eco→Ent” transfer (see Table 7),
δ(loss) achieves 26.29% with LaSA-based method.
All the above experimental results on English and
Chinese corpus show that LaSA-based domain adap-
tation significantly decreases the accuracy loss in the
transfer without any labeled target domain data. Al-
though automatically tagging introduced some er-
rors in English source training data, the relative re-
duction in errors in English NER adaptation seems
comparable to that one in Chinese NER adaptation.
</bodyText>
<subsectionHeader confidence="0.7803705">
5.3.2 Accuracy Enhancement for Each NE
Type Recognition
</subsectionHeader>
<bodyText confidence="0.999835827586207">
Our statistic data (Guo et al., 2006) show that the
distribution of NE types varies with domains. Each
NE type has different domain features. Thus, the
performance stability of each NE type recognition is
very important in the domain transfer.
Figure 2 gives F-measure of each NE type recog-
nition achieved by LaSA-based adaptation on En-
glish and Chinese corpus. Experimental results
show that LaSA-based adaptation effectively in-
creases the accuracy of each NE type recognition in
the most of the domain transfer tests. We perform
t-tests on F-measure of the comparison experiments
on each NE type, respectively. All the p-value is
less than 0.01, which shows that the improvement
on each NE type recognition is statistically signifi-
cant. Especially, the p-value of English and Chinese
PER is 2.44E-06 and 9.43E-05, respectively, which
shows that the improvement on PER recognition is
very significant. For example, in the “Eco→Pol”
transfer on Chinese corpus, compared with FBase,
LaSA-based adaptation enhances F-measure of PER
recognition by 9.53 percent points. Performance en-
hancement for ORG recognition is less than that one
for PER and LOC recognition using LaSA model
since ORG NEs usually contain much more domain-
specific information than PER and LOC.
The major reason for error reduction is that exter-
nal context and internal units are better semantically
associated using LaSA model. For example, LaSA
</bodyText>
<figureCaption confidence="0.993264">
Figure 2: PER, LOC and ORG recognition in the transfer
</figureCaption>
<bodyText confidence="0.9998755">
model better groups various titles from different do-
mains (see Table 1 in Section 4.2). Various industry
terms in ORG NEs are also grouped into the seman-
tic sets. These semantic associations provide useful
hints for detecting the boundary of NEs in the new
target domain. All the above results show that LaSA
model better compensates for the feature distribution
difference of each NE type across domains.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999996421052632">
We present a domain adaptation method with LaSA
model in this paper. LaSA model captures latent se-
mantic association among words from the unlabeled
corpus. It better groups words into a set of concepts
according to the related context snippets. LaSA-
based domain adaptation method projects words to
a low-dimension concept feature space in the trans-
fer. It effectively overcomes the data distribution gap
across domains without using any labeled target do-
main data. Experimental results on English and Chi-
nese corpus show that LaSA-based domain adapta-
tion significantly enhances the performance of NER
across domains. Especially, LaSA model effectively
increases the accuracy of each NE type recogni-
tion in the domain transfer. Moreover, LaSA-based
domain adaptation method works well across lan-
guages. To further reduce the accuracy loss, we will
explore informative sampling to capture fine-grained
data difference in the domain transfer.
</bodyText>
<sectionHeader confidence="0.99806" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.792537">
Rie Ando and Tong Zhang. 2005. A Framework for
Learning Predictive Structures from Multiple Tasks
</reference>
<page confidence="0.972777">
288
</page>
<reference confidence="0.999526416666667">
and Unlabeled Data. In Journal of Machine Learning
Research 6 (2005), pages 1817–1853.
Andrew Arnold, Ramesh Nallapati, and William W. Co-
hen. 2008. Exploiting Feature Hierarchy for Trans-
fer Learning in Named Entity Recognition. In Pro-
ceedings of 46th Annual Meeting of the Association of
Computational Linguistics (ACL’08), pages 245-253.
David Blei, Andrew Ng, and Michael Jordan. 2003. La-
tent Dirichlet Allocation. Journal of Machine Learn-
ing Research, 3:993–1022.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain Adaptation with Structural Correspon-
dence Learning. In Proceedings of the 2006 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2006), pages 120-128.
John Blitzer, Mark Dredze, and Fernando Pereira. 2007.
Biographies, Bollywood, Boom-boxes and Blenders:
Domain Adaptation for Sentiment Classification. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics (ACL’07), pages
440-447.
Andrew Borthwick. 1999. A Maximum Entropy Ap-
proach to Named Entity Recognition. Ph.D. thesis,
New York University.
Yee Seng Chan and Hwee Tou Ng. 2007. Domain Adap-
tation with Active Learning for Word Sense Disam-
biguation. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics
(ACL’07).
Ciprian Chelba and Alex Acero. 2004. Adaptation of
maximum entropy capitalizer: Little data can help a
lot. In Proceedings of the 2004 Conference on Empir-
ical Methods in Natural Language Processing.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information and lexicogra-
phy. Computational Linguistics, 16(1):22–29.
Hal Daume III. 2007. Frustratingly Easy Domain Adap-
tation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics.
Hal Daume III and Daniel Marcu. 2006. Domain adap-
tation for statistical classifiers. Journal of Artificial
Intelligence Research, 26:101–126.
Scott Deerwester, Susan T. Dumais, and Richard Harsh-
man. 1990. Indexing by latent semantic analysis.
Journal of the American Society for Information Sci-
ence, 41(6):391–407.
Radu Florian, Abe Ittycheriah, Hongyan Jing, and Tong
Zhang. 2003. Named entity recogintion through clas-
sifier combination. In Proceedings of the 2003 Confer-
ence on Computational Natural Language Learning.
Freitag. 2004. Trained Named Entity Recognition Using
Distributional Clusters. In Proceedings of the 2004
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2004).
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name Tagging with Word Clusters and Discrim-
inative Training. In Proceedings ofHLT-NAACL 04.
Jianfeng Gao, Mu Li, Anndy Wu, and Changning Huang.
2005. Chinese Word Segmentation and Named Entity
Recognition: A Pragmatic Approach. Computational
Linguisitc, 31(4):531–574.
Honglei Guo, Jianmin Jiang, Gang Hu, and Tong Zhang.
2005. Chinese Named Entity Recognition Based on
Multilevel Linguistic Features. In Lecture Notes in Ar-
tificial Intelligence, 3248:90–99.
Honglei Guo, Li Zhang, and Zhong Su. 2006. Empirical
Study on the Performance Stability of Named Entity
Recognition Model across Domains. In Proceedings
of the 2006 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2006), pages 509-
516.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22th Annual Inter-
national SIGIR Conference on Research and Develop-
ment in Information Retrieval (SIGIR’99).
Jing Jiang and ChengXiang Zhai. 2006. Exploiting Do-
main Structure for Named Entity Recognition. In Pro-
ceedings ofHLT-NAACL 2006, pages 74–81.
Jing Jiang and ChengXiang Zhai. 2007. Instance
Weighting for Domain Adaptation in NLP. In Pro-
ceedings of the 45th Annual Meeting of the Associ-
ation of Computational Linguistics (ACL’07), pages
264–271.
Wei Li and Andrew McCallum. 2005. Semi-supervised
sequence modeling with syntactic topic models. In
Proceedings of Twenty AAAI Conference on Artificial
Intelligence (AAAI-05).
Alexander E. Richman and Patrick Schone. 2008. Min-
ing Wiki Resources for Multilingual Named Entity
Recognition. In Proceedings of the 46th Annual Meet-
ing of the Association of Computational Linguistics.
Brian Roark and Michiel Bacchiani. 2003. Supervised
and unsupervised PCFG adaptation to novel domains.
In Proceedings of the 2003 Human Language Technol-
ogy Conference of the North American Chapter of the
Association for Computational Linguistics.
Erik F. Tjong Kim Sang and Fien De Meulder. 2003.
Introduction to the conll-2003 shared task: Language
independent named entity recognition. In Proceed-
ings of the 2003 Conference on Computational Natural
Language Learning (CoNLL-2003), pages 142–147.
Xing Wei and Bruce Croft. 2006. LDA-based document
models for ad-hoc retrieval. In Proceedings of the 29th
Annual International SIGIR Conference on Research
and Development in Information Retrieval.
Tong Zhang, Fred Damerau, and David Johnson. 2002
Text chunking based on a generalization of Winnow.
Journal ofMachine Learning Research, 2:615–637.
</reference>
<page confidence="0.998641">
289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.670095">
<title confidence="0.9997975">Domain Adaptation with Latent Semantic for Named Entity Recognition</title>
<author confidence="0.990246">Honglei Guo Huijia Zhu Zhili Guo Xiaoxun Zhang Xian Wu</author>
<author confidence="0.990246">Zhong</author>
<affiliation confidence="0.99882">IBM China Research</affiliation>
<address confidence="0.715337">Beijing, P. R.</address>
<email confidence="0.942584">zhuhuiji,guozhili,zhangxx,wuxian,</email>
<abstract confidence="0.999165645161291">Domain adaptation is an important problem in named entity recognition (NER). NER classifiers usually lose accuracy in the domain transfer due to the different data distribution between the source and the target domains. The major reason for performance degrading is that each entity type often has lots of domainspecific term representations in the different domains. The existing approaches usually need an amount of labeled target domain data for tuning the original model. However, it is a labor-intensive and time-consuming task to build annotated training data set for every target domain. We present a domain adaptation method with latent semantic association (LaSA). This method effectively overcomes the data distribution difference without leveraging any labeled target domain data. LaSA model is constructed to capture latent semantic association among words from the unlabeled corpus. It groups words into a set of concepts according to the related context snippets. In the domain transfer, the original term spaces of both domains are projected to a concept space using LaSA model at first, then the original NER model is tuned based on the semantic association features. Experimental results on English and Chinese corpus show that LaSA-based domain adaptation significantly enhances the performance of NER.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rie Ando</author>
<author>Tong Zhang</author>
</authors>
<title>A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data.</title>
<date>2005</date>
<journal>In Journal of Machine Learning Research</journal>
<volume>6</volume>
<pages>1817--1853</pages>
<marker>Ando, Zhang, 2005</marker>
<rawString>Rie Ando and Tong Zhang. 2005. A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data. In Journal of Machine Learning Research 6 (2005), pages 1817–1853.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Arnold</author>
<author>Ramesh Nallapati</author>
<author>William W Cohen</author>
</authors>
<title>Exploiting Feature Hierarchy for Transfer Learning in Named Entity Recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of 46th Annual Meeting of the Association of Computational Linguistics (ACL’08),</booktitle>
<pages>245--253</pages>
<contexts>
<context position="6068" citStr="Arnold et al. (2008)" startWordPosition="947" endWordPosition="950"> training data from the source and target domains. Chelba and Acero (2004) use the parameters of the source domain maximum entropy classifier as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NER. Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. Most of these approaches need the labeled target domain samples for the model estimation in the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to</context>
</contexts>
<marker>Arnold, Nallapati, Cohen, 2008</marker>
<rawString>Andrew Arnold, Ramesh Nallapati, and William W. Cohen. 2008. Exploiting Feature Hierarchy for Transfer Learning in Named Entity Recognition. In Proceedings of 46th Annual Meeting of the Association of Computational Linguistics (ACL’08), pages 245-253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="3115" citStr="Blei et al., 2003" startWordPosition="477" endWordPosition="480">example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher”, ...} are used as context clues for NER. However, the distribution of these representations are varied with domains. We expect to do better domain adaptation for NER by exploiting latent semantic association among words from different domains. Some approaches have been proposed to group words into “topics” to capture important relationships between words, such as Latent Semantic Indexing (LSI) (Deerwester et al., 1990), probabilistic Latent Semantic Indexing (pLSI) (Hofmann, 1999), Latent Dirichlet Allocation (LDA) (Blei et al., 2003). These models have been successfully employed in topic modeling, dimensionality reduction for text categorization (Blei et al., 2003), ad hoc IR (Wei and Croft., 2006), and so on. In this paper, we present a domain adaptation method with latent semantic association. We focus 281 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 281–289, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics on capturing the hidden semantic association among words in the domain adaptation. We introduce the LaSA model to overcome the </context>
<context position="13044" citStr="Blei et al., 2003" startWordPosition="2128" endWordPosition="2131"> vdxi = 283 {f,, ..., fj, ..., fm}, fj denotes jth context feature around xi, 1 &lt; j &lt; m, m denotes the total number of features in vdxz. The value of fj is calculated by Mutual Information (Church and Hanks, 1990) between xi and fj. Weight(fj, xi) = log2 P(h)P�)z) (1) j where, P(fj, xi) is the joint probability of xi and fj co-occurred in the corpus, P(fj) is the probability of fj occurred in the corpus. P(xi) is the probability of xi occurred in the corpus. 4.2 Learning LaSA Model Topic models are statistical models of text that posit a hidden space of topics in which the corpus is embedded (Blei et al., 2003). LDA (Blei et al., 2003) is a probabilistic model that can be used to model and discover underlying topic structures of documents. LDA assumes that there are K “topics”, multinomial distributions over words, which describes a collection. Each document exhibits multiple topics, and each word in each document is associated with one of them. LDA imposes a Dirichlet distribution on the topic mixture weights corresponding to the documents in the corpus. The topics derived by LDA seem to possess semantic coherence. Those words with similar semantics are likely to occur in the same topic. Since the </context>
<context position="14792" citStr="Blei et al (2003)" startWordPosition="2413" endWordPosition="2416">tail, where, Function AddTo(data, Set) denotes that data is added to Set. Given a large-scale unlabeled data set Du which consists of the source and target domain data, virtual context document for each candidate content word is extracted from Du at first, then the value of each feature in a virtual context document is calculated using its Mutual Information ( see Equation 1 in Section 4.1) instead of the counts when running Algorithm 1: LaSA Model Training LDA. LaSA model 03,t with Dirichlet distribution is generated on the virtual context document set V D3,t using the algorithm presented by Blei et al (2003). 1 2 3 4 5 customer theater company Beijing music president showplace government Hongkong film singer courtyard university China arts manager center community Japan concert economist city team Singapore party policeman gymnasium enterprise New York Ballet reporter airport bank Vienna dance director square market America song consumer park organization Korea band dancer building agency international opera Table 1: Top 10 nouns from 5 randomly selected topics computed on the economics and entertainment domains LaSA model learns the posterior distribution to decompose words and their correspondi</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Michael Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain Adaptation with Structural Correspondence Learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>120--128</pages>
<contexts>
<context position="6611" citStr="Blitzer et al. (2006" startWordPosition="1033" endWordPosition="1036">ing examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NER. Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. Most of these approaches need the labeled target domain samples for the model estimation in the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain transfer. We present LaSA model to overcome the data gap across domains by capturing latent semantic association among words from unlabeled source and target data. In addition, Miller et al. (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. Li and McCallum (2005) present a semi-supervised sequence modeling with syntactic topic models. In this paper, we fo</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain Adaptation with Structural Correspondence Learning. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 120-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07),</booktitle>
<pages>440--447</pages>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07), pages 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Borthwick</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>New York University.</institution>
<contexts>
<context position="1931" citStr="Borthwick, 1999" startWordPosition="295" endWordPosition="296">are projected to a concept space using LaSA model at first, then the original NER model is tuned based on the semantic association features. Experimental results on English and Chinese corpus show that LaSA-based domain adaptation significantly enhances the performance of NER. 1 Introduction Named entities (NE) are phrases that contain names of persons, organizations, locations, etc. NER is an important task in information extraction and natural language processing (NLP) applications. Supervised learning methods can effectively solve NER problem by learning a model from manually labeled data (Borthwick, 1999; Sang and Meulder, 2003; Gao et al., 2005; Florian et al., 2003). However, empirical study shows that NE types have different distribution across domains (Guo et al., 2006). Trained NER classifiers in the source domain usually lose accuracy in a new target domain when the data distribution is different between both domains. Domain adaptation is a challenge for NER and other NLP applications. In the domain transfer, the reason for accuracy loss is that each NE type often has various specific term representations and context clues in the different domains. For example, {“economist”, “singer”, “</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>Andrew Borthwick. 1999. A Maximum Entropy Approach to Named Entity Recognition. Ph.D. thesis, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Domain Adaptation with Active Learning for Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07).</booktitle>
<contexts>
<context position="6206" citStr="Chan and Ng, 2007" startWordPosition="970" endWordPosition="973">r as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NER. Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. Most of these approaches need the labeled target domain samples for the model estimation in the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain transfer. We present LaSA model to overcome </context>
</contexts>
<marker>Chan, Ng, 2007</marker>
<rawString>Yee Seng Chan and Hwee Tou Ng. 2007. Domain Adaptation with Active Learning for Word Sense Disambiguation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
<author>Alex Acero</author>
</authors>
<title>Adaptation of maximum entropy capitalizer: Little data can help a lot.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5522" citStr="Chelba and Acero (2004)" startWordPosition="855" endWordPosition="858"> a domain adaptation method based on latent semantic association. Section 4 illustrates how to learn LaSA model from the unlabeled corpus. Section 5 shows experimental results on large-scale English and Chinese corpus across domains, respectively. The conclusion is given in Section 6. 2 Related Works Some domain adaptation techniques have been employed in NLP in recent years. Some of them focus on quantifying the generalizability of certain features across domains. Roark and Bacchiani (2003) use maximum a posteriori (MAP) estimation to combine training data from the source and target domains. Chelba and Acero (2004) use the parameters of the source domain maximum entropy classifier as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NE</context>
</contexts>
<marker>Chelba, Acero, 2004</marker>
<rawString>Ciprian Chelba and Alex Acero. 2004. Adaptation of maximum entropy capitalizer: Little data can help a lot. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="12639" citStr="Church and Hanks, 1990" startWordPosition="2051" endWordPosition="2054">i+t)}. For example, given xi=“singer”, sk=“This popular new singer attended the new year party”. Let the context window size be {-3,3}. F(singer) = {singer, AL(new), AR(attend(ed)), CL(this), CL(popular), CR(the), CR(new) }. vdxi actually describes the semantic and syntactic feature distribution of xi in the domains. We construct the feature vector of xi with all the observed context features in vdxi. Given vdxi = 283 {f,, ..., fj, ..., fm}, fj denotes jth context feature around xi, 1 &lt; j &lt; m, m denotes the total number of features in vdxz. The value of fj is calculated by Mutual Information (Church and Hanks, 1990) between xi and fj. Weight(fj, xi) = log2 P(h)P�)z) (1) j where, P(fj, xi) is the joint probability of xi and fj co-occurred in the corpus, P(fj) is the probability of fj occurred in the corpus. P(xi) is the probability of xi occurred in the corpus. 4.2 Learning LaSA Model Topic models are statistical models of text that posit a hidden space of topics in which the corpus is embedded (Blei et al., 2003). LDA (Blei et al., 2003) is a probabilistic model that can be used to model and discover underlying topic structures of documents. LDA assumes that there are K “topics”, multinomial distribution</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Frustratingly Easy Domain Adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<marker>Daume, 2007</marker>
<rawString>Hal Daume III. 2007. Frustratingly Easy Domain Adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
<author>Daniel Marcu</author>
</authors>
<title>Domain adaptation for statistical classifiers.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>26--101</pages>
<marker>Daume, Marcu, 2006</marker>
<rawString>Hal Daume III and Daniel Marcu. 2006. Domain adaptation for statistical classifiers. Journal of Artificial Intelligence Research, 26:101–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan T Dumais</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="2997" citStr="Deerwester et al., 1990" startWordPosition="461" endWordPosition="464">y loss is that each NE type often has various specific term representations and context clues in the different domains. For example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher”, ...} are used as context clues for NER. However, the distribution of these representations are varied with domains. We expect to do better domain adaptation for NER by exploiting latent semantic association among words from different domains. Some approaches have been proposed to group words into “topics” to capture important relationships between words, such as Latent Semantic Indexing (LSI) (Deerwester et al., 1990), probabilistic Latent Semantic Indexing (pLSI) (Hofmann, 1999), Latent Dirichlet Allocation (LDA) (Blei et al., 2003). These models have been successfully employed in topic modeling, dimensionality reduction for text categorization (Blei et al., 2003), ad hoc IR (Wei and Croft., 2006), and so on. In this paper, we present a domain adaptation method with latent semantic association. We focus 281 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 281–289, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics on captur</context>
</contexts>
<marker>Deerwester, Dumais, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan T. Dumais, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Tong Zhang</author>
</authors>
<title>Named entity recogintion through classifier combination.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="1996" citStr="Florian et al., 2003" startWordPosition="305" endWordPosition="308"> then the original NER model is tuned based on the semantic association features. Experimental results on English and Chinese corpus show that LaSA-based domain adaptation significantly enhances the performance of NER. 1 Introduction Named entities (NE) are phrases that contain names of persons, organizations, locations, etc. NER is an important task in information extraction and natural language processing (NLP) applications. Supervised learning methods can effectively solve NER problem by learning a model from manually labeled data (Borthwick, 1999; Sang and Meulder, 2003; Gao et al., 2005; Florian et al., 2003). However, empirical study shows that NE types have different distribution across domains (Guo et al., 2006). Trained NER classifiers in the source domain usually lose accuracy in a new target domain when the data distribution is different between both domains. Domain adaptation is a challenge for NER and other NLP applications. In the domain transfer, the reason for accuracy loss is that each NE type often has various specific term representations and context clues in the different domains. For example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher”, ...} are used as con</context>
</contexts>
<marker>Florian, Ittycheriah, Jing, Zhang, 2003</marker>
<rawString>Radu Florian, Abe Ittycheriah, Hongyan Jing, and Tong Zhang. 2003. Named entity recogintion through classifier combination. In Proceedings of the 2003 Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freitag</author>
</authors>
<title>Trained Named Entity Recognition Using Distributional Clusters.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="6978" citStr="Freitag (2004)" startWordPosition="1092" endWordPosition="1093">ously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain transfer. We present LaSA model to overcome the data gap across domains by capturing latent semantic association among words from unlabeled source and target data. In addition, Miller et al. (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. Li and McCallum (2005) present a semi-supervised sequence modeling with syntactic topic models. In this paper, we focus on capturing hidden semantic association among words in the domain adaptation. 3 Domain Adaptation Based on Latent Semantic Association The challenge in domain adaptation is how to capture latent semantic association from the source and target domain data. We present a LaSA-based domain adaptation method in this section. NER can be considered as a classificatio</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Freitag. 2004. Trained Named Entity Recognition Using Distributional Clusters. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name Tagging with Word Clusters and Discriminative Training.</title>
<date>2004</date>
<booktitle>In Proceedings ofHLT-NAACL 04.</booktitle>
<contexts>
<context position="6959" citStr="Miller et al. (2004)" startWordPosition="1087" endWordPosition="1090">the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain transfer. We present LaSA model to overcome the data gap across domains by capturing latent semantic association among words from unlabeled source and target data. In addition, Miller et al. (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. Li and McCallum (2005) present a semi-supervised sequence modeling with syntactic topic models. In this paper, we focus on capturing hidden semantic association among words in the domain adaptation. 3 Domain Adaptation Based on Latent Semantic Association The challenge in domain adaptation is how to capture latent semantic association from the source and target domain data. We present a LaSA-based domain adaptation method in this section. NER can be considered</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name Tagging with Word Clusters and Discriminative Training. In Proceedings ofHLT-NAACL 04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Mu Li</author>
<author>Anndy Wu</author>
<author>Changning Huang</author>
</authors>
<title>Chinese Word Segmentation and Named Entity Recognition: A Pragmatic Approach.</title>
<date>2005</date>
<journal>Computational Linguisitc,</journal>
<volume>31</volume>
<issue>4</issue>
<contexts>
<context position="1973" citStr="Gao et al., 2005" startWordPosition="301" endWordPosition="304">SA model at first, then the original NER model is tuned based on the semantic association features. Experimental results on English and Chinese corpus show that LaSA-based domain adaptation significantly enhances the performance of NER. 1 Introduction Named entities (NE) are phrases that contain names of persons, organizations, locations, etc. NER is an important task in information extraction and natural language processing (NLP) applications. Supervised learning methods can effectively solve NER problem by learning a model from manually labeled data (Borthwick, 1999; Sang and Meulder, 2003; Gao et al., 2005; Florian et al., 2003). However, empirical study shows that NE types have different distribution across domains (Guo et al., 2006). Trained NER classifiers in the source domain usually lose accuracy in a new target domain when the data distribution is different between both domains. Domain adaptation is a challenge for NER and other NLP applications. In the domain transfer, the reason for accuracy loss is that each NE type often has various specific term representations and context clues in the different domains. For example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher</context>
</contexts>
<marker>Gao, Li, Wu, Huang, 2005</marker>
<rawString>Jianfeng Gao, Mu Li, Anndy Wu, and Changning Huang. 2005. Chinese Word Segmentation and Named Entity Recognition: A Pragmatic Approach. Computational Linguisitc, 31(4):531–574.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglei Guo</author>
<author>Jianmin Jiang</author>
<author>Gang Hu</author>
<author>Tong Zhang</author>
</authors>
<title>Chinese Named Entity Recognition Based on Multilevel Linguistic Features.</title>
<date>2005</date>
<booktitle>In Lecture Notes in Artificial Intelligence,</booktitle>
<pages>3248--90</pages>
<contexts>
<context position="19435" citStr="Guo et al., 2005" startWordPosition="3170" endWordPosition="3173"> corpus. LaSA models for nouns and adjectives are learned from the unlabeled corpus using Algorithm 1 (see section 4.2), respectively. Our empirical study shows that better adaptation is obtained with a 50-topic LaSA model. Therefore, we set the number of topics N as 50, and define the context view window size as {- 3,3} (i.e. previous 3 words and next 3 words) in the LaSA model learning. LaSA features for other irrespective words (e.g. token unit “the”) are assigned with a default topic value N+1. All the basic NER models are trained on the domain-specific training data using RRM classifier (Guo et al., 2005). RRM is a generalization Winnow learning algorithm (Zhang et al., 2002). We set the context view window size as {-2,2} in NER. Given a word instance x, we employ local linguistic features (e.g. word unit, part of speech) of x and its context units ( i.e. previous 2 words and next 2 words ) in NER. All Chinese texts in the experiments are automatically segmented into words using HMM. In LaSA-based domain adaptation, the semantic association features of each unit in the observation window {-2,2} are generated by LaSA model at first, then the basic source domain NER model is tuned on the origina</context>
</contexts>
<marker>Guo, Jiang, Hu, Zhang, 2005</marker>
<rawString>Honglei Guo, Jianmin Jiang, Gang Hu, and Tong Zhang. 2005. Chinese Named Entity Recognition Based on Multilevel Linguistic Features. In Lecture Notes in Artificial Intelligence, 3248:90–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglei Guo</author>
<author>Li Zhang</author>
<author>Zhong Su</author>
</authors>
<title>Empirical Study on the Performance Stability of Named Entity Recognition Model across Domains.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>509--516</pages>
<contexts>
<context position="2104" citStr="Guo et al., 2006" startWordPosition="323" endWordPosition="326">h and Chinese corpus show that LaSA-based domain adaptation significantly enhances the performance of NER. 1 Introduction Named entities (NE) are phrases that contain names of persons, organizations, locations, etc. NER is an important task in information extraction and natural language processing (NLP) applications. Supervised learning methods can effectively solve NER problem by learning a model from manually labeled data (Borthwick, 1999; Sang and Meulder, 2003; Gao et al., 2005; Florian et al., 2003). However, empirical study shows that NE types have different distribution across domains (Guo et al., 2006). Trained NER classifiers in the source domain usually lose accuracy in a new target domain when the data distribution is different between both domains. Domain adaptation is a challenge for NER and other NLP applications. In the domain transfer, the reason for accuracy loss is that each NE type often has various specific term representations and context clues in the different domains. For example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher”, ...} are used as context clues for NER. However, the distribution of these representations are varied with domains. We expect to</context>
<context position="30650" citStr="Guo et al., 2006" startWordPosition="4983" endWordPosition="4986">16.43% in average. Especially for the “Eco→Ent” transfer (see Table 7), δ(loss) achieves 26.29% with LaSA-based method. All the above experimental results on English and Chinese corpus show that LaSA-based domain adaptation significantly decreases the accuracy loss in the transfer without any labeled target domain data. Although automatically tagging introduced some errors in English source training data, the relative reduction in errors in English NER adaptation seems comparable to that one in Chinese NER adaptation. 5.3.2 Accuracy Enhancement for Each NE Type Recognition Our statistic data (Guo et al., 2006) show that the distribution of NE types varies with domains. Each NE type has different domain features. Thus, the performance stability of each NE type recognition is very important in the domain transfer. Figure 2 gives F-measure of each NE type recognition achieved by LaSA-based adaptation on English and Chinese corpus. Experimental results show that LaSA-based adaptation effectively increases the accuracy of each NE type recognition in the most of the domain transfer tests. We perform t-tests on F-measure of the comparison experiments on each NE type, respectively. All the p-value is less </context>
</contexts>
<marker>Guo, Zhang, Su, 2006</marker>
<rawString>Honglei Guo, Li Zhang, and Zhong Su. 2006. Empirical Study on the Performance Stability of Named Entity Recognition Model across Domains. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 509-516.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22th Annual International SIGIR Conference on Research and Development in Information Retrieval (SIGIR’99).</booktitle>
<contexts>
<context position="3060" citStr="Hofmann, 1999" startWordPosition="470" endWordPosition="472">ns and context clues in the different domains. For example, {“economist”, “singer”, “dancer”, “athlete”, “player”, “philosopher”, ...} are used as context clues for NER. However, the distribution of these representations are varied with domains. We expect to do better domain adaptation for NER by exploiting latent semantic association among words from different domains. Some approaches have been proposed to group words into “topics” to capture important relationships between words, such as Latent Semantic Indexing (LSI) (Deerwester et al., 1990), probabilistic Latent Semantic Indexing (pLSI) (Hofmann, 1999), Latent Dirichlet Allocation (LDA) (Blei et al., 2003). These models have been successfully employed in topic modeling, dimensionality reduction for text categorization (Blei et al., 2003), ad hoc IR (Wei and Croft., 2006), and so on. In this paper, we present a domain adaptation method with latent semantic association. We focus 281 Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 281–289, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics on capturing the hidden semantic association among words in the domain a</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the 22th Annual International SIGIR Conference on Research and Development in Information Retrieval (SIGIR’99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Exploiting Domain Structure for Named Entity Recognition.</title>
<date>2006</date>
<booktitle>In Proceedings ofHLT-NAACL</booktitle>
<pages>74--81</pages>
<contexts>
<context position="5939" citStr="Jiang and Zhai (2006)" startWordPosition="928" endWordPosition="931">neralizability of certain features across domains. Roark and Bacchiani (2003) use maximum a posteriori (MAP) estimation to combine training data from the source and target domains. Chelba and Acero (2004) use the parameters of the source domain maximum entropy classifier as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NER. Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. Most of these approaches need the labeled target domain samples for the model estimation in the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative</context>
</contexts>
<marker>Jiang, Zhai, 2006</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2006. Exploiting Domain Structure for Named Entity Recognition. In Proceedings ofHLT-NAACL 2006, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Instance Weighting for Domain Adaptation in NLP.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07),</booktitle>
<pages>264--271</pages>
<contexts>
<context position="6166" citStr="Jiang and Zhai, 2007" startWordPosition="963" endWordPosition="966">the source domain maximum entropy classifier as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training examples to avoid over-fitting the training domains. Arnold et al. (2008) exploit feature hierarchy for transfer learning in NER. Instance weighting (Jiang and Zhai, 2007) and active learning (Chan and Ng, 2007) are also employed in domain adaptation. Most of these approaches need the labeled target domain samples for the model estimation in the domain transfer. Obviously, they require much efforts for labeling the target domain samples. Some approaches exploit the common structure of related problems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain tran</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007. Instance Weighting for Domain Adaptation in NLP. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07), pages 264–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Li</author>
<author>Andrew McCallum</author>
</authors>
<title>Semi-supervised sequence modeling with syntactic topic models.</title>
<date>2005</date>
<booktitle>In Proceedings of Twenty AAAI Conference on Artificial Intelligence (AAAI-05).</booktitle>
<contexts>
<context position="7117" citStr="Li and McCallum (2005)" startWordPosition="1111" endWordPosition="1114">oblems. Ando et al. (2005) learn predicative structures from multiple tasks and unlabeled data. Blitzer et al. (2006, 2007) employ structural corresponding learning (SCL) to infer a good feature representation from unlabeled source and target data sets in the domain transfer. We present LaSA model to overcome the data gap across domains by capturing latent semantic association among words from unlabeled source and target data. In addition, Miller et al. (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain. Li and McCallum (2005) present a semi-supervised sequence modeling with syntactic topic models. In this paper, we focus on capturing hidden semantic association among words in the domain adaptation. 3 Domain Adaptation Based on Latent Semantic Association The challenge in domain adaptation is how to capture latent semantic association from the source and target domain data. We present a LaSA-based domain adaptation method in this section. NER can be considered as a classification problem. Let X be a feature space to represent the observed word instances, and let Y be the set of class labels. Let ps(x, y) and pt(x, </context>
</contexts>
<marker>Li, McCallum, 2005</marker>
<rawString>Wei Li and Andrew McCallum. 2005. Semi-supervised sequence modeling with syntactic topic models. In Proceedings of Twenty AAAI Conference on Artificial Intelligence (AAAI-05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander E Richman</author>
<author>Patrick Schone</author>
</authors>
<title>Mining Wiki Resources for Multilingual Named Entity Recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="22006" citStr="Richman and Schone, 2008" startWordPosition="3608" endWordPosition="3611"> only NEs with correct boundaries and correct class labels are considered as the correct recognition. We use the standard Precision (P), Recall (R), and F-measure (F = 2P R P +R) to measure the performance of NER models. 5.2 Data We built large-scale English and Chinese annotated corpus. English corpus are generated from wikipedia while Chinese corpus are selected from Chinese newspapers. Moreover, test data do not overlap with training data and unlabeled data. 5.2.1 Generate English Annotated Corpus from Wikipedia Wikipedia provides a variety of data resources for NER and other NLP research (Richman and Schone, 2008). We generate all the annotated English corpus from wikipedia. With the limitation of efforts, only PER NEs in the corpus are automatically tagged using an English person gazetteer. We automatically extract an English Person gazetteer from wikipedia at first. Then we select the articles from wikipedia and tag them using this gazetteer. In order to build the English Person gazetteer from wikipdedia, we manually selected several key phrases, including “births”, “deaths”, “surname”, “given names” and “human names” at first. For each article title of interest, we extracted the categories to which </context>
</contexts>
<marker>Richman, Schone, 2008</marker>
<rawString>Alexander E. Richman and Patrick Schone. 2008. Mining Wiki Resources for Multilingual Named Entity Recognition. In Proceedings of the 46th Annual Meeting of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Michiel Bacchiani</author>
</authors>
<title>Supervised and unsupervised PCFG adaptation to novel domains.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5395" citStr="Roark and Bacchiani (2003)" startWordPosition="835" endWordPosition="838"> across domains. The rest of this paper is organized as follows. Section 2 briefly describes the related works. Section 3 presents a domain adaptation method based on latent semantic association. Section 4 illustrates how to learn LaSA model from the unlabeled corpus. Section 5 shows experimental results on large-scale English and Chinese corpus across domains, respectively. The conclusion is given in Section 6. 2 Related Works Some domain adaptation techniques have been employed in NLP in recent years. Some of them focus on quantifying the generalizability of certain features across domains. Roark and Bacchiani (2003) use maximum a posteriori (MAP) estimation to combine training data from the source and target domains. Chelba and Acero (2004) use the parameters of the source domain maximum entropy classifier as the means of a Gaussian prior when training a new model on the target data. Daume III and Marcu (2006) use an empirical Bayes model to estimate a latent variable model grouping instances into domain-specific or common across both domains. Daume III (2007) further augments the feature space on the instances of both domains. Jiang and Zhai (2006) exploit the domain structure contained in the training </context>
</contexts>
<marker>Roark, Bacchiani, 2003</marker>
<rawString>Brian Roark and Michiel Bacchiani. 2003. Supervised and unsupervised PCFG adaptation to novel domains. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Erik</author>
</authors>
<title>Tjong Kim Sang and Fien De Meulder.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Computational Natural Language Learning (CoNLL-2003),</booktitle>
<pages>142--147</pages>
<marker>Erik, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the conll-2003 shared task: Language independent named entity recognition. In Proceedings of the 2003 Conference on Computational Natural Language Learning (CoNLL-2003), pages 142–147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Wei</author>
<author>Bruce Croft</author>
</authors>
<title>LDA-based document models for ad-hoc retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th Annual International SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<marker>Wei, Croft, 2006</marker>
<rawString>Xing Wei and Bruce Croft. 2006. LDA-based document models for ad-hoc retrieval. In Proceedings of the 29th Annual International SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Zhang</author>
<author>Fred Damerau</author>
<author>David Johnson</author>
</authors>
<title>Text chunking based on a generalization of Winnow.</title>
<date>2002</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>2--615</pages>
<contexts>
<context position="19507" citStr="Zhang et al., 2002" startWordPosition="3181" endWordPosition="3184">abeled corpus using Algorithm 1 (see section 4.2), respectively. Our empirical study shows that better adaptation is obtained with a 50-topic LaSA model. Therefore, we set the number of topics N as 50, and define the context view window size as {- 3,3} (i.e. previous 3 words and next 3 words) in the LaSA model learning. LaSA features for other irrespective words (e.g. token unit “the”) are assigned with a default topic value N+1. All the basic NER models are trained on the domain-specific training data using RRM classifier (Guo et al., 2005). RRM is a generalization Winnow learning algorithm (Zhang et al., 2002). We set the context view window size as {-2,2} in NER. Given a word instance x, we employ local linguistic features (e.g. word unit, part of speech) of x and its context units ( i.e. previous 2 words and next 2 words ) in NER. All Chinese texts in the experiments are automatically segmented into words using HMM. In LaSA-based domain adaptation, the semantic association features of each unit in the observation window {-2,2} are generated by LaSA model at first, then the basic source domain NER model is tuned on the original source domain training data set by incorporating the semantic associat</context>
</contexts>
<marker>Zhang, Damerau, Johnson, 2002</marker>
<rawString>Tong Zhang, Fred Damerau, and David Johnson. 2002 Text chunking based on a generalization of Winnow. Journal ofMachine Learning Research, 2:615–637.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>