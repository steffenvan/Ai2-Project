<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001508">
<title confidence="0.988962">
Structural Topic Model for Latent Topical Structure Analysis
</title>
<author confidence="0.998879">
Hongning Wang, Duo Zhang, ChengXiang Zhai
</author>
<affiliation confidence="0.894728">
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana IL, 61801 USA
</affiliation>
<email confidence="0.997176">
{wang296, dzhang22, czhai}@cs.uiuc.edu
</email>
<sectionHeader confidence="0.993768" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9973232">
Topic models have been successfully applied
to many document analysis tasks to discover
topics embedded in text. However, existing
topic models generally cannot capture the la-
tent topical structures in documents. Since
languages are intrinsically cohesive and coher-
ent, modeling and discovering latent topical
transition structures within documents would
be beneficial for many text analysis tasks.
In this work, we propose a new topic model,
Structural Topic Model, which simultaneously
discovers topics and reveals the latent topi-
cal structures in text through explicitly model-
ing topical transitions with a latent first-order
Markov chain. Experiment results show that
the proposed Structural Topic Model can ef-
fectively discover topical structures in text,
and the identified structures significantly im-
prove the performance of tasks such as sen-
tence annotation and sentence ordering.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940081632653">
A great amount of effort has recently been made in
applying statistical topic models (Hofmann, 1999;
Blei et al., 2003) to explore word co-occurrence pat-
terns, i.e. topics, embedded in documents. Topic
models have become important building blocks of
many interesting applications (see e.g., (Blei and
Jordan, 2003; Blei and Lafferty, 2007; Mei et al.,
2007; Lu and Zhai, 2008)).
In general, topic models can discover word clus-
tering patterns in documents and project each doc-
ument to a latent topic space formed by such word
clusters. However, the topical structure in a docu-
ment, i.e., the internal dependency between the top-
ics, is generally not captured due to the exchange-
ability assumption (Blei et al., 2003), i.e., the doc-
ument generation probabilities are invariant to con-
tent permutation. In reality, natural language text
rarely consists of isolated, unrelated sentences, but
rather collocated, structured and coherent groups of
sentences (Hovy, 1993). Ignoring such latent topi-
cal structures inside the documents means wasting
valuable clues about topics and thus would lead to
non-optimal topic modeling.
Taking apartment rental advertisements as an ex-
ample, when people write advertisements for their
apartments, it’s natural to first introduce “size” and
“address” of the apartment, and then “rent” and
“contact”. Few people would talk about “restric-
tion” first. If this kind of topical structures are cap-
tured by a topic model, it would not only improve
the topic mining results, but, more importantly, also
help many other document analysis tasks, such as
sentence annotation and sentence ordering.
Nevertheless, very few existing topic models at-
tempted to model such structural dependency among
topics. The Aspect HMM model introduced in
(Blei and Moreno, 2001) combines pLSA (Hof-
mann, 1999) with HMM (Rabiner, 1989) to perform
document segmentation over text streams. However,
Aspect HMM separately estimates the topics in the
training set and depends on heuristics to infer the
transitional relations between topics. The Hidden
Topic Markov Model (HTMM) proposed by (Gru-
ber et al., 2007) extends the traditional topic models
by assuming words in each sentence share the same
topic assignment, and topics transit between adja-
cent sentences. However, the transitional structures
among topics, i.e., how likely one topic would fol-
low another topic, are not captured in this model.
</bodyText>
<page confidence="0.934653">
1526
</page>
<note confidence="0.9792075">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1526–1535,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999917">
In this paper, we propose a new topic model,
named Structural Topic Model (strTM) to model and
analyze both latent topics and topical structures in
text documents. To do so, strTM assumes: 1) words
in a document are either drawn from a content topic
or a functional (i.e., background) topic; 2) words in
the same sentence share the same content topic; and
3) content topics in the adjacent sentences follow a
topic transition that satisfies the first order Markov
property. The first assumption distinguishes the se-
mantics of the occurrence of each word in the doc-
ument, the second requirement confines the unreal-
istic “bag-of-word” assumption into a tighter unit,
and the third assumption exploits the connection be-
tween adjacent sentences.
To evaluate the usefulness of the identified top-
ical structures by strTM, we applied strTM to the
tasks of sentence annotation and sentence ordering,
where correctly modeling the document structure
is crucial. On the corpus of 8,031 apartment ad-
vertisements from craiglist (Grenager et al., 2005)
and 1,991 movie reviews from IMDB (Zhuang et
al., 2006), strTM achieved encouraging improve-
ment in both tasks compared with the baseline meth-
ods that don’t explicitly model the topical structure.
The results confirm the necessity of modeling the
latent topical structures inside documents, and also
demonstrate the advantages of the proposed strTM
over existing topic models.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999945328125001">
Topic models have been successfully applied to
many problems, e.g., sentiment analysis (Mei et
al., 2007), document summarization (Lu and Zhai,
2008) and image annotation (Blei and Jordan, 2003).
However, in most existing work, the dependency
among the topics is loosely governed by the prior
topic distribution, e.g., Dirichlet distribution.
Some work has attempted to capture the interre-
lationship among the latent topics. Correlated Topic
Model (Blei and Lafferty, 2007) replaces Dirichlet
prior with logistic Normal prior for topic distribu-
tion in each document in order to capture the cor-
relation between the topics. HMM-LDA (Griffiths
et al., 2005) distinguishes the short-range syntactic
dependencies from long-range semantic dependen-
cies among the words in each document. But in
HMM-LDA, only the latent variables for the syn-
tactic classes are treated as a locally dependent se-
quence, while latent topics are treated the same as in
other topic models. Chen et al. introduced the gen-
eralized Mallows model to constrain the latent topic
assignments (Chen et al., 2009). In their model,
they assume there exists a canonical order among
the topics in the collection of related documents and
the same topics are forced not to appear in discon-
nected portions of the topic sequence in one docu-
ment (sampling without replacement). Our method
relaxes this assumption by only postulating transi-
tional dependency between topics in the adjacent
sentences (sampling with replacement) and thus po-
tentially allows a topic to appear multiple times in
disconnected segments. As discussed in the pre-
vious section, HTMM (Gruber et al., 2007) is the
most similar model to ours. HTMM models the
document structure by assuming words in the same
sentence share the same topic assignment and suc-
cessive sentences are more likely to share the same
topic. However, HTMM only loosely models the
transition between topics as a binary relation: the
same as the previous sentence’s assignment or draw
a new one with a certain probability. This simpli-
fied coarse modeling of dependency could not fully
capture the complex structure across different docu-
ments. In contrast, our strTM model explicitly cap-
tures the regular topic transitions by postulating the
first order Markov property over the topics.
Another line of related work is discourse analysis
in natural language processing: discourse segmen-
tation (Sun et al., 2007; Galley et al., 2003) splits a
document into a linear sequence of multi-paragraph
passages, where lexical cohesion is used to link to-
gether the textual units; discourse parsing (Soricut
and Marcu, 2003; Marcu, 1998) tries to uncover a
more sophisticated hierarchical coherence structure
from text to represent the entire discourse. One work
in this line that shares a similar goal as ours is the
content models (Barzilay and Lee, 2004), where an
HMM is defined over text spans to perform infor-
mation ordering and extractive summarization. A
deficiency of the content models is that the identi-
fication of clusters of text spans is done separately
from transition modeling. Our strTM addresses this
deficiency by defining a generative process to simul-
taneously capture the topics and the transitional re-
</bodyText>
<page confidence="0.98998">
1527
</page>
<bodyText confidence="0.99927">
lationship among topics: allowing topic modeling
and transition modeling to reinforce each other in a
principled framework.
</bodyText>
<sectionHeader confidence="0.992971" genericHeader="method">
3 Structural Topic Model
</sectionHeader>
<bodyText confidence="0.999648705882353">
In this section, we formally define the Structural
Topic Model (strTM) and discuss how it captures the
latent topics and topical structures within the docu-
ments simultaneously. From the theory of linguistic
analysis (Kamp, 1981), we know that document ex-
hibits internal structures, where structural segments
encapsulate semantic units that are closely related.
In strTM, we treat a sentence as the basic structure
unit, and assume all the words in a sentence share the
same topical aspect. Besides, two adjacent segments
are assumed to be highly related (capturing cohesion
in text); specifically, in strTM we pose a strong tran-
sitional dependency assumption among the topics:
the choice of topic for each sentence directly de-
pends on the previous sentence’s topic assignment,
i.e., first order Markov property. Moveover, tak-
ing the insights from HMM-LDA that not all the
words are content conveying (some of them may
just be a result of syntactic requirement), we intro-
duce a dummy functional topic zB for every sen-
tence in the document. We use this functional topic
to capture the document-independent word distribu-
tion, i.e., corpus background (Zhai et al., 2004). As
a result, in strTM, every sentence is treated as a mix-
ture of content and functional topics.
Formally, we assume a corpus consists of D doc-
uments with a vocabulary of size V, and there are
k content topics embedded in the corpus. In a given
document d, there are m sentences and each sentence
i has Ni words. We assume the topic transition prob-
ability p(zIz′) is drawn from a Multinomial distribu-
tion Mul(αz′), and the word emission probability un-
der each topic p(wlz) is drawn from a Multinomial
distribution Mul(βz).
To get a unified description of the generation
process, we add another dummy topic T-START in
strTM, which is the initial topic with position “-1”
for every document but does not emit any words.
In addition, since our functional topic is assumed to
occur in all the sentences, we don’t need to model
its transition with other content topics. We use a
Binomial variable π to control the proportion be-
tween content and functional topics in each sen-
tence. Therefore, there are k+1 topic transitions, one
for T-START and others for k content topics; and k
emission probabilities for the content topics, with an
additional one for the functional topic zB (in total
k+1 emission probability distributions).
Conditioned on the model parameters O =
(α, β, π), the generative process of a document in
strTM can be described as follows:
</bodyText>
<listItem confidence="0.975378">
1. For each sentence si in document d:
(a) Draw topic zi from Multinomial distribu-
tion conditioned on the previous sentence
si_1’s topic assignment zi_1:
zi — Mul(αzi−1)
(b) Draw each word wij in sentence si from
the mixture of content topic zi and func-
tional topic zB:
</listItem>
<equation confidence="0.929124">
wij — πp(wij1β, zi)+(1−π)p(wij�β, zB)
</equation>
<bodyText confidence="0.9918515">
The joint probability of sentences and topics in
one document defined by strTM is thus given by:
</bodyText>
<equation confidence="0.9095755">
p(S0, S1,... , Sm, z|α, β, π) = ∏m p(zi|α, zi−1)p(Si|zi)
i=1
</equation>
<bodyText confidence="0.9990245">
where the topic to sentence emission probability is
defined as:
</bodyText>
<equation confidence="0.8954885">
Ni
p(Si|zi) = ∏ [πp(wij|β, zi) + (1 − π)p(wij|β, zB)]
j=0
This process is graphically illustrated in Figure 1.
</equation>
<figureCaption confidence="0.996283">
Figure 1: Graphical Representation of strTM.
</figureCaption>
<bodyText confidence="0.975170666666667">
From the definition of strTM, we can see that the
document structure is characterized by a document-
specific topic chain, and forcing the words in one
</bodyText>
<equation confidence="0.888364">
D N0 N1 Nm
Tstart
w0
z0 z1
w1
K+1
K+1
wm
zm
</equation>
<page confidence="0.922907">
1528
</page>
<bodyText confidence="0.999981333333333">
sentence to share the same content topic ensures se-
mantic cohesion of the mined topics. Although we
do not directly model the topic mixture for each doc-
ument as the traditional topic models do, the word
co-occurrence patterns within the same document
are captured by topic propagation through the transi-
tions. This can be easily understood when we write
down the posterior probability of the topic assign-
ment for a particular sentence:
</bodyText>
<equation confidence="0.994869777777778">
p(zi|S0, S1, ... , Sm, O)
p(S0, S1, ... , Sm|zi, O)p(zi)
_
p(S0, S1,...,Sm)
oc p(S0, S1, ... , Si, zi) X p(Si+1, Si+2, ... , Sm|zi)
∑_ p(S0, ... , Si−1, zi−1)p(zi|zi−1)p(Si|zi)
zi−1
∑X p(Si+1, ... , Sm|zi+1)p(zi+1|zi) (3)
zi+1
</equation>
<bodyText confidence="0.999987235294118">
The first part of Eq(3) describes the recursive in-
fluence on the choice of topic for the ith sentence
from its preceding sentences, while the second part
captures how the succeeding sentences affect the
current topic assignment. Intuitively, when we need
to decide a sentence’s topic, we will look “back-
ward” and “forward” over all the sentences in the
document to determine a “suitable” one. In addition,
because of the first order Markov property, the local
topical dependency gets more emphasis, i.e., they
are interacting directly through the transition proba-
bilities p(zi|zi−1) and p(zi+1|zi). And such interac-
tion on sentences farther away would get damped by
the multiplication of such probabilities. This result
is reasonable, especially in a long document, since
neighboring sentences are more likely to cover sim-
ilar topics than two sentences far apart.
</bodyText>
<sectionHeader confidence="0.9636055" genericHeader="method">
4 Posterior Inference and Parameter
Estimation
</sectionHeader>
<bodyText confidence="0.99996496">
The chain structure in strTM enables us to perform
exact inference: posterior distribution can be ef-
ficiently calculated by the forward-backward algo-
rithm, the optimal topic sequence can be inferred
using the Viterbi algorithm, and parameter estima-
tion can be solved by the Expectation Maximization
(EM) algorithm. More technical details can be found
in (Rabiner, 1989). In this section, we only discuss
strTM-specific procedures.
In the E-Step of EM algorithm, we need to col-
lect the expected count of a sequential topic pair
(z, z′) and a topic-word pair (z, w) to update the
model parameters α and Q in the M-Step. In strTM,
E[c(z, z′)] can be easily calculated by forward-
backward algorithm. But we have to go one step
further to fetch the required sufficient statistics for
E[c(z, w)], because our emission probabilities are
defined over sentences.
Through forward-backward algorithm, we can get
the posterior probability p(si, z|d, O). In strTM,
words in one sentence are independently drawn from
either a specific content topic z or functional topic
zB according to the mixture weight 7r. Therefore,
we can accumulate the expected count of (z, w) over
all the sentences by:
</bodyText>
<equation confidence="0.9989225">
7rp(w|z)p(s, z|d, O)c(w, s) (4)
7rp(w |z) + (1 − 7r)p(w |zB)
</equation>
<bodyText confidence="0.999421071428572">
where c(w, s) indicates the frequency of word w in
sentence s.
Eq(4) can be easily explained as follows. Since
we already observe topic z and sentence s co-
occur with probability p(s, z|d, O), each word w
in s should share the same probability of be-
ing observed with content topic z. Thus the ex-
pected count of c(z, w) in this sentence would be
p(s, z|d, O)c(w, s). However, since each sentence
is also associated with the functional topic zB, the
word w may also be drawn from zB. By applying
the Bayes’ rule, we can properly reallocate the ex-
pected count of c(z, w) by Eq(4). The same strategy
can be applied to obtain E[c(zB, w)].
As discussed in (Johnson, 2007), to avoid the
problem that EM algorithm tends to assign a uni-
form word/state distribution to each hidden state,
which deviates from the heavily skewed word/state
distributions empirically observed, we can apply a
Bayesian estimation approach for strTM. Thus we
introduce prior distributions over the topic transi-
tion Mul(αz′) and emission probabilities Mul(Qz),
and use the Variational Bayesian (VB) (Jordan et al.,
1999) estimator to obtain a model with more skewed
word/state distributions.
Since both the topic transition and emission prob-
abilities are Multinomial distributions in strTM,
the conjugate Dirichlet distribution is the natural
</bodyText>
<equation confidence="0.9264715">
E[c(z, w)] _ ∑
d,sEd
</equation>
<page confidence="0.868166">
1529
</page>
<bodyText confidence="0.938383">
choice for imposing a prior on them (Diaconis and
Ylvisaker, 1979). Thus, we further assume:
</bodyText>
<equation confidence="0.9999665">
αz — Dir(η) (5)
βz — Dir(γ) (6)
</equation>
<bodyText confidence="0.9986287">
where we use exchangeable Dirichlet distributions
to control the sparsity of αz and βz. As η and γ ap-
proach zero, the prior strongly favors the models in
which each hidden state emits as few words/states as
possible. In our experiments, we empirically tuned
η and γ on different training corpus to optimize log-
likelihood.
The resulting VB estimation only requires a mi-
nor modification to the M-Step in the original EM
algorithm:
</bodyText>
<equation confidence="0.999956333333333">
Φ(E[c(z′, z)] + η)
¯αz = (7)
Φ(E[c(z)] + kη)
Φ(E[c(w, z)] + γ)
¯βz = (8)
Φ(E[c(z)] + Vγ)
</equation>
<bodyText confidence="0.999926333333333">
where Φ(x) is the exponential of the first derivative
of the log-gamma function.
The optimal setting of π for the proportion of con-
tent topics in the documents is empirically tuned by
cross-validation over the training corpus to maxi-
mize the log-likelihood.
</bodyText>
<sectionHeader confidence="0.998195" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999596">
In this section, we demonstrate the effectiveness
of strTM in identifying latent topical structures
from documents, and quantitatively evaluate how the
mined topic transitions can help the tasks of sen-
tence annotation and sentence ordering.
</bodyText>
<subsectionHeader confidence="0.992553">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999646740740741">
We used two different data sets for evaluation: apart-
ment advertisements (Ads) from (Grenager et al.,
2005) and movie reviews (Review) from (Zhuang et
al., 2006).
The Ads data consists of 8,767 advertisements for
apartment rentals crawled from Craigslist website.
302 of them have been labeled with 11 fields, in-
cluding size, feature, address, etc., on the sentence
level. The review data contains 2,000 movie reviews
discussing 11 different movies from IMDB. These
reviews are manually labeled with 12 movie feature
labels (We didn’t use the additional opinion anno-
tations in this data set.) , e.g., VP (vision effects),
MS (music and sound effects), etc., also on the sen-
tences, but the annotations in the review data set is
much sparser than that in the Ads data set (see in Ta-
ble 1). The sentence-level annotations make it pos-
sible to quantitatively evaluate the discovered topic
structures.
We performed simple preprocessing on these
two data sets: 1) removed a standard list of stop
words, terms occurring in less than 2 documents;
2) discarded the documents with less than 2 sen-
tences; 3) aggregated sentence-level annotations
into document-level labels (binary vector) for each
document. Table 1 gives a brief summary on these
two data sets after the processing.
</bodyText>
<table confidence="0.997370857142857">
Ads Review
Document Size 8,031 1,991
Vocabulary Size 21,993 14,507
Avg Stn/Doc 8.0 13.9
Avg Labeled Stn/Doc 7.1* 5.1
Avg Token/Stn 14.1 20.0
*Only in 302 labeled ads
</table>
<tableCaption confidence="0.999788">
Table 1: Summary of evaluation data set
</tableCaption>
<subsectionHeader confidence="0.97321">
5.2 Topic Transition Modeling
</subsectionHeader>
<bodyText confidence="0.9903781">
First, we qualitatively demonstrate the topical struc-
ture identified by strTM from Ads data&apos;. We trained
strTM with 11 content topics in Ads data set, used
word distribution under each class (estimated by
maximum likelihood estimator on document-level
labels) as priors to initialize the emission probabil-
ity Mul(βz) in Eq(6), and treated document-level la-
bels as the prior for transition from T-START in each
document, so that the mined topics can be aligned
with the predefined class labels. Figure 2 shows the
identified topics and the transitions among them. To
get a clearer view, we discarded the transitions be-
low a threshold of 0.1 and removed all the isolated
nodes.
From Figure 2, we can find some interesting top-
ical structures. For example, people usually start
with “size”, “features” and “address”, and end
with “contact” information when they post an apart-
&apos;Due to the page limit, we only show the result in Ads data
set.
</bodyText>
<page confidence="0.850462">
1530
</page>
<figure confidence="0.999884925">
water
garbage
included
paid
utilities
parking
kitchen
room
laundry
storage
close
shopping
transportation
bart
location
TELEPHONE
appointment
information
contact
email
NUM
bedroom
bath
room
large
deposit
month
lease
rent
year
http
photos
click
pictures
view
pets
kitchen
cat
negotiate
smoking
</figure>
<figureCaption confidence="0.999894">
Figure 2: Estimated topics and topical transitions in Ads data set
</figureCaption>
<bodyText confidence="0.999907944444445">
ment ads. Also, we can discover a strong transition
from “size” to “features”. This intuitively makes
sense because people usually write “it’s a two bed-
rooms apartment” first, and then describe other “fea-
tures” about the apartment. The mined topics are
also quite meaningful. For example, “restrictions”
are usually put over pets and smoking, and parking
and laundry are always the major “features” of an
apartment.
To further quantitatively evaluate the estimated
topic transitions, we used Kullback-Leibler (KL) di-
vergency between the estimated transition matrix
and the “ground-truth” transition matrix as the met-
ric. Each element of the “ground-truth” transition
matrix was calculated by Eq(9), where c(z, z′) de-
notes how many sentences annotated by z′ immedi-
ately precede one annotated by z. δ is a smoothing
factor, and we fixed it to 0.01 in the experiment.
</bodyText>
<equation confidence="0.999659">
¯p(z|z′) = c(z, z′) + δ (9)
c(z) + kδ
</equation>
<bodyText confidence="0.99649225">
The KL divergency between two transition matri-
ces is defined in Eq(10). Because we have a k x k
transition matrix (Tstart is not included), we calcu-
lated the average KL divergency against the ground-
</bodyText>
<equation confidence="0.9541764">
truth over all the topics:
∑� ��1 KL(p(z|z′ �)||�p(z|z′ �))+KL(�p(z|z′ �)||p(z|z′ �))
avgKL=
2k
(10)
</equation>
<bodyText confidence="0.999635863636364">
where ¯p(z|z′) is the ground-truth transition proba-
bility estimated by Eq(9), and p(z|z′) is the transi-
tion probability given by the model.
We used pLSA (Hofmann, 1999), latent permuta-
tion model (lPerm) (Chen et al., 2009) and HTMM
(Gruber et al., 2007) as the baseline methods for the
comparison. Because none of these three methods
can generate a topic transition matrix directly, we
extended them a little bit to achieve this goal. For
pLSA, we used the document-level labels as priors
for the topic distribution in each document, so that
the estimated topics can be aligned with the prede-
fined class labels. After the topics were estimated,
for each sentence we selected the topic that had
the highest posterior probability to generate the sen-
tence as its class label. For lPerm and HTMM, we
used Kuhn-Munkres algorithm (Lov´asz and Plum-
mer, 1986) to find the optimal topic-to-class align-
ment based on the sentence-level annotations. Af-
ter the sentences were annotated with class labels,
we estimated the topic transition matrices for all of
these three methods by Eq(9).
</bodyText>
<page confidence="0.981794">
1531
</page>
<bodyText confidence="0.999799714285714">
Since only a small portion of sentences are an-
notated in the Review data set, very few neighbor-
ing sentences are annotated at the same time, which
introduces many noisy transitions. As a result, we
only performed the comparison on the Ads data set.
The “ground-truth” transition matrix was estimated
based on all the 302 annotated ads.
</bodyText>
<table confidence="0.762185666666667">
pLSA+prior lPerm HTMM strTM
avgKL 0.743 1.101 0.572 0.372
p-value 0.023 1e-4 0.007 –
</table>
<tableCaption confidence="0.988651">
Table 2: Comparison of estimated topic transitions on
Ads data set
</tableCaption>
<bodyText confidence="0.999966666666667">
In Table 2, the p-value was calculated based on t-
test of the KL divergency between each topic’s tran-
sition probability against strTM. From the results,
we can see that avgKL of strTM is smaller than the
other three baseline methods, which means the esti-
mated transitional relation by strTM is much closer
to the ground-truth transition. This demonstrates
that strTM captures the topical structure well, com-
pared with other baseline methods.
</bodyText>
<subsectionHeader confidence="0.99842">
5.3 Sentence Annotation
</subsectionHeader>
<bodyText confidence="0.999728404761905">
In this section, we demonstrate how the identified
topical structure can benefit the task of sentence an-
notation. Sentence annotation is one step beyond the
traditional document classification task: in sentence
annotation, we want to predict the class label for
each sentence in the document, and this will be help-
ful for other problems, including extractive summa-
rization and passage retrieval. However, the lack of
detailed annotations on sentences greatly limits the
effectiveness of the supervised classification meth-
ods, which have been proved successful on docu-
ment classifications.
In this experiment, we propose to use strTM to ad-
dress this annotation task. One advantage of strTM
is that it captures the topic transitions on the sen-
tence level within documents, which provides a reg-
ularization over the adjacent predictions.
To examine the effectiveness of such structural
regularization, we compared strTM with four base-
line methods: pLSA, lPerm, HTMM and Naive
Bayes model. The sentence labeling approaches for
strTM, pLSA, lPerm and HTMM have been dis-
cussed in the previous section. As for Naive Bayes
model, we used EM algorithm 2 with both labeled
and unlabeled data for the training purpose (we used
the same unigram features as in topics models). We
set weights for the unlabeled data to be 10−3 in
Naive Bayes with EM.
The comparison was performed on both data sets.
We set the size of topics in each topic model equal
to the number of classes in each data set accord-
ingly. To tackle the situation where some sentences
in the document are not strictly associated with any
classes, we introduced an additional NULL content
topic in all the topic models. During the training
phase, none of the methods used the sentence-level
annotations in the documents, so that we treated the
whole corpus as the training and testing set.
To evaluate the prediction performance, we cal-
culated accuracy, recall and precision based on the
correct predictions over the sentences, and averaged
over all the classes as the criterion.
</bodyText>
<table confidence="0.999538166666667">
Model Accuracy Recall Precison
pLSA+prior 0.432 0.649 0.457
lPerm 0.610 0.514 0.471
HTMM 0.606 0.588 0.443
NB+EM 0.528 0.337 0.612
strTM 0.747 0.674 0.620
</table>
<tableCaption confidence="0.9388165">
Table 3: Sentence annotation performance on Ads data
set
</tableCaption>
<table confidence="0.999949333333333">
Model Accuracy Recall Precison
pLSA+prior 0.342 0.278 0.250
lPerm 0.286 0.205 0.184
HTMM 0.369 0.131 0.149
NB+EM 0.341 0.354 0.431
strTM 0.541 0.398 0.323
</table>
<tableCaption confidence="0.935472">
Table 4: Sentence annotation performance on Review
data set
</tableCaption>
<bodyText confidence="0.999675714285714">
Annotation performance on the two data sets is
shown in Table 3 and Table 4. We can see that strTM
outperformed all the other baseline methods on most
of the metrics: strTM has the best accuracy and re-
call on both of the two data sets. The improvement
confirms our hypothesis that besides solely depend-
ing on the local word patterns to perform predic-
</bodyText>
<footnote confidence="0.997397">
2Mallet package: http://mallet.cs.umass.edu/
</footnote>
<page confidence="0.994925">
1532
</page>
<bodyText confidence="0.999982375">
tions, adjacent sentences provide a structural reg-
ularization in strTM (see Eq(3)). Compared with
lPerm, which postulates a strong constrain over the
topic assignment (sampling without replacement),
strTM performed much better on both of these two
data sets. This validates the benefit of modeling lo-
cal transitional relation compared with the global or-
dering. Besides, strTM achieved over 46% accu-
racy improvement compared with the second best
HTMM in the review data set. This result shows
the advantage of explicitly modeling the topic tran-
sitions between neighbor sentences instead of using
a binary relation to do so as in HTMM.
To further testify how the identified topical struc-
ture can help the sentence annotation task, we first
randomly removed 100 annotated ads from the train-
ing corpus and used them as the testing set. Then,
we used the ground-truth topic transition matrix es-
timated from the training data to order those 100 ads
according to their fitness scores under the ground-
truth topic transition matrix, which is defined in
Eq(11). We tested the prediction accuracy of differ-
ent models over two different partitions, top 50 and
bottom 50, according to this order.
</bodyText>
<equation confidence="0.981815666666667">
|d|
fitness(d) = |dl ∑log p(ti|ti−1) (11)
i=0
</equation>
<bodyText confidence="0.995881">
where ti is the class label for ith sentence in doc-
ument d, |d |is the number of sentences in docu-
ment d, and p(ti|ti−1) is the transition probability
estimated by Eq(9).
</bodyText>
<table confidence="0.999069">
Top 50 p-value Bot 50 p-value
pLSA+prior 0.496 4e-12 0.542 0.004
lPerm 0.669 0.003 0.505 8e-4
HTMM 0.683 0.004 0.579 0.003
NB + EM 0.492 1e-12 0.539 0.002
strTM 0.752 – 0.644 –
</table>
<tableCaption confidence="0.9887795">
Table 5: Sentence annotation performance according to
structural fitness
</tableCaption>
<bodyText confidence="0.9988695">
The results are shown in Table 5. From this table,
we can find that when the testing documents follow
the regular patterns as in the training data, i.e., top
50 group, strTM performs significantly better than
the other methods; when the testing documents don’t
share such structure, i.e., bottom 50 group, strTM’s
performance drops. This comparison confirms that
when a testing document shares similar topic struc-
ture as the training data, the topical transitions cap-
tured by strTM can help the sentence annotation task
a lot. In contrast, because pLSA and Naive Bayes
don’t depend on the document’s structure, their per-
formance does not change much over these two par-
titions.
</bodyText>
<subsectionHeader confidence="0.999032">
5.4 Sentence Ordering
</subsectionHeader>
<bodyText confidence="0.999538272727273">
In this experiment, we illustrate how the learned top-
ical structure can help us better arrange sentences in
a document. Sentence ordering, or text planning, is
essential to many text synthesis applications, includ-
ing multi-document summarization (Goldstein et al.,
2000) and concept-to-text generation (Barzilay and
Lapata, 2005).
In strTM, we evaluate all the possible orderings
of the sentences in a given document and selected
the optimal one which gives the highest generation
probability:
</bodyText>
<equation confidence="0.90076">
∑�σ(m) = arg max p(Sσ[0], Sσ[1],... , Sσ[m], z|0)
σ(m) z
(12)
</equation>
<bodyText confidence="0.999942045454545">
where σ(m) is a permutation of 1 to m, and σ[i] is
the ith element in this permutation.
To quantitatively evaluate the ordering result, we
treated the original sentence order (OSO) as the per-
fect order and used Kendall’s τ(σ) (Lapata, 2006) as
the evaluation metric to compute the divergency be-
tween the optimum ordering given by the model and
OSO. Kendall’s τ(σ) is widely used in information
retrieval domain to measure the correlation between
two ranked lists and it indicates how much an order-
ing differs from OSO, which ranges from 1 (perfect
matching) to -1 (totally mismatching).
Since only the HTMM and lPerm take the order
of sentences in the document into consideration, we
used them as the baselines in this experiment. We
ranked OSO together with candidate permutations
according to the corresponding model’s generation
probability. However, when the size of documents
becomes larger, it’s infeasible to permutate all the
orderings, therefore we randomly permutated 200
possible orderings of sentences as candidates when
there were more than 200 possible candidates. The
</bodyText>
<page confidence="0.978204">
1533
</page>
<reference confidence="0.2746209375">
2bedroom 1bath in very nice complex! Pool,
carport, laundry facilities!! Call Don (650)207-
5769 to see! Great location!! Also available,
2bed.2bath for $1275 in same complex.
2bedroom 1bath in very nice complex! Pool, car-
�� port, laundry facilities!! Great location!! Also
available, 2bed.2bath for $1275 in same complex.
Call Don (650)207-5769 to see!
2 bedrooms 1 bath + a famyly room in a cul-de-
sac location. Please drive by and call Marilyn for ��
appointment 650-652-5806. Address: 517 Price
Way, Vallejo. No Pets Please!
2 bedrooms 1 bath + a famyly room in a cul-de-
sac location. Address: 517 Price Way, Vallejo. No
Pets Please! Please drive by and call Marilyn for
appointment 650-652-5806.
</reference>
<tableCaption confidence="0.976294">
Table 6: Sample results for document ordering by strTM
</tableCaption>
<bodyText confidence="0.997804214285714">
experiment was performed on both data sets with
80% data for training and the other 20% for testing.
We calculated the τ(σ) of all these models for
each document in the two data sets and visualized
the distribution of τ(σ) in each data set with his-
togram in Figure 3. From the results, we could ob-
serve that strTM’s τ(σ) is more skewed towards the
positive range (with mean 0.619 in Ads data set and
0.398 in review data set) than lPerm’s results (with
mean 0.566 in Ads data set and 0.08 in review data
set) and HTMM’s results (with mean 0.332 in Ads
data set and 0.286 in review data set). This indi-
cates that strTM better captures the internal structure
within the documents.
</bodyText>
<figureCaption confidence="0.993639">
Figure 3: Document Ordering Performance in T(Q).
</figureCaption>
<bodyText confidence="0.9999396875">
We see that all methods performed better on the
Ads data set than the review data set, suggesting
that the topical structures are more coherent in the
Ads data set than the review data. Indeed, in the
Ads data, strTM perfectly recovered 52.9% of the
original sentence order. When examining some mis-
matched results, we found that some of them were
due to an “outlier” order given by the original docu-
ment (in comparison to the “regular” patterns in the
set). In Table 6, we show two such examples where
we see the learned structure “suggested” to move
the contact information to the end, which intuitively
gives us a more regular organization of the ads. It’s
hard to say that in this case, the system’s ordering is
inferior to that of the original; indeed, the system or-
der is arguably more natural than the original order.
</bodyText>
<sectionHeader confidence="0.999747" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999918956521739">
In this paper, we proposed a new structural topic
model (strTM) to identify the latent topical struc-
ture in documents. Different from the traditional
topic models, in which exchangeability assumption
precludes them to capture the structure of a docu-
ment, strTM captures the topical structure explicitly
by introducing transitions among the topics. Experi-
ment results show that both the identified topics and
topical structure are intuitive and meaningful, and
they are helpful for improving the performance of
tasks such as sentence annotation and sentence or-
dering, where correctly recognizing the document
structure is crucial. Besides, strTM is shown to out-
perform not only the baseline topic models that fail
to model the dependency between the topics, but
also the semi-supervised Naive Bayes model for the
sentence annotation task.
Our work can be extended by incorporating richer
features, such as named entity and co-reference, to
enhance the model’s capability of structure finding.
Besides, advanced NLP techniques for document
analysis, e.g., shallow parsing, may also be used to
further improve structure finding.
</bodyText>
<sectionHeader confidence="0.999139" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9993852">
We thank the anonymous reviewers for their use-
ful comments. This material is based upon work
supported by the National Science Foundation un-
der Grant Numbers IIS-0713581 and CNS-0834709,
and NASA grant NNX08AC35A.
</bodyText>
<figure confidence="0.9994845625">
Ads Review
τ(σ) τ�σ�
(a) Ads (b) Review
N of Documents
900
800
700
600
500
400
300
200
100
0
1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1
lPerm
HTMM
strTM
R of Documents
160
140
120
100
80
60
40
20
0
�1 ���� ���� ���� ���� 0 0.2 0.4 0.6 0.8 1
��e��
����
�����
</figure>
<page confidence="0.986727">
1534
</page>
<sectionHeader confidence="0.994787" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996989163461538">
R. Barzilay and M. Lapata. 2005. Collective content se-
lection for concept-to-text generation. In Proceedings
of the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 331–338.
R. Barzilay and L. Lee. 2004. Catching the drift: Proba-
bilistic content models, with applications to generation
and summarization. In Proceedings of HLT-NAACL,
pages 113–120.
D.M. Blei and M.I. Jordan. 2003. Modeling annotated
data. In Proceedings of the 26th annual international
ACM SIGIR conference, pages 127–134.
D.M. Blei and J.D. Lafferty. 2007. A correlated topic
model of science. The Annals of Applied Statistics,
1(1):17–35.
D.M. Blei and P.J. Moreno. 2001. Topic segmentation
with an aspect hidden Markov model. In Proceedings
of the 24th annual international ACM SIGIR confer-
ence, page 348. ACM.
D.M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003.
Latent dirichlet allocation. The Journal of Machine
Learning Research, 3(2-3):993 – 1022.
H. Chen, SRK Branavan, R. Barzilay, and D.R. Karger.
2009. Global models of document structure using la-
tent permutations. In Proceedings of HLT-NAACL,
pages 371–379.
P. Diaconis and D. Ylvisaker. 1979. Conjugate pri-
ors for exponential families. The Annals of statistics,
7(2):269–281.
M. Galley, K. McKeown, E. Fosler-Lussier, and H. Jing.
2003. Discourse segmentation of multi-party conver-
sation. In Proceedings of the 41st Annual Meeting on
Association for Computational Linguistics-Volume 1,
pages 562–569.
J. Goldstein, V. Mittal, J. Carbonell, and M. Kantrowitz.
2000. Multi-document summarization by sentence ex-
traction. In NAACL-ANLP 2000 Workshop on Auto-
matic summarization, pages 40–48.
T. Grenager, D. Klein, and C.D. Manning. 2005. Un-
supervised learning of field segmentation models for
information extraction. In Proceedings of the 43rd an-
nual meeting on association for computational linguis-
tics, pages 371–378.
T.L. Griffiths, M. Steyvers, D.M. Blei, and J.B. Tenen-
baum. 2005. Integrating topics and syntax. Advances
in neural information processing systems, 17:537–
544.
Amit Gruber, Yair Weiss, and Michal Rosen-Zvi. 2007.
Hidden topic markov models. volume 2, pages 163–
170.
T. Hofmann. 1999. Probabilistic latent semantic index-
ing. In Proceedings of the 22nd annual international
ACM SIGIR conference on Research and development
in information retrieval, pages 50–57.
E.H. Hovy. 1993. Automated discourse generation using
discourse structure relations. Artificial intelligence,
63(1-2):341–385.
M. Johnson. 2007. Why doesn’t EM find good HMM
POS-taggers. In Proceedings of the 2007Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL), pages 296–305.
M.I. Jordan, Z. Ghahramani, T.S. Jaakkola, and L.K.
Saul. 1999. An introduction to variational methods
for graphical models. Machine learning, 37(2):183–
233.
H. Kamp. 1981. A theory of truth and semantic repre-
sentation. Formal methods in the study of language,
1:277–322.
M. Lapata. 2006. Automatic evaluation of information
ordering: Kendall’s tau. Computational Linguistics,
32(4):471–484.
L. Lov´asz and M.D. Plummer. 1986. Matching theory.
Elsevier Science Ltd.
Y. Lu and C. Zhai. 2008. Opinion integration through
semi-supervised topic modeling. In Proceeding of
the 17th international conference on World Wide Web,
pages 121–130.
Daniel Marcu. 1998. The rhetorical parsing of natural
language texts. In ACL ’98, pages 96–103.
Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. 2007.
Topic sentiment mixture: modeling facets and opin-
ions in weblogs. In Proceedings of the 16th interna-
tional conference on World Wide Web, pages 171–180.
L.R. Rabiner. 1989. A tutorial on hidden Markov models
and selected applications in speech recognition. Pro-
ceedings of the IEEE, 77(2):257–286.
R. Soricut and D. Marcu. 2003. Sentence level dis-
course parsing using syntactic and lexical information.
In Proceedings of the 2003 Conference of the NAACL-
HTC, pages 149–156.
B. Sun, P. Mitra, C.L. Giles, J. Yen, and H. Zha. 2007.
Topic segmentation with shared topic detection and
alignment of multiple documents. In Proceedings of
the 30th ACM SIGIR, pages 199–206.
ChengXiang Zhai, Atulya Velivelli, and Bei Yu. 2004.
A cross-collection mixture model for comparative text
minning. In Proceeding of the 10th ACM SIGKDD
international conference on Knowledge discovery in
data mining, pages 743–748.
L. Zhuang, F. Jing, and X.Y. Zhu. 2006. Movie re-
view mining and summarization. In Proceedings of
the 15th ACM international conference on Information
and knowledge management, pages 43–50.
</reference>
<page confidence="0.991309">
1535
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.876464">
<title confidence="0.999507">Structural Topic Model for Latent Topical Structure Analysis</title>
<author confidence="0.992454">Hongning Wang</author>
<author confidence="0.992454">Duo Zhang</author>
<author confidence="0.992454">ChengXiang</author>
<affiliation confidence="0.997964">Department of Computer University of Illinois at</affiliation>
<address confidence="0.980246">Urbana IL, 61801</address>
<email confidence="0.922974">dzhang22,</email>
<abstract confidence="0.998469476190476">Topic models have been successfully applied to many document analysis tasks to discover topics embedded in text. However, existing topic models generally cannot capture the latent topical structures in documents. Since languages are intrinsically cohesive and coherent, modeling and discovering latent topical transition structures within documents would be beneficial for many text analysis tasks. In this work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>2bedroom 1bath in very nice complex! Pool, carport, laundry facilities!! Call Don (650)207-5769 to see! Great location!! Also available, 2bed.2bath for $1275 in same complex.</title>
<marker></marker>
<rawString>2bedroom 1bath in very nice complex! Pool, carport, laundry facilities!! Call Don (650)207-5769 to see! Great location!! Also available, 2bed.2bath for $1275 in same complex.</rawString>
</citation>
<citation valid="false">
<title>2bedroom 1bath in very nice complex! Pool, car�� port, laundry facilities!! Great location!! Also available, 2bed.2bath for $1275 in same complex. Call Don (650)207-5769 to see! 2 bedrooms 1 bath + a famyly room in a cul-desac location. Please drive by and call Marilyn for �� appointment 650-652-5806. Address: 517 Price Way, Vallejo. No Pets Please!</title>
<marker></marker>
<rawString>2bedroom 1bath in very nice complex! Pool, car�� port, laundry facilities!! Great location!! Also available, 2bed.2bath for $1275 in same complex. Call Don (650)207-5769 to see! 2 bedrooms 1 bath + a famyly room in a cul-desac location. Please drive by and call Marilyn for �� appointment 650-652-5806. Address: 517 Price Way, Vallejo. No Pets Please!</rawString>
</citation>
<citation valid="false">
<title>bath + a famyly room in a cul-desac location. Address: 517 Price Way, Vallejo. No Pets Please! Please drive by and call Marilyn for appointment</title>
<volume>2</volume>
<pages>650--652</pages>
<marker></marker>
<rawString>2 bedrooms 1 bath + a famyly room in a cul-desac location. Address: 517 Price Way, Vallejo. No Pets Please! Please drive by and call Marilyn for appointment 650-652-5806.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Collective content selection for concept-to-text generation.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>331--338</pages>
<contexts>
<context position="28841" citStr="Barzilay and Lapata, 2005" startWordPosition="4657" endWordPosition="4660">topic structure as the training data, the topical transitions captured by strTM can help the sentence annotation task a lot. In contrast, because pLSA and Naive Bayes don’t depend on the document’s structure, their performance does not change much over these two partitions. 5.4 Sentence Ordering In this experiment, we illustrate how the learned topical structure can help us better arrange sentences in a document. Sentence ordering, or text planning, is essential to many text synthesis applications, including multi-document summarization (Goldstein et al., 2000) and concept-to-text generation (Barzilay and Lapata, 2005). In strTM, we evaluate all the possible orderings of the sentences in a given document and selected the optimal one which gives the highest generation probability: ∑�σ(m) = arg max p(Sσ[0], Sσ[1],... , Sσ[m], z|0) σ(m) z (12) where σ(m) is a permutation of 1 to m, and σ[i] is the ith element in this permutation. To quantitatively evaluate the ordering result, we treated the original sentence order (OSO) as the perfect order and used Kendall’s τ(σ) (Lapata, 2006) as the evaluation metric to compute the divergency between the optimum ordering given by the model and OSO. Kendall’s τ(σ) is widely</context>
</contexts>
<marker>Barzilay, Lapata, 2005</marker>
<rawString>R. Barzilay and M. Lapata. 2005. Collective content selection for concept-to-text generation. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 331–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="8012" citStr="Barzilay and Lee, 2004" startWordPosition="1232" endWordPosition="1235">by postulating the first order Markov property over the topics. Another line of related work is discourse analysis in natural language processing: discourse segmentation (Sun et al., 2007; Galley et al., 2003) splits a document into a linear sequence of multi-paragraph passages, where lexical cohesion is used to link together the textual units; discourse parsing (Soricut and Marcu, 2003; Marcu, 1998) tries to uncover a more sophisticated hierarchical coherence structure from text to represent the entire discourse. One work in this line that shares a similar goal as ours is the content models (Barzilay and Lee, 2004), where an HMM is defined over text spans to perform information ordering and extractive summarization. A deficiency of the content models is that the identification of clusters of text spans is done separately from transition modeling. Our strTM addresses this deficiency by defining a generative process to simultaneously capture the topics and the transitional re1527 lationship among topics: allowing topic modeling and transition modeling to reinforce each other in a principled framework. 3 Structural Topic Model In this section, we formally define the Structural Topic Model (strTM) and discu</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>R. Barzilay and L. Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of HLT-NAACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>M I Jordan</author>
</authors>
<title>Modeling annotated data.</title>
<date>2003</date>
<booktitle>In Proceedings of the 26th annual international ACM SIGIR conference,</booktitle>
<pages>127--134</pages>
<contexts>
<context position="1463" citStr="Blei and Jordan, 2003" startWordPosition="206" endWordPosition="209">itions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e., the document generation probabilities are invariant to content permutation. In reality, natural language text rarely consists of isolated, unrelated sentences, but rather collocated, structur</context>
<context position="5367" citStr="Blei and Jordan, 2003" startWordPosition="812" endWordPosition="815">om craiglist (Grenager et al., 2005) and 1,991 movie reviews from IMDB (Zhuang et al., 2006), strTM achieved encouraging improvement in both tasks compared with the baseline methods that don’t explicitly model the topical structure. The results confirm the necessity of modeling the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is loosely governed by the prior topic distribution, e.g., Dirichlet distribution. Some work has attempted to capture the interrelationship among the latent topics. Correlated Topic Model (Blei and Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependencies from long-range semantic dependencies among the words in each document. But in HMM-LDA</context>
</contexts>
<marker>Blei, Jordan, 2003</marker>
<rawString>D.M. Blei and M.I. Jordan. 2003. Modeling annotated data. In Proceedings of the 26th annual international ACM SIGIR conference, pages 127–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>J D Lafferty</author>
</authors>
<title>A correlated topic model of science.</title>
<date>2007</date>
<journal>The Annals of Applied Statistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="1488" citStr="Blei and Lafferty, 2007" startWordPosition="210" endWordPosition="213">rst-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e., the document generation probabilities are invariant to content permutation. In reality, natural language text rarely consists of isolated, unrelated sentences, but rather collocated, structured and coherent groups of</context>
<context position="5646" citStr="Blei and Lafferty, 2007" startWordPosition="853" endWordPosition="856">g the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is loosely governed by the prior topic distribution, e.g., Dirichlet distribution. Some work has attempted to capture the interrelationship among the latent topics. Correlated Topic Model (Blei and Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependencies from long-range semantic dependencies among the words in each document. But in HMM-LDA, only the latent variables for the syntactic classes are treated as a locally dependent sequence, while latent topics are treated the same as in other topic models. Chen et al. introduced the generalized Mallows model to constrain the latent topic assignments (Chen et al., 2009</context>
</contexts>
<marker>Blei, Lafferty, 2007</marker>
<rawString>D.M. Blei and J.D. Lafferty. 2007. A correlated topic model of science. The Annals of Applied Statistics, 1(1):17–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>P J Moreno</author>
</authors>
<title>Topic segmentation with an aspect hidden Markov model.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th annual international ACM SIGIR conference,</booktitle>
<pages>348</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2928" citStr="Blei and Moreno, 2001" startWordPosition="435" endWordPosition="438">as an example, when people write advertisements for their apartments, it’s natural to first introduce “size” and “address” of the apartment, and then “rent” and “contact”. Few people would talk about “restriction” first. If this kind of topical structures are captured by a topic model, it would not only improve the topic mining results, but, more importantly, also help many other document analysis tasks, such as sentence annotation and sentence ordering. Nevertheless, very few existing topic models attempted to model such structural dependency among topics. The Aspect HMM model introduced in (Blei and Moreno, 2001) combines pLSA (Hofmann, 1999) with HMM (Rabiner, 1989) to perform document segmentation over text streams. However, Aspect HMM separately estimates the topics in the training set and depends on heuristics to infer the transitional relations between topics. The Hidden Topic Markov Model (HTMM) proposed by (Gruber et al., 2007) extends the traditional topic models by assuming words in each sentence share the same topic assignment, and topics transit between adjacent sentences. However, the transitional structures among topics, i.e., how likely one topic would follow another topic, are not captu</context>
</contexts>
<marker>Blei, Moreno, 2001</marker>
<rawString>D.M. Blei and P.J. Moreno. 2001. Topic segmentation with an aspect hidden Markov model. In Proceedings of the 24th annual international ACM SIGIR conference, page 348. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>3--2</pages>
<contexts>
<context position="1269" citStr="Blei et al., 2003" startWordPosition="178" endWordPosition="181">s work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D.M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. The Journal of Machine Learning Research, 3(2-3):993 – 1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chen</author>
<author>SRK Branavan</author>
<author>R Barzilay</author>
<author>D R Karger</author>
</authors>
<title>Global models of document structure using latent permutations.</title>
<date>2009</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>371--379</pages>
<contexts>
<context position="6247" citStr="Chen et al., 2009" startWordPosition="949" endWordPosition="952">d Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependencies from long-range semantic dependencies among the words in each document. But in HMM-LDA, only the latent variables for the syntactic classes are treated as a locally dependent sequence, while latent topics are treated the same as in other topic models. Chen et al. introduced the generalized Mallows model to constrain the latent topic assignments (Chen et al., 2009). In their model, they assume there exists a canonical order among the topics in the collection of related documents and the same topics are forced not to appear in disconnected portions of the topic sequence in one document (sampling without replacement). Our method relaxes this assumption by only postulating transitional dependency between topics in the adjacent sentences (sampling with replacement) and thus potentially allows a topic to appear multiple times in disconnected segments. As discussed in the previous section, HTMM (Gruber et al., 2007) is the most similar model to ours. HTMM mod</context>
<context position="21493" citStr="Chen et al., 2009" startWordPosition="3458" endWordPosition="3461">oothing factor, and we fixed it to 0.01 in the experiment. ¯p(z|z′) = c(z, z′) + δ (9) c(z) + kδ The KL divergency between two transition matrices is defined in Eq(10). Because we have a k x k transition matrix (Tstart is not included), we calculated the average KL divergency against the groundtruth over all the topics: ∑� ��1 KL(p(z|z′ �)||�p(z|z′ �))+KL(�p(z|z′ �)||p(z|z′ �)) avgKL= 2k (10) where ¯p(z|z′) is the ground-truth transition probability estimated by Eq(9), and p(z|z′) is the transition probability given by the model. We used pLSA (Hofmann, 1999), latent permutation model (lPerm) (Chen et al., 2009) and HTMM (Gruber et al., 2007) as the baseline methods for the comparison. Because none of these three methods can generate a topic transition matrix directly, we extended them a little bit to achieve this goal. For pLSA, we used the document-level labels as priors for the topic distribution in each document, so that the estimated topics can be aligned with the predefined class labels. After the topics were estimated, for each sentence we selected the topic that had the highest posterior probability to generate the sentence as its class label. For lPerm and HTMM, we used Kuhn-Munkres algorith</context>
</contexts>
<marker>Chen, Branavan, Barzilay, Karger, 2009</marker>
<rawString>H. Chen, SRK Branavan, R. Barzilay, and D.R. Karger. 2009. Global models of document structure using latent permutations. In Proceedings of HLT-NAACL, pages 371–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Diaconis</author>
<author>D Ylvisaker</author>
</authors>
<title>Conjugate priors for exponential families. The Annals of statistics,</title>
<date>1979</date>
<pages>7--2</pages>
<contexts>
<context position="16150" citStr="Diaconis and Ylvisaker, 1979" startWordPosition="2584" endWordPosition="2587">ate, which deviates from the heavily skewed word/state distributions empirically observed, we can apply a Bayesian estimation approach for strTM. Thus we introduce prior distributions over the topic transition Mul(αz′) and emission probabilities Mul(Qz), and use the Variational Bayesian (VB) (Jordan et al., 1999) estimator to obtain a model with more skewed word/state distributions. Since both the topic transition and emission probabilities are Multinomial distributions in strTM, the conjugate Dirichlet distribution is the natural E[c(z, w)] _ ∑ d,sEd 1529 choice for imposing a prior on them (Diaconis and Ylvisaker, 1979). Thus, we further assume: αz — Dir(η) (5) βz — Dir(γ) (6) where we use exchangeable Dirichlet distributions to control the sparsity of αz and βz. As η and γ approach zero, the prior strongly favors the models in which each hidden state emits as few words/states as possible. In our experiments, we empirically tuned η and γ on different training corpus to optimize loglikelihood. The resulting VB estimation only requires a minor modification to the M-Step in the original EM algorithm: Φ(E[c(z′, z)] + η) ¯αz = (7) Φ(E[c(z)] + kη) Φ(E[c(w, z)] + γ) ¯βz = (8) Φ(E[c(z)] + Vγ) where Φ(x) is the expon</context>
</contexts>
<marker>Diaconis, Ylvisaker, 1979</marker>
<rawString>P. Diaconis and D. Ylvisaker. 1979. Conjugate priors for exponential families. The Annals of statistics, 7(2):269–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>K McKeown</author>
<author>E Fosler-Lussier</author>
<author>H Jing</author>
</authors>
<title>Discourse segmentation of multi-party conversation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>562--569</pages>
<contexts>
<context position="7598" citStr="Galley et al., 2003" startWordPosition="1166" endWordPosition="1169"> likely to share the same topic. However, HTMM only loosely models the transition between topics as a binary relation: the same as the previous sentence’s assignment or draw a new one with a certain probability. This simplified coarse modeling of dependency could not fully capture the complex structure across different documents. In contrast, our strTM model explicitly captures the regular topic transitions by postulating the first order Markov property over the topics. Another line of related work is discourse analysis in natural language processing: discourse segmentation (Sun et al., 2007; Galley et al., 2003) splits a document into a linear sequence of multi-paragraph passages, where lexical cohesion is used to link together the textual units; discourse parsing (Soricut and Marcu, 2003; Marcu, 1998) tries to uncover a more sophisticated hierarchical coherence structure from text to represent the entire discourse. One work in this line that shares a similar goal as ours is the content models (Barzilay and Lee, 2004), where an HMM is defined over text spans to perform information ordering and extractive summarization. A deficiency of the content models is that the identification of clusters of text </context>
</contexts>
<marker>Galley, McKeown, Fosler-Lussier, Jing, 2003</marker>
<rawString>M. Galley, K. McKeown, E. Fosler-Lussier, and H. Jing. 2003. Discourse segmentation of multi-party conversation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 562–569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldstein</author>
<author>V Mittal</author>
<author>J Carbonell</author>
<author>M Kantrowitz</author>
</authors>
<title>Multi-document summarization by sentence extraction.</title>
<date>2000</date>
<booktitle>In NAACL-ANLP 2000 Workshop on Automatic summarization,</booktitle>
<pages>40--48</pages>
<contexts>
<context position="28782" citStr="Goldstein et al., 2000" startWordPosition="4650" endWordPosition="4653">on confirms that when a testing document shares similar topic structure as the training data, the topical transitions captured by strTM can help the sentence annotation task a lot. In contrast, because pLSA and Naive Bayes don’t depend on the document’s structure, their performance does not change much over these two partitions. 5.4 Sentence Ordering In this experiment, we illustrate how the learned topical structure can help us better arrange sentences in a document. Sentence ordering, or text planning, is essential to many text synthesis applications, including multi-document summarization (Goldstein et al., 2000) and concept-to-text generation (Barzilay and Lapata, 2005). In strTM, we evaluate all the possible orderings of the sentences in a given document and selected the optimal one which gives the highest generation probability: ∑�σ(m) = arg max p(Sσ[0], Sσ[1],... , Sσ[m], z|0) σ(m) z (12) where σ(m) is a permutation of 1 to m, and σ[i] is the ith element in this permutation. To quantitatively evaluate the ordering result, we treated the original sentence order (OSO) as the perfect order and used Kendall’s τ(σ) (Lapata, 2006) as the evaluation metric to compute the divergency between the optimum or</context>
</contexts>
<marker>Goldstein, Mittal, Carbonell, Kantrowitz, 2000</marker>
<rawString>J. Goldstein, V. Mittal, J. Carbonell, and M. Kantrowitz. 2000. Multi-document summarization by sentence extraction. In NAACL-ANLP 2000 Workshop on Automatic summarization, pages 40–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Grenager</author>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Unsupervised learning of field segmentation models for information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd</booktitle>
<pages>371--378</pages>
<contexts>
<context position="4781" citStr="Grenager et al., 2005" startWordPosition="723" endWordPosition="726">ransition that satisfies the first order Markov property. The first assumption distinguishes the semantics of the occurrence of each word in the document, the second requirement confines the unrealistic “bag-of-word” assumption into a tighter unit, and the third assumption exploits the connection between adjacent sentences. To evaluate the usefulness of the identified topical structures by strTM, we applied strTM to the tasks of sentence annotation and sentence ordering, where correctly modeling the document structure is crucial. On the corpus of 8,031 apartment advertisements from craiglist (Grenager et al., 2005) and 1,991 movie reviews from IMDB (Zhuang et al., 2006), strTM achieved encouraging improvement in both tasks compared with the baseline methods that don’t explicitly model the topical structure. The results confirm the necessity of modeling the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in </context>
<context position="17369" citStr="Grenager et al., 2005" startWordPosition="2789" endWordPosition="2792">ponential of the first derivative of the log-gamma function. The optimal setting of π for the proportion of content topics in the documents is empirically tuned by cross-validation over the training corpus to maximize the log-likelihood. 5 Experimental Results In this section, we demonstrate the effectiveness of strTM in identifying latent topical structures from documents, and quantitatively evaluate how the mined topic transitions can help the tasks of sentence annotation and sentence ordering. 5.1 Data Set We used two different data sets for evaluation: apartment advertisements (Ads) from (Grenager et al., 2005) and movie reviews (Review) from (Zhuang et al., 2006). The Ads data consists of 8,767 advertisements for apartment rentals crawled from Craigslist website. 302 of them have been labeled with 11 fields, including size, feature, address, etc., on the sentence level. The review data contains 2,000 movie reviews discussing 11 different movies from IMDB. These reviews are manually labeled with 12 movie feature labels (We didn’t use the additional opinion annotations in this data set.) , e.g., VP (vision effects), MS (music and sound effects), etc., also on the sentences, but the annotations in the</context>
</contexts>
<marker>Grenager, Klein, Manning, 2005</marker>
<rawString>T. Grenager, D. Klein, and C.D. Manning. 2005. Unsupervised learning of field segmentation models for information extraction. In Proceedings of the 43rd annual meeting on association for computational linguistics, pages 371–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Griffiths</author>
<author>M Steyvers</author>
<author>D M Blei</author>
<author>J B Tenenbaum</author>
</authors>
<title>Integrating topics and syntax. Advances in neural information processing systems,</title>
<date>2005</date>
<pages>17--537</pages>
<contexts>
<context position="5827" citStr="Griffiths et al., 2005" startWordPosition="882" endWordPosition="885">ully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is loosely governed by the prior topic distribution, e.g., Dirichlet distribution. Some work has attempted to capture the interrelationship among the latent topics. Correlated Topic Model (Blei and Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependencies from long-range semantic dependencies among the words in each document. But in HMM-LDA, only the latent variables for the syntactic classes are treated as a locally dependent sequence, while latent topics are treated the same as in other topic models. Chen et al. introduced the generalized Mallows model to constrain the latent topic assignments (Chen et al., 2009). In their model, they assume there exists a canonical order among the topics in the collection of related documents and the same topics are forced not to appear in disconnected po</context>
</contexts>
<marker>Griffiths, Steyvers, Blei, Tenenbaum, 2005</marker>
<rawString>T.L. Griffiths, M. Steyvers, D.M. Blei, and J.B. Tenenbaum. 2005. Integrating topics and syntax. Advances in neural information processing systems, 17:537– 544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Gruber</author>
<author>Yair Weiss</author>
<author>Michal Rosen-Zvi</author>
</authors>
<title>Hidden topic markov models.</title>
<date>2007</date>
<volume>2</volume>
<pages>163--170</pages>
<contexts>
<context position="3256" citStr="Gruber et al., 2007" startWordPosition="485" endWordPosition="489">results, but, more importantly, also help many other document analysis tasks, such as sentence annotation and sentence ordering. Nevertheless, very few existing topic models attempted to model such structural dependency among topics. The Aspect HMM model introduced in (Blei and Moreno, 2001) combines pLSA (Hofmann, 1999) with HMM (Rabiner, 1989) to perform document segmentation over text streams. However, Aspect HMM separately estimates the topics in the training set and depends on heuristics to infer the transitional relations between topics. The Hidden Topic Markov Model (HTMM) proposed by (Gruber et al., 2007) extends the traditional topic models by assuming words in each sentence share the same topic assignment, and topics transit between adjacent sentences. However, the transitional structures among topics, i.e., how likely one topic would follow another topic, are not captured in this model. 1526 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1526–1535, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics In this paper, we propose a new topic model, named Structural Topic Model (strTM) to model and analyze both laten</context>
<context position="6803" citStr="Gruber et al., 2007" startWordPosition="1038" endWordPosition="1041">el to constrain the latent topic assignments (Chen et al., 2009). In their model, they assume there exists a canonical order among the topics in the collection of related documents and the same topics are forced not to appear in disconnected portions of the topic sequence in one document (sampling without replacement). Our method relaxes this assumption by only postulating transitional dependency between topics in the adjacent sentences (sampling with replacement) and thus potentially allows a topic to appear multiple times in disconnected segments. As discussed in the previous section, HTMM (Gruber et al., 2007) is the most similar model to ours. HTMM models the document structure by assuming words in the same sentence share the same topic assignment and successive sentences are more likely to share the same topic. However, HTMM only loosely models the transition between topics as a binary relation: the same as the previous sentence’s assignment or draw a new one with a certain probability. This simplified coarse modeling of dependency could not fully capture the complex structure across different documents. In contrast, our strTM model explicitly captures the regular topic transitions by postulating</context>
<context position="21524" citStr="Gruber et al., 2007" startWordPosition="3464" endWordPosition="3467">it to 0.01 in the experiment. ¯p(z|z′) = c(z, z′) + δ (9) c(z) + kδ The KL divergency between two transition matrices is defined in Eq(10). Because we have a k x k transition matrix (Tstart is not included), we calculated the average KL divergency against the groundtruth over all the topics: ∑� ��1 KL(p(z|z′ �)||�p(z|z′ �))+KL(�p(z|z′ �)||p(z|z′ �)) avgKL= 2k (10) where ¯p(z|z′) is the ground-truth transition probability estimated by Eq(9), and p(z|z′) is the transition probability given by the model. We used pLSA (Hofmann, 1999), latent permutation model (lPerm) (Chen et al., 2009) and HTMM (Gruber et al., 2007) as the baseline methods for the comparison. Because none of these three methods can generate a topic transition matrix directly, we extended them a little bit to achieve this goal. For pLSA, we used the document-level labels as priors for the topic distribution in each document, so that the estimated topics can be aligned with the predefined class labels. After the topics were estimated, for each sentence we selected the topic that had the highest posterior probability to generate the sentence as its class label. For lPerm and HTMM, we used Kuhn-Munkres algorithm (Lov´asz and Plummer, 1986) t</context>
</contexts>
<marker>Gruber, Weiss, Rosen-Zvi, 2007</marker>
<rawString>Amit Gruber, Yair Weiss, and Michal Rosen-Zvi. 2007. Hidden topic markov models. volume 2, pages 163– 170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="1249" citStr="Hofmann, 1999" startWordPosition="176" endWordPosition="177">s tasks. In this work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Ble</context>
<context position="2958" citStr="Hofmann, 1999" startWordPosition="441" endWordPosition="443">tisements for their apartments, it’s natural to first introduce “size” and “address” of the apartment, and then “rent” and “contact”. Few people would talk about “restriction” first. If this kind of topical structures are captured by a topic model, it would not only improve the topic mining results, but, more importantly, also help many other document analysis tasks, such as sentence annotation and sentence ordering. Nevertheless, very few existing topic models attempted to model such structural dependency among topics. The Aspect HMM model introduced in (Blei and Moreno, 2001) combines pLSA (Hofmann, 1999) with HMM (Rabiner, 1989) to perform document segmentation over text streams. However, Aspect HMM separately estimates the topics in the training set and depends on heuristics to infer the transitional relations between topics. The Hidden Topic Markov Model (HTMM) proposed by (Gruber et al., 2007) extends the traditional topic models by assuming words in each sentence share the same topic assignment, and topics transit between adjacent sentences. However, the transitional structures among topics, i.e., how likely one topic would follow another topic, are not captured in this model. 1526 Procee</context>
<context position="21439" citStr="Hofmann, 1999" startWordPosition="3451" endWordPosition="3452"> immediately precede one annotated by z. δ is a smoothing factor, and we fixed it to 0.01 in the experiment. ¯p(z|z′) = c(z, z′) + δ (9) c(z) + kδ The KL divergency between two transition matrices is defined in Eq(10). Because we have a k x k transition matrix (Tstart is not included), we calculated the average KL divergency against the groundtruth over all the topics: ∑� ��1 KL(p(z|z′ �)||�p(z|z′ �))+KL(�p(z|z′ �)||p(z|z′ �)) avgKL= 2k (10) where ¯p(z|z′) is the ground-truth transition probability estimated by Eq(9), and p(z|z′) is the transition probability given by the model. We used pLSA (Hofmann, 1999), latent permutation model (lPerm) (Chen et al., 2009) and HTMM (Gruber et al., 2007) as the baseline methods for the comparison. Because none of these three methods can generate a topic transition matrix directly, we extended them a little bit to achieve this goal. For pLSA, we used the document-level labels as priors for the topic distribution in each document, so that the estimated topics can be aligned with the predefined class labels. After the topics were estimated, for each sentence we selected the topic that had the highest posterior probability to generate the sentence as its class la</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Automated discourse generation using discourse structure relations.</title>
<date>1993</date>
<journal>Artificial intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="2111" citStr="Hovy, 1993" startWordPosition="311" endWordPosition="312">, 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e., the document generation probabilities are invariant to content permutation. In reality, natural language text rarely consists of isolated, unrelated sentences, but rather collocated, structured and coherent groups of sentences (Hovy, 1993). Ignoring such latent topical structures inside the documents means wasting valuable clues about topics and thus would lead to non-optimal topic modeling. Taking apartment rental advertisements as an example, when people write advertisements for their apartments, it’s natural to first introduce “size” and “address” of the apartment, and then “rent” and “contact”. Few people would talk about “restriction” first. If this kind of topical structures are captured by a topic model, it would not only improve the topic mining results, but, more importantly, also help many other document analysis task</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>E.H. Hovy. 1993. Automated discourse generation using discourse structure relations. Artificial intelligence, 63(1-2):341–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>Why doesn’t EM find good HMM POS-taggers.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>296--305</pages>
<contexts>
<context position="15413" citStr="Johnson, 2007" startWordPosition="2475" endWordPosition="2476"> sentence s. Eq(4) can be easily explained as follows. Since we already observe topic z and sentence s cooccur with probability p(s, z|d, O), each word w in s should share the same probability of being observed with content topic z. Thus the expected count of c(z, w) in this sentence would be p(s, z|d, O)c(w, s). However, since each sentence is also associated with the functional topic zB, the word w may also be drawn from zB. By applying the Bayes’ rule, we can properly reallocate the expected count of c(z, w) by Eq(4). The same strategy can be applied to obtain E[c(zB, w)]. As discussed in (Johnson, 2007), to avoid the problem that EM algorithm tends to assign a uniform word/state distribution to each hidden state, which deviates from the heavily skewed word/state distributions empirically observed, we can apply a Bayesian estimation approach for strTM. Thus we introduce prior distributions over the topic transition Mul(αz′) and emission probabilities Mul(Qz), and use the Variational Bayesian (VB) (Jordan et al., 1999) estimator to obtain a model with more skewed word/state distributions. Since both the topic transition and emission probabilities are Multinomial distributions in strTM, the con</context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>M. Johnson. 2007. Why doesn’t EM find good HMM POS-taggers. In Proceedings of the 2007Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 296–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M I Jordan</author>
<author>Z Ghahramani</author>
<author>T S Jaakkola</author>
<author>L K Saul</author>
</authors>
<title>An introduction to variational methods for graphical models.</title>
<date>1999</date>
<journal>Machine learning,</journal>
<volume>37</volume>
<issue>2</issue>
<pages>233</pages>
<contexts>
<context position="15835" citStr="Jordan et al., 1999" startWordPosition="2536" endWordPosition="2539">drawn from zB. By applying the Bayes’ rule, we can properly reallocate the expected count of c(z, w) by Eq(4). The same strategy can be applied to obtain E[c(zB, w)]. As discussed in (Johnson, 2007), to avoid the problem that EM algorithm tends to assign a uniform word/state distribution to each hidden state, which deviates from the heavily skewed word/state distributions empirically observed, we can apply a Bayesian estimation approach for strTM. Thus we introduce prior distributions over the topic transition Mul(αz′) and emission probabilities Mul(Qz), and use the Variational Bayesian (VB) (Jordan et al., 1999) estimator to obtain a model with more skewed word/state distributions. Since both the topic transition and emission probabilities are Multinomial distributions in strTM, the conjugate Dirichlet distribution is the natural E[c(z, w)] _ ∑ d,sEd 1529 choice for imposing a prior on them (Diaconis and Ylvisaker, 1979). Thus, we further assume: αz — Dir(η) (5) βz — Dir(γ) (6) where we use exchangeable Dirichlet distributions to control the sparsity of αz and βz. As η and γ approach zero, the prior strongly favors the models in which each hidden state emits as few words/states as possible. In our ex</context>
</contexts>
<marker>Jordan, Ghahramani, Jaakkola, Saul, 1999</marker>
<rawString>M.I. Jordan, Z. Ghahramani, T.S. Jaakkola, and L.K. Saul. 1999. An introduction to variational methods for graphical models. Machine learning, 37(2):183– 233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
</authors>
<title>A theory of truth and semantic representation. Formal methods in the study of language,</title>
<date>1981</date>
<pages>1--277</pages>
<contexts>
<context position="8760" citStr="Kamp, 1981" startWordPosition="1349" endWordPosition="1350">s is that the identification of clusters of text spans is done separately from transition modeling. Our strTM addresses this deficiency by defining a generative process to simultaneously capture the topics and the transitional re1527 lationship among topics: allowing topic modeling and transition modeling to reinforce each other in a principled framework. 3 Structural Topic Model In this section, we formally define the Structural Topic Model (strTM) and discuss how it captures the latent topics and topical structures within the documents simultaneously. From the theory of linguistic analysis (Kamp, 1981), we know that document exhibits internal structures, where structural segments encapsulate semantic units that are closely related. In strTM, we treat a sentence as the basic structure unit, and assume all the words in a sentence share the same topical aspect. Besides, two adjacent segments are assumed to be highly related (capturing cohesion in text); specifically, in strTM we pose a strong transitional dependency assumption among the topics: the choice of topic for each sentence directly depends on the previous sentence’s topic assignment, i.e., first order Markov property. Moveover, taking</context>
</contexts>
<marker>Kamp, 1981</marker>
<rawString>H. Kamp. 1981. A theory of truth and semantic representation. Formal methods in the study of language, 1:277–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
</authors>
<title>Automatic evaluation of information ordering: Kendall’s tau.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="29308" citStr="Lapata, 2006" startWordPosition="4739" endWordPosition="4740">synthesis applications, including multi-document summarization (Goldstein et al., 2000) and concept-to-text generation (Barzilay and Lapata, 2005). In strTM, we evaluate all the possible orderings of the sentences in a given document and selected the optimal one which gives the highest generation probability: ∑�σ(m) = arg max p(Sσ[0], Sσ[1],... , Sσ[m], z|0) σ(m) z (12) where σ(m) is a permutation of 1 to m, and σ[i] is the ith element in this permutation. To quantitatively evaluate the ordering result, we treated the original sentence order (OSO) as the perfect order and used Kendall’s τ(σ) (Lapata, 2006) as the evaluation metric to compute the divergency between the optimum ordering given by the model and OSO. Kendall’s τ(σ) is widely used in information retrieval domain to measure the correlation between two ranked lists and it indicates how much an ordering differs from OSO, which ranges from 1 (perfect matching) to -1 (totally mismatching). Since only the HTMM and lPerm take the order of sentences in the document into consideration, we used them as the baselines in this experiment. We ranked OSO together with candidate permutations according to the corresponding model’s generation probabil</context>
</contexts>
<marker>Lapata, 2006</marker>
<rawString>M. Lapata. 2006. Automatic evaluation of information ordering: Kendall’s tau. Computational Linguistics, 32(4):471–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lov´asz</author>
<author>M D Plummer</author>
</authors>
<title>Matching theory.</title>
<date>1986</date>
<publisher>Elsevier Science Ltd.</publisher>
<marker>Lov´asz, Plummer, 1986</marker>
<rawString>L. Lov´asz and M.D. Plummer. 1986. Matching theory. Elsevier Science Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lu</author>
<author>C Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th international conference on World Wide Web,</booktitle>
<pages>121--130</pages>
<contexts>
<context position="1526" citStr="Lu and Zhai, 2008" startWordPosition="218" endWordPosition="221">show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e., the document generation probabilities are invariant to content permutation. In reality, natural language text rarely consists of isolated, unrelated sentences, but rather collocated, structured and coherent groups of sentences (Hovy, 1993). Ignoring such</context>
<context position="5322" citStr="Lu and Zhai, 2008" startWordPosition="805" endWordPosition="808">rpus of 8,031 apartment advertisements from craiglist (Grenager et al., 2005) and 1,991 movie reviews from IMDB (Zhuang et al., 2006), strTM achieved encouraging improvement in both tasks compared with the baseline methods that don’t explicitly model the topical structure. The results confirm the necessity of modeling the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is loosely governed by the prior topic distribution, e.g., Dirichlet distribution. Some work has attempted to capture the interrelationship among the latent topics. Correlated Topic Model (Blei and Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependencies from long-range semantic dependencies amo</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Y. Lu and C. Zhai. 2008. Opinion integration through semi-supervised topic modeling. In Proceeding of the 17th international conference on World Wide Web, pages 121–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The rhetorical parsing of natural language texts.</title>
<date>1998</date>
<booktitle>In ACL ’98,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="7792" citStr="Marcu, 1998" startWordPosition="1198" endWordPosition="1199">bability. This simplified coarse modeling of dependency could not fully capture the complex structure across different documents. In contrast, our strTM model explicitly captures the regular topic transitions by postulating the first order Markov property over the topics. Another line of related work is discourse analysis in natural language processing: discourse segmentation (Sun et al., 2007; Galley et al., 2003) splits a document into a linear sequence of multi-paragraph passages, where lexical cohesion is used to link together the textual units; discourse parsing (Soricut and Marcu, 2003; Marcu, 1998) tries to uncover a more sophisticated hierarchical coherence structure from text to represent the entire discourse. One work in this line that shares a similar goal as ours is the content models (Barzilay and Lee, 2004), where an HMM is defined over text spans to perform information ordering and extractive summarization. A deficiency of the content models is that the identification of clusters of text spans is done separately from transition modeling. Our strTM addresses this deficiency by defining a generative process to simultaneously capture the topics and the transitional re1527 lationshi</context>
</contexts>
<marker>Marcu, 1998</marker>
<rawString>Daniel Marcu. 1998. The rhetorical parsing of natural language texts. In ACL ’98, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
<author>C X Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="1506" citStr="Mei et al., 2007" startWordPosition="214" endWordPosition="217">xperiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. 1 Introduction A great amount of effort has recently been made in applying statistical topic models (Hofmann, 1999; Blei et al., 2003) to explore word co-occurrence patterns, i.e. topics, embedded in documents. Topic models have become important building blocks of many interesting applications (see e.g., (Blei and Jordan, 2003; Blei and Lafferty, 2007; Mei et al., 2007; Lu and Zhai, 2008)). In general, topic models can discover word clustering patterns in documents and project each document to a latent topic space formed by such word clusters. However, the topical structure in a document, i.e., the internal dependency between the topics, is generally not captured due to the exchangeability assumption (Blei et al., 2003), i.e., the document generation probabilities are invariant to content permutation. In reality, natural language text rarely consists of isolated, unrelated sentences, but rather collocated, structured and coherent groups of sentences (Hovy, </context>
<context position="5278" citStr="Mei et al., 2007" startWordPosition="799" endWordPosition="802">he document structure is crucial. On the corpus of 8,031 apartment advertisements from craiglist (Grenager et al., 2005) and 1,991 movie reviews from IMDB (Zhuang et al., 2006), strTM achieved encouraging improvement in both tasks compared with the baseline methods that don’t explicitly model the topical structure. The results confirm the necessity of modeling the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is loosely governed by the prior topic distribution, e.g., Dirichlet distribution. Some work has attempted to capture the interrelationship among the latent topics. Correlated Topic Model (Blei and Lafferty, 2007) replaces Dirichlet prior with logistic Normal prior for topic distribution in each document in order to capture the correlation between the topics. HMM-LDA (Griffiths et al., 2005) distinguishes the short-range syntactic dependenci</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the 16th international conference on World Wide Web, pages 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>77--2</pages>
<contexts>
<context position="2983" citStr="Rabiner, 1989" startWordPosition="446" endWordPosition="447">ments, it’s natural to first introduce “size” and “address” of the apartment, and then “rent” and “contact”. Few people would talk about “restriction” first. If this kind of topical structures are captured by a topic model, it would not only improve the topic mining results, but, more importantly, also help many other document analysis tasks, such as sentence annotation and sentence ordering. Nevertheless, very few existing topic models attempted to model such structural dependency among topics. The Aspect HMM model introduced in (Blei and Moreno, 2001) combines pLSA (Hofmann, 1999) with HMM (Rabiner, 1989) to perform document segmentation over text streams. However, Aspect HMM separately estimates the topics in the training set and depends on heuristics to infer the transitional relations between topics. The Hidden Topic Markov Model (HTMM) proposed by (Gruber et al., 2007) extends the traditional topic models by assuming words in each sentence share the same topic assignment, and topics transit between adjacent sentences. However, the transitional structures among topics, i.e., how likely one topic would follow another topic, are not captured in this model. 1526 Proceedings of the 49th Annual </context>
<context position="13877" citStr="Rabiner, 1989" startWordPosition="2203" endWordPosition="2204">the multiplication of such probabilities. This result is reasonable, especially in a long document, since neighboring sentences are more likely to cover similar topics than two sentences far apart. 4 Posterior Inference and Parameter Estimation The chain structure in strTM enables us to perform exact inference: posterior distribution can be efficiently calculated by the forward-backward algorithm, the optimal topic sequence can be inferred using the Viterbi algorithm, and parameter estimation can be solved by the Expectation Maximization (EM) algorithm. More technical details can be found in (Rabiner, 1989). In this section, we only discuss strTM-specific procedures. In the E-Step of EM algorithm, we need to collect the expected count of a sequential topic pair (z, z′) and a topic-word pair (z, w) to update the model parameters α and Q in the M-Step. In strTM, E[c(z, z′)] can be easily calculated by forwardbackward algorithm. But we have to go one step further to fetch the required sufficient statistics for E[c(z, w)], because our emission probabilities are defined over sentences. Through forward-backward algorithm, we can get the posterior probability p(si, z|d, O). In strTM, words in one sente</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L.R. Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Soricut</author>
<author>D Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the NAACLHTC,</booktitle>
<pages>149--156</pages>
<contexts>
<context position="7778" citStr="Soricut and Marcu, 2003" startWordPosition="1194" endWordPosition="1197">ew one with a certain probability. This simplified coarse modeling of dependency could not fully capture the complex structure across different documents. In contrast, our strTM model explicitly captures the regular topic transitions by postulating the first order Markov property over the topics. Another line of related work is discourse analysis in natural language processing: discourse segmentation (Sun et al., 2007; Galley et al., 2003) splits a document into a linear sequence of multi-paragraph passages, where lexical cohesion is used to link together the textual units; discourse parsing (Soricut and Marcu, 2003; Marcu, 1998) tries to uncover a more sophisticated hierarchical coherence structure from text to represent the entire discourse. One work in this line that shares a similar goal as ours is the content models (Barzilay and Lee, 2004), where an HMM is defined over text spans to perform information ordering and extractive summarization. A deficiency of the content models is that the identification of clusters of text spans is done separately from transition modeling. Our strTM addresses this deficiency by defining a generative process to simultaneously capture the topics and the transitional re</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>R. Soricut and D. Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Conference of the NAACLHTC, pages 149–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Sun</author>
<author>P Mitra</author>
<author>C L Giles</author>
<author>J Yen</author>
<author>H Zha</author>
</authors>
<title>Topic segmentation with shared topic detection and alignment of multiple documents.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th ACM SIGIR,</booktitle>
<pages>199--206</pages>
<contexts>
<context position="7576" citStr="Sun et al., 2007" startWordPosition="1162" endWordPosition="1165">sentences are more likely to share the same topic. However, HTMM only loosely models the transition between topics as a binary relation: the same as the previous sentence’s assignment or draw a new one with a certain probability. This simplified coarse modeling of dependency could not fully capture the complex structure across different documents. In contrast, our strTM model explicitly captures the regular topic transitions by postulating the first order Markov property over the topics. Another line of related work is discourse analysis in natural language processing: discourse segmentation (Sun et al., 2007; Galley et al., 2003) splits a document into a linear sequence of multi-paragraph passages, where lexical cohesion is used to link together the textual units; discourse parsing (Soricut and Marcu, 2003; Marcu, 1998) tries to uncover a more sophisticated hierarchical coherence structure from text to represent the entire discourse. One work in this line that shares a similar goal as ours is the content models (Barzilay and Lee, 2004), where an HMM is defined over text spans to perform information ordering and extractive summarization. A deficiency of the content models is that the identificatio</context>
</contexts>
<marker>Sun, Mitra, Giles, Yen, Zha, 2007</marker>
<rawString>B. Sun, P. Mitra, C.L. Giles, J. Yen, and H. Zha. 2007. Topic segmentation with shared topic detection and alignment of multiple documents. In Proceedings of the 30th ACM SIGIR, pages 199–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>Atulya Velivelli</author>
<author>Bei Yu</author>
</authors>
<title>A cross-collection mixture model for comparative text minning.</title>
<date>2004</date>
<booktitle>In Proceeding of the 10th ACM SIGKDD international conference on Knowledge discovery in data mining,</booktitle>
<pages>743--748</pages>
<contexts>
<context position="9698" citStr="Zhai et al., 2004" startWordPosition="1498" endWordPosition="1501">lated (capturing cohesion in text); specifically, in strTM we pose a strong transitional dependency assumption among the topics: the choice of topic for each sentence directly depends on the previous sentence’s topic assignment, i.e., first order Markov property. Moveover, taking the insights from HMM-LDA that not all the words are content conveying (some of them may just be a result of syntactic requirement), we introduce a dummy functional topic zB for every sentence in the document. We use this functional topic to capture the document-independent word distribution, i.e., corpus background (Zhai et al., 2004). As a result, in strTM, every sentence is treated as a mixture of content and functional topics. Formally, we assume a corpus consists of D documents with a vocabulary of size V, and there are k content topics embedded in the corpus. In a given document d, there are m sentences and each sentence i has Ni words. We assume the topic transition probability p(zIz′) is drawn from a Multinomial distribution Mul(αz′), and the word emission probability under each topic p(wlz) is drawn from a Multinomial distribution Mul(βz). To get a unified description of the generation process, we add another dummy</context>
</contexts>
<marker>Zhai, Velivelli, Yu, 2004</marker>
<rawString>ChengXiang Zhai, Atulya Velivelli, and Bei Yu. 2004. A cross-collection mixture model for comparative text minning. In Proceeding of the 10th ACM SIGKDD international conference on Knowledge discovery in data mining, pages 743–748.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zhuang</author>
<author>F Jing</author>
<author>X Y Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international conference on Information and knowledge management,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="4837" citStr="Zhuang et al., 2006" startWordPosition="733" endWordPosition="736">The first assumption distinguishes the semantics of the occurrence of each word in the document, the second requirement confines the unrealistic “bag-of-word” assumption into a tighter unit, and the third assumption exploits the connection between adjacent sentences. To evaluate the usefulness of the identified topical structures by strTM, we applied strTM to the tasks of sentence annotation and sentence ordering, where correctly modeling the document structure is crucial. On the corpus of 8,031 apartment advertisements from craiglist (Grenager et al., 2005) and 1,991 movie reviews from IMDB (Zhuang et al., 2006), strTM achieved encouraging improvement in both tasks compared with the baseline methods that don’t explicitly model the topical structure. The results confirm the necessity of modeling the latent topical structures inside documents, and also demonstrate the advantages of the proposed strTM over existing topic models. 2 Related Work Topic models have been successfully applied to many problems, e.g., sentiment analysis (Mei et al., 2007), document summarization (Lu and Zhai, 2008) and image annotation (Blei and Jordan, 2003). However, in most existing work, the dependency among the topics is l</context>
<context position="17423" citStr="Zhuang et al., 2006" startWordPosition="2798" endWordPosition="2801">ion. The optimal setting of π for the proportion of content topics in the documents is empirically tuned by cross-validation over the training corpus to maximize the log-likelihood. 5 Experimental Results In this section, we demonstrate the effectiveness of strTM in identifying latent topical structures from documents, and quantitatively evaluate how the mined topic transitions can help the tasks of sentence annotation and sentence ordering. 5.1 Data Set We used two different data sets for evaluation: apartment advertisements (Ads) from (Grenager et al., 2005) and movie reviews (Review) from (Zhuang et al., 2006). The Ads data consists of 8,767 advertisements for apartment rentals crawled from Craigslist website. 302 of them have been labeled with 11 fields, including size, feature, address, etc., on the sentence level. The review data contains 2,000 movie reviews discussing 11 different movies from IMDB. These reviews are manually labeled with 12 movie feature labels (We didn’t use the additional opinion annotations in this data set.) , e.g., VP (vision effects), MS (music and sound effects), etc., also on the sentences, but the annotations in the review data set is much sparser than that in the Ads </context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>L. Zhuang, F. Jing, and X.Y. Zhu. 2006. Movie review mining and summarization. In Proceedings of the 15th ACM international conference on Information and knowledge management, pages 43–50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>