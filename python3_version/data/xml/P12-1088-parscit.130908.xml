<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000169">
<title confidence="0.905648">
Automatic Event Extraction with Structured Preference Modeling
</title>
<author confidence="0.99312">
Wei Lu and Dan Roth
</author>
<affiliation confidence="0.99627">
University of Illinois at Urbana-Champaign
</affiliation>
<email confidence="0.995948">
{luwei,danr}@illinois.edu
</email>
<sectionHeader confidence="0.994737" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999843043478261">
This paper presents a novel sequence label-
ing model based on the latent-variable semi-
Markov conditional random fields for jointly
extracting argument roles of events from texts.
The model takes in coarse mention and type
information and predicts argument roles for a
given event template.
This paper addresses the event extraction
problem in a primarily unsupervised setting,
where no labeled training instances are avail-
able. Our key contribution is a novel learning
framework called structured preference mod-
eling (PM), that allows arbitrary preference
to be assigned to certain structures during the
learning procedure. We establish and discuss
connections between this framework and other
existing works. We show empirically that the
structured preferences are crucial to the suc-
cess of our task. Our model, trained with-
out annotated data and with a small number
of structured preferences, yields performance
competitive to some baseline supervised ap-
proaches.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999219">
Automatic template-filling-based event extraction is
an important and challenging task. Consider the fol-
lowing text span that describes an “Attack” event:
</bodyText>
<construct confidence="0.7142666">
... North Korea’s military may have fired a laser
at a U.S. helicopter in March, a U.S. official
said Tuesday, as the communist state ditched its
last legal obligation to keep itselffree of nuclear
weapons ...
</construct>
<bodyText confidence="0.995371307692308">
A partial event template for the “Attack” event is
shown on the left of Figure 1. Each row shows an
argument for the event, together with a set of its ac-
ceptable mention types, where the type specifies a
high-level semantic class a mention belongs to.
The task is to automatically fill the template en-
tries with texts extracted from the text span above.
The correct filling of the template for this particular
example is shown on the right of Figure 1.
Performing such a task without any knowledge
about the semantics of the texts is hard. One typi-
cal assumption is that certain coarse mention-level
information, such as mention boundaries and their
semantic class (a.k.a. types), are available. E.g.:
... [North Korea’s military]ORG may have fired
[a laser]WEA at [a U.S. helicopter]VEH in
[March]TME, a U.S. official said Tuesday, as the
communist state ditched its last legal obligation
to keep itselffree of nuclear weapons ...
Such mention type information as shown on the
left of Figure 1 can be obtained from various sources
such as dictionaries, gazetteers, rule-based systems
(Str¨otgen and Gertz, 2010), statistically trained clas-
sifiers (Ratinov and Roth, 2009), or some web re-
sources such as Wikipedia (Ratinov et al., 2011).
However, in practice, outputs from existing men-
tion identification and typing systems can be far
from ideal. Instead of obtaining the above ideal an-
notation, one might observe the following noisy and
ambiguous annotation for the given event span:
... [[North Korea’s]GPE|LOC military]ORG may have
fired a laser at [a [U.S.]GPE|LOC helicopter]VEH
in [March]TME, [a [U.S.]GPEILOC official]PER said
[Tuesday]TME, as [the communist state]ORG|FAC|LOC
ditched its last legal obligation to keep [itself]ORG
free of [nuclear weapons]WEA ...
Our task is to design a model to effectively select
mentions in an event span and assign them with cor-
responding argument information, given such coarse
</bodyText>
<page confidence="0.980509">
835
</page>
<note confidence="0.989896461538461">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 835–844,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
Argument Possible Types Extracted Text
ATTACKER GPE, ORG, PER N. Korea’s military
INSTRUMENT
PLACE
TIME-WITHIN
VEH, WEA a laser
FAC, GPE, LOC -
TARGET a U.S. helicopter
FAC, GPE, LOC
ORG, PER, VEH
TME March
</note>
<figureCaption confidence="0.9986525">
Figure 1: The partial event template for the Attack event (left),
and the correct event template annotation for the example event
span given in Sec 1 (right). We primarily follow the ACE stan-
dard in defining arguments and types.
</figureCaption>
<bodyText confidence="0.983962666666667">
and often noisy mention type annotations.
This work addresses this problem by making the
following contributions:
</bodyText>
<listItem confidence="0.870466772727273">
• Naturally, we are interested in identifying the
active mentions (the mentions that serve as ar-
guments) and their correct boundaries from the
data. This motivates us to build a novel latent-
variable semi-Markov conditional random fields
model (Sarawagi and Cohen, 2004) for such an
event extraction task. The learned model takes
in coarse information as produced by existing
mention identification and typing modules, and
jointly outputs selected mentions and their cor-
responding argument roles.
• We address the problem in a more realistic sce-
nario where annotated training instances are not
available. We propose a novel general learning
framework called structured preference model-
ing (or preference modeling, PM), which en-
compasses both the fully supervised and the
latent-variable conditional models as special
cases. The framework allows arbitrary declar-
ative structured preference knowledge to be in-
troduced to guide the learning procedure in a pri-
marily unsupervised setting.
</listItem>
<bodyText confidence="0.99885125">
We present our semi-Markov model and discuss
our preference modeling framework in Section 2 and
3 respectively. We then discuss the model’s relation
with existing constraint-driven learning frameworks
in Section 4. Finally, we demonstrate through ex-
periments that structured preference information is
crucial to model and present empirical results on a
standard dataset in Section 5.
</bodyText>
<sectionHeader confidence="0.995744" genericHeader="method">
2 The Model
</sectionHeader>
<bodyText confidence="0.964594">
It is not hard to observe from the example presented
in the previous section that dependencies between
</bodyText>
<figureCaption confidence="0.663399">
Figure 2: A simplified graphical illustration for the semi-
Markov CRF, under a specific segmentation S = C1C2 ... Com,.
In a supervised setting, only correct arguments are observed but
their associated correct mention types are hidden (shaded).
</figureCaption>
<bodyText confidence="0.999906457142857">
arguments can be important and need to be properly
modeled. This motivates us to build a joint model
for extracting the event structures from the text.
We show a simplified graphical representation of
our model in Figure 2. In the graph, C1, C2 ... C,,,
refer to a particular segmentation of the event
span, where C1, C3 ... correspond to mentions
(e.g., “North Korea’s military”, “a laser”) and C2,
C4 ... correspond to in-between mention word se-
quences (we call them gaps) (e.g., “may have
fired”). The symbols T1, T3 ... refer to mention
types (e.g., GPE, ORG). The symbols A1, A3 ... re-
fer to event arguments that carry specific roles (e.g.,
ATTACKER). We also introduce symbols B2, B4 ...
to refer to inter-argument gaps. The event span is
split into segments, where each segment is either
linked to a mention type (Ti; these segments can
be referred to as “argument segments”), or directly
linked to an inter-argument gap (B3; they can be
referred to as “gap segments”). The two types of
segments appear in the sequence in a strictly alter-
nate manner, where the gaps can be of length zero.
In the figure, for example, the segments C1 and C3
are identified as two argument segments (which are
mentions of types T1 and T3 respectively) and are
mapped to two “nodes”, and the segment C2 is iden-
tified as a gap segment that connects the two argu-
ments A1 and A3. Note that no overlapping argu-
ments are allowed in this model 1.
We use s to denote an event span and t to denote
a specific realization (filling) of the event template.
Templates consist of a set of arguments. Denote by h
a particular mention boundary and type assignment
for an event span, which gives us a specific segmen-
tation of the given span. Following the conditional
</bodyText>
<footnote confidence="0.9873845">
1Extending the model to support certain argument overlap-
ping is possible – we leave it for future work.
</footnote>
<figure confidence="0.9722768">
C1
C2
C3
C4
A1
B2
A3
T1
T3
B4
. . .
. . .
C.
Ate,
T.
</figure>
<page confidence="0.99786">
836
</page>
<bodyText confidence="0.999675666666667">
random fields model (Lafferty et al., 2001), we pa-
rameterize the conditional probability of the (t, h)
pair given an event span s as follows:
</bodyText>
<equation confidence="0.9862585">
Pp(t, h |s)
ef(s,h,t)·p =
P (1)
t,h ef(s,h,t)·p
</equation>
<bodyText confidence="0.9999106">
where f gives the feature functions defined on the
tuple (s, h, t), and Θ defines the parameter vector.
Our objective function is the logarithm of the joint
conditional probability of observing the template re-
alization for the observed event span s:
</bodyText>
<equation confidence="0.9982764">
L(Θ) = X log Pp(ti|si)
i
X=
i log Pt,h ef(si,h,t)·p (2)
Ph ef(si,h,ti)·p
</equation>
<bodyText confidence="0.998964611111111">
This function is not convex due to the summation
over the hidden variable h. To optimize it, we take
its partial derivative with respect to 0j:
Ep®(h|si,ti)[fj(si, h, ti)]
Ep®(t,h|si)[fj(si, h, t)] (3)
which requires computation of expectations terms
under two different distributions. Such statistics
can be collected efficiently with a forward-backward
style algorithm in polynomial time (Okanohara et
al., 2006). We will discuss the time complexity for
our case in the next section.
Given its partial derivatives in Equation 3, one
could optimize the objective function of Equation 2
with stochastic gradient ascent (LeCun et al., 1998)
or L-BFGS (Liu and Nocedal, 1989). We choose to
use L-BFGS for all our experiments in this paper.
Inference involves computing the most probable
template realization t for a given event span:
</bodyText>
<equation confidence="0.817185333333333">
arg max
t XPp(t|s) = arg max
t h Pp(t, h|s) (4)
</equation>
<bodyText confidence="0.999969333333333">
where the possible hidden assignments h need to be
marginalized out. In this task, a particular realiza-
tion t already uniquely defines a particular segmen-
tation (mention boundaries) of the event span, thus
the h only contributes type information to t. As we
will discuss in Section 2.3, only a collection of local
features are defined. Thus, a Viterbi-style dynamic
programming algorithm is used to efficiently com-
pute the desired solution.
</bodyText>
<subsectionHeader confidence="0.997252">
2.1 Possible Segmentations
</subsectionHeader>
<bodyText confidence="0.999994695652174">
According to Equation 3, summing over all possi-
ble h is required. Since one primary assumption is
that we have access to the output of existing mention
identification and typing systems, the set of all possi-
ble mentions defines a lattice representation contain-
ing the set of all possible segmentations that com-
ply with such mention-level information. Assuming
there are A possible arguments for the event and K
annotated mentions, the complexity of the forward-
backward style algorithm is in O(A3K2) under the
“second-order” setting that we will discuss in Sec-
tion 2.2. Typically, K is smaller than the number of
words in the span, and the factor A3 can be regarded
as a constant. Thus, the algorithm is very efficient.
As we have mentioned earlier, such coarse infor-
mation, as produced by existing resources, could be
highly ambiguous and noisy. Also, the output men-
tions can highly overlap with each other. For exam-
ple, the phrase “North Korea” as in “North Korea’s
military” can be assigned both type GPE and LOC,
while “North Korea’s military” can be assigned the
type ORG. Our model will need to disambiguate the
mention boundaries as well as their types.
</bodyText>
<subsectionHeader confidence="0.999272">
2.2 The Gap Segments
</subsectionHeader>
<bodyText confidence="0.999976">
We believe the gap segments2 are important to
model since they can potentially capture depen-
dencies between two or more adjacent arguments.
For example, the word sequence “may have fired”
clearly indicates an Attacker-Instrument relation be-
tween the two mentions “North Korea’s military”
and “a laser”. Since we are only interested in
modeling dependencies between adjacent argument
segments, we assign hard labels to each gap seg-
ment based on its contextual argument informa-
tion. Specifically, the label of each gap segment
is uniquely determined by its surrounding argu-
ment segments with a list representation. For ex-
ample, in a “first-order” setting, the gap segment
that appears between its previous argument seg-
ment “ATTACKER” and its next argument segment
“INSTRUMENT” is annotated as the list consisting
of two elements: [ATTACKER, INSTRUMENT]. To
capture longer-range dependencies, in this work we
use a “second-order” setting (as shown in Figure 2),
</bodyText>
<footnote confidence="0.916089666666667">
2The length of a gap segment is arbitrary (including zero),
unlike the seminal semi-Markov CRF model of Sarawagi and
Cohen (2004).
</footnote>
<equation confidence="0.503157">
aL(Θ) X=
a0j i
X−
i
</equation>
<page confidence="0.978813">
837
</page>
<bodyText confidence="0.999961333333333">
which means each gap segment is annotated with a
list that consists of its previous two argument seg-
ments as well as its subsequent one.
</bodyText>
<subsectionHeader confidence="0.973215">
2.3 Features
</subsectionHeader>
<bodyText confidence="0.992914102564102">
Feature functions are factorized as products of two
indicator functions: one defined on the input se-
quence (input features) and the other on the output
labels (output features). In other words, we could
re-write fj(s, h, t) as fin� (s) x f�u�
l (h, t).
For gap segments, we consider the following in-
put feature templates:
N-GRAM: Indicator function for n-gram appeared
in the segment (n = 1, 2)
ANCHOR: Indicator function for its relative position
to the event anchor words (to the left, to
the right, overlaps, contains)
and the following output feature templates:
1STORDER: Indicator function for the combination of
its immediate left argument and its imme-
diate right argument.
2NDORDER: Indicator function for the combination of
its immediate two left arguments and its
immediate right argument.
For argument segments, we also define the same
input feature templates as above, with the following
additional ones to capture contextual information:
CWORDS: Indicator function for the previous and
next k (= 1, 2, 3) words.
CPOS: Indicator function for the previous and
next k (= 1, 2, 3) words’ POS tags.
and we define the following output feature template:
ARGTYPE: Indicator function for the combination of
the argument and its associated type.
Although the semi-Markov CRF model gives us
the flexibility in introducing features that can not be
exploited in a standard CRF, such as entity name
similarity scores and distance measures, in prac-
tice we found the above simple and general features
work well. This way, the unnormalized score as-
signed to each structure is essentially a linear sum
of the feature weights, each corresponding to an in-
dicator function.
</bodyText>
<sectionHeader confidence="0.937181" genericHeader="method">
3 Learning without Annotated Data
</sectionHeader>
<bodyText confidence="0.9999490625">
The supervised model presented in the previous sec-
tion requires substantial human efforts to annotate
the training instances. Human annotations can be
very expensive and sometimes impractical. Even if
annotators are available, getting annotators to agree
with each other is often a difficult task in itself.
Worse still, annotations often can not be reused: ex-
perimenting on a different domain or dataset typi-
cally require annotating new training instances for
that particular domain or dataset.
We investigate inexpensive methods to alleviate
this issue in this section. We introduce a novel gen-
eral learning framework called structured preference
modeling, which allows arbitrary prior knowledge
about structures to be introduced to the learning pro-
cess in a declarative manner.
</bodyText>
<subsectionHeader confidence="0.993751">
3.1 Structured Preference Modeling
</subsectionHeader>
<bodyText confidence="0.994825352941176">
Denote by XΩ and YΩ the entire input and output
space, respectively. For a particular input x E XΩ,
the set x x YΩ gives us all possible structures that
contain x. However, structures are not equally good.
Some structures are generally regarded as better
structures while some are worse.
Let’s asume there is a function κ : {x x YΩ �
[0, 1]} that measures the quality of the structures.
This function returns the quality of a certain struc-
ture (x, y), where the value 1 indicates a perfect
structure, and 0 an impossible structure.
Under such an assumption, it is easy to observe
that for a good structure (x, y), we have pΘ(x, y) x
κ(x, y) = pΘ(x, y), while for a bad structure (x, y),
we have pΘ(x, y) x κ(x, y) = 0.
This motivates us to optimize the following objec-
tive function:
</bodyText>
<equation confidence="0.8041655">
log Ey pΘ (xi, y) x κ(xi, y) (5)
Ey pΘ(xi, y)
</equation>
<bodyText confidence="0.99998">
Intuitively, optimizing such an objective function
is equivalent to pushing the probability mass from
bad structures to good structures corresponding to
the same input.
When the preference function κ is defined as the
indicator function for the correct structure (xi, yi),
the numerator terms of the above formula are simply
of the forms pΘ(xi, yi), and the model corresponds
to the fully supervised CRF model.
The model also contains the latent-variable CRF
as a special case. In a latent-variable CRF, we have
input-output pairs (xi, yi), but the underlying spe-
cific structure h that contains both xi and yi is hid-
den. The objective function is:
</bodyText>
<equation confidence="0.970995142857143">
lo Eh pΘ (xi, h, yi) (6)
g Eh,y&apos; pΘ(xi, h, y&apos;)
�
Gu(Θ) =
i
�
i
</equation>
<page confidence="0.964786">
838
</page>
<bodyText confidence="0.9999935">
where pe(xi, h, yi) = 0 unless h contains (xi, yi).
We define the following two functions:
</bodyText>
<equation confidence="0.9936272">
qe(xi, h) = X pe(xi, h, y0) (7)
y&apos;
~ 1 h contains (xi, yi)
κ(xi, h) = (8)
0 otherwise
</equation>
<bodyText confidence="0.999836666666667">
Note that this definition of κ models instance-
specific preferences since it relies on yi, which can
be thought of as certain external prior knowledge re-
lated to xi. It is easy to verify that pe(xi, h, yi) =
qe(xi, h) × κ(xi, h), with qe remains a distribution.
Thus, we could re-write the objective function as:
</bodyText>
<equation confidence="0.998098">
X log Ph qe (xi, h) × κ (xi, h) (9)
i=1 Ph qe(xi, h)
</equation>
<bodyText confidence="0.998575">
This shows that the latent-variable CRF is a spe-
cial case of our objective function, with the above-
defined κ function. Thus, this new objective func-
tion of Equation 5 is a generalization of both the su-
pervised CRF and the latent-variable CRF.
The preference function κ serves as a source from
which certain prior knowledge about the structure
can be injected into our model in a principled way.
Note that the function is defined at the complete
structure level. This allows us to incorporate both
local and arbitrary global structured information into
the preference function.
Under the log-linear parameterization, we have:
</bodyText>
<equation confidence="0.968875">
L0(Θ) = X
i log y P (10)
P ef(xi,y)·e × κ(xi, y)
y ef(xi,y)·e
</equation>
<bodyText confidence="0.999841857142857">
This is again a non-convex optimization problem
in general, and to solve it we take its partial deriva-
tive with respect to θk:
efficiently and exactly with dynamic programming.
Our main concern is the computation of its numera-
tor terms (and the first term of Equation 11).
The preference function κ is defined at the com-
plete structure level. Unless the function is defined
in specific forms that allow tractable dynamic pro-
gramming (in the supervised case, which gives a
unique term, or in the hidden variable case, which
can define a packed representations of derivations),
the efficient dynamic programming algorithm used
by CRF is no longer generally applicable for arbi-
trary κ. In general, we resort to approximations.
In this work, we exploit a specific form of the
preference function κ. We assume that there exists
a projection from another decomposable function to
κ. Specifically, we assume a collection of auxiliary
functions, each of the form κp : (x, y) → R, that
scores a property p of the complete structure (x, y).
Each such function measures certain aspect of the
quality of the structure. These functions assign pos-
itive scores to good structural properties and nega-
tive scores to bad ones. We then define κ(x, y) = 1
for all structures that appear at the top-n positions
as ranked by Pp κp(x, y) for all possible y’s, and
κ(x, y) = 0 otherwise. We show some actual κp
functions used for a particular event in Section 5.
At each iteration of the training process, to gen-
erate such a n-best list, we first use our model to
produce top n × b candidate outputs as scored by
the current model parameters, and extract the top n
outputs as scored by Pp κp(x, y). In practice we set
n = 10 and b = 1000.
</bodyText>
<subsectionHeader confidence="0.997251">
3.3 Event Extraction
</subsectionHeader>
<bodyText confidence="0.99105025">
Now we can obtain the objective function for our
event extraction task. We replace x by s and y by
(h, t) in Equation 10. This gives us the following
function:
</bodyText>
<equation confidence="0.99799975">
∂L0(Θ) X= Ep®(y|xi;κ)[fk(xi, y)] X lo Et,h ef(si h t)·e × κ(si, h, t) 12
∂θk i Lu(Θ) = g Pt, h ef(si,h,t)·e ( )
i
The partial derivatives are as follows:
∂Lu(Θ)
∂θk
X= Ep®(t,h|si;κ)[fk(si, h, t)]
i
X− Ep®(y|xi)[fk(xi, y)] (11)
i
pe(y|xi; κ) ∝ ef(xi,y)·e × κ(xi, y)
pe(y|xi) ∝ ef(xi,y)·e
</equation>
<subsectionHeader confidence="0.998773">
3.2 Approximate Learning
</subsectionHeader>
<bodyText confidence="0.9816165">
Computation of the denominator terms of Equation
10 (and the second term of Equation 11) can be done
</bodyText>
<equation confidence="0.881599">
X− Ep®(t,h|si)[fk(si, h,t)] (13)
i
pe(t, h|si; κ) ∝ ef(si,h,t)·e × κ(si, h, t)
f(s h t)·e
pe(t, h |si) ∝ e z, ,
</equation>
<page confidence="0.989464">
839
</page>
<bodyText confidence="0.999661666666667">
Recall that s is an event span, t is a specfic re-
alization of the event template, and h is the hidden
mention information for the event span.
</bodyText>
<sectionHeader confidence="0.976418" genericHeader="method">
4 Discussion: Preferences v.s. Constraints
</sectionHeader>
<bodyText confidence="0.99866225">
Note that the objective function in Equation 5, if
written in the additive form, leads to a cost func-
tion reminiscent of the one used in constraint-driven
learning algorithm (CoDL) (Chang et al., 2007) (and
similarly, posterior regularization (Ganchev et al.,
2010), which we will discuss later at Section 6).
Specifically, in CoDL, the following cost function
is involved in its EM-like inference procedure:
</bodyText>
<equation confidence="0.9510005">
arg max O · f(x, y) − p � d(y,Yc) (14)
y c
</equation>
<bodyText confidence="0.999993242424242">
where Yc defines the set of y’s that all satisfy a cer-
tain constraint c, and d defines a distance function
from y to that set. The parameter p controls the de-
gree of the penalty when constraints are violated.
There are some important distinctions between
structured preference modeling (PM) and CoDL.
CoDL primarily concerns constraints, which pe-
nalizes bad structures without explicitly rewarding
good ones. On the other hand, PM concerns prefer-
ences, which can explicitly reward good structures.
Constraints are typically useful when one works
on structured prediction problems for data with cer-
tain (often rigid) regularities, such as citations, ad-
vertisements, or POS tagging for complete sen-
tences. In such tasks, desired structures typically
present certain canonical forms. This allows declar-
ative constraints to be specified as either local struc-
ture prototypes (e.g., in citation extraction, the word
pp. always corresponds to the PAGES field, while
proceedings is always associated with BOOKTITLE
or JOURNAL), or as certain global regulations about
complete structures (e.g., at least one word should
be tagged as verb when performing a sentence-level
POS tagging).
Unfortunately, imposing such (hard or soft) con-
straints for certain tasks such as ours, where the data
tends to be of arbitrary forms without many rigid
regularities, can be difficult and often inappropri-
ate. For example, there is no guarantee that a cer-
tain argument will always be present in the event
span, nor should a particular mention, if appeared,
always be selected and assigned to a specific argu-
ment. For example, in the example event span given
in Section 1, both “March” and “Tuesday” are valid
candidate mentions for the TIME-WITHIN argument
given their annotated type TME. One important clue
is that March appears after the word in and is lo-
cated nearer to other mentions that can be poten-
tially useful arguments. However, encoding such
information as a general constraint can be inappro-
priate, as potentially better structures can be found
if one considers other alternatives. On the other
hand, if we believe the structural pattern “at TAR-
GET in TIME-WITHIN” is in general considered a
better sub-structure than “said TIME-WITHIN” for
the “Attack” event, we may want to assign structured
preference to a complete structure that contains the
former, unless there exist other structured evidence
showing the latter turns out to be better.
In this work, our preference function is related
to another function that can be decomposed into a
collection of property functions rp. Each of them
scores a certain aspect of the complete structure.
This formulation gives us a complete flexibility to
assign arbitrary structured preferences, where posi-
tive scores can be assigned to good properties, and
negative scores to bad ones. Thus, in this way, the
quality of a complete structure is jointly measured
with multiple different property functions.
To summarize, preferences are an effective way to
“define” the event structure to the learner, which is
essential in an unsupervised setting, which may not
be easy to do with other forms of constraints. Prefer-
ences are naturally decomposable, which allows us
to extend their impact without significantly effecting
the complexity of inference.
</bodyText>
<sectionHeader confidence="0.999365" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99982725">
In this section, we present our experimental results
on the standard ACE053 dataset (newswire portion).
We choose to perform our evaluations on 4 events
(namely, “Attack”, “Meet”, “Die” and “Transport”),
which are the only events in this dataset that have
more than 50 instances. For each event, we ran-
domly split the instances into two portions, where
70% are used for learning, and the remaining 30%
for evaluation. We list the corpus statistics in Table
2.
To present general results while making minimal
assumptions, our primary event extraction results
</bodyText>
<footnote confidence="0.965737">
3http://www.itl.nist.gov/iad/mig/tests/ace/2005/doc/
</footnote>
<page confidence="0.981597">
840
</page>
<table confidence="0.999753">
Attack 20.47 30.12 39.25 42.02 54.03 58.82 65.18 63.11
Meet 35.48 26.09 44.07 63.55 65.42 70.48 75.47 76.64
Die 30.03 13.04 40.58 55.38 51.61 59.65 63.18 67.65
Transport 20.40 6.11 44.34 57.29 53.76 57.63 61.02 64.19
</table>
<tableCaption confidence="0.988311">
Table 1: Performance for different events under different experimental settings, with gold mention boundaries and types. We report
F1-measure percentages.
</tableCaption>
<figure confidence="0.657929454545454">
Event
MaxEnt-t
PM
semi-CRF
MaxEnt-b
Rule
Unsup
With Annotated Training Data
MaxEnt-p
Without Annotated Training Data
Random
</figure>
<table confidence="0.968442833333333">
Event #A Learning Set Evaluation Set #P
#I #M #I #M
Attack 8 188 300/509 78 121/228 7
Meet 7 57 134/244 24 52/98 7
Die 9 41 89/174 19 33/61 6
Transport 13 85 243/426 38 104/159 6
</table>
<tableCaption confidence="0.911114">
Table 2: Corpus statistics (#A: number of possible arguments
for the event; #I: number of instances; #M: number of ac-
tive/total mentions; #P: number of preference patterns used
for performing our structured preference modeling.)
</tableCaption>
<bodyText confidence="0.9998451">
are independent of mention identification and typing
modules, which are based on the gold mention in-
formation as given by the dataset. Additionally, we
present results obtained by exploiting our in-house
automatic mention identification and typing mod-
ule, which is a hybrid system that combines statis-
tical and rule-based approaches. The module’s sta-
tistical component is trained on the ACE04 dataset
(newswire portion) and overall it achieves a micro-
averaged F1-measure of 71.25% at our dataset.
</bodyText>
<subsectionHeader confidence="0.994836">
5.1 With Annotated Training Data
</subsectionHeader>
<bodyText confidence="0.999980608695653">
With hand-annotated training data, we are able to
train our model in a fully supervised manner. The
right part of Table 1 shows the performance for
the fully supervised models. For comparison, we
present results from several alternative approaches
based a collection of locally trained maximum en-
tropy (MaxEnt) classifiers. In these approaches, we
treat each argument of the template as one possi-
ble output class, plus a special “NONE” class for
not selecting it as an argument. We train and apply
the classifiers on argument segments (i.e., mentions)
only. All the models are trained with the same fea-
ture set used in the semi-CRF model.
In the simplest baseline approach MaxEnt-b, type
information for each mention is simply treated as
one special feature. In the approach MaxEnt-t, we
instead use the type information to constrain the
classifier’s predictions based on the acceptable types
associated with each argument. This approach gives
better performance than that of MaxEnt-b. This in-
dicates that such locally trained classifiers are not
robust enough to disambiguate arguments that take
different types. As such, type information serving as
additional constraints at the end does help.
To assess the importance of structured preference,
we also perform experiments where structured pref-
erence information is incorporated at the inference
time of the MaxEnt classifiers. Specifically, for each
event, we first generate n-best lists for output struc-
tures. Next, we re-rank this list based on scores
from our structured preference functions (we used
the same preferences as to be discussed in the next
section). The results for these approaches are given
in the column of MaxEnt-p of Table 1. This simple
approach gives us significant improvements, clos-
ing the gap between locally trained classifiers and
the joint model (in one case the former even out-
performs the latter). Note that no structured pref-
erence information is used when training and eval-
uating our semi-CRF model. This set of results is
not surprising. In fact, similar observations are also
reported in previous works when comparing joint
model against local models with constraints incor-
porated (Roth and Yih, 2005). This clearly indicates
that structured preference information is crucial to
model.
</bodyText>
<subsectionHeader confidence="0.999251">
5.2 Without Annotated Training Data
</subsectionHeader>
<bodyText confidence="0.999018555555556">
Now we turn to experiments for the more realistic
scenario where human annotations are not available.
We first build our simplest baseline by randomly
assigning arguments to each mention with mention
type information serving as constraints. Averaged
results over 1000 runs are reported in the first col-
umn of Table 1.
Since our model formulation leaves us with com-
plete freedom in designing the preference function,
</bodyText>
<page confidence="0.994177">
841
</page>
<table confidence="0.999120363636364">
Type Preference pattern (p)
General {at|in|on} followed by PLACE
{during|at|in|on} followed by TIME-WITHIN
Die AGENT (immediately) followed by {killed}
{killed} (immediately) followed by VICTIM
VICTIM (immediately) followed by {he killed}
AGENT followed by {killed} (immediately) followed by VICTIM
Transport X immediately followed by {,|and} immediately followed by X, where X ∈ {ORIGIN|DESTINATION}
{from|leave} (immediately) followed by ORIGIN
{at|in|to|into} immediately followed by DESTINATION
PERSON followed by {to|visit|arrived}
</table>
<figureCaption confidence="0.837207">
Figure 3: The complete list of preference patterns used for the “Die” and “Transport” event. We simply set ry = 1.0 for all p’s. In
</figureCaption>
<bodyText confidence="0.976902892307692">
other words, when a structure contains a pattern, its score is incremented by 1.0. We use {} to refer to a set of possible words or
arguments. For example, {from|leave} means a word which is either from or leave. The symbol O denotes optional. For example,
“{killed} (immediately) followed by VICTIM” is equivalent to the following two preferences: “{killed} immediately followed by
VICTIM”, and “{killed} followed by VICTIM”.
one could design arbitrarily good, domain-specific
or even instance-specific preferences. However, to
demonstrate its general effectiveness, in this work
we only choose a minimal amount of general prefer-
ence patterns for evaluations.
We make our preference patterns as general as
possible. As shown in the last column (#P) of Table
2, we use only 7 preference patterns each for the “At-
tack” and “Meet” events, and 6 patterns each for the
other two events. In Figure 3, we show the complete
list of the 6 preference patterns for the “Die” and
“Transport” event used for our experiments. Out of
those 6 patterns, 2 are more general patterns shared
across different events, and 4 are event-specific. In
contrast, for example, for the “Die” event, the super-
vised approach requires human to select from 174
candidate mentions and annotate 89 of them.
Despite its simplicity, it works very well in prac-
tice. Results are given in the column of “PM” of
Table 1. It generally gives competitive performance
as compared to the supervised MaxEnt baselines.
On the other hand, a completely unsupervised ap-
proach where structured preferences are not speci-
fied, performs substantially worse. To run such com-
pletely unsupervised models, we essentially follow
the same training procedure as that of the prefer-
ence modeling, except that structured preference in-
formation is not in place when generating the n-best
list. In the absence of proper guidances, such a pro-
cedure can easily converge to bad local minima. The
results are reported in the “Unsup” column of Ta-
ble 1. In practice, we found that very often, such
a model would prefer short structures where many
mentions are not selected as desired. As a result, the
unsupervised model without preference information
can even perform worse than the random baseline 4.
Finally, we also compare against an approach that
regards the preferences as rules. All such rules are
associated with a same weight and are used to jointly
score each structure. We then output the structure
that is assigned the highest total weight. Such an ap-
proach performs worse than our approach with pref-
erence modeling. The results are presented in the
column of “Rule” of Table 1. This indicates that
our model is able to learn to generalize with features
through the guidance of our informative preferences.
However, we also note that the performance of pref-
erence modeling depends on the actual quality and
amount of preferences used for learning. In the ex-
treme case, where only few preferences are used, the
performance of preference modeling will be close to
that of the unsupervised approach, while the rule-
based approach will yield performance close to that
of the random baseline.
The results with automatically predicted mention
boundaries and types are given in Table 3. Simi-
lar observations can be made when comparing the
performance of preference modeling with other ap-
proaches. This set of results further confirms the ef-
fectiveness of our approach using preference model-
ing for the event extraction task.
</bodyText>
<sectionHeader confidence="0.999906" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.875899">
Structured prediction with limited supervision is a
popular topic in natural language processing.
</bodyText>
<footnote confidence="0.996653">
4For each event, we only performed 1 run with all the initial
feature weights set to zeros.
</footnote>
<page confidence="0.982932">
842
</page>
<table confidence="0.9995694">
Event Random Unsup PM semi-CRF
Attack 14.26 26.19 32.89 46.92
Meet 26.65 14.08 45.28 58.18
Die 19.17 9.09 44.44 48.57
Transport 15.78 10.14 49.73 52.34
</table>
<tableCaption confidence="0.6794872">
Table 3: Event extraction performance with automatic mention
identifier and typer. We report F1 percentage scores for pref-
erence modeling (PM) as well as two baseline approaches. We
also report performance of the supervised approach trained with
the semi-CRF model for comparison.
</tableCaption>
<bodyText confidence="0.999482903846154">
Prototype driven learning (Haghighi and Klein,
2006) tackled the sequence labeling problem in a
primarily unsupervised setting. In their work, a
Markov random fields model was used, where some
local constraints are specified via their prototype list.
Constraint-driven learning (CoDL) (Chang et al.,
2007) and posterior regularization (PR) (Ganchev et
al., 2010) are both primarily semi-supervised mod-
els. They define a constrained EM framework that
regularizes posterior distribution at the E-step of
each EM iteration, by pushing posterior distributions
towards a constrained posterior set. We have already
discussed CoDL in Section 4 and gave a comparison
to our model. Unlike CoDL, in the PR framework
constraints are relaxed to expectation constraints, in
order to allow tractable dynamic programming. See
also Samdani et al. (2012) for more discussions.
Contrastive estimation (CE) (Smith and Eisner,
2005a) is another log-linear framework for primar-
ily unsupervised structured prediction. Their objec-
tive function is related to the pseudolikelihood es-
timator proposed by Besag (1975). One challenge
is that it requires one to design a priori an effective
neighborhood (which also needs to be designed in
certain forms to allow efficient computation of the
normalization terms) in order to obtain optimal per-
formance. The model has been shown to work in un-
supervised tasks such as POS induction (Smith and
Eisner, 2005a), grammar induction (Smith and Eis-
ner, 2005b), and morphological segmentation (Poon
et al., 2009), where good neighborhoods can be
identified. However, it is less intuitive what consti-
tutes a good neighborhood in this task.
The neighborhood assumption of CE is relaxed
in another latent structure approach (Chang et al.,
2010a; Chang et al., 2010b) that focuses on semi-
supervised learning with indirect supervisions, in-
spired by the CoDL model described above.
The locally normalized logistic regression (Berg-
Kirkpatrick et al., 2010) is another recently proposed
framework for unsupervised structured prediction.
Their model can be regarded as a generative model
whose component multinomial is replaced with a
miniature logistic regression where a rich set of local
features can be incorporated. Empirically the model
is effective in various unsupervised structured pre-
diction tasks, and outperforms the globally normal-
ized model. Although modeling the semi-Markov
properties of our segments (especially the gap seg-
ments) in our task is potentially challenging, we plan
to investigate in the future the feasibility for our task
with such a framework.
</bodyText>
<sectionHeader confidence="0.999671" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999863">
In this paper, we present a novel model based on
the semi-Markov conditional random fields for the
challenging event extraction task. The model takes
in coarse mention boundary and type information
and predicts complete structures indicating the cor-
responding argument role for each mention.
To learn the model in an unsupervised manner,
we further develop a novel learning approach called
structured preference modeling that allows struc-
tured knowledge to be incorporated effectively in a
declarative manner.
Empirically, we show that knowledge about struc-
tured preference is crucial to model and the prefer-
ence modeling is an effective way to guide learn-
ing in this setting. Trained in a primarily unsuper-
vised manner, our model incorporating structured
preference information exhibits performance that is
competitive to that of some supervised baseline ap-
proaches. Our event extraction system and code will
be available for download from our group web page.
</bodyText>
<sectionHeader confidence="0.998237" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999991083333333">
We would like to thank Yee Seng Chan, Mark Sam-
mons, and Quang Xuan Do for their help with the
mention identification and typing system used in
this paper. We gratefully acknowledge the sup-
port of the Defense Advanced Research Projects
Agency (DARPA) Machine Reading Program un-
der Air Force Research Laboratory (AFRL) prime
contract no. FA8750-09-C-0181. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this material are those of the authors
and do not necessarily reflect the view of DARPA,
AFRL, or the US government.
</bodyText>
<page confidence="0.99788">
843
</page>
<sectionHeader confidence="0.993908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99992725">
T. Berg-Kirkpatrick, A. Bouchard-Cˆot´e, J. DeNero, and
D. Klein. 2010. Painless unsupervised learning with
features. In Proc. of HLT-NAACL’10, pages 582–590.
J. Besag. 1975. Statistical analysis of non-lattice data.
The Statistician, pages 179–195.
M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-
supervision with constraint-driven learning. In Proc.
of ACL’07, pages 280–287.
M. Chang, D. Goldwasser, D. Roth, and V. Srikumar.
2010a. Discriminative learning over constrained latent
representations. In Proc. of NAACL’10, 6.
M. Chang, V. Srikumar, D. Goldwasser, and D. Roth.
2010b. Structured output learning with indirect super-
vision. In Proc. ICML’10.
K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar.
2010. Posterior regularization for structured latent
variable models. The Journal of Machine Learning
Research (JMLR), 11:2001–2049.
A. Haghighi and D. Klein. 2006. Prototype-driven learn-
ing for sequence models. In Proc. of HLT-NAACL’06,
pages 320–327.
J. D. Lafferty, A. McCallum, and F. C. N. Pereira. 2001.
Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proc. of
ICML’01, pages 282–289.
Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. 1998.
Gradient-based learning applied to document recogni-
tion. Proc. of the IEEE, pages 2278–2324.
D.C. Liu and J. Nocedal. 1989. On the limited memory
bfgs method for large scale optimization. Mathemati-
cal programming, 45(1):503–528.
D. Okanohara, Y. Miyao, Y. Tsuruoka, and J. Tsujii.
2006. Improving the scalability of semi-markov con-
ditional random fields for named entity recognition. In
Proc. of ACL’06, pages 465–472.
H. Poon, C. Cherry, and K. Toutanova. 2009. Unsu-
pervised morphological segmentation with log-linear
models. In Proc. of HLT-NAACL’09, pages 209–217.
L. Ratinov and D. Roth. 2009. Design challenges and
misconceptions in named entity recognition. In Proc.
of CoNLL’09, pages 147–155.
L. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and global algorithms for disambiguation
to wikipedia. In Proc. of ACL-HLT’11, pages 1375–
1384.
D. Roth and W. Yih. 2005. Integer linear programming
inference for conditional random fields. In Proc. of
ICML’05, pages 736–743.
R. Samdani, M. Chang, and D. Roth. 2012. Unified ex-
pectation maximization. In Proc. NAACL’12.
S. Sarawagi and W.W. Cohen. 2004. Semi-markov
conditional random fields for information extraction.
NIPS’04, pages 1185–1192.
N.A. Smith and J. Eisner. 2005a. Contrastive estimation:
Training log-linear models on unlabeled data. In Proc.
of ACL’05, pages 354–362.
N.A. Smith and J. Eisner. 2005b. Guiding unsupervised
grammar induction using contrastive estimation. In
Proc. of IJCAI Workshop on Grammatical Inference
Applications, pages 73–82.
J. Str¨otgen and M. Gertz. 2010. Heideltime: High qual-
ity rule-based extraction and normalization of tempo-
ral expressions. In Proc. of SemEval’10, pages 321–
324.
</reference>
<page confidence="0.998691">
844
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.819191">
<title confidence="0.999739">Automatic Event Extraction with Structured Preference Modeling</title>
<author confidence="0.999504">Lu Roth</author>
<affiliation confidence="0.969092">University of Illinois at</affiliation>
<abstract confidence="0.993493708333333">This paper presents a novel sequence labeling model based on the latent-variable semi- Markov conditional random fields for jointly extracting argument roles of events from texts. The model takes in coarse mention and type information and predicts argument roles for a given event template. This paper addresses the event extraction problem in a primarily unsupervised setting, where no labeled training instances are available. Our key contribution is a novel learning called preference modthat allows arbitrary preference to be assigned to certain structures during the learning procedure. We establish and discuss connections between this framework and other existing works. We show empirically that the structured preferences are crucial to the success of our task. Our model, trained without annotated data and with a small number of structured preferences, yields performance competitive to some baseline supervised approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Berg-Kirkpatrick</author>
<author>A Bouchard-Cˆot´e</author>
<author>J DeNero</author>
<author>D Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proc. of HLT-NAACL’10,</booktitle>
<pages>582--590</pages>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>T. Berg-Kirkpatrick, A. Bouchard-Cˆot´e, J. DeNero, and D. Klein. 2010. Painless unsupervised learning with features. In Proc. of HLT-NAACL’10, pages 582–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Besag</author>
</authors>
<title>Statistical analysis of non-lattice data. The Statistician,</title>
<date>1975</date>
<pages>179--195</pages>
<contexts>
<context position="34389" citStr="Besag (1975)" startWordPosition="5608" endWordPosition="5609">bution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comparison to our model. Unlike CoDL, in the PR framework constraints are relaxed to expectation constraints, in order to allow tractable dynamic programming. See also Samdani et al. (2012) for more discussions. Contrastive estimation (CE) (Smith and Eisner, 2005a) is another log-linear framework for primarily unsupervised structured prediction. Their objective function is related to the pseudolikelihood estimator proposed by Besag (1975). One challenge is that it requires one to design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon et al., 2009), where good neighborhoods can be identified. However, it is less intuitive what constitutes a good neighborhood in this task. The neighborhood assumption of CE is rel</context>
</contexts>
<marker>Besag, 1975</marker>
<rawString>J. Besag. 1975. Statistical analysis of non-lattice data. The Statistician, pages 179–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semisupervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In Proc. of ACL’07,</booktitle>
<pages>280--287</pages>
<contexts>
<context position="20210" citStr="Chang et al., 2007" startWordPosition="3376" endWordPosition="3379">ximate Learning Computation of the denominator terms of Equation 10 (and the second term of Equation 11) can be done X− Ep®(t,h|si)[fk(si, h,t)] (13) i pe(t, h|si; κ) ∝ ef(si,h,t)·e × κ(si, h, t) f(s h t)·e pe(t, h |si) ∝ e z, , 839 Recall that s is an event span, t is a specfic realization of the event template, and h is the hidden mention information for the event span. 4 Discussion: Preferences v.s. Constraints Note that the objective function in Equation 5, if written in the additive form, leads to a cost function reminiscent of the one used in constraint-driven learning algorithm (CoDL) (Chang et al., 2007) (and similarly, posterior regularization (Ganchev et al., 2010), which we will discuss later at Section 6). Specifically, in CoDL, the following cost function is involved in its EM-like inference procedure: arg max O · f(x, y) − p � d(y,Yc) (14) y c where Yc defines the set of y’s that all satisfy a certain constraint c, and d defines a distance function from y to that set. The parameter p controls the degree of the penalty when constraints are violated. There are some important distinctions between structured preference modeling (PM) and CoDL. CoDL primarily concerns constraints, which penal</context>
<context position="33604" citStr="Chang et al., 2007" startWordPosition="5491" endWordPosition="5494">ransport 15.78 10.14 49.73 52.34 Table 3: Event extraction performance with automatic mention identifier and typer. We report F1 percentage scores for preference modeling (PM) as well as two baseline approaches. We also report performance of the supervised approach trained with the semi-CRF model for comparison. Prototype driven learning (Haghighi and Klein, 2006) tackled the sequence labeling problem in a primarily unsupervised setting. In their work, a Markov random fields model was used, where some local constraints are specified via their prototype list. Constraint-driven learning (CoDL) (Chang et al., 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. They define a constrained EM framework that regularizes posterior distribution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comparison to our model. Unlike CoDL, in the PR framework constraints are relaxed to expectation constraints, in order to allow tractable dynamic programming. See also Samdani et al. (2012) for more discussions. Contrastive estimation (CE) (Smith and Eisner</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semisupervision with constraint-driven learning. In Proc. of ACL’07, pages 280–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>D Goldwasser</author>
<author>D Roth</author>
<author>V Srikumar</author>
</authors>
<title>Discriminative learning over constrained latent representations.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL’10,</booktitle>
<pages>6</pages>
<contexts>
<context position="35050" citStr="Chang et al., 2010" startWordPosition="5713" endWordPosition="5716">design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon et al., 2009), where good neighborhoods can be identified. However, it is less intuitive what constitutes a good neighborhood in this task. The neighborhood assumption of CE is relaxed in another latent structure approach (Chang et al., 2010a; Chang et al., 2010b) that focuses on semisupervised learning with indirect supervisions, inspired by the CoDL model described above. The locally normalized logistic regression (BergKirkpatrick et al., 2010) is another recently proposed framework for unsupervised structured prediction. Their model can be regarded as a generative model whose component multinomial is replaced with a miniature logistic regression where a rich set of local features can be incorporated. Empirically the model is effective in various unsupervised structured prediction tasks, and outperforms the globally normalized </context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>M. Chang, D. Goldwasser, D. Roth, and V. Srikumar. 2010a. Discriminative learning over constrained latent representations. In Proc. of NAACL’10, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>V Srikumar</author>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Structured output learning with indirect supervision.</title>
<date>2010</date>
<booktitle>In Proc. ICML’10.</booktitle>
<contexts>
<context position="35050" citStr="Chang et al., 2010" startWordPosition="5713" endWordPosition="5716">design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon et al., 2009), where good neighborhoods can be identified. However, it is less intuitive what constitutes a good neighborhood in this task. The neighborhood assumption of CE is relaxed in another latent structure approach (Chang et al., 2010a; Chang et al., 2010b) that focuses on semisupervised learning with indirect supervisions, inspired by the CoDL model described above. The locally normalized logistic regression (BergKirkpatrick et al., 2010) is another recently proposed framework for unsupervised structured prediction. Their model can be regarded as a generative model whose component multinomial is replaced with a miniature logistic regression where a rich set of local features can be incorporated. Empirically the model is effective in various unsupervised structured prediction tasks, and outperforms the globally normalized </context>
</contexts>
<marker>Chang, Srikumar, Goldwasser, Roth, 2010</marker>
<rawString>M. Chang, V. Srikumar, D. Goldwasser, and D. Roth. 2010b. Structured output learning with indirect supervision. In Proc. ICML’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Grac¸a</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>The Journal of Machine Learning Research (JMLR),</journal>
<pages>11--2001</pages>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>K. Ganchev, J. Grac¸a, J. Gillenwater, and B. Taskar. 2010. Posterior regularization for structured latent variable models. The Journal of Machine Learning Research (JMLR), 11:2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>D Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL’06,</booktitle>
<pages>320--327</pages>
<contexts>
<context position="33351" citStr="Haghighi and Klein, 2006" startWordPosition="5454" endWordPosition="5457">pular topic in natural language processing. 4For each event, we only performed 1 run with all the initial feature weights set to zeros. 842 Event Random Unsup PM semi-CRF Attack 14.26 26.19 32.89 46.92 Meet 26.65 14.08 45.28 58.18 Die 19.17 9.09 44.44 48.57 Transport 15.78 10.14 49.73 52.34 Table 3: Event extraction performance with automatic mention identifier and typer. We report F1 percentage scores for preference modeling (PM) as well as two baseline approaches. We also report performance of the supervised approach trained with the semi-CRF model for comparison. Prototype driven learning (Haghighi and Klein, 2006) tackled the sequence labeling problem in a primarily unsupervised setting. In their work, a Markov random fields model was used, where some local constraints are specified via their prototype list. Constraint-driven learning (CoDL) (Chang et al., 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. They define a constrained EM framework that regularizes posterior distribution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comp</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>A. Haghighi and D. Klein. 2006. Prototype-driven learning for sequence models. In Proc. of HLT-NAACL’06, pages 320–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Lafferty</author>
<author>A McCallum</author>
<author>F C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of ICML’01,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="7848" citStr="Lafferty et al., 2001" startWordPosition="1259" endWordPosition="1262">that connects the two arguments A1 and A3. Note that no overlapping arguments are allowed in this model 1. We use s to denote an event span and t to denote a specific realization (filling) of the event template. Templates consist of a set of arguments. Denote by h a particular mention boundary and type assignment for an event span, which gives us a specific segmentation of the given span. Following the conditional 1Extending the model to support certain argument overlapping is possible – we leave it for future work. C1 C2 C3 C4 A1 B2 A3 T1 T3 B4 . . . . . . C. Ate, T. 836 random fields model (Lafferty et al., 2001), we parameterize the conditional probability of the (t, h) pair given an event span s as follows: Pp(t, h |s) ef(s,h,t)·p = P (1) t,h ef(s,h,t)·p where f gives the feature functions defined on the tuple (s, h, t), and Θ defines the parameter vector. Our objective function is the logarithm of the joint conditional probability of observing the template realization for the observed event span s: L(Θ) = X log Pp(ti|si) i X= i log Pt,h ef(si,h,t)·p (2) Ph ef(si,h,ti)·p This function is not convex due to the summation over the hidden variable h. To optimize it, we take its partial derivative with r</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. D. Lafferty, A. McCallum, and F. C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. of ICML’01, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y LeCun</author>
<author>L Bottou</author>
<author>Y Bengio</author>
<author>P Haffner</author>
</authors>
<title>Gradient-based learning applied to document recognition.</title>
<date>1998</date>
<booktitle>Proc. of the IEEE,</booktitle>
<pages>2278--2324</pages>
<contexts>
<context position="8957" citStr="LeCun et al., 1998" startWordPosition="1440" endWordPosition="1443"> convex due to the summation over the hidden variable h. To optimize it, we take its partial derivative with respect to 0j: Ep®(h|si,ti)[fj(si, h, ti)] Ep®(t,h|si)[fj(si, h, t)] (3) which requires computation of expectations terms under two different distributions. Such statistics can be collected efficiently with a forward-backward style algorithm in polynomial time (Okanohara et al., 2006). We will discuss the time complexity for our case in the next section. Given its partial derivatives in Equation 3, one could optimize the objective function of Equation 2 with stochastic gradient ascent (LeCun et al., 1998) or L-BFGS (Liu and Nocedal, 1989). We choose to use L-BFGS for all our experiments in this paper. Inference involves computing the most probable template realization t for a given event span: arg max t XPp(t|s) = arg max t h Pp(t, h|s) (4) where the possible hidden assignments h need to be marginalized out. In this task, a particular realization t already uniquely defines a particular segmentation (mention boundaries) of the event span, thus the h only contributes type information to t. As we will discuss in Section 2.3, only a collection of local features are defined. Thus, a Viterbi-style d</context>
</contexts>
<marker>LeCun, Bottou, Bengio, Haffner, 1998</marker>
<rawString>Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc. of the IEEE, pages 2278–2324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Liu</author>
<author>J Nocedal</author>
</authors>
<title>On the limited memory bfgs method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="8991" citStr="Liu and Nocedal, 1989" startWordPosition="1446" endWordPosition="1449">er the hidden variable h. To optimize it, we take its partial derivative with respect to 0j: Ep®(h|si,ti)[fj(si, h, ti)] Ep®(t,h|si)[fj(si, h, t)] (3) which requires computation of expectations terms under two different distributions. Such statistics can be collected efficiently with a forward-backward style algorithm in polynomial time (Okanohara et al., 2006). We will discuss the time complexity for our case in the next section. Given its partial derivatives in Equation 3, one could optimize the objective function of Equation 2 with stochastic gradient ascent (LeCun et al., 1998) or L-BFGS (Liu and Nocedal, 1989). We choose to use L-BFGS for all our experiments in this paper. Inference involves computing the most probable template realization t for a given event span: arg max t XPp(t|s) = arg max t h Pp(t, h|s) (4) where the possible hidden assignments h need to be marginalized out. In this task, a particular realization t already uniquely defines a particular segmentation (mention boundaries) of the event span, thus the h only contributes type information to t. As we will discuss in Section 2.3, only a collection of local features are defined. Thus, a Viterbi-style dynamic programming algorithm is us</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>D.C. Liu and J. Nocedal. 1989. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Okanohara</author>
<author>Y Miyao</author>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Improving the scalability of semi-markov conditional random fields for named entity recognition.</title>
<date>2006</date>
<booktitle>In Proc. of ACL’06,</booktitle>
<pages>465--472</pages>
<contexts>
<context position="8732" citStr="Okanohara et al., 2006" startWordPosition="1403" endWordPosition="1406">ive function is the logarithm of the joint conditional probability of observing the template realization for the observed event span s: L(Θ) = X log Pp(ti|si) i X= i log Pt,h ef(si,h,t)·p (2) Ph ef(si,h,ti)·p This function is not convex due to the summation over the hidden variable h. To optimize it, we take its partial derivative with respect to 0j: Ep®(h|si,ti)[fj(si, h, ti)] Ep®(t,h|si)[fj(si, h, t)] (3) which requires computation of expectations terms under two different distributions. Such statistics can be collected efficiently with a forward-backward style algorithm in polynomial time (Okanohara et al., 2006). We will discuss the time complexity for our case in the next section. Given its partial derivatives in Equation 3, one could optimize the objective function of Equation 2 with stochastic gradient ascent (LeCun et al., 1998) or L-BFGS (Liu and Nocedal, 1989). We choose to use L-BFGS for all our experiments in this paper. Inference involves computing the most probable template realization t for a given event span: arg max t XPp(t|s) = arg max t h Pp(t, h|s) (4) where the possible hidden assignments h need to be marginalized out. In this task, a particular realization t already uniquely defines</context>
</contexts>
<marker>Okanohara, Miyao, Tsuruoka, Tsujii, 2006</marker>
<rawString>D. Okanohara, Y. Miyao, Y. Tsuruoka, and J. Tsujii. 2006. Improving the scalability of semi-markov conditional random fields for named entity recognition. In Proc. of ACL’06, pages 465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
<author>C Cherry</author>
<author>K Toutanova</author>
</authors>
<title>Unsupervised morphological segmentation with log-linear models.</title>
<date>2009</date>
<booktitle>In Proc. of HLT-NAACL’09,</booktitle>
<pages>209--217</pages>
<contexts>
<context position="34822" citStr="Poon et al., 2009" startWordPosition="5677" endWordPosition="5680">, 2005a) is another log-linear framework for primarily unsupervised structured prediction. Their objective function is related to the pseudolikelihood estimator proposed by Besag (1975). One challenge is that it requires one to design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon et al., 2009), where good neighborhoods can be identified. However, it is less intuitive what constitutes a good neighborhood in this task. The neighborhood assumption of CE is relaxed in another latent structure approach (Chang et al., 2010a; Chang et al., 2010b) that focuses on semisupervised learning with indirect supervisions, inspired by the CoDL model described above. The locally normalized logistic regression (BergKirkpatrick et al., 2010) is another recently proposed framework for unsupervised structured prediction. Their model can be regarded as a generative model whose component multinomial is re</context>
</contexts>
<marker>Poon, Cherry, Toutanova, 2009</marker>
<rawString>H. Poon, C. Cherry, and K. Toutanova. 2009. Unsupervised morphological segmentation with log-linear models. In Proc. of HLT-NAACL’09, pages 209–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In Proc. of CoNLL’09,</booktitle>
<pages>147--155</pages>
<contexts>
<context position="2678" citStr="Ratinov and Roth, 2009" startWordPosition="411" endWordPosition="414">al assumption is that certain coarse mention-level information, such as mention boundaries and their semantic class (a.k.a. types), are available. E.g.: ... [North Korea’s military]ORG may have fired [a laser]WEA at [a U.S. helicopter]VEH in [March]TME, a U.S. official said Tuesday, as the communist state ditched its last legal obligation to keep itselffree of nuclear weapons ... Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Str¨otgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al., 2011). However, in practice, outputs from existing mention identification and typing systems can be far from ideal. Instead of obtaining the above ideal annotation, one might observe the following noisy and ambiguous annotation for the given event span: ... [[North Korea’s]GPE|LOC military]ORG may have fired a laser at [a [U.S.]GPE|LOC helicopter]VEH in [March]TME, [a [U.S.]GPEILOC official]PER said [Tuesday]TME, as [the communist state]ORG|FAC|LOC ditched its last legal obligation to keep [itself]ORG free of [nuclear weapons]WEA ... O</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>L. Ratinov and D. Roth. 2009. Design challenges and misconceptions in named entity recognition. In Proc. of CoNLL’09, pages 147–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
<author>D Downey</author>
<author>M Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-HLT’11,</booktitle>
<pages>1375--1384</pages>
<contexts>
<context position="2742" citStr="Ratinov et al., 2011" startWordPosition="423" endWordPosition="426">ch as mention boundaries and their semantic class (a.k.a. types), are available. E.g.: ... [North Korea’s military]ORG may have fired [a laser]WEA at [a U.S. helicopter]VEH in [March]TME, a U.S. official said Tuesday, as the communist state ditched its last legal obligation to keep itselffree of nuclear weapons ... Such mention type information as shown on the left of Figure 1 can be obtained from various sources such as dictionaries, gazetteers, rule-based systems (Str¨otgen and Gertz, 2010), statistically trained classifiers (Ratinov and Roth, 2009), or some web resources such as Wikipedia (Ratinov et al., 2011). However, in practice, outputs from existing mention identification and typing systems can be far from ideal. Instead of obtaining the above ideal annotation, one might observe the following noisy and ambiguous annotation for the given event span: ... [[North Korea’s]GPE|LOC military]ORG may have fired a laser at [a [U.S.]GPE|LOC helicopter]VEH in [March]TME, [a [U.S.]GPEILOC official]PER said [Tuesday]TME, as [the communist state]ORG|FAC|LOC ditched its last legal obligation to keep [itself]ORG free of [nuclear weapons]WEA ... Our task is to design a model to effectively select mentions in a</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>L. Ratinov, D. Roth, D. Downey, and M. Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proc. of ACL-HLT’11, pages 1375– 1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Integer linear programming inference for conditional random fields.</title>
<date>2005</date>
<booktitle>In Proc. of ICML’05,</booktitle>
<pages>736--743</pages>
<contexts>
<context position="27989" citStr="Roth and Yih, 2005" startWordPosition="4605" endWordPosition="4608">erences as to be discussed in the next section). The results for these approaches are given in the column of MaxEnt-p of Table 1. This simple approach gives us significant improvements, closing the gap between locally trained classifiers and the joint model (in one case the former even outperforms the latter). Note that no structured preference information is used when training and evaluating our semi-CRF model. This set of results is not surprising. In fact, similar observations are also reported in previous works when comparing joint model against local models with constraints incorporated (Roth and Yih, 2005). This clearly indicates that structured preference information is crucial to model. 5.2 Without Annotated Training Data Now we turn to experiments for the more realistic scenario where human annotations are not available. We first build our simplest baseline by randomly assigning arguments to each mention with mention type information serving as constraints. Averaged results over 1000 runs are reported in the first column of Table 1. Since our model formulation leaves us with complete freedom in designing the preference function, 841 Type Preference pattern (p) General {at|in|on} followed by </context>
</contexts>
<marker>Roth, Yih, 2005</marker>
<rawString>D. Roth and W. Yih. 2005. Integer linear programming inference for conditional random fields. In Proc. of ICML’05, pages 736–743.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Samdani</author>
<author>M Chang</author>
<author>D Roth</author>
</authors>
<title>Unified expectation maximization.</title>
<date>2012</date>
<booktitle>In Proc. NAACL’12.</booktitle>
<contexts>
<context position="34136" citStr="Samdani et al. (2012)" startWordPosition="5571" endWordPosition="5574">pecified via their prototype list. Constraint-driven learning (CoDL) (Chang et al., 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. They define a constrained EM framework that regularizes posterior distribution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comparison to our model. Unlike CoDL, in the PR framework constraints are relaxed to expectation constraints, in order to allow tractable dynamic programming. See also Samdani et al. (2012) for more discussions. Contrastive estimation (CE) (Smith and Eisner, 2005a) is another log-linear framework for primarily unsupervised structured prediction. Their objective function is related to the pseudolikelihood estimator proposed by Besag (1975). One challenge is that it requires one to design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar i</context>
</contexts>
<marker>Samdani, Chang, Roth, 2012</marker>
<rawString>R. Samdani, M. Chang, and D. Roth. 2012. Unified expectation maximization. In Proc. NAACL’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sarawagi</author>
<author>W W Cohen</author>
</authors>
<title>Semi-markov conditional random fields for information extraction. NIPS’04,</title>
<date>2004</date>
<pages>1185--1192</pages>
<contexts>
<context position="4447" citStr="Sarawagi and Cohen, 2004" startWordPosition="684" endWordPosition="687">EH TME March Figure 1: The partial event template for the Attack event (left), and the correct event template annotation for the example event span given in Sec 1 (right). We primarily follow the ACE standard in defining arguments and types. and often noisy mention type annotations. This work addresses this problem by making the following contributions: • Naturally, we are interested in identifying the active mentions (the mentions that serve as arguments) and their correct boundaries from the data. This motivates us to build a novel latentvariable semi-Markov conditional random fields model (Sarawagi and Cohen, 2004) for such an event extraction task. The learned model takes in coarse information as produced by existing mention identification and typing modules, and jointly outputs selected mentions and their corresponding argument roles. • We address the problem in a more realistic scenario where annotated training instances are not available. We propose a novel general learning framework called structured preference modeling (or preference modeling, PM), which encompasses both the fully supervised and the latent-variable conditional models as special cases. The framework allows arbitrary declarative str</context>
<context position="11935" citStr="Sarawagi and Cohen (2004)" startWordPosition="1926" endWordPosition="1929">ment information. Specifically, the label of each gap segment is uniquely determined by its surrounding argument segments with a list representation. For example, in a “first-order” setting, the gap segment that appears between its previous argument segment “ATTACKER” and its next argument segment “INSTRUMENT” is annotated as the list consisting of two elements: [ATTACKER, INSTRUMENT]. To capture longer-range dependencies, in this work we use a “second-order” setting (as shown in Figure 2), 2The length of a gap segment is arbitrary (including zero), unlike the seminal semi-Markov CRF model of Sarawagi and Cohen (2004). aL(Θ) X= a0j i X− i 837 which means each gap segment is annotated with a list that consists of its previous two argument segments as well as its subsequent one. 2.3 Features Feature functions are factorized as products of two indicator functions: one defined on the input sequence (input features) and the other on the output labels (output features). In other words, we could re-write fj(s, h, t) as fin� (s) x f�u� l (h, t). For gap segments, we consider the following input feature templates: N-GRAM: Indicator function for n-gram appeared in the segment (n = 1, 2) ANCHOR: Indicator function fo</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>S. Sarawagi and W.W. Cohen. 2004. Semi-markov conditional random fields for information extraction. NIPS’04, pages 1185–1192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proc. of ACL’05,</booktitle>
<pages>354--362</pages>
<contexts>
<context position="34210" citStr="Smith and Eisner, 2005" startWordPosition="5581" endWordPosition="5584">ng et al., 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. They define a constrained EM framework that regularizes posterior distribution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comparison to our model. Unlike CoDL, in the PR framework constraints are relaxed to expectation constraints, in order to allow tractable dynamic programming. See also Samdani et al. (2012) for more discussions. Contrastive estimation (CE) (Smith and Eisner, 2005a) is another log-linear framework for primarily unsupervised structured prediction. Their objective function is related to the pseudolikelihood estimator proposed by Besag (1975). One challenge is that it requires one to design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon e</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N.A. Smith and J. Eisner. 2005a. Contrastive estimation: Training log-linear models on unlabeled data. In Proc. of ACL’05, pages 354–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Guiding unsupervised grammar induction using contrastive estimation.</title>
<date>2005</date>
<booktitle>In Proc. of IJCAI Workshop on Grammatical Inference Applications,</booktitle>
<pages>73--82</pages>
<contexts>
<context position="34210" citStr="Smith and Eisner, 2005" startWordPosition="5581" endWordPosition="5584">ng et al., 2007) and posterior regularization (PR) (Ganchev et al., 2010) are both primarily semi-supervised models. They define a constrained EM framework that regularizes posterior distribution at the E-step of each EM iteration, by pushing posterior distributions towards a constrained posterior set. We have already discussed CoDL in Section 4 and gave a comparison to our model. Unlike CoDL, in the PR framework constraints are relaxed to expectation constraints, in order to allow tractable dynamic programming. See also Samdani et al. (2012) for more discussions. Contrastive estimation (CE) (Smith and Eisner, 2005a) is another log-linear framework for primarily unsupervised structured prediction. Their objective function is related to the pseudolikelihood estimator proposed by Besag (1975). One challenge is that it requires one to design a priori an effective neighborhood (which also needs to be designed in certain forms to allow efficient computation of the normalization terms) in order to obtain optimal performance. The model has been shown to work in unsupervised tasks such as POS induction (Smith and Eisner, 2005a), grammar induction (Smith and Eisner, 2005b), and morphological segmentation (Poon e</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N.A. Smith and J. Eisner. 2005b. Guiding unsupervised grammar induction using contrastive estimation. In Proc. of IJCAI Workshop on Grammatical Inference Applications, pages 73–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Str¨otgen</author>
<author>M Gertz</author>
</authors>
<title>Heideltime: High quality rule-based extraction and normalization of temporal expressions.</title>
<date>2010</date>
<booktitle>In Proc. of SemEval’10,</booktitle>
<pages>321--324</pages>
<marker>Str¨otgen, Gertz, 2010</marker>
<rawString>J. Str¨otgen and M. Gertz. 2010. Heideltime: High quality rule-based extraction and normalization of temporal expressions. In Proc. of SemEval’10, pages 321– 324.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>