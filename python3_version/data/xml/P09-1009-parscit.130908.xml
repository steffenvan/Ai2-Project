<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.245991">
<title confidence="0.996374">
Unsupervised Multilingual Grammar Induction
</title>
<author confidence="0.999417">
Benjamin Snyder, Tahira Naseem, and Regina Barzilay
</author>
<affiliation confidence="0.998317">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.984346">
{bsnyder, tahira, regina}@csail.mit.edu
</email>
<sectionHeader confidence="0.994647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998922">
We investigate the task of unsupervised
constituency parsing from bilingual par-
allel corpora. Our goal is to use bilin-
gual cues to learn improved parsing mod-
els for each language and to evaluate these
models on held-out monolingual test data.
We formulate a generative Bayesian model
which seeks to explain the observed par-
allel data through a combination of bilin-
gual and monolingual parameters. To this
end, we adapt a formalism known as un-
ordered tree alignment to our probabilistic
setting. Using this formalism, our model
loosely binds parallel trees while allow-
ing language-specific syntactic structure.
We perform inference under this model us-
ing Markov Chain Monte Carlo and dy-
namic programming. Applying this model
to three parallel corpora (Korean-English,
Urdu-English, and Chinese-English) we
find substantial performance gains over
the CCM model, a strong monolingual
baseline. On average, across a variety of
testing scenarios, our model achieves an
8.8 absolute gain in F-measure. 1
</bodyText>
<sectionHeader confidence="0.998888" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9986064">
In this paper we investigate the task of unsuper-
vised constituency parsing when bilingual paral-
lel text is available. Our goal is to improve pars-
ing performance on monolingual test data for each
language by using unsupervised bilingual cues at
training time. Multilingual learning has been suc-
cessful for other linguistic induction tasks such as
lexicon acquisition, morphological segmentation,
and part-of-speech tagging (Genzel, 2005; Snyder
and Barzilay, 2008; Snyder et al., 2008; Snyder
</bodyText>
<footnote confidence="0.980104">
1Code and the outputs of our experiments are available at
http://groups.csail.mit.edu/rbg/code/multiling induction.
</footnote>
<bodyText confidence="0.999825853658537">
et al., 2009). We focus here on the unsupervised
induction of unlabeled constituency brackets. This
task has been extensively studied in a monolingual
setting and has proven to be difficult (Charniak
and Carroll, 1992; Klein and Manning, 2002).
The key premise of our approach is that am-
biguous syntactic structures in one language may
correspond to less uncertain structures in the other
language. For instance, the English sentence I
saw [the student [from MIT]] exhibits the classic
problem of PP-attachment ambiguity. However,
its Urdu translation, literally glossed as I [[MIT of]
student] saw, uses a genitive phrase that may only
be attached to the adjacent noun phrase. Know-
ing the correspondence between these sentences
should help us resolve the English ambiguity.
One of the main challenges of unsupervised
multilingual learning is to exploit cross-lingual
patterns discovered in data, while still allowing
a wide range of language-specific idiosyncrasies.
To this end, we adapt a formalism known as un-
ordered tree alignment (Jiang et al., 1995) to
a probabilistic setting. Under this formalism,
any two trees can be embedded in an alignment
tree. This alignment tree allows arbitrary parts
of the two trees to diverge in structure, permitting
language-specific grammatical structure to be pre-
served. Additionally, a computational advantage
of this formalism is that the marginalized probabil-
ity over all possible alignments for any two trees
can be efficiently computed with a dynamic pro-
gram in linear time.
We formulate a generative Bayesian model
which seeks to explain the observed parallel data
through a combination of bilingual and mono-
lingual parameters. Our model views each pair
of sentences as having been generated as fol-
lows: First an alignment tree is drawn. Each
node in this alignment tree contains either a soli-
tary monolingual constituent or a pair of coupled
bilingual constituents. For each solitary mono-
</bodyText>
<page confidence="0.988918">
73
</page>
<note confidence="0.999611">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 73–81,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999711964285715">
lingual constituent, a sequence of part-of-speech
tags is drawn from a language-specific distribu-
tion. For each pair of coupled bilingual con-
stituents, a pair of part-of-speech sequences are
drawn jointly from a cross-lingual distribution.
Word-level alignments are then drawn based on
the tree alignment. Finally, parallel sentences are
assembled from these generated part-of-speech se-
quences and word-level alignments.
To perform inference under this model, we use
a Metropolis-Hastings within-Gibbs sampler. We
sample pairs of trees and then compute marginal-
ized probabilities over all possible alignments us-
ing dynamic programming.
We test the effectiveness of our bilingual gram-
mar induction model on three corpora of parallel
text: English-Korean, English-Urdu and English-
Chinese. The model is trained using bilingual
data with automatically induced word-level align-
ments, but is tested on purely monolingual data
for each language. In all cases, our model out-
performs a state-of-the-art baseline: the Con-
stituent Context Model (CCM) (Klein and Man-
ning, 2002), sometimes by substantial margins.
On average, over all the testing scenarios that we
studied, our model achieves an absolute increase
in F-measure of 8.8 points, and a 19% reduction
in error relative to a theoretical upper bound.
</bodyText>
<sectionHeader confidence="0.999732" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999961126984127">
The unsupervised grammar induction task has
been studied extensively, mostly in a monolin-
gual setting (Charniak and Carroll, 1992; Stolcke
and Omohundro, 1994; Klein and Manning, 2002;
Seginer, 2007). While PCFGs perform poorly on
this task, the CCM model (Klein and Manning,
2002) has achieved large gains in performance and
is among the state-of-the-art probabilistic models
for unsupervised constituency parsing. We there-
fore use CCM as our basic model of monolingual
syntax.
While there has been some previous work on
bilingual CFG parsing, it has mainly focused on
improving MT systems rather than monolingual
parsing accuracy. Research in this direction was
pioneered by (Wu, 1997), who developed Inver-
sion Transduction Grammars to capture cross-
lingual grammar variations such as phrase re-
orderings. More general formalisms for the same
purpose were later developed (Wu and Wong,
1998; Chiang, 2005; Melamed, 2003; Eisner,
2003; Zhang and Gildea, 2005; Blunsom et al.,
2008). We know of only one study which eval-
uates these bilingual grammar formalisms on the
task of grammar induction itself (Smith and Smith,
2004). Both our model and even the monolingual
CCM baseline yield far higher performance on the
same Korean-English corpus.
Our approach is closer to the unsupervised
bilingual parsing model developed by Kuhn
(2004), which aims to improve monolingual per-
formance. Assuming that trees induced over paral-
lel sentences have to exhibit certain structural reg-
ularities, Kuhn manually specifies a set of rules
for determining when parsing decisions in the two
languages are inconsistent with GIZA++ word-
level alignments. By incorporating these con-
straints into the EM algorithm he was able to im-
prove performance over a monolingual unsuper-
vised PCFG. Still, the performance falls short of
state-of-the-art monolingual models such as the
CCM.
More recently, there has been a body of work
attempting to improve parsing performance by ex-
ploiting syntactically annotated parallel data. In
one strand of this work, annotations are assumed
only in a resource-rich language and are projected
onto a resource-poor language using the parallel
data (Hwa et al., 2005; Xi and Hwa, 2005). In
another strand of work, syntactic annotations are
assumed on both sides of the parallel data, and a
model is trained to exploit the parallel data at test
time as well (Smith and Smith, 2004; Burkett and
Klein, 2008). In contrast to this work, our goal
is to explore the benefits of multilingual grammar
induction in a fully unsupervised setting.
We finally note a recent paper which uses pa-
rameter tying to improve unsupervised depen-
dency parse induction (Cohen and Smith, 2009).
While the primary performance gains occur when
tying related parameters within a language, some
additional benefit is observed through bilingual ty-
ing, even in the absence of a parallel corpus.
</bodyText>
<sectionHeader confidence="0.992956" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999600571428571">
We propose an unsupervised Bayesian model for
learning bilingual syntactic structure using paral-
lel corpora. Our key premise is that difficult-to-
learn syntactic structures of one language may cor-
respond to simpler or less uncertain structures in
the other language. We treat the part-of-speech
tag sequences of parallel sentences, as well as their
</bodyText>
<page confidence="0.993651">
74
</page>
<figure confidence="0.994585666666667">
(iii)
(ii)
(i)
</figure>
<figureCaption confidence="0.983993666666667">
Figure 1: A pair of trees (i) and two possible alignment trees. In (ii), no empty spaces are inserted, but
the order of one of the original tree’s siblings has been reversed. In (iii), only two pairs of nodes have
been aligned (indicated by arrows) and many empty spaces inserted.
</figureCaption>
<bodyText confidence="0.999935416666667">
word-level alignments, as observed data. We ob-
tain these word-level alignments using GIZA++
(Och and Ney, 2003).
Our model seeks to explain this observed data
through a generative process whereby two aligned
parse trees are produced jointly. Though they
are aligned, arbitrary parts of the two trees are
permitted to diverge, accommodating language-
specific grammatical structure. In effect, our
model loosely binds the two trees: node-to-node
alignments need only be used where repeated
bilingual patterns can be discovered in the data.
</bodyText>
<subsectionHeader confidence="0.998434">
3.1 Tree Alignments
</subsectionHeader>
<bodyText confidence="0.999743428571429">
We achieve this loose binding of trees by adapting
unordered tree alignment (Jiang et al., 1995) to a
probabilistic setting. Under this formalism, any
two trees can be aligned using an alignment tree.
The alignment tree embeds the original two trees
within it: each node is labeled by a pair (x, y),
(A, y), or (x, A) where x is a node from the first
tree, y is a node from the second tree, and A is an
empty space. The individual structure of each tree
must be preserved under the embedding with the
exception of sibling order (to allow variations in
phrase and word order).
The flexibility of this formalism can be demon-
strated by two extreme cases: (1) an alignment be-
tween two trees may actually align none of their
individual nodes, instead inserting an empty space
A for each of the original two trees’ nodes. (2)
if the original trees are isomorphic to one an-
other, the alignment may match their nodes ex-
actly, without inserting any empty spaces. See
Figure 1 for an example.
</bodyText>
<subsectionHeader confidence="0.999881">
3.2 Model overview
</subsectionHeader>
<bodyText confidence="0.999955083333333">
As our basic model of syntactic structure, we
adopt the Constituent-Context Model (CCM) of
Klein and Manning (2002). Under this model,
the part-of-speech sequence of each span in a sen-
tence is generated either as a constituent yield
— if it is dominated by a node in the tree —
or otherwise as a distituent yield. For example,
in the bracketed sentence [John/NNP [climbed/VB
[the/DT tree/NN]]], the sequence VB DT NN is gen-
erated as a constituent yield, since it constitutes a
complete bracket in the tree. On the other hand,
the sequence VB DT is generated as a distituent,
since it does not. Besides these yields, the con-
texts (two surrounding POS tags) of constituents
and distituents are generated as well. In this exam-
ple, the context of the constituent VB DT NN would
be (NNP, #), while the context of the distituent VB
DT would be (NNP, NN). The CCM model em-
ploys separate multinomial distributions over con-
stituents, distituents, constituent contexts, and dis-
tituent contexts. While this model is deficient —
each observed subsequence of part-of-speech tags
is generated many times over — its performance
is far higher than that of unsupervised PCFGs.
Under our bilingual model, each pair of sen-
tences is assumed to have been generated jointly in
the following way: First, an unlabeled alignment
tree is drawn uniformly from the set of all such
trees. This alignment tree specifies the structure
of each of the two individual trees, as well as the
pairs of nodes which are aligned and those which
are not aligned (i.e. paired with a A).
For each pair of aligned nodes, a correspond-
ing pair of constituents and contexts are jointly
drawn from a bilingual distribution. For unaligned
nodes (i.e. nodes paired with a A in the alignment
</bodyText>
<page confidence="0.993205">
75
</page>
<bodyText confidence="0.9998274">
tree), a single constituent and context are drawn,
from language-specific distributions. Distituents
and their contexts are also drawn from language-
specific distributions. Finally, word-level align-
ments are drawn based on the structure of the
alignment tree.
In the next two sections, we describe our model
in more formal detail by specifying the parame-
ters and generative process by which sentences are
formed.
</bodyText>
<subsectionHeader confidence="0.999218">
3.3 Parameters
</subsectionHeader>
<bodyText confidence="0.995575">
Our model employs a number of multinomial dis-
tributions:
</bodyText>
<listItem confidence="0.997398714285714">
• πc : over constituent yields of language i,
• π�D : over distituent yields of language i,
• φc : over constituent contexts of language i,
• φD : over distituent contexts of language i,
• ω : over pairs of constituent yields, one from
the first language and the other from the sec-
ond language,
• Gzpair : over a finite set of integer val-
ues {−m, ... , −2, −1,0,1, 2, ... , m}, mea-
suring the Giza-score of aligned tree node
pairs (see below),
• Gznode : over a finite set of integer values
{−m, . . ., −2, −1,0}, measuring the Giza-
score of unaligned tree nodes (see below).
</listItem>
<bodyText confidence="0.999968394736842">
The first four distributions correspond exactly to
the parameters of the CCM model. Parameter ω is
a “coupling parameter” which measures the com-
patibility of tree-aligned constituent yield pairs.
The final two parameters measure the compatibil-
ity of syntactic alignments with the observed lexi-
cal GIZA++ alignments. Intuitively, aligned nodes
should have a high density of word-level align-
ments between them, and unaligned nodes should
have few lexical alignments.
More formally, consider a tree-aligned node
pair (n1, n2) with corresponding yields (y1, y2).
We call a word-level alignment good if it aligns
a word in y1 with a word in y2. We call a word-
level alignment bad if it aligns a word in y1 with
a word outside y2, or vice versa. The Giza-
score for (n1, n2) is the number of good word
alignments minus the number of bad word align-
ments. For example, suppose the constituent my
long name is node-aligned to its Urdu translation
mera lamba naam. If only the word-pairs my/mera
and name/naam are aligned, then the Giza-score
for this node-alignment would be 2. If however,
the English word long were (incorrectly) aligned
under GIZA++ to some Urdu word outside the cor-
responding constituent, then the score would drop
to 1. This score could even be negative if the num-
ber of bad alignments exceeds those that are good.
Distribution Gzpair provides a probability for these
scores (up to some fixed absolute value).
For an unaligned node n with corresponding
yield y, only bad GIZA++ alignments are possible,
thus the Giza-score for these nodes will always be
zero or negative. Distribution Gznode provides a
probability for these scores (down to some fixed
value). We want our model to find tree alignments
such that both aligned node pairs and unaligned
nodes have high Giza-score.
</bodyText>
<sectionHeader confidence="0.821697" genericHeader="method">
3.4 Generative Process
</sectionHeader>
<bodyText confidence="0.999400363636364">
Now we describe the stochastic process whereby
the observed parallel sentences and their word-
level alignments are generated, according to our
model.
As the first step in the Bayesian generative pro-
cess, all the multinomial parameters listed in the
previous section are drawn from their conjugate
priors — Dirichlet distributions of appropriate di-
mension. Then, each pair of word-aligned parallel
sentences is generated through the following pro-
cess:
</bodyText>
<listItem confidence="0.880241">
1. A pair of binary trees T1 and T2 along with
</listItem>
<bodyText confidence="0.991979642857143">
an alignment tree A are drawn according to
P(T1, T2, A). A is an alignment tree for T1
and T2 if it can be obtained by the follow-
ing steps: First insert blank nodes (labeled by
λ) into T1 and T2. Then permute the order
of sibling nodes such that the two resulting
trees T10 and T20 are identical in structure. Fi-
nally, overlay T10 and T20 to obtain A. We ad-
ditionally require that A contain no extrane-
ous nodes – that is no nodes with two blank
labels (λ, λ). See Figure 1 for an example.
We define the distribution P(T1, T2, A) to be
uniform over all pairs of binary trees and their
alignments.
</bodyText>
<listItem confidence="0.993666466666667">
2. For each node in A of the form (n1, λ) (i.e.
nodes in T1 left unaligned by A), draw
(i) a constituent yield according to π�1 ,
76
(ii) a constituent context according to 0C1 ,
(iii) a Giza-score according to Gznode.
3. For each node in A of the form (A, n2) (i.e.
nodes in T2 left unaligned by A), draw
(i) a constituent yield according to 7rC2 ,
(ii) a constituent context according to 0C2 ,
(iii) a Giza-score according to Gznode.
4. For each node in A of the form (n1, n2) (i.e.
tree-aligned node pairs), draw
(i) a pair of constituent yields (y1, y2) ac-
cording to:
</listItem>
<equation confidence="0.998451">
0C1 (y1) - 0C2 (y2) - W(y1, y2) (1)
Z
</equation>
<bodyText confidence="0.99889725">
which is a product of experts combining
the language specific context-yield dis-
tributions as well as the coupling distri-
bution W with normalization constant Z,
</bodyText>
<listItem confidence="0.95093875">
(ii) a pair of contexts according to the ap-
propriate language-specific parameters,
(iii) a Giza-score according to Gzpair.
5. For each span in Ti not dominated by a node
</listItem>
<bodyText confidence="0.998106333333333">
(for each language i E 11, 2}), draw a dis-
tituent yield according to 7rDi and a distituent
context according to 0Di .
</bodyText>
<listItem confidence="0.876819">
6. Draw actual word-level alignments consis-
</listItem>
<bodyText confidence="0.998739333333333">
tent with the Giza-scores, according to a uni-
form distribution.
In the next section we turn to the problem of
inference under this model when only the part-
of-speech tag sequences of parallel sentences and
their word-level alignments are observed.
</bodyText>
<sectionHeader confidence="0.837589" genericHeader="method">
3.5 Inference
</sectionHeader>
<bodyText confidence="0.99998412195122">
Given a corpus of paired part-of-speech tag se-
quences (s1, s2) and their GIZA++ alignments
g, we would ideally like to predict the set of
tree pairs (T1, T2) which have highest proba-
bility when conditioned on the observed data:
P(T1, T2Is1, s2, g). We could rewrite this by
explicitly integrating over the yield, context, cou-
pling, Giza-score parameters as well as the align-
ment trees. However, since maximizing this in-
tegral directly would be intractable, we resort to
standard Markov chain sampling techniques. We
use Gibbs sampling (Hastings, 1970) to draw trees
for each sentence conditioned on those drawn for
all other sentences. The samples form a Markov
chain which is guaranteed to converge to the true
joint distribution over all sentences.
In the monolingual setting, there is a well-
known tree sampling algorithm (Johnson et al.,
2007). This algorithm proceeds in top-down fash-
ion by sampling individual split points using the
marginal probabilities of all possible subtrees.
These marginals can be efficiently pre-computed
and form the “inside” table of the famous Inside-
Outside algorithm. However, in our setting, trees
come in pairs, and their joint probability crucially
depends on their alignment.
For the ith parallel sentence, we wish to jointly
sample the pair of trees (T1,T2)i together with
their alignment Ai. To do so directly would in-
volve simultaneously marginalizing over all pos-
sible subtrees as well as all possible alignments
between such subtrees when sampling upper-level
split points. We know of no obvious algorithm
for computing this marginal. We instead first sam-
ple the pair of trees (T1, T2)i from a simpler pro-
posal distribution Q. Our proposal distribution as-
sumes that no nodes of the two trees are aligned
and therefore allows us to use the recursive top-
down sampling algorithm mentioned above. After
a new tree pair T∗ _ (T1∗, T2∗ )i is drawn from Q,
we accept the pair with the following probability:
</bodyText>
<equation confidence="0.968346">
min �
1,
P(T∗ T−i, A−i) Q(T|T−i, A−i)
P(T |T−i, A−i) Q(T∗|T−i, A−i)
</equation>
<bodyText confidence="0.999920809523809">
where T is the previously sampled tree-pair for
sentence i, P is the true model probability, and
Q is the probability under the proposal distribu-
tion. This use of a tractable proposal distribution
and acceptance ratio is known as the Metropolis-
Hastings algorithm and it preserves the conver-
gence guarantee of the Gibbs sampler (Hastings,
1970). To compute the terms P(T∗|T−i,A−i)
and P(T |T−i, A−i) in the acceptance ratio above,
we need to marginalize over all possible align-
ments between tree pairs.
Fortunately, for any given pair of trees T1 and
T2 this marginalization can be computed using
a dynamic program in time O(|T1||T2|). Here
we provide a very brief sketch. For every pair
of nodes n1 E T1, n2 E T2, a table stores the
marginal probability of the subtrees rooted at n1
and n2, respectively. A dynamic program builds
this table from the bottom up: For each node pair
n1, n2, we sum the probabilities of all local align-
ment configurations, each multiplied by the appro-
</bodyText>
<page confidence="0.996804">
77
</page>
<bodyText confidence="0.999858074074074">
priate marginals already computed in the table for
lower-level node pairs. This algorithm is an adap-
tation of the dynamic program presented in (Jiang
et al., 1995) for finding minimum cost alignment
trees (Fig. 5 of that publication).
Once a pair of trees (T1, T2) has been sam-
pled, we can proceed to sample an alignment tree
AIT1, T2.2 We sample individual alignment deci-
sions from the top down, at each step using the
alignment marginals for the remaining subtrees
(already computed using the afore-mentioned dy-
namic program). Once the triple (T1, T2, A) has
been sampled, we move on to the next parallel sen-
tence.
We avoid directly sampling parameter val-
ues, instead using the marginalized closed forms
for multinomials with Dirichlet conjugate-priors
using counts and hyperparameter pseudo-counts
(Gelman et al., 2004). Note that in the case of
yield pairs produced according to Distribution 1
(in step 4 of the generative process) conjugacy is
technically broken, since the yield pairs are no
longer produced by a single multinomial distribu-
tion. Nevertheless, we count the produced yields
as if they had been generated separately by each
of the distributions involved in the numerator of
Distribution 1.
</bodyText>
<sectionHeader confidence="0.997975" genericHeader="method">
4 Experimental setup
</sectionHeader>
<bodyText confidence="0.999714947368421">
We test our model on three corpora of bilin-
gual parallel sentences: English-Korean, English-
Urdu, and English-Chinese. Though the model is
trained using parallel data, during testing it has ac-
cess only to monolingual data. This set-up ensures
that we are testing our model’s ability to learn bet-
ter parameters at training time, rather than its abil-
ity to exploit parallel data at test time. Following
(Klein and Manning, 2002), we restrict our model
to binary trees, though we note that the alignment
trees do not follow this restriction.
Data The Penn Korean Treebank (Han et al.,
2002) consists of 5,083 Korean sentences trans-
lated into English for the purposes of language
training in a military setting. Both the Korean
and English sentences are annotated with syntactic
trees. We use the first 4,000 sentences for training
and the last 1,083 sentences for testing. We note
that in the Korean data, a separate tag is given for
</bodyText>
<footnote confidence="0.991214333333333">
2Sampling the alignment tree is important, as it provides
us with counts of aligned constituents for the coupling pa-
rameter.
</footnote>
<bodyText confidence="0.999787734693878">
each morpheme. We simply concatenate all the
morpheme tags given for each word and treat the
concatenation as a single tag. This procedure re-
sults in 199 different tags. The English-Urdu par-
allel corpus3 consists of 4,325 sentences from the
first three sections of the Penn Treebank and their
Urdu translations annotated at the part-of-speech
level. The Urdu side of this corpus does not pro-
vide tree annotations so here we can test parse ac-
curacy only on English. We use the remaining
sections of the Penn Treebank for English test-
ing. The English-Chinese treebank (Bies et al.,
2007) consists of 3,850 Chinese newswire sen-
tences translated into English. Both the English
and Chinese sentences are annotated with parse
trees. We use the first 4/5 for training and the final
1/5 for testing.
During preprocessing of the corpora we remove
all punctuation marks and special symbols, fol-
lowing the setup in previous grammar induction
work (Klein and Manning, 2002). To obtain lex-
ical alignments between the parallel sentences we
employ GIZA++ (Och and Ney, 2003). We use in-
tersection alignments, which are one-to-one align-
ments produced by taking the intersection of one-
to-many alignments in each direction. These one-
to-one intersection alignments tend to have higher
precision.
We initialize the trees by making uniform split
decisions recursively from the top down for sen-
tences in both languages. Then for each pair of
parallel sentences we randomly sample an initial
alignment tree for the two sampled trees.
Baseline We implement a Bayesian version of
the CCM as a baseline. This model uses the same
inference procedure as our bilingual model (Gibbs
sampling). In fact, our model reduces to this
Bayesian CCM when it is assumed that no nodes
between the two parallel trees are ever aligned
and when word-level alignments are ignored. We
also reimplemented the original EM version of
CCM and found virtually no difference in perfor-
mance when using EM or Gibbs sampling. In both
cases our implementation achieves F-measure in
the range of 69-70% on WSJ10, broadly in line
with the performance reported by Klein and Man-
ning (2002).
Hyperparameters Klein (2005) reports using
smoothing pseudo-counts of 2 for constituent
</bodyText>
<footnote confidence="0.990749">
3http://www.crulp.org
</footnote>
<page confidence="0.995998">
78
</page>
<figureCaption confidence="0.984899666666667">
Figure 2: The F-measure of the CCM baseline (dotted line) and bilingual model (solid line) plotted on
the y-axis, as the maximum sentence length in the test set is increased (x-axis). Results are averaged over
all training scenarios given in Table 1.
</figureCaption>
<bodyText confidence="0.999895945454546">
yields and contexts and 8 for distituent yields and
contexts. In our Bayesian model, these similar
smoothing counts occur as the parameters of the
Dirichlet priors. For Korean we found that the
baseline performed well using these values. How-
ever, on our English and Chinese data, we found
that somewhat higher smoothing values worked
best, so we utilized values of 20 and 80 for con-
stituent and distituent smoothing counts, respec-
tively.
Our model additionally requires hyperparam-
eter values for w (the coupling distribution for
aligned yields), Gzpair and Gznode (the distribu-
tions over Giza-scores for aligned nodes and un-
aligned nodes, respectively). For w we used a
symmetric Dirichlet prior with parameter 1. For
Gzpair and Gznode, in order to create a strong bias
towards high Giza-scores, we used non-symmetric
Dirichlet priors. In both cases, we capped the ab-
solute value of the scores at 3, to prevent count
sparsity. In the case of Gzpair we gave pseudo-
counts of 1,000 for negative values and zero, and
pseudo-counts of 1,000,000 for positive scores.
For Gznode we gave a pseudo-count of 1,000,000
for a score of zero, and 1,000 for all nega-
tive scores. This very strong prior bias encodes
our intuition that syntactic alignments which re-
spect lexical alignments should be preferred. Our
method is not sensitive to these exact values and
any reasonably strong bias gave similar results.
In all our experiments, we consider the hyper-
parameters fixed and observed values.
Testing and evaluation As mentioned above,
we test our model only on monolingual data,
where the parallel sentences are not provided to
the model. To predict the bracketings of these
monolingual test sentences, we take the smoothed
counts accumulated in the final round of sampling
over the training data and perform a maximum
likelihood estimate of the monolingual CCM pa-
rameters. These parameters are then used to pro-
duce the highest probability bracketing of the test
set.
To evaluate both our model as well as the base-
line, we use (unlabeled) bracket precision, re-
call, and F-measure (Klein and Manning, 2002).
Following previous work, we include the whole-
sentence brackets but ignore single-word brack-
ets. We perform experiments on different subsets
of training and testing data based on the sentence-
length. In particular we experimented with sen-
tence length limits of 10, 20, and 30 for both the
training and testing sets. We also report the upper
bound on F-measure for binary trees. We average
the results over 10 separate sampling runs.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999763529411765">
Table 1 reports the full results of our experiments.
In all testing scenarios the bilingual model out-
performs its monolingual counterpart in terms of
both precision and recall. On average, the bilin-
gual model gains 10.2 percentage points in preci-
sion, 7.7 in recall, and 8.8 in F-measure. The gap
between monolingual performance and the binary
tree upper bound is reduced by over 19%.
The extent of the gain varies across pairings.
For instance, the smallest improvement is ob-
served for English when trained with Urdu. The
Korean-English pairing results in substantial im-
provements for Korean and quite large improve-
ments for English, for which the absolute gain
reaches 28 points in F-measure. In the case of Chi-
nese and English, the gains for English are fairly
minimal whereas those for Chinese are quite sub-
</bodyText>
<page confidence="0.99676">
79
</page>
<table confidence="0.99980071875">
Max Sent. Length Monolingual Bilingual Upper Bound
EN with KR Test Train Precision Recall F1 Precision Recall F1 F1
10 10 52.74 39.53 45.19 57.76 43.30 49.50 85.6
20 41.87 31.38 35.87 61.66 46.22 52.83 85.6
30 33.43 25.06 28.65 64.41 48.28 55.19 85.6
20 20 35.12 25.12 29.29 56.96 40.74 47.50 83.3
30 26.26 18.78 21.90 60.07 42.96 50.09 83.3
30 30 23.95 16.81 19.76 58.01 40.73 47.86 82.4
KR with EN 10 10 71.07 62.55 66.54 75.63 66.56 70.81 93.6
20 71.35 62.79 66.80 77.61 68.30 72.66 93.6
30 71.37 62.81 66.82 77.87 68.53 72.91 93.6
20 20 64.28 54.73 59.12 70.44 59.98 64.79 91.9
30 64.29 54.75 59.14 70.81 60.30 65.13 91.9
30 30 63.63 54.17 58.52 70.11 59.70 64.49 91.9
EN with CH 10 10 50.09 34.18 40.63 37.46 25.56 30.39 81.0
20 58.86 40.17 47.75 50.24 34.29 40.76 81.0
30 64.81 44.22 52.57 68.24 46.57 55.36 81.0
20 20 41.90 30.52 35.31 38.64 28.15 32.57 84.3
30 52.83 38.49 44.53 58.50 42.62 49.31 84.3
30 30 46.35 33.67 39.00 51.40 37.33 43.25 84.1
CH with EN 10 10 39.87 27.71 32.69 40.62 28.23 33.31 81.9
20 43.44 30.19 35.62 47.54 33.03 38.98 81.9
30 43.63 30.32 35.77 54.09 37.59 44.36 81.9
20 20 29.80 23.46 26.25 36.93 29.07 32.53 88.0
30 30.05 23.65 26.47 43.99 34.63 38.75 88.0
30 30 24.46 19.41 21.64 39.61 31.43 35.05 88.4
EN with UR 10 10 57.98 45.68 51.10 73.43 57.85 64.71 88.1
20 70.57 55.60 62.20 80.24 63.22 70.72 88.1
30 75.39 59.40 66.45 79.04 62.28 69.67 88.1
20 20 57.78 43.86 49.87 67.26 51.06 58.05 86.3
30 63.12 47.91 54.47 64.45 48.92 55.62 86.3
30 30 57.36 43.02 49.17 57.97 43.48 49.69 85.7
</table>
<tableCaption confidence="0.99136575">
Table 1: Unlabeled precision, recall and F-measure for the monolingual baseline and the bilingual model
on several test sets. We report results for different combinations of maximum sentence length in both the
training and test sets. The right most column, in all cases, contains the maximum F-measure achievable
using binary trees. The best performance for each test-length is highlighted in bold.
</tableCaption>
<bodyText confidence="0.9994304">
stantial. This asymmetry should not be surprising,
as Chinese on its own seems to be quite a bit more
difficult to parse than English.
We also investigated the impact of sentence
length for both the training and testing sets. For
our model, adding sentences of greater length to
the training set leads to increases in parse accu-
racy for short sentences. For the baseline, how-
ever, adding this additional training data degrades
performance in the case of English paired with Ko-
rean. Figure 2 summarizes the performance of
our model for different sentence lengths on sev-
eral of the test-sets. As shown in the figure, the
largest improvements tend to occur at longer sen-
tence lengths.
</bodyText>
<sectionHeader confidence="0.999004" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999884777777778">
We have presented a probabilistic model for bilin-
gual grammar induction which uses raw parallel
text to learn tree pairs and their alignments. Our
formalism loosely binds the two trees, using bilin-
gual patterns when possible, but allowing substan-
tial language-specific variation. We tested our
model on three test sets and showed substantial
improvement over a state-of-the-art monolingual
baseline.4
</bodyText>
<footnote confidence="0.997065333333333">
4The authors acknowledge the support of the NSF (CA-
REER grant IIS-0448168, grant IIS-0835445, and grant IIS-
0835652). Thanks to Amir Globerson and members of the
MIT NLP group for their helpful suggestions. Any opinions,
findings, or conclusions are those of the authors, and do not
necessarily reflect the views of the funding organizations
</footnote>
<page confidence="0.997211">
80
</page>
<sectionHeader confidence="0.983477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99989894059406">
Ann Bies, Martha Palmer, Justin Mott, and Colin
Warner. 2007. English Chinese translation treebank
v 1.0. LDC2007T02.
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
Bayesian synchronous grammar induction. In Pro-
ceedings of NIPS.
David Burkett and Dan Klein. 2008. Two languages
are better than one (for syntactic parsing). In Pro-
ceedings of EMNLP, pages 877–886.
Eugene Charniak and Glen Carroll. 1992. Two exper-
iments on learning probabilistic dependency gram-
mars from corpora. In Proceedings of the AAAI
Workshop on Statistically-Based NLP Techniques,
pages 1–13.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the ACL, pages 263–270.
Shay B. Cohen and Noah A. Smith. 2009. Shared lo-
gistic normal distributions for soft parameter tying
in unsupervised grammar induction. In Proceedings
of the NAACL/HLT.
Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In The Compan-
ion Volume to the Proceedings of the ACL, pages
205–208.
Andrew Gelman, John B. Carlin, Hal S. Stern, and
Donald B. Rubin. 2004. Bayesian data analysis.
Chapman and Hall/CRC.
Dmitriy Genzel. 2005. Inducing a multilingual dictio-
nary from a parallel multitext in related languages.
In Proceedings of EMNLP/HLT, pages 875–882.
C. Han, N.R. Han, E.S. Ko, H. Yi, and M. Palmer.
2002. Penn Korean Treebank: Development and
evaluation. In Proc. Pacific Asian Conf. Language
and Comp.
W. K. Hastings. 1970. Monte carlo sampling meth-
ods using Markov chains and their applications.
Biometrika, 57:97–109.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
O. Kolak. 2005. Bootstrapping parsers via syntactic
projection across parallel texts. Journal of Natural
Language Engineering, 11(3):311–325.
T. Jiang, L. Wang, and K. Zhang. 1995. Alignment of
trees – an alternative to tree edit. Theoretical Com-
puter Science, 143(1):137–148.
M. Johnson, T. Griffiths, and S. Goldwater. 2007.
Bayesian inference for PCFGs via Markov chain
Monte Carlo. In Proceedings of the NAACL/HLT,
pages 139–146.
Dan Klein and Christopher D. Manning. 2002. A
generative constituent-context model for improved
grammar induction. In Proceedings of the ACL,
pages 128–135.
D. Klein. 2005. The Unsupervised Learning of Natu-
ral Language Structure. Ph.D. thesis, Stanford Uni-
versity.
Jonas Kuhn. 2004. Experiments in parallel-text based
grammar induction. In Proceedings of the ACL,
pages 470–477.
I. Dan Melamed. 2003. Multitext grammars
and synchronous parsers. In Proceedings of the
NAACL/HLT, pages 79–86.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Yoav Seginer. 2007. Fast unsupervised incremental
parsing. In Proceedings of the ACL, pages 384–391.
David A. Smith and Noah A. Smith. 2004. Bilingual
parsing with factored estimation: Using English to
parse Korean. In Proceeding of EMNLP, pages 49–
56.
Benjamin Snyder and Regina Barzilay. 2008. Un-
supervised multilingual learning for morphological
segmentation. In Proceedings of the ACL/HLT,
pages 737–745.
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
and Regina Barzilay. 2008. Unsupervised multi-
lingual learning for POS tagging. In Proceedings of
EMNLP, pages 1041–1050.
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,
and Regina Barzilay. 2009. Adding more languages
improves unsupervised multilingual part-of-speech
tagging: A Bayesian non-parametric approach. In
Proceedings of the NAACL/HLT.
Andreas Stolcke and Stephen M. Omohundro. 1994.
Inducing probabilistic grammars by Bayesian model
merging. In Proceedings of ICGI, pages 106–118.
Dekai Wu and Hongsing Wong. 1998. Machine
translation with a stochastic grammatical channel.
In Proceedings of the ACL/COLING, pages 1408–
1415.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
Chenhai Xi and Rebecca Hwa. 2005. A backoff
model for bootstrapping resources for non-english
languages. In Proceedings of EMNLP, pages 851 –
858.
Hao Zhang and Daniel Gildea. 2005. Stochastic lex-
icalized inversion transduction grammar for align-
ment. In Proceedings of the ACL, pages 475–482.
</reference>
<page confidence="0.999264">
81
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.859930">
<title confidence="0.970498">Unsupervised Multilingual Grammar Induction</title>
<author confidence="0.941615">Tahira Naseem Snyder</author>
<author confidence="0.941615">Barzilay</author>
<affiliation confidence="0.999965">Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology</affiliation>
<email confidence="0.934781">tahira,</email>
<abstract confidence="0.999266961538461">We investigate the task of unsupervised constituency parsing from bilingual parallel corpora. Our goal is to use bilingual cues to learn improved parsing models for each language and to evaluate these models on held-out monolingual test data. We formulate a generative Bayesian model which seeks to explain the observed parallel data through a combination of bilingual and monolingual parameters. To this we adapt a formalism known as untree alignment our probabilistic setting. Using this formalism, our model loosely binds parallel trees while allowing language-specific syntactic structure. We perform inference under this model using Markov Chain Monte Carlo and dynamic programming. Applying this model to three parallel corpora (Korean-English, Urdu-English, and Chinese-English) we find substantial performance gains over the CCM model, a strong monolingual baseline. On average, across a variety of testing scenarios, our model achieves an absolute gain in F-measure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Martha Palmer</author>
<author>Justin Mott</author>
<author>Colin Warner</author>
</authors>
<title>English Chinese translation treebank v 1.0.</title>
<date>2007</date>
<pages>2007--02</pages>
<contexts>
<context position="23276" citStr="Bies et al., 2007" startWordPosition="3819" endWordPosition="3822">ents for the coupling parameter. each morpheme. We simply concatenate all the morpheme tags given for each word and treat the concatenation as a single tag. This procedure results in 199 different tags. The English-Urdu parallel corpus3 consists of 4,325 sentences from the first three sections of the Penn Treebank and their Urdu translations annotated at the part-of-speech level. The Urdu side of this corpus does not provide tree annotations so here we can test parse accuracy only on English. We use the remaining sections of the Penn Treebank for English testing. The English-Chinese treebank (Bies et al., 2007) consists of 3,850 Chinese newswire sentences translated into English. Both the English and Chinese sentences are annotated with parse trees. We use the first 4/5 for training and the final 1/5 for testing. During preprocessing of the corpora we remove all punctuation marks and special symbols, following the setup in previous grammar induction work (Klein and Manning, 2002). To obtain lexical alignments between the parallel sentences we employ GIZA++ (Och and Ney, 2003). We use intersection alignments, which are one-to-one alignments produced by taking the intersection of oneto-many alignments</context>
</contexts>
<marker>Bies, Palmer, Mott, Warner, 2007</marker>
<rawString>Ann Bies, Martha Palmer, Justin Mott, and Colin Warner. 2007. English Chinese translation treebank v 1.0. LDC2007T02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Miles Osborne</author>
</authors>
<title>Bayesian synchronous grammar induction.</title>
<date>2008</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="6244" citStr="Blunsom et al., 2008" startWordPosition="938" endWordPosition="941">babilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rules for determining when parsing decisions in the two languages</context>
</contexts>
<marker>Blunsom, Cohn, Osborne, 2008</marker>
<rawString>Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008. Bayesian synchronous grammar induction. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>877--886</pages>
<contexts>
<context position="7670" citStr="Burkett and Klein, 2008" startWordPosition="1167" endWordPosition="1170">ce falls short of state-of-the-art monolingual models such as the CCM. More recently, there has been a body of work attempting to improve parsing performance by exploiting syntactically annotated parallel data. In one strand of this work, annotations are assumed only in a resource-rich language and are projected onto a resource-poor language using the parallel data (Hwa et al., 2005; Xi and Hwa, 2005). In another strand of work, syntactic annotations are assumed on both sides of the parallel data, and a model is trained to exploit the parallel data at test time as well (Smith and Smith, 2004; Burkett and Klein, 2008). In contrast to this work, our goal is to explore the benefits of multilingual grammar induction in a fully unsupervised setting. We finally note a recent paper which uses parameter tying to improve unsupervised dependency parse induction (Cohen and Smith, 2009). While the primary performance gains occur when tying related parameters within a language, some additional benefit is observed through bilingual tying, even in the absence of a parallel corpus. 3 Model We propose an unsupervised Bayesian model for learning bilingual syntactic structure using parallel corpora. Our key premise is that </context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of EMNLP, pages 877–886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Glen Carroll</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the AAAI Workshop on Statistically-Based NLP Techniques,</booktitle>
<pages>1--13</pages>
<contexts>
<context position="2077" citStr="Charniak and Carroll, 1992" startWordPosition="296" endWordPosition="299">uage by using unsupervised bilingual cues at training time. Multilingual learning has been successful for other linguistic induction tasks such as lexicon acquisition, morphological segmentation, and part-of-speech tagging (Genzel, 2005; Snyder and Barzilay, 2008; Snyder et al., 2008; Snyder 1Code and the outputs of our experiments are available at http://groups.csail.mit.edu/rbg/code/multiling induction. et al., 2009). We focus here on the unsupervised induction of unlabeled constituency brackets. This task has been extensively studied in a monolingual setting and has proven to be difficult (Charniak and Carroll, 1992; Klein and Manning, 2002). The key premise of our approach is that ambiguous syntactic structures in one language may correspond to less uncertain structures in the other language. For instance, the English sentence I saw [the student [from MIT]] exhibits the classic problem of PP-attachment ambiguity. However, its Urdu translation, literally glossed as I [[MIT of] student] saw, uses a genitive phrase that may only be attached to the adjacent noun phrase. Knowing the correspondence between these sentences should help us resolve the English ambiguity. One of the main challenges of unsupervised</context>
<context position="5393" citStr="Charniak and Carroll, 1992" startWordPosition="807" endWordPosition="810">ilingual data with automatically induced word-level alignments, but is tested on purely monolingual data for each language. In all cases, our model outperforms a state-of-the-art baseline: the Constituent Context Model (CCM) (Klein and Manning, 2002), sometimes by substantial margins. On average, over all the testing scenarios that we studied, our model achieves an absolute increase in F-measure of 8.8 points, and a 19% reduction in error relative to a theoretical upper bound. 2 Related Work The unsupervised grammar induction task has been studied extensively, mostly in a monolingual setting (Charniak and Carroll, 1992; Stolcke and Omohundro, 1994; Klein and Manning, 2002; Seginer, 2007). While PCFGs perform poorly on this task, the CCM model (Klein and Manning, 2002) has achieved large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Gra</context>
</contexts>
<marker>Charniak, Carroll, 1992</marker>
<rawString>Eugene Charniak and Glen Carroll. 1992. Two experiments on learning probabilistic dependency grammars from corpora. In Proceedings of the AAAI Workshop on Statistically-Based NLP Techniques, pages 1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="6168" citStr="Chiang, 2005" startWordPosition="928" endWordPosition="929">ed large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifie</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of the ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL/HLT.</booktitle>
<contexts>
<context position="7933" citStr="Cohen and Smith, 2009" startWordPosition="1210" endWordPosition="1213">ly in a resource-rich language and are projected onto a resource-poor language using the parallel data (Hwa et al., 2005; Xi and Hwa, 2005). In another strand of work, syntactic annotations are assumed on both sides of the parallel data, and a model is trained to exploit the parallel data at test time as well (Smith and Smith, 2004; Burkett and Klein, 2008). In contrast to this work, our goal is to explore the benefits of multilingual grammar induction in a fully unsupervised setting. We finally note a recent paper which uses parameter tying to improve unsupervised dependency parse induction (Cohen and Smith, 2009). While the primary performance gains occur when tying related parameters within a language, some additional benefit is observed through bilingual tying, even in the absence of a parallel corpus. 3 Model We propose an unsupervised Bayesian model for learning bilingual syntactic structure using parallel corpora. Our key premise is that difficult-tolearn syntactic structures of one language may correspond to simpler or less uncertain structures in the other language. We treat the part-of-speech tag sequences of parallel sentences, as well as their 74 (iii) (ii) (i) Figure 1: A pair of trees (i) </context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of the NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Learning non-isomorphic tree mappings for machine translation.</title>
<date>2003</date>
<booktitle>In The Companion Volume to the Proceedings of the ACL,</booktitle>
<pages>205--208</pages>
<contexts>
<context position="6197" citStr="Eisner, 2003" startWordPosition="932" endWordPosition="933"> and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rules for determin</context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In The Companion Volume to the Proceedings of the ACL, pages 205–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Gelman</author>
<author>John B Carlin</author>
<author>Hal S Stern</author>
<author>Donald B Rubin</author>
</authors>
<title>Bayesian data analysis. Chapman and Hall/CRC.</title>
<date>2004</date>
<contexts>
<context position="21227" citStr="Gelman et al., 2004" startWordPosition="3478" endWordPosition="3481">es (Fig. 5 of that publication). Once a pair of trees (T1, T2) has been sampled, we can proceed to sample an alignment tree AIT1, T2.2 We sample individual alignment decisions from the top down, at each step using the alignment marginals for the remaining subtrees (already computed using the afore-mentioned dynamic program). Once the triple (T1, T2, A) has been sampled, we move on to the next parallel sentence. We avoid directly sampling parameter values, instead using the marginalized closed forms for multinomials with Dirichlet conjugate-priors using counts and hyperparameter pseudo-counts (Gelman et al., 2004). Note that in the case of yield pairs produced according to Distribution 1 (in step 4 of the generative process) conjugacy is technically broken, since the yield pairs are no longer produced by a single multinomial distribution. Nevertheless, we count the produced yields as if they had been generated separately by each of the distributions involved in the numerator of Distribution 1. 4 Experimental setup We test our model on three corpora of bilingual parallel sentences: English-Korean, EnglishUrdu, and English-Chinese. Though the model is trained using parallel data, during testing it has ac</context>
</contexts>
<marker>Gelman, Carlin, Stern, Rubin, 2004</marker>
<rawString>Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin. 2004. Bayesian data analysis. Chapman and Hall/CRC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitriy Genzel</author>
</authors>
<title>Inducing a multilingual dictionary from a parallel multitext in related languages.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP/HLT,</booktitle>
<pages>875--882</pages>
<contexts>
<context position="1687" citStr="Genzel, 2005" startWordPosition="243" endWordPosition="244">ins over the CCM model, a strong monolingual baseline. On average, across a variety of testing scenarios, our model achieves an 8.8 absolute gain in F-measure. 1 1 Introduction In this paper we investigate the task of unsupervised constituency parsing when bilingual parallel text is available. Our goal is to improve parsing performance on monolingual test data for each language by using unsupervised bilingual cues at training time. Multilingual learning has been successful for other linguistic induction tasks such as lexicon acquisition, morphological segmentation, and part-of-speech tagging (Genzel, 2005; Snyder and Barzilay, 2008; Snyder et al., 2008; Snyder 1Code and the outputs of our experiments are available at http://groups.csail.mit.edu/rbg/code/multiling induction. et al., 2009). We focus here on the unsupervised induction of unlabeled constituency brackets. This task has been extensively studied in a monolingual setting and has proven to be difficult (Charniak and Carroll, 1992; Klein and Manning, 2002). The key premise of our approach is that ambiguous syntactic structures in one language may correspond to less uncertain structures in the other language. For instance, the English se</context>
</contexts>
<marker>Genzel, 2005</marker>
<rawString>Dmitriy Genzel. 2005. Inducing a multilingual dictionary from a parallel multitext in related languages. In Proceedings of EMNLP/HLT, pages 875–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Han</author>
<author>N R Han</author>
<author>E S Ko</author>
<author>H Yi</author>
<author>M Palmer</author>
</authors>
<title>Penn Korean Treebank: Development and evaluation.</title>
<date>2002</date>
<booktitle>In Proc. Pacific Asian Conf. Language and Comp.</booktitle>
<contexts>
<context position="22222" citStr="Han et al., 2002" startWordPosition="3642" endWordPosition="3645">bution 1. 4 Experimental setup We test our model on three corpora of bilingual parallel sentences: English-Korean, EnglishUrdu, and English-Chinese. Though the model is trained using parallel data, during testing it has access only to monolingual data. This set-up ensures that we are testing our model’s ability to learn better parameters at training time, rather than its ability to exploit parallel data at test time. Following (Klein and Manning, 2002), we restrict our model to binary trees, though we note that the alignment trees do not follow this restriction. Data The Penn Korean Treebank (Han et al., 2002) consists of 5,083 Korean sentences translated into English for the purposes of language training in a military setting. Both the Korean and English sentences are annotated with syntactic trees. We use the first 4,000 sentences for training and the last 1,083 sentences for testing. We note that in the Korean data, a separate tag is given for 2Sampling the alignment tree is important, as it provides us with counts of aligned constituents for the coupling parameter. each morpheme. We simply concatenate all the morpheme tags given for each word and treat the concatenation as a single tag. This pr</context>
</contexts>
<marker>Han, Han, Ko, Yi, Palmer, 2002</marker>
<rawString>C. Han, N.R. Han, E.S. Ko, H. Yi, and M. Palmer. 2002. Penn Korean Treebank: Development and evaluation. In Proc. Pacific Asian Conf. Language and Comp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W K Hastings</author>
</authors>
<title>Monte carlo sampling methods using Markov chains and their applications.</title>
<date>1970</date>
<journal>Biometrika,</journal>
<pages>57--97</pages>
<contexts>
<context position="17961" citStr="Hastings, 1970" startWordPosition="2936" endWordPosition="2937">ces and their word-level alignments are observed. 3.5 Inference Given a corpus of paired part-of-speech tag sequences (s1, s2) and their GIZA++ alignments g, we would ideally like to predict the set of tree pairs (T1, T2) which have highest probability when conditioned on the observed data: P(T1, T2Is1, s2, g). We could rewrite this by explicitly integrating over the yield, context, coupling, Giza-score parameters as well as the alignment trees. However, since maximizing this integral directly would be intractable, we resort to standard Markov chain sampling techniques. We use Gibbs sampling (Hastings, 1970) to draw trees for each sentence conditioned on those drawn for all other sentences. The samples form a Markov chain which is guaranteed to converge to the true joint distribution over all sentences. In the monolingual setting, there is a wellknown tree sampling algorithm (Johnson et al., 2007). This algorithm proceeds in top-down fashion by sampling individual split points using the marginal probabilities of all possible subtrees. These marginals can be efficiently pre-computed and form the “inside” table of the famous InsideOutside algorithm. However, in our setting, trees come in pairs, and</context>
<context position="19765" citStr="Hastings, 1970" startWordPosition="3234" endWordPosition="3235">ligned and therefore allows us to use the recursive topdown sampling algorithm mentioned above. After a new tree pair T∗ _ (T1∗, T2∗ )i is drawn from Q, we accept the pair with the following probability: min � 1, P(T∗ T−i, A−i) Q(T|T−i, A−i) P(T |T−i, A−i) Q(T∗|T−i, A−i) where T is the previously sampled tree-pair for sentence i, P is the true model probability, and Q is the probability under the proposal distribution. This use of a tractable proposal distribution and acceptance ratio is known as the MetropolisHastings algorithm and it preserves the convergence guarantee of the Gibbs sampler (Hastings, 1970). To compute the terms P(T∗|T−i,A−i) and P(T |T−i, A−i) in the acceptance ratio above, we need to marginalize over all possible alignments between tree pairs. Fortunately, for any given pair of trees T1 and T2 this marginalization can be computed using a dynamic program in time O(|T1||T2|). Here we provide a very brief sketch. For every pair of nodes n1 E T1, n2 E T2, a table stores the marginal probability of the subtrees rooted at n1 and n2, respectively. A dynamic program builds this table from the bottom up: For each node pair n1, n2, we sum the probabilities of all local alignment configu</context>
</contexts>
<marker>Hastings, 1970</marker>
<rawString>W. K. Hastings. 1970. Monte carlo sampling methods using Markov chains and their applications. Biometrika, 57:97–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="7431" citStr="Hwa et al., 2005" startWordPosition="1124" endWordPosition="1127">ecisions in the two languages are inconsistent with GIZA++ wordlevel alignments. By incorporating these constraints into the EM algorithm he was able to improve performance over a monolingual unsupervised PCFG. Still, the performance falls short of state-of-the-art monolingual models such as the CCM. More recently, there has been a body of work attempting to improve parsing performance by exploiting syntactically annotated parallel data. In one strand of this work, annotations are assumed only in a resource-rich language and are projected onto a resource-poor language using the parallel data (Hwa et al., 2005; Xi and Hwa, 2005). In another strand of work, syntactic annotations are assumed on both sides of the parallel data, and a model is trained to exploit the parallel data at test time as well (Smith and Smith, 2004; Burkett and Klein, 2008). In contrast to this work, our goal is to explore the benefits of multilingual grammar induction in a fully unsupervised setting. We finally note a recent paper which uses parameter tying to improve unsupervised dependency parse induction (Cohen and Smith, 2009). While the primary performance gains occur when tying related parameters within a language, some </context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Journal of Natural Language Engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Jiang</author>
<author>L Wang</author>
<author>K Zhang</author>
</authors>
<title>Alignment of trees – an alternative to tree edit.</title>
<date>1995</date>
<journal>Theoretical Computer Science,</journal>
<volume>143</volume>
<issue>1</issue>
<contexts>
<context position="2916" citStr="Jiang et al., 1995" startWordPosition="426" endWordPosition="429">aw [the student [from MIT]] exhibits the classic problem of PP-attachment ambiguity. However, its Urdu translation, literally glossed as I [[MIT of] student] saw, uses a genitive phrase that may only be attached to the adjacent noun phrase. Knowing the correspondence between these sentences should help us resolve the English ambiguity. One of the main challenges of unsupervised multilingual learning is to exploit cross-lingual patterns discovered in data, while still allowing a wide range of language-specific idiosyncrasies. To this end, we adapt a formalism known as unordered tree alignment (Jiang et al., 1995) to a probabilistic setting. Under this formalism, any two trees can be embedded in an alignment tree. This alignment tree allows arbitrary parts of the two trees to diverge in structure, permitting language-specific grammatical structure to be preserved. Additionally, a computational advantage of this formalism is that the marginalized probability over all possible alignments for any two trees can be efficiently computed with a dynamic program in linear time. We formulate a generative Bayesian model which seeks to explain the observed parallel data through a combination of bilingual and monol</context>
<context position="9437" citStr="Jiang et al., 1995" startWordPosition="1449" endWordPosition="1452"> data. We obtain these word-level alignments using GIZA++ (Och and Ney, 2003). Our model seeks to explain this observed data through a generative process whereby two aligned parse trees are produced jointly. Though they are aligned, arbitrary parts of the two trees are permitted to diverge, accommodating languagespecific grammatical structure. In effect, our model loosely binds the two trees: node-to-node alignments need only be used where repeated bilingual patterns can be discovered in the data. 3.1 Tree Alignments We achieve this loose binding of trees by adapting unordered tree alignment (Jiang et al., 1995) to a probabilistic setting. Under this formalism, any two trees can be aligned using an alignment tree. The alignment tree embeds the original two trees within it: each node is labeled by a pair (x, y), (A, y), or (x, A) where x is a node from the first tree, y is a node from the second tree, and A is an empty space. The individual structure of each tree must be preserved under the embedding with the exception of sibling order (to allow variations in phrase and word order). The flexibility of this formalism can be demonstrated by two extreme cases: (1) an alignment between two trees may actua</context>
<context position="20568" citStr="Jiang et al., 1995" startWordPosition="3372" endWordPosition="3375">n pair of trees T1 and T2 this marginalization can be computed using a dynamic program in time O(|T1||T2|). Here we provide a very brief sketch. For every pair of nodes n1 E T1, n2 E T2, a table stores the marginal probability of the subtrees rooted at n1 and n2, respectively. A dynamic program builds this table from the bottom up: For each node pair n1, n2, we sum the probabilities of all local alignment configurations, each multiplied by the appro77 priate marginals already computed in the table for lower-level node pairs. This algorithm is an adaptation of the dynamic program presented in (Jiang et al., 1995) for finding minimum cost alignment trees (Fig. 5 of that publication). Once a pair of trees (T1, T2) has been sampled, we can proceed to sample an alignment tree AIT1, T2.2 We sample individual alignment decisions from the top down, at each step using the alignment marginals for the remaining subtrees (already computed using the afore-mentioned dynamic program). Once the triple (T1, T2, A) has been sampled, we move on to the next parallel sentence. We avoid directly sampling parameter values, instead using the marginalized closed forms for multinomials with Dirichlet conjugate-priors using co</context>
</contexts>
<marker>Jiang, Wang, Zhang, 1995</marker>
<rawString>T. Jiang, L. Wang, and K. Zhang. 1995. Alignment of trees – an alternative to tree edit. Theoretical Computer Science, 143(1):137–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
<author>T Griffiths</author>
<author>S Goldwater</author>
</authors>
<title>Bayesian inference for PCFGs via Markov chain Monte Carlo.</title>
<date>2007</date>
<booktitle>In Proceedings of the NAACL/HLT,</booktitle>
<pages>139--146</pages>
<contexts>
<context position="18256" citStr="Johnson et al., 2007" startWordPosition="2983" endWordPosition="2986">a: P(T1, T2Is1, s2, g). We could rewrite this by explicitly integrating over the yield, context, coupling, Giza-score parameters as well as the alignment trees. However, since maximizing this integral directly would be intractable, we resort to standard Markov chain sampling techniques. We use Gibbs sampling (Hastings, 1970) to draw trees for each sentence conditioned on those drawn for all other sentences. The samples form a Markov chain which is guaranteed to converge to the true joint distribution over all sentences. In the monolingual setting, there is a wellknown tree sampling algorithm (Johnson et al., 2007). This algorithm proceeds in top-down fashion by sampling individual split points using the marginal probabilities of all possible subtrees. These marginals can be efficiently pre-computed and form the “inside” table of the famous InsideOutside algorithm. However, in our setting, trees come in pairs, and their joint probability crucially depends on their alignment. For the ith parallel sentence, we wish to jointly sample the pair of trees (T1,T2)i together with their alignment Ai. To do so directly would involve simultaneously marginalizing over all possible subtrees as well as all possible al</context>
</contexts>
<marker>Johnson, Griffiths, Goldwater, 2007</marker>
<rawString>M. Johnson, T. Griffiths, and S. Goldwater. 2007. Bayesian inference for PCFGs via Markov chain Monte Carlo. In Proceedings of the NAACL/HLT, pages 139–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="2103" citStr="Klein and Manning, 2002" startWordPosition="300" endWordPosition="303">ilingual cues at training time. Multilingual learning has been successful for other linguistic induction tasks such as lexicon acquisition, morphological segmentation, and part-of-speech tagging (Genzel, 2005; Snyder and Barzilay, 2008; Snyder et al., 2008; Snyder 1Code and the outputs of our experiments are available at http://groups.csail.mit.edu/rbg/code/multiling induction. et al., 2009). We focus here on the unsupervised induction of unlabeled constituency brackets. This task has been extensively studied in a monolingual setting and has proven to be difficult (Charniak and Carroll, 1992; Klein and Manning, 2002). The key premise of our approach is that ambiguous syntactic structures in one language may correspond to less uncertain structures in the other language. For instance, the English sentence I saw [the student [from MIT]] exhibits the classic problem of PP-attachment ambiguity. However, its Urdu translation, literally glossed as I [[MIT of] student] saw, uses a genitive phrase that may only be attached to the adjacent noun phrase. Knowing the correspondence between these sentences should help us resolve the English ambiguity. One of the main challenges of unsupervised multilingual learning is </context>
<context position="5017" citStr="Klein and Manning, 2002" startWordPosition="747" endWordPosition="751"> under this model, we use a Metropolis-Hastings within-Gibbs sampler. We sample pairs of trees and then compute marginalized probabilities over all possible alignments using dynamic programming. We test the effectiveness of our bilingual grammar induction model on three corpora of parallel text: English-Korean, English-Urdu and EnglishChinese. The model is trained using bilingual data with automatically induced word-level alignments, but is tested on purely monolingual data for each language. In all cases, our model outperforms a state-of-the-art baseline: the Constituent Context Model (CCM) (Klein and Manning, 2002), sometimes by substantial margins. On average, over all the testing scenarios that we studied, our model achieves an absolute increase in F-measure of 8.8 points, and a 19% reduction in error relative to a theoretical upper bound. 2 Related Work The unsupervised grammar induction task has been studied extensively, mostly in a monolingual setting (Charniak and Carroll, 1992; Stolcke and Omohundro, 1994; Klein and Manning, 2002; Seginer, 2007). While PCFGs perform poorly on this task, the CCM model (Klein and Manning, 2002) has achieved large gains in performance and is among the state-of-the-a</context>
<context position="10458" citStr="Klein and Manning (2002)" startWordPosition="1632" endWordPosition="1635">ith the exception of sibling order (to allow variations in phrase and word order). The flexibility of this formalism can be demonstrated by two extreme cases: (1) an alignment between two trees may actually align none of their individual nodes, instead inserting an empty space A for each of the original two trees’ nodes. (2) if the original trees are isomorphic to one another, the alignment may match their nodes exactly, without inserting any empty spaces. See Figure 1 for an example. 3.2 Model overview As our basic model of syntactic structure, we adopt the Constituent-Context Model (CCM) of Klein and Manning (2002). Under this model, the part-of-speech sequence of each span in a sentence is generated either as a constituent yield — if it is dominated by a node in the tree — or otherwise as a distituent yield. For example, in the bracketed sentence [John/NNP [climbed/VB [the/DT tree/NN]]], the sequence VB DT NN is generated as a constituent yield, since it constitutes a complete bracket in the tree. On the other hand, the sequence VB DT is generated as a distituent, since it does not. Besides these yields, the contexts (two surrounding POS tags) of constituents and distituents are generated as well. In t</context>
<context position="22061" citStr="Klein and Manning, 2002" startWordPosition="3614" endWordPosition="3617">omial distribution. Nevertheless, we count the produced yields as if they had been generated separately by each of the distributions involved in the numerator of Distribution 1. 4 Experimental setup We test our model on three corpora of bilingual parallel sentences: English-Korean, EnglishUrdu, and English-Chinese. Though the model is trained using parallel data, during testing it has access only to monolingual data. This set-up ensures that we are testing our model’s ability to learn better parameters at training time, rather than its ability to exploit parallel data at test time. Following (Klein and Manning, 2002), we restrict our model to binary trees, though we note that the alignment trees do not follow this restriction. Data The Penn Korean Treebank (Han et al., 2002) consists of 5,083 Korean sentences translated into English for the purposes of language training in a military setting. Both the Korean and English sentences are annotated with syntactic trees. We use the first 4,000 sentences for training and the last 1,083 sentences for testing. We note that in the Korean data, a separate tag is given for 2Sampling the alignment tree is important, as it provides us with counts of aligned constituent</context>
<context position="23652" citStr="Klein and Manning, 2002" startWordPosition="3879" endWordPosition="3882">peech level. The Urdu side of this corpus does not provide tree annotations so here we can test parse accuracy only on English. We use the remaining sections of the Penn Treebank for English testing. The English-Chinese treebank (Bies et al., 2007) consists of 3,850 Chinese newswire sentences translated into English. Both the English and Chinese sentences are annotated with parse trees. We use the first 4/5 for training and the final 1/5 for testing. During preprocessing of the corpora we remove all punctuation marks and special symbols, following the setup in previous grammar induction work (Klein and Manning, 2002). To obtain lexical alignments between the parallel sentences we employ GIZA++ (Och and Ney, 2003). We use intersection alignments, which are one-to-one alignments produced by taking the intersection of oneto-many alignments in each direction. These oneto-one intersection alignments tend to have higher precision. We initialize the trees by making uniform split decisions recursively from the top down for sentences in both languages. Then for each pair of parallel sentences we randomly sample an initial alignment tree for the two sampled trees. Baseline We implement a Bayesian version of the CCM</context>
<context position="27279" citStr="Klein and Manning, 2002" startWordPosition="4470" endWordPosition="4473">ed values. Testing and evaluation As mentioned above, we test our model only on monolingual data, where the parallel sentences are not provided to the model. To predict the bracketings of these monolingual test sentences, we take the smoothed counts accumulated in the final round of sampling over the training data and perform a maximum likelihood estimate of the monolingual CCM parameters. These parameters are then used to produce the highest probability bracketing of the test set. To evaluate both our model as well as the baseline, we use (unlabeled) bracket precision, recall, and F-measure (Klein and Manning, 2002). Following previous work, we include the wholesentence brackets but ignore single-word brackets. We perform experiments on different subsets of training and testing data based on the sentencelength. In particular we experimented with sentence length limits of 10, 20, and 30 for both the training and testing sets. We also report the upper bound on F-measure for binary trees. We average the results over 10 separate sampling runs. 5 Results Table 1 reports the full results of our experiments. In all testing scenarios the bilingual model outperforms its monolingual counterpart in terms of both pr</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. 2002. A generative constituent-context model for improved grammar induction. In Proceedings of the ACL, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
</authors>
<title>The Unsupervised Learning of Natural Language Structure.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="24850" citStr="Klein (2005)" startWordPosition="4076" endWordPosition="4077">ion of the CCM as a baseline. This model uses the same inference procedure as our bilingual model (Gibbs sampling). In fact, our model reduces to this Bayesian CCM when it is assumed that no nodes between the two parallel trees are ever aligned and when word-level alignments are ignored. We also reimplemented the original EM version of CCM and found virtually no difference in performance when using EM or Gibbs sampling. In both cases our implementation achieves F-measure in the range of 69-70% on WSJ10, broadly in line with the performance reported by Klein and Manning (2002). Hyperparameters Klein (2005) reports using smoothing pseudo-counts of 2 for constituent 3http://www.crulp.org 78 Figure 2: The F-measure of the CCM baseline (dotted line) and bilingual model (solid line) plotted on the y-axis, as the maximum sentence length in the test set is increased (x-axis). Results are averaged over all training scenarios given in Table 1. yields and contexts and 8 for distituent yields and contexts. In our Bayesian model, these similar smoothing counts occur as the parameters of the Dirichlet priors. For Korean we found that the baseline performed well using these values. However, on our English an</context>
</contexts>
<marker>Klein, 2005</marker>
<rawString>D. Klein. 2005. The Unsupervised Learning of Natural Language Structure. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Kuhn</author>
</authors>
<title>Experiments in parallel-text based grammar induction.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>470--477</pages>
<contexts>
<context position="6596" citStr="Kuhn (2004)" startWordPosition="996" endWordPosition="997">tion Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rules for determining when parsing decisions in the two languages are inconsistent with GIZA++ wordlevel alignments. By incorporating these constraints into the EM algorithm he was able to improve performance over a monolingual unsupervised PCFG. Still, the performance falls short of state-of-the-art monolingual models such as the CCM. More recently, there has been a body of work attempting to improve parsing perf</context>
</contexts>
<marker>Kuhn, 2004</marker>
<rawString>Jonas Kuhn. 2004. Experiments in parallel-text based grammar induction. In Proceedings of the ACL, pages 470–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Multitext grammars and synchronous parsers.</title>
<date>2003</date>
<booktitle>In Proceedings of the NAACL/HLT,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="6183" citStr="Melamed, 2003" startWordPosition="930" endWordPosition="931"> in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rule</context>
</contexts>
<marker>Melamed, 2003</marker>
<rawString>I. Dan Melamed. 2003. Multitext grammars and synchronous parsers. In Proceedings of the NAACL/HLT, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="8895" citStr="Och and Ney, 2003" startWordPosition="1366" endWordPosition="1369">lt-tolearn syntactic structures of one language may correspond to simpler or less uncertain structures in the other language. We treat the part-of-speech tag sequences of parallel sentences, as well as their 74 (iii) (ii) (i) Figure 1: A pair of trees (i) and two possible alignment trees. In (ii), no empty spaces are inserted, but the order of one of the original tree’s siblings has been reversed. In (iii), only two pairs of nodes have been aligned (indicated by arrows) and many empty spaces inserted. word-level alignments, as observed data. We obtain these word-level alignments using GIZA++ (Och and Ney, 2003). Our model seeks to explain this observed data through a generative process whereby two aligned parse trees are produced jointly. Though they are aligned, arbitrary parts of the two trees are permitted to diverge, accommodating languagespecific grammatical structure. In effect, our model loosely binds the two trees: node-to-node alignments need only be used where repeated bilingual patterns can be discovered in the data. 3.1 Tree Alignments We achieve this loose binding of trees by adapting unordered tree alignment (Jiang et al., 1995) to a probabilistic setting. Under this formalism, any two</context>
<context position="23750" citStr="Och and Ney, 2003" startWordPosition="3895" endWordPosition="3898">curacy only on English. We use the remaining sections of the Penn Treebank for English testing. The English-Chinese treebank (Bies et al., 2007) consists of 3,850 Chinese newswire sentences translated into English. Both the English and Chinese sentences are annotated with parse trees. We use the first 4/5 for training and the final 1/5 for testing. During preprocessing of the corpora we remove all punctuation marks and special symbols, following the setup in previous grammar induction work (Klein and Manning, 2002). To obtain lexical alignments between the parallel sentences we employ GIZA++ (Och and Ney, 2003). We use intersection alignments, which are one-to-one alignments produced by taking the intersection of oneto-many alignments in each direction. These oneto-one intersection alignments tend to have higher precision. We initialize the trees by making uniform split decisions recursively from the top down for sentences in both languages. Then for each pair of parallel sentences we randomly sample an initial alignment tree for the two sampled trees. Baseline We implement a Bayesian version of the CCM as a baseline. This model uses the same inference procedure as our bilingual model (Gibbs samplin</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Seginer</author>
</authors>
<title>Fast unsupervised incremental parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>384--391</pages>
<contexts>
<context position="5463" citStr="Seginer, 2007" startWordPosition="819" endWordPosition="820">urely monolingual data for each language. In all cases, our model outperforms a state-of-the-art baseline: the Constituent Context Model (CCM) (Klein and Manning, 2002), sometimes by substantial margins. On average, over all the testing scenarios that we studied, our model achieves an absolute increase in F-measure of 8.8 points, and a 19% reduction in error relative to a theoretical upper bound. 2 Related Work The unsupervised grammar induction task has been studied extensively, mostly in a monolingual setting (Charniak and Carroll, 1992; Stolcke and Omohundro, 1994; Klein and Manning, 2002; Seginer, 2007). While PCFGs perform poorly on this task, the CCM model (Klein and Manning, 2002) has achieved large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorde</context>
</contexts>
<marker>Seginer, 2007</marker>
<rawString>Yoav Seginer. 2007. Fast unsupervised incremental parsing. In Proceedings of the ACL, pages 384–391.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Bilingual parsing with factored estimation: Using English to parse Korean.</title>
<date>2004</date>
<booktitle>In Proceeding of EMNLP,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="6386" citStr="Smith and Smith, 2004" startWordPosition="962" endWordPosition="965">some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rules for determining when parsing decisions in the two languages are inconsistent with GIZA++ wordlevel alignments. By incorporating these constraints into the EM algorithm he was able to improve performanc</context>
<context position="7644" citStr="Smith and Smith, 2004" startWordPosition="1163" endWordPosition="1166">G. Still, the performance falls short of state-of-the-art monolingual models such as the CCM. More recently, there has been a body of work attempting to improve parsing performance by exploiting syntactically annotated parallel data. In one strand of this work, annotations are assumed only in a resource-rich language and are projected onto a resource-poor language using the parallel data (Hwa et al., 2005; Xi and Hwa, 2005). In another strand of work, syntactic annotations are assumed on both sides of the parallel data, and a model is trained to exploit the parallel data at test time as well (Smith and Smith, 2004; Burkett and Klein, 2008). In contrast to this work, our goal is to explore the benefits of multilingual grammar induction in a fully unsupervised setting. We finally note a recent paper which uses parameter tying to improve unsupervised dependency parse induction (Cohen and Smith, 2009). While the primary performance gains occur when tying related parameters within a language, some additional benefit is observed through bilingual tying, even in the absence of a parallel corpus. 3 Model We propose an unsupervised Bayesian model for learning bilingual syntactic structure using parallel corpora</context>
</contexts>
<marker>Smith, Smith, 2004</marker>
<rawString>David A. Smith and Noah A. Smith. 2004. Bilingual parsing with factored estimation: Using English to parse Korean. In Proceeding of EMNLP, pages 49– 56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for morphological segmentation.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL/HLT,</booktitle>
<pages>737--745</pages>
<contexts>
<context position="1714" citStr="Snyder and Barzilay, 2008" startWordPosition="245" endWordPosition="248">CM model, a strong monolingual baseline. On average, across a variety of testing scenarios, our model achieves an 8.8 absolute gain in F-measure. 1 1 Introduction In this paper we investigate the task of unsupervised constituency parsing when bilingual parallel text is available. Our goal is to improve parsing performance on monolingual test data for each language by using unsupervised bilingual cues at training time. Multilingual learning has been successful for other linguistic induction tasks such as lexicon acquisition, morphological segmentation, and part-of-speech tagging (Genzel, 2005; Snyder and Barzilay, 2008; Snyder et al., 2008; Snyder 1Code and the outputs of our experiments are available at http://groups.csail.mit.edu/rbg/code/multiling induction. et al., 2009). We focus here on the unsupervised induction of unlabeled constituency brackets. This task has been extensively studied in a monolingual setting and has proven to be difficult (Charniak and Carroll, 1992; Klein and Manning, 2002). The key premise of our approach is that ambiguous syntactic structures in one language may correspond to less uncertain structures in the other language. For instance, the English sentence I saw [the student [</context>
</contexts>
<marker>Snyder, Barzilay, 2008</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2008. Unsupervised multilingual learning for morphological segmentation. In Proceedings of the ACL/HLT, pages 737–745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for POS tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1041--1050</pages>
<contexts>
<context position="1735" citStr="Snyder et al., 2008" startWordPosition="249" endWordPosition="252">ual baseline. On average, across a variety of testing scenarios, our model achieves an 8.8 absolute gain in F-measure. 1 1 Introduction In this paper we investigate the task of unsupervised constituency parsing when bilingual parallel text is available. Our goal is to improve parsing performance on monolingual test data for each language by using unsupervised bilingual cues at training time. Multilingual learning has been successful for other linguistic induction tasks such as lexicon acquisition, morphological segmentation, and part-of-speech tagging (Genzel, 2005; Snyder and Barzilay, 2008; Snyder et al., 2008; Snyder 1Code and the outputs of our experiments are available at http://groups.csail.mit.edu/rbg/code/multiling induction. et al., 2009). We focus here on the unsupervised induction of unlabeled constituency brackets. This task has been extensively studied in a monolingual setting and has proven to be difficult (Charniak and Carroll, 1992; Klein and Manning, 2002). The key premise of our approach is that ambiguous syntactic structures in one language may correspond to less uncertain structures in the other language. For instance, the English sentence I saw [the student [from MIT]] exhibits t</context>
</contexts>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2008</marker>
<rawString>Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay. 2008. Unsupervised multilingual learning for POS tagging. In Proceedings of EMNLP, pages 1041–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian non-parametric approach.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL/HLT.</booktitle>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay. 2009. Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian non-parametric approach. In Proceedings of the NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Stephen M Omohundro</author>
</authors>
<title>Inducing probabilistic grammars by Bayesian model merging.</title>
<date>1994</date>
<booktitle>In Proceedings of ICGI,</booktitle>
<pages>106--118</pages>
<contexts>
<context position="5422" citStr="Stolcke and Omohundro, 1994" startWordPosition="811" endWordPosition="814">ally induced word-level alignments, but is tested on purely monolingual data for each language. In all cases, our model outperforms a state-of-the-art baseline: the Constituent Context Model (CCM) (Klein and Manning, 2002), sometimes by substantial margins. On average, over all the testing scenarios that we studied, our model achieves an absolute increase in F-measure of 8.8 points, and a 19% reduction in error relative to a theoretical upper bound. 2 Related Work The unsupervised grammar induction task has been studied extensively, mostly in a monolingual setting (Charniak and Carroll, 1992; Stolcke and Omohundro, 1994; Klein and Manning, 2002; Seginer, 2007). While PCFGs perform poorly on this task, the CCM model (Klein and Manning, 2002) has achieved large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual</context>
</contexts>
<marker>Stolcke, Omohundro, 1994</marker>
<rawString>Andreas Stolcke and Stephen M. Omohundro. 1994. Inducing probabilistic grammars by Bayesian model merging. In Proceedings of ICGI, pages 106–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Hongsing Wong</author>
</authors>
<title>Machine translation with a stochastic grammatical channel.</title>
<date>1998</date>
<booktitle>In Proceedings of the ACL/COLING,</booktitle>
<pages>1408--1415</pages>
<contexts>
<context position="6154" citStr="Wu and Wong, 1998" startWordPosition="924" endWordPosition="927">g, 2002) has achieved large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn man</context>
</contexts>
<marker>Wu, Wong, 1998</marker>
<rawString>Dekai Wu and Hongsing Wong. 1998. Machine translation with a stochastic grammatical channel. In Proceedings of the ACL/COLING, pages 1408– 1415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="5951" citStr="Wu, 1997" startWordPosition="895" endWordPosition="896">n a monolingual setting (Charniak and Carroll, 1992; Stolcke and Omohundro, 1994; Klein and Manning, 2002; Seginer, 2007). While PCFGs perform poorly on this task, the CCM model (Klein and Manning, 2002) has achieved large gains in performance and is among the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bil</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-english languages.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>851--858</pages>
<contexts>
<context position="7450" citStr="Xi and Hwa, 2005" startWordPosition="1128" endWordPosition="1131">o languages are inconsistent with GIZA++ wordlevel alignments. By incorporating these constraints into the EM algorithm he was able to improve performance over a monolingual unsupervised PCFG. Still, the performance falls short of state-of-the-art monolingual models such as the CCM. More recently, there has been a body of work attempting to improve parsing performance by exploiting syntactically annotated parallel data. In one strand of this work, annotations are assumed only in a resource-rich language and are projected onto a resource-poor language using the parallel data (Hwa et al., 2005; Xi and Hwa, 2005). In another strand of work, syntactic annotations are assumed on both sides of the parallel data, and a model is trained to exploit the parallel data at test time as well (Smith and Smith, 2004; Burkett and Klein, 2008). In contrast to this work, our goal is to explore the benefits of multilingual grammar induction in a fully unsupervised setting. We finally note a recent paper which uses parameter tying to improve unsupervised dependency parse induction (Cohen and Smith, 2009). While the primary performance gains occur when tying related parameters within a language, some additional benefit </context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-english languages. In Proceedings of EMNLP, pages 851 – 858.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Stochastic lexicalized inversion transduction grammar for alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="6221" citStr="Zhang and Gildea, 2005" startWordPosition="934" endWordPosition="937">the state-of-the-art probabilistic models for unsupervised constituency parsing. We therefore use CCM as our basic model of monolingual syntax. While there has been some previous work on bilingual CFG parsing, it has mainly focused on improving MT systems rather than monolingual parsing accuracy. Research in this direction was pioneered by (Wu, 1997), who developed Inversion Transduction Grammars to capture crosslingual grammar variations such as phrase reorderings. More general formalisms for the same purpose were later developed (Wu and Wong, 1998; Chiang, 2005; Melamed, 2003; Eisner, 2003; Zhang and Gildea, 2005; Blunsom et al., 2008). We know of only one study which evaluates these bilingual grammar formalisms on the task of grammar induction itself (Smith and Smith, 2004). Both our model and even the monolingual CCM baseline yield far higher performance on the same Korean-English corpus. Our approach is closer to the unsupervised bilingual parsing model developed by Kuhn (2004), which aims to improve monolingual performance. Assuming that trees induced over parallel sentences have to exhibit certain structural regularities, Kuhn manually specifies a set of rules for determining when parsing decisio</context>
</contexts>
<marker>Zhang, Gildea, 2005</marker>
<rawString>Hao Zhang and Daniel Gildea. 2005. Stochastic lexicalized inversion transduction grammar for alignment. In Proceedings of the ACL, pages 475–482.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>