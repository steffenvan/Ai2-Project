<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000308">
<bodyText confidence="0.983215181818182">
Book Reviews Phonological Parsing in Speech Recognition
engineering standpoint) of an architecture that provides a
clear separation of linguistic and nonlinguistic knowledge,
since it is hard to see how shallow processing could be
implemented without this separation.
Although SPAR is implemented as a complete natural
language system, it unfortunately still has something of a
&amp;quot;toy&amp;quot; flavor for two reasons. First of all, the data texts were
written specifically for this project, although not by people
who knew about SPAR. Although many of the phenomena
in these texts undoubtedly occur in more realistic texts, the
work would perhaps have been more convincing had Carter
used texts written for other purposes. Naturally occurring
texts often contain problematic constructions such as nomi-
nalizations, which present many interesting challenges for
semantics and anaphor resolution in natural language sys-
tems (Dahl et al. 1987), but which don&apos;t occur in Carter&apos;s
texts. The system also has a toy flavor because the end
application, paraphrase, is less obviously useful than many
other applications that might have been selected. There is
no reason to think that these problems affect the fundamen-
tal soundness of the work, but they do tend to make it less
interesting.
This work presents a very comprehensive implementa-
tion of the state of the art of reference resolution in natural
language processing. However, one is left at the end with a
frustrating sense that the whole process consists of exploit-
ing a set of more or less unrelated heuristics, which in fact
lead to very accurate reference resolution, but which don&apos;t
seem to fit together into a general picture of a unified
phenomenon. For example, Carter points out (using Sid-
ner&apos;s terminology) that the discourse focus is preferred to
intra-sentential candidates, but that intra-sentential candi-
dates are preferred to potential discourse foci. It is only
natural to wonder why these preferences (and others)
should be the way they are, and whether they can be
expected to fall out from more general principles. This is
not specifically a criticism of Carter, but points out an
unsatisfying aspect of much computational work in ana-
phora resolution. It is in fact at least partially the result of
the clarity of his presentation that this issue emerges.
I found this book very stimulating, interesting, and clear.
I would recommend it to anyone interested in reference
resolution or computational pragmatics in general.
</bodyText>
<sectionHeader confidence="0.988115" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.828098421052631">
Boguraev, B. K. 1979 Automatic Resolution of Linguistic Ambiguity.
University of Cambridge Computer Laboratory, TR-11.
Dahl, Deborah A. 1985 The Structure and Function of one-anaphora in
English. Indiana University Linguistics Club, Bloomington, Indiana.
Dahl, Deborah A.; Palmer, Martha S.; and Passonneau, Rebecca J. 1987
&amp;quot;Nominalizations in PUNDIT.&amp;quot; Proceedings of the 25th Annual Meet-
ing of the Association for Computational Linguistics, Stanford, CA.
Halliday, M. A. K. and Hasan, R. 1976 Cohesion in English. Longman,
London.
Sidner, Candace L. 1979 Towards a Computational Theory of Definite
Anaphora Comprehension in English Discourse. MIT Artificial Intelli-
gence Laboratory, TR-537.
Webber, Bonnie L. 1978 A Formal Approach to Discourse Anaphora.
Garland, New York.
Webber, Bonnie L. 1983 &amp;quot;So What Can We Talk About Now?&amp;quot; In Brady,
M. and Berwick, R. (eds.), Computational Models of Discourse. MIT
Press, Cambridge, MA.
Wilks, Yorick A. 1975 &amp;quot;A Preferential, Pattern-Seeking Semantics for
Natural Language Inference.&amp;quot; Artificial Intelligence 6:53-74.
</reference>
<bodyText confidence="0.988935833333333">
Deborah Dahl received her Ph.D. in linguistics from the Univer-
sity of Minnesota in 1984. Her dissertation was on the interpreta-
tion of one-anaphora in discourse. She is currently a senior staff
scientist in the natural language processing group at Unisys Paoli
Research Center. Her group is developing PUNDIT, a large text
processing system in Prolog. She designed and implemented
PUNDIT&apos;s components for reference resolution and noun phrase
semantics. She has also worked on the interpretation of indefi-
nite noun phrases and the interaction of prosodic information
with pronoun interpretation. Dahl&apos;s address is: Unisys Paoli
Research Center, P.O. Box 517, Paoli, PA 19301. E-mail:
dahl@prc.unisys.com
</bodyText>
<table confidence="0.256904">
PHONOLOGICAL PARSING IN SPEECH RECOGNITION
Kenneth W. Church
(AT&amp;T Bell Laboratories)
Boston, MA: Kluwer Academic Publishers, 1987,
xv + 261 pp.
(The Kluwer International Series in Electrical
Engineering and Computer Science; VLSI, Computer
Architecture and Digital Signal Processing)
Hardbound, ISBN 0-89838-250-5, $49.95
Reviewed by
Kimmo Koskenniemi
University of Helsinki
</table>
<bodyText confidence="0.988606389830509">
Church argues against the so-called &amp;quot;standard position&amp;quot; in
speech recognition, i.e. the use of syntacticâ€”semantic knowl-
edge to disambiguate uncertain sounds in utterances. The
argument proceeds by showing first that allophonic varia-
tion in speech is a source of useful information and not an
obstacle for speech recognition. The claim sounds reason-
able, but is not trivial because much of the work in the past
was based on an opposite view. A part of this claim is that
allophonic cues often indicate the location of boundaries
(Nakatani&apos;s position).
Another important issue in the book is that syllable
structure is very useful as a framework for describing
allophonic variation. This is also a very reasonable claim
from the linguistic point of view, but it is something that
many of the leading current phonological theories fail to
achieve.
The author assumes a constituency hypothesis where
many allophonic and phonological processes share the same
environments (e.g. foot-initial, foot-internal). This is done
in a phrase-structure and chart-parsing framework. The
Computational Linguistics Volume 16, Number 1, March 1990 45
Book Reviews Prosody and Speech Recognition
chart parsing is reduced into a set of matrix operations
dealing with sparse matrices. Appendices list sample gram-
mars and lexicons, which brings substance to the claims.
&amp;quot;Speech&amp;quot; in this book refers to English only, which is
never made explicit. This seems to be the normal case in
American literature, however. Of course, most of the contri-
bution is relevant to other languages as well.
The book also provides an interesting contribution in the
area of finite-state properties of language, because the
phrase structure grammars used are essentially finite-state.
Other finite-state accounts (such as the two-level model by
Koskenniemi [1984] and cascaded transducers by Kaplan
and Kay [Kay 1983] seem to have been less successful in
combining structural information with segmental pro-
cesses. Both other models are purely segmental, although
syllables are sometimes referred to as contexts.
An interesting problem concerning rule interaction in the
proposed formalism is dealt with on page 113. There would
be an obvious need for subtraction (for defining negative
contexts) and intersection (combining effects). Subtrac-
tion, however, turns out to exclude too much, whereas
intersection is too permissive.
The book is well written and the argumentation proceeds
logically. Both strong and weak points of the theories
proposed are clearly presented. It gives a fair overall pic-
ture of the field of speech recognition, and much of the book
could be suitable as a textbook. Nevertheless, some pas-
sages address mostly readers with a considerable back-
ground. The main topic covers, of course, a specific slice of
the whole field, namely the treatment of allophonic varia-
tion. One minor inconvenience is the use of a reference
format that cites a number only, not the author and the
year. This results in a small savings in space but a larger
burden for the reader. The book appears to be Church&apos;s
(previously unpublished) doctoral dissertation from MIT,
though this is not clearly indicated in the volume. Although
not particularly new, it still is very valuable.
</bodyText>
<sectionHeader confidence="0.986734" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.944006857142857">
Kay, M. 1983 &amp;quot;When Meta-Rules Are not Meta-Rules,&amp;quot; In Sparck Jones,
K. and Wilks, Y. (eds.), Automatic Natural Language Parsing. Ellis
Horwood, Chichester, U.K.
Koskenniemi, K. 1984 &amp;quot;A General Computational Model for Word-Form
Recognition and Production,&amp;quot; In COLING &apos;84: Proceedings of the 10th
International Conference on Computational Linguistics, Stanford, 178-
181.
</reference>
<bodyText confidence="0.977549125">
Kimmo Koskenniemi&apos;s Ph.D. thesis introduced a finite-state two-
level model to account for inflection, derivation, and compounding
in an efficient and language-independent way. He works on
finite-state morphology and syntax at the Research Unit for
Computational Linguistics at the University of Helsinki. Kosken-
niemi&apos;s address is: Department of General Linguistics, University
of Helsinki, Hallituslcatu 11, SF 00100 Helsinki, Finland. E-mail:
koskenniemi@opmvax.csc.fi
</bodyText>
<sectionHeader confidence="0.781471" genericHeader="conclusions">
PROSODY AND SPEECH RECOGNITION
</sectionHeader>
<reference confidence="0.571196142857143">
Alex Waibel
(Carnegie Mellon University)
San Mateo, CA: Morgan Kaufmann Publishers and
London: Pitman, 1988, xii + 212 pp.
(Research Notes in Artificial Intelligence)
Softbound, ISBN 0-934613-70-2 and 0-273-08787-8,
$22.95
</reference>
<figure confidence="0.662639">
Reviewed by
;loan Bachenko
AT&amp;T Bell Laboratories
</figure>
<bodyText confidence="0.998606024390244">
Most research in natural language processing (NLP) con-
centrates on the syntax and semantics of written language,
a situation that exists in part because most NLP applica-
tions are concerned with systems that rely on written
language analysis, e.g. information retrieval and text-
generation systems. Recently, however, we have begun to
see a growing interest in spoken language and the applica-
tion of natural language processing to text-to-speech synthe-
sis and speech recognition. Waibel&apos;s volume, which de-
scribes new results in automated speech recognition, makes
an important contribution to this research direction.
At present, speech recognition technology gives us two
choices: speaker-independent systems that handle small
vocabularies (one to five phonetically distinct words) and
require no training, or speaker-dependent systems that
recognize somewhat larger vocabularies (up to 1,000 words
online) and require training sessions for each user. Al-
though experimental systems can recognize limited contin-
uous speech, freely generated phrases and sentences cannot
be processed, nor can words that are &amp;quot;unknown&amp;quot; to a
recognizer. Waibel believes that this condition can change
if recognition systems, which currently focus on identifying
acoustic phonetic segments, are expanded to include pro-
sodic information, i.e. information about nonsegmental
features such as duration and pitch. His central claim is
that a system equipped with prosody rules can achieve very
large vocabulary recognition, up to 20,000 words, in both
continuous speech and isolated word tasks. To make his
point, Waibel examines four prosodic featuresâ€”duration,
intensity, pitch, and stress. For each feature, he discusses in
detail a series of experiments that demonstrate the tech-
niques that he used (and, in some cases, invented) for
extracting the prosodic features, and rules that use prosodic
feature patterns to narrow the search space for word hypoth-
esization to a small subset of the total vocabulary. Waibel&apos;s
results make a convincing case that prosody can play a
valuable role in machine perception of speech; however,
they fall short of establishing his strongest claims, as he
lacks a complete implementation of the system.
Most of the book is organized around each of the pro-
sodic features that Waibel investigates. His explication is
</bodyText>
<page confidence="0.973784">
46 Computational Linguistics Volume 16, Number 1, March 1990
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000222">
<title confidence="0.960586">Reviews Parsing in Speech Recognition</title>
<abstract confidence="0.998533255813954">engineering standpoint) of an architecture that provides a clear separation of linguistic and nonlinguistic knowledge, since it is hard to see how shallow processing could be implemented without this separation. Although SPAR is implemented as a complete natural language system, it unfortunately still has something of a &amp;quot;toy&amp;quot; flavor for two reasons. First of all, the data texts were written specifically for this project, although not by people who knew about SPAR. Although many of the phenomena in these texts undoubtedly occur in more realistic texts, the work would perhaps have been more convincing had Carter used texts written for other purposes. Naturally occurring texts often contain problematic constructions such as nominalizations, which present many interesting challenges for semantics and anaphor resolution in natural language systems (Dahl et al. 1987), but which don&apos;t occur in Carter&apos;s texts. The system also has a toy flavor because the end application, paraphrase, is less obviously useful than many other applications that might have been selected. There is no reason to think that these problems affect the fundamental soundness of the work, but they do tend to make it less interesting. This work presents a very comprehensive implementation of the state of the art of reference resolution in natural language processing. However, one is left at the end with a frustrating sense that the whole process consists of exploiting a set of more or less unrelated heuristics, which in fact lead to very accurate reference resolution, but which don&apos;t seem to fit together into a general picture of a unified phenomenon. For example, Carter points out (using Sidner&apos;s terminology) that the discourse focus is preferred to intra-sentential candidates, but that intra-sentential candidates are preferred to potential discourse foci. It is only natural to wonder why these preferences (and others) should be the way they are, and whether they can be expected to fall out from more general principles. This is not specifically a criticism of Carter, but points out an unsatisfying aspect of much computational work in anaphora resolution. It is in fact at least partially the result of the clarity of his presentation that this issue emerges. I found this book very stimulating, interesting, and clear. I would recommend it to anyone interested in reference resolution or computational pragmatics in general.</abstract>
<note confidence="0.755034666666666">REFERENCES B. K. 1979 Resolution of Linguistic Ambiguity. University of Cambridge Computer Laboratory, TR-11. Deborah A. 1985 Structure and Function of one-anaphora in University Linguistics Club, Bloomington, Indiana. Dahl, Deborah A.; Palmer, Martha S.; and Passonneau, Rebecca J. 1987 in PUNDIT.&amp;quot; of the 25th Annual Meetof the Association for Computational Linguistics, CA. M. A. K. and Hasan, R. 1976 in English. London. Candace L. 1979 a Computational Theory of Definite Comprehension in English Discourse. Artificial Intelligence Laboratory, TR-537. Bonnie L. 1978 Formal Approach to Discourse Anaphora. Garland, New York. Webber, Bonnie L. 1983 &amp;quot;So What Can We Talk About Now?&amp;quot; In Brady, and Berwick, R. (eds.), Models of Discourse. Press, Cambridge, MA. Wilks, Yorick A. 1975 &amp;quot;A Preferential, Pattern-Seeking Semantics for Language Inference.&amp;quot; Intelligence Dahl her Ph.D. in linguistics from the Univer-</note>
<abstract confidence="0.982197666666667">sity of Minnesota in 1984. Her dissertation was on the interpretation of one-anaphora in discourse. She is currently a senior staff scientist in the natural language processing group at Unisys Paoli Research Center. Her group is developing PUNDIT, a large text processing system in Prolog. She designed and implemented PUNDIT&apos;s components for reference resolution and noun phrase semantics. She has also worked on the interpretation of indefinite noun phrases and the interaction of prosodic information with pronoun interpretation. Dahl&apos;s address is: Unisys Paoli</abstract>
<address confidence="0.576512">Research Center, P.O. Box 517, Paoli, PA 19301. E-mail:</address>
<email confidence="0.996525">dahl@prc.unisys.com</email>
<title confidence="0.928">PHONOLOGICAL PARSING IN SPEECH RECOGNITION</title>
<author confidence="0.999877">Kenneth W Church</author>
<affiliation confidence="0.997011">(AT&amp;T Bell Laboratories)</affiliation>
<address confidence="0.762349">Boston, MA: Kluwer Academic Publishers, 1987,</address>
<note confidence="0.957235">xv + 261 pp. (The Kluwer International Series in Electrical Engineering and Computer Science; VLSI, Computer Architecture and Digital Signal Processing) Hardbound, ISBN 0-89838-250-5, $49.95 Reviewed by</note>
<author confidence="0.988626">Kimmo Koskenniemi</author>
<affiliation confidence="0.999379">University of Helsinki</affiliation>
<abstract confidence="0.965572507042253">Church argues against the so-called &amp;quot;standard position&amp;quot; in speech recognition, i.e. the use of syntacticâ€”semantic knowledge to disambiguate uncertain sounds in utterances. The argument proceeds by showing first that allophonic variation in speech is a source of useful information and not an obstacle for speech recognition. The claim sounds reasonable, but is not trivial because much of the work in the past was based on an opposite view. A part of this claim is that allophonic cues often indicate the location of boundaries (Nakatani&apos;s position). Another important issue in the book is that syllable structure is very useful as a framework for describing allophonic variation. This is also a very reasonable claim from the linguistic point of view, but it is something that many of the leading current phonological theories fail to achieve. The author assumes a constituency hypothesis where many allophonic and phonological processes share the same environments (e.g. foot-initial, foot-internal). This is done in a phrase-structure and chart-parsing framework. The Computational Linguistics Volume 16, Number 1, March 1990 45 Book Reviews Prosody and Speech Recognition chart parsing is reduced into a set of matrix operations dealing with sparse matrices. Appendices list sample grammars and lexicons, which brings substance to the claims. &amp;quot;Speech&amp;quot; in this book refers to English only, which is never made explicit. This seems to be the normal case in American literature, however. Of course, most of the contribution is relevant to other languages as well. The book also provides an interesting contribution in the area of finite-state properties of language, because the phrase structure grammars used are essentially finite-state. Other finite-state accounts (such as the two-level model by Koskenniemi [1984] and cascaded transducers by Kaplan and Kay [Kay 1983] seem to have been less successful in combining structural information with segmental processes. Both other models are purely segmental, although syllables are sometimes referred to as contexts. An interesting problem concerning rule interaction in the proposed formalism is dealt with on page 113. There would be an obvious need for subtraction (for defining negative contexts) and intersection (combining effects). Subtraction, however, turns out to exclude too much, whereas intersection is too permissive. The book is well written and the argumentation proceeds logically. Both strong and weak points of the theories proposed are clearly presented. It gives a fair overall picture of the field of speech recognition, and much of the book could be suitable as a textbook. Nevertheless, some passages address mostly readers with a considerable background. The main topic covers, of course, a specific slice of the whole field, namely the treatment of allophonic variation. One minor inconvenience is the use of a reference format that cites a number only, not the author and the year. This results in a small savings in space but a larger burden for the reader. The book appears to be Church&apos;s (previously unpublished) doctoral dissertation from MIT, though this is not clearly indicated in the volume. Although not particularly new, it still is very valuable. REFERENCES 1983 Meta-Rules Are not Meta-Rules,&amp;quot; In Sparck Jones, and Wilks, Natural Language Parsing. Horwood, Chichester, U.K. K. General Computational Model for Word-Form and Production,&amp;quot; In &apos;84: Proceedings of the 10th Conference on Computational Linguistics, 178- 181. Koskenniemi&apos;s thesis introduced a finite-state twolevel model to account for inflection, derivation, and compounding in an efficient and language-independent way. He works on finite-state morphology and syntax at the Research Unit for</abstract>
<affiliation confidence="0.4685625">Computational Linguistics at the University of Helsinki. Koskenniemi&apos;s address is: Department of General Linguistics, University</affiliation>
<address confidence="0.664118">of Helsinki, Hallituslcatu 11, SF 00100 Helsinki, Finland. E-mail:</address>
<email confidence="0.860298">koskenniemi@opmvax.csc.fi</email>
<title confidence="0.880983">PROSODY AND SPEECH RECOGNITION</title>
<author confidence="0.999793">Alex Waibel</author>
<affiliation confidence="0.999587">(Carnegie Mellon University)</affiliation>
<address confidence="0.690695">San Mateo, CA: Morgan Kaufmann Publishers and</address>
<note confidence="0.9543266">London: Pitman, 1988, xii + 212 pp. (Research Notes in Artificial Intelligence) Softbound, ISBN 0-934613-70-2 and 0-273-08787-8, $22.95 Reviewed by</note>
<author confidence="0.991437">loan Bachenko</author>
<affiliation confidence="0.99666">AT&amp;T Bell Laboratories</affiliation>
<abstract confidence="0.992863170731707">Most research in natural language processing (NLP) concentrates on the syntax and semantics of written language, a situation that exists in part because most NLP applications are concerned with systems that rely on written language analysis, e.g. information retrieval and textgeneration systems. Recently, however, we have begun to see a growing interest in spoken language and the application of natural language processing to text-to-speech synthesis and speech recognition. Waibel&apos;s volume, which describes new results in automated speech recognition, makes an important contribution to this research direction. At present, speech recognition technology gives us two choices: speaker-independent systems that handle small vocabularies (one to five phonetically distinct words) and require no training, or speaker-dependent systems that recognize somewhat larger vocabularies (up to 1,000 words online) and require training sessions for each user. Although experimental systems can recognize limited continuous speech, freely generated phrases and sentences cannot be processed, nor can words that are &amp;quot;unknown&amp;quot; to a recognizer. Waibel believes that this condition can change if recognition systems, which currently focus on identifying acoustic phonetic segments, are expanded to include prosodic information, i.e. information about nonsegmental features such as duration and pitch. His central claim is that a system equipped with prosody rules can achieve very large vocabulary recognition, up to 20,000 words, in both continuous speech and isolated word tasks. To make his point, Waibel examines four prosodic featuresâ€”duration, intensity, pitch, and stress. For each feature, he discusses in detail a series of experiments that demonstrate the techniques that he used (and, in some cases, invented) for extracting the prosodic features, and rules that use prosodic feature patterns to narrow the search space for word hypothesization to a small subset of the total vocabulary. Waibel&apos;s results make a convincing case that prosody can play a valuable role in machine perception of speech; however, they fall short of establishing his strongest claims, as he lacks a complete implementation of the system. Most of the book is organized around each of the prosodic features that Waibel investigates. His explication is</abstract>
<date confidence="0.572348">46 Computational Linguistics Volume 16, Number 1, March 1990</date>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
</authors>
<title>Automatic Resolution of Linguistic Ambiguity.</title>
<date>1979</date>
<institution>University of Cambridge Computer Laboratory,</institution>
<marker>Boguraev, 1979</marker>
<rawString>Boguraev, B. K. 1979 Automatic Resolution of Linguistic Ambiguity. University of Cambridge Computer Laboratory, TR-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deborah A Dahl</author>
</authors>
<title>The Structure and Function of one-anaphora in</title>
<date>1985</date>
<institution>English. Indiana University Linguistics Club,</institution>
<location>Bloomington, Indiana.</location>
<marker>Dahl, 1985</marker>
<rawString>Dahl, Deborah A. 1985 The Structure and Function of one-anaphora in English. Indiana University Linguistics Club, Bloomington, Indiana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deborah A Dahl</author>
<author>Martha S Palmer</author>
<author>Rebecca J Passonneau</author>
</authors>
<title>Nominalizations in PUNDIT.&amp;quot;</title>
<date>1987</date>
<booktitle>Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="929" citStr="Dahl et al. 1987" startWordPosition="135" endWordPosition="138">atural language system, it unfortunately still has something of a &amp;quot;toy&amp;quot; flavor for two reasons. First of all, the data texts were written specifically for this project, although not by people who knew about SPAR. Although many of the phenomena in these texts undoubtedly occur in more realistic texts, the work would perhaps have been more convincing had Carter used texts written for other purposes. Naturally occurring texts often contain problematic constructions such as nominalizations, which present many interesting challenges for semantics and anaphor resolution in natural language systems (Dahl et al. 1987), but which don&apos;t occur in Carter&apos;s texts. The system also has a toy flavor because the end application, paraphrase, is less obviously useful than many other applications that might have been selected. There is no reason to think that these problems affect the fundamental soundness of the work, but they do tend to make it less interesting. This work presents a very comprehensive implementation of the state of the art of reference resolution in natural language processing. However, one is left at the end with a frustrating sense that the whole process consists of exploiting a set of more or les</context>
</contexts>
<marker>Dahl, Palmer, Passonneau, 1987</marker>
<rawString>Dahl, Deborah A.; Palmer, Martha S.; and Passonneau, Rebecca J. 1987 &amp;quot;Nominalizations in PUNDIT.&amp;quot; Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
<author>R Hasan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman,</publisher>
<location>London.</location>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Halliday, M. A. K. and Hasan, R. 1976 Cohesion in English. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<journal>MIT Artificial Intelligence Laboratory,</journal>
<pages>537</pages>
<marker>Sidner, 1979</marker>
<rawString>Sidner, Candace L. 1979 Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. MIT Artificial Intelligence Laboratory, TR-537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie L Webber</author>
</authors>
<title>A Formal Approach to Discourse Anaphora.</title>
<date>1978</date>
<publisher>Garland,</publisher>
<location>New York.</location>
<marker>Webber, 1978</marker>
<rawString>Webber, Bonnie L. 1978 A Formal Approach to Discourse Anaphora. Garland, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie L Webber</author>
</authors>
<title>So What Can We Talk About Now?&amp;quot;</title>
<date>1983</date>
<booktitle>Computational Models of Discourse.</booktitle>
<editor>In Brady, M. and Berwick, R. (eds.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Webber, 1983</marker>
<rawString>Webber, Bonnie L. 1983 &amp;quot;So What Can We Talk About Now?&amp;quot; In Brady, M. and Berwick, R. (eds.), Computational Models of Discourse. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
</authors>
<title>A Preferential, Pattern-Seeking Semantics for Natural Language Inference.&amp;quot;</title>
<date>1975</date>
<journal>Artificial Intelligence</journal>
<pages>6--53</pages>
<marker>Wilks, 1975</marker>
<rawString>Wilks, Yorick A. 1975 &amp;quot;A Preferential, Pattern-Seeking Semantics for Natural Language Inference.&amp;quot; Artificial Intelligence 6:53-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>When Meta-Rules Are not Meta-Rules,&amp;quot;</title>
<date>1983</date>
<booktitle>Automatic Natural Language Parsing.</booktitle>
<editor>In Sparck Jones, K. and Wilks, Y. (eds.),</editor>
<publisher>Ellis Horwood, Chichester, U.K.</publisher>
<marker>Kay, 1983</marker>
<rawString>Kay, M. 1983 &amp;quot;When Meta-Rules Are not Meta-Rules,&amp;quot; In Sparck Jones, K. and Wilks, Y. (eds.), Automatic Natural Language Parsing. Ellis Horwood, Chichester, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>A General Computational Model for Word-Form Recognition and Production,&amp;quot;</title>
<date>1984</date>
<booktitle>In COLING &apos;84: Proceedings of the 10th International Conference on Computational Linguistics, Stanford,</booktitle>
<pages>178--181</pages>
<marker>Koskenniemi, 1984</marker>
<rawString>Koskenniemi, K. 1984 &amp;quot;A General Computational Model for Word-Form Recognition and Production,&amp;quot; In COLING &apos;84: Proceedings of the 10th International Conference on Computational Linguistics, Stanford, 178-181.</rawString>
</citation>
<citation valid="false">
<institution>Alex Waibel (Carnegie Mellon University)</institution>
<marker></marker>
<rawString>Alex Waibel (Carnegie Mellon University)</rawString>
</citation>
<citation valid="true">
<authors>
<author>San Mateo</author>
</authors>
<date>1988</date>
<journal>xii +</journal>
<volume>212</volume>
<pages>pp.</pages>
<publisher>Morgan Kaufmann Publishers and</publisher>
<location>CA:</location>
<marker>Mateo, 1988</marker>
<rawString>San Mateo, CA: Morgan Kaufmann Publishers and London: Pitman, 1988, xii + 212 pp. (Research Notes in Artificial Intelligence) Softbound, ISBN 0-934613-70-2 and 0-273-08787-8, $22.95</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>