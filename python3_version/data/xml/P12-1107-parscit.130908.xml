<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002689">
<title confidence="0.989111">
Sentence Simplification by Monolingual Machine Translation
</title>
<author confidence="0.998776">
Sander Wubben
</author>
<affiliation confidence="0.996189">
Tilburg University
</affiliation>
<address confidence="0.890961666666667">
P.O. Box 90135
5000 LE Tilburg
The Netherlands
</address>
<email confidence="0.995057">
s.wubben@uvt.nl
</email>
<note confidence="0.659457">
Antal van den Bosch
Radboud University Nijmegen
P.O. Box 9103
</note>
<address confidence="0.6400725">
6500 HD Nijmegen
The Netherlands
</address>
<email confidence="0.981606">
a.vandenbosch@let.ru.nl
</email>
<author confidence="0.973101">
Emiel Krahmer
</author>
<affiliation confidence="0.983175">
Tilburg University
</affiliation>
<address confidence="0.885059333333333">
P.O. Box 90135
5000 LE Tilburg
The Netherlands
</address>
<email confidence="0.996898">
e.j.krahmer@uvt.nl
</email>
<sectionHeader confidence="0.995827" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995998894736842">
In this paper we describe a method for simpli-
fying sentences using Phrase Based Machine
Translation, augmented with a re-ranking
heuristic based on dissimilarity, and trained on
a monolingual parallel corpus. We compare
our system to a word-substitution baseline and
two state-of-the-art systems, all trained and
tested on paired sentences from the English
part of Wikipedia and Simple Wikipedia. Hu-
man test subjects judge the output of the dif-
ferent systems. Analysing the judgements
shows that by relatively careful phrase-based
paraphrasing our model achieves similar sim-
plification results to state-of-the-art systems,
while generating better formed output. We
also argue that text readability metrics such
as the Flesch-Kincaid grade level should be
used with caution when evaluating the output
of simplification systems.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958975609756">
Sentence simplification can be defined as the process
of producing a simplified version of a sentence by
changing some of the lexical material and grammat-
ical structure of that sentence, while still preserving
the semantic content of the original sentence, in or-
der to ease its understanding. Particularly language
learners (Siddharthan, 2002), people with reading
disabilities (Inui et al., 2003) such as aphasia (Car-
roll et al., 1999), and low-literacy readers (Watanabe
et al., 2009) can benefit from this application. It can
serve to generate output in a specific limited format,
such as subtitles (Daelemans et al., 2004). Sentence
simplification can also serve to preprocess the input
of other tasks, such as summarization (Knight and
Marcu, 2000), parsing, machine translation (Chan-
drasekar et al., 1996), semantic role labeling (Vick-
rey and Koller, 2008) or sentence fusion (Filippova
and Strube, 2008).
The goal of simplification is to achieve an im-
provement in readability, defined as the ease with
which a text can be understood. Some of the factors
that are known to help increase the readability of text
are the vocabulary used, the length of the sentences,
the syntactic structures present in the text, and the
usage of discourse markers. One effort to create a
simple version of English at the vocabulary level has
been the creation of Basic English by Charles Kay
Ogden. Basic English is a controlled language with
a basic vocabulary consisting of 850 words. Accord-
ing to Ogden, 90 percent of all dictionary entries can
be paraphrased using these 850 words. An exam-
ple of a resource that is written using mainly Basic
English is the English Simple Wikipedia. Articles
on English Simple Wikipedia are similar to articles
found in the traditional English Wikipedia, but writ-
ten using a limited vocabulary (using Basic English
where possible). Generally the structure of the sen-
tences in English Simple Wikipedia is less compli-
cated and the sentences are somewhat shorter than
those found in English Wikipedia; we offer more de-
tailed statistics below.
</bodyText>
<sectionHeader confidence="0.917521" genericHeader="introduction">
1.1 Related work
</sectionHeader>
<bodyText confidence="0.99959025">
Most earlier work on sentence simplification
adopted rule-based approaches. A frequently ap-
plied type of rule, aimed to reduce overall sentence
length, splits long sentences on the basis of syntactic
</bodyText>
<page confidence="0.953567">
1015
</page>
<note confidence="0.985605">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999748222222222">
information (Chandrasekar and Srinivas, 1997; Car-
roll et al., 1998; Canning et al., 2000; Vickrey and
Koller, 2008). There has also been work on lexi-
cal substitution for simplification, where the aim is
to substitute difficult words with simpler synonyms,
derived from WordNet or dictionaries (Inui et al.,
2003).
Zhu et al. (2010) examine the use of paired doc-
uments in English Wikipedia and Simple Wikipedia
for a data-driven approach to the sentence simplifi-
cation task. They propose a probabilistic, syntax-
based machine translation approach to the problem
and compare against a baseline of no simplification
and a phrase-based machine translation approach.
In a similar vein, Coster and Kauchak (2011) use
a parallel corpus of paired documents from Sim-
ple Wikipedia and Wikipedia to train a phrase-based
machine translation model coupled with a deletion
model. Another useful resource is the edit his-
tory of Simple Wikipedia, from which simplifica-
tions can be learned (Yatskar et al., 2010). Woods-
end and Lapata (2011) investigate the use of Simple
Wikipedia edit histories and an aligned Wikipedia–
Simple Wikipedia corpus to induce a model based
on quasi-synchronous grammar. They select the
most appropriate simplification by using integer lin-
ear programming.
We follow Zhu et al. (2010) and Coster and
Kauchak (2011) in proposing that sentence simpli-
fication can be approached as a monolingual ma-
chine translation task, where the source and target
languages are the same and where the output should
be simpler in form from the input but similar in
meaning. We differ from the approach of Zhu et
al. (2010) in the sense that we do not take syntac-
tic information into account; we rely on PBMT to
do its work and implicitly learn simplifying para-
phrasings of phrases. Our approach differs from
Coster and Kauchak (2011) in the sense that instead
of focusing on deletion in the PBMT decoding stage,
we focus on dissimilarity, as simplification does not
necessarily imply shortening (Woodsend and Lap-
ata, 2011), or as the Simple Wikipedia guidelines
state, “simpler does not mean short”1. Table 1.1
shows the average sentence length and the average
</bodyText>
<footnote confidence="0.850527">
1http://simple.wikipedia.org/wiki/Main_
Page/Introduction
</footnote>
<bodyText confidence="0.978172857142857">
word length for Wikipedia and Simple Wikipedia
sentences in the PWKP dataset used in this study
(Zhu et al., 2010). These numbers suggest that, al-
though the selection criteria for sentences to be in-
cluded in this dataset are biased (see Section 2.2),
Simple Wikipedia sentences are about 17% shorter,
while the average word length is virtually equal.
</bodyText>
<table confidence="0.994228333333333">
Sent. length Token length
Simple Wikipedia 20.87 4.89
Wikipedia 25.01 5.06
</table>
<tableCaption confidence="0.988801">
Table 1: Sentence and token length statistics for the
PWKP dataset (Zhu et al., 2010).
</tableCaption>
<bodyText confidence="0.999721606060606">
Statistical machine translation (SMT) has already
been successfully applied to the related task of para-
phrasing (Quirk et al., 2004; Bannard and Callison-
Burch, 2005; Madnani et al., 2007; Callison-Burch,
2008; Zhao et al., 2009; Wubben et al., 2010). SMT
typically makes use of large parallel corpora to train
a model on. These corpora need to be aligned at
the sentence level. Large parallel corpora, such as
the multilingual proceedings of the European Parlia-
ment (Europarl), are readily available for many lan-
guages. Phrase-Based Machine Translation (PBMT)
is a form of SMT where the translation model aims
to translate longer sequences of words (“phrases”)
in one go, solving part of the word ordering problem
along the way that would be left to the target lan-
guage model in a word-based SMT system. PMBT
operates purely on statistics and no linguistic knowl-
edge is involved in the process: the phrases that are
aligned are motivated statistically, rather than lin-
guistically. This makes PBMT adaptable to any lan-
guage pair for which there is a parallel corpus avail-
able. The PBMT model makes use of a translation
model, derived from the parallel corpus, and a lan-
guage model, derived from a monolingual corpus in
the target language. The language model is typically
an n-gram model with smoothing. For any given in-
put sentence, a search is carried out producing an
n-best list of candidate translations, ranked by the
decoder score, a complex scoring function includ-
ing likelihood scores from the translation model,
and the target language model. In principle, all of
this should be transportable to a data-driven machine
translation account of sentence simplification, pro-
</bodyText>
<page confidence="0.989881">
1016
</page>
<bodyText confidence="0.9988165">
vided that a parallel corpus is available that pairs text
to simplified versions of that text.
</bodyText>
<subsectionHeader confidence="0.997856">
1.2 This study
</subsectionHeader>
<bodyText confidence="0.999797523809524">
In this work we aim to investigate the use of phrase-
based machine translation modified with a dissim-
ilarity component for the task of sentence simplifi-
cation. While Zhu et al. (2010) have demonstrated
that their approach outperforms a PBMT approach
in terms of Flesch Reading Ease test scores, we are
not aware of any studies that evaluate PBMT for sen-
tence simplification with human judgements. In this
study we evaluate the output of Zhu et al. (2010)
(henceforth referred to as ‘Zhu’), Woodsend and La-
pata (2011) (henceforth referred to as ‘RevILP’),
our PBMT based system with dissimilarity-based
re-ranking (henceforth referred to as ‘PBMT-R’), a
word-substitution baseline, and, as a gold standard,
the original Simple Wikipedia sentences. We will
first discuss the baseline, followed by the Zhu sys-
tem, the RevILP system, and our PBMT-R system
in Section 2. We then describe the experiment with
human judges in Section 3, and its results in Sec-
tion 4. We close this paper by critically discussing
our results in Section 5.
</bodyText>
<sectionHeader confidence="0.932548" genericHeader="method">
2 Sentence Simplification Models
</sectionHeader>
<subsectionHeader confidence="0.97947">
2.1 Word-Substitution Baseline
</subsectionHeader>
<bodyText confidence="0.999982352941177">
The word substitution baseline replaces words in
the source sentence with (near-)synonyms that are
more likely according to a language model. For
each noun, adjective and verb in the sentence this
model takes that word and its part-of-speech tag
and retrieves from WordNet all synonyms from all
synsets the word occurs in. The word is then re-
placed by all of its synset words, and each replace-
ment is scored by a SRILM language model (Stol-
cke, 2002) with probabilities that are obtained from
training on the Simple Wikipedia data. The alter-
native that has the highest probability according to
the language model is kept. If no relevant alterna-
tive is found, the word is left unchanged. We use
the Memory-Based Tagger (Daelemans et al., 1996)
trained on the Brown corpus to compute the part-of-
speech tags. The WordNet::QueryData2 Perl mod-
</bodyText>
<footnote confidence="0.859891">
2http://search.cpan.org/dist/
WordNet-QueryData/QueryData.pm
</footnote>
<bodyText confidence="0.566736">
ule is used to query WordNet (Fellbaum, 1998).
</bodyText>
<subsectionHeader confidence="0.597534">
2.2 Zhu et al.
</subsectionHeader>
<bodyText confidence="0.999912884615385">
Zhu et al. (2010) learn a sentence simplification
model which is able to perform four rewrite op-
erations on the parse trees of the input sentences,
namely substitution, reordering, splitting, and dele-
tion. Their model is inspired by syntax-based
SMT (Yamada and Knight, 2001) and consists of
a language model, a translation model and a de-
coder. The four mentioned simplification opera-
tions together form the translation model. Their
model is trained on a corpus containing aligned sen-
tences from English Wikipedia and English Simple
Wikipedia called PWKP. The PWKP dataset con-
sists of 108,016 pairs of aligned lines from 65,133
Wikipedia and Simple Wikipedia articles. These ar-
ticles were paired by following the “interlanguage
link”3. TF*IDF at the sentence level was used to
align the sentences in the different articles (Nelken
and Shieber, 2006).
Zhu et al. (2010) evaluate their system using
BLEU and NIST scores, as well as various read-
ability scores that only take into account the output
sentence, such as the Flesch Reading Ease test and
n-gram language model perplexity. Although their
system outperforms several baselines at the level of
these readability metrics, they do not achieve better
when evaluated with BLEU or NIST.
</bodyText>
<subsectionHeader confidence="0.97681">
2.3 RevILP
</subsectionHeader>
<bodyText confidence="0.9999812">
Woodsend and Lapata’s (2011) model is based
on quasi-synchronous grammar (Smith and Eisner,
2006). Quasi-synchronous grammar generates a
loose alignment between parse trees. It operates on
individual sentences annotated with syntactic infor-
mation in the form of phrase structure trees. Quasi-
synchronous grammar is used to generate all pos-
sible rewrite operations, after which integer linear
programming is employed to select the most ap-
propriate simplification. Their model is trained on
two different datasets: one containing alignments
between Wikipedia and English Simple Wikipedia
(AlignILP), and one containing alignments between
edits in the revision history of Simple Wikipedia
(RevILP). RevILP performs best according to the
</bodyText>
<footnote confidence="0.8876615">
3http://en.wikipedia.org/wiki/Help:
Interlanguage_links
</footnote>
<page confidence="0.993703">
1017
</page>
<bodyText confidence="0.993861666666667">
finds the most likely translation p(f|e) with a lan-
guage model that outputs the most likely sentence
p(e):
</bodyText>
<equation confidence="0.878436">
e� = arg max p(f|e)p(e)
eEe
</equation>
<bodyText confidence="0.982005666666667">
human judgements conducted in their study. They
show that it achieves better scores than Zhu et al.
(2010)’s system and is not scored significantly dif-
ferently from English Simple Wikipedia. In this
study we compare against their best performing sys-
tem, the RevILP system.
</bodyText>
<figure confidence="0.9920345">
Flesch-Kincaid
n-best
14
12
10
8
6
4
2
0
</figure>
<figureCaption confidence="0.969394">
Figure 1: Levenshtein distance and Flesch-Kincaid score
of output when varying the n of the n-best output of
Moses.
</figureCaption>
<subsectionHeader confidence="0.992222">
2.4 PBMT-R
</subsectionHeader>
<bodyText confidence="0.999989916666667">
We use the Moses software to train a PBMT
model (Koehn et al., 2007). The data we use is the
PWKP dataset created by Zhu et al. (2010). In gen-
eral, a statistical machine translation model finds a
best translation e� of a text in language f to a text
in language e by combining a translation model that
The GIZA++ statistical alignment package is
used to perform the word alignments, which are
later combined into phrase alignments in the Moses
pipeline (Och and Ney, 2003) to build the sentence
simplification model. GIZA++ utilizes IBM Models
1 to 5 and an HMM word alignment model to find
statistically motivated alignments between words.
We first tokenize and lowercase all data and use all
unique sentences from the Simple Wikipedia part
of the PWKP training set to train an n-gram lan-
guage model with the SRILM toolkit to learn the
probabilities of different n-grams. Then we invoke
the GIZA++ aligner using the training simplifica-
tion pairs. We run GIZA++ with standard settings
and we perform no optimization. This results in a
phrase table containing phrase pairs from Wikipedia
and Simple Wikipedia and their conditional proba-
bilities as assigned by Moses. Finally, we use the
Moses decoder to generate simplifications for the
sentences in the test set. For each sentence we let
the system generate the ten best distinct solutions
(or less, if fewer than ten solutions are generated) as
ranked by Moses.
Arguably, dissimilarity is a key factor in simpli-
fication (and in paraphrasing in general). As output
we would like to be able to select fluent sentences
that adequately convey the meaning of the original
input, yet that contain differences that operational-
ize the intended simplification. When training our
PBMT system on the PWKP data we may assume
that the system learns to simplify automatically, yet
there is no aspect of the decoder function in Moses
that is sensitive to the fact that it should try to be
different from the input – Moses may well trans-
late input to unchanged output, as much of our train-
ing data consists of partially equal input and output
strings.
To expand the functionality of Moses in the in-
tended direction we perform post-hoc re-ranking on
the output based on dissimilarity to the input. We
do this to select output that is as different as possi-
ble from the source sentence, so that it ideally con-
</bodyText>
<figure confidence="0.983410555555555">
3
2
Levenshtein Distance
1
0 2 4 6 8 10 12 14 16 18
4
0
0 2 4 6 8 10 12 14 16 18
n-best
</figure>
<page confidence="0.948172">
1018
</page>
<bodyText confidence="0.999963307692308">
tains multiple simplifications; at the same time, we
base our re-ranking on a top-n of output candidates
according to Moses, with a small n, to ensure that
the quality of the output in terms of fluency and ade-
quacy is also controlled for. Setting n = 10, for each
source sentence we re-rank the ten best sentences
as scored by the decoder according to the Leven-
shtein Distance (or edit distance) measure (Leven-
shtein, 1966) at the word level between the input
and output sentence, counting the minimum num-
ber of edits needed to transform the source string
into the target string, where the allowable edit op-
erations are insertion, deletion, and substitution of a
single word. In case of a tie in Levenshtein Distance,
we select the sequence with the better decoder score.
When Moses is unable to generate ten different sen-
tences, we select from the lower number of outputs.
Figure 1 displays Levenshtein Distance and Flesch-
Kincaid grade level scores for different values of n.
We use the Lingua::EN::Fathom module4 to calcu-
late Flesch-Kincaid grade level scores. The read-
ability score stays more or less the same, indicating
no relation between n and readability. The average
edit distance starts out at just above 2 when selecting
the 1-best output string, and increases roughly until
n = 10.
</bodyText>
<subsectionHeader confidence="0.955064">
2.5 Descriptive statistics
</subsectionHeader>
<bodyText confidence="0.999891764705882">
Table 2 displays the average edit distance and the
percentage of cases in which no edits were per-
formed for each of the systems and for Simple
Wikipedia. We see that the Levenshtein distance be-
tween Wikipedia and Simple Wikipedia is the most
substantial with an average of 12.3 edits. Given
that the average number of tokens is about 25 for
Wikipedia and 21 for Simple Wikipedia (cf. Ta-
ble 1.1), these numbers indicate that the changes in
Simple Wikipedia go substantially beyond the aver-
age four-word length difference. On average, eight
more words are interchanged for other words. About
half of the original tokens in the source sentence do
not return in the output. Of the three simplifica-
tion systems, the Zhu system (7.95) and the RevILP
(7.18) attain similar edit distances, less substantial
than the edits in Simple Wikipedia, but still consid-
</bodyText>
<footnote confidence="0.967862333333333">
4http://http://search.cpan.org/˜kimryan/
Lingua-EN-Fathom-1.15/lib/Lingua/EN/
Fathom.pm
</footnote>
<bodyText confidence="0.742942333333333">
erable compared to the baseline word-substitution
system (4.26) and PBMT-R (3.08). Our system is
clearly conservative in its edits.
</bodyText>
<table confidence="0.999672666666667">
System LD Perc. no edits
Simple Wikipedia 12.30 3
Word Sub 4.26 0
Zhu 7.95 2
RevILP 7.18 22
PBMT-R 3.08 5
</table>
<tableCaption confidence="0.99845">
Table 2: Levenshtein Distance and percentage of unal-
tered output sentences.
</tableCaption>
<bodyText confidence="0.999874">
On the other hand, we observe some differences
in the percentage of cases in which the systems de-
cide to produce a sentence identical to the input.
In 22 percent of the cases the RevILP system does
not alter the sentence. The other systems make this
decision about as often as the gold standard, Sim-
ple Wikipedia, where only 3% of sentences remain
unchanged. The word-substitution baseline always
manages to make at least one change.
</bodyText>
<sectionHeader confidence="0.998866" genericHeader="method">
3 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.956997">
3.1 Participants
</subsectionHeader>
<bodyText confidence="0.9997862">
Participants were 46 students of Tilburg University,
who participated for partial course credits. All were
native speakers of Dutch, and all were proficient in
English, having taken a course on Academic English
at University level.
</bodyText>
<subsectionHeader confidence="0.989148">
3.2 Materials
</subsectionHeader>
<bodyText confidence="0.999982846153846">
We use the test set used by Zhu et al. (2010) and
Woodsend and Lapata (2011). This test set consists
of 100 sentences from articles on English Wikipedia,
paired with sentences from corresponding articles in
English Simple Wikipedia. We selected only those
sentences where every system would perform min-
imally one edit, because we only want to compare
the different systems when they actually generate al-
tered, assumedly simplified output. From this sub-
set we randomly pick 20 source sentences, result-
ing in 20 clusters of one source sentence and 5 sim-
plified sentences, as generated by humans (Simple
Wikipedia) and the four systems.
</bodyText>
<page confidence="0.993177">
1019
</page>
<subsectionHeader confidence="0.986907">
3.3 Procedure
</subsectionHeader>
<bodyText confidence="0.99999205">
The participants were told that they participated in
the evaluation of a system that could simplify sen-
tences, and that they would see one source sentence
and five automatically simplified versions of that
sentence. They were not informed of the fact that we
evaluated in fact four different systems and the orig-
inal Simple Wikipedia sentence. Following earlier
evaluation studies (Doddington, 2002; Woodsend
and Lapata, 2011), we asked participants to evalu-
ate Simplicity, Fluency and Adequacy of the target
headlines on a five point Likert scale. Fluency was
defined in the instructions as the extent to which a
sentence is proper, grammatical English. Adequacy
was defined as the extent to which the sentence has
the same meaning as the source sentence. Simplic-
ity was defined as the extent to which the sentence
was simpler than the original and thus easier to un-
derstand. The order in which the clusters had to be
judged was randomized and the order of the output
of the various systems was randomized as well.
</bodyText>
<sectionHeader confidence="0.999981" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.998722">
4.1 Automatic measures
</subsectionHeader>
<bodyText confidence="0.999937076923077">
The results of the automatic measures are displayed
in Table 3. In terms of the Flesch-Kincaid grade
level score, where lower scores are better, the Zhu
system scores best, with 7.86 even lower than Sim-
ple Wikipedia (8.57). Increasingly worse Flesch-
Kincaid scores are produced by RevILP (8.61) and
PBMT-R (13.38), while the word substitution base-
line scores worst (14.64). With regard to the BLEU
score, where Simple Wikipedia is the reference, the
PBMT-R system scores highest with 0.43, followed
by the RevILP system (0.42) and the Zhu system
(0.38). The word substitution baseline scores low-
est with a BLEU score of 0.34.
</bodyText>
<table confidence="0.997821666666667">
System Flesch-Kincaid BLEU
Simple Wikipedia 8.57 1
Word Sub 14.64 0.34
Zhu 7.86 0.38
RevILP 8.61 0.42
PBMT-R 13.38 0.43
</table>
<tableCaption confidence="0.999953">
Table 3: Flesch-Kincaid grade level and BLEU scores
</tableCaption>
<subsectionHeader confidence="0.991056">
4.2 Human judgements
</subsectionHeader>
<bodyText confidence="0.999703282608696">
To test for significance we ran repeated mea-
sures analyses of variance with system (Sim-
ple Wikipedia, PBMT-R, Zhu, RevILP, word-
substitution baseline) as the independent variable,
and the three individual metrics as well as their com-
bined mean as the dependent variables. Mauchlys
test for sphericity was used to test for homogeneity
of variance, and when this test was significant we
applied a Greenhouse-Geisser correction on the de-
grees of freedom (for the purpose of readability we
report the normal degrees of freedom in these cases).
Planned pairwise comparisons were made with the
Bonferroni method. Table 4 displays these results.
First, we consider the 3 metrics in isolation, be-
ginning with Fluency. We find that participants
rated the Fluency of the simplified sentences from
the four systems and Simple Wikipedia differently,
F(4,180) = 178.436,p &lt; .001,172 = .799. The
word-substitution baseline, Simple Wikipedia and
PBMT-R receive the highest scores (3.86, 3.84 and
3.83 respectively) and don’t achieve significantly
different scores on this dimension. All other pair-
wise comparisons are significant at p &lt; .001. Rev-
ILP attains a score of 3.18, while the Zhu system
achieves the lowest mean judgement score of 2.59.
Participants also rated the systems significantly
differently on the Adequacy scale, F(4,180) =
116.509,p &lt; .001,172 = .721. PBMT-R scores
highest (3.71), followed by the word-substitution
baseline (3.58), RevILP (3.28), and then by Simple
Wikipedia (2.91) and the Zhu system (2.82). Sim-
ple Wikipedia and the Zhu system do not differ sig-
nificantly, and all other pairwise comparisons are
significant at p &lt; .001. The low score of Simple
Wikipedia indicates indirectly that the human edi-
tors of Simple Wikipedia texts often choose to devi-
ate quite markedly from the meaning of the original
text.
Key to the task of simplification are the hu-
man judgements of Simplicity. Participants rated
the Simplicity of the output from the four sys-
tems and Simple Wikipedia differently, F(4,180) =
74.959,p &lt; .001,172 = .625. Simple Wikipedia
scores highest (3.68) and the word substitution base-
line scores lowest (2.42). Between them are the
RevILP (2.96), Zhu (2.93) and PBMT-R (2.88) sys-
</bodyText>
<page confidence="0.985029">
1020
</page>
<table confidence="0.999415">
System Overall Fluency Adequacy Simplicity
Simple Wikipedia 3.46 (0.39) 3.84 (0.46) 2.91 (0.32) 3.68 (0.39)
Word Sub 3.39 (0.43) 3.86 (0.49) 3.58 (0.35) 2.42 (0.48)
Zhu 2.78 (0.45) 2.59 (0.48) 2.82 (0.37) 2.93 (0.50)
RevILP 3.13 (0.36) 3.18 (0.45) 3.28 (0.32) 2.96 (0.39)
PBMT-R 3.47 (0.46) 3.83 (0.49) 3.71 (0.44) 2.88 (0.46)
</table>
<tableCaption confidence="0.988028">
Table 4: Mean scores assigned by human subjects, with the standard deviation between brackets
</tableCaption>
<table confidence="0.9998082">
Adequacy Simplicity Flesch-Kincaid BLEU
Fluency 0.45** 0.24* 0.42** 0.26**
Adequacy -0.19 0.40** -0.14
Simplicity -0.45** 0.42**
Flesch-Kincaid -0.11
</table>
<tableCaption confidence="0.9983105">
Table 5: Pearson correlation between the different dimensions as assigned by humans and the automatic metrics.
Scores marked * are significant at p &lt; .05 and scores marked ** are significant at p &lt; .01
</tableCaption>
<bodyText confidence="0.998181">
tems, which do not score significantly differently
from each other. All other pairwise comparisons are
significant at p &lt; .001.
Finally we report on a combined score created by
averaging over the Fluency, Adequacy and Simplic-
ity scores. Inspection of this score, displayed in the
leftmost column of Table 4, reveals that the PBMT-
R system and Simple Wikipedia score best (3.47
and 3.46 respectively), followed by the word substi-
tution baseline (3.39), which in turn scores higher
than RevILP (3.13) and the Zhu system (2.78).
We find that participants rated the systems signifi-
cantly differently overall, F(4,180) = 98.880,p &lt;
.001,17P = .687. All pairwise comparisons were sta-
tistically significant (p &lt; .01), except the one be-
tween the PBMT-R system and Simple Wikipedia.
</bodyText>
<subsectionHeader confidence="0.99942">
4.3 Correlations
</subsectionHeader>
<bodyText confidence="0.999570764705882">
Table 5 displays the correlations between the scores
assigned by humans (Fluency, Adequacy and Sim-
plicity) and the automatic metrics (Flesch-Kincaid
and BLEU). We see a significant correlation be-
tween Fluency and Adequacy (0.45), as well as be-
tween Fluency and Simplicity (0.24). There is a neg-
ative significant correlation between Flesch-Kincaid
scores and Simplicity (-0.45) while there is a posi-
tive significant correlation between Flesch-Kincaid
and Adequacy and Fluency. The significant correla-
tions between BLEU and Simplicity (0.42) and Flu-
ency (0.26) are both in the positive direction. There
is no significant correlation between BLEU and Ad-
equacy, indicating BLEU’s relative weakness in as-
sessing the semantic overlap between input and out-
put. BLEU and Flesch-Kincaid do not show a sig-
nificant correlation.
</bodyText>
<sectionHeader confidence="0.998064" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99998525">
We conclude that a phrase-based machine trans-
lation system with added dissimilarity-based re-
ranking of the best ten output sentences can suc-
cessfully be used to perform sentence simplifica-
tion. Even though the system merely performs
phrase-based machine translation and is not specif-
ically geared towards simplification were it not for
the dissimilarity-based re-ranking of the output, it
performs not significantly differently from state-of-
the-art sentence simplification systems in terms of
human-judged Simplification. In terms of Fluency
and Adequacy our system is judged to perform sig-
nificantly better. From the relatively low average
numbers of edits made by our system we can con-
clude that our system performs relatively small num-
bers of changes to the input, that still constitute as
sensible simplifications. It does not split sentences
(which the Zhu and RevILP systems regularly do);
it only rephrases phrases. Yet, it does this better
than a word-substitution baseline, which can also be
considered a conservative approach; this is reflected
in the baseline’s high Fluency score (roughly equal
to PBMT-R and Simple Wikipedia) and Adequacy
score (only slightly worse than PBMT-R).
</bodyText>
<page confidence="0.959251">
1021
</page>
<table confidence="0.982629642857143">
Wikipedia the judge ordered that chapman should receive psychiatric treatment in prison and sentenced
him to twenty years to life , slightly less than the maximum possible of twenty-five years to
life .
Simple he was sentenced to twenty-five years to life in prison in 1981 .
Wikipedia
Word- the judge ordered that chapman should have psychiatric treatment in prison and sentenced
substitution him to twenty years to life , slightly less than the maximum possible of twenty-five years to
baseline life .
Zhu the judge ordered that chapman should get psychiatric treatment . in prison and sentenced
him to twenty years to life , less maximum possible of twenty-five years to life .
RevILP the judge ordered that chapman should will get psychiatric treatment in prison. he sentenced
him to twenty years to life to life.
PBMT-R the judge ordered that chapman should get psychiatric treatment in prison and sentenced him
to twenty years to life , a little bit less than the highest possible to twenty-five years to life .
</table>
<tableCaption confidence="0.999255">
Table 6: Example output
</tableCaption>
<bodyText confidence="0.999932949152543">
The output of all systems, the original and the
simplified version of an example sentence from the
PWKP dataset is displayed in Table 6. The Simple
Wikipedia sentences illustrate that significant por-
tions of the original sentences may be dropped, and
parts of the semantics of the original sentence dis-
carded. We also see the Zhu and RevILP systems
resorting to splitting the original sentence in two,
leading to better Flesch-Kincaid scores. The word-
substitution baseline changes ‘receive’ in ‘have’,
while the PBMT-R system changes the same ‘re-
ceive’ in ’get’, ‘slightly’ to ‘a little bit’, and ‘maxi-
mum’ to ‘highest’.
In terms of automatic measures we see that the
Zhu system scores particularly well on the Flesch-
Kincaid metric, while the RevILP system and our
PBMT-R system achieve the highest BLEU scores.
We believe that for the evaluation of sentence sim-
plification, BLEU is a more appropriate metric than
Flesch-Kincaid or a similar readability metric, al-
though it should be noted that BLEU was found only
to correlate significantly with Fluency, not with Ad-
equacy. While BLEU and NIST may be used with
this in mind, readability metrics should be avoided
altogether in our view. Where machine translation
evaluation metrics such as BLEU take into account
gold references, readability metrics only take into
account characteristics of the sentence such as word
length and sentence length, and ignore grammatical-
ity or the semantic adequacy of the content of the
output sentence, which BLEU is aimed to implic-
itly approximate by measuring overlap in n-grams.
Arguably, readability metrics are best suited to be
applied to texts that can be considered grammati-
cal and meaningful, which is not necessarily true for
the output of simplification algorithms. A disrup-
tive example that would illustrate this point would
be a system that would randomly split original sen-
tences in two or more sequences, achieving consid-
erably lower Flesch-Kincaid scores, yet damaging
the grammaticality and semantic coherence of the
original text, as is evidenced by the negative cor-
relation for Simplicity and positive correlations for
Fluency and Adequacy in Table 5.
In the future we would like to investigate how we
can boost the number of edits the system performs,
while still producing grammatical and meaning-
preserving output. Although the comparison against
the Zhu system, which uses syntax-driven machine
translation, shows no clear benefit for syntax-based
machine translation, it may still be the case that ap-
proaches such as Hiero (Chiang et al., 2005) and
Joshua (Li et al., 2009), enhanced by dissimilarity-
based re-ranking, would improve over our current
system. Furthermore, typical simplification oper-
ations such as sentence splitting and more radical
syntax alterations or even document-level operations
such as manipulations of the co-reference structure
would be interesting to implement and test
</bodyText>
<sectionHeader confidence="0.996513" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999716666666667">
We are grateful to Zhemin Zhu and Kristian Woods-
end for sharing their data. We would also like to
thank the anonymous reviewers for their comments.
</bodyText>
<page confidence="0.995751">
1022
</page>
<sectionHeader confidence="0.990195" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997599010989011">
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In ACL ’05:
Proceedings of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, pages 597–604,
Morristown, NJ, USA. Association for Computational
Linguistics.
Chris Callison-Burch. 2008. Syntactic constraints
on paraphrases extracted from parallel corpora. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’08,
pages 196–205, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Yvonne Canning, John Tait, Jackie Archibald, and Ros
Crawley. 2000. Cohesive regeneration of syntacti-
cally simplified newspaper text. In Proceedings ofRO-
MAND 2000, Lausanne.
John Carroll, Guido Minnen, Yvonne Canning, Siobhan
Devlin, and John Tait. 1998. Practical simplification
of English newspaper text to assist aphasic readers.
In AAAI-98 Workshop on Integrating Artificial Intelli-
gence and Assistive Technology, Madison, Wisconsin.
John Carroll, Guido Minnen, Darren Pearce, Yvonne
Canning, Siobhan Devlin, and John Tait. 1999. Sim-
plifying text for language-impaired readers. In Pro-
ceedings of EACL’99, Bergen. ACL.
R. Chandrasekar and B. Srinivas. 1997. Automatic
rules for text simplification. Knowledge-Based Sys-
tems, 10:183–190.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and methods for text
simplification. In Proceedings of the Sixteenth In-
ternational Conference on Computational Linguistics
(COLING’96), pages 1041–1044.
David Chiang, Adam Lopez, Nitin Madnani, Christof
Monz, Philip Resnik, and Michael Subotin. 2005. The
hiero machine translation system: extensions, evalua-
tion, and analysis. In Proceedings of the conference on
Human Language Technology and Empirical Methods
in Natural Language Processing, HLT ’05, pages 779–
786, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Will Coster and David Kauchak. 2011. Learning to
simplify sentences using wikipedia. In Proceedings
of the Workshop on Monolingual Text-To-Text Gener-
ation, pages 1–9, Portland, Oregon, June. Association
for Computational Linguistics.
Walter Daelemans, Jakub Zavrel, Peter Berck, and Steven
Gillis. 1996. MBT: A Memory-Based Part of Speech
Tagger-Generator. In Proc. of Fourth Workshop on
Very Large Corpora, pages 14–27. ACL SIGDAT.
Walter Daelemans, Anja Hothker, and Erik Tjong
Kim Sang. 2004. Automatic sentence simplification
for subtitling in dutch and english. In Proceedings
of the 4th International Conference on Language Re-
sources and Evaluation, pages 1045–1048.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In Proceedings of the second interna-
tional conference on Human Language Technology
Research, HLT ’02, pages 138–145, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. The MIT Press, May.
Katja Filippova and Michael Strube. 2008. Sentence fu-
sion via dependency graph compression. In Proceed-
ings of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 177–185, Hon-
olulu, Hawaii, October. Association for Computational
Linguistics.
Kentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Ryu
Iida, and Tomoya Iwakura. 2003. Text simplification
for reading assistance: A project note. In Proceedings
of the Second International Workshop on Paraphras-
ing, pages 9–16, Sapporo, Japan, July. Association for
Computational Linguistics.
Kevin Knight and Daniel Marcu. 2000. Statistics-based
summarization – step one: Sentence compression. In
Proceedings of the 17th National Conference on Ar-
tificial Intelligence (AAAI), pages 703 – 710, Austin,
Texas, USA, July 30 – August 3.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris C.
Burch, Marcello Federico, Nicola Bertoldi, Brooke
Cowan, Wade Shen, Christine Moran, Richard Zens,
Chris Dyer, Ondrej Bojar, Alexandra Constantin, and
Evan Herbst. 2007. Moses: Open source toolkit for
statistical machine translation. In ACL. The Associa-
tion for Computer Linguistics.
V. Levenshtein. 1966. Binary codes capable of correct-
ing deletions, insertions, and reversals. Soviet Physics
Doklady, 10(8):707–710.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-
itkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren
N. G. Thornton, Jonathan Weese, and Omar F. Zaidan.
2009. Joshua: an open source toolkit for parsing-
based machine translation. In Proceedings of the
Fourth Workshop on Statistical Machine Translation,
pages 135–139, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and
Bonnie J. Dorr. 2007. Using paraphrases for pa-
rameter tuning in statistical machine translation. In
Proceedings of the Second Workshop on Statistical
Machine Translation, StatMT ’07, pages 120–127,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
1023
Rani Nelken and Stuart M. Shieber. 2006. Towards ro-
bust context-sensitive sentence alignment for monolin-
gual corpora. In Proceedings of the 11th Conference
of the European Chapter of the Association for Com-
putational Linguistics (EACL-06), Trento, Italy, 3–7
April.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Comput. Linguist., 29(1):19–51, March.
Chris Quirk, Chris Brockett, and William Dolan. 2004.
Monolingual machine translation for paraphrase gen-
eration. In Dekang Lin and Dekai Wu, editors, Pro-
ceedings of EMNLP 2004, pages 142–149, Barcelona,
Spain, July. Association for Computational Linguis-
tics.
Advaith Siddharthan. 2002. An architecture for a text
simplification system. In Language Engineering Con-
ference, page 64. IEEE Computer Society.
David A. Smith and Jason Eisner. 2006. Quasi-
synchronous grammars: Alignment by soft projection
of syntactic dependencies. In Proceedings of the HLT-
NAACL Workshop on Statistical Machine Translation,
pages 23–30, New York, June.
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In In Proc. Int. Conf. on
Spoken Language Processing, pages 901–904, Denver,
Colorado.
D. Vickrey and D. Koller. 2008. Sentence simplification
for semantic role labeling. In Proceedings of the 46th
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies.
Willian Massami Watanabe, Arnaldo Candido Junior,
Vincius Rodriguez de Uzłda, Renata Pontin de Mat-
tos Fortes, Thiago Alexandre Salgueiro Pardo, and
Sandra M. Alusio. 2009. Facilita: reading assistance
for low-literacy readers. In Brad Mehlenbacher, Aris-
tidis Protopsaltis, Ashley Williams, and Shaun Slat-
tery, editors, SIGDOC, pages 29–36. ACM.
Kristian Woodsend and Mirella Lapata. 2011. Learning
to simplify sentences with quasi-synchronous gram-
mar and integer programming. In Proceedings of
the 2011 Conference on Empirical Methods in Natu-
ral Language Processing, pages 409–420, Edinburgh,
Scotland, UK., July. Association for Computational
Linguistics.
Sander Wubben, Antal van den Bosch, and Emiel Krah-
mer. 2010. Paraphrase generation as monolingual
translation: data and evaluation. In Proceedings of the
6th International Natural Language Generation Con-
ference, INLG ’10, pages 203–207, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings of
the 39th Annual Meeting on Association for Computa-
tional Linguistics, ACL ’01, pages 523–530, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-
Mizil, and Lillian Lee. 2010. For the sake of simplic-
ity: Unsupervised extraction of lexical simplifications
from Wikipedia. In Proceedings of the NAACL, pages
365–368.
Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009.
Application-driven statistical paraphrase generation.
In Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP: Volume 2 - Volume 2, ACL ’09,
pages 834–842, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.
2010. A monolingual tree-based translation model for
sentence simplification. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics
(Coling 2010), pages 1353–1361, Beijing, China, Au-
gust. Coling 2010 Organizing Committee.
</reference>
<page confidence="0.995411">
1024
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.527082">
<title confidence="0.999965">Sentence Simplification by Monolingual Machine Translation</title>
<author confidence="0.99999">Sander Wubben</author>
<affiliation confidence="0.999703">Tilburg University</affiliation>
<address confidence="0.994935333333333">P.O. Box 90135 5000 LE Tilburg The Netherlands</address>
<email confidence="0.994575">s.wubben@uvt.nl</email>
<author confidence="0.993613">Antal van_den</author>
<affiliation confidence="0.999759">Radboud University</affiliation>
<address confidence="0.936304666666667">P.O. Box 6500 HD The Netherlands</address>
<email confidence="0.99219">a.vandenbosch@let.ru.nl</email>
<author confidence="0.67072">Emiel Krahmer</author>
<affiliation confidence="0.999452">Tilburg University</affiliation>
<address confidence="0.995945666666667">P.O. Box 90135 5000 LE Tilburg The Netherlands</address>
<email confidence="0.998582">e.j.krahmer@uvt.nl</email>
<abstract confidence="0.99981285">In this paper we describe a method for simplifying sentences using Phrase Based Machine Translation, augmented with a re-ranking heuristic based on dissimilarity, and trained on a monolingual parallel corpus. We compare our system to a word-substitution baseline and two state-of-the-art systems, all trained and tested on paired sentences from the English part of Wikipedia and Simple Wikipedia. Human test subjects judge the output of the different systems. Analysing the judgements shows that by relatively careful phrase-based paraphrasing our model achieves similar simplification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>597--604</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597–604, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>196--205</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6638" citStr="Callison-Burch, 2008" startWordPosition="1028" endWordPosition="1029">et al., 2010). These numbers suggest that, although the selection criteria for sentences to be included in this dataset are biased (see Section 2.2), Simple Wikipedia sentences are about 17% shorter, while the average word length is virtually equal. Sent. length Token length Simple Wikipedia 20.87 4.89 Wikipedia 25.01 5.06 Table 1: Sentence and token length statistics for the PWKP dataset (Zhu et al., 2010). Statistical machine translation (SMT) has already been successfully applied to the related task of paraphrasing (Quirk et al., 2004; Bannard and CallisonBurch, 2005; Madnani et al., 2007; Callison-Burch, 2008; Zhao et al., 2009; Wubben et al., 2010). SMT typically makes use of large parallel corpora to train a model on. These corpora need to be aligned at the sentence level. Large parallel corpora, such as the multilingual proceedings of the European Parliament (Europarl), are readily available for many languages. Phrase-Based Machine Translation (PBMT) is a form of SMT where the translation model aims to translate longer sequences of words (“phrases”) in one go, solving part of the word ordering problem along the way that would be left to the target language model in a word-based SMT system. PMBT</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 196–205, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yvonne Canning</author>
<author>John Tait</author>
<author>Jackie Archibald</author>
<author>Ros Crawley</author>
</authors>
<title>Cohesive regeneration of syntactically simplified newspaper text.</title>
<date>2000</date>
<booktitle>In Proceedings ofROMAND 2000,</booktitle>
<location>Lausanne.</location>
<contexts>
<context position="3795" citStr="Canning et al., 2000" startWordPosition="575" endWordPosition="578">he sentences are somewhat shorter than those found in English Wikipedia; we offer more detailed statistics below. 1.1 Related work Most earlier work on sentence simplification adopted rule-based approaches. A frequently applied type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster a</context>
</contexts>
<marker>Canning, Tait, Archibald, Crawley, 2000</marker>
<rawString>Yvonne Canning, John Tait, Jackie Archibald, and Ros Crawley. 2000. Cohesive regeneration of syntactically simplified newspaper text. In Proceedings ofROMAND 2000, Lausanne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Yvonne Canning</author>
<author>Siobhan Devlin</author>
<author>John Tait</author>
</authors>
<title>Practical simplification of English newspaper text to assist aphasic readers.</title>
<date>1998</date>
<booktitle>In AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology,</booktitle>
<location>Madison, Wisconsin.</location>
<contexts>
<context position="3773" citStr="Carroll et al., 1998" startWordPosition="570" endWordPosition="574">less complicated and the sentences are somewhat shorter than those found in English Wikipedia; we offer more detailed statistics below. 1.1 Related work Most earlier work on sentence simplification adopted rule-based approaches. A frequently applied type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a </context>
</contexts>
<marker>Carroll, Minnen, Canning, Devlin, Tait, 1998</marker>
<rawString>John Carroll, Guido Minnen, Yvonne Canning, Siobhan Devlin, and John Tait. 1998. Practical simplification of English newspaper text to assist aphasic readers. In AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology, Madison, Wisconsin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Darren Pearce</author>
<author>Yvonne Canning</author>
<author>Siobhan Devlin</author>
<author>John Tait</author>
</authors>
<title>Simplifying text for language-impaired readers.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL’99,</booktitle>
<publisher>ACL.</publisher>
<location>Bergen.</location>
<contexts>
<context position="1660" citStr="Carroll et al., 1999" startWordPosition="235" endWordPosition="239">put. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems. 1 Introduction Sentence simplification can be defined as the process of producing a simplified version of a sentence by changing some of the lexical material and grammatical structure of that sentence, while still preserving the semantic content of the original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be underst</context>
</contexts>
<marker>Carroll, Minnen, Pearce, Canning, Devlin, Tait, 1999</marker>
<rawString>John Carroll, Guido Minnen, Darren Pearce, Yvonne Canning, Siobhan Devlin, and John Tait. 1999. Simplifying text for language-impaired readers. In Proceedings of EACL’99, Bergen. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Chandrasekar</author>
<author>B Srinivas</author>
</authors>
<title>Automatic rules for text simplification. Knowledge-Based Systems,</title>
<date>1997</date>
<pages>10--183</pages>
<contexts>
<context position="3751" citStr="Chandrasekar and Srinivas, 1997" startWordPosition="566" endWordPosition="569">s in English Simple Wikipedia is less complicated and the sentences are somewhat shorter than those found in English Wikipedia; we offer more detailed statistics below. 1.1 Related work Most earlier work on sentence simplification adopted rule-based approaches. A frequently applied type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine trans</context>
</contexts>
<marker>Chandrasekar, Srinivas, 1997</marker>
<rawString>R. Chandrasekar and B. Srinivas. 1997. Automatic rules for text simplification. Knowledge-Based Systems, 10:183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raman Chandrasekar</author>
<author>Christine Doran</author>
<author>Bangalore Srinivas</author>
</authors>
<title>Motivations and methods for text simplification.</title>
<date>1996</date>
<booktitle>In Proceedings of the Sixteenth International Conference on Computational Linguistics (COLING’96),</booktitle>
<pages>1041--1044</pages>
<contexts>
<context position="2035" citStr="Chandrasekar et al., 1996" startWordPosition="292" endWordPosition="296">, while still preserving the semantic content of the original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be understood. Some of the factors that are known to help increase the readability of text are the vocabulary used, the length of the sentences, the syntactic structures present in the text, and the usage of discourse markers. One effort to create a simple version of English at the vocabulary level has been the creation of Basic English by Charles Kay Ogden. Basic English is a contr</context>
</contexts>
<marker>Chandrasekar, Doran, Srinivas, 1996</marker>
<rawString>Raman Chandrasekar, Christine Doran, and Bangalore Srinivas. 1996. Motivations and methods for text simplification. In Proceedings of the Sixteenth International Conference on Computational Linguistics (COLING’96), pages 1041–1044.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Adam Lopez</author>
<author>Nitin Madnani</author>
<author>Christof Monz</author>
<author>Philip Resnik</author>
<author>Michael Subotin</author>
</authors>
<title>The hiero machine translation system: extensions, evaluation, and analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>779--786</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Chiang, Lopez, Madnani, Monz, Resnik, Subotin, 2005</marker>
<rawString>David Chiang, Adam Lopez, Nitin Madnani, Christof Monz, Philip Resnik, and Michael Subotin. 2005. The hiero machine translation system: extensions, evaluation, and analysis. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 779– 786, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Will Coster</author>
<author>David Kauchak</author>
</authors>
<title>Learning to simplify sentences using wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Monolingual Text-To-Text Generation,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon,</location>
<contexts>
<context position="4412" citStr="Coster and Kauchak (2011)" startWordPosition="671" endWordPosition="674">l., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. Another useful resource is the edit history of Simple Wikipedia, from which simplifications can be learned (Yatskar et al., 2010). Woodsend and Lapata (2011) investigate the use of Simple Wikipedia edit histories and an aligned Wikipedia– Simple Wikipedia corpus to induce a model based on quasi-synchronous grammar. They select the most appropriate simplification by using integer linear programming. We follow Zhu et al. (2010) and Coster</context>
</contexts>
<marker>Coster, Kauchak, 2011</marker>
<rawString>Will Coster and David Kauchak. 2011. Learning to simplify sentences using wikipedia. In Proceedings of the Workshop on Monolingual Text-To-Text Generation, pages 1–9, Portland, Oregon, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Peter Berck</author>
<author>Steven Gillis</author>
</authors>
<title>MBT: A Memory-Based Part of Speech Tagger-Generator.</title>
<date>1996</date>
<booktitle>In Proc. of Fourth Workshop on Very Large Corpora,</booktitle>
<pages>14--27</pages>
<publisher>ACL SIGDAT.</publisher>
<contexts>
<context position="10058" citStr="Daelemans et al., 1996" startWordPosition="1591" endWordPosition="1594">ng to a language model. For each noun, adjective and verb in the sentence this model takes that word and its part-of-speech tag and retrieves from WordNet all synonyms from all synsets the word occurs in. The word is then replaced by all of its synset words, and each replacement is scored by a SRILM language model (Stolcke, 2002) with probabilities that are obtained from training on the Simple Wikipedia data. The alternative that has the highest probability according to the language model is kept. If no relevant alternative is found, the word is left unchanged. We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags. The WordNet::QueryData2 Perl mod2http://search.cpan.org/dist/ WordNet-QueryData/QueryData.pm ule is used to query WordNet (Fellbaum, 1998). 2.2 Zhu et al. Zhu et al. (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion. Their model is inspired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. The four mentioned simplification op</context>
</contexts>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Peter Berck, and Steven Gillis. 1996. MBT: A Memory-Based Part of Speech Tagger-Generator. In Proc. of Fourth Workshop on Very Large Corpora, pages 14–27. ACL SIGDAT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
</authors>
<title>Anja Hothker, and Erik Tjong Kim Sang.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>1045--1048</pages>
<marker>Daelemans, 2004</marker>
<rawString>Walter Daelemans, Anja Hothker, and Erik Tjong Kim Sang. 2004. Automatic sentence simplification for subtitling in dutch and english. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 1045–1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research, HLT ’02,</booktitle>
<pages>138--145</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="19664" citStr="Doddington, 2002" startWordPosition="3166" endWordPosition="3167">ut. From this subset we randomly pick 20 source sentences, resulting in 20 clusters of one source sentence and 5 simplified sentences, as generated by humans (Simple Wikipedia) and the four systems. 1019 3.3 Procedure The participants were told that they participated in the evaluation of a system that could simplify sentences, and that they would see one source sentence and five automatically simplified versions of that sentence. They were not informed of the fact that we evaluated in fact four different systems and the original Simple Wikipedia sentence. Following earlier evaluation studies (Doddington, 2002; Woodsend and Lapata, 2011), we asked participants to evaluate Simplicity, Fluency and Adequacy of the target headlines on a five point Likert scale. Fluency was defined in the instructions as the extent to which a sentence is proper, grammatical English. Adequacy was defined as the extent to which the sentence has the same meaning as the source sentence. Simplicity was defined as the extent to which the sentence was simpler than the original and thus easier to understand. The order in which the clusters had to be judged was randomized and the order of the output of the various systems was ra</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second international conference on Human Language Technology Research, HLT ’02, pages 138–145, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press,</publisher>
<contexts>
<context position="10260" citStr="Fellbaum, 1998" startWordPosition="1618" endWordPosition="1619">ord is then replaced by all of its synset words, and each replacement is scored by a SRILM language model (Stolcke, 2002) with probabilities that are obtained from training on the Simple Wikipedia data. The alternative that has the highest probability according to the language model is kept. If no relevant alternative is found, the word is left unchanged. We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags. The WordNet::QueryData2 Perl mod2http://search.cpan.org/dist/ WordNet-QueryData/QueryData.pm ule is used to query WordNet (Fellbaum, 1998). 2.2 Zhu et al. Zhu et al. (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion. Their model is inspired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. The four mentioned simplification operations together form the translation model. Their model is trained on a corpus containing aligned sentences from English Wikipedia and English Simple Wikipedia called PWKP. The PWKP dataset consists o</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. The MIT Press, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Michael Strube</author>
</authors>
<title>Sentence fusion via dependency graph compression.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>177--185</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="2134" citStr="Filippova and Strube, 2008" startWordPosition="308" endWordPosition="311">standing. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be understood. Some of the factors that are known to help increase the readability of text are the vocabulary used, the length of the sentences, the syntactic structures present in the text, and the usage of discourse markers. One effort to create a simple version of English at the vocabulary level has been the creation of Basic English by Charles Kay Ogden. Basic English is a controlled language with a basic vocabulary consisting of 850 words. According to Ogden, 90 percent of a</context>
</contexts>
<marker>Filippova, Strube, 2008</marker>
<rawString>Katja Filippova and Michael Strube. 2008. Sentence fusion via dependency graph compression. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 177–185, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Inui</author>
<author>Atsushi Fujita</author>
<author>Tetsuro Takahashi</author>
<author>Ryu Iida</author>
<author>Tomoya Iwakura</author>
</authors>
<title>Text simplification for reading assistance: A project note.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<contexts>
<context position="1621" citStr="Inui et al., 2003" startWordPosition="228" endWordPosition="231">, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems. 1 Introduction Sentence simplification can be defined as the process of producing a simplified version of a sentence by changing some of the lexical material and grammatical structure of that sentence, while still preserving the semantic content of the original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as th</context>
<context position="4019" citStr="Inui et al., 2003" startWordPosition="610" endWordPosition="613">d type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. Another useful resource is the edit history of </context>
</contexts>
<marker>Inui, Fujita, Takahashi, Iida, Iwakura, 2003</marker>
<rawString>Kentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Ryu Iida, and Tomoya Iwakura. 2003. Text simplification for reading assistance: A project note. In Proceedings of the Second International Workshop on Paraphrasing, pages 9–16, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistics-based summarization – step one: Sentence compression.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th National Conference on Artificial Intelligence (AAAI),</booktitle>
<volume>30</volume>
<pages>703--710</pages>
<location>Austin, Texas, USA,</location>
<contexts>
<context position="1977" citStr="Knight and Marcu, 2000" startWordPosition="285" endWordPosition="288">cal material and grammatical structure of that sentence, while still preserving the semantic content of the original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be understood. Some of the factors that are known to help increase the readability of text are the vocabulary used, the length of the sentences, the syntactic structures present in the text, and the usage of discourse markers. One effort to create a simple version of English at the vocabulary level has been the creation of Ba</context>
</contexts>
<marker>Knight, Marcu, 2000</marker>
<rawString>Kevin Knight and Daniel Marcu. 2000. Statistics-based summarization – step one: Sentence compression. In Proceedings of the 17th National Conference on Artificial Intelligence (AAAI), pages 703 – 710, Austin, Texas, USA, July 30 – August 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris C Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation. In ACL. The Association for Computer Linguistics.</title>
<date>2007</date>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="12963" citStr="Koehn et al., 2007" startWordPosition="2040" endWordPosition="2043">nslation p(f|e) with a language model that outputs the most likely sentence p(e): e� = arg max p(f|e)p(e) eEe human judgements conducted in their study. They show that it achieves better scores than Zhu et al. (2010)’s system and is not scored significantly differently from English Simple Wikipedia. In this study we compare against their best performing system, the RevILP system. Flesch-Kincaid n-best 14 12 10 8 6 4 2 0 Figure 1: Levenshtein distance and Flesch-Kincaid score of output when varying the n of the n-best output of Moses. 2.4 PBMT-R We use the Moses software to train a PBMT model (Koehn et al., 2007). The data we use is the PWKP dataset created by Zhu et al. (2010). In general, a statistical machine translation model finds a best translation e� of a text in language f to a text in language e by combining a translation model that The GIZA++ statistical alignment package is used to perform the word alignments, which are later combined into phrase alignments in the Moses pipeline (Och and Ney, 2003) to build the sentence simplification model. GIZA++ utilizes IBM Models 1 to 5 and an HMM word alignment model to find statistically motivated alignments between words. We first tokenize and lower</context>
</contexts>
<marker>Koehn, Hoang, Birch, Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris C. Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="15752" citStr="Levenshtein, 1966" startWordPosition="2533" endWordPosition="2535">his to select output that is as different as possible from the source sentence, so that it ideally con3 2 Levenshtein Distance 1 0 2 4 6 8 10 12 14 16 18 4 0 0 2 4 6 8 10 12 14 16 18 n-best 1018 tains multiple simplifications; at the same time, we base our re-ranking on a top-n of output candidates according to Moses, with a small n, to ensure that the quality of the output in terms of fluency and adequacy is also controlled for. Setting n = 10, for each source sentence we re-rank the ten best sentences as scored by the decoder according to the Levenshtein Distance (or edit distance) measure (Levenshtein, 1966) at the word level between the input and output sentence, counting the minimum number of edits needed to transform the source string into the target string, where the allowable edit operations are insertion, deletion, and substitution of a single word. In case of a tie in Levenshtein Distance, we select the sequence with the better decoder score. When Moses is unable to generate ten different sentences, we select from the lower number of outputs. Figure 1 displays Levenshtein Distance and FleschKincaid grade level scores for different values of n. We use the Lingua::EN::Fathom module4 to calcu</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>V. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(8):707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Chris Callison-Burch</author>
<author>Chris Dyer</author>
<author>Juri Ganitkevitch</author>
<author>Sanjeev Khudanpur</author>
<author>Lane Schwartz</author>
<author>Wren N G Thornton</author>
<author>Jonathan Weese</author>
<author>Omar F Zaidan</author>
</authors>
<title>Joshua: an open source toolkit for parsingbased machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>135--139</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Li, Callison-Burch, Dyer, Ganitkevitch, Khudanpur, Schwartz, Thornton, Weese, Zaidan, 2009</marker>
<rawString>Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren N. G. Thornton, Jonathan Weese, and Omar F. Zaidan. 2009. Joshua: an open source toolkit for parsingbased machine translation. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 135–139, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Necip Fazil Ayan</author>
<author>Philip Resnik</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Using paraphrases for parameter tuning in statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation, StatMT ’07,</booktitle>
<pages>120--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6616" citStr="Madnani et al., 2007" startWordPosition="1024" endWordPosition="1027">ed in this study (Zhu et al., 2010). These numbers suggest that, although the selection criteria for sentences to be included in this dataset are biased (see Section 2.2), Simple Wikipedia sentences are about 17% shorter, while the average word length is virtually equal. Sent. length Token length Simple Wikipedia 20.87 4.89 Wikipedia 25.01 5.06 Table 1: Sentence and token length statistics for the PWKP dataset (Zhu et al., 2010). Statistical machine translation (SMT) has already been successfully applied to the related task of paraphrasing (Quirk et al., 2004; Bannard and CallisonBurch, 2005; Madnani et al., 2007; Callison-Burch, 2008; Zhao et al., 2009; Wubben et al., 2010). SMT typically makes use of large parallel corpora to train a model on. These corpora need to be aligned at the sentence level. Large parallel corpora, such as the multilingual proceedings of the European Parliament (Europarl), are readily available for many languages. Phrase-Based Machine Translation (PBMT) is a form of SMT where the translation model aims to translate longer sequences of words (“phrases”) in one go, solving part of the word ordering problem along the way that would be left to the target language model in a word-</context>
</contexts>
<marker>Madnani, Ayan, Resnik, Dorr, 2007</marker>
<rawString>Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie J. Dorr. 2007. Using paraphrases for parameter tuning in statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, StatMT ’07, pages 120–127, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart M Shieber</author>
</authors>
<title>Towards robust context-sensitive sentence alignment for monolingual corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06),</booktitle>
<location>Trento,</location>
<contexts>
<context position="11126" citStr="Nelken and Shieber, 2006" startWordPosition="1755" endWordPosition="1758">pired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. The four mentioned simplification operations together form the translation model. Their model is trained on a corpus containing aligned sentences from English Wikipedia and English Simple Wikipedia called PWKP. The PWKP dataset consists of 108,016 pairs of aligned lines from 65,133 Wikipedia and Simple Wikipedia articles. These articles were paired by following the “interlanguage link”3. TF*IDF at the sentence level was used to align the sentences in the different articles (Nelken and Shieber, 2006). Zhu et al. (2010) evaluate their system using BLEU and NIST scores, as well as various readability scores that only take into account the output sentence, such as the Flesch Reading Ease test and n-gram language model perplexity. Although their system outperforms several baselines at the level of these readability metrics, they do not achieve better when evaluated with BLEU or NIST. 2.3 RevILP Woodsend and Lapata’s (2011) model is based on quasi-synchronous grammar (Smith and Eisner, 2006). Quasi-synchronous grammar generates a loose alignment between parse trees. It operates on individual s</context>
</contexts>
<marker>Nelken, Shieber, 2006</marker>
<rawString>Rani Nelken and Stuart M. Shieber. 2006. Towards robust context-sensitive sentence alignment for monolingual corpora. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), Trento, Italy, 3–7 April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="13367" citStr="Och and Ney, 2003" startWordPosition="2112" endWordPosition="2115">14 12 10 8 6 4 2 0 Figure 1: Levenshtein distance and Flesch-Kincaid score of output when varying the n of the n-best output of Moses. 2.4 PBMT-R We use the Moses software to train a PBMT model (Koehn et al., 2007). The data we use is the PWKP dataset created by Zhu et al. (2010). In general, a statistical machine translation model finds a best translation e� of a text in language f to a text in language e by combining a translation model that The GIZA++ statistical alignment package is used to perform the word alignments, which are later combined into phrase alignments in the Moses pipeline (Och and Ney, 2003) to build the sentence simplification model. GIZA++ utilizes IBM Models 1 to 5 and an HMM word alignment model to find statistically motivated alignments between words. We first tokenize and lowercase all data and use all unique sentences from the Simple Wikipedia part of the PWKP training set to train an n-gram language model with the SRILM toolkit to learn the probabilities of different n-grams. Then we invoke the GIZA++ aligner using the training simplification pairs. We run GIZA++ with standard settings and we perform no optimization. This results in a phrase table containing phrase pairs </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
<author>William Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>142--149</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="6561" citStr="Quirk et al., 2004" startWordPosition="1015" endWordPosition="1018">and Simple Wikipedia sentences in the PWKP dataset used in this study (Zhu et al., 2010). These numbers suggest that, although the selection criteria for sentences to be included in this dataset are biased (see Section 2.2), Simple Wikipedia sentences are about 17% shorter, while the average word length is virtually equal. Sent. length Token length Simple Wikipedia 20.87 4.89 Wikipedia 25.01 5.06 Table 1: Sentence and token length statistics for the PWKP dataset (Zhu et al., 2010). Statistical machine translation (SMT) has already been successfully applied to the related task of paraphrasing (Quirk et al., 2004; Bannard and CallisonBurch, 2005; Madnani et al., 2007; Callison-Burch, 2008; Zhao et al., 2009; Wubben et al., 2010). SMT typically makes use of large parallel corpora to train a model on. These corpora need to be aligned at the sentence level. Large parallel corpora, such as the multilingual proceedings of the European Parliament (Europarl), are readily available for many languages. Phrase-Based Machine Translation (PBMT) is a form of SMT where the translation model aims to translate longer sequences of words (“phrases”) in one go, solving part of the word ordering problem along the way tha</context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>Chris Quirk, Chris Brockett, and William Dolan. 2004. Monolingual machine translation for paraphrase generation. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 142–149, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>An architecture for a text simplification system.</title>
<date>2002</date>
<booktitle>In Language Engineering Conference,</booktitle>
<pages>64</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="1567" citStr="Siddharthan, 2002" startWordPosition="222" endWordPosition="223">lar simplification results to state-of-the-art systems, while generating better formed output. We also argue that text readability metrics such as the Flesch-Kincaid grade level should be used with caution when evaluating the output of simplification systems. 1 Introduction Sentence simplification can be defined as the process of producing a simplified version of a sentence by changing some of the lexical material and grammatical structure of that sentence, while still preserving the semantic content of the original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is t</context>
</contexts>
<marker>Siddharthan, 2002</marker>
<rawString>Advaith Siddharthan. 2002. An architecture for a text simplification system. In Language Engineering Conference, page 64. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies.</title>
<date>2006</date>
<booktitle>In Proceedings of the HLTNAACL Workshop on Statistical Machine Translation,</booktitle>
<pages>23--30</pages>
<location>New York,</location>
<contexts>
<context position="11622" citStr="Smith and Eisner, 2006" startWordPosition="1834" endWordPosition="1837">guage link”3. TF*IDF at the sentence level was used to align the sentences in the different articles (Nelken and Shieber, 2006). Zhu et al. (2010) evaluate their system using BLEU and NIST scores, as well as various readability scores that only take into account the output sentence, such as the Flesch Reading Ease test and n-gram language model perplexity. Although their system outperforms several baselines at the level of these readability metrics, they do not achieve better when evaluated with BLEU or NIST. 2.3 RevILP Woodsend and Lapata’s (2011) model is based on quasi-synchronous grammar (Smith and Eisner, 2006). Quasi-synchronous grammar generates a loose alignment between parse trees. It operates on individual sentences annotated with syntactic information in the form of phrase structure trees. Quasisynchronous grammar is used to generate all possible rewrite operations, after which integer linear programming is employed to select the most appropriate simplification. Their model is trained on two different datasets: one containing alignments between Wikipedia and English Simple Wikipedia (AlignILP), and one containing alignments between edits in the revision history of Simple Wikipedia (RevILP). Re</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>David A. Smith and Jason Eisner. 2006. Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies. In Proceedings of the HLTNAACL Workshop on Statistical Machine Translation, pages 23–30, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit. In</title>
<date>2002</date>
<booktitle>In Proc. Int. Conf. on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado.</location>
<contexts>
<context position="9766" citStr="Stolcke, 2002" startWordPosition="1544" endWordPosition="1546">and its results in Section 4. We close this paper by critically discussing our results in Section 5. 2 Sentence Simplification Models 2.1 Word-Substitution Baseline The word substitution baseline replaces words in the source sentence with (near-)synonyms that are more likely according to a language model. For each noun, adjective and verb in the sentence this model takes that word and its part-of-speech tag and retrieves from WordNet all synonyms from all synsets the word occurs in. The word is then replaced by all of its synset words, and each replacement is scored by a SRILM language model (Stolcke, 2002) with probabilities that are obtained from training on the Simple Wikipedia data. The alternative that has the highest probability according to the language model is kept. If no relevant alternative is found, the word is left unchanged. We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags. The WordNet::QueryData2 Perl mod2http://search.cpan.org/dist/ WordNet-QueryData/QueryData.pm ule is used to query WordNet (Fellbaum, 1998). 2.2 Zhu et al. Zhu et al. (2010) learn a sentence simplification model which is able to perform four rew</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - An Extensible Language Modeling Toolkit. In In Proc. Int. Conf. on Spoken Language Processing, pages 901–904, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Vickrey</author>
<author>D Koller</author>
</authors>
<title>Sentence simplification for semantic role labeling.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Meeting of the Association</booktitle>
<contexts>
<context position="2086" citStr="Vickrey and Koller, 2008" startWordPosition="300" endWordPosition="304"> original sentence, in order to ease its understanding. Particularly language learners (Siddharthan, 2002), people with reading disabilities (Inui et al., 2003) such as aphasia (Carroll et al., 1999), and low-literacy readers (Watanabe et al., 2009) can benefit from this application. It can serve to generate output in a specific limited format, such as subtitles (Daelemans et al., 2004). Sentence simplification can also serve to preprocess the input of other tasks, such as summarization (Knight and Marcu, 2000), parsing, machine translation (Chandrasekar et al., 1996), semantic role labeling (Vickrey and Koller, 2008) or sentence fusion (Filippova and Strube, 2008). The goal of simplification is to achieve an improvement in readability, defined as the ease with which a text can be understood. Some of the factors that are known to help increase the readability of text are the vocabulary used, the length of the sentences, the syntactic structures present in the text, and the usage of discourse markers. One effort to create a simple version of English at the vocabulary level has been the creation of Basic English by Charles Kay Ogden. Basic English is a controlled language with a basic vocabulary consisting o</context>
<context position="3822" citStr="Vickrey and Koller, 2008" startWordPosition="579" endWordPosition="582">hat shorter than those found in English Wikipedia; we offer more detailed statistics below. 1.1 Related work Most earlier work on sentence simplification adopted rule-based approaches. A frequently applied type of rule, aimed to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a par</context>
</contexts>
<marker>Vickrey, Koller, 2008</marker>
<rawString>D. Vickrey and D. Koller. 2008. Sentence simplification for semantic role labeling. In Proceedings of the 46th Meeting of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willian Massami Watanabe</author>
</authors>
<title>Arnaldo Candido Junior, Vincius Rodriguez de Uzłda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo,</title>
<date>2009</date>
<pages>29--36</pages>
<editor>In Brad Mehlenbacher, Aristidis Protopsaltis, Ashley Williams, and Shaun Slattery, editors, SIGDOC,</editor>
<publisher>ACM.</publisher>
<location>and</location>
<marker>Watanabe, 2009</marker>
<rawString>Willian Massami Watanabe, Arnaldo Candido Junior, Vincius Rodriguez de Uzłda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra M. Alusio. 2009. Facilita: reading assistance for low-literacy readers. In Brad Mehlenbacher, Aristidis Protopsaltis, Ashley Williams, and Shaun Slattery, editors, SIGDOC, pages 29–36. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Mirella Lapata</author>
</authors>
<title>Learning to simplify sentences with quasi-synchronous grammar and integer programming.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>409--420</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="4729" citStr="Woodsend and Lapata (2011)" startWordPosition="722" endWordPosition="726">ple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. Another useful resource is the edit history of Simple Wikipedia, from which simplifications can be learned (Yatskar et al., 2010). Woodsend and Lapata (2011) investigate the use of Simple Wikipedia edit histories and an aligned Wikipedia– Simple Wikipedia corpus to induce a model based on quasi-synchronous grammar. They select the most appropriate simplification by using integer linear programming. We follow Zhu et al. (2010) and Coster and Kauchak (2011) in proposing that sentence simplification can be approached as a monolingual machine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning. We differ from the approach of Zhu et al. (2010) in the s</context>
<context position="8738" citStr="Woodsend and Lapata (2011)" startWordPosition="1375" endWordPosition="1379"> vided that a parallel corpus is available that pairs text to simplified versions of that text. 1.2 This study In this work we aim to investigate the use of phrasebased machine translation modified with a dissimilarity component for the task of sentence simplification. While Zhu et al. (2010) have demonstrated that their approach outperforms a PBMT approach in terms of Flesch Reading Ease test scores, we are not aware of any studies that evaluate PBMT for sentence simplification with human judgements. In this study we evaluate the output of Zhu et al. (2010) (henceforth referred to as ‘Zhu’), Woodsend and Lapata (2011) (henceforth referred to as ‘RevILP’), our PBMT based system with dissimilarity-based re-ranking (henceforth referred to as ‘PBMT-R’), a word-substitution baseline, and, as a gold standard, the original Simple Wikipedia sentences. We will first discuss the baseline, followed by the Zhu system, the RevILP system, and our PBMT-R system in Section 2. We then describe the experiment with human judges in Section 3, and its results in Section 4. We close this paper by critically discussing our results in Section 5. 2 Sentence Simplification Models 2.1 Word-Substitution Baseline The word substitution</context>
<context position="18689" citStr="Woodsend and Lapata (2011)" startWordPosition="3011" endWordPosition="3014">t of the cases the RevILP system does not alter the sentence. The other systems make this decision about as often as the gold standard, Simple Wikipedia, where only 3% of sentences remain unchanged. The word-substitution baseline always manages to make at least one change. 3 Evaluation 3.1 Participants Participants were 46 students of Tilburg University, who participated for partial course credits. All were native speakers of Dutch, and all were proficient in English, having taken a course on Academic English at University level. 3.2 Materials We use the test set used by Zhu et al. (2010) and Woodsend and Lapata (2011). This test set consists of 100 sentences from articles on English Wikipedia, paired with sentences from corresponding articles in English Simple Wikipedia. We selected only those sentences where every system would perform minimally one edit, because we only want to compare the different systems when they actually generate altered, assumedly simplified output. From this subset we randomly pick 20 source sentences, resulting in 20 clusters of one source sentence and 5 simplified sentences, as generated by humans (Simple Wikipedia) and the four systems. 1019 3.3 Procedure The participants were t</context>
</contexts>
<marker>Woodsend, Lapata, 2011</marker>
<rawString>Kristian Woodsend and Mirella Lapata. 2011. Learning to simplify sentences with quasi-synchronous grammar and integer programming. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 409–420, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sander Wubben</author>
<author>Antal van den Bosch</author>
<author>Emiel Krahmer</author>
</authors>
<title>Paraphrase generation as monolingual translation: data and evaluation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference, INLG ’10,</booktitle>
<pages>203--207</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Wubben, van den Bosch, Krahmer, 2010</marker>
<rawString>Sander Wubben, Antal van den Bosch, and Emiel Krahmer. 2010. Paraphrase generation as monolingual translation: data and evaluation. In Proceedings of the 6th International Natural Language Generation Conference, INLG ’10, pages 203–207, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, ACL ’01,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10552" citStr="Yamada and Knight, 2001" startWordPosition="1664" endWordPosition="1667"> is kept. If no relevant alternative is found, the word is left unchanged. We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags. The WordNet::QueryData2 Perl mod2http://search.cpan.org/dist/ WordNet-QueryData/QueryData.pm ule is used to query WordNet (Fellbaum, 1998). 2.2 Zhu et al. Zhu et al. (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion. Their model is inspired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. The four mentioned simplification operations together form the translation model. Their model is trained on a corpus containing aligned sentences from English Wikipedia and English Simple Wikipedia called PWKP. The PWKP dataset consists of 108,016 pairs of aligned lines from 65,133 Wikipedia and Simple Wikipedia articles. These articles were paired by following the “interlanguage link”3. TF*IDF at the sentence level was used to align the sentences in the different articles (Nelken and Shieber, 2006). Zhu et al. (2010) evalua</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntaxbased statistical translation model. In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, ACL ’01, pages 523–530, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Yatskar</author>
<author>Bo Pang</author>
<author>Cristian Danescu-NiculescuMizil</author>
<author>Lillian Lee</author>
</authors>
<title>For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL,</booktitle>
<pages>365--368</pages>
<contexts>
<context position="4701" citStr="Yatskar et al., 2010" startWordPosition="718" endWordPosition="721">glish Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. Another useful resource is the edit history of Simple Wikipedia, from which simplifications can be learned (Yatskar et al., 2010). Woodsend and Lapata (2011) investigate the use of Simple Wikipedia edit histories and an aligned Wikipedia– Simple Wikipedia corpus to induce a model based on quasi-synchronous grammar. They select the most appropriate simplification by using integer linear programming. We follow Zhu et al. (2010) and Coster and Kauchak (2011) in proposing that sentence simplification can be approached as a monolingual machine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning. We differ from the approach o</context>
</contexts>
<marker>Yatskar, Pang, Danescu-NiculescuMizil, Lee, 2010</marker>
<rawString>Mark Yatskar, Bo Pang, Cristian Danescu-NiculescuMizil, and Lillian Lee. 2010. For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia. In Proceedings of the NAACL, pages 365–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Application-driven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09,</booktitle>
<pages>834--842</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6657" citStr="Zhao et al., 2009" startWordPosition="1030" endWordPosition="1033">umbers suggest that, although the selection criteria for sentences to be included in this dataset are biased (see Section 2.2), Simple Wikipedia sentences are about 17% shorter, while the average word length is virtually equal. Sent. length Token length Simple Wikipedia 20.87 4.89 Wikipedia 25.01 5.06 Table 1: Sentence and token length statistics for the PWKP dataset (Zhu et al., 2010). Statistical machine translation (SMT) has already been successfully applied to the related task of paraphrasing (Quirk et al., 2004; Bannard and CallisonBurch, 2005; Madnani et al., 2007; Callison-Burch, 2008; Zhao et al., 2009; Wubben et al., 2010). SMT typically makes use of large parallel corpora to train a model on. These corpora need to be aligned at the sentence level. Large parallel corpora, such as the multilingual proceedings of the European Parliament (Europarl), are readily available for many languages. Phrase-Based Machine Translation (PBMT) is a form of SMT where the translation model aims to translate longer sequences of words (“phrases”) in one go, solving part of the word ordering problem along the way that would be left to the target language model in a word-based SMT system. PMBT operates purely on</context>
</contexts>
<marker>Zhao, Lan, Liu, Li, 2009</marker>
<rawString>Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven statistical paraphrase generation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09, pages 834–842, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhemin Zhu</author>
<author>Delphine Bernhard</author>
<author>Iryna Gurevych</author>
</authors>
<title>A monolingual tree-based translation model for sentence simplification.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>1353--1361</pages>
<location>Beijing, China,</location>
<contexts>
<context position="4038" citStr="Zhu et al. (2010)" startWordPosition="614" endWordPosition="617">d to reduce overall sentence length, splits long sentences on the basis of syntactic 1015 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1015–1024, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics information (Chandrasekar and Srinivas, 1997; Carroll et al., 1998; Canning et al., 2000; Vickrey and Koller, 2008). There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al., 2003). Zhu et al. (2010) examine the use of paired documents in English Wikipedia and Simple Wikipedia for a data-driven approach to the sentence simplification task. They propose a probabilistic, syntaxbased machine translation approach to the problem and compare against a baseline of no simplification and a phrase-based machine translation approach. In a similar vein, Coster and Kauchak (2011) use a parallel corpus of paired documents from Simple Wikipedia and Wikipedia to train a phrase-based machine translation model coupled with a deletion model. Another useful resource is the edit history of Simple Wikipedia, f</context>
<context position="5320" citStr="Zhu et al. (2010)" startWordPosition="820" endWordPosition="823">Woodsend and Lapata (2011) investigate the use of Simple Wikipedia edit histories and an aligned Wikipedia– Simple Wikipedia corpus to induce a model based on quasi-synchronous grammar. They select the most appropriate simplification by using integer linear programming. We follow Zhu et al. (2010) and Coster and Kauchak (2011) in proposing that sentence simplification can be approached as a monolingual machine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning. We differ from the approach of Zhu et al. (2010) in the sense that we do not take syntactic information into account; we rely on PBMT to do its work and implicitly learn simplifying paraphrasings of phrases. Our approach differs from Coster and Kauchak (2011) in the sense that instead of focusing on deletion in the PBMT decoding stage, we focus on dissimilarity, as simplification does not necessarily imply shortening (Woodsend and Lapata, 2011), or as the Simple Wikipedia guidelines state, “simpler does not mean short”1. Table 1.1 shows the average sentence length and the average 1http://simple.wikipedia.org/wiki/Main_ Page/Introduction wor</context>
<context position="8405" citStr="Zhu et al. (2010)" startWordPosition="1320" endWordPosition="1323">roducing an n-best list of candidate translations, ranked by the decoder score, a complex scoring function including likelihood scores from the translation model, and the target language model. In principle, all of this should be transportable to a data-driven machine translation account of sentence simplification, pro1016 vided that a parallel corpus is available that pairs text to simplified versions of that text. 1.2 This study In this work we aim to investigate the use of phrasebased machine translation modified with a dissimilarity component for the task of sentence simplification. While Zhu et al. (2010) have demonstrated that their approach outperforms a PBMT approach in terms of Flesch Reading Ease test scores, we are not aware of any studies that evaluate PBMT for sentence simplification with human judgements. In this study we evaluate the output of Zhu et al. (2010) (henceforth referred to as ‘Zhu’), Woodsend and Lapata (2011) (henceforth referred to as ‘RevILP’), our PBMT based system with dissimilarity-based re-ranking (henceforth referred to as ‘PBMT-R’), a word-substitution baseline, and, as a gold standard, the original Simple Wikipedia sentences. We will first discuss the baseline, </context>
<context position="10294" citStr="Zhu et al. (2010)" startWordPosition="1624" endWordPosition="1627">ts synset words, and each replacement is scored by a SRILM language model (Stolcke, 2002) with probabilities that are obtained from training on the Simple Wikipedia data. The alternative that has the highest probability according to the language model is kept. If no relevant alternative is found, the word is left unchanged. We use the Memory-Based Tagger (Daelemans et al., 1996) trained on the Brown corpus to compute the part-ofspeech tags. The WordNet::QueryData2 Perl mod2http://search.cpan.org/dist/ WordNet-QueryData/QueryData.pm ule is used to query WordNet (Fellbaum, 1998). 2.2 Zhu et al. Zhu et al. (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion. Their model is inspired by syntax-based SMT (Yamada and Knight, 2001) and consists of a language model, a translation model and a decoder. The four mentioned simplification operations together form the translation model. Their model is trained on a corpus containing aligned sentences from English Wikipedia and English Simple Wikipedia called PWKP. The PWKP dataset consists of 108,016 pairs of aligned lines f</context>
<context position="12560" citStr="Zhu et al. (2010)" startWordPosition="1969" endWordPosition="1972">select the most appropriate simplification. Their model is trained on two different datasets: one containing alignments between Wikipedia and English Simple Wikipedia (AlignILP), and one containing alignments between edits in the revision history of Simple Wikipedia (RevILP). RevILP performs best according to the 3http://en.wikipedia.org/wiki/Help: Interlanguage_links 1017 finds the most likely translation p(f|e) with a language model that outputs the most likely sentence p(e): e� = arg max p(f|e)p(e) eEe human judgements conducted in their study. They show that it achieves better scores than Zhu et al. (2010)’s system and is not scored significantly differently from English Simple Wikipedia. In this study we compare against their best performing system, the RevILP system. Flesch-Kincaid n-best 14 12 10 8 6 4 2 0 Figure 1: Levenshtein distance and Flesch-Kincaid score of output when varying the n of the n-best output of Moses. 2.4 PBMT-R We use the Moses software to train a PBMT model (Koehn et al., 2007). The data we use is the PWKP dataset created by Zhu et al. (2010). In general, a statistical machine translation model finds a best translation e� of a text in language f to a text in language e b</context>
<context position="18658" citStr="Zhu et al. (2010)" startWordPosition="3006" endWordPosition="3009">he input. In 22 percent of the cases the RevILP system does not alter the sentence. The other systems make this decision about as often as the gold standard, Simple Wikipedia, where only 3% of sentences remain unchanged. The word-substitution baseline always manages to make at least one change. 3 Evaluation 3.1 Participants Participants were 46 students of Tilburg University, who participated for partial course credits. All were native speakers of Dutch, and all were proficient in English, having taken a course on Academic English at University level. 3.2 Materials We use the test set used by Zhu et al. (2010) and Woodsend and Lapata (2011). This test set consists of 100 sentences from articles on English Wikipedia, paired with sentences from corresponding articles in English Simple Wikipedia. We selected only those sentences where every system would perform minimally one edit, because we only want to compare the different systems when they actually generate altered, assumedly simplified output. From this subset we randomly pick 20 source sentences, resulting in 20 clusters of one source sentence and 5 simplified sentences, as generated by humans (Simple Wikipedia) and the four systems. 1019 3.3 Pr</context>
</contexts>
<marker>Zhu, Bernhard, Gurevych, 2010</marker>
<rawString>Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1353–1361, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>