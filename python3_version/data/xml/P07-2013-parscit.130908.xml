<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000498">
<title confidence="0.690808">
An API for Measuring the Relatedness of Words in Wikipedia
Simone Paolo Ponzetto and Michael Strube
EML Research gGmbH
Schloss-Wolfsbrunnenweg 33
</title>
<address confidence="0.428391">
69118 Heidelberg, Germany
</address>
<email confidence="0.848724">
http://www.eml-research.de/nlp
</email>
<sectionHeader confidence="0.990474" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997463">
We present an API for computing the seman-
tic relatedness of words in Wikipedia.
</bodyText>
<sectionHeader confidence="0.999262" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962857142857">
The last years have seen a large amount of work in
Natural Language Processing (NLP) using measures
of semantic similarity and relatedness. We believe
that the extensive usage of such measures derives
also from the availability of robust and freely avail-
able software that allows to compute them (Pedersen
et al., 2004, WordNet::Similarity).
In Ponzetto &amp; Strube (2006) and Strube &amp;
Ponzetto (2006) we proposed to take the Wikipedia
categorization system as a semantic network which
served as basis for computing the semantic related-
ness of words. In the following we present the API
we used in our previous work, hoping that it will en-
courage further research in NLP using Wikipedia1.
</bodyText>
<sectionHeader confidence="0.891121" genericHeader="method">
2 Measures of Semantic Relatedness
</sectionHeader>
<bodyText confidence="0.99700675">
Approaches to measuring semantic relatedness that
use lexical resources transform these resources into
a network or graph and compute relatedness using
paths in it (see Budanitsky &amp; Hirst (2006) for an ex-
tensive review). For instance, Rada et al. (1989)
traverse MeSH, a term hierarchy for indexing ar-
ticles in Medline, and compute semantic related-
ness straightforwardly in terms of the number of
edges between terms in the hierarchy. Jarmasz &amp;
Szpakowicz (2003) use the same approach with Ro-
get’s Thesaurus while Hirst &amp; St-Onge (1998) apply
a similar strategy to WordNet.
</bodyText>
<footnote confidence="0.9647245">
1The software can be freely downloaded at http://www.
eml-research.de/nlp/download/wikipediasimilarity.php.
</footnote>
<page confidence="0.999476">
49
</page>
<sectionHeader confidence="0.993941" genericHeader="method">
3 The Application Programming Interface
</sectionHeader>
<bodyText confidence="0.693907">
The API computes semantic relatedness by:
</bodyText>
<listItem confidence="0.995583666666667">
1. taking a pair of words as input;
2. retrieving the Wikipedia articles they refer to
(via a disambiguation strategy based on the link
structure of the articles);
3. computing paths in the Wikipedia categoriza-
tion graph between the categories the articles are
assigned to;
4. returning as output the set of paths found,
scored according to some measure definition.
</listItem>
<bodyText confidence="0.9998735">
The implementation includes path-length (Rada
et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp;
Chodorow, 1998), information-content (Resnik,
1995; Seco et al., 2004) and text-overlap (Lesk,
1986; Banerjee &amp; Pedersen, 2003) measures, as de-
scribed in Strube &amp; Ponzetto (2006).
The API is built on top of several modules and can
be used for tasks other than Wikipedia-based relat-
edness computation. On a basic usage level, it can be
used to retrieve Wikipedia articles by name, option-
ally using disambiguation patterns, as well as to find
a ranked set of articles satisfying a search query (via
integration with the Lucene2 text search engine).
Additionally, it provides functionality for visualiz-
ing the computed paths along the Wikipedia cate-
gorization graph as either Java Swing components
or applets (see Figure 1), based on the JGraph li-
brary3, and methods for computing centrality scores
of the Wikipedia categories using the PageRank al-
gorithm (Brin &amp; Page, 1998). Finally, it currently
</bodyText>
<footnote confidence="0.9999585">
2http://lucene.apache.org
3http://www.jgraph.com
</footnote>
<subsubsectionHeader confidence="0.33884">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 49–52,
</subsubsectionHeader>
<bodyText confidence="0.959651421052632">
Prague, June 2007. c�2007 Association for Computational Linguistics
querying MediaWiki, parsing and structuring the
returned encyclopedia pages.
5. XML-RPC server: an intermediate communica-
tion layer between Java and the Perl routines.
6. Java wrapper library: provides a simple inter-
face to create and access the encyclopedia page
objects and compute the relatedness scores.
The information flow of the API is summarized by
the sequence diagram in Figure 2. The higher in-
put/output layer the user interacts with is provided
by a Java API from which Wikipedia can be queried.
The Java library is responsible for issuing HTTP re-
quests to an XML-RPC daemon which provides a
layer for calling Perl routines from the Java API.
Perl routines take care of the bulk of querying ency-
clopedia entries to the MediaWiki software (which
in turn queries the database) and efficiently parsing
the text responses into structured objects.
</bodyText>
<figureCaption confidence="0.912884">
Figure 1: Shortest path between computer and key- 5 Using the API
board in the English Wikipedia. The API provides factory classes for querying
provides multilingual support for the English, Ger- Wikipedia, in order to retrieve encyclopedia entries
man, French and Italian Wikipedias and can be eas- as well as relatedness scores for word pairs. In
ily extended to other languages4. practice, the Java library provides a simple pro-
</figureCaption>
<table confidence="0.938109608695652">
4 Software Architecture grammatic interface. Users can accordingly ac-
cess the library using only a few methods given
in the factory classes, e.g. getPage(word)
for retrieving Wikipedia articles titled word or
getRelatedness(word1,word2), for com-
puting the relatedness between word1 and word2,
and display(path) for displaying a path found
between two Wikipedia articles in the categorization
graph. Examples of programmatic usage of the API
are presented in Figure 3. In addition, the software
distribution includes UNIX shell scripts to access
the API interactively from a terminal, i.e. it does not
require any knowledge of Java.
6 Application scenarios
Semantic relatedness measures have proven use-
ful in many NLP applications such as word sense
disambiguation (Kohomban &amp; Lee, 2005; Patward-
han et al., 2005), information retrieval (Finkelstein
et al., 2002), information extraction pattern induc-
tion (Stevenson &amp; Greenwood, 2005), interpretation
of noun compounds (Kim &amp; Baldwin, 2005), para-
Wikipedia is freely available for download, and can
be accessed using robust Open Source applications,
</table>
<figureCaption confidence="0.939098666666667">
e.g. the MediaWiki software5, integrated within a
Linux, Apache, MySQL and PHP (LAMP) software
bundle. The architecture of the API consists of the
following modules:
1. RDBMS: at the lowest level, the encyclopedia
content is stored in a relational database manage-
ment system (e.g. MySQL).
2. MediaWiki: a suite of PHP routines for interact-
ing with the RDBMS.
3. WWW-Wikipedia Perl library6: responsible for
4In contrast to WordNet::Similarity, which due to the struc-
tural variations between the respective wordnets was reimple-
</figureCaption>
<figure confidence="0.739302">
mented for German by Gurevych &amp; Niederlich (2005).
5http://www.mediawiki.org
6http://search.cpan.org/dist/WWW-Wikipedia
50
</figure>
<figureCaption confidence="0.977576">
Figure 2: API processing sequence diagram. Wikipedia pages and relatedness measures are accessed
</figureCaption>
<bodyText confidence="0.932770333333333">
through a Java API. The wrapper communicates with a Perl library designed for Wikipedia access and pars-
ing through an XML-RPC server. WWW-Wikipedia in turn accesses the database where the encyclopedia
is stored by means of appropriate queries to MediaWiki.
</bodyText>
<page confidence="0.992897">
51
</page>
<figure confidence="0.968265692307692">
// 1. Get the English Wikipedia page titled &amp;quot;King&amp;quot; using &amp;quot;chess&amp;quot; as disambiguation
WikipediaPage page = WikipediaPageFactory.getInstance().getWikipediaPage(&amp;quot;King&amp;quot;,&amp;quot;chess&amp;quot;);
// 2. Get the German Wikipedia page titled &amp;quot;Ufer&amp;quot; using &amp;quot;Kueste&amp;quot; as disambiguation
WikipediaPage page = WikipediaPageFactory.getInstance().getWikipediaPage(&amp;quot;Ufer&amp;quot;,&amp;quot;Kueste&amp;quot;,Language.DE);
// 3a. Get the Wikipedia-based path-length relatedness measure between &amp;quot;computer&amp;quot; and &amp;quot;keyboard&amp;quot;
WikiRelatedness relatedness = WikiRelatednessFactory.getInstance().getWikiRelatedness(&amp;quot;computer&amp;quot;,&amp;quot;keyboard&amp;quot;);
double shortestPathMeasure = relatedness.getShortestPathMeasure();
// 3b. Display the shortest path
WikiPathDisplayer.getInstance().display(relatedness.getShortestPath());
// 4. Score the importance of the categories in the English Wikipedia using PageRank
WikiCategoryGraph&lt;DefaultScorableGraph&lt;DefaultEdge&gt;&gt; categoryTree =
WikiCategoryGraphFactory.getCategoryGraphForLanguage(Language.EN);
categoryTree.getCategoryGraph().score(new PageRank());
</figure>
<figureCaption confidence="0.999819">
Figure 3: Java API sample usage.
</figureCaption>
<bodyText confidence="0.999919647058824">
phrase detection (Mihalcea et al., 2006) and spelling
correction (Budanitsky &amp; Hirst, 2006). Our API
provides a flexible tool to include such measures
into existing NLP systems while using Wikipedia
as a knowledge source. Programmatic access to the
encyclopedia makes also available in a straightfor-
ward manner the large amount of structured text in
Wikipedia (e.g. for building a language model), as
well as its rich internal link structure (e.g. the links
between articles provide phrase clusters to be used
for query expansion scenarios).
Acknowledgements: This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The first author has been supported by a KTF
grant (09.003.2004). We thank our colleagues Katja
Filippova and Christoph M¨uller for helpful feed-
back.
</bodyText>
<sectionHeader confidence="0.942074" genericHeader="references">
References
</sectionHeader>
<tableCaption confidence="0.736877444444444">
Banerjee, S. &amp; T. Pedersen (2003). Extended gloss overlap as
a measure of semantic relatedness. In Proc. of IJCAI-03, pp.
805–810.
Brin, S. &amp; L. Page (1998). The anatomy of a large-scale hyper-
textual web search engine. Computer Networks and ISDN
Systems, 30(1–7):107–117.
Budanitsky, A. &amp; G. Hirst (2006). Evaluating WordNet-based
measures of semantic distance. Computational Linguistics,
32(1).
</tableCaption>
<reference confidence="0.996451762711864">
Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan,
G. Wolfman &amp; E. Ruppin (2002). Placing search in context:
The concept revisited. ACM Transactions on Information
Systems, 20(1):116–131.
Gurevych, I. &amp; H. Niederlich (2005). Accessing GermaNet data
and computing semantic relatedness. In Comp. Vol. to Proc.
of ACL-05, pp. 5–8.
Hirst, G. &amp; D. St-Onge (1998). Lexical chains as repre-
sentations of context for the detection and correction of
malapropisms. In C. Fellbaum (Ed.), WordNet: An Elec-
tronic Lexical Database, pp. 305–332. Cambridge, Mass.:
MIT Press.
Jarmasz, M. &amp; S. Szpakowicz (2003). Roget’s Thesaurus and
semantic similarity. In Proc. of RANLP-03, pp. 212–219.
Kim, S. N. &amp; T. Baldwin (2005). Automatic interpretation
of noun compounds using WordNet similarity. In Proc. of
IJCNLP-05, pp. 945–956.
Kohomban, U. S. &amp; W. S. Lee (2005). Learning semantic
classes for word sense disambiguation. In Proc. of ACL-05,
pp. 34–41.
Leacock, C. &amp; M. Chodorow (1998). Combining local con-
text and WordNet similarity for word sense identifica-
tion. In C. Fellbaum (Ed.), WordNet. An Electronic Lexical
Database, Chp. 11, pp. 265–283. Cambridge, Mass.: MIT
Press.
Lesk, M. (1986). Automatic sense disambiguation using ma-
chine readable dictionaries: How to tell a pine cone from an
ice cream cone. In Proceedings of the 5th Annual Confer-
ence on Systems Documentation, Toronto, Ontario, Canada,
pp. 24–26.
Mihalcea, R., C. Corley &amp; C. Strapparava (2006). Corpus-based
and knowledge-based measures of text semantic similarity.
In Proc. of AAAI-06, pp. 775–780.
Patwardhan, S., S. Banerjee &amp; T. Pedersen (2005). SenseRe-
late::TargetWord – A generalized framework for word sense
disambiguation. In Proc. of AAAI-05.
Pedersen, T., S. Patwardhan &amp; J. Michelizzi (2004). Word-
Net::Similarity – Measuring the relatedness of concepts. In
Comp. Vol. to Proc. of HLT-NAACL-04, pp. 267–270.
Ponzetto, S. P. &amp; M. Strube (2006). Exploiting semantic role
labeling, WordNet and Wikipedia for coreference resolution.
In Proc. of HLT-NAACL-06, pp. 192–199.
Rada, R., H. Mili, E. Bicknell &amp; M. Blettner (1989). Devel-
opment and application of a metric to semantic nets. IEEE
Transactions on Systems, Man and Cybernetics, 19(1):17–
30.
Resnik, P. (1995). Using information content to evaluate seman-
tic similarity in a taxonomy. In Proc. of IJCAI-95, Vol. 1, pp.
448–453.
Seco, N., T. Veale &amp; J. Hayes (2004). An intrinsic information
content metric for semantic similarity in WordNet. In Proc.
of ECAI-04, pp. 1089–1090.
Stevenson, M. &amp; M. Greenwood (2005). A semantic approach
to IE pattern induction. In Proc. of ACL-05, pp. 379–386.
Strube, M. &amp; S. P. Ponzetto (2006). WikiRelate! Computing
semantic relatedness using Wikipedia. In Proc. of AAAI-06,
pp. 1419–1424.
Wu, Z. &amp; M. Palmer (1994). Verb semantics and lexical selec-
tion. In Proc. of ACL-94, pp. 133–138.
</reference>
<page confidence="0.998859">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.815941">
<title confidence="0.997956">An API for Measuring the Relatedness of Words in Wikipedia</title>
<author confidence="0.999914">Simone Paolo Ponzetto</author>
<author confidence="0.999914">Michael Strube</author>
<affiliation confidence="0.988655">EML Research gGmbH</affiliation>
<address confidence="0.9720845">Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany</address>
<web confidence="0.905914">http://www.eml-research.de/nlp</web>
<abstract confidence="0.987556333333333">We present an API for computing the semantic relatedness of words in Wikipedia.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2002</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="5477" citStr="Finkelstein et al., 2002" startWordPosition="841" endWordPosition="844">, for computing the relatedness between word1 and word2, and display(path) for displaying a path found between two Wikipedia articles in the categorization graph. Examples of programmatic usage of the API are presented in Figure 3. In addition, the software distribution includes UNIX shell scripts to access the API interactively from a terminal, i.e. it does not require any knowledge of Java. 6 Application scenarios Semantic relatedness measures have proven useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraWikipedia is freely available for download, and can be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL). 2. MediaWiki: a suite of PHP routines for interacting with the RDBMS. 3. W</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman &amp; E. Ruppin (2002). Placing search in context: The concept revisited. ACM Transactions on Information Systems, 20(1):116–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Gurevych</author>
<author>H Niederlich</author>
</authors>
<title>Accessing GermaNet data and computing semantic relatedness.</title>
<date>2005</date>
<booktitle>In Comp. Vol. to Proc. of ACL-05,</booktitle>
<pages>5--8</pages>
<contexts>
<context position="6289" citStr="Gurevych &amp; Niederlich (2005)" startWordPosition="963" endWordPosition="966">n be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL). 2. MediaWiki: a suite of PHP routines for interacting with the RDBMS. 3. WWW-Wikipedia Perl library6: responsible for 4In contrast to WordNet::Similarity, which due to the structural variations between the respective wordnets was reimplemented for German by Gurevych &amp; Niederlich (2005). 5http://www.mediawiki.org 6http://search.cpan.org/dist/WWW-Wikipedia 50 Figure 2: API processing sequence diagram. Wikipedia pages and relatedness measures are accessed through a Java API. The wrapper communicates with a Perl library designed for Wikipedia access and parsing through an XML-RPC server. WWW-Wikipedia in turn accesses the database where the encyclopedia is stored by means of appropriate queries to MediaWiki. 51 // 1. Get the English Wikipedia page titled &amp;quot;King&amp;quot; using &amp;quot;chess&amp;quot; as disambiguation WikipediaPage page = WikipediaPageFactory.getInstance().getWikipediaPage(&amp;quot;King&amp;quot;,&amp;quot;chess</context>
</contexts>
<marker>Gurevych, Niederlich, 2005</marker>
<rawString>Gurevych, I. &amp; H. Niederlich (2005). Accessing GermaNet data and computing semantic relatedness. In Comp. Vol. to Proc. of ACL-05, pp. 5–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1998</date>
<booktitle>In C. Fellbaum (Ed.), WordNet: An Electronic Lexical Database,</booktitle>
<pages>305--332</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="1564" citStr="Hirst &amp; St-Onge (1998)" startWordPosition="241" endWordPosition="244">ncourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) for an extensive review). For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness straightforwardly in terms of the number of edges between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; St-Onge (1998) apply a similar strategy to WordNet. 1The software can be freely downloaded at http://www. eml-research.de/nlp/download/wikipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Hirst, G. &amp; D. St-Onge (1998). Lexical chains as representations of context for the detection and correction of malapropisms. In C. Fellbaum (Ed.), WordNet: An Electronic Lexical Database, pp. 305–332. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jarmasz</author>
<author>S Szpakowicz</author>
</authors>
<title>Roget’s Thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proc. of RANLP-03,</booktitle>
<pages>212--219</pages>
<contexts>
<context position="1490" citStr="Jarmasz &amp; Szpakowicz (2003)" startWordPosition="228" endWordPosition="231">ollowing we present the API we used in our previous work, hoping that it will encourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) for an extensive review). For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness straightforwardly in terms of the number of edges between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; St-Onge (1998) apply a similar strategy to WordNet. 1The software can be freely downloaded at http://www. eml-research.de/nlp/download/wikipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as outpu</context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>Jarmasz, M. &amp; S. Szpakowicz (2003). Roget’s Thesaurus and semantic similarity. In Proc. of RANLP-03, pp. 212–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using WordNet similarity.</title>
<date>2005</date>
<booktitle>In Proc. of IJCNLP-05,</booktitle>
<pages>945--956</pages>
<contexts>
<context position="5605" citStr="Kim &amp; Baldwin, 2005" startWordPosition="858" endWordPosition="861"> in the categorization graph. Examples of programmatic usage of the API are presented in Figure 3. In addition, the software distribution includes UNIX shell scripts to access the API interactively from a terminal, i.e. it does not require any knowledge of Java. 6 Application scenarios Semantic relatedness measures have proven useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraWikipedia is freely available for download, and can be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL). 2. MediaWiki: a suite of PHP routines for interacting with the RDBMS. 3. WWW-Wikipedia Perl library6: responsible for 4In contrast to WordNet::Similarity, which due to the structural variations between </context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>Kim, S. N. &amp; T. Baldwin (2005). Automatic interpretation of noun compounds using WordNet similarity. In Proc. of IJCNLP-05, pp. 945–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U S Kohomban</author>
<author>W S Lee</author>
</authors>
<title>Learning semantic classes for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proc. of ACL-05,</booktitle>
<pages>34--41</pages>
<contexts>
<context position="5401" citStr="Kohomban &amp; Lee, 2005" startWordPosition="830" endWordPosition="833">etrieving Wikipedia articles titled word or getRelatedness(word1,word2), for computing the relatedness between word1 and word2, and display(path) for displaying a path found between two Wikipedia articles in the categorization graph. Examples of programmatic usage of the API are presented in Figure 3. In addition, the software distribution includes UNIX shell scripts to access the API interactively from a terminal, i.e. it does not require any knowledge of Java. 6 Application scenarios Semantic relatedness measures have proven useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraWikipedia is freely available for download, and can be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL)</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Kohomban, U. S. &amp; W. S. Lee (2005). Learning semantic classes for word sense disambiguation. In Proc. of ACL-05, pp. 34–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification.</title>
<date>1998</date>
<booktitle>In C. Fellbaum (Ed.), WordNet. An Electronic Lexical Database, Chp.</booktitle>
<volume>11</volume>
<pages>265--283</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="2265" citStr="Leacock &amp; Chodorow, 1998" startWordPosition="344" endWordPosition="347"> at http://www. eml-research.de/nlp/download/wikipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality for visualizing the computed</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Leacock, C. &amp; M. Chodorow (1998). Combining local context and WordNet similarity for word sense identification. In C. Fellbaum (Ed.), WordNet. An Electronic Lexical Database, Chp. 11, pp. 265–283. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th Annual Conference on Systems Documentation,</booktitle>
<pages>24--26</pages>
<location>Toronto, Ontario, Canada,</location>
<contexts>
<context position="2349" citStr="Lesk, 1986" startWordPosition="357" endWordPosition="358">ing Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality for visualizing the computed paths along the Wikipedia categorization graph as either Java Swing components or a</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual Conference on Systems Documentation, Toronto, Ontario, Canada, pp. 24–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Corley</author>
<author>C Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI-06,</booktitle>
<pages>775--780</pages>
<contexts>
<context position="7806" citStr="Mihalcea et al., 2006" startWordPosition="1113" endWordPosition="1116">tedness relatedness = WikiRelatednessFactory.getInstance().getWikiRelatedness(&amp;quot;computer&amp;quot;,&amp;quot;keyboard&amp;quot;); double shortestPathMeasure = relatedness.getShortestPathMeasure(); // 3b. Display the shortest path WikiPathDisplayer.getInstance().display(relatedness.getShortestPath()); // 4. Score the importance of the categories in the English Wikipedia using PageRank WikiCategoryGraph&lt;DefaultScorableGraph&lt;DefaultEdge&gt;&gt; categoryTree = WikiCategoryGraphFactory.getCategoryGraphForLanguage(Language.EN); categoryTree.getCategoryGraph().score(new PageRank()); Figure 3: Java API sample usage. phrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Our API provides a flexible tool to include such measures into existing NLP systems while using Wikipedia as a knowledge source. Programmatic access to the encyclopedia makes also available in a straightforward manner the large amount of structured text in Wikipedia (e.g. for building a language model), as well as its rich internal link structure (e.g. the links between articles provide phrase clusters to be used for query expansion scenarios). Acknowledgements: This work has been funded by the Klaus Tschira Foundation, Heidelberg, Germany. </context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Mihalcea, R., C. Corley &amp; C. Strapparava (2006). Corpus-based and knowledge-based measures of text semantic similarity. In Proc. of AAAI-06, pp. 775–780.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Patwardhan</author>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>SenseRelate::TargetWord – A generalized framework for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proc. of AAAI-05.</booktitle>
<contexts>
<context position="5427" citStr="Patwardhan et al., 2005" startWordPosition="834" endWordPosition="838">ticles titled word or getRelatedness(word1,word2), for computing the relatedness between word1 and word2, and display(path) for displaying a path found between two Wikipedia articles in the categorization graph. Examples of programmatic usage of the API are presented in Figure 3. In addition, the software distribution includes UNIX shell scripts to access the API interactively from a terminal, i.e. it does not require any knowledge of Java. 6 Application scenarios Semantic relatedness measures have proven useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraWikipedia is freely available for download, and can be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL). 2. MediaWiki: a suite of</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2005</marker>
<rawString>Patwardhan, S., S. Banerjee &amp; T. Pedersen (2005). SenseRelate::TargetWord – A generalized framework for word sense disambiguation. In Proc. of AAAI-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet::Similarity – Measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Comp. Vol. to Proc. of HLT-NAACL-04,</booktitle>
<pages>267--270</pages>
<contexts>
<context position="625" citStr="Pedersen et al., 2004" startWordPosition="90" endWordPosition="93">PI for Measuring the Relatedness of Words in Wikipedia Simone Paolo Ponzetto and Michael Strube EML Research gGmbH Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany http://www.eml-research.de/nlp Abstract We present an API for computing the semantic relatedness of words in Wikipedia. 1 Introduction The last years have seen a large amount of work in Natural Language Processing (NLP) using measures of semantic similarity and relatedness. We believe that the extensive usage of such measures derives also from the availability of robust and freely available software that allows to compute them (Pedersen et al., 2004, WordNet::Similarity). In Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) we proposed to take the Wikipedia categorization system as a semantic network which served as basis for computing the semantic relatedness of words. In the following we present the API we used in our previous work, hoping that it will encourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) fo</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., S. Patwardhan &amp; J. Michelizzi (2004). WordNet::Similarity – Measuring the relatedness of concepts. In Comp. Vol. to Proc. of HLT-NAACL-04, pp. 267–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P Ponzetto</author>
<author>M Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL-06,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="676" citStr="Ponzetto &amp; Strube (2006)" startWordPosition="96" endWordPosition="99">ipedia Simone Paolo Ponzetto and Michael Strube EML Research gGmbH Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany http://www.eml-research.de/nlp Abstract We present an API for computing the semantic relatedness of words in Wikipedia. 1 Introduction The last years have seen a large amount of work in Natural Language Processing (NLP) using measures of semantic similarity and relatedness. We believe that the extensive usage of such measures derives also from the availability of robust and freely available software that allows to compute them (Pedersen et al., 2004, WordNet::Similarity). In Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) we proposed to take the Wikipedia categorization system as a semantic network which served as basis for computing the semantic relatedness of words. In the following we present the API we used in our previous work, hoping that it will encourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) for an extensive review). For instance, Rada et al. (</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Ponzetto, S. P. &amp; M. Strube (2006). Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Proc. of HLT-NAACL-06, pp. 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rada</author>
<author>H Mili</author>
<author>E Bicknell</author>
<author>M Blettner</author>
</authors>
<title>Development and application of a metric to semantic nets.</title>
<date>1989</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>30</pages>
<contexts>
<context position="1281" citStr="Rada et al. (1989)" startWordPosition="195" endWordPosition="198">Strube (2006) and Strube &amp; Ponzetto (2006) we proposed to take the Wikipedia categorization system as a semantic network which served as basis for computing the semantic relatedness of words. In the following we present the API we used in our previous work, hoping that it will encourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) for an extensive review). For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness straightforwardly in terms of the number of edges between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; St-Onge (1998) apply a similar strategy to WordNet. 1The software can be freely downloaded at http://www. eml-research.de/nlp/download/wikipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to</context>
</contexts>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Rada, R., H. Mili, E. Bicknell &amp; M. Blettner (1989). Development and application of a metric to semantic nets. IEEE Transactions on Systems, Man and Cybernetics, 19(1):17– 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proc. of IJCAI-95,</booktitle>
<volume>1</volume>
<pages>448--453</pages>
<contexts>
<context position="2300" citStr="Resnik, 1995" startWordPosition="349" endWordPosition="350">ipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality for visualizing the computed paths along the Wikipedia categori</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy. In Proc. of IJCAI-95, Vol. 1, pp. 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Seco</author>
<author>T Veale</author>
<author>J Hayes</author>
</authors>
<title>An intrinsic information content metric for semantic similarity in WordNet.</title>
<date>2004</date>
<booktitle>In Proc. of ECAI-04,</booktitle>
<pages>1089--1090</pages>
<contexts>
<context position="2320" citStr="Seco et al., 2004" startWordPosition="351" endWordPosition="354">ty.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality for visualizing the computed paths along the Wikipedia categorization graph as eith</context>
</contexts>
<marker>Seco, Veale, Hayes, 2004</marker>
<rawString>Seco, N., T. Veale &amp; J. Hayes (2004). An intrinsic information content metric for semantic similarity in WordNet. In Proc. of ECAI-04, pp. 1089–1090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>M Greenwood</author>
</authors>
<title>A semantic approach to IE pattern induction.</title>
<date>2005</date>
<booktitle>In Proc. of ACL-05,</booktitle>
<pages>379--386</pages>
<contexts>
<context position="5549" citStr="Stevenson &amp; Greenwood, 2005" startWordPosition="850" endWordPosition="853">path) for displaying a path found between two Wikipedia articles in the categorization graph. Examples of programmatic usage of the API are presented in Figure 3. In addition, the software distribution includes UNIX shell scripts to access the API interactively from a terminal, i.e. it does not require any knowledge of Java. 6 Application scenarios Semantic relatedness measures have proven useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraWikipedia is freely available for download, and can be accessed using robust Open Source applications, e.g. the MediaWiki software5, integrated within a Linux, Apache, MySQL and PHP (LAMP) software bundle. The architecture of the API consists of the following modules: 1. RDBMS: at the lowest level, the encyclopedia content is stored in a relational database management system (e.g. MySQL). 2. MediaWiki: a suite of PHP routines for interacting with the RDBMS. 3. WWW-Wikipedia Perl library6: responsible for 4In contrast to WordNet::Sim</context>
</contexts>
<marker>Stevenson, Greenwood, 2005</marker>
<rawString>Stevenson, M. &amp; M. Greenwood (2005). A semantic approach to IE pattern induction. In Proc. of ACL-05, pp. 379–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S P Ponzetto</author>
</authors>
<title>WikiRelate! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI-06,</booktitle>
<pages>1419--1424</pages>
<contexts>
<context position="705" citStr="Strube &amp; Ponzetto (2006)" startWordPosition="101" endWordPosition="104">and Michael Strube EML Research gGmbH Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany http://www.eml-research.de/nlp Abstract We present an API for computing the semantic relatedness of words in Wikipedia. 1 Introduction The last years have seen a large amount of work in Natural Language Processing (NLP) using measures of semantic similarity and relatedness. We believe that the extensive usage of such measures derives also from the availability of robust and freely available software that allows to compute them (Pedersen et al., 2004, WordNet::Similarity). In Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) we proposed to take the Wikipedia categorization system as a semantic network which served as basis for computing the semantic relatedness of words. In the following we present the API we used in our previous work, hoping that it will encourage further research in NLP using Wikipedia1. 2 Measures of Semantic Relatedness Approaches to measuring semantic relatedness that use lexical resources transform these resources into a network or graph and compute relatedness using paths in it (see Budanitsky &amp; Hirst (2006) for an extensive review). For instance, Rada et al. (1989) traverse MeSH, a term h</context>
<context position="2428" citStr="Strube &amp; Ponzetto (2006)" startWordPosition="368" endWordPosition="371"> a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality for visualizing the computed paths along the Wikipedia categorization graph as either Java Swing components or applets (see Figure 1), based on the JGraph library3, and methods for computing </context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M. &amp; S. P. Ponzetto (2006). WikiRelate! Computing semantic relatedness using Wikipedia. In Proc. of AAAI-06, pp. 1419–1424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proc. of ACL-94,</booktitle>
<pages>133--138</pages>
<contexts>
<context position="2238" citStr="Wu &amp; Palmer, 1994" startWordPosition="340" endWordPosition="343">e freely downloaded at http://www. eml-research.de/nlp/download/wikipediasimilarity.php. 49 3 The Application Programming Interface The API computes semantic relatedness by: 1. taking a pair of words as input; 2. retrieving the Wikipedia articles they refer to (via a disambiguation strategy based on the link structure of the articles); 3. computing paths in the Wikipedia categorization graph between the categories the articles are assigned to; 4. returning as output the set of paths found, scored according to some measure definition. The implementation includes path-length (Rada et al., 1989; Wu &amp; Palmer, 1994; Leacock &amp; Chodorow, 1998), information-content (Resnik, 1995; Seco et al., 2004) and text-overlap (Lesk, 1986; Banerjee &amp; Pedersen, 2003) measures, as described in Strube &amp; Ponzetto (2006). The API is built on top of several modules and can be used for tasks other than Wikipedia-based relatedness computation. On a basic usage level, it can be used to retrieve Wikipedia articles by name, optionally using disambiguation patterns, as well as to find a ranked set of articles satisfying a search query (via integration with the Lucene2 text search engine). Additionally, it provides functionality f</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Z. &amp; M. Palmer (1994). Verb semantics and lexical selection. In Proc. of ACL-94, pp. 133–138.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>