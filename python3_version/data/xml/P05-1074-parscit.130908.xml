<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018525">
<title confidence="0.994993">
Paraphrasing with Bilingual Parallel Corpora
</title>
<author confidence="0.998374">
Colin Bannard Chris Callison-Burch
</author>
<affiliation confidence="0.998922">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.784469">
2 Buccleuch Place
Edinburgh, EH8 9LW
</address>
<email confidence="0.996292">
{c.j.bannard, callison-burch}@ed.ac.uk
</email>
<sectionHeader confidence="0.997357" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986855">
Previous work has used monolingual par-
allel corpora to extract and generate para-
phrases. We show that this task can be
done using bilingual parallel corpora, a
much more commonly available resource.
Using alignment techniques from phrase-
based statistical machine translation, we
show how paraphrases in one language
can be identified using a phrase in another
language as a pivot. We define a para-
phrase probability that allows paraphrases
extracted from a bilingual parallel corpus
to be ranked using translation probabili-
ties, and show how it can be refined to
take contextual information into account.
We evaluate our paraphrase extraction and
ranking methods using a set of manual
word alignments, and contrast the qual-
ity with paraphrases extracted from auto-
matic alignments.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999899553191489">
Paraphrases are alternative ways of conveying the
same information. Paraphrases are useful in a num-
ber of NLP applications. In natural language gen-
eration the production of paraphrases allows for the
creation of more varied and fluent text (Iordanskaja
et al., 1991). In multidocument summarization the
identification of paraphrases allows information re-
peated across documents to be condensed (McKe-
own et al., 2002). In the automatic evaluation of
machine translation, paraphrases may help to alle-
viate problems presented by the fact that there are
often alternative and equally valid ways of translat-
ing a text (Pang et al., 2003). In question answering,
discovering paraphrased answers may provide addi-
tional evidence that an answer is correct (Ibrahim et
al., 2003).
In this paper we introduce a novel method for ex-
tracting paraphrases that uses bilingual parallel cor-
pora. Past work (Barzilay and McKeown, 2001;
Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et
al., 2003) has examined the use of monolingual par-
allel corpora for paraphrase extraction. Examples
of monolingual parallel corpora that have been used
are multiple translations of classical French novels
into English, and data created for machine transla-
tion evaluation methods such as Bleu (Papineni et
al., 2002) which use multiple reference translations.
While the results reported for these methods are
impressive, their usefulness is limited by the scarcity
of monolingual parallel corpora. Small data sets
mean a limited number of paraphrases can be ex-
tracted. Furthermore, the narrow range of text gen-
res available for monolingual parallel corpora limits
the range of contexts in which the paraphrases can
be used.
Instead of relying on scarce monolingual parallel
data, our method utilizes the abundance of bilingual
parallel data that is available. This allows us to cre-
ate a much larger inventory of phrases that is appli-
cable to a wider range of texts.
Our method for identifying paraphrases is an
extension of recent work in phrase-based statisti-
cal machine translation (Koehn et al., 2003). The
essence of our method is to align phrases in a bilin-
gual parallel corpus, and equate different English
phrases that are aligned with the same phrase in the
other language. This assumption of similar mean-
</bodyText>
<page confidence="0.961797">
597
</page>
<note confidence="0.991572">
Proceedings of the 43rd Annual Meeting of the ACL, pages 597–604,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.9906736">
Emma burst into tears and he tried to comfort
her, saying things to make her smile.
Emma cried, and he tried to console her, adorn-
ing his words with puns.
Figure 1: Using a monolingal parallel corpus to ex-
tract paraphrases
ing when multiple phrases map onto a single for-
eign language phrase is the converse of the assump-
tion made in the word sense disambiguation work of
Diab and Resnik (2002) which posits different word
senses when a single English word maps onto differ-
ent words in the foreign language (we return to this
point in Section 4.4).
The remainder of this paper is as follows: Section
2 contrasts our method for extracting paraphrases
with the monolingual case, and describes how we
rank the extracted paraphrases with a probability
assignment. Section 3 describes our experimental
setup and includes information about how phrases
were selected, how we manually aligned parts of the
bilingual corpus, and how we evaluated the para-
phrases. Section 4 gives the results of our evalua-
tion and gives a number of example paraphrases ex-
tracted with our technique. Section 5 reviews related
work, and Section 6 discusses future directions.
</bodyText>
<sectionHeader confidence="0.873231" genericHeader="method">
2 Extracting paraphrases
</sectionHeader>
<bodyText confidence="0.999973545454545">
Much previous work on extracting paraphrases
(Barzilay and McKeown, 2001; Barzilay and Lee,
2003; Pang et al., 2003) has focused on finding iden-
tifying contexts within aligned monolingual sen-
tences from which divergent text can be extracted,
and treated as paraphrases. Barzilay and McKeown
(2001) gives the example shown in Figure 1 of how
identical surrounding substrings can be used to ex-
tract the paraphrases of burst into tears as cried and
comfort as console.
While monolingual parallel corpora often have
identical contexts that can be used for identifying
paraphrases, bilingual parallel corpora do not. In-
stead, we use phrases in the other language as piv-
ots: we look at what foreign language phrases the
English translates to, find all occurrences of those
foreign phrases, and then look back at what other
English phrases they translate to. We treat the other
English phrases as potential paraphrases. Figure 2 il-
lustrates how a German phrase can be used as a point
of identification for English paraphrases in this way.
Section 2.1 explains which statistical machine trans-
lation techniques are used to align phrases within
sentence pairs in a bilingual corpus.
A significant difference between the present work
and that employing monolingual parallel corpora, is
that our method frequently extracts more than one
possible paraphrase for each phrase. We assign a
probability to each of the possible paraphrases. This
is a mechanism for ranking paraphrases, which can
be utilized when we come to select the correct para-
phrase for a given context. Section 2.2 explains how
we calculate the probability of a paraphrase.
</bodyText>
<subsectionHeader confidence="0.998878">
2.1 Aligning phrase pairs
</subsectionHeader>
<bodyText confidence="0.999622727272727">
We use phrase alignments in a parallel corpus as
pivots between English paraphrases. We find these
alignments using recent phrase-based approaches to
statistical machine translation.
The original formulation of statistical machine
translation (Brown et al., 1993) was defined as a
word-based operation. The probability that a foreign
sentence is the translation of an English sentence is
calculated by summing over the probabilities of all
possible word-level alignments, a, between the sen-
tences:
</bodyText>
<equation confidence="0.956574">
p(f|e) � � p(f, ale)
a
</equation>
<bodyText confidence="0.999755625">
Thus Brown et al. decompose the problem of de-
termining whether a sentence is a good translation
of another into the problem of determining whether
there is a sensible mapping between the words in the
sentences.
More recent approaches to statistical translation
calculate the translation probability using larger
blocks of aligned text. Koehn (2004), Tillmann
(2003), and Vogel et al. (2003) describe various
heuristics for extracting phrase alignments from the
Viterbi word-level alignments that are estimated us-
ing Brown et al. (1993) models. We use the heuris-
tic for phrase alignment described in Och and Ney
(2003) which aligns phrases by incrementally build-
ing longer phrases from words and phrases which
have adjacent alignment points.1
</bodyText>
<footnote confidence="0.974313">
1Note that while we induce the translations of phrases from
</footnote>
<page confidence="0.990989">
598
</page>
<figureCaption confidence="0.978537">
Figure 2: Using a bilingual parallel corpus to extract paraphrases
</figureCaption>
<bodyText confidence="0.883714428571429">
zu haben
what is more, the relevant cost dynamic is completely under control
im Ÿbrigen ist die diesbezŸgliche kostenentwicklung völlig unter kontrolle
wir sind es den steuerzahlern schuldig die kosten
unter kontrolle
in check
we owe it to the taxpayers to keep the costs
</bodyText>
<subsectionHeader confidence="0.999896">
2.2 Assigning probabilities
</subsectionHeader>
<bodyText confidence="0.999978428571429">
We define a paraphrase probability p(e2|e1) in terms
of the translation model probabilities p(f|e1), that
the original English phrase e1 translates as a partic-
ular phrase f in the other language, and p(e2|f), that
the candidate paraphrase e2 translates as the foreign
language phrase. Since e1 can translate as multiple
foreign language phrases, we sum over f:
</bodyText>
<equation confidence="0.97068175">
e2 = arg max p(e2|e1) (1)
e2�e1
E p(f|e1)p(e2|f) (2)
f
</equation>
<bodyText confidence="0.999976333333333">
The translation model probabilities can be com-
puted using any standard formulation from phrase-
based machine translation. For example, p(e|f)
can be calculated straightforwardly using maximum
likelihood estimation by counting how often the
phrases e and f were aligned in the parallel corpus:
</bodyText>
<equation confidence="0.985834">
� (3)
e count(e, f)
</equation>
<bodyText confidence="0.984400285714286">
Note that the paraphrase probability defined in
Equation 2 returns the single best paraphrase, e2, ir-
respective of the context in which e1 appears. Since
the best paraphrase may vary depending on informa-
tion about the sentence that e1 appears in, we extend
the paraphrase probability to include that sentence
S:
</bodyText>
<equation confidence="0.981032">
e2 = arg max p(e2|e1, S) (4)
e2=,4e1
</equation>
<bodyText confidence="0.9978595">
word-level alignments in this paper, direct estimation of phrasal
translations (Marcu and Wong, 2002) would also suffice for ex-
tracting paraphrases from bilingual corpora.
a million, as far as possible, at work, big business,
carbon dioxide, central america, close to, concen-
trate on, crystal clear, do justice to, driving force,
first half, for the first time, global warming, great
care, green light, hard core, horn of africa, last re-
sort, long ago, long run, military action, military
force, moment of truth, new world, noise pollution,
not to mention, nuclear power, on average, only too,
other than, pick up, president clinton, public trans-
port, quest for, red cross, red tape, socialist party,
sooner or later, step up, task force, turn to, under
control, vocational training, western sahara, world
bank
</bodyText>
<tableCaption confidence="0.99527">
Table 1: Phrases that were selected to paraphrase
</tableCaption>
<bodyText confidence="0.999909166666667">
S allows us to re-rank the candidate paraphrases
based on additional contextual information. The ex-
periments in this paper employ one variety of con-
textual information. We include a simple language
model probability, which would additionally rank
e2 based on the probability of the sentence formed
by substiuting e2 for e1 in S. A possible extension
which we do not evaluate might be permitting only
paraphrases that are the same syntactic type as the
original phrase, which we could do by extending the
translation model probabilities to count only phrase
occurrences of that type.
</bodyText>
<sectionHeader confidence="0.998508" genericHeader="method">
3 Experimental Design
</sectionHeader>
<bodyText confidence="0.9995478">
We extracted 46 English phrases to paraphrase
(shown in Table 1), randomly selected from those
multi-word phrases in WordNet which also occured
multiple times in the first 50,000 sentences of our
bilingual corpus. The bilingual corpus that we used
</bodyText>
<equation confidence="0.97443075">
= arg max
e2=,4e1
count(e, f)
p(e|f) =
</equation>
<page confidence="0.990479">
599
</page>
<figure confidence="0.99954248076923">
die
diesbezügliche
völlig
übrigen
kostenentwickl...
unter
kontrolle
im
ist
.
what
Alignment Tool
is
more
,
the
relevant
cost
dynamic
is
completely
under
control
.
wir
den
die
zu
sind
es
steuerzahlern
schuldig
kosten
unter
kontrolle
haben
we
Alignment Tool
owe
it
to
the
taxpayers
to
keep
the
costs
in
check
.
(a) Aligning the English phrase to be paraphrased
(b) Aligning occurrences of its German translation
</figure>
<figureCaption confidence="0.999902">
Figure 3: Phrases highlighted for manual alignment
</figureCaption>
<bodyText confidence="0.9997755">
was the German-English section of the Europarl cor-
pus, version 2 (Koehn, 2002). We produced auto-
matic alignments for it with the Giza++ toolkit (Och
and Ney, 2003). Because we wanted to test our
method independently of the quality of word align-
ment algorithms, we also developed a gold standard
of word alignments for the set of phrases that we
wanted to paraphrase.
</bodyText>
<subsectionHeader confidence="0.997581">
3.1 Manual alignment
</subsectionHeader>
<bodyText confidence="0.999957333333333">
The gold standard alignments were created by high-
lighting all occurrences of the English phrase to
paraphrase and manually aligning it with its Ger-
man equivalent by correcting the automatic align-
ment, as shown in Figure 3a. All occurrences of
its German equivalents were then highlighted, and
aligned with their English translations (Figure 3b).
The other words in the sentences were left with their
automatic alignments.
</bodyText>
<subsectionHeader confidence="0.999362">
3.2 Paraphrase evaluation
</subsectionHeader>
<bodyText confidence="0.999985666666667">
We evaluated the accuracy of each of the para-
phrases that was extracted from the manually
aligned data, as well as the top ranked paraphrases
from the experimental conditions detailed below in
Section 3.3. Because the acccuracy of paraphrases
can vary depending on context, we substituted each
</bodyText>
<subsectionHeader confidence="0.582611">
Under control
</subsectionHeader>
<bodyText confidence="0.999921333333333">
This situation is in check in terms of security.
This situation is checked in terms of security.
This situation is curbed in terms of security.
This situation is curb in terms of security.
This situation is limit in terms of security.
This situation is slow down in terms of security.
</bodyText>
<figureCaption confidence="0.69156">
Figure 4: Paraphrases substituted in for the original
phrase
</figureCaption>
<bodyText confidence="0.99985275">
set of candidate paraphrases into between 2–10 sen-
tences which contained the original phrase. Figure 4
shows the paraphrases for under control substituted
into one of the sentences in which it occurred. We
created a total of 289 such evaluation sets, with a
total of 1366 unique sentences created through sub-
stitution.
We had two native English speakers produce
judgments as to whether the new sentences pre-
served the meaning of the original phrase and as to
whether they remained grammatical. Paraphrases
that were judged to preserve both meaning and
grammaticality were considered to be correct, and
examples which failed on either judgment were con-
sidered to be incorrect.
In Figure 4 in check, checked, and curbed were
</bodyText>
<page confidence="0.992923">
600
</page>
<bodyText confidence="0.997831588235294">
under control checked, curb, curbed, in check, limit, slow down
sooner or later at some point, eventually
military force armed forces, defence, force, forces, military forces, peace-keeping personnel
long ago a little time ago, a long time, a long time ago, a lot of time, a while ago, a while back,
far, for a long time, for some time, for such a long time, long, long period of time, long
term, long time, long while, overdue, some time, some time ago
green light approval, call, go-ahead, indication, message, sign, signal, signals, formal go-ahead
great care a careful approach, greater emphasis, particular attention, special attention, specific
attention, very careful
first half first six months
crystal clear absolutely clear, all clarity, clear, clearly, in great detail, no mistake, no uncertain,
obvious, obviously, particularly clear, perfectly clear, quite clear, quite clearly, quite
explicitly, quite openly, very clear, very clear and comprehensive, very clearly, very
sure, very unclear, very well
carbon dioxide co2
at work at the workplace, employment, held, holding, in the work sphere, operate, organised,
taken place, took place, working
</bodyText>
<tableCaption confidence="0.977562">
Table 2: Paraphrases extracted from a manually word-aligned parallel corpus
</tableCaption>
<bodyText confidence="0.999342">
judged to be correct and curb, limit and slow down
were judged to be incorrect. The inter-annotator
agreement for these judgements was measured at
r. = 0.605, which is conventionally interpreted as
“good” agreement.
</bodyText>
<subsectionHeader confidence="0.954254">
3.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999297333333333">
We evaluated the accuracy of top ranked paraphrases
when the paraphrase probability was calculated us-
ing:
</bodyText>
<listItem confidence="0.996337625">
1. The manual alignments,
2. The automatic alignments,
3. Automatic alignments produced over multiple
corpora in different languages,
4. All of the above with language model re-
ranking.
5. All of the above with the candidate paraphrases
limited to the same sense as the original phrase.
</listItem>
<sectionHeader confidence="0.9999" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.9999668">
We report the percentage of correct translations (ac-
curacy) for each of these experimental conditions. A
summary of these can be seen in Table 3. This sec-
tion will describe each of the set-ups and the score
reported in more detail.
</bodyText>
<subsectionHeader confidence="0.997003">
4.1 Manual alignments
</subsectionHeader>
<bodyText confidence="0.9999715">
Table 2 gives a set of example paraphrases extracted
from the gold standard alignments. The italicized
paraphrases are those that were assigned the highest
probability by Equation 2, which chooses a single
best paraphrase without regard for context. The 289
sentences created by substituting the italicized para-
phrases in for the original phrase were judged to be
correct an average of 74.9% of the time.
Ignoring the constraint that the new sentences re-
main grammatically correct, these paraphrases were
judged to have the correct meaning 84.7% of the
time. This suggests that the context plays a more
important role with respect to the grammaticality
of substituted paraphrases than with respect to their
meaning.
In order to allow the surrounding words in the sen-
tence to have an influence on which paraphrase was
selected, we re-ranked the paraphrase probabilities
based on a trigram language model trained on the
entire English portion of the Europarl corpus. Para-
phrases were selected from among all those in Table
2, and not constrained to the italicized phrases. In
the case of the paraphrases extracted from the man-
ual word alignments, the language model re-ranking
had virtually no influence, and resulted in a slight
dip in accuracy to 71.7%
</bodyText>
<page confidence="0.99702">
601
</page>
<table confidence="0.9998038">
Paraphrase Prob Paraphrase Prob &amp; LM Correct Meaning
Manual Alignments 74.9 71.7 84.7
Automatic Alignments 48.9 55.3 64.5
Using Multiple Corpora 55.0 57.4 65.4
Word Sense Controlled 57.0 61.9 70.4
</table>
<tableCaption confidence="0.999758">
Table 3: Paraphrase accuracy and correct meaning for the different data conditions
</tableCaption>
<subsectionHeader confidence="0.995335">
4.2 Automatic alignments
</subsectionHeader>
<bodyText confidence="0.999992913043478">
In this experimental condition paraphrases were ex-
tracted from a set of automatic alignments produced
by running Giza++ over a set of 1,036,000 German-
English sentence pairs (roughly 28,000,000 words in
each language). When the single best paraphrase (ir-
respective of context) was used in place of the orig-
inal phrase in the evaluation sentence the accuracy
reached 48.9% which is quite low compared to the
74.9% of the manually aligned set.
As with the manual alignments it seems that we
are selecting phrases which have the correct mean-
ing but are not grammatical in context. Indeed our
judges thought the meaning of the paraphrases to
be correct in 64.5% of cases. Using a language
model to select the best paraphrase given the con-
text reduces the number of ungrammatical examples
and gives an improvement in quality from 48.9% to
55.3% correct.
These results suggest two things: that improving
the quality of automatic alignments would lead to
more accurate paraphrases, and that there is room
for improvement in limiting the paraphrases by their
context. We address these points below.
</bodyText>
<subsectionHeader confidence="0.999897">
4.3 Using multiple corpora
</subsectionHeader>
<bodyText confidence="0.999762333333333">
Work in statistical machine translation suggests that,
like many other machine learning problems, perfor-
mance increases as the amount of training data in-
creases. Och and Ney (2003) show that the accuracy
of alignments produced by Giza++ improve as the
size of the training corpus increases.
Since we used the whole of the German-English
section of the Europarl corpus, we could not try
improving the alignments by simply adding more
German-English training data. However, there is
nothing that limits our paraphrase extraction method
to drawing on candidate paraphrases from a sin-
gle target language. We therefore re-formulated the
paraphrase probability to include multiple corpora,
as follows:
</bodyText>
<equation confidence="0.977547666666667">
� �
�e2 = arg max p(f|e1)p(e2|f) (5)
e2=,4e1 C f in C
</equation>
<bodyText confidence="0.9983871">
where C is a parallel corpus from a set of parallel
corpora.
For this condition we used Giza++ to align
the French-English, Spanish-English, and Italian-
English portions of the Europarl corpus in addition
to the German-English portion, for a total of around
4,000,000 sentence pairs in the training data.
The accuracy of paraphrases extracted over mul-
tiple corpora increased to 55%, and further to 57.4%
when the language model re-ranking was included.
</bodyText>
<subsectionHeader confidence="0.994915">
4.4 Controlling for word sense
</subsectionHeader>
<bodyText confidence="0.999993863636363">
As mentioned in Section 1, the way that we extract
paraphrases is the converse of the methodology em-
ployed in word sense disambiguation work that uses
parallel corpora (Diab and Resnik, 2002). The as-
sumption made in the word sense disambiguation
work is that if a source language word aligns with
different target language words then those words
may represent different word senses. This can be
observed in the paraphrases for at work in Table 2.
The paraphrases at the workplace, employment, and
in the work sphere are a different sense of the phrase
than operate, held, and holding, and they are aligned
with different German phrases.
When we calculate the paraphrase probability we
sum over different target language phrases. There-
fore the English phrases that are aligned with the dif-
ferent German phrases (which themselves maybe in-
dicative of different word senses) are mingled. Per-
formance may be degraded since paraphrases that
reflect different senses of the original phrase, and
which therefore have a different meaning, are in-
cluded in the same candidate set.
</bodyText>
<page confidence="0.996726">
602
</page>
<bodyText confidence="0.9995287">
We therefore performed an experiment to see
whether improvement could be had by limiting the
candidate paraphrases to be the same sense as the
original phrase in each test sentence. To do this,
we used the fact that our test sentences were drawn
from a parallel corpus. We limited phrases to the
same word sense by constraining the candidate para-
phrases to those that aligned with the same target
language phrase. Our basic paraphrase calculation
was therefore:
</bodyText>
<equation confidence="0.999731">
p(e2|e1,f) = p(f|e1)p(e2|f) (6)
</equation>
<bodyText confidence="0.9999393">
Using the foreign language phrase to identify the
word sense is obviously not applicable in monolin-
gual settings, but acts as a convenient stand-in for a
proper word sense disambiguation algorithm here.
When word sense is controlled in this way, the
accuracy of the paraphrases extracted from the au-
tomatic alignments raises dramatically from 48.9%
to 57% without language model re-ranking, and fur-
ther to 61.9% when language model re-ranking was
included.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999975822222222">
Barzilay and McKeown (2001) extract both single-
and multiple-word paraphrases from a monolingual
parallel corpus. They co-train a classifier to iden-
tify whether two phrases were paraphrases of each
other based on their surrounding context. Two dis-
advantages of this method are that it requires iden-
tical bounding substrings, and has bias towards sin-
gle words. For an evaluation set of 500 paraphrases,
they report an average precision of 86% at identi-
fying paraphrases out of context, and of 91% when
the paraphrases are substituted into the original con-
text of the aligned sentence. The results of our sys-
tems are not directly comparable, since Barzilay and
McKeown (2001) evaluated their paraphrases with a
different set of criteria (they asked judges whether
to judge paraphrases based on “approximate con-
ceptual equivalence”). Furthermore, their evaluation
was carried out only by substituting the paraphrase
in for the phrase with the identical context, and not
in for arbitrary occurrences of the original phrase, as
we have done.
Lin and Pantel (2001) use a standard (non-
parallel) monolingual corpus to generate para-
phrases, based on dependancy graphs and distribu-
tional similarity. One strong disadvantage of this
method is that their paraphrases can also have op-
posite meanings.
Ibrahim et al. (2003) combine the two approaches:
aligned monolingual corpora and parsing. They
evaluated their system with human judges who were
asked whether the paraphrases were “roughly inter-
changeable given the genre”, scored an average of
41% on a set of 130 paraphrases, with the judges
all agreeing 75% of the time, and a correlation of
0.66. The shortcomings of this method are that it is
dependent upon parse quality, and is limited by the
rareness of the data.
Pang et al. (2003) use parse trees over sentences in
monolingual parallel corpus to identify paraphrases
by grouping similar syntactic constituents. They
use heuristics such as keyword checking to limit
the over-application of this method. Our alignment
method might be an improvement of their heuris-
tics for choosing which constituents ought to be
grouped.
</bodyText>
<sectionHeader confidence="0.999342" genericHeader="discussions">
6 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.990296772727273">
In this paper we have introduced a novel method for
extracting paraphrases, which we believe greatly in-
creases the usefulness of paraphrasing in NLP ap-
plications. The advantages of our method are that
it:
• Produces a ranked list of high quality para-
phrases with associated probabilities, from
which the best paraphrase can be chosen ac-
cording to the target context. We have shown
how a language model can be used to select the
best paraphrase for a particular context from
this list.
• Straightforwardly handles multi-word units.
Whereas for previous approaches the evalua-
tion has been performed over mostly single
word paraphrases, our results are reported ex-
clusively over units of between 2 and 4 words.
• Because we use a much more abundant source
of data, our method can be used for a much
wider range of text genres than previous ap-
proaches, namely any for which parallel data
is available.
</bodyText>
<page confidence="0.997656">
603
</page>
<bodyText confidence="0.999593555555555">
One crucial thing to note is that we have demon-
strated our paraphrases to be of higher quality when
the alignments used to produce them are improved.
This means that our method will reap the benefits
of research that improvements to automatic align-
ment techniques (Callison-Burch et al., 2004), and
will further improve as more parallel data becomes
available.
In the future we plan to:
</bodyText>
<listItem confidence="0.877196111111111">
• Investigate whether our re-ranking can be fur-
ther improved by using a syntax-based lan-
guage model.
• Formulate a paraphrase probability for senten-
tial paraphrases, and use this to try to identify
paraphrases across documents in order to con-
dense information for multi-document summa-
rization.
• See whether paraphrases can be used to in-
</listItem>
<bodyText confidence="0.858275">
crease coverage for statistical machine trans-
lation when translating into “low-density” lan-
guages which have small parallel corpora.
</bodyText>
<sectionHeader confidence="0.999071" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99989025">
The authors would like to thank Beatrice Alex,
Marco Kuhlmann, and Josh Schroeder for their valu-
able input as well as their time spent annotating and
contributing to the software.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999914417910448">
Regina Barzilay and Lillian Lee. 2003. Learning to
paraphrase: An unsupervised approach using multiple-
sequence alignment. In Proceedings ofHLT/NAACL.
Regina Barzilay and Kathleen McKeown. 2001. Extract-
ing paraphrases from a parallel corpus. In Proceedings
ofACL.
Peter Brown, Stephen Della Pietra, Vincent Della Pietra,
and Robert Mercer. 1993. The mathematics of ma-
chine translation: Parameter estimation. Computa-
tional Linguistics, 19(2):263–311, June.
Chris Callison-Burch, David Talbot, and Miles Osborne.
2004. Statistical machine translation with word- and
sentence-aligned parallel corpora. In Proceedings of
ACL.
Mona Diab and Philip Resnik. 2002. An unsupervised
method for word sense tagging using parallel corpora.
In Proceedings ofACL.
Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Extract-
ing structural paraphrases from aligned monolingual
corpora. In Proceedings of the Second International
Workshop on Paraphrasing (ACL 2003).
Lidija Iordanskaja, Richard Kittredge, and Alain Polg´ere.
1991. Lexical selection and paraphrase in a meaning-
text generation model. In C´ecile L. Paris, William R.
Swartout, and William C. Mann, editors, Natural Lan-
guage Generation in Artificial Intelligence and Com-
putational Linguistics. Kluwer Academic.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings ofHLT/NAACL.
Philipp Koehn. 2002. Europarl: A multilingual corpus
for evaluation of machine translation. Unpublished
Draft.
Philipp Koehn. 2004. Pharaoh: A beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings ofAMTA.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proceedings ofEMNLP.
Kathleen R. McKeown, Regina Barzilay, David Evans,
Vasileios Hatzivassiloglou, Judith L. Klavans, Ani
Nenkova, Carl Sable, Barry Schiffman, and Sergey
Sigelman. 2002. Tracking and summarizing news on
a daily basis with Columbia’s Newsblaster. In Pro-
ceedings of the Human Language Technology Confer-
ence.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51, March.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations: Ex-
tracting paraphrases and generating new sentences. In
Proceedings ofHLT/NAACL.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic evalu-
ation of machine translation. In Proceedings ofACL.
Christoph Tillmann. 2003. A projection extension algo-
rithm for statistical machine translation. In Proceed-
ings of EMNLP.
Stephan Vogel, Ying Zhang, Fei Huang, Alicia Trib-
ble, Ashish Venugopal, Bing Zhao, and Alex Waibel.
2003. The CMU statistical machine translation sys-
tem. In Proceedings ofMT Summit 9.
</reference>
<page confidence="0.998722">
604
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.594433">
<title confidence="0.99987">Paraphrasing with Bilingual Parallel Corpora</title>
<author confidence="0.998614">Colin Bannard Chris Callison-Burch</author>
<affiliation confidence="0.891785333333333">School of Informatics University of Edinburgh 2 Buccleuch Place</affiliation>
<address confidence="0.903414">Edinburgh, EH8 9LW</address>
<abstract confidence="0.996936190476191">Previous work has used monolingual parallel corpora to extract and generate paraphrases. We show that this task can be done using bilingual parallel corpora, a much more commonly available resource. Using alignment techniques from phrasebased statistical machine translation, we show how paraphrases in one language can be identified using a phrase in another language as a pivot. We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account. We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiplesequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings ofHLT/NAACL.</booktitle>
<contexts>
<context position="1946" citStr="Barzilay and Lee, 2003" startWordPosition="291" endWordPosition="294"> of paraphrases allows information repeated across documents to be condensed (McKeown et al., 2002). In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al., 2003). In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingual parallel corpora for paraphrase extraction. Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al., 2002) which use multiple reference translations. While the results reported for these methods are impressive, their usefulness is limited by the scarcity of monolingual parallel corpora. Small data sets mean a limited number of paraphrases can be extracted. </context>
<context position="4698" citStr="Barzilay and Lee, 2003" startWordPosition="738" endWordPosition="741">ses with the monolingual case, and describes how we rank the extracted paraphrases with a probability assignment. Section 3 describes our experimental setup and includes information about how phrases were selected, how we manually aligned parts of the bilingual corpus, and how we evaluated the paraphrases. Section 4 gives the results of our evaluation and gives a number of example paraphrases extracted with our technique. Section 5 reviews related work, and Section 6 discusses future directions. 2 Extracting paraphrases Much previous work on extracting paraphrases (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003) has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases. Barzilay and McKeown (2001) gives the example shown in Figure 1 of how identical surrounding substrings can be used to extract the paraphrases of burst into tears as cried and comfort as console. While monolingual parallel corpora often have identical contexts that can be used for identifying paraphrases, bilingual parallel corpora do not. Instead, we use phrases in the other language as pivots: we look at what foreign lan</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiplesequence alignment. In Proceedings ofHLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="1922" citStr="Barzilay and McKeown, 2001" startWordPosition="287" endWordPosition="290">arization the identification of paraphrases allows information repeated across documents to be condensed (McKeown et al., 2002). In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al., 2003). In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingual parallel corpora for paraphrase extraction. Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al., 2002) which use multiple reference translations. While the results reported for these methods are impressive, their usefulness is limited by the scarcity of monolingual parallel corpora. Small data sets mean a limited number of paraph</context>
<context position="4674" citStr="Barzilay and McKeown, 2001" startWordPosition="734" endWordPosition="737">thod for extracting paraphrases with the monolingual case, and describes how we rank the extracted paraphrases with a probability assignment. Section 3 describes our experimental setup and includes information about how phrases were selected, how we manually aligned parts of the bilingual corpus, and how we evaluated the paraphrases. Section 4 gives the results of our evaluation and gives a number of example paraphrases extracted with our technique. Section 5 reviews related work, and Section 6 discusses future directions. 2 Extracting paraphrases Much previous work on extracting paraphrases (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003) has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases. Barzilay and McKeown (2001) gives the example shown in Figure 1 of how identical surrounding substrings can be used to extract the paraphrases of burst into tears as cried and comfort as console. While monolingual parallel corpora often have identical contexts that can be used for identifying paraphrases, bilingual parallel corpora do not. Instead, we use phrases in the other language as pivots: we </context>
<context position="21565" citStr="Barzilay and McKeown (2001)" startWordPosition="3438" endWordPosition="3441">t aligned with the same target language phrase. Our basic paraphrase calculation was therefore: p(e2|e1,f) = p(f|e1)p(e2|f) (6) Using the foreign language phrase to identify the word sense is obviously not applicable in monolingual settings, but acts as a convenient stand-in for a proper word sense disambiguation algorithm here. When word sense is controlled in this way, the accuracy of the paraphrases extracted from the automatic alignments raises dramatically from 48.9% to 57% without language model re-ranking, and further to 61.9% when language model re-ranking was included. 5 Related Work Barzilay and McKeown (2001) extract both singleand multiple-word paraphrases from a monolingual parallel corpus. They co-train a classifier to identify whether two phrases were paraphrases of each other based on their surrounding context. Two disadvantages of this method are that it requires identical bounding substrings, and has bias towards single words. For an evaluation set of 500 paraphrases, they report an average precision of 86% at identifying paraphrases out of context, and of 91% when the paraphrases are substituted into the original context of the aligned sentence. The results of our systems are not directly </context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>Stephen Della Pietra</author>
<author>Vincent Della Pietra</author>
<author>Robert Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="6519" citStr="Brown et al., 1993" startWordPosition="1025" endWordPosition="1028">tly extracts more than one possible paraphrase for each phrase. We assign a probability to each of the possible paraphrases. This is a mechanism for ranking paraphrases, which can be utilized when we come to select the correct paraphrase for a given context. Section 2.2 explains how we calculate the probability of a paraphrase. 2.1 Aligning phrase pairs We use phrase alignments in a parallel corpus as pivots between English paraphrases. We find these alignments using recent phrase-based approaches to statistical machine translation. The original formulation of statistical machine translation (Brown et al., 1993) was defined as a word-based operation. The probability that a foreign sentence is the translation of an English sentence is calculated by summing over the probabilities of all possible word-level alignments, a, between the sentences: p(f|e) � � p(f, ale) a Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences. More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text. Koehn </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter Brown, Stephen Della Pietra, Vincent Della Pietra, and Robert Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="24879" citStr="Callison-Burch et al., 2004" startWordPosition="3979" endWordPosition="3982">evaluation has been performed over mostly single word paraphrases, our results are reported exclusively over units of between 2 and 4 words. • Because we use a much more abundant source of data, our method can be used for a much wider range of text genres than previous approaches, namely any for which parallel data is available. 603 One crucial thing to note is that we have demonstrated our paraphrases to be of higher quality when the alignments used to produce them are improved. This means that our method will reap the benefits of research that improvements to automatic alignment techniques (Callison-Burch et al., 2004), and will further improve as more parallel data becomes available. In the future we plan to: • Investigate whether our re-ranking can be further improved by using a syntax-based language model. • Formulate a paraphrase probability for sentential paraphrases, and use this to try to identify paraphrases across documents in order to condense information for multi-document summarization. • See whether paraphrases can be used to increase coverage for statistical machine translation when translating into “low-density” languages which have small parallel corpora. Acknowledgments The authors would li</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Philip Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="3824" citStr="Diab and Resnik (2002)" startWordPosition="600" endWordPosition="603"> are aligned with the same phrase in the other language. This assumption of similar mean597 Proceedings of the 43rd Annual Meeting of the ACL, pages 597–604, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Emma burst into tears and he tried to comfort her, saying things to make her smile. Emma cried, and he tried to console her, adorning his words with puns. Figure 1: Using a monolingal parallel corpus to extract paraphrases ing when multiple phrases map onto a single foreign language phrase is the converse of the assumption made in the word sense disambiguation work of Diab and Resnik (2002) which posits different word senses when a single English word maps onto different words in the foreign language (we return to this point in Section 4.4). The remainder of this paper is as follows: Section 2 contrasts our method for extracting paraphrases with the monolingual case, and describes how we rank the extracted paraphrases with a probability assignment. Section 3 describes our experimental setup and includes information about how phrases were selected, how we manually aligned parts of the bilingual corpus, and how we evaluated the paraphrases. Section 4 gives the results of our evalu</context>
<context position="19689" citStr="Diab and Resnik, 2002" startWordPosition="3134" endWordPosition="3137">corpora. For this condition we used Giza++ to align the French-English, Spanish-English, and ItalianEnglish portions of the Europarl corpus in addition to the German-English portion, for a total of around 4,000,000 sentence pairs in the training data. The accuracy of paraphrases extracted over multiple corpora increased to 55%, and further to 57.4% when the language model re-ranking was included. 4.4 Controlling for word sense As mentioned in Section 1, the way that we extract paraphrases is the converse of the methodology employed in word sense disambiguation work that uses parallel corpora (Diab and Resnik, 2002). The assumption made in the word sense disambiguation work is that if a source language word aligns with different target language words then those words may represent different word senses. This can be observed in the paraphrases for at work in Table 2. The paraphrases at the workplace, employment, and in the work sphere are a different sense of the phrase than operate, held, and holding, and they are aligned with different German phrases. When we calculate the paraphrase probability we sum over different target language phrases. Therefore the English phrases that are aligned with the differ</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>Mona Diab and Philip Resnik. 2002. An unsupervised method for word sense tagging using parallel corpora. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali Ibrahim</author>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing (ACL</booktitle>
<contexts>
<context position="1776" citStr="Ibrahim et al., 2003" startWordPosition="263" endWordPosition="266">ration the production of paraphrases allows for the creation of more varied and fluent text (Iordanskaja et al., 1991). In multidocument summarization the identification of paraphrases allows information repeated across documents to be condensed (McKeown et al., 2002). In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al., 2003). In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingual parallel corpora for paraphrase extraction. Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al., 2002) which use multiple reference translations. While the results reported for these me</context>
<context position="22846" citStr="Ibrahim et al. (2003)" startWordPosition="3641" endWordPosition="3644">r paraphrases with a different set of criteria (they asked judges whether to judge paraphrases based on “approximate conceptual equivalence”). Furthermore, their evaluation was carried out only by substituting the paraphrase in for the phrase with the identical context, and not in for arbitrary occurrences of the original phrase, as we have done. Lin and Pantel (2001) use a standard (nonparallel) monolingual corpus to generate paraphrases, based on dependancy graphs and distributional similarity. One strong disadvantage of this method is that their paraphrases can also have opposite meanings. Ibrahim et al. (2003) combine the two approaches: aligned monolingual corpora and parsing. They evaluated their system with human judges who were asked whether the paraphrases were “roughly interchangeable given the genre”, scored an average of 41% on a set of 130 paraphrases, with the judges all agreeing 75% of the time, and a correlation of 0.66. The shortcomings of this method are that it is dependent upon parse quality, and is limited by the rareness of the data. Pang et al. (2003) use parse trees over sentences in monolingual parallel corpus to identify paraphrases by grouping similar syntactic constituents. </context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>Ali Ibrahim, Boris Katz, and Jimmy Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Proceedings of the Second International Workshop on Paraphrasing (ACL 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
<author>Richard Kittredge</author>
<author>Alain Polg´ere</author>
</authors>
<title>Lexical selection and paraphrase in a meaningtext generation model.</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artificial Intelligence and Computational Linguistics.</booktitle>
<editor>In C´ecile L. Paris, William R. Swartout, and William C. Mann, editors,</editor>
<publisher>Kluwer Academic.</publisher>
<marker>Iordanskaja, Kittredge, Polg´ere, 1991</marker>
<rawString>Lidija Iordanskaja, Richard Kittredge, and Alain Polg´ere. 1991. Lexical selection and paraphrase in a meaningtext generation model. In C´ecile L. Paris, William R. Swartout, and William C. Mann, editors, Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofHLT/NAACL.</booktitle>
<contexts>
<context position="3081" citStr="Koehn et al., 2003" startWordPosition="471" endWordPosition="474">lel corpora. Small data sets mean a limited number of paraphrases can be extracted. Furthermore, the narrow range of text genres available for monolingual parallel corpora limits the range of contexts in which the paraphrases can be used. Instead of relying on scarce monolingual parallel data, our method utilizes the abundance of bilingual parallel data that is available. This allows us to create a much larger inventory of phrases that is applicable to a wider range of texts. Our method for identifying paraphrases is an extension of recent work in phrase-based statistical machine translation (Koehn et al., 2003). The essence of our method is to align phrases in a bilingual parallel corpus, and equate different English phrases that are aligned with the same phrase in the other language. This assumption of similar mean597 Proceedings of the 43rd Annual Meeting of the ACL, pages 597–604, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Emma burst into tears and he tried to comfort her, saying things to make her smile. Emma cried, and he tried to console her, adorning his words with puns. Figure 1: Using a monolingal parallel corpus to extract paraphrases ing when multiple phrases m</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings ofHLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A multilingual corpus for evaluation of machine translation.</title>
<date>2002</date>
<note>Unpublished Draft.</note>
<contexts>
<context position="11323" citStr="Koehn, 2002" startWordPosition="1795" endWordPosition="1796">bilingual corpus that we used = arg max e2=,4e1 count(e, f) p(e|f) = 599 die diesbezügliche völlig übrigen kostenentwickl... unter kontrolle im ist . what Alignment Tool is more , the relevant cost dynamic is completely under control . wir den die zu sind es steuerzahlern schuldig kosten unter kontrolle haben we Alignment Tool owe it to the taxpayers to keep the costs in check . (a) Aligning the English phrase to be paraphrased (b) Aligning occurrences of its German translation Figure 3: Phrases highlighted for manual alignment was the German-English section of the Europarl corpus, version 2 (Koehn, 2002). We produced automatic alignments for it with the Giza++ toolkit (Och and Ney, 2003). Because we wanted to test our method independently of the quality of word alignment algorithms, we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphrase. 3.1 Manual alignment The gold standard alignments were created by highlighting all occurrences of the English phrase to paraphrase and manually aligning it with its German equivalent by correcting the automatic alignment, as shown in Figure 3a. All occurrences of its German equivalents were then highlighted, a</context>
</contexts>
<marker>Koehn, 2002</marker>
<rawString>Philipp Koehn. 2002. Europarl: A multilingual corpus for evaluation of machine translation. Unpublished Draft.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: A beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proceedings ofAMTA.</booktitle>
<contexts>
<context position="7125" citStr="Koehn (2004)" startWordPosition="1123" endWordPosition="1124"> 1993) was defined as a word-based operation. The probability that a foreign sentence is the translation of an English sentence is calculated by summing over the probabilities of all possible word-level alignments, a, between the sentences: p(f|e) � � p(f, ale) a Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences. More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text. Koehn (2004), Tillmann (2003), and Vogel et al. (2003) describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al. (1993) models. We use the heuristic for phrase alignment described in Och and Ney (2003) which aligns phrases by incrementally building longer phrases from words and phrases which have adjacent alignment points.1 1Note that while we induce the translations of phrases from 598 Figure 2: Using a bilingual parallel corpus to extract paraphrases zu haben what is more, the relevant cost dynamic is completely under contro</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: A beam search decoder for phrase-based statistical machine translation models. In Proceedings ofAMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="22595" citStr="Lin and Pantel (2001)" startWordPosition="3602" endWordPosition="3605"> 86% at identifying paraphrases out of context, and of 91% when the paraphrases are substituted into the original context of the aligned sentence. The results of our systems are not directly comparable, since Barzilay and McKeown (2001) evaluated their paraphrases with a different set of criteria (they asked judges whether to judge paraphrases based on “approximate conceptual equivalence”). Furthermore, their evaluation was carried out only by substituting the paraphrase in for the phrase with the identical context, and not in for arbitrary occurrences of the original phrase, as we have done. Lin and Pantel (2001) use a standard (nonparallel) monolingual corpus to generate paraphrases, based on dependancy graphs and distributional similarity. One strong disadvantage of this method is that their paraphrases can also have opposite meanings. Ibrahim et al. (2003) combine the two approaches: aligned monolingual corpora and parsing. They evaluated their system with human judges who were asked whether the paraphrases were “roughly interchangeable given the genre”, scored an average of 41% on a set of 130 paraphrases, with the judges all agreeing 75% of the time, and a correlation of 0.66. The shortcomings of</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Proceedings of ACM SIGKDD Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>William Wong</author>
</authors>
<title>A phrase-based, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="9128" citStr="Marcu and Wong, 2002" startWordPosition="1439" endWordPosition="1442">can be calculated straightforwardly using maximum likelihood estimation by counting how often the phrases e and f were aligned in the parallel corpus: � (3) e count(e, f) Note that the paraphrase probability defined in Equation 2 returns the single best paraphrase, e2, irrespective of the context in which e1 appears. Since the best paraphrase may vary depending on information about the sentence that e1 appears in, we extend the paraphrase probability to include that sentence S: e2 = arg max p(e2|e1, S) (4) e2=,4e1 word-level alignments in this paper, direct estimation of phrasal translations (Marcu and Wong, 2002) would also suffice for extracting paraphrases from bilingual corpora. a million, as far as possible, at work, big business, carbon dioxide, central america, close to, concentrate on, crystal clear, do justice to, driving force, first half, for the first time, global warming, great care, green light, hard core, horn of africa, last resort, long ago, long run, military action, military force, moment of truth, new world, noise pollution, not to mention, nuclear power, on average, only too, other than, pick up, president clinton, public transport, quest for, red cross, red tape, socialist party, </context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and William Wong. 2002. A phrase-based, joint probability model for statistical machine translation. In Proceedings ofEMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Regina Barzilay</author>
<author>David Evans</author>
<author>Vasileios Hatzivassiloglou</author>
<author>Judith L Klavans</author>
<author>Ani Nenkova</author>
<author>Carl Sable</author>
<author>Barry Schiffman</author>
<author>Sergey Sigelman</author>
</authors>
<title>Tracking and summarizing news on a daily basis with Columbia’s Newsblaster.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference.</booktitle>
<contexts>
<context position="1423" citStr="McKeown et al., 2002" startWordPosition="206" endWordPosition="210">into account. We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments. 1 Introduction Paraphrases are alternative ways of conveying the same information. Paraphrases are useful in a number of NLP applications. In natural language generation the production of paraphrases allows for the creation of more varied and fluent text (Iordanskaja et al., 1991). In multidocument summarization the identification of paraphrases allows information repeated across documents to be condensed (McKeown et al., 2002). In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al., 2003). In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingua</context>
</contexts>
<marker>McKeown, Barzilay, Evans, Hatzivassiloglou, Klavans, Nenkova, Sable, Schiffman, Sigelman, 2002</marker>
<rawString>Kathleen R. McKeown, Regina Barzilay, David Evans, Vasileios Hatzivassiloglou, Judith L. Klavans, Ani Nenkova, Carl Sable, Barry Schiffman, and Sergey Sigelman. 2002. Tracking and summarizing news on a daily basis with Columbia’s Newsblaster. In Proceedings of the Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="7394" citStr="Och and Ney (2003)" startWordPosition="1164" endWordPosition="1167"> Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences. More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text. Koehn (2004), Tillmann (2003), and Vogel et al. (2003) describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al. (1993) models. We use the heuristic for phrase alignment described in Och and Ney (2003) which aligns phrases by incrementally building longer phrases from words and phrases which have adjacent alignment points.1 1Note that while we induce the translations of phrases from 598 Figure 2: Using a bilingual parallel corpus to extract paraphrases zu haben what is more, the relevant cost dynamic is completely under control im Ÿbrigen ist die diesbezŸgliche kostenentwicklung völlig unter kontrolle wir sind es den steuerzahlern schuldig die kosten unter kontrolle in check we owe it to the taxpayers to keep the costs 2.2 Assigning probabilities We define a paraphrase probability p(e2|e1) </context>
<context position="11408" citStr="Och and Ney, 2003" startWordPosition="1808" endWordPosition="1811">esbezügliche völlig übrigen kostenentwickl... unter kontrolle im ist . what Alignment Tool is more , the relevant cost dynamic is completely under control . wir den die zu sind es steuerzahlern schuldig kosten unter kontrolle haben we Alignment Tool owe it to the taxpayers to keep the costs in check . (a) Aligning the English phrase to be paraphrased (b) Aligning occurrences of its German translation Figure 3: Phrases highlighted for manual alignment was the German-English section of the Europarl corpus, version 2 (Koehn, 2002). We produced automatic alignments for it with the Giza++ toolkit (Och and Ney, 2003). Because we wanted to test our method independently of the quality of word alignment algorithms, we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphrase. 3.1 Manual alignment The gold standard alignments were created by highlighting all occurrences of the English phrase to paraphrase and manually aligning it with its German equivalent by correcting the automatic alignment, as shown in Figure 3a. All occurrences of its German equivalents were then highlighted, and aligned with their English translations (Figure 3b). The other words in the senten</context>
<context position="18445" citStr="Och and Ney (2003)" startWordPosition="2934" endWordPosition="2937">uage model to select the best paraphrase given the context reduces the number of ungrammatical examples and gives an improvement in quality from 48.9% to 55.3% correct. These results suggest two things: that improving the quality of automatic alignments would lead to more accurate paraphrases, and that there is room for improvement in limiting the paraphrases by their context. We address these points below. 4.3 Using multiple corpora Work in statistical machine translation suggests that, like many other machine learning problems, performance increases as the amount of training data increases. Och and Ney (2003) show that the accuracy of alignments produced by Giza++ improve as the size of the training corpus increases. Since we used the whole of the German-English section of the Europarl corpus, we could not try improving the alignments by simply adding more German-English training data. However, there is nothing that limits our paraphrase extraction method to drawing on candidate paraphrases from a single target language. We therefore re-formulated the paraphrase probability to include multiple corpora, as follows: � � �e2 = arg max p(f|e1)p(e2|f) (5) e2=,4e1 C f in C where C is a parallel corpus f</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings ofHLT/NAACL.</booktitle>
<contexts>
<context position="1639" citStr="Pang et al., 2003" startWordPosition="243" endWordPosition="246">e alternative ways of conveying the same information. Paraphrases are useful in a number of NLP applications. In natural language generation the production of paraphrases allows for the creation of more varied and fluent text (Iordanskaja et al., 1991). In multidocument summarization the identification of paraphrases allows information repeated across documents to be condensed (McKeown et al., 2002). In the automatic evaluation of machine translation, paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text (Pang et al., 2003). In question answering, discovering paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingual parallel corpora for paraphrase extraction. Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation e</context>
<context position="4718" citStr="Pang et al., 2003" startWordPosition="742" endWordPosition="745"> case, and describes how we rank the extracted paraphrases with a probability assignment. Section 3 describes our experimental setup and includes information about how phrases were selected, how we manually aligned parts of the bilingual corpus, and how we evaluated the paraphrases. Section 4 gives the results of our evaluation and gives a number of example paraphrases extracted with our technique. Section 5 reviews related work, and Section 6 discusses future directions. 2 Extracting paraphrases Much previous work on extracting paraphrases (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003) has focused on finding identifying contexts within aligned monolingual sentences from which divergent text can be extracted, and treated as paraphrases. Barzilay and McKeown (2001) gives the example shown in Figure 1 of how identical surrounding substrings can be used to extract the paraphrases of burst into tears as cried and comfort as console. While monolingual parallel corpora often have identical contexts that can be used for identifying paraphrases, bilingual parallel corpora do not. Instead, we use phrases in the other language as pivots: we look at what foreign language phrases the En</context>
<context position="23315" citStr="Pang et al. (2003)" startWordPosition="3721" endWordPosition="3724">nd distributional similarity. One strong disadvantage of this method is that their paraphrases can also have opposite meanings. Ibrahim et al. (2003) combine the two approaches: aligned monolingual corpora and parsing. They evaluated their system with human judges who were asked whether the paraphrases were “roughly interchangeable given the genre”, scored an average of 41% on a set of 130 paraphrases, with the judges all agreeing 75% of the time, and a correlation of 0.66. The shortcomings of this method are that it is dependent upon parse quality, and is limited by the rareness of the data. Pang et al. (2003) use parse trees over sentences in monolingual parallel corpus to identify paraphrases by grouping similar syntactic constituents. They use heuristics such as keyword checking to limit the over-application of this method. Our alignment method might be an improvement of their heuristics for choosing which constituents ought to be grouped. 6 Discussion and Future Work In this paper we have introduced a novel method for extracting paraphrases, which we believe greatly increases the usefulness of paraphrasing in NLP applications. The advantages of our method are that it: • Produces a ranked list o</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings ofHLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="2293" citStr="Papineni et al., 2002" startWordPosition="345" endWordPosition="348">ring paraphrased answers may provide additional evidence that an answer is correct (Ibrahim et al., 2003). In this paper we introduce a novel method for extracting paraphrases that uses bilingual parallel corpora. Past work (Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003; Ibrahim et al., 2003) has examined the use of monolingual parallel corpora for paraphrase extraction. Examples of monolingual parallel corpora that have been used are multiple translations of classical French novels into English, and data created for machine translation evaluation methods such as Bleu (Papineni et al., 2002) which use multiple reference translations. While the results reported for these methods are impressive, their usefulness is limited by the scarcity of monolingual parallel corpora. Small data sets mean a limited number of paraphrases can be extracted. Furthermore, the narrow range of text genres available for monolingual parallel corpora limits the range of contexts in which the paraphrases can be used. Instead of relying on scarce monolingual parallel data, our method utilizes the abundance of bilingual parallel data that is available. This allows us to create a much larger inventory of phra</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
</authors>
<title>A projection extension algorithm for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7142" citStr="Tillmann (2003)" startWordPosition="1125" endWordPosition="1126">ined as a word-based operation. The probability that a foreign sentence is the translation of an English sentence is calculated by summing over the probabilities of all possible word-level alignments, a, between the sentences: p(f|e) � � p(f, ale) a Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences. More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text. Koehn (2004), Tillmann (2003), and Vogel et al. (2003) describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al. (1993) models. We use the heuristic for phrase alignment described in Och and Ney (2003) which aligns phrases by incrementally building longer phrases from words and phrases which have adjacent alignment points.1 1Note that while we induce the translations of phrases from 598 Figure 2: Using a bilingual parallel corpus to extract paraphrases zu haben what is more, the relevant cost dynamic is completely under control im Ÿbrigen ist </context>
</contexts>
<marker>Tillmann, 2003</marker>
<rawString>Christoph Tillmann. 2003. A projection extension algorithm for statistical machine translation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Ying Zhang</author>
<author>Fei Huang</author>
<author>Alicia Tribble</author>
<author>Ashish Venugopal</author>
<author>Bing Zhao</author>
<author>Alex Waibel</author>
</authors>
<title>The CMU statistical machine translation system.</title>
<date>2003</date>
<booktitle>In Proceedings ofMT Summit 9.</booktitle>
<contexts>
<context position="7167" citStr="Vogel et al. (2003)" startWordPosition="1128" endWordPosition="1131">operation. The probability that a foreign sentence is the translation of an English sentence is calculated by summing over the probabilities of all possible word-level alignments, a, between the sentences: p(f|e) � � p(f, ale) a Thus Brown et al. decompose the problem of determining whether a sentence is a good translation of another into the problem of determining whether there is a sensible mapping between the words in the sentences. More recent approaches to statistical translation calculate the translation probability using larger blocks of aligned text. Koehn (2004), Tillmann (2003), and Vogel et al. (2003) describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al. (1993) models. We use the heuristic for phrase alignment described in Och and Ney (2003) which aligns phrases by incrementally building longer phrases from words and phrases which have adjacent alignment points.1 1Note that while we induce the translations of phrases from 598 Figure 2: Using a bilingual parallel corpus to extract paraphrases zu haben what is more, the relevant cost dynamic is completely under control im Ÿbrigen ist die diesbezŸgliche kosten</context>
</contexts>
<marker>Vogel, Zhang, Huang, Tribble, Venugopal, Zhao, Waibel, 2003</marker>
<rawString>Stephan Vogel, Ying Zhang, Fei Huang, Alicia Tribble, Ashish Venugopal, Bing Zhao, and Alex Waibel. 2003. The CMU statistical machine translation system. In Proceedings ofMT Summit 9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>