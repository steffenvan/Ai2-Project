<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000094">
<title confidence="0.998195">
Predicting Valence-Arousal Ratings of Words Using a Weighted
Graph Method
</title>
<author confidence="0.99976">
Liang-Chih Yu1,3, Jin Wang2,3,4, K. Robert Lai2,3 and Xue-jie Zhang4
</author>
<affiliation confidence="0.9993425">
1Department of Information Management, Yuan Ze University, Taiwan
2Department of Computer Science &amp; Engineering, Yuan Ze University, Taiwan
3Innovation Center for Big Data and Digital Convergence Yuan Ze University, Taiwan
4School of Information Science and Engineering, Yunnan University, Yunnan, P.R. China
</affiliation>
<email confidence="0.99518">
Contact: lcyu@saturn.yzu.edu.tw
</email>
<sectionHeader confidence="0.995464" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999729304347826">
Compared to the categorical approach
that represents affective states as several
discrete classes (e.g., positive and nega-
tive), the dimensional approach repre-
sents affective states as continuous nu-
merical values on multiple dimensions,
such as the valence-arousal (VA) space,
thus allowing for more fine-grained sen-
timent analysis. In building dimensional
sentiment applications, affective lexicons
with valence-arousal ratings are useful
resources but are still very rare. There-
fore, this study proposes a weighted
graph model that considers both the rela-
tions of multiple nodes and their similari-
ties as weights to automatically deter-
mine the VA ratings of affective words.
Experiments on both English and Chi-
nese affective lexicons show that the
proposed method yielded a smaller error
rate on VA prediction than the linear re-
gression, kernel method, and pagerank
algorithm used in previous studies.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999118680851063">
Thanks to the vigorous development of online
social network services, anyone can now easily
publish and disseminate articles expressing their
thoughts and opinions. Sentiment analysis thus
has become a useful technique to automatically
identify affective information from texts (Pang
and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu,
2012; Feldman, 2013). In sentiment analysis,
representation of affective states is an essential
issue and can be generally divided into categori-
cal and dimensional approaches.
The categorical approach represents affective
states as several discrete classes such as binary
(positive and negative) and Ekman’s six basic
emotions (e.g., anger, happiness, fear, sadness,
disgust and surprise) (Ekman, 1992). Based on
this representation, various techniques have been
investigated to develop useful applications such
as deceptive opinion spam detection (Li et al.,
2014), aspect extraction (Mukherjee and Liu,
2012), cross-lingual portability (Banea et al.,
2013; Xu et al., 2015), personalized sentiment
analysis (Ren and Wu, 2013; Yu et al., 2009) and
viewpoint identification (Qiu and Jiang, 2013).
In addition to identifying sentiment classes, an
extension has been made to further determine
their sentiment strength in terms of a multi-point
scale (Taboada et al., 2011; Li et al., 2011; Yu et
al., 2013; Wang and Ester, 2014).
The dimensional approach has drawn consid-
erable attention in recent years as it can provide a
more fine-grained sentiment analysis. It repre-
sents affective states as continuous numerical
values on multiple dimensions, such as valence-
arousal (VA) space (Russell, 1980), as shown in
Figure 1. The valence represents the degree of
pleasant and unpleasant (or positive and negative)
feelings, and the arousal represents the degree of
excitement and calm. Based on such a two-
dimensional representation, a common research
goal is to determine the degrees of valence and
arousal of given texts such that any affective
state can be represented as a point in the VA co-
ordinate plane. To accomplish this goal, affective
lexicons with valence-arousal ratings are useful
resources but few exist. Most existing applica-
tions rely on a handcrafted lexicon ANEW (Af-
</bodyText>
<page confidence="0.747239">
788
</page>
<note confidence="0.340753666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 788–793,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.978802">
Figure 1. Two-dimensional valence-arousal
space.
</figureCaption>
<bodyText confidence="0.999959472727273">
fective Norms for English Words) (Bradley,
1999) which provides 1,034 English words with
ratings in the dimensions of pleasure, arousal and
dominance to predict the VA ratings of short and
long texts (Paltoglou et al, 2013; Kim et al.,
2010). Accordingly, the automatic prediction of
VA ratings of affective words is a critical task in
building a VA lexicon.
Few studies have sought to predict the VA rat-
ing of words using regression-based methods
(Wei et al., 2011; Malandrakis et al., 2011). This
kind of method usually starts from a set of words
with labeled VA ratings (called seeds). The VA
rating of an unseen word is then estimated from
semantically similar seeds. For instance, Wei et
al. (2011) trained a linear regression model for
each seed cluster, and then predicted the VA rat-
ing of an unseen word using the model of the
cluster to which the unseen word belongs.
Malandrakis et al. (2011) used a kernel function
to combine the similarity between seeds and un-
seen words into a linear regression model. In-
stead of estimating VA ratings of words, another
direction is to determine the polarity (i.e., posi-
tive and negative) of words by applying the label
propagation (Rao and Ravichandran, 2009; Has-
san et al., 2011) and pagerank (Esuli et al., 2007)
on a graph. Based on these methods, the polarity
of an unseen word can be determined/ranked
through its neighbor nodes (seeds).
Although the pagerank algorithm has been
used for polarity ranking, it can still be extended
for VA prediction. Therefore, this study extends
the idea of pagerank in two aspects. First, we
implement pagerank for VA prediction by trans-
forming ranking scores into VA ratings. Second,
whereas pagerank assigns an equal weight to the
edges connected between an unseen word and its
neighbor nodes, we consider their similarities as
weights to construct a weighted graph such that
neighbor nodes more similar to the unseen word
may contribute more to estimate its VA ratings.
That is, the proposed weighted graph model con-
siders both the relations of multiple nodes and
the similarity weights among them. In experi-
ments, we evaluate the performance of the pro-
posed method against the linear regression, ker-
nel method, and pagerank algorithm on both
English and Chinese affective lexicons for VA
prediction.
The rest of this paper is organized as follows.
Section 2 describes the proposed weighted graph
model. Section 3 summarizes the comparative
results of different methods for VA prediction.
Conclusions are finally drawn in Section 4.
</bodyText>
<sectionHeader confidence="0.930921" genericHeader="method">
2 Graph Model for VA Prediction
</sectionHeader>
<bodyText confidence="0.990704863636364">
Based on the theory of link analysis, the rela-
tions between unseen words and seed words can
be considered as a graph, as shown in Figure 2.
The valence-arousal ratings of each unseen word
can then be predicted through the links connect-
ed to the seed words to which it is similar using
their similarities as weights. To measure the sim-
ilarity between words (nodes), we use the
word2vec toolkit (Mikolov et al., 2013) provided
by Google (http://code.google.com/p/word2vec/).
The formal definition of a graph model is de-
scribed as follows. Let G=(V, E) be an undirected
graph, where V denotes a set of words and E de-
notes a set of undirected edges. Each edge e in E
denotes a relation between word vi and word vj in
V (1:—i, j:—n, i≠j), representing the similarity be-
tween them. For each node vi,
N (vi ) = {vj  |(vj, vi ) E E} denotes the set of its
neighbor nodes, representing a set of words to
which it is similar. The valence or arousal of vi,
denoted as valvi or arovi , can then be determined
by its neighbors, defined as
</bodyText>
<equation confidence="0.915659">
(1)
</equation>
<bodyText confidence="0.999874875">
where a is a decay factor or a confidence level
for computation (a constant between 0 and 1),
which limits the effect of rank sinks to guarantee
convergence to a unique vector. Initially, the va-
lence (or arousal) of each unseen word is as-
signed to a random value that between 0 and 10.
Later, it is iteratively updated using the following
formula,
</bodyText>
<equation confidence="0.937874076923077">
vj E N j
= (1— a)• val + a
vi
E
(v;
Sim
(vi, • valv
,
ESim(vi,vj)
vj EN (vi)
val
i
v
</equation>
<page confidence="0.980538">
789
</page>
<figureCaption confidence="0.9334155">
Figure 2. Conceptual diagram of a weighted
graph model for VA prediction.
</figureCaption>
<equation confidence="0.9965554375">
RandomValue ( 0)
t 
t  1
Sim v v val
( , ) v
1 ( ) j
j 
t v N v i j
i
(1 )
 
 val   ( 0)
t 
v i(vi,vj)

(2)
</equation>
<bodyText confidence="0.999879666666667">
where t denotes the t-th iteration. It is worth not-
ing that the valence (or arousal) of the seed
words is a constant in each iterative step. Based
on this, the valence (or arousal) of each unseen
word is propagated through the graph in multiple
iterations until convergence.
To improve the efficiency of the iterative
computation, Eq. (2) can be transformed into a
matrix notation. Suppose that the vectors,
</bodyText>
<equation confidence="0.967023333333333">
V  (valv1 , valv1 ,, valvN )T ,
A  (arov,arov,,arov )T
1 1 N
</equation>
<bodyText confidence="0.962477">
are the vectors of the valence-arousal rating of all
words (including seed words and unseen words).
Matrix
is the adjacency matrix of each words, where
Sim(vi, vj) represents the similarity between
words i and j, where i, j=1, 2, ..., N, i ≠ j.
Given two other vectors (1,1, ,1)T
</bodyText>
<equation confidence="0.72711705882353">
I   and
D  d d  dN , where
( 1 , 2 , , )T
  if node  cand
i
di    0 if nodei  seed ,
 is the previously mentioned decay factor. For
vectors ( 1, 2, , )T
A a a  aN and ( 1, 2, , )T
B b b  bN ,
function (A,B) and (A, B) can be defined as
 A,B  a  b a  b a N  b N
( ) ( 1 1 , 2 2 , , )T ,
 A, B  a b a b  a N b N
( ) ( 1 / 1 , 2 / 2 , , / )T .Then, Eq. (2) can be turned into the following
matrix format.
A   I- D A   D  SA  ,S  I (3) [( ) , 1 ] [ , ( 1 )] T T t t  tThrough the transformation of matrix multi-
</equation>
<bodyText confidence="0.973573">
plication, the computation of VA prediction can
converge within only a few iterations.
</bodyText>
<sectionHeader confidence="0.998961" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.9998146">
Data. This experiment used two affective lexi-
cons with VA ratings: 1) ANEW which contains
1,034 English affective words (Bradley, 1999)
and 2) 162 Chinese affective words (CAW) tak-
en from (Wei et al., 2011). Both lexicons were
used for 5-fold cross-validation. That is, for each
run, 80% of the words in the lexicons were con-
sidered as seeds and the remaining 20% were
used as unseen words. The similarities between
English words and between Chinese words were
calculated using the word2vec toolkit trained
with the respective English and Chinese wiki
corpora (https://dumps.wikimedia.org/).
Implementation Details. Two regression-based
methods were used for comparison: linear re-
gression (Wei et al., 2011) and the kernel method
(Malandrakis et al., 2011), along with two graph-
based methods: pagerank (Esuli et al., 2007) and
the proposed weighted graph model. For both
regression-based methods, the similarities and
VA ratings of the seed words were used for train-
ing, and the VA ratings of an unseen word were
predicted by taking as input its similarity to the
seeds. In addition, for the kernel method, the lin-
ear similarity function was chosen because it
yielded top performance. Both graph-based
methods used an iterative procedure for VA pre-
diction and required no training. For pagerank,
the iterative procedure was implemented using
the algorithm presented in (Esuli et al., 2007),
which estimates the VA ratings of an unseen
word by assigning an equal weight to the edges
connected to its neighbor seeds. For the proposed
method, the iterative procedure was implemented
by considering the word similarity as weights.
</bodyText>
<figure confidence="0.984342727272727">
similarity
similarity
unseen
similarity
seed
similarity
similarity similarity
unseen
seed
seed similarity unseen
seed
</figure>
<equation confidence="0.640938405405405">
 Sim(v1,v1)  Sim(v1,vj)  Sim(v1,vN )
 
  
 
Sim v v
( , )  Sim v v
( , )  Sim v v
( , ) 
i 1 i j i N
 
  
 
Sim(vN,v1)  Sim(vN,vj

N
N
)
Sim(v
,v
)J
S

valvt
i




( )
v i
v N
j 
Sim
V  I - D V  D  SV ,SI ,
[( ) , 1] [ , ( 1 )]
T T
t t t
</equation>
<page confidence="0.974677">
790
</page>
<table confidence="0.999280538461539">
Valence ANEW (English) CAW (Chinese)
RMSE MAE MAPE(%) RMSE MAE MAPE(%)
Weighted Graph 1.122 0.812 11.51 1.224 0.904 13.03
PageRank 1.540 1.085 15.69 1.642 1.187 16.84
Kernel 1.926 1.385 19.55 2.028 1.426 20.57
Linear Regression 1.832 1.301 18.61 1.935 1.393 19.66
ANEW (English) CAW (Chinese)
Arousal
RMSE MAE MAPE(%) RMSE MAE MAPE(%)
Weighted Graph 1.203 0.894 12.24 1.311 0.966 13.37
PageRank 1.627 1.149 16.48 1.735 1.238 17.51
Kernel 2.007 1.419 20.27 2.118 1.434 21.44
Linear Regression 1.912 1.382 19.33 2.020 1.421 20.46
</table>
<tableCaption confidence="0.999821">
Table 1. Comparative results of different methods in VA prediction.
</tableCaption>
<figureCaption confidence="0.988586">
Figure 3. Iterative results of the pagerank algo-
rithm and weighted graph model.
</figureCaption>
<bodyText confidence="0.973911833333334">
Evaluation Metrics. The prediction perfor-
mance was evaluated by examining the differ-
ence between the predicted values of VA ratings
and the corresponding actual values in the
ANEW and CAW lexicons. The evaluation met-
rics included:
</bodyText>
<listItem confidence="0.9999215">
• Root mean square error (RMSE)
• Mean absolute percentage error (MAPE)
</listItem>
<equation confidence="0.979123">
n
1 AP 
ii100%
n  A
i 1 i
</equation>
<bodyText confidence="0.999220378378378">
where
is the actual value,
is the predicted
value, and n is the number of test samples. A
lower
MAE or RMSE value indicates
more accurate forecasting performance.
Iterative Results of the Graph-based Methods.
Figure 3 uses RMSE as an example to show the
iterative results of the pagerank and proposed
methods. The results show that the performance
of both methods stabilized after around 10 itera-
tions, indicating its efficiency for VA prediction.
Another observation is that the ultimate converg-
ing result of each word is unrelated to the decay
factor and the initial random assignment.
Comparative Results. Table 1 compares the
results of the regression-based methods (Linear
Regression and Kernel) and graph-based meth-
ods (PageRank and Weighted Graph). The per-
formance of PageRank and Weighted Graph was
taken from results of the 50th iteration. The re-
sults show that both graph-based methods out-
performed the regression-based methods for all
metrics. For the graph-based methods, the pro-
posed Weighted Graph yielded better
per-
formance than PageRank (around 4%), Kernel
(around 8%) and Linear Regression (around 7%)
on both the ANEW and CAW corpora. The
weighted graph model achieved better perfor-
mance because it predicted VA ratings by con-
sidering both the relations of multiple nodes and
the weights between them. For the regression-
based methods, both Linear Regression and Ker-
nel achieved similar results. Another observation
is that the arousal prediction error is greater than
</bodyText>
<equation confidence="0.59885175">
Ai
Pi
MAPE,
MAPE
</equation>
<bodyText confidence="0.9636555">
that for the valence prediction, indicating that the
arousal dimension is more difficult to predict.
</bodyText>
<figure confidence="0.855445941176471">
• Mean absolute error (MAE)
MAE P
i
|
i
1 n
n 
i
,
1
n
RMSE   
 2
A P n
i
i1
MAPE
</figure>
<page confidence="0.993594">
791
</page>
<sectionHeader confidence="0.99486" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999984533333333">
This study presents a weighted graph model to
predict valence-arousal ratings of words which
can be used for lexicon augmentation in the va-
lence and arousal dimensions. Unlike the equal
weight used in the traditional pagerank algorithm,
the proposed method considers the similarities
between words as weights such that the neighbor
nodes more similar to the unseen word may con-
tribute more to VA prediction. Experiments on
both English and Chinese affective lexicons
show that the proposed method yielded a smaller
error rate than the pagerank, kernel and linear
regression methods. Future work will focus on
extending the VA prediction from the word-level
to the sentence- and document-levels.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999871833333334">
This work was supported by the Ministry of Sci-
ence and Technology, Taiwan, ROC, under
Grant No. NSC102-2221-E-155-029-MY3. The
authors would like to thank the anonymous re-
viewers and the area chairs for their constructive
comments.
</bodyText>
<sectionHeader confidence="0.937488" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.716672835616438">
Carmen Banea, Rada Mihalcea, and Janyce
Wiebe. 2013. Porting multilingual subjectivity
resources across languages. IEEE Trans. Af-
fective Computing, 4(2):211-225.
Margaret M. Bradley and Peter J. Lang. 1999.
Affective norms for English words (ANEW):
Instruction manual and affective ratings.
Technical Report C-1, The Center for Re-
search in Psychophysiology, University of
Florida.
Rafael A. Calvo and Sidney D&apos;Mello. 2010. Af-
fect detection: An interdisciplinary review of
models, methods, and their applications. IEEE
Trans. Affective Computing, 1(1): 18-37.
Paul Ekman. 1992. An argument for basic emo-
tions. Cognition and Emotion, 6:169-200.
Andrea Esuli and Fabrizio Sebastiani. 2007. Pag-
eranking wordnet synsets: An application to
opinion mining. In Proceedings of the 45th
Annual Meeting of the Association for Compu-
tational Linguistics (ACL-07), pages 424-431.
Ronen Feldman. 2013. Techniques and applica-
tions for sentiment analysis. Communications
of the ACM, 56(4):82-89.
Ahmed Hassan, Amjad Abu-Jbara, Rahul Jha,
Dragomir Radev. 2011. Identifying the seman-
tic orientation of foreign words. In Proceed-
ings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-11),
pages 592-597.
Sunghwan Mac Kim, Alessandro Valitutti, and
Rafael A. Calvo. 2010. Evaluation of unsuper-
vised emotion models to textual affect recog-
nition. In Proc. of Workshop on Computation-
al Approaches to Analysis and Generation of
Emotion in Text, pages 62-70.
Fangtao Li, Nathan Liu, Hongwei Jin, Kai Zhao,
Qiang Yang, and Xiaoyan Zhu. 2011. Incorpo-
rating reviewer and product information for
review rating prediction. In Proceedings of the
22nd International Joint Conference on Artifi-
cial Intelligence (IJCAI-11), pages 1820-1825.
Jiwei Li, Myle Ott, Claire Cardie, and Eduard
Hovy. 2014. Towards a general rule for identi-
fying deceptive opinion spam. In Proceedings
of the 52nd Annual Meeting of the Association
for Computational Linguistics (ACL-14), pag-
es 1566-1576.
Bing Liu. 2012. Sentiment Analysis and Opinion
Mining. Morgan &amp; Claypool, Chicago, IL.
Nikos Malandrakis, Alexandros Potamianos,
Iosif Elias, and Shrikanth Narayanan. 2011.
Kernel models for affective lexicon creation.
In Proceedings of the 12th Annual Conference
of the International Speech Communication
Association (Interspeech-11), pages 2977-
2980.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg
Corrado, and Jeffrey Dean. 2013. Distributed
representations of words and phrases and their
compositionality. In Advances in Neural In-
formation Processing Systems 26 (NIPS-13),
pages 3111-3119.
Arjun Mukherjee and Bing Liu. 2012. Aspect
extraction through semi-supervised modeling.
In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics
(ACL-12), pages 339-348.
Georgios Paltoglou, Mathias Theunis, Arvid
Kappas, and Mike Thelwall. 2013. Predicting
emotional responses to long informal text.
IEEE Trans. Affective Computing, 4(1):106-
115.
</reference>
<page confidence="0.997624">
792
</page>
<bodyText confidence="0.930309666666667">
words and their intensity for the sentiment
classification of stock market news.
Knowledge-based Systems. 41:89-97.
</bodyText>
<reference confidence="0.99789898">
Bo Pang and Lillian Lee. 2008. Opinion mining
and sentiment analysis. Foundations and
trends in information retrieval, 2(1-2):1-135.
Minghui Qiu and Jing Jiang. 2013. A latent vari-
able model for viewpoint discovery from
threaded forum posts. In Proceedings of the
2013 Conference of the North American
Chapter of the Association for Computational
Linguistics: Human Language Technologies
(NAACL/HLT-13), pages 1031-1040.
Delip Rao and Deepak Ravichandran. 2009.
Semi-supervised polarity lexicon induction. In
Proceedings of the 12th Conference of the Eu-
ropean Chapter of the Association
for Computational Linguistics (EACL-09),
pages 675–682.
Fuji Ren and Ye Wu. 2013. Predicting user-topic
opinions in Twitter with social and topical
context. IEEE Trans. Affective Computing,
4(4):412-424.
James A. Russell. 1980. A circumplex model of
affect. Journal of personality and social psy-
chology, 39(6):1161.
Maite Taboada, Julian Brooke, Milan Tofiloski,
Kimberly Voll, and Manfred Stede. 2011.
Lexicon-based methods for sentiment analysis.
Computational Linguistics, 37(2):267-307.
Hao Wang and Martin Ester. 2014. A sentiment-
aligned topic model for product aspect rating
prediction. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural
Language Processing (EMNLP-14), pages
1192-1202.
Wen-Li Wei, Chung-Hsien Wu, and Jen-Chun
Lin. 2011. A regression approach to affective
rating of Chinese words from ANEW. In Proc.
of Affective Computing and Intelligent Interac-
tion (ACII-11), pages 121-131.
Ruifeng Xu, Lin Gui, Jun Xu, Qin Lu, and Kam-
Fai Wong. 2015. Cross lingual opinion holder
extraction based on multi-kernel SVMs and
transfer learning. World Wide Web, 18:299-
316.
Liang-Chih Yu, Chung-Hsien Wu, and Fong-Lin
Jang. 2009. Psychiatric document retrieval us-
ing a discourse-aware model. Artificial Intelli-
gence, 173(7-8): 817-829.
Liang-Chih Yu, Jheng-Long Wu, Pei-Chann
Chang, and Hsuan-Shou Chu. 2013. Using a
contextual entropy model to expand emotion
</reference>
<page confidence="0.998959">
793
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.379814">
<title confidence="0.992847">Predicting Valence-Arousal Ratings of Words Using a Graph Method</title>
<author confidence="0.999918">Jin K Robert</author>
<affiliation confidence="0.88858225">of Information Management, Yuan Ze University, of Computer Science &amp; Engineering, Yuan Ze University, Center for Big Data and Digital Convergence Yuan Ze University, of Information Science and Engineering, Yunnan University, Yunnan, P.R. China</affiliation>
<email confidence="0.770398">Contact:lcyu@saturn.yzu.edu.tw</email>
<abstract confidence="0.999691166666667">Compared to the categorical approach that represents affective states as several discrete classes (e.g., positive and negative), the dimensional approach represents affective states as continuous numerical values on multiple dimensions, such as the valence-arousal (VA) space, thus allowing for more fine-grained sentiment analysis. In building dimensional sentiment applications, affective lexicons with valence-arousal ratings are useful resources but are still very rare. Therefore, this study proposes a weighted graph model that considers both the relations of multiple nodes and their similarities as weights to automatically determine the VA ratings of affective words. Experiments on both English and Chinese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression, kernel method, and pagerank algorithm used in previous studies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Porting multilingual subjectivity resources across languages.</title>
<date>2013</date>
<journal>IEEE Trans. Affective Computing,</journal>
<pages>4--2</pages>
<contexts>
<context position="2398" citStr="Banea et al., 2013" startWordPosition="335" endWordPosition="338">ysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as val</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, 2013</marker>
<rawString>Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 2013. Porting multilingual subjectivity resources across languages. IEEE Trans. Affective Computing, 4(2):211-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret M Bradley</author>
<author>Peter J Lang</author>
</authors>
<title>Affective norms for English words (ANEW): Instruction manual and affective ratings.</title>
<date>1999</date>
<tech>Technical Report C-1,</tech>
<institution>The Center for Research in Psychophysiology, University of Florida.</institution>
<marker>Bradley, Lang, 1999</marker>
<rawString>Margaret M. Bradley and Peter J. Lang. 1999. Affective norms for English words (ANEW): Instruction manual and affective ratings. Technical Report C-1, The Center for Research in Psychophysiology, University of Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafael A Calvo</author>
<author>Sidney D&apos;Mello</author>
</authors>
<title>Affect detection: An interdisciplinary review of models, methods, and their applications.</title>
<date>2010</date>
<journal>IEEE Trans. Affective Computing,</journal>
<volume>1</volume>
<issue>1</issue>
<pages>18--37</pages>
<contexts>
<context position="1734" citStr="Calvo and D&apos;Mello, 2010" startWordPosition="243" endWordPosition="246">automatically determine the VA ratings of affective words. Experiments on both English and Chinese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression, kernel method, and pagerank algorithm used in previous studies. 1 Introduction Thanks to the vigorous development of online social network services, anyone can now easily publish and disseminate articles expressing their thoughts and opinions. Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherj</context>
</contexts>
<marker>Calvo, D&apos;Mello, 2010</marker>
<rawString>Rafael A. Calvo and Sidney D&apos;Mello. 2010. Affect detection: An interdisciplinary review of models, methods, and their applications. IEEE Trans. Affective Computing, 1(1): 18-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>An argument for basic emotions. Cognition and Emotion,</title>
<date>1992</date>
<pages>6--169</pages>
<contexts>
<context position="2143" citStr="Ekman, 1992" startWordPosition="302" endWordPosition="303">icles expressing their thoughts and opinions. Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 201</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Paul Ekman. 1992. An argument for basic emotions. Cognition and Emotion, 6:169-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Pageranking wordnet synsets: An application to opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07),</booktitle>
<pages>424--431</pages>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2007. Pageranking wordnet synsets: An application to opinion mining. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), pages 424-431.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>Communications of the ACM,</journal>
<pages>56--4</pages>
<contexts>
<context position="1761" citStr="Feldman, 2013" startWordPosition="249" endWordPosition="250">gs of affective words. Experiments on both English and Chinese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression, kernel method, and pagerank algorithm used in previous studies. 1 Introduction Thanks to the vigorous development of online social network services, anyone can now easily publish and disseminate articles expressing their thoughts and opinions. Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-li</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. Communications of the ACM, 56(4):82-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
</authors>
<title>Amjad Abu-Jbara, Rahul Jha, Dragomir Radev.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-11),</booktitle>
<pages>592--597</pages>
<marker>Hassan, 2011</marker>
<rawString>Ahmed Hassan, Amjad Abu-Jbara, Rahul Jha, Dragomir Radev. 2011. Identifying the semantic orientation of foreign words. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-11), pages 592-597.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunghwan Mac Kim</author>
<author>Alessandro Valitutti</author>
<author>Rafael A Calvo</author>
</authors>
<title>Evaluation of unsupervised emotion models to textual affect recognition.</title>
<date>2010</date>
<booktitle>In Proc. of Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>62--70</pages>
<contexts>
<context position="4188" citStr="Kim et al., 2010" startWordPosition="613" endWordPosition="616">ications rely on a handcrafted lexicon ANEW (Af788 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 788–793, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1. Two-dimensional valence-arousal space. fective Norms for English Words) (Bradley, 1999) which provides 1,034 English words with ratings in the dimensions of pleasure, arousal and dominance to predict the VA ratings of short and long texts (Paltoglou et al, 2013; Kim et al., 2010). Accordingly, the automatic prediction of VA ratings of affective words is a critical task in building a VA lexicon. Few studies have sought to predict the VA rating of words using regression-based methods (Wei et al., 2011; Malandrakis et al., 2011). This kind of method usually starts from a set of words with labeled VA ratings (called seeds). The VA rating of an unseen word is then estimated from semantically similar seeds. For instance, Wei et al. (2011) trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the model of the cluste</context>
</contexts>
<marker>Kim, Valitutti, Calvo, 2010</marker>
<rawString>Sunghwan Mac Kim, Alessandro Valitutti, and Rafael A. Calvo. 2010. Evaluation of unsupervised emotion models to textual affect recognition. In Proc. of Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 62-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Nathan Liu</author>
<author>Hongwei Jin</author>
<author>Kai Zhao</author>
<author>Qiang Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Incorporating reviewer and product information for review rating prediction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI-11),</booktitle>
<pages>1820--1825</pages>
<contexts>
<context position="2727" citStr="Li et al., 2011" startWordPosition="388" endWordPosition="391">ust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on such a twodimensional representation, a common research goal is to determine the degrees of valenc</context>
</contexts>
<marker>Li, Liu, Jin, Zhao, Yang, Zhu, 2011</marker>
<rawString>Fangtao Li, Nathan Liu, Hongwei Jin, Kai Zhao, Qiang Yang, and Xiaoyan Zhu. 2011. Incorporating reviewer and product information for review rating prediction. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI-11), pages 1820-1825.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Eduard Hovy</author>
</authors>
<title>Towards a general rule for identifying deceptive opinion spam.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-14),</booktitle>
<pages>1566--1576</pages>
<contexts>
<context position="2306" citStr="Li et al., 2014" startWordPosition="323" endWordPosition="326">(Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It re</context>
</contexts>
<marker>Li, Ott, Cardie, Hovy, 2014</marker>
<rawString>Jiwei Li, Myle Ott, Claire Cardie, and Eduard Hovy. 2014. Towards a general rule for identifying deceptive opinion spam. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-14), pages 1566-1576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="1745" citStr="Liu, 2012" startWordPosition="247" endWordPosition="248">he VA ratings of affective words. Experiments on both English and Chinese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression, kernel method, and pagerank algorithm used in previous studies. 1 Introduction Thanks to the vigorous development of online social network services, anyone can now easily publish and disseminate articles expressing their thoughts and opinions. Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu,</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikos Malandrakis</author>
<author>Alexandros Potamianos</author>
<author>Iosif Elias</author>
<author>Shrikanth Narayanan</author>
</authors>
<title>Kernel models for affective lexicon creation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 12th Annual Conference of the International Speech Communication Association (Interspeech-11),</booktitle>
<pages>2977--2980</pages>
<contexts>
<context position="4439" citStr="Malandrakis et al., 2011" startWordPosition="655" endWordPosition="658"> Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1. Two-dimensional valence-arousal space. fective Norms for English Words) (Bradley, 1999) which provides 1,034 English words with ratings in the dimensions of pleasure, arousal and dominance to predict the VA ratings of short and long texts (Paltoglou et al, 2013; Kim et al., 2010). Accordingly, the automatic prediction of VA ratings of affective words is a critical task in building a VA lexicon. Few studies have sought to predict the VA rating of words using regression-based methods (Wei et al., 2011; Malandrakis et al., 2011). This kind of method usually starts from a set of words with labeled VA ratings (called seeds). The VA rating of an unseen word is then estimated from semantically similar seeds. For instance, Wei et al. (2011) trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the model of the cluster to which the unseen word belongs. Malandrakis et al. (2011) used a kernel function to combine the similarity between seeds and unseen words into a linear regression model. Instead of estimating VA ratings of words, another direction is to determine </context>
<context position="10322" citStr="Malandrakis et al., 2011" startWordPosition="1779" endWordPosition="1782">999) and 2) 162 Chinese affective words (CAW) taken from (Wei et al., 2011). Both lexicons were used for 5-fold cross-validation. That is, for each run, 80% of the words in the lexicons were considered as seeds and the remaining 20% were used as unseen words. The similarities between English words and between Chinese words were calculated using the word2vec toolkit trained with the respective English and Chinese wiki corpora (https://dumps.wikimedia.org/). Implementation Details. Two regression-based methods were used for comparison: linear regression (Wei et al., 2011) and the kernel method (Malandrakis et al., 2011), along with two graphbased methods: pagerank (Esuli et al., 2007) and the proposed weighted graph model. For both regression-based methods, the similarities and VA ratings of the seed words were used for training, and the VA ratings of an unseen word were predicted by taking as input its similarity to the seeds. In addition, for the kernel method, the linear similarity function was chosen because it yielded top performance. Both graph-based methods used an iterative procedure for VA prediction and required no training. For pagerank, the iterative procedure was implemented using the algorithm </context>
</contexts>
<marker>Malandrakis, Potamianos, Elias, Narayanan, 2011</marker>
<rawString>Nikos Malandrakis, Alexandros Potamianos, Iosif Elias, and Shrikanth Narayanan. 2011. Kernel models for affective lexicon creation. In Proceedings of the 12th Annual Conference of the International Speech Communication Association (Interspeech-11), pages 2977-2980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems</booktitle>
<volume>26</volume>
<pages>3111--3119</pages>
<contexts>
<context position="6917" citStr="Mikolov et al., 2013" startWordPosition="1071" endWordPosition="1074">describes the proposed weighted graph model. Section 3 summarizes the comparative results of different methods for VA prediction. Conclusions are finally drawn in Section 4. 2 Graph Model for VA Prediction Based on the theory of link analysis, the relations between unseen words and seed words can be considered as a graph, as shown in Figure 2. The valence-arousal ratings of each unseen word can then be predicted through the links connected to the seed words to which it is similar using their similarities as weights. To measure the similarity between words (nodes), we use the word2vec toolkit (Mikolov et al., 2013) provided by Google (http://code.google.com/p/word2vec/). The formal definition of a graph model is described as follows. Let G=(V, E) be an undirected graph, where V denotes a set of words and E denotes a set of undirected edges. Each edge e in E denotes a relation between word vi and word vj in V (1:—i, j:—n, i≠j), representing the similarity between them. For each node vi, N (vi ) = {vj |(vj, vi ) E E} denotes the set of its neighbor nodes, representing a set of words to which it is similar. The valence or arousal of vi, denoted as valvi or arovi , can then be determined by its neighbors, d</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26 (NIPS-13), pages 3111-3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect extraction through semi-supervised modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL-12),</booktitle>
<pages>339--348</pages>
<contexts>
<context position="2351" citStr="Mukherjee and Liu, 2012" startWordPosition="329" endWordPosition="332">o, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numer</context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL-12), pages 339-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgios Paltoglou</author>
<author>Mathias Theunis</author>
<author>Arvid Kappas</author>
<author>Mike Thelwall</author>
</authors>
<title>Predicting emotional responses to long informal text.</title>
<date>2013</date>
<journal>IEEE Trans. Affective Computing,</journal>
<pages>4--1</pages>
<contexts>
<context position="4169" citStr="Paltoglou et al, 2013" startWordPosition="609" endWordPosition="612">ist. Most existing applications rely on a handcrafted lexicon ANEW (Af788 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 788–793, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1. Two-dimensional valence-arousal space. fective Norms for English Words) (Bradley, 1999) which provides 1,034 English words with ratings in the dimensions of pleasure, arousal and dominance to predict the VA ratings of short and long texts (Paltoglou et al, 2013; Kim et al., 2010). Accordingly, the automatic prediction of VA ratings of affective words is a critical task in building a VA lexicon. Few studies have sought to predict the VA rating of words using regression-based methods (Wei et al., 2011; Malandrakis et al., 2011). This kind of method usually starts from a set of words with labeled VA ratings (called seeds). The VA rating of an unseen word is then estimated from semantically similar seeds. For instance, Wei et al. (2011) trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the </context>
</contexts>
<marker>Paltoglou, Theunis, Kappas, Thelwall, 2013</marker>
<rawString>Georgios Paltoglou, Mathias Theunis, Arvid Kappas, and Mike Thelwall. 2013. Predicting emotional responses to long informal text. IEEE Trans. Affective Computing, 4(1):106-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1709" citStr="Pang and Lee, 2008" startWordPosition="239" endWordPosition="242">ities as weights to automatically determine the VA ratings of affective words. Experiments on both English and Chinese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression, kernel method, and pagerank algorithm used in previous studies. 1 Introduction Thanks to the vigorous development of online social network services, anyone can now easily publish and disseminate articles expressing their thoughts and opinions. Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (Pang and Lee, 2008; Calvo and D&apos;Mello, 2010; Liu, 2012; Feldman, 2013). In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), a</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minghui Qiu</author>
<author>Jing Jiang</author>
</authors>
<title>A latent variable model for viewpoint discovery from threaded forum posts.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL/HLT-13),</booktitle>
<pages>1031--1040</pages>
<contexts>
<context position="2536" citStr="Qiu and Jiang, 2013" startWordPosition="357" endWordPosition="360"> The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive an</context>
</contexts>
<marker>Qiu, Jiang, 2013</marker>
<rawString>Minghui Qiu and Jing Jiang. 2013. A latent variable model for viewpoint discovery from threaded forum posts. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL/HLT-13), pages 1031-1040.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semi-supervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09),</booktitle>
<pages>675--682</pages>
<contexts>
<context position="5152" citStr="Rao and Ravichandran, 2009" startWordPosition="778" endWordPosition="781">d seeds). The VA rating of an unseen word is then estimated from semantically similar seeds. For instance, Wei et al. (2011) trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the model of the cluster to which the unseen word belongs. Malandrakis et al. (2011) used a kernel function to combine the similarity between seeds and unseen words into a linear regression model. Instead of estimating VA ratings of words, another direction is to determine the polarity (i.e., positive and negative) of words by applying the label propagation (Rao and Ravichandran, 2009; Hassan et al., 2011) and pagerank (Esuli et al., 2007) on a graph. Based on these methods, the polarity of an unseen word can be determined/ranked through its neighbor nodes (seeds). Although the pagerank algorithm has been used for polarity ranking, it can still be extended for VA prediction. Therefore, this study extends the idea of pagerank in two aspects. First, we implement pagerank for VA prediction by transforming ranking scores into VA ratings. Second, whereas pagerank assigns an equal weight to the edges connected between an unseen word and its neighbor nodes, we consider their simi</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semi-supervised polarity lexicon induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09), pages 675–682.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuji Ren</author>
<author>Ye Wu</author>
</authors>
<title>Predicting user-topic opinions in Twitter with social and topical context.</title>
<date>2013</date>
<journal>IEEE Trans. Affective Computing,</journal>
<pages>4--4</pages>
<contexts>
<context position="2467" citStr="Ren and Wu, 2013" startWordPosition="346" endWordPosition="349">be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The val</context>
</contexts>
<marker>Ren, Wu, 2013</marker>
<rawString>Fuji Ren and Ye Wu. 2013. Predicting user-topic opinions in Twitter with social and topical context. IEEE Trans. Affective Computing, 4(4):412-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James A Russell</author>
</authors>
<title>A circumplex model of affect.</title>
<date>1980</date>
<journal>Journal of personality and social psychology,</journal>
<volume>39</volume>
<issue>6</issue>
<contexts>
<context position="3036" citStr="Russell, 1980" startWordPosition="438" endWordPosition="439">onalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on such a twodimensional representation, a common research goal is to determine the degrees of valence and arousal of given texts such that any affective state can be represented as a point in the VA coordinate plane. To accomplish this goal, affective lexicons with valence-arousal ratings are useful resources but few exist. Most existing applications rely on a handcrafted lexicon ANEW (Af788 Proceedings of</context>
</contexts>
<marker>Russell, 1980</marker>
<rawString>James A. Russell. 1980. A circumplex model of affect. Journal of personality and social psychology, 39(6):1161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexicon-based methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<pages>37--2</pages>
<contexts>
<context position="2710" citStr="Taboada et al., 2011" startWordPosition="384" endWordPosition="387">s, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on such a twodimensional representation, a common research goal is to determine the </context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexicon-based methods for sentiment analysis. Computational Linguistics, 37(2):267-307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Wang</author>
<author>Martin Ester</author>
</authors>
<title>A sentimentaligned topic model for product aspect rating prediction.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP-14),</booktitle>
<pages>1192--1202</pages>
<contexts>
<context position="2767" citStr="Wang and Ester, 2014" startWordPosition="396" endWordPosition="399">ased on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on such a twodimensional representation, a common research goal is to determine the degrees of valence and arousal of given texts such that a</context>
</contexts>
<marker>Wang, Ester, 2014</marker>
<rawString>Hao Wang and Martin Ester. 2014. A sentimentaligned topic model for product aspect rating prediction. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP-14), pages 1192-1202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-Li Wei</author>
<author>Chung-Hsien Wu</author>
<author>Jen-Chun Lin</author>
</authors>
<title>A regression approach to affective rating of Chinese words from ANEW.</title>
<date>2011</date>
<booktitle>In Proc. of Affective Computing and Intelligent Interaction (ACII-11),</booktitle>
<pages>121--131</pages>
<contexts>
<context position="4412" citStr="Wei et al., 2011" startWordPosition="651" endWordPosition="654">s), pages 788–793, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1. Two-dimensional valence-arousal space. fective Norms for English Words) (Bradley, 1999) which provides 1,034 English words with ratings in the dimensions of pleasure, arousal and dominance to predict the VA ratings of short and long texts (Paltoglou et al, 2013; Kim et al., 2010). Accordingly, the automatic prediction of VA ratings of affective words is a critical task in building a VA lexicon. Few studies have sought to predict the VA rating of words using regression-based methods (Wei et al., 2011; Malandrakis et al., 2011). This kind of method usually starts from a set of words with labeled VA ratings (called seeds). The VA rating of an unseen word is then estimated from semantically similar seeds. For instance, Wei et al. (2011) trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the model of the cluster to which the unseen word belongs. Malandrakis et al. (2011) used a kernel function to combine the similarity between seeds and unseen words into a linear regression model. Instead of estimating VA ratings of words, another</context>
<context position="9772" citStr="Wei et al., 2011" startWordPosition="1697" endWordPosition="1700">be defined as  A,B  a  b a  b a N  b N ( ) ( 1 1 , 2 2 , , )T ,  A, B  a b a b  a N b N ( ) ( 1 / 1 , 2 / 2 , , / )T .Then, Eq. (2) can be turned into the following matrix format. A   I- D A   D  SA  ,S  I (3) [( ) , 1 ] [ , ( 1 )] T T t t  tThrough the transformation of matrix multiplication, the computation of VA prediction can converge within only a few iterations. 3 Experimental Results Data. This experiment used two affective lexicons with VA ratings: 1) ANEW which contains 1,034 English affective words (Bradley, 1999) and 2) 162 Chinese affective words (CAW) taken from (Wei et al., 2011). Both lexicons were used for 5-fold cross-validation. That is, for each run, 80% of the words in the lexicons were considered as seeds and the remaining 20% were used as unseen words. The similarities between English words and between Chinese words were calculated using the word2vec toolkit trained with the respective English and Chinese wiki corpora (https://dumps.wikimedia.org/). Implementation Details. Two regression-based methods were used for comparison: linear regression (Wei et al., 2011) and the kernel method (Malandrakis et al., 2011), along with two graphbased methods: pagerank (Esu</context>
</contexts>
<marker>Wei, Wu, Lin, 2011</marker>
<rawString>Wen-Li Wei, Chung-Hsien Wu, and Jen-Chun Lin. 2011. A regression approach to affective rating of Chinese words from ANEW. In Proc. of Affective Computing and Intelligent Interaction (ACII-11), pages 121-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifeng Xu</author>
<author>Lin Gui</author>
<author>Jun Xu</author>
<author>Qin Lu</author>
<author>KamFai Wong</author>
</authors>
<title>Cross lingual opinion holder extraction based on multi-kernel SVMs and transfer learning. World Wide Web,</title>
<date>2015</date>
<pages>18--299</pages>
<contexts>
<context position="2416" citStr="Xu et al., 2015" startWordPosition="339" endWordPosition="342"> of affective states is an essential issue and can be generally divided into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) s</context>
</contexts>
<marker>Xu, Gui, Xu, Lu, Wong, 2015</marker>
<rawString>Ruifeng Xu, Lin Gui, Jun Xu, Qin Lu, and KamFai Wong. 2015. Cross lingual opinion holder extraction based on multi-kernel SVMs and transfer learning. World Wide Web, 18:299-316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang-Chih Yu</author>
<author>Chung-Hsien Wu</author>
<author>Fong-Lin Jang</author>
</authors>
<title>Psychiatric document retrieval using a discourse-aware model.</title>
<date>2009</date>
<journal>Artificial Intelligence,</journal>
<volume>173</volume>
<issue>7</issue>
<pages>817--829</pages>
<contexts>
<context position="2485" citStr="Yu et al., 2009" startWordPosition="350" endWordPosition="353">ed into categorical and dimensional approaches. The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman’s six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise) (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents th</context>
</contexts>
<marker>Yu, Wu, Jang, 2009</marker>
<rawString>Liang-Chih Yu, Chung-Hsien Wu, and Fong-Lin Jang. 2009. Psychiatric document retrieval using a discourse-aware model. Artificial Intelligence, 173(7-8): 817-829.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang-Chih Yu</author>
<author>Jheng-Long Wu</author>
<author>Pei-Chann Chang</author>
<author>Hsuan-Shou Chu</author>
</authors>
<title>Using a contextual entropy model to expand emotion</title>
<date>2013</date>
<contexts>
<context position="2744" citStr="Yu et al., 2013" startWordPosition="392" endWordPosition="395"> (Ekman, 1992). Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (Li et al., 2014), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (Banea et al., 2013; Xu et al., 2015), personalized sentiment analysis (Ren and Wu, 2013; Yu et al., 2009) and viewpoint identification (Qiu and Jiang, 2013). In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale (Taboada et al., 2011; Li et al., 2011; Yu et al., 2013; Wang and Ester, 2014). The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis. It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space (Russell, 1980), as shown in Figure 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on such a twodimensional representation, a common research goal is to determine the degrees of valence and arousal of </context>
</contexts>
<marker>Yu, Wu, Chang, Chu, 2013</marker>
<rawString>Liang-Chih Yu, Jheng-Long Wu, Pei-Chann Chang, and Hsuan-Shou Chu. 2013. Using a contextual entropy model to expand emotion</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>