<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000231">
<note confidence="0.420832">
Book Reviews Cognitive Science: An Introduction
</note>
<bodyText confidence="0.998872727272728">
For instance, for a direct causal relationship, once the
simple sentences that express the ACT and RESULT
have been chosen, the choice of syntactic structure, the
ordering of information, and the number of sentences
still remain. Moreover, not all combinations of these
choices yield acceptable texts. The discourse grammar
encodes the acceptable choice combinations for the
semantic relationship.
Thus, in order to build a generation system which is
able to handle some particular semantic relation, one
must first do a detailed linguistic analysis to find the
simple sentences that could be used to convey the
information (and encode this in the lexicon grammar),
and next do another linguistic analysis to see how these
simple sentences can be combined, ordered, and syn-
tactically presented so as to convey the semantic rela-
tionship (and encode this in the discourse grammar).
Once the analysis has been done, the generation system
can use these two grammars to do generation. It is the
case, however, that the two grammars encode choices
that are mutually dependent. Thus a choice in one will
limit the available choices in the other. The priority of
these decisions can only be determined within a partic-
ular domain. In applying this generation model to several
domains, Danlos is extremely thorough and insightful.
While one would hope that the domain dependence
that Danlos advocates is not necessary, her analysis is
quite convincing. Throughout the book she points out
areas where &amp;quot;general principles&amp;quot; used by others must
actually be operationalized in a very domain-dependent
fashion. Thus the usefulness of such principles is called
into question.
In all I found the book to be most interesting. As a
computer scientist I found the book&apos;s linguistic analysis
very helpful. It forced me to look at generation from a
new point of view. I would expect that linguists will
have a similar reaction because of the book&apos;s strong
commitment to processing. I believe that Danlos has
been able to successfully straddle the fence that lies
between these two fields. In doing so, she has made a
real contribution to both.
Kathleen McCoy is an assistant professor at the University of
Delaware working in the areas of natural language generation,
discourse, and correcting misconceptions. McCoy&apos;s address
</bodyText>
<affiliation confidence="0.6465335">
is: Department of Computer and Information Sciences, Uni-
versity of Delaware, Newark, DE 19716. E-mail:
</affiliation>
<email confidence="0.651473">
mccoy@udel.edu
</email>
<sectionHeader confidence="0.782072" genericHeader="abstract">
COGNITIVE SCIENCE: AN INTRODUCTION
</sectionHeader>
<bodyText confidence="0.678957857142857">
Neil A. StiRings; Mark H. Feinstein; Jay L. Garfield;
Edwina L. Rissland; David A. Rosenbaum; Steven E.
Weisler; and Lynne Baker-Ward
(Hampshire College and University of Massachusetts,
Amherst, MA)
The MIT Press/Bradford Books, Cambridge, MA
1987, xvii+533 pp.
</bodyText>
<equation confidence="0.233238666666667">
ISBN 0-262-19257-8, $25.00 (hb)
Reviewed by
Helen M. Gigley
</equation>
<subsubsectionHeader confidence="0.511842">
National Science Foundation
</subsubsectionHeader>
<bodyText confidence="0.999970674418605">
The study of cognitive science in modern terms is an
emerging field and the term itself evokes many discus-
sions regarding its nature. For instance, what are criti-
cal aspects of its study, and to what degree can certain
traditional disciplines contribute? Given these facts,
this book makes a significant contribution to providing
a basic overview of current cognitive science. But I am
not reviewing it strictly for its contribution to the study
of cognitive science. Instead, I am reviewing it here as
it might be used for an introduction to natural language
processing (NLP) or to issues which are relevant to
computational linguistics. The attempt will be to focus
only on issues that are related to language and its
processing. However, since there are areas where the
separation of language and cognition in general are
impossible, there will be some related description of the
cognitive discussions.
The overall presentation of the material is at a level
that is easily accessible to students unfamiliar with the
problems raised. Specifically, for persons beginning the
study of language as a part of cognition, including its
acquisition, its processing, and aspects of its knowledge
base, I find the discussions very adequate in most
respects. Because the chapters are individually
authored, there is some disparity in style and type of
information contained, but for most chapters this can be
overlooked.
First, I will raise some problems that I found with the
text that might influence its selection. Of critical import
to a book such as this is a chapter that attempts to
integrate what has been presented separately. This is
lacking here and I feel is a serious omission. Having one
final chapter that pulls together the threads of common-
ality that have been described throughout is very im-
portant for new students in afield. Even having suitable
pointers between chapters as cross-reference to where
another viewpoint of the same problem is presented
would be helpful. This also is not done; the reader is left
to infer such relationships. Without significant guidance
from someone who is knowledgeable across several of
the disciplines, seeing the parallel and interrelated re-
search efforts is not a trivial task, but is necessary to
fully grasp the problems faced in cognitive science
</bodyText>
<page confidence="0.94759">
116 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
<bodyText confidence="0.987791512820513">
Book Reviews Cognitive Science: An Introduction
study. This overall integration is also directly relevant
to the study of language and, I feel, computational
linguistics in particular.
Now with regard to some pickier points, let me
illustrate where more cross-talk among the authors may
have helped. It appears that the authors of &amp;quot;Architec-
ture of the Mind&amp;quot; (Chapter 2) and the Al chapters
(Chapters 4 and 5) did not comment or read each other&apos;s
contributions. In Chapter 2 the following statement
appears without any further expansion:
Anderson (1983) proposes a representation for procedural
knowledge called a production system and provides a
much more detailed theory of how goal-directed behavior
can be maintained than we have been able to provide
here. (p. 60)
There is no reference to the development of a produc-
tion system theory by Newell and Simon (1972) among
others (cf. Chapter 1 of Anderson (1983)). The work of
Newell and Simon is raised in the context of their
general problem-solving approach (GPS) in Chapter 4,
but there is no mention there of the fact that they also
defined a production system control theory as one way
of effectively computing solutions to their problem-
solving strategy. Furthermore, examples and full dis-
cussion of a production system control are presented in
Chapter 4 without any reference to either of these
works. Given the chronology of the original production
system work, this cross-reference omission, as clearly
shown by the Anderson text, demonstrates where
cross-chapter talk would have benefitted this volume.
Another instance where a similar situation arises is in
dealing with the spreading activation paradigm, which
was first defined as a memory access and representation
device by an Al researcher, Quillian (1968). This para-
digm is described as being developed by Collins and
Loftus (1975) and others (Chapter 3) and yet their work
references Quillian&apos;s throughout. There is only one brief
statement in the Al chapter that mentions Quillian&apos;s
significant contribution.
This lack of cross-chapter integration, which I feel to
be especially relevant for new students of language
processing—computationally or otherwise, as well as
for cognitive scientists—requires having a suitable
source of outside information. Again I will state that it
could have been handled either by inclusion of pointers
to related work or a concluding overview chapter.
Now, specifically to the issue of the possible use of
this text as an introduction to NLP or to computational
linguistics, I feel that the book is an excellent beginning
in spite of the issues just discussed. It covers many
basic issues of language from viewpoints emphasizing
linguistic theory through those dealing with perfor-
mance. It defines many basic concepts necessary to
define language processes and provides adequate exam-
ples and discussion of them.
The chapters on Al are extremely well written and
concise. They give a clear introduction to problems
within Al independently of the problems being tackled.
For students lacking exposure to computational issues,
they provide an extremely good basic introduction to
the problems involved in developing a computational
counterpart to any theory. The introductory remarks
relating Alto the other fields of cognitive science more
than adequately cover the issues.
In contrast, the chapter on philosophy (Chapter 8) I
find to be of little relevance to natural language issues as
they might be integrated within either an NLP course or
one on computational linguistics. This is due to the style
of the chapter as well as the fact that many philosoph-
ical issues that are more directly related to natural
language (i.e., truth conditions, possible world seman-
tics, predicate logic, and so on) are described in an
excellent presentation in the chapter on semantics
(Chapter 10). Perhaps this is another instance where the
presentations would have been enhanced by cross-talk.
I believe that philosophical issues of language are a very
critical part of any understanding of natural language
processing as well as computational linguistics in gen-
eral, but find the particular presentation here lacking in
developing a suitable relationship to either. In using this
book as a text, I would probably skip this chapter.
The chapter on neuroscience (Chapter 7), which
many might consider tangential to NLP, however, is
very well done. It is clearly presented and provides
quite a comprehensive overview of neurofunctioning.
There are many examples and the discussions are
intuitive and clearly depict some critical issues that are
important in an introductory text. There seems to be a
minor problem in the discussion of aphasia, though, and
that is the definition of conduction aphasia where com-
prehension is noted as being impaired (p. 294), whereas
several noteworthy references in the study of aphasia
characterize it as good to excellent (cf. Goodglass and
Kaplan 1983, 1972, Kertesz 1979). Perhaps this is just an
error in proofreading.
The breadth of exposure to language issues and
related study that is contained in this text is excellent
for the most part, but the one chapter (Chapter 11)
specific to natural language processing is the weakest.
When reading the title of the chapter, &amp;quot;Natural Lan-
guage Processing&amp;quot;, I immediately thought of computa-
tional approaches to NLP (my bias); but they are given
little emphasis. Within the computational approaches
included, there seems to be an inordinate amount of
credit given to computational approaches using scripts
or frames to the exclusion of other significant ap-
proaches to NLP.
The NLP chapter does mention Winograd&apos;s SHRDLU
model (1972) and briefly describes what is achieved.
However, the import of its development in the historical
perspective of when it was done is lost. After finishing
this chapter, it seems that the only relevant computa-
tional work in NLP was done by the group working
under Schank or within the scripts and frames ap-
proaches. While these have had an impact on some
approaches to NLP, I do not think they should be
Computational Linguistics, Volume 14, Number 3, September 1988 117
Book Reviews Machine Translation: Past, Present, Future
presented as the only significant computational contri-
butions. There is no discussion of processing as it is
defined computationally. There is no mention of proc-
essing concerns that require integration of some of the
issues raised in other chapters (Chapters 2, 4, and 5),
such as the knowledge base necessary for natural lan-
guage processing and the fact that one must consider
what control structures or procedures must be in place
to process language. These issues are never related to
language as a process.
The emphasis is on more psycholinguistically moti-
vated approaches and perhaps that is why the compu-
tational aspects included are biased to only include
those which emphasize meaning representations as
scripts and schemas while ignoring all other computa-
tional approaches. Computational language processing
approaches that are omitted range from the ATN work
of Woods (1970) to the ARPA projects of the mid-&apos;70s
(HWIM, Woods et al. 1976, HEARSAY-II, Erman et al.
1980). These are the biggest omissions and limit the use
of this text to introduce natural language processing or
to form a basis for a computational linguistics course.
However, one can supplement this by using the discus-
sion of language processing in a suitable introductory Al
text such as Barr and Feigenbaum (1981).
In conclusion, this book is an excellent attempt to
present aspects of cognitive science from within disci-
plines that are each approaching its study. For introduc-
tory NLP or computational linguistic study, I would use
this at least as a supplementary text. I know of no other
equally broad and comprehensive source of material
that is relevant to language study from so many per-
spectives. Given the above-stated problems, I would
also be prepared to supplement the book in ways
previously discussed. This is especially critical to the
issues of natural language processing and to integrating
viewpoints of the same problem across the discussion.
</bodyText>
<sectionHeader confidence="0.998765" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.981645024390244">
Anderson, J.R. 1983 The Architecture of Cognition, Harvard Univer-
sity Press, Cambridge, MA.
Barr, A. and Feigenbaum, E.A. 1981 The Handbook of Artificial
Intelligence 1, William Kaufmann, Inc.
Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory
of Semantic Processing. Psychological Review 82(6): 407-428.
Erman, L.D., Hayes-Roth, F., Lesser, V.R., and Reddy, D.R. 1980
The HEARSAY-II speech-understanding system: Integrating
knowledge to resolve uncertainty. Computing Surveys 12: 213-
253.
Goodglass, H. and Kaplan, E. 1983 The Assessment of Aphasia and
Related Disorders (2nd ed.). Lea and Febiger.
Kertesz, A. 1979 Aphasia and Associated Disorders: Taxonomy,
Localization, and Recovery. Grune and Stratton.
Newell, A. and Simon, H.A. 1972 Human problem solving. Prentice-
Hall, Englewood Cliffs, NJ.
Quillian, M.R. 1968 Semantic Memory. In M. Minsky (ed.), Semantic
Information Processing. MIT Press, Cambridge, MA.
Winograd, T. 1972 Understanding Natural Language. Academic
Press, New York, NY.
Woods, W.A. 1970 Transition Network Grammars for Natural Lan-
guage Analysis. Communications of the ACM 13(10): 591-606.
Woods, W. A.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad,
J.; Maldoul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and
Zue, V. 1976 Speech Understanding Systems—Final Report.
Technicd Report 3438, Volume 4, Bolt Beranek and Newman,
Inc.
Helen Gigley&apos; s areas of interest include computational linguis-
tics and neurolinguistics, artificial intelligence and neurophy-
siology, and neural-based cognitive modeling. She received a
Ph.D. in computer science in 1982 from the University of
Massachusetts, Amherst. Gigley&apos;s address is National Sci-
ence Foundation, 1800 G St., NW, Rm. 304, Washington, DC
20550. E-mail: hgigley@note.nsf.gov
MACHINE TRANSLATION: PAST, PRESENT, FUTURE.
William John Hutchins
University of East Anglia)
(Ellis Horwood Series in Computers and their
Applications)
Ellis Horwood: Chichester, 1986, 382 pp.
ISBN 0-85312-788-3, $49.95 (hb)
</reference>
<figure confidence="0.67592625">
Reviewed by
Richard Kittredge
Universite de Montreal and Odyssey Research Asso-
ciates
</figure>
<bodyText confidence="0.999188966666667">
Most computational linguists are probably aware that
machine translation (MT) has provided the impetus for
a number of important advances in linguistics and
computing over the past 40 years. But even those who
have worked on MT could not have fully appreciated
the breadth, depth and impact of MT activity around the
globe before reading Hutchins&apos;s book Machine Trans-
lation: Past, Present, Future. For most of us, I think, its
publication has come as a very pleasant and welcome
surprise for a number of reasons. First, the recent
reawakening of interest in MT worldwide calls for a
balanced historical overview of the approaches used
and the experience gained to date. Hutchins&apos;s volume
helps satisfy this need for a critical collective conscious-
ness, and sets a high standard for future works of this
nature.
Second, Hutchins&apos;s thorough treatment of the his-
tory of MT is interspersed with short summaries of the
technical problems and approaches in linguistic analysis
and natural language processing as they have related to
MT. The result is a very readable and even entertaining
book, which can serve as an introduction to the field for
a wide audience including not only translators, linguists,
and computer scientists, but also the general (techni-
cally literate) public. The students in my graduate MT
seminar, for example, have found it the most useful
single book on the subject.
Third, it satisfies the long-standing need for a good
single-volume reference on MT. Its detailed and cross-
referenced description of virtually all known MT
</bodyText>
<page confidence="0.924096">
118 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
</variant>
</algorithm>

<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>The Architecture of Cognition,</title>
<date>1983</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5772" citStr="Anderson (1983)" startWordPosition="912" endWordPosition="913">Computational Linguistics, Volume 14, Number 3, September 1988 Book Reviews Cognitive Science: An Introduction study. This overall integration is also directly relevant to the study of language and, I feel, computational linguistics in particular. Now with regard to some pickier points, let me illustrate where more cross-talk among the authors may have helped. It appears that the authors of &amp;quot;Architecture of the Mind&amp;quot; (Chapter 2) and the Al chapters (Chapters 4 and 5) did not comment or read each other&apos;s contributions. In Chapter 2 the following statement appears without any further expansion: Anderson (1983) proposes a representation for procedural knowledge called a production system and provides a much more detailed theory of how goal-directed behavior can be maintained than we have been able to provide here. (p. 60) There is no reference to the development of a production system theory by Newell and Simon (1972) among others (cf. Chapter 1 of Anderson (1983)). The work of Newell and Simon is raised in the context of their general problem-solving approach (GPS) in Chapter 4, but there is no mention there of the fact that they also defined a production system control theory as one way of effecti</context>
</contexts>
<marker>Anderson, 1983</marker>
<rawString>Anderson, J.R. 1983 The Architecture of Cognition, Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Barr</author>
<author>E A Feigenbaum</author>
</authors>
<date>1981</date>
<booktitle>The Handbook of Artificial Intelligence 1,</booktitle>
<publisher>Kaufmann, Inc.</publisher>
<location>William</location>
<contexts>
<context position="12686" citStr="Barr and Feigenbaum (1981)" startWordPosition="2010" endWordPosition="2013">se which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use this at least as a supplementary text. I know of no other equally broad and comprehensive source of material that is relevant to language study from so many perspectives. Given the above-stated problems, I would also be prepared to supplement the book in ways previously discussed. This is especially critical to the issues of natural language processing and to integrating viewpo</context>
</contexts>
<marker>Barr, Feigenbaum, 1981</marker>
<rawString>Barr, A. and Feigenbaum, E.A. 1981 The Handbook of Artificial Intelligence 1, William Kaufmann, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Collins</author>
<author>E F Loftus</author>
</authors>
<title>A Spreading Activation Theory of Semantic Processing.</title>
<date>1975</date>
<journal>Psychological Review</journal>
<volume>82</volume>
<issue>6</issue>
<pages>407--428</pages>
<contexts>
<context position="7068" citStr="Collins and Loftus (1975)" startWordPosition="1117" endWordPosition="1120"> examples and full discussion of a production system control are presented in Chapter 4 without any reference to either of these works. Given the chronology of the original production system work, this cross-reference omission, as clearly shown by the Anderson text, demonstrates where cross-chapter talk would have benefitted this volume. Another instance where a similar situation arises is in dealing with the spreading activation paradigm, which was first defined as a memory access and representation device by an Al researcher, Quillian (1968). This paradigm is described as being developed by Collins and Loftus (1975) and others (Chapter 3) and yet their work references Quillian&apos;s throughout. There is only one brief statement in the Al chapter that mentions Quillian&apos;s significant contribution. This lack of cross-chapter integration, which I feel to be especially relevant for new students of language processing—computationally or otherwise, as well as for cognitive scientists—requires having a suitable source of outside information. Again I will state that it could have been handled either by inclusion of pointers to related work or a concluding overview chapter. Now, specifically to the issue of the possib</context>
</contexts>
<marker>Collins, Loftus, 1975</marker>
<rawString>Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory of Semantic Processing. Psychological Review 82(6): 407-428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L D Erman</author>
<author>F Hayes-Roth</author>
<author>V R Lesser</author>
<author>D R Reddy</author>
</authors>
<title>The HEARSAY-II speech-understanding system: Integrating knowledge to resolve uncertainty.</title>
<date>1980</date>
<journal>Computing Surveys</journal>
<volume>12</volume>
<pages>213--253</pages>
<contexts>
<context position="12372" citStr="Erman et al. 1980" startWordPosition="1958" endWordPosition="1961">one must consider what control structures or procedures must be in place to process language. These issues are never related to language as a process. The emphasis is on more psycholinguistically motivated approaches and perhaps that is why the computational aspects included are biased to only include those which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use this at least as a supplementary text. I know of no other equally </context>
</contexts>
<marker>Erman, Hayes-Roth, Lesser, Reddy, 1980</marker>
<rawString>Erman, L.D., Hayes-Roth, F., Lesser, V.R., and Reddy, D.R. 1980 The HEARSAY-II speech-understanding system: Integrating knowledge to resolve uncertainty. Computing Surveys 12: 213-253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Goodglass</author>
<author>E Kaplan</author>
</authors>
<date>1983</date>
<booktitle>The Assessment of Aphasia and Related Disorders (2nd ed.). Lea and Febiger.</booktitle>
<contexts>
<context position="10142" citStr="Goodglass and Kaplan 1983" startWordPosition="1598" endWordPosition="1601"> (Chapter 7), which many might consider tangential to NLP, however, is very well done. It is clearly presented and provides quite a comprehensive overview of neurofunctioning. There are many examples and the discussions are intuitive and clearly depict some critical issues that are important in an introductory text. There seems to be a minor problem in the discussion of aphasia, though, and that is the definition of conduction aphasia where comprehension is noted as being impaired (p. 294), whereas several noteworthy references in the study of aphasia characterize it as good to excellent (cf. Goodglass and Kaplan 1983, 1972, Kertesz 1979). Perhaps this is just an error in proofreading. The breadth of exposure to language issues and related study that is contained in this text is excellent for the most part, but the one chapter (Chapter 11) specific to natural language processing is the weakest. When reading the title of the chapter, &amp;quot;Natural Language Processing&amp;quot;, I immediately thought of computational approaches to NLP (my bias); but they are given little emphasis. Within the computational approaches included, there seems to be an inordinate amount of credit given to computational approaches using scripts </context>
</contexts>
<marker>Goodglass, Kaplan, 1983</marker>
<rawString>Goodglass, H. and Kaplan, E. 1983 The Assessment of Aphasia and Related Disorders (2nd ed.). Lea and Febiger.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kertesz</author>
</authors>
<title>Aphasia and Associated Disorders: Taxonomy, Localization, and Recovery. Grune and Stratton.</title>
<date>1979</date>
<contexts>
<context position="10163" citStr="Kertesz 1979" startWordPosition="1603" endWordPosition="1604">nsider tangential to NLP, however, is very well done. It is clearly presented and provides quite a comprehensive overview of neurofunctioning. There are many examples and the discussions are intuitive and clearly depict some critical issues that are important in an introductory text. There seems to be a minor problem in the discussion of aphasia, though, and that is the definition of conduction aphasia where comprehension is noted as being impaired (p. 294), whereas several noteworthy references in the study of aphasia characterize it as good to excellent (cf. Goodglass and Kaplan 1983, 1972, Kertesz 1979). Perhaps this is just an error in proofreading. The breadth of exposure to language issues and related study that is contained in this text is excellent for the most part, but the one chapter (Chapter 11) specific to natural language processing is the weakest. When reading the title of the chapter, &amp;quot;Natural Language Processing&amp;quot;, I immediately thought of computational approaches to NLP (my bias); but they are given little emphasis. Within the computational approaches included, there seems to be an inordinate amount of credit given to computational approaches using scripts or frames to the excl</context>
</contexts>
<marker>Kertesz, 1979</marker>
<rawString>Kertesz, A. 1979 Aphasia and Associated Disorders: Taxonomy, Localization, and Recovery. Grune and Stratton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
<author>H A Simon</author>
</authors>
<title>Human problem solving. PrenticeHall,</title>
<date>1972</date>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="6085" citStr="Newell and Simon (1972)" startWordPosition="962" endWordPosition="965"> where more cross-talk among the authors may have helped. It appears that the authors of &amp;quot;Architecture of the Mind&amp;quot; (Chapter 2) and the Al chapters (Chapters 4 and 5) did not comment or read each other&apos;s contributions. In Chapter 2 the following statement appears without any further expansion: Anderson (1983) proposes a representation for procedural knowledge called a production system and provides a much more detailed theory of how goal-directed behavior can be maintained than we have been able to provide here. (p. 60) There is no reference to the development of a production system theory by Newell and Simon (1972) among others (cf. Chapter 1 of Anderson (1983)). The work of Newell and Simon is raised in the context of their general problem-solving approach (GPS) in Chapter 4, but there is no mention there of the fact that they also defined a production system control theory as one way of effectively computing solutions to their problemsolving strategy. Furthermore, examples and full discussion of a production system control are presented in Chapter 4 without any reference to either of these works. Given the chronology of the original production system work, this cross-reference omission, as clearly sho</context>
</contexts>
<marker>Newell, Simon, 1972</marker>
<rawString>Newell, A. and Simon, H.A. 1972 Human problem solving. PrenticeHall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Quillian</author>
</authors>
<title>Semantic Memory.</title>
<date>1968</date>
<booktitle>Semantic Information Processing.</booktitle>
<editor>In M. Minsky (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6992" citStr="Quillian (1968)" startWordPosition="1106" endWordPosition="1107">computing solutions to their problemsolving strategy. Furthermore, examples and full discussion of a production system control are presented in Chapter 4 without any reference to either of these works. Given the chronology of the original production system work, this cross-reference omission, as clearly shown by the Anderson text, demonstrates where cross-chapter talk would have benefitted this volume. Another instance where a similar situation arises is in dealing with the spreading activation paradigm, which was first defined as a memory access and representation device by an Al researcher, Quillian (1968). This paradigm is described as being developed by Collins and Loftus (1975) and others (Chapter 3) and yet their work references Quillian&apos;s throughout. There is only one brief statement in the Al chapter that mentions Quillian&apos;s significant contribution. This lack of cross-chapter integration, which I feel to be especially relevant for new students of language processing—computationally or otherwise, as well as for cognitive scientists—requires having a suitable source of outside information. Again I will state that it could have been handled either by inclusion of pointers to related work or</context>
</contexts>
<marker>Quillian, 1968</marker>
<rawString>Quillian, M.R. 1968 Semantic Memory. In M. Minsky (ed.), Semantic Information Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language.</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<location>New York, NY.</location>
<marker>Winograd, 1972</marker>
<rawString>Winograd, T. 1972 Understanding Natural Language. Academic Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<volume>13</volume>
<issue>10</issue>
<pages>591--606</pages>
<contexts>
<context position="12278" citStr="Woods (1970)" startWordPosition="1943" endWordPosition="1944"> such as the knowledge base necessary for natural language processing and the fact that one must consider what control structures or procedures must be in place to process language. These issues are never related to language as a process. The emphasis is on more psycholinguistically motivated approaches and perhaps that is why the computational aspects included are biased to only include those which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational li</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, W.A. 1970 Transition Network Grammars for Natural Language Analysis. Communications of the ACM 13(10): 591-606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>M Bates</author>
<author>G Brown</author>
<author>B Bruce</author>
<author>C Cook</author>
<author>J Klovstad</author>
<author>J Maldoul</author>
<author>B Nash-Webber</author>
<author>R Schwartz</author>
<author>J Wolf</author>
<author>V Zue</author>
</authors>
<title>Speech Understanding Systems—Final Report.</title>
<date>1976</date>
<tech>Technicd Report 3438,</tech>
<volume>4</volume>
<institution>Bolt Beranek and Newman, Inc.</institution>
<contexts>
<context position="12340" citStr="Woods et al. 1976" startWordPosition="1953" endWordPosition="1956">e processing and the fact that one must consider what control structures or procedures must be in place to process language. These issues are never related to language as a process. The emphasis is on more psycholinguistically motivated approaches and perhaps that is why the computational aspects included are biased to only include those which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use this at least as a supplementary t</context>
</contexts>
<marker>Woods, Bates, Brown, Bruce, Cook, Klovstad, Maldoul, Nash-Webber, Schwartz, Wolf, Zue, 1976</marker>
<rawString>Woods, W. A.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad, J.; Maldoul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and Zue, V. 1976 Speech Understanding Systems—Final Report. Technicd Report 3438, Volume 4, Bolt Beranek and Newman, Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Helen</author>
</authors>
<title>Gigley&apos; s areas of interest include computational linguistics and neurolinguistics, artificial intelligence and neurophysiology, and neural-based cognitive modeling. She received a Ph.D. in computer science</title>
<booktitle>in 1982 from the University of Massachusetts, Amherst. Gigley&apos;s address is National Science Foundation, 1800 G St., NW, Rm. 304, Washington, DC 20550. E-mail: hgigley@note.nsf.gov MACHINE TRANSLATION: PAST, PRESENT, FUTURE.</booktitle>
<marker>Helen, </marker>
<rawString>Helen Gigley&apos; s areas of interest include computational linguistics and neurolinguistics, artificial intelligence and neurophysiology, and neural-based cognitive modeling. She received a Ph.D. in computer science in 1982 from the University of Massachusetts, Amherst. Gigley&apos;s address is National Science Foundation, 1800 G St., NW, Rm. 304, Washington, DC 20550. E-mail: hgigley@note.nsf.gov MACHINE TRANSLATION: PAST, PRESENT, FUTURE.</rawString>
</citation>
<citation valid="false">
<booktitle>Anglia) (Ellis Horwood Series in Computers and their Applications)</booktitle>
<institution>William John Hutchins University of East</institution>
<marker></marker>
<rawString>William John Hutchins University of East Anglia) (Ellis Horwood Series in Computers and their Applications)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellis Horwood Chichester</author>
</authors>
<date>1986</date>
<pages>382--0</pages>
<marker>Chichester, 1986</marker>
<rawString>Ellis Horwood: Chichester, 1986, 382 pp. ISBN 0-85312-788-3, $49.95 (hb)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>