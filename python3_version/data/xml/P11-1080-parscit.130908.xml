<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000397">
<title confidence="0.996976">
Large-Scale Cross-Document Coreference Using
Distributed Inference and Hierarchical Models
</title>
<author confidence="0.970796">
Sameer Singh§ Amarnag Subramanya† Fernando Pereira† Andrew McCallum§
</author>
<affiliation confidence="0.7475405">
§ Department of Computer Science, University of Massachusetts, Amherst MA 01002
† Google Research, Mountain View CA 94043
</affiliation>
<email confidence="0.991665">
sameer@cs.umass.edu, asubram@google.com, pereira@google.com, mccallum@cs.umass.edu
</email>
<sectionHeader confidence="0.993835" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999573090909091">
Cross-document coreference, the task of
grouping all the mentions of each entity in a
document collection, arises in information ex-
traction and automated knowledge base con-
struction. For large collections, it is clearly
impractical to consider all possible groupings
of mentions into distinct entities. To solve
the problem we propose two ideas: (a) a dis-
tributed inference technique that uses paral-
lelism to enable large scale processing, and
(b) a hierarchical model of coreference that
represents uncertainty over multiple granular-
ities of entities to facilitate more effective ap-
proximate inference. To evaluate these ideas,
we constructed a labeled corpus of 1.5 million
disambiguated mentions in Web pages by se-
lecting link anchors referring to Wikipedia en-
tities. We show that the combination of the
hierarchical model with distributed inference
quickly obtains high accuracy (with error re-
duction of 38%) on this large dataset, demon-
strating the scalability of our approach.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999667489361702">
Given a collection of mentions of entities extracted
from a body of text, coreference or entity resolu-
tion consists of clustering the mentions such that
two mentions belong to the same cluster if and
only if they refer to the same entity. Solutions to
this problem are important in semantic analysis and
knowledge discovery tasks (Blume, 2005; Mayfield
et al., 2009). While significant progress has been
made in within-document coreference (Ng, 2005;
Culotta et al., 2007; Haghighi and Klein, 2007;
Bengston and Roth, 2008; Haghighi and Klein,
2009; Haghighi and Klein, 2010), the larger prob-
lem of cross-document coreference has not received
as much attention.
Unlike inference in other language processing
tasks that scales linearly in the size of the corpus,
the hypothesis space for coreference grows super-
exponentially with the number of mentions. Conse-
quently, most of the current approaches are devel-
oped on small datasets containing a few thousand
mentions. We believe that cross-document coref-
erence resolution is most useful when applied to a
very large set of documents, such as all the news ar-
ticles published during the last 20 years. Such a cor-
pus would have billions of mentions. In this paper
we propose a model and inference algorithms that
can scale the cross-document coreference problem
to corpora of that size.
Much of the previous work in cross-document
coreference (Bagga and Baldwin, 1998; Ravin and
Kazi, 1999; Gooi and Allan, 2004; Pedersen et al.,
2006; Rao et al., 2010) groups mentions into entities
with some form of greedy clustering using a pair-
wise mention similarity or distance function based
on mention text, context, and document-level statis-
tics. Such methods have not been shown to scale up,
and they cannot exploit cluster features that cannot
be expressed in terms of mention pairs. We provide
a detailed survey of related work in Section 6.
Other previous work attempts to address some of
the above concerns by mapping coreference to in-
ference on an undirected graphical model (Culotta
et al., 2007; Poon et al., 2008; Wellner et al., 2004;
Wick et al., 2009a). These models contain pair-
wise factors between all pairs of mentions captur-
ing similarity between them. Many of these mod-
els also enforce transitivity and enable features over
</bodyText>
<page confidence="0.982606">
793
</page>
<note confidence="0.985107">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figure confidence="0.990050857142857">
Running back
Filmmaker
Cornerback
Firefighter
Author
Rapper
Actor
</figure>
<bodyText confidence="0.3690122">
... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing...
...during the late 60&apos;s and early 70&apos;s, Kevin Smith worked with several local...
...the term hip-hop is attributed to Lovebug Starsli. What does it actually mean...
The filmmaker Kevin Smith returns to the role of Silent Bob...
Nothing could be more irrelevant to Kevin Smith&apos;s audacious &amp;quot;Dogma&amp;quot; than ticking off...
Firefighter Kevin Smith spent almost 20 years preparing for Sept. 11. When he...
Like Back in 2008, the Lions drafted Kevin Smith, even though Smith was badly...
...shorthanded backfield in the wake of Kevin Smith&apos;s knee injury, and the addition of Haynesworth...
...were coming,&amp;quot; said Dallas cornerback Kevin Smith. &amp;quot;We just didn&apos;t know when...
BEIJING, Feb. 21— Kevin Smith, who played the god of war in the &amp;quot;Rena&amp;quot;...
</bodyText>
<figureCaption confidence="0.9807595">
Figure 1: Cross-Document Coreference Problem: Example mentions of “Kevin Smith” from New York
Times articles, with the true entities shown on the right.
</figureCaption>
<bodyText confidence="0.99953031372549">
entities by including set-valued variables. Exact in-
ference in these models is intractable and a number
of approximate inference schemes (McCallum et al.,
2009; Rush et al., 2010; Martins et al., 2010) may
be used. In particular, Markov chain Monte Carlo
(MCMC) based inference has been found to work
well in practice. However as the number of men-
tions grows to Web scale, as in our problem of cross-
document coreference, even these inference tech-
niques become infeasible, motivating the need for
a scalable, parallelizable solution.
In this work we first distribute MCMC-based in-
ference for the graphical model representation of
coreference. Entities are distributed across the ma-
chines such that the parallel MCMC chains on the
different machines use only local proposal distribu-
tions. After a fixed number of samples on each ma-
chine, we redistribute the entities among machines
to enable proposals across entities that were pre-
viously on different machines. In comparison to
the greedy approaches used in related work, our
MCMC-based inference provides better robustness
properties.
As the number of mentions becomes large, high-
quality samples for MCMC become scarce. To
facilitate better proposals, we present a hierarchi-
cal model. We add sub-entity variables that repre-
sent clusters of similar mentions that are likely to
be coreferent; these are used to propose composite
jumps that move multiple mentions together. We
also introduce super-entity variables that represent
clusters of similar entities; these are used to dis-
tribute entities among the machines such that similar
entities are assigned to the same machine. These ad-
ditional levels of hierarchy dramatically increase the
probability of beneficial proposals even with a large
number of entities and mentions.
To create a large corpus for evaluation, we iden-
tify pages that have hyperlinks to Wikipedia, and ex-
tract the anchor text and the context around the link.
We treat the anchor text as the mention, the con-
text as the document, and the title of the Wikipedia
page as the entity label. Using this approach, 1.5
million mentions were annotated with 43k entity la-
bels. On this dataset, our proposed model yields a
B3 (Bagga and Baldwin, 1998) F1 score of 73.7%,
improving over the baseline by 16% absolute (corre-
sponding to 38% error reduction). Our experimen-
tal results also show that our proposed hierarchical
model converges much faster even though it contains
many more variables.
</bodyText>
<sectionHeader confidence="0.984198" genericHeader="method">
2 Cross-document Coreference
</sectionHeader>
<bodyText confidence="0.999864272727273">
The problem of coreference is to identify the sets of
mention strings that refer to the same underlying en-
tity. The identities and the number of the underlying
entities is not known. In within-document corefer-
ence, the mentions occur in a single document. The
number of mentions (and entities) in each document
is usually in the hundreds. The difficulty of the task
arises from a large hypothesis space (exponential in
the number of mentions) and challenge in resolv-
ing nominal and pronominal mentions to the correct
named mentions. In most cases, named mentions
</bodyText>
<page confidence="0.996699">
794
</page>
<bodyText confidence="0.999895695652174">
are not ambiguous within a document. In cross-
document coreference, the number of mentions and
entities is in the millions, making the combinatorics
even more daunting. Furthermore, naming ambigu-
ity is much more common as the same string can
refer to multiple entities in different documents, and
distinct strings may refer to the same entity in differ-
ent documents.
We show examples of ambiguities in Figure 1.
Resolving the identity of individuals with the same
name is a common problem in cross-document
coreference. This problem is further complicated
by the fact that in some situations, these individ-
uals may belong to the same field. Another com-
mon ambiguity is that of alternate names, in which
the same entity is referred to by different names or
aliases (e.g. “Bill” is often used as a substitute for
“William”). The figure also shows an example of
the renaming ambiguity – “Lovebug Starski” refers
to “Kevin Smith”, and this is an extreme form of al-
ternate names. Rare singleton entities (like the fire-
fighter) that may appear only once in the whole cor-
pus are also often difficult to isolate.
</bodyText>
<subsectionHeader confidence="0.976188">
2.1 Pairwise Factor Model
</subsectionHeader>
<bodyText confidence="0.9999693">
Factor graphs are a convenient representation for a
probability distribution over a vector of output vari-
ables given observed variables. The model that we
use for coreference represents mentions (M) and en-
tities (E) as random variables. Each mention can
take an entity as its value, and each entity takes a set
of mentions as its value. Each mention also has a
feature vector extracted from the observed text men-
tion and its context. More precisely, the probability
of a configuration E = e is defined by
</bodyText>
<equation confidence="0.9355355">
p(e) a exp Ee∈e {Em,n∈e,n�m ψa(m,n)
I+ Em∈e,n/∈e ψr(m, n)
</equation>
<bodyText confidence="0.986739916666667">
where factor ψa represents affinity between men-
tions that are coreferent according to e, and factor
ψr represents repulsion between mentions that are
not coreferent. Different factors are instantiated for
different predicted configurations. Figure 2 shows
the model instantiated with five mentions over a two-
entity hypothesis.
For the factor potentials, we use cosine sim-
ilarity of mention context pairs (φmn) such that
Figure 2: Pairwise Coreference Model: Factor
graph for a 2-entity configuration of 5 mentions.
Affinity factors are shown with solid lines, and re-
pulsion factors with dashed lines.
ψa(m, n) = φmn − b and ψr(m, n) = −(φmn − b),
where b is the bias. While one can certainly make
use of a more sophisticated feature set, we leave this
for future work as our focus is to scale up inference.
However, it should be noted that this approach is
agnostic to the particular set of features used. As
we will note in the next section, we do not need to
calculate features between all pairs of mentions (as
would be prohibitively expensive for large datasets);
instead we only compute the features as and when
required.
</bodyText>
<subsectionHeader confidence="0.990461">
2.2 MCMC-based Inference
</subsectionHeader>
<bodyText confidence="0.999678">
Given the above model of coreference, we seek the
maximum a posteriori (MAP) configuration:
</bodyText>
<equation confidence="0.901813333333333">
e� = arg maxe p(e)
arg maxe Ee∈e {Em,n∈e,n,�m ψa(m, n)
I+ Em∈e,n/∈e ψr(m, n)
</equation>
<bodyText confidence="0.998163142857143">
Computing e� exactly is intractable due to the
large space of possible configurations.1 Instead,
we employ MCMC-based optimization to discover
the MAP configuration. A proposal function q is
used to propose a change e0 to the current config-
uration e. This jump is accepted with the following
Metropolis-Hastings acceptance probability:
</bodyText>
<equation confidence="0.896179769230769">
p(e0)1/t q(e) (1)
p(e) ) q(e0)
1Number of possible entities is Bell(n) in the number of
mentions, i.e. number of partitions of n items
m1
m2
e1
m3
m4
e2
m5
1, (
α(e, e0) = min
</equation>
<page confidence="0.981781">
795
</page>
<bodyText confidence="0.998752384615385">
where t is the annealing temperature parameter.
MCMC chains efficiently explore the high-
density regions of the probability distribution. By
slowly reducing the temperature, we can decrease
the entropy of the distribution to encourage con-
vergence to the MAP configuration. MCMC has
been used for optimization in a number of related
work (McCallum et al., 2009; Goldwater and Grif-
fiths, 2007; Changhe et al., 2004).
The proposal function moves a randomly chosen
mention l from its current entity es to a randomly
chosen entity et. For such a proposal, the log-model
ratio is:
</bodyText>
<equation confidence="0.99579375">
log p(e0)
p(e)
�− 0a(l, n) − � 0r(l, m) (2)
n∈e3 m∈et
</equation>
<bodyText confidence="0.999960552631579">
Note that since only the factors between mention l
and mentions in es and et are involved in this com-
putation, the acceptance probability of each proposal
is calculated efficiently.
In general, the model may contain arbitrarily
complex set of features over pairs of mentions, with
parameters associated with them. Given labeled
data, these parameters can be learned by Percep-
tron (Collins, 2002), which uses the MAP config-
uration according to the model (e). There also exist
more efficient training algorithms such as SampleR-
ank (McCallum et al., 2009; Wick et al., 2009b) that
update parameters during inference. However, we
only focus on inference in this work, and the only
parameter that we set manually is the bias b, which
indirectly influences the number of entities in e. Un-
less specified otherwise, in this work the initial con-
figuration for MCMC is the singleton configuration,
i.e. all entities have a size of 1.
This MCMC inference technique, which has been
used in McCallum and Wellner (2004), offers sev-
eral advantages over other inference techniques: (a)
unlike message-passing-methods, it does not require
the full ground graph, (b) we only have to exam-
ine the factors that lie within the changed entities
to evaluate a proposal, and (c) inference may be
stopped at any point to obtain the current best con-
figuration. However, the super exponential nature of
the hypothesis space in cross-doc coreference ren-
ders this algorithm computationally unsuitable for
large scale coreference tasks. In particular, fruit-
ful proposals (that increase the model score) are ex-
tremely rare, resulting in a large number of propos-
als that are not accepted. We describe methods to
speed up inference by 1) evaluating multiple pro-
posal simultaneously (Section 3), and 2) by aug-
menting our model with hierarchical variables that
enable better proposal distributions (Section 4).
</bodyText>
<sectionHeader confidence="0.996659" genericHeader="method">
3 Distributed MAP Inference
</sectionHeader>
<bodyText confidence="0.997971864864865">
The key observation that enables distribution is that
the acceptance probability computation of a pro-
posal only examines a few factors that are not com-
mon to the previous and next configurations (Eq. 2).
Consider a pair of proposals, one that moves men-
tion l from entity es to entity et, and the other that
moves mention l0 from entity e0s to entity e0t. The
set of factors to compute acceptance of the first pro-
posal are factors between l and mentions in es and
et, while the set of factors required to compute ac-
ceptance of the second proposal lie between l0 and
mentions in e0s and e0t. Since these set of factors
are completely disjoint from each other, and the re-
sulting configurations do not depend on each other,
these two proposals are mutually-exclusive. Differ-
ent orders of evaluating such proposals are equiv-
alent, and in fact, these proposals can be proposed
and evaluated concurrently. This mutual-exclusivity
is not restricted only to pairs of proposals; a set of
proposals are mutually-exclusive if no two propos-
als require the same factor for evaluation.
Using this insight, we introduce the following ap-
proach to distributed cross-document coreference.
We divide the mentions and entities among multiple
machines, and propose moves of mentions between
entities assigned to the same machine. These jumps
are evaluated exactly and accepted without commu-
nication between machines. Since acceptance of a
mention’s move requires examining factors that lie
between other mentions in its entity, we ensure that
all mentions of an entity are assigned the same ma-
chine. Unless specified otherwise, the distribution is
performed randomly. To enable exploration of the
complete configuration space, rounds of sampling
are interleaved by redistribution stages, in which the
entities are redistributed among the machines (see
Figure 3). We use MapReduce (Dean and Ghe-
</bodyText>
<equation confidence="0.9161865">
�� 0a(l, m) + � 0r(l, n)
m∈et n∈e3
</equation>
<page confidence="0.979687">
796
</page>
<figureCaption confidence="0.996515">
Figure 3: Distributed MCMC-based Inference:
</figureCaption>
<bodyText confidence="0.9892411875">
Distributor divides the entities among the machines,
and the machines run inference. The process is re-
peated by the redistributing the entities.
mawat, 2004) to manage the distributed computa-
tion.
This approach to distribution is equivalent to in-
ference with all mentions and entities on a single
machine with a restricted proposer, but is faster
since it exploits independencies to propose multiple
jumps simultaneously. By restricting the jumps as
described above, the acceptance probability calcu-
lation is exact. Partitioning the entities and propos-
ing local jumps are restrictions to the single-machine
proposal distribution; redistribution stages ensure
the equivalent Markov chains are still irreducible.
See Singh et al. (2010) for more details.
</bodyText>
<sectionHeader confidence="0.999097" genericHeader="method">
4 Hierarchical Coreference Model
</sectionHeader>
<bodyText confidence="0.9999953125">
The proposal function for MCMC-based MAP infer-
ence presents changes to the current entities. Since
we use MCMC to reach high-scoring regions of the
hypothesis space, we are interested in the changes
that improve the current configuration. But as the
number of mentions and entities increases, these
fruitful samples become extremely rare due to the
blowup in the possible space of configurations, re-
sulting in rejection of a large number of proposals.
By distributing as described in the previous section,
we propose samples in parallel, improving chances
of finding changes that result in better configura-
tions. However, due to random redistribution and a
naive proposal function within each machine, a large
fraction of proposals are still wasted. We address
these concerns by adding hierarchy to the model.
</bodyText>
<subsectionHeader confidence="0.995734">
4.1 Sub-Entities
</subsectionHeader>
<bodyText confidence="0.999911304347826">
Consider the task of proposing moves of mentions
(within a machine). Given the large number of
mentions and entities, the probability that a ran-
domly picked mention that is moved to a random
entity results in a better configuration is extremely
small. If such a move is accepted, this gives us ev-
idence that the mention did not belong to the pre-
vious entity, and we should also move similar men-
tions from the previous entity simultaneously to the
same entity. Since the proposer moves only a sin-
gle mention at a time, a large number of samples
may be required to discover these fruitful moves.
To enable block proposals that move similar men-
tions simultaneously, we introduce latent sub-entity
variables that represent groups of similar mentions
within an entity, where the similarity is defined by
the model. For inference, we have stages of sam-
pling sub-entities (moving individual mentions) in-
terleaved with stages of entity sampling (moving all
mentions within a sub-entity). Even though our con-
figuration space has become larger due to these ex-
tra variables, the proposal distribution has also im-
proved since it proposes composite moves.
</bodyText>
<subsectionHeader confidence="0.994612">
4.2 Super-Entities
</subsectionHeader>
<bodyText confidence="0.999989882352941">
Another issue faced during distributed inference is
that random redistribution is often wasteful. For ex-
ample, if dissimilar entities are assigned to a ma-
chine, none of the proposals may be accepted. For a
large number of entities and machines, the probabil-
ity that similar entities will be assigned to the same
machine is extremely small, leading to a larger num-
ber of wasted proposals. To alleviate this problem,
we introduce super-entities that represent groups of
similar entities. During redistribution, we ensure all
entities in the same super-entity are assigned to the
same machine. As for sub-entities above, inference
switches between regular sampling of entities and
sampling of super-entities (by moving entities). Al-
though these extra variables have made the config-
uration space larger, they also allow more efficient
distribution of entities, leading to useful proposals.
</bodyText>
<subsectionHeader confidence="0.992148">
4.3 Combined Hierarchical Model
</subsectionHeader>
<bodyText confidence="0.999794">
Each of the described levels of the hierarchy are sim-
ilar to the initial model (Section 2.1): mentions/sub-
entities have the same structure as the entities/super-
entities, and are modeled using similar factors. To
represent the “context” of a sub-entity we take the
union of the bags-of-words of the constituent men-
tion contexts. Similarly, we take the union of sub-
</bodyText>
<figure confidence="0.8769135">
Distributor
Inference
Inference
797
</figure>
<figureCaption confidence="0.99909075">
Figure 4: Combined Hierarchical Model with factors instantiated for a hypothesis containing 2 super-
entities, 4 entities, and 8 sub-entities, shown as colored circles, over 16 mentions. Dotted lines represent
repulsion factors and solid lines represent affinity factors (the color denotes the type of variable that the
factor touches). The boxes on factors were excluded for clarity.
</figureCaption>
<figure confidence="0.969447">
Super-Entities
Entities
Sub-Entities
Mentions
</figure>
<bodyText confidence="0.997898333333334">
entity contexts to represent the context of an entity.
The factors are instantiated in the same manner as
Section 2.1 except that we change the bias factor
b for each level (increasing it for sub-entities, and
decreasing it for super-entities). The exact values
of these biases indirectly determines the number of
predicted sub-entities and super-entities.
Since these two levels of hierarchy operate at
separate granularities from each other, we combine
them into a single hierarchical model that contains
both sub- and super-entities. We illustrate this hi-
erarchical structure in Figure 4. Inference for this
model takes a round-robin approach by fixing two
of the levels of the hierarchy and sampling the third,
cycling through these three levels. Unless specified
otherwise, the initial configuration is the singleton
configuration, in which all sub-entities, entities, and
super-entities are of size 1.
</bodyText>
<sectionHeader confidence="0.999611" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999845333333333">
We evaluate our models and algorithms on a number
of datasets. First, we compare performance on the
small, publicly-available “John Smith” dataset. Sec-
ond, we run the automated Person-X evaluation to
obtain thousands of mentions that we use to demon-
strate accuracy and scalability improvements. Most
importantly, we create a large labeled corpus using
links to Wikipedia to explore the performance in the
large-scale setting.
</bodyText>
<subsectionHeader confidence="0.995577">
5.1 John Smith Corpus
</subsectionHeader>
<bodyText confidence="0.999958375">
To compare with related work, we run an evalua-
tion on the “John Smith” corpus (Bagga and Bald-
win, 1998), containing 197 mentions of the name
“John Smith” from New York Times articles (la-
beled to obtain 35 true entities). The bias b for
our approach is set to result in the correct number
of entities. Our model achieves B3 F1 accuracy of
66.4% on this dataset. In comparison, Rao et al.
(2010) obtains 61.8% using the model most similar
to ours, while their best model (which uses sophis-
ticated topic-model features that do not scale easily)
achieves 69.7%. It is encouraging to note that our
approach, using only a subset of the features, per-
forms competitively with related work. However,
due to the small size of the dataset, we require fur-
ther evaluation before reaching any conclusions.
</bodyText>
<subsectionHeader confidence="0.969571">
5.2 Person-X Evaluation
</subsectionHeader>
<bodyText confidence="0.999976941176471">
There is a severe lack of labeled corpora for cross-
document coreference due to the effort required
to evaluate the coreference decisions. Related
approaches have used automated Person-X evalu-
ation (Gooi and Allan, 2004), in which unique
person-name strings are treated as the true entity
labels for the mentions. Every mention string is
replaced with an “X” for the coreference system.
We use this evaluation methodology on 25k person-
name mentions from the New York Times cor-
pus (Sandhaus, 2008) each with one of 50 unique
strings. As before, we set the bias b to achieve the
same number of entities. We use 1 million samples
in each round of inference, followed by random re-
distribution in the flat model, and super-entities in
the hierarchical model. Results are averaged over
five runs.
</bodyText>
<page confidence="0.99704">
798
</page>
<figureCaption confidence="0.996946333333333">
Figure 5: Person-X Evaluation of Pairwise model:
Performance as number of machines is varied, aver-
aged over 5 runs.
</figureCaption>
<table confidence="0.995703">
Number of Entities 43,928
Number of Mentions 1,567,028
Size of Largest Entity 6,096
Average Mentions per Entity 35.7
Variance of Mentions per Entity 5191.7
</table>
<tableCaption confidence="0.9984">
Table 1: Wikipedia Link Corpus Statistics. Size
</tableCaption>
<bodyText confidence="0.970337875">
of an entity is the number of mentions of that entity.
Figure 5 shows accuracy compared to relative
wallclock running time for distributed inference on
the flat, pairwise model. Speed and accuracy im-
prove as additional machines are added, but larger
number of machines lead to diminishing returns for
this small dataset. Distributed inference on our hi-
erarchical model is evaluated in Figure 6 against in-
ference on the pairwise model from Figure 5. We
see that the individual hierarchical models perform
much better than the pairwise model; they achieve
the same accuracy as the pairwise model in approx-
imately 10% of the time. Moreover, distributed in-
ference on the combined hierarchical model is both
faster and more accurate than the individual hierar-
chical models.
</bodyText>
<subsectionHeader confidence="0.987037">
5.3 Wikipedia Link Corpus
</subsectionHeader>
<bodyText confidence="0.999904166666667">
To explore the application of the proposed approach
to a larger, realistic dataset, we construct a corpus
based on the insight that links to Wikipedia that ap-
pear on webpages can be treated as mentions, and
since the links were added manually by the page au-
thor, we use the destination Wikipedia page as the
</bodyText>
<figureCaption confidence="0.7855445">
Figure 6: Person-X Evaluation of Hierarchical
Models: Performance of inference on hierarchical
models compared to the pairwise model. Experi-
ments were run using 50 machines.
</figureCaption>
<bodyText confidence="0.998134">
entity the link refers to.
The dataset is created as follows: First, we crawl
the web and select hyperlinks on webpages that link
to an English Wikipedia page.2 The anchors of
these links form our set of mentions, with the sur-
rounding block of clean text (obtained after remov-
ing markup, etc.) around each link being its con-
text. We assign the title of the linked Wikipedia
page as the entity label of that link. Since this set
of mentions and labels can be noisy, we use the
following filtering steps. All links that have less
than 36 words in their block, or whose anchor text
has a large string edit distance from the title of the
Wikipedia page, are discarded. While this results in
cases in which “President” is discarded when linked
to the “Barack Obama” Wikipedia page, it was nec-
essary to reduce noise. Further, we also discard
links to Wikipedia pages that are concepts (such as
“public_domain”) rather than entities. All enti-
ties with less than 6 links to them are also discarded.
Table 1 shows some statistics about our automat-
ically generated data set. We randomly sampled 5%
of the entities to create a development set, treating
the remaining entities as the test set. Unlike the
John Smith and Person-X evaluation, this data set
also contains non-person entities such as organiza-
tions and locations.
For our models, we augment the factor potentials
with mention-string similarity:
</bodyText>
<footnote confidence="0.911365">
2e.g. http://en.wikipedia.org/Hillary_Clinton
</footnote>
<page confidence="0.985849">
799
</page>
<equation confidence="0.438918">
&apos;Ya/r(m, n) = f (O,,,n − b + wSTREQ(m, n))
</equation>
<bodyText confidence="0.9923237">
where STREQ is 1 if mentions m and n are string
identical (0 otherwise), and w is the weight to this
feature.3 In our experiments we found that setting
w = 0.8 and b = 1e − 4 gave the best results on the
development set.
Due to the large size of the corpus, existing cross-
document coreference approaches could not be ap-
plied to this dataset. However, since a majority
of related work consists of using clustering after
defining a similarity function (Section 6), we pro-
vide a baseline evaluation of clustering with Sub-
Square (Bshouty and Long, 2010), a scalable, dis-
tributed clustering method. Subsquare takes as in-
put a weighted graph with mentions as nodes and
similarity between mentions used as edge weights.
Subsquare works by stochastically assigning a ver-
tex to the cluster of one its neighbors if they have
significant neighborhood overlap. This algorithm
is an efficient form of approximate spectral cluster-
ing (Bshouty and Long, 2010), and since it is given
the same distances between mentions as our models,
we expect it to get similar accuracy. We also gen-
erate another baseline clustering by assigning men-
tions with identical strings to the same entity. This
mention-string clustering is also used as the initial
configuration of our inference.
Figure 7: Wikipedia Link Evaluation: Perfor-
mance of inference for different number of machines
(N = 100, 500). Mention-string match clustering is
used as the initial configuration.
</bodyText>
<footnote confidence="0.671745">
3Note that we do not use mention-string similarity for John
Smith or Person-X as the mention strings are all identical.
</footnote>
<table confidence="0.9997956">
Method Pairwise B3 Score
P/ R F1 P/ R F1
String-Match 30.0 / 66.7 41.5 82.7 / 43.8 57.3
Subsquare 38.2 / 49.1 43.0 87.6 / 51.4 64.8
Our Model 44.2 / 61.4 51.4 89.4 / 62.5 73.7
</table>
<tableCaption confidence="0.976569">
Table 2: F1 Scores on the Wikipedia Link Data.
</tableCaption>
<bodyText confidence="0.999502461538462">
The results are significant at the 0.0001 level over
Subsquare according to the difference of proportions
significance test.
Inference is run for 20 rounds of 10 million sam-
ples each, distributed over N machines. We use
N = 100, 500 and the B3 F1 score results obtained
set for each case are shown in Figure 7. It can
be seen that N = 500 converges to a better solu-
tion faster, showing effective use of parallelism. Ta-
ble 2 compares the results of our approach (at con-
vergence for N = 500), the baseline mention-string
match and the Subsquare algorithm. Our approach
significantly outperforms the competitors.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.99996252">
Although the cross-document coreference problem
is challenging and lacks large labeled datasets, its
ubiquitous role as a key component of many knowl-
edge discovery tasks has inspired several efforts.
A number of previous techniques use scoring
functions between pairs of contexts, which are then
used for clustering. One of the first approaches
to cross-document coreference (Bagga and Bald-
win, 1998) uses an idf-based cosine-distance scor-
ing function for pairs of contexts, similar to the one
we use. Ravin and Kazi (1999) extend this work to
be somewhat scalable by comparing pairs of con-
texts only if the mentions are deemed “ambiguous”
using a heuristic. Others have explored multiple
methods of context similarity, and concluded that
agglomerative clustering provides effective means
of inference (Gooi and Allan, 2004). Pedersen et
al. (2006) and Purandare and Pedersen (2004) inte-
grate second-order co-occurrence of words into the
similarity function. Mann and Yarowsky (2003) use
biographical facts from the Web as features for clus-
tering. Niu et al. (2004) incorporate information ex-
traction into the context similarity model, and anno-
tate a small dataset to learn the parameters. A num-
ber of other approaches include various forms of
</bodyText>
<page confidence="0.986344">
800
</page>
<bodyText confidence="0.999924604166667">
hand-tuned weights, dictionaries, and heuristics to
define similarity for name disambiguation (Blume,
2005; Baron and Freedman, 2008; Popescu et al.,
2008). These approaches are greedy and differ in the
choice of the distance function and the clustering al-
gorithm used. Daum´e III and Marcu (2005) propose
a generative approach to supervised clustering, and
Haghighi and Klein (2010) use entity profiles to as-
sist within-document coreference.
Since many related methods use clustering, there
are a number of distributed clustering algorithms
that may help scale these approaches. Datta et
al. (2006) propose an algorithm for distributed k-
means. Chen et al. (2010) describe a parallel spectral
clustering algorithm. We use the Subsquare algo-
rithm (Bshouty and Long, 2010) as baseline because
it works well in practice. Mocian (2009) presents a
survey of distributed clustering algorithms.
Rao et al. (2010) have proposed an online deter-
ministic method that uses a stream of input mentions
and assigns them greedily to entities. Although it
can resolve mentions from non-trivial sized datasets,
the method is restricted to a single machine, which
is not scalable to the very large number of mentions
that are encountered in practice.
Our representation of the problem as an undi-
rected graphical model, and performing distributed
inference on it, provides a combination of advan-
tages not available in any of these approaches. First,
most of the methods will not scale to the hundreds
of millions of mentions that are present in real-world
applications. By utilizing parallelism across ma-
chines, our method can run on very large datasets
simply by increasing the number of machines used.
Second, approaches that use clustering are limited
to using pairwise distance functions for which ad-
ditional supervision and features are difficult to in-
corporate. In addition to representing features from
all of the related work, graphical models can also
use more complex entity-wide features (Culotta et
al., 2007; Wick et al., 2009a), and parameters can
be learned using supervised (Collins, 2002) or semi-
supervised techniques (Mann and McCallum, 2008).
Finally, the inference for most of the related ap-
proaches is greedy, and earlier decisions are not re-
visited. Our technique is based on MCMC inference
and simulated annealing, which are able to escape
local maxima.
</bodyText>
<sectionHeader confidence="0.998728" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999867">
Motivated by the problem of solving the corefer-
ence problem on billions of mentions from all of the
newswire documents from the past few decades, we
make the following contributions. First, we intro-
duce distributed version of MCMC-based inference
technique that can utilize parallelism to enable scal-
ability. Second, we augment the model with hierar-
chical variables that facilitate fruitful proposal distri-
butions. As an additional contribution, we use links
to Wikipedia pages to obtain a high-quality cross-
document corpus. Scalability and accuracy gains of
our method are evaluated on multiple datasets.
There are a number of avenues for future work.
Although we demonstrate scalability to more than a
million mentions, we plan to explore performance
on datasets in the billions. We also plan to examine
inference on complex coreference models (such as
with entity-wide factors). Another possible avenue
for future work is that of learning the factors. Since
our approach supports parameter estimation, we ex-
pect significant accuracy gains with additional fea-
tures and supervised data. Our work enables cross-
document coreference on very large corpora, and we
would like to explore the downstream applications
that can benefit from it.
</bodyText>
<sectionHeader confidence="0.997644" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999945368421053">
This work was done when the first author was an
intern at Google Research. The authors would
like to thank Mark Dredze, Sebastian Riedel, and
anonymous reviewers for their valuable feedback.
This work was supported in part by the Center
for Intelligent Information Retrieval, the Univer-
sity of Massachusetts gratefully acknowledges the
support of Defense Advanced Research Projects
Agency (DARPA) Machine Reading Program under
Air Force Research Laboratory (AFRL) prime con-
tract no. FA8750-09-C-0181., in part by an award
from Google, in part by The Central Intelligence
Agency, the National Security Agency and National
Science Foundation under NSF grant #IIS-0326249,
in part by NSF grant #CNS-0958392, and in part
by UPenn NSF medium IIS-0803847. Any opin-
ions, findings and conclusions or recommendations
expressed in this material are those of the authors
and do not necessarily reflect those of the sponsor.
</bodyText>
<page confidence="0.996995">
801
</page>
<sectionHeader confidence="0.990129" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998871914285714">
Amit Bagga and Breck Baldwin. 1998. Entity-based
cross-document coreferencing using the vector space
model. In International Conference on Computational
Linguistics, pages 79–85.
A. Baron and M. Freedman. 2008. Who is who and what
is what: experiments in cross-document co-reference.
In Empirical Methods in Natural Language Process-
ing (EMNLP), pages 274–283.
Eric Bengston and Dan Roth. 2008. Understanding
the value of features for coreference resolution. In
Empirical Methods in Natural Language Processing
(EMNLP).
Matthias Blume. 2005. Automatic entity disambigua-
tion: Benefits to NER, relation extraction, link anal-
ysis, and inference. In International Conference on
Intelligence Analysis (ICIA).
Nader H. Bshouty and Philip M. Long. 2010. Find-
ing planted partitions in nearly linear time using ar-
rested spectral clustering. In Johannes F¨urnkranz
and Thorsten Joachims, editors, Proceedings of the
27th International Conference on Machine Learning
(ICML-10), pages 135–142, Haifa, Israel, June. Omni-
press.
Yuan Changhe, Lu Tsai-Ching, and Druzdzel Marek.
2004. Annealed MAP. In Uncertainty in Artificial In-
telligence (UAI), pages 628–635, Arlington, Virginia.
AUAI Press.
Wen-Yen Chen, Yangqiu Song, Hongjie Bai, Chih-Jen
Lin, and Edward Y. Chang. 2010. Parallel spectral
clustering in distributed systems. IEEE Transactions
on Pattern Analysis and Machine Intelligence.
Michael Collins. 2002. Discriminative training methods
for hidden markov models: Theory and experiments
with perceptron algorithm. In Annual Meeting of the
Association for Computational Linguistics (ACL).
Aron Culotta, Michael Wick, and Andrew McCallum.
2007. First-order probabilistic models for coreference
resolution. In North American Chapter of the Associa-
tion for Computational Linguistics - Human Language
Technologies (NAACL HLT).
S. Datta, C. Giannella, and H. Kargupta. 2006. K-Means
Clustering over a Large, Dynamic Network. In SIAM
Data Mining Conference (SDM).
Hal Daum´e III and Daniel Marcu. 2005. A Bayesian
model for supervised clustering with the Dirichlet pro-
cess prior. Journal of Machine Learning Research
(JMLR), 6:1551–1577.
Jeffrey Dean and Sanjay Ghemawat. 2004. Mapreduce:
Simplified data processing on large clusters. Sympo-
sium on Operating Systems Design &amp; Implementation
(OSDI).
Sharon Goldwater and Tom Griffiths. 2007. A fully
bayesian approach to unsupervised part-of-speech tag-
ging. In Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 744–751.
Chung Heong Gooi and James Allan. 2004. Cross-
document coreference on a large scale corpus. In
North American Chapter of the Association for Com-
putational Linguistics - Human Language Technolo-
gies (NAACL HLT), pages 9–16.
Aria Haghighi and Dan Klein. 2007. Unsupervised
coreference resolution in a nonparametric bayesian
model. In Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 848–855.
Aria Haghighi and Dan Klein. 2009. Simple coreference
resolution with rich syntactic and semantic features. In
Empirical Methods in Natural Language Processing
(EMNLP), pages 1152–1161.
Aria Haghighi and Dan Klein. 2010. Coreference reso-
lution in a modular, entity-centered model. In North
American Chapter of the Association for Computa-
tional Linguistics - Human Language Technologies
(NAACL HLT), pages 385–393.
Gideon S. Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learning
of conditional random fields. In Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 870–878.
Gideon S. Mann and David Yarowsky. 2003. Unsuper-
vised personal name disambiguation. In North Amer-
ican Chapter of the Association for Computational
Linguistics - Human Language Technologies (NAACL
HLT), pages 33–40.
Andre Martins, Noah Smith, Eric Xing, Pedro Aguiar,
and Mario Figueiredo. 2010. Turbo parsers: Depen-
dency parsing by approximate variational inference.
In Empirical Methods in Natural Language Process-
ing (EMNLP), pages 34–44, Cambridge, MA, October.
Association for Computational Linguistics.
J. Mayfield, D. Alexander, B. Dorr, J. Eisner, T. Elsayed,
T. Finin, C. Fink, M. Freedman, N. Garera, P. Mc-
Namee, et al. 2009. Cross-document coreference res-
olution: A key technology for learning by reading. In
AAAI Spring Symposium on Learning by Reading and
Learning to Read.
Andrew McCallum and Ben Wellner. 2004. Conditional
models of identity uncertainty with application to noun
coreference. In Neural Information Processing Sys-
tems (NIPS).
Andrew McCallum, Karl Schultz, and Sameer Singh.
2009. FACTORIE: Probabilistic programming via im-
peratively defined factor graphs. In Neural Informa-
tion Processing Systems (NIPS).
Horatiu Mocian. 2009. Survey of Distributed Clustering
Techniques. Ph.D. thesis, Imperial College of London.
</reference>
<page confidence="0.979401">
802
</page>
<reference confidence="0.999884208955224">
Vincent Ng. 2005. Machine learning for coreference res-
olution: From local classification to global ranking. In
Annual Meeting of the Association for Computational
Linguistics (ACL).
Cheng Niu, Wei Li, and Rohini K. Srihari. 2004. Weakly
supervised learning for cross-document person name
disambiguation supported by information extraction.
In Annual Meeting of the Association for Computa-
tional Linguistics (ACL), page 597.
Ted Pedersen, Anagha Kulkarni, Roxana Angheluta, Zor-
nitsa Kozareva, and Thamar Solorio. 2006. An
unsupervised language independent method of name
discrimination using second order co-occurrence fea-
tures. In International Conference on Intelligent Text
Processing and Computational Linguistics (CICLing),
pages 208–222.
Hoifung Poon, Pedro Domingos, and Marc Sumner.
2008. A general method for reducing the complexity
of relational inference and its application to MCMC.
In AAAI Conference on Artificial Intelligence.
Octavian Popescu, Christian Girardi, Emanuele Pianta,
and Bernardo Magnini. 2008. Improving cross-
document coreference. Journ´ees Internationales
d’Analyse statistique des Donn´ees Textuelles, 9:961–
969.
A. Purandare and T. Pedersen. 2004. Word sense dis-
crimination by clustering contexts in vector and simi-
larity spaces. In Conference on Computational Natu-
ral Language Learning (CoNLL), pages 41–48.
Delip Rao, Paul McNamee, and Mark Dredze. 2010.
Streaming cross document entity coreference reso-
lution. In International Conference on Computa-
tional Linguistics (COLING), pages 1050–1058, Bei-
jing, China, August. Coling 2010 Organizing Commit-
tee.
Yael Ravin and Zunaid Kazi. 1999. Is Hillary Rodham
Clinton the president? disambiguating names across
documents. In Annual Meeting of the Association for
Computational Linguistics (ACL), pages 9–16.
Alexander M Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 1–11, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Evan Sandhaus. 2008. The New York Times annotated
corpus. Linguistic Data Consortium.
Sameer Singh, Amarnag Subramanya, Fernando Pereira,
and Andrew McCallum. 2010. Distributed map in-
ference for undirected graphical models. In Neural
Information Processing Systems (NIPS), Workshop on
Learning on Cores, Clusters and Clouds.
Ben Wellner, Andrew McCallum, Fuchun Peng, and
Michael Hay. 2004. An integrated, conditional model
of information extraction and coreference with appli-
cation to citation matching. In Uncertainty in Artificial
Intelligence (UAI), pages 593–601.
Michael Wick, Aron Culotta, Khashayar Rohanimanesh,
and Andrew McCallum. 2009a. An entity-based
model for coreference resolution. In SIAM Interna-
tional Conference on Data Mining (SDM).
Michael Wick, Khashayar Rohanimanesh, Aron Culotta,
and Andrew McCallum. 2009b. Samplerank: Learn-
ing preferences from atomic gradients. In Neural In-
formation Processing Systems (NIPS), Workshop on
Advances in Ranking.
</reference>
<page confidence="0.999161">
803
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946232">
<title confidence="0.994417">Large-Scale Cross-Document Coreference Distributed Inference and Hierarchical Models</title>
<author confidence="0.999579">Amarnag Fernando Andrew</author>
<affiliation confidence="0.982542">of Computer Science, University of Massachusetts, Amherst MA</affiliation>
<address confidence="0.998705">Research, Mountain View CA 94043</address>
<email confidence="0.999554">sameer@cs.umass.edu,asubram@google.com,pereira@google.com,mccallum@cs.umass.edu</email>
<abstract confidence="0.998867782608696">Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve problem we propose two ideas: (a) a distechnique that uses parallelism to enable large scale processing, and a of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, constructed a labeled corpus of disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reof on this large dataset, demonstrating the scalability of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Entity-based cross-document coreferencing using the vector space model.</title>
<date>1998</date>
<booktitle>In International Conference on Computational Linguistics,</booktitle>
<pages>79--85</pages>
<contexts>
<context position="2784" citStr="Bagga and Baldwin, 1998" startWordPosition="415" endWordPosition="418">reference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have billions of mentions. In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical</context>
<context position="7105" citStr="Bagga and Baldwin, 1998" startWordPosition="1103" endWordPosition="1106">ies are assigned to the same machine. These additional levels of hierarchy dramatically increase the probability of beneficial proposals even with a large number of entities and mentions. To create a large corpus for evaluation, we identify pages that have hyperlinks to Wikipedia, and extract the anchor text and the context around the link. We treat the anchor text as the mention, the context as the document, and the title of the Wikipedia page as the entity label. Using this approach, 1.5 million mentions were annotated with 43k entity labels. On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction). Our experimental results also show that our proposed hierarchical model converges much faster even though it contains many more variables. 2 Cross-document Coreference The problem of coreference is to identify the sets of mention strings that refer to the same underlying entity. The identities and the number of the underlying entities is not known. In within-document coreference, the mentions occur in a single document. The number of mentions (and entities) in each document is usually in the</context>
<context position="21953" citStr="Bagga and Baldwin, 1998" startWordPosition="3494" endWordPosition="3498"> sub-entities, entities, and super-entities are of size 1. 5 Experiments We evaluate our models and algorithms on a number of datasets. First, we compare performance on the small, publicly-available “John Smith” dataset. Second, we run the automated Person-X evaluation to obtain thousands of mentions that we use to demonstrate accuracy and scalability improvements. Most importantly, we create a large labeled corpus using links to Wikipedia to explore the performance in the large-scale setting. 5.1 John Smith Corpus To compare with related work, we run an evaluation on the “John Smith” corpus (Bagga and Baldwin, 1998), containing 197 mentions of the name “John Smith” from New York Times articles (labeled to obtain 35 true entities). The bias b for our approach is set to result in the correct number of entities. Our model achieves B3 F1 accuracy of 66.4% on this dataset. In comparison, Rao et al. (2010) obtains 61.8% using the model most similar to ours, while their best model (which uses sophisticated topic-model features that do not scale easily) achieves 69.7%. It is encouraging to note that our approach, using only a subset of the features, performs competitively with related work. However, due to the s</context>
<context position="29352" citStr="Bagga and Baldwin, 1998" startWordPosition="4735" endWordPosition="4739">f parallelism. Table 2 compares the results of our approach (at convergence for N = 500), the baseline mention-string match and the Subsquare algorithm. Our approach significantly outperforms the competitors. 6 Related Work Although the cross-document coreference problem is challenging and lacks large labeled datasets, its ubiquitous role as a key component of many knowledge discovery tasks has inspired several efforts. A number of previous techniques use scoring functions between pairs of contexts, which are then used for clustering. One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Entity-based cross-document coreferencing using the vector space model. In International Conference on Computational Linguistics, pages 79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Baron</author>
<author>M Freedman</author>
</authors>
<title>Who is who and what is what: experiments in cross-document co-reference.</title>
<date>2008</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>274--283</pages>
<contexts>
<context position="30332" citStr="Baron and Freedman, 2008" startWordPosition="4887" endWordPosition="4890">stering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsqu</context>
</contexts>
<marker>Baron, Freedman, 2008</marker>
<rawString>A. Baron and M. Freedman. 2008. Who is who and what is what: experiments in cross-document co-reference. In Empirical Methods in Natural Language Processing (EMNLP), pages 274–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Bengston</author>
<author>Dan Roth</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1894" citStr="Bengston and Roth, 2008" startWordPosition="272" endWordPosition="275">duction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published </context>
</contexts>
<marker>Bengston, Roth, 2008</marker>
<rawString>Eric Bengston and Dan Roth. 2008. Understanding the value of features for coreference resolution. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Blume</author>
</authors>
<title>Automatic entity disambiguation: Benefits to NER, relation extraction, link analysis, and inference.</title>
<date>2005</date>
<booktitle>In International Conference on Intelligence Analysis (ICIA).</booktitle>
<contexts>
<context position="1714" citStr="Blume, 2005" startWordPosition="247" endWordPosition="248"> anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a</context>
<context position="30306" citStr="Blume, 2005" startWordPosition="4885" endWordPosition="4886">omerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering al</context>
</contexts>
<marker>Blume, 2005</marker>
<rawString>Matthias Blume. 2005. Automatic entity disambiguation: Benefits to NER, relation extraction, link analysis, and inference. In International Conference on Intelligence Analysis (ICIA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nader H Bshouty</author>
<author>Philip M Long</author>
</authors>
<title>Finding planted partitions in nearly linear time using arrested spectral clustering.</title>
<date>2010</date>
<booktitle>In Johannes F¨urnkranz and Thorsten Joachims, editors, Proceedings of the 27th International Conference on Machine Learning (ICML-10),</booktitle>
<pages>135--142</pages>
<publisher>Omnipress.</publisher>
<location>Haifa, Israel,</location>
<contexts>
<context position="27094" citStr="Bshouty and Long, 2010" startWordPosition="4360" endWordPosition="4363">ipedia.org/Hillary_Clinton 799 &apos;Ya/r(m, n) = f (O,,,n − b + wSTREQ(m, n)) where STREQ is 1 if mentions m and n are string identical (0 otherwise), and w is the weight to this feature.3 In our experiments we found that setting w = 0.8 and b = 1e − 4 gave the best results on the development set. Due to the large size of the corpus, existing crossdocument coreference approaches could not be applied to this dataset. However, since a majority of related work consists of using clustering after defining a similarity function (Section 6), we provide a baseline evaluation of clustering with SubSquare (Bshouty and Long, 2010), a scalable, distributed clustering method. Subsquare takes as input a weighted graph with mentions as nodes and similarity between mentions used as edge weights. Subsquare works by stochastically assigning a vertex to the cluster of one its neighbors if they have significant neighborhood overlap. This algorithm is an efficient form of approximate spectral clustering (Bshouty and Long, 2010), and since it is given the same distances between mentions as our models, we expect it to get similar accuracy. We also generate another baseline clustering by assigning mentions with identical strings to</context>
<context position="30970" citStr="Bshouty and Long, 2010" startWordPosition="4986" endWordPosition="4989">., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which is not scalable to the very large number of mentions that are encountered in practice. Our representation of the problem as an undirected graphical model, and performing distributed inference on it, provides a combination of </context>
</contexts>
<marker>Bshouty, Long, 2010</marker>
<rawString>Nader H. Bshouty and Philip M. Long. 2010. Finding planted partitions in nearly linear time using arrested spectral clustering. In Johannes F¨urnkranz and Thorsten Joachims, editors, Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 135–142, Haifa, Israel, June. Omnipress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Changhe</author>
<author>Lu Tsai-Ching</author>
<author>Druzdzel Marek</author>
</authors>
<title>Annealed MAP.</title>
<date>2004</date>
<booktitle>In Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>628--635</pages>
<publisher>AUAI Press.</publisher>
<location>Arlington, Virginia.</location>
<contexts>
<context position="11886" citStr="Changhe et al., 2004" startWordPosition="1900" endWordPosition="1903">ings acceptance probability: p(e0)1/t q(e) (1) p(e) ) q(e0) 1Number of possible entities is Bell(n) in the number of mentions, i.e. number of partitions of n items m1 m2 e1 m3 m4 e2 m5 1, ( α(e, e0) = min 795 where t is the annealing temperature parameter. MCMC chains efficiently explore the highdensity regions of the probability distribution. By slowly reducing the temperature, we can decrease the entropy of the distribution to encourage convergence to the MAP configuration. MCMC has been used for optimization in a number of related work (McCallum et al., 2009; Goldwater and Griffiths, 2007; Changhe et al., 2004). The proposal function moves a randomly chosen mention l from its current entity es to a randomly chosen entity et. For such a proposal, the log-model ratio is: log p(e0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled data, these parameters can be learned by Perceptron (Col</context>
</contexts>
<marker>Changhe, Tsai-Ching, Marek, 2004</marker>
<rawString>Yuan Changhe, Lu Tsai-Ching, and Druzdzel Marek. 2004. Annealed MAP. In Uncertainty in Artificial Intelligence (UAI), pages 628–635, Arlington, Virginia. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-Yen Chen</author>
<author>Yangqiu Song</author>
<author>Hongjie Bai</author>
<author>Chih-Jen Lin</author>
<author>Edward Y Chang</author>
</authors>
<title>Parallel spectral clustering in distributed systems.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence.</journal>
<contexts>
<context position="30863" citStr="Chen et al. (2010)" startWordPosition="4970" endWordPosition="4973">ics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which is not scalable to the very large number of mentions that are encountered in practice. Our representation of the probl</context>
</contexts>
<marker>Chen, Song, Bai, Lin, Chang, 2010</marker>
<rawString>Wen-Yen Chen, Yangqiu Song, Hongjie Bai, Chih-Jen Lin, and Edward Y. Chang. 2010. Parallel spectral clustering in distributed systems. IEEE Transactions on Pattern Analysis and Machine Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithm.</title>
<date>2002</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="12497" citStr="Collins, 2002" startWordPosition="2006" endWordPosition="2007">04). The proposal function moves a randomly chosen mention l from its current entity es to a randomly chosen entity et. For such a proposal, the log-model ratio is: log p(e0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled data, these parameters can be learned by Perceptron (Collins, 2002), which uses the MAP configuration according to the model (e). There also exist more efficient training algorithms such as SampleRank (McCallum et al., 2009; Wick et al., 2009b) that update parameters during inference. However, we only focus on inference in this work, and the only parameter that we set manually is the bias b, which indirectly influences the number of entities in e. Unless specified otherwise, in this work the initial configuration for MCMC is the singleton configuration, i.e. all entities have a size of 1. This MCMC inference technique, which has been used in McCallum and Well</context>
<context position="32285" citStr="Collins, 2002" startWordPosition="5196" endWordPosition="5197"> hundreds of millions of mentions that are present in real-world applications. By utilizing parallelism across machines, our method can run on very large datasets simply by increasing the number of machines used. Second, approaches that use clustering are limited to using pairwise distance functions for which additional supervision and features are difficult to incorporate. In addition to representing features from all of the related work, graphical models can also use more complex entity-wide features (Culotta et al., 2007; Wick et al., 2009a), and parameters can be learned using supervised (Collins, 2002) or semisupervised techniques (Mann and McCallum, 2008). Finally, the inference for most of the related approaches is greedy, and earlier decisions are not revisited. Our technique is based on MCMC inference and simulated annealing, which are able to escape local maxima. 7 Conclusions Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. First, we introduce distributed version of MCMC-based inference technique that can utilize parallelism to enable scalability. Secon</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithm. In Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Michael Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT).</booktitle>
<contexts>
<context position="1843" citStr="Culotta et al., 2007" startWordPosition="264" endWordPosition="267">nce quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of </context>
<context position="3412" citStr="Culotta et al., 2007" startWordPosition="520" endWordPosition="523">and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 2009a). These models contain pairwise factors between all pairs of mentions capturing similarity between them. Many of these models also enforce transitivity and enable features over 793 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Running back Filmmaker Cornerback Firefighter Author Rapper Actor ... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing... ...duri</context>
<context position="32200" citStr="Culotta et al., 2007" startWordPosition="5181" endWordPosition="5184"> not available in any of these approaches. First, most of the methods will not scale to the hundreds of millions of mentions that are present in real-world applications. By utilizing parallelism across machines, our method can run on very large datasets simply by increasing the number of machines used. Second, approaches that use clustering are limited to using pairwise distance functions for which additional supervision and features are difficult to incorporate. In addition to representing features from all of the related work, graphical models can also use more complex entity-wide features (Culotta et al., 2007; Wick et al., 2009a), and parameters can be learned using supervised (Collins, 2002) or semisupervised techniques (Mann and McCallum, 2008). Finally, the inference for most of the related approaches is greedy, and earlier decisions are not revisited. Our technique is based on MCMC inference and simulated annealing, which are able to escape local maxima. 7 Conclusions Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. First, we introduce distributed version of MCM</context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Aron Culotta, Michael Wick, and Andrew McCallum. 2007. First-order probabilistic models for coreference resolution. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Datta</author>
<author>C Giannella</author>
<author>H Kargupta</author>
</authors>
<title>K-Means Clustering over a Large, Dynamic Network.</title>
<date>2006</date>
<booktitle>In SIAM Data Mining Conference (SDM).</booktitle>
<contexts>
<context position="30799" citStr="Datta et al. (2006)" startWordPosition="4959" endWordPosition="4962">arious forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which is not scalable to the very large number of mentions t</context>
</contexts>
<marker>Datta, Giannella, Kargupta, 2006</marker>
<rawString>S. Datta, C. Giannella, and H. Kargupta. 2006. K-Means Clustering over a Large, Dynamic Network. In SIAM Data Mining Conference (SDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A Bayesian model for supervised clustering with the Dirichlet process prior.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research (JMLR),</journal>
<pages>6--1551</pages>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2005. A Bayesian model for supervised clustering with the Dirichlet process prior. Journal of Machine Learning Research (JMLR), 6:1551–1577.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dean</author>
<author>Sanjay Ghemawat</author>
</authors>
<title>Mapreduce: Simplified data processing on large clusters.</title>
<date>2004</date>
<booktitle>Symposium on Operating Systems Design &amp; Implementation (OSDI).</booktitle>
<marker>Dean, Ghemawat, 2004</marker>
<rawString>Jeffrey Dean and Sanjay Ghemawat. 2004. Mapreduce: Simplified data processing on large clusters. Symposium on Operating Systems Design &amp; Implementation (OSDI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Tom Griffiths</author>
</authors>
<title>A fully bayesian approach to unsupervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>744--751</pages>
<contexts>
<context position="11863" citStr="Goldwater and Griffiths, 2007" startWordPosition="1895" endWordPosition="1899">h the following Metropolis-Hastings acceptance probability: p(e0)1/t q(e) (1) p(e) ) q(e0) 1Number of possible entities is Bell(n) in the number of mentions, i.e. number of partitions of n items m1 m2 e1 m3 m4 e2 m5 1, ( α(e, e0) = min 795 where t is the annealing temperature parameter. MCMC chains efficiently explore the highdensity regions of the probability distribution. By slowly reducing the temperature, we can decrease the entropy of the distribution to encourage convergence to the MAP configuration. MCMC has been used for optimization in a number of related work (McCallum et al., 2009; Goldwater and Griffiths, 2007; Changhe et al., 2004). The proposal function moves a randomly chosen mention l from its current entity es to a randomly chosen entity et. For such a proposal, the log-model ratio is: log p(e0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled data, these parameters can be lea</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Tom Griffiths. 2007. A fully bayesian approach to unsupervised part-of-speech tagging. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 744–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung Heong Gooi</author>
<author>James Allan</author>
</authors>
<title>Crossdocument coreference on a large scale corpus.</title>
<date>2004</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT),</booktitle>
<pages>9--16</pages>
<contexts>
<context position="2828" citStr="Gooi and Allan, 2004" startWordPosition="423" endWordPosition="426">ber of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have billions of mentions. In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2</context>
<context position="22885" citStr="Gooi and Allan, 2004" startWordPosition="3650" endWordPosition="3653">the model most similar to ours, while their best model (which uses sophisticated topic-model features that do not scale easily) achieves 69.7%. It is encouraging to note that our approach, using only a subset of the features, performs competitively with related work. However, due to the small size of the dataset, we require further evaluation before reaching any conclusions. 5.2 Person-X Evaluation There is a severe lack of labeled corpora for crossdocument coreference due to the effort required to evaluate the coreference decisions. Related approaches have used automated Person-X evaluation (Gooi and Allan, 2004), in which unique person-name strings are treated as the true entity labels for the mentions. Every mention string is replaced with an “X” for the coreference system. We use this evaluation methodology on 25k personname mentions from the New York Times corpus (Sandhaus, 2008) each with one of 50 unique strings. As before, we set the bias b to achieve the same number of entities. We use 1 million samples in each round of inference, followed by random redistribution in the flat model, and super-entities in the hierarchical model. Results are averaged over five runs. 798 Figure 5: Person-X Evalua</context>
<context position="29776" citStr="Gooi and Allan, 2004" startWordPosition="4802" endWordPosition="4805">umber of previous techniques use scoring functions between pairs of contexts, which are then used for clustering. One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches ar</context>
</contexts>
<marker>Gooi, Allan, 2004</marker>
<rawString>Chung Heong Gooi and James Allan. 2004. Crossdocument coreference on a large scale corpus. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT), pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Unsupervised coreference resolution in a nonparametric bayesian model.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>848--855</pages>
<contexts>
<context position="1869" citStr="Haghighi and Klein, 2007" startWordPosition="268" endWordPosition="271">gh accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the</context>
</contexts>
<marker>Haghighi, Klein, 2007</marker>
<rawString>Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 848–855.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Simple coreference resolution with rich syntactic and semantic features.</title>
<date>2009</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1152--1161</pages>
<contexts>
<context position="1920" citStr="Haghighi and Klein, 2009" startWordPosition="276" endWordPosition="279">arge dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. </context>
</contexts>
<marker>Haghighi, Klein, 2009</marker>
<rawString>Aria Haghighi and Dan Klein. 2009. Simple coreference resolution with rich syntactic and semantic features. In Empirical Methods in Natural Language Processing (EMNLP), pages 1152–1161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Coreference resolution in a modular, entity-centered model.</title>
<date>2010</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT),</booktitle>
<pages>385--393</pages>
<contexts>
<context position="1947" citStr="Haghighi and Klein, 2010" startWordPosition="280" endWordPosition="283">g the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have bi</context>
<context position="30583" citStr="Haghighi and Klein (2010)" startWordPosition="4927" endWordPosition="4930"> from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input ment</context>
</contexts>
<marker>Haghighi, Klein, 2010</marker>
<rawString>Aria Haghighi and Dan Klein. 2010. Coreference resolution in a modular, entity-centered model. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT), pages 385–393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>870--878</pages>
<contexts>
<context position="32340" citStr="Mann and McCallum, 2008" startWordPosition="5202" endWordPosition="5205">esent in real-world applications. By utilizing parallelism across machines, our method can run on very large datasets simply by increasing the number of machines used. Second, approaches that use clustering are limited to using pairwise distance functions for which additional supervision and features are difficult to incorporate. In addition to representing features from all of the related work, graphical models can also use more complex entity-wide features (Culotta et al., 2007; Wick et al., 2009a), and parameters can be learned using supervised (Collins, 2002) or semisupervised techniques (Mann and McCallum, 2008). Finally, the inference for most of the related approaches is greedy, and earlier decisions are not revisited. Our technique is based on MCMC inference and simulated annealing, which are able to escape local maxima. 7 Conclusions Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. First, we introduce distributed version of MCMC-based inference technique that can utilize parallelism to enable scalability. Second, we augment the model with hierarchical variables tha</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>Gideon S. Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 870–878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised personal name disambiguation.</title>
<date>2003</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT),</booktitle>
<pages>33--40</pages>
<contexts>
<context position="29935" citStr="Mann and Yarowsky (2003)" startWordPosition="4825" endWordPosition="4828">ent coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supe</context>
</contexts>
<marker>Mann, Yarowsky, 2003</marker>
<rawString>Gideon S. Mann and David Yarowsky. 2003. Unsupervised personal name disambiguation. In North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT), pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
<author>Pedro Aguiar</author>
<author>Mario Figueiredo</author>
</authors>
<title>Turbo parsers: Dependency parsing by approximate variational inference.</title>
<date>2010</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>34--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="5095" citStr="Martins et al., 2010" startWordPosition="780" endWordPosition="783">badly... ...shorthanded backfield in the wake of Kevin Smith&apos;s knee injury, and the addition of Haynesworth... ...were coming,&amp;quot; said Dallas cornerback Kevin Smith. &amp;quot;We just didn&apos;t know when... BEIJING, Feb. 21— Kevin Smith, who played the god of war in the &amp;quot;Rena&amp;quot;... Figure 1: Cross-Document Coreference Problem: Example mentions of “Kevin Smith” from New York Times articles, with the true entities shown on the right. entities by including set-valued variables. Exact inference in these models is intractable and a number of approximate inference schemes (McCallum et al., 2009; Rush et al., 2010; Martins et al., 2010) may be used. In particular, Markov chain Monte Carlo (MCMC) based inference has been found to work well in practice. However as the number of mentions grows to Web scale, as in our problem of crossdocument coreference, even these inference techniques become infeasible, motivating the need for a scalable, parallelizable solution. In this work we first distribute MCMC-based inference for the graphical model representation of coreference. Entities are distributed across the machines such that the parallel MCMC chains on the different machines use only local proposal distributions. After a fixed </context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>Andre Martins, Noah Smith, Eric Xing, Pedro Aguiar, and Mario Figueiredo. 2010. Turbo parsers: Dependency parsing by approximate variational inference. In Empirical Methods in Natural Language Processing (EMNLP), pages 34–44, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mayfield</author>
<author>D Alexander</author>
<author>B Dorr</author>
<author>J Eisner</author>
<author>T Elsayed</author>
<author>T Finin</author>
<author>C Fink</author>
<author>M Freedman</author>
<author>N Garera</author>
<author>P McNamee</author>
</authors>
<title>Cross-document coreference resolution: A key technology for learning by reading.</title>
<date>2009</date>
<booktitle>In AAAI Spring Symposium on Learning by Reading and Learning to Read.</booktitle>
<contexts>
<context position="1738" citStr="Mayfield et al., 2009" startWordPosition="249" endWordPosition="252">rring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. </context>
</contexts>
<marker>Mayfield, Alexander, Dorr, Eisner, Elsayed, Finin, Fink, Freedman, Garera, McNamee, 2009</marker>
<rawString>J. Mayfield, D. Alexander, B. Dorr, J. Eisner, T. Elsayed, T. Finin, C. Fink, M. Freedman, N. Garera, P. McNamee, et al. 2009. Cross-document coreference resolution: A key technology for learning by reading. In AAAI Spring Symposium on Learning by Reading and Learning to Read.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Ben Wellner</author>
</authors>
<title>Conditional models of identity uncertainty with application to noun coreference.</title>
<date>2004</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="13107" citStr="McCallum and Wellner (2004)" startWordPosition="2107" endWordPosition="2110">n (Collins, 2002), which uses the MAP configuration according to the model (e). There also exist more efficient training algorithms such as SampleRank (McCallum et al., 2009; Wick et al., 2009b) that update parameters during inference. However, we only focus on inference in this work, and the only parameter that we set manually is the bias b, which indirectly influences the number of entities in e. Unless specified otherwise, in this work the initial configuration for MCMC is the singleton configuration, i.e. all entities have a size of 1. This MCMC inference technique, which has been used in McCallum and Wellner (2004), offers several advantages over other inference techniques: (a) unlike message-passing-methods, it does not require the full ground graph, (b) we only have to examine the factors that lie within the changed entities to evaluate a proposal, and (c) inference may be stopped at any point to obtain the current best configuration. However, the super exponential nature of the hypothesis space in cross-doc coreference renders this algorithm computationally unsuitable for large scale coreference tasks. In particular, fruitful proposals (that increase the model score) are extremely rare, resulting in </context>
</contexts>
<marker>McCallum, Wellner, 2004</marker>
<rawString>Andrew McCallum and Ben Wellner. 2004. Conditional models of identity uncertainty with application to noun coreference. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Karl Schultz</author>
<author>Sameer Singh</author>
</authors>
<title>FACTORIE: Probabilistic programming via imperatively defined factor graphs.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="5053" citStr="McCallum et al., 2009" startWordPosition="772" endWordPosition="775">rafted Kevin Smith, even though Smith was badly... ...shorthanded backfield in the wake of Kevin Smith&apos;s knee injury, and the addition of Haynesworth... ...were coming,&amp;quot; said Dallas cornerback Kevin Smith. &amp;quot;We just didn&apos;t know when... BEIJING, Feb. 21— Kevin Smith, who played the god of war in the &amp;quot;Rena&amp;quot;... Figure 1: Cross-Document Coreference Problem: Example mentions of “Kevin Smith” from New York Times articles, with the true entities shown on the right. entities by including set-valued variables. Exact inference in these models is intractable and a number of approximate inference schemes (McCallum et al., 2009; Rush et al., 2010; Martins et al., 2010) may be used. In particular, Markov chain Monte Carlo (MCMC) based inference has been found to work well in practice. However as the number of mentions grows to Web scale, as in our problem of crossdocument coreference, even these inference techniques become infeasible, motivating the need for a scalable, parallelizable solution. In this work we first distribute MCMC-based inference for the graphical model representation of coreference. Entities are distributed across the machines such that the parallel MCMC chains on the different machines use only lo</context>
<context position="11832" citStr="McCallum et al., 2009" startWordPosition="1891" endWordPosition="1894">is jump is accepted with the following Metropolis-Hastings acceptance probability: p(e0)1/t q(e) (1) p(e) ) q(e0) 1Number of possible entities is Bell(n) in the number of mentions, i.e. number of partitions of n items m1 m2 e1 m3 m4 e2 m5 1, ( α(e, e0) = min 795 where t is the annealing temperature parameter. MCMC chains efficiently explore the highdensity regions of the probability distribution. By slowly reducing the temperature, we can decrease the entropy of the distribution to encourage convergence to the MAP configuration. MCMC has been used for optimization in a number of related work (McCallum et al., 2009; Goldwater and Griffiths, 2007; Changhe et al., 2004). The proposal function moves a randomly chosen mention l from its current entity es to a randomly chosen entity et. For such a proposal, the log-model ratio is: log p(e0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled da</context>
</contexts>
<marker>McCallum, Schultz, Singh, 2009</marker>
<rawString>Andrew McCallum, Karl Schultz, and Sameer Singh. 2009. FACTORIE: Probabilistic programming via imperatively defined factor graphs. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horatiu Mocian</author>
</authors>
<title>Survey of Distributed Clustering Techniques.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Imperial College of London.</institution>
<contexts>
<context position="31031" citStr="Mocian (2009)" startWordPosition="4998" endWordPosition="4999">istance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which is not scalable to the very large number of mentions that are encountered in practice. Our representation of the problem as an undirected graphical model, and performing distributed inference on it, provides a combination of advantages not available in any of these approaches. First, m</context>
</contexts>
<marker>Mocian, 2009</marker>
<rawString>Horatiu Mocian. 2009. Survey of Distributed Clustering Techniques. Ph.D. thesis, Imperial College of London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Machine learning for coreference resolution: From local classification to global ranking.</title>
<date>2005</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1821" citStr="Ng, 2005" startWordPosition="262" endWordPosition="263">ted inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. Solutions to this problem are important in semantic analysis and knowledge discovery tasks (Blume, 2005; Mayfield et al., 2009). While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al., 2007; Haghighi and Klein, 2007; Bengston and Roth, 2008; Haghighi and Klein, 2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. Unlike inference in other language processing tasks that scales linearly in the size of the corpus, the hypothesis space for coreference grows superexponentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied t</context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>Vincent Ng. 2005. Machine learning for coreference resolution: From local classification to global ranking. In Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cheng Niu</author>
<author>Wei Li</author>
<author>Rohini K Srihari</author>
</authors>
<title>Weakly supervised learning for cross-document person name disambiguation supported by information extraction.</title>
<date>2004</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>597</pages>
<contexts>
<context position="30017" citStr="Niu et al. (2004)" startWordPosition="4840" endWordPosition="4843">ion for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist wit</context>
</contexts>
<marker>Niu, Li, Srihari, 2004</marker>
<rawString>Cheng Niu, Wei Li, and Rohini K. Srihari. 2004. Weakly supervised learning for cross-document person name disambiguation supported by information extraction. In Annual Meeting of the Association for Computational Linguistics (ACL), page 597.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Anagha Kulkarni</author>
<author>Roxana Angheluta</author>
<author>Zornitsa Kozareva</author>
<author>Thamar Solorio</author>
</authors>
<title>An unsupervised language independent method of name discrimination using second order co-occurrence features.</title>
<date>2006</date>
<booktitle>In International Conference on Intelligent Text Processing and Computational Linguistics (CICLing),</booktitle>
<pages>208--222</pages>
<contexts>
<context position="2851" citStr="Pedersen et al., 2006" startWordPosition="427" endWordPosition="430">quently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have billions of mentions. In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 20</context>
<context position="29800" citStr="Pedersen et al. (2006)" startWordPosition="4806" endWordPosition="4809">iques use scoring functions between pairs of contexts, which are then used for clustering. One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in t</context>
</contexts>
<marker>Pedersen, Kulkarni, Angheluta, Kozareva, Solorio, 2006</marker>
<rawString>Ted Pedersen, Anagha Kulkarni, Roxana Angheluta, Zornitsa Kozareva, and Thamar Solorio. 2006. An unsupervised language independent method of name discrimination using second order co-occurrence features. In International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), pages 208–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
<author>Marc Sumner</author>
</authors>
<title>A general method for reducing the complexity of relational inference and its application to MCMC.</title>
<date>2008</date>
<booktitle>In AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="3431" citStr="Poon et al., 2008" startWordPosition="524" endWordPosition="527">nd Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 2009a). These models contain pairwise factors between all pairs of mentions capturing similarity between them. Many of these models also enforce transitivity and enable features over 793 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Running back Filmmaker Cornerback Firefighter Author Rapper Actor ... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing... ...during the late 60&apos;s an</context>
</contexts>
<marker>Poon, Domingos, Sumner, 2008</marker>
<rawString>Hoifung Poon, Pedro Domingos, and Marc Sumner. 2008. A general method for reducing the complexity of relational inference and its application to MCMC. In AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
<author>Christian Girardi</author>
<author>Emanuele Pianta</author>
<author>Bernardo Magnini</author>
</authors>
<title>Improving crossdocument coreference. Journ´ees Internationales d’Analyse statistique des Donn´ees Textuelles,</title>
<date>2008</date>
<pages>9--961</pages>
<contexts>
<context position="30355" citStr="Popescu et al., 2008" startWordPosition="4891" endWordPosition="4894"> means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function and the clustering algorithm used. Daum´e III and Marcu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty </context>
</contexts>
<marker>Popescu, Girardi, Pianta, Magnini, 2008</marker>
<rawString>Octavian Popescu, Christian Girardi, Emanuele Pianta, and Bernardo Magnini. 2008. Improving crossdocument coreference. Journ´ees Internationales d’Analyse statistique des Donn´ees Textuelles, 9:961– 969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Purandare</author>
<author>T Pedersen</author>
</authors>
<title>Word sense discrimination by clustering contexts in vector and similarity spaces.</title>
<date>2004</date>
<booktitle>In Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>41--48</pages>
<contexts>
<context position="29834" citStr="Purandare and Pedersen (2004)" startWordPosition="4811" endWordPosition="4814"> between pairs of contexts, which are then used for clustering. One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context similarity model, and annotate a small dataset to learn the parameters. A number of other approaches include various forms of 800 hand-tuned weights, dictionaries, and heuristics to define similarity for name disambiguation (Blume, 2005; Baron and Freedman, 2008; Popescu et al., 2008). These approaches are greedy and differ in the choice of the distance function</context>
</contexts>
<marker>Purandare, Pedersen, 2004</marker>
<rawString>A. Purandare and T. Pedersen. 2004. Word sense discrimination by clustering contexts in vector and similarity spaces. In Conference on Computational Natural Language Learning (CoNLL), pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Streaming cross document entity coreference resolution.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1050--1058</pages>
<location>Beijing, China,</location>
<contexts>
<context position="2870" citStr="Rao et al., 2010" startWordPosition="431" endWordPosition="434">rrent approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have billions of mentions. In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 20</context>
<context position="22243" citStr="Rao et al. (2010)" startWordPosition="3548" endWordPosition="3551">ions that we use to demonstrate accuracy and scalability improvements. Most importantly, we create a large labeled corpus using links to Wikipedia to explore the performance in the large-scale setting. 5.1 John Smith Corpus To compare with related work, we run an evaluation on the “John Smith” corpus (Bagga and Baldwin, 1998), containing 197 mentions of the name “John Smith” from New York Times articles (labeled to obtain 35 true entities). The bias b for our approach is set to result in the correct number of entities. Our model achieves B3 F1 accuracy of 66.4% on this dataset. In comparison, Rao et al. (2010) obtains 61.8% using the model most similar to ours, while their best model (which uses sophisticated topic-model features that do not scale easily) achieves 69.7%. It is encouraging to note that our approach, using only a subset of the features, performs competitively with related work. However, due to the small size of the dataset, we require further evaluation before reaching any conclusions. 5.2 Person-X Evaluation There is a severe lack of labeled corpora for crossdocument coreference due to the effort required to evaluate the coreference decisions. Related approaches have used automated </context>
<context position="31105" citStr="Rao et al. (2010)" startWordPosition="5007" endWordPosition="5010">cu (2005) propose a generative approach to supervised clustering, and Haghighi and Klein (2010) use entity profiles to assist within-document coreference. Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. Datta et al. (2006) propose an algorithm for distributed kmeans. Chen et al. (2010) describe a parallel spectral clustering algorithm. We use the Subsquare algorithm (Bshouty and Long, 2010) as baseline because it works well in practice. Mocian (2009) presents a survey of distributed clustering algorithms. Rao et al. (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which is not scalable to the very large number of mentions that are encountered in practice. Our representation of the problem as an undirected graphical model, and performing distributed inference on it, provides a combination of advantages not available in any of these approaches. First, most of the methods will not scale to the hundreds of millions of mentions </context>
</contexts>
<marker>Rao, McNamee, Dredze, 2010</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. 2010. Streaming cross document entity coreference resolution. In International Conference on Computational Linguistics (COLING), pages 1050–1058, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Ravin</author>
<author>Zunaid Kazi</author>
</authors>
<title>Is Hillary Rodham Clinton the president? disambiguating names across documents.</title>
<date>1999</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>9--16</pages>
<contexts>
<context position="2806" citStr="Ravin and Kazi, 1999" startWordPosition="419" endWordPosition="422">nentially with the number of mentions. Consequently, most of the current approaches are developed on small datasets containing a few thousand mentions. We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. Such a corpus would have billions of mentions. In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al.</context>
<context position="29475" citStr="Ravin and Kazi (1999)" startWordPosition="4757" endWordPosition="4760">d the Subsquare algorithm. Our approach significantly outperforms the competitors. 6 Related Work Although the cross-document coreference problem is challenging and lacks large labeled datasets, its ubiquitous role as a key component of many knowledge discovery tasks has inspired several efforts. A number of previous techniques use scoring functions between pairs of contexts, which are then used for clustering. One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. Others have explored multiple methods of context similarity, and concluded that agglomerative clustering provides effective means of inference (Gooi and Allan, 2004). Pedersen et al. (2006) and Purandare and Pedersen (2004) integrate second-order co-occurrence of words into the similarity function. Mann and Yarowsky (2003) use biographical facts from the Web as features for clustering. Niu et al. (2004) incorporate information extraction into the context simil</context>
</contexts>
<marker>Ravin, Kazi, 1999</marker>
<rawString>Yael Ravin and Zunaid Kazi. 1999. Is Hillary Rodham Clinton the president? disambiguating names across documents. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--11</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="5072" citStr="Rush et al., 2010" startWordPosition="776" endWordPosition="779">n though Smith was badly... ...shorthanded backfield in the wake of Kevin Smith&apos;s knee injury, and the addition of Haynesworth... ...were coming,&amp;quot; said Dallas cornerback Kevin Smith. &amp;quot;We just didn&apos;t know when... BEIJING, Feb. 21— Kevin Smith, who played the god of war in the &amp;quot;Rena&amp;quot;... Figure 1: Cross-Document Coreference Problem: Example mentions of “Kevin Smith” from New York Times articles, with the true entities shown on the right. entities by including set-valued variables. Exact inference in these models is intractable and a number of approximate inference schemes (McCallum et al., 2009; Rush et al., 2010; Martins et al., 2010) may be used. In particular, Markov chain Monte Carlo (MCMC) based inference has been found to work well in practice. However as the number of mentions grows to Web scale, as in our problem of crossdocument coreference, even these inference techniques become infeasible, motivating the need for a scalable, parallelizable solution. In this work we first distribute MCMC-based inference for the graphical model representation of coreference. Entities are distributed across the machines such that the parallel MCMC chains on the different machines use only local proposal distri</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M Rush, David Sontag, Michael Collins, and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Empirical Methods in Natural Language Processing (EMNLP), pages 1–11, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan Sandhaus</author>
</authors>
<title>The New York Times annotated corpus. Linguistic Data Consortium.</title>
<date>2008</date>
<contexts>
<context position="23161" citStr="Sandhaus, 2008" startWordPosition="3698" endWordPosition="3699">o the small size of the dataset, we require further evaluation before reaching any conclusions. 5.2 Person-X Evaluation There is a severe lack of labeled corpora for crossdocument coreference due to the effort required to evaluate the coreference decisions. Related approaches have used automated Person-X evaluation (Gooi and Allan, 2004), in which unique person-name strings are treated as the true entity labels for the mentions. Every mention string is replaced with an “X” for the coreference system. We use this evaluation methodology on 25k personname mentions from the New York Times corpus (Sandhaus, 2008) each with one of 50 unique strings. As before, we set the bias b to achieve the same number of entities. We use 1 million samples in each round of inference, followed by random redistribution in the flat model, and super-entities in the hierarchical model. Results are averaged over five runs. 798 Figure 5: Person-X Evaluation of Pairwise model: Performance as number of machines is varied, averaged over 5 runs. Number of Entities 43,928 Number of Mentions 1,567,028 Size of Largest Entity 6,096 Average Mentions per Entity 35.7 Variance of Mentions per Entity 5191.7 Table 1: Wikipedia Link Corpu</context>
</contexts>
<marker>Sandhaus, 2008</marker>
<rawString>Evan Sandhaus. 2008. The New York Times annotated corpus. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>Andrew McCallum</author>
</authors>
<title>Distributed map inference for undirected graphical models.</title>
<date>2010</date>
<booktitle>In Neural Information Processing Systems (NIPS), Workshop on Learning on Cores, Clusters and Clouds.</booktitle>
<contexts>
<context position="16693" citStr="Singh et al. (2010)" startWordPosition="2673" endWordPosition="2676"> redistributing the entities. mawat, 2004) to manage the distributed computation. This approach to distribution is equivalent to inference with all mentions and entities on a single machine with a restricted proposer, but is faster since it exploits independencies to propose multiple jumps simultaneously. By restricting the jumps as described above, the acceptance probability calculation is exact. Partitioning the entities and proposing local jumps are restrictions to the single-machine proposal distribution; redistribution stages ensure the equivalent Markov chains are still irreducible. See Singh et al. (2010) for more details. 4 Hierarchical Coreference Model The proposal function for MCMC-based MAP inference presents changes to the current entities. Since we use MCMC to reach high-scoring regions of the hypothesis space, we are interested in the changes that improve the current configuration. But as the number of mentions and entities increases, these fruitful samples become extremely rare due to the blowup in the possible space of configurations, resulting in rejection of a large number of proposals. By distributing as described in the previous section, we propose samples in parallel, improving </context>
</contexts>
<marker>Singh, Subramanya, Pereira, McCallum, 2010</marker>
<rawString>Sameer Singh, Amarnag Subramanya, Fernando Pereira, and Andrew McCallum. 2010. Distributed map inference for undirected graphical models. In Neural Information Processing Systems (NIPS), Workshop on Learning on Cores, Clusters and Clouds.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Wellner</author>
<author>Andrew McCallum</author>
<author>Fuchun Peng</author>
<author>Michael Hay</author>
</authors>
<title>An integrated, conditional model of information extraction and coreference with application to citation matching.</title>
<date>2004</date>
<booktitle>In Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>593--601</pages>
<contexts>
<context position="3453" citStr="Wellner et al., 2004" startWordPosition="528" endWordPosition="531">ersen et al., 2006; Rao et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 2009a). These models contain pairwise factors between all pairs of mentions capturing similarity between them. Many of these models also enforce transitivity and enable features over 793 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Running back Filmmaker Cornerback Firefighter Author Rapper Actor ... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing... ...during the late 60&apos;s and early 70&apos;s, Kevin Sm</context>
</contexts>
<marker>Wellner, McCallum, Peng, Hay, 2004</marker>
<rawString>Ben Wellner, Andrew McCallum, Fuchun Peng, and Michael Hay. 2004. An integrated, conditional model of information extraction and coreference with application to citation matching. In Uncertainty in Artificial Intelligence (UAI), pages 593–601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wick</author>
<author>Aron Culotta</author>
<author>Khashayar Rohanimanesh</author>
<author>Andrew McCallum</author>
</authors>
<title>An entity-based model for coreference resolution.</title>
<date>2009</date>
<booktitle>In SIAM International Conference on Data Mining (SDM).</booktitle>
<contexts>
<context position="3472" citStr="Wick et al., 2009" startWordPosition="532" endWordPosition="535">o et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 2009a). These models contain pairwise factors between all pairs of mentions capturing similarity between them. Many of these models also enforce transitivity and enable features over 793 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Running back Filmmaker Cornerback Firefighter Author Rapper Actor ... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing... ...during the late 60&apos;s and early 70&apos;s, Kevin Smith worked with sev</context>
<context position="12672" citStr="Wick et al., 2009" startWordPosition="2034" endWordPosition="2037">0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled data, these parameters can be learned by Perceptron (Collins, 2002), which uses the MAP configuration according to the model (e). There also exist more efficient training algorithms such as SampleRank (McCallum et al., 2009; Wick et al., 2009b) that update parameters during inference. However, we only focus on inference in this work, and the only parameter that we set manually is the bias b, which indirectly influences the number of entities in e. Unless specified otherwise, in this work the initial configuration for MCMC is the singleton configuration, i.e. all entities have a size of 1. This MCMC inference technique, which has been used in McCallum and Wellner (2004), offers several advantages over other inference techniques: (a) unlike message-passing-methods, it does not require the full ground graph, (b) we only have to exami</context>
<context position="32219" citStr="Wick et al., 2009" startWordPosition="5185" endWordPosition="5188">of these approaches. First, most of the methods will not scale to the hundreds of millions of mentions that are present in real-world applications. By utilizing parallelism across machines, our method can run on very large datasets simply by increasing the number of machines used. Second, approaches that use clustering are limited to using pairwise distance functions for which additional supervision and features are difficult to incorporate. In addition to representing features from all of the related work, graphical models can also use more complex entity-wide features (Culotta et al., 2007; Wick et al., 2009a), and parameters can be learned using supervised (Collins, 2002) or semisupervised techniques (Mann and McCallum, 2008). Finally, the inference for most of the related approaches is greedy, and earlier decisions are not revisited. Our technique is based on MCMC inference and simulated annealing, which are able to escape local maxima. 7 Conclusions Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. First, we introduce distributed version of MCMC-based inference t</context>
</contexts>
<marker>Wick, Culotta, Rohanimanesh, McCallum, 2009</marker>
<rawString>Michael Wick, Aron Culotta, Khashayar Rohanimanesh, and Andrew McCallum. 2009a. An entity-based model for coreference resolution. In SIAM International Conference on Data Mining (SDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wick</author>
<author>Khashayar Rohanimanesh</author>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Samplerank: Learning preferences from atomic gradients.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS), Workshop on Advances in Ranking.</booktitle>
<contexts>
<context position="3472" citStr="Wick et al., 2009" startWordPosition="532" endWordPosition="535">o et al., 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. Such methods have not been shown to scale up, and they cannot exploit cluster features that cannot be expressed in terms of mention pairs. We provide a detailed survey of related work in Section 6. Other previous work attempts to address some of the above concerns by mapping coreference to inference on an undirected graphical model (Culotta et al., 2007; Poon et al., 2008; Wellner et al., 2004; Wick et al., 2009a). These models contain pairwise factors between all pairs of mentions capturing similarity between them. Many of these models also enforce transitivity and enable features over 793 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 793–803, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Running back Filmmaker Cornerback Firefighter Author Rapper Actor ... The Physiological Basis of Politics,” by Kevin B. Smith, Douglas Oxley, Matthew Hibbing... ...during the late 60&apos;s and early 70&apos;s, Kevin Smith worked with sev</context>
<context position="12672" citStr="Wick et al., 2009" startWordPosition="2034" endWordPosition="2037">0) p(e) �− 0a(l, n) − � 0r(l, m) (2) n∈e3 m∈et Note that since only the factors between mention l and mentions in es and et are involved in this computation, the acceptance probability of each proposal is calculated efficiently. In general, the model may contain arbitrarily complex set of features over pairs of mentions, with parameters associated with them. Given labeled data, these parameters can be learned by Perceptron (Collins, 2002), which uses the MAP configuration according to the model (e). There also exist more efficient training algorithms such as SampleRank (McCallum et al., 2009; Wick et al., 2009b) that update parameters during inference. However, we only focus on inference in this work, and the only parameter that we set manually is the bias b, which indirectly influences the number of entities in e. Unless specified otherwise, in this work the initial configuration for MCMC is the singleton configuration, i.e. all entities have a size of 1. This MCMC inference technique, which has been used in McCallum and Wellner (2004), offers several advantages over other inference techniques: (a) unlike message-passing-methods, it does not require the full ground graph, (b) we only have to exami</context>
<context position="32219" citStr="Wick et al., 2009" startWordPosition="5185" endWordPosition="5188">of these approaches. First, most of the methods will not scale to the hundreds of millions of mentions that are present in real-world applications. By utilizing parallelism across machines, our method can run on very large datasets simply by increasing the number of machines used. Second, approaches that use clustering are limited to using pairwise distance functions for which additional supervision and features are difficult to incorporate. In addition to representing features from all of the related work, graphical models can also use more complex entity-wide features (Culotta et al., 2007; Wick et al., 2009a), and parameters can be learned using supervised (Collins, 2002) or semisupervised techniques (Mann and McCallum, 2008). Finally, the inference for most of the related approaches is greedy, and earlier decisions are not revisited. Our technique is based on MCMC inference and simulated annealing, which are able to escape local maxima. 7 Conclusions Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. First, we introduce distributed version of MCMC-based inference t</context>
</contexts>
<marker>Wick, Rohanimanesh, Culotta, McCallum, 2009</marker>
<rawString>Michael Wick, Khashayar Rohanimanesh, Aron Culotta, and Andrew McCallum. 2009b. Samplerank: Learning preferences from atomic gradients. In Neural Information Processing Systems (NIPS), Workshop on Advances in Ranking.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>