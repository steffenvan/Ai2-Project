<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99315">
A Formal Basis for Performance Evaluation
of Natural Language Understanding Systems
</title>
<author confidence="0.837777">
Giovanni Guidal and Giancarlo Mauri2
</author>
<bodyText confidence="0.872787133333333">
Istituto di Matematica, Informatica e Sistemistica
Universiti di Udine
Udine, Italy
The task of evaluating the performance of a natural language understanding system,
despite its largely recognized relevance, is still poorly defined. It mostly relies on intuitive
reasoning and lacks a sound theoretical foundation. This paper sets a formal and quantita-
tive proposal for this task. In particular, a measure of performance that allows the basic
input-output characteristics of a system to be evaluated is introduced first at an abstract
level. The definition of concrete measures is then obtained by assigning actual values to
the functional parameters of the abstract definition; some particular cases are shown and
discussed in detail. Finally, the task of measuring performance in practice is considered,
and a model for experimental performance evaluation is presented. Comparison with
related works is also briefly discussed; open problems and promising directions for future
research are outlined. A limited case study experimentation with the model proposed is
presented in the appendix.
</bodyText>
<sectionHeader confidence="0.990285" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999948857142857">
Research on natural language processing has recently
been featured by the design and implementation of a
number of experimental systems. Recent survey re-
ports (Waltz 1977, Kaplan 1982) mention more than
one hundred items among the most successful and
relevant systems in the classical application fields of
data base inquiry, machine translation, question an-
swering, and man-machine interfacing.
This trend is not surprising in the context of re-
search whose specific aim is that of providing automat-
ed tools for the understanding or translating of natural
languages; but it is also evident even in natural lan-
guage research with a more theoretical flavour. The
successful construction of a good performing system is
</bodyText>
<sectionHeader confidence="0.375578" genericHeader="keywords">
Address:
</sectionHeader>
<affiliation confidence="0.761849857142857">
Prof. Giovanni Guida
Dipartimento di Elettronica
Politecnico di Milano
P.zza Leonardo da Vinci, 32
1-20133 MILANO, Italy
Also with Milan Polytechnic Artificial Intelligence Project, Milano,
Italy.
</affiliation>
<footnote confidence="0.333607">
2 Also with Istituto di Cibernetica, Universita di Milano, Mila-
</footnote>
<note confidence="0.300079">
no, Italy.
</note>
<bodyText confidence="0.9990531875">
in fact often considered as the most evident proof of
the validity of a theory, and, therefore, designing run-
ning systems is routine, and even sometimes the spe-
cific goal of several researchers.
The task of evaluating the performance of a given
system and that of comparing the behaviour of differ-
ent systems appears, therefore, to be a fundamental
issue. Despite its large recognized relevance (Woods
1977, Tennant 1980), measuring the performance of a
system for natural language processing is still poorly
defined. It mostly relies on intuitive reasoning and
lacks a sound theoretical foundation. As Tennant
clearly points out (1980), there is a nearly complete
absence of meaningful evaluation in current natural
language processing research. This leaves several cru-
cial questions unanswered:
</bodyText>
<listItem confidence="0.997798285714286">
• What is the relevance and value of obtained results?
• How general are the proposed solutions?
• How do they compare with other proposals?
• What problems are still open?
• What directions have to be followed?
• What issues are to be faced in the progress of the
research?
</listItem>
<bodyText confidence="0.980264333333333">
Copyright 1984 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the
first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<page confidence="0.401971">
0362-613X/84/030015--16$03.00
</page>
<note confidence="0.624664">
Computational Linguistics, Volume 10, Number 1, January-March 1984 15
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.999888136363637">
The lack of evaluation constitutes a serious obsta-
cle to the development of a sound technology in natu-
ral language processing.
The purpose of this paper is to provide a formal
and quantitative model for the performance evaluation
task. In particular, we give a formal definition of
&amp;quot;understanding power&amp;quot;, and we propose some techni-
ques for measuring this feature in practice. Our pro-
posal is based on several assumptions we discuss be-
low.
First, we assume as object of our attention only
that module of a natural language system that is devot-
ed to understanding natural language, that is, to map-
ping input expressions into formal internal representa-
tions. This can clearly include several kinds of proc-
essing activities, such as linguistic analysis, reasoning,
inferencing, etc.; but must have as ultimate goal the
construction of a correct internal representation, not
the production of any type of service to the end user
of the natural language system. Thus, for example, a
question answering system (Tennant 1979) does not
belong to the class of natural language understanding
systems that concern us; instead, it is the natural lan-
guage interface it contains that meets exactly our re-
quirements.
Second, we assume the following naïve notion of
performance: the extent to which a system is able to
correctly understand natural language expressions in a
given application domain. The resources needed by
the system to accomplish its task are irrelevant in this
case. In other words, we want to capture and measure
the &amp;quot;power&amp;quot; of the system, in terms of how much and
how well it is capable of understanding, not its
&amp;quot;efficiency&amp;quot;, that is, how much does it cost (for exam-
ple, in terms of time and memory requirements) to
understand what it is capable of understanding.
Third, we want to define a measure of performance
that allows the evaluation of the input-output charac-
teristics of a particular system in a given domain. This
kind of measure is clearly inappropriate to reveal and
test features, such as the power of a model as opposed
to that of a particular implementation of it, the appli-
cability of the model to other domains, its extensibili-
ty, etc., which are more closely related to the internal
structure and mode of operation of a system, rather
than to its input-output behaviour. The goal of evalu-
ating such more general properties, worked on by Ten-
nant (1980) through the method of abstract analysis
(mainly based on taxonomies of conceptual, linguistic,
and implementational issues), is not considered in this
work.
This paper is organized in the following way. In
section 2 we discuss in an intuitive, yet precise, way
the basic concepts involved in the performance evalua-
tion problem, in order to have a sufficiently clear
specification of what we want to formalize. Then, in
section 3, we give an abstract definition of the formal
model, and in section 4 we discuss some actual cases
of particular interest. Section 5 presents some techni-
ques that could be used to measure in practice the
performance of a natural language understanding sys-
tem. In section 6 we discuss some concluding re-
marks, and present open problems and promising top-
ics for future research. A limited case study experi-
mentation with the model proposed is presented in the
appendix.
</bodyText>
<sectionHeader confidence="0.7590805" genericHeader="introduction">
2. Basic Definitions and Statement of the
Problem
</sectionHeader>
<bodyText confidence="0.994633558823529">
Let us introduce some background definitions needed
to clearly state the problem of performance evaluation,
as discussed in this work. The model of natural lan-
guage understanding we are going to define is so con-
ceived as to include only those very few features that
are relevant for the purpose of performance evaluation
and is strictly tailored to this particular goal.
Let an expression of a natural language be any fi-
nite sequence of legal words and punctuation marks
from the given language. Let A be the set of all ex-
pressions of a natural language.
Note that the above definition is very loose and
does not take into account the structure of the expres-
sions. So an expression can be a sentence, a dialogue,
a meaningless sequence of words, the whole content of
a book, or just a single word. Introducing a more
definite notion of expression is not necessary at this
point for our purpose of stating the problem of per-
formance evaluation.
Although the above definition includes expressions
of arbitrarily (finite) length, so that A contains infi-
nitely many expressions, in a more pragmatic approach
the length of existing expressions of a natural language
at a given moment of its history has an upper bound.
Therefore, it makes sense to restrict our attention to a
finite subset E of A, containing all expressions of
length less than or equal to an appropriately fixed
integer n.
Let L be the set of all meaningful expressions of a
natural language, that is, of all expressions to which
humans attach a meaning. Note that L is defined on a
purely semantic basis, so that expressions of L do not
have to be syntactically correct with respect to any
fixed syntax, and that, generally, more than one mean-
</bodyText>
<page confidence="0.924843">
16 Computational Linguistics. Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.463675">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.972159670212767">
ing may be attached to the same expression, that is,
expressions are not required to be univocal.
Let S be the set of all possible meanings that can
be attached to expressions of E.
We do not face here the problems of what S actual-
ly contains or of how S could be represented explicitly
(which mostly pertain to cognitive psychology); let us
assume S merely as that basic datum, shared by all
humans speaking a given language, which allows effec-
tive interpersonal communication.
We call the semantics of a natural language the
total function f: E-.2s (into 2S), which associates to
each expression of E the set of all its possible mean-
ings.
Clearly the function f can be computed by any
person who can understand perfectly the natural lan-
guage to which the expressions of E belong (theoreti-
cal problems concerning subjective interpretation and
disagreement between different people are not consid-
ered here).
Moreover, f(e) = 0 denotes that no meaning is
associated to the expression e, and hence eeL
ill f(e)00.
Each expression ecE such that I f(e) I &lt;1 is called
an univocal expression.
Let now D be a nonempty subset of S that contains
meanings all related to a unique subject (&amp;quot;what we are
speaking of&amp;quot;, &amp;quot;the topic of the discourse&amp;quot;, &amp;quot;the con-
ceptual competence of a natural language understand-
ing system&amp;quot;); we call D a domain.
Let fp be the restriction of f to D defined as:
fp(e) = f(e)Il D, for any eeE.
Let LD = E-f D-1(0) be the restriction of L to D.
It is obvious that LD gE.
Let us now try to formalize the concept of natural
language understanding system.
The main problem is that of giving a formal repre-
sentation to the informally defined domain D. To this
purpose, we take a finite set of symbols B, called
alphabet, and then we construct a set R of sequences
of arbitrary finite length over B (that is, RB*), in
such a way that to every element deD an element of
R, r = hp(d), is associated by a bi-univocal function
hp. The sequence r = hp(d) is called the
representation of d, while the set R is called a represen-
tation language for D.
Obviously, the map hp is a total function
-1
hp :R-0.D, which associates to every sequence of R its
informal meaning in D. Both hp and hp-1 are known
to man, in the sense that he is able to compute them.
We are now able to formalize the naïve notion of
natural language understanding system in the following
way.
Let D S be a domain and R a representation lan-
guage for D. A natural language understanding system
UR/D in R on D is an algorithm that computes a total
function gRu/D:E-0.2U (into 2RU ID, where 1. is
called the undefined symbol. g/ (e) = 1. denotes that
U is unable to assign a meaning to the expression e,
that is, that it fails in computing g/(e) (not that e
has no meaning in the domain DO.
Note that in the above definition we have assumed
that a system UR/D should accept as input not only
expression of LD but, generally, all expressions of E.
The reason for this choice is that a basic feature of
natural language understanding is also to recognize
that some expressions are meaningless (they belong to
E-L) or are in no way related to a given domain D
(they are in L-LD). Clearly, this feature is often less
important than the capability of correctly understand-
ing expressions of LD, but this can be appropriately
taken into account when defining a measure of per-
formance.
Measuring the performance of a natural language
understanding system UR/D may now be defined as
evaluating how well UR/D is capable of explicitly rep-
resenting in R the meaning of expressions of E.
To define such a notion in quantitative terms we
can first extend the bi-univocal function hp:D-0.R to
the function (bi-univocal if i is not considered)
defined by:
= U {hp(d)1,
dEx
for xe2D.
Figure 1 illustrates the definitions of the functions
hp, hp, and gR/D presented above.
u Considering now the three functions f p, hp, and
gR/D defined above, if we denote lip 0 fp = gp, the
performance of UR/D can then be expressed as the
degree of precision to which gR/D approaches ip over
E.
This task raises, however, some difficult problems.
Two basic questions are:
</bodyText>
<listItem confidence="0.997826">
(i) how to define the &amp;quot;difference&amp;quot; between guR/D and
gp over E in such a way to match the intuitive
notion of performance;
(ii) how to measure such a &amp;quot;difference&amp;quot; in practice,
that is, through an effective experimental proce-
dure.
</listItem>
<footnote confidence="0.354212">
Computational Linguistics, Volume 10, Number 1, January-March 1984 17
</footnote>
<note confidence="0.454939">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<page confidence="0.542996">
U
</page>
<figureCaption confidence="0.985285">
Figure 1. Relationships between the functions f, fp, hp, hp, and
</figureCaption>
<page confidence="0.964625">
18 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.476029">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.999783666666667">
Both of these problems are discussed in the follow-
ing sections (the former in sections 3 and 4, and the
latter in section 5).
</bodyText>
<sectionHeader confidence="0.496762" genericHeader="method">
3. A Theoretical Framework
</sectionHeader>
<bodyText confidence="0.974855051282052">
Before tackling the core topic of this section in a for-
mal way, let us examine from an intuitive point of
view the basic requirements for a measure of perform-
ance ir to be reasonably acceptable. The primary goal
is that it should allow consistent comparison among
different systems, in the sense that if gr(U1) = v(U2)
the behaviour of the two systems U1 and U2 should be
sufficiently similar, and that if ir(U1 )&gt;/r(U2), U1
should perform better than U2.
Furthermore, this comparison should be as fine and
precise as possible, in such a way to capture all the
essential features of the behaviour of a system U in a
given domain.
Finally, comparison might be between two different
systems, between two versions of the same system,
between a system and a given set of issues, or between
a system and an independent scale (Tennant 1980).
To capture the intuitive notion of performance
according to the above requirements, at least two
points of view seem worth considering. First, a meas-
ure of performance should give a numerical value for
the &amp;quot;distance&amp;quot; between the two functions gRu/D and
gD, that is, the measure should allow us to formalize
how near g/(e) approaches g(e) for any eeE, or,
more explicitly, how well each expression eeE is un-
derstood by the system U. Second, it should weight
this notion of &amp;quot;distance&amp;quot; in such a way as to take into
account the fact that, generally, it is not equally im-
portant to understand well any expression in E; for
example, it could be reasonable to suppose that correct
understanding of expressions in LD is far more rele-
vant than in E—LD, or that correct understanding is
more important for frequently used expressions than
for unusual and rare ones.
According to the above remarks, an appropriate
notion of performance 7T will depend on two basic pa-
rameters:
(i) the shifting ,u
between giz/D(e) and g(e) for any eeE
(ii) the importance p
for any expression eeE to be correctly under-
stood.
Different choices of p. and p clearly provide differ-
ent notions of performance, 74u,p], that fit different
needs for capturing particular classes of features in a
natural language understanding system.
Let us now go further in defining an appropriate
formal framework embedding the above ideas. In the
following, we shall omit in fD, gUR/D, and iD the super-
script U and the subscripts R/D and D, whenever this
will not cause ambiguities.
Let R be a representation language for a domain
DCS a shifting function i on R is a function
U
such that:
— for each pair (r,r&apos;), tt(r,r&apos;) = 0 iff r =
— there exists a pair (r,r&apos;) such that pt.(r,r&apos;) = 1.
From an intuitive point of view, A(g(e),i(e)) repre-
sents the &amp;quot;difference&amp;quot; between the (set of) meaning(s)
of e computed by a natural language understanding
system U, which is expressed by g(e), and its correct
(set of) meaning(s) -g(e). Hence, the value
= 0 denotes perfect understanding of e,
while A(g(e),i(e)) = 1 denotes the worst case of mis-
understanding of e.
Given the set E of all expressions of a natural lan-
guage of length less or equal than an appropriately
fixed integer n, an importance function p on E is a
function
Intuitively, p(e) represents the importance that the
meaning of e is correctly understood by the system U.
The value p(e) = 0 denotes that it is not at all impor-
tant that e be understood correctly or incorrectly;
values of p(e) greater than 0 denote the greater impor-
tance for e to be understood correctly. Given a shift-
ing function pt on R and an importance function p on
E, a performance measure 77. for natural language un-
derstanding systems UR/D is the function
</bodyText>
<equation confidence="0.555746833333333">
7[P,PFIUR/Di
defined by:
Et
,u(giij/D(e),-g-D(e))•p(e)
= eeE
7ritt,P1(UR/D)
</equation>
<bodyText confidence="0.9855955">
Clearly, ranges from the value 0, in the case
where all expressions of E are correctly understood, to
the value 1, in the case where all expressions are com-
pletely (that is, in the worst manner) misunderstood,
</bodyText>
<equation confidence="0.588025">
E p(e)
eeE
</equation>
<bodyText confidence="0.943091789473684">
Computational Linguistics, Volume 10, Number 1, January-March 1984 19
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
independently of the choice of p (of course, p=-7.0 is
not allowed, being meaningless).
rr[A,p] provides a very synthetic representation of
the performance of U that can be useful in several
cases of evaluation and comparison. A richer and
more informed picture of the performance of a system
U fully coherent with the above definitions can be
obtained in the following way, for the cases where the
ranges of p. and p are finite. For given shifting iu and
importance p, let range(p) = {81,...,80 and range(p)
= Then we pose:
= le 1 p(g(e),k(e)) = Siandp(e) =
for iEf 1,...,n1 and j€{ 1,...,n}.
Clearly, UEi = E and all E1 are pairwise disjoint.
Therefore, {E1,j1 is a partitioning of E.
Now let:
=
</bodyText>
<equation confidence="0.826692">
1 E 1
</equation>
<bodyText confidence="0.999966379310345">
for iE{1,...,n} and jE {1,...,m}. (We remember that E
has been assumed to be finite, and hence so is Ei,i gE).
The n x m matrix [1 is called the au-p-profile of
U and and provides a far more informed representa-
tion of the performance of U than the value 7[12,p]. In
fact, [pi,j] allows one to discover and analyse the
specific features of the system, going beyond the glob-
al value ir[A,p].
The relation between [p] and Tr[p.,p1 is straight-
forward:
Note that [p1 depends on t and p only through the
partitioning {Ei,j1 they induce on E, but it is inde-
pendent of the actual values of Si and
Different choices of and p clearly provide differ-
ent measures of performance that can be compared, in
general, only on a qualitative and intuitive basis.
Therefore, evaluating the performance of a system U
requires first the definition of it and p, and then the
computation of wip,p]. Clearly, the most critical of
these two steps is, from a conceptual point of view,
the first as it completely determines the &amp;quot;goodness&amp;quot; of
the measure and its actual matching with desired intui-
tive requirements. The second is only difficult from
the computational point of view since E is usually very
large and, hence, it is not possible to evaluate the sum
in the definition of v[tt,p] in a direct, exhaustive way.
In the next section we discuss in detail the problem
of appropriately defining bt and p, while section 5 is
devoted to the topic of actually computing 16,4
</bodyText>
<subsectionHeader confidence="0.915368">
4. Some Significant Choices of Shifting and
Importance Parameters
</subsectionHeader>
<bodyText confidence="0.973595">
Having discussed in the previous section an abstract
theory of performance evaluation, we now deal with
some implementations of it that may be of practical
interest. Clearly, an implementation is obtained by
assigning actual functions as values for the
(functional) parameters p. and p in the definition of IT.
Different choices of p. and p will yield different models
for performance evaluation and will allow one to ana-
lyse different features of the systems to be evaluated.
Since ji and p are fully independent parameters, we
shall deal with each separately.
Let us begin with the shifting function It; in order
that only the effect of j be relevant to IT, we shall
suppose throughout the following discussion that p has
the constant value p(e)=1 for any eEE.
The simplest case is that where ji may assume only
two (boolean) values 0 and 1, denoting a correct and a
wrong understanding, respectively. Such a boolean
shifting function is denoted by pi and formally de-
fined by:
1 0 if r&apos; =r&amp;quot;
1 if r&apos;Or&amp;quot;
for any pair (r&apos;,r&amp;quot;)E(2RU {1})x 2R.
The intuitive meaning of tti, when used to evalu-
ate a natural language understanding system U, is
straightforward: wip.1,11(U) = x denotes the percent-
age of expressions of E that U is unable to understand
correctly (clearly, 1—x is the percentage of expres-
sions correctly understood by U).
The above definition of is very crude; in fact,
systems with the same Tr[1L1,1] can show a very dif-
ferent behaviour, and, furthermore, w[p1,1](U1) &gt;
vipi,1](U2) does not generally ensure that U1 per-
forms better than U2.
A slight improvement can be obtained by splitting
the case r&apos; Or&amp;quot; into two subcases that cover, when
evaluating U, the following situations:
(i) U is unable to assign a meaning to an expression
e (that is, it fails); hence, g(e) = r&apos; = r&amp;quot; =
(e)
(ii) U assigns to an expression e a meaning that is not
the correct one; hence, g(e) = r&apos; o r&amp;quot; =
with g(e)
</bodyText>
<equation confidence="0.962700333333333">
IE1,I
n m
17.[A pi
,j = E E p• ,j • S. • co • iEi
E
p(e) •
eeE
i=1 j=1
=
</equation>
<page confidence="0.828017">
20 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.377859">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.8327227">
It seems quite reasonable that generally case (i) is
less serious than case (ii), so that we can propose a
new definition of shifting 122:
if r&apos; = r&amp;quot;
if r&apos; = 1
1 if r&apos;01 and r&apos; or&amp;quot;
where 8e(0,1).
Clearly, the choice of 8 strongly affects the values
of Tr[pc,1](U) and will depend on how much we want to
distinguish between cases (i) and (ii) mentioned
above.
Going further to propose more fitting definitions of
it, we may want to analyze in more detail the case
r&apos; 0 1 and r&apos; or&amp;quot;. Recalling that r&apos; and r&amp;quot; are sets of
strings in R, we can distinguish the following cases:
(i) U assigns to an expression e the value 0 (that is,
no meaning), while it has a well-defined mean-
ing;
U assigns to an expression e a proper nonempty
subset of its meanings;
U assigns to an expression e all its correct
meanings and, in addition, other incorrect ones;
U assigns to an expression e a proper nonempty
subset of its meanings and, in addition, other
incorrect ones;
U assigns to an expression e a nonempty set of
meanings that is fully different from the correct
one.
Formally, we can define the shifting i.t3 that covers
all such situations by:
</bodyText>
<equation confidence="0.996605875">
0 if r&apos; = r&amp;quot;
8 if r&apos; = 1
1
82 if r&apos; = q5 and r&amp;quot;
{ oyh
83 if r&apos; #4, and r&apos; cr&amp;quot;
84 if r&apos; D r&amp;quot; and r&amp;quot;o4)
85 if On r&amp;quot;00 and r&apos;—r&amp;quot;00
</equation>
<bodyText confidence="0.969952193548387">
and r&amp;quot;—r&apos; 00
1 if r&apos; 00 and r&apos; 11 r&amp;quot; = q5
where 81e(0,1), for i = 1, 2, 3,4, 5.
It could be reasonably assumed 81 &lt; 82 &lt; 83 &lt; 84
&lt; 85, since the situations to which they are attached
are generally considered as denoting increasing degrees
of misunderstanding (note that it3 deals in great detail
with the case of ambiguous understanding, where at
least one of r&apos; or r&amp;quot; is not a singleton).
Along the line of reasoning shown in the above
definitions, several other improvements are possible.
For example, we can further refine the above case (v),
r&apos;#0 and r&apos;n r&amp;quot; = 0, by taking into account the actu-
al structure of the elements of r&apos; and r&amp;quot;. R being a
well-defined formal language, we can first define an
appropriate notion of &amp;quot;distance&amp;quot; p. between elements
of R, and then extend it to nonempty disjoint elements
of 2R.
This kind of refinement is particularly significant
when both r&apos; and r&amp;quot; are singletons, that is, under-
standing is not ambiguous, as is often the case. Also,
it generally allows far more meaningful definitions of
shifting, thus further approaching the intuitive notion
of &amp;quot;distance&amp;quot; as &amp;quot;degree of understanding&amp;quot;.
Let us turn our attention now to the importance
function p.
Also for this function, a first simple proposal can
be a boolean definition: no importance at all is as-
signed to expressions in E—LD and the same (not
null) importance to every expression in LD. So we
can define pi as:
</bodyText>
<equation confidence="0.921291">
0 if eat),
p1(e) = 1 if eeLD
for each eeE.
</equation>
<bodyText confidence="0.9492157">
A refinement of pi can be obtained by analyzing
the case eeLD and taking into account the frequency
of use of expressions in LD. This will give more im-
portance to the correct understanding of more fre-
quently used expressions and less importance to that
of rare or unusual ones. From the human point of
view, it is obvious that texts with a greater frequency
are used, and hence understood, by a larger number of
people.
Therefore, it seems meaningful to consider a system
that can understand quite well the relatively small
number of the most common texts and fails on the
most unusual ones, to be better than a system that
understands a lot of very rare texts but often fails in
understanding the most common ones.
Formally, we can define the frequency of expres-
sions of e as a map z : E-,10,1], with the constraint
that E z(e) = 1. Then, we can define a new impor-
ecE
tance function i2 such that:
</bodyText>
<equation confidence="0.5677235">
z(e) if eel,D
10 otherwise
</equation>
<bodyText confidence="0.9999364">
The frequency function z(e) can be effectively deter-
mined by collecting, through an appropriate experi-
mental activity, a meaningful bag of texts T, in which
each eeE appears with a given integer multiplicity
m(e), and then by computing
</bodyText>
<equation confidence="0.997407">
A2(1-1,r&amp;quot;) = 1 8
0
kt3(0,r&amp;quot;) =
P2(e) =
</equation>
<bodyText confidence="0.453401">
Computational Linguistics, Volume 10, Number 1, January-March 1984 21
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</bodyText>
<equation confidence="0.95923775">
m(e)
z(e) =
E m(e)
eeE
</equation>
<bodyText confidence="0.999969428571428">
A totally different criterion that could be used to re-
fine the definition of importance functions is structural
complexity of the expressions of E (or of LD).
A very crude notion of structural complexity is
simply given by the length of an expression e. In this
case, given a chain 0 = 0&lt;f 1&lt;...&lt;f m_i of m non-
negative integers, we can partition E into m classes:
</bodyText>
<equation confidence="0.999171666666667">
El = ie I fo&lt; I e
E2 = {el81&lt; I e I 5-f21
Em =
</equation>
<bodyText confidence="0.946310833333333">
Then, a new importance function p3 is defined by:
p3(e) = coi if f e€Ei,
where co1E[0,1], for i = 1,...,m.
It is worth noting that the length of a text is not inde-
pendent of its frequency of use; we feel that in several
application domains (such as, for example, man-
machine interaction) short texts are much more fre-
quent than long ones and that texts exceeding a given
length are not used at all.
A more refined notion of structural complexity of
an expression may be given by taking into account its
syntactic structure, defined on the basis of an appro-
priate set of characteristic features — see, for example,
the classification proposed in Tennant (1980). E can
be partitioned into different and disjoint classes
according to the set of syntactical features they match,
and an importance function p4 can be defined as
above:
</bodyText>
<equation confidence="0.587131">
p4(e) = iff ecEi,
</equation>
<bodyText confidence="0.999937368421053">
where w1e[0,1], for i = 1,...,m.
Let us note that, contrary to the above illustrated
relation between the length of a text and its frequency,
it seems reasonable to consider syntactical complexity
as fully independent of frequency; in fact, quite com-
plex syntactical features (such as ellipsis, anaphora,
broken text, etc.) are frequently found in several ap-
plication domains.
Finally, a couple of other possible choices for as-
signing the importance function p are worth mention-
ing: one based on the notions of &amp;quot;information
content&amp;quot; or &amp;quot;structural complexity&amp;quot; according to Kol-
mogorov (1965, 1968), and the other based on the
concept of &amp;quot;semantic complexity&amp;quot; of an expression,
which could be formally defined, for example, in the
represented domain R. However, some more theoreti-
cal work on these notions is necessary before we can
use them for our needs; hence we will not further de-
velop these notions here.
</bodyText>
<subsectionHeader confidence="0.69805">
5. Measuring Performance in Practice
</subsectionHeader>
<bodyText confidence="0.980774">
In the preceding sections, some theoretical tools for
measuring the performance of a natural language un-
derstanding system have been illustrated. At this
point we have to put them to work: that is, we must
discuss how the performance of a system can be actu-
ally evaluated and how the comparison between two
different systems can be carried out.
We distinguish two steps in the process of perform-
ance evaluation:
</bodyText>
<listItem confidence="0.6017645">
(i) to assign the functions A and p;
(ii) to compute
</listItem>
<bodyText confidence="0.999534677419355">
Let us examine in detail each of the two points.
The choice &apos;of the shifting function A depends only
on the degree to which we want to refine the notion of
error in understanding and on the varying importance
we want to assign to each type of error. Hence it is
often only a matter of subjective feeling choosing ap-
propriate values for A in order to analyse particular
features of the system to be evaluated. Also, the defi-
nition of A is strongly dependent on the representation
language R for the domain D: the richer and more
structured R is, the more refined and subtle are the
possible definitions of A.
On the contrary, however, the choice of the impor-
tance function p can generally be based on more ob-
jective arguments, once an appropriate ranking among
the desired understanding capabilities of the system to
be evaluated has been defined. For example, in the
case where the frequency of texts is taken into ac-
count, an appropriate experimental activity can pro-
vide reliable statistical estimations for the frequency
z(e) of each expression e€E, thus allowing the effec-
tive computation of p(e). (Problems connected with
the choice of a meaningful sample to estimate z(e) —
which could freely include millions of millions of ex-
pressions — are not dealt with here, since they are
more related to statistics than to computational lin-
guistics.)
Clearly, the choice of A and p fully determines the
numerical value of I-414p] (or of the matrix [pi,j]) in
correspondence to a given system U. How a change in
A or p can affect Tr[p,,p] is generally impossible to pre-
</bodyText>
<page confidence="0.955753">
22 Computational Linguistics. Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.654158">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.9999087">
dict, since this strongly depends on the particular fea-
tures of U. Therefore, evaluating a system with differ-
ent choices of A or p can indeed provide a clearer im-
age of its performance. Although the comparison
between different values of Ir obtained with different
pairs (u,p) is often only a matter of intuitive reason-
ing, an interesting particular case that can be conven-
iently dealt with formally is briefly sketched below.
A shifting function AI is a refinement of a shifting
function p (ODA) iff:
</bodyText>
<listItem confidence="0.787942428571428">
— range(u) = 131,...,80 with
— range(&apos;) = {8&apos;1,...,8&apos;n,j, with 6&apos;i&lt; 82&lt;...&lt;
8&apos; n, and n&apos; &gt;n ;
— the partitioning {E&apos;t } of E induced by IL&apos; is a re-
finement of the partitioning {E11 of E induced by
A;
— for each class Ei = U E&apos;, where
</listItem>
<equation confidence="0.98507175">
trET
T = {t1,.. .,t1} g 11,...,n&apos; j, with tt&lt; t2&lt;...&lt; ti:
i—l&lt;81 ti&lt;S, t 2&lt; • • • &lt;V =
or
</equation>
<bodyText confidence="0.999193282051282">
In an analogous way we can define the refinement
p&apos; of an importance function p (p&apos; DI)).
A pair (.0 ,p&apos;) is a refinement of a pair (p,,p) (we
write (&apos;,p&apos;) (p,p)) iff A and p&apos; p.
It is straightforward to prove that:
For any system U and any two pairs (a,p) and
(Iii,p) implies iT[ti&apos;
For example, the shifting function u3 in section 4
refines A2, which in turn refines At, that is,
pt A3. For the importance function p, on the other
hand, not one of the functions pp p2, p3, p4, in
section 4 is a refinement of any other one.
It is worth noting that, when defining appropriate
pairs (u,p) to evaluate a system, there are basically
two ways of reasoning for comparing different choices:
the first one is to start from a first basic proposal and
to proceed through successive refinements until the
desired degree of precision and detail is reached; the
second one consists in proposing functions correspond-
ing to several different points of view and then inte-
grating them together in a well-balanced synthesis.
Generally, the first approach is appropriate for the
definition of p, while the second one can be utilized
for the choice of p.
Let us turn now to the problem of computing
once p. and p have been assigned.
Obviously, it is unrealistic to compute the exact
value of 77- by considering the behaviour of the system
with respect to every expression e€E. Hence, a se-
quence of test cases has to be considered (Gold 1967).
Figure 2 shows a model for experimental perform-
ance evaluation. A GENERATOR provides at each
time instant i (i=1,2,...) an expression et€E. Then,
the system U to be evaluated computes the meaning
g(ed, which is compared by A with the correct mean-
ing (ei) supplied by an EVALUATOR (a man suppos-
ed to be able to compute g, that is, both f and II).
Finally, the value p(e1) is computed, and the current
value of
</bodyText>
<equation confidence="0.9718645">
E p(g(ei),i(ej)) • p(e)
i=1
E
171
</equation>
<bodyText confidence="0.986911777777778">
is determined.
The major problem with the computation of r is
the design of the GENERATOR, that is, the choice of
the sample of E to be used for the evaluation of the
system U.
The mathematically simplest case is the one where
a subset B g E is randomly generated on the basis of a
given probability distribution in E (for example, equi-
probability); then,
</bodyText>
<equation confidence="0.99563475">
E p(g(e),i(e)) • p(e)
eeB
E p(e)
e€B
</equation>
<bodyText confidence="0.999911578947369">
is a random variable such that E(17n) = IT for reason-
able distributions, where E(ITB) denotes the expecta-
tion of TrB. The value of E(TrB) may be estimated by
means of statistical techniques such as, for example,
the maximum likelihood function. Here, we will not
give a detailed account of such techniques. They can
be easily found in classical works of statistics and sam-
pling theory (Kobayashi 1978; Cox, Hinkley 1977;
Mood, Graybill 1980), when needed.
A different technique would be that of fixing a
confidence interval, and then establishing the number
n of tests to be generated in order to obtain the value
of 17-(,p) within the given confidence level, by means,
for example, of x2 techniques.
In addition to these elementary statistical methods,
more sophisticated sampling techniques can be used.
This requires us first to choose a partitioning of E into
meaningful classes, and then to define a sample strati-
fied according to the considered partitioning. In this
</bodyText>
<figure confidence="0.898845333333333">
B =
Computational Linguistics, Volume 10, Number 1, January-March 1984 23
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</figure>
<figureCaption confidence="0.975239">
Figure 2. A model for experimental performance evaluation.
</figureCaption>
<figure confidence="0.88527875">
ei
_..1system U
to be evaluated
EVALUATOR
p(e)
j=1
p led
g
E ii(g(ei).§(ei))•p(ei)
j=1 IC;
E
GENERATOR
</figure>
<bodyText confidence="0.982648761904762">
case, the GENERATOR might not work on a purely
random basis.
All the above-mentioned techniques are independ-
ent of the choice of p, and do not take into account
specific goals that could be assigned to performance
evaluation (for example, syntactic capabilities, linguis-
tic or conceptual competence, etc.). Such general
purpose methods can sometimes provide a too much
global and too less meaningful evaluation. Moreover,
the sample to be used for the computation of 7T is gen-
erally very large and hard to collect.
Special purpose evaluation, centered on the analysis
of some specific features of U, can often be more
interesting and easier to implement. In this case, the
specific goal of the measurement should be carefully
taken into account in the definition of p, and both the
goal and p should direct the choice of the appropriate
sample of E to be used for the experimental computa-
tion of ir. More precisely, an experimental (special
purpose) evaluation session could be organized as
follows:
</bodyText>
<listItem confidence="0.992127666666667">
1. precisely individuating the system U, the domain
D, and the representation language R;
2. defining the goals of the evaluations;
3. deciding which samples of E to collect and how to
collect them;
4. defining IL;
5. defining p (and how to compute it for the chosen
samples);
6. computing 7T (and/or [pi,j]).
</listItem>
<bodyText confidence="0.999514285714286">
Note that several j and p could be generally consid-
ered for a careful experimentation. Moreover, steps 3,
4, and 5 might require, in critical cases, specific pre-
experimentation and some refinement loops for appro-
priate tuning.
In the appendix, a limited case study experimenta-
tion is briefly discussed.
</bodyText>
<sectionHeader confidence="0.956085" genericHeader="method">
6. Discussion and Future Research Directions
</sectionHeader>
<bodyText confidence="0.9991643125">
In this paper we have presented a model for perform-
ance evaluation of natural language understanding
systems. The main task of this model is that of pro-
viding a basis for a quantitative measure of how well a
system can understand natural language, thus allowing
an objective and experimental comparison of the per-
formance of different systems.
Before discussing some open problems and illustrat-
ing the main lines of future research, let us briefly
discuss some further features of our approach by com-
paring it to the classical work by Tennant (1979,
1980) and by Finin, Goodman, and Tennant (1979).
Tennant&apos;s proposal is based on the three main con-
cepts of habitability, completeness, and abstract analy-
sis. This last point is not considered here, as ex-
plained in section 1 (see further in this section for its
</bodyText>
<page confidence="0.979488">
24 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.75729">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.977629658536586">
possible relevance to future work); we therefore focus
on the first two. From a naïve point of view, habita-
bility is used to test whether or not the system does
what it was designed to do; completeness is introduced
to test whether or not the system meets users&apos; require-
ments. More precisely, Tennant introduces the two
notions of coverage and completeness to denote, respec-
tively, the capabilities (both conceptual and linguistic)
that the designer has put within a system, and
(similarly to Woods, Kaplan, Nash-Webber 1972
though differing from Woods 1977) the degree to
which the capabilities expected by a set of users can
actually be found in the system coverage. Further-
more, habitability denotes (quite differently from Watt
1968) the degree to which a system can actually ex-
hibit the capabilities that it was designed to have.
Our approach is based on a slightly different model
and provides in some sense a refinement of the above
concepts.
We denote by the term competence the capabilities
that a system is actually able to show, while by the
term coverage we refer, according to Tennant, to the
theoretical capabilities that a system should have as a
consequence of its design specifications.
More precisely, the conceptual coverage of a sys-
tem UR/D is formalized in our model by the domain
D, which represents, in fact, the range of concepts that
are within the domain of discourse of a given applica-
tion.
The linguistic coverage clearly includes LD but,
generally, is not limited to LD since understanding a
language in a given domain also implies the capability
of recognizing that some expressions are not meaning-
ful in that domain.
In general, for a given importance function p, we
can assume that the linguistic coverage is defined by:
L&apos;D = le I ecE and p(e)&gt;i,
where A(0 &lt; A&lt;l) is a fixed bound.
The linguistic competence can then be defined as:
L&apos;D = fe I e€L&apos;D and g(e) =
and the conceptual competence as:
</bodyText>
<equation confidence="0.8665745">
D = U fD(e).
CEL, D
</equation>
<bodyText confidence="0.99359715">
The above concepts are summarized in Figure 3.
Our definition of performance ir[jt,p] tries to give a
global idea of how well the competence of a system
(without distinction between conceptual and linguistic
aspects) approaches its coverage. This measure is
quite similar to, and provides a refinement of, the
concept of habitability, involving also to some extent
the notion of completeness. In fact, both the choice
of D as an adequate domain and the definition of p as
a suitable importance function (and, therefore, of
L&apos;D) implicitly refer to a set of users and then to
completeness.
It is apparent that the proposal introduced in this
paper demands further work, both theoretical and
experimental, in order to have fully adequate tools for
performance evaluation.
First of all, some of the concepts presented here
have to be further discussed and expanded. For exam-
ple, in the definition of IT, we have normalized it with
respect to p by setting:
</bodyText>
<equation confidence="0.8434028">
IT =
A different choice could be:
E au•p
IT =
E
</equation>
<bodyText confidence="0.999978705882353">
where it and p are given the same importance (in this
case the value ir=1 would be reached only when all
expressions of E are fully misunderstood, that is,
p.-=-1, and when it is important at the highest degree
that each of them is correctly understood, that is,
p1). While we have preferred here the first defini-
tion, arguments could be given in favour of the sec-
ond.
A second critical point is the definition of the
tt—p-profile [p11]. This could be further extended so
as to provide a picture of several dimensions (features,
for example: frequency, syntactic complexity, informa-
tion content, etc.). Third, it is worthwhile considering
and improving the notion of refinement: in fact, the
present definition is not stable with respect to the
choice of IA and p. That is, it could be that, given two
systems U and U&apos;:
</bodyText>
<equation confidence="0.834075">
Trki,p1(u) &lt; IT[A,p](tp)
</equation>
<bodyText confidence="0.9100012">
and, for some refinement (&apos;,p&apos;) of (,u,p):
&gt; ithe,pq(U),
so that the refinement of the evaluation criteria may
give an inversion of the first evaluation. A formal
development of the three points mentioned above will
</bodyText>
<figure confidence="0.51597875">
Computational Linguistics, Volume 10, Number 1, January-March 1984 25
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
capabilities expected by
the users
</figure>
<figureCaption confidence="0.999452">
Figure 3. Coverage and competence of a natural language understanding system.
</figureCaption>
<figure confidence="0.999612909090909">
1
1
1
HABITABILITY
1
1
1
1
system
performance
level
/
/
/
/
/
/
/
/
/
COMPLETENESS
system
design
level
NATURAL LANGUAGE
UNDERSTANDING
SYSTEM
U
■
■
\
\
\
</figure>
<page confidence="0.818311">
26 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.646673">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.908079">
be part of a future paper.
For what concerns the main directions in the devel-
opment of the current research activity, we mention:
</bodyText>
<listItem confidence="0.991991916666667">
• experimentation with the model proposed in the
evaluation of large systems;
• development of appropriate sampling techniques for
the experimental evaluation of IT;
• experimentation with several different choices of
and p;
• design of techniques for special purpose evaluation
(choice of the goal, definition of s and p, sampling,
etc.);
• analysis of the adequacy of the notion of au-p-profile
for representing all interesting details of the per-
formance of a system.
</listItem>
<bodyText confidence="0.999873488372093">
Beyond these issues we also point out two more
ambitious and promising problems; they will be faced
in future work. The approach to performance evalua-
tion presented in this paper has two major limitations:
first, it is only concerned with input-output behaviour
and does not take into account the internal model on
which a system is based; second, it does not deal with
the efficiency of the natural language understanding
process. As far as the former topic is concerned, it is
clear that, except in the case where commercial appli-
cations are considered, one is primarily interested in
models rather than in particular implementations. It is
far more significant that a model, a knowledge repre-
sentation method, and a parsing algorithm have been
designed to build natural language understanding sys-
tems rather than that a specific system has been con-
structed in a particular domain for a particular use.
Tennant (1980) (see also Woods 1977) proposes a
method, called abstract analysis, to organize in an in-
formal but disciplined way the evaluation, through
taxonomies of conceptual, linguistic, and implementa-
tional issues, of the internal behaviour of a natural
language system (including analysis of failure causes,
domain dependent features, knowledge base complete-
ness and closure, algorithm deficiencies, extensibility,
etc.). A very demanding research issue that could
substantially contribute to the development of the
research on natural language processing is the defini-
tion of more formal methods that, starting from the
above proposal, allow a &amp;quot;deep&amp;quot; evaluation and com-
parison of systems on the basis of their internal struc-
ture and mode of operation, opposed to the &amp;quot;surface&amp;quot;
measure of their input-output behaviour, as considered
in the present paper.
Concerning the latter topic, efficiency, two aspects
seem worth considering: the experimental measure of
the efficiency of a specific system in understanding
natural language that could appropriately complete the
concept of performance defined in the present work;
and the theoretical evaluation of the complexity of the
general model underlying the construction of a particu-
lar system, which could possibly complete the notion
of &amp;quot;deep&amp;quot; evaluation mentioned above.
</bodyText>
<sectionHeader confidence="0.968002" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999785">
We are grateful to the anonymous referees for their
useful criticism and suggestions.
We would also like to acknowledge the appreciated
support provided by CSELT Laboratories (Torino,
Italy) with the experimentation of the PARNAX sys-
tem.
</bodyText>
<sectionHeader confidence="0.989876" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.998425444444444">
Comino, R.; Gemello, R.; Guida, G.; Rullent, C.; Sisto, L.; and
Somalvico, M. 1983 Understanding Natural Language
Through Parallel Processing of Syntactic and Semantic Knowl-
edge: An Application to Data Base Query. In Proc. 8th Int.
Joint Conference on Artificial Intelligence. Karlsruhe, West Ger-
many: 663-667.
Cox, D.R. and Hinkley, D.V. 1974 Theoretical Statistics. Chapman
and Hall, London.
Finin, T.; Goodman, B.; and Tennant, H. 1979 JETS: Achieving
Completeness Through Coverage and Closure. In Proc. 6th Int.
Joint Conference on Artificial Intelligence. Tokyo, Japan: 275-
281.
Gold, E.M. 1967 Language Identification in the Limit. Informa-
tion and Control 10: 447-474.
Kaplan, J. 1982 Special Section: Natural Language Processing.
ACM SIGART Newsletter 79: 27-109 and 80: 59-61.
Kolmogorov, A.N. 1965 Three Approaches to the Concept of
&amp;quot;The Amount of Information&amp;quot;. Probl. of Information
Transmission 1(1): 3-11.
Mood, R.S. and Graybill, 1980 Introduction to Statistics.
McGraw-Hill, Englewood Cliffs, New Jersey.
Tennant, H. 1979 Experience with the Evaluation of Natural
Language Question Answerers. In Proc. 6th Int. Joint Confer-
ence on Artificial Intelligence. Tokyo, Japan: 874-876.
Tennant, H. 1980 Evaluation of Natural Language Processes.
Report T-I03. Coordinated Science Laboratory, University of
Illinois, Urbana, Illinois.
Waltz, D. 1977 Natural Language Interfaces. ACM SIGART
Newsletter 61: 16-64.
Watt, W.C. 1968 Habitability. American Documentation 338-351.
Woods, W.A. 1977 A Personal View of Natural Language Under-
standing. ACM SIGART Newsletter 61: 17-20.
Woods, W.A.; Kaplan, R.M.; and Nash-Webber, B. 1972 The
Lunar Sciences Natural Language Information System: Final
Report. Report 2378. Bolt Beranek and Newman, Cambridge,
Massachusetts.
</reference>
<page confidence="0.292553">
Computational Linguistics, Volume 10, Number 1, January-March 1984 27
</page>
<note confidence="0.712865">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<sectionHeader confidence="0.983539" genericHeader="method">
Appendix
</sectionHeader>
<bodyText confidence="0.997288181818182">
In this appendix we present a limited case study ex-
perimentation with the model proposed, which should
help in concretely conveying the ideas on how an eval-
uation session could be carried out in practice. Wider
experiments will be the subject of a future paper.
For this limited experimentation we have chosen
the PARNAX system (Comino et al. 1983): a natural
language interface for querying in Italian ADABAS
data bases. The toy data base utilized concerns the
employees of a company, and contains just the
EMPLOYEE file with the following record structure:
</bodyText>
<figure confidence="0.975077875">
NAME
DATE-OF-BIRTH
PLACE-OF-BIRTH
PLACE-OF-RESIDENCE
HIRING-DATE
DEPARTMENT
JOB-LEVEL
DEGREE
</figure>
<bodyText confidence="0.979913301886793">
The PARNAX system, that is, the natural language
understanding system U to be evaluated, maps natural
language queries (more generally, query dialogues)
into expressions of the formal query language used to
access the ADABAS data base, namely the NATURAL
language.
Owing to the very simple data base chosen, the
domain D is reasonably limited, and so are LD (the
set of all possible queries in Italian to the EMPLOYEE
file) and R (the set of all possible NATURAL queries).
We consider two goals for this experiment: namely,
evaluating some aspects of the conceptual competence
and of the linguistic competence.
According to these goals, two samples of queries
have been collected from L&apos;D2LD (recall that the
linguistic coverage L&apos;D ..cE should generally be larger
than LD — see section 6):
A: A sample of casual queries to the data base. Nine
hundred fifty queries have been collected from 90
people chosen from several different classes of
possible users of the data base.
B: A sample of linguistic variations for expressing a
specific request. The sentence to be rephrased
has been chosen of medium-level complexity with
respect to the sample data base so as to allow
meaningful linguistic variations to be formed.
The query utilized is: &amp;quot;Tell me the birth-date of
all employees who have a master degree in
mathematics&amp;quot;. Five hundred queries have been
collected from 35 people.
The sample A was then slightly preprocessed before
being used for the evaluation. A new sample A&apos; was
obtained from A through the following operations:
(i) eliminating all queries expressing the same request
(not having the same answer!), except one;
(ii) eliminating all queries differing only for the val-
ues of the attributes (for example, &amp;quot;Tell me the
birth-date of John&amp;quot; and &amp;quot;Tell me the birth-date
of Robert&amp;quot;), except one.
Note that this preprocessing constitutes a kind of very
naïve stratification, consisting in the choice of only
some elements as representative for a class of cases.
A&apos; contains about 800 queries.
The shifting function p. has been chosen to be the
boolean function:
= {0 if g(e) = g(e)
1 if g(e)O(e)
(see section 4, 1) for the analysis both of A&apos; and B.
Several different choices have been taken for the
importance function p. For what concerns the sample
A&apos;, two functions have been considered:
—
pIl
</bodyText>
<equation confidence="0.9987815">
0 if eaD
P2(e) = ii if eELD
</equation>
<bodyText confidence="0.998626727272727">
(see section 4, p2).
For the sample B the most natural choice for p
seemed to be the frequency of queries. Unfortunately,
only very few (3!) queries in sample B turned out to
be repeated (one repetition for two queries, two repe-
titions for another query; note that this result is highly
surprising even if the set from which B has been ex-
tracted is enormously large). Therefore, frequency
was abandoned. Two other criteria were considered:
namely length and structural features.
For what concerns the former, the length (number
of words) of each sentence was computed first and
Table 1 obtained. The length interval [5,26] was then
partitioned into three parts:
= [12,16], into which about 70% of the sentences
of B fall;
12 = [7,11]U[17,18], includes about 25% of the ex-
pressions of B;
13 = [5,61U[19,26], to which less than 5% of the
sentences of B belong.
The following importance function p3 has been
defined:
</bodyText>
<equation confidence="0.988982">
{0.70 if ea 1
p3(e) = 0.25 if ecI2
0.05 if eEI3
</equation>
<bodyText confidence="0.99705775">
Here, the importance of recognizing an expression
is assumed to be proportional to the &amp;quot;weight&amp;quot;
(cardinality) of the length class to which it belongs.
For what concerns the latter criterion, we first defined
a taxonomy of linguistic elements suitable for analys-
ing the structural features of the sentences of Sample
B. The following attributes were considered (Tennant
1980):
</bodyText>
<page confidence="0.94985">
28 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
<note confidence="0.441783">
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
</note>
<bodyText confidence="0.996439722222222">
declarative structure
interrogative structure
imperative structure
telegraphic sentences
V cleft and discontinuous sentences, parenthetic
clauses, inversions
multiple sentences
relative clauses
interrogative clauses
non-finite clauses (-ing, -ed participle)
prepositional phrases
quantifiers, predeterminers
possessive and demonstrative clauses, personal
pronouns
The sentences of B were then classified according to
the above taxonomy by assigning to each of them all
the relevant attributes. Fifty-two classes were ob-
tained:
</bodyText>
<figure confidence="0.990567782608696">
44 containing 1 to 12 sentences (total 315)
5 containing 13 to 24 sentences (total
3 containing 25 to 36 sentences (total
LENGTH NUMBER OF
SENTENCES
5 2
6 7
7 11
8 17
9 13
10 25
11 40
12 53
13 130
14 62
15 45
16 50
17 24
18 12
19 5
20 2
21 1
26 1
</figure>
<tableCaption confidence="0.99745">
Table 1.
</tableCaption>
<bodyText confidence="0.999542555555556">
This result suggested restricting the analysis to a
smaller number of classes to be obtained through a
less refined taxonomy of linguistic elements. The fol-
lowing attributes, which characterize the most crude
features of the sentence structure, were chosen: D, G,
E, T, V, M. Ten classes have now been obtained as
shown in Table 2 (each class is denoted by the string
of attributes that characterizes the structure of the
sentences belonging to it).
</bodyText>
<sectionHeader confidence="0.868416" genericHeader="method">
STRUCTURE NUMBER OF
SENTENCES
</sectionHeader>
<figure confidence="0.9722496">
22
91
DV 6
DM 27
79
GM 5
174
EV 44
EM 33
EVM 19
</figure>
<tableCaption confidence="0.994358">
Table 2.
</tableCaption>
<bodyText confidence="0.997920666666667">
The importance function p4 has therefore been
defined to be exactly the frequency of the class to
which every expression belongs, that is:
</bodyText>
<construct confidence="0.9841466">
if eET
if eED
if eEDV
if eEDM
if eEG
if eEGM
if eEE
if eEEV
if eEEM
if e EEVM
</construct>
<bodyText confidence="0.99748625">
Using the samples A&apos; and B and the ht and p functions
defined above, the performance of the PARNAX sys-
tem was evaluated. The following results were ob-
tained:
</bodyText>
<figure confidence="0.997582418604651">
P4(e) = .044
.182
.012
.054
.158
.010
.348
.088
.066
.038
Computational Linguistics, Volume 10, Number 1, January-March 1984 29
Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS
[Pi,j1
r0.41
L0.59i
IT = -472 =0.59
&apos; 800
[Pid]
7T 2 =
371
= 0.53
701
10.00 0.41 1
L0.12 0.47J
274,4 0.30
IT 3 =
Case 3: sample B with j and p3
81,4 =
= [0.03
L 0.01
0.15 0.00
0.04 0.01
Case 4: sample B with p, and p4
21.778
IT =
4 98.916 =0.22 [p..]
Case 1: sample A&apos; with and p1
Case 2: sample A&apos; with p, and p2
0.01 0.11 0.00 0.29 0.07 0.02 0.01 1
0.04 0.05 0.01 0.06 0.02 0.04 0.03J
10.49 0.19 0.01 1
L0.19 0.09 0.03J
[Pi ji
</figure>
<bodyText confidence="0.999190176470588">
A few comments on the above results can be add-
ed. A global analysis of IT shows that the linguistic
capabilities of PARNAX are generally higher than the
conceptual ones (71,72 &gt;&gt; 73,174). In particular, the
value of /7-4, which relies on a fine analysis of syntac-
tic features, seems very good.
Examining further the A-p-profiles obtained (except
case 1, which is not meaningful), several interesting
details of the system performance may be pointed out.
Cases 2 and 3 show that the system performs better in
correspondence to sentences with higher importance,
and, hence, it is reasonably well tailored. On the con-
trary, it generally lacks robustness. Finally, case 4
(especially when the analysis with 52 classes, not re-
ported here, is considered) provides to the system
designer a lot of useful suggestions for corrections and
improvements.
</bodyText>
<page confidence="0.936363">
30 Computational Linguistics, Volume 10, Number 1, January-March 1984
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254708">
<title confidence="0.999375">A Formal Basis for Performance of Natural Language Understanding Systems</title>
<author confidence="0.607854">Guidal</author>
<author confidence="0.607854">Giancarlo</author>
<affiliation confidence="0.764940333333333">Matematica, e Universiti di Udine, Italy</affiliation>
<abstract confidence="0.985336666666667">The task of evaluating the performance of a natural language understanding system, despite its largely recognized relevance, is still poorly defined. It mostly relies on intuitive reasoning and lacks a sound theoretical foundation. This paper sets a formal and quantitative proposal for this task. In particular, a measure of performance that allows the basic input-output characteristics of a system to be evaluated is introduced first at an abstract level. The definition of concrete measures is then obtained by assigning actual values to the functional parameters of the abstract definition; some particular cases are shown and discussed in detail. Finally, the task of measuring performance in practice is considered, and a model for experimental performance evaluation is presented. Comparison with related works is also briefly discussed; open problems and promising directions for future research are outlined. A limited case study experimentation with the model proposed is presented in the appendix.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Comino</author>
<author>R Gemello</author>
<author>G Guida</author>
<author>C Rullent</author>
<author>L Sisto</author>
<author>M Somalvico</author>
</authors>
<title>Understanding Natural Language Through Parallel Processing of Syntactic and Semantic Knowledge: An Application to Data Base Query.</title>
<date>1983</date>
<booktitle>In Proc. 8th Int. Joint Conference on Artificial Intelligence.</booktitle>
<pages>663--667</pages>
<location>Karlsruhe, West Germany:</location>
<marker>Comino, Gemello, Guida, Rullent, Sisto, Somalvico, 1983</marker>
<rawString>Comino, R.; Gemello, R.; Guida, G.; Rullent, C.; Sisto, L.; and Somalvico, M. 1983 Understanding Natural Language Through Parallel Processing of Syntactic and Semantic Knowledge: An Application to Data Base Query. In Proc. 8th Int. Joint Conference on Artificial Intelligence. Karlsruhe, West Germany: 663-667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Cox</author>
<author>D V Hinkley</author>
</authors>
<title>Theoretical Statistics.</title>
<date>1974</date>
<publisher>Chapman and Hall,</publisher>
<location>London.</location>
<marker>Cox, Hinkley, 1974</marker>
<rawString>Cox, D.R. and Hinkley, D.V. 1974 Theoretical Statistics. Chapman and Hall, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Finin</author>
<author>B Goodman</author>
<author>H Tennant</author>
</authors>
<title>JETS: Achieving Completeness Through Coverage and Closure.</title>
<date>1979</date>
<booktitle>In Proc. 6th Int. Joint Conference on Artificial Intelligence.</booktitle>
<pages>275--281</pages>
<location>Tokyo, Japan:</location>
<marker>Finin, Goodman, Tennant, 1979</marker>
<rawString>Finin, T.; Goodman, B.; and Tennant, H. 1979 JETS: Achieving Completeness Through Coverage and Closure. In Proc. 6th Int. Joint Conference on Artificial Intelligence. Tokyo, Japan: 275-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<title>Language Identification in the Limit.</title>
<date>1967</date>
<journal>Information and Control</journal>
<volume>10</volume>
<pages>447--474</pages>
<contexts>
<context position="33003" citStr="Gold 1967" startWordPosition="5743" endWordPosition="5744"> precision and detail is reached; the second one consists in proposing functions corresponding to several different points of view and then integrating them together in a well-balanced synthesis. Generally, the first approach is appropriate for the definition of p, while the second one can be utilized for the choice of p. Let us turn now to the problem of computing once p. and p have been assigned. Obviously, it is unrealistic to compute the exact value of 77- by considering the behaviour of the system with respect to every expression e€E. Hence, a sequence of test cases has to be considered (Gold 1967). Figure 2 shows a model for experimental performance evaluation. A GENERATOR provides at each time instant i (i=1,2,...) an expression et€E. Then, the system U to be evaluated computes the meaning g(ed, which is compared by A with the correct meaning (ei) supplied by an EVALUATOR (a man supposed to be able to compute g, that is, both f and II). Finally, the value p(e1) is computed, and the current value of E p(g(ei),i(ej)) • p(e) i=1 E 171 is determined. The major problem with the computation of r is the design of the GENERATOR, that is, the choice of the sample of E to be used for the evalua</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>Gold, E.M. 1967 Language Identification in the Limit. Information and Control 10: 447-474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kaplan</author>
</authors>
<title>Special Section: Natural Language Processing.</title>
<date>1982</date>
<journal>ACM SIGART Newsletter</journal>
<volume>79</volume>
<pages>27--109</pages>
<contexts>
<context position="1415" citStr="Kaplan 1982" startWordPosition="205" endWordPosition="206">me particular cases are shown and discussed in detail. Finally, the task of measuring performance in practice is considered, and a model for experimental performance evaluation is presented. Comparison with related works is also briefly discussed; open problems and promising directions for future research are outlined. A limited case study experimentation with the model proposed is presented in the appendix. 1. Introduction Research on natural language processing has recently been featured by the design and implementation of a number of experimental systems. Recent survey reports (Waltz 1977, Kaplan 1982) mention more than one hundred items among the most successful and relevant systems in the classical application fields of data base inquiry, machine translation, question answering, and man-machine interfacing. This trend is not surprising in the context of research whose specific aim is that of providing automated tools for the understanding or translating of natural languages; but it is also evident even in natural language research with a more theoretical flavour. The successful construction of a good performing system is Address: Prof. Giovanni Guida Dipartimento di Elettronica Politecnic</context>
</contexts>
<marker>Kaplan, 1982</marker>
<rawString>Kaplan, J. 1982 Special Section: Natural Language Processing. ACM SIGART Newsletter 79: 27-109 and 80: 59-61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A N Kolmogorov</author>
</authors>
<title>Three Approaches to the Concept of &amp;quot;The Amount of Information&amp;quot;.</title>
<date>1965</date>
<journal>Probl. of Information Transmission</journal>
<volume>1</volume>
<issue>1</issue>
<pages>3--11</pages>
<contexts>
<context position="28212" citStr="Kolmogorov (1965" startWordPosition="4890" endWordPosition="4892">s above: p4(e) = iff ecEi, where w1e[0,1], for i = 1,...,m. Let us note that, contrary to the above illustrated relation between the length of a text and its frequency, it seems reasonable to consider syntactical complexity as fully independent of frequency; in fact, quite complex syntactical features (such as ellipsis, anaphora, broken text, etc.) are frequently found in several application domains. Finally, a couple of other possible choices for assigning the importance function p are worth mentioning: one based on the notions of &amp;quot;information content&amp;quot; or &amp;quot;structural complexity&amp;quot; according to Kolmogorov (1965, 1968), and the other based on the concept of &amp;quot;semantic complexity&amp;quot; of an expression, which could be formally defined, for example, in the represented domain R. However, some more theoretical work on these notions is necessary before we can use them for our needs; hence we will not further develop these notions here. 5. Measuring Performance in Practice In the preceding sections, some theoretical tools for measuring the performance of a natural language understanding system have been illustrated. At this point we have to put them to work: that is, we must discuss how the performance of a syst</context>
</contexts>
<marker>Kolmogorov, 1965</marker>
<rawString>Kolmogorov, A.N. 1965 Three Approaches to the Concept of &amp;quot;The Amount of Information&amp;quot;. Probl. of Information Transmission 1(1): 3-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Mood</author>
<author>Graybill</author>
</authors>
<title>Introduction to Statistics. McGraw-Hill,</title>
<date>1980</date>
<location>Englewood Cliffs, New Jersey.</location>
<marker>Mood, Graybill, 1980</marker>
<rawString>Mood, R.S. and Graybill, 1980 Introduction to Statistics. McGraw-Hill, Englewood Cliffs, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tennant</author>
</authors>
<title>Experience with the Evaluation of Natural Language Question Answerers. In</title>
<date>1979</date>
<booktitle>Proc. 6th Int. Joint Conference on Artificial Intelligence.</booktitle>
<pages>874--876</pages>
<location>Tokyo, Japan:</location>
<contexts>
<context position="4865" citStr="Tennant 1979" startWordPosition="748" endWordPosition="749">eral assumptions we discuss below. First, we assume as object of our attention only that module of a natural language system that is devoted to understanding natural language, that is, to mapping input expressions into formal internal representations. This can clearly include several kinds of processing activities, such as linguistic analysis, reasoning, inferencing, etc.; but must have as ultimate goal the construction of a correct internal representation, not the production of any type of service to the end user of the natural language system. Thus, for example, a question answering system (Tennant 1979) does not belong to the class of natural language understanding systems that concern us; instead, it is the natural language interface it contains that meets exactly our requirements. Second, we assume the following naïve notion of performance: the extent to which a system is able to correctly understand natural language expressions in a given application domain. The resources needed by the system to accomplish its task are irrelevant in this case. In other words, we want to capture and measure the &amp;quot;power&amp;quot; of the system, in terms of how much and how well it is capable of understanding, not its</context>
<context position="37341" citStr="Tennant (1979" startWordPosition="6475" endWordPosition="6476"> briefly discussed. 6. Discussion and Future Research Directions In this paper we have presented a model for performance evaluation of natural language understanding systems. The main task of this model is that of providing a basis for a quantitative measure of how well a system can understand natural language, thus allowing an objective and experimental comparison of the performance of different systems. Before discussing some open problems and illustrating the main lines of future research, let us briefly discuss some further features of our approach by comparing it to the classical work by Tennant (1979, 1980) and by Finin, Goodman, and Tennant (1979). Tennant&apos;s proposal is based on the three main concepts of habitability, completeness, and abstract analysis. This last point is not considered here, as explained in section 1 (see further in this section for its 24 Computational Linguistics, Volume 10, Number 1, January-March 1984 Giovanni Guida and Giancarlo Mauri A Formal Basis for Performance Evaluation of NLUS possible relevance to future work); we therefore focus on the first two. From a naïve point of view, habitability is used to test whether or not the system does what it was designed </context>
</contexts>
<marker>Tennant, 1979</marker>
<rawString>Tennant, H. 1979 Experience with the Evaluation of Natural Language Question Answerers. In Proc. 6th Int. Joint Conference on Artificial Intelligence. Tokyo, Japan: 874-876.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tennant</author>
</authors>
<title>Evaluation of Natural Language Processes.</title>
<date>1980</date>
<tech>Report T-I03.</tech>
<institution>Coordinated Science Laboratory, University of Illinois,</institution>
<location>Urbana, Illinois.</location>
<contexts>
<context position="2648" citStr="Tennant 1980" startWordPosition="397" endWordPosition="398">onardo da Vinci, 32 1-20133 MILANO, Italy Also with Milan Polytechnic Artificial Intelligence Project, Milano, Italy. 2 Also with Istituto di Cibernetica, Universita di Milano, Milano, Italy. in fact often considered as the most evident proof of the validity of a theory, and, therefore, designing running systems is routine, and even sometimes the specific goal of several researchers. The task of evaluating the performance of a given system and that of comparing the behaviour of different systems appears, therefore, to be a fundamental issue. Despite its large recognized relevance (Woods 1977, Tennant 1980), measuring the performance of a system for natural language processing is still poorly defined. It mostly relies on intuitive reasoning and lacks a sound theoretical foundation. As Tennant clearly points out (1980), there is a nearly complete absence of meaningful evaluation in current natural language processing research. This leaves several crucial questions unanswered: • What is the relevance and value of obtained results? • How general are the proposed solutions? • How do they compare with other proposals? • What problems are still open? • What directions have to be followed? • What issue</context>
<context position="6223" citStr="Tennant (1980)" startWordPosition="980" endWordPosition="982">tanding. Third, we want to define a measure of performance that allows the evaluation of the input-output characteristics of a particular system in a given domain. This kind of measure is clearly inappropriate to reveal and test features, such as the power of a model as opposed to that of a particular implementation of it, the applicability of the model to other domains, its extensibility, etc., which are more closely related to the internal structure and mode of operation of a system, rather than to its input-output behaviour. The goal of evaluating such more general properties, worked on by Tennant (1980) through the method of abstract analysis (mainly based on taxonomies of conceptual, linguistic, and implementational issues), is not considered in this work. This paper is organized in the following way. In section 2 we discuss in an intuitive, yet precise, way the basic concepts involved in the performance evaluation problem, in order to have a sufficiently clear specification of what we want to formalize. Then, in section 3, we give an abstract definition of the formal model, and in section 4 we discuss some actual cases of particular interest. Section 5 presents some techniques that could b</context>
<context position="14736" citStr="Tennant 1980" startWordPosition="2473" endWordPosition="2474">t should allow consistent comparison among different systems, in the sense that if gr(U1) = v(U2) the behaviour of the two systems U1 and U2 should be sufficiently similar, and that if ir(U1 )&gt;/r(U2), U1 should perform better than U2. Furthermore, this comparison should be as fine and precise as possible, in such a way to capture all the essential features of the behaviour of a system U in a given domain. Finally, comparison might be between two different systems, between two versions of the same system, between a system and a given set of issues, or between a system and an independent scale (Tennant 1980). To capture the intuitive notion of performance according to the above requirements, at least two points of view seem worth considering. First, a measure of performance should give a numerical value for the &amp;quot;distance&amp;quot; between the two functions gRu/D and gD, that is, the measure should allow us to formalize how near g/(e) approaches g(e) for any eeE, or, more explicitly, how well each expression eeE is understood by the system U. Second, it should weight this notion of &amp;quot;distance&amp;quot; in such a way as to take into account the fact that, generally, it is not equally important to understand well any </context>
<context position="27434" citStr="Tennant (1980)" startWordPosition="4766" endWordPosition="4767">d by: p3(e) = coi if f e€Ei, where co1E[0,1], for i = 1,...,m. It is worth noting that the length of a text is not independent of its frequency of use; we feel that in several application domains (such as, for example, manmachine interaction) short texts are much more frequent than long ones and that texts exceeding a given length are not used at all. A more refined notion of structural complexity of an expression may be given by taking into account its syntactic structure, defined on the basis of an appropriate set of characteristic features — see, for example, the classification proposed in Tennant (1980). E can be partitioned into different and disjoint classes according to the set of syntactical features they match, and an importance function p4 can be defined as above: p4(e) = iff ecEi, where w1e[0,1], for i = 1,...,m. Let us note that, contrary to the above illustrated relation between the length of a text and its frequency, it seems reasonable to consider syntactical complexity as fully independent of frequency; in fact, quite complex syntactical features (such as ellipsis, anaphora, broken text, etc.) are frequently found in several application domains. Finally, a couple of other possibl</context>
<context position="43863" citStr="Tennant (1980)" startWordPosition="7571" endWordPosition="7572"> model on which a system is based; second, it does not deal with the efficiency of the natural language understanding process. As far as the former topic is concerned, it is clear that, except in the case where commercial applications are considered, one is primarily interested in models rather than in particular implementations. It is far more significant that a model, a knowledge representation method, and a parsing algorithm have been designed to build natural language understanding systems rather than that a specific system has been constructed in a particular domain for a particular use. Tennant (1980) (see also Woods 1977) proposes a method, called abstract analysis, to organize in an informal but disciplined way the evaluation, through taxonomies of conceptual, linguistic, and implementational issues, of the internal behaviour of a natural language system (including analysis of failure causes, domain dependent features, knowledge base completeness and closure, algorithm deficiencies, extensibility, etc.). A very demanding research issue that could substantially contribute to the development of the research on natural language processing is the definition of more formal methods that, start</context>
</contexts>
<marker>Tennant, 1980</marker>
<rawString>Tennant, H. 1980 Evaluation of Natural Language Processes. Report T-I03. Coordinated Science Laboratory, University of Illinois, Urbana, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Waltz</author>
</authors>
<title>Natural Language Interfaces.</title>
<date>1977</date>
<journal>ACM SIGART Newsletter</journal>
<volume>61</volume>
<pages>16--64</pages>
<contexts>
<context position="1401" citStr="Waltz 1977" startWordPosition="203" endWordPosition="204">finition; some particular cases are shown and discussed in detail. Finally, the task of measuring performance in practice is considered, and a model for experimental performance evaluation is presented. Comparison with related works is also briefly discussed; open problems and promising directions for future research are outlined. A limited case study experimentation with the model proposed is presented in the appendix. 1. Introduction Research on natural language processing has recently been featured by the design and implementation of a number of experimental systems. Recent survey reports (Waltz 1977, Kaplan 1982) mention more than one hundred items among the most successful and relevant systems in the classical application fields of data base inquiry, machine translation, question answering, and man-machine interfacing. This trend is not surprising in the context of research whose specific aim is that of providing automated tools for the understanding or translating of natural languages; but it is also evident even in natural language research with a more theoretical flavour. The successful construction of a good performing system is Address: Prof. Giovanni Guida Dipartimento di Elettron</context>
</contexts>
<marker>Waltz, 1977</marker>
<rawString>Waltz, D. 1977 Natural Language Interfaces. ACM SIGART Newsletter 61: 16-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Watt</author>
</authors>
<title>Habitability. American Documentation 338-351. Woods,</title>
<date>1968</date>
<journal>A Personal View of Natural Language Understanding. ACM SIGART Newsletter</journal>
<volume>61</volume>
<pages>17--20</pages>
<location>W.A.</location>
<contexts>
<context position="38496" citStr="Watt 1968" startWordPosition="6662" endWordPosition="6663">st whether or not the system does what it was designed to do; completeness is introduced to test whether or not the system meets users&apos; requirements. More precisely, Tennant introduces the two notions of coverage and completeness to denote, respectively, the capabilities (both conceptual and linguistic) that the designer has put within a system, and (similarly to Woods, Kaplan, Nash-Webber 1972 though differing from Woods 1977) the degree to which the capabilities expected by a set of users can actually be found in the system coverage. Furthermore, habitability denotes (quite differently from Watt 1968) the degree to which a system can actually exhibit the capabilities that it was designed to have. Our approach is based on a slightly different model and provides in some sense a refinement of the above concepts. We denote by the term competence the capabilities that a system is actually able to show, while by the term coverage we refer, according to Tennant, to the theoretical capabilities that a system should have as a consequence of its design specifications. More precisely, the conceptual coverage of a system UR/D is formalized in our model by the domain D, which represents, in fact, the r</context>
</contexts>
<marker>Watt, 1968</marker>
<rawString>Watt, W.C. 1968 Habitability. American Documentation 338-351. Woods, W.A. 1977 A Personal View of Natural Language Understanding. ACM SIGART Newsletter 61: 17-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>R M Kaplan</author>
<author>B Nash-Webber</author>
</authors>
<title>The Lunar Sciences Natural Language Information System: Final Report. Report 2378. Bolt Beranek and Newman,</title>
<date>1972</date>
<location>Cambridge, Massachusetts.</location>
<marker>Woods, Kaplan, Nash-Webber, 1972</marker>
<rawString>Woods, W.A.; Kaplan, R.M.; and Nash-Webber, B. 1972 The Lunar Sciences Natural Language Information System: Final Report. Report 2378. Bolt Beranek and Newman, Cambridge, Massachusetts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>