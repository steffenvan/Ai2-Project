<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000159">
<title confidence="0.9994785">
Aggregation in the NL-generator of
the VIsual and Natural language Specification Tool
</title>
<author confidence="0.997984">
Hercules Dalianis
</author>
<affiliation confidence="0.989396333333333">
Department of Computer and Systems Sciences
The Royal Institute of Technology and
Stockholm University
</affiliation>
<address confidence="0.618419">
Electrum 230
S-164 40 Kista
Sweden
ph. 08-668 90 98
mob. ph. 010-668 13 59
</address>
<email confidence="0.907855">
email: hercules@dsv.su.se
</email>
<sectionHeader confidence="0.992734" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999084222222222">
In this paper we show how to use the so-
called aggregation technique to remove
redundancies in the fact base of the Visual
and Natural language Specification Tool
(VINST). The current aggregation modules
of the natural language generator of VINST
is described and an improvement is prop-
osed with one new aggregation rule and a
bidirectional grammar.
</bodyText>
<sectionHeader confidence="0.998218" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999483566666667">
This paper describes the aggregation process in the
natural language generator of the Visual and Natural
language Specification Tool (VINST), and how the
aggregation can be improved.
Aggregation is the process which removes redund-
ancy in texts. Redundancy typically occurs when the
material selected for communication contains
information that is duplicated in the text, or else is
so closely related that the reader can automatically
infer one piece when reading another. Aggregation is
also called ellipsis by linguists.
In the VINST-system Natural Language generat-
ion is applied in various places. In the specification
part to paraphrase the rules expressed in formal
language, to paraphrase automata, further on to para-
phrase questions asked to the theorem prover, and to
paraphrase the executed events and the newly created
fact base. We will in this paper only treat the
generation of NL from fact bases.
The kind of text produced in this domain is
illustrated in the right hand window of VINST in
figure 1.
When generating a text from a fact base in VINST
the text becomes very tedious to read since the text
is very redundant and does not feel correct
conceptually. To make the text smoother to read a
new architecture is suggested where a new
aggregation rule from (Dalianis &amp; Hovy 1993) is
suggested to be used, namely predicate grouping
rule.
</bodyText>
<figure confidence="0.861300333333333">
* File Edit UINST Simulator It
Factbase - Bask Cell
nine: 10 ful siaeWer11 &apos;Wag —
(cent, subicaber tl Makes.otthca a hotnurnber 200 and has
a phonenumber 101 and has
EMIIMINEMMIE Eactbese - Basle Cell 1■11=1.
</figure>
<figureCaption confidence="0.8148543125">
TrIgged Time: k an busy subscriber t ban
Rules: (cent:
Domain: Trigged
a hotnumber 200 and has
phonenumber 101 and has
a phonenunber 100 and
an Idle subscriber 12 has
a phonenumber 200 and
an idle subscriber 13 has
a phonenunber 300
off hook
Rules:
Domain: too gact
Am II 5
acc t2
Figure 1. The event window, where the user
</figureCaption>
<bodyText confidence="0.968281764705882">
can execute events and the inter
preter interprets the specification.
The VINST-system is a multi-modal specification
and validation tool, specifically for the functionality
of telecom services. The specification is carried out
with a Visual Language (VL) and a restricted Natural
Language (NL), which are translated to LOXY
(Echarti &amp; StMmarck 1988), a First Order Language
extended with time.
The VINST system is a ready usable prototype
which has been demonstrated and tested on various
sites in the world (Engstedt 1991, Preifelt &amp;
Engstedt 1992). The VINST prototype is imple-
mented in AAIS-Prolog and SuperCard on Macin-
tosh. The Prolog is used for the NL-system and the
SuperCard for the VL-part and for the user
interaction of the system.
</bodyText>
<page confidence="0.99842">
286
</page>
<sectionHeader confidence="0.94434" genericHeader="introduction">
2. Previous research
</sectionHeader>
<bodyText confidence="0.999899866666667">
Several studies on aggregating text based on text
structure appear in the literature. In fact, the term
aggregation was first used in (Mann &amp; Moore
1980). In (Horacek 1992), is described the
integration of aggregation (which he calls grouping)
with quantification under guidance of principles of
conversational implicature. (Dale 1990) calls it
discourse level optimization, (Kempen 1991) calls it
forward and backward conjunction reduction.
In (Hovy 1990) two structural aggregation rules
are used to eliminate redundant information. In an
example in (Scott &amp; de Souza 1990), nine heuristic
rules aggregate six sentences which express a set of
facts using a single sentence. In (Dalianis &amp; Hovy
1993) are eight different aggregation rules described.
</bodyText>
<sectionHeader confidence="0.920757" genericHeader="method">
3. The current NL-generator
</sectionHeader>
<bodyText confidence="0.999959833333333">
To solve the problem of the not &amp;quot;naturalness&amp;quot; of
the LOXY-formulas and make them more &amp;quot;natural&amp;quot;
the following two modules have been constructed:
the natural and compact modules and finally the
surface grammar.
The LOXY-formula which is to be paraphrased is.
processed step by step to natural language by the
different modules to a deep structure. The natural,
and compact modules can be activated and
deactivated separately. Finally the surface generator
generates natural language text from the deep
structure.
The surface grammar contains its own generation
grammar and uses the same dictionary as the NL-
parser. The surface generation grammar is a Definite
Clause Grammar, DCG, (Pereira &amp; Warren 1980,
Clocksin &amp; Mellish 1984), and is not treated in this
paper.
</bodyText>
<sectionHeader confidence="0.911481" genericHeader="method">
4. Natural module
</sectionHeader>
<bodyText confidence="0.967390166666667">
The natural module creates a deep structure from
the flat LOXY-formula, by looking up its elements
in the dictionary. From this information it can
decide what the deep structure should look like. The
natural module is also called sentence planner. i.e. it
plans the length and the internal order of the
different sentences.
tl is a subscriber and ti is idle and
ti has 100 and 100 is a phonenumber and tl
has 101 and 101 is a phonenumber and
t2 is a subscriber and t2 is idle and
t2 has 200 and 200 is a phonenumber.
</bodyText>
<figureCaption confidence="0.71496">
Figure 2a) Normal mode, only surface generation.
</figureCaption>
<bodyText confidence="0.9849105">
The natural module does what (Dalianis &amp; Hovy
1993) calls ordering and economy.
an idle subscriber ti has a phonenumber 100 and
an idle subscriber ti has a phonenumber 101
and
an idle subscriber t2 has a phonenumber 200.
</bodyText>
<figureCaption confidence="0.558621">
Figure 2b) Natural mode
</figureCaption>
<sectionHeader confidence="0.9324" genericHeader="method">
5. Compact module
</sectionHeader>
<bodyText confidence="0.970418176470588">
The natural language expression, after being
processed by the natural module has a lot of
redundant noun phrases. This is solved by the
compact module. Our aggregation rule says: If two
or more identical (and hence redundant) noun phrases
are repeated consecutive then remove all the noun
phrases except the first one This operation will
remove the repetitive generation of the noun phrase
and the text becomes concise. (Dalianis &amp; Hovy
1993) calls this subject grouping.
an idle subscriber ti has a phonenumber 100 and
has a phonenumber 101 and
an idle subscriber t2 has a phonenumber 200.
Figure 2c) Natural mode + compact mode
What we see is that the text can be aggregated in a
different way and also that the subject grouping has
not been fully applied on the phonenumbers.
</bodyText>
<page confidence="0.992147">
287
</page>
<sectionHeader confidence="0.967418" genericHeader="method">
6. Paraphrase fact bases
</sectionHeader>
<bodyText confidence="0.9986556">
Fact bases can be paraphrased into natural
language either after that an event is executed with
the interpreter or as an answer to a question to the
theorem prover. Here we show an example of the
latter, (see Figure 3).
A question expressed in NL (It is difficult to
express questions in VL) is translated to a LOXY
expression that the theorem prover tries to prove.
The generation module takes the proved query and
generates an NL-answer.
</bodyText>
<figure confidence="0.972977526315789">
Flla Edi nue
k Query: does soma subscriber have
a phonenurnber an Idle subsniber 11 has a .7.*.•
0 a holnumber 200 and has
II a phonenumber 101 and has
4 a phavenumber 100 and
an Idle subscriber 12 hes
a phonenumber 200 and
Answer. a subscriber 11 has Lir. a idle subscriber 13 has
a phonenumber 300
a phonenumber 101 re
V.r
o 0
, Imi
lt.
/ o.....: 00 3a0 MI
101 h
111) 200 t2
g.1
</figure>
<figureCaption confidence="0.999976">
Figure 3. The query window, where the user
</figureCaption>
<bodyText confidence="0.486369">
can ask questions and obtain
answers via the theorem prover.
</bodyText>
<sectionHeader confidence="0.499141" genericHeader="method">
7. Improvements on architecture
</sectionHeader>
<bodyText confidence="0.999927714285714">
The present natural language generator of VINST
is difficult to control because there are only two
control features (natural and compact) available. It is
required great effort to adapt the NL-generator to new
domains or to extend it without writing new
grammar rules. Further on it is difficult to express
the NL-paraphrase in a similar fashion as the user
expresses him/herself, therefore are some improve-
ments suggested.
One suggestion is is to use as a natural language
grammar the Core Language Engine (CLE)
(Alshawi 1992). CLE is a bidirectional, unification
and feature-based grammar written in Prolog.
CLE uses Quasi Logical Form (QLF) as
linguistic representation for the parsed NL-string.
QLF can be used to direct the generator, but it needs
to be augmented. We have to construct an
Intermediate Generation Form (IGF) which will
contain the suitable linguistic primitives. The IGF
will be acquired both from the user and from the
context where the NL is to be paraphrased. e.g.
simulation- or query window. The used words of
the user will be reused for generation together with
the LOXY formula.
When the paraphrasing will be carried out from a
VL-expression, then we have to use preset linguistic
primitives and words for the NL-generation because
there will not be any linguistic primitives.
</bodyText>
<sectionHeader confidence="0.508452" genericHeader="method">
8. Intermediate Generation Form
</sectionHeader>
<bodyText confidence="0.999909902439025">
The Intermediate Generation Form (IGF) will
contain the type of sentences, e.g. a fact or an
assertion (dcl), a rule (rule), a yes-no-question
(ynq), a what, which or who-question (whq), a noun
phrase (np) and many more.
The Quasi Logical Form (QLF) of CLE uses
already dcl, ynq and whq and could be extended to
also treat np . The rest of the type of sentences are
context dependent. i.e. rule etc. The sentence types
above are identical with the ones in the QLF, except
of the sentence type np and some others which are
VINST specific.
To each type of sentence, above, there is a set of
features. e.g. adjective form (adj), subjective
predicative complement (predcomp), subject
grouping (sg) and predicate grouping(pg) and many
more.
The features can be unordered and the number can
be arbitrary. Some of the features are the same as
the one QLF uses, except for: predcomp, sg and pg.
The IGF contains also two aggregation features;
subject and predicate grouping which makes the text
nicer to read.
Observe that there is no time feature in the IGF,
since LOXY has an embedded time.
What we also need is a list of words used by the
user. The words are obtained from the parser. The
IGF needs to be stored together with the LOXY
expression until they are going to be used by the
NL-generator. The syntax of the IGF is described by
showing the Prolog predicate int_gen_form/3 and
its content.
int_gen_form(REFNR,
TYPE(FEATURE_LIST),
USED_WORD_LIST).
REFNR is a reference number to the LOXY-
expression to be paraphrased. TYPE is type of
sentence and FEATURE_LIST is a list of feature
names describing the sentences.
USED_WORD_LIST is a list of previous used
words.
</bodyText>
<page confidence="0.996242">
288
</page>
<sectionHeader confidence="0.814243" genericHeader="method">
9. Paraphrase fact bases aggregated
</sectionHeader>
<bodyText confidence="0.993655222222222">
Here follows two examples on how the
paraphrasing would look like with the new
architecture upon paraphrasing a LOXY-fact base to
NL, (Not yet implemented)
The only thing which changes between the two
examples is the content of the IGF.
Before generation input propositions are ordered
based on the characteristics of their subjects, as
described in (Dalianis &amp; Hovy 1993).
</bodyText>
<figure confidence="0.569495">
Idle
4e3
t1 t2
</figure>
<figureCaption confidence="0.895024">
Figure 4. A fact base described in VL
</figureCaption>
<equation confidence="0.9628243">
a) fact(2, p(1, subscriber(t1)) &amp;
p(1, idle(t1)) &amp; p(1,has(t1,100)) &amp;
p(1,has(t1,101)) &amp;
p(1, phonenumber(100)) &amp;
p(1, phonenumber(101)) &amp;
p(1, subscriber(t2)) &amp; p(1, idle(t2)) &amp;
p(1,has(t2,200)) &amp;
p(1, phonenumber(200)))).
b) int_gen_form(2,dclapredcomp,s0,
[subscriber,idle,be,have,phonenumberD.
</equation>
<bodyText confidence="0.990724363636364">
ti is a subscriber and is idle and
has the phonenumber 100 and 101
t2 is a subscriber and is idle and
has the phonenumber 200
c) int_gen_form(2,dclaadj,sg,pg),
[subscriber,idle, be, have,phonenumber]).
ti and t2 are idle subscribers and
tl has the phonenumbers 100 and 101 and
t2 has the phonenumber 200.
In the second NL-example, figure 4c), we see how
the predicate grouping works.
</bodyText>
<sectionHeader confidence="0.724198" genericHeader="conclusions">
10. Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999981307692308">
We have in this paper shortly described the current
NL-generator of the VINST-system. We have found
it too inflexible and the generated text too tedious to
read, therefore is suggested a new NL-architecture
where the user and the context of the user interaction
is used to extract an Intermediate Generation Form
(IGF). The IGF will contain a new aggregation rule,
the so called predicate grouping rule which will
make the generated text easier to read, further on is
proposed to use a bidirectional grammar for the
surface generation.
One future suggestion is also to use the results
from the NL-parsing for the generation.
</bodyText>
<sectionHeader confidence="0.995488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999837125">
Many thanks to Ed Hovy at Information Sciences
Institute/USC for advising me and for stimulating
discussions via email and many thanks also to
Stefan Preifelt and Mans Engstedt at Ellemtel Tele-
communication Systems Laboratory, for beeing
inspiring workmates during the VINST prototype
implementation and also for introducing me to the
telecom domain.
</bodyText>
<sectionHeader confidence="0.998444" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998581756097561">
Alshawi, H. ed. (1992). The Core Language
Engine, MIT Press.
Clocksin, W.F. &amp; Mellish, C.S. (1984).
Programming in Prolog, Springer Verlag.
Dale, R. (1990). Generating Recipes: An Over
view of Epicure, In Current Research in
Natural Language Generation, Dale, R. et al
(Eds). Academic Press Limited, pp. 229-255.
Dalianis, H. &amp; Hovy, E. (1993). Aggregation in
Natural Language Generation: In the
Proceedings of the Fourth European Workshop
on Natural Language Generation, Pisa, Italy,
28-30 April.
Echarti, J-P. &amp; Stalmarck, G. (1988). A logical
framework for specifying discrete dynamic
systems, Advanced Systems Development
Dept., Ellemtel Telecommunication Systems
Laboratory, Alvsjo, Sweden..
Engstedt, M. (1991). A flexible specification
language using Natural Language and
Graphics, Centre for Cognitive Science,
Edinburgh.
Horacek, H. (1992). An integrated view of
textplanning: In Aspects of Automated
Natural Language Generation, Dale, R. et
al, (eds)., Springer Verlag Lecture Notes in
Artifical Intelligence no 587,
pp. 193-227.
Hovy, E.H. (1990). Unresolved Issues in Paragraph
Planning: In Current Research in Natural
Language Generation, R. Dale, et al, (eds).,
Academic Press Limited,
pp. 17-45.
Kempen, G. (1991). Conjunction reduction and
gapping in clause-level coordination: An
inheritance-based approach: In Computational
Intelligence, Vol 7, No 4, pp. 357-360.
Mann, W.C. &amp; Moore, J.A. (1980). Computer
as Author - Results and Prospects,
ReporilISURR-79-82, University of Southern
California/ Information Sciences Institute.
</reference>
<page confidence="0.978117">
289
</page>
<reference confidence="0.996230285714286">
Pereira, F.C.N &amp; Warren, D.H.D. (1980). Definite
Clause Grammars for Language Analysis - A
Survey of the Formalism and a Comparison
with Augmented Transition Networks. J. of
Artificial Intelligence 13, pp. 231-278.
Preifelt, S &amp; Engstedt, M. (1992). Resultat fran
VINST projektet, (In Swedish, Results from
the VINST project), Ellemtel Telecommunicat
ion Systems Laboratory, Alvsjo, Sweden.
Scott, D. &amp; de Souza, C.S. (1990). Getting the
Message Across in RST-based Text
Generation:In Current Research in Natural
Language Generation, R. et al, (eds).
Academic Press Limited, pp. 47-73.
</reference>
<page confidence="0.997114">
290
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.619912">
<title confidence="0.973007">Aggregation in the NL-generator of the VIsual and Natural language Specification Tool</title>
<author confidence="0.988599">Hercules Dalianis</author>
<affiliation confidence="0.989724">Department of Computer and Systems Sciences The Royal Institute of Technology and Stockholm University</affiliation>
<address confidence="0.893918666666667">Electrum 230 S-164 40 Kista Sweden</address>
<phone confidence="0.969597">ph. 08-668 90 98 mob. ph. 010-668 13 59</phone>
<email confidence="0.995946">hercules@dsv.su.se</email>
<abstract confidence="0.9947805">In this paper we show how to use the socalled aggregation technique to remove redundancies in the fact base of the Visual and Natural language Specification Tool (VINST). The current aggregation modules of the natural language generator of VINST is described and an improvement is proposed with one new aggregation rule and a bidirectional grammar.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H ed Alshawi</author>
</authors>
<title>The Core Language Engine,</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8021" citStr="Alshawi 1992" startWordPosition="1336" endWordPosition="1337"> questions and obtain answers via the theorem prover. 7. Improvements on architecture The present natural language generator of VINST is difficult to control because there are only two control features (natural and compact) available. It is required great effort to adapt the NL-generator to new domains or to extend it without writing new grammar rules. Further on it is difficult to express the NL-paraphrase in a similar fashion as the user expresses him/herself, therefore are some improvements suggested. One suggestion is is to use as a natural language grammar the Core Language Engine (CLE) (Alshawi 1992). CLE is a bidirectional, unification and feature-based grammar written in Prolog. CLE uses Quasi Logical Form (QLF) as linguistic representation for the parsed NL-string. QLF can be used to direct the generator, but it needs to be augmented. We have to construct an Intermediate Generation Form (IGF) which will contain the suitable linguistic primitives. The IGF will be acquired both from the user and from the context where the NL is to be paraphrased. e.g. simulation- or query window. The used words of the user will be reused for generation together with the LOXY formula. When the paraphrasin</context>
</contexts>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, H. ed. (1992). The Core Language Engine, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W F Clocksin</author>
<author>C S Mellish</author>
</authors>
<date>1984</date>
<publisher>Springer Verlag.</publisher>
<note>Programming in Prolog,</note>
<contexts>
<context position="4846" citStr="Clocksin &amp; Mellish 1984" startWordPosition="773" endWordPosition="776">owing two modules have been constructed: the natural and compact modules and finally the surface grammar. The LOXY-formula which is to be paraphrased is. processed step by step to natural language by the different modules to a deep structure. The natural, and compact modules can be activated and deactivated separately. Finally the surface generator generates natural language text from the deep structure. The surface grammar contains its own generation grammar and uses the same dictionary as the NLparser. The surface generation grammar is a Definite Clause Grammar, DCG, (Pereira &amp; Warren 1980, Clocksin &amp; Mellish 1984), and is not treated in this paper. 4. Natural module The natural module creates a deep structure from the flat LOXY-formula, by looking up its elements in the dictionary. From this information it can decide what the deep structure should look like. The natural module is also called sentence planner. i.e. it plans the length and the internal order of the different sentences. tl is a subscriber and ti is idle and ti has 100 and 100 is a phonenumber and tl has 101 and 101 is a phonenumber and t2 is a subscriber and t2 is idle and t2 has 200 and 200 is a phonenumber. Figure 2a) Normal mode, only </context>
</contexts>
<marker>Clocksin, Mellish, 1984</marker>
<rawString>Clocksin, W.F. &amp; Mellish, C.S. (1984). Programming in Prolog, Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Recipes: An Over view of Epicure,</title>
<date>1990</date>
<booktitle>In Current Research in Natural Language Generation, Dale, R. et al (Eds).</booktitle>
<pages>229--255</pages>
<publisher>Academic Press Limited,</publisher>
<contexts>
<context position="3674" citStr="Dale 1990" startWordPosition="594" endWordPosition="595"> in the world (Engstedt 1991, Preifelt &amp; Engstedt 1992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3. The current NL-generator To solve the problem of the not &amp;quot;naturalness&amp;quot; of the LOXY-formulas and make them more &amp;quot;natural&amp;quot; the following two modules have been constructed: the natural</context>
</contexts>
<marker>Dale, 1990</marker>
<rawString>Dale, R. (1990). Generating Recipes: An Over view of Epicure, In Current Research in Natural Language Generation, Dale, R. et al (Eds). Academic Press Limited, pp. 229-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dalianis</author>
<author>E Hovy</author>
</authors>
<title>Aggregation in Natural Language Generation:</title>
<date>1993</date>
<booktitle>In the Proceedings of the Fourth European Workshop on Natural Language Generation,</booktitle>
<location>Pisa,</location>
<contexts>
<context position="1978" citStr="Dalianis &amp; Hovy 1993" startWordPosition="314" endWordPosition="317">uage, to paraphrase automata, further on to paraphrase questions asked to the theorem prover, and to paraphrase the executed events and the newly created fact base. We will in this paper only treat the generation of NL from fact bases. The kind of text produced in this domain is illustrated in the right hand window of VINST in figure 1. When generating a text from a fact base in VINST the text becomes very tedious to read since the text is very redundant and does not feel correct conceptually. To make the text smoother to read a new architecture is suggested where a new aggregation rule from (Dalianis &amp; Hovy 1993) is suggested to be used, namely predicate grouping rule. * File Edit UINST Simulator It Factbase - Bask Cell nine: 10 ful siaeWer11 &apos;Wag — (cent, subicaber tl Makes.otthca a hotnurnber 200 and has a phonenumber 101 and has EMIIMINEMMIE Eactbese - Basle Cell 1■11=1. TrIgged Time: k an busy subscriber t ban Rules: (cent: Domain: Trigged a hotnumber 200 and has phonenumber 101 and has a phonenunber 100 and an Idle subscriber 12 has a phonenumber 200 and an idle subscriber 13 has a phonenunber 300 off hook Rules: Domain: too gact Am II 5 acc t2 Figure 1. The event window, where the user can execu</context>
<context position="4040" citStr="Dalianis &amp; Hovy 1993" startWordPosition="649" endWordPosition="652">ture. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3. The current NL-generator To solve the problem of the not &amp;quot;naturalness&amp;quot; of the LOXY-formulas and make them more &amp;quot;natural&amp;quot; the following two modules have been constructed: the natural and compact modules and finally the surface grammar. The LOXY-formula which is to be paraphrased is. processed step by step to natural language by the different modules to a deep structure. The natural, and compact modules can be activated and deactivated separately. Finally the surface generator generates natural language text from the deep structure. The surfac</context>
<context position="5517" citStr="Dalianis &amp; Hovy 1993" startWordPosition="896" endWordPosition="899">ule The natural module creates a deep structure from the flat LOXY-formula, by looking up its elements in the dictionary. From this information it can decide what the deep structure should look like. The natural module is also called sentence planner. i.e. it plans the length and the internal order of the different sentences. tl is a subscriber and ti is idle and ti has 100 and 100 is a phonenumber and tl has 101 and 101 is a phonenumber and t2 is a subscriber and t2 is idle and t2 has 200 and 200 is a phonenumber. Figure 2a) Normal mode, only surface generation. The natural module does what (Dalianis &amp; Hovy 1993) calls ordering and economy. an idle subscriber ti has a phonenumber 100 and an idle subscriber ti has a phonenumber 101 and an idle subscriber t2 has a phonenumber 200. Figure 2b) Natural mode 5. Compact module The natural language expression, after being processed by the natural module has a lot of redundant noun phrases. This is solved by the compact module. Our aggregation rule says: If two or more identical (and hence redundant) noun phrases are repeated consecutive then remove all the noun phrases except the first one This operation will remove the repetitive generation of the noun phras</context>
<context position="10906" citStr="Dalianis &amp; Hovy 1993" startWordPosition="1815" endWordPosition="1818">R is a reference number to the LOXYexpression to be paraphrased. TYPE is type of sentence and FEATURE_LIST is a list of feature names describing the sentences. USED_WORD_LIST is a list of previous used words. 288 9. Paraphrase fact bases aggregated Here follows two examples on how the paraphrasing would look like with the new architecture upon paraphrasing a LOXY-fact base to NL, (Not yet implemented) The only thing which changes between the two examples is the content of the IGF. Before generation input propositions are ordered based on the characteristics of their subjects, as described in (Dalianis &amp; Hovy 1993). Idle 4e3 t1 t2 Figure 4. A fact base described in VL a) fact(2, p(1, subscriber(t1)) &amp; p(1, idle(t1)) &amp; p(1,has(t1,100)) &amp; p(1,has(t1,101)) &amp; p(1, phonenumber(100)) &amp; p(1, phonenumber(101)) &amp; p(1, subscriber(t2)) &amp; p(1, idle(t2)) &amp; p(1,has(t2,200)) &amp; p(1, phonenumber(200)))). b) int_gen_form(2,dclapredcomp,s0, [subscriber,idle,be,have,phonenumberD. ti is a subscriber and is idle and has the phonenumber 100 and 101 t2 is a subscriber and is idle and has the phonenumber 200 c) int_gen_form(2,dclaadj,sg,pg), [subscriber,idle, be, have,phonenumber]). ti and t2 are idle subscribers and tl has the</context>
</contexts>
<marker>Dalianis, Hovy, 1993</marker>
<rawString>Dalianis, H. &amp; Hovy, E. (1993). Aggregation in Natural Language Generation: In the Proceedings of the Fourth European Workshop on Natural Language Generation, Pisa, Italy, 28-30 April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-P Echarti</author>
<author>G Stalmarck</author>
</authors>
<title>A logical framework for specifying discrete dynamic systems,</title>
<date>1988</date>
<booktitle>Advanced Systems Development Dept., Ellemtel Telecommunication Systems Laboratory,</booktitle>
<location>Alvsjo, Sweden..</location>
<marker>Echarti, Stalmarck, 1988</marker>
<rawString>Echarti, J-P. &amp; Stalmarck, G. (1988). A logical framework for specifying discrete dynamic systems, Advanced Systems Development Dept., Ellemtel Telecommunication Systems Laboratory, Alvsjo, Sweden..</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Engstedt</author>
</authors>
<title>A flexible specification language using Natural Language and Graphics, Centre for Cognitive Science,</title>
<date>1991</date>
<location>Edinburgh.</location>
<contexts>
<context position="3092" citStr="Engstedt 1991" startWordPosition="502" endWordPosition="503">ff hook Rules: Domain: too gact Am II 5 acc t2 Figure 1. The event window, where the user can execute events and the inter preter interprets the specification. The VINST-system is a multi-modal specification and validation tool, specifically for the functionality of telecom services. The specification is carried out with a Visual Language (VL) and a restricted Natural Language (NL), which are translated to LOXY (Echarti &amp; StMmarck 1988), a First Order Language extended with time. The VINST system is a ready usable prototype which has been demonstrated and tested on various sites in the world (Engstedt 1991, Preifelt &amp; Engstedt 1992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discours</context>
</contexts>
<marker>Engstedt, 1991</marker>
<rawString>Engstedt, M. (1991). A flexible specification language using Natural Language and Graphics, Centre for Cognitive Science, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>An integrated view of textplanning:</title>
<date>1992</date>
<journal>In Aspects of Automated Natural Language</journal>
<booktitle>Verlag Lecture Notes in Artifical Intelligence no 587,</booktitle>
<pages>193--227</pages>
<publisher>Springer</publisher>
<contexts>
<context position="3511" citStr="Horacek 1992" startWordPosition="573" endWordPosition="574">arti &amp; StMmarck 1988), a First Order Language extended with time. The VINST system is a ready usable prototype which has been demonstrated and tested on various sites in the world (Engstedt 1991, Preifelt &amp; Engstedt 1992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3. The current NL-gen</context>
</contexts>
<marker>Horacek, 1992</marker>
<rawString>Horacek, H. (1992). An integrated view of textplanning: In Aspects of Automated Natural Language Generation, Dale, R. et al, (eds)., Springer Verlag Lecture Notes in Artifical Intelligence no 587, pp. 193-227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Unresolved Issues in Paragraph Planning:</title>
<date>1990</date>
<booktitle>In Current Research in Natural Language Generation,</booktitle>
<pages>17--45</pages>
<publisher>Academic Press Limited,</publisher>
<contexts>
<context position="3795" citStr="Hovy 1990" startWordPosition="611" endWordPosition="612">on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3. The current NL-generator To solve the problem of the not &amp;quot;naturalness&amp;quot; of the LOXY-formulas and make them more &amp;quot;natural&amp;quot; the following two modules have been constructed: the natural and compact modules and finally the surface grammar. The LOXY-formula which is to be paraphrased is. processed step by s</context>
</contexts>
<marker>Hovy, 1990</marker>
<rawString>Hovy, E.H. (1990). Unresolved Issues in Paragraph Planning: In Current Research in Natural Language Generation, R. Dale, et al, (eds)., Academic Press Limited, pp. 17-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kempen</author>
</authors>
<title>Conjunction reduction and gapping in clause-level coordination: An inheritance-based approach:</title>
<date>1991</date>
<journal>In Computational Intelligence,</journal>
<volume>7</volume>
<pages>357--360</pages>
<contexts>
<context position="3727" citStr="Kempen 1991" startWordPosition="601" endWordPosition="602">992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3. The current NL-generator To solve the problem of the not &amp;quot;naturalness&amp;quot; of the LOXY-formulas and make them more &amp;quot;natural&amp;quot; the following two modules have been constructed: the natural and compact modules and finally the surface grammar.</context>
</contexts>
<marker>Kempen, 1991</marker>
<rawString>Kempen, G. (1991). Conjunction reduction and gapping in clause-level coordination: An inheritance-based approach: In Computational Intelligence, Vol 7, No 4, pp. 357-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>J A Moore</author>
</authors>
<title>Computer as Author - Results and Prospects, ReporilISURR-79-82,</title>
<date>1980</date>
<institution>University of Southern California/ Information Sciences Institute.</institution>
<contexts>
<context position="3492" citStr="Mann &amp; Moore 1980" startWordPosition="568" endWordPosition="571"> translated to LOXY (Echarti &amp; StMmarck 1988), a First Order Language extended with time. The VINST system is a ready usable prototype which has been demonstrated and tested on various sites in the world (Engstedt 1991, Preifelt &amp; Engstedt 1992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kempen 1991) calls it forward and backward conjunction reduction. In (Hovy 1990) two structural aggregation rules are used to eliminate redundant information. In an example in (Scott &amp; de Souza 1990), nine heuristic rules aggregate six sentences which express a set of facts using a single sentence. In (Dalianis &amp; Hovy 1993) are eight different aggregation rules described. 3.</context>
</contexts>
<marker>Mann, Moore, 1980</marker>
<rawString>Mann, W.C. &amp; Moore, J.A. (1980). Computer as Author - Results and Prospects, ReporilISURR-79-82, University of Southern California/ Information Sciences Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
<author>D H D Warren</author>
</authors>
<title>Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks.</title>
<date>1980</date>
<journal>J. of Artificial Intelligence</journal>
<volume>13</volume>
<pages>231--278</pages>
<contexts>
<context position="4820" citStr="Pereira &amp; Warren 1980" startWordPosition="769" endWordPosition="772">more &amp;quot;natural&amp;quot; the following two modules have been constructed: the natural and compact modules and finally the surface grammar. The LOXY-formula which is to be paraphrased is. processed step by step to natural language by the different modules to a deep structure. The natural, and compact modules can be activated and deactivated separately. Finally the surface generator generates natural language text from the deep structure. The surface grammar contains its own generation grammar and uses the same dictionary as the NLparser. The surface generation grammar is a Definite Clause Grammar, DCG, (Pereira &amp; Warren 1980, Clocksin &amp; Mellish 1984), and is not treated in this paper. 4. Natural module The natural module creates a deep structure from the flat LOXY-formula, by looking up its elements in the dictionary. From this information it can decide what the deep structure should look like. The natural module is also called sentence planner. i.e. it plans the length and the internal order of the different sentences. tl is a subscriber and ti is idle and ti has 100 and 100 is a phonenumber and tl has 101 and 101 is a phonenumber and t2 is a subscriber and t2 is idle and t2 has 200 and 200 is a phonenumber. Fig</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, F.C.N &amp; Warren, D.H.D. (1980). Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks. J. of Artificial Intelligence 13, pp. 231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Preifelt</author>
<author>M Engstedt</author>
</authors>
<title>Resultat fran VINST projektet,</title>
<date>1992</date>
<booktitle>(In Swedish, Results from the VINST project), Ellemtel Telecommunicat ion Systems Laboratory,</booktitle>
<location>Alvsjo, Sweden.</location>
<contexts>
<context position="3119" citStr="Preifelt &amp; Engstedt 1992" startWordPosition="504" endWordPosition="507">Domain: too gact Am II 5 acc t2 Figure 1. The event window, where the user can execute events and the inter preter interprets the specification. The VINST-system is a multi-modal specification and validation tool, specifically for the functionality of telecom services. The specification is carried out with a Visual Language (VL) and a restricted Natural Language (NL), which are translated to LOXY (Echarti &amp; StMmarck 1988), a First Order Language extended with time. The VINST system is a ready usable prototype which has been demonstrated and tested on various sites in the world (Engstedt 1991, Preifelt &amp; Engstedt 1992). The VINST prototype is implemented in AAIS-Prolog and SuperCard on Macintosh. The Prolog is used for the NL-system and the SuperCard for the VL-part and for the user interaction of the system. 286 2. Previous research Several studies on aggregating text based on text structure appear in the literature. In fact, the term aggregation was first used in (Mann &amp; Moore 1980). In (Horacek 1992), is described the integration of aggregation (which he calls grouping) with quantification under guidance of principles of conversational implicature. (Dale 1990) calls it discourse level optimization, (Kemp</context>
</contexts>
<marker>Preifelt, Engstedt, 1992</marker>
<rawString>Preifelt, S &amp; Engstedt, M. (1992). Resultat fran VINST projektet, (In Swedish, Results from the VINST project), Ellemtel Telecommunicat ion Systems Laboratory, Alvsjo, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Scott</author>
<author>C S de Souza</author>
</authors>
<title>Getting the Message Across in RST-based Text Generation:In Current Research in Natural Language Generation,</title>
<date>1990</date>
<pages>47--73</pages>
<editor>R. et al, (eds).</editor>
<publisher>Academic Press Limited,</publisher>
<marker>Scott, de Souza, 1990</marker>
<rawString>Scott, D. &amp; de Souza, C.S. (1990). Getting the Message Across in RST-based Text Generation:In Current Research in Natural Language Generation, R. et al, (eds). Academic Press Limited, pp. 47-73.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>