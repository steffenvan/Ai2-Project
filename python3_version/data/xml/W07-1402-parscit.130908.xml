<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011767">
<title confidence="0.9993375">
A Semantic Approach To Textual Entailment:
System Evaluation and Task Analysis
</title>
<author confidence="0.997917">
Aljoscha Burchardt, Nils Reiter, Stefan Thater Anette Frank*
</author>
<affiliation confidence="0.888424333333333">
Dept. of Computational Linguistics
Saarland University
Saarbrücken, Germany
Dept. of Computational Linguistics
University of Heidelberg
Germany
</affiliation>
<sectionHeader confidence="0.922535" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999457">
This paper discusses our contribution to the
third RTE Challenge – the SALSA RTE sys-
tem. It builds on an earlier system based on
a relatively deep linguistic analysis, which
we complement with a shallow component
based on word overlap. We evaluate their
(combined) performance on various data
sets. However, earlier observations that the
combination of features improves the over-
all accuracy could be replicated only partly.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998658">
This paper reports on the system we used in the third
PASCAL challenge on Recognizing Textual Entail-
ment. The system is based to a large extent on Bur-
chardt and Frank’s system (2006) used in the second
RTE challenge (Bar-Haim et al., 2006); it relies on
a relatively deep linguistic analysis, which we com-
plement with a shallow component based on word
overlap. As the system has been described earlier,
we concentrate on a more systematic discussion of
the system behaviour, aiming at spotting promising
anchors for future extensions and improvements.
It has been observed for related systems that a
combination of separately trained features in the ma-
chine learning component can lead to an overall im-
provement in system performance, in particular if
features from a more “informed” component and
shallow ones are combined (Hickl et al., 2006; Bos
and Markert, 2006). We provide a detailed analysis
of our system’s behaviour on different training and
test sets. However, we could not replicate the effects
</bodyText>
<footnote confidence="0.6092235">
*By the time of writing, Anette Frank was affiliated at Saar-
land University and DFKI Saarbrücken.
</footnote>
<page confidence="0.984315">
10
</page>
<bodyText confidence="0.999831210526316">
observed by others on all corpora – often, the ac-
curacy of the combined features is not higher than
the best individual features or feature sets. For the
RTE 3 test set, the combined features actually lead
to a slightly lower accuracy.
One candidate future enhancement of our system
is to refine the relatively unrestricted graph match-
ing that compares the analyses of text and hypothe-
sis and underlies the definition of the deep features.
But a more controlled, “rule based” definition of an
adequate graph matching seems to rely on a deeper
understanding of the notion of textual entailment.
In Section 2, we review the basic architecture of
our system, and report on improvements and exten-
sions. In Section 3, we provide a detailed evaluation
of the system on different data sets. In Section 4, we
report on some findings we made in a small annota-
tion experiment we conducted at our department. In
Section 5, we conclude and give a short outlook.
</bodyText>
<sectionHeader confidence="0.981378" genericHeader="method">
2 The SALSA RTE System
</sectionHeader>
<bodyText confidence="0.993785">
In this Section, we review the basic architecture
of the SALSA RTE system, and report on some
improvements and extensions. More details can be
found in (Burchardt and Frank, 2006).
</bodyText>
<subsectionHeader confidence="0.995886">
2.1 Architecture
</subsectionHeader>
<bodyText confidence="0.999384714285714">
The SALSA RTE system is based on three main
components: (i) a linguistic analysis of text and hy-
pothesis based primarily on LFG and Frame Seman-
tics (Baker et al., 1998), (ii) the computation of a
match graph that encodes the “semantic overlap” be-
tween text and hypothesis, and (iii) a statistical en-
tailment decision.
</bodyText>
<note confidence="0.5247095">
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15,
Prague, June 2007. @2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9881185">
Figure 1: Linguistic Analysis of Leloir discovered
the metabolism of carbon hydrates. (RTE3-test).
</figureCaption>
<bodyText confidence="0.998263694444445">
Linguistic analysis. The primary linguistic anal-
ysis components are the probabilistic LFG gram-
mar for English developed at PARC (Riezler et
al., 2002), and a combination of systems for frame
semantic annotation: the probabilistic Shalmaneser
system for frame and role annotation (Erk and Pado,
2006), and the rule-based Detour system for frame
assignment (Burchardt et al., 2005).
Frame semantic analysis is especially interesting
for the task of recognising textual entailment as it
offers a robust yet relatively precise measure for se-
mantic overlap. The lexical meaning of predicates
and their arguments are modelled in terms offrames
and roles. A frame describes a prototypical situation
and roles identify participants involved in the situa-
tion. Frames provide normalisations over divers sur-
face realisations, including variations in argument
structure realisations. For instance, buy, sell, and
purchase are all associated with the same frame.
The linguistic analysis combines LFG f-structures
and FrameNet frames computed by the Shalmaneser
and Detour systems, resulting in a projection from f-
structures to a semantic layer of frames and “pseudo
predicates” for f-structure predicates that do not
project frames. Figure 1 shows the most important
parts of the analysis of hypothesis 109 from the
RTE 3 test set as an example. The LFG f-structure
is shown on the left, and the dotted lines indicate the
projection to semantic nodes on the right. The pred-
icate discover is associated with the frame ACxIEV-
ING_FIRST, the semantic role COGNIZER points to
the pseudo-predicate Leloir and NEW_IDEA points
to the PROCESS frame evoked by metabolism.
Semantic nodes are further projected into an on-
tological analysis layer containing WordNet (Fell-
baum, 1997) senses and SUMO (Niles and Pease,
2001) classes. Semantic phenomena not treated
by FrameNet like anaphora, negation or modality
are (approximately) encoded with special operators.
The resulting, layered graph structures for text and
hypothesis thus provide access to the different types
of information in a principled way.
Semantic overlap and match graphs. The sys-
tem approximates textual entailment in terms of the
“semantic overlap” between text and hypothesis. It
compares their LFG f-structures with semantic and
ontological projection by determining compatible,
matching nodes and edges. The result is stored in a
match graph, which contains all (pairs of) matched
nodes and edges. Nodes can match if they are la-
belled with identical frames or predicates, or if the
nodes are semantically related on the basis of Word-
Net or FrameNet frame relations. One node from the
hypothesis may match multiple nodes from the text
and vice versa. The matching of edges is restricted to
edges that connect matching nodes, or nodes taking
identical atomic values.
The match graph primarily encodes the “similar-
ity” of text and hypothesis. In order to capture also
a certain degree of “dissimilarity,” nodes are deleted
from the match graph if they occur in incompatible
modality contexts.
Statistical entailment decision. Given a match
graph and the graphs for text and hypothesis, we
extract various features to train a machine learn-
ing model for textual entailment. In total, we ex-
tract 47 distinct features, which can be grouped ac-
cording to their (i) level of representation (lexical,
syntactic, semantic), (ii) degree of connectedness
in the match graph, (iii) source (text, hypothesis or
match graph), and (iv) proportional relation (hypoth-
esis/text, match/hypothesis ratio).
</bodyText>
<subsectionHeader confidence="0.99459">
2.2 Improvements
</subsectionHeader>
<bodyText confidence="0.9997602">
Sentence splitter. To cope with longer texts, we
integrated the sentence splitter of the JTok tokeniser
(Schäfer, 2005) into the system.
WordNet interface. The WordNet interface now
treats particle verbs like throw out correctly. More-
</bodyText>
<page confidence="0.995398">
11
</page>
<bodyText confidence="0.997796083333333">
over, we tested the usability of WordNet’s verb en-
tailment information as well as antonymy on nouns,
verbs, and adjectives as basis for heuristic infer-
ences in the graph matching process. However, for
the given data, the number of text-hypothesis pairs
where the relations are instantiated at all is marginal.
Frame semantic projection. The interface be-
tween the LFG and the Detour and Shalmaneser sys-
tems has been improved: by now 97% (+7%) of the
frames and 74% (+10%) of the roles can be pro-
jected (on the RTE3 test set), resulting in an average
of 6.6 frames and 5.5 roles per sentence.
</bodyText>
<subsectionHeader confidence="0.996026">
2.3 Extensions
</subsectionHeader>
<bodyText confidence="0.9998527">
In addition to the above improvements, the sys-
tem has been extended in two respects. We added
a shallow component based on lexical overlap and
a “meta learner” to study the combinatorics of ma-
chine learners’ results.
Lexical overlap. In order to evaluate the perfor-
mance of our system, we implemented a simple
baseline system that approximates textual entail-
ment in terms of lexical overlap between text and
hypothesis. This shallow system is also used as a
component to complement our full system in one of
the two runs submitted to the RTE3 challenge.
The shallow system measures the relative num-
ber of words in the hypothesis that also occur in the
text. Both text and hypothesis are tagged and lemma-
tised using Tree Tagger (Schmid, 1994), taking only
nouns, non-auxiliary verbs, adjectives and adverbs
into account. Training a decision tree on the relative
word-overlap as single feature yields a system which
performs comparable to earlier word-overlap based
systems, achieving an accuracy of 60.6 % if trained
and tested on the RTE 2 development and test set,
respectively (using Weka’s J48 classifier), or 57.5 %
if we use Weka’s LogitBoost classifier.
Weka Interface. Finally, we improved the ma-
chine learning back-end which feeds our extracted
features into the Weka toolkit (Witten and Frank,
2005). This allows to train features in arbitrary com-
binations, with different machine learners.&apos; More-
over, it supports testing the effect of using voting or
</bodyText>
<table confidence="0.8477232">
&apos;The figures we present in the following are all computed
with the LogitBoost classifier.
IE IR QA SUM
Run 1 (III) 62.25% 51% 68% 74% 57%
Run 2 (II) 62.62% 50% 69% 72.5% 59%
</table>
<tableCaption confidence="0.8620315">
Table 1: Results of the SALSA RTE system (com-
bined training set: RTE2-dev/-test and RTE3-dev).
a “meta learner” after training individual features or
feature groups separately.
</tableCaption>
<sectionHeader confidence="0.999907" genericHeader="method">
3 Results
</sectionHeader>
<subsectionHeader confidence="0.999467">
3.1 RTE3 Results
</subsectionHeader>
<bodyText confidence="0.9997062">
In the RTE3 task, we submitted two runs, one with
(run 1) and one without (run 2) the lexical overlap
component. Both achieved almost the same results,
as can be seen in Table 1. The feature combinations
(II, III) are explained below in detail.
</bodyText>
<subsectionHeader confidence="0.996601">
3.2 Feature Combination
</subsectionHeader>
<bodyText confidence="0.831613142857143">
We investigated the behaviour of our systems on var-
ious combinations of three different sets of 800 text
hypothesis pairs (RTE2-dev/-test and RTE3-dev).
We tested four different feature configurations:
(I) All 47 features generated in our system (ex-
cluding the lexical overlap component)
(II) Three selected features of our system (run 2):
</bodyText>
<listItem confidence="0.993911875">
• Overlap of LFG predicates
• Matching of grammatical functions (deep
subject/object, modifier, ... )
• Average size of connected parts (“clus-
ters”) of the match graph, comprising syn-
tactic and semantic information
(III) The features from II plus lexical overlap (run 1)
(IV) Lexical overlap alone
</listItem>
<bodyText confidence="0.999590125">
In every configuration (except IV), the features
were trained separately first, then a “meta classifier”
was used to make the final entailment decision. We
will use
as notation for the configurations, e.g.,
means all 47 features trained on the development
and test set of RTE2, tested on the development set
of RTE3. The results are shown in Table 2.
</bodyText>
<page confidence="0.975369">
12
</page>
<table confidence="0.999872222222222">
test → D2 T2 D3
1 train
I II III IV I II III IV I II III IV
D2 56.25 57.25 58.625 57.5 57.875 61.125 66.375 66.625
T2 56.375 58.75 60.625 61.625 57.5 60.875 63.75 64.625
D3 53.875 61.25 61.75 61.75 56.625 58.75 57.25 57.25
D2T2 58.5 64.25 65.875 66.375
D2D3 58 58.625 60 58.5
T2D3 56.75 61.25 60.875 60.875
</table>
<tableCaption confidence="0.999471">
Table 2: Performance of the different feature combinations on different training and test sets.
</tableCaption>
<subsectionHeader confidence="0.999458">
3.3 Corpus Variance
</subsectionHeader>
<bodyText confidence="0.999955380952381">
A general observation is, that almost all features
behave quite differently on different training and
test sets, as do feature combinations. Testing on T2
(RTE2-test) seems to be the hardest task. Not a sin-
gle feature combination achieved an accuracy of
more than 60%. In contrast, the best performance
was 66.625% accuracy (IV-D2-D3). 2
Usually, using a larger training set (the bottom
part of table 2) should lead to a better performance.3
However, this effect could not be observed here for
all configurations. For most feature sets the perfor-
mance gain is very small, e.g. from 56.375 (I-T2-
D2) and 53.875 (I-D3-D2) to 56.75 (I-T2D3-D2).
On some feature sets, the performance even drops,
e.g. from 61.625 (IV-T2-D2) and 61.75 (IV-D3-D2)
to 60.875 (IV-T2D3-D2). The largest boost occurred
for feature set II. It’s performance increased from
61.125 (II-D2-D3) and 60.875 (II-T2-D3) to 64.25
(II-D2T2-D3). It would be very interesting to see
how the performance would develop on a much
larger training set.
</bodyText>
<subsectionHeader confidence="0.990242">
3.4 Feature Variance
</subsectionHeader>
<bodyText confidence="0.997263454545455">
The variance among individual features and feature
sets is also large. Feature set II contains the most re-
liable and stable features. We tested how this “more
informed” feature set (II) compares to the shallow
word overlap feature (IV) and whether their combi-
nation (III) increases accuracy.
2One indicator for the “difficulty” of a test set is the aver-
age lexical overlap of text and hypothesis. The difference of
the proportion between the entailed and not entailed pairs – the
discriminative power of the overlap feature – differs among dif-
ferent sets: e.g. 0.05 on T2 and 0.13 on D3.
3In terms of machine learning, extending a training set by
factor 2 (from 800 to 1.600 items) does not make a qualitative
difference. The improvement observed by (Hickl et al., 2006)
was achieved by going to 10.000 items.
As can be seen from Table 2, in most of the cases,
IV performs best, e.g. in the D2-D3 configuration,
where feature set II alone achieves 61.125, while the
combination with IV boosts the performance by 5%
(III). On the other hand, there are cases, where the
inclusion of the word overlap feature lowers the per-
formance, e.g. from 61.25 (II-T2D3-D2) to 60.875
(III-T2D3-D2).
It is also interesting that combinations of features
often perform lower than the best individual feature
in the set. For instance, in D2T2-D3 III achieves
65.875, compared to 66.375 for IV alone. We gener-
ally could not observe a positive effect for the com-
bination of features in a meta feature. In almost all
configurations, the meta feature performed worse or
equally well as the best individual feature. Apart
from the size of the training data, feature depen-
dence might be an explanation for this.
</bodyText>
<subsectionHeader confidence="0.976771">
3.5 Task Variance
</subsectionHeader>
<bodyText confidence="0.999918176470588">
Figure 2 shows a per task analysis for the feature sets
II, III and IV (D2T2-D3). The system performs best
on the Question Answering task, where it achieves
almost 80% accuracy. This differs from last year’s
experience, where the system performed best in the
Summarization task. Given the general variance dis-
cussed above, this observation does not seem to al-
low general conclusions.
Again, there is a large variability of the overlap
feature as well, which ranges between 52.5% (IE)
and 79% (QA). This variability can partly be ex-
plained if we compare the average word overlap
measures for positive and negative pairs among the
individual tasks (Table 3). Note however, that the
difference (Δ) between positive and negative exam-
ples in IE and IR is identical while the accuracy of
the word overlap feature differs drastically.
</bodyText>
<page confidence="0.999092">
13
</page>
<figureCaption confidence="0.939617">
Figure 2: Per task accuracy (D2T2-D3).
</figureCaption>
<table confidence="0.999312">
Task Entailed Not Entailed Δ
IE 0.41 0.35 0.06
SUm 0.39 0.22 0.17
IR 0.29 0.23 0.06
QA 0.44 0.20 0.24
</table>
<tableCaption confidence="0.999959">
Table 3: Average word overlap per task for D3
</tableCaption>
<bodyText confidence="0.999665142857143">
The per task analysis also confirms the observa-
tion that the combination of (deep and shallow) fea-
tures behaves heterogeneously in terms of accuracy.
A somewhat unexpected result is that the more
“informed” feature II performs better in SUM as the
shallow feature IV while it is the other way round in
QA (see Figure 2).
</bodyText>
<sectionHeader confidence="0.998907" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.993115734375">
It is a bit surprising that a shallow feature like word
overlap performs comparable to, or even better than,
more informed features obtained from a relatively
deep linguistic analysis, and that the combination of
both types of features does not always increase the
overall accuracy.
One possible explanation is the limited size of the
training data, which seems to be too small for the
machine learner to exploit the full potential of the
deep features. One way to compensate for the lim-
ited training size would be to make the implicit lin-
guistic information encoded in the features more ex-
plicit, for instance by making the graph matching
linguistically more informed. Options are to com-
pute a proper embedding of the hypothesis graph
into the text graph, or interlinking of the various lay-
ers of analysis (syntax, semantics, ontology) in some
other more controlled way.
However, to come up with a more explicit model
of textual entailment, a deeper understanding of the
principles involved in establishing textual entail-
ment relations is necessary. An idea which is derived
from the traditional notion of logical entailment is
that the information encoded in the hypothesis must
(somehow) be subsumed by the text for the entailemt
to hold. Although most approaches to textual entail-
ment seem to rely on this assumption in one way or
another, it is easy to find pairs in the RTE corpora
where the relation between text and hypothesis can-
not be modelled so straightforwardly. In (1), for in-
stance, textual entailment holds although was born
in is more specific than be from.
(1a) As a real native Detroiter, I want to remind ev-
eryone that Madonna is from Bay City, Mich.,
[... ].
(1b) Madonna was born in Bay City, Mich.
Interestingly, textual entailment sometimes does not
hold even if the information expressed by the hy-
pothesis is subsumed by the text:
(2a) [... ] Nizar Hamdoun, announced today, Sun-
day, that thousands of people were killed or in-
jured during the four days of air bombardment
against Iraq.
(2b) Nizar HAMDOON, Iraqi ambassador to the
United Nations, announced that thousands of
people could be killed or wounded due to the
aerial bombardment of Iraq.
Although the hypothesis is logically entailed by the
text (if we ignore the report context) – ‘kill’ implies
‘possibly kill’ – pragmatic principles seem to block
entailment here.
The observation that standard logical entailment
and textual entailment deviate in certain respects is
not surprising and has also been addressed in a dis-
cussion initiated by (Zaenen et al., 2005). Still, there
is no consensus regarding the precise mechanisms
involved in the latter such as “general principles of
plausibility” or pragmatic principles.
We conducted a short annotation experiment dur-
ing a reading circle at our department on a randomly
chosen subset of 10 pairs from the RTE 1 (includ-
ing (1) and (2) from above). A central result was
that it is relatively easy to decide whether textual en-
tailment holds while it often remained controversial
</bodyText>
<page confidence="0.996667">
14
</page>
<bodyText confidence="0.999950875">
why this is the case. In particular, it seems difficult
to tell whether an inference is strict or just plausible,
and whether it relies on lexical knowledge only or
whether “world knowledge” is involved. Currently, a
larger subset of the RTE datasets is annotated as part
of a Master’s thesis project, and we hope to learn
more about the principles that underly the notion of
textual entailment from the analysis of this data.
</bodyText>
<sectionHeader confidence="0.989276" genericHeader="conclusions">
5 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.9998625">
In this paper, we have compared two approximations
to textual entailment – a shallow one based on word
overlap, and a more informed one based on a rel-
atively deep linguistic analysis. The evaluation on
various data sets shows that both perform (by and
large) comparable; sometimes the shallow compo-
nent even outperforms the deeper one. A modest im-
provement in accuracy can be achieved by combin-
ing both components, but this effect cannot be ob-
served invariably on all data sets.
One reason why the deep system does not perform
better seems to be the limited size of the training data
available for the machine learning component. As
we cannot expect the necessary amount of training
data to be available in the near future, we currently
investigate the data more closely in order to arrive
at a more controlled model of textual entailment. In
another current effort, we work on an interface to
upper-level ontologies (Reiter, 2007) in order to ac-
cess more “world-knowledge” which is a desidera-
tum in natural language processing in general, as in
many approaches to textual entailment.
</bodyText>
<sectionHeader confidence="0.994956" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99771875">
This work has partly been funded by the German
Research Foundation DFG (grant PI 154/9-2). We
also acknowledge Katrin Erk’s support of the Shal-
maneser system.
</bodyText>
<sectionHeader confidence="0.999419" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999838142857143">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of COLING-ACL, Montreal, Canada.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo
Giampiccolo, Bernardo Magnini, and Idan Szpektor,
editors. 2006. Proceedings of the Second PASCAL
Challenges Workshop on Recognising Textual Entail-
ment, Venice, Italy.
Johan Bos and Katja Markert. 2006. When logical infer-
ence helps determining textual entailment (and when it
doesn’t). In Proceedings of PASCAL RTE2 Workshop.
Aljoscha Burchardt and Anette Frank. 2006. Approx-
imating Textual Entailment with LFG and FrameNet
Frames. In Proceedings of PASCAL RTE2 Workshop.
Aljoscha Burchardt, Katrin Erk, and Anette Frank. 2005.
A WordNet Detour to FrameNet. In B. Fisseni,
H.-C. Schmitz, B. Schröder, and P. Wagner, editors,
Sprachtechnologie, mobile Kommunikation und lin-
guistische Resourcen, volume 8 of Computer Studies
in Language and Speech. Peter Lang, Frankfurt/Main.
Katrin Erk and Sebastian Pado. 2006. Shalmaneser - a
flexible toolbox for semantic role assignment. In Pro-
ceedings ofLREC 2006, Genoa, Italy.
Christiane Fellbaum. 1997. English verbs as semantic
net. In WordNet: an electronic lexical database. MIT.
Andrew Hickl, Jeremy Bensley, John Williams, Kirk
Roberts, Bryan Rink, and Ying Shi. 2006. Recogniz-
ing Textual Entailment with LCC’s Groundhog Sys-
tem. In Proceedings ofPASCAL RTE2 Workshop.
Ian Niles and Adam Pease. 2001. Towards a standard
upper ontology. In Proceedings of the International
Conference on Formal Ontology in Information Sys-
tems (FOIS), pages 2–9. ACM Press.
Nils Reiter. 2007. Towards linking FrameNet and
SUMO. Diploma Thesis (in preparation).
Stefan Riezler, Tracy H. King, Ronald M. Kaplan,
Richard Crouch, John T. III Maxwell, and Mark John-
son. 2002. Parsing the Wall Street Journal us-
ing a Lexical-Functional Grammar and Discriminative
Estimation Techniques. In Proceedings of ACL’02,
Philadelphia, PA.
Ulrich Schäfer, 2005. Heart of Gold, User and Devel-
oper Documentation. DFKI Language Technology
Lab, Saarbrücken, Germany.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proceedings of Interna-
tional Conference on New Methods in Language Pro-
cessing, Manchester, UK.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Prac-
tical Machine Learning Tools and Techniques. Mor-
gan Kaufmann, San Francisco, 2 edition.
Annie Zaenen, Lauri Karttunen, and Richard Crouch.
2005. Local textual inference: Can it be defined or
circumscribed? In Proceedings of the ACL Workshop
on Empirical Modeling of Semantic Equivalence and
Entailment, Ann Arbor, Michigan, June.
</reference>
<page confidence="0.997933">
15
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539063">
<title confidence="0.9985535">A Semantic Approach To Textual Entailment: System Evaluation and Task Analysis</title>
<author confidence="0.895735">Nils Reiter Burchardt</author>
<author confidence="0.895735">Stefan Thater Anette</author>
<affiliation confidence="0.8756685">Dept. of Computational Saarland</affiliation>
<address confidence="0.87399">Saarbrücken, Germany</address>
<affiliation confidence="0.999808">Dept. of Computational University of</affiliation>
<address confidence="0.965931">Germany</address>
<abstract confidence="0.997708363636363">This paper discusses our contribution to the third RTE Challenge – the SALSA RTE system. It builds on an earlier system based on a relatively deep linguistic analysis, which we complement with a shallow component based on word overlap. We evaluate their (combined) performance on various data sets. However, earlier observations that the combination of features improves the overall accuracy could be replicated only partly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="3180" citStr="Baker et al., 1998" startWordPosition="515" endWordPosition="518">ide a detailed evaluation of the system on different data sets. In Section 4, we report on some findings we made in a small annotation experiment we conducted at our department. In Section 5, we conclude and give a short outlook. 2 The SALSA RTE System In this Section, we review the basic architecture of the SALSA RTE system, and report on some improvements and extensions. More details can be found in (Burchardt and Frank, 2006). 2.1 Architecture The SALSA RTE system is based on three main components: (i) a linguistic analysis of text and hypothesis based primarily on LFG and Frame Semantics (Baker et al., 1998), (ii) the computation of a match graph that encodes the “semantic overlap” between text and hypothesis, and (iii) a statistical entailment decision. Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15, Prague, June 2007. @2007 Association for Computational Linguistics Figure 1: Linguistic Analysis of Leloir discovered the metabolism of carbon hydrates. (RTE3-test). Linguistic analysis. The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic ann</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment,</booktitle>
<editor>Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor, editors.</editor>
<location>Venice, Italy.</location>
<contexts>
<context position="915" citStr="(2006)" startWordPosition="137" endWordPosition="137">sses our contribution to the third RTE Challenge – the SALSA RTE system. It builds on an earlier system based on a relatively deep linguistic analysis, which we complement with a shallow component based on word overlap. We evaluate their (combined) performance on various data sets. However, earlier observations that the combination of features improves the overall accuracy could be replicated only partly. 1 Introduction This paper reports on the system we used in the third PASCAL challenge on Recognizing Textual Entailment. The system is based to a large extent on Burchardt and Frank’s system (2006) used in the second RTE challenge (Bar-Haim et al., 2006); it relies on a relatively deep linguistic analysis, which we complement with a shallow component based on word overlap. As the system has been described earlier, we concentrate on a more systematic discussion of the system behaviour, aiming at spotting promising anchors for future extensions and improvements. It has been observed for related systems that a combination of separately trained features in the machine learning component can lead to an overall improvement in system performance, in particular if features from a more “informed</context>
</contexts>
<marker>2006</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor, editors. 2006. Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>When logical inference helps determining textual entailment (and when it doesn’t).</title>
<date>2006</date>
<booktitle>In Proceedings of PASCAL RTE2 Workshop.</booktitle>
<contexts>
<context position="1600" citStr="Bos and Markert, 2006" startWordPosition="244" endWordPosition="247">elies on a relatively deep linguistic analysis, which we complement with a shallow component based on word overlap. As the system has been described earlier, we concentrate on a more systematic discussion of the system behaviour, aiming at spotting promising anchors for future extensions and improvements. It has been observed for related systems that a combination of separately trained features in the machine learning component can lead to an overall improvement in system performance, in particular if features from a more “informed” component and shallow ones are combined (Hickl et al., 2006; Bos and Markert, 2006). We provide a detailed analysis of our system’s behaviour on different training and test sets. However, we could not replicate the effects *By the time of writing, Anette Frank was affiliated at Saarland University and DFKI Saarbrücken. 10 observed by others on all corpora – often, the accuracy of the combined features is not higher than the best individual features or feature sets. For the RTE 3 test set, the combined features actually lead to a slightly lower accuracy. One candidate future enhancement of our system is to refine the relatively unrestricted graph matching that compares the an</context>
</contexts>
<marker>Bos, Markert, 2006</marker>
<rawString>Johan Bos and Katja Markert. 2006. When logical inference helps determining textual entailment (and when it doesn’t). In Proceedings of PASCAL RTE2 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Anette Frank</author>
</authors>
<title>Approximating Textual Entailment with LFG and FrameNet Frames.</title>
<date>2006</date>
<booktitle>In Proceedings of PASCAL RTE2 Workshop.</booktitle>
<contexts>
<context position="2993" citStr="Burchardt and Frank, 2006" startWordPosition="482" endWordPosition="485">rely on a deeper understanding of the notion of textual entailment. In Section 2, we review the basic architecture of our system, and report on improvements and extensions. In Section 3, we provide a detailed evaluation of the system on different data sets. In Section 4, we report on some findings we made in a small annotation experiment we conducted at our department. In Section 5, we conclude and give a short outlook. 2 The SALSA RTE System In this Section, we review the basic architecture of the SALSA RTE system, and report on some improvements and extensions. More details can be found in (Burchardt and Frank, 2006). 2.1 Architecture The SALSA RTE system is based on three main components: (i) a linguistic analysis of text and hypothesis based primarily on LFG and Frame Semantics (Baker et al., 1998), (ii) the computation of a match graph that encodes the “semantic overlap” between text and hypothesis, and (iii) a statistical entailment decision. Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15, Prague, June 2007. @2007 Association for Computational Linguistics Figure 1: Linguistic Analysis of Leloir discovered the metabolism of carbon hydrates. (RTE3-test). Linguistic analy</context>
</contexts>
<marker>Burchardt, Frank, 2006</marker>
<rawString>Aljoscha Burchardt and Anette Frank. 2006. Approximating Textual Entailment with LFG and FrameNet Frames. In Proceedings of PASCAL RTE2 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
</authors>
<title>A WordNet Detour to FrameNet.</title>
<date>2005</date>
<booktitle>Sprachtechnologie, mobile Kommunikation und linguistische Resourcen,</booktitle>
<volume>8</volume>
<editor>In B. Fisseni, H.-C. Schmitz, B. Schröder, and P. Wagner, editors,</editor>
<location>Frankfurt/Main.</location>
<contexts>
<context position="3956" citStr="Burchardt et al., 2005" startWordPosition="628" endWordPosition="631">ceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15, Prague, June 2007. @2007 Association for Computational Linguistics Figure 1: Linguistic Analysis of Leloir discovered the metabolism of carbon hydrates. (RTE3-test). Linguistic analysis. The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al., 2005). Frame semantic analysis is especially interesting for the task of recognising textual entailment as it offers a robust yet relatively precise measure for semantic overlap. The lexical meaning of predicates and their arguments are modelled in terms offrames and roles. A frame describes a prototypical situation and roles identify participants involved in the situation. Frames provide normalisations over divers surface realisations, including variations in argument structure realisations. For instance, buy, sell, and purchase are all associated with the same frame. The linguistic analysis combi</context>
</contexts>
<marker>Burchardt, Erk, Frank, 2005</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, and Anette Frank. 2005. A WordNet Detour to FrameNet. In B. Fisseni, H.-C. Schmitz, B. Schröder, and P. Wagner, editors, Sprachtechnologie, mobile Kommunikation und linguistische Resourcen, volume 8 of Computer Studies in Language and Speech. Peter Lang, Frankfurt/Main.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pado</author>
</authors>
<title>Shalmaneser - a flexible toolbox for semantic role assignment.</title>
<date>2006</date>
<booktitle>In Proceedings ofLREC 2006,</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="3876" citStr="Erk and Pado, 2006" startWordPosition="616" endWordPosition="619">etween text and hypothesis, and (iii) a statistical entailment decision. Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15, Prague, June 2007. @2007 Association for Computational Linguistics Figure 1: Linguistic Analysis of Leloir discovered the metabolism of carbon hydrates. (RTE3-test). Linguistic analysis. The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al., 2005). Frame semantic analysis is especially interesting for the task of recognising textual entailment as it offers a robust yet relatively precise measure for semantic overlap. The lexical meaning of predicates and their arguments are modelled in terms offrames and roles. A frame describes a prototypical situation and roles identify participants involved in the situation. Frames provide normalisations over divers surface realisations, including variations in argument structure realisations. For instance, buy, sell, an</context>
</contexts>
<marker>Erk, Pado, 2006</marker>
<rawString>Katrin Erk and Sebastian Pado. 2006. Shalmaneser - a flexible toolbox for semantic role assignment. In Proceedings ofLREC 2006, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>English verbs as semantic net. In WordNet: an electronic lexical database.</title>
<date>1997</date>
<publisher>MIT.</publisher>
<contexts>
<context position="5333" citStr="Fellbaum, 1997" startWordPosition="841" endWordPosition="843">and “pseudo predicates” for f-structure predicates that do not project frames. Figure 1 shows the most important parts of the analysis of hypothesis 109 from the RTE 3 test set as an example. The LFG f-structure is shown on the left, and the dotted lines indicate the projection to semantic nodes on the right. The predicate discover is associated with the frame ACxIEVING_FIRST, the semantic role COGNIZER points to the pseudo-predicate Leloir and NEW_IDEA points to the PROCESS frame evoked by metabolism. Semantic nodes are further projected into an ontological analysis layer containing WordNet (Fellbaum, 1997) senses and SUMO (Niles and Pease, 2001) classes. Semantic phenomena not treated by FrameNet like anaphora, negation or modality are (approximately) encoded with special operators. The resulting, layered graph structures for text and hypothesis thus provide access to the different types of information in a principled way. Semantic overlap and match graphs. The system approximates textual entailment in terms of the “semantic overlap” between text and hypothesis. It compares their LFG f-structures with semantic and ontological projection by determining compatible, matching nodes and edges. The r</context>
</contexts>
<marker>Fellbaum, 1997</marker>
<rawString>Christiane Fellbaum. 1997. English verbs as semantic net. In WordNet: an electronic lexical database. MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hickl</author>
<author>Jeremy Bensley</author>
<author>John Williams</author>
<author>Kirk Roberts</author>
<author>Bryan Rink</author>
<author>Ying Shi</author>
</authors>
<title>Recognizing Textual Entailment with LCC’s Groundhog System.</title>
<date>2006</date>
<booktitle>In Proceedings ofPASCAL RTE2 Workshop.</booktitle>
<contexts>
<context position="1576" citStr="Hickl et al., 2006" startWordPosition="240" endWordPosition="243"> et al., 2006); it relies on a relatively deep linguistic analysis, which we complement with a shallow component based on word overlap. As the system has been described earlier, we concentrate on a more systematic discussion of the system behaviour, aiming at spotting promising anchors for future extensions and improvements. It has been observed for related systems that a combination of separately trained features in the machine learning component can lead to an overall improvement in system performance, in particular if features from a more “informed” component and shallow ones are combined (Hickl et al., 2006; Bos and Markert, 2006). We provide a detailed analysis of our system’s behaviour on different training and test sets. However, we could not replicate the effects *By the time of writing, Anette Frank was affiliated at Saarland University and DFKI Saarbrücken. 10 observed by others on all corpora – often, the accuracy of the combined features is not higher than the best individual features or feature sets. For the RTE 3 test set, the combined features actually lead to a slightly lower accuracy. One candidate future enhancement of our system is to refine the relatively unrestricted graph match</context>
<context position="13290" citStr="Hickl et al., 2006" startWordPosition="2140" endWordPosition="2143">s “more informed” feature set (II) compares to the shallow word overlap feature (IV) and whether their combination (III) increases accuracy. 2One indicator for the “difficulty” of a test set is the average lexical overlap of text and hypothesis. The difference of the proportion between the entailed and not entailed pairs – the discriminative power of the overlap feature – differs among different sets: e.g. 0.05 on T2 and 0.13 on D3. 3In terms of machine learning, extending a training set by factor 2 (from 800 to 1.600 items) does not make a qualitative difference. The improvement observed by (Hickl et al., 2006) was achieved by going to 10.000 items. As can be seen from Table 2, in most of the cases, IV performs best, e.g. in the D2-D3 configuration, where feature set II alone achieves 61.125, while the combination with IV boosts the performance by 5% (III). On the other hand, there are cases, where the inclusion of the word overlap feature lowers the performance, e.g. from 61.25 (II-T2D3-D2) to 60.875 (III-T2D3-D2). It is also interesting that combinations of features often perform lower than the best individual feature in the set. For instance, in D2T2-D3 III achieves 65.875, compared to 66.375 for</context>
</contexts>
<marker>Hickl, Bensley, Williams, Roberts, Rink, Shi, 2006</marker>
<rawString>Andrew Hickl, Jeremy Bensley, John Williams, Kirk Roberts, Bryan Rink, and Ying Shi. 2006. Recognizing Textual Entailment with LCC’s Groundhog System. In Proceedings ofPASCAL RTE2 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Niles</author>
<author>Adam Pease</author>
</authors>
<title>Towards a standard upper ontology.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Formal Ontology in Information Systems (FOIS),</booktitle>
<pages>2--9</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="5373" citStr="Niles and Pease, 2001" startWordPosition="847" endWordPosition="850">ucture predicates that do not project frames. Figure 1 shows the most important parts of the analysis of hypothesis 109 from the RTE 3 test set as an example. The LFG f-structure is shown on the left, and the dotted lines indicate the projection to semantic nodes on the right. The predicate discover is associated with the frame ACxIEVING_FIRST, the semantic role COGNIZER points to the pseudo-predicate Leloir and NEW_IDEA points to the PROCESS frame evoked by metabolism. Semantic nodes are further projected into an ontological analysis layer containing WordNet (Fellbaum, 1997) senses and SUMO (Niles and Pease, 2001) classes. Semantic phenomena not treated by FrameNet like anaphora, negation or modality are (approximately) encoded with special operators. The resulting, layered graph structures for text and hypothesis thus provide access to the different types of information in a principled way. Semantic overlap and match graphs. The system approximates textual entailment in terms of the “semantic overlap” between text and hypothesis. It compares their LFG f-structures with semantic and ontological projection by determining compatible, matching nodes and edges. The result is stored in a match graph, which </context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>Ian Niles and Adam Pease. 2001. Towards a standard upper ontology. In Proceedings of the International Conference on Formal Ontology in Information Systems (FOIS), pages 2–9. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Reiter</author>
</authors>
<title>Towards linking FrameNet and SUMO. Diploma Thesis (in preparation).</title>
<date>2007</date>
<marker>Reiter, 2007</marker>
<rawString>Nils Reiter. 2007. Towards linking FrameNet and SUMO. Diploma Thesis (in preparation).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02,</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="3727" citStr="Riezler et al., 2002" startWordPosition="594" endWordPosition="597">hypothesis based primarily on LFG and Frame Semantics (Baker et al., 1998), (ii) the computation of a match graph that encodes the “semantic overlap” between text and hypothesis, and (iii) a statistical entailment decision. Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 10–15, Prague, June 2007. @2007 Association for Computational Linguistics Figure 1: Linguistic Analysis of Leloir discovered the metabolism of carbon hydrates. (RTE3-test). Linguistic analysis. The primary linguistic analysis components are the probabilistic LFG grammar for English developed at PARC (Riezler et al., 2002), and a combination of systems for frame semantic annotation: the probabilistic Shalmaneser system for frame and role annotation (Erk and Pado, 2006), and the rule-based Detour system for frame assignment (Burchardt et al., 2005). Frame semantic analysis is especially interesting for the task of recognising textual entailment as it offers a robust yet relatively precise measure for semantic overlap. The lexical meaning of predicates and their arguments are modelled in terms offrames and roles. A frame describes a prototypical situation and roles identify participants involved in the situation.</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. III Maxwell, and Mark Johnson. 2002. Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques. In Proceedings of ACL’02, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Schäfer</author>
</authors>
<title>Heart of Gold, User and Developer Documentation. DFKI Language Technology Lab,</title>
<date>2005</date>
<location>Saarbrücken, Germany.</location>
<contexts>
<context position="7243" citStr="Schäfer, 2005" startWordPosition="1137" endWordPosition="1138">ailment decision. Given a match graph and the graphs for text and hypothesis, we extract various features to train a machine learning model for textual entailment. In total, we extract 47 distinct features, which can be grouped according to their (i) level of representation (lexical, syntactic, semantic), (ii) degree of connectedness in the match graph, (iii) source (text, hypothesis or match graph), and (iv) proportional relation (hypothesis/text, match/hypothesis ratio). 2.2 Improvements Sentence splitter. To cope with longer texts, we integrated the sentence splitter of the JTok tokeniser (Schäfer, 2005) into the system. WordNet interface. The WordNet interface now treats particle verbs like throw out correctly. More11 over, we tested the usability of WordNet’s verb entailment information as well as antonymy on nouns, verbs, and adjectives as basis for heuristic inferences in the graph matching process. However, for the given data, the number of text-hypothesis pairs where the relations are instantiated at all is marginal. Frame semantic projection. The interface between the LFG and the Detour and Shalmaneser systems has been improved: by now 97% (+7%) of the frames and 74% (+10%) of the role</context>
</contexts>
<marker>Schäfer, 2005</marker>
<rawString>Ulrich Schäfer, 2005. Heart of Gold, User and Developer Documentation. DFKI Language Technology Lab, Saarbrücken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="8708" citStr="Schmid, 1994" startWordPosition="1387" endWordPosition="1388">al overlap and a “meta learner” to study the combinatorics of machine learners’ results. Lexical overlap. In order to evaluate the performance of our system, we implemented a simple baseline system that approximates textual entailment in terms of lexical overlap between text and hypothesis. This shallow system is also used as a component to complement our full system in one of the two runs submitted to the RTE3 challenge. The shallow system measures the relative number of words in the hypothesis that also occur in the text. Both text and hypothesis are tagged and lemmatised using Tree Tagger (Schmid, 1994), taking only nouns, non-auxiliary verbs, adjectives and adverbs into account. Training a decision tree on the relative word-overlap as single feature yields a system which performs comparable to earlier word-overlap based systems, achieving an accuracy of 60.6 % if trained and tested on the RTE 2 development and test set, respectively (using Weka’s J48 classifier), or 57.5 % if we use Weka’s LogitBoost classifier. Weka Interface. Finally, we improved the machine learning back-end which feeds our extracted features into the Weka toolkit (Witten and Frank, 2005). This allows to train features i</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques.</booktitle>
<volume>2</volume>
<pages>edition.</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco,</location>
<contexts>
<context position="9275" citStr="Witten and Frank, 2005" startWordPosition="1472" endWordPosition="1475">e tagged and lemmatised using Tree Tagger (Schmid, 1994), taking only nouns, non-auxiliary verbs, adjectives and adverbs into account. Training a decision tree on the relative word-overlap as single feature yields a system which performs comparable to earlier word-overlap based systems, achieving an accuracy of 60.6 % if trained and tested on the RTE 2 development and test set, respectively (using Weka’s J48 classifier), or 57.5 % if we use Weka’s LogitBoost classifier. Weka Interface. Finally, we improved the machine learning back-end which feeds our extracted features into the Weka toolkit (Witten and Frank, 2005). This allows to train features in arbitrary combinations, with different machine learners.&apos; Moreover, it supports testing the effect of using voting or &apos;The figures we present in the following are all computed with the LogitBoost classifier. IE IR QA SUM Run 1 (III) 62.25% 51% 68% 74% 57% Run 2 (II) 62.62% 50% 69% 72.5% 59% Table 1: Results of the SALSA RTE system (combined training set: RTE2-dev/-test and RTE3-dev). a “meta learner” after training individual features or feature groups separately. 3 Results 3.1 RTE3 Results In the RTE3 task, we submitted two runs, one with (run 1) and one wit</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques. Morgan Kaufmann, San Francisco, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Zaenen</author>
<author>Lauri Karttunen</author>
<author>Richard Crouch</author>
</authors>
<title>Local textual inference: Can it be defined or circumscribed?</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment,</booktitle>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="18123" citStr="Zaenen et al., 2005" startWordPosition="2956" endWordPosition="2959">people were killed or injured during the four days of air bombardment against Iraq. (2b) Nizar HAMDOON, Iraqi ambassador to the United Nations, announced that thousands of people could be killed or wounded due to the aerial bombardment of Iraq. Although the hypothesis is logically entailed by the text (if we ignore the report context) – ‘kill’ implies ‘possibly kill’ – pragmatic principles seem to block entailment here. The observation that standard logical entailment and textual entailment deviate in certain respects is not surprising and has also been addressed in a discussion initiated by (Zaenen et al., 2005). Still, there is no consensus regarding the precise mechanisms involved in the latter such as “general principles of plausibility” or pragmatic principles. We conducted a short annotation experiment during a reading circle at our department on a randomly chosen subset of 10 pairs from the RTE 1 (including (1) and (2) from above). A central result was that it is relatively easy to decide whether textual entailment holds while it often remained controversial 14 why this is the case. In particular, it seems difficult to tell whether an inference is strict or just plausible, and whether it relies</context>
</contexts>
<marker>Zaenen, Karttunen, Crouch, 2005</marker>
<rawString>Annie Zaenen, Lauri Karttunen, and Richard Crouch. 2005. Local textual inference: Can it be defined or circumscribed? In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, Ann Arbor, Michigan, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>