<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9978815">
Name Matching Between Chinese and Roman Scripts:
Machine Complements Human
</title>
<author confidence="0.752366">
Ken Samuel, Alan Rubenstein, Sherri Condon, and Alex Yeh
</author>
<affiliation confidence="0.287862">
The MITRE Corporation; M/S H305; 7515 Colshire Drive; McLean, Virginia 22102-7508
</affiliation>
<email confidence="0.753146">
samuel@mitre.org, rubenstein@mitre.org, scondon@mitre.org, and asy@mitre.org
</email>
<sectionHeader confidence="0.989739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960714285715">
There are generally many ways to translite-
rate a name from one language script into
another. The resulting ambiguity can make it
very difficult to “untransliterate” a name by
reverse engineering the process. In this paper,
we present a highly successful cross-script
name matching system that we developed by
combining the creativity of human intuition
with the power of machine learning. Our sys-
tem determines whether a name in Roman
script and a name in Chinese script match
each other with an F-score of 96%. In addi-
tion, for name pairs that satisfy a computa-
tional test, the F-score is 98%.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999555">
There are generally many ways to transliterate a
person&apos;s name from one language script into
another. For example, writers have transliterated
the Arabic name, LS rel, into Roman characters
in at least 13 ways, such as Al Choukri, Ash-
shukri, and al-Schoukri. This ambiguity can
make it very difficult to “untransliterate” a name
by reverse engineering the process.
We focused on a task that is related to transli-
teration. Cross-script name matching aims to de-
termine whether a given name part in Roman
script matches a given name part in Chinese
(Mandarin) script,1 where a name part is a single
“word” in a person&apos;s name (such as a surname),
and two names match if one is a transliteration of
the other.2 Cross-script name matching has many
</bodyText>
<footnote confidence="0.99367675">
1 In this paper, we often use the word “Roman” to refer to
“Roman script”, and similarly, “Chinese” usually stands
for “Chinese script”.
2 Sometimes a third script comes between the Roman and
Chinese versions of the name. For example, a Roman
name might be transliterated into Arabic, which is then
transliterated into Chinese, or an Arabic name could be
transliterated into Roman and Chinese independently.
</footnote>
<bodyText confidence="0.999320952380953">
applications, such as identity matching, improv-
ing search engines, and aligning parallel corpora.
We combine a) the creative power of human
intuition, which can come up with clever ideas
and b) the computational power of machine
learning, which can analyze large quantities of
data. Wan and Verspoor (1998) provided the
human intuition by designing an algorithm to
divide names into pieces that are just the right
size for Roman-Chinese name matching (Section
2.2.). Armed with Wan and Verspoor&apos;s algo-
rithm, a machine learning approach analyzes
hundreds of thousands of matched name pairs to
build a Roman-Chinese name matching system
(Section 3).
Our experimental results are in Section 4. The
system correctly determines whether a Roman
name and a Chinese name match each other with
F = 96.5%.3 And F = 97.6% for name pairs that
satisfy the Perfect Alignment hypothesis condi-
tion, which is defined in Section 2.2.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99972775">
Wan and Verspoor&apos;s (1998) work had a great
impact on our research, and we explain how we
use it in Section 2.2. In Section 2.1, we identify
other related work.
</bodyText>
<subsectionHeader confidence="0.994761">
2.1 Chinese-English Name Matching
</subsectionHeader>
<bodyText confidence="0.9990632">
Condon et al. (2006) wrote a paper about the
challenges of matching names across Roman and
Chinese scripts. In Section 6 of their paper, they
offered an overview of several papers related to
Roman-Chinese name matching. (Cohen et al.,
</bodyText>
<note confidence="0.595903">
2003; Gao et al., 2004; Goto et al., 2003; Jung et
al., 2000; Kang and Choi, 2000; Knight and
Graehl, 1997; Kondrak, 2000; Kondrak and
Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh
</note>
<footnote confidence="0.490718">
3 F stands for F-score, which is a popular evaluation metric.
(Andrade et al., 2009)
</footnote>
<page confidence="0.92545">
152
</page>
<note confidence="0.88715">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
Roman Characters: Albertson
Phonemes: AE,L,B,ER,T,S,AH,N
Syllables: AEL,BERT,SAHN
Subsyllable Units: AE,L,BER,T,SAHN
Chinese: 阿尔贝特松
Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/
</note>
<tableCaption confidence="0.997171">
Table 1. Subsyllable Units
</tableCaption>
<bodyText confidence="0.992427142857143">
and Choi, 2006; Virga and Khudanpur, 2003;
Wellner et al., 2005; Winkler, 2002)
The Levenshtein algorithm is a popular way to
compute string edit distance. (Levenshtein, 1966)
It can quantify the similarity between two names.
However, this algorithm does not work when the
names are written in different scripts. So Free-
man et al. (2006) developed a strategy for Ro-
man-Arabic string matching that uses equiva-
lence classes of characters to normalize the
names so that Levenshtein&apos;s method can be ap-
plied. Later, Mani et al. (2006) transformed that
system from Roman-Arabic to Roman-Chinese
name matching and extended the Levenshtein
approach, attaining F = 85.2%. Then when they
trained a machine learning algorithm on the out-
put, the performance improved to F = 93.1%
Mani et al. also tried applying a phonological
alignment system (Kondrak, 2000) to the Ro-
man-Chinese name matching task, and they re-
ported an F-score of 91.2%. However, when they
trained a machine learning approach on that sys-
tem&apos;s output, the F-score was only 90.6%.
It is important to recognize that it would be in-
appropriate to present a side-by-side comparison
between Mani&apos;s work and ours (F = 96.5%), be-
cause there are many differences, such as the
data that was used for evaluation.
</bodyText>
<subsectionHeader confidence="0.999309">
2.2 Subsyllable Units
</subsectionHeader>
<bodyText confidence="0.9997074">
Transliteration is usually based on the way
names are pronounced.4 However, each character
in a Roman name generally corresponds to a sin-
gle phoneme, while a Chinese character (CC)
generally corresponds to a subsyllable unit
(SSU). A phoneme is the smallest meaningful
unit of sound, and a subsyllable unit is a se-
quence of one to three phonemes that conform to
the following three constraints. (Wan and Vers-
poor, 1998)
</bodyText>
<footnote confidence="0.5651592">
4 Of course, there are exceptions. For example, when a
name happens to be a word, sometimes that name is trans-
lated (rather than transliterated) into the other language.
But our experimental results suggest that the exceptions
are quite rare.
</footnote>
<listItem confidence="0.86735">
(1) There is exactly one vowel phoneme.5
(2) At most, one consonant phoneme may pre-
cede the vowel phoneme.
(3) The vowel phoneme may be followed by, at
most, one nasal phoneme.6
</listItem>
<bodyText confidence="0.999236285714286">
Consider the example in Table 1. The name
“Albertson” consists of eight phonemes in three
syllables.7 The last syllable, SAHN, satisfies the
definition of SSU, and the other two are split into
smaller pieces, resulting in a total of five SSUs.
There are also five CCs in the Chinese version,
阿尔贝特松. We note that the fourth and sixth rows
in the table show similarities in their pronuncia-
tions. For example, the first SSU, AE, sounds
like the first CC, /a/. And, although the sounds
are not always identical, such as BER and /pei/,
Wan and Verspoor claimed that these SSU-CC
correspondences can be generalized in the fol-
lowing way:
</bodyText>
<subsectionHeader confidence="0.733479">
Perfect Alignment (PA) hypothesis
</subsectionHeader>
<bodyText confidence="0.830032375">
If a Roman name corresponds to a sequence of n
SSUs, S1, S2, ..., Sn, and the Chinese form of that
name is a sequence of n CCs, C1, C2, ..., Cn, then
Ci matches Si for all 1 ≤ i ≤ n.
In Section 4, we show that the PA hypothesis
works very well. However, it is not uncommon
to have more SSUs than CCs in a matching name
pair, in which case, the PA hypothesis does not
apply. Often this happens because an SSU is left
out of the Chinese transliteration, perhaps be-
cause it is a sound that is not common in Chi-
nese. For example, suppose “Carlberg” (KAA,
R,L,BER,G) is transliterated as 卡尔贝里. In
this example, the SSU, R, does not corres-
pond to any of the CCs. We generalize this
phenomenon with another hypothesis:
</bodyText>
<subsectionHeader confidence="0.610871">
SSUs Deletion (SSUD) hypothesis
</subsectionHeader>
<bodyText confidence="0.8783083">
If a Roman name corresponds to a sequence of
n+k SSUs (k&gt;0), S1, S2, ..., Sn+k, and the Chinese
form of that name is a sequence of n CCs, C1, C2,
..., Cn, then, for some set of k Si’s, if those SSUs
are removed from the sequence of SSUs, then the
PA hypothesis holds.
And in the case where the number of CCs is
greater than the number of SSUs, we make the
5 Wan and Verspoor treat the phoneme, /ər/, as in Albertson,
as a vowel phoneme.
</bodyText>
<footnote confidence="0.966618">
6 The nasal phonemes are /n/ and /ŋ/, as in “nothing”.
7 To represent phonemes, we use two different standards in
this paper. The symbols between slashes (like /ər/) are in
the IPA format (International Phonetic Association,
1999). And the phonemes written in capital letters (like
ER) are in the ARPABET format (Klatt, 1990).
</footnote>
<page confidence="0.998168">
153
</page>
<figureCaption confidence="0.999864">
Figure 1. Application Mode
</figureCaption>
<bodyText confidence="0.992586">
corresponding CCs Deletion (CCD) hypothesis.
In the next section, we show how we utilize these
hypotheses.
</bodyText>
<sectionHeader confidence="0.996627" genericHeader="method">
3 Machine Learning
</sectionHeader>
<bodyText confidence="0.9999834">
We designed a machine learning algorithm to
establish a mapping between SSUs and CCs. In
Section 3.1, we show how our system can do
Roman-Chinese name matching, and then we
present the training procedure in Section 3.2.
</bodyText>
<subsectionHeader confidence="0.998831">
3.1 Application Mode
</subsectionHeader>
<bodyText confidence="0.91526244">
Given a Roman-Chinese name pair, our system
computes a match score, which is a number be-
tween 0 and 1 that is meant to represent the like-
lihood that two names match. This is accom-
plished via the process presented in Figure 1.
Starting in the upper-left node of the diagram
with a Roman name and a Chinese name, the
system determines how the Roman name should
A B E G K L L L N R S T
E E H A A I A A
R A H Y H H
N N
伦 0 0 0 0 0 0 1 0 0 0 0 0
利 0 0 0 0 0 0 0 1 0 0 0 0
卡 0 0 0 0 1 0 0 0 0 0 0 0
叶 0 0 1 0 0 0 0 0 0 0 0 0
埃 0 0 1 0 0 0 0 0 0 0 0 0
娜 0 0 0 0 0 0 0 0 1 0 0 0
尔 0 0 0 0 0 2 0 0 0 1 0 0
松 0 0 0 0 0 0 0 0 0 0 1 0
特 0 0 0 0 0 0 0 0 0 0 0 2
贝 0 3 0 0 0 0 0 0 0 0 0 0
连 0 0 0 0 0 0 1 0 0 0 0 0
里 0 0 0 1 0 0 0 0 0 0 0 0
阿 2 0 0 0 0 0 0 0 0 0 0 0
</bodyText>
<tableCaption confidence="0.884668">
Table 2. SSU-CC Matrix #1
</tableCaption>
<figureCaption confidence="0.993862">
Figure 2. Training Mode
</figureCaption>
<bodyText confidence="0.999950958333333">
be pronounced by running it through the Festival
system. (Black et al., 1999) Next, two algorithms
designed by Wan and Verspoor (1998) join the
phonemes to form syllables and divide the syl-
lables into SSUs.8 If the number of SSUs is equal
to the number of characters in the Chinese
name,9 we apply the PA hypothesis to align each
SSU with a CC.
The system computes a match score using a
data structure called the SSU-CC matrix (subsyl-
lable unit – Chinese character matrix), which has
a nonnegative number for each SSU-CC pair,
and this value should represent the strength of
the correspondence between the SSU and the
CC. Table 2 shows an example of an SSU-CC
matrix. With this matrix, the name pair &lt;Albert,
阿尔贝特&gt; receives a relatively high match score,
because the SSUs in Albert are AE, L, BER, and
T, and the numbers in the SSU-CC matrix for
&lt;AE,阿&gt;, &lt;L,尔&gt;, &lt;BER,贝&gt; and &lt;T,特&gt; are 2, 2,
3, and 2, respectively.10 Alternatively, the system
assigns a very low match score to &lt;Albert,
尔贝特阿&gt;, because the values of &lt;AE,尔&gt;, &lt;L,贝&gt;,
&lt;BER,格&gt;, and &lt;T,阿&gt; are all 0.
</bodyText>
<subsectionHeader confidence="0.999429">
3.2 Training Mode
</subsectionHeader>
<bodyText confidence="0.9955201">
To generate an SSU-CC matrix, we train our sys-
tem on a corpus of Roman-Chinese name pairs
8 This procedure passes through three separate modules,
each of which introduces errors, so we would expect the
system to suffer from compounding errors. However, the
excellent evaluation results in Section 4 suggest other-
wise. This may be because the system encounters the
same kinds of errors during training that it sees in the ap-
plication mode, so perhaps it can learn to compensate for
them.
</bodyText>
<tableCaption confidence="0.786776">
9 Section 3.3 discusses the procedure used when these num-
bers are not equal.
10 The equation used to derive the match score from these
values can be found in Section 5.
</tableCaption>
<page confidence="0.991624">
154
</page>
<table confidence="0.998579">
Example # 1 2 3 4 5
Roman Albert Albertson Carly Elena Ellenberg
Characters
Subsyllable AE,L,BER,T AE,L,BER,T,SAHN KAA,R,LIY EH,LAHN,NAH EH,LAHN,BER,G
Units
Chinese 阿尔贝特 阿尔贝特松 卡尔利 叶连娜 埃伦贝里
Characters
</table>
<tableCaption confidence="0.999505">
Table 3. Training Data
</tableCaption>
<bodyText confidence="0.999940307692308">
that match. Figure 2 shows a diagram of the
training system. The procedure for transforming
the Roman name into a sequence of SSUs is
identical to that presented in Section 3.1. Then, if
the number of SSUs is the same as the number of
CCs,9 we apply the PA hypothesis to pair the
SSUs with the CCs. For example, the third name
pair in Table 3 has three SSU-CC pairs: &lt;KAA,
卡&gt;, &lt;R,尔&gt;, and &lt;LIY,利&gt;. So the system mod-
ifies the SSU-CC matrix by adding 1 to each cell
that corresponds to one of these SSU-CC pairs.
Training on the five name pairs in Table 3 pro-
duces the SSU-CC matrix in Table 2.
</bodyText>
<subsectionHeader confidence="0.998046">
3.3 Imperfect Alignment
</subsectionHeader>
<bodyText confidence="0.998470692307692">
The system makes two passes through the train-
ing data. In the first pass, whenever the PA hypo-
thesis does not apply to a name pair (because the
number of SSUs differs from the number of
CCs), that name pair is skipped.
Then, in the second pass, the system builds
another SSU-CC matrix. The procedure for
processing each name pair that satisfies the PA
hypothesis&apos;s condition is exactly the same as in
the first pass (Section 3.2). But the other name
pairs require the SSUD hypothesis or the CCD
hypothesis to delete SSUs or CCs. For a given
Roman-Chinese name pair:
</bodyText>
<table confidence="0.998535833333333">
CCs Score Scaled Score
Ø 卡尔贝里 0.00 0.00
卡Ø 尔贝里 0.90 0.54
卡尔Ø 贝里 0.76 0.46
卡尔贝 Ø 里 0.00 0.00
卡尔贝里 Ø 0.00 0.00
</table>
<tableCaption confidence="0.999752">
Table 4. Subsyllable Unit Deletion
</tableCaption>
<bodyText confidence="0.973640961538462">
For every d in D:
Temporarily make the deletions in d.
Evaluate the resulting name pair with Matrix #1.
Scale the evaluation scores of the d&apos;s to sum to 1.
For every d in D:
Temporarily make the deletions in d.
For every SSU-CC pair, ssu-cc, in the result:
Add d&apos;s scaled score to cell [ssu,cc] in Matrix #2.
where D is the set of all deletion sets that make
the PA hypothesis applicable. Note that the size
of D grows exponentially as the difference be-
tween the number of SSUs and CCs grows.
As an example, consider adding the name pair
&lt;Carlberg, 卡尔贝里&gt; to the data in Table 3. Carl-
berg has five SSUs: KAA,R,L,BER,G, but 卡尔贝-
里 has only four CCs. So the PA hypothesis is not
applicable, and the system ignores this name pair
in the first pass. Table 2 shows the values in Ma-
trix #1 when it is completed.
In the second pass, we must apply the SSUD
hypothesis to &lt;Carlberg, 卡尔贝里&gt; by deleting
one of the SSUs. There are five ways to do this,
as shown in the five rows of Table 4. (For in-
stance, the last row represents the case where G
is deleted ― the SSU-CC pairs are &lt;KAA,卡&gt;,
&lt;R,尔&gt;, &lt;L,贝&gt;, &lt;BER,里&gt;, and &lt;G,Ø&gt;.11)
</bodyText>
<table confidence="0.999351555555556">
Ø B G K L R ...
E A
R A
Ø 0.00 0.00 0.00 0.46 0.54
卡 0.00 0.00 0.00 2.00 0.00 0.00
尔 0.00 0.00 0.00 0.00 2.54 1.46
贝 0.00 4.00 0.00 0.00 0.00 0.00
里 0.00 0.00 2.00 0.00 0.00 0.00
...
</table>
<tableCaption confidence="0.999027">
Table 5. SSU-CC Matrix #2
</tableCaption>
<bodyText confidence="0.986182333333333">
Each of the five options are evaluated using
the values in Matrix #1 (Table 2) to produce the
scores in the second column of Table 4. Then the
</bodyText>
<footnote confidence="0.701158333333333">
11 The Ø represents a deleted SSU. We include a row and
column named Ø in Matrix #2 to record values for the
cases in which the SSUs and CCs are deleted.
</footnote>
<page confidence="0.979693">
155
</page>
<table confidence="0.9934382">
LAHN LAHN BER BER
(BER) (NAH) (G) (T)
伦 1 0 0 0
贝 0 0 1 2
连 0 1 0 0
</table>
<tableCaption confidence="0.976747">
Table 6. Considering Context
</tableCaption>
<bodyText confidence="0.9994044">
system scales the scores to sum to 1, as shown in
the third column, and it uses those values as
weights to determine how much impact each of
the five options has on the second matrix. Table
5 shows part of Matrix #2.
In application mode, when the system encoun-
ters a name pair that does not satisfy the PA hy-
pothesis&apos;s condition it tries all possible deletion
sets and selects the one that produces the highest
match score.
</bodyText>
<subsectionHeader confidence="0.956996">
3.4 Considering Context
</subsectionHeader>
<bodyText confidence="0.9999399375">
It might be easier to estimate the likelihood that
an SSU-CC pair is a match by using information
found in surrounding SSU-CC pairs, such as the
SSU that follows a given SSU-CC pair. We do
this by increasing the number of columns in the
SSU-CC matrix to separate the examples based
on the surrounding context.
For example, in Table 2, we cannot determine
whether LAHN should map to 伦 or 连. But the
SSU that follows LAHN clears up the ambiguity,
because when LAHN immediately precedes
BER, it maps to 伦, but when it is followed by
NAH, it corresponds to 连. Table 6 displays a
portion of the SSU-CC matrix that accounts for
the contextual information provided by the SSU
that follows an SSU-CC pair.
</bodyText>
<subsectionHeader confidence="0.965691">
3.5 The Threshold
</subsectionHeader>
<bodyText confidence="0.999981083333333">
Given an SSU-CC name pair, the system produc-
es a number between 0 and 1. But in order to
evaluate the system in terms of precision, recall,
and F-score, we need the system to return a yes
(a match) or no (not a match) response. So we
use a threshold value to separate those two cases.
The threshold value can be manually selected
by a human, but this is often difficult to do effec-
tively. So we developed the following automated
approach to choose the threshold. After the train-
ing phase finishes developing Matrix #2, the sys-
tem processes the training data12 one more time.
</bodyText>
<footnote confidence="0.969823333333333">
12 We tried selecting the threshold with data that was not
used in training, and we found no statistically significant
improvement.
</footnote>
<table confidence="0.997583125">
Alignment % of Data
#SSUs - #CCs ≥ 3 1.62%
#SSUs - #CCs = 2 6.66%
#SSUs - #CCs = 1 20.00%
#SSUs - #CCs = 0 60.60%
#SSUs - #CCs = -1 10.48%
#SSUs - #CCs = -2 0.61%
#SSUs - #CCs ≤ -3 0.02%
</table>
<tableCaption confidence="0.99969">
Table 7. Statistics of the Data
</tableCaption>
<bodyText confidence="0.999913615384616">
But this time it runs in application mode (Section
3.1), computing a match score for each training
example. Then the system considers all possible
ways to separate the yes and no responses with a
threshold, selecting the threshold value that is the
most effective on the training data.
Building the SSU-CC matrices does not re-
quire any negative examples (name pairs that do
not match). However, we do require negative
examples in order to determine the threshold and
to evaluate the system. Our technique for gene-
rating negative examples involves randomly
rearranging the names in the data.13
</bodyText>
<sectionHeader confidence="0.925995" genericHeader="method">
4 Evaluation of the System
</sectionHeader>
<bodyText confidence="0.993663818181818">
We ran several experiments to test our system
under a variety of different conditions. After de-
scribing our data and experimental method, we
present some of our most interesting experimen-
tal results.
We used a set of nearly 500,000 Roman-
Chinese person name pairs collected from Xin-
hua News Agency newswire texts. (Huang,
2005) Table 7 shows the distribution of the data
based on alignment. Note that the PA hypothesis
applies to more than 60% of the data.
We used the popular 10-fold cross validation
approach 14 to obtain ten different evaluation
scores. For each experiment we present the aver-
age of these scores.
Our system&apos;s precision (P), recall (R), and F-
score (F) are: P = 98.19%, R = 94.83%, and F =
96.48%. These scores are much better than we
originally expected to see for the challenging
task of Roman-Chinese name matching.
Table 8 shows P, R, and F for subsets of the
test data, organized by the number of SSUs mi-
</bodyText>
<footnote confidence="0.6598588">
13 Unfortunately, there is no standard way to generate nega-
tive examples.
14 The data is divided into ten subsets of approximately the
same size, testing the system on each subset when trained
on the other nine.
</footnote>
<page confidence="0.994721">
156
</page>
<table confidence="0.99537575">
Alignment P R F
#SSUs - #CCs ≥ 3 72.38% 94.02% 81.79%
#SSUs - #CCs = 2 95.26% 92.67% 93.95%
#SSUs - #CCs = 1 99.07% 93.27% 96.08%
#SSUs - #CCs = 0 99.87% 95.33% 97.55%
#SSUs - #CCs = -1 98.33% 96.42% 97.37%
#SSUs - #CCs = -2 73.80% 94.98% 83.04%
#SSUs - #CCs ≤ -3 7.54% 78.04% 13.71%
</table>
<tableCaption confidence="0.999821">
Table 8. Varying Alignment of Name Pairs
</tableCaption>
<bodyText confidence="0.999774">
nus the number of CCs in the name pairs. The
differences between scores in adjacent rows of
each column are statistically significant.15 Per-
fectly aligned name pairs proved to be the ea-
siest, with F = 97.55%, but the system was also
very successful on the examples with the number
of SSUs and the number of CCs differing by one
(F = 96.08% and F = 97.37%). These three cases
account for more than 91% of the positive exam-
ples in our data set. (See Table 7.)
</bodyText>
<subsectionHeader confidence="0.986563">
4.1 Deletion Hypotheses
</subsectionHeader>
<bodyText confidence="0.999932">
We ran tests to determine whether the second
pass through the training data (in which the
SSUD and CCD hypotheses are applied) is effec-
tive. Table 9 shows the results on the complete
set of test data, and all of the differences between
the scores are statistically significant.
The first row of Table 9 presents F when the
system made only one pass through the training
data. The second row&apos;s experiments utilized the
CCD hypothesis but ignored examples with more
SSUs than CCs during training. For the third
row, we used the SSUD hypothesis, but not the
CCD hypothesis, and the last row corresponds to
system runs that used all of the training exam-
ples. From these results, it is clear that both of
the deletion hypotheses are useful, particularly
the SSUD hypothesis.
</bodyText>
<subsectionHeader confidence="0.973741">
4.2 Context
</subsectionHeader>
<bodyText confidence="0.908211642857143">
In Section 3.4, we suggested that contextual in-
formation might be useful. So we ran some tests,
obtaining the results shown in Table 10. For the
second row, we used no contextual information.
Row 5 corresponds to the case where we gave
the system access to the SSU immediately fol-
lowing the SSU-CC pair being analyzed. In row
Hypotheses F
PA 75.25%
PA &amp; CCD 83.74%
PA &amp; SSUD 92.86%
se h hmoscedatic t test s t Test
PA &amp; CCD &amp; SSUD 96.48%
id hthe the diffr n t res
6&apos;s experiment, we used the SSU immediately
preceding the SSU-CC pair under consideration,
and row 7 corresponds to system runs that ac-
counted for both surrounding SSUs.
We also tried simplifying the contextual in-
formation to
values that specify whether
an SSU-CC pair is at a boundary of its name or
not, and rows 1, 3, and 4 of Table 10 show those
results.
is true if and only if the
SSU-CC pair is at the beginning of its name,
is true if and only if the SSU-CC
boolean
</bodyText>
<equation confidence="0.9194675">
“LeftBorder”
“RightBorder”
“BothBorders”
tly.
</equation>
<bodyText confidence="0.970764967741935">
pair is at the end of its name, and
is true if and only if the SSU-CC pair is at the
beginning or end of its name. All differences in
the table are statistically significant, except for
those between rows 2, 3, and 4. These results
suggest that the right border provides no useful
information, even if the left border is also in-
cluded in the SSU-CC matrix. But when the
SSU-CC matrix only accounted for the left bor-
der, the F-score was significantly higher than the
baseline. Providing more specific information in
the form of SSUs actually made the scores go
down significan
example, compare the values in the
col-
umns in Table 2 and Table 6.) This means that
the system might have been suffering from a
sparse data problem, which is a situation where
there are not enough training examples to distin-
guish correct answers from incorrect answers,
and so incorrect answers can appear to be correct
by random chance.
There are two factors that can contribute to a
sparse data problem. One is the amount of train-
ing data available
as the quan
“BER”
―
tity of training
data increases, the sparse data problem becomes
less severe. The other factor is the complexity of
</bodyText>
<table confidence="0.997911714285714">
157 # Contextual Information F
1 Left Border 96.48%
2 No Context 96.25%
3 Both Borders 96.24%
4 Right Border 96.19% 47.89%
5 Next SSU 87.53%
d Next SSU
</table>
<tableCaption confidence="0.9559145">
lly significant.
Table 9. Varying the Training Data
</tableCaption>
<subsectionHeader confidence="0.999456">
4.3 Sparse Data
</subsectionHeader>
<bodyText confidence="0.999923666666667">
We were initially surprised to discover that using
the rich information in the surrounding SSUs
made the results worse. The explanation for this
is that adding contextual information increases
the size of the SSU-CC matrix, and so several of
the numbers in the matrix become smaller. (For
</bodyText>
<page confidence="0.420295">
6 Previous SSU 85.89%
7 Previous SSU an
</page>
<tableCaption confidence="0.999863">
Table 10. Evaluation with Context
</tableCaption>
<table confidence="0.999356875">
Contextual Info. All Cells Cells &gt; 10-7
No Context 0.128 4.35
Right Border 0.071 3.45
Left Border 0.069 3.45
Both Borders 0.040 3.13
Next SSU 0.002 1.12
Previous SSU 0.001 0.78
Both SSUs far less far less
</table>
<tableCaption confidence="0.99947">
Table 11. Num. SSU-CC Pairs per Matrix Cell
</tableCaption>
<bodyText confidence="0.948531522727273">
the learned model ― as the model becomes more
complex, the sparse data problem worsens.
Our system&apos;s model is the SSU-CC matrix,
and a reasonable measure of the its complexity is
the number of entries in the matrix. The second
column of Table 11 shows the number of SSU-
CC pairs in training divided by the number of
cells in the SSU-CC matrix. These ratios are
quite low, suggesting that there is a sparse data
problem. Even without using any context, there
are nearly 8 cells for each SSU-CC pair, on aver-
age.16
It might be more reasonable to ignore cells
with extremely low values, since we can assume
that these values are effectively zero. The third
column of Table 11 only counts cells that have
values above 10-7. The numbers in that column
look better, as the ratio of cells to training pairs
is better than 1:4 when no context is used. How-
ever, when using the previous SSU, there are still
more cells than training pairs.
Another standard way to test for sparse data is
to compare the system&apos;s results as a function of
the quantity of training data. As the amount of
training data increases, we expect the F-score to
rise, until there is so much training data that the
F-score is at its optimal value.17 Figure 3 shows
the results of all of the context experiments that
we ran, varying the amount of training data.
(90% of the training data was used to get the F-
scores in Table 10.) The t test tells us that “No
Context” is the only curve that does not increase
significantly on the right end. This suggests that
all of the other curves might continue increasing
if we used more training data. So even the “Both
SSUs” case could potentially achieve a competi-
tive score, given enough training examples. Also,
16 It is true that a name pair can have multiple SSU-CC
pairs, but even if the average number of SSU-CC pairs per
name pair is as high as 8 (and it is not), one training name
pair per SSU-CC matrix cell is still insufficient.
17 Note that this value may not be 100%, because there are
factors that can make perfection difficult to achieve, such
as errors in the data.
</bodyText>
<figure confidence="0.5543895">
10% 20% 30% 40% 50% 60% 70% 80% 90%
Training Set Size (% of available data)
</figure>
<figureCaption confidence="0.993474">
Figure 3. Testing for Sparse Data
</figureCaption>
<bodyText confidence="0.966706">
more training data could produce higher scores
than 96.48%.
</bodyText>
<sectionHeader confidence="0.995315" genericHeader="method">
5 Summary
</sectionHeader>
<bodyText confidence="0.61796132">
We designed a system that achieved an F-score
of 96.48%, and F = 97.55% on the 60.61% of the
data that satisfies the PA hypothesis&apos;s condition.
Due to the paper length restriction, we can on-
ly provide short summaries of the other experi-
ments that that we ran.
1) We experimentally compared six different
equations for computing match scores and
found that the best of them is an arithmetic
or geometric average of Prob(SSU|CC) and
Prob(CC|SSU).
2) We attempted to make use of two simple
handcrafted rules, but they caused the sys-
tem&apos;s performance to drop significantly.
3) We compared two approaches for automati-
cally computing the pronunciation of a Ro-
man name and found that using the Festival
system (Black et al., 1999) alone is just as ef-
fective as using the CMU Pronunciation Dic-
tionary (CMUdict, 1997) supplemented by
Festival.
4) We tried computing the threshold value with
data that was not used in training the system.
However, this failed to improve the system&apos;s
performance significantly.
</bodyText>
<sectionHeader confidence="0.998563" genericHeader="method">
6 Future Work
</sectionHeader>
<bodyText confidence="0.9973405">
There are so many things that we still want to do,
including:
</bodyText>
<listItem confidence="0.986258">
1. modifying our system for the task of
transliteration (Section 6.1),
2. running fair comparisons between our
work and related research,
3. using Levenshtein&apos;s algorithm (Levensh-
tein, 1966) to implement the SSUD and
</listItem>
<figure confidence="0.995507333333333">
F-Score
100%
40%
90%
80%
70%
60%
50%
Left Border Next SSU
No Context Previous SSU
Right Border Both SSUs
Both Borders
</figure>
<page confidence="0.984854">
158
</page>
<bodyText confidence="0.9976997">
CCD hypotheses, instead of exhaustively
evaluating all possible deletion sets (Sec-
tion 3.3),18
4. developing a standard methodology for
creating negative examples,
5. when using contextual information, split-
ting rows or columns of the SSU-CC
matrix only when they are ambiguous
according to a metric such as Informa-
tion Gain (Section 3.4),19
</bodyText>
<listItem confidence="0.860923666666667">
6. combining our system with other Ro-
man-Chinese name matching systems in
a voting structure (Van Halteren, Zavrel,
and Daelemans, 1998),
7. independently evaluating the modules
that determine pronunciation, construct
</listItem>
<bodyText confidence="0.967842727272727">
syllables, and separate subsyllable units
(Section 3),
8. converting phonemes into feature vectors
(Aberdeen, 2006),
9. modifying our methodology to apply it
to other similar languages, such as Japa-
nese, Korean, Vietnamese, and Ha-
waiian.
10. manually creating rules based on infor-
mation in the SSU-CC matrix, and
11. utilizing graphemic information.
</bodyText>
<subsectionHeader confidence="0.969906">
6.1 Transliteration
</subsectionHeader>
<bodyText confidence="0.978566444444445">
We would like to modify our system to enable
it to transliterate a given Roman name into Chi-
nese in the following way. First, the system
computes the SSUs as in Section 3.1. Then it
produces a match score for every possible se-
quence of CCs that has the same length as the
sequence of SSUs, returning all of the CC se-
quences with match scores that satisfy a prede-
termined threshold restriction.
For example, in a preliminary experiment,
given the Roman name Ellen, the matcher pro-
duced the transliterations below, with the match
scores in parentheses.20
埃 伦 (0.32)
埃 兰 (0.14)
埃 隆 (0.11)
埃 朗 (0.05)
18 We thank a reviewer for suggesting this method of im-
proving efficiency.
19 We thank a reviewer for this clever way to control the
size of the SSU-CC matrix when context is considered.
20 A manually-set threshold of 0.05 was used in this experi-
ment.
Based on our data, the first and fourth results
are true transliterations of Ellen, and the only
true transliteration that failed to make the list is
埃it
</bodyText>
<sectionHeader confidence="0.996348" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999981703703703">
There was a time when computational linguistics
research rarely used machine learning. Research-
ers developed programs and then showed how
they could successfully handle a few examples,
knowing that their programs were unable to ge-
neralize much further. Then the language com-
munity became aware of the advantages of ma-
chine learning, and statistical systems almost
completely took over the field. Researchers
solved all kinds of problems by tapping into the
computer&apos;s power to process huge corpora of
data. But eventually, the machine learning sys-
tems reached their limits.
We believe that, in the future, the most suc-
cessful systems will be those developed by
people cooperating with machines. Such systems
can solve problems by combining the computer&apos;s
ability to process massive quantities of data with
the human&apos;s ability to intuitively come up with
new ideas.
Our system is a success story of human-
computer cooperation. The computer tirelessly
processes hundreds of thousands of training ex-
amples to generate the SSU-CC matrix. But it
cannot work at all without the insights of Wan
and Verspoor. And together, they made a system
that is successful more than 96% of the time.
</bodyText>
<sectionHeader confidence="0.998469" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.951737647058823">
Aberdeen, J. (2006) “geometric-featurechart-jsa-
20060616.xls”. Unpublished.
Andrade, Miguel. Smith, S. Paul. Cowlisha, Mike F.
Gantner, Zeno. O&apos;Brien, Philip. Farmbrough, Rich.
et al. “F1 Score.” (2009) Wikipedia: The Free En-
cyclopedia. http://en.wikipedia.org/wiki/F-score.
Black, Alan W. Taylor, Paul. Caley, Richard. (1999)
The Festival Speech Synthesis System: System Do-
cumentation. Centre for Speech Technology Re-
search (CSTR). The University of Edinburgh.
http://www.cstr.ed.ac.uk/projects/festival/manual
CMUdict. (1997) The CMU Pronouncing Dictionary.
v0.6. The Carnegie Mellon Speech Group.
http://www.speech.cs.cmu.edu/cgi-bin/cmudict.
Cohen, W. Ravikumar, P. Fienberg, S. (2003) “A
Comparison of String Distance Metrics for Name-
.
</reference>
<page confidence="0.970186">
159
</page>
<reference confidence="0.9990955">
Matching Tasks.” Proceedings of the IJCAI-03
Workshop on Information Integration on the Web.
Eds. Kambhampati, S. Knoblock, C. 73-78.
Condon, Sherri. Aberdeen, John. Albin, Matthew.
Freeman, Andy. Mani, Inderjeet. Rubenstein, Alan.
Sarver, Keri. Sexton, Mike. Yeh, Alex. (2006)
“Multilingual Name Matching Mid-Year Status
Report.”
Condon, S. Freeman, A. Rubenstein, A. Yeh, A.
(2006) “Strategies for Chinese Name Matching.”
Freeman, A. Condon, S. Ackermann, C. (2006)
&amp;quot;Cross Linguistic Name Matching in English and
Arabic: A „One to Many Mapping‟ Extension of
the Levenshtein Edit Distance Algorithm.&amp;quot; Pro-
ceedings of NAACL/HLT.
Gao, W. Wong, K. Lam, W. (2004) “Phoneme-Based
Transliteration of Foreign Names for OOV Prob-
lem.” Proceedings of the First International Joint
Conference on Natural Language Processing.
Goto, I. Kato, N. Uratani, N. Ehara, T. (2003) “Trans-
literation Considering Context Information Based
on the Maximum Entropy Method.” Proceedings
of MT-Summit IX.
Huang, Shudong. (2005) “LDC2005T34: Chinese &lt;-&gt;
English Named Entity Lists v 1.0.” Linguistics Da-
ta Consortium. Philadelphia, Pennsylvania. ISBN
#1-58563-368-2. http://www.ldc.upenn.edu/Cata
log/CatalogEntry.jsp?catalogId=LDC2005T34.
International Phonetic Association. (1999) Handbook
of the International Phonetic Association : A Guide
to the Use of the International Phonetic Alphabet.
Cambridge University Press, UK. ISBN
0521652367. http://www.cambridge.org/uk/cata
logue/catalogue.asp?isbn=0521652367.
Jung, S. Hong, S. Paek, E. (2000) “An English to Ko-
rean Transliteration Model of Extended Markov
Window.” Proceedings of COLING.
Kang, B.J. Choi, K.S. (2000) “Automatic Translitera-
tion and Back-Transliteration by Decision Tree
Learning.” Proceedings of the 2nd International
Conference on Language Resources and Evalua-
tion.
Klatt, D.H. (1990) “Review of the ARPA Speech Un-
derstanding Project.” Readings in Speech Recogni-
tion. Morgan Kaufmann Publishers Inc. San Fran-
cisco, CA. ISBN 1-55860-124-4. 554-575.
Knight, K. Graehl, J. (1997) “Machine Translitera-
tion.” Proceedings of the Conference of the Asso-
ciation for Computational Linguistics (ACL).
Kondrak, G. (2000) “A New Algorithm for the
Alignment of Phonetic Sequences.” Proceedings of
the First Meeting of the North American Chapter
of the Association for Computational Linguistics
(NAACL). Seattle, Washington. 288-295.
Kondrak, G. Dorr, B. (2004) “Identification of Con-
fusable Drug Names: A New Approach and Evalu-
ation Methodology.” Proceedings of the Twentieth
International Conference on Computational Lin-
guistics (COLING). 952-958.
Levenshtein, V.I. (1966) “Binary Codes Capable of
Correcting Deletions, Insertions and Reversals.”
Sov. Phys. Dokl. 6. 707-710.
Li, H. Zhang, M. Su, J. (2004) “A Joint Source-
Channel Model for Machine Transliteration.” Pro-
ceedings of ACL 2004.
Mani, Inderjeet. Yeh, Alexander. Condon, Sherri.
(2006) &amp;quot;Machine Learning from String Edit Dis-
tance and Phonological Similarity.&amp;quot;
Meng, H. Lo, W. Chen, B. Tang, T. (2001) “Generat-
ing Phonetic Cognates to Handle Named Entities in
English-Chinese Cross-Language Spoken Docu-
ment Retrieval.” Proceedings of ASRU.
Oh, Jong-Hoon. Choi, Key-Sun. (2006) “An Ensem-
ble of Transliteration Models for Information Re-
trieval.” Information Processing &amp; Management.
42(4). 980-1002.
“Student‟s t Test.” (2009) Wikipedia: The Free En-
cyclopedia. http://en.wikipedia.org/wiki/T_test#
Equal_sample_sizes.2C_equal_variance.
Van Halteren, H., Zavrel, J. Daelemans, W. (1998)
”Improving Data Driven Word-Class Tagging by
System Combination.” Proceedings of the 36th
Annual Meeting of the Association for Computa-
tional Linguistics and the 17th International Con-
ference on Computational Linguistics. Montréal,
Québec, Canada. 491-497.
Virga, P. Khudanpur, S. (2003) “Transliteration of
Proper Names in Cross-Lingual Information Re-
trieval.” Proceedings of the ACL Workshop on
Multi-lingual Named Entity Recognition.
Wan, Stephen. Verspoor, Cornelia Maria. (1998).
&amp;quot;Automatic English-Chinese Name Transliteration
for Development of Multilingual Resources.&amp;quot; Pro-
ceedings of the 36th Annual Meeting of the Associ-
ation for Computational Linguistics. Montréal,
Québec, Canada.
Wellner, B. Castano, J. Pustejovsky, J. (2005) “Adap-
tive String Similarity Metrics for Biomedical Ref-
erence Resolution.” Proceedings of the ACL-ISMB
Workshop on Linking Biological Literature, Ontol-
ogies, and Databases: Mining Biological Seman-
tics. 9-16. http://www.cs.brandeis.edu/~wellner/
pubs/Wellner-StringSim-BioLINK.pdf.
Winkler, W. “Methods for Record Linkage and Baye-
sian Networks.” (2002) Proceedings of the Section
on Survey Research Methods, American Statistical
Association. http://www.census.gov/srd/www/
byyear.html.
</reference>
<page confidence="0.997194">
160
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.360342">
<title confidence="0.979678">Name Matching Between Chinese and Roman Machine Complements Human</title>
<author confidence="0.756105">Ken Samuel</author>
<author confidence="0.756105">Alan Rubenstein</author>
<author confidence="0.756105">Sherri Condon</author>
<author confidence="0.756105">Alex Yeh The MITRE Corporation</author>
<author confidence="0.756105">H MS</author>
<author confidence="0.756105">Colshire Drive</author>
<author confidence="0.756105">Virginia McLean</author>
<email confidence="0.980241">rubenstein@mitre.org,scondon@mitre.org,andasy@mitre.org</email>
<abstract confidence="0.977437933333333">There are generally many ways to transliterate a name from one language script into another. The resulting ambiguity can make it very difficult to “untransliterate” a name by reverse engineering the process. In this paper, we present a highly successful cross-script name matching system that we developed by combining the creativity of human intuition with the power of machine learning. Our system determines whether a name in Roman script and a name in Chinese script match each other with an F-score of 96%. In addition, for name pairs that satisfy a computational test, the F-score is 98%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Aberdeen</author>
</authors>
<date>2006</date>
<note>geometric-featurechart-jsa20060616.xls”. Unpublished.</note>
<contexts>
<context position="27310" citStr="Aberdeen, 2006" startWordPosition="4943" endWordPosition="4944">ble deletion sets (Section 3.3),18 4. developing a standard methodology for creating negative examples, 5. when using contextual information, splitting rows or columns of the SSU-CC matrix only when they are ambiguous according to a metric such as Information Gain (Section 3.4),19 6. combining our system with other Roman-Chinese name matching systems in a voting structure (Van Halteren, Zavrel, and Daelemans, 1998), 7. independently evaluating the modules that determine pronunciation, construct syllables, and separate subsyllable units (Section 3), 8. converting phonemes into feature vectors (Aberdeen, 2006), 9. modifying our methodology to apply it to other similar languages, such as Japanese, Korean, Vietnamese, and Hawaiian. 10. manually creating rules based on information in the SSU-CC matrix, and 11. utilizing graphemic information. 6.1 Transliteration We would like to modify our system to enable it to transliterate a given Roman name into Chinese in the following way. First, the system computes the SSUs as in Section 3.1. Then it produces a match score for every possible sequence of CCs that has the same length as the sequence of SSUs, returning all of the CC sequences with match scores tha</context>
</contexts>
<marker>Aberdeen, 2006</marker>
<rawString>Aberdeen, J. (2006) “geometric-featurechart-jsa20060616.xls”. Unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Paul Cowlisha Smith</author>
<author>Mike F Gantner</author>
<author>Zeno O&apos;Brien</author>
<author>Philip Farmbrough</author>
<author>Rich</author>
</authors>
<title>Wikipedia: The Free Encyclopedia.</title>
<date>2009</date>
<booktitle>F1 Score.”</booktitle>
<note>http://en.wikipedia.org/wiki/F-score.</note>
<marker>Smith, Gantner, O&apos;Brien, Farmbrough, Rich, 2009</marker>
<rawString>Andrade, Miguel. Smith, S. Paul. Cowlisha, Mike F. Gantner, Zeno. O&apos;Brien, Philip. Farmbrough, Rich. et al. “F1 Score.” (2009) Wikipedia: The Free Encyclopedia. http://en.wikipedia.org/wiki/F-score.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Caley</author>
</authors>
<title>The Festival Speech Synthesis System: System Documentation.</title>
<date>1999</date>
<booktitle>Centre for Speech Technology Research (CSTR). The University of Edinburgh. http://www.cstr.ed.ac.uk/projects/festival/manual</booktitle>
<marker>Caley, 1999</marker>
<rawString>Black, Alan W. Taylor, Paul. Caley, Richard. (1999) The Festival Speech Synthesis System: System Documentation. Centre for Speech Technology Research (CSTR). The University of Edinburgh. http://www.cstr.ed.ac.uk/projects/festival/manual</rawString>
</citation>
<citation valid="true">
<authors>
<author>CMUdict</author>
</authors>
<title>The CMU Pronouncing Dictionary. v0.6. The Carnegie Mellon Speech Group.</title>
<date>1997</date>
<note>http://www.speech.cs.cmu.edu/cgi-bin/cmudict.</note>
<contexts>
<context position="26027" citStr="CMUdict, 1997" startWordPosition="4746" endWordPosition="4747">rovide short summaries of the other experiments that that we ran. 1) We experimentally compared six different equations for computing match scores and found that the best of them is an arithmetic or geometric average of Prob(SSU|CC) and Prob(CC|SSU). 2) We attempted to make use of two simple handcrafted rules, but they caused the system&apos;s performance to drop significantly. 3) We compared two approaches for automatically computing the pronunciation of a Roman name and found that using the Festival system (Black et al., 1999) alone is just as effective as using the CMU Pronunciation Dictionary (CMUdict, 1997) supplemented by Festival. 4) We tried computing the threshold value with data that was not used in training the system. However, this failed to improve the system&apos;s performance significantly. 6 Future Work There are so many things that we still want to do, including: 1. modifying our system for the task of transliteration (Section 6.1), 2. running fair comparisons between our work and related research, 3. using Levenshtein&apos;s algorithm (Levenshtein, 1966) to implement the SSUD and F-Score 100% 40% 90% 80% 70% 60% 50% Left Border Next SSU No Context Previous SSU Right Border Both SSUs Both Bord</context>
</contexts>
<marker>CMUdict, 1997</marker>
<rawString>CMUdict. (1997) The CMU Pronouncing Dictionary. v0.6. The Carnegie Mellon Speech Group. http://www.speech.cs.cmu.edu/cgi-bin/cmudict.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ravikumar Cohen</author>
<author>P Fienberg</author>
<author>S</author>
</authors>
<date>2003</date>
<journal>A Comparison of String Distance Metrics for Name.</journal>
<contexts>
<context position="3424" citStr="Cohen et al., 2003" startWordPosition="552" endWordPosition="555">d a Chinese name match each other with F = 96.5%.3 And F = 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyll</context>
</contexts>
<marker>Cohen, Fienberg, S, 2003</marker>
<rawString>Cohen, W. Ravikumar, P. Fienberg, S. (2003) “A Comparison of String Distance Metrics for Name.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eds Kambhampati</author>
<author>S Knoblock</author>
<author>C</author>
</authors>
<booktitle>Matching Tasks.” Proceedings of the IJCAI-03 Workshop on Information Integration on the</booktitle>
<pages>73--78</pages>
<marker>Kambhampati, Knoblock, C, </marker>
<rawString>Matching Tasks.” Proceedings of the IJCAI-03 Workshop on Information Integration on the Web. Eds. Kambhampati, S. Knoblock, C. 73-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Albin Aberdeen</author>
<author>Matthew Freeman</author>
<author>Andy Mani</author>
</authors>
<title>Multilingual Name Matching Mid-Year Status Report.”</title>
<date>2006</date>
<location>Inderjeet. Rubenstein, Alan. Sarver, Keri. Sexton, Mike. Yeh, Alex.</location>
<marker>Aberdeen, Freeman, Mani, 2006</marker>
<rawString>Condon, Sherri. Aberdeen, John. Albin, Matthew. Freeman, Andy. Mani, Inderjeet. Rubenstein, Alan. Sarver, Keri. Sexton, Mike. Yeh, Alex. (2006) “Multilingual Name Matching Mid-Year Status Report.”</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Freeman Condon</author>
<author>A Rubenstein</author>
<author>A Yeh</author>
<author>A</author>
</authors>
<title>Strategies for Chinese Name Matching.”</title>
<date>2006</date>
<contexts>
<context position="3205" citStr="Condon et al. (2006)" startWordPosition="516" endWordPosition="519">g approach analyzes hundreds of thousands of matched name pairs to build a Roman-Chinese name matching system (Section 3). Our experimental results are in Section 4. The system correctly determines whether a Roman name and a Chinese name match each other with F = 96.5%.3 And F = 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2</context>
</contexts>
<marker>Condon, Rubenstein, Yeh, A, 2006</marker>
<rawString>Condon, S. Freeman, A. Rubenstein, A. Yeh, A. (2006) “Strategies for Chinese Name Matching.”</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Condon Freeman</author>
<author>S Ackermann</author>
<author>C</author>
</authors>
<title>Cross Linguistic Name Matching in English and Arabic: A „One to Many Mapping‟ Extension of the Levenshtein Edit Distance Algorithm.&amp;quot;</title>
<date>2006</date>
<booktitle>Proceedings of NAACL/HLT.</booktitle>
<contexts>
<context position="4372" citStr="Freeman et al. (2006)" startWordPosition="696" endWordPosition="700">NLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshtein, 1966) It can quantify the similarity between two names. However, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extended the Levenshtein approach, attaining F = 85.2%. Then when they trained a machine learning algorithm on the output, the performance improved to F = 93.1% Mani et al. also tried applying a phonological alignment system (Kondrak, 2000) to the Roman-Chinese name matching task, and they reported an F-score of 91.2%. However, </context>
</contexts>
<marker>Freeman, Ackermann, C, 2006</marker>
<rawString>Freeman, A. Condon, S. Ackermann, C. (2006) &amp;quot;Cross Linguistic Name Matching in English and Arabic: A „One to Many Mapping‟ Extension of the Levenshtein Edit Distance Algorithm.&amp;quot; Proceedings of NAACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wong Gao</author>
<author>K Lam</author>
<author>W</author>
</authors>
<title>Phoneme-Based Transliteration of Foreign Names for OOV</title>
<date>2004</date>
<booktitle>Problem.” Proceedings of the First International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="3442" citStr="Gao et al., 2004" startWordPosition="556" endWordPosition="559">ch each other with F = 96.5%.3 And F = 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Cho</context>
</contexts>
<marker>Gao, Lam, W, 2004</marker>
<rawString>Gao, W. Wong, K. Lam, W. (2004) “Phoneme-Based Transliteration of Foreign Names for OOV Problem.” Proceedings of the First International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Kato Goto</author>
<author>N Uratani</author>
<author>N Ehara</author>
<author>T</author>
</authors>
<title>Transliteration Considering Context Information Based on the Maximum Entropy Method.”</title>
<date>2003</date>
<booktitle>Proceedings of MT-Summit IX.</booktitle>
<contexts>
<context position="3461" citStr="Goto et al., 2003" startWordPosition="560" endWordPosition="563"> F = 96.5%.3 And F = 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and </context>
</contexts>
<marker>Goto, Uratani, Ehara, T, 2003</marker>
<rawString>Goto, I. Kato, N. Uratani, N. Ehara, T. (2003) “Transliteration Considering Context Information Based on the Maximum Entropy Method.” Proceedings of MT-Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shudong Huang</author>
</authors>
<title>LDC2005T34: Chinese &lt;-&gt; English Named Entity Lists v 1.0.” Linguistics Data Consortium.</title>
<date>2005</date>
<location>Philadelphia, Pennsylvania.</location>
<note>ISBN #1-58563-368-2. http://www.ldc.upenn.edu/Cata log/CatalogEntry.jsp?catalogId=LDC2005T34.</note>
<contexts>
<context position="17572" citStr="Huang, 2005" startWordPosition="3216" endWordPosition="3217">y negative examples (name pairs that do not match). However, we do require negative examples in order to determine the threshold and to evaluate the system. Our technique for generating negative examples involves randomly rearranging the names in the data.13 4 Evaluation of the System We ran several experiments to test our system under a variety of different conditions. After describing our data and experimental method, we present some of our most interesting experimental results. We used a set of nearly 500,000 RomanChinese person name pairs collected from Xinhua News Agency newswire texts. (Huang, 2005) Table 7 shows the distribution of the data based on alignment. Note that the PA hypothesis applies to more than 60% of the data. We used the popular 10-fold cross validation approach 14 to obtain ten different evaluation scores. For each experiment we present the average of these scores. Our system&apos;s precision (P), recall (R), and Fscore (F) are: P = 98.19%, R = 94.83%, and F = 96.48%. These scores are much better than we originally expected to see for the challenging task of Roman-Chinese name matching. Table 8 shows P, R, and F for subsets of the test data, organized by the number of SSUs m</context>
</contexts>
<marker>Huang, 2005</marker>
<rawString>Huang, Shudong. (2005) “LDC2005T34: Chinese &lt;-&gt; English Named Entity Lists v 1.0.” Linguistics Data Consortium. Philadelphia, Pennsylvania. ISBN #1-58563-368-2. http://www.ldc.upenn.edu/Cata log/CatalogEntry.jsp?catalogId=LDC2005T34.</rawString>
</citation>
<citation valid="true">
<title>Handbook of the International Phonetic Association : A Guide to the Use of the International Phonetic Alphabet.</title>
<date>1999</date>
<booktitle>UK. ISBN 0521652367. http://www.cambridge.org/uk/cata logue/catalogue.asp?isbn=0521652367.</booktitle>
<publisher>Cambridge University Press,</publisher>
<institution>International Phonetic Association.</institution>
<marker>1999</marker>
<rawString>International Phonetic Association. (1999) Handbook of the International Phonetic Association : A Guide to the Use of the International Phonetic Alphabet. Cambridge University Press, UK. ISBN 0521652367. http://www.cambridge.org/uk/cata logue/catalogue.asp?isbn=0521652367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hong Jung</author>
<author>S Paek</author>
<author>E</author>
</authors>
<title>An English to Korean Transliteration Model of Extended Markov Window.”</title>
<date>2000</date>
<booktitle>Proceedings of COLING.</booktitle>
<contexts>
<context position="3480" citStr="Jung et al., 2000" startWordPosition="564" endWordPosition="567">= 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; We</context>
</contexts>
<marker>Jung, Paek, E, 2000</marker>
<rawString>Jung, S. Hong, S. Paek, E. (2000) “An English to Korean Transliteration Model of Extended Markov Window.” Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Choi Kang</author>
<author>K S</author>
</authors>
<title>Automatic Transliteration and Back-Transliteration by Decision Tree</title>
<date>2000</date>
<booktitle>Learning.” Proceedings of the 2nd International Conference on Language Resources and Evaluation.</booktitle>
<marker>Kang, S, 2000</marker>
<rawString>Kang, B.J. Choi, K.S. (2000) “Automatic Transliteration and Back-Transliteration by Decision Tree Learning.” Proceedings of the 2nd International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Klatt</author>
</authors>
<title>Review of the ARPA Speech Understanding Project.” Readings in Speech Recognition.</title>
<date>1990</date>
<pages>1--55860</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="8327" citStr="Klatt, 1990" startWordPosition="1396" endWordPosition="1397"> Cn, then, for some set of k Si’s, if those SSUs are removed from the sequence of SSUs, then the PA hypothesis holds. And in the case where the number of CCs is greater than the number of SSUs, we make the 5 Wan and Verspoor treat the phoneme, /ər/, as in Albertson, as a vowel phoneme. 6 The nasal phonemes are /n/ and /ŋ/, as in “nothing”. 7 To represent phonemes, we use two different standards in this paper. The symbols between slashes (like /ər/) are in the IPA format (International Phonetic Association, 1999). And the phonemes written in capital letters (like ER) are in the ARPABET format (Klatt, 1990). 153 Figure 1. Application Mode corresponding CCs Deletion (CCD) hypothesis. In the next section, we show how we utilize these hypotheses. 3 Machine Learning We designed a machine learning algorithm to establish a mapping between SSUs and CCs. In Section 3.1, we show how our system can do Roman-Chinese name matching, and then we present the training procedure in Section 3.2. 3.1 Application Mode Given a Roman-Chinese name pair, our system computes a match score, which is a number between 0 and 1 that is meant to represent the likelihood that two names match. This is accomplished via the proce</context>
</contexts>
<marker>Klatt, 1990</marker>
<rawString>Klatt, D.H. (1990) “Review of the ARPA Speech Understanding Project.” Readings in Speech Recognition. Morgan Kaufmann Publishers Inc. San Francisco, CA. ISBN 1-55860-124-4. 554-575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Graehl Knight</author>
<author>J</author>
</authors>
<date>1997</date>
<booktitle>Machine Transliteration.” Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Knight, J, 1997</marker>
<rawString>Knight, K. Graehl, J. (1997) “Machine Transliteration.” Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kondrak</author>
</authors>
<title>A New Algorithm for the Alignment of Phonetic Sequences.”</title>
<date>2000</date>
<booktitle>Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<pages>288--295</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="3541" citStr="Kondrak, 2000" startWordPosition="576" endWordPosition="577">sis condition, which is defined in Section 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm </context>
<context position="4882" citStr="Kondrak, 2000" startWordPosition="780" endWordPosition="781">, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extended the Levenshtein approach, attaining F = 85.2%. Then when they trained a machine learning algorithm on the output, the performance improved to F = 93.1% Mani et al. also tried applying a phonological alignment system (Kondrak, 2000) to the Roman-Chinese name matching task, and they reported an F-score of 91.2%. However, when they trained a machine learning approach on that system&apos;s output, the F-score was only 90.6%. It is important to recognize that it would be inappropriate to present a side-by-side comparison between Mani&apos;s work and ours (F = 96.5%), because there are many differences, such as the data that was used for evaluation. 2.2 Subsyllable Units Transliteration is usually based on the way names are pronounced.4 However, each character in a Roman name generally corresponds to a single phoneme, while a Chinese c</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Kondrak, G. (2000) “A New Algorithm for the Alignment of Phonetic Sequences.” Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL). Seattle, Washington. 288-295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dorr Kondrak</author>
<author>B</author>
</authors>
<title>Identification of Confusable Drug Names: A New Approach and Evaluation</title>
<date>2004</date>
<booktitle>Methodology.” Proceedings of the Twentieth International Conference on Computational Linguistics (COLING).</booktitle>
<pages>952--958</pages>
<marker>Kondrak, B, 2004</marker>
<rawString>Kondrak, G. Dorr, B. (2004) “Identification of Confusable Drug Names: A New Approach and Evaluation Methodology.” Proceedings of the Twentieth International Conference on Computational Linguistics (COLING). 952-958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions,</title>
<date>1966</date>
<journal>Insertions and Reversals.” Sov. Phys. Dokl.</journal>
<volume>6</volume>
<pages>707--710</pages>
<contexts>
<context position="4210" citStr="Levenshtein, 1966" startWordPosition="671" endWordPosition="672">al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshtein, 1966) It can quantify the similarity between two names. However, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extended the Levenshtein approach, attaining F = 85.2%. Then when they trained a machine learning algorithm on the output, the performance improved to F = 93.1% Mani et</context>
<context position="26486" citStr="Levenshtein, 1966" startWordPosition="4817" endWordPosition="4819">a Roman name and found that using the Festival system (Black et al., 1999) alone is just as effective as using the CMU Pronunciation Dictionary (CMUdict, 1997) supplemented by Festival. 4) We tried computing the threshold value with data that was not used in training the system. However, this failed to improve the system&apos;s performance significantly. 6 Future Work There are so many things that we still want to do, including: 1. modifying our system for the task of transliteration (Section 6.1), 2. running fair comparisons between our work and related research, 3. using Levenshtein&apos;s algorithm (Levenshtein, 1966) to implement the SSUD and F-Score 100% 40% 90% 80% 70% 60% 50% Left Border Next SSU No Context Previous SSU Right Border Both SSUs Both Borders 158 CCD hypotheses, instead of exhaustively evaluating all possible deletion sets (Section 3.3),18 4. developing a standard methodology for creating negative examples, 5. when using contextual information, splitting rows or columns of the SSU-CC matrix only when they are ambiguous according to a metric such as Information Gain (Section 3.4),19 6. combining our system with other Roman-Chinese name matching systems in a voting structure (Van Halteren, Z</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Levenshtein, V.I. (1966) “Binary Codes Capable of Correcting Deletions, Insertions and Reversals.” Sov. Phys. Dokl. 6. 707-710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang Li</author>
<author>M Su</author>
<author>J</author>
</authors>
<title>A Joint SourceChannel Model for Machine Transliteration.”</title>
<date>2004</date>
<booktitle>Proceedings of ACL</booktitle>
<contexts>
<context position="3582" citStr="Li et al., 2004" startWordPosition="582" endWordPosition="585">ion 2.2. 2 Related Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit d</context>
</contexts>
<marker>Li, Su, J, 2004</marker>
<rawString>Li, H. Zhang, M. Su, J. (2004) “A Joint SourceChannel Model for Machine Transliteration.” Proceedings of ACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Condon Yeh</author>
<author>Sherri</author>
</authors>
<title>Machine Learning from String Edit Distance and Phonological Similarity.&amp;quot;</title>
<date>2006</date>
<marker>Yeh, Sherri, 2006</marker>
<rawString>Mani, Inderjeet. Yeh, Alexander. Condon, Sherri. (2006) &amp;quot;Machine Learning from String Edit Distance and Phonological Similarity.&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lo Meng</author>
<author>W Chen</author>
<author>B Tang</author>
<author>T</author>
</authors>
<title>Generating Phonetic Cognates to Handle Named Entities in English-Chinese Cross-Language Spoken Document Retrieval.”</title>
<date>2001</date>
<booktitle>Proceedings of ASRU.</booktitle>
<contexts>
<context position="3601" citStr="Meng et al., 2001" startWordPosition="586" endWordPosition="589">d Work Wan and Verspoor&apos;s (1998) work had a great impact on our research, and we explain how we use it in Section 2.2. In Section 2.1, we identify other related work. 2.1 Chinese-English Name Matching Condon et al. (2006) wrote a paper about the challenges of matching names across Roman and Chinese scripts. In Section 6 of their paper, they offered an overview of several papers related to Roman-Chinese name matching. (Cohen et al., 2003; Gao et al., 2004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshte</context>
</contexts>
<marker>Meng, Chen, Tang, T, 2001</marker>
<rawString>Meng, H. Lo, W. Chen, B. Tang, T. (2001) “Generating Phonetic Cognates to Handle Named Entities in English-Chinese Cross-Language Spoken Document Retrieval.” Proceedings of ASRU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Key-Sun Choi</author>
</authors>
<title>An Ensemble of Transliteration Models for Information Retrieval.”</title>
<date>2006</date>
<journal>Information Processing &amp; Management.</journal>
<volume>42</volume>
<issue>4</issue>
<pages>980--1002</pages>
<contexts>
<context position="4049" citStr="Choi, 2006" startWordPosition="647" endWordPosition="648">004; Goto et al., 2003; Jung et al., 2000; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshtein, 1966) It can quantify the similarity between two names. However, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extende</context>
</contexts>
<marker>Choi, 2006</marker>
<rawString>Oh, Jong-Hoon. Choi, Key-Sun. (2006) “An Ensemble of Transliteration Models for Information Retrieval.” Information Processing &amp; Management. 42(4). 980-1002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>“Student‟s t Test ”</author>
</authors>
<title>Wikipedia: The Free Encyclopedia.</title>
<date>2009</date>
<note>http://en.wikipedia.org/wiki/T_test# Equal_sample_sizes.2C_equal_variance.</note>
<marker>”, 2009</marker>
<rawString>“Student‟s t Test.” (2009) Wikipedia: The Free Encyclopedia. http://en.wikipedia.org/wiki/T_test# Equal_sample_sizes.2C_equal_variance.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Van Halteren</author>
<author>J Daelemans Zavrel</author>
<author>W</author>
</authors>
<title>Improving Data Driven Word-Class Tagging by System Combination.”</title>
<date>1998</date>
<booktitle>Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics.</booktitle>
<pages>491--497</pages>
<location>Montréal, Québec,</location>
<marker>Van Halteren, Zavrel, W, 1998</marker>
<rawString>Van Halteren, H., Zavrel, J. Daelemans, W. (1998) ”Improving Data Driven Word-Class Tagging by System Combination.” Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics. Montréal, Québec, Canada. 491-497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Khudanpur Virga</author>
<author>S</author>
</authors>
<date>2003</date>
<booktitle>Transliteration of Proper Names in Cross-Lingual Information Retrieval.” Proceedings of the ACL Workshop on Multi-lingual Named Entity Recognition.</booktitle>
<marker>Virga, S, 2003</marker>
<rawString>Virga, P. Khudanpur, S. (2003) “Transliteration of Proper Names in Cross-Lingual Information Retrieval.” Proceedings of the ACL Workshop on Multi-lingual Named Entity Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelia Maria Verspoor</author>
</authors>
<title>Automatic English-Chinese Name Transliteration for Development of Multilingual Resources.&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Montréal, Québec, Canada.</location>
<contexts>
<context position="2366" citStr="Verspoor (1998)" startWordPosition="377" endWordPosition="378"> usually stands for “Chinese script”. 2 Sometimes a third script comes between the Roman and Chinese versions of the name. For example, a Roman name might be transliterated into Arabic, which is then transliterated into Chinese, or an Arabic name could be transliterated into Roman and Chinese independently. applications, such as identity matching, improving search engines, and aligning parallel corpora. We combine a) the creative power of human intuition, which can come up with clever ideas and b) the computational power of machine learning, which can analyze large quantities of data. Wan and Verspoor (1998) provided the human intuition by designing an algorithm to divide names into pieces that are just the right size for Roman-Chinese name matching (Section 2.2.). Armed with Wan and Verspoor&apos;s algorithm, a machine learning approach analyzes hundreds of thousands of matched name pairs to build a Roman-Chinese name matching system (Section 3). Our experimental results are in Section 4. The system correctly determines whether a Roman name and a Chinese name match each other with F = 96.5%.3 And F = 97.6% for name pairs that satisfy the Perfect Alignment hypothesis condition, which is defined in Sec</context>
<context position="5734" citStr="Verspoor, 1998" startWordPosition="924" endWordPosition="926">appropriate to present a side-by-side comparison between Mani&apos;s work and ours (F = 96.5%), because there are many differences, such as the data that was used for evaluation. 2.2 Subsyllable Units Transliteration is usually based on the way names are pronounced.4 However, each character in a Roman name generally corresponds to a single phoneme, while a Chinese character (CC) generally corresponds to a subsyllable unit (SSU). A phoneme is the smallest meaningful unit of sound, and a subsyllable unit is a sequence of one to three phonemes that conform to the following three constraints. (Wan and Verspoor, 1998) 4 Of course, there are exceptions. For example, when a name happens to be a word, sometimes that name is translated (rather than transliterated) into the other language. But our experimental results suggest that the exceptions are quite rare. (1) There is exactly one vowel phoneme.5 (2) At most, one consonant phoneme may precede the vowel phoneme. (3) The vowel phoneme may be followed by, at most, one nasal phoneme.6 Consider the example in Table 1. The name “Albertson” consists of eight phonemes in three syllables.7 The last syllable, SAHN, satisfies the definition of SSU, and the other two </context>
<context position="9664" citStr="Verspoor (1998)" startWordPosition="1755" endWordPosition="1756">determines how the Roman name should A B E G K L L L N R S T E E H A A I A A R A H Y H H N N 伦 0 0 0 0 0 0 1 0 0 0 0 0 利 0 0 0 0 0 0 0 1 0 0 0 0 卡 0 0 0 0 1 0 0 0 0 0 0 0 叶 0 0 1 0 0 0 0 0 0 0 0 0 埃 0 0 1 0 0 0 0 0 0 0 0 0 娜 0 0 0 0 0 0 0 0 1 0 0 0 尔 0 0 0 0 0 2 0 0 0 1 0 0 松 0 0 0 0 0 0 0 0 0 0 1 0 特 0 0 0 0 0 0 0 0 0 0 0 2 贝 0 3 0 0 0 0 0 0 0 0 0 0 连 0 0 0 0 0 0 1 0 0 0 0 0 里 0 0 0 1 0 0 0 0 0 0 0 0 阿 2 0 0 0 0 0 0 0 0 0 0 0 Table 2. SSU-CC Matrix #1 Figure 2. Training Mode be pronounced by running it through the Festival system. (Black et al., 1999) Next, two algorithms designed by Wan and Verspoor (1998) join the phonemes to form syllables and divide the syllables into SSUs.8 If the number of SSUs is equal to the number of characters in the Chinese name,9 we apply the PA hypothesis to align each SSU with a CC. The system computes a match score using a data structure called the SSU-CC matrix (subsyllable unit – Chinese character matrix), which has a nonnegative number for each SSU-CC pair, and this value should represent the strength of the correspondence between the SSU and the CC. Table 2 shows an example of an SSU-CC matrix. With this matrix, the name pair &lt;Albert, 阿尔贝特&gt; receives a relative</context>
</contexts>
<marker>Verspoor, 1998</marker>
<rawString>Wan, Stephen. Verspoor, Cornelia Maria. (1998). &amp;quot;Automatic English-Chinese Name Transliteration for Development of Multilingual Resources.&amp;quot; Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics. Montréal, Québec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Castano Wellner</author>
<author>J Pustejovsky</author>
<author>J</author>
</authors>
<title>Adaptive String Similarity Metrics for Biomedical Reference Resolution.”</title>
<date>2005</date>
<booktitle>Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies, and Databases: Mining Biological Semantics.</booktitle>
<pages>9--16</pages>
<note>http://www.cs.brandeis.edu/~wellner/ pubs/Wellner-StringSim-BioLINK.pdf.</note>
<contexts>
<context position="4098" citStr="Wellner et al., 2005" startWordPosition="653" endWordPosition="656">00; Kang and Choi, 2000; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshtein, 1966) It can quantify the similarity between two names. However, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extended the Levenshtein approach, attaining F = 85.2%. </context>
</contexts>
<marker>Wellner, Pustejovsky, J, 2005</marker>
<rawString>Wellner, B. Castano, J. Pustejovsky, J. (2005) “Adaptive String Similarity Metrics for Biomedical Reference Resolution.” Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies, and Databases: Mining Biological Semantics. 9-16. http://www.cs.brandeis.edu/~wellner/ pubs/Wellner-StringSim-BioLINK.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Winkler</author>
</authors>
<title>Methods for Record Linkage and Bayesian Networks.”</title>
<date>2002</date>
<booktitle>Proceedings of the Section on Survey Research Methods, American Statistical Association.</booktitle>
<note>http://www.census.gov/srd/www/ byyear.html.</note>
<contexts>
<context position="4114" citStr="Winkler, 2002" startWordPosition="657" endWordPosition="658">0; Knight and Graehl, 1997; Kondrak, 2000; Kondrak and Dorr, 2004; Li et al., 2004; Meng et al., 2001; Oh 3 F stands for F-score, which is a popular evaluation metric. (Andrade et al., 2009) 152 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 152–160, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Roman Characters: Albertson Phonemes: AE,L,B,ER,T,S,AH,N Syllables: AEL,BERT,SAHN Subsyllable Units: AE,L,BER,T,SAHN Chinese: 阿尔贝特松 Chinese Phonemes: /a/,/ər/,/pei/,/thə/,/suŋ/ Table 1. Subsyllable Units and Choi, 2006; Virga and Khudanpur, 2003; Wellner et al., 2005; Winkler, 2002) The Levenshtein algorithm is a popular way to compute string edit distance. (Levenshtein, 1966) It can quantify the similarity between two names. However, this algorithm does not work when the names are written in different scripts. So Freeman et al. (2006) developed a strategy for Roman-Arabic string matching that uses equivalence classes of characters to normalize the names so that Levenshtein&apos;s method can be applied. Later, Mani et al. (2006) transformed that system from Roman-Arabic to Roman-Chinese name matching and extended the Levenshtein approach, attaining F = 85.2%. Then when they t</context>
</contexts>
<marker>Winkler, 2002</marker>
<rawString>Winkler, W. “Methods for Record Linkage and Bayesian Networks.” (2002) Proceedings of the Section on Survey Research Methods, American Statistical Association. http://www.census.gov/srd/www/ byyear.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>