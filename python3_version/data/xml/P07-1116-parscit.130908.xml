<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011407">
<title confidence="0.9993925">
A Language-Independent Unsupervised Model
for Morphological Segmentation
</title>
<author confidence="0.997149">
Vera Demberg
</author>
<affiliation confidence="0.9979175">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.924893">
Edinburgh, EH8 9LW, GB
</address>
<email confidence="0.998038">
v.demberg@sms.ed.ac.uk
</email>
<sectionHeader confidence="0.995611" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999779421052632">
Morphological segmentation has been
shown to be beneficial to a range of NLP
tasks such as machine translation, speech
recognition, speech synthesis and infor-
mation retrieval. Recently, a number of
approaches to unsupervised morphological
segmentation have been proposed. This
paper describes an algorithm that draws
from previous approaches and combines
them into a simple model for morpholog-
ical segmentation that outperforms other
approaches on English and German, and
also yields good results on agglutinative
languages such as Finnish and Turkish.
We also propose a method for detecting
variation within stems in an unsupervised
fashion. The segmentation quality reached
with the new algorithm is good enough to
improve grapheme-to-phoneme conversion.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996606">
Morphological segmentation has been shown to be
beneficial to a number of NLP tasks such as ma-
chine translation (Goldwater and McClosky, 2005),
speech recognition (Kurimo et al., 2006), informa-
tion retrieval (Monz and de Rijke, 2002) and ques-
tion answering. Segmenting a word into meaning-
bearing units is particularly interesting for morpho-
logically complex languages where words can be
composed of several morphemes through inflection,
derivation and composition. Data sparseness for
such languages can be significantly decreased when
words are decomposed morphologically. There ex-
ist a number of rule-based morphological segmen-
tation systems for a range of languages. However,
expert knowledge and labour are expensive, and the
analyzers must be updated on a regular basis in or-
der to cope with language change (the emergence of
new words and their inflections). One might argue
that unsupervised algorithms are not an interesting
option from the engineering point of view, because
rule-based systems usually lead to better results.
However, segmentations from an unsupervised algo-
rithm that is language-independent are “cheap”, be-
cause the only resource needed is unannotated text.
If such an unsupervised system reaches a perfor-
mance level that is good enough to help another task,
it can constitute an attractive additional component.
Recently, a number of approaches to unsupervised
morphological segmentation have been proposed.
These algorithms autonomously discover morpheme
segmentations in unannotated text corpora. Here we
describe a modification of one such unsupervised al-
gorithm, RePortS (Keshava and Pitler, 2006). The
RePortS algorithm performed best on English in a
recent competition on unsupervised morphological
segmentation (Kurimo et al., 2006), but had very low
recall on morphologically more complex languages
like German, Finnish or Turkish. We add a new
step designed to achieve higher recall on morpho-
logically complex languages and propose a method
for identifying related stems that underwent regular
non-concatenative morphological processes such as
umlauting or ablauting, as well as morphological al-
ternations along morpheme boundaries.
The paper is structured as follows: Section
</bodyText>
<page confidence="0.943074">
920
</page>
<note confidence="0.9255445">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 920–927,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.981076010526316">
2 discusses the relationship between language- tie the orthographic form of the word to the mor-
dependency and the level of supervision of a learn- phemes. They are thus not well-suited for coping
ing algorithm. We then give an outline of the main with stem changes or modifications at the edges of
steps of the RePortS algorithm in section 3 and ex- morphemes. Only very few approaches have ad-
plain the modifications to the original algorithm in dressed word internal variations (Yarowski and Wi-
section 4. Section 5 compares results for different centowski, 2000; Neuvel and Fulop, 2002).
languages, quantifies the gains from the modifica- A popular and effective approach for detecting in-
tions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster
on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns
nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004;
2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and Juraf-
The world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neu-
to their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw
or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect ortho-
guages (where a word can be decomposed into a graphic variants of stems; see Section 4.3.
large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntac-
flectional languages (morphemes are fused together, tic and semantic information from the context the
e.g. Latin). word occurs (Schone and Jurafsky, 2000; Bordag,
Phenomena that are difficult to cope with for 2006; Yarowski and Wicentowski, 2000; Jacquemin,
many of the unsupervised algorithms are non- 1997). Exploiting semantic and syntactic informa-
concatenative processes such as vowel harmoniza- tion is very attractive because it adds an additional
tion, ablauting and umlauting, or modifications at dimension, but these approaches have to cope with
the boundaries of morphemes, as well as infixation more severe data sparseness issues than approaches
(e.g. in Tagalog: sulat ‘write’, s-um-ulat ‘wrote’, s- that emphasize word-internal cues, and they can
in-ulat ‘was written’), circumfixation (e.g. in Ger- be computationally expensive, especially when they
man: mach-en ‘do’, ge-mach-t ‘done’), the Ara- use LSA.
bic broken plural or reduplications (e.g. in Pinge- The original RePortS algorithm assumes mor-
lapese: mejr ‘to sleep’, mejmejr ‘sleeping’, mejme- phology to be concatenative, and specializes on pre-
jmejr ‘still sleeping’). For words that are subject to fixation and suffixation, like most of the above ap-
one of the above processes it is not trivial to automat- proaches, which were developed and implemented
ically group related words and detect regular trans- for English (Goldsmith, 2001; Schone and Jurafsky,
formational patterns. 2000; Neuvel and Fulop, 2002; Yarowski and Wi-
A range of automated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many
ical analysis cope with concatenative phenomena, languages are morphologically more complex. For
and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope
esized stems and affixes. These approaches can be with compounding, and in Turkish words can be
further categorized into ones that use conditional very long and complex. We therefore extended the
entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to
aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop-
1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications ren-
shava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and
that use minimal description length and thereby min- thereby make it attractive for applying to other lan-
imize the size of the lexicon as measured in en- guages as well.
tries and links between the entries to constitute a 3 The RePortS Algorithm
word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out-
2006). These two types of approaches very closely performed all other systems in Morpho Challenge
921
20051 (Kurimo et al., 2006), obtaining an F-measure An affix is validated if all three criteria are satisfied
of 76.8% (76.2% prec., 77.4% recall). The next best for at least 5% of its occurrences:
system obtained an F-score of 69%. However, the 1. The substring that remains after peeling off an
algorithm does not perform as well on other lan- affix is also a word in the lexicon.
guages (Turkish, Finnish, German) due to low re- 2. The transitional probability between the
call (see (Keshava and Pitler, 2006) and (Demberg, second-last and the last stem letter is Pz� 1.
2006), p. 47). 3. The transitional probability of the affix letter
There are three main steps in the algorithm. First, next to the stem is &lt;1 (tolerance 0.02).
the data is structured in two trees, which provide the Finally, all affixes that are concatenations of two or
basis for efficient calculation of transitional proba- more other suffixes (e.g., -ungen can be split up in
bilities of a letter given its context. The second step -ung and -en in German) are removed. This step re-
is the affix acquisition step, during which a set of turns two lists of morphological segments. The pre-
morphemes is identified from the corpus data. The fix list contains prefixes as well as stems that usually
third step uses these morphemes to segment words. occur at the beginning of words, while the suffix list
3.1 Data Structure contains suffixes and stems that occur at the end of
The data is stored in two trees, the forward tree and words. In the remainder of the paper, we will refer
the backward tree. Branches correspond to letters, to the content of these lists as “prefixes” and “suf-
and nodes are annotated with the total corpus fre- fixes”, although they also include stems. There are
quency of the letter sequence from the root of the several assumptions encoded in this procedure that
tree up to the node. During the affix identification are specific to English, and cause recall to be low for
process, the forward tree is used for discovering suf- other languages: 1) all stems are valid words in the
fixes by calculating the probability of seeing a cer- lexicon; 2) affixes occur at the beginning or end of
tain letter given the previous letters of the word. The words only; and 3) affixation does not change stems.
backward tree is used to determine the probability In section 4, we propose ways of relaxing these as-
of a letter given the following letters of a word in sumptions to make this step less language-specific.
order to find prefixes. If the transitional probabil- 3.3 Segmenting Words
ity is high, the word should not be split, whereas The final step is the complete segmentation of words
low probability is a good indicator of a morpheme given the list of affixes acquired in the previous step.
boundary. In such a tree, stems tend to stay together The original RePortS algorithm uses a very simple
in long unary branches, while the branching factor is method that peels off the most probable suffix that
high in places where morpheme boundaries occur. has a transitional probability smaller than 1, until no
The underlying idea of exploiting “Letter Succes- more affixes match or until less than half of the word
sor Variety” was first proposed in (Harris, 1955), and remains. This last condition is problematic since it
has since been used in a number of morphemic seg- does not scale up well to languages with complex
mentation algorithms (Hafer and Weiss, 1974; Bern- morphology. The same peeling-off process is exe-
hard, 2006; Bordag, 2006). cuted for prefixes.
3.2 Finding Affixes Although this method is better than using a
The second step is concerned with finding good af- heuristic such as ‘always peel off the longest pos-
fixes. The procedure is quite simple and can be di- sible affix’, because it takes into account probable
vided into two subtasks. (1) generating all possible sites of fractures in words, it is not sensitive to
affixes and (2) validating them. The validation step the affix context or the morphotactics of the lan-
is necessary to exclude bad affix candidates (e.g. let- guage. Typical mistakes that arise from this con-
ter sequences that occur together frequently such as dition are that inflectional suffixes, which can only
sch, spr or ch in German or sh, th, qu in English). occur word-finally, might be split off in the middle
of a word after previously having peeled off a num-
ber of other suffixes.
1www.cis.hut.fi/morphochallenge2005/
922
</bodyText>
<listItem confidence="0.2491245">
4 Modifications and Extensions
4.1 Morpheme Acquisition
</listItem>
<bodyText confidence="0.951915843373494">
When we ran the original algorithm on a German
data set, no suffixes were validated but reasonable
prefix lists were found. The algorithm works fine
for English suffixes – why does it fail on German?
The algorithm’s failure to detect German suffixes is
caused by the invalid assumption that a stem must
be a word in the corpus. German verb stems do
not occur on their own (except for certain impera-
tive forms). After stripping off the suffix of the verb
abholst ‘fetch’, the remaining string abhol cannot be
found in the lexicon. However, words like abholen,
abholt, abhole or Abholung are part of the corpus.
The same problem also occurs for German nouns.
Therefore, this first condition of the affix acqui-
sition step needs to be replaced. We therefore intro-
duced an additional step for building an intermediate
stem candidate list into the affix acquisition process.
The first condition is replaced by a condition that
checks whether a stem is in the stem candidate list.
This new stem candidate acquisition procedure com-
prises three steps:
Step 1: Creation of stem candidate list
All substrings that satisfy conditions 2 and 3 but
not condition 1, are stored together with the set of
affixes they occur with. This process is similar to
the idea of registering signatures (Goldsmith, 2001;
Neuvel and Fulop, 2002). For example, let us as-
sume our corpus contains the words Auff¨uhrender,
Auff¨uhrung, auff¨uhrt and Auff¨uhrlaune but not the
stem itself, since auff¨uhr ‘act’ is not a valid Ger-
man word. Conditions 2 and 3 are met, because
the transitional probability between auff¨uhr and the
next letter is low (there are a lot of different pos-
sible continuations) and the transitional probability
P(r|auff¨uh) Pz� 1. The stem candidate auff¨uhr is then
stored together with the suffix candidates {ender,
ung, en, t, laune}.
Step 2: Ranking candidate stems
There are two types of affix candidates: type-1 affix
candidates are words that are contained in the data
base as full words (those are due to compounding);
type-2 affix candidates are inflectional and deriva-
tional suffixes. When ranking the stem candidates,
we take into account the number of type-1 affix can-
didates and the average frequency of tpye-2 affix
923
Figure 1: Determining the threshold for validating
the best candidates from the stem candidate list.
candidates.
The first condition has very good precision, sim-
ilar to the original method. The morphemes found
with this method are predominantly stem forms that
occur in compounding or derivation (Komposition-
sst¨amme and Derivationsst¨amme). The second con-
dition enables us to differentiate between stems that
occur with common suffixes (and therefore have
high average frequencies), and pseudostems such
as runtersch whose affix list contains many non-
morphemes (e.g. lucken, iebt, aute). These non-
morphemes are very rare since they are not gener-
ated by a regular process.
Step 3: Pruning
All stem candidates that occur less than three times
are removed from the list. The remaining stem can-
didates are ordered according to the average fre-
quency of their non-word suffixes. This criterion
puts the high quality stem candidates (that occur
with very common suffixes) to the top of the list.
In order to obtain a high-precision stem list, it is
necessary to cut the list of candidates at some point.
The threshold for this is determined by the data: we
choose the point at which the function of list-rank
vs. score changes steepness (see Figure 1). This
visual change of steepness corresponds to the point
where potential stems found get more noisy because
the strings with which they occur are not common
affixes. We found the performance of the result-
ing morphological system to be quite stable (±1%
f-score) for any cutting point on the slope between
20% and 50% of the list (for the German data set
ranks 4000 and 12000), but importantly before the
function tails off. The threshold was also robust
across the other languages and data sets.
</bodyText>
<subsectionHeader confidence="0.99158">
4.2 Morphological Segmentation
</subsectionHeader>
<bodyText confidence="0.999972063829787">
As discussed in section 3.3, the original implemen-
tation of the algorithm iteratively chops off the most
probable affixes at both edges of the word without
taking into account the context of the affix. In mor-
phologically complex languages, this context-blind
approach often leads to suboptimal results, and also
allows segmentations that are morphotactically im-
possible, such as inflectional suffixes in the middle
of words. Another risk is that the letter sequence that
is left after removing potential prefixes and suffixes
from both ends is not a proper stem itself but just a
single letter or vowel-less letter-sequence.
These problems can be solved by using a bi-gram
language model to capture the morphotactic proper-
ties of a particular language. Instead of simply peel-
ing off the most probable affixes from both ends of
the word, all possible segmentations of the word are
generated and ranked using the language model. The
probabilities for the language model are learnt from
a set of words that were segmented with the origi-
nal simple approach. This bootstrapping allows us
to ensure that the approach remains fully unsuper-
vised. At the beginning and end of each word, an
edge marker ‘#’ is attached to the word. The model
can then also acquire probabilities about which af-
fixes occur most often at the edges of words.
Table 2 shows that filtering the segmentation re-
sults with the n-gram language model caused a sig-
nificant improvement on the overall F-score for most
languages, and led to significant changes in pre-
cision and recall. Whereas the original segmen-
tation yielded balanced precision and recall (both
68%), the new filtering boosts precision to over
73%, with 64% recall. Which method is preferable
(i.e. whether precision or recall is more important)
is task-dependent.
In future work, we plan to draw on (Creutz and
Lagus, 2006), who use a HMM with morphemic cat-
egories to impose morphotactic constraints. In such
an approach, each element from the affix list is as-
signed with a certain probability to the underlying
categories of “stem”, “prefix” or “suffix”, depend-
ing on the left and right perplexity of morphemes, as
well as morpheme length and frequency. The tran-
sitional probabilities from one category to the next
model the morphotactic rules of a language, which
can thus be learnt automatically.
</bodyText>
<subsectionHeader confidence="0.999638">
4.3 Learning Stem Variation
</subsectionHeader>
<bodyText confidence="0.999950680851064">
Stem variation through ablauting and umlauting
(an English example is run–ran) is an interest-
ing problem that cannot be captured by the algo-
rithm outlined above, as variations take place within
the morphemes. Stem variations can be context-
dependent and do not constitute a morpheme in
themselves. German umlauting and ablauting leads
to data sparseness problems in morphological seg-
mentation and affix acquisition. One problem is that
affixes which usually cause ablauting or umlauting
are very difficult to find. Typically, ablauted or um-
lauted stems are only seen with a very small number
of different affixes, which means that the affix sets
of such stems are divided into several unrelated sub-
sets, causing the stem to be pruned from the stem
candidate list. Secondly, ablauting and umlauting
lead to low transitional probabilities at the positions
in stems where these phenomena occur. Consider
for example the affix set for the stem candidate bock-
spr, which contains the pseudoaffixes ung, ¨unge and
ingen. The morphemes sprung, spr¨ung and sprin-
gen are derived from the root spring ‘to jump’. In
the segmentation step this low transitional probabil-
ity thus leads to oversegmentation.
We therefore investigated whether we can learn
these regular stem variations automatically. A sim-
ple way to acquire the stem variations is to look at
the suffix clusters which are calculated during the
stem-acquisition step. When looking at the sets of
substrings that are clustered together by having the
same prefix, we found that they are often inflections
of one another, because lexicalized compounds are
used frequently in different inflectional variants. For
example, we find Trainingssprung as well as Train-
ingsspr¨unge in the corpus. The affix list of the stem
candidate trainings thus contains the words sprung
and spr¨unge. Edit distance can then be used to
find differences between all words in a certain affix
list. Pairs with small edit distances are stored and
ranked by frequency. Regular transformation rules
(e.g. ablauting and umlauting, u —* ¨u..e) occur at
the top of the list and are automatically accepted as
rules (see Table 1). This method allows us to not
only find the relation between two words in the lex-
icon (Sprung and Spr¨unge) but also to automatically
learn rules that can be applied to unknown words to
check whether their variant is a word in the lexicon.
</bodyText>
<page confidence="0.99352">
924
</page>
<figure confidence="0.939463">
freq. diff. examples
1682 a ¨a..e sack-s¨acke, brach-br¨ache, stark-st¨arke
344 a a¨ sahen-s¨ahen, garten-g¨arten
321 u ¨u..e flug-fl¨uge, bund-b¨unde
289 a¨ a..s vertr¨age-vertrages, p¨asse-passes
189 o ¨o..e chor-ch¨ore, strom-str¨ome, ?r¨ohre-rohr
175 t en setzt-setzen, bringt-bringen
168 a u laden-luden, *damm-dumm
160 ß ss l¨aßt-l¨asst, mißbrauch-missbrauch
[. . .]
136 a en firma-firmen, thema-themen
[. . .]
2 ß g *fließen-fliegen, *laßt-lagt
2 um o *studiums-studios
</figure>
<tableCaption confidence="0.887814333333333">
Table 1: Excerpts from the stem variation detection
algorithm results. Morphologically unrelated word
pairs are marked with an asterisk.
</tableCaption>
<bodyText confidence="0.999859125">
We integrated information about stem variation
from the regular stem transformation rules (those
with the highest frequencies) into the segmentation
step by creating equivalence sets of letters. For ex-
ample, the rule u -* ¨u..e generates an equivalence
set {¨u, u}. These two letters then count as the same
letter when calculating transitional probabilities. We
evaluated the benefit of integrating stem variation
information for German on the German CELEX
data set, and achieved an improvement of 2% in
recall, without any loss in precision (F-measure:
69.4%, Precision: 68.1%, Recall: 70.8%; values for
RePortS-stems). For better comparability to other
systems and languages, results reported in the next
section refer to the system version that does not in-
corporate stem variation.
</bodyText>
<sectionHeader confidence="0.998123" genericHeader="introduction">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999934266666667">
For evaluating the different versions of the algorithm
on English, Turkish and Finnish, we used the train-
ing and test sets from MorphoChallenge to enable
comparison with other systems. Performance of the
algorithm on German was evaluated on 244k manu-
ally annotated words from CELEX because German
was not included in the MorphoChallenge data.
Table 2 shows that the introduction of the stem
candidate acquisition step led to much higher recall
on German, Finnish and Turkish, but caused some
losses in precision. For English, adding both com-
ponents did not have a large effect on either preci-
sion or recall. This means that this component is
well behaved, i.e. it improves performance on lan-
guages where the intermediate stem-acquisition step
</bodyText>
<table confidence="0.999457714285714">
Lang. alg.version F-Meas. Prec. Recall
Eng&apos; original 76.8% 76.2% 77.4%
stems 67.6% 62.9% 73.1%
n-gram seg. 75.1% 74.4% 75.9%
Gere original 59.2% 71.1% 50.7%
stems 68.4% 68.1% 68.6%
n-gram seg. 68.9% 73.7% 64.6%
Turl original 54.2% 72.9% 43.1%
stems 61.8% 65.9% 58.2%
n-gram seg. 64.2% 65.2% 63.3%
Fin&apos; original 47.1% 84.5% 32.6%
stems 56.6% 74.1% 45.8%
n-gram seg. 58.9% 76.1% 48.1%
max-split* 61.3% 66.3% 56.9%
</table>
<tableCaption confidence="0.991137333333333">
Table 2: Performance of the algorithm with the mod-
ifications on different languages.
&apos;MorphoChallenge Data, 2German CELEX
</tableCaption>
<bodyText confidence="0.999758866666667">
is needed, but does not impair results on other lan-
guages. Recall for Finnish is still very low. It can be
improved (at the expense of precision) by selecting
the analysis with the largest number of segments in
the segmentation step. The results for this heuris-
tic was only evaluated on a smaller test set (ca. 700
wds), hence marked with an asterisk in Table 2.
The algorithm is very efficient: When trained on
the 240m tokens of the German TAZ corpus, it takes
up less than 1 GB of memory. The training phase
takes approx. 5 min on a 2.4GHz machine, and the
segmentation of the 250k test words takes 3 min for
the version that does the simple segmentation and
about 8 min for the version that generates all possi-
ble segmentations and uses the language model.
</bodyText>
<subsectionHeader confidence="0.998911">
5.1 Comparison to other systems
</subsectionHeader>
<bodyText confidence="0.975643785714286">
This modified version of the algorithm performs sec-
ond best for English (after original RePortS) and
ranks third for Turkish (after Bernhards algorithm
with 65.3% F-measure and Morfessor-Categories-
MAP with 70.7%). On German, our method sig-
nificantly outperformed the other unsupervised al-
gorithms, see Table 3. While most of the systems
compared here were developed for languages other
than German, (Bordag, 2006) describes a system ini-
tially built for German. When trained on the “Pro-
jekt Deutscher Wortschatz” corpus which comprises
24 million sentences, it achieves an F-score of 61%
(precision 60%, recall 62%2) when evaluated on the
full CELEX corpus.
</bodyText>
<footnote confidence="0.872874">
2Data from personal communication.
</footnote>
<page confidence="0.984155">
925
</page>
<table confidence="0.9996911">
morphology F-Meas. Prec. Recall
SMOR-disamb2 83.6% 87.1% 80.4%
ETI 79.5% 75.4% 84.1%
SMOR-disamb1 71.8% 95.4% 57.6%
RePortS-lm 68.8% 73.7% 64.6%
RePortS-stems 68.4% 68.1% 68.6%
best Bernhard 63.5% 64.9% 62.1%
Bordag 61.4% 60.6% 62.3%
orig. RePortS 59.2% 71.1% 50.7%
best Morfessor 1.0 52.6% 70.9% 41.8%
</table>
<tableCaption confidence="0.976088333333333">
Table 3: Evaluating rule-based and data-based sys-
tems for morphological segmentation with respect to
CELEX manual morphological annotation.
</tableCaption>
<bodyText confidence="0.994585727272727">
Rule-based systems are currently the most com-
mon approach to morphological decomposition and
perform better at segmenting words than state-of-
the-art unsupervised algorithms (see Table 3 for per-
formance of state-of-the-art rule-based systems eval-
uated on the same data). Both the ETI3 and the
SMOR (Schmid et al., 2004) systems rely on a large
lexicon and a set of rules. The SMOR system re-
turns a set of analyses that can be disambiguated in
different ways. For details refer to pp. 29–33 in
(Demberg, 2006).
</bodyText>
<subsectionHeader confidence="0.9730065">
5.2 Evaluation on Grapheme-to-Phoneme
Conversion
</subsectionHeader>
<bodyText confidence="0.999923368421053">
Morphological segmentation is not of value in itself
– the question is whether it can help improve results
on an application. Performance improvements due
to morphological information have been reported for
example in MT, information retrieval, and speech
recognition. For the latter task, morphological seg-
mentations from the unsupervised systems presented
here have been shown to improve accuracy (Kurimo
et al., 2006).
Another motivation for evaluating the system on
a task rather than on manually annotated data is
that linguistically motivated morphological segmen-
tation is not necessarily the best possible segmenta-
tion for a certain task. Evaluation against a manu-
ally annotated corpus prefers segmentations that are
closest to linguistically motivated analyses. Further-
more, it might be important for a certain task to
find a particular type of morpheme boundaries (e.g.
boundaries between stems), but for another task it
</bodyText>
<footnote confidence="0.981758666666667">
3Eloquent Technology, Inc. (ETI) TTS system.
www.mindspring.com/˜ssshp/ssshp_cd/ss_
eloq.htm
</footnote>
<table confidence="0.998533">
morphology F-Meas. (CELEX) PER (dt)
CELEX 100% 2.64%
ETI 79.5% 2.78%
SMOR-disamb2 83.0% 3.00%
SMOR-disamb1 71.8% 3.28%
RePortS-lm 68.8% 3.45%
no morphology 3.63%
orig. RePortS 59.2% 3.83%
Bernhard 63.5% 3.88%
RePortS-stem 68.4% 3.98%
Morfessor 1.0 52.6% 4.10%
Bordag 64.1% 4.38%
</table>
<tableCaption confidence="0.909604">
Table 4: F-measure for evaluation on manually an-
</tableCaption>
<bodyText confidence="0.988443638888889">
notated CELEX and phoneme error rate (PER) from
g2p conversion using a decision tree (dt).
might be very important to find boundaries between
stems and suffixes. The standard evaluation proce-
dure does not differentiate between the types of mis-
takes made. Finally, only evaluation on a task can
provide information as to whether high precision or
high recall is more important, therefore, the decision
as to which version of the algorithm should be cho-
sen can only be taken given a specific task.
For these reasons we decided to evaluate the seg-
mentation from the new versions of the RePortS al-
gorithm on a German grapheme-to-phoneme (g2p)
conversion task. The evaluation on this task is moti-
vated by the fact that (Demberg, 2007) showed that
good-quality morphological preprocessing can im-
prove g2p conversion results. We here compare the
effect of using our system’s segmentations to a range
of different morphological segmentations from other
systems. We ran each of the rule-based systems
(ETI, SMOR-disamb1, SMOR-disamb2) and the
unsupervised algorithms (original RePortS, Bern-
hard, Morfessor 1.0, Bordag) on the CELEX data
set and retrained our decision tree (an implementa-
tion based on (Lucassen and Mercer, 1984)) on the
different morphological segmentations.
Table 4 shows the F-score of the different systems
when evaluated on the manually annotated CELEX
data (full data set) and the phoneme error rate (PER)
for the g2p conversion algorithm when annotated
with morphological boundaries (smaller test set,
since the decision tree is a supervised method and
needs training data). As we can see from the results,
the distribution of precision and recall (see Table 3)
has an important impact on the conversion quality:
the RePortS version with higher precision signifi-
</bodyText>
<page confidence="0.994399">
926
</page>
<bodyText confidence="0.99996">
cantly outperforms the other version on the task, al-
though their F-measures are almost identical. Re-
markably, the RePortS version that uses the filter-
ing step is the only unsupervised system that beats
the no-morphology baseline (p &lt; 0.0001). While
all other unsupervised systems tested here make the
system perform worse than it would without mor-
phological information, this new version improves
accuracy on g2p conversion.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999983125">
A significant improvement in F-score was achieved
by three simple modifications to the RePortS al-
gorithm: generating an intermediary high-precision
stem candidate list, using a language model to dis-
ambiguate between alternative segmentations, and
learning patterns for regular stem variation, which
can then also be exploited for segmentation. These
modifications improved results on four different lan-
guages considered: English, German, Turkish and
Finnish, and achieved the best results reported so far
for an unsupervised system for morphological seg-
mentation on German. We showed that the new ver-
sion of the algorithm is the only unsupervised sys-
tem among the systems evaluated here that achieves
sufficient quality to improve transcription perfor-
mance on a grapheme-to-phoneme conversion task.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999989166666667">
I would like to thank Emily Pitler and Samarth Ke-
shava for making available the code of the RePortS
algorithm, and Stefan Bordag and Delphine Bern-
hard for running their algorithms on the German
data. Many thanks also to Matti Varjokallio for eval-
uating the data on the MorphoChallenge test sets
for Finnish, Turkish and English. Furthermore, I
am very grateful to Christoph Zwirello and Gregor
M¨ohler for training the decision tree on the new mor-
phological segmentation. I also want to thank Frank
Keller and the ACL reviewers for valuable and in-
sightful comments.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999848028985507">
Delphine Bernhard. 2006. Unsupervised morphological seg-
mentation based on segment predictability and word seg-
ments alignment. In Proceedings of 2nd Pascal Challenges
Workshop, pages 19–24, Venice, Italy.
Stefan Bordag. 2006. Two-step approach to unsupervised mor-
pheme segmentation. In Proceedings of 2nd Pascal Chal-
lenges Workshop, pages 25–29, Venice, Italy.
Mathias Creutz and Krista Lagus. 2006. Unsupervised models
for morpheme segmentation and morphology learning. In
ACM Transaction on Speech and Language Processing.
H. D´ejean. 1998. Morphemes as necessary concepts for struc-
tures: Discovery from untagged corpora. In Workshop on
paradigms and Grounding in Natural Language Learning,
pages 295–299, Adelaide, Australia.
Vera Demberg. 2006. Letter-to-phoneme conversion for a Ger-
man TTS-System. Master’s thesis. IMS, Univ. of Stuttgart.
Vera Demberg. 2007. Phonological constraints and morpho-
logical preprocessing for grapheme-to-phoneme conversion.
In Proc. ofACL-2007.
Eric Gaussier. 1999. Unsupervised learning of derivational
morphology from inflectional lexicons. In ACL ’99 Work-
shop Proceedings, University of Maryland.
CELEX German Linguistic User Guide, 1995. Center for Lex-
icalInformation. Max-Planck-Institut for Psycholinguistics,
Nijmegen.
John Goldsmith. 2001. Unsupervised learning of the mor-
phology of a natural language. computational Linguistics,
27(2):153–198, June.
S. Goldwater and D. McClosky. 2005. Improving statistical mt
through morphological analysis. In Proc. of EMNLP.
Margaret A. Hafer and Stephen F. Weiss. 1974. Word segmen-
tation by letter successor varieties. Information Storage and
Retrieval 10, pages 371–385.
Zellig Harris. 1955. From phoneme to morpheme. Language
31, pages 190–222.
Christian Jacquemin. 1997. Guessing morphology from terms
and corpora. In Research and Development in Information
Retrieval, pages 156–165.
S. Keshava and E. Pitler. 2006. A simpler, intuitive approach
to morpheme induction. In Proceedings of 2nd Pascal Chal-
lenges Workshop, pages 31–35, Venice, Italy.
M. Kurimo, M. Creutz, M. Varjokallio, E. Arisoy, and M. Sar-
aclar. 2006. Unsupervsied segmentation of words into mor-
phemes – Challenge 2005: An introduction and evaluation
report. In Proc. of 2nd Pascal Challenges Workshop, Italy.
J. Lucassen and R. Mercer. 1984. An information theoretic
approach to the automatic determination of phonemic base-
forms. In ICASSP 9.
C. Monson, A. Lavie, J. Carbonell, and L. Levin. 2004. Un-
supervised induction of natural language morphology inflec-
tion classes. In Proceedings of the Seventh Meeting ofACL-
SIGPHON, pages 52–61, Barcelona, Spain.
C. Monz and M. de Rijke. 2002. Shallow morphological analy-
sis in monolingual information retrieval for Dutch, German,
and Italian. In Proceedings CLEF 2001, LNCS 2406.
Sylvain Neuvel and Sean Fulop. 2002. Unsupervised learning
of morphology without morphemes. In Proc. of the Wshp on
Morphological and Phonological Learning, ACL Pub.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
SMOR: A German computational morphology covering
derivation, composition and inflection. In Proc. ofLREC.
Patrick Schone and Daniel Jurafsky. 2000. Knowledge-free
induction of morphology using latent semantic analysis. In
Proc. of CoNLL-2000 and LLL-2000, Lisbon, Portugal.
Tageszeitung (TAZ) Corpus. Contrapress Media GmbH.
https://www.taz.de/pt/.etc/nf/dvd.
David Yarowski and Richard Wicentowski. 2000. Minimally
supervised morphological analysis by multimodal align-
ment. In Proceedings ofACL 2000, Hong Kong.
</reference>
<page confidence="0.997132">
927
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969810">
<title confidence="0.9995005">A Language-Independent Unsupervised Model for Morphological Segmentation</title>
<author confidence="0.999442">Vera Demberg</author>
<affiliation confidence="0.9999605">School of Informatics University of Edinburgh</affiliation>
<address confidence="0.997531">Edinburgh, EH8 9LW, GB</address>
<email confidence="0.993414">v.demberg@sms.ed.ac.uk</email>
<abstract confidence="0.99900235">Morphological segmentation has been shown to be beneficial to a range of NLP tasks such as machine translation, speech recognition, speech synthesis and information retrieval. Recently, a number of approaches to unsupervised morphological segmentation have been proposed. This paper describes an algorithm that draws from previous approaches and combines them into a simple model for morphological segmentation that outperforms other approaches on English and German, and also yields good results on agglutinative languages such as Finnish and Turkish. We also propose a method for detecting variation within stems in an unsupervised fashion. The segmentation quality reached with the new algorithm is good enough to improve grapheme-to-phoneme conversion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Delphine Bernhard</author>
</authors>
<title>Unsupervised morphological segmentation based on segment predictability and word segments alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of 2nd Pascal Challenges Workshop,</booktitle>
<pages>pages</pages>
<location>Venice, Italy.</location>
<contexts>
<context position="7141" citStr="Bernhard, 2006" startWordPosition="1060" endWordPosition="1061">concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challenge 921 20051 (Ku</context>
</contexts>
<marker>Bernhard, 2006</marker>
<rawString>Delphine Bernhard. 2006. Unsupervised morphological segmentation based on segment predictability and word segments alignment. In Proceedings of 2nd Pascal Challenges Workshop, pages 19–24, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Bordag</author>
</authors>
<title>Two-step approach to unsupervised morpheme segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of 2nd Pascal Challenges Workshop,</booktitle>
<pages>25--29</pages>
<location>Venice, Italy.</location>
<contexts>
<context position="7232" citStr="Bordag, 2006" startWordPosition="1074" endWordPosition="1075">anics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challenge 921 20051 (Kurimo et al., 2006), obtaining an F-measure An affix is validated if all three criteria are </context>
<context position="11264" citStr="Bordag, 2006" startWordPosition="1762" endWordPosition="1763">e branching factor is method that peels off the most probable suffix that high in places where morpheme boundaries occur. has a transitional probability smaller than 1, until no The underlying idea of exploiting “Letter Succes- more affixes match or until less than half of the word sor Variety” was first proposed in (Harris, 1955), and remains. This last condition is problematic since it has since been used in a number of morphemic seg- does not scale up well to languages with complex mentation algorithms (Hafer and Weiss, 1974; Bern- morphology. The same peeling-off process is exehard, 2006; Bordag, 2006). cuted for prefixes. 3.2 Finding Affixes Although this method is better than using a The second step is concerned with finding good af- heuristic such as ‘always peel off the longest posfixes. The procedure is quite simple and can be di- sible affix’, because it takes into account probable vided into two subtasks. (1) generating all possible sites of fractures in words, it is not sensitive to affixes and (2) validating them. The validation step the affix context or the morphotactics of the lanis necessary to exclude bad affix candidates (e.g. let- guage. Typical mistakes that arise from this </context>
<context position="24885" citStr="Bordag, 2006" startWordPosition="3970" endWordPosition="3971">ds takes 3 min for the version that does the simple segmentation and about 8 min for the version that generates all possible segmentations and uses the language model. 5.1 Comparison to other systems This modified version of the algorithm performs second best for English (after original RePortS) and ranks third for Turkish (after Bernhards algorithm with 65.3% F-measure and Morfessor-CategoriesMAP with 70.7%). On German, our method significantly outperformed the other unsupervised algorithms, see Table 3. While most of the systems compared here were developed for languages other than German, (Bordag, 2006) describes a system initially built for German. When trained on the “Projekt Deutscher Wortschatz” corpus which comprises 24 million sentences, it achieves an F-score of 61% (precision 60%, recall 62%2) when evaluated on the full CELEX corpus. 2Data from personal communication. 925 morphology F-Meas. Prec. Recall SMOR-disamb2 83.6% 87.1% 80.4% ETI 79.5% 75.4% 84.1% SMOR-disamb1 71.8% 95.4% 57.6% RePortS-lm 68.8% 73.7% 64.6% RePortS-stems 68.4% 68.1% 68.6% best Bernhard 63.5% 64.9% 62.1% Bordag 61.4% 60.6% 62.3% orig. RePortS 59.2% 71.1% 50.7% best Morfessor 1.0 52.6% 70.9% 41.8% Table 3: Evalu</context>
</contexts>
<marker>Bordag, 2006</marker>
<rawString>Stefan Bordag. 2006. Two-step approach to unsupervised morpheme segmentation. In Proceedings of 2nd Pascal Challenges Workshop, pages 25–29, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2006</date>
<booktitle>In ACM Transaction on Speech and Language Processing.</booktitle>
<contexts>
<context position="18098" citStr="Creutz and Lagus, 2006" startWordPosition="2886" endWordPosition="2889">el can then also acquire probabilities about which affixes occur most often at the edges of words. Table 2 shows that filtering the segmentation results with the n-gram language model caused a significant improvement on the overall F-score for most languages, and led to significant changes in precision and recall. Whereas the original segmentation yielded balanced precision and recall (both 68%), the new filtering boosts precision to over 73%, with 64% recall. Which method is preferable (i.e. whether precision or recall is more important) is task-dependent. In future work, we plan to draw on (Creutz and Lagus, 2006), who use a HMM with morphemic categories to impose morphotactic constraints. In such an approach, each element from the affix list is assigned with a certain probability to the underlying categories of “stem”, “prefix” or “suffix”, depending on the left and right perplexity of morphemes, as well as morpheme length and frequency. The transitional probabilities from one category to the next model the morphotactic rules of a language, which can thus be learnt automatically. 4.3 Learning Stem Variation Stem variation through ablauting and umlauting (an English example is run–ran) is an interestin</context>
</contexts>
<marker>Creutz, Lagus, 2006</marker>
<rawString>Mathias Creutz and Krista Lagus. 2006. Unsupervised models for morpheme segmentation and morphology learning. In ACM Transaction on Speech and Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H D´ejean</author>
</authors>
<title>Morphemes as necessary concepts for structures: Discovery from untagged corpora.</title>
<date>1998</date>
<booktitle>In Workshop on paradigms and Grounding in Natural Language Learning,</booktitle>
<pages>295--299</pages>
<location>Adelaide, Australia.</location>
<marker>D´ejean, 1998</marker>
<rawString>H. D´ejean. 1998. Morphemes as necessary concepts for structures: Discovery from untagged corpora. In Workshop on paradigms and Grounding in Natural Language Learning, pages 295–299, Adelaide, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Demberg</author>
</authors>
<title>Letter-to-phoneme conversion for a German TTS-System. Master’s thesis.</title>
<date>2006</date>
<institution>IMS, Univ. of Stuttgart.</institution>
<contexts>
<context position="26118" citStr="Demberg, 2006" startWordPosition="4161" endWordPosition="4162">d data-based systems for morphological segmentation with respect to CELEX manual morphological annotation. Rule-based systems are currently the most common approach to morphological decomposition and perform better at segmenting words than state-ofthe-art unsupervised algorithms (see Table 3 for performance of state-of-the-art rule-based systems evaluated on the same data). Both the ETI3 and the SMOR (Schmid et al., 2004) systems rely on a large lexicon and a set of rules. The SMOR system returns a set of analyses that can be disambiguated in different ways. For details refer to pp. 29–33 in (Demberg, 2006). 5.2 Evaluation on Grapheme-to-Phoneme Conversion Morphological segmentation is not of value in itself – the question is whether it can help improve results on an application. Performance improvements due to morphological information have been reported for example in MT, information retrieval, and speech recognition. For the latter task, morphological segmentations from the unsupervised systems presented here have been shown to improve accuracy (Kurimo et al., 2006). Another motivation for evaluating the system on a task rather than on manually annotated data is that linguistically motivated </context>
</contexts>
<marker>Demberg, 2006</marker>
<rawString>Vera Demberg. 2006. Letter-to-phoneme conversion for a German TTS-System. Master’s thesis. IMS, Univ. of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Demberg</author>
</authors>
<title>Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proc. ofACL-2007.</booktitle>
<contexts>
<context position="28248" citStr="Demberg, 2007" startWordPosition="4484" endWordPosition="4485">to find boundaries between stems and suffixes. The standard evaluation procedure does not differentiate between the types of mistakes made. Finally, only evaluation on a task can provide information as to whether high precision or high recall is more important, therefore, the decision as to which version of the algorithm should be chosen can only be taken given a specific task. For these reasons we decided to evaluate the segmentation from the new versions of the RePortS algorithm on a German grapheme-to-phoneme (g2p) conversion task. The evaluation on this task is motivated by the fact that (Demberg, 2007) showed that good-quality morphological preprocessing can improve g2p conversion results. We here compare the effect of using our system’s segmentations to a range of different morphological segmentations from other systems. We ran each of the rule-based systems (ETI, SMOR-disamb1, SMOR-disamb2) and the unsupervised algorithms (original RePortS, Bernhard, Morfessor 1.0, Bordag) on the CELEX data set and retrained our decision tree (an implementation based on (Lucassen and Mercer, 1984)) on the different morphological segmentations. Table 4 shows the F-score of the different systems when evalua</context>
</contexts>
<marker>Demberg, 2007</marker>
<rawString>Vera Demberg. 2007. Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion. In Proc. ofACL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gaussier</author>
</authors>
<title>Unsupervised learning of derivational morphology from inflectional lexicons.</title>
<date>1999</date>
<booktitle>In ACL ’99 Workshop Proceedings,</booktitle>
<institution>University of Maryland.</institution>
<contexts>
<context position="4406" citStr="Gaussier, 1999" startWordPosition="647" endWordPosition="648">inal algorithm in dressed word internal variations (Yarowski and Wisection 4. Section 5 compares results for different centowski, 2000; Neuvel and Fulop, 2002). languages, quantifies the gains from the modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused together, tic and semantic information from the contex</context>
<context position="6487" citStr="Gaussier, 1999" startWordPosition="960" endWordPosition="961">in Pinge- The original RePortS algorithm assumes morlapese: mejr ‘to sleep’, mejmejr ‘sleeping’, mejme- phology to be concatenative, and specializes on prejmejr ‘still sleeping’). For words that are subject to fixation and suffixation, like most of the above apone of the above processes it is not trivial to automat- proaches, which were developed and implemented ically group related words and detect regular trans- for English (Goldsmith, 2001; Schone and Jurafsky, formational patterns. 2000; Neuvel and Fulop, 2002; Yarowski and WiA range of automated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many ical analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a m</context>
</contexts>
<marker>Gaussier, 1999</marker>
<rawString>Eric Gaussier. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL ’99 Workshop Proceedings, University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CELEX German</author>
</authors>
<title>Linguistic User Guide,</title>
<date>1995</date>
<institution>Center for LexicalInformation. Max-Planck-Institut for Psycholinguistics,</institution>
<location>Nijmegen.</location>
<marker>German, 1995</marker>
<rawString>CELEX German Linguistic User Guide, 1995. Center for LexicalInformation. Max-Planck-Institut for Psycholinguistics, Nijmegen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language. computational</title>
<date>2001</date>
<journal>Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="4390" citStr="Goldsmith, 2001" startWordPosition="645" endWordPosition="646">tions to the original algorithm in dressed word internal variations (Yarowski and Wisection 4. Section 5 compares results for different centowski, 2000; Neuvel and Fulop, 2002). languages, quantifies the gains from the modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused together, tic and semantic information</context>
<context position="6318" citStr="Goldsmith, 2001" startWordPosition="936" endWordPosition="937">ation (e.g. in Ger- be computationally expensive, especially when they man: mach-en ‘do’, ge-mach-t ‘done’), the Ara- use LSA. bic broken plural or reduplications (e.g. in Pinge- The original RePortS algorithm assumes morlapese: mejr ‘to sleep’, mejmejr ‘sleeping’, mejme- phology to be concatenative, and specializes on prejmejr ‘still sleeping’). For words that are subject to fixation and suffixation, like most of the above apone of the above processes it is not trivial to automat- proaches, which were developed and implemented ically group related words and detect regular trans- for English (Goldsmith, 2001; Schone and Jurafsky, formational patterns. 2000; Neuvel and Fulop, 2002; Yarowski and WiA range of automated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many ical analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between le</context>
<context position="7565" citStr="Goldsmith, 2001" startWordPosition="1128" endWordPosition="1129">riginal RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challenge 921 20051 (Kurimo et al., 2006), obtaining an F-measure An affix is validated if all three criteria are satisfied of 76.8% (76.2% prec., 77.4% recall). The next best for at least 5% of its occurrences: system obtained an F-score of 69%. However, the 1. The substring that remains after peeling off an algorithm does not perform as well on other lan- affix is also a word in the lexicon. guages (Turkish, Finnish, German) due to low re- 2</context>
<context position="13539" citStr="Goldsmith, 2001" startWordPosition="2142" endWordPosition="2143">rst condition of the affix acquisition step needs to be replaced. We therefore introduced an additional step for building an intermediate stem candidate list into the affix acquisition process. The first condition is replaced by a condition that checks whether a stem is in the stem candidate list. This new stem candidate acquisition procedure comprises three steps: Step 1: Creation of stem candidate list All substrings that satisfy conditions 2 and 3 but not condition 1, are stored together with the set of affixes they occur with. This process is similar to the idea of registering signatures (Goldsmith, 2001; Neuvel and Fulop, 2002). For example, let us assume our corpus contains the words Auff¨uhrender, Auff¨uhrung, auff¨uhrt and Auff¨uhrlaune but not the stem itself, since auff¨uhr ‘act’ is not a valid German word. Conditions 2 and 3 are met, because the transitional probability between auff¨uhr and the next letter is low (there are a lot of different possible continuations) and the transitional probability P(r|auff¨uh) Pz� 1. The stem candidate auff¨uhr is then stored together with the suffix candidates {ender, ung, en, t, laune}. Step 2: Ranking candidate stems There are two types of affix ca</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>John Goldsmith. 2001. Unsupervised learning of the morphology of a natural language. computational Linguistics, 27(2):153–198, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>D McClosky</author>
</authors>
<title>Improving statistical mt through morphological analysis.</title>
<date>2005</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1101" citStr="Goldwater and McClosky, 2005" startWordPosition="151" endWordPosition="154">scribes an algorithm that draws from previous approaches and combines them into a simple model for morphological segmentation that outperforms other approaches on English and German, and also yields good results on agglutinative languages such as Finnish and Turkish. We also propose a method for detecting variation within stems in an unsupervised fashion. The segmentation quality reached with the new algorithm is good enough to improve grapheme-to-phoneme conversion. 1 Introduction Morphological segmentation has been shown to be beneficial to a number of NLP tasks such as machine translation (Goldwater and McClosky, 2005), speech recognition (Kurimo et al., 2006), information retrieval (Monz and de Rijke, 2002) and question answering. Segmenting a word into meaningbearing units is particularly interesting for morphologically complex languages where words can be composed of several morphemes through inflection, derivation and composition. Data sparseness for such languages can be significantly decreased when words are decomposed morphologically. There exist a number of rule-based morphological segmentation systems for a range of languages. However, expert knowledge and labour are expensive, and the analyzers mu</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>S. Goldwater and D. McClosky. 2005. Improving statistical mt through morphological analysis. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret A Hafer</author>
<author>Stephen F Weiss</author>
</authors>
<title>Word segmentation by letter successor varieties.</title>
<date>1974</date>
<journal>Information Storage and Retrieval</journal>
<volume>10</volume>
<pages>371--385</pages>
<contexts>
<context position="7042" citStr="Hafer and Weiss, 1974" startWordPosition="1042" endWordPosition="1045">tomated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many ical analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These</context>
<context position="11184" citStr="Hafer and Weiss, 1974" startWordPosition="1748" endWordPosition="1751">ether The original RePortS algorithm uses a very simple in long unary branches, while the branching factor is method that peels off the most probable suffix that high in places where morpheme boundaries occur. has a transitional probability smaller than 1, until no The underlying idea of exploiting “Letter Succes- more affixes match or until less than half of the word sor Variety” was first proposed in (Harris, 1955), and remains. This last condition is problematic since it has since been used in a number of morphemic seg- does not scale up well to languages with complex mentation algorithms (Hafer and Weiss, 1974; Bern- morphology. The same peeling-off process is exehard, 2006; Bordag, 2006). cuted for prefixes. 3.2 Finding Affixes Although this method is better than using a The second step is concerned with finding good af- heuristic such as ‘always peel off the longest posfixes. The procedure is quite simple and can be di- sible affix’, because it takes into account probable vided into two subtasks. (1) generating all possible sites of fractures in words, it is not sensitive to affixes and (2) validating them. The validation step the affix context or the morphotactics of the lanis necessary to exclu</context>
</contexts>
<marker>Hafer, Weiss, 1974</marker>
<rawString>Margaret A. Hafer and Stephen F. Weiss. 1974. Word segmentation by letter successor varieties. Information Storage and Retrieval 10, pages 371–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>From phoneme to morpheme.</title>
<date>1955</date>
<journal>Language</journal>
<volume>31</volume>
<pages>190--222</pages>
<contexts>
<context position="7019" citStr="Harris, 1955" startWordPosition="1040" endWordPosition="1041">iA range of automated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many ical analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm </context>
<context position="10983" citStr="Harris, 1955" startWordPosition="1716" endWordPosition="1717">is the complete segmentation of words low probability is a good indicator of a morpheme given the list of affixes acquired in the previous step. boundary. In such a tree, stems tend to stay together The original RePortS algorithm uses a very simple in long unary branches, while the branching factor is method that peels off the most probable suffix that high in places where morpheme boundaries occur. has a transitional probability smaller than 1, until no The underlying idea of exploiting “Letter Succes- more affixes match or until less than half of the word sor Variety” was first proposed in (Harris, 1955), and remains. This last condition is problematic since it has since been used in a number of morphemic seg- does not scale up well to languages with complex mentation algorithms (Hafer and Weiss, 1974; Bern- morphology. The same peeling-off process is exehard, 2006; Bordag, 2006). cuted for prefixes. 3.2 Finding Affixes Although this method is better than using a The second step is concerned with finding good af- heuristic such as ‘always peel off the longest posfixes. The procedure is quite simple and can be di- sible affix’, because it takes into account probable vided into two subtasks. (1</context>
</contexts>
<marker>Harris, 1955</marker>
<rawString>Zellig Harris. 1955. From phoneme to morpheme. Language 31, pages 190–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Guessing morphology from terms and corpora.</title>
<date>1997</date>
<booktitle>In Research and Development in Information Retrieval,</booktitle>
<pages>156--165</pages>
<contexts>
<context position="4610" citStr="Jacquemin, 1997" startWordPosition="677" endWordPosition="678">modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused together, tic and semantic information from the context the e.g. Latin). word occurs (Schone and Jurafsky, 2000; Bordag, Phenomena that are difficult to cope with for 2006; Yarowski and Wicentowski, 2000; Jacquemin, many of the unsupervised algorithms are no</context>
</contexts>
<marker>Jacquemin, 1997</marker>
<rawString>Christian Jacquemin. 1997. Guessing morphology from terms and corpora. In Research and Development in Information Retrieval, pages 156–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Keshava</author>
<author>E Pitler</author>
</authors>
<title>A simpler, intuitive approach to morpheme induction.</title>
<date>2006</date>
<booktitle>In Proceedings of 2nd Pascal Challenges Workshop,</booktitle>
<pages>31--35</pages>
<location>Venice, Italy.</location>
<contexts>
<context position="2588" citStr="Keshava and Pitler, 2006" startWordPosition="369" endWordPosition="372">sually lead to better results. However, segmentations from an unsupervised algorithm that is language-independent are “cheap”, because the only resource needed is unannotated text. If such an unsupervised system reaches a performance level that is good enough to help another task, it can constitute an attractive additional component. Recently, a number of approaches to unsupervised morphological segmentation have been proposed. These algorithms autonomously discover morpheme segmentations in unannotated text corpora. Here we describe a modification of one such unsupervised algorithm, RePortS (Keshava and Pitler, 2006). The RePortS algorithm performed best on English in a recent competition on unsupervised morphological segmentation (Kurimo et al., 2006), but had very low recall on morphologically more complex languages like German, Finnish or Turkish. We add a new step designed to achieve higher recall on morphologically complex languages and propose a method for identifying related stems that underwent regular non-concatenative morphological processes such as umlauting or ablauting, as well as morphological alternations along morpheme boundaries. The paper is structured as follows: Section 920 Proceedings</context>
<context position="8244" citStr="Keshava and Pitler, 2006" startWordPosition="1240" endWordPosition="1243">clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challenge 921 20051 (Kurimo et al., 2006), obtaining an F-measure An affix is validated if all three criteria are satisfied of 76.8% (76.2% prec., 77.4% recall). The next best for at least 5% of its occurrences: system obtained an F-score of 69%. However, the 1. The substring that remains after peeling off an algorithm does not perform as well on other lan- affix is also a word in the lexicon. guages (Turkish, Finnish, German) due to low re- 2. The transitional probability between the call (see (Keshava and Pitler, 2006) and (Demberg, second-last and the last stem letter is Pz� 1. 2006), p. 47). 3. The transitional probability of the affix letter There are three main steps in the algorithm. First, next to the stem is &lt;1 (tolerance 0.02). the data is structured in two trees, which provide the Finally, all affixes that are concatenations of two or basis for efficient calculation of transitional proba- more other suffixes (e.g., -ungen can be split up in bilities of a letter given its context. The second step -ung and -en in German) are removed. This step reis the affix acquisition step, during which a set of tu</context>
</contexts>
<marker>Keshava, Pitler, 2006</marker>
<rawString>S. Keshava and E. Pitler. 2006. A simpler, intuitive approach to morpheme induction. In Proceedings of 2nd Pascal Challenges Workshop, pages 31–35, Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kurimo</author>
<author>M Creutz</author>
<author>M Varjokallio</author>
<author>E Arisoy</author>
<author>M Saraclar</author>
</authors>
<title>Unsupervsied segmentation of words into morphemes – Challenge 2005: An introduction and evaluation report.</title>
<date>2006</date>
<booktitle>In Proc. of 2nd Pascal Challenges Workshop,</booktitle>
<location>Italy.</location>
<contexts>
<context position="1143" citStr="Kurimo et al., 2006" startWordPosition="157" endWordPosition="160">aches and combines them into a simple model for morphological segmentation that outperforms other approaches on English and German, and also yields good results on agglutinative languages such as Finnish and Turkish. We also propose a method for detecting variation within stems in an unsupervised fashion. The segmentation quality reached with the new algorithm is good enough to improve grapheme-to-phoneme conversion. 1 Introduction Morphological segmentation has been shown to be beneficial to a number of NLP tasks such as machine translation (Goldwater and McClosky, 2005), speech recognition (Kurimo et al., 2006), information retrieval (Monz and de Rijke, 2002) and question answering. Segmenting a word into meaningbearing units is particularly interesting for morphologically complex languages where words can be composed of several morphemes through inflection, derivation and composition. Data sparseness for such languages can be significantly decreased when words are decomposed morphologically. There exist a number of rule-based morphological segmentation systems for a range of languages. However, expert knowledge and labour are expensive, and the analyzers must be updated on a regular basis in order </context>
<context position="2726" citStr="Kurimo et al., 2006" startWordPosition="388" endWordPosition="391"> resource needed is unannotated text. If such an unsupervised system reaches a performance level that is good enough to help another task, it can constitute an attractive additional component. Recently, a number of approaches to unsupervised morphological segmentation have been proposed. These algorithms autonomously discover morpheme segmentations in unannotated text corpora. Here we describe a modification of one such unsupervised algorithm, RePortS (Keshava and Pitler, 2006). The RePortS algorithm performed best on English in a recent competition on unsupervised morphological segmentation (Kurimo et al., 2006), but had very low recall on morphologically more complex languages like German, Finnish or Turkish. We add a new step designed to achieve higher recall on morphologically complex languages and propose a method for identifying related stems that underwent regular non-concatenative morphological processes such as umlauting or ablauting, as well as morphological alternations along morpheme boundaries. The paper is structured as follows: Section 920 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 920–927, Prague, Czech Republic, June 2007. c�2007 Asso</context>
<context position="7759" citStr="Kurimo et al., 2006" startWordPosition="1157" endWordPosition="1160">06; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challenge 921 20051 (Kurimo et al., 2006), obtaining an F-measure An affix is validated if all three criteria are satisfied of 76.8% (76.2% prec., 77.4% recall). The next best for at least 5% of its occurrences: system obtained an F-score of 69%. However, the 1. The substring that remains after peeling off an algorithm does not perform as well on other lan- affix is also a word in the lexicon. guages (Turkish, Finnish, German) due to low re- 2. The transitional probability between the call (see (Keshava and Pitler, 2006) and (Demberg, second-last and the last stem letter is Pz� 1. 2006), p. 47). 3. The transitional probability of the</context>
<context position="26589" citStr="Kurimo et al., 2006" startWordPosition="4226" endWordPosition="4229">et of rules. The SMOR system returns a set of analyses that can be disambiguated in different ways. For details refer to pp. 29–33 in (Demberg, 2006). 5.2 Evaluation on Grapheme-to-Phoneme Conversion Morphological segmentation is not of value in itself – the question is whether it can help improve results on an application. Performance improvements due to morphological information have been reported for example in MT, information retrieval, and speech recognition. For the latter task, morphological segmentations from the unsupervised systems presented here have been shown to improve accuracy (Kurimo et al., 2006). Another motivation for evaluating the system on a task rather than on manually annotated data is that linguistically motivated morphological segmentation is not necessarily the best possible segmentation for a certain task. Evaluation against a manually annotated corpus prefers segmentations that are closest to linguistically motivated analyses. Furthermore, it might be important for a certain task to find a particular type of morpheme boundaries (e.g. boundaries between stems), but for another task it 3Eloquent Technology, Inc. (ETI) TTS system. www.mindspring.com/˜ssshp/ssshp_cd/ss_ eloq.h</context>
</contexts>
<marker>Kurimo, Creutz, Varjokallio, Arisoy, Saraclar, 2006</marker>
<rawString>M. Kurimo, M. Creutz, M. Varjokallio, E. Arisoy, and M. Saraclar. 2006. Unsupervsied segmentation of words into morphemes – Challenge 2005: An introduction and evaluation report. In Proc. of 2nd Pascal Challenges Workshop, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lucassen</author>
<author>R Mercer</author>
</authors>
<title>An information theoretic approach to the automatic determination of phonemic baseforms.</title>
<date>1984</date>
<booktitle>In ICASSP 9.</booktitle>
<contexts>
<context position="28738" citStr="Lucassen and Mercer, 1984" startWordPosition="4553" endWordPosition="4556">gorithm on a German grapheme-to-phoneme (g2p) conversion task. The evaluation on this task is motivated by the fact that (Demberg, 2007) showed that good-quality morphological preprocessing can improve g2p conversion results. We here compare the effect of using our system’s segmentations to a range of different morphological segmentations from other systems. We ran each of the rule-based systems (ETI, SMOR-disamb1, SMOR-disamb2) and the unsupervised algorithms (original RePortS, Bernhard, Morfessor 1.0, Bordag) on the CELEX data set and retrained our decision tree (an implementation based on (Lucassen and Mercer, 1984)) on the different morphological segmentations. Table 4 shows the F-score of the different systems when evaluated on the manually annotated CELEX data (full data set) and the phoneme error rate (PER) for the g2p conversion algorithm when annotated with morphological boundaries (smaller test set, since the decision tree is a supervised method and needs training data). As we can see from the results, the distribution of precision and recall (see Table 3) has an important impact on the conversion quality: the RePortS version with higher precision signifi926 cantly outperforms the other version on</context>
</contexts>
<marker>Lucassen, Mercer, 1984</marker>
<rawString>J. Lucassen and R. Mercer. 1984. An information theoretic approach to the automatic determination of phonemic baseforms. In ICASSP 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monson</author>
<author>A Lavie</author>
<author>J Carbonell</author>
<author>L Levin</author>
</authors>
<title>Unsupervised induction of natural language morphology inflection classes.</title>
<date>2004</date>
<booktitle>In Proceedings of the Seventh Meeting ofACLSIGPHON,</booktitle>
<pages>52--61</pages>
<location>Barcelona,</location>
<contexts>
<context position="4357" citStr="Monson et al., 2004" startWordPosition="638" endWordPosition="641"> approaches have adplain the modifications to the original algorithm in dressed word internal variations (Yarowski and Wisection 4. Section 5 compares results for different centowski, 2000; Neuvel and Fulop, 2002). languages, quantifies the gains from the modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused toget</context>
<context position="7125" citStr="Monson et al., 2004" startWordPosition="1056" endWordPosition="1059">l analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better adapted to aries (Harris, 1955; Hafer and Weiss, 1974; D´ejean, complex morphology and suggest a method for cop1998; Monson et al., 2004; Bernhard, 2006; Ke- ing with stem variation. These modifications renshava and Pitler, 2006; Bordag, 2006), approaches der the algorithm more language-independent and that use minimal description length and thereby min- thereby make it attractive for applying to other lanimize the size of the lexicon as measured in en- guages as well. tries and links between the entries to constitute a 3 The RePortS Algorithm word form (Goldsmith, 2001; Creutz and Lagus, On English, the RePortS algorithm clearly out2006). These two types of approaches very closely performed all other systems in Morpho Challen</context>
</contexts>
<marker>Monson, Lavie, Carbonell, Levin, 2004</marker>
<rawString>C. Monson, A. Lavie, J. Carbonell, and L. Levin. 2004. Unsupervised induction of natural language morphology inflection classes. In Proceedings of the Seventh Meeting ofACLSIGPHON, pages 52–61, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monz</author>
<author>M de Rijke</author>
</authors>
<title>Shallow morphological analysis in monolingual information retrieval for Dutch, German, and Italian.</title>
<date>2002</date>
<booktitle>In Proceedings CLEF 2001, LNCS</booktitle>
<pages>2406</pages>
<marker>Monz, de Rijke, 2002</marker>
<rawString>C. Monz and M. de Rijke. 2002. Shallow morphological analysis in monolingual information retrieval for Dutch, German, and Italian. In Proceedings CLEF 2001, LNCS 2406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Neuvel</author>
<author>Sean Fulop</author>
</authors>
<title>Unsupervised learning of morphology without morphemes.</title>
<date>2002</date>
<booktitle>In Proc. of the Wshp on Morphological and Phonological Learning, ACL Pub.</booktitle>
<contexts>
<context position="3951" citStr="Neuvel and Fulop, 2002" startWordPosition="576" endWordPosition="579">ation for Computational Linguistics 2 discusses the relationship between language- tie the orthographic form of the word to the mordependency and the level of supervision of a learn- phemes. They are thus not well-suited for coping ing algorithm. We then give an outline of the main with stem changes or modifications at the edges of steps of the RePortS algorithm in section 3 and ex- morphemes. Only very few approaches have adplain the modifications to the original algorithm in dressed word internal variations (Yarowski and Wisection 4. Section 5 compares results for different centowski, 2000; Neuvel and Fulop, 2002). languages, quantifies the gains from the modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolat</context>
<context position="6391" citStr="Neuvel and Fulop, 2002" startWordPosition="944" endWordPosition="947">they man: mach-en ‘do’, ge-mach-t ‘done’), the Ara- use LSA. bic broken plural or reduplications (e.g. in Pinge- The original RePortS algorithm assumes morlapese: mejr ‘to sleep’, mejmejr ‘sleeping’, mejme- phology to be concatenative, and specializes on prejmejr ‘still sleeping’). For words that are subject to fixation and suffixation, like most of the above apone of the above processes it is not trivial to automat- proaches, which were developed and implemented ically group related words and detect regular trans- for English (Goldsmith, 2001; Schone and Jurafsky, formational patterns. 2000; Neuvel and Fulop, 2002; Yarowski and WiA range of automated algorithms for morpholog- centowski, 2000; Gaussier, 1999). However, many ical analysis cope with concatenative phenomena, languages are morphologically more complex. For and base their mechanics on statistics about hypoth- example in German, an algorithm also needs to cope esized stems and affixes. These approaches can be with compounding, and in Turkish words can be further categorized into ones that use conditional very long and complex. We therefore extended the entropy between letters to detect segment bound- original RePortS algorithm to be better ad</context>
<context position="13564" citStr="Neuvel and Fulop, 2002" startWordPosition="2144" endWordPosition="2147">the affix acquisition step needs to be replaced. We therefore introduced an additional step for building an intermediate stem candidate list into the affix acquisition process. The first condition is replaced by a condition that checks whether a stem is in the stem candidate list. This new stem candidate acquisition procedure comprises three steps: Step 1: Creation of stem candidate list All substrings that satisfy conditions 2 and 3 but not condition 1, are stored together with the set of affixes they occur with. This process is similar to the idea of registering signatures (Goldsmith, 2001; Neuvel and Fulop, 2002). For example, let us assume our corpus contains the words Auff¨uhrender, Auff¨uhrung, auff¨uhrt and Auff¨uhrlaune but not the stem itself, since auff¨uhr ‘act’ is not a valid German word. Conditions 2 and 3 are met, because the transitional probability between auff¨uhr and the next letter is low (there are a lot of different possible continuations) and the transitional probability P(r|auff¨uh) Pz� 1. The stem candidate auff¨uhr is then stored together with the suffix candidates {ender, ung, en, t, laune}. Step 2: Ranking candidate stems There are two types of affix candidates: type-1 affix ca</context>
</contexts>
<marker>Neuvel, Fulop, 2002</marker>
<rawString>Sylvain Neuvel and Sean Fulop. 2002. Unsupervised learning of morphology without morphemes. In Proc. of the Wshp on Morphological and Phonological Learning, ACL Pub.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Arne Fitschen</author>
<author>Ulrich Heid</author>
</authors>
<title>SMOR: A German computational morphology covering derivation, composition and inflection.</title>
<date>2004</date>
<booktitle>In Proc. ofLREC.</booktitle>
<contexts>
<context position="25929" citStr="Schmid et al., 2004" startWordPosition="4123" endWordPosition="4126">.6% RePortS-stems 68.4% 68.1% 68.6% best Bernhard 63.5% 64.9% 62.1% Bordag 61.4% 60.6% 62.3% orig. RePortS 59.2% 71.1% 50.7% best Morfessor 1.0 52.6% 70.9% 41.8% Table 3: Evaluating rule-based and data-based systems for morphological segmentation with respect to CELEX manual morphological annotation. Rule-based systems are currently the most common approach to morphological decomposition and perform better at segmenting words than state-ofthe-art unsupervised algorithms (see Table 3 for performance of state-of-the-art rule-based systems evaluated on the same data). Both the ETI3 and the SMOR (Schmid et al., 2004) systems rely on a large lexicon and a set of rules. The SMOR system returns a set of analyses that can be disambiguated in different ways. For details refer to pp. 29–33 in (Demberg, 2006). 5.2 Evaluation on Grapheme-to-Phoneme Conversion Morphological segmentation is not of value in itself – the question is whether it can help improve results on an application. Performance improvements due to morphological information have been reported for example in MT, information retrieval, and speech recognition. For the latter task, morphological segmentations from the unsupervised systems presented he</context>
</contexts>
<marker>Schmid, Fitschen, Heid, 2004</marker>
<rawString>Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004. SMOR: A German computational morphology covering derivation, composition and inflection. In Proc. ofLREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent semantic analysis.</title>
<date>2000</date>
<booktitle>In Proc. of CoNLL-2000 and LLL-2000,</booktitle>
<location>Lisbon,</location>
<note>https://www.taz.de/pt/.etc/nf/dvd.</note>
<contexts>
<context position="5063" citStr="Schone and Jurafsky, 2000" startWordPosition="748" endWordPosition="751">nguages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused together, tic and semantic information from the context the e.g. Latin). word occurs (Schone and Jurafsky, 2000; Bordag, Phenomena that are difficult to cope with for 2006; Yarowski and Wicentowski, 2000; Jacquemin, many of the unsupervised algorithms are non- 1997). Exploiting semantic and syntactic informaconcatenative processes such as vowel harmoniza- tion is very attractive because it adds an additional tion, ablauting and umlauting, or modifications at dimension, but these approaches have to cope with the boundaries of morphemes, as well as infixation more severe data sparseness issues than approaches (e.g. in Tagalog: sulat ‘write’, s-um-ulat ‘wrote’, s- that emphasize word-internal cues, and th</context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>Patrick Schone and Daniel Jurafsky. 2000. Knowledge-free induction of morphology using latent semantic analysis. In Proc. of CoNLL-2000 and LLL-2000, Lisbon, Portugal. Tageszeitung (TAZ) Corpus. Contrapress Media GmbH. https://www.taz.de/pt/.etc/nf/dvd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowski</author>
<author>Richard Wicentowski</author>
</authors>
<title>Minimally supervised morphological analysis by multimodal alignment.</title>
<date>2000</date>
<booktitle>In Proceedings ofACL</booktitle>
<location>Hong Kong.</location>
<contexts>
<context position="4515" citStr="Yarowski and Wicentowski, 2000" startWordPosition="661" endWordPosition="664">res results for different centowski, 2000; Neuvel and Fulop, 2002). languages, quantifies the gains from the modifica- A popular and effective approach for detecting intions on the algorithm and evaluates the algorithm flectional paradigms and filter affix lists is to cluster on a grapheme-to-phoneme conversion task. We fi- together affixes or regular transformational patterns nally summarize our results in section 6. that occur with the same stem (Monson et al., 2004; 2 Previous Work Goldsmith, 2001; Gaussier, 1999; Schone and JurafThe world’s languages can be classified according sky, 2000; Yarowski and Wicentowski, 2000; Neuto their morphology into isolating languages (little vel and Fulop, 2002; Jacquemin, 1997). We draw or no morphology, e.g. Chinese), agglutinative lan- from this idea of clustering in order to detect orthoguages (where a word can be decomposed into a graphic variants of stems; see Section 4.3. large number of morphemes, e.g. Turkish) and in- A few approaches also take into account syntacflectional languages (morphemes are fused together, tic and semantic information from the context the e.g. Latin). word occurs (Schone and Jurafsky, 2000; Bordag, Phenomena that are difficult to cope with </context>
</contexts>
<marker>Yarowski, Wicentowski, 2000</marker>
<rawString>David Yarowski and Richard Wicentowski. 2000. Minimally supervised morphological analysis by multimodal alignment. In Proceedings ofACL 2000, Hong Kong.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>