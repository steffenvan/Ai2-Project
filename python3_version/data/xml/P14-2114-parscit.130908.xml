<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001781">
<title confidence="0.996497">
A Simple Bayesian Modelling Approach to Event Extraction from Twitter
</title>
<author confidence="0.956262">
Deyu Zhou†‡ Liangyu Chen† Yulan He§
</author>
<affiliation confidence="0.83664725">
† School of Computer Science and Engineering, Key Laboratory of Computer Network
and Information Integration, Ministry of Education, Southeast University, China
‡ State Key Laboratory for Novel Software Technology, Nanjing University, China
§ School of Engineering and Applied Science, Aston University, UK
</affiliation>
<email confidence="0.991984">
d.zhou@seu.edu.cn, cly1cn@126.com, y.he@cantab.net
</email>
<sectionHeader confidence="0.99736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999505">
With the proliferation of social media
sites, social streams have proven to con-
tain the most up-to-date information on
current events. Therefore, it is crucial to
extract events from the social streams such
as tweets. However, it is not straight-
forward to adapt the existing event ex-
traction systems since texts in social me-
dia are fragmented and noisy. In this pa-
per we propose a simple and yet effec-
tive Bayesian model, called Latent Event
Model (LEM), to extract structured rep-
resentation of events from social media.
LEM is fully unsupervised and does not
require annotated data for training. We
evaluate LEM on a Twitter corpus. Ex-
perimental results show that the proposed
model achieves 83% in F-measure, and
outperforms the state-of-the-art baseline
by over 7%.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996997833333334">
Event extraction is to automatically identify events
from text with information about what happened,
when, where, to whom, and why. Previous work in
event extraction has focused largely on news ar-
ticles, as the newswire texts have been the best
source of information on current events (Hogen-
boom et al., 2011). Approaches for event ex-
traction include knowledge-based (Piskorski et al.,
2007; Tanev et al., 2008), data-driven (Piskorski
et al., 2008) and a combination of the above two
categories (Grishman et al., 2005). Knowledge-
based approaches often rely on linguistic and lexi-
cographic patterns which represent expert domain
knowledge for particular event types. They lack
the flexibility of porting to new domains since ex-
traction patterns often need to be re-defined. Data-
driven approaches require large annotated data to
train statistical models that approximate linguistic
phenomena. Nevertheless, it is expensive to obtain
annotated data in practice.
With the increasing popularity of social media,
social networking sites such as Twitter have be-
come an important source of event information.
As reported in (Petrovic et al., 2013), even 1% of
the public stream of Twitter contains around 95%
of all the events reported in the newswire. Never-
theless, the social stream data such as Twitter data
pose new challenges. Social media messages are
often short and evolve rapidly over time. As such,
it is not possible to know the event types a priori
and hence violates the use of existing event extrac-
tion approaches.
Approaches to event extraction from Twitter
make use of a graphical model to extract canonical
entertainment events from tweets by aggregating
information across multiple messages (Benson et
al., 2011). In (Liu et al., 2012), social events in-
volving two persons are extracted from multiple
similar tweets using a factor graph by harvesting
the redundancy in tweets. Ritter et al. (2012) pre-
sented a system called TwiCal which extracts an
open-domain calendar of significant events repre-
sented by a 4-tuple set including a named entity,
event phrase, calendar date, and event type from
Twitter.
In our work here, we notice a very important
property in social media data that the same event
could be referenced by high volume messages.
This property allows us resort to statistical mod-
els that can group similar events based on the co-
occurrence patterns of their event elements. Here,
event elements include named entities such as per-
son, company, organization, date/time, location,
and the relations among them. We can treat an
event as a latent variable and model the genera-
tion of an event as a joint distribution of its indi-
vidual event elements. We thus propose a Latent
Event Model (LEM) which can automatically de-
tect events from social media without the use of
labeled data.
</bodyText>
<page confidence="0.928661">
700
</page>
<bodyText confidence="0.305504">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 700–705,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<figure confidence="0.973224176470588">
Tweets
Extracted Events
Name Entity Time Location Key words
Amy 2011/0 London Die,
Winehouse 7/23 Death, ..
Space Shuttle 2011/0 Kennedy Land ...
Atlantis 7/08 Space Center
...
Post-
processing
Latent
Event
Model
Pre-processing
POS Named Entity Stemming
Tagging Recognition
Temporal Resolution
</figure>
<figureCaption confidence="0.999984">
Figure 1: The proposed framework for event extraction from tweets.
</figureCaption>
<bodyText confidence="0.999955315789474">
Our work is similar to TwiCal in the sense that
we also focus on the extraction of structured repre-
sentation of events from Twitter. However, TwiCal
relies on a supervised sequence labeler trained
on tweets annotated with event mentions for the
identification of event-related phrases. We pro-
pose a simple Bayesian modelling approach which
is able to directly extract event-related keywords
from tweets without supervised learning. Also,
TwiCal uses G2 test to choose an entity y with
the strongest association with a date d to form a
binary tuple (y, d) to represent an event. On the
contrary, the structured representation of events
can be directly extracted from the output of our
LEM model. We have conducted experiments on
a Twitter corpus and the results show that our pro-
posed approach outperforms TwiCal, the state-of-
the-art open event extraction system, by 7.7% in
F-measure.
</bodyText>
<sectionHeader confidence="0.996479" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999949714285714">
Events extracted in our proposed framework are
represented as a 4-tuple (y, d,l, k), where y stands
for a non-location named entity, d for a date, l for a
location, and k for an event-related keyword. Each
event mentioned in tweets can be closely depicted
by this representation. It should be noted that for
some events, one or more elements in their corre-
sponding tuples might be absent as their related in-
formation is not available in tweets. As illustrated
in Figure 1, our proposed framework consists of
three main steps, pre-processing, event extraction
based on the LEM model and post-processing.
The details of our proposed framework are de-
scribed below.
</bodyText>
<subsectionHeader confidence="0.998979">
2.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.999946761904762">
Tweets are pre-processed by time expression
recognition, named entity recognition, POS tag-
ging and stemming.
Time Expression Recognition. Twitter users
might represent the same date in various forms.
For example, “tomorrow”, “next Monday”, “ Au-
gust 23th” in tweets might all refer to the same
day, depending on the date that users wrote the
tweets. To resolve the ambiguity of the time ex-
pressions, SUTime1 (Chang and Manning, 2012)
is employed, which takes text and a reference date
as input and outputs a more accurate date which
the time expression refers to.
Named Entity Recognition. Named entity
recognition (NER) is a crucial step since the
results would directly impact the final extracted
4-tuple (y, d,l, k). It is not easy to accurately
identify named entities in the Twitter data since
tweets contain a lot of misspellings and abbrevi-
ations. However, it is often observed that events
mentioned in tweets are also reported in news
articles in the same period (Petrovic et al., 2013).
Therefore, named entities mentioned in tweets are
likely to appear in news articles as well. We thus
perform named entity recognition in the following
way. First, a traditional NER tool such as the
Stanford Named Entity Recognizer2 is used to
identify named entities from the news articles
crawled from BBC and CNN during the same
period that the tweets were published. The recog-
nised named entities from news are then used to
build a dictionary. Named entities from tweets
are extracted by looking up the dictionary through
fuzzy matching. We have also used a named
entity tagger trained specifically on the Twitter
data3 (Ritter et al., 2011) to directly extract named
entities from tweets. However, as will be shown
in Section 3 that using our constructed dictionary
for named entity extraction gives better results.
We distinguish between location entities, denoted
as l, and non-location entities such as person or
organization, denoted as y.
</bodyText>
<footnote confidence="0.9971376">
1http://nlp.stanford.edu/software/
sutime.shtml
2http://nlp.stanford.edu/software/
CRF-NER.shtml
3http://github.com/aritter/twitter-nlp
</footnote>
<page confidence="0.996464">
701
</page>
<bodyText confidence="0.999968909090909">
Finally, we use a POS tagger4 trained on
tweets (Gimpel et al., 2011) to perform POS tag-
ging on the tweets data and apart from the pre-
viously recognised named entities, only words
tagged with nouns, verbs or adjectives are kept.
These remaining words are subsequently stemmed
and words occurred less than 3 times are filtered.
After the pre-processing step, non-location enti-
ties y, locations l, dates d and candidate keywords
of the tweets are collected as the input to the LEM
model for event extraction.
</bodyText>
<subsectionHeader confidence="0.999502">
2.2 Event Extraction using the Latent Event
Model (LEM)
</subsectionHeader>
<bodyText confidence="0.998948733333333">
We propose an unsupervised latent variable model,
called the Latent Event Model (LEM), to extract
events from tweets. The graphical model of LEM
is shown in Figure 2.
In this model, we assume that each tweet mes-
sage m E {1..M} is assigned to one event in-
stance e, while e is modeled as a joint distribution
over the named entities y, the date/time d when
the event occurred, the location l where the event
occurred and the event-related keywords k. This
assumption essentially encourages events that in-
volve the same named entities, occur at the same
time and in the same location and have similar
keyword to be assigned with the same event.
The generative process of LEM is shown below.
</bodyText>
<listItem confidence="0.973010833333333">
• Draw the event distribution πe —
Dirichlet(α)
• For each event e E {1..E}, draw multino-
mial distributions θe — Dirichlet(β), ϕe —
Dirichlet(γ), ψe — Dirichlet(η), ωe —
Dirichlet(λ).
</listItem>
<footnote confidence="0.530798">
4http://www.ark.cs.cmu.edu/TweetNLP
</footnote>
<listItem confidence="0.874754666666667">
• For each tweet w
– Choose an event e — Multinomial(π),
– For each named entity occur in tweet
</listItem>
<bodyText confidence="0.829005">
w, choose a named entity y —
Multinomial(θe),
– For each date occur in tweet w, choose
a date d — Multinomial(ϕe),
</bodyText>
<listItem confidence="0.807943">
– For each location occur in tweet w,
choose a location l — Multinomial(ψe),
– For other words in tweet w, choose a
</listItem>
<bodyText confidence="0.976959285714286">
word k — Multinomial(ωe).
We use Collapsed Gibbs Sampling (Griffiths
and Steyvers, 2004) to infer the parameters of the
model and the latent class assignments for events,
given observed data D and the total likelihood.
Gibbs sampling allows us repeatedly sample from
a Markov chain whose stationary distribution is
the posterior of em from the distribution over that
variable given the current values of all other vari-
ables and the data. Such samples can be used to
empirically estimate the target distribution. Let-
ting the subscript —m denote a quantity that ex-
cludes data from mth tweet , the conditional pos-
terior for em is:
</bodyText>
<equation confidence="0.999388857142857">
P(em = t|e−m, y, d, l, z, A) a n−m
t + α
M X
+ Ea
(m)
Qb t,1 (nt,y − b + β) X
Qn(m)
b=1 (nt − b + Yβ)
t
(m)
Qb t,1 (nt,l − b + η) X
Qn(m)
b=1 (nt − b + Lη)
t
</equation>
<bodyText confidence="0.999531944444444">
where nt is the number of tweets that have been
assigned to the event t; M is the total number of
tweets, nt,y is the number of times named entity y
has been associated with event t; nt,d is the num-
ber of times dates d has been associated with event
t; nt,l is the number of times locations l has been
assigned with event t; nt,k is the number of times
keyword k has associated with event t, counts with
(m) notation denote the counts relating to tweet
m only. Y, D, L, V are the total numbers of dis-
tinct named entities, dates, locations, and words
appeared in the whole Twitter corpus respectively.
E is the total number of events which needs to be
set.
Once the class assignments for all events are
known, we can easily estimate the model param-
eters {π, θ, ϕ,ψ, ω}. We set the hyperparame-
ters α = β = γ = η = λ = 0.5 and run Gibbs
</bodyText>
<figureCaption confidence="0.980214">
Figure 2: Laten Event Model (LEM).
</figureCaption>
<figure confidence="0.844213606060606">
y
e 9) w w
R r I �
d l k
Į
X
e
N M
E
Y
Y
y=1
L
XY
l=1
Qn(m)
b=1 (nt,k − b + λ)
t,k
Qn(m)
b=1 (nt − b + V λ)
t
V
Y
k=1
Qn(m)
b=1 (nt,d − b + γ)
t,d
Qn(m)
b=1 (nt − b + Dγ)
t
D
Y
d=1
</figure>
<page confidence="0.991677">
702
</page>
<bodyText confidence="0.999971666666667">
sampler for 10,000 iterations and stop the iteration
once the log-likelihood of the training data con-
verges under the learned model. Finally we select
an entity, a date, a location, and the top 2 keywords
of the highest probability of every event to form a
4-tuple as the representation of that event.
</bodyText>
<subsectionHeader confidence="0.999828">
2.3 Post-processing
</subsectionHeader>
<bodyText confidence="0.999978857142857">
To improve the precision of event extraction, we
remove the least confident event element from the
4-tuples using the following rule. If P(element)
is less than 1ξP(5), where P(5) is the sum of
probabilities of the other three elements and ξ is a
threshold value and is set to 5 empirically, the ele-
ment will be removed from the extracted results.
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999986666666667">
In this section, we first describe the Twitter corpus
used in our experiments and then present how we
build a baseline based on the previously proposed
TwiCal system (Ritter et al., 2012), the state-of-
the-art open event extraction system on tweets. Fi-
nally, we present our experimental results.
</bodyText>
<subsectionHeader confidence="0.991469">
3.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999985434782609">
We use the First Story Detection (FSD)
dataset (Petrovic et al., 2013) in our experi-
ment. It consists of 2,499 tweets which are
manually annotated with the corresponding event
instances resulting in a total of 27 events. The
tweets were published between 7th July and 12th
September 2011. These events cover a range of
categories, from celebrity news to accidents, and
from natural disasters to science discoveries. It
should be noted here that some event elements
such as location is not always available in the
tweets. Automatically inferring geolocation of the
tweets is a challenging task and will be considered
in our future work. For the tweets without time
expressions, we used the tweets’ publication dates
as a default. The number of tweets for each event
ranges from 2 to around 1000. We believe that in
reality, events which are mentioned in very few
tweets are less likely to be significant. Therefore,
the dataset was filtered by removing the events
which are mentioned in less than 10 tweets. This
results in a final dataset containing 2468 tweets
annotated with 21 events.
</bodyText>
<subsectionHeader confidence="0.998305">
3.2 Baseline construction
</subsectionHeader>
<bodyText confidence="0.999996222222222">
The baseline we chose is TwiCal (Ritter et al.,
2012). The events extracted in the baseline are
represented as a 3-tuple (y, d, k)5, where y stands
for a non-location named entity, d for a date and
k for an event phrase. We re-implemented the
system and evaluate the performance of the base-
line on the correctness of the exacted three ele-
ments excluding the location element. In the base-
line approach, the tuple (y, d, k) are extracted in
the following ways. Firstly, a named entity rec-
ognizer (Ritter et al., 2011) is employed to iden-
tify named entities. The TempEx (Mani and Wil-
son, 2000) is used to resolve temporal expressions.
For each date, the baseline approach chose the en-
tity y with the strongest association with the date
and form the binary tuple (y, d) to represent an
event. An event phrase extractor trained on an-
notated tweets is required to extract event-related
phrases. Due to the difficulties of re-implementing
the sequence labeler without knowing the actual
features set and the annotated training data, we as-
sume all the event-related phrases are identified
correctly and simply use the event trigger words
annotated in the FSD corpus as k to form the event
3-tuples. It is worth noting that the F-measure re-
ported for the event phrase extraction is only 64%
in the baseline approach (Ritter et al., 2012).
</bodyText>
<subsectionHeader confidence="0.999445">
3.3 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999626333333333">
To evaluate the performance of the propose ap-
proach, we use precison, recall, and F −
measure as in general information extraction sys-
tems (Makhoul et al., 1999). For the 4-tuple
(y, d,l, k), the precision is calculated based on the
following criteria:
</bodyText>
<listItem confidence="0.841228666666667">
1. Do the entity y, location l and date d that we
have extracted refer to the same event?
2. Are the keywords k in accord with the event
that other extracted elements y,l, d refer to
and are they informative enough to tell us
what happened?
</listItem>
<bodyText confidence="0.9993862">
If the extracted representation does not contain
keywords, its precision is calculated by check-
ing the criteria 1. If the extracted representation
contains keywords, its precision is calculated by
checking both criteria 1 and 2.
</bodyText>
<subsectionHeader confidence="0.992366">
3.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9998055">
The number of events, E, in the LEM model
is set to 25. The performance of the proposed
</bodyText>
<footnote confidence="0.992472">
5TwiCal also groups event instances into event types such
as ”Sport” or ”Politics” using LinkLDA which is not consid-
ered here.
</footnote>
<page confidence="0.99274">
703
</page>
<table confidence="0.9997435">
Method Tuple Evaluated Precision Recall F-measure
Baseline (y, d, k) 75% 76.19% 75.59%
Proposed (y, d, l) 96% 80.95% 87.83%
Proposed (y, d,l, k) 92% 76.19% 83.35%
</table>
<tableCaption confidence="0.956184">
Table 1: Comparison of the performance of event
extraction on the FSD dataset.
</tableCaption>
<table confidence="0.99995">
Method Tuple Evaluated Precision Recall
0 0 0 0 0
in a � co ie
TW-NER (y, d, l) 88% 76.19%
TW-NER (y, d,l, k) 84% 76.19%
NW-NER (y, d, l) 96% 80.95%
NW-NER (y, d,l, k) 92% 76.19%
</table>
<tableCaption confidence="0.949896">
Table 2: Comparison of the performance of event
extraction using different NER method.
</tableCaption>
<bodyText confidence="0.834321">
ber of events E so long as E is set to a relatively
larger value.
</bodyText>
<figure confidence="0.697723">
F-measure
80.35%
79.90%
87.83%
83.35%
� 8� 8� �
rtformance
</figure>
<bodyText confidence="0.998949555555556">
framework is presented in Table 1. The base-
line re-implemented here can only output 3-tuples
(y, d, k) and we simply use the gold standard event
trigger words to assign to k. Still, we observe
that compared to the baseline approach, the per-
formance of our proposed framework evaluated on
the 4-tuple achieves nearly 17% improvement on
precision. The overall improvement on F-measure
is around 7.76%.
</bodyText>
<subsectionHeader confidence="0.985864">
3.5 Impact of Named Entity Recognition
</subsectionHeader>
<bodyText confidence="0.9999952">
We experimented with two approaches for named
entity recognition (NER) in preprocessing. One
is to use the NER tool trained specifically on the
Twitter data (Ritter et al., 2011), denoted as “TW-
NER” in Table 2. The other uses the traditional
Stanford NER to extract named entities from news
articles published in the same period and then
perform fuzzy matching to identify named enti-
ties from tweets. The latter method is denoted
as “NW-NER” in Table 2. It can be observed
from Table 2 that by using NW-NER, the per-
formance of event extraction system is improved
significantly by 7.5% and 3% respectively on F-
measure when evaluated on 3-tuples (without key-
words) or 4-tuples (with keywords).
</bodyText>
<subsectionHeader confidence="0.995702">
3.6 Impact of the Number of Events E
</subsectionHeader>
<bodyText confidence="0.9997829">
We need to set the number of events E in the
LEM model. Figure 3 shows the performance of
event extraction versus different value of E. It can
be observed that the performance of the proposed
framework improves with the increase of the value
of E until it reaches 25, which is close to the actual
number of events in our data. If further increasing
E, we notice more balanced precision/recall val-
ues and a relatively stable F-measure. This shows
that our LEM model is less sensitive to the num-
</bodyText>
<figureCaption confidence="0.9739825">
Figure 3: The performance of the proposed frame-
work with different number of events E.
</figureCaption>
<sectionHeader confidence="0.998842" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999697380952381">
In this paper we have proposed an unsupervised
Bayesian model, called the Latent Event Model
(LEM), to extract the structured representation of
events from social media data. Instead of em-
ploying labeled corpora for training, the proposed
model only requires the identification of named
entities, locations and time expressions. After that,
the model can automatically extract events which
involving a named entity at certain time, location,
and with event-related keywords based on the co-
occurrence patterns of the event elements. Our
proposed model has been evaluated on the FSD
corpus. Experimental results show our proposed
framework outperforms the state-of-the-art base-
line by over 7% in F-measure. In future work,
we plan to investigate inferring geolocations au-
tomatically from tweets. We also intend to study
a better method to infer date more accurately from
tweets and explore efficient ranking strategies to
rank evens extracted for a better presentation of
results.
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997510888888889">
This work was funded by the National Natural
Science Foundation of China (61103077), Ph.D.
Programs Foundation of Ministry of Education
of China for Young Faculties (20100092120031),
Scientific Research Foundation for the Returned
Overseas Chinese Scholars, State Education Min-
istry, the Fundamental Research Funds for the
Central Universities, and the UK’s EPSRC grant
EP/L010690/1.
</bodyText>
<page confidence="0.997164">
704
</page>
<sectionHeader confidence="0.996346" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999910909090909">
Edward Benson, Aria Haghighi, and Regina Barzilay.
2011. Event discovery in social media feeds. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages
389–398, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Angel X. Chang and Christopher D. Manning. 2012.
Sutime: A library for recognizing and normaliz-
ing time expressions. In 8th International Confer-
ence on Language Resources and Evaluation (LREC
2012).
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of ACL.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. In Proceedings of the Na-
tional Academy of Sciences 101 (Suppl. 1), page
5228C5235.
Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s english ace 2005 system description.
In ACE 05 Evaluation Workshop.
Frederik Hogenboom, Flavius Frasincar, Uzay Kay-
mak, and Franciska de Jong. 2011. An overview of
event extraction from text. In Workshop on Detec-
tion, Representation, and Exploitation of Events in
the Semantic Web (DeRiVE 2011) at Tenth Interna-
tional Semantic Web Conference (ISWC2011), pages
48–57.
Xiaohua Liu, Xiangyang Zhou, Zhongyang Fu, Furu
Wei, and Ming Zhou. 2012. Exacting social events
for tweets using a factor graph. In Proceedings of
the Twenty-Sixth AAAI Conference on Artificial In-
telligence, pages 1692–1698.
John Makhoul, Francis Kubala, Richard Schwartz, and
Ralph Weischedel. 1999. Performance measures for
information extraction. In Proceedings of DARPA
Broadcast News Workshop.
Inderjeet Mani and George Wilson. 2000. Robust tem-
poral processing of news. In Proceedings of the
38th Annual Meeting on Association for Computa-
tional Linguistics, ACL ’00, pages 69–76, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Sasa Petrovic, Miles Osborne, Richard McCreadie,
Craig Macdonald, Iadh Ounis, and Luke Shrimpton.
2013. Can twitter replace newswire for breaking
news? In Proceedings of ICWSM’13.
J. Piskorski, H. Tanev, and P. Oezden Wennerberg.
2007. Extracting violent events from on-line news
for ontology population. In Business Information
Systems, pages 287–300.
J. Piskorski, H. Tanev, M. Atkinson, and E. Van
Der Goot. 2008. Cluster-centric approach to news
event extraction. In International Conference on
New Trends in Multimedia and Network Information
Systems, pages 276–290.
Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011.
Named entity recognition in tweets: an experimental
study. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1524–1534. Association for Computational Linguis-
tics.
Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.
2012. Open domain event extraction from twitter.
In Proceedings of the 18th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and
Data Mining, KDD ’12, pages 1104–1112, New
York, NY, USA. ACM.
H. Tanev, J. Piskorski, and M. Atkinson. 2008. Real-
time news event extraction for global crisis monitor-
ing. In 13th International Conference on Applica-
tions of Natural Language to Information Systems
(NLDB), pages 207–218.
</reference>
<page confidence="0.998564">
705
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.339781">
<title confidence="0.949304">A Simple Bayesian Modelling Approach to Event Extraction from Twitter</title>
<affiliation confidence="0.90289375">of Computer Science and Engineering, Key Laboratory of Computer and Information Integration, Ministry of Education, Southeast University, Key Laboratory for Novel Software Technology, Nanjing University, of Engineering and Applied Science, Aston University,</affiliation>
<email confidence="0.763002">d.zhou@seu.edu.cn,cly1cn@126.com,y.he@cantab.net</email>
<abstract confidence="0.988986904761905">With the proliferation of social media sites, social streams have proven to contain the most up-to-date information on current events. Therefore, it is crucial to extract events from the social streams such as tweets. However, it is not straightforward to adapt the existing event extraction systems since texts in social media are fragmented and noisy. In this paper we propose a simple and yet effective Bayesian model, called Latent Event Model (LEM), to extract structured representation of events from social media. LEM is fully unsupervised and does not require annotated data for training. We evaluate LEM on a Twitter corpus. Experimental results show that the proposed model achieves 83% in F-measure, and outperforms the state-of-the-art baseline by over 7%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Edward Benson</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Event discovery in social media feeds.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>389--398</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2980" citStr="Benson et al., 2011" startWordPosition="458" endWordPosition="461">s reported in (Petrovic et al., 2013), even 1% of the public stream of Twitter contains around 95% of all the events reported in the newswire. Nevertheless, the social stream data such as Twitter data pose new challenges. Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches. Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages (Benson et al., 2011). In (Liu et al., 2012), social events involving two persons are extracted from multiple similar tweets using a factor graph by harvesting the redundancy in tweets. Ritter et al. (2012) presented a system called TwiCal which extracts an open-domain calendar of significant events represented by a 4-tuple set including a named entity, event phrase, calendar date, and event type from Twitter. In our work here, we notice a very important property in social media data that the same event could be referenced by high volume messages. This property allows us resort to statistical models that can group</context>
</contexts>
<marker>Benson, Haghighi, Barzilay, 2011</marker>
<rawString>Edward Benson, Aria Haghighi, and Regina Barzilay. 2011. Event discovery in social media feeds. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 389–398, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>Sutime: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In 8th International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="6646" citStr="Chang and Manning, 2012" startWordPosition="1048" endWordPosition="1051">mework consists of three main steps, pre-processing, event extraction based on the LEM model and post-processing. The details of our proposed framework are described below. 2.1 Pre-processing Tweets are pre-processed by time expression recognition, named entity recognition, POS tagging and stemming. Time Expression Recognition. Twitter users might represent the same date in various forms. For example, “tomorrow”, “next Monday”, “ August 23th” in tweets might all refer to the same day, depending on the date that users wrote the tweets. To resolve the ambiguity of the time expressions, SUTime1 (Chang and Manning, 2012) is employed, which takes text and a reference date as input and outputs a more accurate date which the time expression refers to. Named Entity Recognition. Named entity recognition (NER) is a crucial step since the results would directly impact the final extracted 4-tuple (y, d,l, k). It is not easy to accurately identify named entities in the Twitter data since tweets contain a lot of misspellings and abbreviations. However, it is often observed that events mentioned in tweets are also reported in news articles in the same period (Petrovic et al., 2013). Therefore, named entities mentioned i</context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel X. Chang and Christopher D. Manning. 2012. Sutime: A library for recognizing and normalizing time expressions. In 8th International Conference on Language Resources and Evaluation (LREC 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>In Proceedings of the National Academy of Sciences</booktitle>
<volume>101</volume>
<pages>5228--5235</pages>
<contexts>
<context position="10183" citStr="Griffiths and Steyvers, 2004" startWordPosition="1628" endWordPosition="1631"> the event distribution πe — Dirichlet(α) • For each event e E {1..E}, draw multinomial distributions θe — Dirichlet(β), ϕe — Dirichlet(γ), ψe — Dirichlet(η), ωe — Dirichlet(λ). 4http://www.ark.cs.cmu.edu/TweetNLP • For each tweet w – Choose an event e — Multinomial(π), – For each named entity occur in tweet w, choose a named entity y — Multinomial(θe), – For each date occur in tweet w, choose a date d — Multinomial(ϕe), – For each location occur in tweet w, choose a location l — Multinomial(ψe), – For other words in tweet w, choose a word k — Multinomial(ωe). We use Collapsed Gibbs Sampling (Griffiths and Steyvers, 2004) to infer the parameters of the model and the latent class assignments for events, given observed data D and the total likelihood. Gibbs sampling allows us repeatedly sample from a Markov chain whose stationary distribution is the posterior of em from the distribution over that variable given the current values of all other variables and the data. Such samples can be used to empirically estimate the target distribution. Letting the subscript —m denote a quantity that excludes data from mth tweet , the conditional posterior for em is: P(em = t|e−m, y, d, l, z, A) a n−m t + α M X + Ea (m) Qb t,1</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. In Proceedings of the National Academy of Sciences 101 (Suppl. 1), page 5228C5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>David Westbrook</author>
<author>Adam Meyers</author>
</authors>
<title>Nyu’s english ace 2005 system description.</title>
<date>2005</date>
<booktitle>In ACE 05 Evaluation Workshop.</booktitle>
<contexts>
<context position="1776" citStr="Grishman et al., 2005" startWordPosition="270" endWordPosition="273">el achieves 83% in F-measure, and outperforms the state-of-the-art baseline by over 7%. 1 Introduction Event extraction is to automatically identify events from text with information about what happened, when, where, to whom, and why. Previous work in event extraction has focused largely on news articles, as the newswire texts have been the best source of information on current events (Hogenboom et al., 2011). Approaches for event extraction include knowledge-based (Piskorski et al., 2007; Tanev et al., 2008), data-driven (Piskorski et al., 2008) and a combination of the above two categories (Grishman et al., 2005). Knowledgebased approaches often rely on linguistic and lexicographic patterns which represent expert domain knowledge for particular event types. They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. Datadriven approaches require large annotated data to train statistical models that approximate linguistic phenomena. Nevertheless, it is expensive to obtain annotated data in practice. With the increasing popularity of social media, social networking sites such as Twitter have become an important source of event information. As reported in (P</context>
</contexts>
<marker>Grishman, Westbrook, Meyers, 2005</marker>
<rawString>Ralph Grishman, David Westbrook, and Adam Meyers. 2005. Nyu’s english ace 2005 system description. In ACE 05 Evaluation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederik Hogenboom</author>
<author>Flavius Frasincar</author>
<author>Uzay Kaymak</author>
<author>Franciska de Jong</author>
</authors>
<title>An overview of event extraction from text.</title>
<date>2011</date>
<booktitle>In Workshop on Detection, Representation, and Exploitation of Events in the Semantic Web (DeRiVE 2011) at Tenth International Semantic Web Conference (ISWC2011),</booktitle>
<pages>48--57</pages>
<marker>Hogenboom, Frasincar, Kaymak, de Jong, 2011</marker>
<rawString>Frederik Hogenboom, Flavius Frasincar, Uzay Kaymak, and Franciska de Jong. 2011. An overview of event extraction from text. In Workshop on Detection, Representation, and Exploitation of Events in the Semantic Web (DeRiVE 2011) at Tenth International Semantic Web Conference (ISWC2011), pages 48–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Xiangyang Zhou</author>
<author>Zhongyang Fu</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
</authors>
<title>Exacting social events for tweets using a factor graph.</title>
<date>2012</date>
<booktitle>In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>1692--1698</pages>
<contexts>
<context position="3003" citStr="Liu et al., 2012" startWordPosition="463" endWordPosition="466"> al., 2013), even 1% of the public stream of Twitter contains around 95% of all the events reported in the newswire. Nevertheless, the social stream data such as Twitter data pose new challenges. Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches. Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages (Benson et al., 2011). In (Liu et al., 2012), social events involving two persons are extracted from multiple similar tweets using a factor graph by harvesting the redundancy in tweets. Ritter et al. (2012) presented a system called TwiCal which extracts an open-domain calendar of significant events represented by a 4-tuple set including a named entity, event phrase, calendar date, and event type from Twitter. In our work here, we notice a very important property in social media data that the same event could be referenced by high volume messages. This property allows us resort to statistical models that can group similar events based o</context>
</contexts>
<marker>Liu, Zhou, Fu, Wei, Zhou, 2012</marker>
<rawString>Xiaohua Liu, Xiangyang Zhou, Zhongyang Fu, Furu Wei, and Ming Zhou. 2012. Exacting social events for tweets using a factor graph. In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, pages 1692–1698.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Makhoul</author>
<author>Francis Kubala</author>
<author>Richard Schwartz</author>
<author>Ralph Weischedel</author>
</authors>
<title>Performance measures for information extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of DARPA Broadcast News Workshop.</booktitle>
<contexts>
<context position="15553" citStr="Makhoul et al., 1999" startWordPosition="2621" endWordPosition="2624"> to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event trigger words annotated in the FSD corpus as k to form the event 3-tuples. It is worth noting that the F-measure reported for the event phrase extraction is only 64% in the baseline approach (Ritter et al., 2012). 3.3 Evaluation Metric To evaluate the performance of the propose approach, we use precison, recall, and F − measure as in general information extraction systems (Makhoul et al., 1999). For the 4-tuple (y, d,l, k), the precision is calculated based on the following criteria: 1. Do the entity y, location l and date d that we have extracted refer to the same event? 2. Are the keywords k in accord with the event that other extracted elements y,l, d refer to and are they informative enough to tell us what happened? If the extracted representation does not contain keywords, its precision is calculated by checking the criteria 1. If the extracted representation contains keywords, its precision is calculated by checking both criteria 1 and 2. 3.4 Experimental Results The number of</context>
</contexts>
<marker>Makhoul, Kubala, Schwartz, Weischedel, 1999</marker>
<rawString>John Makhoul, Francis Kubala, Richard Schwartz, and Ralph Weischedel. 1999. Performance measures for information extraction. In Proceedings of DARPA Broadcast News Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>George Wilson</author>
</authors>
<title>Robust temporal processing of news.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL ’00,</booktitle>
<pages>69--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14630" citStr="Mani and Wilson, 2000" startWordPosition="2465" endWordPosition="2469">ents. 3.2 Baseline construction The baseline we chose is TwiCal (Ritter et al., 2012). The events extracted in the baseline are represented as a 3-tuple (y, d, k)5, where y stands for a non-location named entity, d for a date and k for an event phrase. We re-implemented the system and evaluate the performance of the baseline on the correctness of the exacted three elements excluding the location element. In the baseline approach, the tuple (y, d, k) are extracted in the following ways. Firstly, a named entity recognizer (Ritter et al., 2011) is employed to identify named entities. The TempEx (Mani and Wilson, 2000) is used to resolve temporal expressions. For each date, the baseline approach chose the entity y with the strongest association with the date and form the binary tuple (y, d) to represent an event. An event phrase extractor trained on annotated tweets is required to extract event-related phrases. Due to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event trigger words annotated in the FSD corpus as k to form the event 3-tuples.</context>
</contexts>
<marker>Mani, Wilson, 2000</marker>
<rawString>Inderjeet Mani and George Wilson. 2000. Robust temporal processing of news. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL ’00, pages 69–76, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasa Petrovic</author>
<author>Miles Osborne</author>
<author>Richard McCreadie</author>
<author>Craig Macdonald</author>
<author>Iadh Ounis</author>
<author>Luke Shrimpton</author>
</authors>
<title>Can twitter replace newswire for breaking news?</title>
<date>2013</date>
<booktitle>In Proceedings of ICWSM’13.</booktitle>
<contexts>
<context position="2397" citStr="Petrovic et al., 2013" startWordPosition="362" endWordPosition="365">). Knowledgebased approaches often rely on linguistic and lexicographic patterns which represent expert domain knowledge for particular event types. They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. Datadriven approaches require large annotated data to train statistical models that approximate linguistic phenomena. Nevertheless, it is expensive to obtain annotated data in practice. With the increasing popularity of social media, social networking sites such as Twitter have become an important source of event information. As reported in (Petrovic et al., 2013), even 1% of the public stream of Twitter contains around 95% of all the events reported in the newswire. Nevertheless, the social stream data such as Twitter data pose new challenges. Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches. Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages (Benson et al., 2011). In (Liu et al.,</context>
<context position="7207" citStr="Petrovic et al., 2013" startWordPosition="1142" endWordPosition="1145">ty of the time expressions, SUTime1 (Chang and Manning, 2012) is employed, which takes text and a reference date as input and outputs a more accurate date which the time expression refers to. Named Entity Recognition. Named entity recognition (NER) is a crucial step since the results would directly impact the final extracted 4-tuple (y, d,l, k). It is not easy to accurately identify named entities in the Twitter data since tweets contain a lot of misspellings and abbreviations. However, it is often observed that events mentioned in tweets are also reported in news articles in the same period (Petrovic et al., 2013). Therefore, named entities mentioned in tweets are likely to appear in news articles as well. We thus perform named entity recognition in the following way. First, a traditional NER tool such as the Stanford Named Entity Recognizer2 is used to identify named entities from the news articles crawled from BBC and CNN during the same period that the tweets were published. The recognised named entities from news are then used to build a dictionary. Named entities from tweets are extracted by looking up the dictionary through fuzzy matching. We have also used a named entity tagger trained specifica</context>
<context position="12996" citStr="Petrovic et al., 2013" startWordPosition="2187" endWordPosition="2190"> following rule. If P(element) is less than 1ξP(5), where P(5) is the sum of probabilities of the other three elements and ξ is a threshold value and is set to 5 empirically, the element will be removed from the extracted results. 3 Experiments In this section, we first describe the Twitter corpus used in our experiments and then present how we build a baseline based on the previously proposed TwiCal system (Ritter et al., 2012), the state-ofthe-art open event extraction system on tweets. Finally, we present our experimental results. 3.1 Dataset We use the First Story Detection (FSD) dataset (Petrovic et al., 2013) in our experiment. It consists of 2,499 tweets which are manually annotated with the corresponding event instances resulting in a total of 27 events. The tweets were published between 7th July and 12th September 2011. These events cover a range of categories, from celebrity news to accidents, and from natural disasters to science discoveries. It should be noted here that some event elements such as location is not always available in the tweets. Automatically inferring geolocation of the tweets is a challenging task and will be considered in our future work. For the tweets without time expres</context>
</contexts>
<marker>Petrovic, Osborne, McCreadie, Macdonald, Ounis, Shrimpton, 2013</marker>
<rawString>Sasa Petrovic, Miles Osborne, Richard McCreadie, Craig Macdonald, Iadh Ounis, and Luke Shrimpton. 2013. Can twitter replace newswire for breaking news? In Proceedings of ICWSM’13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>H Tanev</author>
<author>P Oezden Wennerberg</author>
</authors>
<title>Extracting violent events from on-line news for ontology population.</title>
<date>2007</date>
<booktitle>In Business Information Systems,</booktitle>
<pages>287--300</pages>
<contexts>
<context position="1647" citStr="Piskorski et al., 2007" startWordPosition="249" endWordPosition="252">oes not require annotated data for training. We evaluate LEM on a Twitter corpus. Experimental results show that the proposed model achieves 83% in F-measure, and outperforms the state-of-the-art baseline by over 7%. 1 Introduction Event extraction is to automatically identify events from text with information about what happened, when, where, to whom, and why. Previous work in event extraction has focused largely on news articles, as the newswire texts have been the best source of information on current events (Hogenboom et al., 2011). Approaches for event extraction include knowledge-based (Piskorski et al., 2007; Tanev et al., 2008), data-driven (Piskorski et al., 2008) and a combination of the above two categories (Grishman et al., 2005). Knowledgebased approaches often rely on linguistic and lexicographic patterns which represent expert domain knowledge for particular event types. They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. Datadriven approaches require large annotated data to train statistical models that approximate linguistic phenomena. Nevertheless, it is expensive to obtain annotated data in practice. With the increasing popularity</context>
</contexts>
<marker>Piskorski, Tanev, Wennerberg, 2007</marker>
<rawString>J. Piskorski, H. Tanev, and P. Oezden Wennerberg. 2007. Extracting violent events from on-line news for ontology population. In Business Information Systems, pages 287–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>H Tanev</author>
<author>M Atkinson</author>
<author>E Van Der Goot</author>
</authors>
<title>Cluster-centric approach to news event extraction.</title>
<date>2008</date>
<booktitle>In International Conference on New Trends in Multimedia and Network Information Systems,</booktitle>
<pages>276--290</pages>
<marker>Piskorski, Tanev, Atkinson, Van Der Goot, 2008</marker>
<rawString>J. Piskorski, H. Tanev, M. Atkinson, and E. Van Der Goot. 2008. Cluster-centric approach to news event extraction. In International Conference on New Trends in Multimedia and Network Information Systems, pages 276–290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: an experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1524--1534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7853" citStr="Ritter et al., 2011" startWordPosition="1249" endWordPosition="1252">s mentioned in tweets are likely to appear in news articles as well. We thus perform named entity recognition in the following way. First, a traditional NER tool such as the Stanford Named Entity Recognizer2 is used to identify named entities from the news articles crawled from BBC and CNN during the same period that the tweets were published. The recognised named entities from news are then used to build a dictionary. Named entities from tweets are extracted by looking up the dictionary through fuzzy matching. We have also used a named entity tagger trained specifically on the Twitter data3 (Ritter et al., 2011) to directly extract named entities from tweets. However, as will be shown in Section 3 that using our constructed dictionary for named entity extraction gives better results. We distinguish between location entities, denoted as l, and non-location entities such as person or organization, denoted as y. 1http://nlp.stanford.edu/software/ sutime.shtml 2http://nlp.stanford.edu/software/ CRF-NER.shtml 3http://github.com/aritter/twitter-nlp 701 Finally, we use a POS tagger4 trained on tweets (Gimpel et al., 2011) to perform POS tagging on the tweets data and apart from the previously recognised nam</context>
<context position="14555" citStr="Ritter et al., 2011" startWordPosition="2452" endWordPosition="2455">is results in a final dataset containing 2468 tweets annotated with 21 events. 3.2 Baseline construction The baseline we chose is TwiCal (Ritter et al., 2012). The events extracted in the baseline are represented as a 3-tuple (y, d, k)5, where y stands for a non-location named entity, d for a date and k for an event phrase. We re-implemented the system and evaluate the performance of the baseline on the correctness of the exacted three elements excluding the location element. In the baseline approach, the tuple (y, d, k) are extracted in the following ways. Firstly, a named entity recognizer (Ritter et al., 2011) is employed to identify named entities. The TempEx (Mani and Wilson, 2000) is used to resolve temporal expressions. For each date, the baseline approach chose the entity y with the strongest association with the date and form the binary tuple (y, d) to represent an event. An event phrase extractor trained on annotated tweets is required to extract event-related phrases. Due to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event</context>
<context position="17609" citStr="Ritter et al., 2011" startWordPosition="2979" endWordPosition="2982">ce framework is presented in Table 1. The baseline re-implemented here can only output 3-tuples (y, d, k) and we simply use the gold standard event trigger words to assign to k. Still, we observe that compared to the baseline approach, the performance of our proposed framework evaluated on the 4-tuple achieves nearly 17% improvement on precision. The overall improvement on F-measure is around 7.76%. 3.5 Impact of Named Entity Recognition We experimented with two approaches for named entity recognition (NER) in preprocessing. One is to use the NER tool trained specifically on the Twitter data (Ritter et al., 2011), denoted as “TWNER” in Table 2. The other uses the traditional Stanford NER to extract named entities from news articles published in the same period and then perform fuzzy matching to identify named entities from tweets. The latter method is denoted as “NW-NER” in Table 2. It can be observed from Table 2 that by using NW-NER, the performance of event extraction system is improved significantly by 7.5% and 3% respectively on Fmeasure when evaluated on 3-tuples (without keywords) or 4-tuples (with keywords). 3.6 Impact of the Number of Events E We need to set the number of events E in the LEM </context>
</contexts>
<marker>Ritter, Clark, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011. Named entity recognition in tweets: an experimental study. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1524–1534. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Oren Etzioni Mausam</author>
<author>Sam Clark</author>
</authors>
<title>Open domain event extraction from twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’12,</booktitle>
<pages>1104--1112</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3165" citStr="Ritter et al. (2012)" startWordPosition="489" endWordPosition="492">as Twitter data pose new challenges. Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches. Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages (Benson et al., 2011). In (Liu et al., 2012), social events involving two persons are extracted from multiple similar tweets using a factor graph by harvesting the redundancy in tweets. Ritter et al. (2012) presented a system called TwiCal which extracts an open-domain calendar of significant events represented by a 4-tuple set including a named entity, event phrase, calendar date, and event type from Twitter. In our work here, we notice a very important property in social media data that the same event could be referenced by high volume messages. This property allows us resort to statistical models that can group similar events based on the cooccurrence patterns of their event elements. Here, event elements include named entities such as person, company, organization, date/time, location, and t</context>
<context position="12806" citStr="Ritter et al., 2012" startWordPosition="2157" endWordPosition="2160">orm a 4-tuple as the representation of that event. 2.3 Post-processing To improve the precision of event extraction, we remove the least confident event element from the 4-tuples using the following rule. If P(element) is less than 1ξP(5), where P(5) is the sum of probabilities of the other three elements and ξ is a threshold value and is set to 5 empirically, the element will be removed from the extracted results. 3 Experiments In this section, we first describe the Twitter corpus used in our experiments and then present how we build a baseline based on the previously proposed TwiCal system (Ritter et al., 2012), the state-ofthe-art open event extraction system on tweets. Finally, we present our experimental results. 3.1 Dataset We use the First Story Detection (FSD) dataset (Petrovic et al., 2013) in our experiment. It consists of 2,499 tweets which are manually annotated with the corresponding event instances resulting in a total of 27 events. The tweets were published between 7th July and 12th September 2011. These events cover a range of categories, from celebrity news to accidents, and from natural disasters to science discoveries. It should be noted here that some event elements such as locatio</context>
<context position="14093" citStr="Ritter et al., 2012" startWordPosition="2369" endWordPosition="2372">olocation of the tweets is a challenging task and will be considered in our future work. For the tweets without time expressions, we used the tweets’ publication dates as a default. The number of tweets for each event ranges from 2 to around 1000. We believe that in reality, events which are mentioned in very few tweets are less likely to be significant. Therefore, the dataset was filtered by removing the events which are mentioned in less than 10 tweets. This results in a final dataset containing 2468 tweets annotated with 21 events. 3.2 Baseline construction The baseline we chose is TwiCal (Ritter et al., 2012). The events extracted in the baseline are represented as a 3-tuple (y, d, k)5, where y stands for a non-location named entity, d for a date and k for an event phrase. We re-implemented the system and evaluate the performance of the baseline on the correctness of the exacted three elements excluding the location element. In the baseline approach, the tuple (y, d, k) are extracted in the following ways. Firstly, a named entity recognizer (Ritter et al., 2011) is employed to identify named entities. The TempEx (Mani and Wilson, 2000) is used to resolve temporal expressions. For each date, the ba</context>
<context position="15368" citStr="Ritter et al., 2012" startWordPosition="2590" endWordPosition="2593">ssociation with the date and form the binary tuple (y, d) to represent an event. An event phrase extractor trained on annotated tweets is required to extract event-related phrases. Due to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event trigger words annotated in the FSD corpus as k to form the event 3-tuples. It is worth noting that the F-measure reported for the event phrase extraction is only 64% in the baseline approach (Ritter et al., 2012). 3.3 Evaluation Metric To evaluate the performance of the propose approach, we use precison, recall, and F − measure as in general information extraction systems (Makhoul et al., 1999). For the 4-tuple (y, d,l, k), the precision is calculated based on the following criteria: 1. Do the entity y, location l and date d that we have extracted refer to the same event? 2. Are the keywords k in accord with the event that other extracted elements y,l, d refer to and are they informative enough to tell us what happened? If the extracted representation does not contain keywords, its precision is calcul</context>
</contexts>
<marker>Ritter, Mausam, Clark, 2012</marker>
<rawString>Alan Ritter, Mausam, Oren Etzioni, and Sam Clark. 2012. Open domain event extraction from twitter. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’12, pages 1104–1112, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tanev</author>
<author>J Piskorski</author>
<author>M Atkinson</author>
</authors>
<title>Realtime news event extraction for global crisis monitoring.</title>
<date>2008</date>
<booktitle>In 13th International Conference on Applications of Natural Language to Information Systems (NLDB),</booktitle>
<pages>207--218</pages>
<contexts>
<context position="1668" citStr="Tanev et al., 2008" startWordPosition="253" endWordPosition="256">d data for training. We evaluate LEM on a Twitter corpus. Experimental results show that the proposed model achieves 83% in F-measure, and outperforms the state-of-the-art baseline by over 7%. 1 Introduction Event extraction is to automatically identify events from text with information about what happened, when, where, to whom, and why. Previous work in event extraction has focused largely on news articles, as the newswire texts have been the best source of information on current events (Hogenboom et al., 2011). Approaches for event extraction include knowledge-based (Piskorski et al., 2007; Tanev et al., 2008), data-driven (Piskorski et al., 2008) and a combination of the above two categories (Grishman et al., 2005). Knowledgebased approaches often rely on linguistic and lexicographic patterns which represent expert domain knowledge for particular event types. They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. Datadriven approaches require large annotated data to train statistical models that approximate linguistic phenomena. Nevertheless, it is expensive to obtain annotated data in practice. With the increasing popularity of social media, soc</context>
</contexts>
<marker>Tanev, Piskorski, Atkinson, 2008</marker>
<rawString>H. Tanev, J. Piskorski, and M. Atkinson. 2008. Realtime news event extraction for global crisis monitoring. In 13th International Conference on Applications of Natural Language to Information Systems (NLDB), pages 207–218.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>