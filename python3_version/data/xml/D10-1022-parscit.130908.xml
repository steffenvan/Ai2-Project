<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.832225">
Negative Training Data can be Harmful to Text Classification
</title>
<author confidence="0.996115">
Xiao-Li Li Bing Liu See-Kiong Ng
</author>
<affiliation confidence="0.992278">
Institute for Infocomm Research University of Illinois at Chicago Institute for Infocomm Research
</affiliation>
<address confidence="0.8965135">
1 Fusionopolis Way #21-01, 851 South Morgan Street, 1 Fusionopolis Way #21-01,
Connexis Singapore 138632 Chicago, IL 60607-7053, USA Connexis Singapore 138632
</address>
<email confidence="0.993965">
xlli@i2r.a-star.edu.sg liub@cs.uic.edu skng@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.994645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999641956521739">
This paper studies the effects of training data
on binary text classification and postulates
that negative training data is not needed and
may even be harmful for the task. Traditional
binary classification involves building a clas-
sifier using labeled positive and negative
training examples. The classifier is then ap-
plied to classify test instances into positive
and negative classes. A fundamental assump-
tion is that the training and test data are iden-
tically distributed. However, this assumption
may not hold in practice. In this paper, we
study a particular problem where the positive
data is identically distributed but the negative
data may or may not be so. Many practical
text classification and retrieval applications fit
this model. We argue that in this setting nega-
tive training data should not be used, and that
PU learning can be employed to solve the
problem. Empirical evaluation has been con-
ducted to support our claim. This result is im-
portant as it may fundamentally change the
current binary classification paradigm.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999138">
Text classification is a well-studied problem in
machine learning, natural language processing, and
information retrieval. To build a text classifier, a
set of training documents is first labeled with pre-
defined classes. Then, a supervised machine learn-
ing algorithm (e.g., Support Vector Machines
(SVM), naïve Bayesian classifier (NB)) is applied
to the training examples to build a classifier that is
subsequently employed to assign class labels to the
instances in the test set. In this paper, we focus on
binary text classification with two classes (i.e. pos-
itive and negative classes).
Most learning methods assume that the training
and test data have identical distributions. However,
this assumption may not hold in practice, i.e., the
training and the test distributions can be different.
The problem is called covariate shift or sample
selection bias (Heckman 1979; Shimodaira 2000;
Zadrozny 2004; Huang et al. 2007; Sugiyama et al.
2008; Bickel et al. 2009). In general, this problem
is not solvable because the two distributions can be
arbitrarily far apart from each other. Various as-
sumptions were made to solve special cases of the
problem. One main assumption was that the condi-
tional distribution of the class given an instance is
the same over the training and test sets (Shimodai-
ra 2000; Huang et al. 2007; Bickel et al. 2009).
In this paper, we study another special case of
the problem in which the positive training and test
samples have identical distributions, but the nega-
tive training and test samples may have different
distributions. We believe this scenario is more ap-
plicable for binary text classification. As the focus
in many applications is on identifying positive in-
stances correctly, it is important that the positive
training and the positive test data have the same
distribution. The distributions of the negative train-
ing and negative test data can be different. We be-
lieve that this special case of the sample selection
bias problem is also more applicable for machine
learning. We will show that a partially supervised
learning model, called PU learning (learning from
Positive and Unlabeled examples) fits this special
case quite well (Liu et al. 2002).
Following the notations in (Bickel et al. 2009),
our special case of the sample selection bias prob-
lem can be formulated as follows: We are given a
training sample matrix XL with row vectors x1, ...,
xk. The positive and negative training instances are
governed by different unknown distributions p(x|λ)
</bodyText>
<page confidence="0.966191">
218
</page>
<note confidence="0.8176755">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 218–228,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999943176470589">
and p(x|δ) respectively. The element yi of vector y
= (y1, y2, ..., yk) is the class label for training in-
stance xi (yi ∈{+1, -1}, where +1 and -1 denote
positive and negative classes respectively) and is
drawn based on an unknown target concept p(y|x).
In addition, we are also given an unlabeled test set
in matrix XT with rows xk+1, ..., xk+m. The (hidden)
positive test instances in XT are also governed by
the unknown distribution p(x|λ), but the (hidden)
negative test instances in XT are governed by an
unknown distribution, p(x|θ), where θ may or may
not be the same as δ. p(x|θ) and p(x|δ) can differ
arbitrarily, but there is only one unknown target
conditional class distribution p(y|x).
This problem setting is common in many appli-
cations, especially in those applications where the
user is interested in identifying a particular type of
documents (i.e. binary text classification). For ex-
ample, we want to find sentiment analysis papers
in the literature. For training a text classifier, we
may label the papers in some EMNLP proceedings
as sentiment analysis (positive) and non-sentiment
analysis (negative) papers. A classifier can then be
built to find sentiment analysis papers from ACL
and other EMNLP proceedings. However, this la-
beled training set will not be appropriate for identi-
fying sentiment analysis papers from the WWW,
KDD and SIGIR conference proceedings. This is
because although the sentiment analysis papers in
these proceedings are similar to those in the train-
ing data, the non-sentiment analysis papers in these
conferences can be quite different. Another exam-
ple is email spam detection. A spam classification
system built using the training data of spam and
non-spam emails from a university may not per-
form well in a company. The reason is that al-
though the spam emails (e.g., unsolicited
commercial ads) are similar in both environments,
the non-spam emails in them can be quite different.
One can consider labeling the negative data in
each environment individually so that only the
negative instances relevant to the testing environ-
ment are used to train the classifier. However, it is
often impractical (if not impossible) to do so. For
example, given a large blog hosting site, we want
to classify its blogs into those that discuss stock
markets (positive), and those that do not (nega-
tive). In this case, the negative data covers an arbi-
trary range of topics. It is clearly impractical to
label all the negative data.
Most existing methods for addressing the sam-
ple selection bias problem work as follows. First,
they estimate the bias of the training data based on
the given test data using statistical methods. Then,
a classifier is trained on a weighted version of the
original training set based on the estimated bias. In
this paper, we show that our special case of the
sample selection bias problem can be solved in a
much simpler and somewhat radical manner—by
simply discarding the negative training data alto-
gether. We can use the positive training data and
the unlabeled test data to build the classifier using
the PU learning model (Liu et al. 2002).
PU learning was originally proposed to solve the
learning problem where no labeled negative train-
ing data exist. Several algorithms have been devel-
oped in the past few years that can learn from a set
of labeled positive examples augmented with a set
of unlabeled examples. That is, given a set P of
positive examples of a particular class (called the
positive class) and a set U of unlabeled examples
(which contains both hidden positive and hidden
negative examples), a classifier is built using P and
U to classify the data in U as well as future test
data into two classes, i.e., those belonging to P
(positive) and those not belonging to P (negative).
In this paper, we also propose a new PU learning
method which gives more consistently accurate
results than the current methods.
Our experimental evaluation shows that when
the distributions of the negative training and test
samples are different, PU learning is much more
accurate than traditional supervised learning from
the positive and negative training samples. This
means that the negative training data actually
harms classification in this case. In addition, when
the distributions of the negative training and test
samples are identical, PU learning is shown to per-
form equally well as supervised learning, which
means that the negative training data is not needed.
This paper thus makes three contributions. First,
it formulates a new special case of the sample se-
lection bias problem, and proposes to solve the
problem using PU learning by discarding the nega-
tive training data. Second, it proposes a new PU
learning method which is more accurate than the
existing methods. Third, it experimentally demon-
strates the effectiveness of the proposed method
and shows that negative training data is not needed
and can even be harmful. This result is important
as it may fundamentally change the way that many
practical classification problems should be solved.
</bodyText>
<page confidence="0.999364">
219
</page>
<sectionHeader confidence="0.99971" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99975">
A key assumption made by most machine learning
algorithms is that the training and test samples
must be drawn from the same distribution. As
mentioned, this assumption can be violated in prac-
tice. Some researchers have addressed this problem
under covariate shift or sample selection bias.
Sample selection bias was first introduced in the
econometrics by Heckman (1979). It came into the
field of machine learning through the work of Za-
drozny (2004). The main approach in machine
learning is to first estimate the distribution bias of
the training data based on the test data, and then
learn using weighted training examples to compen-
sate for the bias (Bickel et al. 2009).
Shimodaira (2000) and Sugiyama and Muller
(2005) proposed to estimate the training and test
data distributions using kernel density estimation.
The estimated density ratio could then be used to
generate weighted training examples. Dudik et al.
(2005) and Bickel and Scheffer (2007) used maxi-
mum entropy density estimation, while Huang et
al. (2007) proposed kernel mean matching. Su-
giyama et al. (2008) and Tsuboi et al. (2008) esti-
mated the weights for the training instances by
minimizing the Kullback-Leibler divergence be-
tween the test and the weighted training distribu-
tions. Bickel et al. (2009) proposed an integrated
model. In this paper, we adopt an entirely different
approach by dropping the negative training data
altogether in learning. Without the negative train-
ing data, we use PU learning to solve the problem
(Liu et al. 2002; Yu et al. 2002; Denis et al. 2002;
Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003;
Denis et al. 2003; Li et al. 2007; Elkan and Noto,
2008; Li et al. 2009; Li et al. 2010). We will dis-
cuss this learning model further in Section 3.
Another related work to ours is transfer learning
or domain adaptation. Unlike our problem setting,
transfer learning addresses the scenario where one
has little or no training data for the target domain,
but has ample training data in a related domain
where the data could be in a different feature space
and follow a different distribution. A survey of
transfer learning can be found in (Pan and Yang
2009). Several NLP researchers have studied trans-
fer learning for different applications (Wu et al.
2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009;
Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser
&amp; Roth 2008; Li and Zong 2008; Andrew et al.
2008; Chan and Ng 2007; Jiang and Zhai 2007;
Zhou et al. 2006), but none of them addresses the
problem studied here.
</bodyText>
<sectionHeader confidence="0.975556" genericHeader="method">
3 PU Learning Techniques
</sectionHeader>
<bodyText confidence="0.999939371428571">
In traditional supervised learning, ideally, there is a
large number of labeled positive and negative ex-
amples for learning. In practice, the negative ex-
amples can often be limited or unavailable. This
has motivated the development of the model of
learning from positive and unlabeled examples, or
PU learning, where P denotes a set of positive ex-
amples, and U a set of unlabeled examples (which
contains both hidden positive and hidden negative
instances). The PU learning problem is to build a
classifier using P and U in the absence of negative
examples to classify the data in U or a future test
data T. In our setting, the test set T will also act as
the unlabeled set U.
PU learning has been investigated by several re-
searchers in the past decade. A study of PAC learn-
ing for the setting under the statistical query model
was given in (Denis, 1998). Liu et al. reported the
sample complexity result and showed how the
problem may be solved (Liu et al., 2002). Subse-
quently, a number of practical algorithms (e.g., Liu
et al., 2002; Yu et al., 2002; Li and Liu, 2003)
were proposed. They generally follow a two-step
strategy: (i) identifying a set of reliable negative
documents RN from the unlabeled set; and then (ii)
building a classifier using P (positive set), RN (re-
liable negative set) and U-RN (unlabelled set) by
applying an existing learning algorithm (such as
naive Bayesian classifier or SVM) iteratively.
There are also some other approaches based on
unbalanced errors (e.g., Liu et al. 2003; Lee and
Liu, 2003; Elkan and Noto, 2008).
In this section, we first introduce a representa-
tive PU learning technique S-EM, and then present
a new technique called CR-SVM.
</bodyText>
<subsectionHeader confidence="0.986361">
3.1 S-EM Algorithm
</subsectionHeader>
<bodyText confidence="0.798328125">
S-EM (Liu et al. 2002) is based on naïve Bayesian
classification (NB) (Lewis, 1995; Nigam et al.,
2000) and the EM algorithm (Dempster et al.
1977). It has two steps. The first step uses a spy
technique to identify some reliable negatives (RN)
from the unlabeled set U and the second step uses
the EM algorithm to learn a Bayesian classifier
from P, RN and U–RN.
</bodyText>
<page confidence="0.995908">
220
</page>
<tableCaption confidence="0.5022335">
Step 1: Extracting reliable negatives RN from U
using a spy technique
</tableCaption>
<bodyText confidence="0.9992696">
The spy technique in S-EM works as follows (Fig-
ure 1): First, a small set of positive examples (de-
noted by SP) called “spies” is randomly sampled
from P (line 2). The default sampling ratio in S-
EM is s = 15%. Then, an NB classifier is built us-
ing P–SP as the positive set and U∪SP as the neg-
ative set (lines 3-5). The NB classifier is applied to
classify each u E U∪SP, i.e., to assign a probabil-
istic class label p(+|u) (+ means positive) to u. The
idea of the spy technique is as follows. Since the
spy examples were from P and were put into U as
negatives in building the NB classifier, they should
behave similarly to the hidden positive instances in
U. We thus can use them to find the reliable nega-
tive set RN from U. Using the probabilistic labels
of spies in SP and an input parameter l (noise lev-
el), a probability threshold t is determined. Due to
space constraints, we are unable to explain l. De-
tails can be found in (Liu et al. 2002). t is then used
to find RN from U (lines 8-10).
</bodyText>
<listItem confidence="0.9859923">
1. RN +- 0; // Reliable negative set
2. SP +- Sample(P, s%); // spy set
3. Assign each example in P – SP the class label +1;
4. Assign each example in U USP the class label -1;
5. C +-NB(P – SP, UUSP); // Produce a NB classifier
6. Classify each u EUUSP using C;
7. Decide a probability threshold t using SP and l;
8. For each u EU do
9. If its probability p(+|u) &lt; t then
10. RN +- RN U {u};
</listItem>
<figureCaption confidence="0.759594">
Figure 1. Spy technique for extracting RN from U
Step 2: Learning using the EM algorithm
</figureCaption>
<bodyText confidence="0.999859">
Given the positive set P, the reliable negative set
RN, and the remaining unlabeled set U–RN, we run
EM using NB as the base learning algorithm.
The naive Bayesian (NB) method is an effective
text classification algorithm. There are two differ-
ent NB models, namely, the multinomial NB and
the multi-variate Bernoulli NB. In this paper, we
use the multinomial NB since it has been observed
to perform consistently better than the multi-
variate Bernoulli NB (Nigam et al., 2000).
Given a set of training documents D, each doc-
ument di E D is an ordered list of words. We use
wdi,k to denote the word in position k of di, where
each word is from the vocabulary V = {w1, ... , w|v|},
which is the set of all words considered in classifi-
</bodyText>
<listItem confidence="0.984020588235294">
1. Each document in P is assigned the class label 1;
2. Each document in RN is assigned the class label −1;
3. Learn an initial NB classifier f from P and RN, us-
ing Equations (1) and (2);
4. Repeat
5. For each document di in U-RN do // E-Step
6. Using the current classifier f compute
Pr(cj|di) using Equation (3);
7. Learn a new NB classifier f from P, RN and U-
RN by computing Pr(cj) and Pr(wt|cj), using
Equations (1) and (2); // M-Step
8. Until the classifier parameters stabilize
9. The last iteration of EM gives the final classifier f ;
10. For each document di in U do
11. If its probability Pr(+|di) &gt;! 0.5 then
12. Output di as a positive document;
13. else Output di as a negative document
</listItem>
<figureCaption confidence="0.999456">
Figure 2. EM algorithm with the NB classifier
</figureCaption>
<bodyText confidence="0.9997738">
cation. We also have a set of classes C = {c1, c2}
representing positive and negative classes. For
classification, we compute the posterior probability
Pr(cj|di). Based on the Bayes rule and multinomial
model, we have
</bodyText>
<equation confidence="0.9840944375">
l:i=1Pr(cj  |di
 ||
D
and with Laplacian smoothing,
Pr(
wt cj) = 1+ V  |+Z�
� i
|;1|D|
|D|
1N(wt, di)Pr(cj  |di)
N(ws, di)Pr(cj  |di )
wt occurs in document di, and
E
0,1}
Pr(cj|di)
{
</equation>
<bodyText confidence="0.9971994">
de-
pending on the class label of the document. As-
suming that probabilities of words are independent
given the class, we have the NB classifier:
where N(wt,di) is the number of times that the word
</bodyText>
<equation confidence="0.997265285714286">
Pr(cj)�Ik
1Pr(
wd„k
i|
|
cj
E
</equation>
<bodyText confidence="0.992730846153846">
EM (Dempster et al. 1977) is a popular class of
iterative algorithms for maximum likelihood esti-
mation in problems with incomplete data. It is of-
ten used to address missing values in the data by
computing expected values using the existing val-
ues. The EM algorithm consists of two steps, the
E-step an
d the M-step. The E-step fills in the miss-
ing data, and M-step re-estimated the parameters.
This process is iterated till satisfaction (i.e. con-
vergence). For NB, the steps used by EM are iden-
tical to those used to build the classifier (equations
(3) for the E-step, and equations (1) and (2) for the
</bodyText>
<equation confidence="0.99711915">
Pr(cj  |di) =
1Pr(
|r=|
cr)�
P r( |
w c
= d k r
,
k 1 i
)
)
(3)
|
|di
=
Pr
( cj)
 ||
D
)
</equation>
<page confidence="0.982264">
221
</page>
<bodyText confidence="0.997656142857143">
M-step). In EM, Pr(cj|di) takes the value in [0, 1]
instead of {0, 1} in all the three equations.
The algorithm for the second step of S-EM is
given in Figure 2. Lines 1-3 build a NB classifier f
using P and RN. Lines 4-8 run EM until conver-
gence. Finally, the converged classifier is used to
classify the unlabeled set U (lines 10-13).
</bodyText>
<subsectionHeader confidence="0.996596">
3.2 Proposed CR-SVM
</subsectionHeader>
<bodyText confidence="0.981369717391305">
As we will see in the experiment section, the per-
formance of S-EM can be weak in some cases.
This is due to the mixture model assumption of its
NB classifier (Nigam et al. 2000), which requires
that the mixture components and classes be of one-
to-one correspondence. Intuitively, this means that
each class should come from a distinctive distribu-
tion rather than a mixture of multiple distributions.
In our setting, however, the negative class often
has documents of mixed topics, e.g., representing
the broad class of everything else except the top-
ic(s) represented by the positive class.
There are some existing PU learning methods
based on SVM which can deal with this problem,
e.g., Roc-SVM (Li and Liu, 2003). Like S-EM,
Roc-SVM also has two steps. The first step uses
Rocchio classification (Rocchio, 1971) to find a set
of reliable negatives RN from U. In particular, this
method treats the entire unlabeled set U as negative
documents and then uses the positive set P and the
unlabeled set U as the training data to build a Roc-
chio classifier. The classifier is subsequently ap-
plied to classify the unlabeled set U. Those
documents that are classified as negative are then
considered as reliable negative examples RN. The
second step of Roc-SVM runs SVM iteratively
(instead of EM). Unlike NB, SVM does not make
any distributional assumption.
However, Roc-SVM does not do well due to the
weakness of its first step in finding a good set of
reliable negatives RN. This motivates us to propose
a new SVM based method CR-SVM to detect a
better quality RN set. The second step of CR-SVM
is similar to that in Roc-SVM.
Step 1: Extracting reliable negatives RN from U
using Cosine and Rocchio
The first step of the proposed CR-SVM algorithm
for finding a RN set consists of two sub-steps:
Sub-step 1 (extracting the potential negative set
PN using the cosine similarity): Given the positive
set P and the unlabeled set U, we extract a set of
potential negatives PN from U by computing the
similarities of the unlabeled documents in U and
the positive documents in P. The idea is that those
documents in U that are very dissimilar to the doc-
uments in P are likely to be negative.
</bodyText>
<listItem confidence="0.99827">
1. PN = ∅;
2. Represent each document in P and U as vectors us-
ing the TF-IDF representation;
3. For each dj ∈ P do
</listItem>
<equation confidence="0.8542848">
vector d =
...,
using the TF-IDF scheme
(Salton 1986). Each element
(i=1, 2, ..., n) in d
</equation>
<bodyText confidence="0.9949215625">
represents a word feature
A positive representa-
tive vector (pr) is built by summing up the docu-
ments in P and normalizing it (lines 3-5). Lines 6-7
compute the similarities of each document
in P
with pr using the cosine similarity, cos(pr,
Line 8 sorts the documents in P according to
their cos(pr, dj) values. We want to filter away as
many as possible hidden positive documents from
U so that we can obtain a very pure negative set.
Since the hidden positives in U should have the
same behaviors as the positives in P in terms of
their similarities to pr, we set their minimum simi-
larity as the threshold value
which is the mini-
</bodyText>
<figure confidence="0.95138958974359">
mum similari
(q1,q2,
qn)
qi
wi.
dj
dj).
ω
ty before a document is considered as
a potential negative document:
 ||
P
=min cos (pr,dj), d
ω
∈ P
j
1
4. pr = pr /
r 2
5. For each
P do
6. compute cos(pr, dj) using Equation (4);
7. Sort all the documents
according to cos(pr, dj)
in decreasing order;
= cos(pr, dp) where
is ranked in the position of
(1-
||
p
;
dj∈
dj∈P
ω
dp
l)*|P|;
9. For each di ∈ U do
10. If cos(pr, di)&lt; ω then
11. PN = PN ∪{di}
</figure>
<figureCaption confidence="0.993226">
Figure 3. Extracting potential negatives PN from U
</figureCaption>
<bodyText confidence="0.781971">
The detailed algorithm is given in Figure 3.
Each document in P and U is first represented as a
In a noiseless scenario, using the minimum simi-
larity is acceptable. However, most real-life appli-
cations contain outliers and noisy artifacts. Using
the absolute minimum similarity may be unrelia-
ble; the similarity cos(pr, dj) of an
outlier docu-
</bodyText>
<figure confidence="0.995556357142857">
|
d
j
=
|
pr
 |P
1
P  |j=
2
1   |
d j
(4)
=
</figure>
<page confidence="0.950942">
222
</page>
<listItem confidence="0.992393333333333">
1. RN = ∅;
2. Represent each document in P, PN and U as vectors
using the TF-IDF representation;
</listItem>
<equation confidence="0.995378111111111">
p =α − ∑

P d
1 d 1 d
d ∈P j d ∈ PN
∑ β
j i i
j i
PN d ;
</equation>
<listItem confidence="0.981231">
4. For each di ∈ U do
5. If cos(di, n)&gt; cos(di, p) then
6. RN = RN ∪ {di}
</listItem>
<figureCaption confidence="0.993257">
Figure 4. Identifying RN using the Rocchio classifier
</figureCaption>
<bodyText confidence="0.69604125">
uments in U (lines 5-7).
are parameters for
adjusting the relative impact of the positive and
negative examples. In this work, we use
</bodyText>
<equation confidence="0.8355924">
= 16 an
αand ,B
α
d
,B = 4 as recommended in (Buckley et al. 1994).
</equation>
<bodyText confidence="0.985689846153846">
Step 2: Learning by running SVM iteratively
This step is similar to that in Roc-SVM, building
ment
in P could be near 0 or smaller than most
(or even all) negative documents. It would there-
fore be prudent to ignore a small percentage
of
the documents in P most dissimilar to the repre-
sentative positive (pr) and assume them as noise or
outliers. Since we do not know the noise level of
the data, to be safe, we use a noise level
= 5% as
the default. The final classification result is not
sensitive to
as long as it is not too big. In line 9,
we use the noise level
to decide on a suitable
Then, for each document
in U, if its cosine simi-
larity cos(pr,
&lt; co, we regard it as a potential
negative and store it in PN (lines 10-12).
Our experiment results showed that PN is still
not sufficient or big enough for accurate PU learn-
ing. Thus, we need to do a bit more work to find
the fi
</bodyText>
<equation confidence="0.899245222222222">
dj
l
l
l
l
co.
di
di)
nal RN.
</equation>
<bodyText confidence="0.990399391304348">
Sub-step 2 (extracting the final reliable negative
set RN from U using Rocchio with PN): At this
point, we have a positive set P and a potential neg-
ative set PN where PN is a purer negative set than
U. To extract the final reliable negatives, we em-
ploy the Rocchio classification to build a classifier
RC using P and PN (We do not use SVM here as it
is very sensitive to the noise in PN). Those docu-
ments in U that are classified as negatives by RC
will then be regarded as reliable negatives, and
stored in set RN.
The algorithm for this sub-step is given in Fig-
ure 4. Following the Rocchio formula, a positive
and a negative prototype vectors p and n are built
(lines 3 and 4), which are used to classify the doc-
223 the final classifier by running SVM iteratively with
the sets P, RN and the remaining unlabeled set Q
The algorithm is given in Figure 5. We run
SVM classifiers Si (line 3) iteratively to extract
more and more negative documents from Q. The
iteration stops when no more negative documents
can be extracted from Q (line 5). There is, howev-
er,
in running SVM iteratively, as SVM is
quite sensitive to noise. It is possible that during
some iteration, SVM is misled by noisy data to
extract many positive documents from Q and put
them in the negative set RN. If this happens, the
final SVM classifier will be inferior. As such, we
employ a test to decide whether to keep the first
SVM classifier or the final one. To do so, we use
the final SVM classifier obtained at convergence
(called
line 9) to classify the positive set P to
see if many positive documents in P are classified
as negatives. Roc-SVM chooses 5% as the thre-
shold, so CR-SVM also uses this threshold. If there
are 5% of positive documents
in P that
are classified as negative, it indicates that SVM has
gone wrong and we should use the first SVM clas-
sifier
In our experience, the first classifier is
always quite strong; good results can therefore be
achieved even without catching the last (possibly
better) classifier.
The main difference between Roc-SVM and
CR-SVM is that Roc-SVM does not produce PN. It
simply treats the unlabeled set U as negatives for
extracting RN. Since PN is clearly a purer negative
set than U, the use of PN by CR-SVM helps ex-
tract
quality reliable negative set RN which
subsequently allows the final classifier of CR-
SVM to give better results than Roc-SVM.
Note that the methods (S-EM and CR-SVM) are
all two-step algorithms in which the first step and
the second step are independent of each other. The
algorithm for the second step basically needs a
good set of reliable negatives RN extracted from U.
This means that one can pick any algorithm for the
first step to work with any algorithm for the second
step. For example, we can also have CR-EM which
uses the algorithm (shown in Figures 3 and 4) of
the first step of CR-SVM to combine with the al-
gorithm of the second step of S-EM. CR-EM ac-
tually works quite well as it is also able to exploit
the more accurate reliable negative set RN ex-
tracted using cosine an
</bodyText>
<figure confidence="0.515108666666667">
(Q = U – RN).
a danger
Slast,
(5%*|P|)
(S1).
a better
d Rocchio.
7. ;
1 d 1 d
n β
i j
= α ∑ − ∑ ∈
 ||
PN i   |
d P j
    |d
d ∈ PN i d P j
||
</figure>
<sectionHeader confidence="0.954677" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.999983043478261">
We now present the experimental results to support
our claim that negative training data is not needed
and can even harm text classification. We also
show the effectiveness of the proposed PU learning
methods CR-SVM and CR-EM. The following
methods are compared: (1) traditional supervised
learning methods SVM and NB which use both
positive and negative training data; (2) PU learning
methods, including two existing methods S-EM
and Roc-SVM and two new methods CR-SVM and
CR-EM, and (3) one-class SVM (Schölkop et al.,
1999) where only positive training data is used in
learning (the unlabeled set is not used at all).
We used LIBSVM 1 for SVM and one-class
SVM, and two publicly available 2 PU learning
techniques S-EM and Roc-SVM. Note that we do
not compare with some other PU learning methods
such as those in (Liu et al. 2003, Lee and Liu, 2003
and Elkan and Noto, 2008) as the purpose of this
paper is not to find the best PU learning method
but to show that PU learning can address our spe-
cial sample selection bias problem. Our current
methods already do very well for this purpose.
</bodyText>
<subsectionHeader confidence="0.975639">
4.1 Datasets and Experimental Settings
</subsectionHeader>
<bodyText confidence="0.992047">
We used two well-known benchmark data collec-
tions for text classification, the Reuters-21578 col-
lection 3 and the 20 Newsgroup collection 4 .
Reuters-21578 contains 21578 documents. We
used the most populous 10 out of the 135 catego-
ries following the common practice of other re-
searchers. 20 Newsgroup has 11997 documents
from 20 discussion groups. The 20 groups were
also categorized into 4 main categories.
We have performed two sets of experiments,
and just used bag-of-words as features since our
objective in this paper is not feature engineering.
(1) Test set has other topic documents. This set
of experiments simulates the scenario in which the
negative training and test samples have different
distributions. We select positive, negative and oth-
er topic documents for Reuters and 20 Newsgroup,
and produce various data sets. Using these data
sets, we want to show that PU learning can do bet-
</bodyText>
<footnote confidence="0.9991875">
1 http://www.csie.ntu.edu.tw/~cjlin/libsvm/
2 http://www.cs.uic.edu/~liub/LPU/LPU-download.html
3 http://www.research.att.com/~lewis/reuters21578.html
4 http://people.csail.mit.edu/jrennie/20Newsgroups/
</footnote>
<listItem confidence="0.903647333333333">
1. Every document in P is assigned the class label +1;
2. Every document in RN is assigned the label –1;
3. Use P and RN to train a SVM classifier Si, with i =
1 initially and i = i+1 with each iteration (line 3-7);
4. Classify Q using Si. Let the set of documents in Q
that are classified as negative be W;
5. If (W = ∅) then stop;
6. else Q = Q – W;
7. RN = RN ∪W
8. goto (3);
9. Use the last SVM classifier Slast to classify P;
10. If more than 5% positives are classified as negative
</listItem>
<figure confidence="0.6462115">
11. then use S1 as the final classifier;
12. else use Slast as the final classifier;
</figure>
<figureCaption confidence="0.998996">
Figure 5. Constructing the final classifier using SVM
</figureCaption>
<bodyText confidence="0.99718175">
ter than traditional learning that uses both positive
and negative training data.
For the Reuters collection, each of the 10 cate-
gories is used as a positive class. We randomly
select one or two of the remaining categories as the
negative class (denoted by Neg 1 or Neg 2), and
then we randomly choose some documents from
the rest of the categories as other topic documents.
These other topic documents are regarded as nega-
tives and added to the test set but not to the nega-
tive training data. They thus introduce a different
distribution to the negative test data. We generated
20 data sets (10*2) for our experiments this way.
The 20 Newsgroup collection has 4 main cate-
gories with sub-categories5; the sub-categories in
the same main category are relatively similar to
each other. We are able to simulate two scenarios:
(1) the other topic documents are similar to the
negative class documents (similar case), and (2)
the other topic documents are quite different from
the negative class documents (different case). This
allows us to investigate whether the classification
results will be affected when the other topic docu-
ments are somewhat similar or vastly different
from the negative training set. To create the train-
ing and test data for our experiments, we randomly
select one sub-category from a main category (cat
1) as the positive class, and one (or two) sub-
category from another category (cat 2) as the nega-
tive class (again denoted by Neg 1 or Neg 2). For
the other topics, we randomly choose some docu-
5 The four main categories and their corresponding sub-
categories are: computer (graphics, os, ibmpc.hardware,
mac.hardware, windows.x), recreation (autos, motorcycles,
baseball, hockey), science (crypt, electronics, med, space), and
talk (politics.misc, politics.guns, politics.mideast, religion).
</bodyText>
<page confidence="0.995544">
224
</page>
<bodyText confidence="0.99777872">
ments from the remaining sub-categories of cat 2
for the similar case, and some documents from a
randomly chosen different category (cat 3) (as the
other topic documents) for the different case. We
generated 8 data sets (4*2) for the similar case,
and 8 data sets (4*2) for the different case.
The training and test sets are then constructed as
follows: we partition the positive (and similarly for
the negative) class documents into two standard
subsets: 70% for training and 30% for testing. In
order to create different experimental settings, we
vary the number of the other topic documents that
are added to the test set as negatives, controlled by
a parameter α, which is a percentage of |TN|, where
|TN |is the size of the negative test set without the
other topic documents. That is, the number of oth-
er topic documents added is α × |TN|.
(2) Test set has no other topic documents. This
set of experiments is the traditional classification
in which the training and test data have the same
distribution. We employ the same data sets as in
(1) but without having any other topic documents
in the test set. Here we want to show that PU learn-
ing can do equally well without using the negative
training data even in the traditional setting.
</bodyText>
<subsectionHeader confidence="0.9969785">
4.2 Results with Other Topic Documents in
Test Set
</subsectionHeader>
<bodyText confidence="0.999972777777778">
We show the results for experiment set (1), i.e. the
distributions of the negative training and test data
are different (caused by the inclusion of other topic
documents in the test set, or the addition of other
topic documents to complement existing negatives
in the test set). The evaluation metric is the F-score
on the positive class (Bollmann and Cherniavsky,
1981), which is commonly used for evaluating text
classification.
</bodyText>
<subsubsectionHeader confidence="0.814233">
4.2.1 Results on the Reuters data
</subsubsectionHeader>
<bodyText confidence="0.999171862068965">
Figure 6 shows the comparison results when the
negative class contains only one category of doc-
uments (Neg 1), while Figure 7 shows the results
when the negative class contains documents from
two categories (Neg 2) in the Reuters collection.
The data points in the figures are the averages of
the results from the corresponding datasets.
Our proposed method CR-SVM is shown to per-
form consistently better than the other techniques.
When the size of the other topic documents (x-
axis) in the test set increases, the F-scores of the
two traditional learning methods SVM and NB
decreased much more dramatically as compared
with the PU learning techniques. The traditional
learning models were clearly unable to handle dif-
ferent distributions for training and test data.
Among the PU learning techniques, the proposed
CR-SVM gave the best results consistently. Roc-
SVM did not do consistently well as it did not
manage to find high quality reliable negatives RN
sometimes. The EM based methods (CR-EM and
S-EM) performed well in the case when we had
only one negative class (Figure 6). However, it did
not do well in the situation where there were two
negative classes (Figure 7) due to the underlying
mixture model assumption of the naïve Bayesian
classifier. One-class SVM (OSVM) performed
poorly because it did not exploit the useful infor-
mation in the unlabeled set at all.
</bodyText>
<figureCaption confidence="0.9997415">
Figure 6. Results of Neg 1 using the Reuter data
Figure 7. Results of Neg 2 using the Reuter data
</figureCaption>
<subsubsectionHeader confidence="0.738739">
4.2.2 Results on 20 Newsgroup data
</subsubsectionHeader>
<bodyText confidence="0.896095333333333">
Recall that for the 20 Newsgroup data, we have
two settings: similar case and different case.
Similar case: Here, the other topic documents are
</bodyText>
<figure confidence="0.995350857142857">
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
F-score
0.9
0.8
0.7
0.6
1
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
e%*|TN |of other topic documents
F-score
0.9
0.8
0.7
0.6
0.5
1
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
e%*|TN |of other topic documents
</figure>
<page confidence="0.996308">
225
</page>
<bodyText confidence="0.999951705882353">
similar to the negative class documents, as they
belong to the same main category.
The comparison results are given in Figure 8
(Neg 1) and Figure 9 (Neg 2). We observe that
CR-EM, S-EM and CR-SVM all performed well.
EM based methods (CR-EM and S-EM) have a
slight edge over CR-SVM. Again, the F-scores of
the traditional supervised learning (SVM and NB)
deteriorated when more other topic documents
were added to the test set, while CR-EM, S-EM
and CR-SVM were able to remain unaffected and
maintained roughly constant F-scores. When the
negative class contained documents from two cate-
gories (Neg 2), the F-scores of the traditional
learning dropped even more rapidly. Both Roc-
SVM and One-class SVM (OSVM) performed
poorly, due to the same reasons given previously.
</bodyText>
<figureCaption confidence="0.95263775">
Figure 8. Results of Neg 1, similar case – using the 20
Newsgroup data
Figure 9. Results of Neg 2, similar case – using the 20
Newsgroup data
</figureCaption>
<bodyText confidence="0.995645">
Different case: In this case, the other topic docu-
ments are quite different from the negative class
documents, since they are originated from different
main categories.
The results are shown in Figures 10 (Neg 1) and
11 (Neg 2). The trends are similar to those for the
similar case, except that the performance of the
traditional supervised learning methods (SVM and
NB) dropped even more rapidly with more other
topic documents. As the other topic documents
have very different distributions from the negatives
in the training set in this case, they really confused
the traditional classifiers. In contrast, the three PU
learning techniques were still able to perform con-
sistently well, regardless of the number of other
topic documents added to the test data.
</bodyText>
<figureCaption confidence="0.9616315">
Figure 10. Results of Neg 1, different case – using the
20 Newsgroup data
Figure 11. Results of Neg 2, different case – using the
20 Newsgroup data
</figureCaption>
<bodyText confidence="0.99995725">
In summary, the results showed that learning
with negative training data based on the traditional
paradigm actually harms classification when the
identical distribution assumption does not hold.
</bodyText>
<subsectionHeader confidence="0.931172">
4.3 Results without Other Topic Documents in
Test Set
</subsectionHeader>
<bodyText confidence="0.972791">
Given an application, one may not know whether
</bodyText>
<figure confidence="0.999372525">
F-score
0.9
0.8
0.7
0.6
1
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
a%*|TN |of other topic documents
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
F-score
0.9
0.8
0.7
0.6
1
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
a%*|TN |of other topic documents
F-score
0.9
0.8
0.7
0.6
1
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
a%*|TN |of other topic documents
SVM NB OSVM S-EM
Roc-SVM CR-EM CR-SVM
F-score
0.9
0.8
0.7
0.6
1
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
a%*|TN |of other topic documents
</figure>
<page confidence="0.996766">
226
</page>
<bodyText confidence="0.999906">
the identical distribution assumption holds. The
above results showed that PU learning is better
when it does not hold. How about when the as-
sumption does hold? To find out, we compared the
results of SVM, NB, and three PU learning me-
thods using the datasets without any other topic
documents added to the test set. In this case, the
training and test data distributions are the same.
Table 1 shows the results for this scenario. Note
that for PU learning, the negative training data
were not used. The traditional supervised learning
techniques (SVM and NB), which made full use of
the positive and negative training data, only per-
formed just about 1-2% better than the PU learning
method CR-SVM (which is not statistically signifi-
cant based on paired t-test). This suggests that we
can do away with negative training data, since PU
learning can perform equally well without them.
This has practical importance since the full cover-
age of negative training data is hard to find and to
label in many applications.
From the results in Figures 6–11 and Table 1,
we can conclude that PU learning can be used for
binary text classification without the negative
training data (which can be harmful for the task).
CR-SVM is our recommended PU learning method
based on its generally consistent performance.
</bodyText>
<tableCaption confidence="0.974198">
Table 1. Comparison of methods without other docu-
ments in test set
</tableCaption>
<table confidence="0.999293285714286">
Methods Reuters Reuters 20News 20News
(Neg 1) (Neg 2) (Neg 1) (Neg 2)
SVM 0.971 0.964 0.988 0.990
NB 0.972 0.947 0.988 0.992
S-EM 0.952 0.921 0.974 0.975
CR-EM 0.955 0.897 0.983 0.986
CR-SVM 0.960 0.959 0.967 0.974
</table>
<sectionHeader confidence="0.999035" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999944617647059">
This paper studied a special case of the sample se-
lection bias problem in which the positive training
and test distributions are the same, but the negative
training and test distributions may be different. We
showed that in this case, the negative training data
should not be used in learning, and PU learning
can be applied to this setting. A new PU learning
algorithm (called CR-SVM) was also proposed to
overcome the weaknesses of the current two-step
algorithms.
Our experiments showed that the traditional
classification methods suffered greatly when the
distributions are different for the negative training
and test data, but PU learning does not. We also
showed that PU learning performed equally well in
the ideal case where the training and test data have
identical distributions. As such, it can be advanta-
geous to discard the potentially harmful negative
training data and use PU learning for classification.
In our future work, we plan to do more compre-
hensive experiments to compare the classic super-
vised learning and PU learning techniques with
different kinds of settings, for example, by varying
the ratio between positive and negative examples,
as well as their sizes. It is also important to explore
how to catch the best iteration of the SVM/NB
classifier in the iterative running process of the
algorithms. Finally, we would like to point out that
it is conceivable that negative training data could
still be useful in many cases. An interesting direc-
tion to explore is to somehow combine the ex-
tracted reliable negative data from the unlabeled
set and the existing negative training data to further
enhance learning algorithms.
</bodyText>
<sectionHeader confidence="0.998721" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997357">
Agirre E., Lacalle L.O. 2009. Supervised Domain Adap-
tion for WSD. Proceedings of the 12th Conference of
the European Chapter for Computational Linguistics
(EACL09), pp 42-50.
Andrew A., Nallapati R., Cohen W., 2008. Exploiting
Feature Hierarchy for Transfer Learning in Named
Entity Recognition, ACL.
Bickel, S., Bruckner, M., and Scheffer. 2009. T. Dis-
criminative learning under covariate shift. Journal of
Machine Learning Research.
Bickel S. and Scheffer T. 2007. Dirichlet-enhanced
spam filtering based on biased samples. In Advances
in Neural Information Processing Systems.
Bollmann, P.,&amp; Cherniavsky, V. 1981. Measurement-
theoretical investigation of the mz-metric. Informa-
tion Retrieval Research.
Buckley, C., Salton, G., &amp; Allan, J. 1994. The effect of
adding relevance information in a relevance feed-
back environment, SIGIR.
Blum, A. and Mitchell, T. 1998. Combining labeled and
unlabeled data with co-training. In Proc. of Compu-
tational Learning Theory, pp. 92–10.
Chan Y. S., Ng H. T. 2007. Domain Adaptation with
Active Learning for Word Sense Disambiguation,
ACL.
Dempster A., Laird N. and Rubin D.. 1977. Maximum
likelihood from incomplete data via the EM algorithm,
Journal of the Royal Statistical Society.
Denis F., PAC learning from positive statistical queries.
ALT, 1998.
</reference>
<page confidence="0.967577">
227
</page>
<reference confidence="0.999761266666666">
Denis F., Laurent A., Rémi G., Marc T. 2003. Text clas-
sification and co-training from positive and unlabeled
examples. ICML.
Denis, F, Rémi G, and Marc T. 2002. Text Classifica-
tion from Positive and Unlabeled Examples. In Pro-
ceedings of the 9th International Conference on
Information Processing and Management of Uncer-
tainty in Knowledge-Based Systems.
Downey, D., Broadhead, M. and Etzioni, O. 2007. Lo-
cating complex named entities in Web Text. IJCAI.
Dudik M., Schapire R., and Phillips S. 2005. Correcting
sample selection bias in maximum entropy density
estimation. In Advances in Neural Information Proc-
essing Systems.
Elkan, C. and Noto, K. 2008. Learning classifiers from
only positive and unlabeled data. KDD, 213-220.
Goldwasser, D., Roth D. 2008. Active Sample Selection
for Named Entity Transliteration, ACL.
Heckman J. 1979. Sample selection bias as a specifica-
tion error. Econometrica, 47:153–161.
Huang J., Smola A., Gretton A., Borgwardt K., and
Scholkopf B. 2007. Correcting sample selection bias
by unlabeled data. In Advances in Neural Informa-
tion Processing Systems.
Jiang J. and Zhai C. X. 2007. Instance Weighting for
Domain Adaptation in NLP, ACL.
Lee, W. S. and Liu, B. 2003. Learning with Positive and
Unlabeled Examples Using Weighted Logistic Re-
gression. ICML.
Lewis D. 1995. A sequential algorithm for training text
classifiers: corrigendum and additional data. SIGIR
Forum, 13-19.
Li, S., Zong C., 2008. Multi-Domain Sentiment Classifi-
cation, ACL.
Li, X., Liu, B. 2003. Learning to classify texts using
positive and unlabeled data, IJCAI.
Li, X., Liu, B., 2005. Learning from Positive and Unla-
beled Examples with Different Data Distributions.
ECML.
Li, X., Liu, B., 2007. Learning to Identify Unexpected
Instances in the Test Set. IJCAI.
Li, X., Yu, P. S., Liu B., and Ng, S. 2009. Positive
Unlabeled Learning for Data Stream Classification,
SDM.
Li, X., Zhang L., Liu B., and Ng, S. 2010. Distribution-
al Similarity vs. PU Learning for Entity Set Expan-
sion, ACL.
Liu, B, Dai, Y., Li, X., Lee, W-S., and Yu. P. 2003.
Building text classifiers using positive and unlabeled
examples. ICDM, 179-188.
Liu, B, Lee, W-S, Yu, P. S, and Li, X. 2002. Partially
supervised text classification. ICML, 387-394.
Nigam, K., McCallum, A., Thrun, S. and Mitchell, T.
2000. Text classification from labeled and unlabeled
documents using EM. Machine Learning, 39(2/3),
103–134.
Pan, S. J. and Yang, Q. 2009. A survey on transfer
learning. IEEE Transactions on Knowledge and Da-
ta Engineering, Vol. 99, No. 1.
Rocchio, J. 1971. Relevant feedback in information
retrieval. In G. Salton (ed.). The smart retrieval sys-
tem: experiments in automatic document processing,
Englewood Cliffs, NJ, 1971.Sagae K., Tsujii J. 2008.
Online Methods for Multi-Domain Learning and
Adaptation, EMNLP.
Salton G. and McGill M. J. 1986. Introduction to Mod-
ern Information Retrieval.
Schölkop f B., Platt J.C., Shawe-Taylor J., Smola A.J.,
and Williamson R.C. 1999. Estimating the support
of a high-dimensional distribution. Technical report,
Microsoft Research, MSR-TR-99-87.
Shimodaira H. 2000. Improving predictive inference
under covariate shift by weighting the log-likelihood
function. Journal of Statistical Planning and Infer-
ence, 90:227–244.
Sugiyama M. and Muller K.-R. 2005. Input-dependent
estimation of generalization error under covariate
shift. Statistics and Decision, 23(4):249–279.
Sugiyama M., Nakajima S., Kashima H., von Bunau P.,
and Kawanabe M. 2008. Direct importance estima-
tion with model selection and its application to co-
variate shift adaptation. In Advances in Neural
Information Processing Systems.
Tsuboi J., Kashima H., Hido S., Bickel S., and Sugi-
yama M. 2008. Direct density ratio estimation for
large-scale covariate shift adaptation. In Proceed-
ings of the SIAM International Conference on Data
Mining, 2008.
Wu D., Lee W.S., Ye N. and Chieu H. L. 2009. Domain
adaptive bootstrapping for named entity recognition,
ACL.
Wu Q., Tan S. and Cheng X. 2009. Graph Ranking for
Sentiment Transfer, ACL.
Yang Q., Chen Y., Xue G., Dai W., Yu Y. 2009. Hete-
rogeneous Transfer Learning for Image Clustering
via the SocialWeb, ACL
Yu, H., Han, J., K. Chang. 2002. PEBL: Positive exam-
ple based learning for Web page classification using
SVM. KDD, 239-248.
Zadrozny B. 2004. Learning and evaluating classifiers
under s ample selection bias, ICML.
Zhou Z., Gao J., Soong F., Meng H. 2006. A Compara-
tive Study of Discriminative Methods for Reranking
LVCSR N-best Hypotheses in Domain Adaptation
and Generalization. ICASSP.
</reference>
<page confidence="0.997635">
228
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.478108">
<title confidence="0.999903">Negative Training Data can be Harmful to Text Classification</title>
<author confidence="0.991067">Xiao-Li Li Bing Liu See-Kiong Ng</author>
<affiliation confidence="0.956913">Institute for Infocomm Research University of Illinois at Chicago Institute for Infocomm Research</affiliation>
<note confidence="0.719051">1 Fusionopolis Way #21-01, 851 South Morgan Street, 1 Fusionopolis Way #21-01, Connexis Singapore 138632 Chicago, IL 60607-7053, USA Connexis Singapore 138632 xlli@i2r.a-star.edu.sg liub@cs.uic.edu skng@i2r.a-star.edu.sg</note>
<abstract confidence="0.991654833333333">This paper studies the effects of training data on binary text classification and postulates that negative training data is not needed and may even be harmful for the task. Traditional binary classification involves building a classifier using labeled positive and negative training examples. The classifier is then applied to classify test instances into positive and negative classes. A fundamental assumption is that the training and test data are identically distributed. However, this assumption may not hold in practice. In this paper, we study a particular problem where the positive data is identically distributed but the negative data may or may not be so. Many practical text classification and retrieval applications fit this model. We argue that in this setting negative training data should not be used, and that PU learning can be employed to solve the problem. Empirical evaluation has been conducted to support our claim. This result is important as it may fundamentally change the current binary classification paradigm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>L O Lacalle</author>
</authors>
<title>Supervised Domain Adaption for WSD.</title>
<date>2009</date>
<booktitle>Proceedings of the 12th Conference of the European Chapter for Computational Linguistics (EACL09),</booktitle>
<pages>42--50</pages>
<contexts>
<context position="11528" citStr="Agirre &amp; Lacalle 2009" startWordPosition="1875" endWordPosition="1878">et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a</context>
</contexts>
<marker>Agirre, Lacalle, 2009</marker>
<rawString>Agirre E., Lacalle L.O. 2009. Supervised Domain Adaption for WSD. Proceedings of the 12th Conference of the European Chapter for Computational Linguistics (EACL09), pp 42-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Andrew</author>
<author>R Nallapati</author>
<author>W Cohen</author>
</authors>
<title>Exploiting Feature Hierarchy for Transfer Learning in Named Entity Recognition,</title>
<date>2008</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11628" citStr="Andrew et al. 2008" startWordPosition="1895" endWordPosition="1898"> transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positive and hidden negative instances). The </context>
</contexts>
<marker>Andrew, Nallapati, Cohen, 2008</marker>
<rawString>Andrew A., Nallapati R., Cohen W., 2008. Exploiting Feature Hierarchy for Transfer Learning in Named Entity Recognition, ACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T</author>
</authors>
<title>Discriminative learning under covariate shift.</title>
<journal>Journal of Machine Learning Research.</journal>
<marker>T, </marker>
<rawString>Bickel, S., Bruckner, M., and Scheffer. 2009. T. Discriminative learning under covariate shift. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bickel</author>
<author>T Scheffer</author>
</authors>
<title>Dirichlet-enhanced spam filtering based on biased samples.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="10181" citStr="Bickel and Scheffer (2007)" startWordPosition="1640" endWordPosition="1643">ed in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li</context>
</contexts>
<marker>Bickel, Scheffer, 2007</marker>
<rawString>Bickel S. and Scheffer T. 2007. Dirichlet-enhanced spam filtering based on biased samples. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bollmann</author>
<author>V Cherniavsky</author>
</authors>
<title>Measurementtheoretical investigation of the mz-metric.</title>
<date>1981</date>
<journal>Information Retrieval Research.</journal>
<contexts>
<context position="33357" citStr="Bollmann and Cherniavsky, 1981" startWordPosition="5878" endWordPosition="5881"> sets as in (1) but without having any other topic documents in the test set. Here we want to show that PU learning can do equally well without using the negative training data even in the traditional setting. 4.2 Results with Other Topic Documents in Test Set We show the results for experiment set (1), i.e. the distributions of the negative training and test data are different (caused by the inclusion of other topic documents in the test set, or the addition of other topic documents to complement existing negatives in the test set). The evaluation metric is the F-score on the positive class (Bollmann and Cherniavsky, 1981), which is commonly used for evaluating text classification. 4.2.1 Results on the Reuters data Figure 6 shows the comparison results when the negative class contains only one category of documents (Neg 1), while Figure 7 shows the results when the negative class contains documents from two categories (Neg 2) in the Reuters collection. The data points in the figures are the averages of the results from the corresponding datasets. Our proposed method CR-SVM is shown to perform consistently better than the other techniques. When the size of the other topic documents (xaxis) in the test set increa</context>
</contexts>
<marker>Bollmann, Cherniavsky, 1981</marker>
<rawString>Bollmann, P.,&amp; Cherniavsky, V. 1981. Measurementtheoretical investigation of the mz-metric. Information Retrieval Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Buckley</author>
<author>G Salton</author>
<author>J Allan</author>
</authors>
<title>The effect of adding relevance information in a relevance feedback environment,</title>
<date>1994</date>
<publisher>SIGIR.</publisher>
<contexts>
<context position="22907" citStr="Buckley et al. 1994" startWordPosition="4022" endWordPosition="4025">he absolute minimum similarity may be unreliable; the similarity cos(pr, dj) of an outlier docu| d j = | pr |P 1 P |j= 2 1 | d j (4) = 222 1. RN = ∅; 2. Represent each document in P, PN and U as vectors using the TF-IDF representation; p =α − ∑ P d 1 d 1 d d ∈P j d ∈ PN ∑ β j i i j i PN d ; 4. For each di ∈ U do 5. If cos(di, n)&gt; cos(di, p) then 6. RN = RN ∪ {di} Figure 4. Identifying RN using the Rocchio classifier uments in U (lines 5-7). are parameters for adjusting the relative impact of the positive and negative examples. In this work, we use = 16 an αand ,B α d ,B = 4 as recommended in (Buckley et al. 1994). Step 2: Learning by running SVM iteratively This step is similar to that in Roc-SVM, building ment in P could be near 0 or smaller than most (or even all) negative documents. It would therefore be prudent to ignore a small percentage of the documents in P most dissimilar to the representative positive (pr) and assume them as noise or outliers. Since we do not know the noise level of the data, to be safe, we use a noise level = 5% as the default. The final classification result is not sensitive to as long as it is not too big. In line 9, we use the noise level to decide on a suitable Then, fo</context>
</contexts>
<marker>Buckley, Salton, Allan, 1994</marker>
<rawString>Buckley, C., Salton, G., &amp; Allan, J. 1994. The effect of adding relevance information in a relevance feedback environment, SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In Proc. of Computational Learning Theory,</booktitle>
<pages>92--10</pages>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Blum, A. and Mitchell, T. 1998. Combining labeled and unlabeled data with co-training. In Proc. of Computational Learning Theory, pp. 92–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
</authors>
<title>Domain Adaptation with Active Learning for Word Sense Disambiguation,</title>
<date>2007</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11646" citStr="Chan and Ng 2007" startWordPosition="1899" endWordPosition="1902">r domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positive and hidden negative instances). The PU learning proble</context>
</contexts>
<marker>Chan, Ng, 2007</marker>
<rawString>Chan Y. S., Ng H. T. 2007. Domain Adaptation with Active Learning for Word Sense Disambiguation, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm,</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society. Denis F., PAC</journal>
<publisher>ALT,</publisher>
<contexts>
<context position="13614" citStr="Dempster et al. 1977" startWordPosition="2239" endWordPosition="2242">ilding a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique called CR-SVM. 3.1 S-EM Algorithm S-EM (Liu et al. 2002) is based on naïve Bayesian classification (NB) (Lewis, 1995; Nigam et al., 2000) and the EM algorithm (Dempster et al. 1977). It has two steps. The first step uses a spy technique to identify some reliable negatives (RN) from the unlabeled set U and the second step uses the EM algorithm to learn a Bayesian classifier from P, RN and U–RN. 220 Step 1: Extracting reliable negatives RN from U using a spy technique The spy technique in S-EM works as follows (Figure 1): First, a small set of positive examples (denoted by SP) called “spies” is randomly sampled from P (line 2). The default sampling ratio in SEM is s = 15%. Then, an NB classifier is built using P–SP as the positive set and U∪SP as the negative set (lines 3-</context>
<context position="17504" citStr="Dempster et al. 1977" startWordPosition="2987" endWordPosition="2990"> of classes C = {c1, c2} representing positive and negative classes. For classification, we compute the posterior probability Pr(cj|di). Based on the Bayes rule and multinomial model, we have l:i=1Pr(cj |di || D and with Laplacian smoothing, Pr( wt cj) = 1+ V |+Z� � i |;1|D| |D| 1N(wt, di)Pr(cj |di) N(ws, di)Pr(cj |di ) wt occurs in document di, and E 0,1} Pr(cj|di) { depending on the class label of the document. Assuming that probabilities of words are independent given the class, we have the NB classifier: where N(wt,di) is the number of times that the word Pr(cj)�Ik 1Pr( wd„k i| | cj E EM (Dempster et al. 1977) is a popular class of iterative algorithms for maximum likelihood estimation in problems with incomplete data. It is often used to address missing values in the data by computing expected values using the existing values. The EM algorithm consists of two steps, the E-step an d the M-step. The E-step fills in the missing data, and M-step re-estimated the parameters. This process is iterated till satisfaction (i.e. convergence). For NB, the steps used by EM are identical to those used to build the classifier (equations (3) for the E-step, and equations (1) and (2) for the Pr(cj |di) = 1Pr( |r=|</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Dempster A., Laird N. and Rubin D.. 1977. Maximum likelihood from incomplete data via the EM algorithm, Journal of the Royal Statistical Society. Denis F., PAC learning from positive statistical queries. ALT, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Denis</author>
<author>A Laurent</author>
<author>G Rémi</author>
<author>T Marc</author>
</authors>
<title>Text classification and co-training from positive and unlabeled examples.</title>
<date>2003</date>
<publisher>ICML.</publisher>
<contexts>
<context position="10848" citStr="Denis et al. 2003" startWordPosition="1756" endWordPosition="1759">ang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for </context>
</contexts>
<marker>Denis, Laurent, Rémi, Marc, 2003</marker>
<rawString>Denis F., Laurent A., Rémi G., Marc T. 2003. Text classification and co-training from positive and unlabeled examples. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Denis</author>
<author>G Rémi</author>
<author>T Marc</author>
</authors>
<title>Text Classification from Positive and Unlabeled Examples.</title>
<date>2002</date>
<booktitle>In Proceedings of the 9th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems.</booktitle>
<contexts>
<context position="10777" citStr="Denis et al. 2002" startWordPosition="1740" endWordPosition="1743">l and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and </context>
</contexts>
<marker>Denis, Rémi, Marc, 2002</marker>
<rawString>Denis, F, Rémi G, and Marc T. 2002. Text Classification from Positive and Unlabeled Examples. In Proceedings of the 9th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Downey</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<title>Locating complex named entities in Web Text.</title>
<date>2007</date>
<publisher>IJCAI.</publisher>
<marker>Downey, Broadhead, Etzioni, 2007</marker>
<rawString>Downey, D., Broadhead, M. and Etzioni, O. 2007. Locating complex named entities in Web Text. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dudik</author>
<author>R Schapire</author>
<author>S Phillips</author>
</authors>
<title>Correcting sample selection bias in maximum entropy density estimation.</title>
<date>2005</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="10150" citStr="Dudik et al. (2005)" startWordPosition="1635" endWordPosition="1638"> bias was first introduced in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et </context>
</contexts>
<marker>Dudik, Schapire, Phillips, 2005</marker>
<rawString>Dudik M., Schapire R., and Phillips S. 2005. Correcting sample selection bias in maximum entropy density estimation. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Elkan</author>
<author>K Noto</author>
</authors>
<title>Learning classifiers from only positive and unlabeled data.</title>
<date>2008</date>
<journal>KDD,</journal>
<pages>213--220</pages>
<contexts>
<context position="10886" citStr="Elkan and Noto, 2008" startWordPosition="1764" endWordPosition="1767">ean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009</context>
<context position="13317" citStr="Elkan and Noto, 2008" startWordPosition="2189" endWordPosition="2192">m may be solved (Liu et al., 2002). Subsequently, a number of practical algorithms (e.g., Liu et al., 2002; Yu et al., 2002; Li and Liu, 2003) were proposed. They generally follow a two-step strategy: (i) identifying a set of reliable negative documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique called CR-SVM. 3.1 S-EM Algorithm S-EM (Liu et al. 2002) is based on naïve Bayesian classification (NB) (Lewis, 1995; Nigam et al., 2000) and the EM algorithm (Dempster et al. 1977). It has two steps. The first step uses a spy technique to identify some reliable negatives (RN) from the unlabeled set U and the second step uses the EM algorithm to learn a Bayesian classifier from P, RN and U–RN. 220 Step 1: Extracting reliable negatives RN from U using a spy technique The spy techn</context>
<context position="27888" citStr="Elkan and Noto, 2008" startWordPosition="4964" endWordPosition="4967">pared: (1) traditional supervised learning methods SVM and NB which use both positive and negative training data; (2) PU learning methods, including two existing methods S-EM and Roc-SVM and two new methods CR-SVM and CR-EM, and (3) one-class SVM (Schölkop et al., 1999) where only positive training data is used in learning (the unlabeled set is not used at all). We used LIBSVM 1 for SVM and one-class SVM, and two publicly available 2 PU learning techniques S-EM and Roc-SVM. Note that we do not compare with some other PU learning methods such as those in (Liu et al. 2003, Lee and Liu, 2003 and Elkan and Noto, 2008) as the purpose of this paper is not to find the best PU learning method but to show that PU learning can address our special sample selection bias problem. Our current methods already do very well for this purpose. 4.1 Datasets and Experimental Settings We used two well-known benchmark data collections for text classification, the Reuters-21578 collection 3 and the 20 Newsgroup collection 4 . Reuters-21578 contains 21578 documents. We used the most populous 10 out of the 135 categories following the common practice of other researchers. 20 Newsgroup has 11997 documents from 20 discussion grou</context>
</contexts>
<marker>Elkan, Noto, 2008</marker>
<rawString>Elkan, C. and Noto, K. 2008. Learning classifiers from only positive and unlabeled data. KDD, 213-220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Active Sample Selection for Named Entity Transliteration,</title>
<date>2008</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11590" citStr="Goldwasser &amp; Roth 2008" startWordPosition="1887" endWordPosition="1890">Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positiv</context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>Goldwasser, D., Roth D. 2008. Active Sample Selection for Named Entity Transliteration, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Heckman</author>
</authors>
<title>Sample selection bias as a specification error.</title>
<date>1979</date>
<journal>Econometrica,</journal>
<pages>47--153</pages>
<contexts>
<context position="2349" citStr="Heckman 1979" startWordPosition="355" endWordPosition="356">rithm (e.g., Support Vector Machines (SVM), naïve Bayesian classifier (NB)) is applied to the training examples to build a classifier that is subsequently employed to assign class labels to the instances in the test set. In this paper, we focus on binary text classification with two classes (i.e. positive and negative classes). Most learning methods assume that the training and test data have identical distributions. However, this assumption may not hold in practice, i.e., the training and the test distributions can be different. The problem is called covariate shift or sample selection bias (Heckman 1979; Shimodaira 2000; Zadrozny 2004; Huang et al. 2007; Sugiyama et al. 2008; Bickel et al. 2009). In general, this problem is not solvable because the two distributions can be arbitrarily far apart from each other. Various assumptions were made to solve special cases of the problem. One main assumption was that the conditional distribution of the class given an instance is the same over the training and test sets (Shimodaira 2000; Huang et al. 2007; Bickel et al. 2009). In this paper, we study another special case of the problem in which the positive training and test samples have identical dist</context>
<context position="9595" citStr="Heckman (1979)" startWordPosition="1546" endWordPosition="1547">f the proposed method and shows that negative training data is not needed and can even be harmful. This result is important as it may fundamentally change the way that many practical classification problems should be solved. 219 2 Related Work A key assumption made by most machine learning algorithms is that the training and test samples must be drawn from the same distribution. As mentioned, this assumption can be violated in practice. Some researchers have addressed this problem under covariate shift or sample selection bias. Sample selection bias was first introduced in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum </context>
</contexts>
<marker>Heckman, 1979</marker>
<rawString>Heckman J. 1979. Sample selection bias as a specification error. Econometrica, 47:153–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huang</author>
<author>A Smola</author>
<author>A Gretton</author>
<author>K Borgwardt</author>
<author>B Scholkopf</author>
</authors>
<title>Correcting sample selection bias by unlabeled data.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="2400" citStr="Huang et al. 2007" startWordPosition="361" endWordPosition="364">ïve Bayesian classifier (NB)) is applied to the training examples to build a classifier that is subsequently employed to assign class labels to the instances in the test set. In this paper, we focus on binary text classification with two classes (i.e. positive and negative classes). Most learning methods assume that the training and test data have identical distributions. However, this assumption may not hold in practice, i.e., the training and the test distributions can be different. The problem is called covariate shift or sample selection bias (Heckman 1979; Shimodaira 2000; Zadrozny 2004; Huang et al. 2007; Sugiyama et al. 2008; Bickel et al. 2009). In general, this problem is not solvable because the two distributions can be arbitrarily far apart from each other. Various assumptions were made to solve special cases of the problem. One main assumption was that the conditional distribution of the class given an instance is the same over the training and test sets (Shimodaira 2000; Huang et al. 2007; Bickel et al. 2009). In this paper, we study another special case of the problem in which the positive training and test samples have identical distributions, but the negative training and test sampl</context>
<context position="10248" citStr="Huang et al. (2007)" startWordPosition="1651" endWordPosition="1654">e learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003</context>
</contexts>
<marker>Huang, Smola, Gretton, Borgwardt, Scholkopf, 2007</marker>
<rawString>Huang J., Smola A., Gretton A., Borgwardt K., and Scholkopf B. 2007. Correcting sample selection bias by unlabeled data. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>C X Zhai</author>
</authors>
<title>Instance Weighting for Domain Adaptation in NLP,</title>
<date>2007</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11667" citStr="Jiang and Zhai 2007" startWordPosition="1903" endWordPosition="1906">n. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positive and hidden negative instances). The PU learning problem is to build a class</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jiang J. and Zhai C. X. 2007. Instance Weighting for Domain Adaptation in NLP, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W S Lee</author>
<author>B Liu</author>
</authors>
<title>Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression.</title>
<date>2003</date>
<publisher>ICML.</publisher>
<contexts>
<context position="10812" citStr="Lee and Liu, 2003" startWordPosition="1748" endWordPosition="1751">entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers</context>
<context position="13294" citStr="Lee and Liu, 2003" startWordPosition="2185" endWordPosition="2188">owed how the problem may be solved (Liu et al., 2002). Subsequently, a number of practical algorithms (e.g., Liu et al., 2002; Yu et al., 2002; Li and Liu, 2003) were proposed. They generally follow a two-step strategy: (i) identifying a set of reliable negative documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique called CR-SVM. 3.1 S-EM Algorithm S-EM (Liu et al. 2002) is based on naïve Bayesian classification (NB) (Lewis, 1995; Nigam et al., 2000) and the EM algorithm (Dempster et al. 1977). It has two steps. The first step uses a spy technique to identify some reliable negatives (RN) from the unlabeled set U and the second step uses the EM algorithm to learn a Bayesian classifier from P, RN and U–RN. 220 Step 1: Extracting reliable negatives RN from U using a spy </context>
<context position="27862" citStr="Lee and Liu, 2003" startWordPosition="4959" endWordPosition="4962">lowing methods are compared: (1) traditional supervised learning methods SVM and NB which use both positive and negative training data; (2) PU learning methods, including two existing methods S-EM and Roc-SVM and two new methods CR-SVM and CR-EM, and (3) one-class SVM (Schölkop et al., 1999) where only positive training data is used in learning (the unlabeled set is not used at all). We used LIBSVM 1 for SVM and one-class SVM, and two publicly available 2 PU learning techniques S-EM and Roc-SVM. Note that we do not compare with some other PU learning methods such as those in (Liu et al. 2003, Lee and Liu, 2003 and Elkan and Noto, 2008) as the purpose of this paper is not to find the best PU learning method but to show that PU learning can address our special sample selection bias problem. Our current methods already do very well for this purpose. 4.1 Datasets and Experimental Settings We used two well-known benchmark data collections for text classification, the Reuters-21578 collection 3 and the 20 Newsgroup collection 4 . Reuters-21578 contains 21578 documents. We used the most populous 10 out of the 135 categories following the common practice of other researchers. 20 Newsgroup has 11997 documen</context>
</contexts>
<marker>Lee, Liu, 2003</marker>
<rawString>Lee, W. S. and Liu, B. 2003. Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
</authors>
<title>A sequential algorithm for training text classifiers: corrigendum and additional data.</title>
<date>1995</date>
<journal>SIGIR Forum,</journal>
<pages>13--19</pages>
<contexts>
<context position="13549" citStr="Lewis, 1995" startWordPosition="2229" endWordPosition="2230">e documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique called CR-SVM. 3.1 S-EM Algorithm S-EM (Liu et al. 2002) is based on naïve Bayesian classification (NB) (Lewis, 1995; Nigam et al., 2000) and the EM algorithm (Dempster et al. 1977). It has two steps. The first step uses a spy technique to identify some reliable negatives (RN) from the unlabeled set U and the second step uses the EM algorithm to learn a Bayesian classifier from P, RN and U–RN. 220 Step 1: Extracting reliable negatives RN from U using a spy technique The spy technique in S-EM works as follows (Figure 1): First, a small set of positive examples (denoted by SP) called “spies” is randomly sampled from P (line 2). The default sampling ratio in SEM is s = 15%. Then, an NB classifier is built usin</context>
</contexts>
<marker>Lewis, 1995</marker>
<rawString>Lewis D. 1995. A sequential algorithm for training text classifiers: corrigendum and additional data. SIGIR Forum, 13-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>C Zong</author>
</authors>
<date>2008</date>
<booktitle>Multi-Domain Sentiment Classification, ACL.</booktitle>
<contexts>
<context position="11608" citStr="Li and Zong 2008" startWordPosition="1891" endWordPosition="1894">ed work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positive and hidden negat</context>
</contexts>
<marker>Li, Zong, 2008</marker>
<rawString>Li, S., Zong C., 2008. Multi-Domain Sentiment Classification, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>B Liu</author>
</authors>
<title>Learning to classify texts using positive and unlabeled data,</title>
<date>2003</date>
<journal>IJCAI.</journal>
<contexts>
<context position="12838" citStr="Li and Liu, 2003" startWordPosition="2112" endWordPosition="2115">). The PU learning problem is to build a classifier using P and U in the absence of negative examples to classify the data in U or a future test data T. In our setting, the test set T will also act as the unlabeled set U. PU learning has been investigated by several researchers in the past decade. A study of PAC learning for the setting under the statistical query model was given in (Denis, 1998). Liu et al. reported the sample complexity result and showed how the problem may be solved (Liu et al., 2002). Subsequently, a number of practical algorithms (e.g., Liu et al., 2002; Yu et al., 2002; Li and Liu, 2003) were proposed. They generally follow a two-step strategy: (i) identifying a set of reliable negative documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique calle</context>
<context position="19242" citStr="Li and Liu, 2003" startWordPosition="3308" endWordPosition="3311">is is due to the mixture model assumption of its NB classifier (Nigam et al. 2000), which requires that the mixture components and classes be of oneto-one correspondence. Intuitively, this means that each class should come from a distinctive distribution rather than a mixture of multiple distributions. In our setting, however, the negative class often has documents of mixed topics, e.g., representing the broad class of everything else except the topic(s) represented by the positive class. There are some existing PU learning methods based on SVM which can deal with this problem, e.g., Roc-SVM (Li and Liu, 2003). Like S-EM, Roc-SVM also has two steps. The first step uses Rocchio classification (Rocchio, 1971) to find a set of reliable negatives RN from U. In particular, this method treats the entire unlabeled set U as negative documents and then uses the positive set P and the unlabeled set U as the training data to build a Rocchio classifier. The classifier is subsequently applied to classify the unlabeled set U. Those documents that are classified as negative are then considered as reliable negative examples RN. The second step of Roc-SVM runs SVM iteratively (instead of EM). Unlike NB, SVM does no</context>
</contexts>
<marker>Li, Liu, 2003</marker>
<rawString>Li, X., Liu, B. 2003. Learning to classify texts using positive and unlabeled data, IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>B Liu</author>
</authors>
<title>Learning from Positive and Unlabeled Examples with Different Data Distributions.</title>
<date>2005</date>
<publisher>ECML.</publisher>
<marker>Li, Liu, 2005</marker>
<rawString>Li, X., Liu, B., 2005. Learning from Positive and Unlabeled Examples with Different Data Distributions. ECML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>B Liu</author>
</authors>
<date>2007</date>
<booktitle>Learning to Identify Unexpected Instances in the Test Set. IJCAI.</booktitle>
<marker>Li, Liu, 2007</marker>
<rawString>Li, X., Liu, B., 2007. Learning to Identify Unexpected Instances in the Test Set. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>P S Yu</author>
<author>B Liu</author>
<author>S Ng</author>
</authors>
<title>Positive Unlabeled Learning for Data Stream Classification,</title>
<date>2009</date>
<publisher>SDM.</publisher>
<contexts>
<context position="10902" citStr="Li et al. 2009" startWordPosition="1768" endWordPosition="1771"> et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2</context>
</contexts>
<marker>Li, Yu, Liu, Ng, 2009</marker>
<rawString>Li, X., Yu, P. S., Liu B., and Ng, S. 2009. Positive Unlabeled Learning for Data Stream Classification, SDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>L Zhang</author>
<author>B Liu</author>
<author>S Ng</author>
</authors>
<title>Distributional Similarity vs. PU Learning for Entity Set Expansion,</title>
<date>2010</date>
<publisher>ACL.</publisher>
<contexts>
<context position="10919" citStr="Li et al. 2010" startWordPosition="1772" endWordPosition="1775">nd Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lac</context>
</contexts>
<marker>Li, Zhang, Liu, Ng, 2010</marker>
<rawString>Li, X., Zhang L., Liu B., and Ng, S. 2010. Distributional Similarity vs. PU Learning for Entity Set Expansion, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P</author>
</authors>
<title>Building text classifiers using positive and unlabeled examples.</title>
<date>2003</date>
<journal>ICDM,</journal>
<pages>179--188</pages>
<marker>P, 2003</marker>
<rawString>Liu, B, Dai, Y., Li, X., Lee, W-S., and Yu. P. 2003. Building text classifiers using positive and unlabeled examples. ICDM, 179-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
<author>W-S Lee</author>
<author>P S Yu</author>
<author>X Li</author>
</authors>
<title>Partially supervised text classification.</title>
<date>2002</date>
<journal>ICML,</journal>
<pages>387--394</pages>
<contexts>
<context position="3669" citStr="Liu et al. 2002" startWordPosition="572" endWordPosition="575">scenario is more applicable for binary text classification. As the focus in many applications is on identifying positive instances correctly, it is important that the positive training and the positive test data have the same distribution. The distributions of the negative training and negative test data can be different. We believe that this special case of the sample selection bias problem is also more applicable for machine learning. We will show that a partially supervised learning model, called PU learning (learning from Positive and Unlabeled examples) fits this special case quite well (Liu et al. 2002). Following the notations in (Bickel et al. 2009), our special case of the sample selection bias problem can be formulated as follows: We are given a training sample matrix XL with row vectors x1, ..., xk. The positive and negative training instances are governed by different unknown distributions p(x|λ) 218 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 218–228, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics and p(x|δ) respectively. The element yi of vector y = (y1, y2, ..., yk) is the class label for</context>
<context position="7280" citStr="Liu et al. 2002" startWordPosition="1167" endWordPosition="1170">addressing the sample selection bias problem work as follows. First, they estimate the bias of the training data based on the given test data using statistical methods. Then, a classifier is trained on a weighted version of the original training set based on the estimated bias. In this paper, we show that our special case of the sample selection bias problem can be solved in a much simpler and somewhat radical manner—by simply discarding the negative training data altogether. We can use the positive training data and the unlabeled test data to build the classifier using the PU learning model (Liu et al. 2002). PU learning was originally proposed to solve the learning problem where no labeled negative training data exist. Several algorithms have been developed in the past few years that can learn from a set of labeled positive examples augmented with a set of unlabeled examples. That is, given a set P of positive examples of a particular class (called the positive class) and a set U of unlabeled examples (which contains both hidden positive and hidden negative examples), a classifier is built using P and U to classify the data in U as well as future test data into two classes, i.e., those belonging</context>
<context position="10742" citStr="Liu et al. 2002" startWordPosition="1732" endWordPosition="1735">es. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer</context>
<context position="12730" citStr="Liu et al., 2002" startWordPosition="2092" endWordPosition="2095">amples, and U a set of unlabeled examples (which contains both hidden positive and hidden negative instances). The PU learning problem is to build a classifier using P and U in the absence of negative examples to classify the data in U or a future test data T. In our setting, the test set T will also act as the unlabeled set U. PU learning has been investigated by several researchers in the past decade. A study of PAC learning for the setting under the statistical query model was given in (Denis, 1998). Liu et al. reported the sample complexity result and showed how the problem may be solved (Liu et al., 2002). Subsequently, a number of practical algorithms (e.g., Liu et al., 2002; Yu et al., 2002; Li and Liu, 2003) were proposed. They generally follow a two-step strategy: (i) identifying a set of reliable negative documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this sec</context>
<context position="14850" citStr="Liu et al. 2002" startWordPosition="2477" endWordPosition="2480">r is applied to classify each u E U∪SP, i.e., to assign a probabilistic class label p(+|u) (+ means positive) to u. The idea of the spy technique is as follows. Since the spy examples were from P and were put into U as negatives in building the NB classifier, they should behave similarly to the hidden positive instances in U. We thus can use them to find the reliable negative set RN from U. Using the probabilistic labels of spies in SP and an input parameter l (noise level), a probability threshold t is determined. Due to space constraints, we are unable to explain l. Details can be found in (Liu et al. 2002). t is then used to find RN from U (lines 8-10). 1. RN +- 0; // Reliable negative set 2. SP +- Sample(P, s%); // spy set 3. Assign each example in P – SP the class label +1; 4. Assign each example in U USP the class label -1; 5. C +-NB(P – SP, UUSP); // Produce a NB classifier 6. Classify each u EUUSP using C; 7. Decide a probability threshold t using SP and l; 8. For each u EU do 9. If its probability p(+|u) &lt; t then 10. RN +- RN U {u}; Figure 1. Spy technique for extracting RN from U Step 2: Learning using the EM algorithm Given the positive set P, the reliable negative set RN, and the remai</context>
</contexts>
<marker>Liu, Lee, Yu, Li, 2002</marker>
<rawString>Liu, B, Lee, W-S, Yu, P. S, and Li, X. 2002. Partially supervised text classification. ICML, 387-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>A McCallum</author>
<author>S Thrun</author>
<author>T Mitchell</author>
</authors>
<title>Text classification from labeled and unlabeled documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<volume>39</volume>
<issue>2</issue>
<pages>103--134</pages>
<contexts>
<context position="13570" citStr="Nigam et al., 2000" startWordPosition="2231" endWordPosition="2234">N from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a new technique called CR-SVM. 3.1 S-EM Algorithm S-EM (Liu et al. 2002) is based on naïve Bayesian classification (NB) (Lewis, 1995; Nigam et al., 2000) and the EM algorithm (Dempster et al. 1977). It has two steps. The first step uses a spy technique to identify some reliable negatives (RN) from the unlabeled set U and the second step uses the EM algorithm to learn a Bayesian classifier from P, RN and U–RN. 220 Step 1: Extracting reliable negatives RN from U using a spy technique The spy technique in S-EM works as follows (Figure 1): First, a small set of positive examples (denoted by SP) called “spies” is randomly sampled from P (line 2). The default sampling ratio in SEM is s = 15%. Then, an NB classifier is built using P–SP as the positiv</context>
<context position="15856" citStr="Nigam et al., 2000" startWordPosition="2671" endWordPosition="2674">If its probability p(+|u) &lt; t then 10. RN +- RN U {u}; Figure 1. Spy technique for extracting RN from U Step 2: Learning using the EM algorithm Given the positive set P, the reliable negative set RN, and the remaining unlabeled set U–RN, we run EM using NB as the base learning algorithm. The naive Bayesian (NB) method is an effective text classification algorithm. There are two different NB models, namely, the multinomial NB and the multi-variate Bernoulli NB. In this paper, we use the multinomial NB since it has been observed to perform consistently better than the multivariate Bernoulli NB (Nigam et al., 2000). Given a set of training documents D, each document di E D is an ordered list of words. We use wdi,k to denote the word in position k of di, where each word is from the vocabulary V = {w1, ... , w|v|}, which is the set of all words considered in classifi1. Each document in P is assigned the class label 1; 2. Each document in RN is assigned the class label −1; 3. Learn an initial NB classifier f from P and RN, using Equations (1) and (2); 4. Repeat 5. For each document di in U-RN do // E-Step 6. Using the current classifier f compute Pr(cj|di) using Equation (3); 7. Learn a new NB classifier f</context>
<context position="18707" citStr="Nigam et al. 2000" startWordPosition="3223" endWordPosition="3226">di) = 1Pr( |r=| cr)� P r( | w c = d k r , k 1 i ) ) (3) | |di = Pr ( cj) || D ) 221 M-step). In EM, Pr(cj|di) takes the value in [0, 1] instead of {0, 1} in all the three equations. The algorithm for the second step of S-EM is given in Figure 2. Lines 1-3 build a NB classifier f using P and RN. Lines 4-8 run EM until convergence. Finally, the converged classifier is used to classify the unlabeled set U (lines 10-13). 3.2 Proposed CR-SVM As we will see in the experiment section, the performance of S-EM can be weak in some cases. This is due to the mixture model assumption of its NB classifier (Nigam et al. 2000), which requires that the mixture components and classes be of oneto-one correspondence. Intuitively, this means that each class should come from a distinctive distribution rather than a mixture of multiple distributions. In our setting, however, the negative class often has documents of mixed topics, e.g., representing the broad class of everything else except the topic(s) represented by the positive class. There are some existing PU learning methods based on SVM which can deal with this problem, e.g., Roc-SVM (Li and Liu, 2003). Like S-EM, Roc-SVM also has two steps. The first step uses Rocc</context>
</contexts>
<marker>Nigam, McCallum, Thrun, Mitchell, 2000</marker>
<rawString>Nigam, K., McCallum, A., Thrun, S. and Mitchell, T. 2000. Text classification from labeled and unlabeled documents using EM. Machine Learning, 39(2/3), 103–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Pan</author>
<author>Q Yang</author>
</authors>
<title>A survey on transfer learning.</title>
<date>2009</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>99</volume>
<contexts>
<context position="11387" citStr="Pan and Yang 2009" startWordPosition="1852" endWordPosition="1855">al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the d</context>
</contexts>
<marker>Pan, Yang, 2009</marker>
<rawString>Pan, S. J. and Yang, Q. 2009. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, Vol. 99, No. 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rocchio</author>
</authors>
<title>Relevant feedback in information retrieval.</title>
<date>1971</date>
<editor>In G. Salton (ed.).</editor>
<contexts>
<context position="19341" citStr="Rocchio, 1971" startWordPosition="3325" endWordPosition="3326">t the mixture components and classes be of oneto-one correspondence. Intuitively, this means that each class should come from a distinctive distribution rather than a mixture of multiple distributions. In our setting, however, the negative class often has documents of mixed topics, e.g., representing the broad class of everything else except the topic(s) represented by the positive class. There are some existing PU learning methods based on SVM which can deal with this problem, e.g., Roc-SVM (Li and Liu, 2003). Like S-EM, Roc-SVM also has two steps. The first step uses Rocchio classification (Rocchio, 1971) to find a set of reliable negatives RN from U. In particular, this method treats the entire unlabeled set U as negative documents and then uses the positive set P and the unlabeled set U as the training data to build a Rocchio classifier. The classifier is subsequently applied to classify the unlabeled set U. Those documents that are classified as negative are then considered as reliable negative examples RN. The second step of Roc-SVM runs SVM iteratively (instead of EM). Unlike NB, SVM does not make any distributional assumption. However, Roc-SVM does not do well due to the weakness of its </context>
</contexts>
<marker>Rocchio, 1971</marker>
<rawString>Rocchio, J. 1971. Relevant feedback in information retrieval. In G. Salton (ed.). The smart retrieval system: experiments in automatic document processing,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Englewood Cliffs</author>
<author>NJ</author>
</authors>
<date>1971</date>
<booktitle>Online Methods for Multi-Domain Learning and Adaptation, EMNLP.</booktitle>
<marker>Cliffs, NJ, 1971</marker>
<rawString>Englewood Cliffs, NJ, 1971.Sagae K., Tsujii J. 2008. Online Methods for Multi-Domain Learning and Adaptation, EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1986</date>
<marker>Salton, McGill, 1986</marker>
<rawString>Salton G. and McGill M. J. 1986. Introduction to Modern Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>f B Schölkop</author>
<author>J C Platt</author>
<author>J Shawe-Taylor</author>
<author>A J Smola</author>
<author>R C Williamson</author>
</authors>
<title>Estimating the support of a high-dimensional distribution.</title>
<date>1999</date>
<tech>Technical report, Microsoft Research,</tech>
<pages>99--87</pages>
<contexts>
<context position="27537" citStr="Schölkop et al., 1999" startWordPosition="4898" endWordPosition="4901">o. 7. ; 1 d 1 d n β i j = α ∑ − ∑ ∈ || PN i | d P j |d d ∈ PN i d P j || 4 Empirical Evaluation We now present the experimental results to support our claim that negative training data is not needed and can even harm text classification. We also show the effectiveness of the proposed PU learning methods CR-SVM and CR-EM. The following methods are compared: (1) traditional supervised learning methods SVM and NB which use both positive and negative training data; (2) PU learning methods, including two existing methods S-EM and Roc-SVM and two new methods CR-SVM and CR-EM, and (3) one-class SVM (Schölkop et al., 1999) where only positive training data is used in learning (the unlabeled set is not used at all). We used LIBSVM 1 for SVM and one-class SVM, and two publicly available 2 PU learning techniques S-EM and Roc-SVM. Note that we do not compare with some other PU learning methods such as those in (Liu et al. 2003, Lee and Liu, 2003 and Elkan and Noto, 2008) as the purpose of this paper is not to find the best PU learning method but to show that PU learning can address our special sample selection bias problem. Our current methods already do very well for this purpose. 4.1 Datasets and Experimental Set</context>
</contexts>
<marker>Schölkop, Platt, Shawe-Taylor, Smola, Williamson, 1999</marker>
<rawString>Schölkop f B., Platt J.C., Shawe-Taylor J., Smola A.J., and Williamson R.C. 1999. Estimating the support of a high-dimensional distribution. Technical report, Microsoft Research, MSR-TR-99-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Shimodaira</author>
</authors>
<title>Improving predictive inference under covariate shift by weighting the log-likelihood function.</title>
<date>2000</date>
<journal>Journal of Statistical Planning and Inference,</journal>
<pages>90--227</pages>
<contexts>
<context position="2366" citStr="Shimodaira 2000" startWordPosition="357" endWordPosition="358">upport Vector Machines (SVM), naïve Bayesian classifier (NB)) is applied to the training examples to build a classifier that is subsequently employed to assign class labels to the instances in the test set. In this paper, we focus on binary text classification with two classes (i.e. positive and negative classes). Most learning methods assume that the training and test data have identical distributions. However, this assumption may not hold in practice, i.e., the training and the test distributions can be different. The problem is called covariate shift or sample selection bias (Heckman 1979; Shimodaira 2000; Zadrozny 2004; Huang et al. 2007; Sugiyama et al. 2008; Bickel et al. 2009). In general, this problem is not solvable because the two distributions can be arbitrarily far apart from each other. Various assumptions were made to solve special cases of the problem. One main assumption was that the conditional distribution of the class given an instance is the same over the training and test sets (Shimodaira 2000; Huang et al. 2007; Bickel et al. 2009). In this paper, we study another special case of the problem in which the positive training and test samples have identical distributions, but th</context>
<context position="9917" citStr="Shimodaira (2000)" startWordPosition="1602" endWordPosition="1603">ing and test samples must be drawn from the same distribution. As mentioned, this assumption can be violated in practice. Some researchers have addressed this problem under covariate shift or sample selection bias. Sample selection bias was first introduced in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an int</context>
</contexts>
<marker>Shimodaira, 2000</marker>
<rawString>Shimodaira H. 2000. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Inference, 90:227–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sugiyama</author>
<author>K-R Muller</author>
</authors>
<title>Input-dependent estimation of generalization error under covariate shift.</title>
<date>2005</date>
<journal>Statistics and Decision,</journal>
<volume>23</volume>
<issue>4</issue>
<contexts>
<context position="9948" citStr="Sugiyama and Muller (2005)" startWordPosition="1605" endWordPosition="1608">ust be drawn from the same distribution. As mentioned, this assumption can be violated in practice. Some researchers have addressed this problem under covariate shift or sample selection bias. Sample selection bias was first introduced in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, w</context>
</contexts>
<marker>Sugiyama, Muller, 2005</marker>
<rawString>Sugiyama M. and Muller K.-R. 2005. Input-dependent estimation of generalization error under covariate shift. Statistics and Decision, 23(4):249–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sugiyama</author>
<author>S Nakajima</author>
<author>H Kashima</author>
<author>P von Bunau</author>
<author>M Kawanabe</author>
</authors>
<title>Direct importance estimation with model selection and its application to covariate shift adaptation.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<marker>Sugiyama, Nakajima, Kashima, von Bunau, Kawanabe, 2008</marker>
<rawString>Sugiyama M., Nakajima S., Kashima H., von Bunau P., and Kawanabe M. 2008. Direct importance estimation with model selection and its application to covariate shift adaptation. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tsuboi</author>
<author>H Kashima</author>
<author>S Hido</author>
<author>S Bickel</author>
<author>M Sugiyama</author>
</authors>
<title>Direct density ratio estimation for large-scale covariate shift adaptation.</title>
<date>2008</date>
<booktitle>In Proceedings of the SIAM International Conference on Data Mining,</booktitle>
<contexts>
<context position="10327" citStr="Tsuboi et al. (2008)" startWordPosition="1665" endWordPosition="1668">earning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We wil</context>
</contexts>
<marker>Tsuboi, Kashima, Hido, Bickel, Sugiyama, 2008</marker>
<rawString>Tsuboi J., Kashima H., Hido S., Bickel S., and Sugiyama M. 2008. Direct density ratio estimation for large-scale covariate shift adaptation. In Proceedings of the SIAM International Conference on Data Mining, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>W S Lee</author>
<author>N Ye</author>
<author>H L Chieu</author>
</authors>
<title>Domain adaptive bootstrapping for named entity recognition,</title>
<date>2009</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11486" citStr="Wu et al. 2009" startWordPosition="1867" endWordPosition="1870">and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P d</context>
</contexts>
<marker>Wu, Lee, Ye, Chieu, 2009</marker>
<rawString>Wu D., Lee W.S., Ye N. and Chieu H. L. 2009. Domain adaptive bootstrapping for named entity recognition, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Wu</author>
<author>S Tan</author>
<author>X Cheng</author>
</authors>
<title>Graph Ranking for Sentiment Transfer,</title>
<date>2009</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11486" citStr="Wu et al. 2009" startWordPosition="1867" endWordPosition="1870">and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P d</context>
</contexts>
<marker>Wu, Tan, Cheng, 2009</marker>
<rawString>Wu Q., Tan S. and Cheng X. 2009. Graph Ranking for Sentiment Transfer, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Yang</author>
<author>Y Chen</author>
<author>G Xue</author>
<author>W Dai</author>
<author>Y Yu</author>
</authors>
<title>Heterogeneous Transfer Learning for Image Clustering via the SocialWeb,</title>
<date>2009</date>
<publisher>ACL</publisher>
<contexts>
<context position="11505" citStr="Yang et al. 2009" startWordPosition="1871" endWordPosition="1874">i et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of pos</context>
</contexts>
<marker>Yang, Chen, Xue, Dai, Yu, 2009</marker>
<rawString>Yang Q., Chen Y., Xue G., Dai W., Yu Y. 2009. Heterogeneous Transfer Learning for Image Clustering via the SocialWeb, ACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yu</author>
<author>J Han</author>
<author>K Chang</author>
</authors>
<title>PEBL: Positive example based learning for Web page classification using SVM.</title>
<date>2002</date>
<pages>239--248</pages>
<publisher>KDD,</publisher>
<contexts>
<context position="10758" citStr="Yu et al. 2002" startWordPosition="1736" endWordPosition="1739">(2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean matching. Sugiyama et al. (2008) and Tsuboi et al. (2008) estimated the weights for the training instances by minimizing the Kullback-Leibler divergence between the test and the weighted training distributions. Bickel et al. (2009) proposed an integrated model. In this paper, we adopt an entirely different approach by dropping the negative training data altogether in learning. Without the negative training data, we use PU learning to solve the problem (Liu et al. 2002; Yu et al. 2002; Denis et al. 2002; Li et al. 2003; Lee and Liu, 2003; Liu et al. 2003; Denis et al. 2003; Li et al. 2007; Elkan and Noto, 2008; Li et al. 2009; Li et al. 2010). We will discuss this learning model further in Section 3. Another related work to ours is transfer learning or domain adaptation. Unlike our problem setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be</context>
<context position="12819" citStr="Yu et al., 2002" startWordPosition="2108" endWordPosition="2111">egative instances). The PU learning problem is to build a classifier using P and U in the absence of negative examples to classify the data in U or a future test data T. In our setting, the test set T will also act as the unlabeled set U. PU learning has been investigated by several researchers in the past decade. A study of PAC learning for the setting under the statistical query model was given in (Denis, 1998). Liu et al. reported the sample complexity result and showed how the problem may be solved (Liu et al., 2002). Subsequently, a number of practical algorithms (e.g., Liu et al., 2002; Yu et al., 2002; Li and Liu, 2003) were proposed. They generally follow a two-step strategy: (i) identifying a set of reliable negative documents RN from the unlabeled set; and then (ii) building a classifier using P (positive set), RN (reliable negative set) and U-RN (unlabelled set) by applying an existing learning algorithm (such as naive Bayesian classifier or SVM) iteratively. There are also some other approaches based on unbalanced errors (e.g., Liu et al. 2003; Lee and Liu, 2003; Elkan and Noto, 2008). In this section, we first introduce a representative PU learning technique S-EM, and then present a </context>
</contexts>
<marker>Yu, Han, Chang, 2002</marker>
<rawString>Yu, H., Han, J., K. Chang. 2002. PEBL: Positive example based learning for Web page classification using SVM. KDD, 239-248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zadrozny</author>
</authors>
<title>Learning and evaluating classifiers under s ample selection bias,</title>
<date>2004</date>
<journal>ICML.</journal>
<contexts>
<context position="2381" citStr="Zadrozny 2004" startWordPosition="359" endWordPosition="360">hines (SVM), naïve Bayesian classifier (NB)) is applied to the training examples to build a classifier that is subsequently employed to assign class labels to the instances in the test set. In this paper, we focus on binary text classification with two classes (i.e. positive and negative classes). Most learning methods assume that the training and test data have identical distributions. However, this assumption may not hold in practice, i.e., the training and the test distributions can be different. The problem is called covariate shift or sample selection bias (Heckman 1979; Shimodaira 2000; Zadrozny 2004; Huang et al. 2007; Sugiyama et al. 2008; Bickel et al. 2009). In general, this problem is not solvable because the two distributions can be arbitrarily far apart from each other. Various assumptions were made to solve special cases of the problem. One main assumption was that the conditional distribution of the class given an instance is the same over the training and test sets (Shimodaira 2000; Huang et al. 2007; Bickel et al. 2009). In this paper, we study another special case of the problem in which the positive training and test samples have identical distributions, but the negative trai</context>
<context position="9675" citStr="Zadrozny (2004)" startWordPosition="1560" endWordPosition="1562">an even be harmful. This result is important as it may fundamentally change the way that many practical classification problems should be solved. 219 2 Related Work A key assumption made by most machine learning algorithms is that the training and test samples must be drawn from the same distribution. As mentioned, this assumption can be violated in practice. Some researchers have addressed this problem under covariate shift or sample selection bias. Sample selection bias was first introduced in the econometrics by Heckman (1979). It came into the field of machine learning through the work of Zadrozny (2004). The main approach in machine learning is to first estimate the distribution bias of the training data based on the test data, and then learn using weighted training examples to compensate for the bias (Bickel et al. 2009). Shimodaira (2000) and Sugiyama and Muller (2005) proposed to estimate the training and test data distributions using kernel density estimation. The estimated density ratio could then be used to generate weighted training examples. Dudik et al. (2005) and Bickel and Scheffer (2007) used maximum entropy density estimation, while Huang et al. (2007) proposed kernel mean match</context>
</contexts>
<marker>Zadrozny, 2004</marker>
<rawString>Zadrozny B. 2004. Learning and evaluating classifiers under s ample selection bias, ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhou</author>
<author>J Gao</author>
<author>F Soong</author>
<author>H Meng</author>
</authors>
<title>A Comparative Study of Discriminative Methods for Reranking LVCSR N-best Hypotheses in Domain Adaptation and Generalization.</title>
<date>2006</date>
<publisher>ICASSP.</publisher>
<contexts>
<context position="11686" citStr="Zhou et al. 2006" startWordPosition="1907" endWordPosition="1910"> setting, transfer learning addresses the scenario where one has little or no training data for the target domain, but has ample training data in a related domain where the data could be in a different feature space and follow a different distribution. A survey of transfer learning can be found in (Pan and Yang 2009). Several NLP researchers have studied transfer learning for different applications (Wu et al. 2009a; Yang et al. 2009; Agirre &amp; Lacalle 2009; Wu et al. 2009b; Sagae &amp; Tsujii 2008; Goldwasser &amp; Roth 2008; Li and Zong 2008; Andrew et al. 2008; Chan and Ng 2007; Jiang and Zhai 2007; Zhou et al. 2006), but none of them addresses the problem studied here. 3 PU Learning Techniques In traditional supervised learning, ideally, there is a large number of labeled positive and negative examples for learning. In practice, the negative examples can often be limited or unavailable. This has motivated the development of the model of learning from positive and unlabeled examples, or PU learning, where P denotes a set of positive examples, and U a set of unlabeled examples (which contains both hidden positive and hidden negative instances). The PU learning problem is to build a classifier using P and U</context>
</contexts>
<marker>Zhou, Gao, Soong, Meng, 2006</marker>
<rawString>Zhou Z., Gao J., Soong F., Meng H. 2006. A Comparative Study of Discriminative Methods for Reranking LVCSR N-best Hypotheses in Domain Adaptation and Generalization. ICASSP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>