<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998744">
Improving Named Entity Translation Combining Phonetic
and Semantic Similarities
</title>
<author confidence="0.926558">
Fei Huang, Stephan Vogel and Alex Waibel
</author>
<affiliation confidence="0.932802666666667">
Language Technologies Institute
School of Computer Sciences
Carnegie Mellon University
</affiliation>
<email confidence="0.998847">
{fhuang,vogel,ahw}@cs.cmu.edu
</email>
<sectionHeader confidence="0.9948" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999872636363636">
This paper describes an approach to translate
rarely occurring named entities (NE) by com-
bining phonetic and semantic similarities. The
phonetic similarity is estimated from a surface
string transliteration model, and the semantic
similarity is calculated from a context vector
semantic model. Given a source (Chinese) NE
and its context, this approach first generates
queries in the target (English) language ac-
cording to the context translation hypotheses,
then searches for relevant documents from a
target language corpus. Target NEs in re-
trieved documents are compared with the
source NE based on their phonetic and contex-
tual semantic similarities, and the best-
matched one is selected as the correct transla-
tion. Experiments show that this approach
achieves 67% accuracy on translating rarely
occurring NEs, and consistently improves the
translation quality on different tasks over a
state-of-the-art statistical machine translation
system.
</bodyText>
<sectionHeader confidence="0.998877" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997678262135922">
Translating Named Entities (NE), in particular named
persons, locations and organizations, can benefit many
natural language processing tasks. Correct NE transla-
tions often act as either key queries in cross-lingual in-
formation retrieval or correct answers in multilingual
question answering. Moreover, in machine translation,
incorrect NE translations not only discard meaningful
information from the original sentences, but also intro-
duce a distorted context which degrades the overall
translation quality. However, translating NEs is also a
challenging problem. Part of the reason is that NEs are
either phonetically transliterated (mostly for person
names) or semantically translated (mostly for organiza-
tion names) or both (mostly for location names, like
&amp;quot;Appalachian Mountains&amp;quot;), and often there is no one-to-
one mapping in transliteration and translation between
source and target languages. Although pre-compiled NE
translation dictionaries may help in translating some
frequent NEs, such as the names of countries, big com-
panies or famous persons, it cannot handle the transla-
tion of rarely occurring names, especially new names.
For example, in the 2001 Chinese-English translation
evaluation test data, 20% of the automatically tagged
Chinese NEs are not included in the 50K LDC Chinese-
English translation lexicon.
Although many research efforts have been focused
on automatic NE detection, and good performance has
been achieved in some languages (Chinchor 1997),
there are still many areas in NE translation that call for
further investigation. (Knight and Graehl 1997) pro-
posed a generative model for Japanese-English back
transliteration, (Stalls and Knight 1998) expanded that
model to Arabic-English transliteration, and (Al-
Onaizan and Knight 2002) additionally incorporated
web counts to re-score the transliteration candidates.
(Meng et al. 2001) developed an English-Chinese NE
transliteration technique using a pronunciation lexicon
and phonetic mapping rules. (Moore 2003) proposed
statistical phrase translation models to find NE transla-
tions in English-French software manuals. (Huang et al.
2003) extracted NE translation pairs from a Chinese-
English parallel corpus combining letter transliteration,
word translation and NE tagging features, then con-
structed an NE translation dictionary based on align-
ment costs and frequencies.
Aligning NE translations from a parallel corpus usu-
ally achieves high accuracy on frequently occurring
NEs, but it fails in translating rarely occurring NEs
which may not appear in the bilingual corpus, as shown
in the following example:
Chn:
Ref.: netherlands&apos; ambassador to china, van houten
Hyp: netherlands ambassador hao germany hurls
It is noticed that &amp;quot;van houten&amp;quot;, the ambassador&apos;s
name, was not included in the translation lexicon and
parallel corpus, thus the name was inappropriately se-
mantically translated character by character, &amp;quot; /hao
/germany /hurls&amp;quot;.
In this paper we will propose an approach focusing
on translating these rarely occurring NEs. Given a Chi-
nese NE and its context (e.g., the document where the
NE appears), this approach first generates queries in
English according to the initial document translation
hypotheses, then searches for relevant documents from
an English corpus using a search engine. It compares the
Chinese NE with English NEs in retrieved documents
based on their phonetic and semantic similarities, and
selects the best-matched one as the translation. The pho-
netic similarity is calculated from the surface string
transliteration model, and the semantic similarity is
measured according to the &amp;quot;distance&amp;quot; between the two
NEs&apos; context vectors, where the context vector is con-
structed based on the part-of-speech (POS) and relative
locations of the NEs&apos; surrounding words. Experiments
show that NE translation achieves a 67% accuracy with
the combined similarity models, and the translation
quality is consistently better on different translation
tasks than a state-of-the-art statistical machine transla-
tion system.
The structure of this paper is as follows: in section 2
we introduce the surface string transliteration model; in
section 3 we describe the contextual semantic similarity
model; we detail the query generation and retrieval
process in section 4. In section 5 we present the experi-
ments and analysis of the results. Conclusions will be
given in the last section.
applied in order to find NE pairs to estimate the translit-
eration probability from pinyin to English letter se-
quences.
To extract the NE pair (f *,e *) from a given bi-
lingual dictionary D , we want to find the entry with the
highest joint probability,
where P (f) is the probability of generating the charac-
ter sequence of the Chinese NE, which can be computed
directly from a character language model for Chinese
NEs. The estimation of P (e If), the probability of
transliterating the Chinese NE f into an English NE e ,
is as follows.
Suppose f has m characters. For i 1,2,..m , charac-
ter f is mapped into its pinyin syllable y , which is
further transliterated into an English letter string e .
Given that mappings from Chinese characters to their
pinyin syllables are mostly deterministic, i.e.,
</bodyText>
<figure confidence="0.978274769230769">
p(y I f )  1, we have
P(e If)
(2)
,
e
)
(1)
,
arg max
arg max
P (f
P (f
( I
e f
(
)
P
f
e
)
)
(
P
If)
e

</figure>
<sectionHeader confidence="0.830623" genericHeader="introduction">
2 Surface String Transliteration Model
</sectionHeader>
<bodyText confidence="0.99986256">
NE transliteration is the phonetic translation based on
pronunciation similarities between source and target NE
pairs. Considering that person and location names are
often phonetically translated and their written forms
resemble their pronunciations, it is possible to discover
NE translation pairs through their written forms, i.e.,
surface string transliteration. Compared with the tradi-
tional phoneme transliteration method, surface string
transliteration does not require a pronunciation lexicon,
which is an advantage especially for rare names. For
non-Latin-derived languages like Chinese and Arabic,
indirect surface string transliteration is feasible through
a romanization process which maps each character into
one or more Latin letters with similar pronunciation. For
example, the Chinese word &amp;quot; &amp;quot; is romanized
as the pinyin form &amp;quot;fei ci wo te&amp;quot;, which is the translation
of &amp;quot;fitzwater&amp;quot;.
Mappings between Chinese characters and their pin-
yin forms are usually deterministic, while mappings
between pinyin and English letters are more sophisti-
cated, and can be learned from a bilingual NE list. To
acquire such an NE list, we propose an unsupervised
learning approach in which NE pairs are automatically
extracted from a large bilingual dictionary. Dynamic
programming (DP)-based string alignment is iteratively
</bodyText>
<equation confidence="0.881337">
) � e y
( I ) .
Suppose y is composed of m letters, and for
</equation>
<bodyText confidence="0.95988225">
j 1,2,...m , the pinyin letter y is aligned to e , the
k th letter in e , where the alignment is represented
ask  a . Assuming independence of transliterated let-
ters we obtain,
</bodyText>
<subsectionHeader confidence="0.737936">
P (eIf)P(e Iy)P(e Iy ).(3)
</subsectionHeader>
<bodyText confidence="0.999949666666667">
That is, the transliteration probability between a
Chinese NE and an English NE is approximated by the
product of their letter transliteration probabilities.
Dynamic programming has been successfully ap-
plied to find the &amp;quot;optimal&amp;quot; alignment path between two
strings, where &amp;quot;optimal&amp;quot; means the minimum accumu-
lated editing cost between aligned word/letter pairs
(Levenstein 1965). Here the cost is usually defined as 0
if they are the same or 1 in case of an insertion, deletion
or substitution error. However, this binary cost function
is not appropriate for pronunciation-based transliteration,
because the phonetic similarity is more important than
the orthographic similarity; therefore, the alignment cost
between letters with similar pronunciations (e.g., &amp;quot;c&amp;quot;
and &amp;quot;k&amp;quot; or &amp;quot;p&amp;quot; and &amp;quot;b&amp;quot;) should be smaller. We take the
</bodyText>
<equation confidence="0.934030166666667">
I

f
� e y � y
( I ) (

</equation>
<bodyText confidence="0.999953705882353">
negative logarithm of the letter transliteration probabil-
ity as the matching cost, where the transliteration prob-
abilities are computed based on their alignment
frequency. However, the alignment frequency is
counted under a certain alignment cost function. To
resolve this model interdependency, the binary cost
function is initially applied to the DP string alignment.
Bilingual NE pairs are extracted from the dictionary
according to their alignment cost. Based on this initial
imperfect name list, the letter transliteration model and
character language model are trained, and employed for
the NE joint probability estimation. In the subsequent
iterations, the alignment cost function as well as the
transliteration probability is updated, NE pairs are re-
selected according to their joint probabilities, and trans-
literation and language models are re-trained using the
cleaner NE list.
</bodyText>
<sectionHeader confidence="0.984544" genericHeader="method">
3 Contextual Semantic Similarity Model
</sectionHeader>
<bodyText confidence="0.999914038461538">
Surface string transliteration model is effective in
finding NE translation pairs with similar pronunciations
and spellings, but it is weak at identifying NE pairs with
dissimilar pronunciations or discriminating different
target NEs with similar pronunciations. On the other
hand, NEs often occur within certain semantically re-
lated contexts, such as the title of a person or the
neighbor area of a location. It is possible to combine the
context&apos;s semantic similarity with the phonetic similar-
ity to improve the NE translation accuracy. As shown in
the previous example, although the pronunciations be-
tween &amp;quot; /hao /de /yang&amp;quot; and &amp;quot;van houten&amp;quot; are less
similar, the common context with which they both occur,
(here it is the title of the named person, &amp;quot;netherlands&apos;
ambassador to china&amp;quot;, although expressed in different
languages), indicates the strong association between the
source NE and the target NE.
Different context words have different power in pre-
dicting an NE&apos;s meanings; in other words, they have
different semantic correlation weights with regard to the
NE. The context words and their correlation weights can
be represented by a context vector, which characterizes
the NE&apos;s topical information. In this section, we will
describe how to create a context vector for a given NE,
and how to calculate the semantic similarity between the
source and target context vectors.
</bodyText>
<subsectionHeader confidence="0.999704">
3.1 Context Vector Selection
</subsectionHeader>
<bodyText confidence="0.999007615384615">
A context vector represents the words within a cer-
tain context of a given NE, while each word has a dif-
ferent weight reflecting its semantic significance to the
NE. Our task is to select context vector words and cal-
culate their correlation weights based on their POS tags
and distances to the NE. For each NE-word pair, the
word&apos;s correlation to the NE is initially measured by
Phi-square coefficients, which are further used for esti-
mating the weights of different POS tags and locations.
The POS tag weights imply the types of words that
should be included in the context vector, and the loca-
tion weights indicate the optimal length of the context
vector.
While mutual information describes the independ-
ence between random variables, Chi-square, including
its variant, Phi-square, is better at correlating two cate-
gorical variables. Unlike Chi-square, Phi-square&apos;s value
ranges from 0 (no correlation between the two variables)
to 1 (perfect correlation between them), thus a probabil-
istic interpretation is possible. In our problem, we want
to measure the correlation between an NE and its con-
text word, so the NE-word semantic correlation coeffi-
cient can be defined as:
,
,
,
are the frequencies that they co-occur,
that neither occur, and that one occurs and the other
does not occur. The higher the coefficient, the more
likely is it that the NE and the word are semantically
correlated.
To estimate a POS tag&apos;s semantic significance to an
NE, we calculate the mean of the correlation weight
over all NE-word pairs. The correlation weight is also
weighted by the probability that the word&apos;s POS is the
current POS tag. Suppose under the empirical NE-word
pair distribution f (n, w) , tis the POS tag of w ,which
is a context word of an NE n , and then p(t w) is the
probability that word w has POS tag t ,
</bodyText>
<figure confidence="0.49196485">
0
0
0
0
the POS tag&apos;s
weight is defined as:
) E Lp(t w)o(n, w)]
ranging fr
om -10 (left 10 CV words) to 10 (right 10 CV
0 ( , )
n w
(0 0 0 0 0 0 0 0
 )(  )(  )(  )

( 0 0  0 0 )
,
4
(
where n, w are the NE and its context word respectively,
where C(n, w) is the frequency that (n, w) co-occur.
</figure>
<figureCaption confidence="0.470901769230769">
Figure 1 illustrates the normalized weights of differ-
ent English POS tags, where one can observe that high
correlations are often associated with content words
(e.g., nouns, verbs and adjectives are likely the most
semantically related context words of an NE). Therefore
context vectors only include those content words whose
POS tag weight is larger than 0.03 (corresponding to the
top14 POS tags). We call them context vector (CV)
words, and only consider these CV words in the location
weight estimation.
Similar to the POS tag weights, location weights
represent the semantic significance of CV words at dif-
ferent positions. Starting from a 20 word long window
</figureCaption>
<figure confidence="0.732349454545455">
)
(n, w)p(t w)o(n, w), (5)
C

W(t
 1
 ( , )
C n w
words), the weight corresponding to location  can be
similarly estimated from the NE-word correlation coef-
ficients:
</figure>
<figureCaption confidence="0.996522">
Figure 2. Normalized Word Location Weights
</figureCaption>
<equation confidence="0.990437">
() = 1 I       
( , , ) ( I ), (6)
�   
( , , )
</equation>
<bodyText confidence="0.7431385">
where  is the location index,  E [-1 0, 1 0] ,  * 0.
(, , ) is the frequency that word  occurs at the
</bodyText>
<equation confidence="0.646428">
location  in the context vector of  .
</equation>
<figureCaption confidence="0.915025833333333">
Figure 2 illustrates the distribution of normalized lo-
cation weights, which looks Gaussian: the closer a loca-
tion is to the NE, the higher correlations it has. Notice
that about 95% of weights are distributed within the [-
7,7] window, so only the content words within this win-
dow are included in the context vector.
</figureCaption>
<bodyText confidence="0.7054795">
To summarize, the context vector of an NE is con-
structed from its left and right 7 content words, where
&amp;quot;content words&amp;quot; are those whose POS tags are in the top
14 Content POS tag Set (CPS). The context vector is
composed of both word identities and their semantic
significance to the NE:
</bodyText>
<equation confidence="0.745298">
={(,(,)) IE[-7,7] ,*0,E}, (7)
</equation>
<bodyText confidence="0.991175">
where (,) =()() is the product of their POS
and relative location weights.
</bodyText>
<subsectionHeader confidence="0.999923">
3.2 Semantic Similarity between Context Vectors
</subsectionHeader>
<bodyText confidence="0.938831">
Given a source and target NE pair ( ,  ) with their
context vectors ( ,  ) , the semantic similarity be-
tween the two vectors can be defined as the &amp;quot;mutual
translation probability&amp;quot;, which is the product of two
conditional semantic translation probabilities,
( ,  ) = ( I )( I ) (8)
where ( I  ) is regarded as the probability that the
</bodyText>
<note confidence="0.709695666666667">
source vector is &amp;quot;semantically translated&amp;quot; into the target
vector. It is computed with a modified IBM translation
model-2 [Brown et al. 1993],
</note>
<equation confidence="0.962278">
  
( I ) = 1 11 [ ( ,  )E( I)] (9)
</equation>
<bodyText confidence="0.976678">
where  is the length of the source vector and  is the
length of the target vector. With this formula, each word
in the source vector can be translated from any word in
the target vector. The word translation probability is
also adjusted by the POS and location weights of the
target word, which emphasize the correct translations of
important context words, for example the title of a per-
son. ( I ) is the word translation probability esti-
mated from a Chinese-English aligned corpus with IBM
model 1. ( I  ) is estimated in the similar way.
</bodyText>
<figureCaption confidence="0.991561">
Figure 1. Normalized Word POS Weights
</figureCaption>
<sectionHeader confidence="0.9790335" genericHeader="method">
4 Cross-lingual Retrieval for NE Transla-
tions
</sectionHeader>
<bodyText confidence="0.999939842105263">
Two similarity measures have been introduced to find
NE translation pairs: pronunciation similarity based on a
surface string transliteration model and semantic simi-
larities based on a context vector semantic model. In
this section, we will demonstrate how to apply these
measures to search for NE translation pairs using the
cross-lingual retrieval approach.
Given a Chinese NE together with the context in
which it occurs (e.g., a document), we want to find Eng-
lish documents containing the NE translation, such that
after automatically tagging all NEs in the retrieved text,
we can compare the source NE with each English NE
based on their phonetic and semantic measures, and
ultimately choose the best-matched English NE as the
translation. Assuming that documents containing the
same NE share common topics (even if the texts are
from different languages), our task is to search for topic-
relevant English documents using the Chinese document
as the query.
</bodyText>
<subsectionHeader confidence="0.996948">
4.1 Query Generation
</subsectionHeader>
<bodyText confidence="0.999989428571429">
Given the source document, the query for a target NE
translation search can be flexible: a few key phrases
around the NE, the sentence holding the NE, or even the
whole document. Containing less irrelevant information,
short queries usually can generate less unrelated target
text. However the identification and translation of key
source phrases are crucial: if the query is not carefully
selected or correctly translated, retrieved documents
may not contain the target NE translation. On the other
hand, long queries such as a sentence or the whole
document may be less focused but with richer context,
and the danger of missing relevant documents and cor-
rect NE translations is also reduced.
Due to the high risk of missing correct NE transla-
tion because of errors in identifying and translating
source key phrases, we prefer to choose a longer context
as the query, such as the whole document. In our current
implementation, we use a statistical machine translation
system to translate the Chinese document into English,
after that feed the translation hypothesis into any search
engine, such as Google or the Lemur Toolkit.
</bodyText>
<subsectionHeader confidence="0.999007">
4.2 Corpus Indexing and Search Engine
</subsectionHeader>
<bodyText confidence="0.999913928571429">
Most commercial search engines have the advantage of
accessing a large corpus and collecting huge informa-
tion from web pages on the World Wide Web, which is
very helpful for rare NE translations. However for our
research purposes at this stage we prefer a more flexible
corpus indexing strategy allowing both sentence-based
and document-based indexing. So we start by building
our own search engine using Lemur (Ogilvie and Callan
2002), a toolkit for language modeling and information
retrieval.
The indexed corpus is composed of 963,478 English
documents from the Xinhua News Agency, which cor-
responds to over 7.3 million sentences and 200 million
words. The indexing just follows the standard procedure
where no stemming and stop word removal is used. The
retrieval model is the widely used TF-IDF model.
Given a query, the search engine returns a ranked
list of relevant sentences or documents with relevance
scores. We experiment with both sentence-based and
document-based query generation and corpus indexing.
From a test data of Chinese newswire documents, we
selected 114 Chinese NEs and manually translated them,
then we used our MT system to translate the Chinese
sentences/documents containing these NEs into English.
Considering that rarely occurring NEs are the most dif-
ficult to translate, the translated NEs are mostly incor-
rect in the translation hypotheses. These English
hypotheses are fed into the search engine as the queries,
and the top 1000 English sentences or documents are
selected as the relevant text. We evaluated NE coverage
by counting how many correct NE translations can be
found in the retrieved texts, and it turned out that the
document-based query/indexing covered about 70% of
correct NE translations, while the sentence-based
query/indexing has the coverage of about 60%. The
reason may be that the topic information provided by
each sentence is rather limited, and if its translation hy-
pothesis is not reliable, the generated query could be
severely distorted from the original meaning, thus the
retrieved text may become irrelevant. In the following
experiments we only use document-based querying and
indexing.
</bodyText>
<subsectionHeader confidence="0.9976105">
4.3 Combining Similarity Features for NE Trans-
lation Selection
</subsectionHeader>
<bodyText confidence="0.999890357142857">
English NEs in the retrieved text are automatically
tagged using IdentiFinderTM, the NE tagging tool from
BBN (Bikel et al., 1997). For each tagged English NE,
its context vector is created according to its neighbor
content words, with their POS tags and locations, as
described in section 3.1.
To find the translation of a source NE n , we com-
pare it with each tagged NE in the retrieved English text,
using both transliteration similarity and context vector
semantic similarity. We create the context vector for
both the source NE and each tagged target NE. For each
source and target NE pair (n , n ) , with their corre-
sponding context vectors (v , v ) , their overall similar-
ity score is defined as:
</bodyText>
<equation confidence="0.707213">
D(n ,n ) P (n �n ) S(v ,v ),
�� �� (10)
</equation>
<bodyText confidence="0.991461888888889">
where P is the transliteration probability as computed
in formula (3) and S is the context vector semantic
similarity as computed in formula (8), A and A are the
weights of each model empirically chosen based on
experiment. The NE pairs with the highest overall simi-
larity scores are considered translations. In practice,
one source NE can be translated in several different
ways, which have similar pronunciations but different
spellings, and some of them are just typos. To make
sure that translated NEs follow most people&apos;s usage,
from among the top NE hypotheses with similar spell-
ing, we choose the one with the highest frequency as the
translation.
Figure 3 illustrates the overall architecture of the
NE translation. In addition to various modules and data
flows described above, one may notice the link from the
NE Translation Selector to the Machine Translation
module, which indicates that translated NE pairs can be
further integrated into the machine translation engine to
improve the query translation quality, retrieve better
relevant documents and improve NE translation again,
and this can be an iterative process.
into the existing NE pair list to update models. This
process continues until adding more NE pairs does not
improve the extraction accuracy further, which usually
happens at the 5-6 iteration where a total of
5,500�6,000 NE entries are included.
</bodyText>
<table confidence="0.9413295">
Iter. 0/1 1 2 3 4 5 6
Prec. 93.1 96.0 95.8 97.8 99.1 99.1 99.1
</table>
<tableCaption confidence="0.999613">
Table 1. Precision of Top 6000 NE Pairs Using
</tableCaption>
<subsectionHeader confidence="0.801312">
Different Models
</subsectionHeader>
<bodyText confidence="0.982232">
Table 1 presents the NE extraction precision of the top
6000 NE pairs using a different model in each iteration.
&amp;quot;0/1&amp;quot; represents the result when using only the starting
0/1 cost function. One can notice a trend of increasing
precision after each iteration, although the increase is
smaller and smaller until negligible at the 5-6 iteration,
indicating that most NE pairs in the dictionary have
already been included and that adding more non-NE
entries will not benefit the transliteration model.
</bodyText>
<subsectionHeader confidence="0.998751">
5.2 Creating Context Vectors
</subsectionHeader>
<bodyText confidence="0.999957833333333">
In section 3.1, the NE-word correlation coefficients are
estimated from a subset of the indexed English Xinhua
News corpus. It is composed of over 37 million words
from 188,755 documents. 380,641 unique English NEs
are automatically tagged, and the coefficient is calcu-
lated for each (NE, word) pair.
</bodyText>
<figureCaption confidence="0.914364">
Figure 3. Overall Architecture of NE Translation
</figureCaption>
<sectionHeader confidence="0.854676" genericHeader="method">
5 Experiment Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.54274">
5.1 Transliteration Model Training and Evalua-
</subsectionHeader>
<bodyText confidence="0.973354076923077">
tion
We train the Chinese-English surface string translitera-
tion model using the manually compiled Chinese-
English dictionary provided by LDC, which contains
English translations for 54,131 unique Chinese words.
Initially, 3,000 word translation pairs with a minimum
string matching cost are extracted, under the 0/1 cost
function. Most of them are NE pairs whose pinyin for-
mat resembles the English translation. The initial letter
transliteration model and Chinese character language
model are trained from this name list. Using these mod-
els, an additional 500 NE pairs with a minimum translit-
eration cost are extracted in each iteration, and added
</bodyText>
<figureCaption confidence="0.954507">
Figure 4. Context Words with High Correlation
</figureCaption>
<subsectionHeader confidence="0.546471">
Coefficients for the NE &amp;quot;Ehud Barak&amp;quot;
</subsectionHeader>
<bodyText confidence="0.894877357142857">
Figure 4 shows the top 20 words/coefficients for the
NE &amp;quot;Ehud Barak&amp;quot;, the former Israeli Prime Minister. It
shows that words with high coefficients are mostly topic
relevant words, which indicates that the Phi-square
based NE-word correlation coefficient is an effective
measure of topical relevance.
In the following example, we will show a Chinese
NE ( )&apos;s context vector created from a Chinese
sentence and the best-matched English NE (Otmar
Issing)&apos;s context vector created from the retrieved text,
then illustrate the semantic correlations between the two
vectors.
Chn: /NR /NN /NN
/NN /NR /NR /NN 20/CD /NR /P
</bodyText>
<sectionHeader confidence="0.6665052" genericHeader="method">
/NN /VV...
Eng: European/JJ Central/NNP Bank/NNP
Chief/NNP Economist/NNP Otmar/NNP Issing/VBG
told/VBD the/DT European/JJ Parliament/NNP last/JJ
week/NN that/IN ...
</sectionHeader>
<bodyText confidence="0.999847461538462">
In the above sentences, NEs are automatically
tagged and highlighted for each language. The POS
information has been automatically tagged as well,
where the taggers are trained from some manually anno-
tated data for each language using transformation-based
learning (Brill 1995). Considering POS and distance to
the NE, the context vectors (words and their normalized
weights) for the Chinese NE (left) and English NE
(right) are shown in Figure 5. The links between Chi-
nese and English words indicate they are translations of
each other. In this example, links between words with
high semantic weights show a strong correlation be-
tween the two context vectors.
</bodyText>
<figureCaption confidence="0.918418">
Figure 5. Context Vector of Chinese NE (left) and
Best-matched English NE (right)
</figureCaption>
<subsectionHeader confidence="0.917615">
5.3 Improving Machine Translation Quality with
NE Translation
</subsectionHeader>
<bodyText confidence="0.999707333333333">
To evaluate the effectiveness of the proposed NE trans-
lation strategy, we test it for a Chinese-English machine
translation task. The test dataset is the NIST 2002 Ma-
chine Translation Evaluation test data. The test data is
composed of 100 Chinese documents, 878 sentences,
and 25,430 words. 2469 NEs are automatically tagged,
and among them PERSON, LOCATION and
ORGANIZATION names roughly account for 20%,
60% and 20% respectively. Since most
ORGANIZATION NEs are semantically translated
word-by-word, and since we already have good word
and phrase translation components in the baseline sys-
tem, we will focus on PERSON and LOCATION NE
translations, as they are often transliterated.
The baseline system incorporates several word and
phrase transducers for text translation: a 50K entry
word-based C-E translation lexicon from LDC, which
has the best word translation accuracy because of man-
ual verification; several phrase transducers automati-
cally constructed from a 6M words bilingual corpus
using HMMs and integrated segmentation and align-
ment approaches (Vogel et. al. 2003). Importantly, the
baseline also includes a 39K entry NE transducer which
is constructed by aligning tagged NEs from the same
parallel corpus according to multiple NE alignment
costs (Huang et. al. 2003).
Among 1,898 tagged PERSON and LOCATION
NEs, 400 NEs are not covered by the LDC translation
lexicon. After manually removing incorrectly tagged
NEs, 338 true NEs (corresponding to 158 unique NEs)
are translated with the transliteration model plus the
semantic context vector model, and the translation hy-
potheses are compared with the reference translations
for evaluation.
Table 2 shows the type and token NE translation
precision using different similarity models, where
&amp;quot;Translit&amp;quot; means using the transliteration model only,
and &amp;quot;+SCV&amp;quot; means additionally combining the context
vector semantic model. It also shows the performance of
the baseline system, where the translations basically
come from several phrase and NE transducers trained
from the 6M words bilingual corpus. The limited paral-
lel corpus coverage explains the relatively lower per-
formance of the Baseline system, as the source NEs
cannot be found in the parallel corpus. When finding
NE translations from the retrieved monolingual text, the
surface string transliteration model alone increases the
translation precision by about 30%, and the context vec-
tor semantic model additionally improves the translation
accuracy by about 10%. Further error analysis indicates
that 50% of errors are due to the limited coverage of
retrieved documents, i.e., correct NE translations are
either not included in or not retrieved from the indexed
English corpus.
</bodyText>
<table confidence="0.9998798">
Token (338) Type (158)
Precision Precision
Baseline 27.8% 27.8%
+Translit 57.1% 50.0%
+SCV 67.8% 59.5%
</table>
<tableCaption confidence="0.998372">
Table 2. NE Translation Precision
</tableCaption>
<bodyText confidence="0.999935041666667">
We integrate both sets of NE translation hypotheses
into the baseline system: &amp;quot;+Translit&amp;quot; and &amp;quot;+SCV&amp;quot;, and
test them in different translation tasks: the small data
track and the large data track differing in the amount of
bilingual resources allowed for use. To accurately meas-
ure the contribution of the proposed NE translation
method, we first extract 164 sentences containing these
rarely occurring NEs from the whole test set (887 Chi-
nese sentences), translate and evaluate on this subset,
then we evaluate the NE translations on the whole test
data. The translation quality is measured by the auto-
matic MT evaluation metrics, such as NIST and Bleu
scores.
Table 3 shows the translation scores of different sys-
tem configurations on the NE sentences subset, and ta-
ble 4 shows the translation scores on the whole test data.
Because the selected sentences are hard to translate due
to these rarely occurring NEs, their translations have
lower NIST and Bleu scores than the whole test set (1.0
difference in NIST and 0.03 difference in Bleu for the
Baseline). When adding transliterated NE translations,
an obvious improvement can be observed in all the
cases. Additionally adding the context vector model also
leads to a small but consistent improvement.
</bodyText>
<table confidence="0.99695">
Small track Large track
NIST Bleu NIST Bleu
Baseline 5.6234 0.1166 6.8483 0.1794
+Translit 6.2684 0.1387 7.1969 0.2005
+SCV 6.3618 0.1404 7.2779 0.2025
</table>
<tableCaption confidence="0.997709">
Table 3. C-E MT Evaluation on NE Sentences
</tableCaption>
<table confidence="0.961908166666667">
Subset
Small track Large track
NIST Bleu NIST Bleu
Baseline 6.5765 0.1479 7.8733 0.2023
+Translit 6.7718 0.1537 7.9573 0.2075
+SCV 6.8702 0.1580 7.9790 0.2079
</table>
<tableCaption confidence="0.86653">
Table 4. C-E MT Evaluation on Whole Test
Set
</tableCaption>
<sectionHeader confidence="0.998406" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999970083333333">
We propose an approach to translate rarely occurring
NEs by combining their phonetic and semantic similari-
ties . Given a source NE and its context, this approach
generates queries in the target language according to the
context translation hypotheses, then searches for rele-
vant documents from a target corpus. Target NEs in
retrieved documents are compared with the source NE
based on their phonetic and contextual semantic simi-
larities, and the best-matched one is selected as the cor-
rect translation. Experiments show that this approach
achieves 67% on translation accuracy, and consistently
improves the translation quality on different tasks.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999871">
Y. Al-Onaizan and K. Knight. Translating named enti-
ties using monolingual and bilingual resources. In
Proceedings of the 40th Annual Meeting of the Asso-
ciation for Computational Linguistics, pp400-408,
Philadelphia, PA, July, 2002.
D. Bikel, S. Miller, R. Schwarz and R. Weischedel.
Nymble: A high-performance learning name-finder.
In Proceedings of Applied Natural Language
Processing, pp.194-201, Washington DC. 1997.
E. Brill. Transformation-based error-driven learning and
natural language processing: A case study in part of
speech tagging. Computational Linguistics, 21(4):
543--565. 1995.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and
R.L. Mercer. The mathematics of machine translation:
parameter estimation. In Computational Linguistics,
vol 19, number 2. pp.263-311. 1993.
N. A. Chinchor. Overview of MUC-7/MET-2. In Pro-
ceedings of the Seventh Message Understanding Con-
ference(MUC-7), Fairfax, VA, April, 1998.
F. Huang, S. Vogel and A. Waibel. Automatic extrac-
tion of named entity translingual equivalence based
on multi-feature cost minimization. In Proceedings of
the ACL&apos;03, Workshop on Multilingual and Mixed
Language Named Entity Recognition. Sapporo, Japan,
July, 2003.
K. Knight and J. Graehl. Machine transliteration. In
Proceedings of the ACL &apos;97. pp.128-135, Somerset,
New Jersey, 1997.
V. I. Levenshtein. Binary codes capable of correcting
deletions, insertions and reversals. Doklady Akademii
Nauk SSSR 163(4) p845-848, 1965.
H. Meng, W. K. Lo, B. Chen and K. Tang. Generating
phonetic cognates to handle named entities in Eng-
lish-Chinese cross-language spoken document re-
trieval. In Proceedings of the Automatic Speech
Recognition and Understanding Workshop, Trento,
Italy, December, 2001.
R. C. Moore. Learning translations of named-entity
phrases from parallel corpora. In Proceedings of 10th
Conference of the European Chapter of ACL, Buda-
pest, Hungary, 2003.
P. Ogilvie and J. Callan. Experiments using the Lemur
toolkit. In Proceedings of the 2001 Text REtrieval
Conference (TREC 2001). pp. 103-108, 2002.
http://www.cs.cmu.edu/-lemur
B. Stalls and K. Knight. Translating names and techni-
cal terms in Arabic text. In Proceedings of the
COLING/ACL Workshop on Computational Ap-
proaches to Semitic Languages. Montreal, Quebec,
Canada, 1998.
S. Vogel, Y. Zhang, F. Huang, A. Tribble, A. Venogu-
pal, B. Zhao and A. Waibel. The CMU statistical ma-
chine translation system. In Proceedings of the MT
Summit IX Conference New Orlean, LA, September,
2003.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.579882">
<title confidence="0.9978345">Improving Named Entity Translation Combining and Semantic Similarities</title>
<author confidence="0.911051">Fei Huang</author>
<author confidence="0.911051">Stephan Vogel</author>
<author confidence="0.911051">Alex</author>
<affiliation confidence="0.863902">Language Technologies School of Computer Carnegie Mellon</affiliation>
<email confidence="0.998992">fhuang@cs.cmu.edu</email>
<email confidence="0.998992">vogel@cs.cmu.edu</email>
<email confidence="0.998992">ahw@cs.cmu.edu</email>
<abstract confidence="0.999030608695652">This paper describes an approach to translate rarely occurring named entities (NE) by combining phonetic and semantic similarities. The phonetic similarity is estimated from a surface string transliteration model, and the semantic similarity is calculated from a context vector semantic model. Given a source (Chinese) NE and its context, this approach first generates queries in the target (English) language according to the context translation hypotheses, then searches for relevant documents from a target language corpus. Target NEs in retrieved documents are compared with the source NE based on their phonetic and contextual semantic similarities, and the bestmatched one is selected as the correct translation. Experiments show that this approach achieves 67% accuracy on translating rarely occurring NEs, and consistently improves the translation quality on different tasks over a state-of-the-art statistical machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>K Knight</author>
</authors>
<title>Translating named entities using monolingual and bilingual resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>400--408</pages>
<location>Philadelphia, PA,</location>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Y. Al-Onaizan and K. Knight. Translating named entities using monolingual and bilingual resources. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp400-408, Philadelphia, PA, July, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bikel</author>
<author>S Miller</author>
<author>R Schwarz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: A high-performance learning name-finder.</title>
<date>1997</date>
<booktitle>In Proceedings of Applied Natural Language Processing,</booktitle>
<pages>194--201</pages>
<location>Washington DC.</location>
<contexts>
<context position="20956" citStr="Bikel et al., 1997" startWordPosition="3410" endWordPosition="3413">ranslations, while the sentence-based query/indexing has the coverage of about 60%. The reason may be that the topic information provided by each sentence is rather limited, and if its translation hypothesis is not reliable, the generated query could be severely distorted from the original meaning, thus the retrieved text may become irrelevant. In the following experiments we only use document-based querying and indexing. 4.3 Combining Similarity Features for NE Translation Selection English NEs in the retrieved text are automatically tagged using IdentiFinderTM, the NE tagging tool from BBN (Bikel et al., 1997). For each tagged English NE, its context vector is created according to its neighbor content words, with their POS tags and locations, as described in section 3.1. To find the translation of a source NE n , we compare it with each tagged NE in the retrieved English text, using both transliteration similarity and context vector semantic similarity. We create the context vector for both the source NE and each tagged target NE. For each source and target NE pair (n , n ) , with their corresponding context vectors (v , v ) , their overall similarity score is defined as: D(n ,n ) P (n �n ) S(v ,v </context>
</contexts>
<marker>Bikel, Miller, Schwarz, Weischedel, 1997</marker>
<rawString>D. Bikel, S. Miller, R. Schwarz and R. Weischedel. Nymble: A high-performance learning name-finder. In Proceedings of Applied Natural Language Processing, pp.194-201, Washington DC. 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>543--565</pages>
<contexts>
<context position="25820" citStr="Brill 1995" startWordPosition="4196" endWordPosition="4197">sing)&apos;s context vector created from the retrieved text, then illustrate the semantic correlations between the two vectors. Chn: /NR /NN /NN /NN /NR /NR /NN 20/CD /NR /P /NN /VV... Eng: European/JJ Central/NNP Bank/NNP Chief/NNP Economist/NNP Otmar/NNP Issing/VBG told/VBD the/DT European/JJ Parliament/NNP last/JJ week/NN that/IN ... In the above sentences, NEs are automatically tagged and highlighted for each language. The POS information has been automatically tagged as well, where the taggers are trained from some manually annotated data for each language using transformation-based learning (Brill 1995). Considering POS and distance to the NE, the context vectors (words and their normalized weights) for the Chinese NE (left) and English NE (right) are shown in Figure 5. The links between Chinese and English words indicate they are translations of each other. In this example, links between words with high semantic weights show a strong correlation between the two context vectors. Figure 5. Context Vector of Chinese NE (left) and Best-matched English NE (right) 5.3 Improving Machine Translation Quality with NE Translation To evaluate the effectiveness of the proposed NE translation strategy, w</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics, 21(4): 543--565. 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of machine translation: parameter estimation.</title>
<date>1993</date>
<journal>In Computational Linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<contexts>
<context position="15780" citStr="Brown et al. 1993" startWordPosition="2570" endWordPosition="2573">re (,) =()() is the product of their POS and relative location weights. 3.2 Semantic Similarity between Context Vectors Given a source and target NE pair ( ,  ) with their context vectors ( ,  ) , the semantic similarity between the two vectors can be defined as the &amp;quot;mutual translation probability&amp;quot;, which is the product of two conditional semantic translation probabilities, ( ,  ) = ( I )( I ) (8) where ( I  ) is regarded as the probability that the source vector is &amp;quot;semantically translated&amp;quot; into the target vector. It is computed with a modified IBM translation model-2 [Brown et al. 1993],    ( I ) = 1 11 [ ( ,  )E( I)] (9) where  is the length of the source vector and  is the length of the target vector. With this formula, each word in the source vector can be translated from any word in the target vector. The word translation probability is also adjusted by the POS and location weights of the target word, which emphasize the correct translations of important context words, for example the title of a person. ( I ) is the word translation probability estimated from a Chinese-English aligned corpus with IBM model 1. ( I  ) is estimated in the similar way. Figu</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and R.L. Mercer. The mathematics of machine translation: parameter estimation. In Computational Linguistics, vol 19, number 2. pp.263-311. 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Chinchor</author>
</authors>
<title>Overview of MUC-7/MET-2.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conference(MUC-7),</booktitle>
<location>Fairfax, VA,</location>
<marker>Chinchor, 1998</marker>
<rawString>N. A. Chinchor. Overview of MUC-7/MET-2. In Proceedings of the Seventh Message Understanding Conference(MUC-7), Fairfax, VA, April, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>S Vogel</author>
<author>A Waibel</author>
</authors>
<title>Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL&apos;03, Workshop on Multilingual and Mixed Language Named Entity Recognition.</booktitle>
<location>Sapporo, Japan,</location>
<contexts>
<context position="3330" citStr="Huang et al. 2003" startWordPosition="467" endWordPosition="470">in NE translation that call for further investigation. (Knight and Graehl 1997) proposed a generative model for Japanese-English back transliteration, (Stalls and Knight 1998) expanded that model to Arabic-English transliteration, and (AlOnaizan and Knight 2002) additionally incorporated web counts to re-score the transliteration candidates. (Meng et al. 2001) developed an English-Chinese NE transliteration technique using a pronunciation lexicon and phonetic mapping rules. (Moore 2003) proposed statistical phrase translation models to find NE translations in English-French software manuals. (Huang et al. 2003) extracted NE translation pairs from a ChineseEnglish parallel corpus combining letter transliteration, word translation and NE tagging features, then constructed an NE translation dictionary based on alignment costs and frequencies. Aligning NE translations from a parallel corpus usually achieves high accuracy on frequently occurring NEs, but it fails in translating rarely occurring NEs which may not appear in the bilingual corpus, as shown in the following example: Chn: Ref.: netherlands&apos; ambassador to china, van houten Hyp: netherlands ambassador hao germany hurls It is noticed that &amp;quot;van ho</context>
</contexts>
<marker>Huang, Vogel, Waibel, 2003</marker>
<rawString>F. Huang, S. Vogel and A. Waibel. Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization. In Proceedings of the ACL&apos;03, Workshop on Multilingual and Mixed Language Named Entity Recognition. Sapporo, Japan, July, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine transliteration.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL &apos;97.</booktitle>
<pages>128--135</pages>
<location>Somerset, New Jersey,</location>
<contexts>
<context position="2791" citStr="Knight and Graehl 1997" startWordPosition="395" endWordPosition="398">n translating some frequent NEs, such as the names of countries, big companies or famous persons, it cannot handle the translation of rarely occurring names, especially new names. For example, in the 2001 Chinese-English translation evaluation test data, 20% of the automatically tagged Chinese NEs are not included in the 50K LDC ChineseEnglish translation lexicon. Although many research efforts have been focused on automatic NE detection, and good performance has been achieved in some languages (Chinchor 1997), there are still many areas in NE translation that call for further investigation. (Knight and Graehl 1997) proposed a generative model for Japanese-English back transliteration, (Stalls and Knight 1998) expanded that model to Arabic-English transliteration, and (AlOnaizan and Knight 2002) additionally incorporated web counts to re-score the transliteration candidates. (Meng et al. 2001) developed an English-Chinese NE transliteration technique using a pronunciation lexicon and phonetic mapping rules. (Moore 2003) proposed statistical phrase translation models to find NE translations in English-French software manuals. (Huang et al. 2003) extracted NE translation pairs from a ChineseEnglish paralle</context>
</contexts>
<marker>Knight, Graehl, 1997</marker>
<rawString>K. Knight and J. Graehl. Machine transliteration. In Proceedings of the ACL &apos;97. pp.128-135, Somerset, New Jersey, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1965</date>
<journal>Doklady Akademii Nauk SSSR</journal>
<volume>163</volume>
<issue>4</issue>
<pages>845--848</pages>
<marker>Levenshtein, 1965</marker>
<rawString>V. I. Levenshtein. Binary codes capable of correcting deletions, insertions and reversals. Doklady Akademii Nauk SSSR 163(4) p845-848, 1965.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>W K Lo</author>
<author>B Chen</author>
<author>K Tang</author>
</authors>
<title>Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the Automatic Speech Recognition and Understanding Workshop,</booktitle>
<location>Trento, Italy,</location>
<contexts>
<context position="3074" citStr="Meng et al. 2001" startWordPosition="433" endWordPosition="436">inese NEs are not included in the 50K LDC ChineseEnglish translation lexicon. Although many research efforts have been focused on automatic NE detection, and good performance has been achieved in some languages (Chinchor 1997), there are still many areas in NE translation that call for further investigation. (Knight and Graehl 1997) proposed a generative model for Japanese-English back transliteration, (Stalls and Knight 1998) expanded that model to Arabic-English transliteration, and (AlOnaizan and Knight 2002) additionally incorporated web counts to re-score the transliteration candidates. (Meng et al. 2001) developed an English-Chinese NE transliteration technique using a pronunciation lexicon and phonetic mapping rules. (Moore 2003) proposed statistical phrase translation models to find NE translations in English-French software manuals. (Huang et al. 2003) extracted NE translation pairs from a ChineseEnglish parallel corpus combining letter transliteration, word translation and NE tagging features, then constructed an NE translation dictionary based on alignment costs and frequencies. Aligning NE translations from a parallel corpus usually achieves high accuracy on frequently occurring NEs, bu</context>
</contexts>
<marker>Meng, Lo, Chen, Tang, 2001</marker>
<rawString>H. Meng, W. K. Lo, B. Chen and K. Tang. Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval. In Proceedings of the Automatic Speech Recognition and Understanding Workshop, Trento, Italy, December, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Learning translations of named-entity phrases from parallel corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of 10th Conference of the European Chapter of ACL,</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="3203" citStr="Moore 2003" startWordPosition="451" endWordPosition="452">atic NE detection, and good performance has been achieved in some languages (Chinchor 1997), there are still many areas in NE translation that call for further investigation. (Knight and Graehl 1997) proposed a generative model for Japanese-English back transliteration, (Stalls and Knight 1998) expanded that model to Arabic-English transliteration, and (AlOnaizan and Knight 2002) additionally incorporated web counts to re-score the transliteration candidates. (Meng et al. 2001) developed an English-Chinese NE transliteration technique using a pronunciation lexicon and phonetic mapping rules. (Moore 2003) proposed statistical phrase translation models to find NE translations in English-French software manuals. (Huang et al. 2003) extracted NE translation pairs from a ChineseEnglish parallel corpus combining letter transliteration, word translation and NE tagging features, then constructed an NE translation dictionary based on alignment costs and frequencies. Aligning NE translations from a parallel corpus usually achieves high accuracy on frequently occurring NEs, but it fails in translating rarely occurring NEs which may not appear in the bilingual corpus, as shown in the following example: C</context>
</contexts>
<marker>Moore, 2003</marker>
<rawString>R. C. Moore. Learning translations of named-entity phrases from parallel corpora. In Proceedings of 10th Conference of the European Chapter of ACL, Budapest, Hungary, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ogilvie</author>
<author>J Callan</author>
</authors>
<title>Experiments using the Lemur toolkit.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Text REtrieval Conference (TREC</booktitle>
<pages>103--108</pages>
<note>http://www.cs.cmu.edu/-lemur</note>
<marker>Ogilvie, Callan, 2001</marker>
<rawString>P. Ogilvie and J. Callan. Experiments using the Lemur toolkit. In Proceedings of the 2001 Text REtrieval Conference (TREC 2001). pp. 103-108, 2002. http://www.cs.cmu.edu/-lemur</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Stalls</author>
<author>K Knight</author>
</authors>
<title>Translating names and technical terms in Arabic text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="2887" citStr="Stalls and Knight 1998" startWordPosition="408" endWordPosition="411">, it cannot handle the translation of rarely occurring names, especially new names. For example, in the 2001 Chinese-English translation evaluation test data, 20% of the automatically tagged Chinese NEs are not included in the 50K LDC ChineseEnglish translation lexicon. Although many research efforts have been focused on automatic NE detection, and good performance has been achieved in some languages (Chinchor 1997), there are still many areas in NE translation that call for further investigation. (Knight and Graehl 1997) proposed a generative model for Japanese-English back transliteration, (Stalls and Knight 1998) expanded that model to Arabic-English transliteration, and (AlOnaizan and Knight 2002) additionally incorporated web counts to re-score the transliteration candidates. (Meng et al. 2001) developed an English-Chinese NE transliteration technique using a pronunciation lexicon and phonetic mapping rules. (Moore 2003) proposed statistical phrase translation models to find NE translations in English-French software manuals. (Huang et al. 2003) extracted NE translation pairs from a ChineseEnglish parallel corpus combining letter transliteration, word translation and NE tagging features, then constr</context>
</contexts>
<marker>Stalls, Knight, 1998</marker>
<rawString>B. Stalls and K. Knight. Translating names and technical terms in Arabic text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages. Montreal, Quebec, Canada, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>Y Zhang</author>
<author>F Huang</author>
<author>A Tribble</author>
<author>A Venogupal</author>
<author>B Zhao</author>
<author>A Waibel</author>
</authors>
<title>The CMU statistical machine translation system.</title>
<date>2003</date>
<booktitle>In Proceedings of the MT Summit IX Conference</booktitle>
<location>New Orlean, LA,</location>
<marker>Vogel, Zhang, Huang, Tribble, Venogupal, Zhao, Waibel, 2003</marker>
<rawString>S. Vogel, Y. Zhang, F. Huang, A. Tribble, A. Venogupal, B. Zhao and A. Waibel. The CMU statistical machine translation system. In Proceedings of the MT Summit IX Conference New Orlean, LA, September, 2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>