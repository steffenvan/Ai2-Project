<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005224">
<title confidence="0.981923">
Evidentiality for Text Trustworthiness Detection
</title>
<author confidence="0.998743">
Qi Su1, 2, Chu-Ren Huang and Helen Kai-yun Chen
</author>
<affiliation confidence="0.996655">
1Depart of Chinese &amp; Bilingual Studies, The Hong Kong Polytechnic University
2Key Laboratory of Computational Linguistics, Peking University
</affiliation>
<email confidence="0.99419">
sukia@pku.edu.cn, {helenkychen, churen.huang}@gmail.com
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999771888888889">
Evidentiality is the linguistic representation of
the nature of evidence for a statement. In
other words, it is the linguistically encoded
evidence for the trustworthiness of a state-
ment. In this paper, we aim to explore how
linguistically encoded information of eviden-
tiality can contribute to the prediction of
trustworthiness in natural language processing
(NLP). We propose to incorporate evidential-
ity into a framework of machine learning
based text classification. We first construct a
taxonomy of evidentials. Then experiments
involving collaborative question answering
(CQA) are designed and implemented using
this taxonomy. The experimental results con-
firm that evidentiality is an important clue for
text trustworthiness detection. With the bi-
narized vector setting, evidential based text
representation model has considerably per-
formaned better than both the bag-of-word
model and the content word based model.
Most crucially, we show that the best trust-
worthiness detection result is achieved when
evidentiality is incorporated in a linguistically
sophisticated model where their meanings are
interpreted in both semantic and pragmatic
terms.
</bodyText>
<sectionHeader confidence="0.999338" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999990166666667">
With the exponential increase in web sites and
documents, the amount of information is no
longer a main concern for automatic knowledge
acquisition. This trend raises, however, at least
two new issues. The first is how to locate the
information which exactly meets our needs
among the vast web content. Efforts to address
this issue can be exemplified by advanced re-
search in information retrieval, information ex-
traction, etc. The second is how to judge the va-
lidity of the acquired information, that is, the
trustworthiness of information. This issue has
attracted considerable interest in some related
research areas recently. Taking the specific in-
formation retrieval task, question answering
(QA) as an example, a QA system attempts to
retrieve the most appropriate answers to ques-
tions from web resources. To determine the
trustworthiness of the extracted candidate an-
swers, a common approach is to exploit the co-
occurrence frequency of questions and candidate
answers. That is, if a candidate answer co-occurs
more frequently with the question than other
candidates, the QA system may judge it as the
best answer (Magnini, 2002). This approach pre-
supposes and relies crucially on information re-
dundancy. Although this heuristic method is
simple and straightforward, it is not applicable
to all cases. For the applications which don’t
involve much information redundancy, the heu-
ristic could cease to be effective. The task of
collaborative question answering (CQA) which
we will address in this paper is just one of such
examples. For a user posted question, there are
usually only few answers provided. So, the heu-
ristic is not useful in providing the best answer.
In addition, since the spread of unsubstantiated
rumors on the Internet is so pervasive, the high-
frequency information on the Web sometimes
may mislead the judgment of trustworthiness. In
terms of the above consideration, it is essential
to look for other approaches which allow di-
rectly modeling of the trustworthiness of a text.
Given that non-textual features (such as user&apos;s
Web behavior) used in text trustworthiness de-
tection are often manipulated by information
providers, as well as no directly related textual
features for the task has been proposed up to
</bodyText>
<page confidence="0.987157">
10
</page>
<note confidence="0.97926">
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 10–17,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999994689655172">
date, we need a more felicitous model for detect-
ing the trustworthiness of statements. Noting
that evidentiality is often linguistically encoded
and hence provides inherent information on
trustworthiness for a statement, we propose to
incorporate the linguistic model of evidentiality
in our study. Specifically, we incorporate evi-
dentiality into a machine learning based text
classification framework, and attempt to verify
the validity of evidentiality in trustworthiness
prediction of text information in the context of
collaborative question answering. The experi-
mental results show that evidentials are impor-
tant clues in predicting the trustworthiness of
text. Since none of the task-specific heuristics
has been incorporated, the current approach
could also be easily adapted to fit other natural
language processing applications.
The paper proceeds as follows. In section 2
we discuss related work on text trustworthiness
detection. The section is divided into two parts:
the current methodology and the textual features
for analysis in the task. Section 3 introduces the
linguistic researches on evidentiality and our
taxonomy of evidentials based on the trustwor-
thiness indication. Section 4 presents the ex-
periment settings and results. Finally, in section
5 we discuss the experiment results and con-
clude the current research.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999693153846154">
The research of text trustworthiness is very
helpful for many other natural language process-
ing applications. For example, in their research
on question answering, Banerjee and Han (2009)
modulate answer grade by using a weighted
combination of the original score and answer
credibility evaluation. Also, Weerkamp and Ri-
jke (2008) incorporate textual credibility indica-
tors in the retrieval process to improve topical
blog posts retrieval. Gyongyi et al (2004) pro-
pose a TrustRank algorithm for semi-
automatically separating reputable, good Web
pages from spams.
</bodyText>
<subsectionHeader confidence="0.989528">
2.1 General Approaches for Text Trust-
worthiness Detection
</subsectionHeader>
<bodyText confidence="0.999953641509434">
In past research, the judgment for the trustwor-
thiness or credibility of a given text content is
usually tackled from two aspects: entity oriented
and content oriented (Rubin and Liddy, 2005).
The former approach takes into consideration
the information providers’ individual profiles,
such as their identity, reputation, authority and
past web behavior; whereas the latter approach
considers the actual content of texts. Metzger
(2007) reviews several cognitive models of
credibility assessment and points out that credi-
bility is a multifaceted concept with two primary
dimensions: expertise and trustworthiness. Fol-
lowing Matzger’s framework, Rubin and Liddy
(2005) compile a list of factors that users may
take into account in assessing credibility of blog
sites. This list could also be summarized as the
above mentioned two-folds: the bloggers’ pro-
files and the information posted in the entries.
Comparing these two aspects, most existing
research on text trustworthiness focuses on the
user oriented features. Lots of user oriented fea-
tures have been proposed in the research of
credibility detection. To score the user oriented
features such as user’s authority, a common ap-
proach is based on a graph-based ranking algo-
rithm such as HITS and PageRank (Zhang et al,
2007; Bouguessa et al, 2008).
In the research of text trustworthiness detec-
tion, the overwhelmingly adaption of non-
textual features such as entity profiles over text
content based features reflect some researchers’
belief that superficial textual features cannot
meet the need of text credibility identification
(Jeon et al, 2006). In this paper, we examine the
lexical semantic feature of evidential and argue
that evidentiality, as a linguistically instantiated
representation of quality of information content,
offers a robust processing model for text trust-
worthiness detection.
The detection of information trustworthiness
also has promising application values. Google
News 1 is just such an application that ranks
search results according to the credibility of the
news. Other online news aggregation service,
such as NewTrust 2, also focuses on providing
users with credible and high quality news and
stories. The existed applications, however, rely
on either the quality of web sites or user voting.
So, it is anticipated that the improvement on the
technology of text trustworthiness detection by
incorporating lexical semantic cues such as evi-
dentiality may shed light on these applications.
</bodyText>
<subsectionHeader confidence="0.9992775">
2.2 Textual Feature Based Text Trustwor-
thiness Detection
</subsectionHeader>
<bodyText confidence="0.997884666666667">
Although non-textual features have been popular
in text credibility detection, there has been a few
research focusing on textual features so far. Gil
</bodyText>
<footnote confidence="0.9988185">
1 http://news.google.com/
2 http://www.newstrust.net/
</footnote>
<page confidence="0.999246">
11
</page>
<bodyText confidence="0.999970666666667">
and Artz (2006) argue that the degree of trust in
an entity is only one ingredient in deciding
whether or not to trust the information it pro-
vides. They further point out that entity-centered
issues are made with respect to publicly avail-
able data and services, and thus will not be pos-
sible in many cases. In their research of topical
blog posts retrieval, Weerkamp and Rijke (2008)
also consider only textual credibility indicators
since they mentioned that additional resources
(such as bloggers’ profiles) is hard to obtain for
technical or legal reasons.
However, most research which utilizes textual
features in text trustworthiness detection usually
equates writing quality of document with its
trustworthiness. Therefore, some secondary fea-
tures which may not directly related to trustwor-
thiness are proposed, including spelling errors,
the lack of leading capitals, the large number of
exclamation markers, personal pronouns and
text length (Weerkamp and Rijke, 2008). There
has not been attempted to directly evaluate in-
herent linguistic cues for trustworthiness of a
statement.
</bodyText>
<sectionHeader confidence="0.87891" genericHeader="method">
3 On Evidentiality in Text
</sectionHeader>
<bodyText confidence="0.999958909090909">
Evidentiality, as an explicit linguistic system to
encode quality of information, offers obvious
and straightforward evidence for text trustwor-
thiness detection. Yet it has not attracted the at-
tention which it deserves in most of the natural
language processing studies. In this paper, we
aim to explore how we can incorporate the lin-
guistic model of evidentiality into a robust and
efficient machine learning based text classifica-
tion framework.
Aikhenvald (2003) observes that every lan-
guage has some way of making reference to the
source of information. Once the language is be-
ing used, it always imprinted with the subjective
relationship from the speakers towards the in-
formation. Evidentiality is information provid-
ers’ specifications for the information sources
and their attitudes toward the information. As a
common linguistic phenomenon to all the lan-
guages, it has attracted linguists’ attention since
the beginning of 20th century. In any language,
evidentiality is a semantic category which could
be expressed on both grammatical level (as in
some American Indian language) and lexical
level (as in English, Chinese and many other
languages). The linguistic expressions of eviden-
tiality are named as evidentials or evidential
markers.
Mushin (2000) defines evidential as a marker
which qualifies the reliability of information. It
is an explicit expression of the speaker’s atti-
tudes toward the trustworthiness of information
source. For instance,
</bodyText>
<figure confidence="0.7572666">
a). It’s probably raining.
b). It must be raining.
c). It sounds like it’s raining.
d). I think/guess/suppose it’s raining.
e). I can hear/see/feel/smell it raining.
</figure>
<bodyText confidence="0.99956">
It is obvious that the information provided in
the above examples is subjective. The informa-
tion expresses the personal experience or atti-
tudes, while at the same time reflects the speak-
ers’ estimation for the trustworthiness of the
statement by information providers.
</bodyText>
<subsectionHeader confidence="0.996182">
3.1 The Definition of Evidentiality
</subsectionHeader>
<bodyText confidence="0.93754308">
There are two dimensions of the linguistic defi-
nition for evidentiality. The term evidentiality is
originally introduced by Jakobson (1957) as a
label for the verbal category indicating the al-
leged source of information about the narrated
events. In line with Jakobson’s definition, the
narrow definition of evidentiality proposed by
other researchers focuses mainly on the specifi-
cation of the information sources, that is, the
evidence through which information is acquired
(DeLancey, 2001). Comparing with the narrow
definition, the board definition explains eviden-
tiality in a much wider sense, and characterizes
evidentiality as expressions of speaker’s attitude
toward information, typically expressed by mo-
dalities (Chafe, 1986; Mushin, 2000).
Ifantidou (2001) also holds that evidential has
two main functions: 1) indicating the source of
knowledge; 2) indicating the speaker’s degree of
certainty about the proposition expressed. He
further divides them in details as follows.
a) Information can be acquired in various
ways, including observation (e.g. see), hearsay
(e.g. hear, reportedly), inference (e.g. must, de-
duce), memory (e.g. recall).
</bodyText>
<listItem confidence="0.9450082">
b) Evidentiality can indicate the speaker’s de-
gree of certainty, including certain propositional
attitude (e.g. think, guess) and adverbials (e.g.
certainly, surely), also epistemic models (e.g.
may, ought to).
</listItem>
<subsectionHeader confidence="0.999081">
3.2 The Taxonomy of Evidentials
</subsectionHeader>
<bodyText confidence="0.99977275">
Evidentiality has its hierarchy which forms a
continuum that marks from the highest to the
least trustworthiness. Up to now, there are many
hierarchical schemes proposed by researchers.
</bodyText>
<page confidence="0.989669">
12
</page>
<table confidence="0.99979">
Absolute High Moderate Low
Attributive/modal certainly, sure, of clearly, obviously, ap- Seemingly, maybe, personally,
adverb course, definitely, ab- parently, really, always probably perhaps, possibly,
solutely, undoubtedly presumably
Lexical verb report, certain believe, see seem, think, sound doubt, wish, wonder,
infer, assume, fore-
cast, fell, heard
Auxiliary verb must ought, should, would, may, might
could, can
Epistemic adjec- definite possible, likely, not sure, doubtful
tive unlikely, probable,
positive, potential
</table>
<tableCaption confidence="0.999365">
Table 1. The Categorization and Inside Items of Evidentiality
</tableCaption>
<table confidence="0.5563045">
Oswalt (1986) suggests a priority hierarchy of
evidentials as:
Performative &gt; Factual &gt; Visual &gt; Auditory &gt;
Inferential &gt; Quotative
</table>
<bodyText confidence="0.994191966666667">
In this evidential hierarchy, performative car-
ries the highest degree of trustworthiness since
Oswalt considers that the speaker is speaking of
the act he himself is performing. It is the most
reliable source of evidence for the knowledge of
that event.
Whereas Barners (1984) proposes the follow-
ing hierarchy:
Visual &gt; Non-visual &gt; Apparent &gt; Second-
hand &gt; Assumed
He points out that visual evidence takes
precedence over the auditory evidence and is
more reliable.
The above two hierarchies are based on the
narrow definition of evidentiality mentioned
above. There are also some hierarchies involving
the board definition of evidentiality, such as
Chafe (1986)’s categories of evidentiality.
In this paper, we adopt a broad definition of
evidentiality and focus on a trustworthiness
categorization. This categorization follows the
model of four-dimensional certainty categoriza-
tion by Rubin et al (2005). In this model, it is
suggested that the division of the certainty level
dimension into four categories - Absolute, High,
Moderate and Low. With some revision, there
are different items of evidential words and
phrased that we extracted from the corpus.
These items from each category to be adopted in
our experiments are presented in Table 1.
</bodyText>
<sectionHeader confidence="0.995733" genericHeader="method">
4 Incorporating Evidentiality into Ma-
chine Learning for Trustworthiness
Detection
</sectionHeader>
<bodyText confidence="0.999981725">
In this section, we apply evidentiality in an ac-
tual implement of text trustworthiness detection.
It is based on a specific web application service,
collaborative question answering (CQA), in
which the trustworthiness of text content is very
helpful for finding the best answers in the ser-
vice.
With the development of Web2.0, the services
of CQA in community media have largely at-
tracted people’s attention. Comparing with the
general ad hoc information searching, question
answering could help in finding the most accu-
rate answers extracted from the vast web content.
Whereas in the collaborative question answering,
the CQA community media just provide a web
space in which users can freely post their ques-
tions, and at the same time other users may an-
swer these questions based on their knowledge
and interests. Due to the advantage of interactiv-
ity, CQA usually could settle some questions
which cannot be dealt with by ad hoc informa-
tion retrieval. However, since the platform is
open to anyone, the quality of the answers pro-
vided by users is hard to identify. People may
present answers of various qualities due to the
limitation of their knowledge, attitude and pur-
pose of answering the questions. As a result, the
issue of how to identify the most trustworthy
answers from the user-provided content turns
out to be the most challenging part to the system.
As mentioned previously, the trustworthiness
of text content could be identified from two di-
mensions. The first one relies on the features
related with information distributors. The second
one relies on the content of a text. In current re-
search we focus on textual features, especially
the feature of evidentiality in texts. The feature
will be incorporated into a machine learning
based text classification framework in order to
identify the best answers for CQA questions.
</bodyText>
<page confidence="0.997632">
13
</page>
<subsectionHeader confidence="0.977535">
4.1 The Dataset
</subsectionHeader>
<bodyText confidence="0.999938228571429">
For the experiments, we use the snapshot of Ya-
hoo! Answers dataset which is crawled by Emo-
ry University3. Since our experiments only in-
volve text features, we use the answer parts from
it without considering the question sets and user
profiles. Such information could be incorporated
to achieve a higher performance in the future.
With regard to the text classification problems,
there is typically a substantial class distribution
skew (Forman, 2003). For the Yahoo! Answers
dataset, a question only has one best answer and
accordingly all the other answers will be marked
as non-best answers. Thus the class of best an-
swer contains much fewer texts than the class of
non-best answers. In our dataset (a proportion of
the overall CQA dataset provided by Emory
University), the number of best answers is 2,165,
and the number of non-best answers is 17,654.
The proportion of the size of the two answer sets
is around 1:8.15, showing a significant skews.
For a better comparison of experimental results,
we use a balanced dataset which is generated
from a normal distribution dataset.
A 10-fold validation is used for the evaluation,
where the datasets of best and non-best answers
are divided into 10 subsets of approximately
equal size respectively. In the normally distrib-
uted dataset, we use one of the ten subsets as the
test set, while the other nine are combined to-
gether to from the training set. In the balanced
dataset, for each subset of the non-best answers,
we only use the first k answers, in which k is the
size of each subset of best answers. The training
data and test data used in the machine learning
process are shown in Table 2.
</bodyText>
<table confidence="0.999617333333333">
Training Best Non-best
/Test Set answer answer
normal training 19,490 158,889
distribution
dataset
test 2,165 17,654
balanced training 19,490 19,490
dataset
test 2,165 2,165
</table>
<tableCaption confidence="0.999869">
Table 2. The Dataset Used for the Experiments
</tableCaption>
<subsectionHeader confidence="0.982632">
4.2 Experiment Settings
</subsectionHeader>
<bodyText confidence="0.99998175">
To conduct a machine learning based classifica-
tion for best answers and non-best answers, we
first need to construct the feature vectors. The
representation of text is the core issue in the ma-
</bodyText>
<footnote confidence="0.724735">
3 http://ir.mathcs.emory.edu/shared
</footnote>
<bodyText confidence="0.867998574074074">
chine learning model for text classification. In
text domains, feature selection plays an essential
role to make the learning task efficient and more
accurate. As the baseline comparison, we use the
following feature vector settings.
·Baseline1 represents using all the words in
the text as features (when the frequency of the
word in the dataset is bigger than a predefined
threshold j).
· Baseline2 represents using all the content
words (here we include the four main categories
of content words - nouns, verbs, adjectives and
adverbs identified by a POS tagger) in the data-
set as features.
We use both the above two baselines. The
bag-of-word model of Baseline1 is a conven-
tional method in text representation. However,
since not all the words are linguistically signifi-
cant, in Baseline2, we consider only the content
words in the dataset, since content words convey
the core meaning of a sentence.
For the evidentiality-based classification, we
adopt the following feature vector settings.
·Evidential represents using all the evidentials
in text as features.
·Evidential’ represents using all the eviden-
tials except for those in the category of Moder-
ate as features.
·Evid.cat4 represents using the four eviden-
tiality categories of Absolute, High, Moderate
and Low from Table 1.
·Evid.cat2 represents using the two categories
of Absolute and High as the positive evidential
and Moderate and Low as the negative evidential.
·Evid.cat2’ omits the evidential category of
Moderate, and represents using the two catego-
ries of Absolute and High as the positive eviden-
tial and only the category of Low as the negative
evidential feature.
Some researchers have proved that usually a
Boolean indicator of whether the feature item
occurred in the document is sufficient for classi-
fication (Forman, 2003). Although there are also
some other feature weighting schemes such as
term frequency (TF), document frequency (DF),
etc, comparison of these different weighting
schemes is not the object of the current research.
So in this paper, we only consider Boolean
weighting. In the Boolean text representation
model, each feature represents the Boolean oc-
currence of a word, evidential, or evidential cat-
egory according to the different feature settings.
By the experimental settings, we want to verify
the hypothesis that incorporating the knowledge
</bodyText>
<page confidence="0.997757">
14
</page>
<bodyText confidence="0.999484882352941">
of evidentiality into text representation can lead
to improvement in classification performance.
In our experiment, we perform text preproc-
essing including word segmentation and part-of-
speech (POS) tagging. The Stanford Log-linear
Part-Of-Speech Tagger (http://nlp.stanford.edu/
software/tagger.shtml) is used for POS tagging.
We adopt support vector machine (SVM) as the
machine learning model to classify best answers
from non-best ones, and use the SVMlight pack-
age (http://svmlight.joachims.org) as the classi-
fier with the default parameters and a linear ker-
nel. For the evaluation, we use the metrics of
precision (Prec. as in table 3), recall (Rec. as in
table 3), accuracy (Acc. as in table 3) and F1:
F1-measure, the harmonic mean of the precision
and recall.
</bodyText>
<subsectionHeader confidence="0.99463">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999836714285714">
Table 3 shows the experimental results using the
balanced dataset with Boolean weighting. The
focus of the experiment evaluation is on identi-
fying the best answers, so the evaluation metrics
are all for the best answers collection. From the
table, we see increases of the two feature vector
setting of evidentials over both baseline results.
The highest improvement is 14.85%, achieved
by the feature set of Evidential’. However, there
is no increase found in the settings of using evi-
dential categories. This means that although the
category of evidentials in indicating text trust-
worthiness is obvious for human, it is not neces-
sary a preferred feature for machine learning.
</bodyText>
<table confidence="0.999680375">
Prec. Rec. Acc. F1
Baseline1 45.62% 51.51% 45.15% 47.94%
Baseline2 59.58% 39.20% 56.30% 47.28%
Evidential 67.78% 44.18% 61.59% 53.49%
Evidential’ 47.40% 90.12% 45.06% 62.13%
Evid.cat4 64.15% 25.85% 55.70% 36.85%
Evid.cat2 60.86% 28.21% 55.03% 38.55%
Evid.cat2’ 40.35% 25.85% 43.81% 31.51%
</table>
<tableCaption confidence="0.735129666666667">
Table 3. Experimental Results Using the Bal-
anced Training/Test Dataset (with Boolean
Weighting)
</tableCaption>
<bodyText confidence="0.996512">
To eliminate the potential effect of term
weighting scheme on performance trend among
different text representation models, we also
conduct experiments using TF weighting. By the
experiments, we aim to compare the relative per-
formances of different feature vectors con-
structed with evidentials, and the results are
demonstrated in Table 4.
</bodyText>
<table confidence="0.999628">
Prec. Rec. Acc. F1
Evidential 66.78% 45.57% 61.45% 54.17%
Evidential’ 59.66% 20.82% 53.37% 30.87%
Evid.cat4 50.00% 18.14% 50.00% 26.63%
Evid.cat2 55.91% 16.39% 51.73% 25.35%
</table>
<tableCaption confidence="0.9720045">
Table 4. Experimental Results Using the Bal-
anced Training/Test Dataset (with TF Weighting)
</tableCaption>
<bodyText confidence="0.9997035625">
From the table, it can be observed that using
evidentials as features shows better improve-
ment in the performance than the category of
evidentials as a feature. A similar performance
has been summarized in Table 3.
Finally, but not the least, to better understand
the effect of evidential category on the machine
learning performance, we design additional ex-
periments as follows.
·Evid_cat1 stands for combining the four evi-
dential categories into one, and uses only this
one category of evidential as a feature. The ap-
proach of Boolean weighting is actually the
same as a rule-based approach that classifies the
test dataset according to whether evidential oc-
curs or not.
</bodyText>
<table confidence="0.9752885">
BOOL Prec. Rec. Acc. F1
Evid_cat1 59.42% 61.59% 59.76% 60.49%
</table>
<tableCaption confidence="0.846654">
Table 5. Experimental Results Using the Bal-
anced Training/Test Dataset (with Boolean
Weighting; Only One Evidential Category)
</tableCaption>
<bodyText confidence="0.991209692307692">
Table 5 presents a set of interesting experi-
mental result. In the result, all the four evalua-
tion metrics show performance increases com-
paring to the baseline, and it even outperforms
almost all the other results from both weighting
schemes. Based on this result, it is suggested
that evidentiality still may contribute to the task
of text trustworthiness detection. Moreover, it
can significantly reduce the dimensionality of
feature space (e.g. for Baseline 1, the dimen-
sionality of feature dimension is 218,328 in one
of our cases; while for the experiment of Evi-
dential, it reduced to only 51 as shown in Table
</bodyText>
<page confidence="0.992426">
15
</page>
<bodyText confidence="0.9991818">
1). However, we should address the question of
why not all types of evidential features demon-
strate improvement of detection. We will further
discuss the issue from a pragmatic viewpoint in
the next section.
</bodyText>
<sectionHeader confidence="0.976238" genericHeader="conclusions">
5 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.99998982278481">
In this paper, we propose to incorporate the lin-
guistic knowledge of evidentiality in the NLP
task of trustworthiness prediction. As evidential-
ity is an integral and inherent part of any state-
ment and explicitly expresses information about
the trustworthiness of this statement, it should
provide the most robust and direct model for
trustworthiness detection. We first set up the
taxonomy of lexical evidentials. By incorporat-
ing evidentiality into a machine learning based
text classification framework, we conduct ex-
periments for a specific application, CQA. The
evidentials in the dataset are extracted to form
different text representation schemes. Our ex-
perimental results using evidentials show im-
provements up to 14.85% over the baselines.
However, not all types of evidential features
contributed to the improvement of detection. We
also compared the effect of different types of
evidential based feature representation schemes
on the classification performance.
The way to model evidentiality for trustwor-
thiness detection which we adopted in our initial
experiment design actually could also be ex-
plained by Grice’s Maxim of Quality: be truthful.
As the Maxim of Quality requires one “not to
say that for which one lacks adequate evidence&amp;quot;,
we hypothesize that evidential constructions
mark the adequacy of evidence and should indi-
cate reliable answers. However, the results from
our experiments only partially supported this
hypothesis. The results showed a satisfactory
performance was achieved when all evidential
markers were treated as negative evidence for
reliability. This result could then be accounted
by invoking another Gricean maxim: Quantity.
The Maxim of Quantity requires that “one
makes his/her contribution as informative as is
required, and at the same time does not make the
contribution more informative than is required.&amp;quot;
As evidentiality is not grammaticalized in Eng-
lish, the use of evidentiality is not a required
grammatical element. An answer marked by evi-
dentials would violate Maxim of Quantity if it is
correct. The Maxim of Quantity predicts that
good answers are plain statements without evi-
dential markers. On the frequent use of eviden-
tial markers for less reliable answers can be ac-
counted for by speakers’ attempt to follow both
Maxims of Quality and Quantity. The evidential
marks are used to compensate for the fact that
speakers are not very confident about the answer,
yet would like to adhere to the Maxim of Quality.
In other words, evidentials are not likely to be
used in reliable answers because of the Maxim
of Quality, but it is likely used in less reliable
answers because the speakers may try to provide
proof of adequate evidence by a grammatical
device instead of providing true answer.
Therefore, this model elaborated above takes
into account not only the grammatical function
of evidential constructions but also how this lin-
guistic structure is used as a pragmatic/discourse
device. In other words, this study suggests that
modeling linguistic theory in NLP needs to take
a more comprehensive approach than the simple
modular approach where only one module
(based on evidentiality) is used. Linguistic mod-
eling needs to consider both how linguistic
structure/knowledge is represented and proc-
essed, we also need to model how a particular
linguistic device in use.
In the further works, we plan to continue de-
veloping and elaborate on a multi-modular lin-
guistic model of evidentiality for knowledge
acquisition. We will also explore the possibility
of incorporating other features, both textual and
non-textual, to further improve performances in
the tasks of text trustworthiness detection.
</bodyText>
<sectionHeader confidence="0.999262" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885947368421">
Agichtein E, Castillo C, and etc. 2008. Finding high-
quality content in social media. In Proceedings of
WSDM2008.
Aikhenvald A and Dixon, ed. 2003. Studies in evi-
dentiality. Amsterdam/Philadelphia: John Benja-
mins Publishing Company
Banerjee P, Han H. 2009. Credibility: A Language
Modeling Approach to Answer Validation, In Pro-
ceedings of NAACL HLT 2009, Boulder, Bolorado,
US
Barners J. 1984. Evidentials in the Tuyuca Verb. IN
International Journal of American Linguistics, 50
Bouguessa M, Dumoulin B, Wang S. 2008. Identify-
ing Authoritative Actors in Question-Answering
Forums - The Case of Yahoo! Answers, In Pro-
ceedings of KDD’08, Las Vegas, Nevada, USA
Chafe W. 1986. Evidentiality: The Linguistic Coding
of Epistemology, Evidentiality in English Conver-
sation and Academic Writing. In Chafe and Nich-
</reference>
<page confidence="0.987477">
16
</page>
<note confidence="0.570579">
Algorithms. In Proceedings of the 16th ACM Inter-
national World Wide Web Conference (WWW’07)
</note>
<reference confidence="0.999619169811321">
ols, (ed.). Evidentiality: The Linguistic Coding of
Epistemology. Norwood, NJ: Ablex
DeLancey S. 2001. The mirative and evidentiality. In
Journal of Pragmatic, 33
Forman G. 2003. An Extensive Empirical Study of
Feature Selection Metrics for Text Classification,
In Journal of Machine Learning Research, 3
Gil Y, Artz D. 2006. Towards Content Trust of Web
Resources, In Proceedings of the 15th International
World Wide Web Conference, Edinburgh, Scotland
Gyongyi Z, Molina H, Pedersen J. 2004. Combating
Web Spam with TrustRank. In Proceedings of the
30th VLDB Conference, Toronto, Canada
Ifantidou E. 2001. Evidentials and Relevance. John
Benjamins Publishing Company.
Jeon J, Croft W, Lee J and Park S. 2006. A Frame-
work to Predict the Quality of Answers with Non-
textual Features, In Proceedings of SIGIR’06, Se-
attle, Washington, USA
Leopold E, Kindermann J. 2002. Text Categorization
with Support Vector Machines. How to Represent
Texts in Input Space?, In Machine Learning, 46,
423-444
Oswalt R. 1986. The evidential system of Kashaya.
IN Chafe W and Nichols (Eds.), Evidentiality: The
linguistic coding of epistemology. Norwood, NJ:
Ablex
Rubin V, Liddy E, Kando N. 2005. Certainty Identi-
fication in Texts: Categorization Model and Man-
ual Tagging Results, In Shanahan J and et al (Eds.),
Computing Attitude and Affect in Text: Theory and
Applications (The Information Retrieval Series):
Springer-Verlag New York, Inc.
Rubin V, Liddy E. 2006. Assessing Credibility of
Weblogs, In Proceedings of the AAAI Spring Sym-
posium: Computational Approaches to Analyzing
Weblogs (CAAW)
Magnini B, Negri M, Prevete R and Tanev H. 2002.
Is It the Right Answer? Exploiting Web Redun-
dancy for Answer Validation, In Proceedings of
the 40th Annual Meeting of the Association for
Computational Linguistics, Philadelphia, PA
Metzger M. 2007. Evaluating Online Information and
Recommendations for Future Research, Journal of
the American Society for Information Science and
Technology, 58(13)
Mushin I. 2000. Evidentiality and Deixis in Retelling,
In Journal of Pragmatics, 32
Weerkamp W, Rijke M. 2008. Credibility Improves
Topical Blog Post Retrieval. In Proceedings of
ACL08: HLT
Zhang J, Ackerman M, Adamic L. 2007. Expertise
Networks in Online Communities: Structure and
</reference>
<page confidence="0.999408">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.731713">
<title confidence="0.999844">Evidentiality for Text Trustworthiness Detection</title>
<author confidence="0.9995">Chu-Ren Huang</author>
<author confidence="0.9995">Helen Kai-yun Chen</author>
<affiliation confidence="0.8927755">of Chinese &amp; Bilingual Studies, The Hong Kong Polytechnic Laboratory of Computational Linguistics, Peking University</affiliation>
<email confidence="0.992897">sukia@pku.edu.cn,{helenkychen,churen.huang}@gmail.com</email>
<abstract confidence="0.997688285714286">Evidentiality is the linguistic representation of the nature of evidence for a statement. In other words, it is the linguistically encoded evidence for the trustworthiness of a statement. In this paper, we aim to explore how linguistically encoded information of evidentiality can contribute to the prediction of trustworthiness in natural language processing (NLP). We propose to incorporate evidentiality into a framework of machine learning based text classification. We first construct a taxonomy of evidentials. Then experiments involving collaborative question answering (CQA) are designed and implemented using this taxonomy. The experimental results confirm that evidentiality is an important clue for text trustworthiness detection. With the binarized vector setting, evidential based text representation model has considerably performaned better than both the bag-of-word model and the content word based model. Most crucially, we show that the best trustworthiness detection result is achieved when evidentiality is incorporated in a linguistically sophisticated model where their meanings are interpreted in both semantic and pragmatic terms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>C Castillo</author>
<author>etc</author>
</authors>
<title>Finding highquality content in social media.</title>
<date>2008</date>
<booktitle>In Proceedings of WSDM2008.</booktitle>
<marker>Agichtein, Castillo, etc, 2008</marker>
<rawString>Agichtein E, Castillo C, and etc. 2008. Finding highquality content in social media. In Proceedings of WSDM2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aikhenvald</author>
<author>ed Dixon</author>
</authors>
<date>2003</date>
<booktitle>Studies in evidentiality. Amsterdam/Philadelphia:</booktitle>
<publisher>John Benjamins Publishing Company</publisher>
<marker>Aikhenvald, Dixon, 2003</marker>
<rawString>Aikhenvald A and Dixon, ed. 2003. Studies in evidentiality. Amsterdam/Philadelphia: John Benjamins Publishing Company</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Banerjee</author>
<author>H Han</author>
</authors>
<title>Credibility: A Language Modeling Approach to Answer Validation,</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL HLT 2009,</booktitle>
<location>Boulder, Bolorado, US</location>
<contexts>
<context position="5442" citStr="Banerjee and Han (2009)" startWordPosition="813" endWordPosition="816">tworthiness detection. The section is divided into two parts: the current methodology and the textual features for analysis in the task. Section 3 introduces the linguistic researches on evidentiality and our taxonomy of evidentials based on the trustworthiness indication. Section 4 presents the experiment settings and results. Finally, in section 5 we discuss the experiment results and conclude the current research. 2 Related Work The research of text trustworthiness is very helpful for many other natural language processing applications. For example, in their research on question answering, Banerjee and Han (2009) modulate answer grade by using a weighted combination of the original score and answer credibility evaluation. Also, Weerkamp and Rijke (2008) incorporate textual credibility indicators in the retrieval process to improve topical blog posts retrieval. Gyongyi et al (2004) propose a TrustRank algorithm for semiautomatically separating reputable, good Web pages from spams. 2.1 General Approaches for Text Trustworthiness Detection In past research, the judgment for the trustworthiness or credibility of a given text content is usually tackled from two aspects: entity oriented and content oriented</context>
</contexts>
<marker>Banerjee, Han, 2009</marker>
<rawString>Banerjee P, Han H. 2009. Credibility: A Language Modeling Approach to Answer Validation, In Proceedings of NAACL HLT 2009, Boulder, Bolorado, US</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Barners</author>
</authors>
<title>Evidentials in the Tuyuca Verb.</title>
<date>1984</date>
<journal>IN International Journal of American Linguistics,</journal>
<volume>50</volume>
<contexts>
<context position="14245" citStr="Barners (1984)" startWordPosition="2129" endWordPosition="2130">hould, would, may, might could, can Epistemic adjec- definite possible, likely, not sure, doubtful tive unlikely, probable, positive, potential Table 1. The Categorization and Inside Items of Evidentiality Oswalt (1986) suggests a priority hierarchy of evidentials as: Performative &gt; Factual &gt; Visual &gt; Auditory &gt; Inferential &gt; Quotative In this evidential hierarchy, performative carries the highest degree of trustworthiness since Oswalt considers that the speaker is speaking of the act he himself is performing. It is the most reliable source of evidence for the knowledge of that event. Whereas Barners (1984) proposes the following hierarchy: Visual &gt; Non-visual &gt; Apparent &gt; Secondhand &gt; Assumed He points out that visual evidence takes precedence over the auditory evidence and is more reliable. The above two hierarchies are based on the narrow definition of evidentiality mentioned above. There are also some hierarchies involving the board definition of evidentiality, such as Chafe (1986)’s categories of evidentiality. In this paper, we adopt a broad definition of evidentiality and focus on a trustworthiness categorization. This categorization follows the model of four-dimensional certainty categor</context>
</contexts>
<marker>Barners, 1984</marker>
<rawString>Barners J. 1984. Evidentials in the Tuyuca Verb. IN International Journal of American Linguistics, 50</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bouguessa</author>
<author>B Dumoulin</author>
<author>S Wang</author>
</authors>
<title>Identifying Authoritative Actors in Question-Answering Forums - The Case of Yahoo! Answers,</title>
<date>2008</date>
<booktitle>In Proceedings of KDD’08,</booktitle>
<location>Las Vegas, Nevada, USA</location>
<contexts>
<context position="7176" citStr="Bouguessa et al, 2008" startWordPosition="1078" endWordPosition="1081">ist of factors that users may take into account in assessing credibility of blog sites. This list could also be summarized as the above mentioned two-folds: the bloggers’ profiles and the information posted in the entries. Comparing these two aspects, most existing research on text trustworthiness focuses on the user oriented features. Lots of user oriented features have been proposed in the research of credibility detection. To score the user oriented features such as user’s authority, a common approach is based on a graph-based ranking algorithm such as HITS and PageRank (Zhang et al, 2007; Bouguessa et al, 2008). In the research of text trustworthiness detection, the overwhelmingly adaption of nontextual features such as entity profiles over text content based features reflect some researchers’ belief that superficial textual features cannot meet the need of text credibility identification (Jeon et al, 2006). In this paper, we examine the lexical semantic feature of evidential and argue that evidentiality, as a linguistically instantiated representation of quality of information content, offers a robust processing model for text trustworthiness detection. The detection of information trustworthiness </context>
</contexts>
<marker>Bouguessa, Dumoulin, Wang, 2008</marker>
<rawString>Bouguessa M, Dumoulin B, Wang S. 2008. Identifying Authoritative Actors in Question-Answering Forums - The Case of Yahoo! Answers, In Proceedings of KDD’08, Las Vegas, Nevada, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chafe</author>
</authors>
<title>Evidentiality: The Linguistic Coding of Epistemology, Evidentiality in English Conversation and Academic Writing. In</title>
<date>1986</date>
<booktitle>Evidentiality: The Linguistic Coding of Epistemology.</booktitle>
<editor>Chafe and Nichols, (ed.).</editor>
<publisher>Ablex</publisher>
<location>Norwood, NJ:</location>
<contexts>
<context position="12396" citStr="Chafe, 1986" startWordPosition="1864" endWordPosition="1865"> Jakobson (1957) as a label for the verbal category indicating the alleged source of information about the narrated events. In line with Jakobson’s definition, the narrow definition of evidentiality proposed by other researchers focuses mainly on the specification of the information sources, that is, the evidence through which information is acquired (DeLancey, 2001). Comparing with the narrow definition, the board definition explains evidentiality in a much wider sense, and characterizes evidentiality as expressions of speaker’s attitude toward information, typically expressed by modalities (Chafe, 1986; Mushin, 2000). Ifantidou (2001) also holds that evidential has two main functions: 1) indicating the source of knowledge; 2) indicating the speaker’s degree of certainty about the proposition expressed. He further divides them in details as follows. a) Information can be acquired in various ways, including observation (e.g. see), hearsay (e.g. hear, reportedly), inference (e.g. must, deduce), memory (e.g. recall). b) Evidentiality can indicate the speaker’s degree of certainty, including certain propositional attitude (e.g. think, guess) and adverbials (e.g. certainly, surely), also epistemi</context>
<context position="14631" citStr="Chafe (1986)" startWordPosition="2189" endWordPosition="2190"> the highest degree of trustworthiness since Oswalt considers that the speaker is speaking of the act he himself is performing. It is the most reliable source of evidence for the knowledge of that event. Whereas Barners (1984) proposes the following hierarchy: Visual &gt; Non-visual &gt; Apparent &gt; Secondhand &gt; Assumed He points out that visual evidence takes precedence over the auditory evidence and is more reliable. The above two hierarchies are based on the narrow definition of evidentiality mentioned above. There are also some hierarchies involving the board definition of evidentiality, such as Chafe (1986)’s categories of evidentiality. In this paper, we adopt a broad definition of evidentiality and focus on a trustworthiness categorization. This categorization follows the model of four-dimensional certainty categorization by Rubin et al (2005). In this model, it is suggested that the division of the certainty level dimension into four categories - Absolute, High, Moderate and Low. With some revision, there are different items of evidential words and phrased that we extracted from the corpus. These items from each category to be adopted in our experiments are presented in Table 1. 4 Incorporati</context>
</contexts>
<marker>Chafe, 1986</marker>
<rawString>Chafe W. 1986. Evidentiality: The Linguistic Coding of Epistemology, Evidentiality in English Conversation and Academic Writing. In Chafe and Nichols, (ed.). Evidentiality: The Linguistic Coding of Epistemology. Norwood, NJ: Ablex</rawString>
</citation>
<citation valid="true">
<authors>
<author>S DeLancey</author>
</authors>
<title>The mirative and evidentiality.</title>
<date>2001</date>
<journal>In Journal of Pragmatic,</journal>
<volume>33</volume>
<contexts>
<context position="12154" citStr="DeLancey, 2001" startWordPosition="1831" endWordPosition="1832">peakers’ estimation for the trustworthiness of the statement by information providers. 3.1 The Definition of Evidentiality There are two dimensions of the linguistic definition for evidentiality. The term evidentiality is originally introduced by Jakobson (1957) as a label for the verbal category indicating the alleged source of information about the narrated events. In line with Jakobson’s definition, the narrow definition of evidentiality proposed by other researchers focuses mainly on the specification of the information sources, that is, the evidence through which information is acquired (DeLancey, 2001). Comparing with the narrow definition, the board definition explains evidentiality in a much wider sense, and characterizes evidentiality as expressions of speaker’s attitude toward information, typically expressed by modalities (Chafe, 1986; Mushin, 2000). Ifantidou (2001) also holds that evidential has two main functions: 1) indicating the source of knowledge; 2) indicating the speaker’s degree of certainty about the proposition expressed. He further divides them in details as follows. a) Information can be acquired in various ways, including observation (e.g. see), hearsay (e.g. hear, repo</context>
</contexts>
<marker>DeLancey, 2001</marker>
<rawString>DeLancey S. 2001. The mirative and evidentiality. In Journal of Pragmatic, 33</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Forman</author>
</authors>
<title>An Extensive Empirical Study of Feature Selection Metrics for Text Classification,</title>
<date>2003</date>
<journal>In Journal of Machine Learning Research,</journal>
<volume>3</volume>
<contexts>
<context position="17612" citStr="Forman, 2003" startWordPosition="2668" endWordPosition="2669">ture will be incorporated into a machine learning based text classification framework in order to identify the best answers for CQA questions. 13 4.1 The Dataset For the experiments, we use the snapshot of Yahoo! Answers dataset which is crawled by Emory University3. Since our experiments only involve text features, we use the answer parts from it without considering the question sets and user profiles. Such information could be incorporated to achieve a higher performance in the future. With regard to the text classification problems, there is typically a substantial class distribution skew (Forman, 2003). For the Yahoo! Answers dataset, a question only has one best answer and accordingly all the other answers will be marked as non-best answers. Thus the class of best answer contains much fewer texts than the class of non-best answers. In our dataset (a proportion of the overall CQA dataset provided by Emory University), the number of best answers is 2,165, and the number of non-best answers is 17,654. The proportion of the size of the two answer sets is around 1:8.15, showing a significant skews. For a better comparison of experimental results, we use a balanced dataset which is generated fro</context>
<context position="21082" citStr="Forman, 2003" startWordPosition="3233" endWordPosition="3234">presents using the four evidentiality categories of Absolute, High, Moderate and Low from Table 1. ·Evid.cat2 represents using the two categories of Absolute and High as the positive evidential and Moderate and Low as the negative evidential. ·Evid.cat2’ omits the evidential category of Moderate, and represents using the two categories of Absolute and High as the positive evidential and only the category of Low as the negative evidential feature. Some researchers have proved that usually a Boolean indicator of whether the feature item occurred in the document is sufficient for classification (Forman, 2003). Although there are also some other feature weighting schemes such as term frequency (TF), document frequency (DF), etc, comparison of these different weighting schemes is not the object of the current research. So in this paper, we only consider Boolean weighting. In the Boolean text representation model, each feature represents the Boolean occurrence of a word, evidential, or evidential category according to the different feature settings. By the experimental settings, we want to verify the hypothesis that incorporating the knowledge 14 of evidentiality into text representation can lead to </context>
</contexts>
<marker>Forman, 2003</marker>
<rawString>Forman G. 2003. An Extensive Empirical Study of Feature Selection Metrics for Text Classification, In Journal of Machine Learning Research, 3</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Gil</author>
<author>D Artz</author>
</authors>
<title>Towards Content Trust of Web Resources,</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th International World Wide Web Conference,</booktitle>
<location>Edinburgh, Scotland</location>
<marker>Gil, Artz, 2006</marker>
<rawString>Gil Y, Artz D. 2006. Towards Content Trust of Web Resources, In Proceedings of the 15th International World Wide Web Conference, Edinburgh, Scotland</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Gyongyi</author>
<author>H Molina</author>
<author>J Pedersen</author>
</authors>
<title>Combating Web Spam with TrustRank.</title>
<date>2004</date>
<booktitle>In Proceedings of the 30th VLDB Conference,</booktitle>
<location>Toronto, Canada</location>
<contexts>
<context position="5715" citStr="Gyongyi et al (2004)" startWordPosition="854" endWordPosition="857">ction 4 presents the experiment settings and results. Finally, in section 5 we discuss the experiment results and conclude the current research. 2 Related Work The research of text trustworthiness is very helpful for many other natural language processing applications. For example, in their research on question answering, Banerjee and Han (2009) modulate answer grade by using a weighted combination of the original score and answer credibility evaluation. Also, Weerkamp and Rijke (2008) incorporate textual credibility indicators in the retrieval process to improve topical blog posts retrieval. Gyongyi et al (2004) propose a TrustRank algorithm for semiautomatically separating reputable, good Web pages from spams. 2.1 General Approaches for Text Trustworthiness Detection In past research, the judgment for the trustworthiness or credibility of a given text content is usually tackled from two aspects: entity oriented and content oriented (Rubin and Liddy, 2005). The former approach takes into consideration the information providers’ individual profiles, such as their identity, reputation, authority and past web behavior; whereas the latter approach considers the actual content of texts. Metzger (2007) rev</context>
</contexts>
<marker>Gyongyi, Molina, Pedersen, 2004</marker>
<rawString>Gyongyi Z, Molina H, Pedersen J. 2004. Combating Web Spam with TrustRank. In Proceedings of the 30th VLDB Conference, Toronto, Canada</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ifantidou</author>
</authors>
<title>Evidentials and Relevance.</title>
<date>2001</date>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="12429" citStr="Ifantidou (2001)" startWordPosition="1868" endWordPosition="1869">for the verbal category indicating the alleged source of information about the narrated events. In line with Jakobson’s definition, the narrow definition of evidentiality proposed by other researchers focuses mainly on the specification of the information sources, that is, the evidence through which information is acquired (DeLancey, 2001). Comparing with the narrow definition, the board definition explains evidentiality in a much wider sense, and characterizes evidentiality as expressions of speaker’s attitude toward information, typically expressed by modalities (Chafe, 1986; Mushin, 2000). Ifantidou (2001) also holds that evidential has two main functions: 1) indicating the source of knowledge; 2) indicating the speaker’s degree of certainty about the proposition expressed. He further divides them in details as follows. a) Information can be acquired in various ways, including observation (e.g. see), hearsay (e.g. hear, reportedly), inference (e.g. must, deduce), memory (e.g. recall). b) Evidentiality can indicate the speaker’s degree of certainty, including certain propositional attitude (e.g. think, guess) and adverbials (e.g. certainly, surely), also epistemic models (e.g. may, ought to). 3.</context>
</contexts>
<marker>Ifantidou, 2001</marker>
<rawString>Ifantidou E. 2001. Evidentials and Relevance. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jeon</author>
<author>W Croft</author>
<author>J Lee</author>
<author>S Park</author>
</authors>
<title>A Framework to Predict the Quality of Answers with Nontextual Features,</title>
<date>2006</date>
<booktitle>In Proceedings of SIGIR’06,</booktitle>
<location>Seattle, Washington, USA</location>
<contexts>
<context position="7478" citStr="Jeon et al, 2006" startWordPosition="1122" endWordPosition="1125">on the user oriented features. Lots of user oriented features have been proposed in the research of credibility detection. To score the user oriented features such as user’s authority, a common approach is based on a graph-based ranking algorithm such as HITS and PageRank (Zhang et al, 2007; Bouguessa et al, 2008). In the research of text trustworthiness detection, the overwhelmingly adaption of nontextual features such as entity profiles over text content based features reflect some researchers’ belief that superficial textual features cannot meet the need of text credibility identification (Jeon et al, 2006). In this paper, we examine the lexical semantic feature of evidential and argue that evidentiality, as a linguistically instantiated representation of quality of information content, offers a robust processing model for text trustworthiness detection. The detection of information trustworthiness also has promising application values. Google News 1 is just such an application that ranks search results according to the credibility of the news. Other online news aggregation service, such as NewTrust 2, also focuses on providing users with credible and high quality news and stories. The existed a</context>
</contexts>
<marker>Jeon, Croft, Lee, Park, 2006</marker>
<rawString>Jeon J, Croft W, Lee J and Park S. 2006. A Framework to Predict the Quality of Answers with Nontextual Features, In Proceedings of SIGIR’06, Seattle, Washington, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Leopold</author>
<author>J Kindermann</author>
</authors>
<title>Text Categorization with Support Vector Machines. How to Represent Texts in Input Space?,</title>
<date>2002</date>
<booktitle>In Machine Learning,</booktitle>
<volume>46</volume>
<pages>423--444</pages>
<marker>Leopold, Kindermann, 2002</marker>
<rawString>Leopold E, Kindermann J. 2002. Text Categorization with Support Vector Machines. How to Represent Texts in Input Space?, In Machine Learning, 46, 423-444</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Oswalt</author>
</authors>
<title>The evidential system of Kashaya. IN Chafe W and Nichols (Eds.), Evidentiality: The linguistic coding of epistemology.</title>
<date>1986</date>
<publisher>Ablex</publisher>
<location>Norwood, NJ:</location>
<contexts>
<context position="13850" citStr="Oswalt (1986)" startWordPosition="2067" endWordPosition="2068">rchers. 12 Absolute High Moderate Low Attributive/modal certainly, sure, of clearly, obviously, ap- Seemingly, maybe, personally, adverb course, definitely, ab- parently, really, always probably perhaps, possibly, solutely, undoubtedly presumably Lexical verb report, certain believe, see seem, think, sound doubt, wish, wonder, infer, assume, forecast, fell, heard Auxiliary verb must ought, should, would, may, might could, can Epistemic adjec- definite possible, likely, not sure, doubtful tive unlikely, probable, positive, potential Table 1. The Categorization and Inside Items of Evidentiality Oswalt (1986) suggests a priority hierarchy of evidentials as: Performative &gt; Factual &gt; Visual &gt; Auditory &gt; Inferential &gt; Quotative In this evidential hierarchy, performative carries the highest degree of trustworthiness since Oswalt considers that the speaker is speaking of the act he himself is performing. It is the most reliable source of evidence for the knowledge of that event. Whereas Barners (1984) proposes the following hierarchy: Visual &gt; Non-visual &gt; Apparent &gt; Secondhand &gt; Assumed He points out that visual evidence takes precedence over the auditory evidence and is more reliable. The above two h</context>
</contexts>
<marker>Oswalt, 1986</marker>
<rawString>Oswalt R. 1986. The evidential system of Kashaya. IN Chafe W and Nichols (Eds.), Evidentiality: The linguistic coding of epistemology. Norwood, NJ: Ablex</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rubin</author>
<author>E Liddy</author>
<author>N Kando</author>
</authors>
<title>Certainty Identification in Texts: Categorization Model and Manual Tagging Results,</title>
<date>2005</date>
<booktitle>In Shanahan J and et al (Eds.), Computing Attitude and Affect in Text: Theory and Applications (The Information Retrieval Series):</booktitle>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc.</location>
<contexts>
<context position="14874" citStr="Rubin et al (2005)" startWordPosition="2221" endWordPosition="2224">he following hierarchy: Visual &gt; Non-visual &gt; Apparent &gt; Secondhand &gt; Assumed He points out that visual evidence takes precedence over the auditory evidence and is more reliable. The above two hierarchies are based on the narrow definition of evidentiality mentioned above. There are also some hierarchies involving the board definition of evidentiality, such as Chafe (1986)’s categories of evidentiality. In this paper, we adopt a broad definition of evidentiality and focus on a trustworthiness categorization. This categorization follows the model of four-dimensional certainty categorization by Rubin et al (2005). In this model, it is suggested that the division of the certainty level dimension into four categories - Absolute, High, Moderate and Low. With some revision, there are different items of evidential words and phrased that we extracted from the corpus. These items from each category to be adopted in our experiments are presented in Table 1. 4 Incorporating Evidentiality into Machine Learning for Trustworthiness Detection In this section, we apply evidentiality in an actual implement of text trustworthiness detection. It is based on a specific web application service, collaborative question an</context>
</contexts>
<marker>Rubin, Liddy, Kando, 2005</marker>
<rawString>Rubin V, Liddy E, Kando N. 2005. Certainty Identification in Texts: Categorization Model and Manual Tagging Results, In Shanahan J and et al (Eds.), Computing Attitude and Affect in Text: Theory and Applications (The Information Retrieval Series): Springer-Verlag New York, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rubin</author>
<author>E Liddy</author>
</authors>
<title>Assessing Credibility of Weblogs,</title>
<date>2006</date>
<booktitle>In Proceedings of the AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs (CAAW)</booktitle>
<marker>Rubin, Liddy, 2006</marker>
<rawString>Rubin V, Liddy E. 2006. Assessing Credibility of Weblogs, In Proceedings of the AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs (CAAW)</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>M Negri</author>
<author>R Prevete</author>
<author>H Tanev</author>
</authors>
<title>Is It the Right Answer? Exploiting Web Redundancy for Answer Validation,</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Philadelphia, PA</location>
<marker>Magnini, Negri, Prevete, Tanev, 2002</marker>
<rawString>Magnini B, Negri M, Prevete R and Tanev H. 2002. Is It the Right Answer? Exploiting Web Redundancy for Answer Validation, In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Metzger</author>
</authors>
<title>Evaluating Online Information and Recommendations for Future Research,</title>
<date>2007</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>58</volume>
<issue>13</issue>
<contexts>
<context position="6311" citStr="Metzger (2007)" startWordPosition="943" endWordPosition="944">ongyi et al (2004) propose a TrustRank algorithm for semiautomatically separating reputable, good Web pages from spams. 2.1 General Approaches for Text Trustworthiness Detection In past research, the judgment for the trustworthiness or credibility of a given text content is usually tackled from two aspects: entity oriented and content oriented (Rubin and Liddy, 2005). The former approach takes into consideration the information providers’ individual profiles, such as their identity, reputation, authority and past web behavior; whereas the latter approach considers the actual content of texts. Metzger (2007) reviews several cognitive models of credibility assessment and points out that credibility is a multifaceted concept with two primary dimensions: expertise and trustworthiness. Following Matzger’s framework, Rubin and Liddy (2005) compile a list of factors that users may take into account in assessing credibility of blog sites. This list could also be summarized as the above mentioned two-folds: the bloggers’ profiles and the information posted in the entries. Comparing these two aspects, most existing research on text trustworthiness focuses on the user oriented features. Lots of user orient</context>
</contexts>
<marker>Metzger, 2007</marker>
<rawString>Metzger M. 2007. Evaluating Online Information and Recommendations for Future Research, Journal of the American Society for Information Science and Technology, 58(13)</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mushin</author>
</authors>
<title>Evidentiality and Deixis in Retelling,</title>
<date>2000</date>
<journal>In Journal of Pragmatics,</journal>
<volume>32</volume>
<contexts>
<context position="10991" citStr="Mushin (2000)" startWordPosition="1656" endWordPosition="1657">the speakers towards the information. Evidentiality is information providers’ specifications for the information sources and their attitudes toward the information. As a common linguistic phenomenon to all the languages, it has attracted linguists’ attention since the beginning of 20th century. In any language, evidentiality is a semantic category which could be expressed on both grammatical level (as in some American Indian language) and lexical level (as in English, Chinese and many other languages). The linguistic expressions of evidentiality are named as evidentials or evidential markers. Mushin (2000) defines evidential as a marker which qualifies the reliability of information. It is an explicit expression of the speaker’s attitudes toward the trustworthiness of information source. For instance, a). It’s probably raining. b). It must be raining. c). It sounds like it’s raining. d). I think/guess/suppose it’s raining. e). I can hear/see/feel/smell it raining. It is obvious that the information provided in the above examples is subjective. The information expresses the personal experience or attitudes, while at the same time reflects the speakers’ estimation for the trustworthiness of the s</context>
<context position="12411" citStr="Mushin, 2000" startWordPosition="1866" endWordPosition="1867">57) as a label for the verbal category indicating the alleged source of information about the narrated events. In line with Jakobson’s definition, the narrow definition of evidentiality proposed by other researchers focuses mainly on the specification of the information sources, that is, the evidence through which information is acquired (DeLancey, 2001). Comparing with the narrow definition, the board definition explains evidentiality in a much wider sense, and characterizes evidentiality as expressions of speaker’s attitude toward information, typically expressed by modalities (Chafe, 1986; Mushin, 2000). Ifantidou (2001) also holds that evidential has two main functions: 1) indicating the source of knowledge; 2) indicating the speaker’s degree of certainty about the proposition expressed. He further divides them in details as follows. a) Information can be acquired in various ways, including observation (e.g. see), hearsay (e.g. hear, reportedly), inference (e.g. must, deduce), memory (e.g. recall). b) Evidentiality can indicate the speaker’s degree of certainty, including certain propositional attitude (e.g. think, guess) and adverbials (e.g. certainly, surely), also epistemic models (e.g. </context>
</contexts>
<marker>Mushin, 2000</marker>
<rawString>Mushin I. 2000. Evidentiality and Deixis in Retelling, In Journal of Pragmatics, 32</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Weerkamp</author>
<author>M Rijke</author>
</authors>
<title>Credibility Improves Topical Blog Post Retrieval.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08: HLT</booktitle>
<contexts>
<context position="5585" citStr="Weerkamp and Rijke (2008)" startWordPosition="834" endWordPosition="838">ion 3 introduces the linguistic researches on evidentiality and our taxonomy of evidentials based on the trustworthiness indication. Section 4 presents the experiment settings and results. Finally, in section 5 we discuss the experiment results and conclude the current research. 2 Related Work The research of text trustworthiness is very helpful for many other natural language processing applications. For example, in their research on question answering, Banerjee and Han (2009) modulate answer grade by using a weighted combination of the original score and answer credibility evaluation. Also, Weerkamp and Rijke (2008) incorporate textual credibility indicators in the retrieval process to improve topical blog posts retrieval. Gyongyi et al (2004) propose a TrustRank algorithm for semiautomatically separating reputable, good Web pages from spams. 2.1 General Approaches for Text Trustworthiness Detection In past research, the judgment for the trustworthiness or credibility of a given text content is usually tackled from two aspects: entity oriented and content oriented (Rubin and Liddy, 2005). The former approach takes into consideration the information providers’ individual profiles, such as their identity, </context>
<context position="8997" citStr="Weerkamp and Rijke (2008)" startWordPosition="1356" endWordPosition="1359">sed Text Trustworthiness Detection Although non-textual features have been popular in text credibility detection, there has been a few research focusing on textual features so far. Gil 1 http://news.google.com/ 2 http://www.newstrust.net/ 11 and Artz (2006) argue that the degree of trust in an entity is only one ingredient in deciding whether or not to trust the information it provides. They further point out that entity-centered issues are made with respect to publicly available data and services, and thus will not be possible in many cases. In their research of topical blog posts retrieval, Weerkamp and Rijke (2008) also consider only textual credibility indicators since they mentioned that additional resources (such as bloggers’ profiles) is hard to obtain for technical or legal reasons. However, most research which utilizes textual features in text trustworthiness detection usually equates writing quality of document with its trustworthiness. Therefore, some secondary features which may not directly related to trustworthiness are proposed, including spelling errors, the lack of leading capitals, the large number of exclamation markers, personal pronouns and text length (Weerkamp and Rijke, 2008). There</context>
</contexts>
<marker>Weerkamp, Rijke, 2008</marker>
<rawString>Weerkamp W, Rijke M. 2008. Credibility Improves Topical Blog Post Retrieval. In Proceedings of ACL08: HLT</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zhang</author>
<author>M Ackerman</author>
<author>L Adamic</author>
</authors>
<date>2007</date>
<booktitle>Expertise Networks in Online Communities: Structure and</booktitle>
<contexts>
<context position="7152" citStr="Zhang et al, 2007" startWordPosition="1074" endWordPosition="1077"> (2005) compile a list of factors that users may take into account in assessing credibility of blog sites. This list could also be summarized as the above mentioned two-folds: the bloggers’ profiles and the information posted in the entries. Comparing these two aspects, most existing research on text trustworthiness focuses on the user oriented features. Lots of user oriented features have been proposed in the research of credibility detection. To score the user oriented features such as user’s authority, a common approach is based on a graph-based ranking algorithm such as HITS and PageRank (Zhang et al, 2007; Bouguessa et al, 2008). In the research of text trustworthiness detection, the overwhelmingly adaption of nontextual features such as entity profiles over text content based features reflect some researchers’ belief that superficial textual features cannot meet the need of text credibility identification (Jeon et al, 2006). In this paper, we examine the lexical semantic feature of evidential and argue that evidentiality, as a linguistically instantiated representation of quality of information content, offers a robust processing model for text trustworthiness detection. The detection of info</context>
</contexts>
<marker>Zhang, Ackerman, Adamic, 2007</marker>
<rawString>Zhang J, Ackerman M, Adamic L. 2007. Expertise Networks in Online Communities: Structure and</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>