<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99818">
Modeling Regular Polysemy: A Study on the
Semantic Classification of Catalan Adjectives
</title>
<author confidence="0.945659">
Gemma Boleda*
</author>
<affiliation confidence="0.677586">
Universitat Pompeu Fabra
</affiliation>
<author confidence="0.996436">
Sabine Schulte im Walde**
</author>
<affiliation confidence="0.994709">
University of Stuttgart
</affiliation>
<author confidence="0.90363">
Toni Badia†
</author>
<affiliation confidence="0.582427">
Universitat Pompeu Fabra
</affiliation>
<bodyText confidence="0.997496235294117">
We present a study on the automatic acquisition of semantic classes for Catalan adjectives from
distributional and morphological information, with particular emphasis on polysemous adjec-
tives. The aim is to distinguish and characterize broad classes, such as qualitative (gran ‘big’)
and relational (pulmonar ‘pulmonary’) adjectives, as well as to identify polysemous adjectives
such as econ`omic (‘economic  |cheap’). We specifically aim at modeling regular polysemy, that
is, types of sense alternations that are shared across lemmata. To date, both semantic classes for
adjectives and regular polysemy have only been sparsely addressed in empirical computational
linguistics.
Two main specific questions are tackled in this article. First, what is an adequate broad
semantic classification for adjectives? We provide empirical support for the qualitative and
relational classes as defined in theoretical work, and uncover one type of adjective that has
not received enough attention, namely, the event-related class. Second, how is regular polysemy
best modeled in computational terms? We present two models, and argue that the second one,
which models regular polysemy in terms of simultaneous membership to multiple basic classes,
is both theoretically and empirically more adequate than the first one, which attempts to identify
independent polysemous classes. Our best classifier achieves 69.1% accuracy, against a 51%
baseline.
</bodyText>
<sectionHeader confidence="0.996899" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.997177666666667">
Adjectives are one of the most elusive parts of speech with respect to meaning. For
example, it is very difficult to establish a broad classification of adjectives into semantic
classes, analogous to a broad ontological classification of nouns (Raskin and Nirenburg
</bodyText>
<note confidence="0.84306025">
* Department of Translation and Language Sciences, Universitat Pompeu Fabra, Roc Boronat 138, 08018
Barcelona, Spain. E-mail: gemma.boleda®upf.edu.
** E-mail: schulte®ims.uni-stuttgart.de.
† E-mail: toni.badia®upf.edu.
</note>
<footnote confidence="0.720297333333333">
Submission received: 10 December 2008; revised submission received: 16 July 2011; accepted for publication:
5 September 2011. Part of the work reported in this article was done while the first author was a postdoctoral
scholar at U. Polit`ecnica de Catalunya and a visiting researcher at U. Stuttgart.
</footnote>
<note confidence="0.837356">
© 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.998028363636363">
1998). This article tackles precisely this task, that is, the semantic classification of adjectives,
for Catalan. We aim at automatically inducing the semantic class for an adjective given
its linguistic properties, as extracted from corpora and other resources.
The acquisition of semantic classes has been widely studied for verbs (Dorr and
Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew
2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent,
for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions
(Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Fur-
thermore, we cannot rely on a well-established classification for adjectives. The classes
themselves are subject to experimentation. We will test two different classifications,
analyzing the empirical properties of the classes and the problems in their definition.
Another significant challenge is posed by polysemy, or the fact that one and the
same adjective can have multiple senses. Different senses may fall into different classes,
such that it is no longer possible to identify one single semantic class per adjective.
Moreover, many adjectives exhibit similar sense alternations, in a phenomenon known
as regular or systematic polysemy (Apresjan 1974; Copestake and Briscoe 1995). A special
focus of the research presented, therefore, is on modeling regular polysemy. As an
example of regular polysemy, take for instance the sense alternation for the adjective
econ`omic exemplified in Example (1). Econ`omic, derived from economia (‘economy’), can
be translated as ‘economic, of the economy’, as in Example (1a), or as ‘cheap’, as in
Example (1b). As we will see, each of these senses corresponds to a different semantic
class in our classifications.
</bodyText>
<listItem confidence="0.748103333333333">
(1) a. recuperaci´o econ`omica
recovery economySUFFIX
‘recovery of the economy’
b. pantalons econ`omics
trousers economySUFFIX
‘cheap trousers’
</listItem>
<bodyText confidence="0.942647">
Other adjectives exhibit similar sense alternations; for example, familiar (derived
from fam´ılia, ‘family’) and amor´os (derived from amor, ‘love’), as shown in Example (2).
</bodyText>
<listItem confidence="0.880151">
(2) a. reuni´o familiar / cara familiar
meeting familySUFFIX/ face familySUFFIX
‘family meeting / familiar face’
</listItem>
<bodyText confidence="0.883799888888889">
b. problema amor´os / noi amor´os
problem loveSUFFIX/ boy loveSUFFIX
‘love problem / lovely boy’
The first senses in Examples (1) and (2) have a transparent relation to the denotation of
the deriving noun, as witnessed by the fact that they are translated as nouns in English
(economy, family, love), whereas the other senses are translated as adjectives (cheap, famil-
iar, lovely). For each of these adjectives, there is a relationship between the two senses,
such that the sense alternations seem to correspond to a productive semantic process
along the lines of Example (3) (Raskin and Nirenburg 1998, schema (43), page 173).
</bodyText>
<listItem confidence="0.948983">
(3) PERTAINING TO [noun meaning] → CHARACTERISTIC OF [noun meaning]
</listItem>
<page confidence="0.995606">
576
</page>
<note confidence="0.903329">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.999904714285714">
Because of the systematic semantic relationship between the two senses of these adjec-
tives, they constitute an instance of regular polysemy. In this article, therefore, we not
only address the acquisition of semantic classes, but also the acquisition of polysemy: Our
goal is to determine, for a given adjective, whether it is monosemous or polysemous,
and to which class(es) it belongs. Note that we are not dealing with individual sense
alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al.
2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold
across different lemmata. Thus, the present research is at the crossroad between sense
induction and lexical acquisition.
Regularities in sense alternations are pervasive in human languages, and they
are probably favored by the properties of human cognition (Murphy 2002). Regular
polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995)
and in symbolic approaches to computational semantics (Copestake and Briscoe 1995).
It has received little attention in empirical computational semantics, however. This
is surprising, given the amount of work devoted to sense-related tasks such as Word
Sense Disambiguation (WSD). In WSD (see Navigli [2009] for an overview) sense
ambiguities are almost exclusively modeled for each individual lemma, despite the
ensuing sparsity problems (Ando [2006] is an exception). Properly modeling regular
polysemy, therefore, promises to improve computational semantic tasks such as WSD
and sense discrimination.
This article has the goal of finding a computational model that responds to the
theoretical and empirical properties of regular polysemy. In this direction, we test two
alternative approaches. We first model polysemy in terms of independent classes to be
separately acquired (e.g., an adjective with two senses ai and bi belongs to a class AB
defined independently of classes A and B), and show that this model is not adequate.
A second approach, which posits that polysemous adjectives simultaneously belong to
more than one class (e.g., an adjective with two senses ai and bi belongs to both class
A and class B), is more successful. Our best classifier achieves 69.1% accuracy against a
51% baseline, which is satisfactory, considering that the estimated upper bound (human
agreement) for this task is 68%. We discuss pros and cons of the two models described
and ways to overcome their limitations.
In the following, we first review related work (Section 2) and linguistic aspects
of adjective classification (Section 3), then present the two acquisition experiments
(Sections 4 and 5), and finish with a general discussion (Section 6) and some conclusions
and directions for future research (Section 7).
</bodyText>
<sectionHeader confidence="0.99988" genericHeader="related work">
2. Related Work
</sectionHeader>
<bodyText confidence="0.999850181818182">
As mentioned in the Introduction, there has been very little research in the semantic
classification of adjectives. We know of only two articles on specifically this topic:
Carvalho and Ranchhod (2003) used adjective classes similar to the ones explored here
to disambiguate between nominal and adjectival readings in Portuguese. Adjective
information, manually coded, served to establish constraints in a finite-state transducer
part-of-speech tagger. Actually, POS tagging was also the initial motivation for the
present research, as adjective–noun and adjective–verb (participle) ambiguities cause
most difficulties to both humans and machines in languages such as English, German,
and Catalan (Marcus, Santorini, and Marcinkiewicz 1993; Brants 2000; Boleda 2007).
Bohnet, Klatt, and Wanner (2002) also has similar goals to the present research, as it
is aimed at automatically classifying German adjectives. However, the classification
</bodyText>
<page confidence="0.988821">
577
</page>
<note confidence="0.796255">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999392">
used is not purely semantic, polysemy is not taken into account, and the evidence and
techniques used are more limited than the ones used here.
Other research on adjectives within computational linguistics is oriented toward
different goals than ours. Yallop, Korhonen, and Briscoe (2005) tackle syntactic, not
semantic classification, akin to the acquisition of subcategorization frames for verbs.
Another relevant line of research pursues WSD. Justeson and Katz (1995) and Chao
and Dyer (2000) showed that adjectives are a very useful cue for disambiguating the
sense of the nouns they modify. Adjective classes could be further exploited in WSD
in at least two respects: (1) to establish an inventory of adjective senses (if polysemous
instances are correctly detected; this is where sense induction and our own work fits
in), and (2) to exploit class-based properties for the disambiguation, similar to related
work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and
Lee 2005).
The application where adjectives have received most attention, however, is Opinion
Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey
much of the evaluative and subjective information in language (Wiebe et al. 2004).
The typical goal of this kind of study has been to identify subjective adjectives and
their orientation (positive, neutral, negative). This type of research, from pioneering
work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997;
Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts
2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can
be translated into values that can be ordered along a scale. These adjectives typically
enter into antonymy relations (the semantic relation between good and bad), and in fact
antonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), the
most widely used semantic resource in NLP. However, when examining a large scale
lexicon, it becomes immediately apparent that there are many other types of adjectives
that do not easily fit in a scale-based or antonymy-based view of adjectives (Alonge
et al. 2000). Some examples are pulmonary, former, and foldable. It is not clear, for in-
stance, whether it makes sense to ask for an antonym of pulmonary, or to establish a
“foldability” scale for foldable. These adjectives need a different treatment, and they are
treated in terms of different semantic classes in this article.
The semantic properties of adjectives can also be exploited in advanced NLP tasks
and applications such as Question Answering, Dialog Systems, Natural Language Gen-
eration, or Information Extraction. For instance, from a sentence like This maimai is round
and sweet, we can quite safely infer that the (invented) object maimai is a physical object,
probably edible. This type of process could be exploited in, for instance, Information
Extraction and ontology population, although to our knowledge this possibility has
received but little attention (Malouf 2000; Almuhareb and Poesio 2004).
As for polysemy, previous approaches to the automatic acquisition of semantic
classes have mostly disregarded the problem, by biasing the experimental material
to include monosemous words only, or by choosing an approach that ignores
polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis,
Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira,
Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx
(2003), who used soft clustering methods for multiple assignment to verb semantic
classes (see Section 4.5).
There is very little related work in empirical computational semantics in modeling
regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to
account for regular polysemy with the CoreLex resource. CoreLex, building on the
Generative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 “basic
</bodyText>
<page confidence="0.994275">
578
</page>
<note confidence="0.902335">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.99988075">
types” (broad ontological categories). In CoreLex, each word is associated to a polysemy
class, that is, the set of all basic types its synsets belong to. Some of these polysemy
classes constitute instances of regular polysemy, as recently explored in Utt and Pad´o
(2011).
Lapata (2000, 2001) also addresses regular polysemy in the Generative Lexicon
framework. This work attempts to establish all the possible meanings of adjective-noun
combinations, and rank them using information gathered from the British National
Corpus (Burnage and Dunlop 1992). This information should indicate that an easy
problem is usually equivalent to problem that is easy to solve (as opposed to, for example,
easy text, that is usually equivalent to text that is easy to read). Thus, the focus is on
the meaning of adjective-noun combinations, not on that of adjectives alone as in the
present research.
</bodyText>
<sectionHeader confidence="0.926272" genericHeader="method">
3. Basis for a Semantic Classification of Adjectives
</sectionHeader>
<bodyText confidence="0.99775275">
Adjective classes in our definition are broad classes of lexical meaning. We will present
lexical acquisition experiments in which, given the evidence found in corpora and other
lexical resources, a semantic class can be assigned to a given adjective. For this purpose,
two preconditions are required:
</bodyText>
<listItem confidence="0.994615">
(a) a classification that establishes the number and characteristics of the target
semantic classes;
(b) a stable relation between observable features and each semantic class.
</listItem>
<bodyText confidence="0.999918666666667">
There is no established semantic classification for adjectives in computational linguistics
that we can use and, therefore, one subgoal of the research is to establish the clas-
sification in the first place, addressing (a), and exploiting the morphology–semantics
and syntax–semantics interfaces for acquisition, addressing (b). We are thus facing
a highly exploratory endeavor, and we do not regard the classifications we use as
final. We test two different classifications: an initial classification, based on the lit-
erature, for the experiments reported in Section 4, and an alternative classification,
for the experiments reported in Section 5. We next turn to presenting the two tested
classifications.
</bodyText>
<subsectionHeader confidence="0.96484">
3.1 Initial Classification
</subsectionHeader>
<bodyText confidence="0.9995102">
In the acquisition experiments reported in Section 4, we distinguish between qualita-
tive, intensional, and relational adjectives, which have the following properties (Miller
1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011).
Qualitative adjectives. These are prototypical adjectives like gran (‘big’) or dol¸c (‘sweet’),
including scalar adjectives, which denote attributes or properties of objects. Adjectives
in this class tend to be gradable and comparable (see Examples (4a–4b)). They are char-
acterized by exhibiting the greatest variability with respect to their syntactic behavior:
In Catalan, they can act as predicates in copular sentences and other constructions
(Examples (4c–4d)), and they can typically act as both pre- and post-nominal modifiers
(Examples (4e–4f)). When an adjective modifies a head noun in pre-nominal position,
</bodyText>
<page confidence="0.99395">
579
</page>
<figure confidence="0.980018063829788">
Computational Linguistics Volume 38, Number 3
the interpretation is usually nonrestrictive, as shown by the fact that they can modify
proper nouns (Example (4e)).
/
/
gran
big
molt
very
(4) a. Taula
Table
‘Very big table’
b. Aquesta
This
grandfssima
bigSUPERLATIVE
aquella
that
´es
is
m´es
more
taula
table
que
than
gran
big
‘This table is bigger than that one’
c. Aquesta
This
‘This table is big’
´es
is
taula
table
gran
big
d. Aquesta taula la veig massa gran
This table itOBJ-CL-FEM seepres−1stp−sg too big
‘This table seems to me to be too big’
e. La gran Diana va seguir cantant
The great Diana PAST-AUX continue singing.
‘Great Diana continued singing.’
f. Van portar una taula gran
PAST-AUX bring a table big
‘They brought in a big table’
</figure>
<bodyText confidence="0.830534125">
Intensional adjectives. These are adjectives like presumpte (‘alleged’) or antic (‘former’),
which according to formal semantics denote second-order properties (Montague 1974,
and subsequent work). Most intensional adjectives modify nouns in pre-nominal posi-
tion only (Example (5a)), and they cannot functionally act as predicates (Example (5b)).
They are also typically not gradable (Example (5c)).
(5) a. El Joan ´es el presumpte assassfmurderer
The Joan is the alleged
‘Joan is the alleged murderer’
</bodyText>
<figure confidence="0.9784295">
b. #El
The
presumpte
alleged
‘#Joan is alleged’
Joan
Joan
´es
is
c. #M´es presumpte assassfmurderer / #presumptfssim assassfmurderer
More alleged / allegedSUPERLATIVE
‘#More/very alleged murderer’
</figure>
<footnote confidence="0.579417">
Intensional adjectives like presumpte may appear in any order with respect to
qualitative adjectives, as in Example (6). The order, however, affects interpretation:
Example (6a) entails that the referent of the noun phrase is young, whereas Example
(6b) does not (McNally and Boleda 2004).
(6) a. jove presumpte assassf‘young alleged murderer’
</footnote>
<page confidence="0.987161">
580
</page>
<note confidence="0.547963">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.9090391">
b. presumpte jove assass´ı
‘alleged young murderer’
Relational adjectives. Adjectives such as pulmonar, estacional, bot`anic (‘pulmonary, sea-
sonal, botanical’) denote a relationship to an object (in the mentioned examples, LUNG,
SEASON, and PLANT objects). Most of them are denominal (e.g., pulmonar is derived
from pulm´o, ‘lung’) and can only modify nouns post-nominally (see Example (7a)).
Also, contrary to qualitative adjectives, they are not gradable (Example (7b)) and act
as predicates only under very restricted circumstances (Example (7c) vs. (7d)). If other
adjectives or modifiers co-occur with relational adjectives, these occur after the adjective
(Example (7e)). We will say relational adjectives are adjacent to the head noun.
</bodyText>
<listItem confidence="0.833772571428572">
(7) a. Tenia una malaltia pulmonar / #pulmonar malaltia
Had a disease pulmonary / pulmonary disease
‘He/she had a pulmonary disease’
b. #Malaltia molt pulmonar / pulmonar´ıssima
Disease very pulmonary / pulmonarySUPERLATIVE
#‘Very pulmonary disease’
c. La decisi´o europea → ??Aquesta decisi´o ´es europea
</listItem>
<bodyText confidence="0.996175">
The decision European → This decision is European
‘The European decision → ??This decision is European’
pulmonar
pulmonary
‘Tuberculose can be pulmonary’
e. inflamaci´o pulmonar greu / #inflamaci´o greu pulmonar
inflamation pulmonary serious / inflamation serious pulmonary
‘serious pulmonary inflammation’
Table 1 summarizes the properties just explained. Our goal is to use these properties
to induce the semantic class of adjectives. For instance, if an adjective is denominal,
appears almost exclusively in postnominal position, and is strictly adjacent to the head
noun, we predict that it is relational. In the experiments reported in Sections 4 and 5, we
</bodyText>
<tableCaption confidence="0.932391">
Table 1
</tableCaption>
<subsectionHeader confidence="0.7556055">
Initial classification: Linguistic properties of qualitative, intensional, and relational adjectives.
Qualitative Intensional Relational
</subsectionHeader>
<bodyText confidence="0.899191">
gran (‘big’) presumpte (‘alleged’) pulmonar ‘pulmonary’
</bodyText>
<equation confidence="0.806891833333333">
Property
predicative + − restricted
gradable/comparable + − −
position with respect to head noun both pre-nom. post-nom.
adjacent − − +
denominal − − +
</equation>
<bodyText confidence="0.380962">
d. La tuberculosi pot ser
The tuberculose can be
</bodyText>
<page confidence="0.899042">
581
</page>
<note confidence="0.266099">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.9792535">
extract data related to these and other properties of adjectives from linguistic resources,
and use them as features in machine learning experiments.
</bodyText>
<subsectionHeader confidence="0.999161">
3.2 Alternative Classification
</subsectionHeader>
<bodyText confidence="0.999843">
In the acquisition experiments reported in Section 5, we distinguish between qualitative,
relational, and event-related adjectives. The classification presented in Section 3.1 is
thus altered in two ways: (1) The intensional class is dropped. (2) A new class, that
of event-related adjectives, is added to the classification. The reasons for these changes
will become clear in the discussion of the experiments in Section 4. Here, we describe
the new class and provide a summary table of the alternative classification.
Event-related adjectives. Adjectives such as exportador, prom`es, resultant (‘exporting,
promised, resulting’) denote a relationship to an event, in this case, EXPORT, PROMISE,
and RESULT events, respectively. Most of them are deverbal. Like relational adjectives,
they are typically nongradable (see Example (8a)) and prefer the postnominal position
when modifying nouns (Example (8b)). Like qualitative adjectives, they typically can
act as predicates (Example (8c)).
</bodyText>
<listItem confidence="0.857672666666667">
(8) a. ´Es un pats {exportador / #molt exportador} de petroli
Is a country {exporting / very exporting} of oil
‘It is an oil exporting / #very exporting country’
b. #exportador pats
‘exporting country’
c. Aquest pats ´es exportador
</listItem>
<bodyText confidence="0.874461666666667">
This country is exporting
‘This is an exporting country’
Table 2 summarizes the properties of the alternative classification (for a more
thorough discussion of previous research on the semantics of adjectives and more
motivation for the classification, see Boleda [2007]). For comparison, we will briefly
outline the treatment of adjectives in WordNet (Miller 1998; Alonge et al. 2000). As
</bodyText>
<tableCaption confidence="0.783205">
Table 2
</tableCaption>
<figure confidence="0.188633666666667">
Alternative classification: Linguistic properties of qualitative, event-related, and relational
adjectives.
Qualitative Event-related Relational
gran (‘big’) exportador (‘exporting’) pulmonar ‘pulmonary’
Property
predicative + + restricted
</figure>
<footnote confidence="0.639599">
gradable/comparable + typically not −
position with respect to both post-nom. post-nom.
head noun
adjacent − − +
derivational type non-derived deverbal denominal
</footnote>
<page confidence="0.990643">
582
</page>
<note confidence="0.602317">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.999748090909091">
mentioned in Section 2, the main semantic relation around which adjectives are or-
ganized in WordNet is antonymy. Also as explained, however, not all adjectives have
antonyms. This is solved in WordNet by the use of indirect antonyms (e.g., swift and
slow are indirect antonyms, through the semantic similarity between swift and fast). Still,
indirect antonymy only applies to a small subset of the adjectives in WordNet (slightly
over 20% in WordNet 1.5). Therefore, some kinds of adjectives receive a differentiated
treatment.
Specifically, two main kinds of adjectives are distinguished in WordNet: (1) Descrip-
tive adjectives, akin to our qualitative adjectives, which are organized around antonymy
(descriptive adjectives, however, include intensional adjectives). (2) Relational adjec-
tives, as defined in this article, for which two different solutions are adopted. If a suit-
able antonym can be found for a given relational adjective (antonym in a broad sense;
in Miller [1998, page 60], physical and mental are considered antonyms), it is treated in
the same way as a descriptive adjective. Otherwise, it is linked through a PERTAIN-TO
pointer to the related noun. In addition, a subclass of descriptive adjectives, having
the form of past or present participles, is distinguished, and also receives a hybrid
treatment. Those that can be accommodated to antonymy are treated as descriptive
adjectives (laughing–unhappy, through the similarity between laughing and happy). Those
which cannot are linked to the source verb through a PRINCIPAL-PART-OF pointer. Our
event-related class includes not only past and present participles, but other types of
deverbal adjectives. Thus, most of the classes used in this article are to some extent
backed up by the organization of adjectives in WordNet.
</bodyText>
<subsectionHeader confidence="0.999453">
3.3 The Role of Polysemy
</subsectionHeader>
<bodyText confidence="0.9999028">
As explained in the Introduction, some adjectives are polysemous such that each sense
falls into a different class of the classifications just presented. Consider for instance
the adjective econ`omic in Example (1), repeated here as Example (9) for convenience.
The two main senses of econ`omic instantiate the relational (sense in Example (9a))
and the qualitative class (sense in Example (9b)), respectively.
</bodyText>
<listItem confidence="0.8778235">
(9) a. an`alisi econ`omica
‘economic analysis’
b. pantalons econ`omics
‘cheap trousers’
</listItem>
<bodyText confidence="0.998269">
Crucially for our purposes, in each of the senses the adjective exhibits the properties
of each of the associated classes. When used as a relational adjective, it is not gradable
and cannot be used in a pre-nominal position (Example (10)). When used as a qualitative
adjective, it is gradable and it can be used predicatively (see Example (11)). In the
experiments that follow, we aim at capturing this hybrid behavior.
</bodyText>
<figure confidence="0.3913802">
(10) a. #L’an`alisi molt econ`omica de les dades
The-analysis very economic of the data
‘#The very economic analysis of the data’
b. #Va dur a terme una econ`omica an`alisi
‘PAST-AUX bring to term an economic analysis
</figure>
<footnote confidence="0.769029">
‘#He/she carried out an economic analysis’
</footnote>
<page confidence="0.982511">
583
</page>
<figure confidence="0.680019">
Computational Linguistics Volume 38, Number 3
(11) Aquests pantalons s´on molt econ`omics!
These trousers are very economic!
</figure>
<bodyText confidence="0.947792833333333">
‘These trousers are very cheap!’
Cases of regular polysemy between the intensional and qualitative classes also exist,
as illustrated in Examples (12) and (13). Antic has two major senses, a qualitative one
(equivalent to ‘old, ancient’) and an intensional one (equivalent to ‘former’). Note again
that, when used in the intensional sense, it exhibits properties of the intensional class: It
appears pre-nominally (Example (13a)) and is not gradable (Example (13b)).
</bodyText>
<listItem confidence="0.954016">
(12) a. edifici antic
building ancient
‘ancient building’
b. edifici molt antic
building very ancient
‘very ancient building’
(13) a. antic president
ancient president
‘former president’
b. #molt antic president
very ancient president
‘#very former president’
</listItem>
<bodyText confidence="0.9995805">
The new class in the alternative classification, that of event-related adjectives, also
introduces regular polysemy, specifically, between event-related and qualitative adjec-
tives, as illustrated in Examples (14) and (15). The participial adjective sabut (‘known’)
has an event-related sense, corresponding to the verb saber (‘know’), and a qualitative
sense that can be translated as ‘wise’. Likewise, the deverbal adjective cridaner derived
from cridar (‘to shout’) alternates between an event-related sense and a qualitative sense.
</bodyText>
<listItem confidence="0.4540905">
(14) problema sabut / home sabut
problem known / man known
‘known problem / wise man’
(15) noi cridaner / camisa cridanera
</listItem>
<bodyText confidence="0.992079083333333">
boy shoutSUFFIX/ shirt attention-gaining
‘boy who shouts a lot / attention-gaining shirt’
Examples (14) and (15) represent cases of regular polysemy because, as can be drawn
from the translations, there is a systematic shift from a transparent relation with the
event to a quality that bears a more distant relation to the event. In the case of sabut the
relation is clear (if a man knows a lot, he is wise); in the case of cridaner, a shirt qualifies
for the adjective if it is for instance loud-colored or has an eccentric cut, such that it gains
the attention of people, as shouting does.
In this article, we only consider types of polysemy that cut across the classification
pursued. Other kinds of polysemy that have traditionally been tackled in the literature
will not be considered. For instance, we will not be concerned with the polysemy
illustrated in Example (16), which arguably has more to do with the semantics of the
</bodyText>
<page confidence="0.992807">
584
</page>
<note confidence="0.519868">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<listItem confidence="0.747357625">
modified noun than that of the adjective (Pustejovsky 1995). Both of the uses of trist
(‘sad’) illustrated in Example (16) fall into the qualitative class, so, contrary to the work
by Lapata (2000, 2001) cited previously, we do not treat the adjective as polysemous in
the context of the present experiments.
(16) noi trist / pel·l´ıcula trista
boy sad / film sad
‘sad boy / sad film’
4. First Model: Polysemous Adjectives Constitute Independent Classes
</listItem>
<bodyText confidence="0.999967476190476">
Given the hybrid behavior of polysemous adjectives explained in Section 3, we can
expect that they behave differently from adjectives in the basic classes. For instance,
adjectives polysemous between a qualitative and a relational use should exhibit more
evidence for gradability than pure relational adjectives, but less than pure qualitative
adjectives. In this view, polysemous adjectives belong to a class, for instance, the
qualitative-relational class, that is distinct from both the qualitative and the relational
classes, typically exhibiting feature values that are in between those of the basic classes.
In this section, we report on experiments testing precisely this model for regular
polysemy. We will therefore distinguish between five types of adjectives: qualitative,
intensional, relational, polysemous between a qualitative and an intensional reading
(intensional-qualitative), and polysemous between a qualitative and a relational reading
(qualitative-relational). There is one polysemous class missing (intensional-relational).
No cases of polysemy between intensional and relational adjectives were observed in
our data.
Recall from the previous sections that we cannot reuse an established classification,
and that there is virtually no previous work on the automatic semantic classification of
adjectives. The present experiments also aim at testing the overall enterprise of inducing
semantic classes from distributional properties for adjectives. Given the exploratory
nature of the experiment, we use clustering, an unsupervised technique, to uncover
natural groupings of adjectives and test to what extent these correspond to the classes
described in the literature.
</bodyText>
<subsectionHeader confidence="0.997856">
4.1 Data and Gold Standard
</subsectionHeader>
<bodyText confidence="0.998310615384615">
The experiments reported in this section are based on an eight million word fragment
of the CTILC corpus (Corpus Informatitzat de la Llengua Catalana; Rafel 1994), developed
at the Institut d’Estudis Catalans. Each word is associated with its lemma, part of speech,
and inflectional features, as well as syntactic function. Lemma and morphological in-
formation have been manually checked. We automatically added syntactic information
with CatCG (Alsina et al. 2002). CatCG is a shallow parser that assigns one or more
syntactic functions to each word. In the case of the adjective, CatCG distinguishes
between (1) predicate of a copular sentence; (2) predicate in another construction; (3)
pre-nominal modifier; (4) post-nominal modifier. As no full dependencies are indicated,
the head noun can only be identified with heuristics.
In the experiments, we cluster all adjectives occurring more than ten times in the
corpus (a total of 3,521 lemmata), and analyze the results using a subset of the data.
This is a randomly chosen 101-lemma gold standard (available in the Appendix). Fifty
</bodyText>
<page confidence="0.99381">
585
</page>
<note confidence="0.296394">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.99993172">
lemmata were chosen token-wise and 50 type-wise to balance high-frequency and low-
frequency adjectives (one lemma was chosen with both methods, so the repetition was
removed). Two lemmata were added in a post-hoc fashion, as explained subsequently.
The lemmata were annotated by four doctoral students in computational linguistics.
The task of the judges was to assign each lemma to one of the five classes (qualitative,
intensional, relational, qualitative-intensional, and qualitative-relational). The instruc-
tions for the judges included information about all linguistic characteristics discussed
in Section 3, including syntactic and semantic characteristics.
The judges had a moderate degree of agreement, comparable to that obtained in
other tasks on semantics or discourse, inter-annotator scores ranging between K = 0.54
and 0.64 (see Artstein and Poesio [2008] for a discussion of agreement measures for
computational linguistics). For comparison, V´eronis (1998) reported a mean pair-wise
weighted K = 0.43 for a word sense tagging task in French; and Merlo and Stevenson
(2001) obtained K = 0.53–0.66 for the task of classifying English verbs as unergative,
unaccusative, or object-drop. Poesio and Artstein (2005) report K values of 0.63–0.66
(0.45–0.50 if a trivial category is dropped) for the tagging of anaphoric relations. Our
judges reported difficulties in tagging particular kinds of adjectives, such as deverbal
adjectives. This issue will be retaken in Section 4.5.
No intensional adjectives were identified in the data by the judges, and only
one intensional-qualitative adjective was identified. Two intensional lemmata were
manually added to be able to minimally track the class. This is clearly insufficient for
a quantitative approach, however, so the intensional class is dropped in the alternative
classification. It is striking that intensional adjectives, which have traditionally been the
focus of formal semantic approaches to the semantics of adjectives, constitute a very
small class (less than a dozen lemmata are mentioned in the reviewed literature).
</bodyText>
<subsectionHeader confidence="0.838403">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.999973555555555">
We use two sets of distributional features to model adjective behavior: on the one hand,
theoretically motivated features (theoretical features for short); on the other hand,
features that encode the part-of-speech distribution of a four-word window around the
adjective (POS features). The former provide a theoretically informed model of adjec-
tives, because they are cues to the properties of each class as described in the literature.
The latter are meant to provide a theory-independent representation of adjectives, to
test to what extent the structures obtained with theoretical and POS features are similar.
Both sets of features take a narrow context into account (at most five words to each side
of the adjective), because of the limited syntactic behavior of adjectives.
</bodyText>
<listItem confidence="0.537737833333333">
4.2.1 Theoretical Features. Theoretical features model the syntactic and semantic proper-
ties of the classes described in Section 3. The features used, together with their mean
and standard deviation values (computed on all 3,521 adjectives), are summarized in
Table 3. A feature value va,i for an adjective lemma a and a feature i corresponds to the
proportion of the occurrences in which i is observed for adjective a over all occurrences
of a (see Equation (1); f stands for absolute frequency).
</listItem>
<equation confidence="0.989796666666667">
f (a, i)
va,i = (1)
f(a)
</equation>
<page confidence="0.957935">
586
</page>
<note confidence="0.511948">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.997906125">
Table 3 is the translation of Table 1 into shallow cues that can be extracted from
a corpus. The mean values in Table 3 are very low, which points to the sparseness of
theoretically defined properties such as predicativity or gradability, at least in written
texts (oral corpora would presumably yield different values). Also note that standard
deviations are higher than mean values, which indicates a high variability in the feature
values, something that will be exploited for classification.
From the discussion in Section 3, the following predictions with respect to the
semantic features can be made.
</bodyText>
<listItem confidence="0.949388692307692">
(1) In comparison with the other classes, qualitative adjectives should have
higher values for features gradable, comparable, copular, predicative, middle
values for feature prenominal, and low values for feature adjacent.
(2) Relational adjectives should have an almost opposite distribution, with
very low values for all features except for adjacent.
(3) Intensional adjectives should exhibit very low values for all features
except for pre-nominal, for which a very high value is expected.
(4) With respect to polysemous adjectives, it can be foreseen that their feature
values will be in between those of the basic classes. For instance, an
adjective that is polysemous between a qualitative and a relational reading
should exhibit a higher value for feature gradable than a monosemous
relational adjective, but a lower value than a monosemous qualitative
adjective.
</listItem>
<bodyText confidence="0.994745888888889">
Figure 1 shows that the predictions just outlined are met to a large extent, showing that
the empirical (corpus) data support the theoretical predictions. This graph represents
the value distribution of each feature in the form of boxplots. In the boxplots, the
rectangles have three horizontal lines, representing the first quartile, the median, and
the third quartile, respectively. The dotted line at each side of the rectangle stretches to
the minimum and maximum values, at most 1.5 times the length of the rectangle. Values
that are outside this range are represented as points and termed outliers (Verzani 2005).
Note that the scale in Figure 1 does not range from 0 to 1; this is because the data are
standardized, as will be explained subsequently.
</bodyText>
<tableCaption confidence="0.755079">
Table 3
</tableCaption>
<bodyText confidence="0.923914">
Theoretical features. The mean and SD values are computed on all clustered adjectives. Feature
copular accounts for predicative constructions with the copula verbs ser, estar (‘be’). Feature
predicative accounts for other predicative constructions, such as Example (4d).
</bodyText>
<subsectionHeader confidence="0.894499">
Feature Textual correlate Mean SD
</subsectionHeader>
<bodyText confidence="0.74718">
gradable degree adverbs, degree suffixation
</bodyText>
<footnote confidence="0.819152636363636">
comparable comparative constructions
copular copular predicate syntactic tag
predicative predicate syntactic tag
pre-nom pre-nominal modifier syntactic tag
adjacent first adjective in a series of two or more
0.04 0.08
0.03 0.07
0.06 0.10
0.03 0.06
0.04 0.08
0.03 0.05
</footnote>
<page confidence="0.92991">
587
</page>
<figure confidence="0.877603">
Computational Linguistics Volume 38, Number 3
</figure>
<figureCaption confidence="0.996572">
Figure 1
</figureCaption>
<bodyText confidence="0.95640825">
Theoretical features: Feature value distribution in the gold standard. Class labels: I = intensional;
IQ = polysemous between intensional and qualitative; Q = qualitative; QR = polysemous
between qualitative and relational; R = relational.
The differences in value distributions, although significant,1 are not sharp, as most
of the ranges in the boxes overlap. This affects mainly polysemous classes: Although
they show the tendency predicted—exhibiting values that are in between those of the
basic classes—they do not present clearly distinct values. The clustering results will be
affected by this distribution, as will be discussed in Section 4.5.
</bodyText>
<subsubsectionHeader confidence="0.673002">
4.2.2 POS Features. POS features encode the part-of-speech distribution of a four-word
</subsubsectionHeader>
<bodyText confidence="0.9998302">
window around the adjective, providing a theory-independent representation of the
linguistic behavior of adjectives. To avoid data sparseness, we encode possible POS for
each position as a different feature. For instance, for an occurrence of alta (‘tall’) as in Ex-
ample (17a), the representation would be as in Example (17b). In the example, the target
adjective is in boldface, and the relevant word window is in italics. Negative numbers
</bodyText>
<footnote confidence="0.581858666666667">
1 Tested by one-way ANOVA tests on each of the features (factor: Classes), excluding items in the I and
IQ classes because not enough observations are available. The test yields p-values lower than 0.05
(predicative), 0.01 (comparable, pre-nominal, adjacent), and 0.001 (gradable, copular), respectively.
</footnote>
<page confidence="0.992819">
588
</page>
<note confidence="0.766884">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<tableCaption confidence="0.7118915">
Table 4
POS features. The mean and SD values are computed on all clustered adjectives.
</tableCaption>
<table confidence="0.9990485">
Feature Mean SD Feature Mean SD
−1 noun 0.52 0.25 −2 preposition 0.13 0.09
+1 punctuation 0.42 0.15 −1 adverb 0.10 0.11
−2 determiner 0.39 0.20 −1 verb 0.08 0.11
+2 determiner 0.24 0.13 −1 determiner 0.06 0.10
+1 preposition 0.21 0.15 +1 noun 0.06 0.10
</table>
<bodyText confidence="0.957760545454545">
indicate positions to the left, positive ones positions to the right. The representation in
Example (17b) corresponds to the parts of speech of ´es, m´es, que, and la, respectively.
l’Angelina
the-Angelina
‘Bruna is taller than Angelina’
b. -2 verb, -1 adverb, +1 conjunction, +2 determiner
Feature values are defined as in theoretical features (see Equation (1)). The ten
features with the overall highest mean value in our data (among a total of 36 features)
are listed in Table 4. Note that the mean values are much higher for the POS features
(Table 4) than for the theoretical features (Table 3), as theoretical features are much
sparser.
</bodyText>
<subsectionHeader confidence="0.999925">
4.3 Clustering Algorithm and Parameters
</subsectionHeader>
<bodyText confidence="0.9999895">
We use the k-means clustering algorithm (see Kaufman and Rousseeuw [1990] and
Everitt, Landau, and Leese [2001] for comprehensive introductions to clustering).2 This
is a classical algorithm, conceptually simple and computationally efficient, which has
been used in related work, such as the induction of German semantic verb classes
(Schulte im Walde 2006) and the syntactic classification of Catalan verbs (Mayol, Boleda,
and Badia 2005). Also, it performs hard clustering, which is adequate for our purposes
(recall from Section 4.1 that we model polysemy in terms of separate classes). Additional
experiments with other clustering methods yielded similar results: We tested two hier-
archical and one flat algorithm, one of them agglomerative and the other two partitional,
with several clustering criteria, always using the cosine distance measure.
K-means is a flat, partitional algorithm that aims at minimizing the overall distance
from objects to their centroids (mean vectors of each cluster), which favors globular
cluster structures. An initial random partition into k clusters is performed on the data.
The centroids (mean vectors) of each cluster are computed, and each object is re-
assigned to the cluster with the nearest centroid. The centroids are recomputed, and the
process is iterated until no further changes take place, or a pre-specified number of times
(20 in our case). Equation (2) shows the formula for the clustering criterion, where k is
the total number of clusters and l are the lemmata in each cluster c1, ... , ck. To avoid the
</bodyText>
<listItem confidence="0.676475">
2 More specifically, because we are using the cosine measure, the algorithm is spherical k-means (Dhillon
and Modha 2001). All the experiments were performed with the CLUTO toolkit (Karypis 2002).
(17) a. la Bruna ´es m´es alta que
the Bruna is more tall than
</listItem>
<page confidence="0.900143">
589
</page>
<note confidence="0.259206">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999685666666667">
influence of the initial partition on the final structure, the whole experiment is repeated
several times (25 in our case) with different random partitions, and the partition that
better satisfies the clustering criterion is chosen.
</bodyText>
<equation confidence="0.9331745">
�minimize � cos(l, centroid(ci)) (2)
i∈k l∈ci
</equation>
<bodyText confidence="0.999905714285714">
We experimented with two representations of the feature values: raw and stan-
dardized proportions. In clustering, features with higher mean and standard deviation
values tend to dominate over more sparse features. Standardization smooths the differ-
ences in the strengths of features. We standardize to z-scores, so that all features have
mean 0 and standard deviation 1. As the most interpretable results were obtained with
standardized values, we will restrict the discussion in the next section to the results
obtained with standardized values.
</bodyText>
<subsectionHeader confidence="0.632096">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.999944833333333">
The discussion focuses on the cluster analyses with three and five clusters because
our basis is three classes (intensional, qualitative, and relational) and we consider a
total of five classes (basic classes plus polysemous classes: intensional-qualitative and
qualitative-relational). A higher number of clusters introduces more noise (in the form
of small clusters with no clear content).
The contingency tables of the clustering results with three clusters are depicted in
Table 5. Part A of the table depicts the solution obtained with theoretical features, while
Part B represents the solution obtained with POS features. Rows are gold standard
classes and columns are clusters, labeled with the cluster number provided by the
algorithm. The ordering of the cluster numbers corresponds to the quality of the cluster,
measured in terms of the clustering criterion (see Equation (2)), 0 representing the
cluster with the highest quality. In each cell Cij of Table 5, the number of adjectives
</bodyText>
<tableCaption confidence="0.698095">
Table 5
</tableCaption>
<bodyText confidence="0.9774408">
First model: Three-way solution contingency tables for theoretical and POS features. Rows are
gold standard classes, columns are clusters. Row TotalGS shows the number of Gold Standard
lemmata and row Totalcl the total number of lemmata contained in each cluster. Note that the
column labeled Total represents the row sum for each part (as the number of items per class
is identical).
</bodyText>
<subsectionHeader confidence="0.896244">
A: Theoretical B: POS
</subsectionHeader>
<bodyText confidence="0.987273">
Cluster 0 1 2 0 1
</bodyText>
<equation confidence="0.9260306">
intensional (I) 0 0 2 0 2
intensional-qualitative (IQ) 0 0 1 0 1
qualitative (Q) 4 13 35 10 37
qualitative-relational (QR) 3 5 3 7 2
relational (R) 21 13 1 20 5
</equation>
<figure confidence="0.876356666666667">
28 31 42 37 47
834 1,287 1,400 1,234 1,754
2 Total
0 2
0 1
5 52
2 11
10 35
17 101
533 3,521
TotalGS
Totalcl
</figure>
<page confidence="0.895432">
590
</page>
<note confidence="0.479216">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.99856775">
of class i that are assigned to cluster j by the algorithm is given. The largest value for
each class is highlighted (see gray cells).
A striking feature of Table 5 is that results in the two parts (A and B) are very similar.
The following can be observed:
</bodyText>
<listItem confidence="0.994729">
(1) There is one cluster (cluster 0 in both solutions) that contains the majority
of relational adjectives in the gold standard. This is the most compact
cluster according to the clustering criterion.
(2) Another cluster (2 in solution A, 1 in solution B) contains the majority of
qualitative adjectives in the gold standard, as well as all intensional and
IQ adjectives.
(3) The remaining cluster contains a mixture of qualitative and relational
adjectives in both solutions.
(4) Adjectives that are polysemous between a qualitative and a relational
reading (QR) are scattered through all the clusters, although they show a
tendency to be ascribed to the relational cluster in solution B (cluster 0).
</listItem>
<bodyText confidence="0.9995061875">
The five-way results are depicted in Table 6. On the one hand, the table shows that
the five-way structure found by the clustering algorithm is very similar to the three-
way structure in Table 5. This means that the three clusters in A and B have basically
been replicated by the three first clusters in C and D, respectively. On the other hand,
the differences between the structures obtained using theoretical versus POS features
are more obvious in the five-way solutions. From the set-up of the experiment, we
had expected one cluster per class, plus QR and IQ adjectives isolated in a cluster of
their own. This is clearly not borne out in Table 6. What we find instead is that (a)
the mixed clusters persist and score high in the clustering criterion (see clusters 0 in
solution C and 0–1 in solution D, with a mixture of Q, QR, and R adjectives), and (b)
two additional small clusters are created (clusters 3 and 4 in both solutions) with no
clear interpretation, suggesting that the three-way set-up matches better the structure
uncovered by the clustering algorithm.
From the discussion of Tables 5 and 6 we conclude that the three-way clustering
meets the target classification better than the five-way clustering, and that polysemous
adjectives are not identified as a separate class. These results suggest that modeling
</bodyText>
<tableCaption confidence="0.924872">
Table 6
</tableCaption>
<figure confidence="0.959809966666667">
First model: Five-way solution contingency tables. Information presented as in Table 5.
C: Theoretical D: POS
Cluster 0 1
I 0 0
IQ 0 0
Q 7 4
QR 5 3
R 12 21
TotalGS 24 28
Totalcl 857 854
3 4 0 1
0 0 0 0
0 0 0 0
4 2 3 7
0 0 6 1
0 1 11 9
4 3 20 17
156 192 828 406
3 4 Total
0 0 2
0 0 1
2 3 52
1 1 11
7 3 35
10 7 101
275 258 3,521
2
2
1
35
</figure>
<page confidence="0.858065538461538">
3
1
42
1462
2
2
1
37
2
5
47
1,754
591
</page>
<bodyText confidence="0.968931411764706">
Computational Linguistics Volume 38, Number 3
polysemous adjectives in terms of additional, complex classes is not an adequate strat-
egy (we return to this point subsequently).
Recall that we defined theoretical and POS features to compare the structures
obtained using theoretically informed and theory-independent features. Further feature
analysis, not reported here for space reasons, reveals a high correlation between the
most descriptive features of solutions A and B.3 This highlights the correspondence
between the two feature representations with respect to the clustering results: The
POS features elicited as most discriminative by the clustering algorithm are precisely
those that correspond to the theoretical features. This correspondence explains the
resemblance between the solutions obtained with the two types of representation and
at the same time provides support for the present definition of the theoretical features.
Last but not least, note that we do not assign a score to each clustering solution.
Evaluation of clustering is very problematic when there is no one-to-one correspon-
dence between classes and clusters (Hatzivassiloglou and McKeown 1993), as is our
case. Schulte im Walde (2006) provides a thorough discussion of this issue and proposes
different metrics and types of evaluation. We defer numerical evaluation until Section 5.
</bodyText>
<subsectionHeader confidence="0.850356">
4.5 Discussion
</subsectionHeader>
<bodyText confidence="0.998157464285714">
4.5.1 Classification. The experiments presented provide feedback to the question, what is
an appropriate broad semantic classification for adjectives? The clustering experiments
provide empirical support for the qualitative and relational classes, as is particularly
evident in the three-way solution (Table 5). These are classes that have traditionally been
taken into account in descriptive grammar (Bally 1944; Picallo 2002) and computational
resources such as WordNet (Miller 1998; Alonge et al. 2000), so we consider them to be
quite stable and keep them in our classification.
Intensional and IQ adjectives, in contrast, are grouped together with qualitative
adjectives in all solutions, because they do not exhibit distinctive enough distributional
properties to differentiate them, a fact aggravated by the small size of the intensional
class. From the point of view of NLP, it is reasonable to encode intensional adjectives
by hand, given their limited number. For these reasons, we include the intensional
class in the qualitative class in what follows (remember that, as mentioned in Sec-
tion 3, WordNet also includes intensional adjectives in the qualitative—in their terms,
descriptive—class).
”Hybrid” clusters, that is, clusters that contain adjectives from several semantic
classes, play an interesting role in our cluster analyses. Such clusters seem to be coherent
and stable, as they appear in all examined solutions (A, B, and also C and D in Tables 5
and 6) and have good scores in the clustering criterion. Significantly, however, most of
the adjectives that are problematic for humans are assigned to hybrid clusters, where
problematic means that they are not assigned to the same class by all four judges.
Conversely, most adjectives in the hybrid clusters are problematic. Thus, hybrid clusters
are useful to signal problems in the proposed classification. As an example, consider
cluster 0 in Part C of Table 6: 17 out of the 24 (70.1%) gold standard adjectives in this
hybrid cluster are problematic for humans. This cluster contrasts with the qualitative
cluster (cluster 2 of Table 6), where only 10 out of its 42 (23.8%) lemmata are problematic.
Two kinds of adjectives crop up among problematic adjectives: so-called ethnic
adjectives (alemany ‘German’, menorqui‘Menorcan’, sud-afric`a ‘South African’, xin`es
</bodyText>
<footnote confidence="0.841467">
3 Descriptive features are defined here as those that are among the three features with highest or lowest
mean values for at least three clusters in the five-way solution.
</footnote>
<page confidence="0.979467">
592
</page>
<note confidence="0.768189">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.966487608695652">
‘Chinese’), and deverbal adjectives (indicador ‘indicating’, parlant ‘speaking’, protector
‘protecting, protective’, salvador ‘savior’). Ethnic adjectives can act as predicates of
copular sentences in a much more natural way than typical relational adjectives,
and seem to be vague between a relational and a qualitative reading in their
semantics (Raskin and Nirenburg 1998, page 173). This kind of adjective will mainly be
treated as polysemous in the experiments reported in Section 5.
As for deverbal adjectives, they are clearly neither relational (they do not express
a relationship to an object) nor intensional. They are also not typically qualitative,
however, because they trigger a relationship to an event instead of denoting a simple
property. For instance, protector triggers a relationship with a stable event of protecting
in Example (18): A person named Serra belongs to the kind of associates who have as a
primary role to protect the association.
(18) Serra ... Era soci protector de l’Associaci´o de concerts
Serra ... was associate protecting of the-Association of concerts
‘Serra was a protecting associate of the Association of concerts’
These considerations motivate the addition of a class of event-related adjectives
in the overall classification. Event-related adjectives have not received much attention
in the linguistic literature, except for one particular subtype, namely, adjectival uses of
the participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995). As for compu-
tational resources, the English WordNet, as explained in Section 3, only distinguishes
some participial adjectives. In the Italian WordNet, however, other event-related adjec-
tives receive a specific treatment, through the encoding of the lexical relations CAUSES
and LIABLE-TO, as exemplified in Example (19) (Alonge et al. 2000):
</bodyText>
<listItem confidence="0.7744985">
(19) a. depuratorio ‘depurative, purifying’ CAUSES depurare ‘to depurate/purify’.
b. giudicabile ‘triable’ LIABLE-TO giudicare ‘to judge’.
</listItem>
<bodyText confidence="0.9998402">
To sum up, the results of the experiments reported in this section motivate a three-
way classification between qualitative, event-related, and relational adjectives. Note
that, in the revised classification proposed in this section, classes are uniformly defined
according to the ontological type of their denotation: Qualitative adjectives denote at-
tributes or properties, relational adjectives denote relationships to objects, and event-
related adjectives denote relationships to events. The classes correspond to the three
major types of entities in an ontology (attributes, objects, events), more specifically, to
the way adjectives participate from those entities. In this view, relational and event-
related adjectives denote properties, just as qualitative adjectives do, but they are a
specific type of property involving a relationship with either an object or an event.
The classification is in fact similar to the one proposed in the Ontological Semantics
framework (Raskin and Nirenburg 1998; Nirenburg and Raskin 2004).
Also note that the revised semantic classification bears a prominent relationship
to morphology: In the default case, qualitative adjectives are not derived, event-
related adjectives are deverbal, and relational adjectives are denominal. However, the
correspondence between semantic classes and derivational type is not a one-to-one
mapping. Although most event-related adjectives are deverbal, not only strictly
deverbal adjectives evoke events: For instance, tangible ‘tangible’ evokes an event of
touching, but there is no verb *tangir in Catalan (tangible is built on the Latin verb
tang¯o, ‘touch’). Raskin and Nirenburg (1998, page 187) cite examples for English
</bodyText>
<page confidence="0.990298">
593
</page>
<note confidence="0.477264">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.98679340625">
such as audible or ablaze. Similarly, some object adjectives are not denominal (such as
bot`anic ‘botanical’). Conversely, some denominal or deverbal adjectives are qualitative:
vergony´os ‘shy’ (from vergonya ‘shyness’), amable (literally ‘suitable to be loved’; has
evolved to ‘kind, friendly’). We will empirically check the correspondence between
morphology and semantic class in Section 5.5.
4.5.2 Regular Polysemy. Our first series of experiments also provides feedback to the
question, what is an adequate computational model for regular polysemy? Specifically,
we have shown that the treatment of regular polysemy in terms of independent classes
is not adequate. Remember that the motivation for the experiments presented in this
section was the hypothesis that polysemous adjectives exhibit a linguistic behavior
that participates from the basic classes involved in the regular polysemy, thus yielding
feature values that are in between those of the basic classes (cf. Figure 1). Thus, we had
expected that polysemous adjectives form a homogeneous group of lexical items, char-
acterized precisely by the fact that they exhibit properties from each class to a certain
degree. However, this expectation is not borne out in the results of the experiments.
To this respect, it is striking that QR adjectives (polysemous between a qualitative
and a relational reading) are spread throughout all the clusters in all solutions. They
are not identified as a homogeneous group, nor as distinct from the rest. Crucially, as
pointed out in Section 4.2, the differences between the feature values of polysemous
adjectives and those of the basic classes are not strong enough to motivate a separate
cluster.
We believe that the reason for these results is the fact that polysemous adjectives do
not in fact have a homogeneous, differentiated profile: In a given corpus, most adjec-
tives are used predominantly in one of their senses, corresponding to one of the basic
classes, and thus the “hard” classification with three clusters fits better. For instance, the
qualitative-relational adjective ir`onic (‘ironic’) is mainly used as a qualitative adjective
in the corpus. Accordingly, it always appears in the qualitative clusters. Conversely,
militar (‘military’) is mostly used as a relational adjective, and is consistently assigned
to one of the relational clusters in all solutions. Thus, although polysemous adjectives
on average do show a mixed behavior, each lexical item tends to pattern with one of the
basic classes. An alternative conceptualization of regular polysemy and experimental
design is called for, and this will be the topic of the next section.
</bodyText>
<sectionHeader confidence="0.9603945" genericHeader="method">
5. Second Model: Polysemous Adjectives Simultaneously Belong to
Different Classes
</sectionHeader>
<bodyText confidence="0.999888363636364">
The experiments presented in the previous section pursued two goals: on the one hand,
to test the initial classification proposal; on the other, to test a model of regular polysemy
that treats polysemous adjectives in terms of separate classes. With respect to the first
goal, the experiments in this section rely on the results of the previous experiments, and
use the alternative classification described in Section 3.2. The alternative classification
has in addition been supported by a clustering experiment not reported here for space
reasons (see Boleda, Badia, and Batlle [2004] for details and discussion).
With respect to the second goal, we have shown that the first model is not suc-
cessful at modeling regular polysemy. Furthermore, the analysis of feature values
in the previous section suggests that the lack of success is not related to the spe-
cific technique used in the initial experiment, but to the properties of polysemous
</bodyText>
<page confidence="0.98621">
594
</page>
<note confidence="0.760569">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.999465777777778">
adjectives: the fact that they are used predominantly in one of their senses, and the
fact that the feature distributions of “polysemous classes” largely overlap with those of
the basic classes.
In the present experiments, we develop an alternative approach to regular poly-
semy that is based on the perspective that polysemous adjectives belong to more than
one semantic class, in the framework of multi-label classification. A typical example
of a multi-label classification task is Text Categorization (Schapire and Singer 2000),
where a document can be described via more than one label (e.g., Health and Local), so
that it effectively belongs to more than one of the target classes. The motivation for this
new approach is the fact that polysemous adjectives exhibit properties of all the classes
involved (see Section 3.3). The hypothesis is that the evidence found for a polysemous
adjective that is polysemous between, say, a relational and a qualitative use should be
strong enough for the adjective to be assigned to both the relational and the qualitative
classes. Note that by assigning the adjective to the two classes independently, we make
an implicit classification of the adjective as polysemous. The success of the approach will
depend on whether the different senses are sufficiently represented in the data, and it
will be especially challenging to distinguish between noise and evidence for a given
class.
</bodyText>
<subsectionHeader confidence="0.984071">
5.1 Data and Gold Standard
</subsectionHeader>
<bodyText confidence="0.999969652173913">
The experiments reported in this section are based on a 16 million word fragment of
the CTILC corpus (see Section 4.1). We additionally use an adjective database (Sanrom`a
and Boleda 2010) with manually coded information about all adjectives occurring more
than 50 times in the corpus (2,296 lemmata). The database codes the derivational type
(deverbal, denominal, participial, non-derived) and suffix of each adjective.
A gold standard of 210 adjective lemmata (available in the Appendix) was selected
from this database for the experiments. The lemmata were randomly sampled in a
stratified fashion, balancing three factors of variability: frequency, morphological type,
and suffix. Thus, the gold standard contains an equal number of adjectives from three
frequency bands (low, medium, high), from the four derivational types, and from a
series of suffixes within each type. This sampling method is aimed at achieving semantic
variability.
Three experts assigned each of the 210 lemmata to one or two of the classes in the
alternative classification, namely, event-related, qualitative, or relational. The decisions
were reached by consensus and were based on expert knowledge together with the
examination of the information in the database, corpus examples, and the judgments
provided by 322 naive subjects in a large-scale annotation experiment.4
Table 7 shows the distribution of adjectives in the gold standard into classes ac-
cording to the three experts. These are the data used in the experiments presented in
this section. The proportion of polysemous adjectives is quite high, over 17%, with
qualitative-relational being the most frequent type of polysemy. Also note that 51%
of the adjectives are qualitative; this will be the baseline for the machine learning
experiments presented subsequently.
</bodyText>
<footnote confidence="0.979598">
4 For details on the annotation experiment, see Boleda, Schulte im Walde, and Badia (2008). The experiment
yielded low inter-coder agreement scores (estimated κ 0.31–0.45, observed agreement 0.62-0.70). Note
that the consensus classification is sub-optimal in the sense that its replicability cannot be estimated.
</footnote>
<page confidence="0.980334">
595
</page>
<table confidence="0.581589">
Computational Linguistics Volume 38, Number 3
</table>
<tableCaption confidence="0.987331">
Table 7
</tableCaption>
<table confidence="0.995276555555556">
Gold standard classification: Distribution and examples.
Class Label Example # %
qualitative Q tena¸c, ‘tenacious’ 107 51.0
event E informatiu, ‘informative’ 37 17.6
relational R crani`a, ‘cranial’ 30 14.3
qualitative-relational QR familiar, ‘familiar’ 23 11.0
qualitative-event QE sabut, ‘known’ 7 3.3
event-relational ER comptable, ‘countable’ 6 2.9
Total 210 100
</table>
<tableCaption confidence="0.999344">
Table 8
</tableCaption>
<bodyText confidence="0.779347818181818">
Feature sets. From left to right, each column depicts, for each feature set, an identifier, a
description of the type of information used, the total number of features, and one example
feature. Feature set morph contains two categorical features that are transformed into 25 if
binarization is applied; the remaining feature sets are numerical.
Feature set Description # Example
morph morphological (derivational) properties 2 (25) suffix
func syntactic function of the adjective 4 post-nom. modifier
uni uni-gram POS (1 word to left or to right) 24 −1noun
bi bi-gram POS (1 word to left and 1 to right) 50 −1noun+1adj
theor distributional cues of theoretical properties 18 gradable
Total 98 (121)
</bodyText>
<subsectionHeader confidence="0.841001">
5.2 Features
</subsectionHeader>
<bodyText confidence="0.983777294117647">
5.2.1 Feature Definition. We define five feature sets based on different types of linguistic
information, to gain further insight into the properties of each class. In particular, we
are interested in the properties of event-related adjectives, for which we do not have a
description in the linguistic literature. Table 8 summarizes the properties of the feature
sets used for the present experiments.
Feature set morph represents derivational properties of adjectives, as encoded in
the adjective database. We include this type of information because of the relevance
of morphology for the new classification (see Section 4.5). Func encodes the syntactic
functions of the adjectives in the corpus, as explained in Section 4.1. Uni (for unigram)
and bi (for bigram) encode the distribution of the adjective in the corpus in terms of
the parts of speech of the surrounding words. Feature analysis of the first experiment
showed that the word preceding and following the target were the most informative,
so in the present experiment only a one-word window is taken into account. The
unigram distribution (uni) encodes each part of speech separately, as was done in the
first experiment, and the bigram distribution (bi) takes the left and right word jointly,
to avoid feature correlation effects. In the latter feature set, only the 50 most frequent
bigrams are considered, to avoid features that are too sparse.5
</bodyText>
<footnote confidence="0.6473945">
5 For a more detailed explanation of the information encoded in feature sets uni and bi, see Boleda (2007,
section 5.2.2).
</footnote>
<page confidence="0.98954">
596
</page>
<note confidence="0.7816">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<tableCaption confidence="0.994942">
Table 9
</tableCaption>
<bodyText confidence="0.96089">
New or revised features in feature set theor. Each row lists the property we aim to capture and
the features through which the property is encoded. The information relies on the information
in the corpus, which does not include full syntactic structure.
</bodyText>
<subsectionHeader confidence="0.858689">
Property Features
</subsectionHeader>
<bodyText confidence="0.966636222222222">
type of determiner NP headed by definite/indefinite/no determiner
agreement properties gender and number of the NP
syntactic function of head noun subject, object, complement to a preposition
complement-bearing adjective followed by a preposition
distance to the head linear distance (number of words)
Finally, feature set theor (for theoretical) generalizes and adds to the theoretical
properties used in the first experiment (Table 3 in Section 4.2). Upon inspection of
the clustering solutions (not reported here for space reasons), some further potentially
relevant distributional pieces of information cropped up that were included in the
theor features of the present experiment. The new features, summarized in Table 9,
cover several aspects of the noun phrases (NPs) in which adjectives occur: The type
of determiner of the NP, agreement properties (as these can correlate with semantic
properties), the syntactic function of the head noun, and the presence of a potential
adjective complement. The latter are usually headed by prepositions (El Joan est`a gel´os
d’en Pere, ‘Joan is jealous of Pere’). Finally, feature distance to the head is a reformulation
of feature adjacent from Section 4.2. It encodes the mean distance of the adjective to
the head, in number of words, as this is a more general definition that alleviates data
sparseness.
As for feature values, they are computed as in the first experiment (see Equation (1)),
with the following exceptions: (1) morph features are of categorical type, so their values
are not numerical; (2) the two first features in Table 9, due to data sparseness consider-
ations, are computed as proportions over the use of the adjective as a nominal modifier
(see Equation (3), where amod is the number of occurrences of the adjective as modifier);
(3) the values for feature distance to the head, also in Table 9, do not range from 0 to 1 as
the other feature values, because they correspond to the mean distance to the head in
number of words. The data set used for the present experiments is available at the ACL
repository.6
</bodyText>
<equation confidence="0.8778785">
__ f (amod, i) (3)
va,i f(amod)
</equation>
<bodyText confidence="0.929764571428571">
5.2.2 Feature Tuning. We test the effects of feature selection in the performance of the
classifiers. The features are selected according to their performance within the machine
learning algorithm used for classification. Accuracy for a given subset of features is
estimated by cross-validation over the training data. Because the number of subsets in-
creases exponentially with the number of features, this method is computationally very
expensive, so we use a best-first search strategy. We also experiment with binarization
of the two categorical features (suffix, derivational type).
</bodyText>
<footnote confidence="0.792041">
6 http://aclweb.org/aclwiki/index.php?title=Database_of_Catalan_Adjectives_(Repository).
</footnote>
<page confidence="0.955677">
597
</page>
<note confidence="0.429043">
Computational Linguistics Volume 38, Number 3
</note>
<subsectionHeader confidence="0.983868">
5.3 Method
</subsectionHeader>
<bodyText confidence="0.996812">
The classification task is approached with a two-level architecture.
</bodyText>
<listItem confidence="0.9929658">
1. The decision on the class of the adjective is decomposed into three binary
decisions: Is it qualitative or not? Is it event-related or not? Is it relational
or not?
2. A complete classification is achieved by merging the results of the binary
decisions. A consistency check is applied by which (a) if all decisions
are negative, the adjective is assigned to the qualitative class (the
most frequent one; this was the case for a mean of 4.6% of the class
assignments); (b) if all decisions are positive, we randomly discard
one (three-way polysemy is not foreseen in our classification; this was
the case for a mean of 0.6% of the class assignments).
</listItem>
<bodyText confidence="0.999947903225806">
This is the standard architecture for multi-label classification tasks (Schapire and Singer
2000; Ghamrawi and McCallum 2005), and it has also been applied to NLP problems
such as entity extraction and noun-phrase chunking (McDonald, Crammer, and Pereira
2005).
Note that in the present experiments we change both the classification and the
approach (unsupervised vs. supervised) with respect to the first set of experiments
presented in Section 4, which can be seen as a sub-optimal technical choice. After
the first series of experiments that required a more exploratory analysis, however, we
believe that we have now reached a more stable classification, which we can test by
supervised methods. In addition, we need a one-to-one correspondence between gold
standard classes and clusters for the approach to work, which we cannot guarantee
when using an unsupervised approach that outputs a certain number of clusters with
no mapping to the gold standard classes.
We test two types of classifiers. The first type are Decision Tree classifiers trained
on different types of linguistic information coded as feature sets. Decision Trees are one
of the most widely machine learning techniques (Quinlan 1993), and they have been
used in related work (Merlo and Stevenson 2001). They have relatively few parameters
to tune (a requirement with small data sets such as ours) and provide a transparent
representation of the decisions made by the algorithm, which facilitates the inspection
of results and the error analysis. We will refer to these Decision Tree classifiers as simple
classifiers, in opposition to the ensemble classifiers, which are complex, as explained
next.
The second type of classifier we use are ensemble classifiers, which have received
much attention in the machine learning community (Dietterich 2000). When building
an ensemble classifier, several class proposals for each item are obtained from multiple
simple classifiers, and one of them is chosen on the basis of majority voting, weighted
voting, or more sophisticated decision methods. It has been shown that in most
cases, the accuracy of the ensemble classifier is higher than the best individual
classifier (Freund and Schapire 1996; Dietterich 2000; Breiman 2001). The main reason
for the general success of ensemble classifiers is that they are more robust towards
the biases particular to individual classifiers: A bias shows up in the data in the form
</bodyText>
<page confidence="0.992457">
598
</page>
<note confidence="0.751243">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.999235666666667">
of “strange” class assignments made by one single classifier, which are therefore
overridden by the class assignments of the remaining classifiers.7
For the evaluation, 100 different estimates of accuracy are obtained for each feature
set using 10-run, 10-fold cross-validation (10x10 cv for short). In this schema, 10-fold
cross-validation is performed 10 times, that is, 10 different random partitions of the
data (runs) are made, and 10-fold cross-validation is carried out for each partition. To
avoid the inflated Type I error probability when reusing data (Dietterich 1998), the
significance of the differences between accuracies is tested with the corrected resampled
t-test as proposed by Nadeau and Bengio (2003).8
</bodyText>
<subsectionHeader confidence="0.469341">
5.4 Results
</subsectionHeader>
<subsubsectionHeader confidence="0.614331">
5.4.1 Simple Classifiers. The accuracies for the simple classifiers are shown in Table 10.
</subsubsectionHeader>
<bodyText confidence="0.98573455">
Part A of the table lists the results for each of the binary decisions (qualitative/
non-qualitative, event/non-event, relational/non-relational). The accuracy for each de-
cision is computed independently. For instance, a qualitative-event adjective is judged
correct within the qualitative class iff the decision is qualitative; correct within the event
class iff the decision is event; and correct within the relational class iff the decision is
non-relational.
Part B reports the accuracies for the overall, merged class assignments, taking
polysemy into account (qualitative vs. qualitative-event vs. qualitative-relational vs.
event, etc.).9 In Part B, we report two accuracy measures: full and partial. Full accuracy
requires the class assignments to be identical (an assignment of qualitative for an adjec-
tive labeled as qualitative-relational in the gold standard will count as an error), whereas
partial accuracy only requires some overlap in the classification of the machine learning
algorithm and the gold standard for a given class assignment (a qualitative assignment
for a qualitative-relational adjective will be counted as correct). The motivation for
reporting partial accuracy is that a class assignment with some overlap with the gold
standard is more useful than a class assignment with no overlap. The figures in the
discussion that follow refer to full accuracy unless otherwise stated.
For the qualitative and relational classes, taking into account distributional infor-
mation allows for an improvement over the default morphology–semantics mapping
outlined in Section 4.5: Feature set all, containing all the features, achieves 75.5% accu-
racy for qualitative adjectives; feature set theor, with carefully defined features, achieves
86.4% for relational adjectives. In contrast, morphology seems to act as a ceiling for
7 The experiments discussed in this section were carried out with the Weka software package (Witten
and Frank 2011), version 3.6. The Decision Tree algorithm used is J48, the latest open source version of
C4.5 (Quinlan 1993), with default parameters (binary splits = False, confidence factor for pruning = 0.25,
minimum number of instances per leaf = 2, reduced-error pruning = False, subtree raising = True, unpruned =
False, use Laplace = False). AdaBoost has also been used with default parameters (base classifier = Decision
Stump, number of iterations = 10, random seed = 1, use resampling instead of reweighting = False, weight
threshold = 100). For Attribute Bagging, we used the Random Subspace algorithm, with J48 as base
classifier (parameters as before), bag size = 1/3, and random seed = 1. We experimented with different
values for the number of iterations (see Section 5.4.2).
8 Note that the corrected resampled t-test can only compare accuracies obtained under two conditions
(algorithms or, as is our case, feature sets); ANOVA would be more adequate. In the field of machine
learning, there is no established correction for ANOVA for the purposes of testing differences in
accuracy (Bouckaert 2004). Therefore, we use multiple t-tests instead, which increases the overall
error probability of the results for the significance tests.
9 Note that, for each adjective, only 10 different full classification proposals are obtained in each feature
set, because each adjective is only used once per run for testing. Therefore, while the per-class accuracy
for each feature set is assessed from 100 estimates (obtained via 10x10 cv), the accuracy of the different
feature sets for full classification is assessed comparing 10 accuracies. This holds for Tables 10 and 11.
</bodyText>
<page confidence="0.996886">
599
</page>
<table confidence="0.419051">
Computational Linguistics Volume 38, Number 3
</table>
<tableCaption confidence="0.74885825">
Table 10
Second model: Results with simple classifiers using different feature sets. The frequency
baseline (first row) is marked in italics. The last row, headed by all, shows the accuracy
obtained when using all features together for tree construction. The remaining rows follow the
nomenclature in Table 8; a FS subscript indicates that automatic feature selection is used as
explained in Section 4.2. For each feature set, we record the mean and the standard deviation
(marked by f) of the accuracies. Best and second best results are boldfaced. Significant
improvements over the baseline are marked as follows: *p &lt; 0.05; **p &lt; 0.01; ***p &lt; 0.001.
</tableCaption>
<table confidence="0.993951916666667">
A: Per-class accuracy B: Overall accuracy
Qualitative Event Relational Full Partial
baseline 65.2 f 11.1 76.2 f 9.9 71.9 f 9.6 51.0 f 0.0 65.2 f 0.0
morph 68.2 f 11.1 87.3** f 6.3 85.2*** f 7.2 59.9*** f 2.2 84.7*** f 0.7
morphFS 72.5* f 7.9 89.1** f 6.0 84.2*** f 7.5 60.6*** f 1.3 87.8*** f 0.4
func 75.1** f 9.0 76.1 f 9.8 82.8** f 7.5 56.0*** f 1.9 80.6*** f 1.8
uni 64.2 f 10.8 68.4 f 12.0 82.1** f 9.0 42.8 f 2.7 74.8*** f 2.6
uniFS 66.0 f 9.3 75.1 f 10.6 82.2** f 7.5 52.9 f 1.9 77.0*** f 2.0
bi 63.8 f 9.9 66.2 f 9.8 78.2* f 8.2 46.1 f 2.3 77.8*** f 1.8
biFS 67.4 f 10.6 72.3 f 10.2 83.0*** f 8.3 52.3 f 1.7 76.7*** f 1.0
theor 71.8 f 10.0 74.1 f 9.9 86.4*** f 7.6 54.8*** f 1.7 81.8*** f 1.8
all 75.5** f 9.0 86.5** f 6.4 86.0*** f 6.5 62.5*** f 2.5 87.6*** f 2.5
</table>
<bodyText confidence="0.95766962962963">
event-related adjectives: The best result, 89.1%, is obtained with morphological features
using feature selection. As will be shown in Section 5.5, event-related adjectives do not
exhibit a differentiated distributional profile from qualitative adjectives, which accounts
for the failure of distributional features to capture this class. As could be expected,
the best overall result is obtained with feature set all, that is, by taking all features
into account: 62.5% full accuracy is a highly significant improvement over the baseline,
51.0%. The second best results are obtained with morphological features using feature
selection (60.6%), due to the high performance of morphological information with event
adjectives.
Also note that the POS feature sets, uni and bi, are not able to beat the baseline for
full accuracy: Results are 42.8% and 46.1%, respectively, jumping to 52.9% and 52.3%
when feature selection is used, still not enough to achieve a significant improvement
over the baseline. Thus, for this task and this set-up, it is necessary to use well motivated
features. In this respect, it is also remarkable that feature selection actually decreased per-
formance for the motivated distributional feature sets (func, sem, all; results not shown in
the table), and only slightly improved over morph (59.9% to 60.6% accuracy). Carefully
defined features are of high quality and therefore do not benefit from automatic feature
selection. Actually, Witten and Frank (2011, page 308) state that “the best way to select
relevant attributes is manually, based on a deep understanding of the learning problem
and what the [features] actually mean.”
In the partial evaluation condition, however, all feature sets achieve a highly signif-
icant improvement over the baseline (p &lt; 0.001). Therefore, the classifications obtained
with any of the feature sets are more useful than the baseline, in the sense that they
present more overlap with the gold standard.
5.4.2 Ensemble Classifiers. Error analysis on the results using simple classifiers (not
reported for space reasons) revealed that the errors made by the different classifiers,
using different feature sets, are qualitatively quite different. This motivated the use
</bodyText>
<page confidence="0.99265">
600
</page>
<note confidence="0.834552">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<figureCaption confidence="0.991458">
Figure 2
</figureCaption>
<bodyText confidence="0.999281103448276">
Accuracy of the Attribute Bagging classifier as a function of the number of random partitions i.
Increasing i leads to a rapid increase of accuracy up to i = 30; after that, accuracy stabilizes and
experiences only a slight increase.
of Attribute Bagging (Ho 1998; Bryll, Gutierrez-Osuna, and Quek 2003), an ensemble
classifier (EC) in which the class assignments are obtained by majority voting over
randomly sampled feature subsets.10 Attribute Bagging has two main parameters: the
bag size (number of features used for each classification; it was set to 1/3 given results
reported in the literature, although varying this parameter did not affect the results
much), and the number of iterations i (we tested 3, 4, 5, 6, 10, 20, 30, 40, 50, 60, 70, 80, 90,
100; note that our total feature size is 121, see Table 8). Figure 2 shows that increasing i
leads to a rapid increase of accuracy up to i = 30; with higher i, accuracy experiments
only a slight increase.
Table 11 shows the results of Attribute Bagging, compared to the best simple clas-
sifier and human agreement (observed agreement, in percentage). The results obtained
with AdaBoost (a standard EC; default parameters) are also included as a sanity check.
The best results with Attribute Bagging, reported in the table, were obtained using
both feature selection and binarization (binarization did not improve results for the
remaining classifiers in Tables 10 and 11).
The Attribute Bagging EC with i = 5 achieves comparable accuracy to AdaBoost
with default parameters. Full accuracy results with the Attribute Bagging classifier with
i = 100 (69.1%) are significantly higher than those of the best simple classifier (62.5%; p &lt;
0.0001) and the AdaBoost classifier (p = 0.01; recall however that we did not optimize
AdaBoost’s parameters). Ensemble classifiers are thus helpful for our task.
The best classifier in our experiments (Att. Bagg.FS,bin,i = 100) obtains 69.1% full and
89.0% partial accuracy. This is comparable to the agreement between the expert anno-
tation of the gold standard and naive subjects participating in a large-scale annotation
experiment (po = 0.68, or 68%, and K = 0.55 for full accuracy, po = 0.85, or 85%, and K =
0.72 for overlapping accuracy; see Boleda, Schulte im Walde, and Badia [2008] for details
on the comparison). If we view human agreement as an upper bound, we have reached
</bodyText>
<footnote confidence="0.581607">
10 Grouping subsets according to linguistic considerations (i.e., building an EC over the feature subsets
listed in Table 8) improved upon the best simple classifier, but not upon Attribute Bagging.
</footnote>
<page confidence="0.989131">
601
</page>
<table confidence="0.421581">
Computational Linguistics Volume 38, Number 3
</table>
<tableCaption confidence="0.995893571428571">
Table 11
Second model: Results of the ensemble classifiers, compared to the best simple classifier (first
row) and to the human agreement on the gold standard (last row). Att. Bagg. stands for Attribute
Bagging, and i corresponds to the number of iterations. Percentage human agreement is included
in the last row. An FS subscript indicates feature selection, and bin binarization. Columns as in
Table 10. Best and second best results are boldfaced. Significant improvements over the best
simple classifier are marked as follows: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.
</tableCaption>
<table confidence="0.958223714285714">
A: Per-class accuracy B: Overall accuracy
Qualitative Event Relational Full Partial
best simple (all) 75.5 f 9.0 86.5 f 6.4 86.0 f 6.5 62.5 f 2.5 87.6 f 2.5
AdaBoost 82.0* f 8.6 85.6 f 7.1 88.0 f 6.7 66.0* f 1.9 89.9* f 1.3
Att. Bagg.FS,bin,i=5 77.0 f 8.7 85.8 f 7.1 89.0 f 6.5 66.3* f 1.1 87.0 f 1.5
Att. Bagg.FS,bin,i=100 81.0 f 8.8 86.1 f 6.9 90.1* f 5.3 69.1*** f 1.0 89.0 f 1.0
Human agreement � � � 68 85
</table>
<bodyText confidence="0.9938114375">
the maximum accuracy that could be obtained via machine learning for the present task.
Further improvements will need to be preceded by an improvement in the agreement
scores of human judges, that is, by a better definition of the classes and the classifying
task.
Finally, Table 11 shows that the best results are obtained for the relational class
(90.1%), followed by the event class (86.5%), and the qualitative class has the lowest
scores (at most 82%). The qualitative class contains attribute-denoting adjectives, but in
the present definition it is also populated with adjectives that simply do not fit into the
other classes (such as intensional adjectives, as explained earlier). Also, whereas some
adjectives in the class are prototypical qualitative adjectives such as gros ‘big’ or llarg
‘long’, others are unprototypical types of properties (subaltern ‘subordinate’, subsidiari
‘subsidiary’). This factor brings heterogeneity into the class, which justifies the relatively
poor performance of the classifier on this task. Significantly, also, ECs do not improve
upon simple classifiers for the event class; again, morphological information acts as
a ceiling and no combination of information serves to go beyond that ceiling, as will
become clear in the error analysis explained next.
</bodyText>
<subsectionHeader confidence="0.844567">
5.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999884461538462">
Table 12 depicts the contingency table of the classifications by the experts (rows) and
one randomly chosen run of the Attribute Bagging classifier with i = 100 (columns). The
table shows that there are two major sources of errors: First, the confusion between the
qualitative and event classes, which is responsible for 14 errors (see dark-gray shaded
cells in the table; also note that the related Q–QE and E–QE misclassifications account
for another 14 errors). To compare, note that the confusion between the qualitative and
relational classes only accounts for six of the errors, and there are no cases of confusion
between event and relational adjectives.
The second major source of errors is the overgeneration of polysemous adjectives
(see medium-gray shaded cells): there are 26 adjectives tagged as monosemous by the
experts and assigned a polysemous class by the system. To compare, the opposite case
(i.e., tagging polysemous adjectives as monosemous) accounts for 13 errors only (see
light-gray shaded cells). We next examine the two main types of errors in more detail.
</bodyText>
<page confidence="0.997056">
602
</page>
<note confidence="0.849468">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<tableCaption confidence="0.992396">
Table 12
</tableCaption>
<bodyText confidence="0.9865034">
Contingency table comparing the gold standard (rows) against run 2 of the Attribute Bagging
classifier with i = 100 (columns). Dark-gray cells highlight the confusion between the qualitative
and event classes; medium-gray cells highlight the overgeneration of polysemous adjectives;
light-gray cells highlight the opposite case, that is, the generation of monosemous adjectives
that should have been tagged as polysemous.
</bodyText>
<figure confidence="0.991899190476191">
QE ER Total
0 107
8
6 3 37
0 2 30
0 1 23
5 0 7
0 3 6
19 9 210
Q E R QR
Total 110 22 28 22
Q 90 4 2 3
E 10 17 0 1
R 4 0 20 4
0 4 13
1 0 0
ER 0 0 2 1
5
1
QR
QE
</figure>
<bodyText confidence="0.955111636363636">
5.5.1 Distinguishing between Qualitative and Event Adjectives. Table 12 suggests that there
are difficulties in distinguishing event-related from qualitative adjectives. Feature anal-
ysis confirms that the distinction between these two classes is only partially possible
on morphological grounds, but not on distributional grounds. As for morphological
information, Figure 3 shows that most event-related adjectives are deverbal or participle
adjectives, although the reverse is not true: 14 deverbal and two participle adjectives are
qualitative.
In fact, the class distribution varies with the suffix (see Table 13): Some types, such
as -or and the participle, show a clear predominance of the event class (see dark-gray
shaded cells); other types, such as -ble, -iu, or -nt, are more spread in their distribution
(see light-gray shaded cells). Thus, the suffix seems to influence the resulting readings,
with some active-like suffixes building a much more transparent relation to the
event (creador ‘creating’, exportador ‘exporting’, recomanat ‘recommended’), and some
passive-like or stative suffixes being more prone to creating a stative meaning
(contingent ‘contingent’, formidable ‘formidable I terrific’, significatiu ‘significant’). The
aspectual class of the deriving verb (Vendler 1957) also plays a role: For instance,
although the meaning of abundant (‘abundant’) is related to that of the verb abundar
(‘abound’), it clearly has a more stative (property-like) meaning than many of the other
event adjectives, due to the fact that the deriving verb is stative. Correspondingly,
Figure 3
Derivational types in the qualitative (Q) and event-related (E) classes. The bars represent the
classes, and the colors the derivational types, as shown in the legend.
</bodyText>
<page confidence="0.998227">
603
</page>
<table confidence="0.41704">
Computational Linguistics Volume 38, Number 3
</table>
<tableCaption confidence="0.991927">
Table 13
</tableCaption>
<bodyText confidence="0.999622447368421">
Contingency table of the most frequent deverbal suffixes (rows) and classification (columns).
Dark-gray cells highlight suffixes that mostly create event-related adjectives, and light-gray cells
indicate suffixes with a more spread class distribution.
abundant is classified as qualitative by the Attribute Bagging algorithm. This variation in
the morphology–semantics interface is also mirrored in the feature value distributions,
as will be shown subsequently.
As for distributional information, Figure 4 depicts the feature value distribution
for nine selected features across basic classes qualitative (Q), event-related (E), and
relational (R), excluding polysemous adjectives. The figure clearly shows that, whereas
relational adjectives tend to have a differentiated value distribution for many of
the features, the values for the event-related class in general overlap with those of
the qualitative class. In fact, of the 18 theoretically motivated features defined for the
experiments, only two exhibit statistically significant differences in the distribution
of the qualitative and event-related class according to a two-tailed t-test (α = 0.01; no
equality of variance assumed). These are pre-nominal and complement-bearing (graphs A
and I in Figure 4; df = 108.9/54.6, t = 3.56/−3.09, p-value = 0.0005/0.003, respectively).
These two features show that in general event-related adjectives appear less often than
qualitative adjectives in pre-nominal position and tend to bear more complements.
Both differences are presumably due to the fact that many event adjectives inherit
the argument structure of the deriving verb, with arguments expressed via PPs,
constituting heavier constituents that are placed after the head noun. This is but a slight
tendency and it is not homogeneous through the class, however.
The remaining features do not show differences between event and qualitative
adjectives, but rather properties of relational adjectives. In addition to the properties
that were already known, the figure shows that relational adjectives appear more often
in definite NPs acting as preposition complements (graphs E and H). Thus, the typical
syntactic context for a relational adjective is preposition + definite determiner + noun +
relational adjective). This type of adjective also appears slightly more often with feminine
head nouns, which could be due to the fact that, in Catalan, many abstract nouns ( f´ısica
‘physics’, capacitat ‘ability’) are feminine, for morphological reasons. These nouns are
often modified by relational adjectives to select for subtypes of the class of objects
denoted by the nouns (McNally and Boleda 2004).
Another difficulty in the distributional characterization of the event class is the
fact that it is quite heterogeneous, due to the variation at the morphology–semantics
interface discussed earlier. This can be traced in Figure 4 by the fact that for most of
the features, the box of the event class is larger than the box of the other two classes,
meaning that there is more variation within the event class than within the other two
classes.
</bodyText>
<figure confidence="0.999601379310345">
Q
-ble
3
-iu 3
-nt 4
-or 1
participle 2
Total 16
E
6
1
36
6
10
8
R QR QE
0 0 1
1 2 0
0 0 0
0 0 0
0 0 5
3 2 7
ER Total
1 11
4 11
1 11
0 11
0 15
6 70
</figure>
<page confidence="0.877123">
604
</page>
<note confidence="0.796718">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<figureCaption confidence="0.986866">
Figure 4
</figureCaption>
<bodyText confidence="0.935514615384615">
Feature value distribution across classes qualitative (Q), event-related (E), and relational (R) for
nine selected features (see Section 5.2 for the definition of these features).
To sum up, morphological features can quite reliably spot event-related adjectives,
but distributional information cannot. As a result, in the cases where morphology gives
the wrong prediction, nothing can be done on the distributional side to remedy this. This
results in the confusion of event-related and qualitative adjectives shown in Table 12.
5.5.2 Detecting Polysemous Adjectives. Recall from Table 12 that the system overgenerates
polysemous adjectives: There are 26 monosemous adjectives assigned to a polysemous
class. One of the reasons for this overgeneration is the procedure followed. The proce-
dure treats the decision on each of the basic classes as if they were all independent.
Thus, the probability for an adjective being polysemous amounts to the product of
the probabilities of the adjective belonging to each of the basic classes, as expressed
in Equation (4) for two arbitrary given classes, A and B.
</bodyText>
<equation confidence="0.996801">
p(AB) = p(A) ∗ p(B) (4)
</equation>
<bodyText confidence="0.5228115">
Table 14 shows that the distribution of polysemous items predicted by Equation (4)
is more similar to the distribution obtained with the best machine learning classifier
</bodyText>
<page confidence="0.992373">
605
</page>
<note confidence="0.446938">
Computational Linguistics Volume 38, Number 3
</note>
<tableCaption confidence="0.992002">
Table 14
</tableCaption>
<table confidence="0.923350571428571">
Distribution of polysemous items and absolute numbers, according to the prediction
(Equation (4); first column), in the machine learning (ML) results shown in Table 12
(second column), and in the gold standard (GS; third column).
Predicted ML GS
QR 15 22 23
QE 19 19 7
ER 5 9 6
</table>
<bodyText confidence="0.99818052173913">
(ML) than to the distribution of polysemous items in the gold standard (GS) for the QE
cases. The distribution is estimated from the frequency over the 210 adjectives in the
gold standard, and shown as absolute numbers.
Both Equation (4) and the ML classifier assign 19 adjectives to the QE polysemy
type, although the gold standard contains only 7 QE adjectives. The equation predicts
fewer QR adjectives than observed in the data, but in this case the classifier produces a
similar number of QR adjectives than attested (22 vs. 23). Finally, the classifier produces
more ER adjectives than observed and also than predicted by Equation (4), but in
this case the numbers are so small that no clear tendencies can be observed. Thus,
the procedure followed can be said to cause the overgeneration of items for the QE
polysemy type, but it does not account for the other two polysemous classes.
Further qualitative analysis on the overgenerated polysemous adjectives (corre-
sponding to the middle-gray cells in Table 12; not reported because of space concerns)
showed that different types of evidence motivate the inclusion of monosemous adjec-
tives in two classes, causing them to be considered polysemous. This suggests that,
because polysemous adjectives exhibit only partial or limited evidence of each class,
the threshold for positive assignment to a class is lowered, resulting in the observed
overgeneration. Recall that at the beginning of this section, when introducing the model,
we warned that it would be specially challenging to distinguish between noise and
evidence for a given class. We have indeed found this to be a challenge. The mentioned
effect is amplified by the procedure followed, which assumes that the class assignments
are independent, thus not adequately enough modeling the empirical distribution of
polysemy.
</bodyText>
<sectionHeader confidence="0.589666" genericHeader="method">
6. Discussion: Towards a Model for Regular Polysemy
</sectionHeader>
<bodyText confidence="0.955944545454545">
The acquisition experiments presented in Sections 4 and 5 correspond to two differ-
ent underlying models of regular polysemy. Figure 5 represents the two models in a
simplified scenario with just two basic classes (A and B). The first model (Figure 5(a);
experiments in Section 4) treats polysemous words in terms of independent classes. The
second model (Figure 5(b); experiments in Section 5) treats polysemous words alike to
those of the basic classes: Polysemous assignments result from membership in two basic
classes.
As can be seen in the figure, there are two main differences between the models.
First, the number of classes considered: Whereas the second model only considers n
classes, in the general case the first model will need to consider
n +121
</bodyText>
<page confidence="0.996079">
606
</page>
<note confidence="0.904477">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<figureCaption confidence="0.943149">
Figure 5
</figureCaption>
<bodyText confidence="0.999838444444445">
The two models of regular polysemy tested in this article, assuming a simplified scenario with
just two basic classes (A and B). The rows represent three different cases: one monosemous
adjective of class A (MonosemousA), one monosemous adjective of class B (MonosemousB), and
one polysemous adjective (PolysemousAB). The columns represent the classes assumed in each
model: Three classes (a), or only two (b). The correct class assignments for each case are shown
as dashed rectangles.
classes (n monosemous classes plus (Z) polysemous classes, all the possible two-
combinations of the monosemous classes). This formula assumes that only two-way
regular polysemy is allowed, as in this article; polysemy across three or more classes
would make the explosion of classes even worse. It is clear that the second model is
easier to learn.
The second difference concerns the way class assignments to polysemous words
are carried out. In the first model, polysemous words are assigned to one single, inde-
pendent class, whereas in the second they are assigned to each of the two basic classes
that give rise to the regular polysemy. Recall that the motivation for the first model was
that—given that regularly polysemous adjectives show a particular hybrid behavior—
we could expect that polysemous adjectives could be characterized as differentiated
classes. This expectation has clearly not been borne out. A further problem with the first
model it that it in principle allows for a polysemous class AB whose properties do not
necessarily have anything to do with those of the basic classes A and B. The second
model, in contrast, enforces that polysemous adjectives exhibit properties of each of the
classes they participate in, which is both theoretically and empirically more adequate.
For these reasons, we believe that the second model is more suitable to represent regular
polysemy than the first model.
The second model is also not completely satisfactory, however. As discussed in the
previous section, in the current implementation of the model the class assignments are
assumed to be independent (though this need not be the case in other instantiations of
the model). Also, in a way, it is at the opposite end of the scale with respect to the first
model: Whereas in the first model polysemous adjectives do not need to have anything
in common with the basic classes, in the second model a polysemous word is assumed
to be just like any other word in each of the basic classes. For instance, a qualitative-
relational adjective is assumed to function both as a full-fledged qualitative adjective
and a full-fledged relational adjective. By their very nature, polysemous words will
show only some evidence for each of the classes, as their occurrences (and thus their
properties) will be distributed across the two classes. Therefore, they will be untypical
members of at least one of the intervening classes.
</bodyText>
<page confidence="0.990251">
607
</page>
<note confidence="0.591542">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999813913043478">
An alternative instantiation of the second model could use soft clustering (Pereira,
Tishby, and Lee 1993; Rooth et al. 1999; Korhonen, Krymolowski, and Marx 2003), which
assigns a probability to each of the classes and is thus not bound to a hard yes/no
decision, as our approach does. From a theoretical point of view (and for many practical
purposes such as dictionary construction), however, a distinction between monosemous
and polysemous words is desirable, which adds a further parameter to be optimized
in a soft clustering setting. Overlapping clustering (Banerjee et al. 2005), which allows
for membership in multiple clusters, avoids this difficulty. Both methods have the
advantage that they do not assume independence of the decisions. The most serious
problem for the experiments presented in this article, however, would presumably also
be a problem for these settings: The fact that the skewed sense distribution of many
words makes it difficult to distinguish evidence for a particular class from noise. In
the soft clustering setting, for instance, it would be hard to distinguish whether 10%
evidence for class A and 90% for class B corresponds to polysemy with a skewed
distribution, to noise in the data, or simply to an untypical instance.
To sum up, the main problem for the models presented in this article is that nei-
ther model can capture the distributional connection between P(AB) and P(A), either
because AB and A are seen as unrelated atoms in the first place (first model), or because
AB is diluted into A and B (second model). A more refined statistical approach that can
model this interdependency is needed for further progress. Such a model should take
into account both the differences of polysemous adjectives with respect to the other
adjectives in the basic classes (first model) and their similarities (second model), thus
directly capturing their hybrid behavior.
</bodyText>
<sectionHeader confidence="0.826243" genericHeader="method">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.999958739130435">
This article has tackled the automatic induction of semantic classes for Catalan ad-
jectives, with a special emphasis on regular polysemy. To our knowledge, this is the
first time that such an endeavor has been carried out, as (1) related work on lexical
acquisition has focused on verbs (and, to a lesser extent, nouns) and on major languages
such as English and German; and (2) polysemy in general has been largely ignored in
lexical acquisition, and regular polysemy has only been sparsely addressed in empirical
computational semantics.
We have explored the relationship between observable cues and semantic proper-
ties for adjectives, and, specifically, the morphology–semantics and syntax–semantics
interfaces. We have showed that there is a systematic relation between the type of
denotation of an adjective and its morphological and distributional properties. Our
experiments have furthermore related the linguistic properties of adjectives as described
in the literature to the information that can be extracted from linguistic resources, such
as corpora or lexical databases. The presented results and analyses provide empirical
support for the qualitative and relational classes, defined in theoretical work, and bring
event-related adjectives into focus, a type of adjective that has been largely neglected in
the literature.
This article has focused on Catalan as a case study, but most of the properties
discussed (predicativity, gradability, complementation patterns), as well as the types
of polysemy explored, are relevant for a broader range of languages, specially Indo-
European languages (Dixon and Aikhenvald 2004). The approach does not require
deep-processing resources (full parsing, semantic tagging, semantic role labeling),
which makes it useful for lesser-researched languages.
</bodyText>
<page confidence="0.995339">
608
</page>
<note confidence="0.829662">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.99997012">
The experiments show that a major bottleneck for our purposes is the definition of
the classification itself: The machine learning results obtained have reached an upper
bound, as the best classifier has achieved 69.1% accuracy (against a 51.0% baseline), and
the human agreement is 68%. Thus, improvements in the computational task will need
to be preceded by improvements in the agreement scores, that is, by a better and clearer
definition of the classification and the classification task. We have shown that this is
by no means a trivial issue. In fact, low inter-coder agreement scores are a problem for
machine learning approaches to semantic and discourse-related phenomena in general.
This is in contrast to tasks such as POS tagging or syntactic parsing, where relatively
high inter-coder agreement scores are achieved. This state of affairs is probably due to
the fact that semantic and pragmatic phenomena are much less well understood than
morphological or syntactic phenomena.
Our experiments have highlighted a number of problems with the current classifi-
cation proposal. First, the distinction between event-related and qualitative adjectives.
The event class cannot be distinguished from the qualitative class with the distributional
information used in this article, and its members are not homogeneous. We have shown
that factors such as the aspectual class of the deriving verb or the suffix of the deverbal
adjective play a role in the semantic and syntactic behavior of these adjectives that
should be further explored. Also, a crucial type of evidence remains to be explored,
namely, the selectional preferences of adjectives. These may be a relevant clue to the dif-
ferences between qualitative and event-related adjectives. The second main problem is
the fact that the qualitative class contains adjectives that do not fit into the other classes,
constituting a sort of “catch-all” class. A natural extension for the work presented in
this article would be to define a finer-grained categorization including the problematic
cases discussed earlier. For instance, adjectives deriving from stative verbs could be
distinguished from those deriving from active verbs, and different types of qualitative
adjectives could be treated as different classes.
As for regular polysemy, we have shown that polysemous adjectives exhibit a
hybrid behavior, with properties from all the classes involved in each type of regular
polysemy. We have empirically tested two models of the phenomenon aimed at
exploiting this hybrid behavior. The first model treats polysemous words in terms
of independent classes, and we have argued that it is not adequate, neither from
a theoretical nor from an empirical perspective. The second model assumes that
polysemous words belong to each of the basic classes participating in the regular
polysemy. This model is more adequate than the first one, as it accounts for the
properties of the basic classes found in polysemous words, but it fails to account for the
differences between polysemous and monosemous words. To improve on the modeling
of regular polysemy, we plan to move to token-based (word-in-context) models
(Sch¨utze 1998; Erk and Pad´o 2010), as opposed to type-based models as we have done
in this article. This should in turn shed light into the problem of distinguishing between
evidence for a particular class from noise, discussed previously.
Finally, at a methodological level, we have illustrated how the broad coverage,
large-scale, radically empirical approaches developed in computational linguistics can
be of use to uncover phenomena and facts that are relevant for the study of language,
providing complementary evidence to the analytic tools traditionally used by linguists.
Most prominently, we have shown that (1) by randomly sampling the set of words to be
analyzed, new or neglected phenomena emerge; (2) the feature representation typically
used by machine learning algorithms provides an empirical handle to the linguistic
properties of words that can be explored in different ways (e.g., to test hypotheses
about the morphology-syntax and semantics-syntax interfaces); (3) machine learning
</bodyText>
<page confidence="0.995471">
609
</page>
<note confidence="0.593177">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999279666666667">
experiments provide a framework for the systematic evaluation of different models
of the phenomenon under study (in our case, both adjective classification and regular
polysemy). Computational linguistic studies are also inherently limited in several
aspects, such as the type of evidence that can be used or the ways in which it can be
used. Despite these limitations, we believe that empirical computational linguistics
approaches are a gold mine of new knowledge about language.
</bodyText>
<sectionHeader confidence="0.500625" genericHeader="method">
Appendix: Gold Standard Data
</sectionHeader>
<bodyText confidence="0.995057583333333">
In the following, we include the lemmata that were manually classified for the first and
second set of experiments, respectively (Sections 4 and 5). For details on the classes and
the methodology, see the body of the article. The translation of the adjectives has been
carried out with the help of the Spanish–English/English–Spanish Collins Dictionary
(3rd edition) and Google Translator.11 Different senses are separated with a vertical bar
(‘|’), different translations of the same sense with a comma (‘,’). Whenever possible,
we have included adjective equivalents; many of the relational adjectives, however, are
equivalent to attributive uses of nouns. Such nominal translations have been marked
with (attr.).
Recall that the gold standard for the second experiment, together with its feature
values, is available at the ACL repository (see URL in footnote 6).
Gold standard for the experiments with the first model (Section 4).
</bodyText>
<listItem confidence="0.950407217391305">
• intensional (I): mer ‘mere’, presumpte ‘alleged’.
• qualitative (Q): accidental ‘accidental’, accidentat ‘uneven, rough  |injured’,
alienant ‘alienating’, anticlerical ‘anticlerical’, avergonyit ‘ashamed’, bastard
‘bastard’, benigne ‘benign’, caracurt‘short-faced’, coherent ‘coherent’,
colpidor ‘striking’, contradictori ‘contradictory’, cosmopolita ‘cosmopolitan’,
destructor ‘destructive’, diversificador ‘diversifying’, duratiu ‘durative’,
esc`apol ‘fleeing’, esfere¨ıdor ‘terrifying’, evident ‘evident’, exempt ‘exempt’,
expeditiu ‘expeditious’, fortu¨ıt ‘fortuitous’, gradual ‘gradual’, grandi´os
‘grand’, gratu¨ıt ‘free  |gratuitous’, honest ‘honest’, implacable ‘implacable’,
infreq¨uent ‘infrequent’, innoble ‘ignoble’, inquiet ‘anxious  |restless’,
insalvable ‘insuperable’, inservible ‘useless’, invers ‘inverse’, irreductible
‘unyielding’, laber´ıntic ‘labyrinthine’, llaminer‘sweet-toothed  |appetising’,
malalt ‘ill’, morat ‘purple’, negatiu ‘negative’, nombr´os ‘numerous’, pen´os
‘distressing’, preeminent ‘pre-eminent’, preponderant ‘preponderant’,
raonable ‘reasonable’, real ‘real’, representatiu ‘representative’, sobrenatural
‘supernatural’, subsidiari ‘subsidiary’, supraracional ‘supra-rational’, trivial
‘trivial’, uniforme ‘uniform’, usual ‘usual’, ut`opic ‘Utopian’, vitalista
‘vitalist(ic)’.
• relational (R): adquisitiu ‘acquisitive’, alfab`etic ‘alphabetical’, carb`onic
‘carbonic’, cervical ‘neck (attr.), cervical’, climatol`ogic ‘climatologic’,
col·laborador ‘collaborating’, curatiu ‘curative’, diof`antic ‘diophantic’,
formatiu ‘formative’, freudi`a ‘Freudian’, governatiu ‘governmental’,
indicador ‘indicating’, onom`astic ‘name (attr.), onomastic’, parlant ‘talking’,
</listItem>
<page confidence="0.7466755">
11 http://translate.google.com.
610
</page>
<note confidence="0.818213">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.710052">
penitenciari ‘penitentiary, prison (attr.)’, periglacial ‘periglacial’, pesquer
‘fishing’, petri ‘stony’, preescolar ‘preschool (attr.)’, protector ‘protecting’,
salvador ‘rescueing’, sociocultural ‘sociocultural’, sud-afric`a ‘South African’,
t`actil ‘tactile’, terciari ‘tertiary’, terminol`ogic ‘terminological’, topogr`afic
‘topographic(al)’, tor`acic ‘thoracic’, vaginal ‘vaginal’, valencianoparlant
‘Valencian-speaking’, ventral ‘ventral’, veterinari ‘veterinary’, voc`alic
‘vocalic, vowel (attr.)’, xin`es ‘Chinese’.
</bodyText>
<listItem confidence="0.8699756">
• intensional-qualitative (IQ): antic ‘ancient  |former’.
• qualitative-relational (QR): alemany ‘German’, celest ‘celestial  |sky blue’,
contaminant ‘pollutant’, cultural ‘cultural’, femeni‘female (attr.)  |feminine’,
ir`onic ‘irony (attr.)  |ironic’, menorqui‘Menorcan’, militar ‘war (attr.) |
military’, sonor ‘sound (attr.)  |sonorous’, triomfal ‘triumphal  |triumphant’,
viril ‘man (attr.)  |virile, manly’.
Gold standard for the experiments with the second model (Section 5).
• qualitative (Q): absort ‘absorbed’, aleatori ‘random’, altiu ‘haughty’, ample
‘wide’, animal ‘animal’, an`omal ‘anomalous’, baix ‘low’, benigne ‘benign’,
bord ‘infertile (plant)  |stroppy (person)’, caduc ‘deciduous’, calb ‘bald’,
</listItem>
<bodyText confidence="0.959236807692308">
capa¸c ‘able’, cardinal ‘cardinal’, caut ‘cautious’, c`elebre ‘famous’, concret
‘concrete’, conservador ‘conservative’, contingent ‘contingent’, cru ‘raw |
crude’, curull ‘full’, decisiu ‘decisive’, deficient ‘deficient, defective’, delici´os
‘delicious’, desproporcionat ‘disproportionate’, dificult´os ‘difficult’, esquerre
‘left’, excels ‘sublime’, exquisit ‘exquisite’, fluix ‘weak  |loose’, foll ‘crazy’,
formidable ‘formidable  |terrific’, franc ‘frank’, fresc ‘fresh’, gros ‘big’, gruixut
‘thick’, humil ‘humble’, igual ‘equal, alike’, imperfecte ‘imperfect’, impropi
‘improper’, incomplet ‘incomplet’, inhum`a ‘inhuman’, insuficient
‘insufficient’, integral ‘integral  |wholegrain’, integre ‘entire’, intel·ligent
‘intelligent’, intern ‘intern’, liquid ‘liquid’, llarg ‘long’, llis ‘smooth’, mal
‘bad’, m`axim ‘maximum’, menor ‘minor  |smaller  |younger’, minim
‘minimum’, moll ‘wet’, morat ‘purple’, mutu ‘mutual’, notori ‘notorious’,
ocult ‘hidden’, opac ‘opaque’, paradoxal ‘paradoxical’, peculiar ‘peculiar’,
perill´os ‘dangerous’, pertinent ‘pertinent’, pessimista ‘pessimistic’, pl`acid
‘placid’, preco¸c ‘precocious’, predilecte ‘favorite’, primari ‘primary’, primitiu
‘primitive’, propens ‘prone’, pr`osper ‘prosperous’, prudent ‘prudent’,
punxegut ‘sharp-pointed’, quadrat ‘square’, reaccionari ‘reactionary’, recent
‘recent’, reciproc ‘reciprocal’, remarcable ‘remarkable’, responsable
‘responsible’, rigid ‘rigid’, roent ‘burning’, sant ‘saint’, semicircular
‘semicircular’, seri´os ‘serious’, significatiu ‘significant’, silenci´os ‘silent’,
similar ‘similar’, simplista ‘simplistic’, subaltern ‘subordinate’, sublim
‘sublime’, subsidiari ‘subsidiary’, subterrani ‘underground’, superflu
‘superfluous’, tena¸c ‘tenacious’, terrible ‘terrible’, tipic ‘typical’, titular
‘titular, official’, tort ‘bent’, total ‘total’, tou ‘soft’, triangular ‘triangular’,
vague ‘vague’, ver ‘true’, vici´os ‘vicious’, vigor´os ‘vigorous’, viril ‘virile’,
vulgar ‘vulgar’.
</bodyText>
<listItem confidence="0.886445">
• event-related (E): abundant ‘abundant’, abund´os ‘plentiful’, acompanyat
‘accompanied’, admirable ‘admirable’, contradictori ‘contradictory’,
convincent ‘convincing’, creador ‘creative’, divergent ‘divergent’, encarregat
</listItem>
<page confidence="0.99126">
611
</page>
<note confidence="0.562899">
Computational Linguistics Volume 38, Number 3
</note>
<bodyText confidence="0.999707111111111">
‘in charge’, exigent ‘demanding’, exportador ‘exporting’, immutable
‘immutable’, imperceptible ‘imperceptible’, informatiu ‘informative’, irat
‘angry’, matiner ‘who gets up early’, motor ‘motor’, oblidat ‘forgotten’,
orientat ‘oriented’, picat ‘pricked  |minced  |offended’, preferible ‘preferable’,
productor ‘producing’, prom`es ‘promised’, protector ‘protecting, protective’,
receptor ‘receiving’, recomanat ‘recommended’, regulador ‘regulating’,
resultant ‘resulting’, revelador ‘revealing’, salvador ‘savior’, satisfactori
‘satisfactory’, sospit´os ‘suspicious  |suspect’, temible ‘fearsome’, treballador
‘working’, variable ‘variable’, victori´os ‘victorious’, vivent ‘living’.
</bodyText>
<listItem confidence="0.850296">
• relational: americ`a ‘American’, angular ‘angular’, at`omic ‘atomic’, barceloni‘Barcelonian’, calcari ‘calcareous’, causal ‘causal’, ciutad`a ‘city (attr.)’,
</listItem>
<bodyText confidence="0.998361714285714">
conflictiu ‘conflict (attr.)’, corporatiu ‘corporate’, crani`a ‘skull (attr.)’, diari
‘daily’, el`ectric ‘electric(al)’, epistemol`ogic ‘epistemological’, esc`enic ‘scenic’,
estacional ‘seasonal’, fang´os ‘muddy’, imperial ‘imperial’, lleidat`a ‘Leridan’,
manres`a ‘Manresan’, marxi`a ‘Marx (attr.)’, mel`odic ‘melodic’, mercantil
‘mercantile’, obrer ‘working-class, labour (attr.)’, ontol`ogic ‘ontological’,
pasqual ‘paschal’, peninsular ‘peninsular’, renaixentista ‘Renaissance (attr.)’,
respiratori ‘respiratory’, terrestre ‘terrestrial’, viari ‘road (attr.)’.
</bodyText>
<listItem confidence="0.9629759">
• event-qualitative (EQ): animat ‘animate  |lively’, cridaner ‘who usually
shouts  |loud-colored’, embolicat ‘wrapped up  |messy’, encantat ‘charmed |
happy’, obert ‘opened  |open’, raonable ‘that can be reasoned on |
reasonable, fair’, sabut ‘known  |wise’.
• event-relational (ER): comptable ‘countable  |account (attr.)’, cooperatiu
‘cooperative  |cooperative (attr.)’, digestiu ‘digestive  |digestion (attr.)’,
docent ‘teaching  |educational’, nutritiu ‘nutritive  |nutritional’, vegetatiu
‘vegetative  |vegetation (attr.)’.
• qualitative-relational (QR): alegre ‘cheerful’, amor´os ‘lovely  |love (attr.)’,
anarquista ‘anarchistic  |anarchist’, capitalista ‘capitalistic  |capitalist’,
catalanista ‘Catalanistic  |Catalanist’, comunista ‘communistic  |communist’,
di¨urn ‘diurnal, day (attr.)’, er`otic ‘erotic  |love (attr.)’, familiar ‘familiar |
family (attr.)’, feminista ‘feminist  |feminism (attr.)’, hum`a ‘humane |
human’, infantil ‘childish  |child (attr.)’, intu¨ıtiu ‘intuitive  |intuition (attr.)’,
local ‘local  |place (attr.)’, nocturn ‘nocturnal, night (attr.)’, po`etic ‘poetic,
idealized  |poetry (attr.)’, professional ‘(worker) who works well |
professional, job (attr.)’, revolucionari ‘revolutionary  |revolution (attr.)’,
sensitiu ‘sensitive  |sensation (attr.)’, socialista ‘socialistic  |socialist’, turistic
‘touristy  |tourist (attr.)’, unitari ‘unitary  |union (attr.)’, utilitari ‘utilitarian |
utility (attr.)’.
</listItem>
<sectionHeader confidence="0.998379" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.96577725">
The authors wish to thank `Angel Gil,
Laia Mayol, MartiQuixal, and Roser
Sanrom`a for participating in the annotation
of the gold standards; David Farwell,
</bodyText>
<footnote confidence="0.770068272727273">
Louise McNally, Sebastian Pad´o, and MartiQuixal for comments and discussion on
previous versions of this article; Josep
Maria Boleda, Montse Cuadros, and Edgar
Gonz`alez for technical help; and the
anonymous reviewers for their constructive
criticism, which has greatly helped improve
the article. This work has been supported
via Ph.D. grants to the first author by the
Generalitat de Catalunya (2001FI 00582), the
Fundaci´on Caja Madrid, and the Universitat
Pompeu Fabra; also by the Ministry of
</footnote>
<page confidence="0.983782">
612
</page>
<note confidence="0.81607">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<bodyText confidence="0.934727111111111">
Education and the Ministry of Science and
Technology of Spain under contracts
FFI2010-09464-E (REDISIM), FFI2010-15006
(OntoSem 2), TIN2009-14715-C04-04
(KNOW2), and JCI2007-57-1479; and by
the European Union via the EU PASCAL2
Network of Excellence (FP7-ICT-216886).
The second author was funded by the DFG
Collaborative Research Center 732.
</bodyText>
<sectionHeader confidence="0.99844" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99903791509434">
Almuhareb, Abdulrahman and Massimo
Poesio. 2004. Attribute-based and
value-based clustering: An evaluation.
In Proceedings of EMNLP 2004,
pages 158–165, Barcelona.
Alonge, Antonietta, Francesca Bertagna,
Nicoletta Calzolari, Adriana Roventini,
and Antonio Zampolli. 2000. Encoding
information on adjectives in a lexical-
semantic net for computational
applications. In Proceedings of the 1st
North American Chapter of the Association
for Computational Linguistics Conference,
NAACL ’00, pages 42–49, San Francisco, CA.
Alsina, `Alex, Toni Badia, Gemma Boleda,
Stefan Bott, `Angel Gil, MartiQuixal,
and Oriol Valentin. 2002. CATCG: a
general purpose parsing tool applied. In
Proceedings of Third International Conference
on Language Resources and Evaluation,
volume III, pages 1130–1135, Las Palmas.
Ando, Rie Kubota. 2006. Applying
alternating structure optimization to word
sense disambiguation. In Proceedings of the
Tenth Conference on Computational Natural
Language Learning, pages 77–84, New York
City, NY.
Apresjan, Juri D. 1974. Regular polysemy.
Linguistics, 142:5–32.
Artstein, Ron and Massimo Poesio. 2008.
Inter-coder agreement for computational
linguistics. Computational Linguistics,
34(4):555–596.
Bally, Charles. 1944. Linguistique g´en´erale et
linguistique fran¸caise. A. Francke, Berne.
Banerjee, Arindam, Chase Krumpelman,
Joydeep Ghosh, Sugato Basu, and
Raymond J. Mooney. 2005. Model-based
overlapping clustering. In Proceedings
of the Eleventh ACM SIGKDD International
Conference on Knowledge Discovery in Data
Mining, KDD ’05, pages 532–537,
New York, NY.
Bohnet, Berndt, Stefan Klatt, and Leo
Wanner. 2002. An approach to automatic
annotation of functional information to
adjectives with an application to German.
In Proceedings of the 3rd LREC Conference,
Workshop: Linguistic Knowledge Acquisition
and Representation, pages 24–33,
Las Palmas.
Boleda, Gemma. 2007. Automatic Acquisition
of Semantic Classes for Adjectives. Ph.D.
thesis, Pompeu Fabra University.
Boleda, Gemma, Toni Badia, and Eloi Batlle.
2004. Acquisition of semantic classes for
adjectives from distributional evidence.
In Proceedings of the 20th International
Conference on Computational Linguistics
(COLING-04), pages 1119–1125,
Morristown, NJ.
Boleda, Gemma, Sabine Schulte im Walde,
and Toni Badia. 2008. Analysis of
agreement on adjective semantic
classification. Research on Language
and Computation, 6(3):247–271.
Bouckaert, Remco R. 2004. Estimating
replicability of classifier learning
experiments. In Proceedings of the
Twenty-first International Conference
on Machine Learning, ICML ’04,
pages 15–23, New York, NY.
Brants, Thorsten. 2000. Inter-annotator
agreement for a German newspaper
corpus. In Second International Conference
on Language Resources and Evaluation,
LREC ’02, Athens.
Breiman, Leo. 2001. Random forests. Machine
Learning, 45:5–23.
Bresnan, Joan. 1982. The passive in lexical
theory. In Joan Bresnan, editor, The Mental
Representation of Grammatical Relations.
The MIT Press, Cambridge, MA,
pages 3–86.
Bresnan, Joan. 1995. Lexicality and argument
structure. Invited talk at the Paris Syntax
and Semantics Conference. 12 October.
Brody, Samuel and Mirella Lapata. 2009.
Bayesian word sense induction. In
Proceedings of the 12th Conference of the
European Chapter of the Association for
Computational Linguistics, EACL ’09,
pages 103–111, Stroudsburg, PA.
Bryll, Robert K., Ricardo Gutierrez-Osuna,
and Francis K. H. Quek. 2003. Attribute
bagging: Improving accuracy of classifier
ensembles by using random feature
subsets. Pattern Recognition,
36(6):1291–1302.
Buitelaar, Paul. 1998. CoreLex: An ontology
of systematic polysemous classes.
In Proceedings of Formal Ontologies in
Information Systems, pages 221–235,
Amsterdam.
Burnage, Gavin and Dominic Dunlop. 1992.
Encoding the British National Corpus. In
</reference>
<page confidence="0.995171">
613
</page>
<note confidence="0.541385">
Computational Linguistics Volume 38, Number 3
</note>
<reference confidence="0.994361737288135">
English Language Corpora: Design, Analysis
and Exploitation. Papers from the Thirteenth
International Conference on English Language
Research on Computerized Corpora,
pages 79–95, Amsterdam.
Carvalho, Paula and Elisabete Ranchhod.
2003. Analysis and disambiguation of
nouns and adjectives in Portuguese by
FST. In Proceedings of the Workshop on
Finite-State Methods for Natural Language
Processing at EACL-03, pages 105–112,
Budapest.
Chao, Gerald and Michael G. Dyer.
2000. Word sense disambiguation of
adjectives using probabilistic networks.
In Proceedings of the 18th Conference on
Computational Linguistics (COLING-00),
pages 152–158, Morristown, NJ.
Copestake, Ann and Ted Briscoe. 1995.
Semi-productive polysemy and sense
extension. Journal of Semantics, 12:15–67.
de Marneffe, Marie-Catherine,
Christopher D. Manning, and
Christopher Potts. 2010. “Was it good? It
was provocative.” Learning the meaning
of scalar adjectives. In Proceedings of the
48th Annual Meeting of the Association for
Computational Linguistics, ACL ’10,
pages 167–176, Stroudsburg, PA.
Demonte, Violeta. 2011. Adjectives.
In Klaus von Heusinger, Claudia
Maienborn, and Paul Portner, editors,
Semantics: An International Handbook of
Natural Language Meaning, volume 2.
Mouton de Gruyter, Berlin,
pages 1314–1340.
Dhillon, Inderjit S. and Dharmendra S.
Modha. 2001. Concept decompositions for
large sparse text data using clustering.
Machine Learning, 42:143–175.
Dietterich, Thomas G. 1998. Approximate
statistical tests for comparing supervised
classification learning algorithms. Neural
Computation, 10(7):1895–1924.
Dietterich, Thomas G. 2000. An experimental
comparison of three methods for
constructing ensembles of decision trees:
Bagging, boosting, and randomization.
Machine Learning, 40:5–23.
Dixon, Robert M. W. and Alexandra Y.
Aikhenvald, editors. 2004. Adjective
Classes. Oxford University Press, Oxford.
Dorr, Bonnie J. and Douglas Jones. 1996. Role
of word sense disambiguation in lexical
acquisition: Predicting semantics from
syntactic cues. In Proceedings of the 16th
International Conference on Computational
Linguistics (COLING-96), pages 322–333,
Morristown, NJ.
Erk, Katrin and Sebastian Pad´o. 2010.
Exemplar-based models for word meaning
in context. In Proceedings of the ACL 2010
Conference Short Papers, ACLShort ’10,
pages 92–97, Stroudsburg, PA.
Everitt, Brian S., Sabine Landau, and
Morven Leese. 2001. Cluster Analysis.
Arnold, London, 4th edition.
Freund, Yoav and Robert E. Schapire.
1996. Experiments with a new boosting
algorithm. In Proceedings of the Thirteenth
International Conference on Machine
Learning, ICML ’96, pages 148–156,
San Francisco, CA.
Ghamrawi, Nadia and Andrew McCallum.
2005. Collective multi-label classification.
In Proceedings of the 14th ACM International
Conference on Information and Knowledge
Management, CIKM ’05, pages 195–200,
New York, NY.
Hatzivassiloglou, Vasileios and Kathleen R.
McKeown. 1993. Towards the automatic
identification of adjectival scales:
Clustering adjectives according to
meaning. In Proceedings of the 31st Annual
Meeting of the Association for Computational
Linguistics (ACL’93), pages 172–182,
Morristown, NJ.
Hatzivassiloglou, Vasileios and Kathleen R.
McKeown. 1997. Predicting the semantic
orientation of adjectives. In Proceedings
of the Eighth Conference of the European
Chapter of the Association for Computational
Linguistics (EACL’97), pages 174–181,
Morristown, NJ.
Hatzivassiloglou, Vasileios and Janyce M.
Wiebe. 2000. Effects of adjective
orientation and gradability on sentence
subjectivity. In Proceedings of the 18th
International Conference on Computational
Linguistics (COLING-00), pages 299–305,
Morristown, NJ.
Hindle, Donald. 1990. Noun classification
from predicate-argument structures. In
Proceedings of the 28th Annual Meeting of the
Association for Computational Linguistics,
ACL ’90, pages 268–275, Stroudsburg, PA.
Ho, Tin Kam. 1998. The random subspace
method for constructing decision forests.
IEEE Transactions on Pattern Analysis and
Machine Intelligence, 20:832–844.
Joanis, Eric, Suzanne Stevenson, and David
James. 2008. A general feature space for
automatic verb classification. Natural
Language Engineering, 14(03):337–367.
Justeson, John S. and Slava M. Katz. 1995.
Principled disambiguation: Discriminating
adjective senses with modified nouns.
Computational Linguistics, 21(1):1–27.
</reference>
<page confidence="0.970028">
614
</page>
<note confidence="0.566749">
Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives
</note>
<reference confidence="0.999901355932203">
Karypis, George. 2002. CLUTO—A
Clustering Toolkit. Technical Report TR
02-017, Department of Computer Science
and Engineering, University of Minnesota,
Minneapolis, MN.
Kaufman, Leonard and Peter J. Rousseeuw.
1990. Finding Groups in Data: An
Introduction to Cluster Analysis.
John Wiley, New York.
Kohomban, Upali S. and Wee Sun Lee.
2005. Learning semantic classes for
Word Sense Disambiguation. In
Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics,
pages 34–41, Ann Arbor, MI.
Korhonen, Anna, Yuval Krymolowski, and
Zvika Marx. 2003. Clustering polysemic
subcategorization frame distributions
semantically. In Proceedings of the
41st Annual Meeting of the Association for
Computational Linguistics - Volume 1,
ACL ’03, pages 64–71, Stroudsburg, PA.
Lapata, Maria. 2001. A corpus-based
account of regular polysemy: The case of
context-sensitive adjectives. In Proceedings
of the Second Meeting of the North American
Chapter of the Association for Computational
Linguistics on Language Technologies,
NAACL ’01, pages 1–8, Stroudsburg, PA.
Lapata, Mirella. 2000. The Acquisition and
Modeling of Lexical Knowledge: A Corpus-
based Investigation of Systematic Polysemy.
Ph.D. thesis, University of Edinburgh.
Lapata, Mirella and Chris Brew. 2004. Verb
class disambiguation using informative
priors. Computational Linguistics,
30(2):45–73.
Levin, Beth and Malka Rappaport. 1986. The
formation of adjectival passives. Linguistic
Inquiry, 17:623–661.
Malouf, Robert. 2000. The order of
prenominal adjectives in natural
language generation. In Proceedings of
the 38th Annual Meeting of the Association
for Computational Linguistics, ACL ’00,
pages 85–92, Stroudsburg, PA.
Marcus, M., B. Santorini, and
M. Marcinkiewicz.1993. Building a large
annotated corpus of English: The Penn
Treebank. Computational Linguistics,
19:313–330.
Mayol, Laia, Gemma Boleda, and Toni Badia.
2005. Automatic acquisition of syntactic
verb classes with basic resources. Language
Resources and Evaluation, 39(4):295–312.
McCarthy, Diana. 2000. Using semantic
preferences to identify verbal
participation in role switching alternations.
In Proceedings of the 1st North American
Chapter of the Association for Computational
Linguistics Conference, NAACL ’00,
pages 256–263, San Francisco, CA.
McCarthy, Diana, Rob Koeling, Julie Weeds,
and John Carroll. 2004. Finding
predominant word senses in untagged
text. In Proceedings of the 42nd Annual
Meeting of the Association for Computational
Linguistics, ACL ’04, pages 279–286,
Stroudsburg, PA.
McDonald, Ryan, Koby Crammer, and
Fernando Pereira. 2005. Flexible text
segmentation with structured multilabel
classification. In Proceedings of the
Conference on Human Language Technology
and Empirical Methods in Natural Language
Processing, HLT ’05, pages 987–994,
Stroudsburg, PA.
McNally, Louise and Gemma Boleda. 2004.
Relational adjectives as properties of
kinds. Empirical Issues in Syntax and
Semantics, 5:179–196.
Merlo, Paola and Suzanne Stevenson. 2001.
Automatic verb classification based on
statistical distributions of argument
structure. Computational Linguistics,
27(3):373–408.
Miller, Katharine J. 1998. Modifiers in
WordNet. In Christiane Fellbaum, editor,
WordNet: an Electronic Lexical Database.
The MIT Press, Cambridge, MA,
pages 47–67.
Montague, Richard. 1974. English as a
formal language. In Richmond H.
Thomason, editor, Formal Philosophy:
Selected Papers of Richard Montague. Yale
University Press, New Haven, CT,
chapter 6, pages 188–221.
Murphy, Gregory L. 2002. The Big Book of
Concepts. The MIT Press, Cambridge, MA.
Nadeau, Claude and Yoshua Bengio. 2003.
Inference for the generalization error.
Machine Learning, 52(3):239–281.
Navigli, Roberto. 2009. Word sense
disambiguation: A survey. ACM
Computing Surveys, 41:10:1–10:69.
Nirenburg, Sergei and Victor Raskin. 2004.
Ontological Semantics. The MIT Press,
Cambridge, MA.
Pang, Bo and Lillian Lee. 2008. Opinion
mining and sentiment analysis.
Foundations and Trends in Information
Retrieval, 2(1-2):1–135.
Pereira, Fernando, Naftali Tishby, and
Lillian Lee. 1993. Distributional clustering
of English words. In Proceedings of
the 31st Annual Meeting of the Association
for Computational Linguistics, ACL ’93,
pages 183–190, Stroudsburg, PA.
</reference>
<page confidence="0.960504">
615
</page>
<reference confidence="0.993124139784946">
Computational Linguistics Volume 38, Number 3
Picallo, Carme. 2002. L’adjectiu i el sintagma
adjectival. In Joan Sol`a, editor, Gram`atica
del catal`a contemporani. Emp´uries,
Barcelona, pages 1643–1688.
Poesio, Massimo and Ron Artstein. 2005.
The reliability of anaphoric annotation,
reconsidered: Taking ambiguity into
account. In Proceedings of the Workshop on
Frontiers in Corpus Annotations II: Pie in
the Sky, CorpusAnno ’05, pages 76–83,
Stroudsburg, PA.
Prescher, Detlef, Stefan Riezler, and Mats
Rooth. 2000. Using a probabilistic
class-based lexicon for lexical ambiguity
resolution. In Proceedings of the 18th
Conference on Computational Linguistics -
Volume 2, COLING ’00, pages 649–655,
Stroudsburg, PA.
Pustejovsky, James. 1995. The Generative
Lexicon. The MIT Press, Cambridge, MA.
Quinlan, Ross. 1993. C4.5: Programs for
Machine Learning. Morgan Kaufmann,
San Francisco, CA.
Rafel, Joaquim. 1994. Un corpus general de
refer`encia de la llengua catalana. Caplletra,
17:219–250.
Raskin, Victor and Sergei Nirenburg.
1998. An applied ontological semantic
microtheory of adjective meaning for
natural language processing. Machine
Translation, 13(2-3):135–227.
Resnik, Philip. 1993. Selection and Information:
A Class-Based Approach to Lexical
Relationships. Ph.D. thesis, Department
of Computer and Information Science,
University of Pennsylvania.
Rooth, Mats, Stefan Riezler, Detlef Prescher,
Glenn Carroll, and Franz Beil. 1999.
Inducing a semantically annotated
lexicon via em-based clustering.
In Proceedings of the 37th Annual Meeting
of the Association for Computational
Linguistics, ACL ’99, pages 104–111,
Stroudsburg, PA.
Sanrom`a, Roser and Gemma Boleda. 2010.
The database of Catalan adjectives. In
Proceedings of the Seventh Conference on
International Language Resources and
Evaluation, LREC ’10, Valletta.
Schapire, Robert E. and Yoram Singer. 2000.
Boostexter: A boosting-based system for
text categorization. Machine Learning,
39(2-3):135–168.
Schulte im Walde, Sabine. 2006. Experiments
on the automatic induction of German
semantic verb classes. Computational
Linguistics, 32(2):159–194.
Sch¨utze, Hinrich. 1998. Automatic word
sense discrimination. Computational
Linguistics, 24(1):97–123.
Utt, Jason and Sebastian Pad´o. 2011.
Ontology-based distinction between
polysemy and homonymy. In Proceedings
of the Ninth International Conference on
Computational Semantics, IWCS ’11,
pages 265–274, Stroudsburg, PA.
Vendler, Zeno. 1957. Verbs and times.
The Philosophical Review, 66:143–60.
V´eronis, Jean. 1998. A study of polysemy
judgements and inter-annotator
agreement. In Programme and Advanced
Papers of the Senseval Workshop, pages 2–4,
Herstmonceux Castle.
Verzani, John. 2005. Using R for Introductory
Statistics. Chapman &amp; Hall/CRC,
Boca Raton, FL.
Wiebe, Janyce M., Theresa Wilson,
Rebecca Bruce, Matthew Bell, and
Melanie Martin. 2004. Learning subjective
language. Computational Linguistics,
30(3):277–308.
Witten, Ian H. and Eibe Frank. 2011. Data
Mining: Practical Machine Learning Tools
and Techniques with Java Implementations.
Morgan Kaufmann, Amsterdam,
3rd edition.
Yallop, Jeremy, Anna Korhonen, and Ted
Briscoe. 2005. Automatic acquisition of
adjectival subcategorization from corpora.
In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics,
ACL ’05, pages 614–621, Stroudsburg, PA.
</reference>
<page confidence="0.99853">
616
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.535707">
<title confidence="0.886800666666667">Modeling Regular Polysemy: A Study on the Semantic Classification of Catalan Adjectives Universitat Pompeu Fabra</title>
<author confidence="0.964434">Schulte im</author>
<affiliation confidence="0.9733935">University of Stuttgart Universitat Pompeu Fabra</affiliation>
<abstract confidence="0.989724647058824">We present a study on the automatic acquisition of semantic classes for Catalan adjectives from distributional and morphological information, with particular emphasis on polysemous adjec- The aim is to distinguish and characterize broad classes, such as qualitative relational adjectives, as well as to identify polysemous adjectives as We specifically aim at modeling regular polysemy, that is, types of sense alternations that are shared across lemmata. To date, both semantic classes for adjectives and regular polysemy have only been sparsely addressed in empirical computational linguistics. Two main specific questions are tackled in this article. First, what is an adequate broad semantic classification for adjectives? We provide empirical support for the qualitative and relational classes as defined in theoretical work, and uncover one type of adjective that has not received enough attention, namely, the event-related class. Second, how is regular polysemy best modeled in computational terms? We present two models, and argue that the second one, which models regular polysemy in terms of simultaneous membership to multiple basic classes, is both theoretically and empirically more adequate than the first one, which attempts to identify independent polysemous classes. Our best classifier achieves 69.1% accuracy, against a 51% baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abdulrahman Almuhareb</author>
<author>Massimo Poesio</author>
</authors>
<title>Attribute-based and value-based clustering: An evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP 2004,</booktitle>
<pages>158--165</pages>
<location>Barcelona.</location>
<contexts>
<context position="12536" citStr="Almuhareb and Poesio 2004" startWordPosition="1865" endWordPosition="1868">ent semantic classes in this article. The semantic properties of adjectives can also be exploited in advanced NLP tasks and applications such as Question Answering, Dialog Systems, Natural Language Generation, or Information Extraction. For instance, from a sentence like This maimai is round and sweet, we can quite safely infer that the (invented) object maimai is a physical object, probably edible. This type of process could be exploited in, for instance, Information Extraction and ontology population, although to our knowledge this possibility has received but little attention (Malouf 2000; Almuhareb and Poesio 2004). As for polysemy, previous approaches to the automatic acquisition of semantic classes have mostly disregarded the problem, by biasing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). The</context>
</contexts>
<marker>Almuhareb, Poesio, 2004</marker>
<rawString>Almuhareb, Abdulrahman and Massimo Poesio. 2004. Attribute-based and value-based clustering: An evaluation. In Proceedings of EMNLP 2004, pages 158–165, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonietta Alonge</author>
<author>Francesca Bertagna</author>
<author>Nicoletta Calzolari</author>
<author>Adriana Roventini</author>
<author>Antonio Zampolli</author>
</authors>
<title>Encoding information on adjectives in a lexicalsemantic net for computational applications.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL ’00,</booktitle>
<pages>42--49</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="11631" citStr="Alonge et al. 2000" startWordPosition="1725" endWordPosition="1728">), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can be translated into values that can be ordered along a scale. These adjectives typically enter into antonymy relations (the semantic relation between good and bad), and in fact antonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), the most widely used semantic resource in NLP. However, when examining a large scale lexicon, it becomes immediately apparent that there are many other types of adjectives that do not easily fit in a scale-based or antonymy-based view of adjectives (Alonge et al. 2000). Some examples are pulmonary, former, and foldable. It is not clear, for instance, whether it makes sense to ask for an antonym of pulmonary, or to establish a “foldability” scale for foldable. These adjectives need a different treatment, and they are treated in terms of different semantic classes in this article. The semantic properties of adjectives can also be exploited in advanced NLP tasks and applications such as Question Answering, Dialog Systems, Natural Language Generation, or Information Extraction. For instance, from a sentence like This maimai is round and sweet, we can quite safe</context>
<context position="22392" citStr="Alonge et al. 2000" startWordPosition="3328" endWordPosition="3331">. (8) a. ´Es un pats {exportador / #molt exportador} de petroli Is a country {exporting / very exporting} of oil ‘It is an oil exporting / #very exporting country’ b. #exportador pats ‘exporting country’ c. Aquest pats ´es exportador This country is exporting ‘This is an exporting country’ Table 2 summarizes the properties of the alternative classification (for a more thorough discussion of previous research on the semantics of adjectives and more motivation for the classification, see Boleda [2007]). For comparison, we will briefly outline the treatment of adjectives in WordNet (Miller 1998; Alonge et al. 2000). As Table 2 Alternative classification: Linguistic properties of qualitative, event-related, and relational adjectives. Qualitative Event-related Relational gran (‘big’) exportador (‘exporting’) pulmonar ‘pulmonary’ Property predicative + + restricted gradable/comparable + typically not − position with respect to both post-nom. post-nom. head noun adjacent − − + derivational type non-derived deverbal denominal 582 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives mentioned in Section 2, the main semantic relation around which adjectives are organized in WordN</context>
<context position="49804" citStr="Alonge et al. 2000" startWordPosition="7616" endWordPosition="7619">proposes different metrics and types of evaluation. We defer numerical evaluation until Section 5. 4.5 Discussion 4.5.1 Classification. The experiments presented provide feedback to the question, what is an appropriate broad semantic classification for adjectives? The clustering experiments provide empirical support for the qualitative and relational classes, as is particularly evident in the three-way solution (Table 5). These are classes that have traditionally been taken into account in descriptive grammar (Bally 1944; Picallo 2002) and computational resources such as WordNet (Miller 1998; Alonge et al. 2000), so we consider them to be quite stable and keep them in our classification. Intensional and IQ adjectives, in contrast, are grouped together with qualitative adjectives in all solutions, because they do not exhibit distinctive enough distributional properties to differentiate them, a fact aggravated by the small size of the intensional class. From the point of view of NLP, it is reasonable to encode intensional adjectives by hand, given their limited number. For these reasons, we include the intensional class in the qualitative class in what follows (remember that, as mentioned in Section 3,</context>
<context position="53735" citStr="Alonge et al. 2000" startWordPosition="8213" endWordPosition="8216"> event-related adjectives in the overall classification. Event-related adjectives have not received much attention in the linguistic literature, except for one particular subtype, namely, adjectival uses of the participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995). As for computational resources, the English WordNet, as explained in Section 3, only distinguishes some participial adjectives. In the Italian WordNet, however, other event-related adjectives receive a specific treatment, through the encoding of the lexical relations CAUSES and LIABLE-TO, as exemplified in Example (19) (Alonge et al. 2000): (19) a. depuratorio ‘depurative, purifying’ CAUSES depurare ‘to depurate/purify’. b. giudicabile ‘triable’ LIABLE-TO giudicare ‘to judge’. To sum up, the results of the experiments reported in this section motivate a threeway classification between qualitative, event-related, and relational adjectives. Note that, in the revised classification proposed in this section, classes are uniformly defined according to the ontological type of their denotation: Qualitative adjectives denote attributes or properties, relational adjectives denote relationships to objects, and eventrelated adjectives den</context>
</contexts>
<marker>Alonge, Bertagna, Calzolari, Roventini, Zampolli, 2000</marker>
<rawString>Alonge, Antonietta, Francesca Bertagna, Nicoletta Calzolari, Adriana Roventini, and Antonio Zampolli. 2000. Encoding information on adjectives in a lexicalsemantic net for computational applications. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL ’00, pages 42–49, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>`Alex Alsina</author>
<author>Toni Badia</author>
<author>Gemma Boleda</author>
<author>Stefan Bott</author>
<author>`Angel Gil</author>
<author>MartiQuixal</author>
<author>Oriol Valentin</author>
</authors>
<title>CATCG: a general purpose parsing tool applied.</title>
<date>2002</date>
<booktitle>In Proceedings of Third International Conference on Language Resources and Evaluation, volume III,</booktitle>
<pages>1130--1135</pages>
<location>Las Palmas.</location>
<contexts>
<context position="31071" citStr="Alsina et al. 2002" startWordPosition="4630" endWordPosition="4633">to uncover natural groupings of adjectives and test to what extent these correspond to the classes described in the literature. 4.1 Data and Gold Standard The experiments reported in this section are based on an eight million word fragment of the CTILC corpus (Corpus Informatitzat de la Llengua Catalana; Rafel 1994), developed at the Institut d’Estudis Catalans. Each word is associated with its lemma, part of speech, and inflectional features, as well as syntactic function. Lemma and morphological information have been manually checked. We automatically added syntactic information with CatCG (Alsina et al. 2002). CatCG is a shallow parser that assigns one or more syntactic functions to each word. In the case of the adjective, CatCG distinguishes between (1) predicate of a copular sentence; (2) predicate in another construction; (3) pre-nominal modifier; (4) post-nominal modifier. As no full dependencies are indicated, the head noun can only be identified with heuristics. In the experiments, we cluster all adjectives occurring more than ten times in the corpus (a total of 3,521 lemmata), and analyze the results using a subset of the data. This is a randomly chosen 101-lemma gold standard (available in</context>
</contexts>
<marker>Alsina, Badia, Boleda, Bott, Gil, MartiQuixal, Valentin, 2002</marker>
<rawString>Alsina, `Alex, Toni Badia, Gemma Boleda, Stefan Bott, `Angel Gil, MartiQuixal, and Oriol Valentin. 2002. CATCG: a general purpose parsing tool applied. In Proceedings of Third International Conference on Language Resources and Evaluation, volume III, pages 1130–1135, Las Palmas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rie Kubota Ando</author>
</authors>
<title>Applying alternating structure optimization to word sense disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>77--84</pages>
<location>New York City, NY.</location>
<marker>Ando, 2006</marker>
<rawString>Ando, Rie Kubota. 2006. Applying alternating structure optimization to word sense disambiguation. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 77–84, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri D Apresjan</author>
</authors>
<title>Regular polysemy.</title>
<date>1974</date>
<journal>Linguistics,</journal>
<pages>142--5</pages>
<contexts>
<context position="3888" citStr="Apresjan 1974" startWordPosition="559" endWordPosition="560">ed classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant challenge is posed by polysemy, or the fact that one and the same adjective can have multiple senses. Different senses may fall into different classes, such that it is no longer possible to identify one single semantic class per adjective. Moreover, many adjectives exhibit similar sense alternations, in a phenomenon known as regular or systematic polysemy (Apresjan 1974; Copestake and Briscoe 1995). A special focus of the research presented, therefore, is on modeling regular polysemy. As an example of regular polysemy, take for instance the sense alternation for the adjective econ`omic exemplified in Example (1). Econ`omic, derived from economia (‘economy’), can be translated as ‘economic, of the economy’, as in Example (1a), or as ‘cheap’, as in Example (1b). As we will see, each of these senses corresponds to a different semantic class in our classifications. (1) a. recuperaci´o econ`omica recovery economySUFFIX ‘recovery of the economy’ b. pantalons econ`</context>
<context position="6568" citStr="Apresjan 1974" startWordPosition="964" endWordPosition="965">us, and to which class(es) it belongs. Note that we are not dealing with individual sense alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational semantics, however. This is surprising, given the amount of work devoted to sense-related tasks such as Word Sense Disambiguation (WSD). In WSD (see Navigli [2009] for an overview) sense ambiguities are almost exclusively modeled for each individual lemma, despite the ensuing sparsity problems (Ando [2006] is an exception). Properly modeling regular polysemy, therefore, promises to improve computational semantic tasks such as WSD an</context>
</contexts>
<marker>Apresjan, 1974</marker>
<rawString>Apresjan, Juri D. 1974. Regular polysemy. Linguistics, 142:5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Inter-coder agreement for computational linguistics.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<marker>Artstein, Poesio, 2008</marker>
<rawString>Artstein, Ron and Massimo Poesio. 2008. Inter-coder agreement for computational linguistics. Computational Linguistics, 34(4):555–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Bally</author>
</authors>
<title>Linguistique g´en´erale et linguistique fran¸caise.</title>
<date>1944</date>
<publisher>A.</publisher>
<location>Francke, Berne.</location>
<contexts>
<context position="49711" citStr="Bally 1944" startWordPosition="7604" endWordPosition="7605"> our case. Schulte im Walde (2006) provides a thorough discussion of this issue and proposes different metrics and types of evaluation. We defer numerical evaluation until Section 5. 4.5 Discussion 4.5.1 Classification. The experiments presented provide feedback to the question, what is an appropriate broad semantic classification for adjectives? The clustering experiments provide empirical support for the qualitative and relational classes, as is particularly evident in the three-way solution (Table 5). These are classes that have traditionally been taken into account in descriptive grammar (Bally 1944; Picallo 2002) and computational resources such as WordNet (Miller 1998; Alonge et al. 2000), so we consider them to be quite stable and keep them in our classification. Intensional and IQ adjectives, in contrast, are grouped together with qualitative adjectives in all solutions, because they do not exhibit distinctive enough distributional properties to differentiate them, a fact aggravated by the small size of the intensional class. From the point of view of NLP, it is reasonable to encode intensional adjectives by hand, given their limited number. For these reasons, we include the intensio</context>
</contexts>
<marker>Bally, 1944</marker>
<rawString>Bally, Charles. 1944. Linguistique g´en´erale et linguistique fran¸caise. A. Francke, Berne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arindam Banerjee</author>
<author>Chase Krumpelman</author>
<author>Joydeep Ghosh</author>
<author>Sugato Basu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Model-based overlapping clustering.</title>
<date>2005</date>
<booktitle>In Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD ’05,</booktitle>
<pages>532--537</pages>
<location>New York, NY.</location>
<contexts>
<context position="100160" citStr="Banerjee et al. 2005" startWordPosition="15534" endWordPosition="15537">al Linguistics Volume 38, Number 3 An alternative instantiation of the second model could use soft clustering (Pereira, Tishby, and Lee 1993; Rooth et al. 1999; Korhonen, Krymolowski, and Marx 2003), which assigns a probability to each of the classes and is thus not bound to a hard yes/no decision, as our approach does. From a theoretical point of view (and for many practical purposes such as dictionary construction), however, a distinction between monosemous and polysemous words is desirable, which adds a further parameter to be optimized in a soft clustering setting. Overlapping clustering (Banerjee et al. 2005), which allows for membership in multiple clusters, avoids this difficulty. Both methods have the advantage that they do not assume independence of the decisions. The most serious problem for the experiments presented in this article, however, would presumably also be a problem for these settings: The fact that the skewed sense distribution of many words makes it difficult to distinguish evidence for a particular class from noise. In the soft clustering setting, for instance, it would be hard to distinguish whether 10% evidence for class A and 90% for class B corresponds to polysemy with a ske</context>
</contexts>
<marker>Banerjee, Krumpelman, Ghosh, Basu, Mooney, 2005</marker>
<rawString>Banerjee, Arindam, Chase Krumpelman, Joydeep Ghosh, Sugato Basu, and Raymond J. Mooney. 2005. Model-based overlapping clustering. In Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD ’05, pages 532–537, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Berndt Bohnet</author>
<author>Stefan Klatt</author>
<author>Leo Wanner</author>
</authors>
<title>An approach to automatic annotation of functional information to adjectives with an application to German.</title>
<date>2002</date>
<marker>Bohnet, Klatt, Wanner, 2002</marker>
<rawString>Bohnet, Berndt, Stefan Klatt, and Leo Wanner. 2002. An approach to automatic annotation of functional information to adjectives with an application to German.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 3rd LREC Conference, Workshop: Linguistic Knowledge Acquisition and Representation,</booktitle>
<pages>24--33</pages>
<location>Las Palmas.</location>
<marker></marker>
<rawString>In Proceedings of the 3rd LREC Conference, Workshop: Linguistic Knowledge Acquisition and Representation, pages 24–33, Las Palmas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gemma Boleda</author>
</authors>
<title>Automatic Acquisition of Semantic Classes for Adjectives.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Pompeu Fabra University.</institution>
<contexts>
<context position="9183" citStr="Boleda 2007" startWordPosition="1353" endWordPosition="1354">ically this topic: Carvalho and Ranchhod (2003) used adjective classes similar to the ones explored here to disambiguate between nominal and adjectival readings in Portuguese. Adjective information, manually coded, served to establish constraints in a finite-state transducer part-of-speech tagger. Actually, POS tagging was also the initial motivation for the present research, as adjective–noun and adjective–verb (participle) ambiguities cause most difficulties to both humans and machines in languages such as English, German, and Catalan (Marcus, Santorini, and Marcinkiewicz 1993; Brants 2000; Boleda 2007). Bohnet, Klatt, and Wanner (2002) also has similar goals to the present research, as it is aimed at automatically classifying German adjectives. However, the classification 577 Computational Linguistics Volume 38, Number 3 used is not purely semantic, polysemy is not taken into account, and the evidence and techniques used are more limited than the ones used here. Other research on adjectives within computational linguistics is oriented toward different goals than ours. Yallop, Korhonen, and Briscoe (2005) tackle syntactic, not semantic classification, akin to the acquisition of subcategoriza</context>
<context position="65635" citStr="Boleda (2007" startWordPosition="10026" endWordPosition="10027">st experiment showed that the word preceding and following the target were the most informative, so in the present experiment only a one-word window is taken into account. The unigram distribution (uni) encodes each part of speech separately, as was done in the first experiment, and the bigram distribution (bi) takes the left and right word jointly, to avoid feature correlation effects. In the latter feature set, only the 50 most frequent bigrams are considered, to avoid features that are too sparse.5 5 For a more detailed explanation of the information encoded in feature sets uni and bi, see Boleda (2007, section 5.2.2). 596 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives Table 9 New or revised features in feature set theor. Each row lists the property we aim to capture and the features through which the property is encoded. The information relies on the information in the corpus, which does not include full syntactic structure. Property Features type of determiner NP headed by definite/indefinite/no determiner agreement properties gender and number of the NP syntactic function of head noun subject, object, complement to a preposition complement-bearing adj</context>
</contexts>
<marker>Boleda, 2007</marker>
<rawString>Boleda, Gemma. 2007. Automatic Acquisition of Semantic Classes for Adjectives. Ph.D. thesis, Pompeu Fabra University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gemma Boleda</author>
<author>Toni Badia</author>
<author>Eloi Batlle</author>
</authors>
<title>Acquisition of semantic classes for adjectives from distributional evidence.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING-04),</booktitle>
<pages>1119--1125</pages>
<location>Morristown, NJ.</location>
<marker>Boleda, Badia, Batlle, 2004</marker>
<rawString>Boleda, Gemma, Toni Badia, and Eloi Batlle. 2004. Acquisition of semantic classes for adjectives from distributional evidence. In Proceedings of the 20th International Conference on Computational Linguistics (COLING-04), pages 1119–1125, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gemma Boleda</author>
<author>Sabine Schulte im Walde</author>
<author>Toni Badia</author>
</authors>
<title>Analysis of agreement on adjective semantic classification.</title>
<date>2008</date>
<journal>Research on Language and Computation,</journal>
<volume>6</volume>
<issue>3</issue>
<marker>Boleda, Walde, Badia, 2008</marker>
<rawString>Boleda, Gemma, Sabine Schulte im Walde, and Toni Badia. 2008. Analysis of agreement on adjective semantic classification. Research on Language and Computation, 6(3):247–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remco R Bouckaert</author>
</authors>
<title>Estimating replicability of classifier learning experiments.</title>
<date>2004</date>
<booktitle>In Proceedings of the Twenty-first International Conference on Machine Learning, ICML ’04,</booktitle>
<pages>15--23</pages>
<location>New York, NY.</location>
<contexts>
<context position="76001" citStr="Bouckaert 2004" startWordPosition="11626" endWordPosition="11627">d of reweighting = False, weight threshold = 100). For Attribute Bagging, we used the Random Subspace algorithm, with J48 as base classifier (parameters as before), bag size = 1/3, and random seed = 1. We experimented with different values for the number of iterations (see Section 5.4.2). 8 Note that the corrected resampled t-test can only compare accuracies obtained under two conditions (algorithms or, as is our case, feature sets); ANOVA would be more adequate. In the field of machine learning, there is no established correction for ANOVA for the purposes of testing differences in accuracy (Bouckaert 2004). Therefore, we use multiple t-tests instead, which increases the overall error probability of the results for the significance tests. 9 Note that, for each adjective, only 10 different full classification proposals are obtained in each feature set, because each adjective is only used once per run for testing. Therefore, while the per-class accuracy for each feature set is assessed from 100 estimates (obtained via 10x10 cv), the accuracy of the different feature sets for full classification is assessed comparing 10 accuracies. This holds for Tables 10 and 11. 599 Computational Linguistics Volu</context>
</contexts>
<marker>Bouckaert, 2004</marker>
<rawString>Bouckaert, Remco R. 2004. Estimating replicability of classifier learning experiments. In Proceedings of the Twenty-first International Conference on Machine Learning, ICML ’04, pages 15–23, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>Inter-annotator agreement for a German newspaper corpus.</title>
<date>2000</date>
<booktitle>In Second International Conference on Language Resources and Evaluation, LREC ’02,</booktitle>
<location>Athens.</location>
<contexts>
<context position="9169" citStr="Brants 2000" startWordPosition="1351" endWordPosition="1352">les on specifically this topic: Carvalho and Ranchhod (2003) used adjective classes similar to the ones explored here to disambiguate between nominal and adjectival readings in Portuguese. Adjective information, manually coded, served to establish constraints in a finite-state transducer part-of-speech tagger. Actually, POS tagging was also the initial motivation for the present research, as adjective–noun and adjective–verb (participle) ambiguities cause most difficulties to both humans and machines in languages such as English, German, and Catalan (Marcus, Santorini, and Marcinkiewicz 1993; Brants 2000; Boleda 2007). Bohnet, Klatt, and Wanner (2002) also has similar goals to the present research, as it is aimed at automatically classifying German adjectives. However, the classification 577 Computational Linguistics Volume 38, Number 3 used is not purely semantic, polysemy is not taken into account, and the evidence and techniques used are more limited than the ones used here. Other research on adjectives within computational linguistics is oriented toward different goals than ours. Yallop, Korhonen, and Briscoe (2005) tackle syntactic, not semantic classification, akin to the acquisition of</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, Thorsten. 2000. Inter-annotator agreement for a German newspaper corpus. In Second International Conference on Language Resources and Evaluation, LREC ’02, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>45--5</pages>
<contexts>
<context position="71835" citStr="Breiman 2001" startWordPosition="10994" endWordPosition="10995">rs, which are complex, as explained next. The second type of classifier we use are ensemble classifiers, which have received much attention in the machine learning community (Dietterich 2000). When building an ensemble classifier, several class proposals for each item are obtained from multiple simple classifiers, and one of them is chosen on the basis of majority voting, weighted voting, or more sophisticated decision methods. It has been shown that in most cases, the accuracy of the ensemble classifier is higher than the best individual classifier (Freund and Schapire 1996; Dietterich 2000; Breiman 2001). The main reason for the general success of ensemble classifiers is that they are more robust towards the biases particular to individual classifiers: A bias shows up in the data in the form 598 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives of “strange” class assignments made by one single classifier, which are therefore overridden by the class assignments of the remaining classifiers.7 For the evaluation, 100 different estimates of accuracy are obtained for each feature set using 10-run, 10-fold cross-validation (10x10 cv for short). In this schema, 10-f</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Breiman, Leo. 2001. Random forests. Machine Learning, 45:5–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>The passive in lexical theory.</title>
<date>1982</date>
<booktitle>The Mental Representation of Grammatical Relations. The</booktitle>
<pages>3--86</pages>
<editor>In Joan Bresnan, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="53351" citStr="Bresnan 1982" startWordPosition="8159" endWordPosition="8160">n Example (18): A person named Serra belongs to the kind of associates who have as a primary role to protect the association. (18) Serra ... Era soci protector de l’Associaci´o de concerts Serra ... was associate protecting of the-Association of concerts ‘Serra was a protecting associate of the Association of concerts’ These considerations motivate the addition of a class of event-related adjectives in the overall classification. Event-related adjectives have not received much attention in the linguistic literature, except for one particular subtype, namely, adjectival uses of the participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995). As for computational resources, the English WordNet, as explained in Section 3, only distinguishes some participial adjectives. In the Italian WordNet, however, other event-related adjectives receive a specific treatment, through the encoding of the lexical relations CAUSES and LIABLE-TO, as exemplified in Example (19) (Alonge et al. 2000): (19) a. depuratorio ‘depurative, purifying’ CAUSES depurare ‘to depurate/purify’. b. giudicabile ‘triable’ LIABLE-TO giudicare ‘to judge’. To sum up, the results of the experiments reported in this section motivate</context>
</contexts>
<marker>Bresnan, 1982</marker>
<rawString>Bresnan, Joan. 1982. The passive in lexical theory. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations. The MIT Press, Cambridge, MA, pages 3–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Lexicality and argument structure. Invited talk at the Paris Syntax and Semantics Conference.</title>
<date>1995</date>
<contexts>
<context position="53392" citStr="Bresnan 1995" startWordPosition="8165" endWordPosition="8166">ongs to the kind of associates who have as a primary role to protect the association. (18) Serra ... Era soci protector de l’Associaci´o de concerts Serra ... was associate protecting of the-Association of concerts ‘Serra was a protecting associate of the Association of concerts’ These considerations motivate the addition of a class of event-related adjectives in the overall classification. Event-related adjectives have not received much attention in the linguistic literature, except for one particular subtype, namely, adjectival uses of the participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995). As for computational resources, the English WordNet, as explained in Section 3, only distinguishes some participial adjectives. In the Italian WordNet, however, other event-related adjectives receive a specific treatment, through the encoding of the lexical relations CAUSES and LIABLE-TO, as exemplified in Example (19) (Alonge et al. 2000): (19) a. depuratorio ‘depurative, purifying’ CAUSES depurare ‘to depurate/purify’. b. giudicabile ‘triable’ LIABLE-TO giudicare ‘to judge’. To sum up, the results of the experiments reported in this section motivate a threeway classification between qualit</context>
</contexts>
<marker>Bresnan, 1995</marker>
<rawString>Bresnan, Joan. 1995. Lexicality and argument structure. Invited talk at the Paris Syntax and Semantics Conference. 12 October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Mirella Lapata</author>
</authors>
<title>Bayesian word sense induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09,</booktitle>
<pages>103--111</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="6159" citStr="Brody and Lapata 2009" startWordPosition="905" endWordPosition="908"> im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives Because of the systematic semantic relationship between the two senses of these adjectives, they constitute an instance of regular polysemy. In this article, therefore, we not only address the acquisition of semantic classes, but also the acquisition of polysemy: Our goal is to determine, for a given adjective, whether it is monosemous or polysemous, and to which class(es) it belongs. Note that we are not dealing with individual sense alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational semantics, however. This is</context>
</contexts>
<marker>Brody, Lapata, 2009</marker>
<rawString>Brody, Samuel and Mirella Lapata. 2009. Bayesian word sense induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’09, pages 103–111, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert K Bryll</author>
<author>Ricardo Gutierrez-Osuna</author>
<author>Francis K H Quek</author>
</authors>
<title>Attribute bagging: Improving accuracy of classifier ensembles by using random feature subsets.</title>
<date>2003</date>
<journal>Pattern Recognition,</journal>
<volume>36</volume>
<issue>6</issue>
<marker>Bryll, Gutierrez-Osuna, Quek, 2003</marker>
<rawString>Bryll, Robert K., Ricardo Gutierrez-Osuna, and Francis K. H. Quek. 2003. Attribute bagging: Improving accuracy of classifier ensembles by using random feature subsets. Pattern Recognition, 36(6):1291–1302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Buitelaar</author>
</authors>
<title>CoreLex: An ontology of systematic polysemous classes.</title>
<date>1998</date>
<booktitle>In Proceedings of Formal Ontologies in Information Systems,</booktitle>
<pages>221--235</pages>
<location>Amsterdam.</location>
<contexts>
<context position="13284" citStr="Buitelaar (1998)" startWordPosition="1979" endWordPosition="1980">ing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). There is very little related work in empirical computational semantics in modeling regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 “basic 578 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives types” (broad ontological categories). In CoreLex, each word is associated to a polysemy class, that is, the set of all basic types its synsets belong to. Some of these polysemy classes constitute instances of regular polysemy, as recently explored in Utt and Pad´o (2011). Lapata (2000, 2001) also addresses regular polysemy in th</context>
</contexts>
<marker>Buitelaar, 1998</marker>
<rawString>Buitelaar, Paul. 1998. CoreLex: An ontology of systematic polysemous classes. In Proceedings of Formal Ontologies in Information Systems, pages 221–235, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gavin Burnage</author>
<author>Dominic Dunlop</author>
</authors>
<title>Encoding the British National Corpus.</title>
<date>1992</date>
<booktitle>In English Language Corpora: Design, Analysis and Exploitation. Papers from the Thirteenth International Conference on English Language Research on Computerized Corpora,</booktitle>
<pages>79--95</pages>
<location>Amsterdam.</location>
<contexts>
<context position="14105" citStr="Burnage and Dunlop 1992" startWordPosition="2099" endWordPosition="2102">lte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives types” (broad ontological categories). In CoreLex, each word is associated to a polysemy class, that is, the set of all basic types its synsets belong to. Some of these polysemy classes constitute instances of regular polysemy, as recently explored in Utt and Pad´o (2011). Lapata (2000, 2001) also addresses regular polysemy in the Generative Lexicon framework. This work attempts to establish all the possible meanings of adjective-noun combinations, and rank them using information gathered from the British National Corpus (Burnage and Dunlop 1992). This information should indicate that an easy problem is usually equivalent to problem that is easy to solve (as opposed to, for example, easy text, that is usually equivalent to text that is easy to read). Thus, the focus is on the meaning of adjective-noun combinations, not on that of adjectives alone as in the present research. 3. Basis for a Semantic Classification of Adjectives Adjective classes in our definition are broad classes of lexical meaning. We will present lexical acquisition experiments in which, given the evidence found in corpora and other lexical resources, a semantic clas</context>
</contexts>
<marker>Burnage, Dunlop, 1992</marker>
<rawString>Burnage, Gavin and Dominic Dunlop. 1992. Encoding the British National Corpus. In English Language Corpora: Design, Analysis and Exploitation. Papers from the Thirteenth International Conference on English Language Research on Computerized Corpora, pages 79–95, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paula Carvalho</author>
<author>Elisabete Ranchhod</author>
</authors>
<title>Analysis and disambiguation of nouns and adjectives in Portuguese by FST.</title>
<date>2003</date>
<booktitle>In Proceedings of the Workshop on Finite-State Methods for Natural Language Processing at EACL-03,</booktitle>
<pages>105--112</pages>
<location>Budapest.</location>
<contexts>
<context position="3206" citStr="Carvalho and Ranchhod 2003" startWordPosition="457" endWordPosition="460">isely this task, that is, the semantic classification of adjectives, for Catalan. We aim at automatically inducing the semantic class for an adjective given its linguistic properties, as extracted from corpora and other resources. The acquisition of semantic classes has been widely studied for verbs (Dorr and Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew 2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent, for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions (Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Furthermore, we cannot rely on a well-established classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant challenge is posed by polysemy, or the fact that one and the same adjective can have multiple senses. Different senses may fall into different classes, such that it is no longer possible to identify one single semantic class per adjective. Moreover, many adjectives exhibit similar sense al</context>
<context position="8618" citStr="Carvalho and Ranchhod (2003)" startWordPosition="1276" endWordPosition="1279">ask is 68%. We discuss pros and cons of the two models described and ways to overcome their limitations. In the following, we first review related work (Section 2) and linguistic aspects of adjective classification (Section 3), then present the two acquisition experiments (Sections 4 and 5), and finish with a general discussion (Section 6) and some conclusions and directions for future research (Section 7). 2. Related Work As mentioned in the Introduction, there has been very little research in the semantic classification of adjectives. We know of only two articles on specifically this topic: Carvalho and Ranchhod (2003) used adjective classes similar to the ones explored here to disambiguate between nominal and adjectival readings in Portuguese. Adjective information, manually coded, served to establish constraints in a finite-state transducer part-of-speech tagger. Actually, POS tagging was also the initial motivation for the present research, as adjective–noun and adjective–verb (participle) ambiguities cause most difficulties to both humans and machines in languages such as English, German, and Catalan (Marcus, Santorini, and Marcinkiewicz 1993; Brants 2000; Boleda 2007). Bohnet, Klatt, and Wanner (2002) </context>
</contexts>
<marker>Carvalho, Ranchhod, 2003</marker>
<rawString>Carvalho, Paula and Elisabete Ranchhod. 2003. Analysis and disambiguation of nouns and adjectives in Portuguese by FST. In Proceedings of the Workshop on Finite-State Methods for Natural Language Processing at EACL-03, pages 105–112, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Chao</author>
<author>Michael G Dyer</author>
</authors>
<title>Word sense disambiguation of adjectives using probabilistic networks.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Conference on Computational Linguistics (COLING-00),</booktitle>
<pages>152--158</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="9902" citStr="Chao and Dyer (2000)" startWordPosition="1457" endWordPosition="1460">t automatically classifying German adjectives. However, the classification 577 Computational Linguistics Volume 38, Number 3 used is not purely semantic, polysemy is not taken into account, and the evidence and techniques used are more limited than the ones used here. Other research on adjectives within computational linguistics is oriented toward different goals than ours. Yallop, Korhonen, and Briscoe (2005) tackle syntactic, not semantic classification, akin to the acquisition of subcategorization frames for verbs. Another relevant line of research pursues WSD. Justeson and Katz (1995) and Chao and Dyer (2000) showed that adjectives are a very useful cue for disambiguating the sense of the nouns they modify. Adjective classes could be further exploited in WSD in at least two respects: (1) to establish an inventory of adjective senses (if polysemous instances are correctly detected; this is where sense induction and our own work fits in), and (2) to exploit class-based properties for the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Min</context>
</contexts>
<marker>Chao, Dyer, 2000</marker>
<rawString>Chao, Gerald and Michael G. Dyer. 2000. Word sense disambiguation of adjectives using probabilistic networks. In Proceedings of the 18th Conference on Computational Linguistics (COLING-00), pages 152–158, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Ted Briscoe</author>
</authors>
<title>Semi-productive polysemy and sense extension.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<pages>12--15</pages>
<contexts>
<context position="3917" citStr="Copestake and Briscoe 1995" startWordPosition="561" endWordPosition="564">on for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant challenge is posed by polysemy, or the fact that one and the same adjective can have multiple senses. Different senses may fall into different classes, such that it is no longer possible to identify one single semantic class per adjective. Moreover, many adjectives exhibit similar sense alternations, in a phenomenon known as regular or systematic polysemy (Apresjan 1974; Copestake and Briscoe 1995). A special focus of the research presented, therefore, is on modeling regular polysemy. As an example of regular polysemy, take for instance the sense alternation for the adjective econ`omic exemplified in Example (1). Econ`omic, derived from economia (‘economy’), can be translated as ‘economic, of the economy’, as in Example (1a), or as ‘cheap’, as in Example (1b). As we will see, each of these senses corresponds to a different semantic class in our classifications. (1) a. recuperaci´o econ`omica recovery economySUFFIX ‘recovery of the economy’ b. pantalons econ`omics trousers economySUFFIX </context>
<context position="6670" citStr="Copestake and Briscoe 1995" startWordPosition="975" endWordPosition="978">e alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational semantics, however. This is surprising, given the amount of work devoted to sense-related tasks such as Word Sense Disambiguation (WSD). In WSD (see Navigli [2009] for an overview) sense ambiguities are almost exclusively modeled for each individual lemma, despite the ensuing sparsity problems (Ando [2006] is an exception). Properly modeling regular polysemy, therefore, promises to improve computational semantic tasks such as WSD and sense discrimination. This article has the goal of finding a computational model that responds to th</context>
</contexts>
<marker>Copestake, Briscoe, 1995</marker>
<rawString>Copestake, Ann and Ted Briscoe. 1995. Semi-productive polysemy and sense extension. Journal of Semantics, 12:15–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
<author>Christopher Potts</author>
</authors>
<title>Was it good? It was provocative.” Learning the meaning of scalar adjectives.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>167--176</pages>
<location>Stroudsburg, PA.</location>
<marker>de Marneffe, Manning, Potts, 2010</marker>
<rawString>de Marneffe, Marie-Catherine, Christopher D. Manning, and Christopher Potts. 2010. “Was it good? It was provocative.” Learning the meaning of scalar adjectives. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 167–176, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Demonte</author>
</authors>
<date>2011</date>
<booktitle>Semantics: An International Handbook of Natural Language Meaning, volume 2. Mouton de Gruyter,</booktitle>
<pages>1314--1340</pages>
<editor>Adjectives. In Klaus von Heusinger, Claudia Maienborn, and Paul Portner, editors,</editor>
<location>Berlin,</location>
<contexts>
<context position="15939" citStr="Demonte 2011" startWordPosition="2376" endWordPosition="2377"> exploratory endeavor, and we do not regard the classifications we use as final. We test two different classifications: an initial classification, based on the literature, for the experiments reported in Section 4, and an alternative classification, for the experiments reported in Section 5. We next turn to presenting the two tested classifications. 3.1 Initial Classification In the acquisition experiments reported in Section 4, we distinguish between qualitative, intensional, and relational adjectives, which have the following properties (Miller 1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011). Qualitative adjectives. These are prototypical adjectives like gran (‘big’) or dol¸c (‘sweet’), including scalar adjectives, which denote attributes or properties of objects. Adjectives in this class tend to be gradable and comparable (see Examples (4a–4b)). They are characterized by exhibiting the greatest variability with respect to their syntactic behavior: In Catalan, they can act as predicates in copular sentences and other constructions (Examples (4c–4d)), and they can typically act as both pre- and post-nominal modifiers (Examples (4e–4f)). When an adjective modifies a head noun in pr</context>
</contexts>
<marker>Demonte, 2011</marker>
<rawString>Demonte, Violeta. 2011. Adjectives. In Klaus von Heusinger, Claudia Maienborn, and Paul Portner, editors, Semantics: An International Handbook of Natural Language Meaning, volume 2. Mouton de Gruyter, Berlin, pages 1314–1340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjit S Dhillon</author>
<author>Dharmendra S Modha</author>
</authors>
<title>Concept decompositions for large sparse text data using clustering.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>42--143</pages>
<contexts>
<context position="42434" citStr="Dhillon and Modha 2001" startWordPosition="6382" endWordPosition="6385">ndom partition into k clusters is performed on the data. The centroids (mean vectors) of each cluster are computed, and each object is reassigned to the cluster with the nearest centroid. The centroids are recomputed, and the process is iterated until no further changes take place, or a pre-specified number of times (20 in our case). Equation (2) shows the formula for the clustering criterion, where k is the total number of clusters and l are the lemmata in each cluster c1, ... , ck. To avoid the 2 More specifically, because we are using the cosine measure, the algorithm is spherical k-means (Dhillon and Modha 2001). All the experiments were performed with the CLUTO toolkit (Karypis 2002). (17) a. la Bruna ´es m´es alta que the Bruna is more tall than 589 Computational Linguistics Volume 38, Number 3 influence of the initial partition on the final structure, the whole experiment is repeated several times (25 in our case) with different random partitions, and the partition that better satisfies the clustering criterion is chosen. �minimize � cos(l, centroid(ci)) (2) i∈k l∈ci We experimented with two representations of the feature values: raw and standardized proportions. In clustering, features with highe</context>
</contexts>
<marker>Dhillon, Modha, 2001</marker>
<rawString>Dhillon, Inderjit S. and Dharmendra S. Modha. 2001. Concept decompositions for large sparse text data using clustering. Machine Learning, 42:143–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Approximate statistical tests for comparing supervised classification learning algorithms.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<volume>10</volume>
<issue>7</issue>
<contexts>
<context position="72694" citStr="Dietterich 1998" startWordPosition="11126" endWordPosition="11127">gular Polysemy in Catalan Adjectives of “strange” class assignments made by one single classifier, which are therefore overridden by the class assignments of the remaining classifiers.7 For the evaluation, 100 different estimates of accuracy are obtained for each feature set using 10-run, 10-fold cross-validation (10x10 cv for short). In this schema, 10-fold cross-validation is performed 10 times, that is, 10 different random partitions of the data (runs) are made, and 10-fold cross-validation is carried out for each partition. To avoid the inflated Type I error probability when reusing data (Dietterich 1998), the significance of the differences between accuracies is tested with the corrected resampled t-test as proposed by Nadeau and Bengio (2003).8 5.4 Results 5.4.1 Simple Classifiers. The accuracies for the simple classifiers are shown in Table 10. Part A of the table lists the results for each of the binary decisions (qualitative/ non-qualitative, event/non-event, relational/non-relational). The accuracy for each decision is computed independently. For instance, a qualitative-event adjective is judged correct within the qualitative class iff the decision is qualitative; correct within the even</context>
</contexts>
<marker>Dietterich, 1998</marker>
<rawString>Dietterich, Thomas G. 1998. Approximate statistical tests for comparing supervised classification learning algorithms. Neural Computation, 10(7):1895–1924.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>40--5</pages>
<contexts>
<context position="71413" citStr="Dietterich 2000" startWordPosition="10929" endWordPosition="10930">), and they have been used in related work (Merlo and Stevenson 2001). They have relatively few parameters to tune (a requirement with small data sets such as ours) and provide a transparent representation of the decisions made by the algorithm, which facilitates the inspection of results and the error analysis. We will refer to these Decision Tree classifiers as simple classifiers, in opposition to the ensemble classifiers, which are complex, as explained next. The second type of classifier we use are ensemble classifiers, which have received much attention in the machine learning community (Dietterich 2000). When building an ensemble classifier, several class proposals for each item are obtained from multiple simple classifiers, and one of them is chosen on the basis of majority voting, weighted voting, or more sophisticated decision methods. It has been shown that in most cases, the accuracy of the ensemble classifier is higher than the best individual classifier (Freund and Schapire 1996; Dietterich 2000; Breiman 2001). The main reason for the general success of ensemble classifiers is that they are more robust towards the biases particular to individual classifiers: A bias shows up in the dat</context>
</contexts>
<marker>Dietterich, 2000</marker>
<rawString>Dietterich, Thomas G. 2000. An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization. Machine Learning, 40:5–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M W Dixon</author>
<author>Y Alexandra</author>
</authors>
<title>Adjective Classes.</title>
<date>2004</date>
<editor>Aikhenvald, editors.</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<marker>Dixon, Alexandra, 2004</marker>
<rawString>Dixon, Robert M. W. and Alexandra Y. Aikhenvald, editors. 2004. Adjective Classes. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Douglas Jones</author>
</authors>
<title>Role of word sense disambiguation in lexical acquisition: Predicting semantics from syntactic cues.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96),</booktitle>
<pages>322--333</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="2900" citStr="Dorr and Jones 1996" startWordPosition="409" endWordPosition="412">of the work reported in this article was done while the first author was a postdoctoral scholar at U. Polit`ecnica de Catalunya and a visiting researcher at U. Stuttgart. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 1998). This article tackles precisely this task, that is, the semantic classification of adjectives, for Catalan. We aim at automatically inducing the semantic class for an adjective given its linguistic properties, as extracted from corpora and other resources. The acquisition of semantic classes has been widely studied for verbs (Dorr and Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew 2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent, for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions (Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Furthermore, we cannot rely on a well-established classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Anot</context>
</contexts>
<marker>Dorr, Jones, 1996</marker>
<rawString>Dorr, Bonnie J. and Douglas Jones. 1996. Role of word sense disambiguation in lexical acquisition: Predicting semantics from syntactic cues. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96), pages 322–333, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Exemplar-based models for word meaning in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers, ACLShort ’10,</booktitle>
<pages>92--97</pages>
<location>Stroudsburg, PA.</location>
<marker>Erk, Pad´o, 2010</marker>
<rawString>Erk, Katrin and Sebastian Pad´o. 2010. Exemplar-based models for word meaning in context. In Proceedings of the ACL 2010 Conference Short Papers, ACLShort ’10, pages 92–97, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian S Everitt</author>
<author>Sabine Landau</author>
<author>Morven Leese</author>
</authors>
<title>Cluster Analysis.</title>
<date>2001</date>
<location>Arnold, London,</location>
<note>4th edition.</note>
<marker>Everitt, Landau, Leese, 2001</marker>
<rawString>Everitt, Brian S., Sabine Landau, and Morven Leese. 2001. Cluster Analysis. Arnold, London, 4th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Experiments with a new boosting algorithm.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth International Conference on Machine Learning, ICML ’96,</booktitle>
<pages>148--156</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="71803" citStr="Freund and Schapire 1996" startWordPosition="10988" endWordPosition="10991">rs, in opposition to the ensemble classifiers, which are complex, as explained next. The second type of classifier we use are ensemble classifiers, which have received much attention in the machine learning community (Dietterich 2000). When building an ensemble classifier, several class proposals for each item are obtained from multiple simple classifiers, and one of them is chosen on the basis of majority voting, weighted voting, or more sophisticated decision methods. It has been shown that in most cases, the accuracy of the ensemble classifier is higher than the best individual classifier (Freund and Schapire 1996; Dietterich 2000; Breiman 2001). The main reason for the general success of ensemble classifiers is that they are more robust towards the biases particular to individual classifiers: A bias shows up in the data in the form 598 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives of “strange” class assignments made by one single classifier, which are therefore overridden by the class assignments of the remaining classifiers.7 For the evaluation, 100 different estimates of accuracy are obtained for each feature set using 10-run, 10-fold cross-validation (10x10 cv </context>
</contexts>
<marker>Freund, Schapire, 1996</marker>
<rawString>Freund, Yoav and Robert E. Schapire. 1996. Experiments with a new boosting algorithm. In Proceedings of the Thirteenth International Conference on Machine Learning, ICML ’96, pages 148–156, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadia Ghamrawi</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective multi-label classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM ’05,</booktitle>
<pages>195--200</pages>
<location>New York, NY.</location>
<contexts>
<context position="69717" citStr="Ghamrawi and McCallum 2005" startWordPosition="10663" endWordPosition="10666">lational or not? 2. A complete classification is achieved by merging the results of the binary decisions. A consistency check is applied by which (a) if all decisions are negative, the adjective is assigned to the qualitative class (the most frequent one; this was the case for a mean of 4.6% of the class assignments); (b) if all decisions are positive, we randomly discard one (three-way polysemy is not foreseen in our classification; this was the case for a mean of 0.6% of the class assignments). This is the standard architecture for multi-label classification tasks (Schapire and Singer 2000; Ghamrawi and McCallum 2005), and it has also been applied to NLP problems such as entity extraction and noun-phrase chunking (McDonald, Crammer, and Pereira 2005). Note that in the present experiments we change both the classification and the approach (unsupervised vs. supervised) with respect to the first set of experiments presented in Section 4, which can be seen as a sub-optimal technical choice. After the first series of experiments that required a more exploratory analysis, however, we believe that we have now reached a more stable classification, which we can test by supervised methods. In addition, we need a one</context>
</contexts>
<marker>Ghamrawi, McCallum, 2005</marker>
<rawString>Ghamrawi, Nadia and Andrew McCallum. 2005. Collective multi-label classification. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM ’05, pages 195–200, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL’93),</booktitle>
<pages>172--182</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="10914" citStr="Hatzivassiloglou and McKeown 1993" startWordPosition="1612" endWordPosition="1615">r the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey much of the evaluative and subjective information in language (Wiebe et al. 2004). The typical goal of this kind of study has been to identify subjective adjectives and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts 2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can be translated into values that can be ordered along a scale. These adjectives typically enter into antonymy relations (the semantic relation between good and bad), and in fact antonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), the most widely used semantic resource in NLP. However, when examining a large scale lexicon, it becomes immediately apparent that there are many other </context>
<context position="49094" citStr="Hatzivassiloglou and McKeown 1993" startWordPosition="7514" endWordPosition="7517">ntations with respect to the clustering results: The POS features elicited as most discriminative by the clustering algorithm are precisely those that correspond to the theoretical features. This correspondence explains the resemblance between the solutions obtained with the two types of representation and at the same time provides support for the present definition of the theoretical features. Last but not least, note that we do not assign a score to each clustering solution. Evaluation of clustering is very problematic when there is no one-to-one correspondence between classes and clusters (Hatzivassiloglou and McKeown 1993), as is our case. Schulte im Walde (2006) provides a thorough discussion of this issue and proposes different metrics and types of evaluation. We defer numerical evaluation until Section 5. 4.5 Discussion 4.5.1 Classification. The experiments presented provide feedback to the question, what is an appropriate broad semantic classification for adjectives? The clustering experiments provide empirical support for the qualitative and relational classes, as is particularly evident in the three-way solution (Table 5). These are classes that have traditionally been taken into account in descriptive gr</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>Hatzivassiloglou, Vasileios and Kathleen R. McKeown. 1993. Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL’93), pages 172–182, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Eighth Conference of the European Chapter of the Association for Computational Linguistics (EACL’97),</booktitle>
<pages>174--181</pages>
<location>Morristown, NJ.</location>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Hatzivassiloglou, Vasileios and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the Eighth Conference of the European Chapter of the Association for Computational Linguistics (EACL’97), pages 174–181, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Janyce M Wiebe</author>
</authors>
<title>Effects of adjective orientation and gradability on sentence subjectivity.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00),</booktitle>
<pages>299--305</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="10954" citStr="Hatzivassiloglou and Wiebe 2000" startWordPosition="1617" endWordPosition="1620">work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey much of the evaluative and subjective information in language (Wiebe et al. 2004). The typical goal of this kind of study has been to identify subjective adjectives and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts 2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can be translated into values that can be ordered along a scale. These adjectives typically enter into antonymy relations (the semantic relation between good and bad), and in fact antonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), the most widely used semantic resource in NLP. However, when examining a large scale lexicon, it becomes immediately apparent that there are many other types of adjectives that do not easily f</context>
</contexts>
<marker>Hatzivassiloglou, Wiebe, 2000</marker>
<rawString>Hatzivassiloglou, Vasileios and Janyce M. Wiebe. 2000. Effects of adjective orientation and gradability on sentence subjectivity. In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00), pages 299–305, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, ACL ’90,</booktitle>
<pages>268--275</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="3082" citStr="Hindle 1990" startWordPosition="440" endWordPosition="441">for Computational Linguistics Computational Linguistics Volume 38, Number 3 1998). This article tackles precisely this task, that is, the semantic classification of adjectives, for Catalan. We aim at automatically inducing the semantic class for an adjective given its linguistic properties, as extracted from corpora and other resources. The acquisition of semantic classes has been widely studied for verbs (Dorr and Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew 2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent, for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions (Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Furthermore, we cannot rely on a well-established classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant challenge is posed by polysemy, or the fact that one and the same adjective can have multiple senses. Different senses may fall into different classes, such that it i</context>
<context position="12793" citStr="Hindle 1990" startWordPosition="1904" endWordPosition="1905">This maimai is round and sweet, we can quite safely infer that the (invented) object maimai is a physical object, probably edible. This type of process could be exploited in, for instance, Information Extraction and ontology population, although to our knowledge this possibility has received but little attention (Malouf 2000; Almuhareb and Poesio 2004). As for polysemy, previous approaches to the automatic acquisition of semantic classes have mostly disregarded the problem, by biasing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). There is very little related work in empirical computational semantics in modeling regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative </context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, Donald. 1990. Noun classification from predicate-argument structures. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, ACL ’90, pages 268–275, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tin Kam Ho</author>
</authors>
<title>The random subspace method for constructing decision forests.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<pages>20--832</pages>
<contexts>
<context position="80630" citStr="Ho 1998" startWordPosition="12397" endWordPosition="12398">assifiers. Error analysis on the results using simple classifiers (not reported for space reasons) revealed that the errors made by the different classifiers, using different feature sets, are qualitatively quite different. This motivated the use 600 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives Figure 2 Accuracy of the Attribute Bagging classifier as a function of the number of random partitions i. Increasing i leads to a rapid increase of accuracy up to i = 30; after that, accuracy stabilizes and experiences only a slight increase. of Attribute Bagging (Ho 1998; Bryll, Gutierrez-Osuna, and Quek 2003), an ensemble classifier (EC) in which the class assignments are obtained by majority voting over randomly sampled feature subsets.10 Attribute Bagging has two main parameters: the bag size (number of features used for each classification; it was set to 1/3 given results reported in the literature, although varying this parameter did not affect the results much), and the number of iterations i (we tested 3, 4, 5, 6, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100; note that our total feature size is 121, see Table 8). Figure 2 shows that increasing i leads to a </context>
</contexts>
<marker>Ho, 1998</marker>
<rawString>Ho, Tin Kam. 1998. The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20:832–844.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
<author>David James</author>
</authors>
<title>A general feature space for automatic verb classification.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>03</issue>
<marker>Joanis, Stevenson, James, 2008</marker>
<rawString>Joanis, Eric, Suzanne Stevenson, and David James. 2008. A general feature space for automatic verb classification. Natural Language Engineering, 14(03):337–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Principled disambiguation: Discriminating adjective senses with modified nouns.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="9877" citStr="Justeson and Katz (1995)" startWordPosition="1452" endWordPosition="1455">nt research, as it is aimed at automatically classifying German adjectives. However, the classification 577 Computational Linguistics Volume 38, Number 3 used is not purely semantic, polysemy is not taken into account, and the evidence and techniques used are more limited than the ones used here. Other research on adjectives within computational linguistics is oriented toward different goals than ours. Yallop, Korhonen, and Briscoe (2005) tackle syntactic, not semantic classification, akin to the acquisition of subcategorization frames for verbs. Another relevant line of research pursues WSD. Justeson and Katz (1995) and Chao and Dyer (2000) showed that adjectives are a very useful cue for disambiguating the sense of the nouns they modify. Adjective classes could be further exploited in WSD in at least two respects: (1) to establish an inventory of adjective senses (if polysemous instances are correctly detected; this is where sense induction and our own work fits in), and (2) to exploit class-based properties for the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>Justeson, John S. and Slava M. Katz. 1995. Principled disambiguation: Discriminating adjective senses with modified nouns. Computational Linguistics, 21(1):1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Karypis</author>
</authors>
<title>CLUTO—A Clustering Toolkit.</title>
<date>2002</date>
<tech>Technical Report TR 02-017,</tech>
<institution>Department of Computer Science and Engineering, University of Minnesota,</institution>
<location>Minneapolis, MN.</location>
<contexts>
<context position="42508" citStr="Karypis 2002" startWordPosition="6395" endWordPosition="6396">) of each cluster are computed, and each object is reassigned to the cluster with the nearest centroid. The centroids are recomputed, and the process is iterated until no further changes take place, or a pre-specified number of times (20 in our case). Equation (2) shows the formula for the clustering criterion, where k is the total number of clusters and l are the lemmata in each cluster c1, ... , ck. To avoid the 2 More specifically, because we are using the cosine measure, the algorithm is spherical k-means (Dhillon and Modha 2001). All the experiments were performed with the CLUTO toolkit (Karypis 2002). (17) a. la Bruna ´es m´es alta que the Bruna is more tall than 589 Computational Linguistics Volume 38, Number 3 influence of the initial partition on the final structure, the whole experiment is repeated several times (25 in our case) with different random partitions, and the partition that better satisfies the clustering criterion is chosen. �minimize � cos(l, centroid(ci)) (2) i∈k l∈ci We experimented with two representations of the feature values: raw and standardized proportions. In clustering, features with higher mean and standard deviation values tend to dominate over more sparse fea</context>
</contexts>
<marker>Karypis, 2002</marker>
<rawString>Karypis, George. 2002. CLUTO—A Clustering Toolkit. Technical Report TR 02-017, Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Kaufman</author>
<author>Peter J Rousseeuw</author>
</authors>
<title>Finding Groups in Data: An Introduction to Cluster Analysis.</title>
<date>1990</date>
<publisher>John Wiley,</publisher>
<location>New York.</location>
<marker>Kaufman, Rousseeuw, 1990</marker>
<rawString>Kaufman, Leonard and Peter J. Rousseeuw. 1990. Finding Groups in Data: An Introduction to Cluster Analysis. John Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Upali S Kohomban</author>
<author>Wee Sun Lee</author>
</authors>
<title>Learning semantic classes for Word Sense Disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>34--41</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="10414" citStr="Kohomban and Lee 2005" startWordPosition="1539" endWordPosition="1542">es for verbs. Another relevant line of research pursues WSD. Justeson and Katz (1995) and Chao and Dyer (2000) showed that adjectives are a very useful cue for disambiguating the sense of the nouns they modify. Adjective classes could be further exploited in WSD in at least two respects: (1) to establish an inventory of adjective senses (if polysemous instances are correctly detected; this is where sense induction and our own work fits in), and (2) to exploit class-based properties for the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey much of the evaluative and subjective information in language (Wiebe et al. 2004). The typical goal of this kind of study has been to identify subjective adjectives and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts 2010),</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Kohomban, Upali S. and Wee Sun Lee. 2005. Learning semantic classes for Word Sense Disambiguation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 34–41, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Zvika Marx</author>
</authors>
<title>Clustering polysemic subcategorization frame distributions semantically.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>64--71</pages>
<location>Stroudsburg, PA.</location>
<marker>Korhonen, Krymolowski, Marx, 2003</marker>
<rawString>Korhonen, Anna, Yuval Krymolowski, and Zvika Marx. 2003. Clustering polysemic subcategorization frame distributions semantically. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics - Volume 1, ACL ’03, pages 64–71, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>A corpus-based account of regular polysemy: The case of context-sensitive adjectives.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies, NAACL ’01,</booktitle>
<pages>1--8</pages>
<location>Stroudsburg, PA.</location>
<marker>Lapata, 2001</marker>
<rawString>Lapata, Maria. 2001. A corpus-based account of regular polysemy: The case of context-sensitive adjectives. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies, NAACL ’01, pages 1–8, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>The Acquisition and Modeling of Lexical Knowledge: A Corpusbased Investigation of Systematic Polysemy.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="13839" citStr="Lapata (2000" startWordPosition="2064" endWordPosition="2065">ysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 “basic 578 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives types” (broad ontological categories). In CoreLex, each word is associated to a polysemy class, that is, the set of all basic types its synsets belong to. Some of these polysemy classes constitute instances of regular polysemy, as recently explored in Utt and Pad´o (2011). Lapata (2000, 2001) also addresses regular polysemy in the Generative Lexicon framework. This work attempts to establish all the possible meanings of adjective-noun combinations, and rank them using information gathered from the British National Corpus (Burnage and Dunlop 1992). This information should indicate that an easy problem is usually equivalent to problem that is easy to solve (as opposed to, for example, easy text, that is usually equivalent to text that is easy to read). Thus, the focus is on the meaning of adjective-noun combinations, not on that of adjectives alone as in the present research.</context>
<context position="28628" citStr="Lapata (2000" startWordPosition="4281" endWordPosition="4282">le, we only consider types of polysemy that cut across the classification pursued. Other kinds of polysemy that have traditionally been tackled in the literature will not be considered. For instance, we will not be concerned with the polysemy illustrated in Example (16), which arguably has more to do with the semantics of the 584 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives modified noun than that of the adjective (Pustejovsky 1995). Both of the uses of trist (‘sad’) illustrated in Example (16) fall into the qualitative class, so, contrary to the work by Lapata (2000, 2001) cited previously, we do not treat the adjective as polysemous in the context of the present experiments. (16) noi trist / pel·l´ıcula trista boy sad / film sad ‘sad boy / sad film’ 4. First Model: Polysemous Adjectives Constitute Independent Classes Given the hybrid behavior of polysemous adjectives explained in Section 3, we can expect that they behave differently from adjectives in the basic classes. For instance, adjectives polysemous between a qualitative and a relational use should exhibit more evidence for gradability than pure relational adjectives, but less than pure qualitativ</context>
</contexts>
<marker>Lapata, 2000</marker>
<rawString>Lapata, Mirella. 2000. The Acquisition and Modeling of Lexical Knowledge: A Corpusbased Investigation of Systematic Polysemy. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Chris Brew</author>
</authors>
<title>Verb class disambiguation using informative priors.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="2975" citStr="Lapata and Brew 2004" startWordPosition="420" endWordPosition="423"> postdoctoral scholar at U. Polit`ecnica de Catalunya and a visiting researcher at U. Stuttgart. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 1998). This article tackles precisely this task, that is, the semantic classification of adjectives, for Catalan. We aim at automatically inducing the semantic class for an adjective given its linguistic properties, as extracted from corpora and other resources. The acquisition of semantic classes has been widely studied for verbs (Dorr and Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew 2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent, for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions (Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Furthermore, we cannot rely on a well-established classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant challenge is posed by polysemy, or the fact that one and th</context>
</contexts>
<marker>Lapata, Brew, 2004</marker>
<rawString>Lapata, Mirella and Chris Brew. 2004. Verb class disambiguation using informative priors. Computational Linguistics, 30(2):45–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
<author>Malka Rappaport</author>
</authors>
<title>The formation of adjectival passives. Linguistic Inquiry,</title>
<date>1986</date>
<pages>17--623</pages>
<contexts>
<context position="53377" citStr="Levin and Rappaport 1986" startWordPosition="8161" endWordPosition="8164">: A person named Serra belongs to the kind of associates who have as a primary role to protect the association. (18) Serra ... Era soci protector de l’Associaci´o de concerts Serra ... was associate protecting of the-Association of concerts ‘Serra was a protecting associate of the Association of concerts’ These considerations motivate the addition of a class of event-related adjectives in the overall classification. Event-related adjectives have not received much attention in the linguistic literature, except for one particular subtype, namely, adjectival uses of the participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995). As for computational resources, the English WordNet, as explained in Section 3, only distinguishes some participial adjectives. In the Italian WordNet, however, other event-related adjectives receive a specific treatment, through the encoding of the lexical relations CAUSES and LIABLE-TO, as exemplified in Example (19) (Alonge et al. 2000): (19) a. depuratorio ‘depurative, purifying’ CAUSES depurare ‘to depurate/purify’. b. giudicabile ‘triable’ LIABLE-TO giudicare ‘to judge’. To sum up, the results of the experiments reported in this section motivate a threeway classification</context>
</contexts>
<marker>Levin, Rappaport, 1986</marker>
<rawString>Levin, Beth and Malka Rappaport. 1986. The formation of adjectival passives. Linguistic Inquiry, 17:623–661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
</authors>
<title>The order of prenominal adjectives in natural language generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, ACL ’00,</booktitle>
<pages>85--92</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="12508" citStr="Malouf 2000" startWordPosition="1863" endWordPosition="1864">rms of different semantic classes in this article. The semantic properties of adjectives can also be exploited in advanced NLP tasks and applications such as Question Answering, Dialog Systems, Natural Language Generation, or Information Extraction. For instance, from a sentence like This maimai is round and sweet, we can quite safely infer that the (invented) object maimai is a physical object, probably edible. This type of process could be exploited in, for instance, Information Extraction and ontology population, although to our knowledge this possibility has received but little attention (Malouf 2000; Almuhareb and Poesio 2004). As for polysemy, previous approaches to the automatic acquisition of semantic classes have mostly disregarded the problem, by biasing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic cl</context>
</contexts>
<marker>Malouf, 2000</marker>
<rawString>Malouf, Robert. 2000. The order of prenominal adjectives in natural language generation. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, ACL ’00, pages 85–92, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz 1993</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date></date>
<marker>Marcus, Santorini, 1993, </marker>
<rawString>Marcus, M., B. Santorini, and M. Marcinkiewicz.1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laia Mayol</author>
<author>Gemma Boleda</author>
<author>Toni Badia</author>
</authors>
<title>Automatic acquisition of syntactic verb classes with basic resources.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<issue>4</issue>
<marker>Mayol, Boleda, Badia, 2005</marker>
<rawString>Mayol, Laia, Gemma Boleda, and Toni Badia. 2005. Automatic acquisition of syntactic verb classes with basic resources. Language Resources and Evaluation, 39(4):295–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Using semantic preferences to identify verbal participation in role switching alternations.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL ’00,</booktitle>
<pages>256--263</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="2915" citStr="McCarthy 2000" startWordPosition="413" endWordPosition="414">in this article was done while the first author was a postdoctoral scholar at U. Polit`ecnica de Catalunya and a visiting researcher at U. Stuttgart. © 2012 Association for Computational Linguistics Computational Linguistics Volume 38, Number 3 1998). This article tackles precisely this task, that is, the semantic classification of adjectives, for Catalan. We aim at automatically inducing the semantic class for an adjective given its linguistic properties, as extracted from corpora and other resources. The acquisition of semantic classes has been widely studied for verbs (Dorr and Jones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew 2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent, for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions (Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives. Furthermore, we cannot rely on a well-established classification for adjectives. The classes themselves are subject to experimentation. We will test two different classifications, analyzing the empirical properties of the classes and the problems in their definition. Another significant</context>
</contexts>
<marker>McCarthy, 2000</marker>
<rawString>McCarthy, Diana. 2000. Using semantic preferences to identify verbal participation in role switching alternations. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, NAACL ’00, pages 256–263, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, ACL ’04,</booktitle>
<pages>279--286</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="6135" citStr="McCarthy et al. 2004" startWordPosition="901" endWordPosition="904">g] 576 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives Because of the systematic semantic relationship between the two senses of these adjectives, they constitute an instance of regular polysemy. In this article, therefore, we not only address the acquisition of semantic classes, but also the acquisition of polysemy: Our goal is to determine, for a given adjective, whether it is monosemous or polysemous, and to which class(es) it belongs. Note that we are not dealing with individual sense alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational sem</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>McCarthy, Diana, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant word senses in untagged text. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, ACL ’04, pages 279–286, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Flexible text segmentation with structured multilabel classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>987--994</pages>
<location>Stroudsburg, PA.</location>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>McDonald, Ryan, Koby Crammer, and Fernando Pereira. 2005. Flexible text segmentation with structured multilabel classification. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 987–994, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louise McNally</author>
<author>Gemma Boleda</author>
</authors>
<title>Relational adjectives as properties of kinds.</title>
<date>2004</date>
<booktitle>Empirical Issues in Syntax and Semantics,</booktitle>
<pages>5--179</pages>
<contexts>
<context position="18297" citStr="McNally and Boleda 2004" startWordPosition="2734" endWordPosition="2737">ically not gradable (Example (5c)). (5) a. El Joan ´es el presumpte assassfmurderer The Joan is the alleged ‘Joan is the alleged murderer’ b. #El The presumpte alleged ‘#Joan is alleged’ Joan Joan ´es is c. #M´es presumpte assassfmurderer / #presumptfssim assassfmurderer More alleged / allegedSUPERLATIVE ‘#More/very alleged murderer’ Intensional adjectives like presumpte may appear in any order with respect to qualitative adjectives, as in Example (6). The order, however, affects interpretation: Example (6a) entails that the referent of the noun phrase is young, whereas Example (6b) does not (McNally and Boleda 2004). (6) a. jove presumpte assassf‘young alleged murderer’ 580 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives b. presumpte jove assass´ı ‘alleged young murderer’ Relational adjectives. Adjectives such as pulmonar, estacional, bot`anic (‘pulmonary, seasonal, botanical’) denote a relationship to an object (in the mentioned examples, LUNG, SEASON, and PLANT objects). Most of them are denominal (e.g., pulmonar is derived from pulm´o, ‘lung’) and can only modify nouns post-nominally (see Example (7a)). Also, contrary to qualitative adjectives, they are not gradable</context>
<context position="91539" citStr="McNally and Boleda 2004" startWordPosition="14121" endWordPosition="14124"> relational adjectives appear more often in definite NPs acting as preposition complements (graphs E and H). Thus, the typical syntactic context for a relational adjective is preposition + definite determiner + noun + relational adjective). This type of adjective also appears slightly more often with feminine head nouns, which could be due to the fact that, in Catalan, many abstract nouns ( f´ısica ‘physics’, capacitat ‘ability’) are feminine, for morphological reasons. These nouns are often modified by relational adjectives to select for subtypes of the class of objects denoted by the nouns (McNally and Boleda 2004). Another difficulty in the distributional characterization of the event class is the fact that it is quite heterogeneous, due to the variation at the morphology–semantics interface discussed earlier. This can be traced in Figure 4 by the fact that for most of the features, the box of the event class is larger than the box of the other two classes, meaning that there is more variation within the event class than within the other two classes. Q -ble 3 -iu 3 -nt 4 -or 1 participle 2 Total 16 E 6 1 36 6 10 8 R QR QE 0 0 1 1 2 0 0 0 0 0 0 0 0 0 5 3 2 7 ER Total 1 11 4 11 1 11 0 11 0 15 6 70 604 Bo</context>
</contexts>
<marker>McNally, Boleda, 2004</marker>
<rawString>McNally, Louise and Gemma Boleda. 2004. Relational adjectives as properties of kinds. Empirical Issues in Syntax and Semantics, 5:179–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="12819" citStr="Merlo and Stevenson 2001" startWordPosition="1906" endWordPosition="1909">s round and sweet, we can quite safely infer that the (invented) object maimai is a physical object, probably edible. This type of process could be exploited in, for instance, Information Extraction and ontology population, although to our knowledge this possibility has received but little attention (Malouf 2000; Almuhareb and Poesio 2004). As for polysemy, previous approaches to the automatic acquisition of semantic classes have mostly disregarded the problem, by biasing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). There is very little related work in empirical computational semantics in modeling regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative Lexicon theory (Pustejovsk</context>
<context position="32830" citStr="Merlo and Stevenson (2001)" startWordPosition="4894" endWordPosition="4897">nsional, and qualitative-relational). The instructions for the judges included information about all linguistic characteristics discussed in Section 3, including syntactic and semantic characteristics. The judges had a moderate degree of agreement, comparable to that obtained in other tasks on semantics or discourse, inter-annotator scores ranging between K = 0.54 and 0.64 (see Artstein and Poesio [2008] for a discussion of agreement measures for computational linguistics). For comparison, V´eronis (1998) reported a mean pair-wise weighted K = 0.43 for a word sense tagging task in French; and Merlo and Stevenson (2001) obtained K = 0.53–0.66 for the task of classifying English verbs as unergative, unaccusative, or object-drop. Poesio and Artstein (2005) report K values of 0.63–0.66 (0.45–0.50 if a trivial category is dropped) for the tagging of anaphoric relations. Our judges reported difficulties in tagging particular kinds of adjectives, such as deverbal adjectives. This issue will be retaken in Section 4.5. No intensional adjectives were identified in the data by the judges, and only one intensional-qualitative adjective was identified. Two intensional lemmata were manually added to be able to minimally </context>
<context position="70866" citStr="Merlo and Stevenson 2001" startWordPosition="10844" endWordPosition="10847">ication, which we can test by supervised methods. In addition, we need a one-to-one correspondence between gold standard classes and clusters for the approach to work, which we cannot guarantee when using an unsupervised approach that outputs a certain number of clusters with no mapping to the gold standard classes. We test two types of classifiers. The first type are Decision Tree classifiers trained on different types of linguistic information coded as feature sets. Decision Trees are one of the most widely machine learning techniques (Quinlan 1993), and they have been used in related work (Merlo and Stevenson 2001). They have relatively few parameters to tune (a requirement with small data sets such as ours) and provide a transparent representation of the decisions made by the algorithm, which facilitates the inspection of results and the error analysis. We will refer to these Decision Tree classifiers as simple classifiers, in opposition to the ensemble classifiers, which are complex, as explained next. The second type of classifier we use are ensemble classifiers, which have received much attention in the machine learning community (Dietterich 2000). When building an ensemble classifier, several class</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Merlo, Paola and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharine J Miller</author>
</authors>
<title>Modifiers in WordNet.</title>
<date>1998</date>
<booktitle>WordNet: an Electronic Lexical Database. The</booktitle>
<pages>47--67</pages>
<editor>In Christiane Fellbaum, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="11360" citStr="Miller 1998" startWordPosition="1683" endWordPosition="1684"> and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts 2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can be translated into values that can be ordered along a scale. These adjectives typically enter into antonymy relations (the semantic relation between good and bad), and in fact antonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), the most widely used semantic resource in NLP. However, when examining a large scale lexicon, it becomes immediately apparent that there are many other types of adjectives that do not easily fit in a scale-based or antonymy-based view of adjectives (Alonge et al. 2000). Some examples are pulmonary, former, and foldable. It is not clear, for instance, whether it makes sense to ask for an antonym of pulmonary, or to establish a “foldability” scale for foldable. These adjectives need a different treatment, and they are treated in terms of different semantic classes in this article. The semantic</context>
<context position="15883" citStr="Miller 1998" startWordPosition="2368" endWordPosition="2369">quisition, addressing (b). We are thus facing a highly exploratory endeavor, and we do not regard the classifications we use as final. We test two different classifications: an initial classification, based on the literature, for the experiments reported in Section 4, and an alternative classification, for the experiments reported in Section 5. We next turn to presenting the two tested classifications. 3.1 Initial Classification In the acquisition experiments reported in Section 4, we distinguish between qualitative, intensional, and relational adjectives, which have the following properties (Miller 1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011). Qualitative adjectives. These are prototypical adjectives like gran (‘big’) or dol¸c (‘sweet’), including scalar adjectives, which denote attributes or properties of objects. Adjectives in this class tend to be gradable and comparable (see Examples (4a–4b)). They are characterized by exhibiting the greatest variability with respect to their syntactic behavior: In Catalan, they can act as predicates in copular sentences and other constructions (Examples (4c–4d)), and they can typically act as both pre- and post-nominal modifiers (Example</context>
<context position="22371" citStr="Miller 1998" startWordPosition="3326" endWordPosition="3327">Example (8c)). (8) a. ´Es un pats {exportador / #molt exportador} de petroli Is a country {exporting / very exporting} of oil ‘It is an oil exporting / #very exporting country’ b. #exportador pats ‘exporting country’ c. Aquest pats ´es exportador This country is exporting ‘This is an exporting country’ Table 2 summarizes the properties of the alternative classification (for a more thorough discussion of previous research on the semantics of adjectives and more motivation for the classification, see Boleda [2007]). For comparison, we will briefly outline the treatment of adjectives in WordNet (Miller 1998; Alonge et al. 2000). As Table 2 Alternative classification: Linguistic properties of qualitative, event-related, and relational adjectives. Qualitative Event-related Relational gran (‘big’) exportador (‘exporting’) pulmonar ‘pulmonary’ Property predicative + + restricted gradable/comparable + typically not − position with respect to both post-nom. post-nom. head noun adjacent − − + derivational type non-derived deverbal denominal 582 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives mentioned in Section 2, the main semantic relation around which adjectives a</context>
<context position="49783" citStr="Miller 1998" startWordPosition="7614" endWordPosition="7615">is issue and proposes different metrics and types of evaluation. We defer numerical evaluation until Section 5. 4.5 Discussion 4.5.1 Classification. The experiments presented provide feedback to the question, what is an appropriate broad semantic classification for adjectives? The clustering experiments provide empirical support for the qualitative and relational classes, as is particularly evident in the three-way solution (Table 5). These are classes that have traditionally been taken into account in descriptive grammar (Bally 1944; Picallo 2002) and computational resources such as WordNet (Miller 1998; Alonge et al. 2000), so we consider them to be quite stable and keep them in our classification. Intensional and IQ adjectives, in contrast, are grouped together with qualitative adjectives in all solutions, because they do not exhibit distinctive enough distributional properties to differentiate them, a fact aggravated by the small size of the intensional class. From the point of view of NLP, it is reasonable to encode intensional adjectives by hand, given their limited number. For these reasons, we include the intensional class in the qualitative class in what follows (remember that, as me</context>
</contexts>
<marker>Miller, 1998</marker>
<rawString>Miller, Katharine J. 1998. Modifiers in WordNet. In Christiane Fellbaum, editor, WordNet: an Electronic Lexical Database. The MIT Press, Cambridge, MA, pages 47–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>English as a formal language. In</title>
<date>1974</date>
<volume>6</volume>
<pages>188--221</pages>
<editor>Richmond H. Thomason, editor,</editor>
<publisher>Yale University Press,</publisher>
<location>New</location>
<contexts>
<context position="17483" citStr="Montague 1974" startWordPosition="2616" endWordPosition="2617">que than gran big ‘This table is bigger than that one’ c. Aquesta This ‘This table is big’ ´es is taula table gran big d. Aquesta taula la veig massa gran This table itOBJ-CL-FEM seepres−1stp−sg too big ‘This table seems to me to be too big’ e. La gran Diana va seguir cantant The great Diana PAST-AUX continue singing. ‘Great Diana continued singing.’ f. Van portar una taula gran PAST-AUX bring a table big ‘They brought in a big table’ Intensional adjectives. These are adjectives like presumpte (‘alleged’) or antic (‘former’), which according to formal semantics denote second-order properties (Montague 1974, and subsequent work). Most intensional adjectives modify nouns in pre-nominal position only (Example (5a)), and they cannot functionally act as predicates (Example (5b)). They are also typically not gradable (Example (5c)). (5) a. El Joan ´es el presumpte assassfmurderer The Joan is the alleged ‘Joan is the alleged murderer’ b. #El The presumpte alleged ‘#Joan is alleged’ Joan Joan ´es is c. #M´es presumpte assassfmurderer / #presumptfssim assassfmurderer More alleged / allegedSUPERLATIVE ‘#More/very alleged murderer’ Intensional adjectives like presumpte may appear in any order with respect</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard. 1974. English as a formal language. In Richmond H. Thomason, editor, Formal Philosophy: Selected Papers of Richard Montague. Yale University Press, New Haven, CT, chapter 6, pages 188–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory L Murphy</author>
</authors>
<title>The Big Book of Concepts.</title>
<date>2002</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6491" citStr="Murphy 2002" startWordPosition="954" endWordPosition="955">is to determine, for a given adjective, whether it is monosemous or polysemous, and to which class(es) it belongs. Note that we are not dealing with individual sense alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational semantics, however. This is surprising, given the amount of work devoted to sense-related tasks such as Word Sense Disambiguation (WSD). In WSD (see Navigli [2009] for an overview) sense ambiguities are almost exclusively modeled for each individual lemma, despite the ensuing sparsity problems (Ando [2006] is an exception). Properly modeling regular polysem</context>
</contexts>
<marker>Murphy, 2002</marker>
<rawString>Murphy, Gregory L. 2002. The Big Book of Concepts. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claude Nadeau</author>
<author>Yoshua Bengio</author>
</authors>
<title>Inference for the generalization error.</title>
<date>2003</date>
<booktitle>Machine Learning,</booktitle>
<volume>52</volume>
<issue>3</issue>
<contexts>
<context position="72836" citStr="Nadeau and Bengio (2003)" startWordPosition="11145" endWordPosition="11148">he class assignments of the remaining classifiers.7 For the evaluation, 100 different estimates of accuracy are obtained for each feature set using 10-run, 10-fold cross-validation (10x10 cv for short). In this schema, 10-fold cross-validation is performed 10 times, that is, 10 different random partitions of the data (runs) are made, and 10-fold cross-validation is carried out for each partition. To avoid the inflated Type I error probability when reusing data (Dietterich 1998), the significance of the differences between accuracies is tested with the corrected resampled t-test as proposed by Nadeau and Bengio (2003).8 5.4 Results 5.4.1 Simple Classifiers. The accuracies for the simple classifiers are shown in Table 10. Part A of the table lists the results for each of the binary decisions (qualitative/ non-qualitative, event/non-event, relational/non-relational). The accuracy for each decision is computed independently. For instance, a qualitative-event adjective is judged correct within the qualitative class iff the decision is qualitative; correct within the event class iff the decision is event; and correct within the relational class iff the decision is non-relational. Part B reports the accuracies f</context>
</contexts>
<marker>Nadeau, Bengio, 2003</marker>
<rawString>Nadeau, Claude and Yoshua Bengio. 2003. Inference for the generalization error. Machine Learning, 52(3):239–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<pages>41--10</pages>
<marker>Navigli, 2009</marker>
<rawString>Navigli, Roberto. 2009. Word sense disambiguation: A survey. ACM Computing Surveys, 41:10:1–10:69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Victor Raskin</author>
</authors>
<title>Ontological Semantics.</title>
<date>2004</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="54903" citStr="Nirenburg and Raskin 2004" startWordPosition="8377" endWordPosition="8380"> relationships to objects, and eventrelated adjectives denote relationships to events. The classes correspond to the three major types of entities in an ontology (attributes, objects, events), more specifically, to the way adjectives participate from those entities. In this view, relational and eventrelated adjectives denote properties, just as qualitative adjectives do, but they are a specific type of property involving a relationship with either an object or an event. The classification is in fact similar to the one proposed in the Ontological Semantics framework (Raskin and Nirenburg 1998; Nirenburg and Raskin 2004). Also note that the revised semantic classification bears a prominent relationship to morphology: In the default case, qualitative adjectives are not derived, eventrelated adjectives are deverbal, and relational adjectives are denominal. However, the correspondence between semantic classes and derivational type is not a one-to-one mapping. Although most event-related adjectives are deverbal, not only strictly deverbal adjectives evoke events: For instance, tangible ‘tangible’ evokes an event of touching, but there is no verb *tangir in Catalan (tangible is built on the Latin verb tang¯o, ‘tou</context>
</contexts>
<marker>Nirenburg, Raskin, 2004</marker>
<rawString>Nirenburg, Sergei and Victor Raskin. 2004. Ontological Semantics. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="10548" citStr="Pang and Lee 2008" startWordPosition="1558" endWordPosition="1561">a very useful cue for disambiguating the sense of the nouns they modify. Adjective classes could be further exploited in WSD in at least two respects: (1) to establish an inventory of adjective senses (if polysemous instances are correctly detected; this is where sense induction and our own work fits in), and (2) to exploit class-based properties for the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey much of the evaluative and subjective information in language (Wiebe et al. 2004). The typical goal of this kind of study has been to identify subjective adjectives and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) to current research (de Marneffe, Manning, and Potts 2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which can be translated into values that can be ordered</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, Bo and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, ACL ’93,</booktitle>
<volume>38</volume>
<pages>183--190</pages>
<location>Stroudsburg, PA.</location>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira, Fernando, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, ACL ’93, pages 183–190, Stroudsburg, PA. Computational Linguistics Volume 38, Number 3</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carme Picallo</author>
</authors>
<title>L’adjectiu i el sintagma adjectival.</title>
<date>2002</date>
<pages>1643--1688</pages>
<editor>In Joan Sol`a, editor, Gram`atica del catal`a contemporani. Emp´uries,</editor>
<location>Barcelona,</location>
<contexts>
<context position="15924" citStr="Picallo 2002" startWordPosition="2374" endWordPosition="2375">acing a highly exploratory endeavor, and we do not regard the classifications we use as final. We test two different classifications: an initial classification, based on the literature, for the experiments reported in Section 4, and an alternative classification, for the experiments reported in Section 5. We next turn to presenting the two tested classifications. 3.1 Initial Classification In the acquisition experiments reported in Section 4, we distinguish between qualitative, intensional, and relational adjectives, which have the following properties (Miller 1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011). Qualitative adjectives. These are prototypical adjectives like gran (‘big’) or dol¸c (‘sweet’), including scalar adjectives, which denote attributes or properties of objects. Adjectives in this class tend to be gradable and comparable (see Examples (4a–4b)). They are characterized by exhibiting the greatest variability with respect to their syntactic behavior: In Catalan, they can act as predicates in copular sentences and other constructions (Examples (4c–4d)), and they can typically act as both pre- and post-nominal modifiers (Examples (4e–4f)). When an adjective modifies a </context>
<context position="49726" citStr="Picallo 2002" startWordPosition="7606" endWordPosition="7607">chulte im Walde (2006) provides a thorough discussion of this issue and proposes different metrics and types of evaluation. We defer numerical evaluation until Section 5. 4.5 Discussion 4.5.1 Classification. The experiments presented provide feedback to the question, what is an appropriate broad semantic classification for adjectives? The clustering experiments provide empirical support for the qualitative and relational classes, as is particularly evident in the three-way solution (Table 5). These are classes that have traditionally been taken into account in descriptive grammar (Bally 1944; Picallo 2002) and computational resources such as WordNet (Miller 1998; Alonge et al. 2000), so we consider them to be quite stable and keep them in our classification. Intensional and IQ adjectives, in contrast, are grouped together with qualitative adjectives in all solutions, because they do not exhibit distinctive enough distributional properties to differentiate them, a fact aggravated by the small size of the intensional class. From the point of view of NLP, it is reasonable to encode intensional adjectives by hand, given their limited number. For these reasons, we include the intensional class in th</context>
</contexts>
<marker>Picallo, 2002</marker>
<rawString>Picallo, Carme. 2002. L’adjectiu i el sintagma adjectival. In Joan Sol`a, editor, Gram`atica del catal`a contemporani. Emp´uries, Barcelona, pages 1643–1688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Ron Artstein</author>
</authors>
<title>The reliability of anaphoric annotation, reconsidered: Taking ambiguity into account.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Frontiers in Corpus Annotations II: Pie in the Sky, CorpusAnno ’05,</booktitle>
<pages>76--83</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="32967" citStr="Poesio and Artstein (2005)" startWordPosition="4914" endWordPosition="4917"> in Section 3, including syntactic and semantic characteristics. The judges had a moderate degree of agreement, comparable to that obtained in other tasks on semantics or discourse, inter-annotator scores ranging between K = 0.54 and 0.64 (see Artstein and Poesio [2008] for a discussion of agreement measures for computational linguistics). For comparison, V´eronis (1998) reported a mean pair-wise weighted K = 0.43 for a word sense tagging task in French; and Merlo and Stevenson (2001) obtained K = 0.53–0.66 for the task of classifying English verbs as unergative, unaccusative, or object-drop. Poesio and Artstein (2005) report K values of 0.63–0.66 (0.45–0.50 if a trivial category is dropped) for the tagging of anaphoric relations. Our judges reported difficulties in tagging particular kinds of adjectives, such as deverbal adjectives. This issue will be retaken in Section 4.5. No intensional adjectives were identified in the data by the judges, and only one intensional-qualitative adjective was identified. Two intensional lemmata were manually added to be able to minimally track the class. This is clearly insufficient for a quantitative approach, however, so the intensional class is dropped in the alternativ</context>
</contexts>
<marker>Poesio, Artstein, 2005</marker>
<rawString>Poesio, Massimo and Ron Artstein. 2005. The reliability of anaphoric annotation, reconsidered: Taking ambiguity into account. In Proceedings of the Workshop on Frontiers in Corpus Annotations II: Pie in the Sky, CorpusAnno ’05, pages 76–83, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Detlef Prescher</author>
<author>Stefan Riezler</author>
<author>Mats Rooth</author>
</authors>
<title>Using a probabilistic class-based lexicon for lexical ambiguity resolution.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Conference on Computational Linguistics -Volume 2, COLING ’00,</booktitle>
<pages>649--655</pages>
<location>Stroudsburg, PA.</location>
<marker>Prescher, Riezler, Rooth, 2000</marker>
<rawString>Prescher, Detlef, Stefan Riezler, and Mats Rooth. 2000. Using a probabilistic class-based lexicon for lexical ambiguity resolution. In Proceedings of the 18th Conference on Computational Linguistics -Volume 2, COLING ’00, pages 649–655, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6587" citStr="Pustejovsky 1995" startWordPosition="966" endWordPosition="967">h class(es) it belongs. Note that we are not dealing with individual sense alternations, as related work on sense induction does (Sch¨utze 1998; McCarthy et al. 2004; Brody and Lapata 2009), but with sense alternation types, that systematically hold across different lemmata. Thus, the present research is at the crossroad between sense induction and lexical acquisition. Regularities in sense alternations are pervasive in human languages, and they are probably favored by the properties of human cognition (Murphy 2002). Regular polysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995) and in symbolic approaches to computational semantics (Copestake and Briscoe 1995). It has received little attention in empirical computational semantics, however. This is surprising, given the amount of work devoted to sense-related tasks such as Word Sense Disambiguation (WSD). In WSD (see Navigli [2009] for an overview) sense ambiguities are almost exclusively modeled for each individual lemma, despite the ensuing sparsity problems (Ando [2006] is an exception). Properly modeling regular polysemy, therefore, promises to improve computational semantic tasks such as WSD and sense discriminat</context>
<context position="13426" citStr="Pustejovsky 1995" startWordPosition="1999" endWordPosition="2000">enson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). There is very little related work in empirical computational semantics in modeling regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 “basic 578 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives types” (broad ontological categories). In CoreLex, each word is associated to a polysemy class, that is, the set of all basic types its synsets belong to. Some of these polysemy classes constitute instances of regular polysemy, as recently explored in Utt and Pad´o (2011). Lapata (2000, 2001) also addresses regular polysemy in the Generative Lexicon framework. This work attempts to establish all the possible meanings of adjective-noun combinations, and rank them using </context>
<context position="28491" citStr="Pustejovsky 1995" startWordPosition="4257" endWordPosition="4258">ective if it is for instance loud-colored or has an eccentric cut, such that it gains the attention of people, as shouting does. In this article, we only consider types of polysemy that cut across the classification pursued. Other kinds of polysemy that have traditionally been tackled in the literature will not be considered. For instance, we will not be concerned with the polysemy illustrated in Example (16), which arguably has more to do with the semantics of the 584 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives modified noun than that of the adjective (Pustejovsky 1995). Both of the uses of trist (‘sad’) illustrated in Example (16) fall into the qualitative class, so, contrary to the work by Lapata (2000, 2001) cited previously, we do not treat the adjective as polysemous in the context of the present experiments. (16) noi trist / pel·l´ıcula trista boy sad / film sad ‘sad boy / sad film’ 4. First Model: Polysemous Adjectives Constitute Independent Classes Given the hybrid behavior of polysemous adjectives explained in Section 3, we can expect that they behave differently from adjectives in the basic classes. For instance, adjectives polysemous between a qua</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>Pustejovsky, James. 1995. The Generative Lexicon. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="70798" citStr="Quinlan 1993" startWordPosition="10834" endWordPosition="10835">e believe that we have now reached a more stable classification, which we can test by supervised methods. In addition, we need a one-to-one correspondence between gold standard classes and clusters for the approach to work, which we cannot guarantee when using an unsupervised approach that outputs a certain number of clusters with no mapping to the gold standard classes. We test two types of classifiers. The first type are Decision Tree classifiers trained on different types of linguistic information coded as feature sets. Decision Trees are one of the most widely machine learning techniques (Quinlan 1993), and they have been used in related work (Merlo and Stevenson 2001). They have relatively few parameters to tune (a requirement with small data sets such as ours) and provide a transparent representation of the decisions made by the algorithm, which facilitates the inspection of results and the error analysis. We will refer to these Decision Tree classifiers as simple classifiers, in opposition to the ensemble classifiers, which are complex, as explained next. The second type of classifier we use are ensemble classifiers, which have received much attention in the machine learning community (D</context>
<context position="75009" citStr="Quinlan 1993" startWordPosition="11467" endWordPosition="11468">aking into account distributional information allows for an improvement over the default morphology–semantics mapping outlined in Section 4.5: Feature set all, containing all the features, achieves 75.5% accuracy for qualitative adjectives; feature set theor, with carefully defined features, achieves 86.4% for relational adjectives. In contrast, morphology seems to act as a ceiling for 7 The experiments discussed in this section were carried out with the Weka software package (Witten and Frank 2011), version 3.6. The Decision Tree algorithm used is J48, the latest open source version of C4.5 (Quinlan 1993), with default parameters (binary splits = False, confidence factor for pruning = 0.25, minimum number of instances per leaf = 2, reduced-error pruning = False, subtree raising = True, unpruned = False, use Laplace = False). AdaBoost has also been used with default parameters (base classifier = Decision Stump, number of iterations = 10, random seed = 1, use resampling instead of reweighting = False, weight threshold = 100). For Attribute Bagging, we used the Random Subspace algorithm, with J48 as base classifier (parameters as before), bag size = 1/3, and random seed = 1. We experimented with </context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, Ross. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joaquim Rafel</author>
</authors>
<title>Un corpus general de refer`encia de la llengua catalana.</title>
<date>1994</date>
<journal>Caplletra,</journal>
<pages>17--219</pages>
<contexts>
<context position="30769" citStr="Rafel 1994" startWordPosition="4588" endWordPosition="4589"> on the automatic semantic classification of adjectives. The present experiments also aim at testing the overall enterprise of inducing semantic classes from distributional properties for adjectives. Given the exploratory nature of the experiment, we use clustering, an unsupervised technique, to uncover natural groupings of adjectives and test to what extent these correspond to the classes described in the literature. 4.1 Data and Gold Standard The experiments reported in this section are based on an eight million word fragment of the CTILC corpus (Corpus Informatitzat de la Llengua Catalana; Rafel 1994), developed at the Institut d’Estudis Catalans. Each word is associated with its lemma, part of speech, and inflectional features, as well as syntactic function. Lemma and morphological information have been manually checked. We automatically added syntactic information with CatCG (Alsina et al. 2002). CatCG is a shallow parser that assigns one or more syntactic functions to each word. In the case of the adjective, CatCG distinguishes between (1) predicate of a copular sentence; (2) predicate in another construction; (3) pre-nominal modifier; (4) post-nominal modifier. As no full dependencies </context>
</contexts>
<marker>Rafel, 1994</marker>
<rawString>Rafel, Joaquim. 1994. Un corpus general de refer`encia de la llengua catalana. Caplletra, 17:219–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Raskin</author>
<author>Sergei Nirenburg</author>
</authors>
<title>An applied ontological semantic microtheory of adjective meaning for natural language processing.</title>
<date>1998</date>
<journal>Machine Translation,</journal>
<pages>13--2</pages>
<contexts>
<context position="5424" citStr="Raskin and Nirenburg 1998" startWordPosition="790" endWordPosition="793">eting / familiar face’ b. problema amor´os / noi amor´os problem loveSUFFIX/ boy loveSUFFIX ‘love problem / lovely boy’ The first senses in Examples (1) and (2) have a transparent relation to the denotation of the deriving noun, as witnessed by the fact that they are translated as nouns in English (economy, family, love), whereas the other senses are translated as adjectives (cheap, familiar, lovely). For each of these adjectives, there is a relationship between the two senses, such that the sense alternations seem to correspond to a productive semantic process along the lines of Example (3) (Raskin and Nirenburg 1998, schema (43), page 173). (3) PERTAINING TO [noun meaning] → CHARACTERISTIC OF [noun meaning] 576 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives Because of the systematic semantic relationship between the two senses of these adjectives, they constitute an instance of regular polysemy. In this article, therefore, we not only address the acquisition of semantic classes, but also the acquisition of polysemy: Our goal is to determine, for a given adjective, whether it is monosemous or polysemous, and to which class(es) it belongs. Note that we are not dealing w</context>
<context position="15910" citStr="Raskin and Nirenburg 1998" startWordPosition="2370" endWordPosition="2373">dressing (b). We are thus facing a highly exploratory endeavor, and we do not regard the classifications we use as final. We test two different classifications: an initial classification, based on the literature, for the experiments reported in Section 4, and an alternative classification, for the experiments reported in Section 5. We next turn to presenting the two tested classifications. 3.1 Initial Classification In the acquisition experiments reported in Section 4, we distinguish between qualitative, intensional, and relational adjectives, which have the following properties (Miller 1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011). Qualitative adjectives. These are prototypical adjectives like gran (‘big’) or dol¸c (‘sweet’), including scalar adjectives, which denote attributes or properties of objects. Adjectives in this class tend to be gradable and comparable (see Examples (4a–4b)). They are characterized by exhibiting the greatest variability with respect to their syntactic behavior: In Catalan, they can act as predicates in copular sentences and other constructions (Examples (4c–4d)), and they can typically act as both pre- and post-nominal modifiers (Examples (4e–4f)). When an adjecti</context>
<context position="52273" citStr="Raskin and Nirenburg 1998" startWordPosition="7994" endWordPosition="7997">tive features are defined here as those that are among the three features with highest or lowest mean values for at least three clusters in the five-way solution. 592 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives ‘Chinese’), and deverbal adjectives (indicador ‘indicating’, parlant ‘speaking’, protector ‘protecting, protective’, salvador ‘savior’). Ethnic adjectives can act as predicates of copular sentences in a much more natural way than typical relational adjectives, and seem to be vague between a relational and a qualitative reading in their semantics (Raskin and Nirenburg 1998, page 173). This kind of adjective will mainly be treated as polysemous in the experiments reported in Section 5. As for deverbal adjectives, they are clearly neither relational (they do not express a relationship to an object) nor intensional. They are also not typically qualitative, however, because they trigger a relationship to an event instead of denoting a simple property. For instance, protector triggers a relationship with a stable event of protecting in Example (18): A person named Serra belongs to the kind of associates who have as a primary role to protect the association. (18) Ser</context>
<context position="54875" citStr="Raskin and Nirenburg 1998" startWordPosition="8373" endWordPosition="8376">elational adjectives denote relationships to objects, and eventrelated adjectives denote relationships to events. The classes correspond to the three major types of entities in an ontology (attributes, objects, events), more specifically, to the way adjectives participate from those entities. In this view, relational and eventrelated adjectives denote properties, just as qualitative adjectives do, but they are a specific type of property involving a relationship with either an object or an event. The classification is in fact similar to the one proposed in the Ontological Semantics framework (Raskin and Nirenburg 1998; Nirenburg and Raskin 2004). Also note that the revised semantic classification bears a prominent relationship to morphology: In the default case, qualitative adjectives are not derived, eventrelated adjectives are deverbal, and relational adjectives are denominal. However, the correspondence between semantic classes and derivational type is not a one-to-one mapping. Although most event-related adjectives are deverbal, not only strictly deverbal adjectives evoke events: For instance, tangible ‘tangible’ evokes an event of touching, but there is no verb *tangir in Catalan (tangible is built on</context>
</contexts>
<marker>Raskin, Nirenburg, 1998</marker>
<rawString>Raskin, Victor and Sergei Nirenburg. 1998. An applied ontological semantic microtheory of adjective meaning for natural language processing. Machine Translation, 13(2-3):135–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="10355" citStr="Resnik 1993" startWordPosition="1532" endWordPosition="1533">kin to the acquisition of subcategorization frames for verbs. Another relevant line of research pursues WSD. Justeson and Katz (1995) and Chao and Dyer (2000) showed that adjectives are a very useful cue for disambiguating the sense of the nouns they modify. Adjective classes could be further exploited in WSD in at least two respects: (1) to establish an inventory of adjective senses (if polysemous instances are correctly detected; this is where sense induction and our own work fits in), and (2) to exploit class-based properties for the disambiguation, similar to related work on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban and Lee 2005). The application where adjectives have received most attention, however, is Opinion Mining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to convey much of the evaluative and subjective information in language (Wiebe et al. 2004). The typical goal of this kind of study has been to identify subjective adjectives and their orientation (positive, neutral, negative). This type of research, from pioneering work by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997; Hatzivassiloglou and Wiebe 2000) </context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Resnik, Philip. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via em-based clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, ACL ’99,</booktitle>
<pages>104--111</pages>
<location>Stroudsburg, PA.</location>
<contexts>
<context position="12986" citStr="Rooth et al. (1999)" startWordPosition="1934" endWordPosition="1937">ce, Information Extraction and ontology population, although to our knowledge this possibility has received but little attention (Malouf 2000; Almuhareb and Poesio 2004). As for polysemy, previous approaches to the automatic acquisition of semantic classes have mostly disregarded the problem, by biasing the experimental material to include monosemous words only, or by choosing an approach that ignores polysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis, Stevenson, and James 2008). There are a few exceptions to this tradition, such as Pereira, Tishby, and Lee (1993), Rooth et al. (1999), and Korhonen, Krymolowski, and Marx (2003), who used soft clustering methods for multiple assignment to verb semantic classes (see Section 4.5). There is very little related work in empirical computational semantics in modeling regular polysemy. A pioneering piece of research is Buitelaar (1998), which tried to account for regular polysemy with the CoreLex resource. CoreLex, building on the Generative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 “basic 578 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives types” (broad ontological categor</context>
<context position="99698" citStr="Rooth et al. 1999" startWordPosition="15462" endWordPosition="15465">asic classes. For instance, a qualitativerelational adjective is assumed to function both as a full-fledged qualitative adjective and a full-fledged relational adjective. By their very nature, polysemous words will show only some evidence for each of the classes, as their occurrences (and thus their properties) will be distributed across the two classes. Therefore, they will be untypical members of at least one of the intervening classes. 607 Computational Linguistics Volume 38, Number 3 An alternative instantiation of the second model could use soft clustering (Pereira, Tishby, and Lee 1993; Rooth et al. 1999; Korhonen, Krymolowski, and Marx 2003), which assigns a probability to each of the classes and is thus not bound to a hard yes/no decision, as our approach does. From a theoretical point of view (and for many practical purposes such as dictionary construction), however, a distinction between monosemous and polysemous words is desirable, which adds a further parameter to be optimized in a soft clustering setting. Overlapping clustering (Banerjee et al. 2005), which allows for membership in multiple clusters, avoids this difficulty. Both methods have the advantage that they do not assume indepe</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Rooth, Mats, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via em-based clustering. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, ACL ’99, pages 104–111, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Sanrom`a</author>
<author>Gemma Boleda</author>
</authors>
<title>The database of Catalan adjectives.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh Conference on International Language Resources and Evaluation, LREC ’10,</booktitle>
<location>Valletta.</location>
<marker>Sanrom`a, Boleda, 2010</marker>
<rawString>Sanrom`a, Roser and Gemma Boleda. 2010. The database of Catalan adjectives. In Proceedings of the Seventh Conference on International Language Resources and Evaluation, LREC ’10, Valletta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Boostexter: A boosting-based system for text categorization.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="59927" citStr="Schapire and Singer 2000" startWordPosition="9140" endWordPosition="9143">semous 594 Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives adjectives: the fact that they are used predominantly in one of their senses, and the fact that the feature distributions of “polysemous classes” largely overlap with those of the basic classes. In the present experiments, we develop an alternative approach to regular polysemy that is based on the perspective that polysemous adjectives belong to more than one semantic class, in the framework of multi-label classification. A typical example of a multi-label classification task is Text Categorization (Schapire and Singer 2000), where a document can be described via more than one label (e.g., Health and Local), so that it effectively belongs to more than one of the target classes. The motivation for this new approach is the fact that polysemous adjectives exhibit properties of all the classes involved (see Section 3.3). The hypothesis is that the evidence found for a polysemous adjective that is polysemous between, say, a relational and a qualitative use should be strong enough for the adjective to be assigned to both the relational and the qualitative classes. Note that by assigning the adjective to the two classes</context>
<context position="69688" citStr="Schapire and Singer 2000" startWordPosition="10659" endWordPosition="10662">t-related or not? Is it relational or not? 2. A complete classification is achieved by merging the results of the binary decisions. A consistency check is applied by which (a) if all decisions are negative, the adjective is assigned to the qualitative class (the most frequent one; this was the case for a mean of 4.6% of the class assignments); (b) if all decisions are positive, we randomly discard one (three-way polysemy is not foreseen in our classification; this was the case for a mean of 0.6% of the class assignments). This is the standard architecture for multi-label classification tasks (Schapire and Singer 2000; Ghamrawi and McCallum 2005), and it has also been applied to NLP problems such as entity extraction and noun-phrase chunking (McDonald, Crammer, and Pereira 2005). Note that in the present experiments we change both the classification and the approach (unsupervised vs. supervised) with respect to the first set of experiments presented in Section 4, which can be seen as a sub-optimal technical choice. After the first series of experiments that required a more exploratory analysis, however, we believe that we have now reached a more stable classification, which we can test by supervised method</context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>Schapire, Robert E. and Yoram Singer. 2000. Boostexter: A boosting-based system for text categorization. Machine Learning, 39(2-3):135–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>Experiments on the automatic induction of German semantic verb classes.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<marker>Walde, Sabine, 2006</marker>
<rawString>Schulte im Walde, Sabine. 2006. Experiments on the automatic induction of German semantic verb classes. Computational Linguistics, 32(2):159–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Sch¨utze, Hinrich. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Utt</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Ontology-based distinction between polysemy and homonymy.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics, IWCS ’11,</booktitle>
<pages>265--274</pages>
<location>Stroudsburg, PA.</location>
<marker>Utt, Pad´o, 2011</marker>
<rawString>Utt, Jason and Sebastian Pad´o. 2011. Ontology-based distinction between polysemy and homonymy. In Proceedings of the Ninth International Conference on Computational Semantics, IWCS ’11, pages 265–274, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Verbs and times.</title>
<date>1957</date>
<journal>The Philosophical Review,</journal>
<pages>66--143</pages>
<contexts>
<context position="88348" citStr="Vendler 1957" startWordPosition="13652" endWordPosition="13653">ce of the event class (see dark-gray shaded cells); other types, such as -ble, -iu, or -nt, are more spread in their distribution (see light-gray shaded cells). Thus, the suffix seems to influence the resulting readings, with some active-like suffixes building a much more transparent relation to the event (creador ‘creating’, exportador ‘exporting’, recomanat ‘recommended’), and some passive-like or stative suffixes being more prone to creating a stative meaning (contingent ‘contingent’, formidable ‘formidable I terrific’, significatiu ‘significant’). The aspectual class of the deriving verb (Vendler 1957) also plays a role: For instance, although the meaning of abundant (‘abundant’) is related to that of the verb abundar (‘abound’), it clearly has a more stative (property-like) meaning than many of the other event adjectives, due to the fact that the deriving verb is stative. Correspondingly, Figure 3 Derivational types in the qualitative (Q) and event-related (E) classes. The bars represent the classes, and the colors the derivational types, as shown in the legend. 603 Computational Linguistics Volume 38, Number 3 Table 13 Contingency table of the most frequent deverbal suffixes (rows) and cl</context>
</contexts>
<marker>Vendler, 1957</marker>
<rawString>Vendler, Zeno. 1957. Verbs and times. The Philosophical Review, 66:143–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean V´eronis</author>
</authors>
<title>A study of polysemy judgements and inter-annotator agreement.</title>
<date>1998</date>
<booktitle>In Programme and Advanced Papers of the Senseval Workshop,</booktitle>
<pages>2--4</pages>
<location>Herstmonceux Castle.</location>
<marker>V´eronis, 1998</marker>
<rawString>V´eronis, Jean. 1998. A study of polysemy judgements and inter-annotator agreement. In Programme and Advanced Papers of the Senseval Workshop, pages 2–4, Herstmonceux Castle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Verzani</author>
</authors>
<title>Using R for Introductory Statistics. Chapman &amp; Hall/CRC,</title>
<date>2005</date>
<location>Boca Raton, FL.</location>
<contexts>
<context position="37332" citStr="Verzani 2005" startWordPosition="5592" endWordPosition="5593">e 1 shows that the predictions just outlined are met to a large extent, showing that the empirical (corpus) data support the theoretical predictions. This graph represents the value distribution of each feature in the form of boxplots. In the boxplots, the rectangles have three horizontal lines, representing the first quartile, the median, and the third quartile, respectively. The dotted line at each side of the rectangle stretches to the minimum and maximum values, at most 1.5 times the length of the rectangle. Values that are outside this range are represented as points and termed outliers (Verzani 2005). Note that the scale in Figure 1 does not range from 0 to 1; this is because the data are standardized, as will be explained subsequently. Table 3 Theoretical features. The mean and SD values are computed on all clustered adjectives. Feature copular accounts for predicative constructions with the copula verbs ser, estar (‘be’). Feature predicative accounts for other predicative constructions, such as Example (4d). Feature Textual correlate Mean SD gradable degree adverbs, degree suffixation comparable comparative constructions copular copular predicate syntactic tag predicative predicate synt</context>
</contexts>
<marker>Verzani, 2005</marker>
<rawString>Verzani, John. 2005. Using R for Introductory Statistics. Chapman &amp; Hall/CRC, Boca Raton, FL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Janyce M Wiebe</author>
</authors>
<location>Theresa Wilson,</location>
<marker>Wiebe, </marker>
<rawString>Wiebe, Janyce M., Theresa Wilson,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<marker>Bruce, Bell, Martin, 2004</marker>
<rawString>Rebecca Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Computational Linguistics, 30(3):277–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2011</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>Amsterdam,</location>
<note>3rd edition.</note>
<contexts>
<context position="74900" citStr="Witten and Frank 2011" startWordPosition="11447" endWordPosition="11450">e discussion that follow refer to full accuracy unless otherwise stated. For the qualitative and relational classes, taking into account distributional information allows for an improvement over the default morphology–semantics mapping outlined in Section 4.5: Feature set all, containing all the features, achieves 75.5% accuracy for qualitative adjectives; feature set theor, with carefully defined features, achieves 86.4% for relational adjectives. In contrast, morphology seems to act as a ceiling for 7 The experiments discussed in this section were carried out with the Weka software package (Witten and Frank 2011), version 3.6. The Decision Tree algorithm used is J48, the latest open source version of C4.5 (Quinlan 1993), with default parameters (binary splits = False, confidence factor for pruning = 0.25, minimum number of instances per leaf = 2, reduced-error pruning = False, subtree raising = True, unpruned = False, use Laplace = False). AdaBoost has also been used with default parameters (base classifier = Decision Stump, number of iterations = 10, random seed = 1, use resampling instead of reweighting = False, weight threshold = 100). For Attribute Bagging, we used the Random Subspace algorithm, w</context>
<context position="79525" citStr="Witten and Frank (2011" startWordPosition="12221" endWordPosition="12224">ctively, jumping to 52.9% and 52.3% when feature selection is used, still not enough to achieve a significant improvement over the baseline. Thus, for this task and this set-up, it is necessary to use well motivated features. In this respect, it is also remarkable that feature selection actually decreased performance for the motivated distributional feature sets (func, sem, all; results not shown in the table), and only slightly improved over morph (59.9% to 60.6% accuracy). Carefully defined features are of high quality and therefore do not benefit from automatic feature selection. Actually, Witten and Frank (2011, page 308) state that “the best way to select relevant attributes is manually, based on a deep understanding of the learning problem and what the [features] actually mean.” In the partial evaluation condition, however, all feature sets achieve a highly significant improvement over the baseline (p &lt; 0.001). Therefore, the classifications obtained with any of the feature sets are more useful than the baseline, in the sense that they present more overlap with the gold standard. 5.4.2 Ensemble Classifiers. Error analysis on the results using simple classifiers (not reported for space reasons) rev</context>
</contexts>
<marker>Witten, Frank, 2011</marker>
<rawString>Witten, Ian H. and Eibe Frank. 2011. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, Amsterdam, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy Yallop</author>
<author>Anna Korhonen</author>
<author>Ted Briscoe</author>
</authors>
<title>Automatic acquisition of adjectival subcategorization from corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>614--621</pages>
<location>Stroudsburg, PA.</location>
<marker>Yallop, Korhonen, Briscoe, 2005</marker>
<rawString>Yallop, Jeremy, Anna Korhonen, and Ted Briscoe. 2005. Automatic acquisition of adjectival subcategorization from corpora. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL ’05, pages 614–621, Stroudsburg, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>