<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.581004" genericHeader="abstract">
ABSTRACTS OF CURRENT LITERATURE
</sectionHeader>
<bodyText confidence="0.536433">
Technical Reports University of Rochester Computer Science Department 1988-1990
Listed below are the abstracts of our recent natural language technical reports. There is a nominal charge for each report.
The fee is waived for libraries in nonprofit, educational institutions and for institutions with which we have exchange
agreements. To order, send your request with a check (made payable to the University of Rochester) to:
TR Librarian
</bodyText>
<affiliation confidence="0.8370585">
Computer Science Dept.
734 Computer Studies Building
University of Rochester
Rochester, NY, 14627, USA
</affiliation>
<bodyText confidence="0.826228818181818">
Alternatively, send e-mail to tr@cs.rochester.edu, and we will include a bill with your TR(s).
TR 271 Existing plan-based theories of speech act interpretation do not account
Two Constraints on Speech Act Ambiguity for the conventional aspect of speech acts. We use patterns of linguistic
Hinkelman, E. A. and Allen J. F. features (e.g., mood, verb form, sentence adverbials, thematic roles) to
April 1989, 30 pages, $1.25 suggest a range of speech act interpretations for the utterance. These are
filtered using plan-based conversational implicatures to eliminate
inappropriate ones. Extended plan reasoning is available but not
necessary for familiar forms. Taking speech act ambiguity seriously,
with these two constraints, explains how Can you pass the salt? is
a typical indirect request while Are you able to pass the salt? is
not.
</bodyText>
<figure confidence="0.59164">
TR 288
Linguistic and Pragmatic Constraints on
Utterance Interpretation
Hinkelman, E. A.
Ph.D. Thesis, May 1990, 159 pages, $5.25
</figure>
<bodyText confidence="0.999463391304348">
To model how people understand language, it becomes necessary to
understand not only grammar and logic, but also how people use
language to affect their environment. This area of study is known as
natural language pragmatics. Speech acts, for instance, are the offers,
promises, announcements, and so on that people make by talking. The
same expression may be different acts in different contexts, and yet not
every expression performs every act. We want to understand how people
are able to recognize each other&apos;s intentions and implications in saying
something. Previous plan-based theories of speech act interpretation do
not account for the conventional aspect of speech acts. They can,
however, be made sensitive to both linguistic and propositional
information. This document presents a method of speech act
interpretation that uses patterns of linguistic features (e.g., mood, verb
form, sentence adverbials, thematic roles) to identify a range of speech
act interpretations for the utterance. These are then filtered and
elaborated by inferences about agents, goals, and plans. In many cases
the plan reasoning consists of short, local inference chains (that are in
fact conversational implicatures), and extended reasoning is necessary
only for the most difficult cases. The method is able to accommodate a
wide range of cases, from those that seem very idiomatic to those that
must be analyzed using knowledge about the world and human behavior.
It explains how Can you pass the salt? can be a request while Are you
able to pass the salt? is not.
</bodyText>
<figure confidence="0.377261235294118">
Computational Linguistics Volume 16, Number 4, December 1990 247
Abstracts of Current Literature
TR 298
The RHET Plan Recognition System,
Version 1.0
Miller, B. W.
Jan. 1990, 50 pages, $2.00
TR 317
The Discourse System Project
Allen, J. F., Guez, S., Hoebel, L. J.,
Hinkelman, E. A., Jackson, K. J., Kyburg,
A. I., and Traum, D. R.
Nov. 1989, 82 pages, $3.25
TR 324
ARMTRAK: A Domain for the Unified
Study of Natural Language, Planning, and
Active Vision
</figure>
<figureCaption confidence="0.2124065">
Martin, N. G., Allen, J. F., and Brown, C. M.
Jan. 1990, 43 pages, $2.00
</figureCaption>
<bodyText confidence="0.944346762711865">
TR 345
An Episodic Knowledge Representation for
Narrative Texts
Schubert, L. K. and Hwang, C. H.
May 1990, 53 pages, $2.25
RPRS is a hierarchial plan recognition system built within the RHET
knowledge representation system. It provides a powerful system for plan
recognition based on the algorithms of Kautz with the general reasoning
capabilities of RHET. RPRS takes special advantage of RHET&apos;s type
relations, constraints, equality and contextual reasoning abilities. It is
also intended as a demonstration of the RHET programming and
knowledge representation systems hybrid reasoning capabilities.
Utilizing the Lisp interface to Rhet, RPRS allows the user to use the
Rhet-structured—type system to build plan types, and given some
observation or set of observations have RHET derive the set of plans that
are consistent with these observations. Since RPRS includes the
TEMPOS specialized reasoner for RHET, steps and observations can
have reference to time intervals, and/or be temporally constrained with
respect to one another.
There has been significant work in the last decade on the processing of
discourse for modeling two-person extended dialogues, story and text
understanding, and extended question answering systems. While there
has been important progress in the use of world knowledge in language
interpretation, the use of plan-based models of language (e.g., speech act
planning), models of reference and focus, and models of discourse
structure itself, work in each area has not been related to work in the
other areas. No one has determined how individual processing
techniques can be combined to form a fully functional discourse system.
Some suggestions on the organization of discourse have arisen recently,
and while showing promise, have not been explored in enough detail for
an actual application. This report describes an architecture for discourse
systems that allows the integration of many different processing
modules. It also describes an initial set of modules that have been
implemented and tested using the architecture.
ARMTRAK is a micro-world, based on the control of model trains,
designed to integrate work in natural language, planning, vision, and
robotics. The primary advantage of the domain is that it provides
examples that involve few objects but require sophisticated analysis.
Because they involve few objects, the complex reasoning required is not
intractable. On the other hand, more objects can be introduced to study
techniques for tractable reasoning. Simple and complex examples in the
same domain allow work at different levels to take place simultaneously.
As a planning domain, ARMTRAK allows exercising planners in a
real-time domain about which the planner has only imperfect
knowledge. As a domain for natural language research, it allows
research into the grounding of language in real situations and the
problem of coordinating the behavior of agents through language. As a
domain for active vision research, it is challenging because it requires
extracting information whose parameters cannot be completely specified
beforehand. Two implementations of ARMTRAK have been developed:
a simulation and a version using the Rochester Robot. The simulation
allows work on real-time planning, and a robot version shows the
feasibility of a real &apos;working system based on model trains.
We would like to build story understanding systems that are transparent,
modular, and extensible. To this end, we have been working on a new
logical approach to narrative understanding that features a GPSG-style
grammar and an episodic logic with probabilistic inference rules. The
grammar represents phrase structure and the relationship between
phrase structure and logical form in a modular, explicit form. The
</bodyText>
<page confidence="0.868744">
248 Computational Linguistics Volume 16, Number 4, December 1990
</page>
<subsectionHeader confidence="0.95604">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999862142857143">
logical representation allows propositional attitudes, unreliable
generalizations, and other nonstandard constructs, providing a uniform,
transparent knowledge representation for both the explicit content of
stories and for the background knowledge needed to understand them. It
makes systematic use of episodic variables in the representation of
episodic sentences, using these to capture temporal and causal
relationships. The rules of inference include probabilistic versions of
deduction rules resembling forward and backward chaining rules in
expert systems. These can be used for predictive, explanatory, and
simulative inference. We illustrate our approach with nontrivial
grammar fragments (including semantic rules), and with an extended
example of forward-chaining inference based on a sentence from Little
Red Riding Hood. A pilot implementation is able to make many (though
not all) of the inferences we describe.
</bodyText>
<equation confidence="0.3502214">
TR 346
Semantic Nets Are in the Eye of the
Beholder
Schubert, L. K.
May 1990, 13 pages, $1.00
</equation>
<bodyText confidence="0.971999230769231">
The term semantic nets, in its broadest sense, has become virtually
meaningless. It is applied to systems that, as a class, lack distinctive
representational and computational properties vis-à-vis other knowledge
representation (KR) schemes. This terminological problem is not due to
lack of substance or coherence of work done under the semantic net
banner. Rather, it is due to convergence of the major KR schemes: the
representational and computational strategies employed in semantic net
systems are abstractly equivalent to those employed in virtually all
state-of-the-art systems incorporating a substantial propositional
knowledge base, whether they are described as logic-based, frame-based,
rule-based, or something else. In particular, I will argue that using a
graph-theoretic propositional representation does not automatically
distinguish it from others: even sets of PC formulas, abstractly viewed,
are graphs. Nor is proximity-based inference (using graph-theoretic
distance) automatically distinctive, since even resolution strategies (with
reasonable indexing schemes) are proximity-based in the abstract; nor its
hierarchic property inheritance any longer distinctive, given its
availability in state-of-the-art logic-based, frame-based, and rule-based
systems. So I urge some more restrictive, and hence more meaningful
use of the term semantic nets than is the current practice.
The following new papers are available on request from:
The Technical Report Librarian Centre for Cognitive Science
University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW Scotland, UK
EUCCS/RP-26
</bodyText>
<subsectionHeader confidence="0.534598">
Grammar Frameworks
Klein, Ewan
</subsectionHeader>
<bodyText confidence="0.5542392">
December 1988,45 pages, $1.50
EUCCS/RP-27
Autonomy, Implementation and Cognitive
Architecture: A Reply to Fodor and
Pylyshyn
</bodyText>
<subsubsectionHeader confidence="0.286011">
Chater, Nick and Oaksford, Mike
</subsubsectionHeader>
<bodyText confidence="0.992305285714286">
April 1989, 20 pages, 750
This paper provides a brief overview of the main developments in recent
work on grammatical frameworks, covering transformational,
&amp;quot;monostratal,&amp;quot; lexicalist, and unification-based approaches. Among the
topics touched on are syntax-semantics interaction, the interpretation of
grammar formalisms, the lexicon, grammar and computation, and some
prospects for future research in the area. An extensive bibliography is
provided.
Fodor and Pylyshyn (1988) claim that the current inability of
connectionism to deal with structured representations makes it
inappropriate as a theory of cognitive architecture. This poses an
important challenge to the new technology. That many connectionists
are attempting to address this issue suggests that a commitment to the
need for structured representation does not separate connectionist and
</bodyText>
<figure confidence="0.720398714285714">
Computational Linguistics Volume 16, Number 4, December 1990 249
Abstracts of Current Literature
EUCCS/RP-28
Choosing Computational Architectures for
Text Processing
Stenning, Keith and Oaksford, Mike
April 1989, 36 pages, $1.75
</figure>
<bodyText confidence="0.9999817">
classicist as Fodor and Pylyshyn claim. We identify the issue of
computational and explanatory autonomy of cognitive and
implementational levels as the substantive dispute between connectionist
and classicist. This diagnosis is born out in Fodor and Pylyshyn&apos;s
discussion of the &amp;quot;lures&amp;quot; of connect ionism which are typically taken to
challenge the classicist position. Fodor and Pylshyn believe that the lures
are, in principle, quite compatible with the classicist autonomy
assumption. However, we argue in detail that the classicist has yet to
adequately meet this challenge, in practice. Moreover, we adduce
arguments concerning the nature of nondemonstrative inference,
especially default reasoning, which strongly suggest that the classicist&apos;s
task is impossible, in principle.
In this paper we investigate various criteria that bear on the choice of
computational architectures for text processing. The principle role of the
computational or cognitive architecture is to provide mechanisms for
inference. In the study of text processing two forms of inference are
fundamental, (i) the implicit elaborative inferences required for
interpretation and (ii) explicit inferences that can be the subject of a
text. We suggest that the decision of what architecture to employ in
accounting for these inferential modes cannot be made a priori. We
argue that classical cognitive architectures based on logic and proof
theory although eminently suited to (ii) fail to provide tractable theories
of (i), while more recent proposals like PDP (Rumelhart and
McClelland, 1986) and classifier systems (Holland, Holyoak, Nisbett
and Thagard, 1986), seem to offer new insights into (i) while leaving (ii)
untouched. We examine the computational issues involved in a review of
recent candidate architectures beginning at one extreme with Prolog,
going through ACT and Classifier systems, ending with PDP. We then
examine the empirical work from verbal reasoning tasks involving
conditional and syllogistic reasoning in arguing that the grounds upon
which to choose between architectures are largely a posteriori and
empirical and moreover indicate that satisfactory explanations of this
data must invoke both (i) and (ii). In the process we shall proffer novel
interpretations both of conditional reasoning experiments as being
largely inductive (and hence of scant relevance to assessing our facility
for logical thought) and of Johnson-Laird&apos;s theory of syllogisms as
providing a heuristic theorem prover along the lines of any other
practical implementation of logic. We believe that this allows the
explanatory burden for a lot of this data to be correctly located at the
implementation rather than the cognitive level.
</bodyText>
<figure confidence="0.610826333333333">
EUCCS/RP-29
Connectionism, Classical Cognitive Science
and Experimental Psychology
Oaksford, Mike, Chater, Nick, and Stenning,
Keith
April 1989, 22 pages, 750
</figure>
<bodyText confidence="0.999026461538462">
Classical symbolic computational models of cognition are at variance
with the empirical findings in the cognitive psychology of memory and
inference. Standard symbolic computers are well suited to remembering
arbitrary lists of symbols and performing logical inferences. In contrast,
human performance on such tasks is extremely limited. Standard models
do not easily capture content-addressable memory or context-sensitive
defeasible inference, which are natural and effortless for people. We
argue that connectionism provides a more natural framework in which to
model human cognition. In addition to capturing the gross human
performance profile, connectionist systems seem well suited to
accounting for the systematic patterns of errors observed in the human
data. We take these arguments to counter Fodor and Pylyshyn&apos;s (1988)
recent claim that connectionism is in principle irrelevant to psychology.
</bodyText>
<page confidence="0.721808">
250 Computational Linguistics Volume 16, Number 4, December 1990
</page>
<figure confidence="0.497507">
Abstracts of Current Literature
EUCCS/RP-30
A Note on Multiple VP Ellipsis
Klein, Ewan and Stainton-Ellis, Kate
April 1989, 7 pages, 500
EUCCS/RP-31
</figure>
<figureCaption confidence="0.436825">
Devlin on Information and Cognition
Seligman, Jerry and Chater, Nick
May 1989, 16 pages, 75¢
</figureCaption>
<bodyText confidence="0.9990175">
This squib draws attention to the phenomenon of multiple VP ellipsis, as
illustrated in the following example:
&amp;quot;If you work hard, make the right choices and keep your nose clean,
you get ahead. If you don&apos;t, you don&apos;t.&amp;quot;
We present a taxonomy of such data, pointing out that they are
somewhat less rare than one might have expected. We also suggest, as a
consequence, that the resolution problem for ellipsed VPs is potentially
as complex as that required for nominal anaphora.
Dretske (1981) and Barwise and Perry (1983) both aim to provide a
naturalized theory of meaning and information. In his new book, Logic
and Information, Keith Devlin hints at various connections between the
two. In particular, he suggests that the individuation of the primitives of
situation theory—objects, locations and relations—can be explained
using Dretske&apos;s distinction between information carried in analog and
digital form. Since situation theory claims to be a general theory of
information, it should be able to express Dretske&apos;s distinction. This raises
the possibility of situation theory being able to explain the individuation
of its own primitives. We conclude that if the ontological burden is to be
shifted, then the situation theoretic notion of constraint, rather than that
of object and relation, must take the weight. In the second half of the
paper, we examine more thoroughly the claim the analog/digital
distinction is sufficient to capture the process by which an agent
individuates the world into categories suitable for cognitive activity. We
note that Dretske&apos;s account of the distinction between cognitive and
noncognitive activity is relative to a number of factors that must be
captured by an adequate situation theoretic treatment.
</bodyText>
<figure confidence="0.9933161">
EUCCS/RP-32
Intensionality, Boundedness, and Modal
Logic
Morrill, Glyn
May 1989, 16 pages, 750
EUCCS/RP-33
Partiality and Coherence in Concept
Combination
Myers, Terry, Franks, Bradley, and Braisby,
Nick
</figure>
<figureCaption confidence="0.847448">
March 1989. 19 pages, 750
</figureCaption>
<bodyText confidence="0.999910961538461">
In order to characterize facts about locality, the study of syntax has led
to the hypothesis of boundaries and bounded domains. But from the
point of view of semantics, domains already exist in the form of
intensional domains. The question arises as to whether intensionality, a
necessary feature of semantic theory, in fact also provides appropriate
terms of reference for syntactic description.
The paper presents the associative Lambek calculus and observes that
while this provides a characterization of discontinuity phenomena, it
fails to capture the idea of locality, e.g. it does not distinguish between
relativization, which is unbounded, and reflexivization, which is
bounded. We present an intensionalisation of the Lambek calculus, and
show that this provides a handle in terms of which the boundedness of
reflexivization can be expressed. It is then further argued that while the
combinatorics of the Lambek calculus correspond to implicational linear
logic, the intensionalised calculus corresponds to a modal logic, i.e., the
logical character of intensional types is the logic of necessity.
This paper explores the possibility for accounts of the semantic content
of lexical entries to respect current arguments concerning coherence. We
begin by outlining the tension that exists between the twin requirements
on meaning, specificity, and flexibility. Then we consider the positions
that we believe are characterized by Clark&apos;s (1983) description, &amp;quot;sense
selection.&amp;quot; In considering coherence in sense selection approaches, we
rely heavily on Murphy and Medin&apos;s (1985) arguments. We claim that
their arguments in favor of a theory determined account of coherence
lead to the rejection of the sense selection view. We then outline our own
position, one we call sense generation. We argue that specificity and
</bodyText>
<figure confidence="0.8986862">
Computational Linguistics Volume 16, Number 4, December 1990 251
Abstracts of Current Literature
EUCCS/RP-34
Grammar as Logic
Morrill, Glyn
July 1989, 16 pages, 75¢
EUCCS/RP-35
How the Laws of Thought Lie
Oberlander, Jon
July 1989, 27 pages, $1.00
</figure>
<bodyText confidence="0.982011939393939">
flexibility suggest that lexical concepts must be treated as quite specific,
yet partial objects. Such lexical concepts may be extended, that is,
features may be added or denied, relative to constraints provided by local
theories. Such a position divorces coherence from issues of metaphysics
and allows for the suggestion that the process of &amp;quot;using words to mean&amp;quot;
is intrinsically perspectival. Following on from this general outline, we
briefly discuss two views consonant with this position: Braisby (1989)
and Franks (1989). We illustrate these by considering examples of
concept combination, such as &amp;quot;stone lion,&amp;quot; &amp;quot;attractive dancer,&amp;quot; and
&amp;quot;adoptive mother.&amp;quot;
The notion of &amp;quot;parsing as deduction&amp;quot; appears to presuppose that of
&amp;quot;grammar as logic,&amp;quot; though in fact the former has largely involved
embedding grammars in logics using a fragment conducive to
theorem-proving. It is well known that categorial grammars take the
form of implicational logics; in this case the grammar is not embedded,
but simply is a logic The paper argues that many further operations
may be added to such a grammar, the result having close relations with
linear logic. Thus categorical grammar emerges as the implicational
fragment of a much more general logical grammar. A Prolog
implementation illustrates applications to polymorphism, optionality,
intensionality, bounded and unbounded extraction, and coordination
reduction.
The paper explores the relevance for knowledge representation of Nancy
Cartwright&apos;s views on the organization of scientific theories.
Correspondences between different types of scientific laws and KR&apos;s
default rules are established, focusing on a distinction between
phenomenal and fundamental laws. The tradeoff between truthfulness
and usefulness present in scientific laws allows a new perspective on the
KR tradeoff, and differing types of explanation in science carry over into
KR. The crucial role of approximation in scientific inference suggests a
specific type of knowledge organization, based on the notion of
simulacra.
EUCCS/RP-36
</bodyText>
<subsectionHeader confidence="0.703929">
Processing Extractions without Gaps
Pickering, Martin and Barry, Guy
September 1989, 20 pages, 50¢
</subsectionHeader>
<bodyText confidence="0.462498666666667">
EUCCS/RP-37
Generating Recipes: An Overview of
Epicure
</bodyText>
<subsectionHeader confidence="0.669193">
Dale, Robert
</subsectionHeader>
<bodyText confidence="0.9882174">
November 1989,26 pages, $1.00
Most psycholinguist ic theories have traditionally made use of the
transformational grammar notions of filler and gap in explaining the
processing of constructions involving extraction. On the assumption that
recursive nesting of dependencies must ultimately cause processing
difficulty, we show that standard analyses using gaps make incorrect
predictions for a class of sentences involving pied-piping (and that
alternative analyses using gaps are deficient in other respects). From this
we argue that the processor establishes dependency relations between
filler and subcateg,orizer rather than between filler and gap, and
demonstrate that the use of a theory of syntax without gaps, such as a
flexible categorial grammar, yields a more appropriate processing model.
We show how this approach can be used to describe the processing of
center-embedded constructions, and integrated with experimental results
on long-distance dependencies.
This paper describes the overall architecture and operation of Epicure, a
natural language generation system that embodies the view that a
discourse can be generated on the basis of a plan, and expanded to a level
of detail commensurate with the knowledge of the hearer, resulting in
the generation of a structured discourse. The paper shows how the
</bodyText>
<page confidence="0.754099">
252 Computational Linguistics Volume 16, Number 4, December 1990
</page>
<subsectionHeader confidence="0.840925">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.878498">
various components that make up the system contribute to the
achievement of this goal.
</bodyText>
<table confidence="0.298310928571429">
EUCCS/RP-38
Prosodic Morphology and
Constraint-Based Phonology
Bird, Steven
June 1990,28 pages, $1.00
EUCCS/RP-39
Sense Generation or How to Make the
Mental Lexicon Flexible
Franks, Bradley and Braisby, Nick
June 1990, 12 pages, 50¢
EUCCS/RP-40
Nominal Tense Logic
Blackburn, Patrick
June 1990, 18 pages, 65¢
</table>
<bodyText confidence="0.999759392156863">
Unification-based grammar formalisms have been employed in the
analysis of a vast range of syntactic and semantic phenomena.
Applications to morphological and phonological domains have proceeded
at a slower pace, largely because they have taken phonological
representation to be linear. This is in stark contrast with the
developments in the phonology literature over at least the last decade,
where many have proposed the adoption of multilinear (or nonlinear)
representations. The chief purpose of this paper is to reconcile this
difference, by showing how complex hierarchical phonological structures
may be represented using the descriptive vocabulary of a
unification-based grammar formalism. A complementary goal is to
advocate the use of computationally interpretable theories of phonology,
because of the increased theoretical and empirical rigor such a shift will
bring to the domain.
A unification-based approach (formalized in a decidable subset of
classical first-order logic) is used in the representation of prosodic
structure, where syllables are composed of moras which in turn are
composed of Browman and Goldstein&apos;s (1989) articulatory gestures.
Two devices, namely re-entrancy and sequencing, are employed for the
representation of geminates and affricates. The main exemplification is
taken from the verb paradigm of Cairene Arabic. The appendix contains
an outline of (i) a feature logic for phonological description, (ii) the
translation of the Arabic analysis into the logical language and (iii) a
working implementation.
In this paper we address some key issues in the psychology of word
meaning, and thereby motivate a sense generation approach to the
diversity of senses that a word may have. We note that an adequate
account must allow for the flexibility and specificity of senses, and must
also make appropriate distinctions betwen default and nondefault senses
of a word, and between different senses for vague, and ambiguous words.
We then discuss two central components of a theory of sense. First,
lexicons, the stable representations, in a &amp;quot;mental lexicon&amp;quot; of word
meanings: second, senses, the mentally represented descriptions
associated with particular uses of words. We argue that the crucial issues
in accounting for the diversity of sense are: the number of lexicons we
need to postulate, and the relationship between the contents of those
lexicons and their associated senses. Sense selection accounts, of which
we distinguish strong and weak versions, both of which find considerable
support in the cognitive science literature, fail to account for the
flexibility and specificity of senses in a way that is consonant with
linguistic evidence regarding the ambiguity of words, and psychological
evidence regarding the coherence which underlies their use. We will
show how the sense generation approach, by positing a nonmonotonic
relationship between lexons and their senses, respects these
considerations. We sketch this approach, and finally note some of its
promising implications for other aspects of word meaning.
Nominal Tense Logic is an extension of ordinary tense logic in which
reference to times is possible. The mechanism used to achieve this is to
introduce a second sort of propositional variable—the
nominal—constrained to be true at exactly one time in any
interpretation. The paper discusses the increase in expressive power thus
</bodyText>
<figure confidence="0.882985545454546">
Computational Linguistics Volume 16, Number 4, December 1990 253
Abstracts of Current Literature
EUCCS/RP-41
Multiple PP Gaps
Tait, Mary
February 1990, 25 pages, 90¢
EUCCS/RP-42
Specifiers, Complements and Adjuncts in
HPSG
Cooper, Richard
July 1990, 25 pages, 90¢
</figure>
<bodyText confidence="0.990781642857143">
gained (conditions such as irreflexivity and discreteness become tense
logically definable), presents a number of completeness and decidability
results for temporally interesting classes of frames, and briefly discusses
the import of such sorted intensional languages for natural language
semantics.
In this paper I will show that PP double dependencies exhibit rather
different behavior than do NP dependencies. By double dependency I
refer to syntactic phenomena involving a PP filler with two dependent
gaps. I will deal, primarily, with the double dependency construction of
parasitic gaps, and will argue first, that there are no grammatical
instances of a PP filler with two PP gaps; secondly, I will argue that
there are grammatical instances of a PP filler with a PP licensed gap and
an NP parasitic gap, thus demonstrating the existence of something
&amp;quot;sloppy&amp;quot; about filler-gap relations. I will mention, briefly, the double
dependency construction of coordination and will suggest that here,
unlike in parasitic gap phenomena, PP double dependencies do occur,
but show a marked awkwardness in the case of extracted complements
as opposed to adjuncts. I will also briefly touch on PP dependencies in .
headless relatives. In conclusion, I will sketch a parsing explanation for
these phenomena but will offer no syntactic solution to account for the
data.
The paper consists of a presentation and exploration of a number of
modifications to the basic framework of HPSG as presented in Pollard
and Sag (1987). Three independent modifications are considered: the
separation of subjects and other complements as argued for in Borsley
(1987); the use of sets rather than lists to represent subcategorization
requirements (along with the introduction of grammatical functions to
distinguish complements); and the selection by adjuncts for the heads
they modify.
EUCCS/WP-4
Papers from the 1989 Edinburgh Round
Table on the Mental Lexicon
Dunbar, George, Franks, Bradley, and Myers,
Terry (eds.)
June 1989, 147 pages, $6.00
The &amp;quot;1989 Edinburgh Round Table on the Mental Lexicon&amp;quot; brought
together participants from the U.K., Europe, and Israel. This volume
collects together papers based on many of the participants&apos; contributions.
The papers emphasize interdisciplinary responses to problems regarding
the syntax and semantics of words, and their mental representation. As a
result, the papers reflect concerns in descriptive and formal linguistics, in
cognitive psychology, and in philosophical and logical semantics.
</bodyText>
<reference confidence="0.9861588">
Terry Myers, Bradley Franks, Nick Braisby: &amp;quot;Partiality and Coherence
in Concept Combination&amp;quot;
George Dunbar: &amp;quot;Making Senses of Words&amp;quot;
Ilse Karius: &amp;quot;Polysemy as an Instance of Lexical Regularity:
Prepositions&amp;quot;
Jim Miller: &amp;quot;Thematic Roles, Truth Conditions and Lexical-Conceptual
Structure&amp;quot;
James Hampton: &amp;quot;Attribute Inheritance under Negation&amp;quot;
Renate Bartsch: &amp;quot;What is in the (Mental) Lexicon?&amp;quot;
Bradley Franks: &amp;quot;Concept Combination: Towards an Account of
Privatives&amp;quot;
Nick Braisby: &amp;quot;Prototypes and Word Meaning&amp;quot;
Benny Shanon: &amp;quot;Remarks on the Problem of Context&amp;quot;
Nick Chater: &amp;quot;Conceptual Change, Innateness and Internal
Representation&amp;quot;
</reference>
<page confidence="0.934247">
254 Computational Linguistics Volume 16, Number 4, December 1990
</page>
<figure confidence="0.6414595">
Abstracts of Current Literature
EUCCS/WP-5
Studies in Categorial Grammar
Barry, Guy and Morrill, Glyn (eds.)
May 1990, 148 pages, $5.00
EUCCS/WP-6
Parametric Variation in Germanic and
Romance
</figure>
<bodyText confidence="0.905947071428572">
Engdahl, Elisabet, Reape, Mike, Mellor,
Martin, and Cooper, Richard (eds.)
July 1990, 244 pages, $7.50
The papers collected together in this volume are representative of work
on categorial grammar that has been carried out at the Centre for
Cognitive Science over the past year. Much previous work at the Centre
has investigated empirical arguments for a flexible notion of categorial
constituency (cf. Volume 1 of this series); phenomena such as extraction,
coordination, and incremental interpretation have motivated the
addition of further combinatorial possibilities to basic categorial
grammar. Such moves can be seen as leading to the logical framework
that had already been presented by Joachim Lambek in 1958. This
system, the Lambek calculus, forms the basis on which the current
volume builds.
</bodyText>
<reference confidence="0.982816518518518">
Glyn Morrill, Neil Leslie, Mark Hepple, Guy Barry: &amp;quot;Categorial
Deductions and Structural Operations&amp;quot;
Guy Barry and Martin Pickering: &amp;quot;Dependency and Constituency in
Categorial Grammar&amp;quot;
Mark Hepple: &amp;quot;Word Order and Obliqueness in Categorial Grammar&amp;quot;
Martin Emms: &amp;quot;Polymorphic Quantifiers&amp;quot;
Neil Leslie: &amp;quot;Contrasting Styles of Categorial Derivations&amp;quot;
Glyn Morrill: &amp;quot;Grammar and Logical Types&amp;quot;
The papers in this volume are the result of a workshop on Parametric
Variation in Germanic and Romance that was held at Edinburgh
University, September 24-26, 1989. The workshop was organized in
connection with the ESPRIT Basic Research Action 3175 DYANA
(Dynamic Interpretation of Natural Language).
Lars Ahrenberg: &amp;quot;Topological Fields and Word Order Constraints&amp;quot;
Josef Bayer and Jaklin Kornfilt: &amp;quot;Restructuring Effects in German&amp;quot;
John Beaven: &amp;quot;A Unification Based Treatment of Spanish Clitics&amp;quot;
Kathrin Cooper: &amp;quot;Zurich German z and Verb Raising Constructions&amp;quot;
Martin Everaert: &amp;quot;Case Theory and Binding Theory&amp;quot;
Gisbet Fanselow: &amp;quot;Constraints on Movement at S-Structure&amp;quot;
Mark Hepple: &amp;quot;Word Order and Obliqueness in Categorial Grammar&amp;quot;
Ian Roberts: &amp;quot;Inversion and Subject Clitics in Valdotain&amp;quot;
Antonio Sanfilippo: &amp;quot;Clitic Doubling and Dislocation in Italian: Towards
a Parametric Account&amp;quot;
Ineke Schuurman: &amp;quot;Some Particular Verb-Raising Phenomena&amp;quot;
Mary Tait and Ronnie Cann: &amp;quot;On Empty Subjects&amp;quot;
Stephen Wechsler: &amp;quot;Verb Second and Illocutionary Force in Swedish&amp;quot;
Computational Linguistics Volume 16, Number 4, December 1990 255
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.915176">ABSTRACTS OF CURRENT LITERATURE</title>
<pubnum confidence="0.706225">Technical Reports University of Rochester Computer Science Department 1988-1990</pubnum>
<note confidence="0.5439585">Listed below are the abstracts of our recent natural language technical reports. There is a nominal charge for each report. The fee is waived for libraries in nonprofit, educational institutions and for institutions with which we have exchange</note>
<author confidence="0.793657">To order</author>
<author confidence="0.793657">send your request with a check to</author>
<affiliation confidence="0.9116465">TR Librarian Computer Science Dept.</affiliation>
<address confidence="0.988834">734 Computer Studies Building</address>
<affiliation confidence="0.997455">University of Rochester</affiliation>
<address confidence="0.999803">Rochester, NY, 14627, USA</address>
<note confidence="0.5827405">Alternatively, send e-mail to tr@cs.rochester.edu, and we will include a bill with your TR(s). TR 271 Existing plan-based theories of speech act interpretation do not account for the conventional aspect of speech acts. We use patterns of linguistic features (e.g., mood, verb form, sentence adverbials, thematic roles) to suggest a range of speech act interpretations for the utterance. These are filtered using plan-based conversational implicatures to eliminate inappropriate ones. Extended plan reasoning is available but not necessary for familiar forms. Taking speech act ambiguity seriously, with these two constraints, explains how Can you pass the salt? is a typical indirect request while Are you able to pass the salt? is not. Two Constraints on Speech Act Ambiguity Hinkelman, E. A. and Allen J. F. April 1989, 30 pages, $1.25</note>
<pubnum confidence="0.953905">TR 288</pubnum>
<title confidence="0.9351145">Linguistic and Pragmatic Constraints on Utterance Interpretation</title>
<note confidence="0.607716666666667">Hinkelman, E. A. Ph.D. Thesis, May 1990, 159 pages, $5.25 To model how people understand language, it becomes necessary to</note>
<abstract confidence="0.995232409090909">understand not only grammar and logic, but also how people use language to affect their environment. This area of study is known as natural language pragmatics. Speech acts, for instance, are the offers, promises, announcements, and so on that people make by talking. The same expression may be different acts in different contexts, and yet not every expression performs every act. We want to understand how people are able to recognize each other&apos;s intentions and implications in saying something. Previous plan-based theories of speech act interpretation do not account for the conventional aspect of speech acts. They can, however, be made sensitive to both linguistic and propositional information. This document presents a method of speech act interpretation that uses patterns of linguistic features (e.g., mood, verb form, sentence adverbials, thematic roles) to identify a range of speech act interpretations for the utterance. These are then filtered and elaborated by inferences about agents, goals, and plans. In many cases the plan reasoning consists of short, local inference chains (that are in fact conversational implicatures), and extended reasoning is necessary only for the most difficult cases. The method is able to accommodate a wide range of cases, from those that seem very idiomatic to those that must be analyzed using knowledge about the world and human behavior. explains how Can you the salt? can be a request while Are you able to pass the salt? is not.</abstract>
<note confidence="0.919684">Computational Linguistics Volume 16, Number 4, December 1990 247</note>
<title confidence="0.704192">Abstracts of Current Literature</title>
<pubnum confidence="0.857463">TR 298</pubnum>
<title confidence="0.42032">The RHET Plan Recognition System, Version 1.0</title>
<author confidence="0.439107">B W Miller</author>
<date confidence="0.485991">Jan. 1990, 50 pages, $2.00</date>
<pubnum confidence="0.888636">TR 317</pubnum>
<title confidence="0.942864">The Discourse System Project</title>
<author confidence="0.8007625">J F Allen</author>
<author confidence="0.8007625">S Guez</author>
<author confidence="0.8007625">L J Hoebel</author>
<author confidence="0.8007625">E A Hinkelman</author>
<author confidence="0.8007625">K J Jackson</author>
<author confidence="0.8007625">Kyburg</author>
<note confidence="0.6809105">A. I., and Traum, D. R. Nov. 1989, 82 pages, $3.25</note>
<pubnum confidence="0.87633">TR 324</pubnum>
<title confidence="0.850986">ARMTRAK: A Domain for the Unified Study of Natural Language, Planning, and Active Vision</title>
<author confidence="0.909293">N G Martin</author>
<author confidence="0.909293">J F Allen</author>
<author confidence="0.909293">C M Brown</author>
<date confidence="0.726161">Jan. 1990, 43 pages, $2.00</date>
<pubnum confidence="0.967175">TR 345</pubnum>
<title confidence="0.998282">An Episodic Knowledge Representation for Narrative Texts</title>
<author confidence="0.979555">L K Schubert</author>
<author confidence="0.979555">C H Hwang</author>
<date confidence="0.927403">May 1990, 53 pages, $2.25</date>
<abstract confidence="0.98101865625">a hierarchial plan recognition system built within the knowledge representation system. It provides a powerful system for plan recognition based on the algorithms of Kautz with the general reasoning of RHET. special advantage of RHET&apos;s type relations, constraints, equality and contextual reasoning abilities. It is intended as a demonstration of the and knowledge representation systems hybrid reasoning capabilities. the Lisp interface to Rhet, the user to use the Rhet-structured—type system to build plan types, and given some or set of observations have the set of plans that consistent with these observations. Since the reasoner for and observations can have reference to time intervals, and/or be temporally constrained with respect to one another. There has been significant work in the last decade on the processing of discourse for modeling two-person extended dialogues, story and text understanding, and extended question answering systems. While there has been important progress in the use of world knowledge in language interpretation, the use of plan-based models of language (e.g., speech act planning), models of reference and focus, and models of discourse structure itself, work in each area has not been related to work in the other areas. No one has determined how individual processing techniques can be combined to form a fully functional discourse system. Some suggestions on the organization of discourse have arisen recently, and while showing promise, have not been explored in enough detail for an actual application. This report describes an architecture for discourse systems that allows the integration of many different processing modules. It also describes an initial set of modules that have been implemented and tested using the architecture. a micro-world, based on the control of model trains, designed to integrate work in natural language, planning, vision, and robotics. The primary advantage of the domain is that it provides examples that involve few objects but require sophisticated analysis. Because they involve few objects, the complex reasoning required is not intractable. On the other hand, more objects can be introduced to study techniques for tractable reasoning. Simple and complex examples in the same domain allow work at different levels to take place simultaneously. a planning domain, exercising planners in a real-time domain about which the planner has only imperfect knowledge. As a domain for natural language research, it allows research into the grounding of language in real situations and the problem of coordinating the behavior of agents through language. As a domain for active vision research, it is challenging because it requires extracting information whose parameters cannot be completely specified Two implementations of been developed: simulation and using the Rochester Robot. The simulation allows work on real-time planning, and a robot version shows the feasibility of a real &apos;working system based on model trains. We would like to build story understanding systems that are transparent, modular, and extensible. To this end, we have been working on a new logical approach to narrative understanding that features a GPSG-style grammar and an episodic logic with probabilistic inference rules. The grammar represents phrase structure and the relationship between phrase structure and logical form in a modular, explicit form. The 248 Computational Linguistics Volume 16, Number 4, December 1990 Abstracts of Current Literature logical representation allows propositional attitudes, unreliable generalizations, and other nonstandard constructs, providing a uniform, transparent knowledge representation for both the explicit content of stories and for the background knowledge needed to understand them. It makes systematic use of episodic variables in the representation of episodic sentences, using these to capture temporal and causal relationships. The rules of inference include probabilistic versions of deduction rules resembling forward and backward chaining rules in expert systems. These can be used for predictive, explanatory, and simulative inference. We illustrate our approach with nontrivial grammar fragments (including semantic rules), and with an extended example of forward-chaining inference based on a sentence from Little Red Riding Hood. A pilot implementation is able to make many (though not all) of the inferences we describe. TR 346 Semantic Nets Are in the Eye of the Beholder Schubert, L. K. May 1990, 13 pages, $1.00 The term semantic nets, in its broadest sense, has become virtually meaningless. It is applied to systems that, as a class, lack distinctive representational and computational properties vis-à-vis other knowledge representation (KR) schemes. This terminological problem is not due to lack of substance or coherence of work done under the semantic net banner. Rather, it is due to convergence of the major KR schemes: the representational and computational strategies employed in semantic net systems are abstractly equivalent to those employed in virtually all state-of-the-art systems incorporating a substantial propositional knowledge base, whether they are described as logic-based, frame-based, rule-based, or something else. In particular, I will argue that using a graph-theoretic propositional representation does not automatically distinguish it from others: even sets of PC formulas, abstractly viewed, are graphs. Nor is proximity-based inference (using graph-theoretic distance) automatically distinctive, since even resolution strategies (with reasonable indexing schemes) are proximity-based in the abstract; nor its hierarchic property inheritance any longer distinctive, given its availability in state-of-the-art logic-based, frame-based, and rule-based systems. So I urge some more restrictive, and hence more meaningful use of the term semantic nets than is the current practice. The following new papers are available on request from:</abstract>
<affiliation confidence="0.931648666666667">The Technical Report Librarian Centre for Cognitive Science University of Edinburgh 2 Buccleuch Place</affiliation>
<address confidence="0.969095">Edinburgh EH8 9LW Scotland, UK</address>
<pubnum confidence="0.545454">EUCCS/RP-26</pubnum>
<title confidence="0.946706">Grammar Frameworks</title>
<author confidence="0.945142">Ewan Klein</author>
<note confidence="0.671694">December 1988,45 pages, $1.50 EUCCS/RP-27</note>
<title confidence="0.956855666666667">Autonomy, Implementation and Cognitive Architecture: A Reply to Fodor and Pylyshyn</title>
<author confidence="0.885681">Nick Chater</author>
<author confidence="0.885681">Mike Oaksford</author>
<abstract confidence="0.947247142857143">April 1989, 20 pages, 750 This paper provides a brief overview of the main developments in recent work on grammatical frameworks, covering transformational, &amp;quot;monostratal,&amp;quot; lexicalist, and unification-based approaches. Among the topics touched on are syntax-semantics interaction, the interpretation of grammar formalisms, the lexicon, grammar and computation, and some prospects for future research in the area. An extensive bibliography is provided. Fodor and Pylyshyn (1988) claim that the current inability of connectionism to deal with structured representations makes it inappropriate as a theory of cognitive architecture. This poses an important challenge to the new technology. That many connectionists are attempting to address this issue suggests that a commitment to the need for structured representation does not separate connectionist and</abstract>
<note confidence="0.683317666666667">Computational Linguistics Volume 16, Number 4, December 1990 249 Abstracts of Current Literature EUCCS/RP-28</note>
<title confidence="0.9840285">Choosing Computational Architectures for Text Processing</title>
<author confidence="0.884768">Keith Stenning</author>
<author confidence="0.884768">Mike Oaksford</author>
<date confidence="0.523622">April 1989, 36 pages, $1.75</date>
<abstract confidence="0.99859425">classicist as Fodor and Pylyshyn claim. We identify the issue of computational and explanatory autonomy of cognitive and implementational levels as the substantive dispute between connectionist and classicist. This diagnosis is born out in Fodor and Pylyshyn&apos;s discussion of the &amp;quot;lures&amp;quot; of connect ionism which are typically taken to challenge the classicist position. Fodor and Pylshyn believe that the lures are, in principle, quite compatible with the classicist autonomy assumption. However, we argue in detail that the classicist has yet to adequately meet this challenge, in practice. Moreover, we adduce arguments concerning the nature of nondemonstrative inference, especially default reasoning, which strongly suggest that the classicist&apos;s task is impossible, in principle. In this paper we investigate various criteria that bear on the choice of computational architectures for text processing. The principle role of the computational or cognitive architecture is to provide mechanisms for inference. In the study of text processing two forms of inference are fundamental, (i) the implicit elaborative inferences required for interpretation and (ii) explicit inferences that can be the subject of a text. We suggest that the decision of what architecture to employ in accounting for these inferential modes cannot be made a priori. We argue that classical cognitive architectures based on logic and proof theory although eminently suited to (ii) fail to provide tractable theories of (i), while more recent proposals like PDP (Rumelhart and McClelland, 1986) and classifier systems (Holland, Holyoak, Nisbett and Thagard, 1986), seem to offer new insights into (i) while leaving (ii) untouched. We examine the computational issues involved in a review of recent candidate architectures beginning at one extreme with Prolog, through ACT and Classifier systems, ending with then examine the empirical work from verbal reasoning tasks involving conditional and syllogistic reasoning in arguing that the grounds upon which to choose between architectures are largely a posteriori and empirical and moreover indicate that satisfactory explanations of this data must invoke both (i) and (ii). In the process we shall proffer novel interpretations both of conditional reasoning experiments as being largely inductive (and hence of scant relevance to assessing our facility for logical thought) and of Johnson-Laird&apos;s theory of syllogisms as providing a heuristic theorem prover along the lines of any other practical implementation of logic. We believe that this allows the explanatory burden for a lot of this data to be correctly located at the implementation rather than the cognitive level.</abstract>
<pubnum confidence="0.463375">EUCCS/RP-29</pubnum>
<affiliation confidence="0.9358065">Connectionism, Classical Cognitive Science and Experimental Psychology</affiliation>
<address confidence="0.8067275">Oaksford, Mike, Chater, Nick, and Stenning, Keith</address>
<date confidence="0.559547">April 1989, 22 pages, 750</date>
<abstract confidence="0.984690538461538">Classical symbolic computational models of cognition are at variance with the empirical findings in the cognitive psychology of memory and inference. Standard symbolic computers are well suited to remembering arbitrary lists of symbols and performing logical inferences. In contrast, human performance on such tasks is extremely limited. Standard models do not easily capture content-addressable memory or context-sensitive defeasible inference, which are natural and effortless for people. We argue that connectionism provides a more natural framework in which to model human cognition. In addition to capturing the gross human performance profile, connectionist systems seem well suited to accounting for the systematic patterns of errors observed in the human data. We take these arguments to counter Fodor and Pylyshyn&apos;s (1988) recent claim that connectionism is in principle irrelevant to psychology.</abstract>
<note confidence="0.759487">250 Computational Linguistics Volume 16, Number 4, December 1990 Abstracts of Current Literature EUCCS/RP-30</note>
<title confidence="0.909082">A Note on Multiple VP Ellipsis</title>
<author confidence="0.733559">Ewan</author>
<author confidence="0.733559">Kate</author>
<phone confidence="0.177843">1989, 7 pages,</phone>
<title confidence="0.672426">Devlin on Information and Cognition</title>
<author confidence="0.724901">Jerry Seligman</author>
<author confidence="0.724901">Nick Chater</author>
<date confidence="0.684949">May 1989, 16 pages, 75¢</date>
<abstract confidence="0.983336384615385">This squib draws attention to the phenomenon of multiple VP ellipsis, as illustrated in the following example: &amp;quot;If you work hard, make the right choices and keep your nose clean, you get ahead. If you don&apos;t, you don&apos;t.&amp;quot; We present a taxonomy of such data, pointing out that they are somewhat less rare than one might have expected. We also suggest, as a consequence, that the resolution problem for ellipsed VPs is potentially as complex as that required for nominal anaphora. Dretske (1981) and Barwise and Perry (1983) both aim to provide a theory of meaning and information. In his new book, Information, Devlin hints at various connections between the two. In particular, he suggests that the individuation of the primitives of situation theory—objects, locations and relations—can be explained using Dretske&apos;s distinction between information carried in analog and digital form. Since situation theory claims to be a general theory of information, it should be able to express Dretske&apos;s distinction. This raises the possibility of situation theory being able to explain the individuation of its own primitives. We conclude that if the ontological burden is to be shifted, then the situation theoretic notion of constraint, rather than that of object and relation, must take the weight. In the second half of the paper, we examine more thoroughly the claim the analog/digital distinction is sufficient to capture the process by which an agent individuates the world into categories suitable for cognitive activity. We note that Dretske&apos;s account of the distinction between cognitive and noncognitive activity is relative to a number of factors that must be captured by an adequate situation theoretic treatment.</abstract>
<note confidence="0.346489">EUCCS/RP-32</note>
<title confidence="0.5391825">Intensionality, Boundedness, and Modal Logic</title>
<author confidence="0.958979">Glyn Morrill</author>
<date confidence="0.902732">May 1989, 16 pages, 750</date>
<pubnum confidence="0.574389">EUCCS/RP-33</pubnum>
<title confidence="0.916484666666667">Partiality and Coherence in Concept Combination Myers, Terry, Franks, Bradley, and Braisby,</title>
<author confidence="0.937952">Nick</author>
<date confidence="0.584859">March 1989. 19 pages, 750</date>
<abstract confidence="0.995141653846154">In order to characterize facts about locality, the study of syntax has led to the hypothesis of boundaries and bounded domains. But from the point of view of semantics, domains already exist in the form of intensional domains. The question arises as to whether intensionality, a necessary feature of semantic theory, in fact also provides appropriate terms of reference for syntactic description. The paper presents the associative Lambek calculus and observes that while this provides a characterization of discontinuity phenomena, it fails to capture the idea of locality, e.g. it does not distinguish between relativization, which is unbounded, and reflexivization, which is bounded. We present an intensionalisation of the Lambek calculus, and show that this provides a handle in terms of which the boundedness of reflexivization can be expressed. It is then further argued that while the combinatorics of the Lambek calculus correspond to implicational linear logic, the intensionalised calculus corresponds to a modal logic, i.e., the logical character of intensional types is the logic of necessity. This paper explores the possibility for accounts of the semantic content of lexical entries to respect current arguments concerning coherence. We begin by outlining the tension that exists between the twin requirements on meaning, specificity, and flexibility. Then we consider the positions that we believe are characterized by Clark&apos;s (1983) description, &amp;quot;sense selection.&amp;quot; In considering coherence in sense selection approaches, we rely heavily on Murphy and Medin&apos;s (1985) arguments. We claim that their arguments in favor of a theory determined account of coherence lead to the rejection of the sense selection view. We then outline our own position, one we call sense generation. We argue that specificity and</abstract>
<note confidence="0.5851855">Computational Linguistics Volume 16, Number 4, December 1990 251 Abstracts of Current Literature EUCCS/RP-34 Grammar as Logic</note>
<author confidence="0.84639">Glyn Morrill</author>
<date confidence="0.828826">July 1989, 16 pages, 75¢</date>
<pubnum confidence="0.613633">EUCCS/RP-35</pubnum>
<title confidence="0.833807">How the Laws of Thought Lie</title>
<author confidence="0.720294">Jon Oberlander</author>
<date confidence="0.785302">July 1989, 27 pages, $1.00</date>
<abstract confidence="0.999584125">flexibility suggest that lexical concepts must be treated as quite specific, yet partial objects. Such lexical concepts may be extended, that is, features may be added or denied, relative to constraints provided by local theories. Such a position divorces coherence from issues of metaphysics and allows for the suggestion that the process of &amp;quot;using words to mean&amp;quot; is intrinsically perspectival. Following on from this general outline, we briefly discuss two views consonant with this position: Braisby (1989) and Franks (1989). We illustrate these by considering examples of concept combination, such as &amp;quot;stone lion,&amp;quot; &amp;quot;attractive dancer,&amp;quot; and &amp;quot;adoptive mother.&amp;quot; The notion of &amp;quot;parsing as deduction&amp;quot; appears to presuppose that of &amp;quot;grammar as logic,&amp;quot; though in fact the former has largely involved embedding grammars in logics using a fragment conducive to theorem-proving. It is well known that categorial grammars take the form of implicational logics; in this case the grammar is not embedded, but simply is a logic The paper argues that many further operations may be added to such a grammar, the result having close relations with linear logic. Thus categorical grammar emerges as the implicational fragment of a much more general logical grammar. A Prolog implementation illustrates applications to polymorphism, optionality, intensionality, bounded and unbounded extraction, and coordination reduction. The paper explores the relevance for knowledge representation of Nancy Cartwright&apos;s views on the organization of scientific theories. Correspondences between different types of scientific laws and KR&apos;s default rules are established, focusing on a distinction between phenomenal and fundamental laws. The tradeoff between truthfulness and usefulness present in scientific laws allows a new perspective on the KR tradeoff, and differing types of explanation in science carry over into KR. The crucial role of approximation in scientific inference suggests a specific type of knowledge organization, based on the notion of simulacra.</abstract>
<note confidence="0.54226">EUCCS/RP-36</note>
<title confidence="0.980524">Processing Extractions without Gaps</title>
<author confidence="0.957497">Martin Pickering</author>
<author confidence="0.957497">Guy Barry</author>
<date confidence="0.844871">September 1989, 20 pages, 50¢</date>
<pubnum confidence="0.521128">EUCCS/RP-37</pubnum>
<title confidence="0.970923">Generating Recipes: An Overview of Epicure</title>
<author confidence="0.99044">Robert Dale</author>
<date confidence="0.664278">November 1989,26 pages, $1.00</date>
<abstract confidence="0.993203521739131">Most psycholinguist ic theories have traditionally made use of the transformational grammar notions of filler and gap in explaining the processing of constructions involving extraction. On the assumption that recursive nesting of dependencies must ultimately cause processing difficulty, we show that standard analyses using gaps make incorrect predictions for a class of sentences involving pied-piping (and that alternative analyses using gaps are deficient in other respects). From this we argue that the processor establishes dependency relations between filler and subcateg,orizer rather than between filler and gap, and demonstrate that the use of a theory of syntax without gaps, such as a flexible categorial grammar, yields a more appropriate processing model. We show how this approach can be used to describe the processing of center-embedded constructions, and integrated with experimental results on long-distance dependencies. This paper describes the overall architecture and operation of Epicure, a natural language generation system that embodies the view that a discourse can be generated on the basis of a plan, and expanded to a level of detail commensurate with the knowledge of the hearer, resulting in the generation of a structured discourse. The paper shows how the 252 Computational Linguistics Volume 16, Number 4, December 1990 Abstracts of Current Literature various components that make up the system contribute to the achievement of this goal.</abstract>
<note confidence="0.418408">EUCCS/RP-38</note>
<title confidence="0.978831">Prosodic Morphology and Constraint-Based Phonology</title>
<author confidence="0.995304">Steven Bird</author>
<date confidence="0.924985">June 1990,28 pages, $1.00</date>
<pubnum confidence="0.640152">EUCCS/RP-39</pubnum>
<title confidence="0.8098945">Sense Generation or How to Make the Mental Lexicon Flexible</title>
<author confidence="0.850347">Bradley Franks</author>
<author confidence="0.850347">Nick Braisby</author>
<date confidence="0.855436">June 1990, 12 pages, 50¢</date>
<pubnum confidence="0.528208">EUCCS/RP-40</pubnum>
<title confidence="0.320652">Nominal Tense Logic</title>
<author confidence="0.353756">Patrick Blackburn</author>
<date confidence="0.750189">June 1990, 18 pages, 65¢</date>
<abstract confidence="0.996689">Unification-based grammar formalisms have been employed in the analysis of a vast range of syntactic and semantic phenomena. Applications to morphological and phonological domains have proceeded at a slower pace, largely because they have taken phonological representation to be linear. This is in stark contrast with the developments in the phonology literature over at least the last decade, where many have proposed the adoption of multilinear (or nonlinear) representations. The chief purpose of this paper is to reconcile this difference, by showing how complex hierarchical phonological structures may be represented using the descriptive vocabulary of a unification-based grammar formalism. A complementary goal is to advocate the use of computationally interpretable theories of phonology, because of the increased theoretical and empirical rigor such a shift will bring to the domain. A unification-based approach (formalized in a decidable subset of classical first-order logic) is used in the representation of prosodic structure, where syllables are composed of moras which in turn are composed of Browman and Goldstein&apos;s (1989) articulatory gestures. Two devices, namely re-entrancy and sequencing, are employed for the representation of geminates and affricates. The main exemplification is taken from the verb paradigm of Cairene Arabic. The appendix contains an outline of (i) a feature logic for phonological description, (ii) the translation of the Arabic analysis into the logical language and (iii) a working implementation. In this paper we address some key issues in the psychology of word meaning, and thereby motivate a sense generation approach to the diversity of senses that a word may have. We note that an adequate account must allow for the flexibility and specificity of senses, and must also make appropriate distinctions betwen default and nondefault senses of a word, and between different senses for vague, and ambiguous words. We then discuss two central components of a theory of sense. First, lexicons, the stable representations, in a &amp;quot;mental lexicon&amp;quot; of word meanings: second, senses, the mentally represented descriptions associated with particular uses of words. We argue that the crucial issues in accounting for the diversity of sense are: the number of lexicons we need to postulate, and the relationship between the contents of those lexicons and their associated senses. Sense selection accounts, of which we distinguish strong and weak versions, both of which find considerable support in the cognitive science literature, fail to account for the flexibility and specificity of senses in a way that is consonant with linguistic evidence regarding the ambiguity of words, and psychological evidence regarding the coherence which underlies their use. We will show how the sense generation approach, by positing a nonmonotonic relationship between lexons and their senses, respects these considerations. We sketch this approach, and finally note some of its promising implications for other aspects of word meaning. Tense Logic an extension of ordinary tense logic in which reference to times is possible. The mechanism used to achieve this is to introduce a second sort of propositional variable—the nominal—constrained to be true at exactly one time in any interpretation. The paper discusses the increase in expressive power thus</abstract>
<note confidence="0.422666666666667">Computational Linguistics Volume 16, Number 4, December 1990 253 Abstracts of Current Literature EUCCS/RP-41</note>
<title confidence="0.983073">Multiple PP Gaps</title>
<author confidence="0.968167">Mary Tait</author>
<date confidence="0.772612">February 1990, 25 pages, 90¢</date>
<title confidence="0.735238">Specifiers, Complements and Adjuncts in HPSG</title>
<author confidence="0.790988">Richard Cooper</author>
<date confidence="0.717132">July 1990, 25 pages, 90¢</date>
<abstract confidence="0.9992858">gained (conditions such as irreflexivity and discreteness become tense logically definable), presents a number of completeness and decidability results for temporally interesting classes of frames, and briefly discusses the import of such sorted intensional languages for natural language semantics. In this paper I will show that PP double dependencies exhibit rather different behavior than do NP dependencies. By double dependency I refer to syntactic phenomena involving a PP filler with two dependent gaps. I will deal, primarily, with the double dependency construction of parasitic gaps, and will argue first, that there are no grammatical instances of a PP filler with two PP gaps; secondly, I will argue that there are grammatical instances of a PP filler with a PP licensed gap and an NP parasitic gap, thus demonstrating the existence of something &amp;quot;sloppy&amp;quot; about filler-gap relations. I will mention, briefly, the double dependency construction of coordination and will suggest that here, unlike in parasitic gap phenomena, PP double dependencies do occur, but show a marked awkwardness in the case of extracted complements as opposed to adjuncts. I will also briefly touch on PP dependencies in . headless relatives. In conclusion, I will sketch a parsing explanation for these phenomena but will offer no syntactic solution to account for the data. The paper consists of a presentation and exploration of a number of modifications to the basic framework of HPSG as presented in Pollard and Sag (1987). Three independent modifications are considered: the separation of subjects and other complements as argued for in Borsley</abstract>
<intro confidence="0.796993">(1987); the use of sets rather than lists to represent subcategorization</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Terry Myers</author>
<author>Bradley Franks</author>
<author>Nick</author>
</authors>
<title>Braisby: &amp;quot;Partiality and Coherence in Concept Combination&amp;quot; George Dunbar: &amp;quot;Making Senses of Words&amp;quot; Ilse Karius: &amp;quot;Polysemy as an Instance of Lexical Regularity: Prepositions&amp;quot;</title>
<marker>Myers, Franks, Nick, </marker>
<rawString>Terry Myers, Bradley Franks, Nick Braisby: &amp;quot;Partiality and Coherence in Concept Combination&amp;quot; George Dunbar: &amp;quot;Making Senses of Words&amp;quot; Ilse Karius: &amp;quot;Polysemy as an Instance of Lexical Regularity: Prepositions&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jim Miller</author>
</authors>
<title>Thematic Roles, Truth Conditions and Lexical-Conceptual Structure&amp;quot; James Hampton: &amp;quot;Attribute Inheritance under Negation&amp;quot; Renate Bartsch: &amp;quot;What is in the (Mental) Lexicon?&amp;quot;</title>
<marker>Miller, </marker>
<rawString>Jim Miller: &amp;quot;Thematic Roles, Truth Conditions and Lexical-Conceptual Structure&amp;quot; James Hampton: &amp;quot;Attribute Inheritance under Negation&amp;quot; Renate Bartsch: &amp;quot;What is in the (Mental) Lexicon?&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bradley Franks</author>
</authors>
<title>Concept Combination: Towards an Account of Privatives&amp;quot; Nick Braisby: &amp;quot;Prototypes and Word Meaning&amp;quot; Benny Shanon: &amp;quot;Remarks on the Problem of Context&amp;quot; Nick Chater: &amp;quot;Conceptual Change, Innateness and Internal Representation&amp;quot;</title>
<marker>Franks, </marker>
<rawString>Bradley Franks: &amp;quot;Concept Combination: Towards an Account of Privatives&amp;quot; Nick Braisby: &amp;quot;Prototypes and Word Meaning&amp;quot; Benny Shanon: &amp;quot;Remarks on the Problem of Context&amp;quot; Nick Chater: &amp;quot;Conceptual Change, Innateness and Internal Representation&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Glyn Morrill</author>
<author>Neil Leslie</author>
<author>Mark Hepple</author>
<author>Guy Barry</author>
</authors>
<title>Categorial Deductions and Structural Operations&amp;quot;</title>
<marker>Morrill, Leslie, Hepple, Barry, </marker>
<rawString>Glyn Morrill, Neil Leslie, Mark Hepple, Guy Barry: &amp;quot;Categorial Deductions and Structural Operations&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Guy Barry</author>
<author>Martin Pickering</author>
</authors>
<title>Dependency and Constituency in Categorial Grammar&amp;quot;</title>
<marker>Barry, Pickering, </marker>
<rawString>Guy Barry and Martin Pickering: &amp;quot;Dependency and Constituency in Categorial Grammar&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mark Hepple</author>
</authors>
<title>Word Order and Obliqueness in Categorial Grammar&amp;quot; Martin Emms: &amp;quot;Polymorphic Quantifiers&amp;quot;</title>
<marker>Hepple, </marker>
<rawString>Mark Hepple: &amp;quot;Word Order and Obliqueness in Categorial Grammar&amp;quot; Martin Emms: &amp;quot;Polymorphic Quantifiers&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Neil Leslie</author>
</authors>
<title>Contrasting Styles of Categorial Derivations&amp;quot; Glyn Morrill: &amp;quot;Grammar and Logical Types&amp;quot; The papers in this volume are the result of a workshop on Parametric Variation in Germanic and Romance that was held at</title>
<date>1989</date>
<institution>Edinburgh University,</institution>
<marker>Leslie, 1989</marker>
<rawString>Neil Leslie: &amp;quot;Contrasting Styles of Categorial Derivations&amp;quot; Glyn Morrill: &amp;quot;Grammar and Logical Types&amp;quot; The papers in this volume are the result of a workshop on Parametric Variation in Germanic and Romance that was held at Edinburgh University, September 24-26, 1989. The workshop was organized in connection with the ESPRIT Basic Research Action 3175 DYANA (Dynamic Interpretation of Natural Language).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lars Ahrenberg</author>
</authors>
<title>Topological Fields and Word Order Constraints&amp;quot; Josef Bayer and Jaklin Kornfilt: &amp;quot;Restructuring Effects in German&amp;quot; John Beaven: &amp;quot;A Unification Based Treatment of Spanish Clitics&amp;quot; Kathrin Cooper: &amp;quot;Zurich German z and Verb Raising Constructions&amp;quot; Martin Everaert: &amp;quot;Case Theory and Binding Theory&amp;quot; Gisbet Fanselow: &amp;quot;Constraints on Movement at S-Structure&amp;quot; Mark Hepple: &amp;quot;Word Order and Obliqueness in Categorial Grammar&amp;quot; Ian Roberts: &amp;quot;Inversion and Subject Clitics in Valdotain&amp;quot;</title>
<marker>Ahrenberg, </marker>
<rawString>Lars Ahrenberg: &amp;quot;Topological Fields and Word Order Constraints&amp;quot; Josef Bayer and Jaklin Kornfilt: &amp;quot;Restructuring Effects in German&amp;quot; John Beaven: &amp;quot;A Unification Based Treatment of Spanish Clitics&amp;quot; Kathrin Cooper: &amp;quot;Zurich German z and Verb Raising Constructions&amp;quot; Martin Everaert: &amp;quot;Case Theory and Binding Theory&amp;quot; Gisbet Fanselow: &amp;quot;Constraints on Movement at S-Structure&amp;quot; Mark Hepple: &amp;quot;Word Order and Obliqueness in Categorial Grammar&amp;quot; Ian Roberts: &amp;quot;Inversion and Subject Clitics in Valdotain&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Antonio Sanfilippo</author>
</authors>
<title>Clitic Doubling and Dislocation in Italian: Towards a Parametric Account&amp;quot;</title>
<marker>Sanfilippo, </marker>
<rawString>Antonio Sanfilippo: &amp;quot;Clitic Doubling and Dislocation in Italian: Towards a Parametric Account&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ineke Schuurman</author>
</authors>
<title>Some Particular Verb-Raising Phenomena&amp;quot; Mary Tait and Ronnie Cann: &amp;quot;On Empty Subjects&amp;quot;</title>
<marker>Schuurman, </marker>
<rawString>Ineke Schuurman: &amp;quot;Some Particular Verb-Raising Phenomena&amp;quot; Mary Tait and Ronnie Cann: &amp;quot;On Empty Subjects&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wechsler</author>
</authors>
<title>Verb Second and Illocutionary Force in Swedish&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<pages>255</pages>
<marker>Wechsler, 1990</marker>
<rawString>Stephen Wechsler: &amp;quot;Verb Second and Illocutionary Force in Swedish&amp;quot; Computational Linguistics Volume 16, Number 4, December 1990 255</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>