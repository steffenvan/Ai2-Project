<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000085">
<title confidence="0.985463">
Fine Granular Aspect Analysis using Latent Structural Models
</title>
<author confidence="0.984234">
Lei Fang&apos; and Minlie Huang2
</author>
<affiliation confidence="0.960208">
State Key Laboratory of Intelligent Technology and Systems,
Tsinghua National Laboratory for Information Science and Technology,
Department of Computer Science and Technology,
Tsinghua University, Beijing 100084, PR China.
</affiliation>
<email confidence="0.9772355">
&apos;fang-l10@mails.tsinghua.edu.cn
2aihuang@tsinghua.edu.cn
</email>
<sectionHeader confidence="0.998515" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999284823529412">
In this paper, we present a structural learning
model for joint sentiment classification and as-
pect analysis of text at various levels of gran-
ularity. Our model aims to identify highly in-
formative sentences that are aspect-specific in
online custom reviews. The primary advan-
tages of our model are two-fold: first, it per-
forms document-level and sentence-level sen-
timent polarity classification jointly; second,
it is able to find informative sentences that are
closely related to some respects in a review,
which may be helpful for aspect-level senti-
ment analysis such as aspect-oriented sum-
marization. The proposed method was eval-
uated with 9,000 Chinese restaurant reviews.
Preliminary experiments demonstrate that our
model obtains promising performance.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991693877551">
Online reviews have been a major resource from
which users may find opinions or comments on the
products or services they want to consume. How-
ever, users sometimes might be overwhelmed, and
not be able to read reviews one by one when facing
a considerably large number of reviews, and they
may be not be satisfied by only being served with
document-level reviews statistics (that is, the num-
ber of reviews with 1-star, 2-star, ..., respectively).
Aspect-level review analysis may be alternative for
addressing this issue as aspect-specific opinions may
more clearly, explicitly, and completely describe the
quality of a product from different properties.
Our goal is to discover informative sentences that
are consistent with the overall rating of a review, and
simultaneously, to perform sentiment analysis at as-
pect level. Notice, that a review with a high rating
(say, 4/5 stars) may contain both negative and posi-
tive opinions, and the same to a review with a very
low rating (say, 1/2 star). From our point of view,
each review has a set of sentences that are informa-
tive and coherent to its overall rating. To perform
fine granular sentiment analysis, the first step is to
discover such coherent content.
Many information needs require the systems to
perform fine granular sentiment analysis. Aspect-
level sentiment analysis may be more useful for
users to have a global picture of opinions on the
product’s properties. Furthermore, different users
may have different preferences on different aspects
of a product. Taking the reviews on mobile phones
as an example, female users may focus more on the
appearance while male users may lay more emphasis
on the hardware configuration; younger users prefer
to the app or game resources while older users may
just pay attention to the basic function of calling or
messaging.
In recent years, there has been much work focused
multilevel sentiment classification using structural
learning models. Yi (2007) extends the standard
conditional random fields to model the local senti-
ment flow. Ryan (2007) proposed structured models
for fine-to-coarse sentiment analysis. Oscar (2011)
proposed to discover fine-grained sentiment with
hidden-state CRF(Quattoni et al., 2007). Yessenali-
na (2010) deployed the framework of latent struc-
tural SVMs(Yu and Joachims., 2009) for multilevel
sentiment classification. As for aspect level rating,
ranking, or summarization, Benjamin(2007) em-
</bodyText>
<page confidence="0.991902">
333
</page>
<note confidence="0.6839225">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.99991625">
ployed the good grief algorithm for multiple aspect
ranking and the extensions of the generative topic
models were also widely studied, such as (Titov and
McDonald., 2008; Brody and Elhadad., 2010; Wang
et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and
Oh., 2011; Lin and He, 2009).
In this paper, we build a general structural learn-
ing model for joint sentiment classification and as-
pect analysis using a latent discriminate method.
Our model is able to predict the sentiment polari-
ty of document as well as to identify aspect-specific
sentences and predict the polarity of such sentences.
The proposed method was evaluated with 9,000 Chi-
nese restaurant reviews. Preliminary experiments
demonstrate that our model obtains promising per-
formance.
</bodyText>
<sectionHeader confidence="0.998677" genericHeader="introduction">
2 Model
</sectionHeader>
<subsectionHeader confidence="0.99966">
2.1 Document Structure
</subsectionHeader>
<bodyText confidence="0.996094896551724">
We assume that the polarity of document is closely
related to some aspects for the reason that people are
writing reviews to praise or criticize certain aspect-
s. Therefore, each informative sentence of the doc-
ument characterizes one aspect, expressing aspec-
t specific polarity or subjective features. Similar to
previous work on aspect analysis (Wang et al., 2010)
and multi-level sentiment classification (Yessenali-
na et al., 2010), we define the aspect as a collection
of synonyms. For instance, the word set {“value”,
“price”, “cost”, “worth”, “quality”} is a synonym
set corresponding to the aspect “price”. For each
document, an aspect is described by one or several
sentences expressing aspect specific polarity or sub-
jective information.
Let document be denoted by x, and y ∈ {+1, −1}
represents the positive or negative polarity of the
document, s is the set of informative sentences, in
which each sentence is attached with certain aspect
ai ∈ A = {a1, ..., ak}. Yessenalina (2010) chooses
a sentence set that best explains the sentiment of the
whole document while the s here retain this proper-
ty. Let Ψ(x, y, s) denote the joint feature map that
outputs the features describing the quality of predict-
ing sentiment y using the sentence set s.
Let xj denote the j-th sentence of documen-
t x, and aj is the attached aspect of xj. In spirit
to (Yessenalina et al., 2010), we propose the follow-
ing formulation of the discriminate function
</bodyText>
<equation confidence="0.977614666666667">
⃗wTΨ(x,y,s) =
N(x) E (y · wTpo laj ψpol(xj) + wTsubjaj ψsubj(xj))
jEs
</equation>
<bodyText confidence="0.999444625">
where N(x) is the normalizing factor, ψpol(xj) and
ψsubj(xj) represents the polarity and subjectivity
features of sentence xj respectively. ⃗wpol and ⃗wsubj
denote the weight for polarity and subjectivity fea-
tures. To be specific for each aspect, we have ⃗wpola
and ⃗wsubja representing the vector of feature weight
for aspect a to calculate the polarity and subjectivity
score.
</bodyText>
<equation confidence="0.9497703">
� ⃗wT
pola0
� .
� ..
⃗wT
polak
To make prediction, we have the document-level
sentiment classifier as
h(x; ⃗w) = argmax
y=±1
</equation>
<bodyText confidence="0.9995705">
where S(x) = {s ⊆ 1,..., |x |: |s |≤ f(|x|)},
f(|x|) is a function that depends only on the number
of sentences in x, as illustrated in (Yessenalina et al.,
2010). Therefore, for each sentence xj, we compute
the joint subjectivity and polarity score with respect
to aspect a and label y as
</bodyText>
<equation confidence="0.982551">
score(xj, a, y) = y·⃗wTpolaψpol(xj)+⃗wTsubjaψsubj(xj)
we then assign aspect aj to sentence xj if
aj = argmax score(xj, a, y)
aEA
</equation>
<bodyText confidence="0.999943333333333">
After sorting score(xj, aj, y) in decreasing order
and taking summation by selecting the top f(|x|) (or
fewer, if there are fewer than f(|x|) that have posi-
tive joint score) sentences as the total score for each
y ∈{+1,−1} , we then predict y with the higher joint
score as the sentiment of the whole document. This
formulation of ⃗wTΨ(x, y, s) and classifier explains
that for each sentence, the assigned aspect has the
highest score over other aspects.
</bodyText>
<equation confidence="0.989604375">
⃗wT pol =
� � ⃗T 1
�, � �⃗T wsubja0
wsubj = � ...
⃗T
wsubjak
max ⃗wTΨ(x, y, s)
sES�x)
</equation>
<page confidence="0.994038">
334
</page>
<subsectionHeader confidence="0.952969">
2.2 Feature Space
</subsectionHeader>
<bodyText confidence="0.997040571428571">
In our model, we use bag-of-words features. In or-
der to obtain a model that is jointly trained, and sat-
isfy the condition that the overall polarity of docu-
ment should influence the sentiment of extracted in-
formative sentences. We denote the weight vector
modeling the polarity of entire document as ⃗wdoc, as
follows:
</bodyText>
<figure confidence="0.913515111111111">
335 example, starting with an initialization sentence set
⃗wTΨ(x,y,s) =
∑(⃗wTpolajψpol(xj) +⃗wTdo cψpol(xj))
(jEs
�
∑ wTsubjajψsubj(xj) +y&apos;⃗wTdocψpol(x)
jEs
2.3
We trained our model using the latent structural
SVMs (Yu and Joachims., 2009).
Training
OP1:
⃗w,ξ&gt;0
2  ||w ||2 + N N ξi
i=1
s.t.di :
max ⃗wTΨ(xi, yi, s) &gt;
sES(xi)
</figure>
<bodyText confidence="0.947282230769231">
We define 0(yi,
= 1, that is, we view
document level sentiment classification loss as the
loss function. It should be noticed that OP1 is non-
convex. To circumvent the optimization difficul-
ty, we employ the framework of structural SVM-
s (Tsochantaridis et al., 2004) with latent variables
proposed by Yu (2009) using the CCCP algorith-
m (Yuille and Rangarajan., 2003). In terms of the
formulation here, since the true informative sentence
set is never observed, it is a hidden or latent variable.
Thus, we keep si fixed to compute the upper bound
for the concave part of each constraint, and rewrite
</bodyText>
<equation confidence="0.480134111111111">
−yi,s′)
aints as
⃗wTΨ(xi,−yi,s′)− ⃗wTΨ(xi,yi,si)+1
y
N(x)
1
+
N(x)
aining
</equation>
<bodyText confidence="0.835056625">
in which each sentence is with an aspect label, the
training procedure alternates between solving an in-
stance of the structural SVM using the si and pre-
dicting anew sentence until the learned weight vec-
tor
In our work, we use the perfor-
man
w⃗converges.
ce on a validation set to choose the halting iter-
ation, as is similar to Yessenalina (2010).
zation
= 0.3 *
that is, we only select the top
30% of the total sentences as the set of informative
part of the document. The normalizing factor is set
as Yessenali
</bodyText>
<equation confidence="0.97594">
f(|x|)
|x|,
√
as N(x) = f|x|,
na (2010) demon-
similarity(xl,Pa′)a′EA
</equation>
<bodyText confidence="0.972956333333333">
tent with the overall
rating of a review as the initial
guess of the latent variable.
</bodyText>
<sectionHeader confidence="0.997222" genericHeader="method">
3 Experiments
</sectionHeader>
<equation confidence="0.9215814">
min
max
s′ES(xi)
+ 0(yi,
⃗wTΨ(xi,−yi,s′)
−yi,s′) − ξi
the constr
&gt; max
ξi
s′ES(xi)
</equation>
<bodyText confidence="0.9688055">
After that, we have yi completed with the laten-
t variable si as if it is observed. For each tr
</bodyText>
<subsectionHeader confidence="0.996841">
2.4 Model Initiali
</subsectionHeader>
<bodyText confidence="0.963572">
To initialize the informative sentence set, following
the experiment result of Yessenalina (2010), we set
that square root normalization can be useful.
To analyze the aspect of each sentence, we need to
give an initial guess of the aspect and sentiment for
each sentence.
Sentence level sentiment initialization : To ini-
tialize the sentence level sentiment, we employ a
rule based method incorporating positive and neg-
ative sentiment terms, with adversative relation con-
sidered.
Sentence aspect assignment initialization : Obvi-
ously, if a synonym of aspect a occurs in sentence
we assign aspect a to
and add
to an aspect
specific sentence set Pa.For sentence
</bodyText>
<equation confidence="0.715716888888889">
without an
strates
xl,
xl,
xl
xl
y
aspect term, we set a as the aspect label if
a = argmax
</equation>
<bodyText confidence="0.979552419354839">
We select the sentences whose sentiment is consis-
In this section, we evaluate our model in terms of
document and sentence level sentiment classifica-
tion, we also analyze the performance of aspect as-
signment for each sentence. The model is evaluated
on the Chinese restaurant reviews crawled from Di-
anpingl. Each of the reviews has an overall rating
ran
ging from one to five stars. To be specific, we
consider a review as positive if its rating is greater
lhttp://www.dianping.com/
than or equal to 4 stars, or negative if less than or
equal to 2 stars. The corpus has 4500 positive and
4500 negative reviews. Data and an implementation
of our model are publicly available2.
We train 5 different models by splitting these re-
views into 9 folds. Two folds are left out as the test-
ing set, and each model takes 5 folds as training set,
2 folds as validation set, and the performance is aver-
aged. Besides, we also manually label 100 reviews,
in which each sentence is labeled as positive or neg-
ative corresponding to certain aspect or with no as-
pect description. On average, each review has 9.66
sentences. However, only 21.5% of the total sen-
tences can be assigned to aspect by directly match-
ing with aspect terms, which explains that keywords
based aspect sentiment analysis may fail. For restau-
rant reviews, we pre-defined 11 aspects, and for each
aspect, we select about 5 frequently used terms to
describe that aspect. Table 1 shows some examples
of the aspect synonym set used in this paper:
</bodyText>
<table confidence="0.999231181818182">
Aspect Synonym Set
Taste *i_“taste”, r2*“flavor”
Price 0 “price” , 0A“cost”
Dishes Xa“dishes”, XA“cuisine”
Ingredients **“food” , *,4“ingredients”
Facility AA“facility”, 94-al-“seat”
Location 4-al-I“location”,
Environment Jq,A“environment”,
�f“decoration”
Service AV�-“service” , AV�-A“waiter”
�&amp;“attitude”
</table>
<tableCaption confidence="0.99987">
Table 1: Samples of Aspect Synonym.
</tableCaption>
<bodyText confidence="0.99901575">
Document level sentiment classification We com-
pare our method with previous work on sentimen-
t classification using standard SVM(Pang et al.,
2002). Our model yields an accuracy of 94.15%
while the standard SVM classifier yields an accu-
racy of 90.35%. Clearly, our model outperforms the
baseline on document level sentiment classification.
Sentence level sentiment classification Our
method can extract a set of informative sentence
that are coherent to the overall rating of a re-
view. The evaluation of sentence-level sentiment
classification is based on manual annotation. We
</bodyText>
<footnote confidence="0.850202">
2http://www.qanswers.net/faculty/hml/
</footnote>
<bodyText confidence="0.99926305882353">
sample 100 reviews, and present the extracted 300
sentences to annotators who have been asked to
assign positive/negative/non-related labels. Among
the sentences, 251 correctly classified as positive
or negative while 49 are misclassified. And, 38
sentences of the 49 sentences have mix opinions or
are non-subjective sentences.
Aspect Assignment To evaluate the accuracy of as-
pect assignment, we compare the predicted aspec-
t labels with the ground truth (manual annotation).
As some of sentences have explicit aspect terms and
can be easily identified, we only consider those sen-
tences without aspect words. In the extracted 300
sentences, 78 sentences have aspect terms, and for
the rest, our model assigns correct aspect labels to
44 sentences while random guess only maps 21 sen-
tences with right labels.
</bodyText>
<sectionHeader confidence="0.998905" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999966708333333">
In this paper, we address the task of multilevel sen-
timent classification of online custom reviews for
fine granular aspect analysis. We present a struc-
tural learning model based on struct-SVM with la-
tent variables. The informative sentence set is re-
garded as latent variable, in which each sentence is
attached with certain aspect label. The training pro-
cedure alternates between solving an instance of the
standard structural SVM optimization and predict-
ing a new sentence set until the halting condition is
satisfied. In addition, our model is a enough gen-
eral model which can be easily extended to other
domains. Preliminary experiments demonstrate that
our model obtains promising performance.
There are several possibilities to improve our
model. For future work, we propose to incorpo-
rate prior knowledge of latent variables to the mod-
el. One possible way is to reformulate the loss func-
tion by taking the predicted aspect of the extract-
ed sentences into consideration. Another is to in-
troduce confidence score to the extracted sentences,
such that the learned support vectors that are labeled
with higher confidence shall assert more force on the
decision plane.
</bodyText>
<sectionHeader confidence="0.998857" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.904649">
This paper was supported by Chinese 973 project
under No.2012CB316301 and National Chinese Sci-
</bodyText>
<page confidence="0.996914">
336
</page>
<bodyText confidence="0.958256">
ence Foundation projects with No.60803075 and
No.60973104.
</bodyText>
<sectionHeader confidence="0.994284" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998304945945946">
Samuel Brody and Noemie Elhadad. 2010. An unsuper-
vised aspect-sentiment model for online reviews. In
Proceedings ofAnnual Conference of the North Amer-
ican Chapter of the ACL, (NAACL).
Yohan Jo and Alice Oh. 2011. Aspect and sentiment uni-
fication model for online review analysis. In Proceed-
ings of Conference on Web Search and Data Mining
(WSDM).
Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011.
Generating aspect-oriented multi-document summa-
rization with event-aspect model. In Proceedings of
Conference on Empirical Methods in Natural Lan-
guage Processing, (EMNLP).
Chenghua Lin and Yulan He. 2009. Joint sentimen-
t/topic model for sentiment analysis. In Proceedings
of the conference on Information and knowledge man-
agement(CIKM).
Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou.
2011. Multi-aspect sentiment analysis with topic mod-
els. In The ICDM’2011 Workshop on Sentiment Elic-
itation from Natural Textfor Information Retrieval and
Extraction.
Yi Mao and Guy Lebanon. 2007. Isotonic conditional
random fields and local sentiment flow. In Proceed-
ings of Advances in Neural Information Processing
Systems (NIPS).
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeff Reynar. 2007. Structured models for
fine-to-coarse sentiment analysis. In Proceedings of
Annual Meeting of the Association for Computational
Linguistics, (ACL).
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using ma-
chine learning techniques. In Proceedings of Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP).
A. Quattoni, S. Wang, L.-P Morency, M. Collins, and
T. Darrell. 2007. Hidden-state conditional random
fields. IEEE Transactions on Pattern Analysis and
Machine Intelligence.
Benjamin Snyder and Regina Barzilay. 2007. Multiple
aspect ranking using the good grief algorithm. In Pro-
ceedings of Annual Conference of the North American
Chapter of the ACL, (NAACL).
Oscar T¨ackstr¨om and Ryan McDonald. 2011. Discov-
ering fine-grained sentiment with latent variable struc-
tured prediction models. In Proceedings ofAnnual Eu-
ropean Conference on Information Retrieval, (ECIR).
Ivan Titov and Ryan McDonald. 2008. A joint model of
text and aspect ratings for sentiment summarization.
In Proceedings of Annual Meeting of the Association
for Computational Linguistics, (ACL).
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the International
Conference on Machine Learning, (ICML).
Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010.
Latent aspect rating analysis on review text data: A
rating regression approach. In Proceedings of the In-
ternational Conference on Knowledge Discovery and
Data Mining (KDD).
Ainur Yessenalina, Yisong Yue, and Claire Cardie. 2010.
Multi-level structured models for document-level sen-
timent classification. In Proceedings of Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In Pro-
ceedings of the International Conference on Machine
Learning, (ICML).
A. L. Yuille and Anand Rangarajan. 2003. The
concave-convex procedure (cccp). Neural Computa-
tion, 15:915–936.
</reference>
<page confidence="0.998451">
337
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.237460">
<title confidence="0.975893">Fine Granular Aspect Analysis using Latent Structural Models</title>
<author confidence="0.664296">State Key Laboratory of Intelligent Technology</author>
<affiliation confidence="0.760397">Tsinghua National Laboratory for Information Science and Department of Computer Science and</affiliation>
<note confidence="0.510673">Tsinghua University, Beijing 100084, PR</note>
<abstract confidence="0.998925722222222">In this paper, we present a structural learning model for joint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings ofAnnual Conference of the North American Chapter of the ACL,</booktitle>
<location>(NAACL).</location>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings ofAnnual Conference of the North American Chapter of the ACL, (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of Conference on Web Search and Data Mining (WSDM).</booktitle>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of Conference on Web Search and Data Mining (WSDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Li</author>
<author>Yinglin Wang</author>
<author>Wei Gao</author>
<author>Jing Jiang</author>
</authors>
<title>Generating aspect-oriented multi-document summarization with event-aspect model.</title>
<date>2011</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>(EMNLP).</location>
<contexts>
<context position="4005" citStr="Li et al., 2011" startWordPosition="602" endWordPosition="605">eployed the framework of latent structural SVMs(Yu and Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 2010; Wang et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and Oh., 2011; Lin and He, 2009). In this paper, we build a general structural learning model for joint sentiment classification and aspect analysis using a latent discriminate method. Our model is able to predict the sentiment polarity of document as well as to identify aspect-specific sentences and predict the polarity of such sentences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 Model 2.1 Document Structure We assume that the polarity of document is closely</context>
</contexts>
<marker>Li, Wang, Gao, Jiang, 2011</marker>
<rawString>Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011. Generating aspect-oriented multi-document summarization with event-aspect model. In Proceedings of Conference on Empirical Methods in Natural Language Processing, (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the conference on Information and knowledge management(CIKM).</booktitle>
<contexts>
<context position="4059" citStr="Lin and He, 2009" startWordPosition="614" endWordPosition="617">nd Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 2010; Wang et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and Oh., 2011; Lin and He, 2009). In this paper, we build a general structural learning model for joint sentiment classification and aspect analysis using a latent discriminate method. Our model is able to predict the sentiment polarity of document as well as to identify aspect-specific sentences and predict the polarity of such sentences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 Model 2.1 Document Structure We assume that the polarity of document is closely related to some aspects for the reason that people ar</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of the conference on Information and knowledge management(CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin Tsou</author>
</authors>
<title>Multi-aspect sentiment analysis with topic models.</title>
<date>2011</date>
<booktitle>In The ICDM’2011 Workshop on Sentiment Elicitation from Natural Textfor Information Retrieval and Extraction.</booktitle>
<contexts>
<context position="4022" citStr="Lu et al., 2011" startWordPosition="606" endWordPosition="609">work of latent structural SVMs(Yu and Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 2010; Wang et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and Oh., 2011; Lin and He, 2009). In this paper, we build a general structural learning model for joint sentiment classification and aspect analysis using a latent discriminate method. Our model is able to predict the sentiment polarity of document as well as to identify aspect-specific sentences and predict the polarity of such sentences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 Model 2.1 Document Structure We assume that the polarity of document is closely related to some </context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou. 2011. Multi-aspect sentiment analysis with topic models. In The ICDM’2011 Workshop on Sentiment Elicitation from Natural Textfor Information Retrieval and Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Mao</author>
<author>Guy Lebanon</author>
</authors>
<title>Isotonic conditional random fields and local sentiment flow.</title>
<date>2007</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems (NIPS).</booktitle>
<marker>Mao, Lebanon, 2007</marker>
<rawString>Yi Mao and Guy Lebanon. 2007. Isotonic conditional random fields and local sentiment flow. In Proceedings of Advances in Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeff Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>(ACL).</location>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeff Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of Annual Meeting of the Association for Computational Linguistics, (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="12477" citStr="Pang et al., 2002" startWordPosition="2032" endWordPosition="2035">about 5 frequently used terms to describe that aspect. Table 1 shows some examples of the aspect synonym set used in this paper: Aspect Synonym Set Taste *i_“taste”, r2*“flavor” Price 0 “price” , 0A“cost” Dishes Xa“dishes”, XA“cuisine” Ingredients **“food” , *,4“ingredients” Facility AA“facility”, 94-al-“seat” Location 4-al-I“location”, Environment Jq,A“environment”, �f“decoration” Service AV�-“service” , AV�-A“waiter” �&amp;“attitude” Table 1: Samples of Aspect Synonym. Document level sentiment classification We compare our method with previous work on sentiment classification using standard SVM(Pang et al., 2002). Our model yields an accuracy of 94.15% while the standard SVM classifier yields an accuracy of 90.35%. Clearly, our model outperforms the baseline on document level sentiment classification. Sentence level sentiment classification Our method can extract a set of informative sentence that are coherent to the overall rating of a review. The evaluation of sentence-level sentiment classification is based on manual annotation. We 2http://www.qanswers.net/faculty/hml/ sample 100 reviews, and present the extracted 300 sentences to annotators who have been asked to assign positive/negative/non-relat</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Quattoni</author>
<author>S Wang</author>
<author>L-P Morency</author>
<author>M Collins</author>
<author>T Darrell</author>
</authors>
<title>Hidden-state conditional random fields.</title>
<date>2007</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence.</journal>
<contexts>
<context position="3368" citStr="Quattoni et al., 2007" startWordPosition="508" endWordPosition="511">more on the appearance while male users may lay more emphasis on the hardware configuration; younger users prefer to the app or game resources while older users may just pay attention to the basic function of calling or messaging. In recent years, there has been much work focused multilevel sentiment classification using structural learning models. Yi (2007) extends the standard conditional random fields to model the local sentiment flow. Ryan (2007) proposed structured models for fine-to-coarse sentiment analysis. Oscar (2011) proposed to discover fine-grained sentiment with hidden-state CRF(Quattoni et al., 2007). Yessenalina (2010) deployed the framework of latent structural SVMs(Yu and Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 201</context>
</contexts>
<marker>Quattoni, Wang, Morency, Collins, Darrell, 2007</marker>
<rawString>A. Quattoni, S. Wang, L.-P Morency, M. Collins, and T. Darrell. 2007. Hidden-state conditional random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Multiple aspect ranking using the good grief algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings of Annual Conference of the North American Chapter of the ACL,</booktitle>
<location>(NAACL).</location>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. In Proceedings of Annual Conference of the North American Chapter of the ACL, (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
</authors>
<title>Discovering fine-grained sentiment with latent variable structured prediction models.</title>
<date>2011</date>
<booktitle>In Proceedings ofAnnual European Conference on Information Retrieval,</booktitle>
<location>(ECIR).</location>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan McDonald. 2011. Discovering fine-grained sentiment with latent variable structured prediction models. In Proceedings ofAnnual European Conference on Information Retrieval, (ECIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>(ACL).</location>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. A joint model of text and aspect ratings for sentiment summarization. In Proceedings of Annual Meeting of the Association for Computational Linguistics, (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<location>(ICML).</location>
<contexts>
<context position="8461" citStr="Tsochantaridis et al., 2004" startWordPosition="1358" endWordPosition="1361">f entire document as ⃗wdoc, as follows: 335 example, starting with an initialization sentence set ⃗wTΨ(x,y,s) = ∑(⃗wTpolajψpol(xj) +⃗wTdo cψpol(xj)) (jEs � ∑ wTsubjajψsubj(xj) +y&apos;⃗wTdocψpol(x) jEs 2.3 We trained our model using the latent structural SVMs (Yu and Joachims., 2009). Training OP1: ⃗w,ξ&gt;0 2 ||w ||2 + N N ξi i=1 s.t.di : max ⃗wTΨ(xi, yi, s) &gt; sES(xi) We define 0(yi, = 1, that is, we view document level sentiment classification loss as the loss function. It should be noticed that OP1 is nonconvex. To circumvent the optimization difficulty, we employ the framework of structural SVMs (Tsochantaridis et al., 2004) with latent variables proposed by Yu (2009) using the CCCP algorithm (Yuille and Rangarajan., 2003). In terms of the formulation here, since the true informative sentence set is never observed, it is a hidden or latent variable. Thus, we keep si fixed to compute the upper bound for the concave part of each constraint, and rewrite −yi,s′) aints as ⃗wTΨ(xi,−yi,s′)− ⃗wTΨ(xi,yi,si)+1 y N(x) 1 + N(x) aining in which each sentence is with an aspect label, the training procedure alternates between solving an instance of the structural SVM using the si and predicting anew sentence until the learned w</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings of the International Conference on Machine Learning, (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Latent aspect rating analysis on review text data: A rating regression approach.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<contexts>
<context position="3988" citStr="Wang et al., 2010" startWordPosition="598" endWordPosition="601">essenalina (2010) deployed the framework of latent structural SVMs(Yu and Joachims., 2009) for multilevel sentiment classification. As for aspect level rating, ranking, or summarization, Benjamin(2007) em333 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 333–337, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics ployed the good grief algorithm for multiple aspect ranking and the extensions of the generative topic models were also widely studied, such as (Titov and McDonald., 2008; Brody and Elhadad., 2010; Wang et al., 2010; Li et al., 2011; Lu et al., 2011; Jo and Oh., 2011; Lin and He, 2009). In this paper, we build a general structural learning model for joint sentiment classification and aspect analysis using a latent discriminate method. Our model is able to predict the sentiment polarity of document as well as to identify aspect-specific sentences and predict the polarity of such sentences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 Model 2.1 Document Structure We assume that the polarity of do</context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010. Latent aspect rating analysis on review text data: A rating regression approach. In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Yisong Yue</author>
<author>Claire Cardie</author>
</authors>
<title>Multi-level structured models for document-level sentiment classification.</title>
<date>2010</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="4987" citStr="Yessenalina et al., 2010" startWordPosition="756" endWordPosition="760">ences. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 2 Model 2.1 Document Structure We assume that the polarity of document is closely related to some aspects for the reason that people are writing reviews to praise or criticize certain aspects. Therefore, each informative sentence of the document characterizes one aspect, expressing aspect specific polarity or subjective features. Similar to previous work on aspect analysis (Wang et al., 2010) and multi-level sentiment classification (Yessenalina et al., 2010), we define the aspect as a collection of synonyms. For instance, the word set {“value”, “price”, “cost”, “worth”, “quality”} is a synonym set corresponding to the aspect “price”. For each document, an aspect is described by one or several sentences expressing aspect specific polarity or subjective information. Let document be denoted by x, and y ∈ {+1, −1} represents the positive or negative polarity of the document, s is the set of informative sentences, in which each sentence is attached with certain aspect ai ∈ A = {a1, ..., ak}. Yessenalina (2010) chooses a sentence set that best explains</context>
<context position="6735" citStr="Yessenalina et al., 2010" startWordPosition="1059" endWordPosition="1062">l(xj) and ψsubj(xj) represents the polarity and subjectivity features of sentence xj respectively. ⃗wpol and ⃗wsubj denote the weight for polarity and subjectivity features. To be specific for each aspect, we have ⃗wpola and ⃗wsubja representing the vector of feature weight for aspect a to calculate the polarity and subjectivity score. � ⃗wT pola0 � . � .. ⃗wT polak To make prediction, we have the document-level sentiment classifier as h(x; ⃗w) = argmax y=±1 where S(x) = {s ⊆ 1,..., |x |: |s |≤ f(|x|)}, f(|x|) is a function that depends only on the number of sentences in x, as illustrated in (Yessenalina et al., 2010). Therefore, for each sentence xj, we compute the joint subjectivity and polarity score with respect to aspect a and label y as score(xj, a, y) = y·⃗wTpolaψpol(xj)+⃗wTsubjaψsubj(xj) we then assign aspect aj to sentence xj if aj = argmax score(xj, a, y) aEA After sorting score(xj, aj, y) in decreasing order and taking summation by selecting the top f(|x|) (or fewer, if there are fewer than f(|x|) that have positive joint score) sentences as the total score for each y ∈{+1,−1} , we then predict y with the higher joint score as the sentiment of the whole document. This formulation of ⃗wTΨ(x, y, s</context>
</contexts>
<marker>Yessenalina, Yue, Cardie, 2010</marker>
<rawString>Ainur Yessenalina, Yisong Yue, and Claire Cardie. 2010. Multi-level structured models for document-level sentiment classification. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Nam John Yu</author>
<author>Thorsten Joachims</author>
</authors>
<title>Learning structural svms with latent variables.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<location>(ICML).</location>
<marker>Yu, Joachims, 2009</marker>
<rawString>Chun-Nam John Yu and Thorsten Joachims. 2009. Learning structural svms with latent variables. In Proceedings of the International Conference on Machine Learning, (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Yuille</author>
<author>Anand Rangarajan</author>
</authors>
<title>The concave-convex procedure (cccp).</title>
<date>2003</date>
<journal>Neural Computation,</journal>
<pages>15--915</pages>
<marker>Yuille, Rangarajan, 2003</marker>
<rawString>A. L. Yuille and Anand Rangarajan. 2003. The concave-convex procedure (cccp). Neural Computation, 15:915–936.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>