<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000402">
<title confidence="0.999504">
Soft Dependency Constraints for Reordering
in Hierarchical Phrase-Based Translation
</title>
<author confidence="0.999192">
Yang Gao, Philipp Koehn and Alexandra Birch
</author>
<affiliation confidence="0.9984455">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.875683">
Edinburgh, UK, EH8 9AB
</address>
<email confidence="0.992011">
yanggao1119@gmail.com, pkoehn@inf.ed.ac.uk, a.birch@ed.ac.uk
</email>
<sectionHeader confidence="0.998558" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999684941176471">
Long-distance reordering remains one of the
biggest challenges facing machine translation.
We derive soft constraints from the source de-
pendency parsing to directly address the re-
ordering problem for the hierarchical phrase-
based model. Our approach significantly im-
proves Chinese–English machine translation
on a large-scale task by 0.84 BLEU points
on average. Moreover, when we switch the
tuning function from BLEU to the LRscore
which promotes reordering, we observe total
improvements of 1.21 BLEU, 1.30 LRscore
and 3.36 TER over the baseline. On aver-
age our approach improves reordering preci-
sion and recall by 6.9 and 0.3 absolute points,
respectively, and is found to be especially ef-
fective for long-distance reodering.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997354266666667">
Reordering, especially movement over longer dis-
tances, continues to be a hard problem in statistical
machine translation. It motivates much of the re-
cent work on tree-based translation models, such as
the hierarchical phrase-based model (Chiang, 2007)
which extends the phrase-based model (Koehn et al.,
2003) by allowing the so-called hierarchical phrases
containing subphrases.
The hierarchical phrase-based model captures the
recursiveness of language without relying on syntac-
tic annotation, and promises better reordering than
the phrase-based model. However, Birch et al.
(2009) find that although the hierarchical phrase-
based model outperforms the phrase-based model in
terms of medium-range reordering, it does equally
poorly in long-distance reordering due to constraints
to guarantee efficiency.
Syntax-based models that use phrase structure
constituent labels as non-terminals in their transfer
rules, exemplified by that of Galley et al. (2004),
produce smarter and syntactically motivated re-
ordering. However, when working with off-the-shelf
tools for parsing and alignment, this approach may
impose harsh limits on rule extraction and requires
serious efforts of optimization (Wang et al., 2010).
An alternative approach is to augment the general
hierarchical phrase-based model with soft syntactic
constraints. Here, we derive three word-based, com-
plementary constraints from the source dependency
parsing, including:
</bodyText>
<listItem confidence="0.991430727272727">
• A dependency orientation feature, trained with
maximum entropy on the word-aligned par-
allel data, which directly models the head-
dependent orientation for source words;
• An integer-valued cohesion penalty that com-
plements the dependency orientation feature,
and fires when a word is not translated with its
head. It measures derivation well-formedness
and is used to indirectly help reordering;
• An auxiliary unaligned penalty feature that mit-
igates search error given the other two features.
</listItem>
<bodyText confidence="0.9998848">
We achieve significant improvements in terms of
the overall translation quality and reordering behav-
ior. To our knowledge we are the first to use the
source dependency parsing to target the reordering
problem for hierarchical phrase-based MT.
</bodyText>
<page confidence="0.96906">
857
</page>
<note confidence="0.9588185">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 857–868,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<figure confidence="0.8940262">
punct
澳洲 是 与 北韩 有 邦交 的 少数 国家 之一 .
Aozhou shi yu Beihan you bangjiao de shaoshu guojia zhiyi .
Australia is with North Korea have dipl. rels. that few countries one of .
Australia is one of the few countries that have diplomatic relations with North Korea.
</figure>
<figureCaption confidence="0.990738">
Figure 1: Example dependency parsing generated by the Stanford Parser. The Chinese source sentence and its English
translation come from (Chiang, 2007).
</figureCaption>
<figure confidence="0.987831571428572">
attr
rcmod
top
pobj dobj
prep
cpm nummod
nn
</figure>
<sectionHeader confidence="0.981629" genericHeader="method">
2 Three Soft Dependency Constraints
</sectionHeader>
<bodyText confidence="0.999928666666667">
Our features are based on the source dependency
parsing, as shown in Figure 1. The basic unit of de-
pendency parsing is a triple consisting of the depen-
dent word, the head word and the dependency rela-
tion that connects them. For example, in Figure 1,
an arrow labelled prep goes from the word yu (En-
glish with) to the word you (English have), showing
that yu is a prepositional modifier of you.
We use the Stanford Parser1 to generate depen-
dency parsing, which automatically extracts de-
pendency relations from phrase structure parsing
(de Marneffe et al., 2006).
</bodyText>
<subsectionHeader confidence="0.893019">
2.1 Dependency Orientation
</subsectionHeader>
<bodyText confidence="0.999702666666666">
Based on the assumption that constituents generally
move as a whole (Quirk et al., 2005), we decompose
the sentence reordering probability into the reorder-
ing probability for each aligned source word with re-
spect to its head, excluding the root word at the top
of the dependency hierarchy which does not have a
head word. Similarly, Hayashi et al. (2010) also take
a word-based reordering approach for HPBMT, but
they model all possible pairwise orientation from
the source side as a general linear ordering prob-
lem (Tromble and Eisner, 2009).
To be more specific, we have a maximum entropy
orientation classifier that predicts the probability of
a source word being translated in a monotone or re-
versed manner with respect to its head. For example,
</bodyText>
<footnote confidence="0.722313">
1http://nlp.stanford.edu/software/lex-parser.shtml
</footnote>
<figure confidence="0.97190325">
(a) (b)
idep idep ihead
ihead
S 1 S 2 S 3 S 1 S 2 S 3
</figure>
<bodyText confidence="0.863283166666667">
en tsto il lust rateorient at ionclas-si fication.In( a),mo
notone(M); in (b), reversed (R). given thealignmenti
nFigure2(a),withthe align- ment p oint s(e dep,nd
ep)f orthe s ource d epend ent wor d and(e head,dhea
d)fo rth e source head wo rd, wed efinetw oori entat
io nclas ses as:e=taif(n dep−she ad )
</bodyText>
<equation confidence="0.940349333333333">
( _ J e p− Uead ) j0eotherwis e (1)Whe n a
1 s ourcehead
ord
</equation>
<bodyText confidence="0.992164666666667">
epen d entwor disa li gnedtomul tipl e t argetwo
rd s,asshow ninFig ure2(b ), wealw ay staket hefirs
tt arget w ordf oro rien tation clas sifi cation.Theo
</bodyText>
<sectionHeader confidence="0.358148" genericHeader="method">
rientationclas
</sectionHeader>
<bodyText confidence="0.986827666666667">
sifi eristrained onthelarg ew ord-ali gn edp arall
elcorpus.Var iousfeat urescan potenti allybeus ed,
basedonthes ou rcean d targ et con textas wel lassyn
tactica nd sema nt icanalysi s.T heorient ationpro b
abi lityisevalu ated inthefo l- lowinglog -l ine areq
uation ,wherenist hesourcec ontex t , s ist hesour
cedepend e nc ypa rsing, d∗isthetar getconte xt pr
odu cedsof ar,t∗is the align -m entp ro du ced sofara
ndni stheorie nt ati onc l as s:8 58ientation class:
</bodyText>
<table confidence="0.9945934375">
e2:W T 1 Figur T 1
l ignm T 2 orda T 2
T 3 T 3
T 4 T 4
Word p(M) p(R)
Aozhou 0.81 0.19
shi NA NA
yu 0.45 0.55
Beihan 0.88 0.12
you 0.12 0.88
bangjiao 0.83 0.17
de 0.58 0.42
shaoshu 0.30 0.70
guojia 0.19 0.81
zhiyi 0.85 0.15
. 1.00 0.00
</table>
<tableCaption confidence="0.957914">
Table 1: The dependency orientation probabilities for
words of the Figure 1 sentence, in both monotone and
reversed cases.
</tableCaption>
<equation confidence="0.898964">
p(c|f, d, e*, a*) =
exp(ENn=1 Anhn(f, d, e*, a*, c))
Ec&apos;E{M,R} exp(�Nn=1 Anhn(f, d, e*, a*, c�))
(2)
</equation>
<bodyText confidence="0.998086518518519">
Currently, we only use two kinds of features: (1)
the concatenation of the source dependent word with
the dependency relation and (2) the concatenation of
the source head word with the dependency relation.
So for the word yu (English with) in Figure 1, we
extract these features for orientation classification:
prep DEP yu and prep HEAD you.
We define the dependency orientation feature
score for a translation hypothesis as the sum of the
log orientation probabilities for each source word.
This score is used as one feature in the log-linear
formulation of the hierarchical phrase-based model.
Table 1 shows the dependency orientation proba-
bilities for all words in the Figure 1 sentence. Most
interestingly, the orientation probabilities for you
(English have) strongly support global reordering of
one of the few countries with the relative clause that
have diplomatic relations with North Korea. We find
that it is a general trend for long-distance reordering
to gain stronger support, since it is often correlated
with prominent reordering patterns (such as relative
clause and preposition) as well as lexical evidences
(such as “... zhiyi” (English “one of ...”)) for which
the reversed orientation takes up the majority of the
training cases.
Consider the following rules (both terminals and
nonterminals are coindexed):
</bodyText>
<equation confidence="0.9962615">
X → (yu1 Beihan2 you3 bangjiao4,
have3 dipl.4 rels.4 with1 North2 Korea2)
X → (yu1 Beihan2 you3 bangjiao4,
with1 North2 Korea2 have3 dipl.4 rels.4)
</equation>
<bodyText confidence="0.999924965517241">
According to Table 1, the hypothesis that applies
Rule 3 receives a probability of 0.55 for yu getting
reversed with its head you, as well as 0.88 and 0.83
for translating Beihan and bangjiao in a monotone
manner with respect to their heads. Rule 4 is associ-
ated with probabilities 0.45, 0.88 and 0.83 for mono-
tone translation of yu, Beihan and bangjiao. Thus
our dependency orientation feature is able to trace
the difference in ordering the PP with North Korea
(as underlined) and the VP have dipl. rels. down to
the orientation of the preposition yu (English with)
with respect to its head you (English have), and pro-
mote Rule 3 which has the right word order.
The word you (English have) cannot be scored
in Rules 3 or 4, since its head word zhiyi (English
one of) is not covered. In this case, we say that
the word you is unresolved. We carry an unre-
solved word along in the derivation process until we
reach a terminator hypothesis which translates the
head word. Then the resulting dependency orien-
tation score is added to the terminator hypothesis.
This means that the dependency orientation feature
is “stateless”, i.e., hypotheses that cover the same
source span with the same orientation information
will receive the same feature score, regardless of the
derivation history. Therefore, Derivation 5 in the fol-
lowing will have the same dependency orientation
score as Derivation (Rule) 3, and Derivation 6 will
score the same as Derivation (Rule) 4.
</bodyText>
<equation confidence="0.9718396">
5.1 X → (yu1, with1)
5.2 X → (Beihan1, North1 Korea1)
5.3 X → (X1 X2, X1 X2)
5.4 X → (X1 you2 bangjiao3,
have2 dipl.3 rels.3 X1)
859
6.1 X → (Beihan1 you2, North1 Korea1 has2)
6.2 X → (X1 bangjiao2, X1 dipl.2 rels.2)
6.3 X → (yu1 X2, with1 X2)
(6)
</equation>
<subsectionHeader confidence="0.998932">
2.2 Cohesion Penalty
</subsectionHeader>
<bodyText confidence="0.999930347222222">
When the dependency orientation for a word is
temporarily unavailable (“unresolved”), a cohesion
penalty fires. Cohesion penalty counts the total oc-
currences of unresolved words for a translation hy-
pothesis, which involve newly encountered unre-
solved words as well as old unresolved words car-
ried on from the derivation history. Therefore, the
cohesion penalty is “stateful”, i.e., an unresolved
word is repeatedly penalized until it gets resolved.
Under this definition, the most cohesive derivation
translates the entire sentence with one rule, where
every word is locally resolved. The least cohe-
sive derivation translates each word individually and
glues word translations together. Consulting Fig-
ure 1, the cohesion penalty in Derivation 5 is 4, since
the word yu (English with) is unresolved twice (in
5.1 and 5.3), and both Beihan (English North Ko-
rea) and you (English have) are unresolved once (in
5.2 and 5.4, respectively); the cohesion penalty in
Derivation 6 is 5: 2 from Beihan (English North
Korea) (in 6.1 and 6.2) and 3 from you (English
have). As a result, Derivation 5 gets promoted,
which echoes with human intuition since Deriva-
tion 5 translates syntactic constituents. To sum
up, our cohesion penalty provides an integer-valued
measure of derivation well-formedness in the hierar-
chical phrase-based MT. Same as dependency orien-
tation, the cohesion penalty is not applicable to the
root word of the sentence.
We propose the cohesion penalty in order to fur-
ther improve reordering, especially in long-distance
cases, since a well-formed derivation at an earlier
stage makes it more likely to explore hierarchical
rules that perform more reliable reordering. In this
respect, the cohesion penalty can be seen as an aid
to the glue rule penalty and as an alternative to
constituency-based constraints.
Specifically, the glue rule penalty (Chiang, 2007)
promotes hierarchical rules. Hierarchical rules
whose lexical evidence helps resolve words locally
will also be favored by our cohesion penalty feature.
However, ignorant of the syntactic structure, the
glue rule penalty may penalize a reasonably cohe-
sive derivation such as Derivation 5 and at the same
time promote a less cohesive hierarchical transla-
tion, such as Derivation 6.
Compared with constituency constraints based on
the phrase structure, our cohesion penalty derived
from the binary dependency parsing has two differ-
ent characteristics.
First, our cohesion penalty is by nature more tol-
erant to some meaningful noncontituent translations.
For example, constituency constraints in (Chiang,
2005; Marton and Resnik, 2008; Chiang et al., 2009)
would penalize Rule 7 below which is useful for
German–English translation (Koehn et al., 2003),
and Rule 8 which can be applied to the Figure 1
sentence. Fuzzy constituency constraints can solve
this problem with a combination of product cate-
gories and slash categories (Chiang, 2010). Yet
our cohesion penalty by nature admits these trans-
lations as cohesive (with no extra cost from es and
Aozhou since both are locally resolved). Admittedly,
our current implementation of the cohesion penalty
is blind to some other meaningful nonconstituent
collocations, such as neighbouring siblings of a
common uncovered head (regulated as the “floating
structure” in (Shen et al., 2008)). A concrete exam-
ple is Rule 9 which is useful for the Figure 1 sen-
tence. To address this problem, another feature can
be defined in the same manner to capture how each
head word is translated with its children.
</bodyText>
<equation confidence="0.999282333333333">
X → (es1 gibt2, there1 is2)
X → (Aozhou1 shi2, Australia1 is2)
X → (shaoshu1 guojia2, few1 countries2)
</equation>
<bodyText confidence="0.999311384615385">
Second, our cohesion penalty can be by na-
ture more discriminative. Compared with the
constituency constraints, the cohesion penalty is
integer-valued, and can be made sensitive to the
depth of each word in the dependency hierarchy (see
Section 2.4). Inspired by (Marton and Resnik, 2008;
Chiang et al., 2009), the cohesion penalty could
also be made sensitive to the dependency relation
of each word. However, this drastically increases
the number of features and requires a tuning algo-
rithm which scales better to high-dimensional model
spaces, such as MIRA (Watanabe et al., 2007; Chi-
ang et al., 2008).
</bodyText>
<page confidence="0.994042">
860
</page>
<figureCaption confidence="0.998806">
Figure 3: Using 2 bins for the dependency parse tree of
the Figure 1 sentence.
</figureCaption>
<subsectionHeader confidence="0.998816">
2.3 Unaligned Penalty
</subsectionHeader>
<bodyText confidence="0.999980428571429">
The dependency orientation and cohesion penalty
cannot be applied to unaligned source words. This
may lead to search error, such as dropping (i.e., un-
aligning) key content words that are important for
lexical translation and reordering. The problem is
mitigated by an unaligned penalty applicable to all
words in the dependency hierarchy.
</bodyText>
<subsectionHeader confidence="0.998231">
2.4 Grouping Words into Bins
</subsectionHeader>
<bodyText confidence="0.999372230769231">
Having defined dependency orientation, cohesion
penalty and unaligned penalty, we section the source
dependency tree uniformly by depth, group words at
different depths into bins and only add the feature
scores of a word into its respective bin. In this way
one feature is split into several sub-features and each
can be trained discriminatively by MERT.
There are two motivations for binning. The pri-
mary motivation is to distinguish long-distance re-
ordering which is still problematic for the hiero-
style model, since local reorderings generally op-
erate at low levels of the tree while high tree lev-
els tend to take more care of long-distance reorder-
ing. Parsing accuracy is another concern, yet its
impact on feature performance is intricate and our
MaxEnt-trained dependency orientation feature also
buffers against odd parsing. Using bins, we simply
let the tuning process decide how much to trust fea-
ture scores coming from different levels of parsing.
We experiment with 1, 2 and 3 bins. An example
of binning for the Figure 1 sentence can be found in
Figure 3. With 2 bins (hereafter “bin-2”), words at
Depth 1 and 2 are grouped into Bin 1, and words at
Depth 3, 4, 5 are grouped into Bin 2. As a simple
approach, binning does not take into account how
the tree levels spread out.
</bodyText>
<sectionHeader confidence="0.999724" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99979">
3.1 General Settings
</subsectionHeader>
<bodyText confidence="0.999975466666667">
We used a parallel training corpus with 2.1 mil-
lion Chinese–English sentence pairs, aligned by
GIZA++. The Chinese side was parsed by the Stan-
ford Parser. Then we extracted 33.8 million exam-
ples from the parsed Chinese side to discriminatively
train 1.1 million features (using the MegaM soft-
ware2) for dependency orientation classification.
We trained three 5-gram language models with
modified Kneser-Ney smoothing (Kneser and Ney,
1995): one on the English half of the parallel cor-
pus, one on the Xinhua part of the Gigaword corpus,
one on the AFP part, and interpolated them for best
fit to the tuning set (Schwenk and Koehn, 2008).
We used NIST MT06 evaluation data (1664 lines)
as our tuning set, and tested on NIST MT02 (878
lines), MT05 (1082 lines) and MT08 (1357 lines).
Our baseline system was the Moses implemen-
tation of the hierarchical phrase-based model with
standard settings (Hoang et al., 2009). When only
1 bin was used, 3 additional features were added to
the baseline, one each from the soft dependency con-
straints. When we used 2 or 3 bins, the additional
feature counts doubled or tripled. We preserved ter-
minal alignment alongside nonterminal alignment
during the rule extraction and output word align-
ments together with translated strings. Since the fea-
tures we currently define are based entirely on the
source side, we used preprocessing to speed up de-
coding of our feature-augmented model. All experi-
ments were tuned with MERT (Och, 2003).
</bodyText>
<subsectionHeader confidence="0.999759">
3.2 Using BLEU as the Tuning Metric
</subsectionHeader>
<bodyText confidence="0.999955333333333">
As a standard practice, we first used BLEU (Pap-
ineni et al., 2002) as the objective function for tun-
ing. Table 2 shows the results of the baseline model
as well as our complete feature-augmented model
with different bin numbers. With the “bin-2” setting,
we get substantial improvement of up to 1.03 BLEU
points (on MT02 data), and 0.84 BLEU points on
average. Using more than one bin (i.e., differentiat-
ing tree depths) is generally beneficial, although the
</bodyText>
<footnote confidence="0.584946">
2http://www.umiacs.umd.edu/∼hal/megam/index.html
</footnote>
<figure confidence="0.998994038461538">
Depth 5
pobj
3L
top
punct
attr
ABX
k
�� �
!&apos;*t: IQI:
4
rcmod
nummod
nn
prep
5
dobj
cpm
0
AS-Z
Depth 1
Depth 2
Depth 3
Depth 4
Bin 1
Bin 2
</figure>
<page confidence="0.976206">
861
</page>
<table confidence="0.999852166666667">
Setting BLEU / LRscore / TER
MT02 MT05 MT08 Average
baseline 34.01 / 41.85 / 68.93 32.23 / 40.50 / 68.15 28.09 / 37.17 / 66.82 31.44 / 39.84 / 67.97
bin-2 35.04 / 43.07 / 65.58 33.18 / 41.62 / 65.59 28.63 / 38.12 / 65.36 32.28 / 40.94 / 65.51
baseline-lr 34.23 / 42.06 / 68.08 32.28 / 40.61 / 67.61 27.99 / 37.27 / 66.98 31.50 / 39.98 / 67.56
bin-2-lr 35.42 / 43.25 / 64.82 33.44 / 41.80 / 64.88 29.10 / 38.38 / 64.14 32.65 / 41.14 / 64.61
</table>
<tableCaption confidence="0.870494666666667">
Table 4: Results for the baseline model and the complete feature-augmented model with 2 bins (“bin-2”), using BLEU
and LRscore (“-lr”) as the tuning function. The BLEU scores of “bin-2” and “bin-2-lr” are significantly better than
baseline (p &lt; 0.05), computed by paired bootstrap resampling (Koehn, 2004).
</tableCaption>
<table confidence="0.999899833333333">
Setting BLEU
MT02 MT05 MT08 Average
baseline 34.01 32.23 28.09 31.44
bin-1 34.20 32.13 28.41 31.58(+.14)
bin-2 35.04 33.18 28.63 32.28(+.84)
bin-3 34.35 32.79 28.37 31.84(+.40)
</table>
<tableCaption confidence="0.994413">
Table 2: Results of the baseline model as well as our
complete feature-augmented model with 1, 2 and 3 bins.
BLEU is the tuning function.
</tableCaption>
<table confidence="0.9998755">
Setting BLEU
MT02 MT05 MT08 Average
baseline 34.01 32.23 28.09 31.44
dep 34.26 32.58 28.07 31.64(+.20)
dep+coP 34.47 32.81 28.61 31.96(+.52)
dep+coP+unP 35.04 33.18 28.63 32.28(+.84)
</table>
<tableCaption confidence="0.964433">
Table 3: Contributions of the three soft dependency con-
straints, with the “bin-2” setting
</tableCaption>
<bodyText confidence="0.999473">
problem of overfitting sets in when we use 3 bins
(with slightly higher tuning BLEU, not shown here).
We also studied the effect of adding features in-
crementally onto the baseline with the “bin-2” set-
ting, as shown in Table 3. On average, all three fea-
tures seem to have similar contributions.
</bodyText>
<subsectionHeader confidence="0.998927">
3.3 Using LRscore as the Tuning Metric
</subsectionHeader>
<bodyText confidence="0.9999867">
Since our features are proposed to address the re-
ordering problem and BLEU is not sensitive enough
to reordering (especially in long-distance cases), we
have also tried tuning with a metric that highlights
reordering, i.e., the LRscore (Birch and Osborne,
2010). LRscore is a linear interpolation of a lexi-
cal metric and a reordering metric. We interpolated
BLEU (as the lexical metric) with the Kendall’s
tau permutation distance (as the reordering metric).
The Kendall’s tau permutation distance measures the
relative word order difference between the transla-
tion output and the reference(s) and is particularly
sensitive to long-distance reordering. Testing re-
sults in terms of BLEU, LRscore and TER (Snover
et al., 2006) are shown in Table 4. Tuned with
the LRscore, our feature-augmented model achieves
further average improvements (compare “bin-2” and
“bin-2-lr”) of 0.20 LRscore as well as 0.37 BLEU
and 0.90 TER. Note that while the BLEU increase
can largely be seen as a projection of the LRscore
increase back into its lexical component, the consis-
tent TER drop confirms that our improvement is not
metric-specific3. Altogether the final improvement
is 1.21 BLEU, 1.30 LRscore and 3.36 TER on aver-
age over the baseline.
However, an important question is how our fea-
tures affect short, medium and long-distance re-
orderings. In the next section, we conduct quanti-
tative analysis on reordering precision and recall, as
well as qualitative analysis on translation examples.
</bodyText>
<sectionHeader confidence="0.999538" genericHeader="method">
4 Analysis
</sectionHeader>
<subsectionHeader confidence="0.998784">
4.1 Precision and Recall of Reordering
</subsectionHeader>
<bodyText confidence="0.706411625">
The key to obtaining precision and recall for reorder-
ing is to investigate whether reorderings in the refer-
ences are reproduced in the translations. We calcu-
late precision as the number of reproduced reorder-
ings divided by the total number of reorderings in
the translation, and recall as the number of repro-
duced reorderings divided by the number of reorder-
3One of our reviewers points out that according to the in-
ductive learning theory, it is counter-intuitive to improve on
BLEU and TER if we optimize by the LRscore. Yet we do
observe some other papers reporting increased TER or other
metric scores when BLEU is used for tuning (Carpuat and Wu,
2007; Shen et al., 2008), suggesting that MT evaluation might
be too complicated to be characterized just with inductive learn-
ing. Similar results based on extensive experiments can also be
found in (Birch and Osborne, 2011).
</bodyText>
<page confidence="0.989053">
862
</page>
<table confidence="0.9998012">
Setting MT02 MT05 MT08 Average
baseline 37.0 35.3 35.6 36.0
bin-2 42.7 40.8 38.7 40.7 (+4.7)
baseline-lr 37.3 35.0 34.2 35.5 (-0.5)
bin-2-lr 44.1 42.0 42.5 42.9 (+6.9)
</table>
<tableCaption confidence="0.943223">
Table 5: Overall precision for the test sets.
</tableCaption>
<table confidence="0.9999274">
Setting MT02 MT05 MT08 Average
baseline 37.5 36.2 33.2 35.6
bin-2 36.8 35.9 31.8 34.8 (-0.8)
baseline-lr 37.0 35.6 32.2 34.9 (-0.7)
bin-2-lr 37.7 36.7 33.2 35.9 (+0.3)
</table>
<tableCaption confidence="0.998831">
Table 6: Overall recall for the test sets.
</tableCaption>
<bodyText confidence="0.999789848484849">
ings in the reference. Then we average the precision
and recall over all four reference translations.
Details of measuring reproduced reordering can
be found in Birch et al. (2008). An important dif-
ference in this work is in handling many-to-one and
one-to-many alignments, as we only retain the first
word alignment for any source or target word which
has multiple alignments. This is consistent with our
treatment in dependency orientation classification,
and results in more reorderings being extracted.
From Table 5 we can see that our features im-
prove precision by an average of 4.7 absolute points
when BLEU is used for tuning (“bin-2”). Switch-
ing from BLEU to the LRscore (“bin-2-lr”), we gain
2.2 points more and have a total improvement of 6.9
absolute points on average. This is a novel and im-
portant finding as we directly show that the quality
of reordering has been improved.
From Table 6, we observe a small but consistent
increase in recall with the “bin-2-lr” setting, averag-
ing 0.3 absolute points. However, the drop of recall
with the “bin-2” setting (by an average 0.8 points
from the baseline) is unexpected. It seems that when
applying our features alone, we are trading a small
drop in recall for a large gain in precision.
In Figure 4 we break down the precision and re-
call statistics in MT08 by the reordering width on
the source side. We find that our features con-
sistently help precision over all word ranges, with
more substantial improvement in the medium and
long word ranges. When recall is concerned, our
model does not help for short ranges of up to Width
4, but improves consistently for longer distance re-
</bodyText>
<figure confidence="0.9601355">
Reordering Widths
Reordering Widths
</figure>
<figureCaption confidence="0.988697">
Figure 4: Precision and recall breakdown for the source-
side reordering width 2-15 for the NIST MT08 dataset.
</figureCaption>
<bodyText confidence="0.9994434">
orderings. Once again, it seems that the feature-
augmented model is able to benefit from tuning with
a metric that is more sensitive to reordering, as the
performance of “bin-2-lr” is the best in all reorder-
ing statistics.
</bodyText>
<subsectionHeader confidence="0.996688">
4.2 Translation Examples
</subsectionHeader>
<bodyText confidence="0.999839230769231">
We observe a number of outputs with improved
word order and more cohesive derivation, as the one
in Figure 5. The baseline translation is fragmented
and requires more glue rule applications. Specifi-
cally, it fails to translate the boxed area as a whole
into “the relations between the palestinian national
authority (pna) and the european union (eu)”. The
key dependency orientation that controls the global
reordering is between the prepositional modifier dui
(English to) and its head word, the verb gandao (En-
glish feel). The baseline system translates dui (En-
glish to) as “of the” and misorders the sentence. In
contrast, the feature-augmented model “bin-2” cap-
</bodyText>
<figure confidence="0.973574">
2 3 4 5 6 7 8 9 10 11 12 13 14 15
Precision
0.0 0.1 0.2 0.3 0.4 0.5 0.6
baseline
bin−2
bin−2−lr
2 3 4 5 6 7 8 9 10 11 12 13 14 15
Recall
0.0 0.1 0.2 0.3 0.4 0.5 0.6
baseline
bin−2
bin−2−lr
</figure>
<page confidence="0.658302">
863
</page>
<figure confidence="0.835174571428571">
prep
5ittnft , Prt$&apos;r At t P�A 4Y_)J 4n#J 5 OkA _z*_q 0 �9
yucitongshi , Abasi dui Ba minzu quanli jigou yu Oumeng zhijian de guanxi
at the same time , Abbas to Palestinian Natl. Authority with EU between DE relations
AJf�1 AA �
gandao manyi .
feel satisfaction .
</figure>
<bodyText confidence="0.82407575">
baseline: [at the same time, abbas] [of the] [palestinian [national authority ( pna )]] [and] [is satisfied
with the [relations] [between [the european union ( eu )]]] [.]
bin-2: [at the same time, abbas] [expressed satisfaction with [the relations between the [palestinian
[national authority ( pna ) [and the european union ( eu )]]]] .]
</bodyText>
<figureCaption confidence="0.9987985">
Figure 5: Example translations from the NIST MT08 set, output by the baseline model and “bin-2” model. The “-lr”
version outputs are quite similar and not shown here. Translation outputs are in lower case.
</figureCaption>
<bodyText confidence="0.992603">
tures the boxed area as a whole and uses Rule 10 to
perform the right global reordering.
</bodyText>
<equation confidence="0.9929105">
X → (dui1 X2 gandao3 manyi4 .5 , (10)
expressed3 satisfaction4 with1 X2 .5 )
</equation>
<sectionHeader confidence="0.999853" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999959783333334">
In recent years, there has been a growing body of re-
search on using dependency for statistical machine
translation. Some directly encodes dependency in
the translation model (Ding and Palmer, 2005; Quirk
et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi
and Liu, 2010), while others use dependency as a
soft constraint (Cherry, 2008; Bach et al., 2009a,b;
Chang et al., 2009). Among them, Shen et al. (2008)
report that just filtering the phrase table by the so-
called well-formed target dependency structure does
not help, yet adding a target dependency language
model improves performance significantly. Our in-
tuitive interpretation is that the target dependency
language model capitalizes on two characteristics of
the dependency structure: it is based on words and it
directly connects head and child. Therefore, the tar-
get dependency language model makes good use of
the dependency representation as well as the target
side training data.
We follow the second line of research, and derive
three word-based soft constraints from the source
dependency parsing. Note that although we reuse
the word “cohesion” to name one of the constraints,
our work is different from (Cherry, 2008; Bach
et al., 2009a,b) which have successfully defined an-
other cohesion constraint from the source depen-
dency structure, with the aim of improving reorder-
ing in phrase-based MT.
To take a glance, Cherry (2008) and Bach et al.
(2009b) define cohesion as translating a source de-
pendency subtree contiguously into the target side
without interruption (span or subtree overlapping),
following Fox (2002). This span-based cohesion
constraint has a different criterion from our word-
based cohesion penalty and often leads to opposite
conclusions. Bach et al. (2009a) also use cohesion to
correlate with the lexicalized reordering model (Till-
man, 2004; Koehn et al., 2005), whereas we define
an orthogonal dependency orientation feature to ex-
plicitly model head-dependent reordering.
The fundamental difference, however, is rooted
in the translation model. Their span-based cohe-
sion constraint is implemented as an “interruption
check” to encourage finishing a subtree before trans-
lating something else. This check is very effective
for phrase-based decoding which searches over an
entire space within the distortion limit in order to
advance a hypothesis. In fact, it constrains reorder-
ing for the phrase-based model, as Cherry finds that
the cohesion constraint is used “primarily to prevent
distortion” and to provide “an intelligent estimate as
to when source order must be respected” (Cherry,
2008). However, since the hierarchical phrase-
based model already conducts principled reorder-
ing search with rules through the more constrained
chart-decoding, ill-formed derivations exhibit them-
selves more often as nonconstituent translation than
interrupted translation as defined in (Cherry, 2008;
Bach et al., 2009a,b) (They do have a non-empty in-
tersection, but neither subsumes the other). There-
</bodyText>
<page confidence="0.995883">
864
</page>
<bodyText confidence="0.999899170212766">
fore, our cohesion penalty is better suited for the hi-
erarchical phrase-based model.
To discourage nonconstituent translation, Chiang
(2005) has proposed a constituency feature to exam-
ine whether a source rule span matches the source
constituent as defined by phrase structure parsing.
Finer-grained constituency constraints significantly
improve hierarchical phrase-based MT when ap-
plied on the source side (Marton and Resnik, 2008;
Chiang et al., 2009), or on the target side in a
more tolerant fashion (Zollmann and Venugopal,
2006). Using both source and target syntax, but
relaxing on rule extraction and substitution enables
HPBMT to produce more well-formed and syntac-
tically richer derivations (Chiang, 2010). Softening
constituency matching with latent syntactic distribu-
tions proves to be helpful (Huang et al., 2010). Com-
pared to constituency-based approaches, our cohe-
sion penalty based on the dependency structure nat-
urally supports constituent translations as well as
some nonconstituent translations, if not all of them
(as discussed in Section 2.2).
Our dependency orientation feature is similar to
the order model within dependency treelet trans-
lation (Quirk et al., 2005). Yet instead of a
head-relative position number for each modifier
word, we simply predict the head-dependent ori-
entation which is either monotone or reversed.
Our coarser-grained approach is more robust from
a machine learning perspective, yet still captures
prominent and long-distance reordering patterns ob-
served in Chinese–English (Wang et al., 2007),
German–English (Collins et al., 2005), Japanese–
English (Katz-Brown and Collins, 2008) and trans-
lation from English to a group of SOV lan-
guages (Xu et al., 2009). Not committed to spe-
cific language pairs, we learn orientation classifi-
cation from the word-aligned parallel data through
maximum entropy training as Zens and Ney (2006)
and Chang et al. (2009) for phrase-based translation
and Xiong et al. (2006) for the BTG model (Wu,
1996). While Chang et al. (2009) also make use
of source dependency, their orientation classifica-
tion concerns two subsequent phrase pairs in the left-
to-right phrase-based decoding (as apposed to each
dependent word and its head) and is therefore less
linguistically-motivated.
</bodyText>
<sectionHeader confidence="0.994646" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999918710526316">
We have derived three novel features from the source
dependency structure for hierarchical phrase-based
MT. They work as a whole to capitalize on two char-
acteristics of the dependency representation: it is di-
rectly based on words and it directly connects head
and child. The effectiveness of our approach has
been demonstrated by a final average improvement
of 1.21 BLEU, 1.30 LRscore and 3.36 TER. On av-
erage we improve reordering precision and recall by
6.9 and 0.3 absolute points, respectively, over the
baseline. Moreover, our approach is found to be es-
pecially effective for long-distance reodering.
As mentioned in Section 2.2, the cohesion penalty
can be extended to also account for how a head
word is translated with its children so that we are
not biased towards one form of cohesive noncon-
stituent translation. All our features can be made
sensitive to the dependency relations or even words.
This fine-grainedness is especially desirable when
we want to reward words for being unaligned or un-
resolved, such as punctuations and function words
in certain context. Word alignment quality is crucial
for the performance of our features as well as the
LRscore which uses word alignment to compute the
permutation distance. As an alternative to GIZA++,
we would like to experiment with syntactically in-
formed aligners that better handle function words
which often exhibit high alignment ambiguity due
to low cross-lingual correspondence.
Finally, since our soft dependency constraints
promote reordering without increasing model com-
plexity, further gains can be achieved when combin-
ing our approach with orthogonal studies to improve
the quantity and quality of hierarchical (reordering)
rules, such as relaxing hierarchical rule extraction
constraints (Setiawan and Resnik, 2010) and selec-
tively lexicalizing rules with function words (Seti-
awan et al., 2009).
</bodyText>
<sectionHeader confidence="0.991721" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.952101857142857">
We would like to thank Miles Osborne, Adam
Lopez, Barry Haddow, Hieu Hoang, Philip Williams
and Michael Auli in the Edinburgh SMT group
as well as Kevin Knight, David Chiang and An-
drew Dai for inspiring discussions. We appreci-
ate Pichuan Chang, Huihsin Tseng, Richard Zens,
Matthew Snover and Nguyen Bach for helping us
</bodyText>
<page confidence="0.995272">
865
</page>
<bodyText confidence="0.999894625">
understand their brilliant work. Many thanks to the
anonymous reviewers for their insightful comments
and suggestions. This work was supported in part
by the EuroMatrixPlus project funded by the Euro-
pean Commission (7th Framework Programme) and
in part under the GALE program of the Defense
Advanced Research Projects Agency, Contract No.
HR0011-06-C-0022.
</bodyText>
<sectionHeader confidence="0.997855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997813044444444">
Bach, N., Gao, Q., and Vogel, S. (2009a). Source-
side dependency tree reordering models with sub-
tree movements and constraints. In Proceedings of
the Twelfth Machine Translation Summit (MTSummit-
XII), Ottawa, Canada. International Association for
Machine Translation.
Bach, N., Vogel, S., and Cherry, C. (2009b). Cohesive
constraints in a beam search phrase-based decoder. In
Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
Companion Volume: Short Papers, pages 1–4, Boul-
der, Colorado.
Birch, A., Blunsom, P., and Osborne, M. (2009). A quan-
titative analysis of reordering phenomena. In Proceed-
ings of the Fourth Workshop on Statistical Machine
Translation, pages 197–205, Athens, Greece.
Birch, A. and Osborne, M. (2010). LRscore for evaluat-
ing lexical and reordering quality in MT. In Proceed-
ings of the Joint Fifth Workshop on Statistical Machine
Translation and MetricsMATR, pages 327–332, Upp-
sala, Sweden.
Birch, A. and Osborne, M. (2011). Reordering metrics
for mt. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Techologies, pages 1027–1035, Port-
land, Oregon, USA.
Birch, A., Osborne, M., and Koehn, P. (2008). Predict-
ing success in machine translation. In Proceedings of
the 2008 Conference on Empirical Methods in Natu-
ral Language Processing, pages 745–754, Honolulu,
Hawaii.
Carpuat, M. and Wu, D. (2007). Improving statistical
machine translation using word sense disambiguation.
In Proceedings of the 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 61–72, Prague, Czech Republic.
Chang, P.-C., Tseng, H., Jurafsky, D., and Manning, C. D.
(2009). Discriminative reordering with Chinese gram-
matical relations features. In Proceedings of the Third
Workshop on Syntax and Structure in Statistical Trans-
lation (SSST-3) at NAACL HLT 2009, pages 51–59,
Boulder, Colorado.
Cherry, C. (2008). Cohesive phrase-based decoding for
statistical machine translation. In Proceedings ofACL-
08: HLT, pages 72–80, Columbus, Ohio.
Chiang, D. (2005). A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics, ACL ’05, pages 263–270, Strouds-
burg, PA, USA.
Chiang, D. (2007). Hierarchical phrase-based translation.
Computational Linguistics, 33(2).
Chiang, D. (2010). Learning to translate with source and
target syntax. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 1443–1452, Uppsala, Sweden.
Chiang, D., Knight, K., and Wang, W. (2009). 11,001
new features for statistical machine translation. In Pro-
ceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
218–226, Boulder, Colorado.
Chiang, D., Marton, Y., and Resnik, P. (2008). Online
large-margin training of syntactic and structural trans-
lation features. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Process-
ing, pages 224–233, Honolulu, Hawaii.
Collins, M., Koehn, P., and Kucerova, I. (2005). Clause
restructuring for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL’05), pages
531–540, Ann Arbor, Michigan.
de Marneffe, M.-C., MacCartney, B., and Manning, C. D.
(2006). Generating typed dependency parses from
phrase structure parses. In Proceedings of LREC-06.
Ding, Y. and Palmer, M. (2005). Machine translation
using probabilistic synchronous dependency insertion
grammars. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL’05), pages 541–548, Ann Arbor, Michigan.
Fox, H. (2002). Phrasal cohesion and statistical machine
translation. In Proceedings of the 2002 Conference on
Empirical Methods in Natural Language Processing,
pages 304–3111.
Galley, M., Hopkins, M., Knight, K., and Marcu, D.
(2004). What’s in a translation rule? In HLT-NAACL
2004: Main Proceedings, pages 273–280, Boston,
Massachusetts, USA.
</reference>
<page confidence="0.994309">
866
</page>
<reference confidence="0.999676343137255">
Hayashi, K., Tsukada, H., Sudoh, K., Duh, K., and Ya-
mamoto, S. (2010). Hierarchical phrase-based ma-
chine translation with word-based reordering model.
In Proceedings of the 23rd International Conference
on Computational Linguistics (Coling 2010), pages
439–446, Beijing, China.
Hoang, H., Koehn, P., and Lopez, A. (2009). A unified
framework for phrase-based, hierarchical, and syntax-
based statistical machine translation. In Proceedings
of the International Workshop on Spoken Language
Translation, pages 152–159, Tokyo, Japan.
Huang, Z., Cmejrek, M., and Zhou, B. (2010). Soft syn-
tactic constraints for hierarchical phrase-based trans-
lation using latent syntactic distributions. In Proceed-
ings of the 2010 Conference on Empirical Methods in
Natural Language Processing, pages 138–147, Cam-
bridge, MA.
Katz-Brown, J. and Collins, M. (2008). Syntactic reorder-
ing in preprocessing for japanese-to-english transla-
tion: Mit system description for ntcir-7 patent transla-
tion task. In Proceedings of NTCIR-7 Workshop Meet-
ing, Tokyo, Japan.
Kneser, R. and Ney, H. (1995). Improved backing-off
for m-gram language modeling. In Proceedings of the
IEEE International Conference on Acoustics, Speech,
and Signal Processing, pages 181–184.
Koehn, P. (2004). Statistical significance tests for ma-
chine translation evaluation. In Lin, D. and Wu, D.,
editors, Proceedings of EMNLP 2004, pages 388–395,
Barcelona, Spain. Association for Computational Lin-
guistics.
Koehn, P., Axelrod, A., Birch, A., Callison-burch, C., Os-
borne, M., and Talbot, D. (2005). Edinburgh system
description for the 2005 iwslt speech translation eval-
uation. In Proceedings of IWSLT2005.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statisti-
cal phrase based translation. In Proceedings of the
Joint Conference on Human Language Technologies
and the Annual Meeting of the North American Chap-
ter of the Association of Computational Linguistics
(HLT-NAACL).
Marton, Y. and Resnik, P. (2008). Soft syntactic con-
straints for hierarchical phrased-based translation. In
Proceedings of ACL-08: HLT, pages 1003–1011,
Columbus, Ohio.
Mi, H. and Liu, Q. (2010). Constituency to dependency
translation with forests. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics, pages 1433–1442, Uppsala, Sweden.
Och, F. J. (2003). Minimum error rate training for statis-
tical machine translation. In Proceedings of the 41st
Annual Meeting of the Association of Computational
Linguistics (ACL).
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
(2002). Bleu: a method for automatic evaluation of
machine translation. In Proceedings of 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 311–318, Philadelphia, Pennsylvania,
USA. Association for Computational Linguistics.
Quirk, C., Menezes, A., and Cherry, C. (2005). De-
pendency treelet translation: Syntactically informed
phrasal SMT. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL’05), pages 271–279, Ann Arbor, Michigan.
Schwenk, H. and Koehn, P. (2008). Large and diverse
language models for statistical machine translation. In
Proceedings of International Joint Conference on Nat-
ural Language Processing.
Setiawan, H., Kan, M. Y., Li, H., and Resnik, P. (2009).
Topological ordering of function words in hierarchical
phrase-based translation. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 324–332, Sun-
tec, Singapore.
Setiawan, H. and Resnik, P. (2010). Generalizing hierar-
chical phrase-based translation using rules with adja-
cent nonterminals. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics, pages 349–352, Los Angeles, California.
Shen, L., Xu, J., and Weischedel, R. (2008). A new
string-to-dependency machine translation algorithm
with a target dependency language model. In Pro-
ceedings of ACL-08: HLT, pages 577–585, Columbus,
Ohio.
Snover, M., Dorr, B., Schwartz, R., Micciulla, L., and
Makhoul, J. (2006). A study of translation edit rate
with targeted human annotation. In Proceedings ofAs-
sociation for Machine Translation in the Americas.
Tillman, C. (2004). A unigram orientation model for
statistical machine translation. In HLT-NAACL 2004:
Short Papers, pages 101–104, Boston, Massachusetts,
USA.
Tromble, R. and Eisner, J. (2009). Learning linear order-
ing problems for better translation. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
Language Processing, pages 1007–1016, Singapore.
Wang, C., Collins, M., and Koehn, P. (2007). Chinese
syntactic reordering for statistical machine translation.
In Proceedings of the 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
</reference>
<page confidence="0.978107">
867
</page>
<reference confidence="0.999223477272728">
Computational Natural Language Learning (EMNLP-
CoNLL), pages 737–745, Prague, Czech Republic.
Wang, W., May, J., Knight, K., and Marcu, D. (2010).
Re-structuring, re-labeling, and re-aligning for syntax-
based machine translation. Computational Linguistics,
36(2).
Watanabe, T., Suzuki, J., Tsukada, H., and Isozaki, H.
(2007). Online large-margin training for statistical ma-
chine translation. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 764–773,
Prague, Czech Republic.
Wu, D. (1996). A polynomial-time algorithm for statis-
tical machine translation. In Proceedings of the 34th
Annual Meeting of the Association for Computational
Linguistics, pages 152–158, Santa Cruz, California,
USA.
Xiong, D., Liu, Q., and Lin, S. (2006). Maximum en-
tropy based phrase reordering model for statistical ma-
chine translation. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computa-
tional Linguistics, pages 521–528, Sydney, Australia.
Xiong, D., Liu, Q., and Lin, S. (2007). A dependency
treelet string correspondence model for statistical ma-
chine translation. In Proceedings of the Second Work-
shop on Statistical Machine Translation, pages 40–47,
Prague, Czech Republic.
Xu, P., Kang, J., Ringgaard, M., and Och, F. (2009). Us-
ing a dependency parser to improve smt for subject-
object-verb languages. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 245–253, Boulder,
Colorado.
Zens, R. and Ney, H. (2006). Discriminative reordering
models for statistical machine translation. In Proceed-
ings on the Workshop on Statistical Machine Transla-
tion, pages 55–63, New York City.
Zollmann, A. and Venugopal, A. (2006). Syntax aug-
mented machine translation via chart parsing. In
Proceedings on the Workshop on Statistical Machine
Translation, pages 138–141, New York City.
</reference>
<page confidence="0.99756">
868
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.811286">
<title confidence="0.9992395">Soft Dependency Constraints for in Hierarchical Phrase-Based Translation</title>
<author confidence="0.988423">Yang Gao</author>
<author confidence="0.988423">Philipp Koehn</author>
<author confidence="0.988423">Alexandra</author>
<affiliation confidence="0.9972475">School of University of</affiliation>
<address confidence="0.874195">Edinburgh, UK, EH8</address>
<email confidence="0.979076">yanggao1119@gmail.com,pkoehn@inf.ed.ac.uk,a.birch@ed.ac.uk</email>
<abstract confidence="0.997201277777778">Long-distance reordering remains one of the biggest challenges facing machine translation. We derive soft constraints from the source dependency parsing to directly address the reordering problem for the hierarchical phrasebased model. Our approach significantly improves Chinese–English machine translation on a large-scale task by 0.84 BLEU points on average. Moreover, when we switch the tuning function from BLEU to the LRscore which promotes reordering, we observe total improvements of 1.21 BLEU, 1.30 LRscore and 3.36 TER over the baseline. On average our approach improves reordering precision and recall by 6.9 and 0.3 absolute points, respectively, and is found to be especially effective for long-distance reodering.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Bach</author>
<author>Q Gao</author>
<author>S Vogel</author>
</authors>
<title>Sourceside dependency tree reordering models with subtree movements and constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twelfth Machine Translation Summit (MTSummitXII), Ottawa, Canada. International Association for Machine Translation.</booktitle>
<contexts>
<context position="26903" citStr="Bach et al., 2009" startWordPosition="4440" endWordPosition="4443">s are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language model makes good use of the dependency representation as well as the target side training data. We follo</context>
<context position="28293" citStr="Bach et al. (2009" startWordPosition="4656" endWordPosition="4659">f the constraints, our work is different from (Cherry, 2008; Bach et al., 2009a,b) which have successfully defined another cohesion constraint from the source dependency structure, with the aim of improving reordering in phrase-based MT. To take a glance, Cherry (2008) and Bach et al. (2009b) define cohesion as translating a source dependency subtree contiguously into the target side without interruption (span or subtree overlapping), following Fox (2002). This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions. Bach et al. (2009a) also use cohesion to correlate with the lexicalized reordering model (Tillman, 2004; Koehn et al., 2005), whereas we define an orthogonal dependency orientation feature to explicitly model head-dependent reordering. The fundamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. This check is very effective for phrase-based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis. In fact,</context>
</contexts>
<marker>Bach, Gao, Vogel, 2009</marker>
<rawString>Bach, N., Gao, Q., and Vogel, S. (2009a). Sourceside dependency tree reordering models with subtree movements and constraints. In Proceedings of the Twelfth Machine Translation Summit (MTSummitXII), Ottawa, Canada. International Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bach</author>
<author>S Vogel</author>
<author>C Cherry</author>
</authors>
<title>Cohesive constraints in a beam search phrase-based decoder.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers,</booktitle>
<pages>1--4</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="26903" citStr="Bach et al., 2009" startWordPosition="4440" endWordPosition="4443">s are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language model makes good use of the dependency representation as well as the target side training data. We follo</context>
<context position="28293" citStr="Bach et al. (2009" startWordPosition="4656" endWordPosition="4659">f the constraints, our work is different from (Cherry, 2008; Bach et al., 2009a,b) which have successfully defined another cohesion constraint from the source dependency structure, with the aim of improving reordering in phrase-based MT. To take a glance, Cherry (2008) and Bach et al. (2009b) define cohesion as translating a source dependency subtree contiguously into the target side without interruption (span or subtree overlapping), following Fox (2002). This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions. Bach et al. (2009a) also use cohesion to correlate with the lexicalized reordering model (Tillman, 2004; Koehn et al., 2005), whereas we define an orthogonal dependency orientation feature to explicitly model head-dependent reordering. The fundamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. This check is very effective for phrase-based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis. In fact,</context>
</contexts>
<marker>Bach, Vogel, Cherry, 2009</marker>
<rawString>Bach, N., Vogel, S., and Cherry, C. (2009b). Cohesive constraints in a beam search phrase-based decoder. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers, pages 1–4, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>P Blunsom</author>
<author>M Osborne</author>
</authors>
<title>A quantitative analysis of reordering phenomena.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>197--205</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="1594" citStr="Birch et al. (2009)" startWordPosition="221" endWordPosition="224">distance reodering. 1 Introduction Reordering, especially movement over longer distances, continues to be a hard problem in statistical machine translation. It motivates much of the recent work on tree-based translation models, such as the hierarchical phrase-based model (Chiang, 2007) which extends the phrase-based model (Koehn et al., 2003) by allowing the so-called hierarchical phrases containing subphrases. The hierarchical phrase-based model captures the recursiveness of language without relying on syntactic annotation, and promises better reordering than the phrase-based model. However, Birch et al. (2009) find that although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency. Syntax-based models that use phrase structure constituent labels as non-terminals in their transfer rules, exemplified by that of Galley et al. (2004), produce smarter and syntactically motivated reordering. However, when working with off-the-shelf tools for parsing and alignment, this approach may impose harsh limits on rule extraction and requires serious efforts of optimiz</context>
</contexts>
<marker>Birch, Blunsom, Osborne, 2009</marker>
<rawString>Birch, A., Blunsom, P., and Osborne, M. (2009). A quantitative analysis of reordering phenomena. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 197–205, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
</authors>
<title>LRscore for evaluating lexical and reordering quality in MT.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>327--332</pages>
<location>Uppsala,</location>
<contexts>
<context position="20091" citStr="Birch and Osborne, 2010" startWordPosition="3283" endWordPosition="3286">nts, with the “bin-2” setting problem of overfitting sets in when we use 3 bins (with slightly higher tuning BLEU, not shown here). We also studied the effect of adding features incrementally onto the baseline with the “bin-2” setting, as shown in Table 3. On average, all three features seem to have similar contributions. 3.3 Using LRscore as the Tuning Metric Since our features are proposed to address the reordering problem and BLEU is not sensitive enough to reordering (especially in long-distance cases), we have also tried tuning with a metric that highlights reordering, i.e., the LRscore (Birch and Osborne, 2010). LRscore is a linear interpolation of a lexical metric and a reordering metric. We interpolated BLEU (as the lexical metric) with the Kendall’s tau permutation distance (as the reordering metric). The Kendall’s tau permutation distance measures the relative word order difference between the translation output and the reference(s) and is particularly sensitive to long-distance reordering. Testing results in terms of BLEU, LRscore and TER (Snover et al., 2006) are shown in Table 4. Tuned with the LRscore, our feature-augmented model achieves further average improvements (compare “bin-2” and “bi</context>
</contexts>
<marker>Birch, Osborne, 2010</marker>
<rawString>Birch, A. and Osborne, M. (2010). LRscore for evaluating lexical and reordering quality in MT. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 327–332, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
</authors>
<title>Reordering metrics for mt.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies,</booktitle>
<pages>1027--1035</pages>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="22235" citStr="Birch and Osborne, 2011" startWordPosition="3631" endWordPosition="3634">ngs in the translation, and recall as the number of reproduced reorderings divided by the number of reorder3One of our reviewers points out that according to the inductive learning theory, it is counter-intuitive to improve on BLEU and TER if we optimize by the LRscore. Yet we do observe some other papers reporting increased TER or other metric scores when BLEU is used for tuning (Carpuat and Wu, 2007; Shen et al., 2008), suggesting that MT evaluation might be too complicated to be characterized just with inductive learning. Similar results based on extensive experiments can also be found in (Birch and Osborne, 2011). 862 Setting MT02 MT05 MT08 Average baseline 37.0 35.3 35.6 36.0 bin-2 42.7 40.8 38.7 40.7 (+4.7) baseline-lr 37.3 35.0 34.2 35.5 (-0.5) bin-2-lr 44.1 42.0 42.5 42.9 (+6.9) Table 5: Overall precision for the test sets. Setting MT02 MT05 MT08 Average baseline 37.5 36.2 33.2 35.6 bin-2 36.8 35.9 31.8 34.8 (-0.8) baseline-lr 37.0 35.6 32.2 34.9 (-0.7) bin-2-lr 37.7 36.7 33.2 35.9 (+0.3) Table 6: Overall recall for the test sets. ings in the reference. Then we average the precision and recall over all four reference translations. Details of measuring reproduced reordering can be found in Birch et</context>
</contexts>
<marker>Birch, Osborne, 2011</marker>
<rawString>Birch, A. and Osborne, M. (2011). Reordering metrics for mt. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies, pages 1027–1035, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>Predicting success in machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>745--754</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="22846" citStr="Birch et al. (2008)" startWordPosition="3733" endWordPosition="3736">e, 2011). 862 Setting MT02 MT05 MT08 Average baseline 37.0 35.3 35.6 36.0 bin-2 42.7 40.8 38.7 40.7 (+4.7) baseline-lr 37.3 35.0 34.2 35.5 (-0.5) bin-2-lr 44.1 42.0 42.5 42.9 (+6.9) Table 5: Overall precision for the test sets. Setting MT02 MT05 MT08 Average baseline 37.5 36.2 33.2 35.6 bin-2 36.8 35.9 31.8 34.8 (-0.8) baseline-lr 37.0 35.6 32.2 34.9 (-0.7) bin-2-lr 37.7 36.7 33.2 35.9 (+0.3) Table 6: Overall recall for the test sets. ings in the reference. Then we average the precision and recall over all four reference translations. Details of measuring reproduced reordering can be found in Birch et al. (2008). An important difference in this work is in handling many-to-one and one-to-many alignments, as we only retain the first word alignment for any source or target word which has multiple alignments. This is consistent with our treatment in dependency orientation classification, and results in more reorderings being extracted. From Table 5 we can see that our features improve precision by an average of 4.7 absolute points when BLEU is used for tuning (“bin-2”). Switching from BLEU to the LRscore (“bin-2-lr”), we gain 2.2 points more and have a total improvement of 6.9 absolute points on average.</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2008</marker>
<rawString>Birch, A., Osborne, M., and Koehn, P. (2008). Predicting success in machine translation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 745–754, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carpuat</author>
<author>D Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>61--72</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="22015" citStr="Carpuat and Wu, 2007" startWordPosition="3596" endWordPosition="3599">recall for reordering is to investigate whether reorderings in the references are reproduced in the translations. We calculate precision as the number of reproduced reorderings divided by the total number of reorderings in the translation, and recall as the number of reproduced reorderings divided by the number of reorder3One of our reviewers points out that according to the inductive learning theory, it is counter-intuitive to improve on BLEU and TER if we optimize by the LRscore. Yet we do observe some other papers reporting increased TER or other metric scores when BLEU is used for tuning (Carpuat and Wu, 2007; Shen et al., 2008), suggesting that MT evaluation might be too complicated to be characterized just with inductive learning. Similar results based on extensive experiments can also be found in (Birch and Osborne, 2011). 862 Setting MT02 MT05 MT08 Average baseline 37.0 35.3 35.6 36.0 bin-2 42.7 40.8 38.7 40.7 (+4.7) baseline-lr 37.3 35.0 34.2 35.5 (-0.5) bin-2-lr 44.1 42.0 42.5 42.9 (+6.9) Table 5: Overall precision for the test sets. Setting MT02 MT05 MT08 Average baseline 37.5 36.2 33.2 35.6 bin-2 36.8 35.9 31.8 34.8 (-0.8) baseline-lr 37.0 35.6 32.2 34.9 (-0.7) bin-2-lr 37.7 36.7 33.2 35.9</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Carpuat, M. and Wu, D. (2007). Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 61–72, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P-C Chang</author>
<author>H Tseng</author>
<author>D Jurafsky</author>
<author>C D Manning</author>
</authors>
<title>Discriminative reordering with Chinese grammatical relations features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009,</booktitle>
<pages>51--59</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="26927" citStr="Chang et al., 2009" startWordPosition="4444" endWordPosition="4447">d not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language model makes good use of the dependency representation as well as the target side training data. We follow the second line of res</context>
<context position="31433" citStr="Chang et al. (2009)" startWordPosition="5121" endWordPosition="5124">head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less linguistically-motivated. 6 Conclusion We have derived three novel features from the source dependency structure for hierarchical phrase-based MT. They work as a whole to capitalize on two characteristics of the dependency representation: it is directly based on words an</context>
</contexts>
<marker>Chang, Tseng, Jurafsky, Manning, 2009</marker>
<rawString>Chang, P.-C., Tseng, H., Jurafsky, D., and Manning, C. D. (2009). Discriminative reordering with Chinese grammatical relations features. In Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation (SSST-3) at NAACL HLT 2009, pages 51–59, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cherry</author>
</authors>
<title>Cohesive phrase-based decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL08: HLT,</booktitle>
<pages>72--80</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="26884" citStr="Cherry, 2008" startWordPosition="4438" endWordPosition="4439">version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language model makes good use of the dependency representation as well as the target side trai</context>
<context position="29131" citStr="Cherry, 2008" startWordPosition="4783" endWordPosition="4784">ndamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. This check is very effective for phrase-based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis. In fact, it constrains reordering for the phrase-based model, as Cherry finds that the cohesion constraint is used “primarily to prevent distortion” and to provide “an intelligent estimate as to when source order must be respected” (Cherry, 2008). However, since the hierarchical phrasebased model already conducts principled reordering search with rules through the more constrained chart-decoding, ill-formed derivations exhibit themselves more often as nonconstituent translation than interrupted translation as defined in (Cherry, 2008; Bach et al., 2009a,b) (They do have a non-empty intersection, but neither subsumes the other). There864 fore, our cohesion penalty is better suited for the hierarchical phrase-based model. To discourage nonconstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a sou</context>
</contexts>
<marker>Cherry, 2008</marker>
<rawString>Cherry, C. (2008). Cohesive phrase-based decoding for statistical machine translation. In Proceedings ofACL08: HLT, pages 72–80, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>263--270</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12566" citStr="Chiang, 2005" startWordPosition="2018" endWordPosition="2019">ally will also be favored by our cohesion penalty feature. However, ignorant of the syntactic structure, the glue rule penalty may penalize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation, such as Derivation 6. Compared with constituency constraints based on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations. For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for German–English translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent colloca</context>
<context position="29670" citStr="Chiang (2005)" startWordPosition="4858" endWordPosition="4859">lligent estimate as to when source order must be respected” (Cherry, 2008). However, since the hierarchical phrasebased model already conducts principled reordering search with rules through the more constrained chart-decoding, ill-formed derivations exhibit themselves more often as nonconstituent translation than interrupted translation as defined in (Cherry, 2008; Bach et al., 2009a,b) (They do have a non-empty intersection, but neither subsumes the other). There864 fore, our cohesion penalty is better suited for the hierarchical phrase-based model. To discourage nonconstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, D. (2005). A hierarchical phrase-based model for statistical machine translation. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05, pages 263–270, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1261" citStr="Chiang, 2007" startWordPosition="178" endWordPosition="179">witch the tuning function from BLEU to the LRscore which promotes reordering, we observe total improvements of 1.21 BLEU, 1.30 LRscore and 3.36 TER over the baseline. On average our approach improves reordering precision and recall by 6.9 and 0.3 absolute points, respectively, and is found to be especially effective for long-distance reodering. 1 Introduction Reordering, especially movement over longer distances, continues to be a hard problem in statistical machine translation. It motivates much of the recent work on tree-based translation models, such as the hierarchical phrase-based model (Chiang, 2007) which extends the phrase-based model (Koehn et al., 2003) by allowing the so-called hierarchical phrases containing subphrases. The hierarchical phrase-based model captures the recursiveness of language without relying on syntactic annotation, and promises better reordering than the phrase-based model. However, Birch et al. (2009) find that although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency. Syntax-based models that use phrase structure</context>
<context position="3788" citStr="Chiang, 2007" startWordPosition="551" endWordPosition="552">ed MT. 857 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 857–868, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics punct 澳洲 是 与 北韩 有 邦交 的 少数 国家 之一 . Aozhou shi yu Beihan you bangjiao de shaoshu guojia zhiyi . Australia is with North Korea have dipl. rels. that few countries one of . Australia is one of the few countries that have diplomatic relations with North Korea. Figure 1: Example dependency parsing generated by the Stanford Parser. The Chinese source sentence and its English translation come from (Chiang, 2007). attr rcmod top pobj dobj prep cpm nummod nn 2 Three Soft Dependency Constraints Our features are based on the source dependency parsing, as shown in Figure 1. The basic unit of dependency parsing is a triple consisting of the dependent word, the head word and the dependency relation that connects them. For example, in Figure 1, an arrow labelled prep goes from the word yu (English with) to the word you (English have), showing that yu is a prepositional modifier of you. We use the Stanford Parser1 to generate dependency parsing, which automatically extracts dependency relations from phrase st</context>
<context position="11859" citStr="Chiang, 2007" startWordPosition="1915" endWordPosition="1916"> of derivation well-formedness in the hierarchical phrase-based MT. Same as dependency orientation, the cohesion penalty is not applicable to the root word of the sentence. We propose the cohesion penalty in order to further improve reordering, especially in long-distance cases, since a well-formed derivation at an earlier stage makes it more likely to explore hierarchical rules that perform more reliable reordering. In this respect, the cohesion penalty can be seen as an aid to the glue rule penalty and as an alternative to constituency-based constraints. Specifically, the glue rule penalty (Chiang, 2007) promotes hierarchical rules. Hierarchical rules whose lexical evidence helps resolve words locally will also be favored by our cohesion penalty feature. However, ignorant of the syntactic structure, the glue rule penalty may penalize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation, such as Derivation 6. Compared with constituency constraints based on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tol</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Learning to translate with source and target syntax.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1443--1452</pages>
<location>Uppsala,</location>
<contexts>
<context position="12899" citStr="Chiang, 2010" startWordPosition="2072" endWordPosition="2073">on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations. For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for German–English translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations, such as neighbouring siblings of a common uncovered head (regulated as the “floating structure” in (Shen et al., 2008)). A concrete example is Rule 9 which is useful for the Figure 1 sentence. To address this problem, another feature can be defined in the same manner to capture how each head word is translated with its child</context>
<context position="30246" citStr="Chiang, 2010" startWordPosition="4944" endWordPosition="4945">onstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which</context>
</contexts>
<marker>Chiang, 2010</marker>
<rawString>Chiang, D. (2010). Learning to translate with source and target syntax. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1443–1452, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
<author>K Knight</author>
<author>W Wang</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>218--226</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="12613" citStr="Chiang et al., 2009" startWordPosition="2024" endWordPosition="2027">on penalty feature. However, ignorant of the syntactic structure, the glue rule penalty may penalize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation, such as Derivation 6. Compared with constituency constraints based on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations. For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for German–English translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations, such as neighbouring siblings of a commo</context>
<context position="13915" citStr="Chiang et al., 2009" startWordPosition="2237" endWordPosition="2240"> concrete example is Rule 9 which is useful for the Figure 1 sentence. To address this problem, another feature can be defined in the same manner to capture how each head word is translated with its children. X → (es1 gibt2, there1 is2) X → (Aozhou1 shi2, Australia1 is2) X → (shaoshu1 guojia2, few1 countries2) Second, our cohesion penalty can be by nature more discriminative. Compared with the constituency constraints, the cohesion penalty is integer-valued, and can be made sensitive to the depth of each word in the dependency hierarchy (see Section 2.4). Inspired by (Marton and Resnik, 2008; Chiang et al., 2009), the cohesion penalty could also be made sensitive to the dependency relation of each word. However, this drastically increases the number of features and requires a tuning algorithm which scales better to high-dimensional model spaces, such as MIRA (Watanabe et al., 2007; Chiang et al., 2008). 860 Figure 3: Using 2 bins for the dependency parse tree of the Figure 1 sentence. 2.3 Unaligned Penalty The dependency orientation and cohesion penalty cannot be applied to unaligned source words. This may lead to search error, such as dropping (i.e., unaligning) key content words that are important f</context>
<context position="29984" citStr="Chiang et al., 2009" startWordPosition="4902" endWordPosition="4905">ion than interrupted translation as defined in (Cherry, 2008; Bach et al., 2009a,b) (They do have a non-empty intersection, but neither subsumes the other). There864 fore, our cohesion penalty is better suited for the hierarchical phrase-based model. To discourage nonconstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Se</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>Chiang, D., Knight, K., and Wang, W. (2009). 11,001 new features for statistical machine translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 218–226, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
<author>Y Marton</author>
<author>P Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>224--233</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="14210" citStr="Chiang et al., 2008" startWordPosition="2284" endWordPosition="2288">few1 countries2) Second, our cohesion penalty can be by nature more discriminative. Compared with the constituency constraints, the cohesion penalty is integer-valued, and can be made sensitive to the depth of each word in the dependency hierarchy (see Section 2.4). Inspired by (Marton and Resnik, 2008; Chiang et al., 2009), the cohesion penalty could also be made sensitive to the dependency relation of each word. However, this drastically increases the number of features and requires a tuning algorithm which scales better to high-dimensional model spaces, such as MIRA (Watanabe et al., 2007; Chiang et al., 2008). 860 Figure 3: Using 2 bins for the dependency parse tree of the Figure 1 sentence. 2.3 Unaligned Penalty The dependency orientation and cohesion penalty cannot be applied to unaligned source words. This may lead to search error, such as dropping (i.e., unaligning) key content words that are important for lexical translation and reordering. The problem is mitigated by an unaligned penalty applicable to all words in the dependency hierarchy. 2.4 Grouping Words into Bins Having defined dependency orientation, cohesion penalty and unaligned penalty, we section the source dependency tree uniforml</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>Chiang, D., Marton, Y., and Resnik, P. (2008). Online large-margin training of syntactic and structural translation features. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 224–233, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>531--540</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="31113" citStr="Collins et al., 2005" startWordPosition="5068" endWordPosition="5071">slations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each de</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Collins, M., Koehn, P., and Kucerova, I. (2005). Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 531–540, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C de Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-06.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>de Marneffe, M.-C., MacCartney, B., and Manning, C. D. (2006). Generating typed dependency parses from phrase structure parses. In Proceedings of LREC-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ding</author>
<author>M Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>541--548</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="26742" citStr="Ding and Palmer, 2005" startWordPosition="4410" endWordPosition="4413">[and the european union ( eu )]]]] .] Figure 5: Example translations from the NIST MT08 set, output by the baseline model and “bin-2” model. The “-lr” version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects h</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Ding, Y. and Palmer, M. (2005). Machine translation using probabilistic synchronous dependency insertion grammars. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 541–548, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Fox</author>
</authors>
<title>Phrasal cohesion and statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>304--3111</pages>
<contexts>
<context position="28135" citStr="Fox (2002)" startWordPosition="4634" endWordPosition="4635">esearch, and derive three word-based soft constraints from the source dependency parsing. Note that although we reuse the word “cohesion” to name one of the constraints, our work is different from (Cherry, 2008; Bach et al., 2009a,b) which have successfully defined another cohesion constraint from the source dependency structure, with the aim of improving reordering in phrase-based MT. To take a glance, Cherry (2008) and Bach et al. (2009b) define cohesion as translating a source dependency subtree contiguously into the target side without interruption (span or subtree overlapping), following Fox (2002). This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions. Bach et al. (2009a) also use cohesion to correlate with the lexicalized reordering model (Tillman, 2004; Koehn et al., 2005), whereas we define an orthogonal dependency orientation feature to explicitly model head-dependent reordering. The fundamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. Thi</context>
</contexts>
<marker>Fox, 2002</marker>
<rawString>Fox, H. (2002). Phrasal cohesion and statistical machine translation. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 304–3111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>M Hopkins</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Main Proceedings,</booktitle>
<pages>273--280</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="1966" citStr="Galley et al. (2004)" startWordPosition="273" endWordPosition="276">hierarchical phrases containing subphrases. The hierarchical phrase-based model captures the recursiveness of language without relying on syntactic annotation, and promises better reordering than the phrase-based model. However, Birch et al. (2009) find that although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency. Syntax-based models that use phrase structure constituent labels as non-terminals in their transfer rules, exemplified by that of Galley et al. (2004), produce smarter and syntactically motivated reordering. However, when working with off-the-shelf tools for parsing and alignment, this approach may impose harsh limits on rule extraction and requires serious efforts of optimization (Wang et al., 2010). An alternative approach is to augment the general hierarchical phrase-based model with soft syntactic constraints. Here, we derive three word-based, complementary constraints from the source dependency parsing, including: • A dependency orientation feature, trained with maximum entropy on the word-aligned parallel data, which directly models t</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Galley, M., Hopkins, M., Knight, K., and Marcu, D. (2004). What’s in a translation rule? In HLT-NAACL 2004: Main Proceedings, pages 273–280, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hayashi</author>
<author>H Tsukada</author>
<author>K Sudoh</author>
<author>K Duh</author>
<author>S Yamamoto</author>
</authors>
<title>Hierarchical phrase-based machine translation with word-based reordering model.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>439--446</pages>
<location>Beijing, China.</location>
<contexts>
<context position="4813" citStr="Hayashi et al. (2010)" startWordPosition="724" endWordPosition="727">you (English have), showing that yu is a prepositional modifier of you. We use the Stanford Parser1 to generate dependency parsing, which automatically extracts dependency relations from phrase structure parsing (de Marneffe et al., 2006). 2.1 Dependency Orientation Based on the assumption that constituents generally move as a whole (Quirk et al., 2005), we decompose the sentence reordering probability into the reordering probability for each aligned source word with respect to its head, excluding the root word at the top of the dependency hierarchy which does not have a head word. Similarly, Hayashi et al. (2010) also take a word-based reordering approach for HPBMT, but they model all possible pairwise orientation from the source side as a general linear ordering problem (Tromble and Eisner, 2009). To be more specific, we have a maximum entropy orientation classifier that predicts the probability of a source word being translated in a monotone or reversed manner with respect to its head. For example, 1http://nlp.stanford.edu/software/lex-parser.shtml (a) (b) idep idep ihead ihead S 1 S 2 S 3 S 1 S 2 S 3 en tsto il lust rateorient at ionclas-si fication.In( a),mo notone(M); in (b), reversed (R). given </context>
</contexts>
<marker>Hayashi, Tsukada, Sudoh, Duh, Yamamoto, 2010</marker>
<rawString>Hayashi, K., Tsukada, H., Sudoh, K., Duh, K., and Yamamoto, S. (2010). Hierarchical phrase-based machine translation with word-based reordering model. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 439–446, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hoang</author>
<author>P Koehn</author>
<author>A Lopez</author>
</authors>
<title>A unified framework for phrase-based, hierarchical, and syntaxbased statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>152--159</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="16920" citStr="Hoang et al., 2009" startWordPosition="2737" endWordPosition="2740">are2) for dependency orientation classification. We trained three 5-gram language models with modified Kneser-Ney smoothing (Kneser and Ney, 1995): one on the English half of the parallel corpus, one on the Xinhua part of the Gigaword corpus, one on the AFP part, and interpolated them for best fit to the tuning set (Schwenk and Koehn, 2008). We used NIST MT06 evaluation data (1664 lines) as our tuning set, and tested on NIST MT02 (878 lines), MT05 (1082 lines) and MT08 (1357 lines). Our baseline system was the Moses implementation of the hierarchical phrase-based model with standard settings (Hoang et al., 2009). When only 1 bin was used, 3 additional features were added to the baseline, one each from the soft dependency constraints. When we used 2 or 3 bins, the additional feature counts doubled or tripled. We preserved terminal alignment alongside nonterminal alignment during the rule extraction and output word alignments together with translated strings. Since the features we currently define are based entirely on the source side, we used preprocessing to speed up decoding of our feature-augmented model. All experiments were tuned with MERT (Och, 2003). 3.2 Using BLEU as the Tuning Metric As a sta</context>
</contexts>
<marker>Hoang, Koehn, Lopez, 2009</marker>
<rawString>Hoang, H., Koehn, P., and Lopez, A. (2009). A unified framework for phrase-based, hierarchical, and syntaxbased statistical machine translation. In Proceedings of the International Workshop on Spoken Language Translation, pages 152–159, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Huang</author>
<author>M Cmejrek</author>
<author>B Zhou</author>
</authors>
<title>Soft syntactic constraints for hierarchical phrase-based translation using latent syntactic distributions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>138--147</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="30357" citStr="Huang et al., 2010" startWordPosition="4958" endWordPosition="4961">e span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspectiv</context>
</contexts>
<marker>Huang, Cmejrek, Zhou, 2010</marker>
<rawString>Huang, Z., Cmejrek, M., and Zhou, B. (2010). Soft syntactic constraints for hierarchical phrase-based translation using latent syntactic distributions. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 138–147, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Katz-Brown</author>
<author>M Collins</author>
</authors>
<title>Syntactic reordering in preprocessing for japanese-to-english translation: Mit system description for ntcir-7 patent translation task.</title>
<date>2008</date>
<booktitle>In Proceedings of NTCIR-7 Workshop Meeting,</booktitle>
<location>Tokyo, Japan.</location>
<contexts>
<context position="31163" citStr="Katz-Brown and Collins, 2008" startWordPosition="5074" endWordPosition="5077">anslations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less l</context>
</contexts>
<marker>Katz-Brown, Collins, 2008</marker>
<rawString>Katz-Brown, J. and Collins, M. (2008). Syntactic reordering in preprocessing for japanese-to-english translation: Mit system description for ntcir-7 patent translation task. In Proceedings of NTCIR-7 Workshop Meeting, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kneser</author>
<author>H Ney</author>
</authors>
<title>Improved backing-off for m-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<pages>181--184</pages>
<contexts>
<context position="16447" citStr="Kneser and Ney, 1995" startWordPosition="2653" endWordPosition="2656">Bin 1, and words at Depth 3, 4, 5 are grouped into Bin 2. As a simple approach, binning does not take into account how the tree levels spread out. 3 Experiments 3.1 General Settings We used a parallel training corpus with 2.1 million Chinese–English sentence pairs, aligned by GIZA++. The Chinese side was parsed by the Stanford Parser. Then we extracted 33.8 million examples from the parsed Chinese side to discriminatively train 1.1 million features (using the MegaM software2) for dependency orientation classification. We trained three 5-gram language models with modified Kneser-Ney smoothing (Kneser and Ney, 1995): one on the English half of the parallel corpus, one on the Xinhua part of the Gigaword corpus, one on the AFP part, and interpolated them for best fit to the tuning set (Schwenk and Koehn, 2008). We used NIST MT06 evaluation data (1664 lines) as our tuning set, and tested on NIST MT02 (878 lines), MT05 (1082 lines) and MT08 (1357 lines). Our baseline system was the Moses implementation of the hierarchical phrase-based model with standard settings (Hoang et al., 2009). When only 1 bin was used, 3 additional features were added to the baseline, one each from the soft dependency constraints. Wh</context>
</contexts>
<marker>Kneser, Ney, 1995</marker>
<rawString>Kneser, R. and Ney, H. (1995). Improved backing-off for m-gram language modeling. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 181–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>Proceedings of EMNLP 2004,</booktitle>
<pages>388--395</pages>
<editor>In Lin, D. and Wu, D., editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona,</location>
<contexts>
<context position="18907" citStr="Koehn, 2004" startWordPosition="3094" endWordPosition="3095">/ 39.84 / 67.97 bin-2 35.04 / 43.07 / 65.58 33.18 / 41.62 / 65.59 28.63 / 38.12 / 65.36 32.28 / 40.94 / 65.51 baseline-lr 34.23 / 42.06 / 68.08 32.28 / 40.61 / 67.61 27.99 / 37.27 / 66.98 31.50 / 39.98 / 67.56 bin-2-lr 35.42 / 43.25 / 64.82 33.44 / 41.80 / 64.88 29.10 / 38.38 / 64.14 32.65 / 41.14 / 64.61 Table 4: Results for the baseline model and the complete feature-augmented model with 2 bins (“bin-2”), using BLEU and LRscore (“-lr”) as the tuning function. The BLEU scores of “bin-2” and “bin-2-lr” are significantly better than baseline (p &lt; 0.05), computed by paired bootstrap resampling (Koehn, 2004). Setting BLEU MT02 MT05 MT08 Average baseline 34.01 32.23 28.09 31.44 bin-1 34.20 32.13 28.41 31.58(+.14) bin-2 35.04 33.18 28.63 32.28(+.84) bin-3 34.35 32.79 28.37 31.84(+.40) Table 2: Results of the baseline model as well as our complete feature-augmented model with 1, 2 and 3 bins. BLEU is the tuning function. Setting BLEU MT02 MT05 MT08 Average baseline 34.01 32.23 28.09 31.44 dep 34.26 32.58 28.07 31.64(+.20) dep+coP 34.47 32.81 28.61 31.96(+.52) dep+coP+unP 35.04 33.18 28.63 32.28(+.84) Table 3: Contributions of the three soft dependency constraints, with the “bin-2” setting problem of</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Koehn, P. (2004). Statistical significance tests for machine translation evaluation. In Lin, D. and Wu, D., editors, Proceedings of EMNLP 2004, pages 388–395, Barcelona, Spain. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>A Axelrod</author>
<author>A Birch</author>
<author>C Callison-burch</author>
<author>M Osborne</author>
<author>D Talbot</author>
</authors>
<title>Edinburgh system description for the 2005 iwslt speech translation evaluation.</title>
<date>2005</date>
<booktitle>In Proceedings of IWSLT2005.</booktitle>
<contexts>
<context position="28400" citStr="Koehn et al., 2005" startWordPosition="4673" endWordPosition="4676">y defined another cohesion constraint from the source dependency structure, with the aim of improving reordering in phrase-based MT. To take a glance, Cherry (2008) and Bach et al. (2009b) define cohesion as translating a source dependency subtree contiguously into the target side without interruption (span or subtree overlapping), following Fox (2002). This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions. Bach et al. (2009a) also use cohesion to correlate with the lexicalized reordering model (Tillman, 2004; Koehn et al., 2005), whereas we define an orthogonal dependency orientation feature to explicitly model head-dependent reordering. The fundamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. This check is very effective for phrase-based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis. In fact, it constrains reordering for the phrase-based model, as Cherry finds that the cohesion constraint is used </context>
</contexts>
<marker>Koehn, Axelrod, Birch, Callison-burch, Osborne, Talbot, 2005</marker>
<rawString>Koehn, P., Axelrod, A., Birch, A., Callison-burch, C., Osborne, M., and Talbot, D. (2005). Edinburgh system description for the 2005 iwslt speech translation evaluation. In Proceedings of IWSLT2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Joint Conference on Human Language Technologies and the Annual Meeting of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL).</booktitle>
<contexts>
<context position="1319" citStr="Koehn et al., 2003" startWordPosition="185" endWordPosition="188">hich promotes reordering, we observe total improvements of 1.21 BLEU, 1.30 LRscore and 3.36 TER over the baseline. On average our approach improves reordering precision and recall by 6.9 and 0.3 absolute points, respectively, and is found to be especially effective for long-distance reodering. 1 Introduction Reordering, especially movement over longer distances, continues to be a hard problem in statistical machine translation. It motivates much of the recent work on tree-based translation models, such as the hierarchical phrase-based model (Chiang, 2007) which extends the phrase-based model (Koehn et al., 2003) by allowing the so-called hierarchical phrases containing subphrases. The hierarchical phrase-based model captures the recursiveness of language without relying on syntactic annotation, and promises better reordering than the phrase-based model. However, Birch et al. (2009) find that although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency. Syntax-based models that use phrase structure constituent labels as non-terminals in their transfer rul</context>
<context position="12709" citStr="Koehn et al., 2003" startWordPosition="2039" endWordPosition="2042">ize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation, such as Derivation 6. Compared with constituency constraints based on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations. For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for German–English translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations, such as neighbouring siblings of a common uncovered head (regulated as the “floating structure” in (Shen et al., 2008)). A concrete exam</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, P., Och, F. J., and Marcu, D. (2003). Statistical phrase based translation. In Proceedings of the Joint Conference on Human Language Technologies and the Annual Meeting of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Marton</author>
<author>P Resnik</author>
</authors>
<title>Soft syntactic constraints for hierarchical phrased-based translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1003--1011</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="12591" citStr="Marton and Resnik, 2008" startWordPosition="2020" endWordPosition="2023"> be favored by our cohesion penalty feature. However, ignorant of the syntactic structure, the glue rule penalty may penalize a reasonably cohesive derivation such as Derivation 5 and at the same time promote a less cohesive hierarchical translation, such as Derivation 6. Compared with constituency constraints based on the phrase structure, our cohesion penalty derived from the binary dependency parsing has two different characteristics. First, our cohesion penalty is by nature more tolerant to some meaningful noncontituent translations. For example, constituency constraints in (Chiang, 2005; Marton and Resnik, 2008; Chiang et al., 2009) would penalize Rule 7 below which is useful for German–English translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations, such as neighbouri</context>
<context position="13893" citStr="Marton and Resnik, 2008" startWordPosition="2233" endWordPosition="2236">n (Shen et al., 2008)). A concrete example is Rule 9 which is useful for the Figure 1 sentence. To address this problem, another feature can be defined in the same manner to capture how each head word is translated with its children. X → (es1 gibt2, there1 is2) X → (Aozhou1 shi2, Australia1 is2) X → (shaoshu1 guojia2, few1 countries2) Second, our cohesion penalty can be by nature more discriminative. Compared with the constituency constraints, the cohesion penalty is integer-valued, and can be made sensitive to the depth of each word in the dependency hierarchy (see Section 2.4). Inspired by (Marton and Resnik, 2008; Chiang et al., 2009), the cohesion penalty could also be made sensitive to the dependency relation of each word. However, this drastically increases the number of features and requires a tuning algorithm which scales better to high-dimensional model spaces, such as MIRA (Watanabe et al., 2007; Chiang et al., 2008). 860 Figure 3: Using 2 bins for the dependency parse tree of the Figure 1 sentence. 2.3 Unaligned Penalty The dependency orientation and cohesion penalty cannot be applied to unaligned source words. This may lead to search error, such as dropping (i.e., unaligning) key content word</context>
<context position="29962" citStr="Marton and Resnik, 2008" startWordPosition="4898" endWordPosition="4901">s nonconstituent translation than interrupted translation as defined in (Cherry, 2008; Bach et al., 2009a,b) (They do have a non-empty intersection, but neither subsumes the other). There864 fore, our cohesion penalty is better suited for the hierarchical phrase-based model. To discourage nonconstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of th</context>
</contexts>
<marker>Marton, Resnik, 2008</marker>
<rawString>Marton, Y. and Resnik, P. (2008). Soft syntactic constraints for hierarchical phrased-based translation. In Proceedings of ACL-08: HLT, pages 1003–1011, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mi</author>
<author>Q Liu</author>
</authors>
<title>Constituency to dependency translation with forests.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1433--1442</pages>
<location>Uppsala,</location>
<contexts>
<context position="26820" citStr="Mi and Liu, 2010" startWordPosition="4426" endWordPosition="4429"> MT08 set, output by the baseline model and “bin-2” model. The “-lr” version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language model makes good use </context>
</contexts>
<marker>Mi, Liu, 2010</marker>
<rawString>Mi, H. and Liu, Q. (2010). Constituency to dependency translation with forests. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1433–1442, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association of Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="17474" citStr="Och, 2003" startWordPosition="2831" endWordPosition="2832">-based model with standard settings (Hoang et al., 2009). When only 1 bin was used, 3 additional features were added to the baseline, one each from the soft dependency constraints. When we used 2 or 3 bins, the additional feature counts doubled or tripled. We preserved terminal alignment alongside nonterminal alignment during the rule extraction and output word alignments together with translated strings. Since the features we currently define are based entirely on the source side, we used preprocessing to speed up decoding of our feature-augmented model. All experiments were tuned with MERT (Och, 2003). 3.2 Using BLEU as the Tuning Metric As a standard practice, we first used BLEU (Papineni et al., 2002) as the objective function for tuning. Table 2 shows the results of the baseline model as well as our complete feature-augmented model with different bin numbers. With the “bin-2” setting, we get substantial improvement of up to 1.03 BLEU points (on MT02 data), and 0.84 BLEU points on average. Using more than one bin (i.e., differentiating tree depths) is generally beneficial, although the 2http://www.umiacs.umd.edu/∼hal/megam/index.html Depth 5 pobj 3L top punct attr ABX k �� � !&apos;*t: IQI: 4</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. (2003). Minimum error rate training for statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association of Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania, USA.</location>
<contexts>
<context position="17578" citStr="Papineni et al., 2002" startWordPosition="2848" endWordPosition="2852">onal features were added to the baseline, one each from the soft dependency constraints. When we used 2 or 3 bins, the additional feature counts doubled or tripled. We preserved terminal alignment alongside nonterminal alignment during the rule extraction and output word alignments together with translated strings. Since the features we currently define are based entirely on the source side, we used preprocessing to speed up decoding of our feature-augmented model. All experiments were tuned with MERT (Och, 2003). 3.2 Using BLEU as the Tuning Metric As a standard practice, we first used BLEU (Papineni et al., 2002) as the objective function for tuning. Table 2 shows the results of the baseline model as well as our complete feature-augmented model with different bin numbers. With the “bin-2” setting, we get substantial improvement of up to 1.03 BLEU points (on MT02 data), and 0.84 BLEU points on average. Using more than one bin (i.e., differentiating tree depths) is generally beneficial, although the 2http://www.umiacs.umd.edu/∼hal/megam/index.html Depth 5 pobj 3L top punct attr ABX k �� � !&apos;*t: IQI: 4 rcmod nummod nn prep 5 dobj cpm 0 AS-Z Depth 1 Depth 2 Depth 3 Depth 4 Bin 1 Bin 2 861 Setting BLEU / L</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). Bleu: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>A Menezes</author>
<author>C Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>271--279</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="4547" citStr="Quirk et al., 2005" startWordPosition="679" endWordPosition="682">s shown in Figure 1. The basic unit of dependency parsing is a triple consisting of the dependent word, the head word and the dependency relation that connects them. For example, in Figure 1, an arrow labelled prep goes from the word yu (English with) to the word you (English have), showing that yu is a prepositional modifier of you. We use the Stanford Parser1 to generate dependency parsing, which automatically extracts dependency relations from phrase structure parsing (de Marneffe et al., 2006). 2.1 Dependency Orientation Based on the assumption that constituents generally move as a whole (Quirk et al., 2005), we decompose the sentence reordering probability into the reordering probability for each aligned source word with respect to its head, excluding the root word at the top of the dependency hierarchy which does not have a head word. Similarly, Hayashi et al. (2010) also take a word-based reordering approach for HPBMT, but they model all possible pairwise orientation from the source side as a general linear ordering problem (Tromble and Eisner, 2009). To be more specific, we have a maximum entropy orientation classifier that predicts the probability of a source word being translated in a monot</context>
<context position="26762" citStr="Quirk et al., 2005" startWordPosition="4414" endWordPosition="4417"> ( eu )]]]] .] Figure 5: Example translations from the NIST MT08 set, output by the baseline model and “bin-2” model. The “-lr” version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. There</context>
<context position="30719" citStr="Quirk et al., 2005" startWordPosition="5012" endWordPosition="5015">ax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification f</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Quirk, C., Menezes, A., and Cherry, C. (2005). Dependency treelet translation: Syntactically informed phrasal SMT. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 271–279, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schwenk</author>
<author>P Koehn</author>
</authors>
<title>Large and diverse language models for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="16643" citStr="Schwenk and Koehn, 2008" startWordPosition="2691" endWordPosition="2694">arallel training corpus with 2.1 million Chinese–English sentence pairs, aligned by GIZA++. The Chinese side was parsed by the Stanford Parser. Then we extracted 33.8 million examples from the parsed Chinese side to discriminatively train 1.1 million features (using the MegaM software2) for dependency orientation classification. We trained three 5-gram language models with modified Kneser-Ney smoothing (Kneser and Ney, 1995): one on the English half of the parallel corpus, one on the Xinhua part of the Gigaword corpus, one on the AFP part, and interpolated them for best fit to the tuning set (Schwenk and Koehn, 2008). We used NIST MT06 evaluation data (1664 lines) as our tuning set, and tested on NIST MT02 (878 lines), MT05 (1082 lines) and MT08 (1357 lines). Our baseline system was the Moses implementation of the hierarchical phrase-based model with standard settings (Hoang et al., 2009). When only 1 bin was used, 3 additional features were added to the baseline, one each from the soft dependency constraints. When we used 2 or 3 bins, the additional feature counts doubled or tripled. We preserved terminal alignment alongside nonterminal alignment during the rule extraction and output word alignments toge</context>
</contexts>
<marker>Schwenk, Koehn, 2008</marker>
<rawString>Schwenk, H. and Koehn, P. (2008). Large and diverse language models for statistical machine translation. In Proceedings of International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Setiawan</author>
<author>M Y Kan</author>
<author>H Li</author>
<author>P Resnik</author>
</authors>
<title>Topological ordering of function words in hierarchical phrase-based translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>324--332</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="33667" citStr="Setiawan et al., 2009" startWordPosition="5467" endWordPosition="5471">tive to GIZA++, we would like to experiment with syntactically informed aligners that better handle function words which often exhibit high alignment ambiguity due to low cross-lingual correspondence. Finally, since our soft dependency constraints promote reordering without increasing model complexity, further gains can be achieved when combining our approach with orthogonal studies to improve the quantity and quality of hierarchical (reordering) rules, such as relaxing hierarchical rule extraction constraints (Setiawan and Resnik, 2010) and selectively lexicalizing rules with function words (Setiawan et al., 2009). Acknowledgments We would like to thank Miles Osborne, Adam Lopez, Barry Haddow, Hieu Hoang, Philip Williams and Michael Auli in the Edinburgh SMT group as well as Kevin Knight, David Chiang and Andrew Dai for inspiring discussions. We appreciate Pichuan Chang, Huihsin Tseng, Richard Zens, Matthew Snover and Nguyen Bach for helping us 865 understand their brilliant work. Many thanks to the anonymous reviewers for their insightful comments and suggestions. This work was supported in part by the EuroMatrixPlus project funded by the European Commission (7th Framework Programme) and in part under</context>
</contexts>
<marker>Setiawan, Kan, Li, Resnik, 2009</marker>
<rawString>Setiawan, H., Kan, M. Y., Li, H., and Resnik, P. (2009). Topological ordering of function words in hierarchical phrase-based translation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 324–332, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Setiawan</author>
<author>P Resnik</author>
</authors>
<title>Generalizing hierarchical phrase-based translation using rules with adjacent nonterminals.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>349--352</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="33588" citStr="Setiawan and Resnik, 2010" startWordPosition="5455" endWordPosition="5458">Rscore which uses word alignment to compute the permutation distance. As an alternative to GIZA++, we would like to experiment with syntactically informed aligners that better handle function words which often exhibit high alignment ambiguity due to low cross-lingual correspondence. Finally, since our soft dependency constraints promote reordering without increasing model complexity, further gains can be achieved when combining our approach with orthogonal studies to improve the quantity and quality of hierarchical (reordering) rules, such as relaxing hierarchical rule extraction constraints (Setiawan and Resnik, 2010) and selectively lexicalizing rules with function words (Setiawan et al., 2009). Acknowledgments We would like to thank Miles Osborne, Adam Lopez, Barry Haddow, Hieu Hoang, Philip Williams and Michael Auli in the Edinburgh SMT group as well as Kevin Knight, David Chiang and Andrew Dai for inspiring discussions. We appreciate Pichuan Chang, Huihsin Tseng, Richard Zens, Matthew Snover and Nguyen Bach for helping us 865 understand their brilliant work. Many thanks to the anonymous reviewers for their insightful comments and suggestions. This work was supported in part by the EuroMatrixPlus projec</context>
</contexts>
<marker>Setiawan, Resnik, 2010</marker>
<rawString>Setiawan, H. and Resnik, P. (2010). Generalizing hierarchical phrase-based translation using rules with adjacent nonterminals. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 349–352, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>J Xu</author>
<author>R Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>577--585</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="13291" citStr="Shen et al., 2008" startWordPosition="2130" endWordPosition="2133">ish translation (Koehn et al., 2003), and Rule 8 which can be applied to the Figure 1 sentence. Fuzzy constituency constraints can solve this problem with a combination of product categories and slash categories (Chiang, 2010). Yet our cohesion penalty by nature admits these translations as cohesive (with no extra cost from es and Aozhou since both are locally resolved). Admittedly, our current implementation of the cohesion penalty is blind to some other meaningful nonconstituent collocations, such as neighbouring siblings of a common uncovered head (regulated as the “floating structure” in (Shen et al., 2008)). A concrete example is Rule 9 which is useful for the Figure 1 sentence. To address this problem, another feature can be defined in the same manner to capture how each head word is translated with its children. X → (es1 gibt2, there1 is2) X → (Aozhou1 shi2, Australia1 is2) X → (shaoshu1 guojia2, few1 countries2) Second, our cohesion penalty can be by nature more discriminative. Compared with the constituency constraints, the cohesion penalty is integer-valued, and can be made sensitive to the depth of each word in the dependency hierarchy (see Section 2.4). Inspired by (Marton and Resnik, 20</context>
<context position="22035" citStr="Shen et al., 2008" startWordPosition="3600" endWordPosition="3603">is to investigate whether reorderings in the references are reproduced in the translations. We calculate precision as the number of reproduced reorderings divided by the total number of reorderings in the translation, and recall as the number of reproduced reorderings divided by the number of reorder3One of our reviewers points out that according to the inductive learning theory, it is counter-intuitive to improve on BLEU and TER if we optimize by the LRscore. Yet we do observe some other papers reporting increased TER or other metric scores when BLEU is used for tuning (Carpuat and Wu, 2007; Shen et al., 2008), suggesting that MT evaluation might be too complicated to be characterized just with inductive learning. Similar results based on extensive experiments can also be found in (Birch and Osborne, 2011). 862 Setting MT02 MT05 MT08 Average baseline 37.0 35.3 35.6 36.0 bin-2 42.7 40.8 38.7 40.7 (+4.7) baseline-lr 37.3 35.0 34.2 35.5 (-0.5) bin-2-lr 44.1 42.0 42.5 42.9 (+6.9) Table 5: Overall precision for the test sets. Setting MT02 MT05 MT08 Average baseline 37.5 36.2 33.2 35.6 bin-2 36.8 35.9 31.8 34.8 (-0.8) baseline-lr 37.0 35.6 32.2 34.9 (-0.7) bin-2-lr 37.7 36.7 33.2 35.9 (+0.3) Table 6: Ove</context>
<context position="26801" citStr="Shen et al., 2008" startWordPosition="4422" endWordPosition="4425">tions from the NIST MT08 set, output by the baseline model and “bin-2” model. The “-lr” version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dependency language mo</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Shen, L., Xu, J., and Weischedel, R. (2008). A new string-to-dependency machine translation algorithm with a target dependency language model. In Proceedings of ACL-08: HLT, pages 577–585, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciulla</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings ofAssociation for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="20554" citStr="Snover et al., 2006" startWordPosition="3354" endWordPosition="3357">ordering (especially in long-distance cases), we have also tried tuning with a metric that highlights reordering, i.e., the LRscore (Birch and Osborne, 2010). LRscore is a linear interpolation of a lexical metric and a reordering metric. We interpolated BLEU (as the lexical metric) with the Kendall’s tau permutation distance (as the reordering metric). The Kendall’s tau permutation distance measures the relative word order difference between the translation output and the reference(s) and is particularly sensitive to long-distance reordering. Testing results in terms of BLEU, LRscore and TER (Snover et al., 2006) are shown in Table 4. Tuned with the LRscore, our feature-augmented model achieves further average improvements (compare “bin-2” and “bin-2-lr”) of 0.20 LRscore as well as 0.37 BLEU and 0.90 TER. Note that while the BLEU increase can largely be seen as a projection of the LRscore increase back into its lexical component, the consistent TER drop confirms that our improvement is not metric-specific3. Altogether the final improvement is 1.21 BLEU, 1.30 LRscore and 3.36 TER on average over the baseline. However, an important question is how our features affect short, medium and long-distance reor</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Snover, M., Dorr, B., Schwartz, R., Micciulla, L., and Makhoul, J. (2006). A study of translation edit rate with targeted human annotation. In Proceedings ofAssociation for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillman</author>
</authors>
<title>A unigram orientation model for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Short Papers,</booktitle>
<pages>101--104</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="28379" citStr="Tillman, 2004" startWordPosition="4670" endWordPosition="4672">ave successfully defined another cohesion constraint from the source dependency structure, with the aim of improving reordering in phrase-based MT. To take a glance, Cherry (2008) and Bach et al. (2009b) define cohesion as translating a source dependency subtree contiguously into the target side without interruption (span or subtree overlapping), following Fox (2002). This span-based cohesion constraint has a different criterion from our wordbased cohesion penalty and often leads to opposite conclusions. Bach et al. (2009a) also use cohesion to correlate with the lexicalized reordering model (Tillman, 2004; Koehn et al., 2005), whereas we define an orthogonal dependency orientation feature to explicitly model head-dependent reordering. The fundamental difference, however, is rooted in the translation model. Their span-based cohesion constraint is implemented as an “interruption check” to encourage finishing a subtree before translating something else. This check is very effective for phrase-based decoding which searches over an entire space within the distortion limit in order to advance a hypothesis. In fact, it constrains reordering for the phrase-based model, as Cherry finds that the cohesio</context>
</contexts>
<marker>Tillman, 2004</marker>
<rawString>Tillman, C. (2004). A unigram orientation model for statistical machine translation. In HLT-NAACL 2004: Short Papers, pages 101–104, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tromble</author>
<author>J Eisner</author>
</authors>
<title>Learning linear ordering problems for better translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1007--1016</pages>
<contexts>
<context position="5001" citStr="Tromble and Eisner, 2009" startWordPosition="754" endWordPosition="757">om phrase structure parsing (de Marneffe et al., 2006). 2.1 Dependency Orientation Based on the assumption that constituents generally move as a whole (Quirk et al., 2005), we decompose the sentence reordering probability into the reordering probability for each aligned source word with respect to its head, excluding the root word at the top of the dependency hierarchy which does not have a head word. Similarly, Hayashi et al. (2010) also take a word-based reordering approach for HPBMT, but they model all possible pairwise orientation from the source side as a general linear ordering problem (Tromble and Eisner, 2009). To be more specific, we have a maximum entropy orientation classifier that predicts the probability of a source word being translated in a monotone or reversed manner with respect to its head. For example, 1http://nlp.stanford.edu/software/lex-parser.shtml (a) (b) idep idep ihead ihead S 1 S 2 S 3 S 1 S 2 S 3 en tsto il lust rateorient at ionclas-si fication.In( a),mo notone(M); in (b), reversed (R). given thealignmenti nFigure2(a),withthe align- ment p oint s(e dep,nd ep)f orthe s ource d epend ent wor d and(e head,dhea d)fo rth e source head wo rd, wed efinetw oori entat io nclas ses as:e=</context>
</contexts>
<marker>Tromble, Eisner, 2009</marker>
<rawString>Tromble, R. and Eisner, J. (2009). Learning linear ordering problems for better translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1007–1016, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>M Collins</author>
<author>P Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>737--745</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="31074" citStr="Wang et al., 2007" startWordPosition="5063" endWordPosition="5066"> naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phras</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Wang, C., Collins, M., and Koehn, P. (2007). Chinese syntactic reordering for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 737–745, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>J May</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Re-structuring, re-labeling, and re-aligning for syntaxbased machine translation.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="2219" citStr="Wang et al., 2010" startWordPosition="309" endWordPosition="312">hat although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency. Syntax-based models that use phrase structure constituent labels as non-terminals in their transfer rules, exemplified by that of Galley et al. (2004), produce smarter and syntactically motivated reordering. However, when working with off-the-shelf tools for parsing and alignment, this approach may impose harsh limits on rule extraction and requires serious efforts of optimization (Wang et al., 2010). An alternative approach is to augment the general hierarchical phrase-based model with soft syntactic constraints. Here, we derive three word-based, complementary constraints from the source dependency parsing, including: • A dependency orientation feature, trained with maximum entropy on the word-aligned parallel data, which directly models the headdependent orientation for source words; • An integer-valued cohesion penalty that complements the dependency orientation feature, and fires when a word is not translated with its head. It measures derivation well-formedness and is used to indirec</context>
</contexts>
<marker>Wang, May, Knight, Marcu, 2010</marker>
<rawString>Wang, W., May, J., Knight, K., and Marcu, D. (2010). Re-structuring, re-labeling, and re-aligning for syntaxbased machine translation. Computational Linguistics, 36(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Watanabe</author>
<author>J Suzuki</author>
<author>H Tsukada</author>
<author>H Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>764--773</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="14188" citStr="Watanabe et al., 2007" startWordPosition="2280" endWordPosition="2283">X → (shaoshu1 guojia2, few1 countries2) Second, our cohesion penalty can be by nature more discriminative. Compared with the constituency constraints, the cohesion penalty is integer-valued, and can be made sensitive to the depth of each word in the dependency hierarchy (see Section 2.4). Inspired by (Marton and Resnik, 2008; Chiang et al., 2009), the cohesion penalty could also be made sensitive to the dependency relation of each word. However, this drastically increases the number of features and requires a tuning algorithm which scales better to high-dimensional model spaces, such as MIRA (Watanabe et al., 2007; Chiang et al., 2008). 860 Figure 3: Using 2 bins for the dependency parse tree of the Figure 1 sentence. 2.3 Unaligned Penalty The dependency orientation and cohesion penalty cannot be applied to unaligned source words. This may lead to search error, such as dropping (i.e., unaligning) key content words that are important for lexical translation and reordering. The problem is mitigated by an unaligned penalty applicable to all words in the dependency hierarchy. 2.4 Grouping Words into Bins Having defined dependency orientation, cohesion penalty and unaligned penalty, we section the source de</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Watanabe, T., Suzuki, J., Tsukada, H., and Isozaki, H. (2007). Online large-margin training for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 764–773, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>A polynomial-time algorithm for statistical machine translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>152--158</pages>
<location>Santa Cruz, California, USA.</location>
<contexts>
<context position="31515" citStr="Wu, 1996" startWordPosition="5137" endWordPosition="5138">h is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less linguistically-motivated. 6 Conclusion We have derived three novel features from the source dependency structure for hierarchical phrase-based MT. They work as a whole to capitalize on two characteristics of the dependency representation: it is directly based on words and it directly connects head and child. The effectiveness of our approach has been </context>
</contexts>
<marker>Wu, 1996</marker>
<rawString>Wu, D. (1996). A polynomial-time algorithm for statistical machine translation. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, pages 152–158, Santa Cruz, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Xiong</author>
<author>Q Liu</author>
<author>S Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>521--528</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="31486" citStr="Xiong et al. (2006)" startWordPosition="5129" endWordPosition="5132">r reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less linguistically-motivated. 6 Conclusion We have derived three novel features from the source dependency structure for hierarchical phrase-based MT. They work as a whole to capitalize on two characteristics of the dependency representation: it is directly based on words and it directly connects head and child. The effectiven</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Xiong, D., Liu, Q., and Lin, S. (2006). Maximum entropy based phrase reordering model for statistical machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 521–528, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Xiong</author>
<author>Q Liu</author>
<author>S Lin</author>
</authors>
<title>A dependency treelet string correspondence model for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>40--47</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="26782" citStr="Xiong et al., 2007" startWordPosition="4418" endWordPosition="4421">e 5: Example translations from the NIST MT08 set, output by the baseline model and “bin-2” model. The “-lr” version outputs are quite similar and not shown here. Translation outputs are in lower case. tures the boxed area as a whole and uses Rule 10 to perform the right global reordering. X → (dui1 X2 gandao3 manyi4 .5 , (10) expressed3 satisfaction4 with1 X2 .5 ) 5 Related Work In recent years, there has been a growing body of research on using dependency for statistical machine translation. Some directly encodes dependency in the translation model (Ding and Palmer, 2005; Quirk et al., 2005; Xiong et al., 2007; Shen et al., 2008; Mi and Liu, 2010), while others use dependency as a soft constraint (Cherry, 2008; Bach et al., 2009a,b; Chang et al., 2009). Among them, Shen et al. (2008) report that just filtering the phrase table by the socalled well-formed target dependency structure does not help, yet adding a target dependency language model improves performance significantly. Our intuitive interpretation is that the target dependency language model capitalizes on two characteristics of the dependency structure: it is based on words and it directly connects head and child. Therefore, the target dep</context>
</contexts>
<marker>Xiong, Liu, Lin, 2007</marker>
<rawString>Xiong, D., Liu, Q., and Lin, S. (2007). A dependency treelet string correspondence model for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 40–47, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Xu</author>
<author>J Kang</author>
<author>M Ringgaard</author>
<author>F Och</author>
</authors>
<title>Using a dependency parser to improve smt for subjectobject-verb languages.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>245--253</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="31238" citStr="Xu et al., 2009" startWordPosition="5090" endWordPosition="5093"> feature is similar to the order model within dependency treelet translation (Quirk et al., 2005). Yet instead of a head-relative position number for each modifier word, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less linguistically-motivated. 6 Conclusion We have derived three novel features </context>
</contexts>
<marker>Xu, Kang, Ringgaard, Och, 2009</marker>
<rawString>Xu, P., Kang, J., Ringgaard, M., and Och, F. (2009). Using a dependency parser to improve smt for subjectobject-verb languages. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 245–253, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Discriminative reordering models for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>55--63</pages>
<location>New York City.</location>
<contexts>
<context position="31409" citStr="Zens and Ney (2006)" startWordPosition="5116" endWordPosition="5119">, we simply predict the head-dependent orientation which is either monotone or reversed. Our coarser-grained approach is more robust from a machine learning perspective, yet still captures prominent and long-distance reordering patterns observed in Chinese–English (Wang et al., 2007), German–English (Collins et al., 2005), Japanese– English (Katz-Brown and Collins, 2008) and translation from English to a group of SOV languages (Xu et al., 2009). Not committed to specific language pairs, we learn orientation classification from the word-aligned parallel data through maximum entropy training as Zens and Ney (2006) and Chang et al. (2009) for phrase-based translation and Xiong et al. (2006) for the BTG model (Wu, 1996). While Chang et al. (2009) also make use of source dependency, their orientation classification concerns two subsequent phrase pairs in the leftto-right phrase-based decoding (as apposed to each dependent word and its head) and is therefore less linguistically-motivated. 6 Conclusion We have derived three novel features from the source dependency structure for hierarchical phrase-based MT. They work as a whole to capitalize on two characteristics of the dependency representation: it is di</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>Zens, R. and Ney, H. (2006). Discriminative reordering models for statistical machine translation. In Proceedings on the Workshop on Statistical Machine Translation, pages 55–63, New York City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zollmann</author>
<author>A Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>138--141</pages>
<location>New York City.</location>
<contexts>
<context position="30065" citStr="Zollmann and Venugopal, 2006" startWordPosition="4916" endWordPosition="4919">., 2009a,b) (They do have a non-empty intersection, but neither subsumes the other). There864 fore, our cohesion penalty is better suited for the hierarchical phrase-based model. To discourage nonconstituent translation, Chiang (2005) has proposed a constituency feature to examine whether a source rule span matches the source constituent as defined by phrase structure parsing. Finer-grained constituency constraints significantly improve hierarchical phrase-based MT when applied on the source side (Marton and Resnik, 2008; Chiang et al., 2009), or on the target side in a more tolerant fashion (Zollmann and Venugopal, 2006). Using both source and target syntax, but relaxing on rule extraction and substitution enables HPBMT to produce more well-formed and syntactically richer derivations (Chiang, 2010). Softening constituency matching with latent syntactic distributions proves to be helpful (Huang et al., 2010). Compared to constituency-based approaches, our cohesion penalty based on the dependency structure naturally supports constituent translations as well as some nonconstituent translations, if not all of them (as discussed in Section 2.2). Our dependency orientation feature is similar to the order model with</context>
</contexts>
<marker>Zollmann, Venugopal, 2006</marker>
<rawString>Zollmann, A. and Venugopal, A. (2006). Syntax augmented machine translation via chart parsing. In Proceedings on the Workshop on Statistical Machine Translation, pages 138–141, New York City.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>