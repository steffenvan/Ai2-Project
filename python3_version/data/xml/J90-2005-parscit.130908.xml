<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000051">
<bodyText confidence="0.8560002">
Book Reviews Natural Language Processing in LISP, POP-11, and PROLOG
processing. LDOCE has some attractive special features,
but so do other dictionaries. There can be little doubt, on
the other hand, about the importance and value of the kind
of research reported in this book.
</bodyText>
<sectionHeader confidence="0.995868" genericHeader="abstract">
REFERENCES
</sectionHeader>
<reference confidence="0.9826205">
Hofland, Knut and Johansson, Stig. 1982 Word Frequencies in British
and American English. Norwegian Computing Centre for the Humani-
ties, Bergen.
Jansen, J.; Mergeai, J.P.; and Vanandroye, J. 1987 Controlling LDOCE&apos;s
Controlled Vocabulary. In: Cowie, A.P., ed., The Dictionary and the
Language Learner (Lexicographica, series maior, 17). Niemeyer, Tu-
bingen, 78-94.
Mitton, Roger. 1986 A partial dictionary of English in Computer-Usable
Form. Literary and Linguistic Computing 1:214-215.
Sampson, G.R. 1989 How Fully Does a Machine-Usable Dictionary
Cover English Text? Literary and Linguistic Computing. 4:29-35.
Walker, D.E. and Amsler, R.A. 1986 The Use of Machine-Readable
Dictionaries in Sublanguage Analysis. In: Grishman, Ralph and Kit-
tredge, Richard, eds., Analyzing Language in Restricted Domains:
Sublanguage Description and Processing. Lawrence Erlbaum, Hills-
dale, NJ: 69-83.
</reference>
<affiliation confidence="0.820358">
Geoffrey Sampson is Professor of Linguistics and Director of the
Centre for Computer Analysis of Language and Speech at the
University of Leeds, Britain&apos;s largest unitary university. His
</affiliation>
<bodyText confidence="0.7775915">
computational linguistics research is corpus-based, and includes
development of a system of robust parsing by stochastic optimiza-
tion (Project APRIL). With Roger Garside and Geoffrey Leech
he coedited The Computational Analysis of English (Longman,
1987). Sampson&apos;s address is: Department of Linguistics and
Phonetics, University of Leeds, Leeds LS2 9JT, U.K.
</bodyText>
<sectionHeader confidence="0.988406166666667" genericHeader="keywords">
NATURAL LANGUAGE PROCESSING IN LISP: AN
INTRODUCTION TO COMPUTATIONAL LINGUISTICS
NATURAL LANGUAGE PROCESSING IN POP-11: AN
INTRODUCTION TO COMPUTATIONAL LINGUISTICS
NATURAL LANGUAGE PROCESSING IN PROLOG: AN
INTRODUCTION TO COMPUTATIONAL LINGUISTICS
</sectionHeader>
<subsectionHeader confidence="0.963379">
Gerald Gazdar and Chris Mellish
</subsectionHeader>
<bodyText confidence="0.859618">
(University of Sussex and University of Edinburgh,
respectively)
Workingham, England: Addison-Wesley, 1989
Lisp volume: xv + 524 pp.
Hardbound, ISBN 0-201-17825-7, £17.95
Pop-11 volume: xv 524 pp.
Hardbound, ISBN 0-201-17448-0, £17.95
Prolog volume: xv + 504 pp.
Hardbound, ISBN 0-201-18053-7, £17.95
</bodyText>
<footnote confidence="0.6417355">
Reviewed by
Kwee TjoeLiong
</footnote>
<affiliation confidence="0.613152">
University of Amsterdam
</affiliation>
<bodyText confidence="0.981636982456141">
This is a very interesting and intriguing array of textbooks
to read, to compare, and to review. It also has been a rather
hard job for me to do so. The last paragraphs try to explain
why. First of all, however, an objective and factual sum-
mary of the contents and form of Gazdar and Mellish&apos;s
NLP in X: An Introduction to CL, where Xis instantiated
to one of (PROLOG, POP-11, LISP} (reviewer&apos;s short-
hand).
Quotations can be helpful as the shortest way to give you
a rapid impression. From the letter that the book review
editor sent me is this encouraging line: &amp;quot;They are really
three separate versions of the same book, so there&apos;s not
nearly as much reading as there first appears.&amp;quot; Therefore,
one of the titles is treated here as prototypical (to wit, the
Prolog volume). Whenever they differ, the other two are,
subjectively, considered as derivative.
I am going to quote amply from the authors&apos; Preface,
since it is a characterization of the book in their own words.
It is neatly split into sections, and I distinguish three
aspects: &apos;What,&apos; What Exactly,&apos; and &apos;In What Way,&apos; each
aspect being handled in a pair of consecutive sections of the
preface.
What: From the first two sections, Audience and Cover-
age:
This book is aimed at computer scientists and linguists
at undergraduate, postgraduate or faculty level, who
have taken, or are concurrently taking, a programming
course in X. . . . The book is specifically intended to
teach NLP and computational linguistics: it does not
attempt to teach programming or computer science to
linguists, or to provide more than an implicit introduc-
tion to linguistics for computer scientists. . .
The major focus of this book, as of the field to which it
provides an introduction, is on the processing of the
orthographic forms of natural language utterances and
text. [No issues in speech, because those are] topics that
deserve books to themselves, books that we would not be
competent to write. Most of the book deals with the
parsing and understanding of natural language, much
less on the production of it. This bias reflects the present
shape of the field, and of the state of knowledge. . .
The book is formally oriented and technical in charac-
ter, and organized, for the most part, around formal
techniques. The perspective adopted is that of computer
science, not cognitive science. . . . We concentrate on
areas that are beginning to be well understood, and for
which standard techniques. . . have begun to emerge. . . .
[Hence,] a good deal more time on syntactic processing
than on semantic or pragmatic processing. . . . Discus-
sion of developments at the leading edge of NLP re-
search, on such topics as parallel parsing algorithms, the
new style categorial grammars, connectionist approaches
or the emerging implementations of situation semantics
and discourse representation theory are excluded alto-
gether or relegated to the further reading sections.. . . A
less readily excusable omission is any consideration of
the role of probabilistic techniques in NLP. [But . . . ]
</bodyText>
<page confidence="0.929938">
116 Computational Linguistics Volume 16, Number 2, June 1990
</page>
<bodyText confidence="0.997658709821429">
Book Reviews Natural Language Processing in LISP, POP-II, and PROLOG
probabilistic NLP work is largely restricted, at present,
to those few centres that have the necessary data and the
resources to process it.
What Exactly: Now that they have roughly sketched what
the book is about and what not, it is possible for the authors
to specify some more details. In the fourth section, Con-
tents, the table of contents, that is, the list of chapter and
section titles, is paraphrased in running text. I in turn
squeeze it back into an enumeration of key words a bit
further on below. In the third section, Grammar formal-
ism, it is announced that:
Rather than attempt to survey some subset of [the many
different grammar formalisms adopted by computa-
tional linguists, over the years and even today,] . . . we
have simply adopted one, PATR. . . . PATR is relatively
widely used in the NLP community. . . . From the per-
spective of this book, it represents a very clean, unclut-
tered, basic unification grammar formalism that is suffi-
ciently expressive that pretty much anything one might
want to say in another grammar formalism can be
readily translated into a PATR equivalent. It is also
rather straightforward to implement an interpreter for
PATR in X, and we show how to do this.
In What Way: In conclusion, the authors describe their
own way of handling the matter. From the fifth and sixth
sections of the preface, Organization and Programming
language:
Each chapter contains material of two types. The first
type is a relatively self-contained treatment of some
theoretical topic. Here, computational issues are dis-
cussed without reference to the details of X or any other
programming language. A person without much compu-
tational background should be able to get a feel for the
issues in NLP by just reading this material. The second
type contains extracts of programs, notes on techniques
and exercises in X. . . . We have attempted to grade
exercises as follows . . . [easy, intermediate, hard,
project].
In our view, for a computational linguistics or NLP
textbook to be maximally useful, it must commit itself to
a particular choice of real programming language. . . .
The choice. . . has to recognize the major regional lan-
guage divisions in computing and Al.
We feel that the study of computational linguistics is
only brought to life by actually writing and running
programs. So, a textbook on the subject should provide a
source of ideas and examples to stimulate the student&apos;s
initial programming activity. It is much easier to follow
a particular computational concept or algorithm, espe-
cially to those lacking a thorough computer science
background, if it is expressed in a familiar programming
language than if it is expressed (formally or informally)
in some unfamiliar way. . . . We have chosen to base our
discussions of programming and algorithms around ex-
amples in an actual programming language, namely X.
Let me now enter into the form and the contents proper.
Here are some general statistics: the body of the text
consists of slightly more than 400 pages; the remaining
100-120 pages are mainly taken by code listings (Prolog,
66 pages, and Pop-11 and Lisp, 80 pages, for 54 listings; not
always the same examples in all versions) and a bibliogra-
phy (some 20 pages for some 350-400 titles); there are
solutions (mostly hints) to (a few) selected exercises, a
name index, and a general index. Each of the ten chapters
is subdivided into short sections (with an average of eight or
nine per chapter). The chapter lengths cluster around an
average of 40 pages, with, exceptionally, 20 pages for
Chapter 1, and 65 pages (plus or minus 3 for the different
language versions) for Chapter 7 (which, for its contents,
might as well have figured as two, or one-and-a-half,
separate chapters). Altogether the chapters can be grouped
into three chunks, in the proportion of 100:175:125 pages,
as follows (for each part I have supplied an appropriate
characteristic motto):
Part 1, the first three chapters (&amp;quot;What happened
before&amp;quot;): One chapter on introductory generalities and two
on the classic stock of automata, transducers, and transi-
tion network techniques (finite-state; pushdown or recursive;
augmented).
Part 2, the middle four chapters (&amp;quot;Today&apos;s frontiers&amp;quot;):
Basic concepts are introduced and illustrated in an up-to-
date, feature-theoretic, unification-based directed-acyclic-
graph—oriented setting: grammar in Chapter 4 (rules, struc-
tures, context-freeness); parsing, search, and ambiguity in
Chapter 5 (bottom-up, top-down; breadth-first, depth-first;
determinism, look-ahead); charts in Chapter 6. The culmi-
nation point is reached in Chapter 7 on feature theory
(graphs, subsumption, unification), where almost every-
thing is being resumed and connected to almost everything
else, the lexicon included.
Part 3, the last three chapters (&amp;quot;The future has already
begun&amp;quot;): A selection of established and recent topics, from
semantics in Chapter 8 (meaning representation language,
which may remind one of logical form and of knowledge
representation), via its corollaries in Chapter 9, question-
answering (database query), inference (backwards, for-
wards; frames), and primitives (inheritance, defaults; se-
mantic networks), to pragmatics in Chapter 10 (the variety
of different roles of noun phrases; prediction and scripts;
discourse structure).
The Prolog version is distinguished from the other two in
that is has practically nothing on ATNs (which means
twelve fewer pages in Chapter 3), and no random genera-
tion either (six fewer pages in Chapter 7). This is made up
for by the insertion of definite clause grammar here and
there in the remaining middle chapters.
The central part of the Prolog version is, obviously, the
Computational Linguistics Volume 16, Number 2, June 1990 117
Book Reviews Natural Language Processing in LISP, POP-11, and PROLOG
piece de resistance of the work. Why do I think it is?
Because it is here that the authors show their commitment.
And also because it might be possible to use this part as a
classroom text independently from the other two. I would
dare to bet that Part 1 is not really a prerequisite for it. Part
3, on the other hand, is not really an essential or natural
sequel to it. In turn, Part 3 possibly does not require Part 2
either, except for the fact that a predicate logic formula can
be represented as, or translated into, a directed acyclic
graph. Furthermore, there is far less programming in Part
3. In short, Part 3 functions rather as a first introduction,
albeit in a feature theoretic coating, to issues in formal
semantics, philosophy of language, and discourse analysis.&apos;
Some authors of classroom texts want their, book to be
self-contained. Gazdar and Mellish do not have this desire;
witness the quotation above from their Preface. Indeed,
linguists who have no knowledge of programming and who
missed the explicit clues given there will soon be at a loss
and give up, or else skip the programming part and try &amp;quot;to
get a feel for the issues in NLP&amp;quot; anyhow. Now, imagine
computer scientists who have little or no knowledge of what
linguistics is and who missed the implicit clues given in the
Preface (they will also miss the warning that is to follow
here, since they are not among the readership of this
journal anyway). Chances are, they will be able neverthe-
less to finish the book. On the one hand, that is certainly a
merit of the book; on the other hand, is it not also because
the story it tells is a little bit misleading? At least, the story
is a bit risky. Grammars and linguistic examples are invari-
ably of the toy kind. Interesting complex structures are
hardly shown. One gets a strong feeling that the book is
addressed to linguists in the first place, in order to persuade
them into CL (an endeavor I support, for that matter), and
that the main interesting problems in grammar are as-
sumed to be known to the readers. But these problems are
not treated at all, at most hinted at in some exercises. Why?
I suppose, because they would need a lot more technique,
being much more intricate than the toy examples. The
necessary techniques, however, not only in the specific
programming language but in general in the domain of
concepts and formalisms, as they already possess a certain
level of intricacy by themselves, must be presented and
illustrated with the help of simple cases—an approach I
approve of, with one proviso: students should realize that
this is not the whole story. Are nonlinguists in general
really aware of more interesting problems at an advanced
level of grammar? I often doubt it. It is alarming how false
an impression of NLP/CL people get from the lecture of
just one chapter in an introductory book on Al: only simple
examples are handled, and it is tacitly implied that the rest
of grammar is pretty much alike. Knowledge of language is
often mistaken for knowledge of linguistics. (Think of
mechanical translation in the 1950s and early 1960s and
the naive optimism it aroused at that time. What is, by the
way, the first meaning of the word linguist, in most dictio-
naries and in daily life outside our field?) So, to use the
jargon of movie rating, I have to give this warning: adult
linguistic guidance is strongly advised (in the second dictio-
nary sense of linguist).
Some users of classroom texts have been spoiled by a
certain tradition of Hints on How to Use This Book, either
as scheduling suggestions (during W weeks, M meetings
per week, of H hours each) or in the form of a chart-like
diagra m (or a DAG—why not?) of the dependencies be-
tween the chapters. To the slight annoyance of those peo-
ple, there are no such suggestions here whatsoever. Why?
Is it forgetfulness? Or is it because the chapters are equally
important and one simply has to work through them one by
one in linear order? Is it indulgent liberality, the wish to
avoid imposing strict schedules upon others? Or is it a
challenge, in the sense that one should find out oneself
which chapters to treat in full, which sections to skip if time
presses, and in which pace? Yet some guidelines in one way
or another would probably have been appreciated, for
instance, by those with little experience in teaching this
material, possibly in order to avoid overcharging their
class, or to check that their demands were reasonable after
all.
If no other points are mentioned here that might be
considered doubtful or mistaken, that does not mean that I
entirely agree with every detail I set my eyes upon. For
instance, minor errors have, inevitably, arisen in the wealth
unfolded in the recommendable further reading sections
and in the extensive bibliography. It is left to attentive
readers to find those corrigenda et addenda by themselves. I
pass over them in silence.
Literature in NLP/CL, as in all new emerging fields, has
for a long time been suffering from a &amp;quot;case history&amp;quot; syn-
drome. Textbooks, or overview chapters in Al books, were
typically surveys of the various research projects, telling
over and over again the stories of Eliza, SHRDLU, Lunar,
and so on. It was often unclear what the field consisted of
exactly; even its name was problematic.2 In the title of the
work under review, the authors have taken a stand: NLP is
technology, and they present it as a road toward CL. CL is
much more than just (syntactic) NLP. CL is theory, and it
is based not only on grammar but also on formal logic and
on discourse analysis. The authors have demonstrated this
point of view in their choice of one single particular nota-
tion throughout, in the coherence and consistency of their
treatment, and in the extent of their subject matter.3
To sum up, then, this is my evaluation of the quality and
importance of the work at hand. In my opinion, this book is
in general fairly good, and in part very good. It is important
enough for the interested and well-prepared reader (who
took a full-year linguistic course, and has done at least a
moderate amount of programming) to try to get a copy in
her or his own preferred language version.
As a rule, this kind of text has two types of readership. I
don&apos;t mean those who approach the field from computer
science and those who approach from linguistics; on that
aspect I have already made an observation. Now, I have
another distinction in mind: between what I call Readers-
from-Outside and Readers-from-Inside. People from both
</bodyText>
<page confidence="0.859588">
118 Computational Linguistics Volume 16, Number 2, June 1990
</page>
<bodyText confidence="0.995957449438202">
Book Reviews Natural Language Processing in LISP, POP-11, and PROLOG
categories are interested in the question What can you do
with natural language on a computer? The first group take
you in the generic reading. They would like to know, to see,
to get acquainted with, what one can do, what people can
do. The second group gives you a specific interpretation,
because they want to find out, to study, to learn, what the
addressee can do, that is, what they themselves can do. By
association, I count among the last category not only
students but also those who teach them, that is, those who
put the question to the addressees.
In reading and reviewing a new classroom text on NLP/
CL, it is difficult not to compare it to other books one is
already familiar with—the more so, when one such other
book is generally known, widely used, and frequently re-
ferred to: Winograd (1983) (see Cohen 1986).4
It is here that the biased part of the review starts. I am
using Winograd&apos;s book in my classes and I am happy with
it. I admit the merits of the work under review, and won&apos;t
take back anything I have said above. I perfectly realize
that the next few paragraphs express a one-sided view that
not everybody would share, or would agree with; nobody
has to. It is one particular approach, heavily influenced by
one particular situation. The typical audience in that situa-
tion has not quite taken a full-year linguistic course, and
has done only a very modest (less than moderate) amount
of programming.5
In an introductory NLP/CL course, I claim—especially
in an NLP/CL cum programming course—one should be
made aware of three distinct levels of reflection, or three
subsequent stages. At the linguistic level, a clear definition
and description is needed of the phenomena to be captured.
At the algorithmic level, the data and the goals have to be
set, and a method has to be traced out. At the coding level,
the formal algorithm must be translated into code of a real
programming language. The last two things must abso-
lutely be kept apart.
These three levels are well distinguished in Winograd&apos;s
book. Language and linguistics are treated in two chapters
(on transformational grammar, and feature and function
grammars) and two appendices (syntax of English and
recent developments in TG), together good for about forty
percent of the book. A drawback is that theoretical ap-
proaches become obsolete. But interesting complex phenom-
ena and structures are here to stay. Algorithms are care-
fully presented in a clear formalism (which, unfamiliar as it
may be at first, is not difficult to understand) and are kept
visually well separated, displayed in special boxes. One big
advantage, for my goals, is that the coding level is simply
left out, that is, the book is programming language–free.
Thus it is suitable for giving students the training they need
in writing programs. At a certain level, coding is a creative
activity. Moreover, coding a given algorithm has a twofold
effect. It invites students to reflect, both upon the proce-
dures they thought to have understood, and upon the
expressiveness of the language they have to acquire fluency
in. Winograd&apos;s Chapter 2 (patterns, FTNs), Chapter 3
(context-free parsing) and Chapter 5 (RTNs, ATNs) are
very useful for this goal and for our audience (as a matter
of fact, I have been myself preparing a little Prolog Com-
panion to Winograd&apos;s LCP1: Syntax). The same subjects
can be found in Gazdar and Mellish&apos;s Chapter 2, Chapters
4 to 6, and Chapter 3, respectively.6
Some people object that, in this way, students have to
re-invent the wheel, an activity they consider unnecessary.
I contend that before you have your students tackle new
and big (and may be as yet unsolved) problems, you&apos;d
better let them have some experience in tackling small and
simple problems, the solutions of which you know and they
don&apos;t. In this way you will be able to help them and to coach
them, and you give them the opportunity to grind their
knives at their own levels. The work under review lends
itself better to another strategy. Here, the programming
language is an essential tool for exposition: algorithms are
often presented in the form of a working program. Thus, a
twofold goal of another type is pursued. Not only do
students learn to read and understand real code, but they
are also given, for free, the techniques that may lead them
smoothly into the advanced realms of research. Winograd&apos;s
book and this work are each better suited for one of two
rather opposite pedagogical styles. Both styles have their
supporters. To be able to profit maximally from the study of
this work, I think, students need a higher level at least in
programming than used to be required for our introductory
NLP/CL classes. This book as a classroom text makes it
harder for relatively inexperienced programmers to develop
(and to show) their creativity in writing code. Regrettably
so, for re-inventing the wheel can be a satisfying and
rewarding activity, worthwhile of investment.
</bodyText>
<subsectionHeader confidence="0.326904">
NOTES
</subsectionHeader>
<bodyText confidence="0.93586728">
1. And why in particular the Prolog version? Because I think this version
is their prototype text. Here is some circumstantial evidence. As most
readers will remember, the second author is also co-author of a
well-known book on Prolog. The authors already used an early draft
of the Prolog version when teaching their CL course at the LSA
Linguistic Institute, Stanford 1987. The formalism they adopt has an
inherently declarative character. The font they use for sample concep-
tual objects (such as grammar rules and feature structures) is dif-
ferent from the font they use for program code, but logic formulae all
over the three editions are typeset in the same conspicuous boldface as
the Prolog code, widely distinct from the Pop-11 and Lisp lightface
sans-serif fonts. The bibliographies have about 350 titles in common,
to which a varying number of language-specific references is added in
the different editions: 8 for Pop-11, 20 for Lisp, and not fewer than 49
for Prolog. The preface in the Prolog version bears the date of
February 1989, and, although the Pop-11 preface shows the same
month, the Lisp version (which in the noncode parts is quite identical
to the Pop-11 one) has its preface dated March 1989.
Post scriptum: I would like to add that this conclusion, although an
easy one to come to, turned out to be completely wrong. In fact,
Mellish informs me: &amp;quot;The Prolog-specific material was created rela-
tively late in the writing, and was not parasitic on the others, or
conversely. Actually we had a quite elaborate. .. set-up that allowed
us to write all three books simultaneously. . . without any text having
a priority.&amp;quot;
</bodyText>
<note confidence="0.3059615">
Computational Linguistics Volume 16, Number 2, June 1990 119
Book Reviews Modelisation du dialogue: Representation de l&apos;inference argumentative
</note>
<reference confidence="0.912213523809524">
2. Compare the rather amusing confusion produced by the most promi-
nent bibliography of the field published to date, Gazdar etal. (1987).
The book is called NLP in the 1980s on the cover and title page, for
The Outside World, so to speak. Inside the book, the list itself is called
&amp;quot;CL in the 1980s,&amp;quot; for The Inside World. In addition, it is computer-
accessible as CLBIB at Stanford, and letter mail must be sent to
CLBIB at the School of Cognitive Sciences, University of Sussex.
3. It is to be hoped that this tendency will continue to develop, similar to
the line of growing insight shown in the sequence of (titles of) books
by Nilsson: Problem-Solving Methods in Al (1971), Principles of Al
(1980/1982), and Logicdl Foundations of Al (1987, with Gen-
esereth).
4. In this survey of CL courses Winograd (1983) as the most frequently
cited reference, with 23 citations in 51 courses described as &apos;only CL&apos;;
the most frequently cited references in all 76 courses (including 25
described as &apos;courses with topics other than CL&apos;)-46 courses within
North America and 30 outside North America—are: Winograd 30,
King 10, Tennant 8, Schank and Riesbeck 7 (Cohen 1986:4).
5. A quick sketch of the local context at our department: University
entrance level in Europe is in general considered to be equivalent to
American junior college graduation. Four years at a European univer-
</reference>
<bodyText confidence="0.674598888888889">
sity are comparable to junior and senior year plus graduate studies up
to Master&apos;s thesis in the U.S. Students enter our seven-to-eight-
quarter CL program after at least one year study at a language
department, and they have to take (or to have taken) optionals for two
additional quarters. The core program in the first two to three terms
consists of classes in linguistics, formal logic, and computer science
(that is, introductory programming and an introduction to formal
languages and automata theory). Students used to take the Winograd
course at some point around the end of the core program and the
beginning of the advanced terms. We are currently engaged in
incorporating it into the core program (as of Spring 1990).
6. Setting aside the fact that ATNs are admittedly in decline, it is
surprising to see how the choice of a language can determine which
subjects to treat: see my previous remark on the differences between
the Prolog edition and the other two versions. Programming an ATN
in Prolog is not so thoroughly perverse as Gazdar and Mellish think it
is (p. 96), nor is it too difficult. Some of our students succeed in doing
so without much contriving, and it looks like really nice Prolog.
</bodyText>
<sectionHeader confidence="0.982214" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.970969125">
Cohen, Robin (compiler). 1986 Survey of Computational Linguistics
Courses. Computational Linguistics. 12:course survey supplement.
Gazdar, Gerald; Franz, Alex; Osborne, Karen; and Evans, Roger. 1987
Natural Language Processing in the 1980s: A Bibliography. Center for
the Study of Language and Information, Stanford, CA.
Genesereth, Michael R., and Nilsson, Nils J. 1987 Logical Foundations
of Artificial Intelligence. Morgan Kaufmann, Los Altos, CA.
Nilsson, Nils J. 1971 Problem-Solving Methods in Artificial Intelligence.
McGraw-Hill, New York, NY.
Nilsson, Nils J. 1980 Principles of Artificial Intelligence. Tioga, Palo
Alto, CA. Also: 1982 Springer, Heidelberg.
Winograd, Terry. 1983 Language as a Cognitive Process. Volume 1:
Syntax. Addison-Wesley, Reading, MA.
Kwee TjoeLiong (in the U.S.: TjoeLiong Kwee) is a mathemati-
cian and a lecturer at the Department of Computational Linguis-
tics, University of Amsterdam, is teaching courses in program-
ming and in computational linguistics, and is doing research on
generation and on modeling and testing of linguistic theories.
Kwee&apos;s address is: Department of Computational Linguistics,
University of Amsterdam, Spuistraat 134, 1012 VB Amsterdam.
The Netherlands. E-mail: tl@alf.let.uva.n1
MODE LISATION DU DIALOGUE: REPRESENTATION DE
L&apos;INFERENCE ARGUMENTATIVE (MODELING DIALOGUE:
REP RESENTATION OF INFERENTIAL ARGUMENTATION)
Jacques Moeschler
(Universite de Geneve)
Paris: Hermes, 1989, 266 p. (Langue, raisonnement,
calcul)
Hardbound, ISBN 2-86601-191-0, FF 200
Reviewed by
Klaus Schubert
BSO/Research
</reference>
<bodyText confidence="0.999910069767442">
The other day a professor of linguistics told me about one of
his student&apos;s worlcs:&amp;quot;It is very mathematical but intelligent.&amp;quot;
If you want to know what this little but means, implies, and
reveals, read this book.
Jacques Moeschler, who is engaged in the linguistics of
French at the University of Geneva, offers a model for
recognizing and formally representing the structure of
dialogues. His work is a contribution to the insufficiently
explored field of discourse analysis in the original sense
of the term, that is, the analysis of oral conversation.
Moeschler&apos;s analyses are based on a corpus of French
telephone conservations and similar materials, but many of
his findings may apply even to the broader field of text
linguistics.
A special focus in Moeschler&apos;s argumentation is on the
ways that propositions are linked up to form a text or a
dialogue. Many text grammarians distinguish various kinds
of linkedness in dialogues (cf. de Beaugrande and Dressler&apos;s
Koharenz vs. Kohasion, 1981: 3ff). Moeschler&apos;s terms are
pertinence for the connectedness in the context and coher-
ence for the connectedness in the discourse situation. The
central element in Moeschler&apos;s reasoning, which gives the
book its special interest and also its individual flavour in the
current flood of text-linguistic studies, is the notion of
connecteur. To put it simply, such connectors are function
words or word groups that link up propositions logically,
temporally, or otherwise. Examples (which, due to their
very nature, normally cannot easily be glossed out of con-
text) are et, ou, ne pas, quand meme, and alors.
The theoretical background of the work is to be sought in
predicate logic and speech act theory. Among the major
sources are works by Ducrot, Austin, and Grice. The book
falls into three parts, of which the first is mainly dedicated
to a predicate-logical analysis of the meaning of connec-
tors. Although Moeschler pursues this analysis in much
detail, the main object of his analysis remains the word
itself, rather than some underlying semantic or logical
representation. To my personal taste, this is the most
important virtue of the book: Moeschler has understood
that human language is richer than formal representations
(cf. Schubert 1988a: 137-138). He gives this insight right
in the introduction (p. 10), stating that in natural language,
there are a large number of connectors that lack equiva-
</bodyText>
<page confidence="0.815536">
120 Computational Linguistics Volume 16, Number 2, June 1990
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.031084">
<title confidence="0.805836">Reviews Language Processing in LISP, POP-11, and PROLOG</title>
<abstract confidence="0.949816">some attractive special features, but so do other dictionaries. There can be little doubt, on the other hand, about the importance and value of the kind of research reported in this book.</abstract>
<note confidence="0.743764944444444">REFERENCES Knut and Johansson, Stig. 1982 Frequencies in British American English. Computing Centre for the Humanities, Bergen. J.; Mergeai, J.P.; and Vanandroye, J. 1987 Controlling Vocabulary. In: Cowie, A.P., ed., Dictionary and the Learner series maior, 17). Niemeyer, Tubingen, 78-94. Mitton, Roger. 1986 A partial dictionary of English in Computer-Usable and Linguistic Computing 1:214-215. Sampson, G.R. 1989 How Fully Does a Machine-Usable Dictionary English Text? and Linguistic Computing. Walker, D.E. and Amsler, R.A. 1986 The Use of Machine-Readable Dictionaries in Sublanguage Analysis. In: Grishman, Ralph and Kit- Richard, eds., Language in Restricted Domains: Description and Processing. Erlbaum, Hillsdale, NJ: 69-83. Sampson Professor of Linguistics and Director of the</note>
<affiliation confidence="0.707827">Centre for Computer Analysis of Language and Speech at the University of Leeds, Britain&apos;s largest unitary university. His</affiliation>
<abstract confidence="0.894534">computational linguistics research is corpus-based, and includes development of a system of robust parsing by stochastic optimization (Project APRIL). With Roger Garside and Geoffrey Leech coedited Computational Analysis of English 1987). Sampson&apos;s address is: Department of Linguistics and Phonetics, University of Leeds, Leeds LS2 9JT, U.K.</abstract>
<intro confidence="0.895456">LANGUAGE PROCESSING IN</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Knut Hofland</author>
<author>Stig Johansson</author>
</authors>
<date>1982</date>
<booktitle>Word Frequencies in British and American English. Norwegian Computing Centre for the Humanities,</booktitle>
<location>Bergen.</location>
<marker>Hofland, Johansson, 1982</marker>
<rawString>Hofland, Knut and Johansson, Stig. 1982 Word Frequencies in British and American English. Norwegian Computing Centre for the Humanities, Bergen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jansen</author>
<author>J P Mergeai</author>
<author>J Vanandroye</author>
</authors>
<title>Controlling LDOCE&apos;s Controlled Vocabulary.</title>
<date>1987</date>
<booktitle>The Dictionary and the Language Learner (Lexicographica, series maior, 17). Niemeyer, Tubingen,</booktitle>
<pages>78--94</pages>
<editor>In: Cowie, A.P., ed.,</editor>
<marker>Jansen, Mergeai, Vanandroye, 1987</marker>
<rawString>Jansen, J.; Mergeai, J.P.; and Vanandroye, J. 1987 Controlling LDOCE&apos;s Controlled Vocabulary. In: Cowie, A.P., ed., The Dictionary and the Language Learner (Lexicographica, series maior, 17). Niemeyer, Tubingen, 78-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Mitton</author>
</authors>
<title>A partial dictionary of English</title>
<date>1986</date>
<booktitle>in Computer-Usable Form. Literary and Linguistic Computing</booktitle>
<pages>1--214</pages>
<marker>Mitton, 1986</marker>
<rawString>Mitton, Roger. 1986 A partial dictionary of English in Computer-Usable Form. Literary and Linguistic Computing 1:214-215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Sampson</author>
</authors>
<title>How Fully Does a Machine-Usable Dictionary Cover English Text? Literary and Linguistic Computing.</title>
<date>1989</date>
<pages>4--29</pages>
<marker>Sampson, 1989</marker>
<rawString>Sampson, G.R. 1989 How Fully Does a Machine-Usable Dictionary Cover English Text? Literary and Linguistic Computing. 4:29-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Walker</author>
<author>R A Amsler</author>
</authors>
<title>The Use of Machine-Readable Dictionaries in Sublanguage Analysis.</title>
<date>1986</date>
<booktitle>Analyzing Language in Restricted Domains: Sublanguage Description and Processing. Lawrence Erlbaum,</booktitle>
<pages>69--83</pages>
<editor>In: Grishman, Ralph and Kittredge, Richard, eds.,</editor>
<location>Hillsdale, NJ:</location>
<marker>Walker, Amsler, 1986</marker>
<rawString>Walker, D.E. and Amsler, R.A. 1986 The Use of Machine-Readable Dictionaries in Sublanguage Analysis. In: Grishman, Ralph and Kittredge, Richard, eds., Analyzing Language in Restricted Domains: Sublanguage Description and Processing. Lawrence Erlbaum, Hillsdale, NJ: 69-83.</rawString>
</citation>
<citation valid="false">
<title>Compare the rather amusing confusion produced by the most prominent bibliography of the field published to date, Gazdar etal.</title>
<date>1987</date>
<institution>University of Sussex.</institution>
<marker>1987</marker>
<rawString>2. Compare the rather amusing confusion produced by the most prominent bibliography of the field published to date, Gazdar etal. (1987). The book is called NLP in the 1980s on the cover and title page, for The Outside World, so to speak. Inside the book, the list itself is called &amp;quot;CL in the 1980s,&amp;quot; for The Inside World. In addition, it is computeraccessible as CLBIB at Stanford, and letter mail must be sent to CLBIB at the School of Cognitive Sciences, University of Sussex.</rawString>
</citation>
<citation valid="true">
<title>It is to be hoped that this tendency will continue to develop, similar to the line of growing insight shown in the sequence of (titles of) books by Nilsson: Problem-Solving Methods in Al</title>
<date>1971</date>
<booktitle>Principles of Al (1980/1982), and Logicdl Foundations of Al</booktitle>
<note>with Genesereth).</note>
<marker>1971</marker>
<rawString>3. It is to be hoped that this tendency will continue to develop, similar to the line of growing insight shown in the sequence of (titles of) books by Nilsson: Problem-Solving Methods in Al (1971), Principles of Al (1980/1982), and Logicdl Foundations of Al (1987, with Genesereth).</rawString>
</citation>
<citation valid="true">
<title>as the most frequently cited reference, with 23 citations in 51 courses described as &apos;only CL&apos;; the most frequently cited references in all 76 courses (including 25 described as &apos;courses with topics other than CL&apos;)-46 courses within North America and 30 outside North America—are: Winograd 30, King 10, Tennant 8, Schank and Riesbeck 7</title>
<date>1983</date>
<booktitle>In this survey of CL courses Winograd</booktitle>
<location>Cohen</location>
<marker>1983</marker>
<rawString>4. In this survey of CL courses Winograd (1983) as the most frequently cited reference, with 23 citations in 51 courses described as &apos;only CL&apos;; the most frequently cited references in all 76 courses (including 25 described as &apos;courses with topics other than CL&apos;)-46 courses within North America and 30 outside North America—are: Winograd 30, King 10, Tennant 8, Schank and Riesbeck 7 (Cohen 1986:4).</rawString>
</citation>
<citation valid="false">
<title>A quick sketch of the local context at our department: University entrance level in Europe is in general considered to be equivalent to American junior college graduation. Four years at a European univer-</title>
<marker></marker>
<rawString>5. A quick sketch of the local context at our department: University entrance level in Europe is in general considered to be equivalent to American junior college graduation. Four years at a European univer-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cohen</author>
</authors>
<title>Survey of Computational Linguistics Courses. Computational Linguistics. 12:course survey supplement.</title>
<date>1986</date>
<marker>Cohen, 1986</marker>
<rawString>Cohen, Robin (compiler). 1986 Survey of Computational Linguistics Courses. Computational Linguistics. 12:course survey supplement.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Alex Franz</author>
<author>Karen Osborne</author>
<author>Roger Evans</author>
</authors>
<title>Natural Language Processing in the 1980s: A Bibliography. Center for the Study of Language and Information,</title>
<date>1987</date>
<location>Stanford, CA.</location>
<marker>Gazdar, Franz, Osborne, Evans, 1987</marker>
<rawString>Gazdar, Gerald; Franz, Alex; Osborne, Karen; and Evans, Roger. 1987 Natural Language Processing in the 1980s: A Bibliography. Center for the Study of Language and Information, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Genesereth</author>
<author>Nils J Nilsson</author>
</authors>
<title>Logical Foundations of Artificial Intelligence.</title>
<date>1987</date>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, CA.</location>
<marker>Genesereth, Nilsson, 1987</marker>
<rawString>Genesereth, Michael R., and Nilsson, Nils J. 1987 Logical Foundations of Artificial Intelligence. Morgan Kaufmann, Los Altos, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils J Nilsson</author>
</authors>
<date>1971</date>
<booktitle>Problem-Solving Methods in Artificial Intelligence.</booktitle>
<publisher>McGraw-Hill,</publisher>
<location>New York, NY.</location>
<marker>Nilsson, 1971</marker>
<rawString>Nilsson, Nils J. 1971 Problem-Solving Methods in Artificial Intelligence. McGraw-Hill, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils J Nilsson</author>
</authors>
<title>Principles of Artificial Intelligence. Tioga,</title>
<date>1980</date>
<publisher>Springer,</publisher>
<location>Palo Alto, CA. Also:</location>
<marker>Nilsson, 1980</marker>
<rawString>Nilsson, Nils J. 1980 Principles of Artificial Intelligence. Tioga, Palo Alto, CA. Also: 1982 Springer, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Language as a Cognitive Process. Volume 1: Syntax.</title>
<date>1983</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<marker>Winograd, 1983</marker>
<rawString>Winograd, Terry. 1983 Language as a Cognitive Process. Volume 1: Syntax. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Amsterdam</author>
</authors>
<title>Kwee TjoeLiong (in the U.S.: TjoeLiong Kwee) is a mathematician and a lecturer at the Department of Computational Linguistics, University of Amsterdam, is teaching courses in programming and in computational linguistics, and is doing research on generation and on modeling and testing of linguistic theories. Kwee&apos;s address is:</title>
<volume>134</volume>
<institution>Department of Computational Linguistics, University of Amsterdam, Spuistraat</institution>
<marker>Amsterdam, </marker>
<rawString>Kwee TjoeLiong (in the U.S.: TjoeLiong Kwee) is a mathematician and a lecturer at the Department of Computational Linguistics, University of Amsterdam, is teaching courses in programming and in computational linguistics, and is doing research on generation and on modeling and testing of linguistic theories. Kwee&apos;s address is: Department of Computational Linguistics, University of Amsterdam, Spuistraat 134, 1012 VB Amsterdam. The Netherlands. E-mail: tl@alf.let.uva.n1</rawString>
</citation>
<citation valid="false">
<authors>
<author>MODE LISATION DU DIALOGUE</author>
</authors>
<journal>REPRESENTATION DE L&apos;INFERENCE ARGUMENTATIVE (MODELING DIALOGUE: REP RESENTATION OF INFERENTIAL ARGUMENTATION) Jacques Moeschler (Universite de Geneve)</journal>
<marker>DIALOGUE, </marker>
<rawString>MODE LISATION DU DIALOGUE: REPRESENTATION DE L&apos;INFERENCE ARGUMENTATIVE (MODELING DIALOGUE: REP RESENTATION OF INFERENTIAL ARGUMENTATION) Jacques Moeschler (Universite de Geneve)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paris Hermes</author>
</authors>
<date>1989</date>
<pages>266</pages>
<note>(Langue, raisonnement, calcul)</note>
<marker>Hermes, 1989</marker>
<rawString>Paris: Hermes, 1989, 266 p. (Langue, raisonnement, calcul)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hardbound</author>
</authors>
<tech>ISBN 2-86601-191-0, FF 200</tech>
<note>Reviewed by Klaus Schubert BSO/Research</note>
<marker>Hardbound, </marker>
<rawString>Hardbound, ISBN 2-86601-191-0, FF 200 Reviewed by Klaus Schubert BSO/Research</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>