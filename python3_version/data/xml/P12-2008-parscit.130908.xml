<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.127384">
<title confidence="0.978695">
Joint Learning of a Dual SMT System for Paraphrase Generation
</title>
<author confidence="0.999591">
Hong Sun* Ming Zhou
</author>
<affiliation confidence="0.9982585">
School of Computer Science and Technology Microsoft Research Asia
Tianjin University
</affiliation>
<email confidence="0.996384">
kaspersky@tju.edu.cn mingzhou@microsoft.com
</email>
<sectionHeader confidence="0.995583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999867318181818">
SMT has been used in paraphrase generation
by translating a source sentence into another
(pivot) language and then back into the source.
The resulting sentences can be used as candi-
date paraphrases of the source sentence. Exist-
ing work that uses two independently trained
SMT systems cannot directly optimize the
paraphrase results. Paraphrase criteria espe-
cially the paraphrase rate is not able to be en-
sured in that way. In this paper, we propose
a joint learning method of two SMT systems
to optimize the process of paraphrase genera-
tion. In addition, a revised BLEU score (called
iBLEU) which measures the adequacy and
diversity of the generated paraphrase sentence
is proposed for tuning parameters in SMT sys-
tems. Our experiments on NIST 2008 test-
ing data with automatic evaluation as well as
human judgments suggest that the proposed
method is able to enhance the paraphrase qual-
ity by adjusting between semantic equivalency
and surface dissimilarity.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999716142857143">
Paraphrasing (at word, phrase, and sentence levels)
is a procedure for generating alternative expressions
with an identical or similar meaning to the origi-
nal text. Paraphrasing technology has been applied
in many NLP applications, such as machine trans-
lation (MT), question answering (QA), and natural
language generation (NLG).
</bodyText>
<footnote confidence="0.9986645">
1This work has been done while the author was visiting Mi-
crosoft Research Asia.
</footnote>
<page confidence="0.995525">
38
</page>
<bodyText confidence="0.999969970588235">
As paraphrasing can be viewed as a transla-
tion process between the original expression (as in-
put) and the paraphrase results (as output), both
in the same language, statistical machine transla-
tion (SMT) has been used for this task. Quirk et al.
(2004) build a monolingual translation system us-
ing a corpus of sentence pairs extracted from news
articles describing same events. Zhao et al. (2008a)
enrich this approach by adding multiple resources
(e.g., thesaurus) and further extend the method by
generating different paraphrase in different applica-
tions (Zhao et al., 2009). Performance of the mono-
lingual MT-based method in paraphrase generation
is limited by the large-scale paraphrase corpus it re-
lies on as the corpus is not readily available (Zhao et
al., 2010).
In contrast, bilingual parallel data is in abundance
and has been used in extracting paraphrase (Ban-
nard and Callison-Burch, 2005; Zhao et al., 2008b;
Callison-Burch, 2008; Kok and Brockett, 2010;
Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus
researchers leverage bilingual parallel data for this
task and apply two SMT systems (dual SMT system)
to translate the original sentences into another pivot
language and then translate them back into the orig-
inal language. For question expansion, Dubou´e and
Chu-Carroll (2006) paraphrase the questions with
multiple MT engines and select the best paraphrase
result considering cosine distance, length, etc. Max
(2009) generates paraphrase for a given segment by
forcing the segment being translated independently
in both of the translation processes. Context features
are added into the SMT system to improve trans-
lation correctness against polysemous. To reduce
</bodyText>
<note confidence="0.47">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 38–42,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998985">
the noise introduced by machine translation, Zhao et
al. (2010) propose combining the results of multiple
machine translation engines’ by performing MBR
(Minimum Bayes Risk) (Kumar and Byrne, 2004)
decoding on the N-best translation candidates.
The work presented in this paper belongs to
the pivot language method for paraphrase genera-
tion. Previous work employs two separately trained
SMT systems the parameters of which are tuned
for SMT scheme and therefore cannot directly op-
timize the paraphrase purposes, for example, opti-
mize the diversity against the input. Another prob-
lem comes from the contradiction between two cri-
teria in paraphrase generation: adequacy measuring
the semantic equivalency and paraphrase rate mea-
suring the surface dissimilarity. As they are incom-
patible (Zhao and Wang, 2010), the question arises
how to adapt between them to fit different applica-
tion scenarios. To address these issues, in this paper,
we propose a joint learning method of two SMT sys-
tems for paraphrase generation. The jointly-learned
dual SMT system: (1) Adapts the SMT systems so
that they are tuned specifically for paraphrase gener-
ation purposes, e.g., to increase the dissimilarity; (2)
Employs a revised BLEU score (named iBLEU, as
it’s an input-aware BLEU metric) that measures ad-
equacy and dissimilarity of the paraphrase results at
the same time. We test our method on NIST 2008
testing data. With both automatic and human eval-
uations, the results show that the proposed method
effectively balance between adequacy and dissimi-
larity.
</bodyText>
<subsectionHeader confidence="0.550165">
2 Paraphrasing with a Dual SMT System
</subsectionHeader>
<bodyText confidence="0.9999895">
We focus on sentence level paraphrasing and lever-
age homogeneous machine translation systems for
this task bi-directionally. Generating sentential para-
phrase with the SMT system is done by first trans-
lating a source sentence into another pivot language,
and then back into the source. Here, we call these
two procedures a dual SMT system. Given an En-
glish sentence es, there could be n candidate trans-
lations in another language F, each translation could
have m candidates {e�} which may contain potential
paraphrases for es. Our task is to locate the candi-
date that best fit in the demands of paraphrasing.
</bodyText>
<subsectionHeader confidence="0.986393">
2.1 Joint Inference of Dual SMT System
</subsectionHeader>
<bodyText confidence="0.999977555555556">
During the translation process, it is needed to select
a translation from the hypothesis based on the qual-
ity of the candidates. Each candidate’s quality can
be expressed by log-linear model considering dif-
ferent SMT features such as translation model and
language model.
When generating the paraphrase results for each
source sentence es, the selection of the best para-
phrase candidate e0∗ from e0 ∈ C is performed by:
</bodyText>
<equation confidence="0.9963615">
e0∗(es, {f}, AM) =
M
arg maxe,∈C,fE{f} E Amhm(e0|f)t(e0,f)(1)
m=1
</equation>
<bodyText confidence="0.9894764">
where {f} is the set of sentences in pivot language
translated from es, hm is the mth feature value and
Am is the corresponding weight. t is an indicator
function equals to 1 when e0 is translated from f and
0 otherwise.
The parameter weight vector A is trained by
MERT (Minimum Error Rate Training) (Och, 2003).
MERT integrates the automatic evaluation metrics
into the training process to achieve optimal end-to-
end performance. In the joint inference method, the
feature vector of each e0 comes from two parts: vec-
tor of translating es to {f} and vector of translating
{f} to e0, the two vectors are jointly learned at the
same time:
G(rs, e0∗(es, {f}, A1, A2))
(2)
where G is the automatic evaluation metric for para-
phrasing. S is the development set for training the
parameters and for each source sentence several hu-
man translations rs are listed as references.
</bodyText>
<subsectionHeader confidence="0.999605">
2.2 Paraphrase Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999727625">
The joint inference method with MERT enables the
dual SMT system to be optimized towards the qual-
ity of paraphrasing results. Different application
scenarios of paraphrase have different demands on
the paraphrasing results and up to now, the widely
mentioned criteria include (Zhao et al., 2009; Zhao
et al., 2010; Liu et al., 2010; Chen and Dolan, 2011;
Metzler et al., 2011): Semantic adequacy, fluency
</bodyText>
<equation confidence="0.8176072">
(A∗1, A∗2) = arg max
(a1,a2)
S
E
s=1
</equation>
<page confidence="0.989549">
39
</page>
<bodyText confidence="0.999884545454546">
and dissimilarity. However, as pointed out by (Chen
and Dolan, 2011), there is the lack of automatic met-
ric that is capable to measure all the three criteria in
paraphrase generation. Two issues are also raised
in (Zhao and Wang, 2010) about using automatic
metrics: paraphrase changes less gets larger BLEU
score and the evaluations of paraphrase quality and
rate tend to be incompatible.
To address the above problems, we propose a met-
ric for tuning parameters and evaluating the quality
of each candidate paraphrase c :
</bodyText>
<equation confidence="0.999573">
iBLEU(s, rs, c) = αBLEU(c, rs)
− (1 − α)BLEU(c, s) (3)
</equation>
<bodyText confidence="0.999954125">
where s is the input sentence, rs represents the ref-
erence paraphrases. BLEU(c,rs) captures the se-
mantic equivalency between the candidates and the
references (Finch et al. (2005) have shown the ca-
pability for measuring semantic equivalency using
BLEU score); BLEU(c, s) is the BLEU score com-
puted between the candidate and the source sen-
tence to measure the dissimilarity. α is a parameter
taking balance between adequacy and dissimilarity,
smaller α value indicates larger punishment on self-
paraphrase. Fluency is not explicitly presented be-
cause there is high correlation between fluency and
adequacy (Zhao et al., 2010) and SMT has already
taken this into consideration. By using iBLEU, we
aim at adapting paraphrasing performance to differ-
ent application needs by adjusting α value.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="introduction">
3 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.990885">
3.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999065642857143">
For English sentence paraphrasing task, we utilize
Chinese as the pivot language, our experiments are
built on English and Chinese bi-directional transla-
tion. We use 2003 NIST Open Machine Transla-
tion Evaluation data (NIST 2003) as development
data (containing 919 sentences) for MERT and test
the performance on NIST 2008 data set (containing
1357 sentences). NIST Chinese-to-English evalua-
tion data offers four English human translations for
every Chinese sentence. For each sentence pair, we
choose one English sentence e1 as source and use
the three left sentences e2, e3 and e4 as references.
The English-Chinese and Chinese-English sys-
tems are built on bilingual parallel corpus contain-
</bodyText>
<table confidence="0.999639666666667">
Joint learning BLEU BLEU Self-iBLEU
No Joint 27.16 35.42 /
α = 1 30.75 53.51 30.75
α = 0.9 28.28 48.08 20.64
α = 0.8 27.39 35.64 14.78
α = 0.7 23.27 26.30 8.39
</table>
<tableCaption confidence="0.97567">
Table 1: iBLEU Score Results(NIST 2008)
</tableCaption>
<table confidence="0.999381142857143">
Adequacy Fluency Variety Overall
(0/1/2) (0/1/2) (0/1/2) (0/1/2)
No Joint 30/82/88 22/83/95 25/117/58 23/127/50
α = 1 33/53/114 15/80/105 62/127/11 16/128/56
α = 0.9 31/77/92 16/93/91 23/157/20 20/119/61
α = 0.8 31/78/91 19/91/90 20/123/57 19/121/60
α = 0.7 35/105/60 32/101/67 9/108/83 35/107/58
</table>
<tableCaption confidence="0.999209">
Table 2: Human Evaluation Label Distribution
</tableCaption>
<bodyText confidence="0.9995852">
ing 497,862 sentences. Language model is trained
on 2,007,955 sentences for Chinese and 8,681,899
sentences for English. We adopt a phrase based MT
system of Chiang (2007). 10-best lists are used in
both of the translation processes.
</bodyText>
<subsectionHeader confidence="0.999199">
3.2 Paraphrase Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999982833333333">
The results of paraphrasing are illustrated in Table 1.
We show the BLEU score (computed against ref-
erences) to measure the adequacy and self-BLEU
(computed against source sentence) to evaluate the
dissimilarity (lower is better). By “No Joint”, it
means two independently trained SMT systems are
employed in translating sentences from English to
Chinese and then back into English. This result is
listed to indicate the performance when we do not
involve joint learning to control the quality of para-
phrase results. For joint learning, results of α from
0.7 to 1 are listed.
From the results we can see that, when the value
of α decreases to address more penalty on self-
paraphrase, the self-BLEU score rapidly decays
while the consequence effect is that BLEU score
computed against references also drops seriously.
When α drops under 0.6 we observe the sentences
become completely incomprehensible (this is the
reason why we leave out showing the results of α un-
der 0.7). The best balance is achieved when α is be-
tween 0.7 and 0.9, where both of the sentence qual-
ity and variety are relatively preserved. As α value is
manually defined and not specially tuned, the exper-
</bodyText>
<page confidence="0.994452">
40
</page>
<table confidence="0.99956325">
Source Torrential rains hit western india ,
43 people dead
No Joint Rainstorms in western india ,
Joint(α = 1) 43 deaths
Joint(α = 0.9) Rainstorms hit western india ,
Joint(α = 0.8) 43 people dead
Joint(α = 0.7) Rainstorms hit western india
43 people dead
Heavy rain in western india ,
43 dead
Heavy rain in western india ,
43 killed
</table>
<tableCaption confidence="0.999929">
Table 3: Example of the Paraphrase Results
</tableCaption>
<bodyText confidence="0.999986871794872">
iments only achieve comparable results with no joint
learning when α equals 0.8. However, the results
show that our method is able to effectively control
the self-paraphrase rate and lower down the score of
self-BLEU, this is done by both of the process of
joint learning and introducing the metric of iBLEU
to avoid trivial self-paraphrase. It is not capable with
no joint learning or with the traditional BLEU score
does not take self-paraphrase into consideration.
Human evaluation results are shown in Table 2.
We randomly choose 100 sentences from testing
data. For each setting, two annotators are asked to
give scores about semantic adequacy, fluency, vari-
ety and overall quality. The scales are 0 (meaning
changed; incomprehensible; almost same; cannot be
used), 1 (almost same meaning; little flaws; con-
taining different words; may be useful) and 2 (same
meaning; good sentence; different sentential form;
could be used). The agreements between the anno-
tators on these scores are 0.87, 0.74, 0.79 and 0.69
respectively. From the results we can see that human
evaluations are quite consistent with the automatic
evaluation, where higher BLEU scores correspond
to larger number of good adequacy and fluency la-
bels, and higher self-BLEU results tend to get lower
human evaluations over dissimilarity.
In our observation, we found that adequacy and
fluency are relatively easy to be kept especially for
short sentences. In contrast, dissimilarity is not easy
to achieve. This is because the translation tables
are used bi-directionally so lots of source sentences’
fragments present in the paraphrasing results.
We show an example of the paraphrase results
under different settings. All the results’ sentential
forms are not changed comparing with the input sen-
tence and also well-formed. This is due to the short
length of the source sentence. Also, with smaller
value of α, more variations show up in the para-
phrase results.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="method">
4 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999973">
4.1 SMT Systems and Pivot Languages
</subsectionHeader>
<bodyText confidence="0.9999924">
We have test our method by using homogeneous
SMT systems and a single pivot language. As the
method highly depends on machine translation, a
natural question arises to what is the impact when
using different pivots or SMT systems. The joint
learning method works by combining both of the
processes to concentrate on the final objective so it
is not affected by the selection of language or SMT
model.
In addition, our method is not limited to a ho-
mogeneous SMT model or a single pivot language.
As long as the models’ translation candidates can
be scored with a log-linear model, the joint learning
process can tune the parameters at the same time.
When dealing with multiple pivot languages or het-
erogeneous SMT systems, our method will take ef-
fect by optimizing parameters from both the forward
and backward translation processes, together with
the final combination feature vector, to get optimal
paraphrase results.
</bodyText>
<subsectionHeader confidence="0.99666">
4.2 Effect of iBLEU
</subsectionHeader>
<bodyText confidence="0.999988941176471">
iBLEU plays a key role in our method. The first
part of iBLEU, which is the traditional BLEU
score, helps to ensure the quality of the machine
translation results. Further, it also helps to keep
the semantic equivalency. These two roles unify the
goals of optimizing translation and paraphrase ade-
quacy in the training process.
Another contribution from iBLEU is its ability
to balance between adequacy and dissimilarity as the
two aspects in paraphrasing are incompatible (Zhao
and Wang, 2010). This is not difficult to explain be-
cause when we change many words, the meaning
and the sentence quality are hard to preserve. As
the paraphrasing task is not self-contained and will
be employed by different applications, the two mea-
sures should be given different priorities based on
the application scenario. For example, for a query
</bodyText>
<page confidence="0.998032">
41
</page>
<bodyText confidence="0.999812875">
expansion task in QA that requires higher recall, va-
riety should be considered first. Lower α value is
preferred but should be kept in a certain range as sig-
nificant change may lead to the loss of constraints
presented in the original sentence. The advantage
of the proposed method is reflected in its ability to
adapt to different application requirements by ad-
justing the value of α in a reasonable range.
</bodyText>
<sectionHeader confidence="0.998865" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999773818181818">
We propose a joint learning method for pivot
language-based paraphrase generation. The jointly
learned dual SMT system which combines the train-
ing processes of two SMT systems in paraphrase
generation, enables optimization of the final para-
phrase quality. Furthermore, a revised BLEU score
that balances between paraphrase adequacy and dis-
similarity is proposed in our training process. In the
future, we plan to go a step further to see whether
we can enhance dissimilarity with penalizing phrase
tables used in both of the translation processes.
</bodyText>
<sectionHeader confidence="0.997843" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999017076923077">
Colin J. Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In ACL.
Chris Callison-Burch. 2008. Syntactic constraints
on paraphrases extracted from parallel corpora. In
EMNLP, pages 196–205.
David Chen and William B. Dolan. 2011. Collecting
highly parallel data for paraphrase evaluation. In ACL,
pages 190–200.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
Pablo Ariel Dubou´e and Jennifer Chu-Carroll. 2006. An-
swering the question you wish they had asked: The im-
pact of paraphrasing for question answering. In HLT-
NAACL.
Andrew Finch, Young-Sook Hwang, and Eiichiro
Sumita. 2005. Using machine translation evalua-
tion techniques to determine sentence-level semantic
equivalence. In In IWP2005.
Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learning
sentential paraphrases from bilingual parallel corpora
for text-to-text generation. In EMNLP, pages 1168–
1179.
Stanley Kok and Chris Brockett. 2010. Hitting the right
paraphrases in good time. In HLT-NAACL, pages 145–
153.
Roland Kuhn, Boxing Chen, George F. Foster, and Evan
Stratford. 2010. Phrase clustering for smoothing
tm probabilities - or, how to extract paraphrases from
phrase tables. In COLING, pages 608–616.
Shankar Kumar and William J. Byrne. 2004. Minimum
bayes-risk decoding for statistical machine translation.
In HLT-NAACL, pages 169–176.
Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng. 2010.
Pem: A paraphrase evaluation metric exploiting paral-
lel texts. In EMNLP, pages 923–932.
Aurelien Max. 2009. Sub-sentential paraphrasing by
contextual pivot translation. In Proceedings of the
2009 Workshop on Applied Textual Inference, ACLI-
JCNLP, pages 18–26.
Donald Metzler, Eduard H. Hovy, and Chunliang Zhang.
2011. An empirical evaluation of data-driven para-
phrase generation techniques. In ACL (Short Papers),
pages 546–551.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In ACL, pages 160–
167.
Chris Quirk, Chris Brockett, and William B. Dolan.
2004. Monolingual machine translation for paraphrase
generation. In EMNLP, pages 142–149.
Shiqi Zhao and Haifeng Wang. 2010. Paraphrases and
applications. In COLING (Tutorials), pages 1–87.
Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and Sheng
Li. 2008a. Combining multiple resources to improve
smt-based paraphrasing model. In ACL, pages 1021–
1029.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008b. Pivot approach for extracting paraphrase pat-
terns from bilingual corpora. In ACL, pages 780–788.
Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009.
Application-driven statistical paraphrase generation.
In ACL/AFNLP, pages 834–842.
Shiqi Zhao, Haifeng Wang, Xiang Lan, and Ting Liu.
2010. Leveraging multiple mt engines for paraphrase
generation. In COLING, pages 1326–1334.
</reference>
<page confidence="0.999297">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.961556">
<title confidence="0.999283">Joint Learning of a Dual SMT System for Paraphrase Generation</title>
<author confidence="0.997026">Zhou</author>
<affiliation confidence="0.99988">School of Computer Science and Technology Microsoft Research Tianjin University</affiliation>
<email confidence="0.980893">kaspersky@tju.edu.cnmingzhou@microsoft.com</email>
<abstract confidence="0.999282956521739">SMT has been used in paraphrase generation by translating a source sentence into another (pivot) language and then back into the source. The resulting sentences can be used as candidate paraphrases of the source sentence. Existing work that uses two independently trained SMT systems cannot directly optimize the paraphrase results. Paraphrase criteria especially the paraphrase rate is not able to be ensured in that way. In this paper, we propose a joint learning method of two SMT systems to optimize the process of paraphrase generation. In addition, a revised BLEU score (called which measures the adequacy and diversity of the generated paraphrase sentence is proposed for tuning parameters in SMT systems. Our experiments on NIST 2008 testing data with automatic evaluation as well as human judgments suggest that the proposed method is able to enhance the paraphrase quality by adjusting between semantic equivalency and surface dissimilarity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin J Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2506" citStr="Bannard and Callison-Burch, 2005" startWordPosition="387" endWordPosition="391">gual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best paraphrase result considering cosine distance, length, etc. Max (2009) generates paraphrase for a given segment by forcing the segm</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin J. Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In EMNLP,</booktitle>
<pages>196--205</pages>
<contexts>
<context position="2548" citStr="Callison-Burch, 2008" startWordPosition="396" endWordPosition="397">rs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best paraphrase result considering cosine distance, length, etc. Max (2009) generates paraphrase for a given segment by forcing the segment being translated independently in both</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In EMNLP, pages 196–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chen</author>
<author>William B Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>190--200</pages>
<contexts>
<context position="7451" citStr="Chen and Dolan, 2011" startWordPosition="1179" endWordPosition="1182">: G(rs, e0∗(es, {f}, A1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint inference method with MERT enables the dual SMT system to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and evaluating the quality of each candidate </context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David Chen and William B. Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In ACL, pages 190–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="10361" citStr="Chiang (2007)" startWordPosition="1649" endWordPosition="1650">08 20.64 α = 0.8 27.39 35.64 14.78 α = 0.7 23.27 26.30 8.39 Table 1: iBLEU Score Results(NIST 2008) Adequacy Fluency Variety Overall (0/1/2) (0/1/2) (0/1/2) (0/1/2) No Joint 30/82/88 22/83/95 25/117/58 23/127/50 α = 1 33/53/114 15/80/105 62/127/11 16/128/56 α = 0.9 31/77/92 16/93/91 23/157/20 20/119/61 α = 0.8 31/78/91 19/91/90 20/123/57 19/121/60 α = 0.7 35/105/60 32/101/67 9/108/83 35/107/58 Table 2: Human Evaluation Label Distribution ing 497,862 sentences. Language model is trained on 2,007,955 sentences for Chinese and 8,681,899 sentences for English. We adopt a phrase based MT system of Chiang (2007). 10-best lists are used in both of the translation processes. 3.2 Paraphrase Evaluation Results The results of paraphrasing are illustrated in Table 1. We show the BLEU score (computed against references) to measure the adequacy and self-BLEU (computed against source sentence) to evaluate the dissimilarity (lower is better). By “No Joint”, it means two independently trained SMT systems are employed in translating sentences from English to Chinese and then back into English. This result is listed to indicate the performance when we do not involve joint learning to control the quality of paraph</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Ariel Dubou´e</author>
<author>Jennifer Chu-Carroll</author>
</authors>
<title>Answering the question you wish they had asked: The impact of paraphrasing for question answering.</title>
<date>2006</date>
<booktitle>In HLTNAACL.</booktitle>
<marker>Dubou´e, Chu-Carroll, 2006</marker>
<rawString>Pablo Ariel Dubou´e and Jennifer Chu-Carroll. 2006. Answering the question you wish they had asked: The impact of paraphrasing for question answering. In HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Young-Sook Hwang</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Using machine translation evaluation techniques to determine sentence-level semantic equivalence. In</title>
<date>2005</date>
<booktitle>In IWP2005.</booktitle>
<contexts>
<context position="8300" citStr="Finch et al. (2005)" startWordPosition="1323" endWordPosition="1326"> the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and evaluating the quality of each candidate paraphrase c : iBLEU(s, rs, c) = αBLEU(c, rs) − (1 − α)BLEU(c, s) (3) where s is the input sentence, rs represents the reference paraphrases. BLEU(c,rs) captures the semantic equivalency between the candidates and the references (Finch et al. (2005) have shown the capability for measuring semantic equivalency using BLEU score); BLEU(c, s) is the BLEU score computed between the candidate and the source sentence to measure the dissimilarity. α is a parameter taking balance between adequacy and dissimilarity, smaller α value indicates larger punishment on selfparaphrase. Fluency is not explicitly presented because there is high correlation between fluency and adequacy (Zhao et al., 2010) and SMT has already taken this into consideration. By using iBLEU, we aim at adapting paraphrasing performance to different application needs by adjusting </context>
</contexts>
<marker>Finch, Hwang, Sumita, 2005</marker>
<rawString>Andrew Finch, Young-Sook Hwang, and Eiichiro Sumita. 2005. Using machine translation evaluation techniques to determine sentence-level semantic equivalence. In In IWP2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Chris Callison-Burch</author>
<author>Courtney Napoles</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation. In</title>
<date>2011</date>
<booktitle>EMNLP,</booktitle>
<pages>1168--1179</pages>
<marker>Ganitkevitch, Callison-Burch, Napoles, Van Durme, 2011</marker>
<rawString>Juri Ganitkevitch, Chris Callison-Burch, Courtney Napoles, and Benjamin Van Durme. 2011. Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation. In EMNLP, pages 1168– 1179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Chris Brockett</author>
</authors>
<title>Hitting the right paraphrases in good time.</title>
<date>2010</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>145--153</pages>
<contexts>
<context position="2572" citStr="Kok and Brockett, 2010" startWordPosition="398" endWordPosition="401"> articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best paraphrase result considering cosine distance, length, etc. Max (2009) generates paraphrase for a given segment by forcing the segment being translated independently in both of the translation proc</context>
</contexts>
<marker>Kok, Brockett, 2010</marker>
<rawString>Stanley Kok and Chris Brockett. 2010. Hitting the right paraphrases in good time. In HLT-NAACL, pages 145– 153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Kuhn</author>
<author>Boxing Chen</author>
<author>George F Foster</author>
<author>Evan Stratford</author>
</authors>
<title>Phrase clustering for smoothing tm probabilities - or, how to extract paraphrases from phrase tables.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>608--616</pages>
<contexts>
<context position="2591" citStr="Kuhn et al., 2010" startWordPosition="402" endWordPosition="405">e events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best paraphrase result considering cosine distance, length, etc. Max (2009) generates paraphrase for a given segment by forcing the segment being translated independently in both of the translation processes. Context feat</context>
</contexts>
<marker>Kuhn, Chen, Foster, Stratford, 2010</marker>
<rawString>Roland Kuhn, Boxing Chen, George F. Foster, and Evan Stratford. 2010. Phrase clustering for smoothing tm probabilities - or, how to extract paraphrases from phrase tables. In COLING, pages 608–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William J Byrne</author>
</authors>
<title>Minimum bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>169--176</pages>
<contexts>
<context position="3680" citStr="Kumar and Byrne, 2004" startWordPosition="560" endWordPosition="563">raphrase for a given segment by forcing the segment being translated independently in both of the translation processes. Context features are added into the SMT system to improve translation correctness against polysemous. To reduce Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 38–42, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics the noise introduced by machine translation, Zhao et al. (2010) propose combining the results of multiple machine translation engines’ by performing MBR (Minimum Bayes Risk) (Kumar and Byrne, 2004) decoding on the N-best translation candidates. The work presented in this paper belongs to the pivot language method for paraphrase generation. Previous work employs two separately trained SMT systems the parameters of which are tuned for SMT scheme and therefore cannot directly optimize the paraphrase purposes, for example, optimize the diversity against the input. Another problem comes from the contradiction between two criteria in paraphrase generation: adequacy measuring the semantic equivalency and paraphrase rate measuring the surface dissimilarity. As they are incompatible (Zhao and Wa</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William J. Byrne. 2004. Minimum bayes-risk decoding for statistical machine translation. In HLT-NAACL, pages 169–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang Liu</author>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Pem: A paraphrase evaluation metric exploiting parallel texts.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>923--932</pages>
<contexts>
<context position="7429" citStr="Liu et al., 2010" startWordPosition="1175" endWordPosition="1178">d at the same time: G(rs, e0∗(es, {f}, A1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint inference method with MERT enables the dual SMT system to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and evaluating the qual</context>
</contexts>
<marker>Liu, Dahlmeier, Ng, 2010</marker>
<rawString>Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng. 2010. Pem: A paraphrase evaluation metric exploiting parallel texts. In EMNLP, pages 923–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurelien Max</author>
</authors>
<title>Sub-sentential paraphrasing by contextual pivot translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Applied Textual Inference, ACLIJCNLP,</booktitle>
<pages>18--26</pages>
<contexts>
<context position="3045" citStr="Max (2009)" startWordPosition="471" endWordPosition="472">as been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best paraphrase result considering cosine distance, length, etc. Max (2009) generates paraphrase for a given segment by forcing the segment being translated independently in both of the translation processes. Context features are added into the SMT system to improve translation correctness against polysemous. To reduce Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 38–42, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics the noise introduced by machine translation, Zhao et al. (2010) propose combining the results of multiple machine translation engines’ by performing MBR (Minimum </context>
</contexts>
<marker>Max, 2009</marker>
<rawString>Aurelien Max. 2009. Sub-sentential paraphrasing by contextual pivot translation. In Proceedings of the 2009 Workshop on Applied Textual Inference, ACLIJCNLP, pages 18–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>Eduard H Hovy</author>
<author>Chunliang Zhang</author>
</authors>
<title>An empirical evaluation of data-driven paraphrase generation techniques.</title>
<date>2011</date>
<booktitle>In ACL (Short Papers),</booktitle>
<pages>546--551</pages>
<contexts>
<context position="7474" citStr="Metzler et al., 2011" startWordPosition="1183" endWordPosition="1186">1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint inference method with MERT enables the dual SMT system to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and evaluating the quality of each candidate paraphrase c : iBLEU(s,</context>
</contexts>
<marker>Metzler, Hovy, Zhang, 2011</marker>
<rawString>Donald Metzler, Eduard H. Hovy, and Chunliang Zhang. 2011. An empirical evaluation of data-driven paraphrase generation techniques. In ACL (Short Papers), pages 546–551.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="6508" citStr="Och, 2003" startWordPosition="1025" endWordPosition="1026">del considering different SMT features such as translation model and language model. When generating the paraphrase results for each source sentence es, the selection of the best paraphrase candidate e0∗ from e0 ∈ C is performed by: e0∗(es, {f}, AM) = M arg maxe,∈C,fE{f} E Amhm(e0|f)t(e0,f)(1) m=1 where {f} is the set of sentences in pivot language translated from es, hm is the mth feature value and Am is the corresponding weight. t is an indicator function equals to 1 when e0 is translated from f and 0 otherwise. The parameter weight vector A is trained by MERT (Minimum Error Rate Training) (Och, 2003). MERT integrates the automatic evaluation metrics into the training process to achieve optimal end-toend performance. In the joint inference method, the feature vector of each e0 comes from two parts: vector of translating es to {f} and vector of translating {f} to e0, the two vectors are jointly learned at the same time: G(rs, e0∗(es, {f}, A1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL, pages 160– 167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
<author>William B Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation. In</title>
<date>2004</date>
<booktitle>EMNLP,</booktitle>
<pages>142--149</pages>
<contexts>
<context position="1858" citStr="Quirk et al. (2004)" startWordPosition="287" endWordPosition="290">evels) is a procedure for generating alternative expressions with an identical or similar meaning to the original text. Paraphrasing technology has been applied in many NLP applications, such as machine translation (MT), question answering (QA), and natural language generation (NLG). 1This work has been done while the author was visiting Microsoft Research Asia. 38 As paraphrasing can be viewed as a translation process between the original expression (as input) and the paraphrase results (as output), both in the same language, statistical machine translation (SMT) has been used for this task. Quirk et al. (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extract</context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>Chris Quirk, Chris Brockett, and William B. Dolan. 2004. Monolingual machine translation for paraphrase generation. In EMNLP, pages 142–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
</authors>
<title>Paraphrases and applications.</title>
<date>2010</date>
<booktitle>In COLING (Tutorials),</booktitle>
<pages>1--87</pages>
<contexts>
<context position="4289" citStr="Zhao and Wang, 2010" startWordPosition="653" endWordPosition="656">yrne, 2004) decoding on the N-best translation candidates. The work presented in this paper belongs to the pivot language method for paraphrase generation. Previous work employs two separately trained SMT systems the parameters of which are tuned for SMT scheme and therefore cannot directly optimize the paraphrase purposes, for example, optimize the diversity against the input. Another problem comes from the contradiction between two criteria in paraphrase generation: adequacy measuring the semantic equivalency and paraphrase rate measuring the surface dissimilarity. As they are incompatible (Zhao and Wang, 2010), the question arises how to adapt between them to fit different application scenarios. To address these issues, in this paper, we propose a joint learning method of two SMT systems for paraphrase generation. The jointly-learned dual SMT system: (1) Adapts the SMT systems so that they are tuned specifically for paraphrase generation purposes, e.g., to increase the dissimilarity; (2) Employs a revised BLEU score (named iBLEU, as it’s an input-aware BLEU metric) that measures adequacy and dissimilarity of the paraphrase results at the same time. We test our method on NIST 2008 testing data. With</context>
<context position="7778" citStr="Zhao and Wang, 2010" startWordPosition="1237" endWordPosition="1240">stem to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and evaluating the quality of each candidate paraphrase c : iBLEU(s, rs, c) = αBLEU(c, rs) − (1 − α)BLEU(c, s) (3) where s is the input sentence, rs represents the reference paraphrases. BLEU(c,rs) captures the semantic equivalency between the candidates and the references (Finch et al. (2005) have shown the capability for measuring semantic equivalency using BLEU score</context>
<context position="15424" citStr="Zhao and Wang, 2010" startWordPosition="2482" endWordPosition="2485">slation processes, together with the final combination feature vector, to get optimal paraphrase results. 4.2 Effect of iBLEU iBLEU plays a key role in our method. The first part of iBLEU, which is the traditional BLEU score, helps to ensure the quality of the machine translation results. Further, it also helps to keep the semantic equivalency. These two roles unify the goals of optimizing translation and paraphrase adequacy in the training process. Another contribution from iBLEU is its ability to balance between adequacy and dissimilarity as the two aspects in paraphrasing are incompatible (Zhao and Wang, 2010). This is not difficult to explain because when we change many words, the meaning and the sentence quality are hard to preserve. As the paraphrasing task is not self-contained and will be employed by different applications, the two measures should be given different priorities based on the application scenario. For example, for a query 41 expansion task in QA that requires higher recall, variety should be considered first. Lower α value is preferred but should be kept in a certain range as significant change may lead to the loss of constraints presented in the original sentence. The advantage </context>
</contexts>
<marker>Zhao, Wang, 2010</marker>
<rawString>Shiqi Zhao and Haifeng Wang. 2010. Paraphrases and applications. In COLING (Tutorials), pages 1–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Cheng Niu</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Combining multiple resources to improve smt-based paraphrasing model.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>1021--1029</pages>
<contexts>
<context position="2001" citStr="Zhao et al. (2008" startWordPosition="310" endWordPosition="313">as been applied in many NLP applications, such as machine translation (MT), question answering (QA), and natural language generation (NLG). 1This work has been done while the author was visiting Microsoft Research Asia. 38 As paraphrasing can be viewed as a translation process between the original expression (as input) and the paraphrase results (as output), both in the same language, statistical machine translation (SMT) has been used for this task. Quirk et al. (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkev</context>
</contexts>
<marker>Zhao, Niu, Zhou, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Cheng Niu, Ming Zhou, Ting Liu, and Sheng Li. 2008a. Combining multiple resources to improve smt-based paraphrasing model. In ACL, pages 1021– 1029.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot approach for extracting paraphrase patterns from bilingual corpora.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>780--788</pages>
<contexts>
<context position="2001" citStr="Zhao et al. (2008" startWordPosition="310" endWordPosition="313">as been applied in many NLP applications, such as machine translation (MT), question answering (QA), and natural language generation (NLG). 1This work has been done while the author was visiting Microsoft Research Asia. 38 As paraphrasing can be viewed as a translation process between the original expression (as input) and the paraphrase results (as output), both in the same language, statistical machine translation (SMT) has been used for this task. Quirk et al. (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkev</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008b. Pivot approach for extracting paraphrase patterns from bilingual corpora. In ACL, pages 780–788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Application-driven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In ACL/AFNLP,</booktitle>
<pages>834--842</pages>
<contexts>
<context position="2182" citStr="Zhao et al., 2009" startWordPosition="336" endWordPosition="339">r was visiting Microsoft Research Asia. 38 As paraphrasing can be viewed as a translation process between the original expression (as input) and the paraphrase results (as output), both in the same language, statistical machine translation (SMT) has been used for this task. Quirk et al. (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivo</context>
<context position="7392" citStr="Zhao et al., 2009" startWordPosition="1167" endWordPosition="1170">e0, the two vectors are jointly learned at the same time: G(rs, e0∗(es, {f}, A1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint inference method with MERT enables the dual SMT system to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuni</context>
</contexts>
<marker>Zhao, Lan, Liu, Li, 2009</marker>
<rawString>Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven statistical paraphrase generation. In ACL/AFNLP, pages 834–842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
</authors>
<title>Leveraging multiple mt engines for paraphrase generation. In</title>
<date>2010</date>
<booktitle>COLING,</booktitle>
<pages>1326--1334</pages>
<contexts>
<context position="2375" citStr="Zhao et al., 2010" startWordPosition="368" endWordPosition="371">same language, statistical machine translation (SMT) has been used for this task. Quirk et al. (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events. Zhao et al. (2008a) enrich this approach by adding multiple resources (e.g., thesaurus) and further extend the method by generating different paraphrase in different applications (Zhao et al., 2009). Performance of the monolingual MT-based method in paraphrase generation is limited by the large-scale paraphrase corpus it relies on as the corpus is not readily available (Zhao et al., 2010). In contrast, bilingual parallel data is in abundance and has been used in extracting paraphrase (Bannard and Callison-Burch, 2005; Zhao et al., 2008b; Callison-Burch, 2008; Kok and Brockett, 2010; Kuhn et al., 2010; Ganitkevitch et al., 2011). Thus researchers leverage bilingual parallel data for this task and apply two SMT systems (dual SMT system) to translate the original sentences into another pivot language and then translate them back into the original language. For question expansion, Dubou´e and Chu-Carroll (2006) paraphrase the questions with multiple MT engines and select the best </context>
<context position="7411" citStr="Zhao et al., 2010" startWordPosition="1171" endWordPosition="1174"> are jointly learned at the same time: G(rs, e0∗(es, {f}, A1, A2)) (2) where G is the automatic evaluation metric for paraphrasing. S is the development set for training the parameters and for each source sentence several human translations rs are listed as references. 2.2 Paraphrase Evaluation Metrics The joint inference method with MERT enables the dual SMT system to be optimized towards the quality of paraphrasing results. Different application scenarios of paraphrase have different demands on the paraphrasing results and up to now, the widely mentioned criteria include (Zhao et al., 2009; Zhao et al., 2010; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011): Semantic adequacy, fluency (A∗1, A∗2) = arg max (a1,a2) S E s=1 39 and dissimilarity. However, as pointed out by (Chen and Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation. Two issues are also raised in (Zhao and Wang, 2010) about using automatic metrics: paraphrase changes less gets larger BLEU score and the evaluations of paraphrase quality and rate tend to be incompatible. To address the above problems, we propose a metric for tuning parameters and e</context>
<context position="8744" citStr="Zhao et al., 2010" startWordPosition="1393" endWordPosition="1396"> s is the input sentence, rs represents the reference paraphrases. BLEU(c,rs) captures the semantic equivalency between the candidates and the references (Finch et al. (2005) have shown the capability for measuring semantic equivalency using BLEU score); BLEU(c, s) is the BLEU score computed between the candidate and the source sentence to measure the dissimilarity. α is a parameter taking balance between adequacy and dissimilarity, smaller α value indicates larger punishment on selfparaphrase. Fluency is not explicitly presented because there is high correlation between fluency and adequacy (Zhao et al., 2010) and SMT has already taken this into consideration. By using iBLEU, we aim at adapting paraphrasing performance to different application needs by adjusting α value. 3 Experiments and Results 3.1 Experiment Setup For English sentence paraphrasing task, we utilize Chinese as the pivot language, our experiments are built on English and Chinese bi-directional translation. We use 2003 NIST Open Machine Translation Evaluation data (NIST 2003) as development data (containing 919 sentences) for MERT and test the performance on NIST 2008 data set (containing 1357 sentences). NIST Chinese-to-English eva</context>
</contexts>
<marker>Zhao, Wang, Lan, Liu, 2010</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Xiang Lan, and Ting Liu. 2010. Leveraging multiple mt engines for paraphrase generation. In COLING, pages 1326–1334.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>