<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993356">
Highly constrained unification grammars
</title>
<author confidence="0.998556">
Daniel Feinstein
</author>
<affiliation confidence="0.9979165">
Department of Computer Science
University of Haifa
</affiliation>
<address confidence="0.617506">
31905 Haifa, Israel
</address>
<email confidence="0.990475">
daniel@cs.haifa.ac.il
</email>
<author confidence="0.974651">
Shuly Wintner
</author>
<affiliation confidence="0.997841">
Department of Computer Science
University of Haifa
</affiliation>
<address confidence="0.620299">
31905 Haifa, Israel
</address>
<email confidence="0.995908">
shuly@cs.haifa.ac.il
</email>
<sectionHeader confidence="0.994743" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998376">
Unification grammars are widely accepted
as an expressive means for describing the
structure of natural languages. In gen-
eral, the recognition problem is undecid-
able for unification grammars. Even with
restricted variants of the formalism, off-
line parsable grammars, the problem is
computationally hard. We present two nat-
ural constraints on unification grammars
which limit their expressivity. We first
show that non-reentrant unification gram-
mars generate exactly the class of context-
free languages. We then relax the con-
straint and show that one-reentrant unifi-
cation grammars generate exactly the class
of tree-adjoining languages. We thus re-
late the commonly used and linguistically
motivated formalism of unification gram-
mars to more restricted, computationally
tractable classes of languages.
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999812480769231">
Unification grammars (UG) (Shieber, 1986;
Shieber, 1992; Carpenter, 1992) have originated
as an extension of context-free grammars, the ba-
sic idea being to augment the context-free rules
with non context-free annotations (feature struc-
tures) in order to express additional information.
They can describe phonological, morphological,
syntactic and semantic properties of languages si-
multaneously and are thus linguistically suitable
for modeling natural languages. Several formula-
tions of unification grammars have been proposed,
and they are used extensively by computational
linguists to describe the structure of a variety of
natural languages.
Unification grammars are Turing equivalent:
determining whether a given string is generated by
a given grammar is as hard as deciding whether
a Turing machine halts on the empty input (John-
son, 1988). Therefore, the recognition problem for
unification grammars is undecidable in the general
case. To ensure its decidability, several constraints
on unification grammars, commonly known as the
off-line parsability (OLP) constraints, were sug-
gested, such that the recognition problem is decid-
able for off-line parsable grammars (Jaeger et al.,
2005). The idea behind all the OLP definitions is
to rule out grammars which license trees in which
unbounded amount of material is generated with-
out expanding the frontier word. This can happen
due to two kinds of rules: c-rules (whose bodies
are empty) and unit rules (whose bodies consist
of a single element). However, even for unifica-
tion grammars with no such rules the recognition
problem is NP-hard (Barton et al., 1987).
In order for a grammar formalism to make pre-
dictions about the structure of natural language
its generative capacity must be constrained. It is
now generally accepted that Context-free Gram-
mars (CFGs) lack the generative power needed for
this purpose (Savitch et al., 1987), due to natu-
ral language constructions such as reduplication,
multiple agreement and crossed agreement. Sev-
eral linguistic formalisms have been proposed as
capable of modeling these phenomena, including
Linear Indexed Grammars (LIG) (Gazdar, 1988),
Head Grammars (Pollard, 1984), Tree Adjoin-
ing Grammars (TAG) (Joshi, 2003) and Combina-
tory Categorial Grammars (Steedman, 2000). In
a seminal work, Vijay-Shanker and Weir (1994)
prove that all four formalisms are weakly equiv-
alent. They all generate the class of mildly
context-sensitive languages (MCSL), all members
</bodyText>
<page confidence="0.972245">
1089
</page>
<note confidence="0.528415">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999975590909091">
of which have recognition algorithms with time
complexity O(n6) (Vijay-Shanker and Weir, 1993;
Satta, 1994).1 As a result of the weak equiva-
lence of four independently developed (and lin-
guistically motivated) extensions of CFG, the class
MCSL is considered to be linguistically meaning-
ful, a natural class of languages for characterizing
natural languages.
Several authors tried to approximate unifica-
tion grammars by means of context-free gram-
mars (Rayner et al., 2001; Kiefer and Krieger,
2004) and even finite-state grammars (Pereira and
Wright, 1997; Johnson, 1998), but we are not
aware of any work which relates unification gram-
mars with the class MCSL. The main objective of
this work is to define constraints on UGs which
naturally limit their generative capacity. We de-
fine two natural and easily testable syntactic con-
straints on UGs which ensure that grammars sat-
isfying them generate the context-free and the
mildly context-sensitive languages, respectively.
The contribution of this result is twofold:
</bodyText>
<listItem confidence="0.860840181818182">
• From a theoretical point of view, constraining
unification grammars to generate exactly the
class MCSL results in a grammatical formal-
ism which is, on one hand, powerful enough
for linguists to express linguistic generaliza-
tions in, and on the other hand cognitively ad-
equate, in the sense that its generative capac-
ity is constrained;
• Practically, such a constraint can provide ef-
ficient recognition algorithms for the limited
class of unification grammars.
</listItem>
<bodyText confidence="0.9999901">
We define some preliminary notions in section 2
and then show a constrained version of UG which
generates the class CFL of context-free languages
in section 3. Section 4 presents the main result,
namely a restricted version of UG and a mapping
of its grammars to LIG, establishing the proposi-
tion that such grammars generate exactly the class
MCSL. For lack of space, we favor intuitive expla-
nation over rigorous proofs; the full details can be
found in Feinstein (2004).
</bodyText>
<sectionHeader confidence="0.94998" genericHeader="method">
2 Preliminary notions
</sectionHeader>
<bodyText confidence="0.99166">
A CFG is a four-tuple Gcf = hVN, Vt, Rcf, Si
where Vt is a set of terminals, VN is a set of non-
</bodyText>
<footnote confidence="0.99794125">
1The term mildly context-sensitive was coined by Joshi
(1985), in reference to a less formally defined class of lan-
guages. Strictly speaking, what we call MCSL here is also
known as the class of tree-adjoining languages.
</footnote>
<bodyText confidence="0.999831684210526">
terminals, including the start symbol S, and Rcf
is a set of productions, assumed to be in a nor-
mal form where each rule has either (zero or more)
non-terminals or a single terminal in its body, and
where the start symbol never occurs in the right
hand side of rules. The set of all such context-free
grammars is denoted CFGS.
In a linear indexed grammar (LIG),2 strings
are derived from nonterminals with an associated
stack denoted A[l1 ... ln], where A is a nontermi-
nal, each li is a stack symbol, and l1 is the top
of the stack. Since stacks can grow to be of un-
bounded size during a derivation, some way of
partially specifying unbounded stacks in LIG pro-
ductions is needed. We use A[l1 ... ln ∞] to de-
note the nonterminal A associated with any stack
η whose top n symbols are l1, l2 ..., ln. The set
of all nonterminals in VN, associated with stacks
whose symbols come from Vs, is denoted VN[Vs∗ ].
</bodyText>
<listItem confidence="0.686730875">
Definition 1. A Linear Indexed Grammar is a five
tuple Gli = hVN, Vt, Vs, Rli, Si where Vt, VN and
S are as above, Vs is a finite set of indices (stack
symbols) and Rli is a finite set ofproductions in
one of the following two forms:
• fixed stack: Ni[p1 . . . pn] → α
• unbounded stack: Ni[p1 . . . pn ∞] → α or
Ni[p1 ... pn ∞] → αNj[q1 ... qm ∞]β
</listItem>
<bodyText confidence="0.9927862">
where Ni, Nj ∈ VN, p1 . . . pn, q1 . . . qm ∈ Vs,
n, m ≥ 0 and α, β ∈ (Vt ∪ VN[Vs∗ ])∗.
A crucial characteristic of LIG is that only one
copy of the stack can be copied to a single element
in the body of a rule. If more than one copy were
allowed, the expressive power would grow beyond
MCSL.
Definition 2. Given a LIG hVN, Vt, Vs, Rli, Si,
the derivation relation ‘⇒li’ is defined as follows:
for all XF1,XF2 ∈ (VN[Vs∗]∪Vt)∗andη∈Vs∗,
</bodyText>
<listItem confidence="0.9999308">
• If Ni[p1 ... pn]
&apos;F1Ni[p1 ... pn]&apos;F2 ⇒li I&amp;1α&apos;&amp;2
• If Ni[p1 ... pn ∞] → α ∈ Rli then
&apos;F1Ni[p1 . . .pnη]*2 ⇒li qf1αXF2
• If Ni[p1 ... pn ∞] → αNj[q1 ... qm ∞]β ∈
</listItem>
<bodyText confidence="0.476582">
Rli then IF1Ni[p1 . . . pnη] 2 ⇒li
&apos;F1αNj[q1 ... qmη]β&apos;&amp;2
</bodyText>
<footnote confidence="0.9111385">
2The definition is based on Vijay-Shanker and Weir
(1994).
</footnote>
<equation confidence="0.592183">
→ α ∈ Rli then
</equation>
<page confidence="0.770503">
1090
</page>
<bodyText confidence="0.798806">
The language generated by Gli is L(Gli) = {w ∈
</bodyText>
<equation confidence="0.8873205">
V∗
t  |S[ ] ∗⇒li w}, where ‘∗⇒li’ is the reflexive,
</equation>
<bodyText confidence="0.959821">
transitive closure of ‘⇒li’.
Unification grammars are defined over fea-
ture structures (FSs) which are directed, con-
nected, rooted, labeled graphs, usually depicted as
attribute-value matrices (AVM). A feature struc-
ture A can be characterized by its set of paths,
IIA, an assignment of atomic values to the ends of
some paths, OA(·), and a reentrancy relation ‘*&amp;quot;’
relating paths which lead to the same node. A se-
quence of feature structures, where some nodes
may be shared by more than one element, is a
multi-rooted structure (MRS).
</bodyText>
<construct confidence="0.696844">
Definition 3. Unification grammars are defined
over a signature consisting of a finite set ATOMS
of atoms; a finite set FEATS offeatures and a fi-
nite set WORDS ofwords. A unification grammar
is a tuple Gu = hRu, As, Li where Ru is a finite
set of rules, each of which is an MRS of length
n ≥ 1, L is a lexicon, which associates with ev-
ery word w ∈ WORDS a finite set offeature struc-
tures, L(w), and As is a feature structure, the start
symbol.
Definition 4. A unification grammar hRu, As, Li
over the signature hATOMS, FEATS, WORDSi is
non-reentrant iff for any rule ru
</construct>
<bodyText confidence="0.994549794117647">
non-reentrant. It is one-reentrant ifffor every rule
ru ∈ Ru, ru includes at most one reentrancy, be-
tween the head of the rule and some element of
the body. Let UGnr, UG1r be the sets of all non-
reentrant and one-reentrant unification grammars,
respectively.
Informally, a rule is non-reentrant if (on an
AVM view) no reentrancy tags occur in it. When
the rule is viewed as a (multi-rooted) graph, it is
non-reentrant if the in-degree of all nodes is at
most 1. A rule is one-reentrant if (on an AVM
view) at most one reentrancy tag occurs in it, ex-
actly twice: once in the head of the rule and once
in an element of its body. When the rule is viewed
as a (multi-rooted) graph, it is one-reentrant if the
in-degree of all nodes is at most 1, with the excep-
tion of one node whose in-degree can be 2, pro-
vided that the only two distinct paths that lead to
this node leave from the roots of the head of the
rule and an element of the body.
FSs and MRSs are partially ordered by sub-
sumption, denoted ‘v’. The least upper bound
with respect to subsumption is unification, de-
noted ‘t’. Unification is partial; when A t B is
undefined we say that the unification fails and de-
note it as AtB = &gt;. Unification is lifted to MRSs:
given two MRSs Q and p, it is possible to unify
the i-th element of Q with the j-th element of p.
This operation, called unification in context and
denoted (Q, i) t (p, j), yields two modified vari-
ants of Q and p: (Q0, p0).
In unification grammars, forms are MRSs. A
form QA = hA1, ... , Aki immediately derives
another form QB = hB1, ... , Bmi (denoted by
</bodyText>
<equation confidence="0.634819">
⇒u QB) iff there exists a rule ru ∈ Ru of
1
</equation>
<bodyText confidence="0.882031090909091">
length n that licenses the derivation. The head
of ru is matched against some element Ai in QA
using unification in context: (QA, i) t (ru, 0) =
(Q0A, r0). If the unification does not fail, QB is ob-
tained by replacing the i-th element of Q0A with the
body of r0. The reflexive transitive closure of ‘1⇒u’
is denoted by ‘∗⇒u’.
Definition 5. The language of a unification gram-
mar Gu is L(Gu) = {w1 · · · wn ∈ WORDS∗ |
As ∗⇒u hA1, ... , Ani}, where Ai ∈ L(wi) for
1 ≤ i ≤ n.
</bodyText>
<sectionHeader confidence="0.870497" genericHeader="method">
3 Context-free unification grammars
</sectionHeader>
<bodyText confidence="0.999515038461539">
We define a constraint on unification grammars
which ensures that grammars satisfying it generate
the class CFL. The constraint disallows any reen-
trancies in the rules of the grammar. When rules
are non-reentrant, applying a rule implies that an
exact copy of the body of the rule is inserted
into the generated (sentential) form, not affecting
neighboring elements of the form the rule is ap-
plied to. The only difference between rule appli-
cation in UGnr and the analog operation in CFGS
is that the former requires unification whereas the
latter only calls for identity check. This small dif-
ference does not affect the generative power of the
formalisms, since unification can be pre-compiled
in this simple case.
The trivial direction is to map a CFG to a non-
reentrant unification grammar, since every CFG
is, trivially, such a grammar (where terminal and
non-terminal symbols are viewed as atomic fea-
ture structures). For the inverse direction, we de-
fine a mapping from UGnr to CFGS. The non-
terminals of the CFG in the image of the mapping
are the set of all feature structures defined in the
source UG.
Definition 6. Let ug2cfg : UGnr 7→ CFGS
be a mapping of UGnr to CFGS, such that
</bodyText>
<equation confidence="0.8629875">
∈ Ru, ru is
QA
</equation>
<page confidence="0.920749">
1091
</page>
<bodyText confidence="0.727605666666667">
if Gu = hRu, As, Li is over the signature
hATOMS, FEATS, WORDSi then ug2cfg(Gu) =
hVN, Vt, Rcf, Scfi, where:
</bodyText>
<listItem confidence="0.9867906">
• VN = {Ai  |A0 → A1 ...An ∈ Ru,i ≥ 0} ∪
{A  |A ∈ L(a), a ∈ ATOMS} ∪ {As}. VN is
the set of all the feature structures occurring
in any of the rules or the lexicon of Gu.
• Scf = As • Vt = WORDS
• Rcf consists of the following rules:
1. Let A0 → A1 ... An ∈ Ru and B ∈
L(b). Iffor some i, 1 ≤ i ≤ n, Ai t B =6
&gt;, then Ai → b ∈ Rcf
2. If A0 → A1 ... An ∈ Ru and As t A0 =6
&gt; then Scf → A1 ... An ∈ Rcf.
3. Let ru1 = A0 → A1 ... An and ru2 =
B0 → B1 ... Bm, where ru1 , ru2 ∈ Ru. If
for some i, 1 ≤ i ≤ n, Ai t B0 =6 &gt;,
then the rule Ai → B1 ... Bm ∈ Rcf
</listItem>
<bodyText confidence="0.998701">
The size of ug2cfg(Gu) is polynomial in the
size of Gu. By inductions on the lengths of the
derivation sequences, we prove the following the-
orem:
Theorem 1. If Gu = hRu, As, Li is a non-
reentrant unification grammar and Gcf =
ug2cfg(Gu), then L(Gcf) = L(Gu).
Corollary 2. Non-reentrant unification grammars
are weakly equivalent to CFGS.
</bodyText>
<sectionHeader confidence="0.956268" genericHeader="method">
4 Mildly context-sensitive UG
</sectionHeader>
<bodyText confidence="0.999947333333333">
In this section we show that one-reentrant unifica-
tion grammars generate exactly the class MCSL.
In such grammars each rule can have at most
one reentrancy, reflecting the LIG situation where
stacks can be copied to exactly one daughter in
each rule.
</bodyText>
<subsectionHeader confidence="0.980092">
4.1 Mapping LIG to UG1r
</subsectionHeader>
<bodyText confidence="0.999652466666667">
In order to simulate a given LIG with a unification
grammar, a dedicated signature is defined based
on the parameters of the LIG.
Definition 7. Given a LIG hVN, Vt, Vs, Rli, Si, let
τ be hATOMS, FEATS, WORDSi, where ATOMS =
VN ∪ Vs ∪ {elist}, FEATS = {HEAD, TAIL}, and
WORDS = Vt.
We use τ throughout this section as the signa-
ture over which UGs are defined. We use FSs over
the signature τ to represent and simulate LIG sym-
bols. In particular, FSs will encode lists in the nat-
ural way, hence the features HEAD and TAIL. For
the sake of brevity, we use standard list notation
when FSs encode lists. LIG symbols are mapped
to FSs thus:
</bodyText>
<construct confidence="0.805149">
Definition 8. Let toFs be a mapping of LIG sym-
bols to feature structures, such that:
</construct>
<listItem confidence="0.97738">
1. If t ∈ Vt then toFs(t) = hti
2. If N ∈ VN and pi ∈ Vs, 1 ≤ i ≤ n, then
toFs(N[p1,...,pn]) = hN,p1, ..., pni
</listItem>
<bodyText confidence="0.997845681818182">
The mapping toFs is extended to sequences of
symbols by setting toFs(αβ) = toFs(α)toFs(β).
Note that toFs is one to one.
When FSs that are images of LIG symbols are
concerned, unification is reduced to identity:
Lemma 3. Let X1, X2 ∈ VN[Vs� ] ∪ Vt. If
toFs(X1) t toFs(X2) =6 &gt; then toFs(X1) =
toFs(X2).
When a feature structure which is represented as
an unbounded list (a list that is not terminated by
elist) is unifiable with an image of a LIG symbol,
the former is a prefix of the latter.
Lemma 4. Let C = hp1, ... , pn, i i be a non-
reentrant feature structure, where p1, ... , pn ∈
Vs, and letX ∈ VN[Vs� ]∪Vt. Then CttoFs(X) =6
&gt; iff toFs(X) = hp1, ... , pn, αi, for some α ∈
Vs* .
To simulate LIGs with UGs we represent each
symbol in the LIG as a feature structure, encod-
ing the stack of LIG non-terminals as lists. Rules
that propagate stacks (from mother to daughter)
are simulated by means of reentrancy in the UG.
</bodyText>
<listItem confidence="0.772202333333333">
Definition 9. Let lig2ug be a mapping of LIGS to
UG1r, such that if Gli = hVN, Vt, Vs, Rli, Si and
Gu = hRu, As, Li = lig2ug(Gli) then Gu is over
the signature τ (definition 7), As = toFs(S[ ]), for
all t ∈ Vt, L(t) = {toFs(t)} and Ru is defined
by:
• A LIG rule of the form X0 → α is mapped to
the unification rule toFs(X0) → toFs(α)
• A LIG rule of the form Ni[p1, ... , pn ∞] →
α Nj[q1, ... , qm ∞] β is mapped to the
unification rule hNi, p1, . . . , pn, 1 i→
toFs(α) hNj, q1, ... , qm, 1 i toFs(β)
</listItem>
<bodyText confidence="0.9117715">
Evidently, lig2ug(Gli) ∈ UG1r for any LIG
Gli.
</bodyText>
<page confidence="0.982896">
1092
</page>
<note confidence="0.7475605">
Theorem 5. If Gli = hVN, Vt, Vs, Rli, Slii is a
LIG and Gu = lig2ug(Gli) then L(Gu) = L(Gli).
</note>
<subsectionHeader confidence="0.896581">
4.2 Mapping UG1r to LIG
</subsectionHeader>
<bodyText confidence="0.998908842857143">
We are now interested in the reverse direction,
namely mapping UGs to LIG. Of course, since
UGs are more expressive than LIGs, only a sub-
set of the former can be correctly simulated by the
latter. The differences between the two formalisms
can be summarized along three dimensions:
The basic elements UG manipulates feature
structures, and rules (and forms) are MRSs;
whereas LIG manipulates terminals and
non-terminals with stacks of elements, and
rules (and forms) are sequences of such
symbols.
Rule application In UG a rule is applied by uni-
fication in context of the rule and a sentential
form, both of which are MRSs, whereas in
LIG, the head of a rule and the selected ele-
ment of a sentential form must have the same
non-terminal symbol and consistent stacks.
Propagation of information in rules In UG in-
formation is shared through reentrancies,
whereas In LIG, information is propagated by
copying the stack from the head of the rule to
one element of its body.
We show that one-reentrant UGs can all be cor-
rectly mapped to LIG. For the rest of this section
we fix a signature hATOMS, FEATS, WORDSi over
which UGs are defined. Let NRFSS be the set of
all non-reentrant FSs over this signature.
One-reentrant UGs induce highly constrained
(sentential) forms: in such forms, there are no
reentrancies whatsoever, neither between distinct
elements nor within a single element. Hence all
the FSs in forms induced by a one-reentrant UG
are non-reentrant.
Definition 10. Let A be a feature structure with no
reentrancies. The height of A, denoted |A|, is the
length of the longestpath in A. This is well-defined
since non-reentrant feature structures are acyclic.
Let Gu = hRu, As, Li ∈ UG1r be a one-reentrant
unification grammar. The maximum height of the
grammar, maxHt(Gu), is the height of the high-
est feature structure in the grammar. This is well
defined since all the feature structures of one-
reentrant grammars are non-reentrant.
The following lemma indicates an important
property of one-reentrant UGs. Informally, in any
FS that is an element of a sentential form induced
by such grammars, if two paths are long (specif-
ically, longer than the maximum height of the
grammar), they must have a long common prefix.
Lemma 6. Let Gu = hRu, As, Li ∈ UG1r be a
one-reentrant unification grammar. Let A be an
element of a sentential form induced by Gu. If 7r ·
hFji·7r1,7r·hFki·7r2 ∈ ΠA, where Fj, Fk ∈ FEATS,
j =6 k and |7r1 |≤ |7r2|, then |7r1 |≤ maxHt(Gu).
Lemma 6 facilitates a view of all the FSs in-
duced by such a grammar as (unboundedly long)
lists of elements drawn from a finite, predefined
set. The set consists of all features in FEATS
and all the non-reentrant feature structures whose
height is limited by the maximal height of the
unification grammar. Note that even with one-
reentrant UGs, feature structures can be unbound-
edly deep. What lemma 6 establishes is that if a
feature structure induced by a one-reentrant uni-
fication grammar is deep, then it can be repre-
sented as a single “core” path which is long, and
all the sub-structures which “hang” from this core
are depth-bounded. We use this property to encode
such feature structures as cords.
</bodyText>
<construct confidence="0.772680857142857">
Definition 11. Let Ψ : NRFSS × PATHS 7→
(FEATS ∪ NRFSS)* be a mapping such
that if A is a non-reentrant FS and
7r = hF1, ... , Fni ∈ ΠA, then the cord
Ψ(A, 7r) is hA1, F1, ... , An, Fn, An+1i, where
for 1 ≤ i ≤ n + 1, Ai are non-reentrant FSs such
that:
</construct>
<listItem confidence="0.986558">
• ΠAi = {hGi · 7r  |hF1, . . . , Fi−1, Gi · 7r ∈
ΠA, i ≤ n, G =6Fi} ∪ {E}
• ΘAi(7r) = ΘA(hF1, ... , Fi−1i · 7r) (if it is de-
fined).
</listItem>
<bodyText confidence="0.999357833333333">
We also define last(Ψ(A,7r)) = An+1. The
height of a cord is defined as |Ψ(A,7r) |=
max1&lt;i&lt;n+1(|Ai|). For each cord Ψ(A, 7r) we re-
fer to A as the base feature structure and to 7r as
the base path. The length of a cord is the length
of the base path.
The function Ψ is one to one: given Ψ(A, 7r),
both A and 7r are uniquely determined.
Lemma 7. Let Gu be a one-reentrant unification
grammar and let A be an element of a sentential
form induced by Gu. Then there is a path 7r ∈ ΠA
such that |Ψ(A, 7r) |&lt; maxHt(Gu).
</bodyText>
<page confidence="0.977534">
1093
</page>
<bodyText confidence="0.998513362745098">
Lemma 7 implies that every non-reentrant FS
(i.e., FSs induced by one-reentrant grammars) can
be represented as a height-limited cord. This map-
ping resolves the first difference between LIG and
UG, by providing a representation of the basic el-
ements. We use cords as the stack contents of LIG
non-terminals: cords can be unboundedly long,
but so can LIG stacks; the crucial point is that
cords are height limited, implying that they can be
represented using a finite number of elements.
We now show how to simulate, in LIG, the uni-
fication in context of a rule and a sentential form.
The first step is to have exactly one non-terminal
symbol (in addition to the start symbol); when all
non-terminal symbols are identical, only the con-
tent of the stack has to be taken into account. Re-
call that in order for a LIG rule to be applicable
to a sentential form, the stack of the rule’s head
must be a prefix of the stack of the selected ele-
ment in the form. The only question is whether the
two stacks are equal (fixed rule head) or not (un-
bounded rule head). Since the contents of stacks
are cords, we need a property relating two cords,
on one hand, with unifiability of their base feature
structures, on the other. Lemma 8 establishes such
a property. Informally, if the base path of one cord
is a prefix of the base path of the other cord and all
feature structures along the common path of both
cords are unifiable, then the base feature structures
of both cords are unifiable. The reverse direction
also holds.
Lemma 8. Let A, B E NRFSS be non-reentrant
feature structures and π1, π2 E PATHS be paths
such that π1 E IIB, π1 ·π2 E IIA, XF(A, π1 ·π2) =
(t1, F1, ... , F|π1|, t|π1|+1, F|π1|+1, ... , t|π1·π2|+1),
XF(B, π1) = (s1, F1, ... , s|π1|+1), and
(F|π1|+1) E� IIs|,1|+1. Then A U B =� T iff
for all i, 1 &lt; i &lt; |π1 |+ 1, si U ti =� T.
The length of a cord of an element of a sen-
tential form induced by the grammar cannot be
bounded, but the length of any cord representation
of a rule head is limited by the grammar height. By
lemma 8, unifiability of two feature structures can
be reduced to a comparison of two cords represent-
ing them and only the prefix of the longer cord (as
long as the shorter cord) affects the result. Since
the cord representation of any grammar rule’s head
is limited by the height of the grammar we always
choose it as the shorter cord in the comparison.
We now define, for a feature structure C (which
is a head of a rule) and some path π, the set that
includes all feature structures that are both unifi-
able with C and can be represented as a cord whose
height is limited by the grammar height and whose
base path is π. We call this set the compatibility set
of C and π and use it to define the set of all possi-
ble prefixes of cords whose base FSs are unifiable
with C (see definition 13). Crucially, the compat-
ibility set of C is finite for any feature structure C
since the heights and the lengths of the cords are
limited.
Definition 12. Given a non-reentrant feature
structure C, a path π = (F1, ... , Fn) E IIC
and a natural number h, the compatibility set,
F(C, π, h), is defined as the set of allfeature struc-
tures A such that C U A =7� T, π E IIA, and
|XF(A,π) |&lt; h.
The compatibility set is defined for a feature
structure and a given path (when h is taken to be
the grammar height). We now define two similar
sets, FH and UH, for a given FS, independently of
a path. When rules of a one-reentrant unification
grammar are mapped to LIG rules (definition 14),
FH and UH are used to define heads of fixed and
unbounded LIG rules, respectively. A single unifi-
cation rule is mapped to a set of LIG rules, each
with a different head. The stack of the head is
some member of the sets FH and UH. Each such
member is a prefix of the stack of potential ele-
ments of sentential forms that the LIG rule can be
applied to.
Definition 13. Let C be a non-reentrant feature
structure and h be a natural number. Then:
FH(C, h) = {xF(A, ir)  |ir E 11C, A E r(C, ir, h)J
UH(C, h) = {xF(A, ir) (F)  |T(A, ir) E FH(C, h),
OC(ir) T, F E FEATS, val(last(xF(C U A, ir)), (F)) TJ
This accounts for the second difference between
LIG and one-reentrant UG, namely rule appli-
cation. We now briefly illustrate our account of
the last difference, propagation of information in
rules. In UG1r information is shared between the
rule’s head and a single element in its body. Let
ru = (C0, ... , Cn) be a reentrant unification rule
in which the path µe, leaving the e-th element of
the body, is reentrant with the path µ0 leaving the
head. This rule is mapped to a set of LIG rules,
corresponding to the possible rule heads induced
by the compatibility set of C0. Let r be a member
of this set, and let X0 and Xe be the head and the
e-th element of r, respectively. Reentrancy in ru is
modeled in the LIG rule by copying the stack from
X0 to Xe. The major complication is the contents
</bodyText>
<page confidence="0.991463">
1094
</page>
<bodyText confidence="0.9752535">
of this stack, which varies according to the cord
representations of C0 and Ce and to the reentrant
paths.
Summing up, in a LIG simulating a one-
reentrant UG, FSs are represented as stacks of
symbols. The set of stack symbols V3, therefore,
is defined as a set of height bounded non-reentrant
FSs. Also, all the features of the UG are stack
symbols. V3 is finite due to the restriction on FSs
(no reentrancies and height-boundedness). The set
of terminals, Vt, is the words of the UG. There
are exactly two non-terminal symbols, 5 (the start
symbol) and N.
The set of rules is divided to four. The start
rule only applies once in a derivation, simulating
the situation in UGs of a rule whose head is unifi-
able with the start symbol. Terminal rules are a
straight-forward implementation of the lexicon in
terms of LIG. Non-reentrant rules are simulated
in a similar way to how rules of a non-reentrant
UG are simulated by CFG (section 3). The ma-
jor difference is the head of the rule, X0, which
is defined as explained above. One-reentrant rules
are simulated similarly to non-reentrant ones, the
only difference being the selected element of the
rule body, Xe, which is defined as follows.
Definition 14. Let ug2lig be a mapping of UG1r
to LIGS, such that if Gu = hRu, A3, Li ∈ UG1r
then ug2lig(Gu) = hVN, Vt, V3, Rlz, 5i, where
VN = {N, 5} (fresh symbols), Vt = WORDS,
V3 = FEATS ∪ {A  |A ∈ NRFSS, |A |≤
maxHt(Gu)}, and Rlz is defined as follows:3
</bodyText>
<listItem confidence="0.972437">
1. 5[ ] → N[IF(A3, E)]
2. For every w ∈ WORDS such that L(w) =
{C0} and for every 7r0 ∈ Hyo, the rule
N[IF(C0, 7r0)] → w is in Rlz.
3. If hC0, ... , Cni ∈ Ru is a non-reentrant
rule, then for every X0 ∈ LIGHEAD(C0) the
</listItem>
<equation confidence="0.781242333333333">
rule X0 → N[IF(C1, E)] ... N[IF(Cn, E)] is
in Rlz.
ru
4. Let ru = hC0, ... , Cni ∈ Ru and (0, µ0)
(e, µe), where 1 ≤ e ≤ n. Then for every
X0 ∈ LIGHEAD(C0) the rule
X0 → N[IF(C1, E)] ... N[IF(Ce−1, E)]
Xe
N[IF(Ce+1, E)] ... N[IF(Cn, E)]
</equation>
<footnote confidence="0.570627666666667">
3For a non-reentrant FS Co, we define: LIGHEAD(C0)
as {N[77]  |77 E FH(C0, maxHt(Gu))I U {N[77 oo]  |77 E
UH(Co, maxHt(Gu))I
</footnote>
<bodyText confidence="0.9637546">
is in Rlz, where Xe is defined as follows.
Let 7r0 be the base path of X0 and A be
the base feature structure of X0. Applying
the rule ru to A, define (hAi, 0) t (ru, 0) =
(hP0i, hP0, ... , Pe, ... , Pni).
</bodyText>
<figure confidence="0.924944714285714">
(a) If µ0 is not a prefix of 7r0 then Xe =
N[IF(Pe, µe)].
(b) If 7r0 = µ0 · v, v ∈ PATHS then
i. If X0 = N[IF(A, 7r0)] then Xe =
N[IF(Pe, µe · v)].
ii. If X0 = N[IF(A, 7r0), F ∞] then
Xe = N[IF(Pe, µe · v), F ∞].
</figure>
<bodyText confidence="0.6831075">
By inductions on the lengths of the derivations
we prove that the mapping is correct:
</bodyText>
<construct confidence="0.5259135">
Theorem 9. If Gu ∈ UG1r, then L(Gu) =
L(ug2lig(Gu)).
</construct>
<sectionHeader confidence="0.996507" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99997946875">
The main contribution of this work is the definition
of two constraints on unification grammars which
dramatically limit their expressivity. We prove
that non-reentrant unification grammars generate
exactly the class of context-free languages; and
that one-reentrant unification grammars generate
exactly the class of mildly context-sensitive lan-
guages. We thus obtain two linguistically plausi-
ble constrained formalisms whose computational
processing is tractable.
This main result is primarily a formal grammar
result. However, we maintain that it can be easily
adapted such that its consequences to (practical)
computational linguistics are more evident. The
motivation behind this observation is that reen-
trancy only adds to the expressivity of a gram-
mar formalism when it is potentially unbounded,
i.e., when infinitely many feature structures can
be the possible values at the end of the reentrant
paths. It is therefore possible to modestly ex-
tend the class of unification grammars which can
be shown to generate exactly the class of mildly
context-sensitive languages, by allowing also a
limited form of multiple reentrancies among the
elements in a rule (e.g., to handle agreement phe-
nomena). This can be most useful for grammar
writers, and at the same time adds nothing to the
expressivity of the formalism. We leave the formal
details of such an extension to future work.
This work can also be extended in other direc-
tions. The mapping of one-reentrant UGs to LIG
is highly verbose, resulting in LIGs with a huge
</bodyText>
<page confidence="0.977315">
1095
</page>
<bodyText confidence="0.999699588235294">
number of rules. We believe that it should be
possible to optimize the mapping such that much
smaller grammars are generated. In particular, we
are looking into mappings of one-reentrant UGs to
other MCSL formalisms, notably TAG.
The two constraints on unification grammars
(non-reentrant and one-reentrant) are parallel to
the first two classes of the Weir (1992) hierarchy
of languages. A possible extension of this work
could be a definition of constraints on unification
grammars that would generate all the classes of
the hierarchy. Another direction is an extension
of one-reentrant unification grammars, where the
reentrancy does not have to be between the head
and one element of the body. Also of interest are
two-reentrant unification grammars, possibly with
limited kinds of reentrancies.
</bodyText>
<sectionHeader confidence="0.998609" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.98791825">
This research was supported by The Israel Science
Foundation (grant no. 136/01). We are grateful
to Yael Cohen-Sygal, Nissim Francez and James
Rogers for their comments and help.
</bodyText>
<sectionHeader confidence="0.997747" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999953783132531">
G. Edward Barton, Jr., Robert C. Berwick, and
Eric Sven Ristad. 1987. The complexity of LFG.
In G. Edward Barton, Jr., Robert C. Berwick, and
Eric Sven Ristad, editors, Computational Complex-
ity and Natural Language, Computational Models of
Cognition and Perception, chapter 3, pages 89–102.
MIT Press, Cambridge, MA.
Bob Carpenter. 1992. The Logic of Typed Feature
Structures. Cambridge University Press.
Daniel Feinstein. 2004. Computational investigation
of unification grammars. Master’s thesis, University
of Haifa.
Gerald Gazdar. 1988. Applicability of indexed gram-
mars to natural languages. In Uwe Reyle and Chris-
tian Rohrer, editors, Natural Language Parsing and
Linguistic Theories, pages 69–94. Reidel.
Efrat Jaeger, Nissim Francez, and Shuly Wintner.
2005. Unification grammars and off-line parsabil-
ity. Journal of Logic, Language and Information,
14(2):199–234.
Mark Johnson. 1988. Attribute-Value Logic and the
Theory of Grammar, volume 16 of CSLI Lecture
Notes. CSLI, Stanford, California.
Mark Johnson. 1998. Finite-state approximation of
constraint-based grammars using left-corner gram-
mar transforms. In Proceedings of the 17th inter-
national conference on Computational linguistics,
pages 619–623.
Aravind K. Joshi. 1985. Tree Adjoining Grammars:
How much context Sensitivity is required to provide
a reasonable structural description. In D. Dowty,
I. Karttunen, and A. Zwicky, editors, Natural Lan-
guage Parsing, pages 206–250. Cambridge Univer-
sity Press, Cambridge, U.K.
Aravind K. Joshi. 2003. Tree-adjoining grammars. In
Ruslan Mitkov, editor, The Oxford handbook of com-
putational linguistics, chapter 26, pages 483–500.
Oxford university Press.
Bernd Kiefer and Hans-Ulrich Krieger. 2004. A
context-free superset approximation of unification-
based grammars. In Harry Bunt, John Carroll, and
Giorgio Satta, editors, New Developments in Pars-
ing Technology, pages 229–250. Kluwer Academic
Publishers.
Fernando C. N. Pereira and Rebecca N. Wright. 1997.
Finite-state approximation of phrase-structure gram-
mars. In Emmanuel Roche and Yves Schabes, edi-
tors, Finite-State Language Processing, Language,
Speech and Communication, chapter 5, pages 149–
174. MIT Press, Cambridge, MA.
Carl Pollard. 1984. Generalized phrase structure
grammars, head grammars and natural language.
Ph.D. thesis, Stanford University.
Manny Rayner, John Dowding, and Beth Ann Hockey.
2001. A baseline method for compiling typed uni-
fication grammars into context free language mod-
els. In Proceedings of EUROSPEECH 2001, Aal-
borg, Denmark.
Giorgio Satta. 1994. Tree-adjoining grammar parsing
and boolean matrix multiplication. In Proceedings
of the 20st Annual Meeting of the Association for
Computational Linguistics, volume 20.
Walter J. Savitch, Emmon Bach, William Marsh, and
Gila Safran-Naveh, editors. 1987. The formal com-
plexity of natural language, volume 33 of Studies in
Linguistics and Philosophy. D. Reidel, Dordrecht.
Stuart M. Shieber. 1986. An Introduction to Unifica-
tion Based Approaches to Grammar. Number 4 in
CSLI Lecture Notes. CSLI.
Stuart M. Shieber. 1992. Constraint-Based Grammar
Formalisms. MIT Press, Cambridge, Mass.
Mark Steedman. 2000. The Syntactic Process. Lan-
guage, Speech and Communication. The MIT Press,
Cambridge, Mass.
K. Vijay-Shanker and David J. Weir. 1993. Parsing
some constrained grammar formalisms. Computa-
tional Linguistics, 19(4):591 – 636.
K. Vijay-Shanker and David J. Weir. 1994. The equiv-
alence of four extensions of context-free grammars.
Mathematical systems theory, 27:511–545.
David J. Weir. 1992. A geometric hierarchy beyond
context-free languages. Theoretical Computer Sci-
ence, 104:235–261.
</reference>
<page confidence="0.992254">
1096
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971549">
<title confidence="0.999862">Highly constrained unification grammars</title>
<author confidence="0.999991">Daniel Feinstein</author>
<affiliation confidence="0.999916">Department of Computer Science University of Haifa</affiliation>
<address confidence="0.999996">31905 Haifa, Israel</address>
<email confidence="0.999164">daniel@cs.haifa.ac.il</email>
<author confidence="0.993589">Shuly Wintner</author>
<affiliation confidence="0.9998975">Department of Computer Science University of Haifa</affiliation>
<address confidence="0.99999">31905 Haifa, Israel</address>
<email confidence="0.999203">shuly@cs.haifa.ac.il</email>
<abstract confidence="0.998344952380952">Unification grammars are widely accepted as an expressive means for describing the structure of natural languages. In general, the recognition problem is undecidable for unification grammars. Even with variants of the formalism, offparsable the problem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first that grammars generate exactly the class of contextfree languages. We then relax the conand show that unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Edward Barton</author>
<author>Robert C Berwick</author>
<author>Eric Sven Ristad</author>
</authors>
<title>The complexity of LFG.</title>
<date>1987</date>
<booktitle>Computational Complexity and Natural Language, Computational Models of Cognition and Perception, chapter 3,</booktitle>
<pages>89--102</pages>
<editor>In G. Edward Barton, Jr., Robert C. Berwick, and Eric Sven Ristad, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2697" citStr="Barton et al., 1987" startWordPosition="388" endWordPosition="391">ification grammars, commonly known as the off-line parsability (OLP) constraints, were suggested, such that the recognition problem is decidable for off-line parsable grammars (Jaeger et al., 2005). The idea behind all the OLP definitions is to rule out grammars which license trees in which unbounded amount of material is generated without expanding the frontier word. This can happen due to two kinds of rules: c-rules (whose bodies are empty) and unit rules (whose bodies consist of a single element). However, even for unification grammars with no such rules the recognition problem is NP-hard (Barton et al., 1987). In order for a grammar formalism to make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) </context>
</contexts>
<marker>Barton, Berwick, Ristad, 1987</marker>
<rawString>G. Edward Barton, Jr., Robert C. Berwick, and Eric Sven Ristad. 1987. The complexity of LFG. In G. Edward Barton, Jr., Robert C. Berwick, and Eric Sven Ristad, editors, Computational Complexity and Natural Language, Computational Models of Cognition and Perception, chapter 3, pages 89–102. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures.</title>
<date>1992</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1153" citStr="Carpenter, 1992" startWordPosition="156" endWordPosition="157">roblem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first show that non-reentrant unification grammars generate exactly the class of contextfree languages. We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages. 1 Introduction Unification grammars (UG) (Shieber, 1986; Shieber, 1992; Carpenter, 1992) have originated as an extension of context-free grammars, the basic idea being to augment the context-free rules with non context-free annotations (feature structures) in order to express additional information. They can describe phonological, morphological, syntactic and semantic properties of languages simultaneously and are thus linguistically suitable for modeling natural languages. Several formulations of unification grammars have been proposed, and they are used extensively by computational linguists to describe the structure of a variety of natural languages. Unification grammars are T</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. The Logic of Typed Feature Structures. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Feinstein</author>
</authors>
<title>Computational investigation of unification grammars. Master’s thesis,</title>
<date>2004</date>
<institution>University of Haifa.</institution>
<contexts>
<context position="5691" citStr="Feinstein (2004)" startWordPosition="851" endWordPosition="852">city is constrained; • Practically, such a constraint can provide efficient recognition algorithms for the limited class of unification grammars. We define some preliminary notions in section 2 and then show a constrained version of UG which generates the class CFL of context-free languages in section 3. Section 4 presents the main result, namely a restricted version of UG and a mapping of its grammars to LIG, establishing the proposition that such grammars generate exactly the class MCSL. For lack of space, we favor intuitive explanation over rigorous proofs; the full details can be found in Feinstein (2004). 2 Preliminary notions A CFG is a four-tuple Gcf = hVN, Vt, Rcf, Si where Vt is a set of terminals, VN is a set of non1The term mildly context-sensitive was coined by Joshi (1985), in reference to a less formally defined class of languages. Strictly speaking, what we call MCSL here is also known as the class of tree-adjoining languages. terminals, including the start symbol S, and Rcf is a set of productions, assumed to be in a normal form where each rule has either (zero or more) non-terminals or a single terminal in its body, and where the start symbol never occurs in the right hand side of</context>
</contexts>
<marker>Feinstein, 2004</marker>
<rawString>Daniel Feinstein. 2004. Computational investigation of unification grammars. Master’s thesis, University of Haifa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Applicability of indexed grammars to natural languages.</title>
<date>1988</date>
<booktitle>In Uwe Reyle</booktitle>
<pages>69--94</pages>
<editor>and Christian Rohrer, editors,</editor>
<publisher>Reidel.</publisher>
<contexts>
<context position="3220" citStr="Gazdar, 1988" startWordPosition="468" endWordPosition="469">ation grammars with no such rules the recognition problem is NP-hard (Barton et al., 1987). In order for a grammar formalism to make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shank</context>
</contexts>
<marker>Gazdar, 1988</marker>
<rawString>Gerald Gazdar. 1988. Applicability of indexed grammars to natural languages. In Uwe Reyle and Christian Rohrer, editors, Natural Language Parsing and Linguistic Theories, pages 69–94. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efrat Jaeger</author>
<author>Nissim Francez</author>
<author>Shuly Wintner</author>
</authors>
<title>Unification grammars and off-line parsability.</title>
<date>2005</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="2274" citStr="Jaeger et al., 2005" startWordPosition="316" endWordPosition="319">l linguists to describe the structure of a variety of natural languages. Unification grammars are Turing equivalent: determining whether a given string is generated by a given grammar is as hard as deciding whether a Turing machine halts on the empty input (Johnson, 1988). Therefore, the recognition problem for unification grammars is undecidable in the general case. To ensure its decidability, several constraints on unification grammars, commonly known as the off-line parsability (OLP) constraints, were suggested, such that the recognition problem is decidable for off-line parsable grammars (Jaeger et al., 2005). The idea behind all the OLP definitions is to rule out grammars which license trees in which unbounded amount of material is generated without expanding the frontier word. This can happen due to two kinds of rules: c-rules (whose bodies are empty) and unit rules (whose bodies consist of a single element). However, even for unification grammars with no such rules the recognition problem is NP-hard (Barton et al., 1987). In order for a grammar formalism to make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Con</context>
</contexts>
<marker>Jaeger, Francez, Wintner, 2005</marker>
<rawString>Efrat Jaeger, Nissim Francez, and Shuly Wintner. 2005. Unification grammars and off-line parsability. Journal of Logic, Language and Information, 14(2):199–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Attribute-Value Logic and the Theory of Grammar,</title>
<date>1988</date>
<booktitle>CSLI Lecture Notes. CSLI,</booktitle>
<volume>16</volume>
<location>Stanford, California.</location>
<contexts>
<context position="1926" citStr="Johnson, 1988" startWordPosition="268" endWordPosition="270">ructures) in order to express additional information. They can describe phonological, morphological, syntactic and semantic properties of languages simultaneously and are thus linguistically suitable for modeling natural languages. Several formulations of unification grammars have been proposed, and they are used extensively by computational linguists to describe the structure of a variety of natural languages. Unification grammars are Turing equivalent: determining whether a given string is generated by a given grammar is as hard as deciding whether a Turing machine halts on the empty input (Johnson, 1988). Therefore, the recognition problem for unification grammars is undecidable in the general case. To ensure its decidability, several constraints on unification grammars, commonly known as the off-line parsability (OLP) constraints, were suggested, such that the recognition problem is decidable for off-line parsable grammars (Jaeger et al., 2005). The idea behind all the OLP definitions is to rule out grammars which license trees in which unbounded amount of material is generated without expanding the frontier word. This can happen due to two kinds of rules: c-rules (whose bodies are empty) an</context>
</contexts>
<marker>Johnson, 1988</marker>
<rawString>Mark Johnson. 1988. Attribute-Value Logic and the Theory of Grammar, volume 16 of CSLI Lecture Notes. CSLI, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Finite-state approximation of constraint-based grammars using left-corner grammar transforms.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics,</booktitle>
<pages>619--623</pages>
<contexts>
<context position="4313" citStr="Johnson, 1998" startWordPosition="627" endWordPosition="628">06 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work is to define constraints on UGs which naturally limit their generative capacity. We define two natural and easily testable syntactic constraints on UGs which ensure that grammars satisfying them generate the context-free and the mildly context-sensitive languages, respectively. The contribution of this result is twofold: • From a theoretical point of view, constraining unification grammars to generate exactly the class MCSL results in a grammatical formalism which is, on o</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. Finite-state approximation of constraint-based grammars using left-corner grammar transforms. In Proceedings of the 17th international conference on Computational linguistics, pages 619–623.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree Adjoining Grammars: How much context Sensitivity is required to provide a reasonable structural description. In</title>
<date>1985</date>
<booktitle>Natural Language Parsing,</booktitle>
<pages>206--250</pages>
<editor>D. Dowty, I. Karttunen, and A. Zwicky, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, U.K.</location>
<contexts>
<context position="5871" citStr="Joshi (1985)" startWordPosition="887" endWordPosition="888">section 2 and then show a constrained version of UG which generates the class CFL of context-free languages in section 3. Section 4 presents the main result, namely a restricted version of UG and a mapping of its grammars to LIG, establishing the proposition that such grammars generate exactly the class MCSL. For lack of space, we favor intuitive explanation over rigorous proofs; the full details can be found in Feinstein (2004). 2 Preliminary notions A CFG is a four-tuple Gcf = hVN, Vt, Rcf, Si where Vt is a set of terminals, VN is a set of non1The term mildly context-sensitive was coined by Joshi (1985), in reference to a less formally defined class of languages. Strictly speaking, what we call MCSL here is also known as the class of tree-adjoining languages. terminals, including the start symbol S, and Rcf is a set of productions, assumed to be in a normal form where each rule has either (zero or more) non-terminals or a single terminal in its body, and where the start symbol never occurs in the right hand side of rules. The set of all such context-free grammars is denoted CFGS. In a linear indexed grammar (LIG),2 strings are derived from nonterminals with an associated stack denoted A[l1 .</context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Aravind K. Joshi. 1985. Tree Adjoining Grammars: How much context Sensitivity is required to provide a reasonable structural description. In D. Dowty, I. Karttunen, and A. Zwicky, editors, Natural Language Parsing, pages 206–250. Cambridge University Press, Cambridge, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>2003</date>
<booktitle>The Oxford handbook of computational linguistics, chapter 26,</booktitle>
<pages>483--500</pages>
<editor>In Ruslan Mitkov, editor,</editor>
<publisher>Oxford university Press.</publisher>
<contexts>
<context position="3296" citStr="Joshi, 2003" startWordPosition="479" endWordPosition="480">et al., 1987). In order for a grammar formalism to make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of fou</context>
</contexts>
<marker>Joshi, 2003</marker>
<rawString>Aravind K. Joshi. 2003. Tree-adjoining grammars. In Ruslan Mitkov, editor, The Oxford handbook of computational linguistics, chapter 26, pages 483–500. Oxford university Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Kiefer</author>
<author>Hans-Ulrich Krieger</author>
</authors>
<title>A context-free superset approximation of unificationbased grammars.</title>
<date>2004</date>
<booktitle>New Developments in Parsing Technology,</booktitle>
<pages>229--250</pages>
<editor>In Harry Bunt, John Carroll, and Giorgio Satta, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="4240" citStr="Kiefer and Krieger, 2004" startWordPosition="615" endWordPosition="618">uistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work is to define constraints on UGs which naturally limit their generative capacity. We define two natural and easily testable syntactic constraints on UGs which ensure that grammars satisfying them generate the context-free and the mildly context-sensitive languages, respectively. The contribution of this result is twofold: • From a theoretical point of view, constraining unification grammars to generate</context>
</contexts>
<marker>Kiefer, Krieger, 2004</marker>
<rawString>Bernd Kiefer and Hans-Ulrich Krieger. 2004. A context-free superset approximation of unificationbased grammars. In Harry Bunt, John Carroll, and Giorgio Satta, editors, New Developments in Parsing Technology, pages 229–250. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Rebecca N Wright</author>
</authors>
<title>Finite-state approximation of phrase-structure grammars.</title>
<date>1997</date>
<booktitle>In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, Language, Speech and Communication, chapter 5,</booktitle>
<pages>149--174</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4297" citStr="Pereira and Wright, 1997" startWordPosition="623" endWordPosition="626">6, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work is to define constraints on UGs which naturally limit their generative capacity. We define two natural and easily testable syntactic constraints on UGs which ensure that grammars satisfying them generate the context-free and the mildly context-sensitive languages, respectively. The contribution of this result is twofold: • From a theoretical point of view, constraining unification grammars to generate exactly the class MCSL results in a grammatical formalis</context>
</contexts>
<marker>Pereira, Wright, 1997</marker>
<rawString>Fernando C. N. Pereira and Rebecca N. Wright. 1997. Finite-state approximation of phrase-structure grammars. In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, Language, Speech and Communication, chapter 5, pages 149– 174. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
</authors>
<title>Generalized phrase structure grammars, head grammars and natural language.</title>
<date>1984</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="3251" citStr="Pollard, 1984" startWordPosition="472" endWordPosition="473">les the recognition problem is NP-hard (Barton et al., 1987). In order for a grammar formalism to make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994)</context>
</contexts>
<marker>Pollard, 1984</marker>
<rawString>Carl Pollard. 1984. Generalized phrase structure grammars, head grammars and natural language. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
<author>John Dowding</author>
<author>Beth Ann Hockey</author>
</authors>
<title>A baseline method for compiling typed unification grammars into context free language models.</title>
<date>2001</date>
<booktitle>In Proceedings of EUROSPEECH 2001,</booktitle>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="4213" citStr="Rayner et al., 2001" startWordPosition="611" endWordPosition="614">on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work is to define constraints on UGs which naturally limit their generative capacity. We define two natural and easily testable syntactic constraints on UGs which ensure that grammars satisfying them generate the context-free and the mildly context-sensitive languages, respectively. The contribution of this result is twofold: • From a theoretical point of view, constraining unifi</context>
</contexts>
<marker>Rayner, Dowding, Hockey, 2001</marker>
<rawString>Manny Rayner, John Dowding, and Beth Ann Hockey. 2001. A baseline method for compiling typed unification grammars into context free language models. In Proceedings of EUROSPEECH 2001, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Tree-adjoining grammar parsing and boolean matrix multiplication.</title>
<date>1994</date>
<booktitle>In Proceedings of the 20st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>20</volume>
<contexts>
<context position="3851" citStr="Satta, 1994" startWordPosition="557" endWordPosition="558">llard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work is to define co</context>
</contexts>
<marker>Satta, 1994</marker>
<rawString>Giorgio Satta. 1994. Tree-adjoining grammar parsing and boolean matrix multiplication. In Proceedings of the 20st Annual Meeting of the Association for Computational Linguistics, volume 20.</rawString>
</citation>
<citation valid="true">
<title>The formal complexity of natural language,</title>
<date>1987</date>
<booktitle>of Studies in Linguistics and Philosophy.</booktitle>
<volume>33</volume>
<editor>Walter J. Savitch, Emmon Bach, William Marsh, and Gila Safran-Naveh, editors.</editor>
<location>Dordrecht.</location>
<marker>1987</marker>
<rawString>Walter J. Savitch, Emmon Bach, William Marsh, and Gila Safran-Naveh, editors. 1987. The formal complexity of natural language, volume 33 of Studies in Linguistics and Philosophy. D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification Based Approaches to Grammar.</title>
<date>1986</date>
<journal>Number</journal>
<booktitle>in CSLI Lecture Notes. CSLI.</booktitle>
<volume>4</volume>
<contexts>
<context position="1120" citStr="Shieber, 1986" startWordPosition="152" endWordPosition="153">fline parsable grammars, the problem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first show that non-reentrant unification grammars generate exactly the class of contextfree languages. We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages. 1 Introduction Unification grammars (UG) (Shieber, 1986; Shieber, 1992; Carpenter, 1992) have originated as an extension of context-free grammars, the basic idea being to augment the context-free rules with non context-free annotations (feature structures) in order to express additional information. They can describe phonological, morphological, syntactic and semantic properties of languages simultaneously and are thus linguistically suitable for modeling natural languages. Several formulations of unification grammars have been proposed, and they are used extensively by computational linguists to describe the structure of a variety of natural lang</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Stuart M. Shieber. 1986. An Introduction to Unification Based Approaches to Grammar. Number 4 in CSLI Lecture Notes. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Constraint-Based Grammar Formalisms.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="1135" citStr="Shieber, 1992" startWordPosition="154" endWordPosition="155">grammars, the problem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first show that non-reentrant unification grammars generate exactly the class of contextfree languages. We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages. 1 Introduction Unification grammars (UG) (Shieber, 1986; Shieber, 1992; Carpenter, 1992) have originated as an extension of context-free grammars, the basic idea being to augment the context-free rules with non context-free annotations (feature structures) in order to express additional information. They can describe phonological, morphological, syntactic and semantic properties of languages simultaneously and are thus linguistically suitable for modeling natural languages. Several formulations of unification grammars have been proposed, and they are used extensively by computational linguists to describe the structure of a variety of natural languages. Unificat</context>
</contexts>
<marker>Shieber, 1992</marker>
<rawString>Stuart M. Shieber. 1992. Constraint-Based Grammar Formalisms. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process. Language, Speech and Communication.</title>
<date>2000</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="3349" citStr="Steedman, 2000" startWordPosition="486" endWordPosition="487"> make predictions about the structure of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivat</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. Language, Speech and Communication. The MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>Parsing some constrained grammar formalisms.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>4</issue>
<pages>636</pages>
<contexts>
<context position="3837" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="553" endWordPosition="556">zdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considered to be linguistically meaningful, a natural class of languages for characterizing natural languages. Several authors tried to approximate unification grammars by means of context-free grammars (Rayner et al., 2001; Kiefer and Krieger, 2004) and even finite-state grammars (Pereira and Wright, 1997; Johnson, 1998), but we are not aware of any work which relates unification grammars with the class MCSL. The main objective of this work i</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1993</marker>
<rawString>K. Vijay-Shanker and David J. Weir. 1993. Parsing some constrained grammar formalisms. Computational Linguistics, 19(4):591 – 636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
</authors>
<title>The equivalence of four extensions of context-free grammars.</title>
<date>1994</date>
<booktitle>Mathematical systems theory,</booktitle>
<pages>27--511</pages>
<contexts>
<context position="3399" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="492" endWordPosition="495">e of natural language its generative capacity must be constrained. It is now generally accepted that Context-free Grammars (CFGs) lack the generative power needed for this purpose (Savitch et al., 1987), due to natural language constructions such as reduplication, multiple agreement and crossed agreement. Several linguistic formalisms have been proposed as capable of modeling these phenomena, including Linear Indexed Grammars (LIG) (Gazdar, 1988), Head Grammars (Pollard, 1984), Tree Adjoining Grammars (TAG) (Joshi, 2003) and Combinatory Categorial Grammars (Steedman, 2000). In a seminal work, Vijay-Shanker and Weir (1994) prove that all four formalisms are weakly equivalent. They all generate the class of mildly context-sensitive languages (MCSL), all members 1089 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089–1096, Sydney, July 2006. c�2006 Association for Computational Linguistics of which have recognition algorithms with time complexity O(n6) (Vijay-Shanker and Weir, 1993; Satta, 1994).1 As a result of the weak equivalence of four independently developed (and linguistically motivated) extensions of CFG, the class MCSL is considere</context>
<context position="7998" citStr="Vijay-Shanker and Weir (1994)" startWordPosition="1314" endWordPosition="1317">)∗. A crucial characteristic of LIG is that only one copy of the stack can be copied to a single element in the body of a rule. If more than one copy were allowed, the expressive power would grow beyond MCSL. Definition 2. Given a LIG hVN, Vt, Vs, Rli, Si, the derivation relation ‘⇒li’ is defined as follows: for all XF1,XF2 ∈ (VN[Vs∗]∪Vt)∗andη∈Vs∗, • If Ni[p1 ... pn] &apos;F1Ni[p1 ... pn]&apos;F2 ⇒li I&amp;1α&apos;&amp;2 • If Ni[p1 ... pn ∞] → α ∈ Rli then &apos;F1Ni[p1 . . .pnη]*2 ⇒li qf1αXF2 • If Ni[p1 ... pn ∞] → αNj[q1 ... qm ∞]β ∈ Rli then IF1Ni[p1 . . . pnη] 2 ⇒li &apos;F1αNj[q1 ... qmη]β&apos;&amp;2 2The definition is based on Vijay-Shanker and Weir (1994). → α ∈ Rli then 1090 The language generated by Gli is L(Gli) = {w ∈ V∗ t |S[ ] ∗⇒li w}, where ‘∗⇒li’ is the reflexive, transitive closure of ‘⇒li’. Unification grammars are defined over feature structures (FSs) which are directed, connected, rooted, labeled graphs, usually depicted as attribute-value matrices (AVM). A feature structure A can be characterized by its set of paths, IIA, an assignment of atomic values to the ends of some paths, OA(·), and a reentrancy relation ‘*&amp;quot;’ relating paths which lead to the same node. A sequence of feature structures, where some nodes may be shared by more</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1994</marker>
<rawString>K. Vijay-Shanker and David J. Weir. 1994. The equivalence of four extensions of context-free grammars. Mathematical systems theory, 27:511–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Weir</author>
</authors>
<title>A geometric hierarchy beyond context-free languages.</title>
<date>1992</date>
<journal>Theoretical Computer Science,</journal>
<pages>104--235</pages>
<contexts>
<context position="29747" citStr="Weir (1992)" startWordPosition="5466" endWordPosition="5467"> the expressivity of the formalism. We leave the formal details of such an extension to future work. This work can also be extended in other directions. The mapping of one-reentrant UGs to LIG is highly verbose, resulting in LIGs with a huge 1095 number of rules. We believe that it should be possible to optimize the mapping such that much smaller grammars are generated. In particular, we are looking into mappings of one-reentrant UGs to other MCSL formalisms, notably TAG. The two constraints on unification grammars (non-reentrant and one-reentrant) are parallel to the first two classes of the Weir (1992) hierarchy of languages. A possible extension of this work could be a definition of constraints on unification grammars that would generate all the classes of the hierarchy. Another direction is an extension of one-reentrant unification grammars, where the reentrancy does not have to be between the head and one element of the body. Also of interest are two-reentrant unification grammars, possibly with limited kinds of reentrancies. Acknowledgments This research was supported by The Israel Science Foundation (grant no. 136/01). We are grateful to Yael Cohen-Sygal, Nissim Francez and James Roger</context>
</contexts>
<marker>Weir, 1992</marker>
<rawString>David J. Weir. 1992. A geometric hierarchy beyond context-free languages. Theoretical Computer Science, 104:235–261.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>