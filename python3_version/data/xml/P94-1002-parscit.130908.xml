<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000337">
<sectionHeader confidence="0.7599035" genericHeader="abstract">
MULTI-PARAGRAPH SEGMENTATION OF
EXPOSITORY TEXT
</sectionHeader>
<author confidence="0.946716">
Marti A. Hearst
</author>
<affiliation confidence="0.998005">
Computer Science Division, 571 Evans Hall
University of California, Berkeley
</affiliation>
<address confidence="0.687706">
Berkeley, CA 94720
and
Xerox Palo Alto Research Center
</address>
<email confidence="0.994684">
marti@cs.berkeley.edu
</email>
<sectionHeader confidence="0.996606" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.9999532">
This paper describes TextTiling, an algorithm for parti-
tioning expository texts into coherent multi-paragraph
discourse units which reflect the subtopic structure of
the texts. The algorithm uses domain-independent lex-
ical frequency and distribution information to recog-
nize the interactions of multiple simultaneous themes.
Two fully-implemented versions of the algorithm are de-
scribed and shown to produce segmentation that corre-
sponds well to human judgments of the major subtopic
boundaries of thirteen lengthy texts.
</bodyText>
<sectionHeader confidence="0.997908" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999737285714286">
The structure of expository texts can be characterized
as a sequence of subtopical discussions that occur in the
context of a few main topic discussions. For example, a
popular science text called Stargazers, whose main topic
is the existence of life on earth and other planets, can be
described as consisting of the following subdiscussions
(numbers indicate paragraph numbers):
</bodyText>
<footnote confidence="0.993963166666667">
1-3 Intro — the search .for life in space
4-5 The moon&apos;s chemical composition
6-8 How early proximity of the moon shaped it
9-12 How the moon helped life evolve on earth
13 Improbability of the earth-moon system
14-16 Binary/trinary star systems make life un-
</footnote>
<figure confidence="0.4537088">
likely
17-18 The low probability of non-binary/trinary
systems
19-20 Properties of our sun that facilitate life
21 Summary
</figure>
<bodyText confidence="0.999173477272727">
Subtopic structure is sometimes marked in techni-
cal texts by headings and subheadings which divide the
text into coherent segments; Brown &amp; Yule (1983:140)
state that this kind of division is one of the most basic
in discourse. However, many expository texts consist of
long sequences of paragraphs with very little structural
demarcation. This paper presents fully-implemented al-
gorithms that use lexical cohesion relations to partition
expository texts into multi-paragraph segments that re-
flect their subtopic structure. Because the model of dis-
course structure is one in which text is partitioned into
contiguous, nonoverlapping blocks, I call the general
approach TextTiling. The ultimate goal is to not only
identify the extents of the subtopical units, but to label
their contents as well. This paper focusses only on the
discovery of subtopic structure, leaving determination
of subtopic content to future work.
Most discourse segmentation work is done at a finer
granularity than that suggested here. However, for
lengthy written expository texts, multi-paragraph seg-
mentation has many potential uses, including the im-
provement of computational tasks that make use of dis-
tributional information. For example, disambiguation
algorithms that train on arbitrary-size text windows,
e.g., Yarowsky (1992) and Gale et a/. (1992b), and al-
gorithms that use lexical co-occurrence to determine se-
mantic relatedness, e.g., Schiitze (1993), might benefit
from using windows with motivated boundaries instead.
Information retrieval algorithms can use subtopic
structuring to return meaningful portions of a text if
paragraphs are too short and sections are too long
(or are not present). Motivated segments can also be
used as a more meaningful unit for indexing long texts.
Salton et at. (1993), working with encyclopedia text,
find that comparing a query against sections and then
paragraphs is more successful than comparing against
full documents alone. I have used the results of Text-
Tiling in a new paradigm for information access on full-
text documents (Hearst 1994).
The next section describes the discourse model that
motivates the approach. This is followed by a descrip-
tion of two algorithms for subtopic structuring that
make use only of lexical cohesion relations, the evalua-
tion of these algorithms, and a summary and discussion
</bodyText>
<page confidence="0.994523">
9
</page>
<bodyText confidence="0.768905">
of future work.
</bodyText>
<sectionHeader confidence="0.916163" genericHeader="method">
THE DISCOURSE MODEL
</sectionHeader>
<bodyText confidence="0.994282111111111">
Many discourse models assume a hierarchical segmen-
tation model, e.g., attentional/intentional structure
(Grosz &amp; Sidner 1986) and Rhetorical Structure Theory
(Mann &amp; Thompson 1987). Although many aspects of
discourse analysis require such a model, I choose to cast
expository text into a linear sequence of segments, both
for computational simplicity and because such a struc-
ture is sufficient for the coarse-grained tasks of interest
here.&apos;
</bodyText>
<figure confidence="0.99182325">
Chained
Ringed
Monolith
Piecewise
</figure>
<figureCaption confidence="0.996662333333333">
Figure 1: Skorochod&apos;ko&apos;s text structure types. Nodes
correspond to sentences and edges between nodes indi-
cate strong term overlap between the sentences.
</figureCaption>
<bodyText confidence="0.985593223684211">
Skorochod&apos;ko (1972) suggests discovering a text&apos;s
structure by dividing it up into sentences and seeing
how much word overlap appears among the sentences.
The overlap forms a kind of intra-structure; fully con-
nected graphs might indicate dense discussions of a
topic, while long spindly chains of connectivity might
indicate a sequential account (see Figure 1). The cen-
tral idea is that of defining the structure of a text as a
function of the connectivity patterns of the terms that
comprise it. This is in contrast with segmenting guided
primarily by fine-grained discourse cues such as register
change, focus shift, and cue words. From a computa-
tional viewpoint, deducing textual topic structure from
lexical connectivity alone is appealing, both because it
is easy to compute, and also because discourse cues are
sometimes misleading with respect to the topic struc-
ture (Brown &amp; Yule 1983)(§3).
I Additionally, (Passonneau 8.6 Litman 1993) concede the
difficulty of eliciting hierarchical intentional structure with
any degree of consistency from their human judges.
The topology most of interest to this work is the final
one in the diagram, the Piecewise Monolithic Structure,
since it represents sequences of densely interrelated dis-
cussions linked together, one after another. This topol-
ogy maps nicely onto that of viewing documents as a
sequence of densely interrelated subtopical discussions,
one following another. This assumption, as will be seen,
is not always valid, but is nevertheless quite useful.
This theoretical stance bears a close resemblance to
Chafe&apos;s notion of The Flow Model of discourse (Chafe
1979), in description of which he writes (pp 179-180):
Our data.., suggest that as a speaker moves from
focus to focus (or from thought to thought) there
are certain points at which there may be a more or
less radical change in space, time, character config-
uration, event structure, or, even, world. ... At
points where all of these change in a maximal way,
an episode boundary is strongly present. But often
one or another will change considerably while oth-
ers will change less radically, and all kinds of var-
ied interactions between these several factors are
possible.2
Although Chafe&apos;s work concerns narrative text, the
same kind of observation applies to expository text.
The TextTiling algorithms are designed to recognize
episode boundaries by determining where thematic
components like those listed by Chafe change in a max-
imal way.
Many researchers have studied the patterns of occur-
rence of characters, setting, time, and the other the-
matic factors that Chafe mentions, usually in the con-
text of narrative. In contrast, I attempt to determine
where a relatively large set of active themes changes
simultaneously, regardless of the type of thematic fac-
tor. This is especially important in expository text in
which the subject matter tends to structure the dis-
course more so than characters, setting, etc. For ex-
ample, in the Stargazers text, a discussion of continen-
tal movement, shoreline acreage, and habitability gives
way to a discussion of binary and unary star systems.
This is not so much a change in setting or character
as a change in subject matter. Therefore, to recognize
where the subtopic changes occur, I make use of lexical
cohesion relations (Halliday &amp; Hasan 1976) in a manner
similar to that suggested by Skorochod&apos;ko.
Morris and Hirst&apos;s pioneering work on computing dis-
course structure from lexical relations (Morris &amp; Hirst
1991), (Morris 1988) is a precursor to the work reported
on here. Influenced by Halliday &amp; Hasan&apos;s (1976) the-
ory of lexical coherence, Morris developed an algorithm
that finds chains of related terms via a comprehensive
thesaurus (Roget&apos;s Fourth Edition).3 For example, the
2Interestingly, Chafe arrived at the Flow Model after
working extensively with, and then becoming dissatisfied
with, a hierarchical model of paragraph structure like that
of Longacre (1979).
</bodyText>
<footnote confidence="0.987702">
3The algorithm is executed by hand since the thesaurus
</footnote>
<page confidence="0.993152">
10
</page>
<table confidence="0.9769155625">
Sentence: 05 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95
14 form 1 111 1 1 11 1 1 1 1 1 1
8 scientist 11 1 1 1 1 1 1
5 space 11 1 1 1
25 star 1 1 11 22 111112 1 1 1 11 1111 1
5 binary 11 1 1 1
4 trinary 1 1 1 1
8 astronomer 1 1 11 1 1 1 1
7 orbit 1 1 12 1 1
6 pull 2 11 1 1
16 planet 1 1 11 1 1 21 11111 1 1
7 galaxy 1 1 1 11 1 1
4 lunar 1 1 1
19 life 1 1 1 1 11 1 11 1 1 11 1 111 1 1
27 moon 13 1111 1 1 22 21 21 21 11
3 move 1 1 1
</table>
<figure confidence="0.886056571428571">
7 continent 2 1 1 2 1
3 shoreline 12
6 time 1 1 1 1 1 1
3 water 11 1
6 say 11 1 11
3 species 1 1 1
Sentence: 05 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95
</figure>
<figureCaption confidence="0.9961425">
Figure 2: Distribution of selected terms from the Stargazer text, with a single digit frequency per sentence number
(blanks indicate a frequency of zero).
</figureCaption>
<bodyText confidence="0.999685704545454">
words residential and apartment both index the same
thesaural category and can thus be considered to be
in a coherence relation with one another. The chains
are used to structure texts according to the atten-
tional/intentional theory of discourse structure (Grosz
Sidner 1986), and the extent of the chains correspond
to the extent of a segment. The algorithm also incorpo-
rates the notion of &amp;quot;chain returns&amp;quot; — repetition of terms
after a long hiatus — to close off an intention that spans
over a digression.
Since the Morris St Hirst (1991) algorithm attempts
to discover attentional/intentional structure, their goals
are different than those of TextTiling. Specifically, the
discourse structure they attempt to discover is hierar-
chical and more fine-grained than that discussed here.
Thus their model is not set up to take advantage of
the fact that multiple simultaneous chains might occur
over the same intention. Furthermore, chains tend to
overlap one another extensively in long texts. Figure 2
shows the distribution, by sentence number, of selected
terms from the Stargazers text. The first two terms
have fairly uniform distribution and so should not be
expected to provide much information about the di-
visions of the discussion. The next two terms occur
mainly at the beginning and the end of the text, while
terms binary through planet have considerable overlap
is not generally available online.
from sentences 58 to 78. There is a somewhat well-
demarked cluster of terms between sentences 35 and 50,
corresponding to the grouping together of paragraphs
10, 11, and 12 by human judges who have read the text.
From the diagram it is evident that simply looking
for chains of repeated terms is not sufficient for deter-
mining subtopic breaks. Even combining terms that are
closely related semantically into single chains is insuf-
ficient, since often several different themes are active
in the same segment. For example, sentences 37 - 51
contain dense interaction among the terms move, con-
tinent, shoreline, time, species, and life, and all but the
latter occur only in this region. However, it is the case
that the interlinked terms of sentences 57 - 71 (space,
star, binary, trinary, astronomer, orbit) are closely re-
lated semantically, assuming the appropriate senses of
the terms have been determined.
</bodyText>
<sectionHeader confidence="0.9981625" genericHeader="method">
ALGORITHMS FOR DISCOVERING
SUBTOPIC STRUCTURE
</sectionHeader>
<bodyText confidence="0.999934857142857">
Many researchers (e.g., Halliday St Hasan (1976), Tan-
nen (1989), Walker (1991)) have noted that term rep-
etition is a strong cohesion indicator. I have found in
this work that term repetition alone is a very useful in-
dicator of subtopic structure, when analyzed in terms
of multiple simultaneous information threads. This sec-
tion describes two algorithms for discovering subtopic
</bodyText>
<page confidence="0.995398">
11
</page>
<bodyText confidence="0.999905625">
structure using term repetition as a lexical cohesion in-
dicator.
The first method compares, for a given window size,
each pair of adjacent blocks of text according to how
similar they are lexically. This method assumes that the
more similar two blocks of text are, the more likely it is
that the current subtopic continues, and, conversely, if
two adjacent blocks of text are dissimilar, this implies a
change in subtopic flow. The second method, an exten-
sion of Morris Si Hirst&apos;s (1991) approach, keeps track
of active chains of repeated terms, where membership
in a chain is determined by location in the text. The
method determines subtopic flow by recording where in
the discourse the bulk of one set of chains ends and a
new set of chains begins.
The core algorithm has three main parts:
</bodyText>
<listItem confidence="0.988305666666667">
1. Tokenization
2. Similarity Determination
3. Boundary Identification
</listItem>
<bodyText confidence="0.989364561797753">
Tokenization refers to the division of the input text
into individual lexical units. For both versions of the
algorithm, the text is subdivided into psuedosentences
of a pre-defined size w (a parameter of the algorithm)
rather than actual syntactically-determined sentences,
thus circumventing normalization problems. For the
purposes of the rest of the discussion these groupings of
tokens will be referred to as token-seguences. In prac-
tice, setting w to 20 tokens per token-sequence works
best for many texts. The morphologically-analyzed to-
ken is stored in a table along with a record of the token-
sequence number it occurred in, and how frequently it
appeared in the token-sequence. A record is also kept of
the locations of the paragraph breaks within the text.
Closed-class and other very frequent words are elimi-
nated from the analysis.
After tokenization, the next step is the comparison
of adjacent pairs of blocks of token-sequences for over-
all lexical similarity. Another important parameter for
the algorithm is the blocksize: the number of token-
sequences that are grouped together into a block to be
compared against an adjacent group of token-sequences.
This value, labeled k, varies slightly from text to text;
as a heuristic it is the average paragraph length (in
token-sequences). In practice, a value of k = 6 works
well for many texts. Actual paragraphs are not used
because their lengths can be highly irregular, leading
to unbalanced comparisons.
Similarity values are computed for every token-
sequence gap number; that is, a score is assigned to
token-sequence gap i corresponding to how similar the
token-sequences from token-sequence i—k through i are
to the token-sequences from i +1 to i+ k +1. Note that
this moving window approach means that each token-
sequence appears in k * 2 similarity computations.
Similarity between blocks is calculated by a cosine
measure: given two text blocks b1 and 62, each with k
token-sequences,
E, uh,b1wi,b2
VE, &apos;4,bl Ent-1 &apos;14,b2
where t ranges over all the terms that have been reg-
istered during the tokenization step, and wt,bi is the
weight assigned to term t in block 61. In this version
of the algorithm, the weights on the terms are simply
their frequency within the block.4 Thus if the similarity
score between two blocks is high, then the blocks have
many terms in common. This formula yields a score
between 0 and 1, inclusive.
These scores can be plotted, token-sequence number
against similarity score. However, since similarity is
measured between blocks b1 and 62, where b1 spans
token-sequences i k through i and 62 spans i + 1 to
i + k +1, the measurement&apos;s x-axis coordinate falls be-
tween token-sequences i and i + 1. Rather than plot-
ting a token-sequence number on the x-axis, we plot
token-sequence gap number i. The plot is smoothed
with average smoothing; in practice one round of aver-
age smoothing with a window size of three works best
for most texts.
Boundaries are determined by changes in the se-
quence of similarity scores. The token-sequence gap
numbers are ordered according to how steeply the slopes
of the plot are to either side of the token-sequence gap,
rather than by their absolute similarity score. For a
given token-sequence gap i, the algorithm looks at the
scores of the token-sequence gaps to the left of i as long
are their values are increasing. When the values to the
left peak out, the difference between the score at the
peak and the score at i is recorded. The same proce-
dure takes place with the token-sequence gaps to the
right of i; their scores are examined as long as they
continue to rise. The relative height of the peak to the
right of i is added to the relative height of the peak to
the left. (A gap occurring at a peak will have a score
of zero since neither of its neighbors is higher than it.)
These new scores, called depth scores, corresponding to
how sharp a change occurs on both sides of the token-
sequence gap, are then sorted. Segment boundaries are
assigned to the token-sequence gaps with the largest
corresponding scores, adjusted as necessary to corre-
spond to true paragraph breaks. A proviso check is
done that prevents assignment of very close adjacent
segment boundaries. Currently there must be at least
three intervening token-sequences between boundaries.
This helps control for the fact that many texts have
spurious header information and single-sentence para-
graphs.
The algorithm must determine how many segments
to assigned to a document, since every paragraph is a
</bodyText>
<footnote confidence="0.82951175">
4Earlier work weighted the terms according to their fre-
quency times their inverse document frequency. In these
more recent experiments, simple term frequencies seem to
work better.
</footnote>
<note confidence="0.385864">
sim(bi , ba)
</note>
<page confidence="0.935687">
12
</page>
<figure confidence="0.969005888888889">
•NIN Miia•M• MMNIMMI WWWWMi _
_MIN= IMMMIEMMIIR MMI■IMM MOMMWS MWMNIMS
INNWIIMEVE MMUNIMMOMMEMill limwsimmerwromrmwwwW1 iNiMniffiliMMENEM
_IMMINNI • IMMNIMMIII■M Mil MUM OMEN MaNIMIMMWMUMMI UMMNIONMINIMI MEM _
■ININ MOB MINIMMMUON UMMIN INMNNTINILIMMI IIMMIMME MEE _
_EWEN •111111111•111I 11•1=11131:11=g1.211:5111111 111111211111111B11 11211111111111:1111=1.111111 _
Jrnillit. =NRROMINi=Ni
• • 6 7 0 10 11 16 Is 14 v6 IS 17 IS 10 SO
1 0 20 20 • 0 SO 00 70 DO • 00
</figure>
<figureCaption confidence="0.99985275">
Figure 3: Judgments of seven readers on the Stargazer text. Internal numbers indicate location of gaps between
paragraphs; x-axis indicates token-sequence gap number, y-axis indicates judge number, a break in a horizontal line
indicates a judge-specified segment break.
Figure 4: Results of the block similarity algorithm on the Stargazer text. Internal numbers indicate paragraph
numbers, x-axis indicates token-sequence gap number, y-axis indicates similarity between blocks centered at the
corresponding token-sequence gap. Vertical lines indicate boundaries chosen by the algorithm; for example, the
leftmost vertical line represents a boundary after paragraph 3. Note how these align with the boundary gaps of
Figure 3 above.
</figureCaption>
<bodyText confidence="0.99971475">
potential segment boundary. Any attempt to make an
absolute cutoff is problematic since there would need
to be some correspondence to the document style and
length. A cutoff based on a particular valley depth is
similarly problematic.
I have devised a method for determining the number
of boundaries to assign that scales with the size of the
document and is sensitive to the patterns of similarity
scores that it produces: the cutoff is a function of the
average and standard deviations of the depth scores for
the text under analysis. Currently a boundary is drawn
only if the depth score exceeds g — a/2.
</bodyText>
<sectionHeader confidence="0.96828" genericHeader="evaluation">
EVALUATION
</sectionHeader>
<bodyText confidence="0.99992125">
One way to evaluate these segmentation algorithms is
to compare against judgments made by human readers,
another is to compare the algorithms against texts pre-
marked by authors, and a third way is to see how well
the results improve a computational task. This section
compares the algorithm against reader judgments, since
author markups are fallible and are usually applied to
text types that this algorithm is not designed for, and
Hearst (1994) shows how to use TextTiles in a task
(although it does not show whether or not the results
of the algorithms used here are better than some other
algorithm with similar goals).
</bodyText>
<subsectionHeader confidence="0.785845">
Reader Judgments
</subsectionHeader>
<bodyText confidence="0.782689555555555">
Judgments were obtained from seven readers for each
of thirteen magazine articles which satisfied the length
criteria (between 1800 and 2500 words)5 and which
contained little structural demarkation. The judges
50ne longer text of 2932 words was used since reader
judgments had been obtained for it from an earlier ex-
periment. Judges were technical researchers. Two texts
had three or four short headers which were removed for
consistency.
</bodyText>
<page confidence="0.99856">
13
</page>
<bodyText confidence="0.999968513513514">
were asked simply to mark the paragraph boundaries
at which the topic changed; they were not given more
explicit instructions about the granularity of the seg-
mentation.
Figure 3 shows the boundaries marked by seven
judges on the Stargazers text. This format helps il-
lustrate the general trends made by the judges and
also helps show where and how often they disagree.
For instance, all but one judge marked a boundary be-
tween paragraphs 2 and 3. The dissenting judge did
mark a boundary after 3, as did two of the concurring
judges. The next three major boundaries occur after
paragraphs 5, 9, 12, and 13. There is some contention
in the later paragraphs; three readers marked both 16
and 18, two marked 18 alone, and two marked 17 alone.
The outline in the Introduction gives an idea of what
each segment is about.
Passonneau &amp; Litman (1993) discuss at length con-
siderations about evaluating segmentation algorithms
according to reader judgment information. As Figure 3
shows, agreement among judges is imperfect, but trends
can be discerned. In Passonneau &amp; Litman&apos;s (1993)
data, if 4 or more out of 7 judges mark a boundary, the
segmentation is found to be significant using a variation
of the Q-test (Cochran 1950). My data showed similar
results. However, it isn&apos;t clear how useful this signifi-
cance information is, since a simple majority does not
provide overwhelming proof about the objective real-
ity of the subtopic break. Since readers often disagree
about where to draw a boundary marking for a topic
shift, one can only use the general trends as a basis
from which to compare different algorithms. Since the
goals of TextTiling are better served by algorithms that
produce more rather than fewer boundaries, I set the
cutoff for &amp;quot;true&amp;quot; boundaries to three rather than four
judges per paragraph.6 The remaining gaps are consid-
ered nonboundaries.
</bodyText>
<sectionHeader confidence="0.79474" genericHeader="evaluation">
Results
</sectionHeader>
<bodyText confidence="0.989669220779221">
Figure 4 shows a plot of the results of applying the block
comparison algorithm to the Stargazer text. When the
lowermost portion of a valley is not located at a para-
graph gap, the judgment is moved to the nearest para-
graph gap.7 For the most part, the regions of strong
similarity correspond to the regions of strong agree-
ment among the readers. (The results for this text were
fifth highest out of the 13 test texts.) Note however,
that the similarity information around paragraph 12 is
weak. This paragraph briefly summarizes the contents
of the previous three paragraphs; much of the terminol-
&apos;Paragraphs of three or fewer sentences were combined
with their neighbor if that neighbor was deemed to follow at
&amp;quot;true&amp;quot; boundary, as in paragraphs 2 and 3 of the Stargazers
text.
&apos;This might be explained in part by (Stark 1988) who
shows that readers disagree measurably about where to
place paragraph boundaries when presented with texts with
those boundaries removed,
ogy that occurred in all of them reappears in this one
location (in the spirit of a Grosz &amp; Sidner (1986) &amp;quot;pop&amp;quot;
operation). Thus it displays low similarity both to itself
and to its neighbors. This is an example of a breakdown
caused by the assumptions about the subtopic struc-
ture. It is possible that an additional pass through the
text could be used to find structure of this kind.
The final paragraph is a summary of the entire text;
the algorithm recognizes the change in terminology
from the preceding paragraphs and marks a boundary;
only two of the readers chose to differentiate the sum-
mary; for this reason the algorithm is judged to have
made an error even though this sectioning decision is
reasonable. This illustrates the inherent fallibility of
testing against reader judgments, although in part this
is because the judges were given loose constraints.
Following the advice of Gale et al. (1992a), I compare
the algorithm against both upper and lower bounds.
The upper bound in this case is the reader judgment
data. The lower bound is a baseline algorithm that is
a simple, reasonable approach to the problem that can
be automated. A simple way to segment the texts is
to place boundaries randomly in the document, con-
straining the number of boundaries to equal that of the
average number of paragraph gaps assigned by judges.
In the test data, boundaries are placed in about 41% of
the paragraph gaps. A program was written that places
a boundary at each potential gap 41% of the time (us-
ing a random number generator), and run 10,000 times
for each text, and the average of the scores of these runs
was found. These scores appear in Table 1 (results at
33% are also shown for comparison purposes).
The algorithms are evaluated according to how many
true boundaries they select out of the total selected
(precision) and how many true boundaries are found out
of the total possible (recall) (Salton 1988). The recall
measure implicitly signals the number of missed bound-
aries (false negatives, or deletion errors); the number of
false positives, or insertion errors, is indicated explic-
itly.
In many cases the algorithms are almost correct but
off by one paragraph, especially in the texts that the al-
gorithm performs poorly on. When the block similarity
algorithm is allowed to be off by one paragraph, there is
dramatic improvement in the scores for the texts that
lower part of Table 2, yielding an overall precision of
83% and recall of 78%. As in Figure 4, it is often the
case that where the algorithm is incorrect, e.g., para-
graph gap 11, the overall blocking is very close to what
the judges intended.
Table 1 shows that both the blocking algorithm and
the chaining algorithm are sandwiched between the up-
per and lower bounds. Table 2 shows some of these
results in more detail. The block similarity algorithm
seems to work slightly better than the chaining algo-
rithm, although the difference may not prove significant
over the long run. Furthermore, in both versions of the
algorithm, changes to the parameters of the algorithm
</bodyText>
<page confidence="0.997869">
14
</page>
<table confidence="0.999937285714286">
Precision Recall
s a s
Baseline 33% 33% .44 .08 .37 .04
Baseline 41% .43 .08 .42 .03
Chains .64 .17 .58 .17
Blocks .66 .18 .61 .13
Judges .81 .06 .71 .06
</table>
<tableCaption confidence="0.999913">
Table 1: Precision and Recall values for 13 test texts.
</tableCaption>
<bodyText confidence="0.99918875">
perturbs the resulting boundary markings. This is an
undesirable property and perhaps could be remedied
with some kind of information-theoretic formulation of
the problem.
</bodyText>
<sectionHeader confidence="0.999385" genericHeader="conclusions">
SUMMARY AND FUTURE WORK
</sectionHeader>
<bodyText confidence="0.999990409090909">
This paper has described algorithms for the segmen-
tation of expository texts into discourse units that re-
flect the subtopic structure of expository text. I have
introduced the notion of the recognition of multiple si-
multaneous themes, which bears some resemblance to
.Chafe&apos;s Flow Model of discourse and Skorochod&apos;ko&apos;s
text structure types. The algorithms are fully imple-
mented: term repetition alone, without use of thesaural
relations, knowledge bases, or inference mechanisms,
works well for many of the experimental texts. The
structure it obtains is coarse-grained but generally re-
flects human judgment data.
Earlier work (Hearst 1993) incorporated thesaural
information into the algorithms; surprisingly the lat-
est experiments find that this information degrades the
performance. This could very well be due to problems
with the algorithm used. A simple algorithm that just
posits relations among terms that are a small distance
apart according to WordNet (Miller et a/. 1990) or Ro-
get&apos;s 1911 thesaurus (from Project Gutenberg), mod-
eled after Morris and Hirst&apos;s heuristics, might work bet-
ter. Therefore I do not feel the issue is closed, and in-
stead consider successful grouping of related words as
future work. As another possible alternative Kozima
(1993) has suggested using a (computationally expen-
sive) semantic similarity metric to find similarity among
terms within a small window of text (5 to 7 words).
This work does not incorporate the notion of multi-
ple simultaneous themes but instead just tries to find
breaks in semantic similarity among a small number
of terms. A good strategy may be to substitute this
kind of similarity information for term repetition in al-
gorithms like those described here. Another possibility
would be to use semantic similarity information as com-
puted in Schiitze (1993), Resnik (1993), or Dagan et al.
(1993).
The use of discourse cues for detection of segment
boundaries and other discourse purposes has been ex-
tensively researched, although predominantly on spo-
ken text (see Hirschberg &amp; Litman (1993) for a sum-
mary of six research groups&apos; treatments of 64 cue
words). It is possible that incorporation of such in-
formation may provide a relatively simple way improve
the cases where the algorithm is off by one paragraph.
</bodyText>
<sectionHeader confidence="0.99135" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999943666666667">
This paper has benefited from the comments of Graeme
Hirst, Jan Pedersen, Penni Sibun, and Jeff Siskind. I
would like to thank Anne Fontaine for her interest and
help in the early stages of this work, and Robert Wilen-
sky for supporting this line of research. This work was
sponsored in part by the Advanced Research Projects
Agency under Grant No. MDA972-92-J-1029 with the
Corporation for National Research Initiatives (CNRI),
and by the Xerox Palo Alto Research Center.
</bodyText>
<sectionHeader confidence="0.996479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998676743589743">
BROWN, GILLIAN, &amp; GEORGE YULE. 1983. Discourse Anal-
ysis. Cambridge Textbooks in Linguistics Series. Cam-
bridge University Press.
CHAFE, WALLACE L. 1979. The flow of thought and the
flow of language. In Syntax and Semantics: Discourse
and Syntax, ed. by Talmy Givon, volume 12, 159-182.
Academic Press.
COCHRAN, W. G. 1950. The comparison of percentages in
matched samples. Biometrika 37.256-266.
DAGAN, IDO, SI4AUL MARCUS, &amp; SHAUL MARKOVITCH.
1993. Contextual word similarity and estimation from
sparse data. In Proceedings of the 3Ith Annual Meet-
ing of the Association for Computational Linguistics,
164-171.
GALE, WILLIAM A., KENNETH W. CHURCH, &amp; DAVID
YAROWSKY. 1992a. Estimating upper and lower
bounds on the performance of word-sense disambigua-
tion programs. In Proceedings of the 30th Meeting of
the Association for Computational Linguistics, 249-
256.
&amp; 1992b. A method for disambiguating
word senses in a large corpus. Computers and the Hu-
manities 5-6.415-439.
GROSZ, BARBARA J., &amp; CANDACE L. SIDNER. 1986. Atten-
tion, intention, and the structure of discourse. Compu-
tational Linguistics 12.172-204.
HALLIDAY, M. A. K., &amp; R. HASAN. 1976. Cohesion in
English. London: Longman.
HEARST, MART! A. 1993. TextTiling: A quantitative ap-
proach to discourse segmentation. Technical Report
Sequoia 93/24, Computer Science Department, Univer-
sity of California, Berkeley.
-, 1994. Context and Structure in Automated Full-Text
Information Access. University of California at Berke-
ley dissertation. (Computer Science Division Technical
Report).
HIRSCHBERG, JULIA, &amp; DIANE LITMAN. 1993. Empirical
studies on the disambiguation of cue phrases. Compu-
tational Linguistics 19.501-530.
</reference>
<page confidence="0.959566">
15
</page>
<figure confidence="0.9852954">
Text Total Baseline 41% (avg) Prec Blocks I Chains I Judges (avg) I
Possible Prec Rec C I Rec C Prec Rec C Prec Rec C
1 9 .44 .44 4 5 1.0 .78 7 0 1.0 .78 7 0 .78 .78 7 2
2 9 .50 .44 4 4 .88 .78 7 1 .75 .33 3 1 .88 .78 7 1
3 9 .40 .44 4 6 .78 .78 7 2 .56 .56 5 4 .75 .67 6 2
4 12 .63 .42 5 3 .86 .50 6 1 .56 .42 5 4 .91 .83 10 1
5 8 .43 .38 3 4 .70 .75 6 2 .86 .75 6 1 .86 .75 6 1
6 8 .40 .38 3 9 .60 .75 6 3 .42 .63 5 8 .75 .75 6 2
7 9 .36 .44 4 7 .60 .56 5 3 .40 .44 4 6 .75 .67 6 2
8 8 .43 .38 3 4 .50 .63 5 4 .67 .75 6 3 .86 .75 6 1
9 9 .36 .44 4 7 .50 .44 4 3 .60 .33 3 2 .75 .67 6 2
10 8 .50 .38 3 3 .50 .50 4 3 .63 .63 5 3 .86 .75 6 1
11 9 .36 .44 4 7 .50 .44 4 4 .71 .56 5 2 .75 .67 6 2
12 9 .44 .44 4 5 .50 .56 5 5 .54 .78 7 6 .86 .67 6 1
13 10 .36 .40 4 7 .30 .50 5 9 .60 .60 6 4 .78 .70 7 2
</figure>
<reference confidence="0.985904044776119">
Table 2: Scores by text, showing precision and recall. (C) indicates the number of correctly placed boundaries, (I)
indicates the number of inserted boundaries. The number of deleted boundaries can be determined by subtracting
(C) from Total Possible.
KOZIMA, HIDEKI. 1993. Text segmentation based on similar-
ity between words. In Proceedings of the 31th Annual
Meeting of the Association for Computational Linguis-
tics, 286-288, Columbus, OH.
LONGACRE, R. E. 1979. The paragraph as a grammatical
unit. In Syntax and Semantics: Discourse and Syntax,
ed. by Talmy Givon, volume 12, 115-134. Academic
Press.
MANN, WILLIAM C., &amp; SANDRA A. THOMPSON. 1987.
Rhetorical structure theory: A theory of text organi-
zation. Technical Report ISI/RS 87-190, ISI.
MILLER, GEORGE A., RICHARD BECKWITH, CHRISTIANE
FELLBAUM, DEREK GROSS, SZ KATHERINE J. MILLER.
1990. Introduction to WordNet: An on-line lexical
database. Journal of Lexicography 3.235-244.
Moms, JANE. 1988. Lexical cohesion, the thesaurus,
and the structure of text. Technical Report CSRI-
219, Computer Systems Research Institute, University
of Toronto.
&amp; GRAEME HIRST. 1991. Lexical cohesion computed
by thesaural relations as an indicator of the structure
of text. Computational Linguistics 17.21-48.
PASSONNEAU, REBECCA J., &amp; DIANE J. LITMAN. 1993.
Intention-based segmentation: Human reliability and
correlation with linguistic cues. In Proceedings of the
31st Annual Meeting of the Association for Computa-
tional Linguistics, 148-155.
RESNIK, PHILIP, 1993. Selection and Information: A Class-
Based Approach to Lexical Relationships. University of
Pennsylvania dissertation. (Institute for Research in
Cognitive Science report IRCS-93-42).
SALTON, GERARD. 1988. Automatic text processing : the
transformation, analysis, and retrieval of information
by computer. Reading, MA: Addison-Wesley.
-, JAMES ALLAN, &amp; CHRIS BUCKLEY. 1993. Ap-
proaches to passage retrieval in full text information
systems. In Proceedings of the 16th Annual Inter-
national A CM/SIGIR Conference, 49-58, Pittsburgh,
PA.
SCIR.JTZE, HINRICH. 1993. Word space. In Advances
in Neural Information Processing Systems 5, ed. by
Stephen J. Hanson, Jack D. Cowan, &amp; C. Lee Giles.
San Mateo CA: Morgan Kaufmann.
SKOROCHOD&apos;KO, E.F. 1972. Adaptive method of automatic
abstracting and indexing. In Information Processing
71: Proceedings of the IFIP Congress 71, ed. by C.V.
Freiman, 1179-1182. North-Holland Publishing Com-
pany.
STARK, HEATHER. 1988. What do paragraph markers do?
Discourse Processes 11.275-304.
TANNEN, DEBORAH. 1989. Talking Voices: Repetition, dia-
logue, and imagery in conversational discourse. Studies
in Interactional Sociolinguistics 6. Cambridge Univer-
sity Press.
WALKER, MARILYN. 1991. Redundancy in collaborative dia-
logue. In A A AI Fall Symposium on Discourse Structure
in Natural Language Understanding and Generation,
ed. by Julia Hirschberg, Diane Litman, Kathy McCoy,
&amp; Candy Sidner, Pacific Grove, CA.
YAROWSKY, DAVID. 1992. Word sense disambiguation us-
ing statistical models of Roget&apos;s categories trained on
large corpora. In Proceedings of the Fourteenth Interna-
tional Conference on Computational Linguistics, 454-
460, Nantes, France.
</reference>
<page confidence="0.998697">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.775982">
<title confidence="0.9951235">MULTI-PARAGRAPH SEGMENTATION OF EXPOSITORY TEXT</title>
<author confidence="0.999993">Marti A Hearst</author>
<affiliation confidence="0.9935135">Computer Science Division, 571 Evans Hall University of California, Berkeley</affiliation>
<address confidence="0.999412">Berkeley, CA 94720</address>
<affiliation confidence="0.8902635">and Xerox Palo Alto Research Center</affiliation>
<email confidence="0.999245">marti@cs.berkeley.edu</email>
<abstract confidence="0.999481454545455">This paper describes TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts. The algorithm uses domain-independent lexical frequency and distribution information to recognize the interactions of multiple simultaneous themes. Two fully-implemented versions of the algorithm are described and shown to produce segmentation that corresponds well to human judgments of the major subtopic boundaries of thirteen lengthy texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>GILLIAN BROWN</author>
<author>GEORGE YULE</author>
</authors>
<title>Discourse Analysis. Cambridge Textbooks in Linguistics Series.</title>
<date>1983</date>
<publisher>Cambridge University Press.</publisher>
<marker>BROWN, YULE, 1983</marker>
<rawString>BROWN, GILLIAN, &amp; GEORGE YULE. 1983. Discourse Analysis. Cambridge Textbooks in Linguistics Series. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WALLACE L CHAFE</author>
</authors>
<title>The flow of thought and the flow of language.</title>
<date>1979</date>
<booktitle>In Syntax and Semantics: Discourse and Syntax, ed. by Talmy Givon,</booktitle>
<volume>12</volume>
<pages>159--182</pages>
<publisher>Academic Press.</publisher>
<marker>CHAFE, 1979</marker>
<rawString>CHAFE, WALLACE L. 1979. The flow of thought and the flow of language. In Syntax and Semantics: Discourse and Syntax, ed. by Talmy Givon, volume 12, 159-182. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G COCHRAN</author>
</authors>
<title>The comparison of percentages in matched samples.</title>
<date>1950</date>
<journal>Biometrika</journal>
<pages>37--256</pages>
<marker>COCHRAN, 1950</marker>
<rawString>COCHRAN, W. G. 1950. The comparison of percentages in matched samples. Biometrika 37.256-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IDO DAGAN</author>
<author>SI4AUL MARCUS</author>
<author>SHAUL MARKOVITCH</author>
</authors>
<title>Contextual word similarity and estimation from sparse data.</title>
<date>1993</date>
<booktitle>In Proceedings of the 3Ith Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>164--171</pages>
<marker>DAGAN, MARCUS, MARKOVITCH, 1993</marker>
<rawString>DAGAN, IDO, SI4AUL MARCUS, &amp; SHAUL MARKOVITCH. 1993. Contextual word similarity and estimation from sparse data. In Proceedings of the 3Ith Annual Meeting of the Association for Computational Linguistics, 164-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WILLIAM A GALE</author>
<author>KENNETH W CHURCH</author>
<author>DAVID YAROWSKY</author>
</authors>
<title>Estimating upper and lower bounds on the performance of word-sense disambiguation programs.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Meeting of the Association for Computational Linguistics,</booktitle>
<pages>249--256</pages>
<marker>GALE, CHURCH, YAROWSKY, 1992</marker>
<rawString>GALE, WILLIAM A., KENNETH W. CHURCH, &amp; DAVID YAROWSKY. 1992a. Estimating upper and lower bounds on the performance of word-sense disambiguation programs. In Proceedings of the 30th Meeting of the Association for Computational Linguistics, 249-256.</rawString>
</citation>
<citation valid="false">
<authors>
<author>1992b</author>
</authors>
<title>A method for disambiguating word senses in a large corpus.</title>
<journal>Computers and the Humanities</journal>
<pages>5--6</pages>
<contexts>
<context position="2831" citStr="(1992)" startWordPosition="418" endWordPosition="418">to not only identify the extents of the subtopical units, but to label their contents as well. This paper focusses only on the discovery of subtopic structure, leaving determination of subtopic content to future work. Most discourse segmentation work is done at a finer granularity than that suggested here. However, for lengthy written expository texts, multi-paragraph segmentation has many potential uses, including the improvement of computational tasks that make use of distributional information. For example, disambiguation algorithms that train on arbitrary-size text windows, e.g., Yarowsky (1992) and Gale et a/. (1992b), and algorithms that use lexical co-occurrence to determine semantic relatedness, e.g., Schiitze (1993), might benefit from using windows with motivated boundaries instead. Information retrieval algorithms can use subtopic structuring to return meaningful portions of a text if paragraphs are too short and sections are too long (or are not present). Motivated segments can also be used as a more meaningful unit for indexing long texts. Salton et at. (1993), working with encyclopedia text, find that comparing a query against sections and then paragraphs is more successful</context>
</contexts>
<marker>1992b, </marker>
<rawString>&amp; 1992b. A method for disambiguating word senses in a large corpus. Computers and the Humanities 5-6.415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BARBARA J GROSZ</author>
<author>CANDACE L SIDNER</author>
</authors>
<title>Attention, intention, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<pages>12--172</pages>
<marker>GROSZ, SIDNER, 1986</marker>
<rawString>GROSZ, BARBARA J., &amp; CANDACE L. SIDNER. 1986. Attention, intention, and the structure of discourse. Computational Linguistics 12.172-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K HALLIDAY</author>
<author>R HASAN</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English.</booktitle>
<publisher>Longman.</publisher>
<location>London:</location>
<marker>HALLIDAY, HASAN, 1976</marker>
<rawString>HALLIDAY, M. A. K., &amp; R. HASAN. 1976. Cohesion in English. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MART A HEARST</author>
</authors>
<title>TextTiling: A quantitative approach to discourse segmentation.</title>
<date>1993</date>
<tech>Technical Report Sequoia 93/24,</tech>
<institution>Computer Science Department, University of California, Berkeley.</institution>
<marker>HEARST, 1993</marker>
<rawString>HEARST, MART! A. 1993. TextTiling: A quantitative approach to discourse segmentation. Technical Report Sequoia 93/24, Computer Science Department, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<title>Context and Structure in Automated Full-Text Information Access.</title>
<date>1994</date>
<tech>Technical Report).</tech>
<institution>University of California at Berkeley dissertation. (Computer Science Division</institution>
<contexts>
<context position="19859" citStr="(1994)" startWordPosition="3265" endWordPosition="3265">age and standard deviations of the depth scores for the text under analysis. Currently a boundary is drawn only if the depth score exceeds g — a/2. EVALUATION One way to evaluate these segmentation algorithms is to compare against judgments made by human readers, another is to compare the algorithms against texts premarked by authors, and a third way is to see how well the results improve a computational task. This section compares the algorithm against reader judgments, since author markups are fallible and are usually applied to text types that this algorithm is not designed for, and Hearst (1994) shows how to use TextTiles in a task (although it does not show whether or not the results of the algorithms used here are better than some other algorithm with similar goals). Reader Judgments Judgments were obtained from seven readers for each of thirteen magazine articles which satisfied the length criteria (between 1800 and 2500 words)5 and which contained little structural demarkation. The judges 50ne longer text of 2932 words was used since reader judgments had been obtained for it from an earlier experiment. Judges were technical researchers. Two texts had three or four short headers w</context>
</contexts>
<marker>1994</marker>
<rawString>-, 1994. Context and Structure in Automated Full-Text Information Access. University of California at Berkeley dissertation. (Computer Science Division Technical Report).</rawString>
</citation>
<citation valid="true">
<authors>
<author>JULIA HIRSCHBERG</author>
<author>DIANE LITMAN</author>
</authors>
<title>Empirical studies on the disambiguation of cue phrases.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<pages>19--501</pages>
<marker>HIRSCHBERG, LITMAN, 1993</marker>
<rawString>HIRSCHBERG, JULIA, &amp; DIANE LITMAN. 1993. Empirical studies on the disambiguation of cue phrases. Computational Linguistics 19.501-530.</rawString>
</citation>
<citation valid="false">
<title>Table 2: Scores by text, showing precision and recall. (C) indicates the number of correctly placed boundaries, (I) indicates the number of inserted boundaries. The number of deleted boundaries can be determined by subtracting (C) from Total Possible.</title>
<marker></marker>
<rawString>Table 2: Scores by text, showing precision and recall. (C) indicates the number of correctly placed boundaries, (I) indicates the number of inserted boundaries. The number of deleted boundaries can be determined by subtracting (C) from Total Possible.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HIDEKI KOZIMA</author>
</authors>
<title>Text segmentation based on similarity between words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>286--288</pages>
<location>Columbus, OH.</location>
<marker>KOZIMA, 1993</marker>
<rawString>KOZIMA, HIDEKI. 1993. Text segmentation based on similarity between words. In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, 286-288, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E LONGACRE</author>
</authors>
<title>The paragraph as a grammatical unit.</title>
<date>1979</date>
<booktitle>In Syntax and Semantics: Discourse and Syntax, ed. by Talmy Givon,</booktitle>
<volume>12</volume>
<pages>115--134</pages>
<publisher>Academic Press.</publisher>
<marker>LONGACRE, 1979</marker>
<rawString>LONGACRE, R. E. 1979. The paragraph as a grammatical unit. In Syntax and Semantics: Discourse and Syntax, ed. by Talmy Givon, volume 12, 115-134. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WILLIAM C MANN</author>
<author>SANDRA A THOMPSON</author>
</authors>
<title>Rhetorical structure theory: A theory of text organization.</title>
<date>1987</date>
<tech>Technical Report ISI/RS 87-190, ISI.</tech>
<marker>MANN, THOMPSON, 1987</marker>
<rawString>MANN, WILLIAM C., &amp; SANDRA A. THOMPSON. 1987. Rhetorical structure theory: A theory of text organization. Technical Report ISI/RS 87-190, ISI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GEORGE A MILLER</author>
<author>RICHARD BECKWITH</author>
<author>CHRISTIANE FELLBAUM</author>
<author>DEREK GROSS</author>
<author>SZ KATHERINE J MILLER</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>Journal of Lexicography</journal>
<pages>3--235</pages>
<marker>MILLER, BECKWITH, FELLBAUM, GROSS, MILLER, 1990</marker>
<rawString>MILLER, GEORGE A., RICHARD BECKWITH, CHRISTIANE FELLBAUM, DEREK GROSS, SZ KATHERINE J. MILLER. 1990. Introduction to WordNet: An on-line lexical database. Journal of Lexicography 3.235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JANE Moms</author>
</authors>
<title>Lexical cohesion, the thesaurus, and the structure of text.</title>
<date>1988</date>
<tech>Technical Report CSRI219,</tech>
<institution>Computer Systems Research Institute, University of Toronto.</institution>
<marker>Moms, 1988</marker>
<rawString>Moms, JANE. 1988. Lexical cohesion, the thesaurus, and the structure of text. Technical Report CSRI219, Computer Systems Research Institute, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GRAEME HIRST</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics</journal>
<pages>17--21</pages>
<marker>HIRST, 1991</marker>
<rawString>&amp; GRAEME HIRST. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics 17.21-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>REBECCA J PASSONNEAU</author>
<author>DIANE J LITMAN</author>
</authors>
<title>Intention-based segmentation: Human reliability and correlation with linguistic cues.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>148--155</pages>
<marker>PASSONNEAU, LITMAN, 1993</marker>
<rawString>PASSONNEAU, REBECCA J., &amp; DIANE J. LITMAN. 1993. Intention-based segmentation: Human reliability and correlation with linguistic cues. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, 148-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PHILIP RESNIK</author>
</authors>
<title>Selection and Information: A ClassBased Approach to Lexical Relationships.</title>
<date>1993</date>
<institution>University of Pennsylvania</institution>
<note>dissertation. (Institute for Research in Cognitive Science report IRCS-93-42).</note>
<marker>RESNIK, 1993</marker>
<rawString>RESNIK, PHILIP, 1993. Selection and Information: A ClassBased Approach to Lexical Relationships. University of Pennsylvania dissertation. (Institute for Research in Cognitive Science report IRCS-93-42).</rawString>
</citation>
<citation valid="true">
<authors>
<author>GERARD SALTON</author>
</authors>
<title>Automatic text processing : the transformation, analysis, and retrieval of information by computer.</title>
<date>1988</date>
<publisher>Addison-Wesley.</publisher>
<location>Reading, MA:</location>
<marker>SALTON, 1988</marker>
<rawString>SALTON, GERARD. 1988. Automatic text processing : the transformation, analysis, and retrieval of information by computer. Reading, MA: Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JAMES ALLAN</author>
<author>CHRIS BUCKLEY</author>
</authors>
<title>Approaches to passage retrieval in full text information systems.</title>
<date>1993</date>
<booktitle>In Proceedings of the 16th Annual International A CM/SIGIR Conference,</booktitle>
<pages>49--58</pages>
<location>Pittsburgh, PA.</location>
<marker>ALLAN, BUCKLEY, 1993</marker>
<rawString>-, JAMES ALLAN, &amp; CHRIS BUCKLEY. 1993. Approaches to passage retrieval in full text information systems. In Proceedings of the 16th Annual International A CM/SIGIR Conference, 49-58, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HINRICH SCIR JTZE</author>
</authors>
<title>Word space.</title>
<date>1993</date>
<booktitle>In Advances in Neural Information Processing Systems 5,</booktitle>
<editor>ed. by Stephen J. Hanson, Jack D. Cowan, &amp; C. Lee Giles.</editor>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo CA:</location>
<marker>JTZE, 1993</marker>
<rawString>SCIR.JTZE, HINRICH. 1993. Word space. In Advances in Neural Information Processing Systems 5, ed. by Stephen J. Hanson, Jack D. Cowan, &amp; C. Lee Giles. San Mateo CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F SKOROCHOD&apos;KO</author>
</authors>
<title>Adaptive method of automatic abstracting and indexing.</title>
<date>1972</date>
<booktitle>In Information Processing 71: Proceedings of the IFIP Congress 71,</booktitle>
<pages>1179--1182</pages>
<editor>ed. by C.V. Freiman,</editor>
<publisher>North-Holland Publishing Company.</publisher>
<marker>SKOROCHOD&apos;KO, 1972</marker>
<rawString>SKOROCHOD&apos;KO, E.F. 1972. Adaptive method of automatic abstracting and indexing. In Information Processing 71: Proceedings of the IFIP Congress 71, ed. by C.V. Freiman, 1179-1182. North-Holland Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HEATHER STARK</author>
</authors>
<title>What do paragraph markers do?</title>
<date>1988</date>
<booktitle>Discourse Processes</booktitle>
<pages>11--275</pages>
<marker>STARK, 1988</marker>
<rawString>STARK, HEATHER. 1988. What do paragraph markers do? Discourse Processes 11.275-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DEBORAH TANNEN</author>
</authors>
<title>Talking Voices: Repetition, dialogue, and imagery in conversational discourse.</title>
<date>1989</date>
<booktitle>Studies in Interactional Sociolinguistics 6.</booktitle>
<publisher>Cambridge University Press.</publisher>
<marker>TANNEN, 1989</marker>
<rawString>TANNEN, DEBORAH. 1989. Talking Voices: Repetition, dialogue, and imagery in conversational discourse. Studies in Interactional Sociolinguistics 6. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MARILYN WALKER</author>
</authors>
<title>Redundancy in collaborative dialogue.</title>
<date>1991</date>
<booktitle>In A A AI Fall Symposium on Discourse Structure in Natural Language Understanding and Generation,</booktitle>
<editor>ed. by Julia Hirschberg, Diane Litman, Kathy McCoy, &amp; Candy Sidner,</editor>
<location>Pacific Grove, CA.</location>
<marker>WALKER, 1991</marker>
<rawString>WALKER, MARILYN. 1991. Redundancy in collaborative dialogue. In A A AI Fall Symposium on Discourse Structure in Natural Language Understanding and Generation, ed. by Julia Hirschberg, Diane Litman, Kathy McCoy, &amp; Candy Sidner, Pacific Grove, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DAVID YAROWSKY</author>
</authors>
<title>Word sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics,</booktitle>
<pages>454--460</pages>
<location>Nantes, France.</location>
<marker>YAROWSKY, 1992</marker>
<rawString>YAROWSKY, DAVID. 1992. Word sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora. In Proceedings of the Fourteenth International Conference on Computational Linguistics, 454-460, Nantes, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>