<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007788">
<title confidence="0.94968">
Multilingual Collocation Extraction: Issues and Solutions
</title>
<author confidence="0.989699">
Violeta Seretan
</author>
<affiliation confidence="0.9970695">
Language Technology Laboratory
University of Geneva
</affiliation>
<address confidence="0.769109">
2, rue de Candolle, 1211 Geneva
</address>
<email confidence="0.983827">
Violeta.Seretan@latl.unige.ch
</email>
<author confidence="0.997662">
Eric Wehrli
</author>
<affiliation confidence="0.9981155">
Language Technology Laboratory
University of Geneva
</affiliation>
<address confidence="0.772903">
2, rue de Candolle, 1211 Geneva
</address>
<email confidence="0.992278">
Eric.Wehrli@latl.unige.ch
</email>
<sectionHeader confidence="0.99367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999945875">
Although traditionally seen as a language-
independent task, collocation extraction
relies nowadays more and more on the
linguistic preprocessing of texts (e.g.,
lemmatization, POS tagging, chunking or
parsing) prior to the application of sta-
tistical measures. This paper provides
a language-oriented review of the exist-
ing extraction work. It points out sev-
eral language-specific issues related to ex-
traction and proposes a strategy for cop-
ing with them. It then describes a hybrid
extraction system based on a multilingual
parser. Finally, it presents a case-study on
the performance of an association measure
across a number of languages.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996289">
Collocations are understood in this paper as “id-
iosyncratic syntagmatic combination of lexical
items” (Fontenelle, 1992, 222): heavy rain, light
breeze, great difficulty, grow steadily, meet re-
quirement, reach consensus, pay attention, ask a
question. Unlike idioms (kick the bucket, lend a
hand, pull someone’s leg), their meaning is fairly
transparent and easy to decode. Yet, differently
from the regular productions, (big house, cultural
activity, read a book), collocational expressions
are highly idiosyncratic, since the lexical items
a headword combines with in order to express
a given meaning is contingent upon that word
(Mel’ˇcuk, 2003).
This is apparent when comparing a colloca-
tion’s equivalents across different languages. The
English collocation ask a question translates as
poser une question in French (lit., ?put a question),
and as fare una domanda, hacer una pregunta in
Italian and Spanish (lit., to make a question).
As it has been pointed out by many researchers
(Cruse, 1986; Benson, 1990; McKeown and
Radev, 2000), collocations cannot be described
by means of general syntactic and semantic rules.
They are arbitrary and unpredictable, and there-
fore need to be memorized and used as such. They
constitute the so-called “semi-finished products”
of language (Hausmann, 1985) or the “islands of
reliability” (Lewis, 2000) on which the speakers
build their utterances.
</bodyText>
<sectionHeader confidence="0.989198" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999377708333333">
The key importance of collocations in text pro-
duction tasks such as machine translation and nat-
ural language generation has been stressed many
times. It has been equally shown that collocations
are useful in a range of other applications, such as
word sense disambiguation (Brown et al., 1991)
and parsing (Alshawi and Carter, 1994).
The NLP community fully acknowledged the
need for an appropriate treatment of multi-word
expressions in general (Sag et al., 2002). Collo-
cations are particularly important because of their
prevalence in language, regardless of the domain
or genre. According to Jackendoff (1997, 156)
and Mel’ˇcuk (1998, 24), collocations constitute
the bulk of a language’s lexicon.
The last decades have witnessed a considerable
development of collocation extraction techniques,
that concern both monolingual and (parallel) mul-
tilingual corpora.
We can mention here only part of this work:
(Berry-Rogghe, 1973; Church et al., 1989;
Smadja, 1993; Lin, 1998; Krenn and Evert, 2001)
for monolingual extraction, and (Kupiec, 1993;
Wu, 1994; Smadja et al., 1996; Kitamura and Mat-
</bodyText>
<page confidence="0.993652">
40
</page>
<note confidence="0.7002395">
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999161759493671">
sumoto, 1996; Melamed, 1997) for bilingual ex-
traction via alignment.
Traditionally, collocation extraction was con-
sidered a language-independent task. Since collo-
cations are recurrent, typical lexical combinations,
a wide range of statistical methods based on word
co-occurrence frequency have been heavily used
for detecting them in text corpora. Among the
most often used types of lexical association mea-
sures (henceforth AMs) we mention: statistical
hypothesis tests (e.g., binomial, Poisson, Fisher, z-
score, chi-squared, t-score, and log-likelihood ra-
tio tests), that measure the significance of the asso-
ciation between two words based on a contingency
table listing their joint and marginal frequency,
and Information-theoretic measures (Mutual In-
formation — henceforth MI — and its variants),
that quantity of ‘information’ shared by two ran-
dom variables. A detailed review of the statistical
methods employed in collocation extraction can be
found, for instance, in (Evert, 2004). A compre-
hensive list of AMs is given (Pecina, 2005).
Very often, in addition to the information on co-
occurrence frequency, language-specific informa-
tion is also integrated in a collocation extraction
system (as it will be seen in section 3):
- morphological information, in order to count
inflected word forms as instances of the same
base form. For instance, ask questions, asks
question, asked question are all instances of
the same word pair, ask - question;
- syntactic information, in order to recognize a
word pair even if subject to (complex) syntac-
tic transformations: ask multiple questions,
question asked, questions that one might ask.
The language-specific modules thus aim at cop-
ing with the problem of morphosyntactic varia-
tion, in order to improve the accuracy of frequency
information. This becomes truly important espe-
cially for free-word order and for high-inflection
languages, for which the token(form)-based fre-
quency figures become too skewed due to the high
lexical dispersion. Not only the data scattering
modify the frequency numbers used by AMs, but
it also alters the performance of AMs, if the the
probabilities in the contingency table become very
low.
Morphosyntactic information has in fact been
shown to significantly improve the extraction re-
sults (Breidt, 1993; Smadja, 1993; Zajac et al.,
2003). Morphological tools such as lemmatizers
and POS taggers are being commonly used in ex-
traction systems; they are employed both for deal-
ing with text variation and for validating the can-
didate pairs: combinations of function words are
typically ruled out (Justeson and Katz, 1995), as
are the ungrammatical combinations in the sys-
tems that make use of parsers (Church and Hanks,
1990; Smadja, 1993; Basili et al., 1994; Lin, 1998;
Goldman et al., 2001; Seretan et al., 2004).
Given the motivations for performing a
linguistically-informed extraction — which were
also put forth, among others, by Church and
Hanks (1990, 25), Smadja (1993, 151) and Heid
(1994) — and given the recent development of
linguistic analysis tools, it seems plausible that the
linguistic structure will be more and more taken
into account by collocation extraction systems.
The rest of the paper is organized as follows. In
section 3 we provide a language-oriented review
of the existing collocation extraction work. Then
we highlight, in section 4, a series of problems that
arise in the transfer of methodology to a new lan-
guage, and we propose a strategy for dealing with
them. Section 5 describes an extraction system,
and, finally, section 6 presents a case-study on the
collocations extracted for four languages, illustrat-
ing the cross-lingual variation in the performance
of a particular AM.
</bodyText>
<sectionHeader confidence="0.902676" genericHeader="method">
3 Overview of Extraction Work
</sectionHeader>
<subsectionHeader confidence="0.992422">
3.1 English
</subsectionHeader>
<bodyText confidence="0.9999331875">
As one might expect, the bulk of the collocation
extraction work concerns the English language:
(Choueka, 1988; Church et al., 1989; Church and
Hanks, 1990; Smadja, 1993; Justeson and Katz,
1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998),
among many others1.
Choueka’s method (1988) detects n-grams (ad-
jacent words) only, by simply computing the co-
occurrence frequency. Justeson and Katz (1995)
apply a POS-filter on the pairs they extract. As in
(Kjellmer, 1994), the AM they use is the simple
frequency.
Smadja (1993) employs the z-score in conjunc-
tion with several heuristics (e.g., the systematic
occurrence of two lexical items at the same dis-
tance in text) and extracts predicative collocations,
</bodyText>
<footnote confidence="0.917847333333333">
1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al.,
2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al.,
2004; Pecina, 2005), and the list can be continued.
</footnote>
<page confidence="0.999459">
41
</page>
<bodyText confidence="0.999922333333333">
rigid noun phrases and phrasal templates. He then
uses the a parser in order to validate the results.
The parsing is shown to lead to an increase in ac-
curacy from 40% to 80%.
(Church et al., 1989) and (Church and Hanks,
1990) use POS information and a parser to extract
verb-object pairs, which then they rank according
to the mutual information (MI) measure they in-
troduce.
Lin’s (1998) is also a hybrid approach that relies
on a dependency parser. The candidates extracted
are then ranked with MI.
</bodyText>
<subsectionHeader confidence="0.999077">
3.2 German
</subsectionHeader>
<bodyText confidence="0.999845666666667">
German is the second most investigated language,
thanks to the early work of Breidt (1993) and,
more recently, to that of Krenn and Evert, such as
(Krenn and Evert, 2001; Evert and Krenn, 2001;
Evert, 2004) centered on evaluation.
Breidt uses MI and t-score and compares the
results accuracy when various parameters vary,
such as the window size, presence vs. absence
of lemmatization, corpus size, and presence vs.
absence of POS and syntactic information. She
focuses on N-V pairs2 and, despite the lack of
syntactic analysis tools at the time, by simulating
parsing she comes to the conclusion that “Very
high precision rates, which are an indispensable
requirement for lexical acquisition, can only real-
istically be envisaged for German with parsed cor-
pora” (Breidt, 1993, 82).
Later, Krenn and Evert (2001) used a German
chunker to extract syntactic pairs such as P-N-V.
Their work put the basis of formal and system-
atic methods in collocation extraction evaluation.
Zinsmeister and Heid (2003; 2004) focused on
N-V and A-N-V combinations identified using a
stochastic parser. They applied machine learning
techniques in combination to the log-likelihood
measure (henceforth LL) for distinguishing trivial
compounds from lexicalized ones.
Finally, Wermter and Hahn (2004) identified
PP-V combinations using a POS tagger and a
chunker. They based their method on a linguistic
criterion (that of limited modifiability) and com-
pared their results with those obtained using the
t-score and LL tests.
</bodyText>
<footnote confidence="0.774509666666667">
2The following abbreviations are used in this paper: N -
noun, V - verb, A - adjective, Adv - adverb, Det - determiner,
Conj - conjunction, P - preposition.
</footnote>
<subsectionHeader confidence="0.998299">
3.3 French
</subsectionHeader>
<bodyText confidence="0.999810571428571">
Thanks to the outstanding work of Gross on
lexicon-grammar (1984), French is one of the
most studied languages in terms of distributional
and transformational potential of words. This
work has been carried out before the computer era
and the advent of corpus linguistics, while auto-
matic extraction was later performed, for instance,
in (Lafon, 1984; Daille, 1994; Bourigault, 1992;
Goldman et al., 2001).
Daille (1994) aimed at extracting compound
nouns, defined a priori by means of certain syn-
tactic patterns, like N-A, N-N, N-`a-N, N-de-N, N
P Det N. She used a lemmatizer and a POS-tagger
before applying a series of AMs, which she then
evaluated against a domain-specific terminology
dictionary and against a gold-standard manually
created from the extraction corpus.
Similarly, Bourigault (1992) extracted noun-
phrases from shallow-parsed text, and Goldman et
al. (2001) extracted syntactic collocations by us-
ing a full parser and applying the LL test.
</bodyText>
<subsectionHeader confidence="0.988122">
3.4 Other Languages
</subsectionHeader>
<bodyText confidence="0.98073825">
In addition to English, German and French, other
languages for which notable collocation extraction
work was performed, are — as we are aware of —
the following:
</bodyText>
<listItem confidence="0.983016">
• Italian: early extraction work was carried out
by Calzolari and Bindi (1990) and employed
MI. It was followed by (Basili et al., 1994),
that made use of parsing information;
• Korean: (Shimohata et al., 1997) used an ad-
jacency n-gram model, and (Kim et al., 1999)
relied on POS-tagging;
• Chinese: (Huang et al., 2005) used POS in-
formation, while (Lu et al., 2004) applied ex-
traction techniques similar to Xtract system
(Smadja, 1993);
• Japanese: (Ikehara et al., 1995) was based on
an improved n-gram method.
</listItem>
<bodyText confidence="0.999848428571429">
As for multilingual extraction via alignment
(where collocations are first detected in one lan-
guage and then matched with their translation in
another language), most or the existing work con-
cern the English-French language pair, and the
Hansard corpus of Canadian Parliament proceed-
ings. Wu (1994) signals a number of problems
</bodyText>
<page confidence="0.994959">
42
</page>
<bodyText confidence="0.999957153846154">
that non-Indo-European languages pose for the
existing alignment methods based on word- and
sentence-length: in Chinese, for instance, most of
the words are just one or two characters long, and
there are no word delimiters. This result suggests
that the portability of existing alignment methods
to new language pairs is questionable.
We are not concerned here with extraction via
alignment. We assume, instead, that multilingual
support in collocation extraction means the cus-
tomization of the extraction procedure for each
language. This topic will be addressed in the next
sections.
</bodyText>
<sectionHeader confidence="0.866959" genericHeader="method">
4 Multilingualism: Why and How?
</sectionHeader>
<subsectionHeader confidence="0.995481">
4.1 Some Issues
</subsectionHeader>
<bodyText confidence="0.999972375">
As the previous section showed, many systems of
collocation extraction rely on the linguistic pre-
processing of source corpora in order to support
the candidate identification process. Language-
specific information, such as the one derived from
morphological and syntactic analysis, was shown
to be highly beneficial for extraction. Moreover,
the possibility to apply the association measures
on syntactically homogenous material is argued to
benefit extraction, as the performance of associa-
tion measures might vary with the syntactic con-
figurations because of the differences in distribu-
tion (Krenn and Evert, 2001).
The lexical distribution is therefore a relevant
issue from the perspective of multilingual colloca-
tion extraction. Different languages show different
proportions of lexical categories (N, V, A, Adv,
P, etc.) which are evenly distributed across syn-
tactic types3. Depending on the frequency num-
bers, a given AM could be more suited for a spe-
cific syntactic configuration in one language, and
less suited for the same configuration in another.
Ideally, each language should be assigned a suit-
able set of AMs to be applied on syntactically-
homogenous data.
Another issue that is relevant in the multi-
lingualism perspective is that of the syntactic
configurations characterizing collocations. Sev-
eral such relations (e.g., noun-adjectival modifier,
predicate-argument) are likely to remain constant
through languages, i.e., to be judged as colloca-
tionally interesting in many languages. However,
</bodyText>
<footnote confidence="0.492119333333333">
3For instance, V-P pairs are more represented in English
than in other languages (as phrasal verbs or verb-particle con-
structions).
</footnote>
<bodyText confidence="0.999591435897436">
other configurations could be language-specific
(like P-N-V in German, whose English equiva-
lent is V-P-N). Yet other configurations might have
no counterpart at all in another language (e.g., the
French P-A pair a` neuf is translated into English
as a Conj-A pair, as new).
Finding all the collocationally-relevant syntac-
tic types for a language is therefore another prob-
lem that has to be solved in multilingual extrac-
tion. Since a priori defining these types based
on intuition does not ensure the necessary cover-
age, an alternative proposal is to induce them from
POS data and dependency relations, as in (Seretan,
2005).
The morphoyntactic differences between lan-
guages also have to be taken into account. With
English as the most investigated language, several
hypotheses were put forth in extraction and be-
came common place.
For instance, using a 5-words window as search
space for collocation pairs is a usual practice, since
this span length was shown sufficient to cover a
high percentage of syntactic co-occurrences in En-
glish. But — as suggested by other researchers,
e.g., (Goldman et al., 2001) —, this assumption
does not necessary hold for other languages.
Similarly, the higher inflection and the higher
transformation potential shown by some lan-
guages pose additional problems in extraction,
which were rather ignored for English. As Kim et
al. (1999) notice, collocation extraction is particu-
larly difficult in free-order languages like Korean,
where arguments scramble freely. Breidt (1993)
also pointed out a couple of problems that makes
extraction for German more difficult than for En-
glish: the strong inflection for verbs, the variable
word-order, and the positional ambiguity of the ar-
guments. She shows that even distinguishing sub-
jects from objects is very difficult without parsing.
</bodyText>
<subsectionHeader confidence="0.998783">
4.2 A Strategy for Multilingual Extraction
</subsectionHeader>
<bodyText confidence="0.994190875">
Summing up the previous discussion, the cus-
tomization of collocation extraction for a given
language needs to take into account:
- the syntactic configurations characterizing
collocations,
- the lexical distribution over syntactic config-
urations,
- the adequacy of AMs to these configurations.
</bodyText>
<page confidence="0.998963">
43
</page>
<bodyText confidence="0.973853045454546">
These are language-specific parameters which
need to be set in a successful multilingual extrac-
tion procedure. Truly multilingual systems have
not been developed yet, but we suggest the fol-
lowing strategy for building such a system:
A. parse the source corpus, extract all the syn-
tactic pairs (e.g., head-modifier, predicate-
argument) and rank them with a given AM,
B. analyze the results and find the syntactic con-
figurations characterizing collocations,
C. evaluate the adequacy of AMs for ranking col-
locations in each syntactic configuration, and
find the most convenient mapping configura-
tions - AMs.
Once customized for a language, the extraction
procedure involves:
Stage 1. parsing the source corpus for extract-
ing the lexical pairs in the relevant,
language-specific syntactic configura-
tions found in step B;
Stage 2. ranking the pairs from each syntactic
class with the AM assigned in step C.
</bodyText>
<sectionHeader confidence="0.9437855" genericHeader="method">
5 A Multilingual Collocation Extractor
Based on Parsing
</sectionHeader>
<bodyText confidence="0.999872176470588">
Ever since the collocation was brought to the at-
tention of linguists in the framework of contextu-
alism (Firth, 1957; Firth, 1968), it has been pre-
ponderantly seen as a pure statistical phenomenon
of lexical association. In fact, according to a well-
known definition, “a collocation is an arbitrary and
recurrent word combination” (Benson, 1990).
This approach was at the basis of the computa-
tional work on collocation, although there exist an
alternative approach — the linguistic, or lexico-
graphic one — that imposes a restricted view on
collocation, which is seen first of all as an expres-
sion of language.
The existing extraction work (section 3) shows
that there is a growing interest in adopting the
more restricted (linguistic) view. As mentioned in
section 3, the importance of parsing for extraction
was confirmed by several evaluation experiments.
With the recent development in the field of linguis-
tic analysis, hybrid extraction systems (i.e., sys-
tems relying on syntactical analysis for colloca-
tion extraction) are likely to become the rule rather
than the exception.
Our system (Goldman et al., 2001; Seretan and
Wehrli, 2006) is — to our knowledge — the first
to perform the full syntactic analysis as support for
collocation extraction; similar approaches rely on
dependency parsers or on chunking.
It is based on a symbolic parser that was de-
veloped over the last decade (Wehrli, 2004) and
achieves a high level of performance, in terms of
accuracy, speed and robustness. The languages it
supports are, for the time being, French, English,
Italian, Spanish and German. A few other lan-
guages are being also implemented in the frame-
work of a multilingualism project.
Provided that collocation extraction can be seen
as a two-stage process (where, in stage 1, collo-
cation candidates are identified in the text corpora,
and in stage 2, they are ranked according to a given
AM, cf. section 4.2), the role of the parser is to
support the first stage. A pair of lexical items is
selected as a candidate only if there exist a syntac-
tic relation holding between the two items.
Unlike the traditional, window-based methods,
candidate selection is based on syntactic proxim-
ity (as opposed to textual proximity). Another
peculiarity of our system is that candidate pairs
are identified as the parsing goes on; in other ap-
proaches, they are extracted by post-processing
the output of syntactic tools.
The candidate pairs identified are classified into
syntactically homogenous sets, according to the
syntactic relations holding between the two items.
Only certain predefined syntactic relations are
kept, that were judged as collocationally rele-
vant after multiple experiments of extraction and
data analysis (e.g., adjective-noun, verb-object,
subject-verb, noun-noun, verb-preposition-noun).
The sets obtained are then ranked using the log-
likelihood ratios test (Dunning, 1993).
More details about the system and its perfor-
mance can be found in (Seretan and Wehrli, 2006).
The following examples (taken from the extraction
experiment we will describe below) illustrate its
potential to detect collocation candidates, even if
these are subject to complex syntactic transforma-
tions:
</bodyText>
<listItem confidence="0.818573666666667">
1.a) atteindre objectif (Fr): Les objec-
tifs fix´es a` l’´echelle internationale
visant a` r´eduire les ´emissions ne
peuvent pas ˆetre atteints a` l’aide de
ces seuls programmes.
1.b) accogliere emendamento (It):
</listItem>
<page confidence="0.996948">
44
</page>
<bodyText confidence="0.999181176470588">
Posso pertanto accogliere in parte
e in linea di principio gli emenda-
menti nn. 43-46 e l’emendamento
n. 85.
1.c) reforzar cooperaci´on (Es): Quer-
emos permitir a los pases que lo
deseen reforzar, en un contexto
unitario, su cooperaci´on en cierto
n´umero de sectores.
The collocation extractor is part of a bigger sys-
tem (Seretan et al., 2004) that integrates a con-
cordancer and a sentence aligner, and that sup-
ports the visualization, the manual validation and
the management of a multilingual terminology
database. The validated collocations are used for
populating the lexicon of the parser and that of a
translation system (Wehrli, 2003).
</bodyText>
<sectionHeader confidence="0.954353" genericHeader="method">
6 A Cross-Lingual Extraction
Experiment
</sectionHeader>
<bodyText confidence="0.9978055">
A collocation extraction experiment concern-
ing four different languages (English, Spanish,
French, Italian) has been conducted on a parallel
subcorpus of 42 files from the European Parlia-
ment proceedings. Several statistics and extraction
results are reported in Table 1.
</bodyText>
<table confidence="0.999001">
Statistics English Spanish Italian French
tokens 2526403 2666764 2575858 2938118
sent/file 2329.1 2513.7 2331.6 2392.8
complete 63.4% 35.5% 46.8% 63.7%
parses
tokens/sent 25.8 25.3 26.3 29.2
extr. pairs 617353 568998 666122 565287
(tokens)
token/type 2.6 2.5 2.3 2.3
LL is def. 85.9% 90.6% 83.5% 92.8%
</table>
<tableCaption confidence="0.999938">
Table 1: Extraction statistics
</tableCaption>
<bodyText confidence="0.976009666666666">
We computed the distribution of pair tokens
according to the syntactic type and noted that
the most marked distributional difference among
these languages concern the following types: N-A
(7.12), A-N (4.26), V-O (2.68), V-P (4.16), N-P-N
(3.81)4.
Unsurprisingly, the Romance languages are less
different in terms of syntactic co-occurrence dis-
tribution, and the deviation of English from the
Romance mean is more pronounced — in particu-
lar, for N-A (9.72), V-P (5.63), A-N (5.25), N-P-N
4The numbers represent the values the standard deviation
of the relative percentages in the whole lists of pairs.
(4.77), and V-O (3.57). These distributional differ-
ences might account for the types of collocations
highlighted by a particular AM (such as LL) in a
language vs. another. Figure 1 displays the rela-
tive proportions of 3 syntactic types — adjective-
noun, subject-verb and verb-object — that can be
found at different levels in the significance list re-
turned by LL.
</bodyText>
<figureCaption confidence="0.867599333333333">
Figure 1: Cross-lingual proportions of A-N, S-V
and V-O pairs at different levels in the significance
lists
</figureCaption>
<bodyText confidence="0.9997">
We performed a contrastive analysis of results,
by carrying out a case-study aimed at checking
the LL performance variability across languages.
The study concerned the verb-object collocations
having the noun policy as the direct object. We
specifically focused on the best-scored collocation
extracted from the French corpus, namely mener
une politique (lit., conduct a policy).
We looked at the translation equivalents of its
74 instances identified by our extraction system
in the corpus. The analysis revealed that — at
least in this particular case — the verbal collo-
cates of this noun are highly scattered: pursue,
implement, conduct, adopt, apply, develop, have,
draft, launch, run, carry out for English; prac-
ticar, llevar a cabo, desarrollar, realizar, aplicar,
seguir, hacer, adoptar, ejercer for Spanish; con-
durre, attuare, portare avanti, perseguire, pratti-
care, adottare, fare for Italian (among several oth-
ers). Some of the collocates (those listed first) are
more prominently used. But generally they are
highly dispersed, and this might indicate a bigger
difficulty for LL to pinpoint the best collocate in a
language vs. another.
We also observed that quite frequently (in about
25% of the cases) the collocation did not conserve
its syntactic configuration. Either the verb — here,
</bodyText>
<page confidence="0.99843">
45
</page>
<bodyText confidence="0.971843612244898">
the equivalent for the French mener — is omitted
in translations (like in 2.b below):
2.a) des contradictions existent dans la
politique qui est men´ee (Fr);
2.b) we are dealing with contradictory
policy (En),
or, in a few other cases, the whole collocation
disappears, since paraphrased with a completely
different syntactic construction:
3.a) direction qui a men´e une politique
insens´ee de r´eduction de personnel
(Fr);
3.b) a management that foolishly en-
gaged in staff reductions (En).
In order to quantify the impact such factors have
on the performance of the AM considered, we
further scrutinized the collocates list for politique
proposed by LL test for each language (see Table
2). The rank of a pair in the whole list of verb-
object collocations extracted, as assigned by the
LL test, is shown in the last column. In these sig-
nificance lists, the collocations with politique as an
object constitute a small fraction, and from these,
only the top collocations are displayed in Table 2.
The threshold was manually defined in accordance
with our intuition that the lower-scored pairs ob-
served manifest less a collocational strength. It
happens to be situated around the LL value of 20
for each language (and is of course specific to the
size of our corpus and to the number of V-O tokens
identified therein).
If we consider the LL rank as the success mea-
sure for collocate detection, we can infer that the
collocates of the word under investigation are eas-
ier to found in French, as compared to English,
Italian or Spanish, because the value in the first
row of the last column is smaller. This holds if we
are interested in only one (the most salient) collo-
cate for a word.
If we measure the success of retrieving all the
collocates (by considering, for instance, the speed
to access them in the results list — the higher the
rank, the better), then French can be again consid-
ered the easiest because overall, the positions in
the V-O list are higher (i.e., the mean of the rank
column is smaller) with respect to Spanish, Italian
and, respectively, English.
This latter result corresponds, approximately,
to the order given by relative proportion of V-O
</bodyText>
<table confidence="0.9997854">
Language collocate freq LL score rank
French mener 74 376.8 45
politique ´elaborer 17 50.1 734
adapter 5 48.3 780
axer 8 41.4 955
pratiquer 9 39.7 1011
d´evelopper 13 28.1 1599
adapter 8 25.2 1867
poursuivre 11 24.4 1943
English pursue 39 214.9 122
policy implement 38 108.7 325
develop 30 81.1 473
conduct 8 28.9 2014
harmonize 9 28.2 2090
gear 5 27.7 2201
need 25 24.9 2615
apply 16 23.3 2930
Spanish practicar 17 98.7 246
politica desarrollar 27 82.4 312
aplicar 25 65.7 431
seguir 17 33.5 1003
coordinar 8 31.0 1112
basar 11 25.1 1473
orientar 6 22.5 1707
adaptar 5 20.0 1987
construir 6 19.4 2057
Italian attuare 23 79.5 382
politica perseguire 14 46.4 735
praticare 8 37.6 976
seguire 18 30.2 1314
portare 12 29.7 1348
rivedere 9 26.0 1607
riformare 7 25.6 1639
sviluppare 12 22.1 1975
adottare 20 21.2 2087
</table>
<tableCaption confidence="0.998517">
Table 2: Verbal collocates for the headword policy
</tableCaption>
<bodyText confidence="0.9995378">
pairs in each language (Spanish 15.12%, French
15.14%, Italian 17.06%, and English 20.82%).
Given that in English V-O pairs are more numer-
ous and the verbs also participate in V-P construc-
tions, it might seem reasonable to expect lower
LL scores for V-O collocations in English vs. the
other 3 languages.
In general, we expect a correlation between ex-
traction difficulty and the distributional properties
of co-occurrence types.
</bodyText>
<sectionHeader confidence="0.992492" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999841">
The paper pointed out several issues that oc-
cur in transfering a hybrid collocation extraction
methodology (that combines linguistic with statis-
tic information) to a new language.
Besides the questionable availability of
language-specific text analysis tools for the new
language, a number of issues that are relevant to
extraction proper were addressed: the changes
in the distribution of (syntactic) word pairs, and
the need to find, for each language, the most
</bodyText>
<page confidence="0.998454">
46
</page>
<bodyText confidence="0.999989644444445">
appropriate association measure to apply for each
syntactic type (given that AMs are sensitive to
distributions and syntactic types); the lack of
a priori defined syntactic types for a language;
and, finally, the portability of some widely used
techniques (such as the window method) from
English to other languages exhibiting a higher
word order freedom.
It is again in the multilingualism perspective
that the inescapable need for preprocessing the
text emerged (cf. different researchers cited in sec-
tion 3): highly inflected languages need lemma-
tizers, free-word order languages need structural
information in order to guarantee acceptable re-
sults. As language tools become nowadays more
and more available, we expect the collocation ex-
traction (and terminology acquisition in general)
to be exclusively performed in the future by re-
lying on linguistic analysis. We therefore believe
that multilingualism is a true concern for colloca-
tion extraction.
The paper reviewed the extraction work in a
language-oriented fashion, while mentioning the
type of linguistic preprocessing performed when-
ever it was the case, as well as the language-
specific issues identified by the authors. It then
proposed a strategy for implementing a multilin-
gual extraction procedure that takes into account
the language-specific issues identified.
An extraction system for four different lan-
guages, based on full parsing, was then described.
Finally, an experiment was carried out as a case
study, which pointed out several factors that might
determine a particular AM to perform differently
across languages. The experiment suggested that
log-likelihood ratios test might highlight certain
verb-object collocations easier in French than in
Spanish, Italian and English (in terms of salience
in the significance list).
Future work needs to extend the type of cross-
linguistic analysis initiated here, in order to pro-
vide more insights on the differences expected at
extraction between one language and another and
on the responsible factors, and, accordingly, to de-
fines strategies to deal with them.
</bodyText>
<sectionHeader confidence="0.984585" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998899333333333">
The research described in this paper has been sup-
ported in part by a grant from the Swiss National
Foundation (No. 101412-103999).
</bodyText>
<sectionHeader confidence="0.977422" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998507490566038">
Hiyan Alshawi and David Carter. 1994. Training
and scaling preference functions for disambiguation.
Computational Linguistics, 20(4):635–648.
Roberto Basili, Maria Teresa Pazienza, and Paola Ve-
lardi. 1994. A ”not-so-shallow” parser for colloca-
tional analysis. In Proceedings of the 15th confer-
ence on Computational linguistics, pages 447–453,
Kyoto, Japan. Association for Computational Lin-
guistics.
Morton Benson. 1990. Collocations and general-
purpose dictionaries. International Journal of Lexi-
cography, 3(1):23–35.
Godelieve L. M. Berry-Rogghe. 1973. The com-
putation of collocations and their relevance to lex-
ical studies. In A. J. Aitken, R. W. Bailey, and
N. Hamilton-Smith, editors, The Computer and Lit-
erary Studies, pages 103–112. Edinburgh.
Didier Bourigault. 1992. Surface grammatical analysis
for the extraction of terminological noun phrases. In
Proceedings of the 15th International Conference on
Computational Linguistics, pages 977–981, Nantes,
France.
Elisabeth Breidt. 1993. Extraction of V-N-collocations
from text corpora: A feasibility study for Ger-
man. In Proceedings of the Workshop on Very
Large Corpora: Academic and Industrial Perspec-
tives, Columbus, U.S.A.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1991. Word-
sense disambiguation using statistical methods. In
Proceedings of the 29th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 1991),
pages 264–270, Berkeley, California.
Nicoletta Calzolari and Remo Bindi. 1990. Acqui-
sition of lexical information from a large textual
Italian corpus. In Proceedings of the 13th Inter-
national Conference on Computational Linguistics,
pages 54–59, Helsinki, Finland.
Yaacov Choueka. 1988. Looking for needles in a
haystack, or locating interesting collocational ex-
pressions in large textual databases. In Proceedings
of the International Conference on User-Oriented
Content-Based Text and Image Handling, pages
609–623, Cambridge, U.S.A.
Kenneth Church and Patrick Hanks. 1990. Word as-
sociation norms, mutual information, and lexicogra-
phy. Computational Linguistics, 16(1):22–29.
Kenneth Church, William Gale, Patrick Hanks, and
Donald Hindle. 1989. Parsing, word associations
and typical predicate-argument relations. In Pro-
ceedings of the International Workshop on Parsing
Technologies, pages 103–112, Pittsburgh. Carnegie
Mellon University.
</reference>
<page confidence="0.994915">
47
</page>
<reference confidence="0.996636650943396">
D. Alan Cruse. 1986. Lexical Semantics. Cambridge
University Press, Cambridge.
B´eatrice Daille. 1994. Approche mixte pour
l’extraction automatique de terminologie : statis-
tiques lexicales et filtres linguistiques. Ph.D. thesis,
Universit´e Paris 7.
Ga¨el Dias. 2003. Multiword unit hybrid extraction.
In Proceedings of the ACL Workshop on Multiword
Expressions, pages 41–48, Sapporo, Japan.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Stefan Evert and Brigitte Krenn. 2001. Methods for
the qualitative evaluation of lexical association mea-
sures. In Proceedings of the 39th Annual Meeting
of the Association for Computational Linguistics,
pages 188–195, Toulouse, France.
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
University of Stuttgart.
John Rupert Firth, 1957. Papers in Linguistics 1934-
1951, chapter Modes of Meaning, pages 190–215.
Oxford Univ. Press, Oxford.
J. R. Firth. 1968. A synopsis of linguistic theory,
1930–55. In F.R. Palmer, editor, Selected papers
of J. R. Firth, 1952-1959. Indiana University Press,
Bloomington.
Thierry Fontenelle. 1992. Collocation acquisition
from a corpus or from a dictionary: a comparison.
Proceedings I-II. Papers submitted to the 5th EU-
RALEX International Congress on Lexicography in
Tampere, pages 221–228.
Katerina T. Frantzi, Sophia Ananiadou, and Hideki
Mima. 2000. Automatic recognition of multi-word
terms: the C-value/NC-value method. International
Journal on Digital Libraries, 2(3):115–130.
Jean-Philippe Goldman, Luka Nerima, and Eric
Wehrli. 2001. Collocation extraction using a syn-
tactic parser. In Proceedings of the ACL Workshop
on Collocations, pages 61–66, Toulouse, France.
Maurice Gross. 1984. Lexicon-grammar and the syn-
tactic analysis of French. In Proceedings of the 22nd
conference on Association for Computational Lin-
guistics, pages 275–282, Morristown, NJ, USA.
Franz Iosef Hausmann. 1985. Kollokationen im
deutschen w¨orterbuch. ein beitrag zur theorie des
lexikographischen beispiels”. In Henning Bergen-
holtz and Joachim Mugdan, editors, Lezikographie
und Grammatik. Akten des Essener Kolloquiums zur
Grammatik im W¨orterbuch., Lexicographica. Series
Major 3, pages 118–129.
Ulrich Heid. 1994. On ways words work together -
research topics in lexical combinatorics. In W. Mar-
tin, W. Meijs, M. Moerland, E. ten Pas, P. van
Sterkenburg, and P. Vossen, editors, Proceedings of
the VIth Euralex International Congress (EURALEX
’94), pages 226–257, Amsterdam.
Chu-Ren Huang, Adam Kilgarriff, Yiching Wu, Chih-
Ming Chiu, Simon Smith, Pavel Rychly, Ming-Hong
Bai, and Keh-Jiann Chen. 2005. Chinese Sketch
Engine and the extraction of grammatical colloca-
tions. In Proceedings of the Fourth SIGHAN Work-
shop on Chinese Language Processing, pages 48–
55, Jeju Island, Republic of Korea.
Satoru Ikehara, Satoshi Shirai, and Tsukasa Kawaoka.
1995. Automatic extraction of uninterrupted collo-
cations by n-gram statistics. In Proceedings offirst
Annual Meeting of the Association for Natural Lan-
guage Processing, pages 313–316.
Ray Jackendoff. 1997. The Architecture of the Lan-
guage Faculty. MIT Press, Cambridge, MA.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: Some linguistis properties and an al-
gorithm for identification in text. Natural Language
Engineering, 1:9–27.
Seonho Kim, Zooil Yang, Mansuk Song, and Jung-Ho
Ahn. 1999. Retrieving collocations from Korean
text. In Proceedings of the 1999 Joint SIGDAT Con-
ference on Empirical Methods in Natural Language
Processing and Very Large Corpora, pages 71–81,
Maryland, U.S.A.
Mihoko Kitamura and Yuji Matsumoto. 1996. Auto-
matic extraction of word sequence correspondences
in parallel corpora. In Proceedings of the 4th Work-
shop on Very Large Corpora, pages 79–87, Copen-
hagen, Denmark, August.
G¨oran Kjellmer. 1994. A Dictionary of English Collo-
cations. Claredon Press, Oxford.
Brigitte Krenn and Stefan Evert. 2001. Can we do
better than frequency? A case study on extracting
PP-verb collocations. In Proceedings of the ACL
Workshop on Collocations, pages 39–46, Toulouse,
France.
Julian Kupiec. 1993. An algorithm for finding noun
phrase correspondences in bilingual corpora. In 31st
Annual Meeting of the Association for Computa-
tional Linguistics, pages 17–22, Columbus, Ohio,
U.S.A.
P. Lafon. 1984. D´epouillement et statistique en
l´exicometrie. Slatkine-Champion, Paris.
Michael Lewis. 2000. Teaching Collocations. Further
Developments In The Lexical Approach. Language
Teaching Publications, Hove.
Dekang Lin. 1998. Extracting collocations from text
corpora. In First Workshop on Computational Ter-
minology, pages 57–63, Montreal.
</reference>
<page confidence="0.983464">
48
</page>
<reference confidence="0.999694551020408">
Qin Lu, Yin Li, and Ruifeng Xu. 2004. Improving
Xtract for Chinese collocation extraction. In Pro-
ceedings of IEEE International Conference on Natu-
ral Language Processing and Knowledge Engineer-
ing, pages 333–338.
Kathleen R. McKeown and Dragomir R. Radev. 2000.
Collocations. In Robert Dale, Hermann Moisl,
and Harold Somers, editors, A Handbook of Nat-
ural Language Processing, pages 507–523. Marcel
Dekker, New York, U.S.A.
I. Dan Melamed. 1997. A portable algorithm for
mapping bitext correspondence. In Proceedings of
the 35th Conference of the Association for Com-
putational Linguistics (ACL’97), pages 305–312,
Madrid, Spain.
Igor Mel’ˇcuk. 1998. Collocations and lexical func-
tions. In Anthony P. Cowie, editor, Phraseology.
Theory, Analysis, and Applications, pages 23–53.
Claredon Press, Oxford.
Igor Mel’ˇcuk. 2003. Collocations: d´efinition, rˆole et
utilit´e. In Francis Grossmann and Agn`es Tutin, ed-
itors, Les collocations: analyse et traitement, pages
23–32. Editions ”De Werelt”, Amsterdam.
Darren Pearce. 2001. Synonymy in collocation extrac-
tion. In WordNet and Other Lexical Resources: Ap-
plications, Extensions and Customizations (NAACL
2001 Workshop), pages 41–46, Pittsburgh, U.S.A.
Pavel Pecina. 2005. An extensive empirical study of
collocation extraction methods. In Proceedings of
the ACL Student Research Workshop, pages 13–18,
Ann Arbor, Michigan, June.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1–15, Mexico City.
Violeta Seretan and Eric Wehrli. 2006. Accurate col-
location extraction using a multilingual parser. In
Proceedings of COLING/ACL 2006. To appear.
Violeta Seretan, Luka Nerima, and Eric Wehrli. 2004.
A tool for multi-word collocation extraction and vi-
sualization in multilingual corpora. In Proceedings
of the Eleventh EURALEX International Congress,
EURALEX 2004, pages 755–766, Lorient, France.
Violeta Seretan. 2005. Induction of syntactic col-
location patterns from generic syntactic relations.
In Proceedings of Nineteenth International Joint
Conference on Artificial Intelligence (IJCAI 2005),
pages 1698–1699, Edinburgh, Scotland, July.
Sayori Shimohata, Toshiyuki Sugio, and Junji Nagata.
1997. Retrieving collocations by co-occurrences
and word order constraints. In Proceedings of the
Annual Meeting of the Association for Computa-
tional Linguistics, pages 476–481, Madrid, Spain.
John Sinclair. 1995. Collins Cobuild English Dictio-
nary. Harper Collins, London.
Frank Smadja, Kathleen McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: a statistical approach. Computa-
tional Linguistics, 22(1):1–38.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics, 19(1):143–
177.
Eric Wehrli. 2003. Translation of words in context.
In Proceedings of Machine Translation Summit IX,
pages 502–504, New Orleans, Lousiana, U.S.A.
Eric Wehrli. 2004. Un mod`ele multilingue d’analyse
syntaxique. In A. Auchlin et al., editor, Structures
et discours - M´elanges offerts a` Eddy Roulet, pages
311–329. ´Editions Nota bene, Qu´ebec.
Joachim Wermter and Udo Hahn. 2004. Collocation
extraction based on modifiability statistics. In Pro-
ceedings of the 20th International Conference on
Computational Linguistics (COLING 2004), pages
980–986, Geneva, Switzerland.
Dekai Wu. 1994. Aligning a parallel English-Chinese
corpus statistically with lexical criteria. In Proceed-
ings of the 32nd Annual Meeting of the Association
for Computational Linguistics (ACL 1994), pages
80–87, Las Cruces (New Mexico), U.S.A.
Diana Zaiu Inkpen and Graeme Hirst. 2002. Ac-
quiring collocations for lexical choice between near-
synonyms. In Proceedings of the ACL-02 Workshop
on Unsupervised Lexical Acquisition, pages 67–76,
Philadephia, Pennsylvania.
R´emi Zajac, Elke Lange, and Jin Yang. 2003. Cus-
tomizing complex lexical entries for high-quality
MT. In Proceedings of the Ninth Machine Trans-
lation Summit, New Orleans, U.S.A.
Heike Zinsmeister and Ulrich Heid. 2003. Signif-
icant triples: Adjective+Noun+Verb combinations.
In Proceedings of the 7th Conference on Compu-
tational Lexicography and Text Research (Complex
2003), Budapest.
Heike Zinsmeister and Ulrich Heid. 2004. Colloca-
tions of complex nouns: Evidence for lexicalisation.
In Proceedings of KONVENS 2004, Vienna, Austria.
</reference>
<page confidence="0.999543">
49
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.482806">
<title confidence="0.999382">Multilingual Collocation Extraction: Issues and Solutions</title>
<author confidence="0.886702">Violeta</author>
<affiliation confidence="0.9901525">Language Technology University of</affiliation>
<address confidence="0.907982">2, rue de Candolle, 1211</address>
<title confidence="0.756352">Violeta.Seretan@latl.unige.ch</title>
<author confidence="0.96145">Eric</author>
<affiliation confidence="0.9978525">Language Technology University of</affiliation>
<address confidence="0.960705">2, rue de Candolle, 1211</address>
<email confidence="0.846538">Eric.Wehrli@latl.unige.ch</email>
<abstract confidence="0.999863823529412">Although traditionally seen as a languageindependent task, collocation extraction relies nowadays more and more on the linguistic preprocessing of texts (e.g., lemmatization, POS tagging, chunking or parsing) prior to the application of statistical measures. This paper provides a language-oriented review of the existing extraction work. It points out several language-specific issues related to extraction and proposes a strategy for coping with them. It then describes a hybrid extraction system based on a multilingual parser. Finally, it presents a case-study on the performance of an association measure across a number of languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>David Carter</author>
</authors>
<title>Training and scaling preference functions for disambiguation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2710" citStr="Alshawi and Carter, 1994" startWordPosition="398" endWordPosition="401">antic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Ch</context>
</contexts>
<marker>Alshawi, Carter, 1994</marker>
<rawString>Hiyan Alshawi and David Carter. 1994. Training and scaling preference functions for disambiguation. Computational Linguistics, 20(4):635–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Maria Teresa Pazienza</author>
<author>Paola Velardi</author>
</authors>
<title>A ”not-so-shallow” parser for collocational analysis.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on Computational linguistics,</booktitle>
<pages>447--453</pages>
<institution>Kyoto, Japan. Association for Computational Linguistics.</institution>
<contexts>
<context position="6375" citStr="Basili et al., 1994" startWordPosition="954" endWordPosition="957">obabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extraction work. Then we highlight, in sec</context>
<context position="11712" citStr="Basili et al., 1994" startWordPosition="1813" endWordPosition="1816">st a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language</context>
</contexts>
<marker>Basili, Pazienza, Velardi, 1994</marker>
<rawString>Roberto Basili, Maria Teresa Pazienza, and Paola Velardi. 1994. A ”not-so-shallow” parser for collocational analysis. In Proceedings of the 15th conference on Computational linguistics, pages 447–453, Kyoto, Japan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morton Benson</author>
</authors>
<title>Collocations and generalpurpose dictionaries.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1987" citStr="Benson, 1990" startWordPosition="288" endWordPosition="289">egular productions, (big house, cultural activity, read a book), collocational expressions are highly idiosyncratic, since the lexical items a headword combines with in order to express a given meaning is contingent upon that word (Mel’ˇcuk, 2003). This is apparent when comparing a collocation’s equivalents across different languages. The English collocation ask a question translates as poser une question in French (lit., ?put a question), and as fare una domanda, hacer una pregunta in Italian and Spanish (lit., to make a question). As it has been pointed out by many researchers (Cruse, 1986; Benson, 1990; McKeown and Radev, 2000), collocations cannot be described by means of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a</context>
<context position="18145" citStr="Benson, 1990" startWordPosition="2810" endWordPosition="2811"> the source corpus for extracting the lexical pairs in the relevant, language-specific syntactic configurations found in step B; Stage 2. ranking the pairs from each syntactic class with the AM assigned in step C. 5 A Multilingual Collocation Extractor Based on Parsing Ever since the collocation was brought to the attention of linguists in the framework of contextualism (Firth, 1957; Firth, 1968), it has been preponderantly seen as a pure statistical phenomenon of lexical association. In fact, according to a wellknown definition, “a collocation is an arbitrary and recurrent word combination” (Benson, 1990). This approach was at the basis of the computational work on collocation, although there exist an alternative approach — the linguistic, or lexicographic one — that imposes a restricted view on collocation, which is seen first of all as an expression of language. The existing extraction work (section 3) shows that there is a growing interest in adopting the more restricted (linguistic) view. As mentioned in section 3, the importance of parsing for extraction was confirmed by several evaluation experiments. With the recent development in the field of linguistic analysis, hybrid extraction syst</context>
</contexts>
<marker>Benson, 1990</marker>
<rawString>Morton Benson. 1990. Collocations and generalpurpose dictionaries. International Journal of Lexicography, 3(1):23–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Godelieve L M Berry-Rogghe</author>
</authors>
<title>The computation of collocations and their relevance to lexical studies. In</title>
<date>1973</date>
<booktitle>The Computer and Literary Studies,</booktitle>
<pages>103--112</pages>
<editor>A. J. Aitken, R. W. Bailey, and N. Hamilton-Smith, editors,</editor>
<location>Edinburgh.</location>
<contexts>
<context position="3306" citStr="Berry-Rogghe, 1973" startWordPosition="486" endWordPosition="487">hawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word c</context>
</contexts>
<marker>Berry-Rogghe, 1973</marker>
<rawString>Godelieve L. M. Berry-Rogghe. 1973. The computation of collocations and their relevance to lexical studies. In A. J. Aitken, R. W. Bailey, and N. Hamilton-Smith, editors, The Computer and Literary Studies, pages 103–112. Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Didier Bourigault</author>
</authors>
<title>Surface grammatical analysis for the extraction of terminological noun phrases.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>977--981</pages>
<location>Nantes, France.</location>
<contexts>
<context position="10816" citStr="Bourigault, 1992" startWordPosition="1671" endWordPosition="1672"> their results with those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adverb, Det - determiner, Conj - conjunction, P - preposition. 3.3 French Thanks to the outstanding work of Gross on lexicon-grammar (1984), French is one of the most studied languages in terms of distributional and transformational potential of words. This work has been carried out before the computer era and the advent of corpus linguistics, while automatic extraction was later performed, for instance, in (Lafon, 1984; Daille, 1994; Bourigault, 1992; Goldman et al., 2001). Daille (1994) aimed at extracting compound nouns, defined a priori by means of certain syntactic patterns, like N-A, N-N, N-`a-N, N-de-N, N P Det N. She used a lemmatizer and a POS-tagger before applying a series of AMs, which she then evaluated against a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In</context>
</contexts>
<marker>Bourigault, 1992</marker>
<rawString>Didier Bourigault. 1992. Surface grammatical analysis for the extraction of terminological noun phrases. In Proceedings of the 15th International Conference on Computational Linguistics, pages 977–981, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Breidt</author>
</authors>
<title>Extraction of V-N-collocations from text corpora: A feasibility study for German.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<location>Columbus, U.S.A.</location>
<contexts>
<context position="5922" citStr="Breidt, 1993" startWordPosition="881" endWordPosition="882">aim at coping with the problem of morphosyntactic variation, in order to improve the accuracy of frequency information. This becomes truly important especially for free-word order and for high-inflection languages, for which the token(form)-based frequency figures become too skewed due to the high lexical dispersion. Not only the data scattering modify the frequency numbers used by AMs, but it also alters the performance of AMs, if the the probabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were al</context>
<context position="8856" citStr="Breidt (1993)" startWordPosition="1362" endWordPosition="1363">ntinued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, thanks to the early work of Breidt (1993) and, more recently, to that of Krenn and Evert, such as (Krenn and Evert, 2001; Evert and Krenn, 2001; Evert, 2004) centered on evaluation. Breidt uses MI and t-score and compares the results accuracy when various parameters vary, such as the window size, presence vs. absence of lemmatization, corpus size, and presence vs. absence of POS and syntactic information. She focuses on N-V pairs2 and, despite the lack of syntactic analysis tools at the time, by simulating parsing she comes to the conclusion that “Very high precision rates, which are an indispensable requirement for lexical acquisiti</context>
<context position="16203" citStr="Breidt (1993)" startWordPosition="2508" endWordPosition="2509">ion pairs is a usual practice, since this span length was shown sufficient to cover a high percentage of syntactic co-occurrences in English. But — as suggested by other researchers, e.g., (Goldman et al., 2001) —, this assumption does not necessary hold for other languages. Similarly, the higher inflection and the higher transformation potential shown by some languages pose additional problems in extraction, which were rather ignored for English. As Kim et al. (1999) notice, collocation extraction is particularly difficult in free-order languages like Korean, where arguments scramble freely. Breidt (1993) also pointed out a couple of problems that makes extraction for German more difficult than for English: the strong inflection for verbs, the variable word-order, and the positional ambiguity of the arguments. She shows that even distinguishing subjects from objects is very difficult without parsing. 4.2 A Strategy for Multilingual Extraction Summing up the previous discussion, the customization of collocation extraction for a given language needs to take into account: - the syntactic configurations characterizing collocations, - the lexical distribution over syntactic configurations, - the ad</context>
</contexts>
<marker>Breidt, 1993</marker>
<rawString>Elisabeth Breidt. 1993. Extraction of V-N-collocations from text corpora: A feasibility study for German. In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, Columbus, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Wordsense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>264--270</pages>
<location>Berkeley, California.</location>
<contexts>
<context position="2671" citStr="Brown et al., 1991" startWordPosition="392" endWordPosition="395">eans of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only par</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1991</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1991. Wordsense disambiguation using statistical methods. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL 1991), pages 264–270, Berkeley, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
<author>Remo Bindi</author>
</authors>
<title>Acquisition of lexical information from a large textual Italian corpus.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<pages>54--59</pages>
<location>Helsinki, Finland.</location>
<contexts>
<context position="11654" citStr="Calzolari and Bindi (1990)" startWordPosition="1802" endWordPosition="1805"> before applying a series of AMs, which she then evaluated against a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), mos</context>
</contexts>
<marker>Calzolari, Bindi, 1990</marker>
<rawString>Nicoletta Calzolari and Remo Bindi. 1990. Acquisition of lexical information from a large textual Italian corpus. In Proceedings of the 13th International Conference on Computational Linguistics, pages 54–59, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaacov Choueka</author>
</authors>
<title>Looking for needles in a haystack, or locating interesting collocational expressions in large textual databases.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on User-Oriented Content-Based Text and Image Handling,</booktitle>
<pages>609--623</pages>
<location>Cambridge, U.S.A.</location>
<contexts>
<context position="7484" citStr="Choueka, 1988" startWordPosition="1133" endWordPosition="1134">rovide a language-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., </context>
</contexts>
<marker>Choueka, 1988</marker>
<rawString>Yaacov Choueka. 1988. Looking for needles in a haystack, or locating interesting collocational expressions in large textual databases. In Proceedings of the International Conference on User-Oriented Content-Based Text and Image Handling, pages 609–623, Cambridge, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="6340" citStr="Church and Hanks, 1990" startWordPosition="948" endWordPosition="951"> the performance of AMs, if the the probabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extract</context>
<context position="8480" citStr="Church and Hanks, 1990" startWordPosition="1298" endWordPosition="1301">s the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, thanks to the early work of Breidt (1993) and, more recently, to that of Krenn and Evert, such as (Krenn and Evert, 2001; Evert and Krenn, 2001; Evert, 2004) centered on evaluation. Breidt uses MI and t-score and compares the results accuracy when various parameter</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>William Gale</author>
<author>Patrick Hanks</author>
<author>Donald Hindle</author>
</authors>
<title>Parsing, word associations and typical predicate-argument relations.</title>
<date>1989</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies,</booktitle>
<pages>103--112</pages>
<institution>Pittsburgh. Carnegie Mellon University.</institution>
<contexts>
<context position="3327" citStr="Church et al., 1989" startWordPosition="488" endWordPosition="491">4). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequenc</context>
<context position="7505" citStr="Church et al., 1989" startWordPosition="1135" endWordPosition="1138">ge-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1989</marker>
<rawString>Kenneth Church, William Gale, Patrick Hanks, and Donald Hindle. 1989. Parsing, word associations and typical predicate-argument relations. In Proceedings of the International Workshop on Parsing Technologies, pages 103–112, Pittsburgh. Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Alan Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="1973" citStr="Cruse, 1986" startWordPosition="286" endWordPosition="287">ly from the regular productions, (big house, cultural activity, read a book), collocational expressions are highly idiosyncratic, since the lexical items a headword combines with in order to express a given meaning is contingent upon that word (Mel’ˇcuk, 2003). This is apparent when comparing a collocation’s equivalents across different languages. The English collocation ask a question translates as poser une question in French (lit., ?put a question), and as fare una domanda, hacer una pregunta in Italian and Spanish (lit., to make a question). As it has been pointed out by many researchers (Cruse, 1986; Benson, 1990; McKeown and Radev, 2000), collocations cannot be described by means of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations a</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. Alan Cruse. 1986. Lexical Semantics. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B´eatrice Daille</author>
</authors>
<title>Approche mixte pour l’extraction automatique de terminologie : statistiques lexicales et filtres linguistiques.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e Paris</institution>
<contexts>
<context position="10798" citStr="Daille, 1994" startWordPosition="1669" endWordPosition="1670">) and compared their results with those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adverb, Det - determiner, Conj - conjunction, P - preposition. 3.3 French Thanks to the outstanding work of Gross on lexicon-grammar (1984), French is one of the most studied languages in terms of distributional and transformational potential of words. This work has been carried out before the computer era and the advent of corpus linguistics, while automatic extraction was later performed, for instance, in (Lafon, 1984; Daille, 1994; Bourigault, 1992; Goldman et al., 2001). Daille (1994) aimed at extracting compound nouns, defined a priori by means of certain syntactic patterns, like N-A, N-N, N-`a-N, N-de-N, N P Det N. She used a lemmatizer and a POS-tagger before applying a series of AMs, which she then evaluated against a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 </context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>B´eatrice Daille. 1994. Approche mixte pour l’extraction automatique de terminologie : statistiques lexicales et filtres linguistiques. Ph.D. thesis, Universit´e Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ga¨el Dias</author>
</authors>
<title>Multiword unit hybrid extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL Workshop on Multiword Expressions,</booktitle>
<pages>41--48</pages>
<location>Sapporo, Japan.</location>
<marker>Ga¨el Dias, 2003</marker>
<rawString>Ga¨el Dias. 2003. Multiword unit hybrid extraction. In Proceedings of the ACL Workshop on Multiword Expressions, pages 41–48, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="20683" citStr="Dunning, 1993" startWordPosition="3212" endWordPosition="3213"> pairs are identified as the parsing goes on; in other approaches, they are extracted by post-processing the output of syntactic tools. The candidate pairs identified are classified into syntactically homogenous sets, according to the syntactic relations holding between the two items. Only certain predefined syntactic relations are kept, that were judged as collocationally relevant after multiple experiments of extraction and data analysis (e.g., adjective-noun, verb-object, subject-verb, noun-noun, verb-preposition-noun). The sets obtained are then ranked using the loglikelihood ratios test (Dunning, 1993). More details about the system and its performance can be found in (Seretan and Wehrli, 2006). The following examples (taken from the extraction experiment we will describe below) illustrate its potential to detect collocation candidates, even if these are subject to complex syntactic transformations: 1.a) atteindre objectif (Fr): Les objectifs fix´es a` l’´echelle internationale visant a` r´eduire les ´emissions ne peuvent pas ˆetre atteints a` l’aide de ces seuls programmes. 1.b) accogliere emendamento (It): 44 Posso pertanto accogliere in parte e in linea di principio gli emendamenti nn. 4</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>188--195</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="8958" citStr="Evert and Krenn, 2001" startWordPosition="1379" endWordPosition="1382">lidate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, thanks to the early work of Breidt (1993) and, more recently, to that of Krenn and Evert, such as (Krenn and Evert, 2001; Evert and Krenn, 2001; Evert, 2004) centered on evaluation. Breidt uses MI and t-score and compares the results accuracy when various parameters vary, such as the window size, presence vs. absence of lemmatization, corpus size, and presence vs. absence of POS and syntactic information. She focuses on N-V pairs2 and, despite the lack of syntactic analysis tools at the time, by simulating parsing she comes to the conclusion that “Very high precision rates, which are an indispensable requirement for lexical acquisition, can only realistically be envisaged for German with parsed corpora” (Breidt, 1993, 82). Later, Kre</context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 188–195, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="4626" citStr="Evert, 2004" startWordPosition="677" endWordPosition="678">types of lexical association measures (henceforth AMs) we mention: statistical hypothesis tests (e.g., binomial, Poisson, Fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on a contingency table listing their joint and marginal frequency, and Information-theoretic measures (Mutual Information — henceforth MI — and its variants), that quantity of ‘information’ shared by two random variables. A detailed review of the statistical methods employed in collocation extraction can be found, for instance, in (Evert, 2004). A comprehensive list of AMs is given (Pecina, 2005). Very often, in addition to the information on cooccurrence frequency, language-specific information is also integrated in a collocation extraction system (as it will be seen in section 3): - morphological information, in order to count inflected word forms as instances of the same base form. For instance, ask questions, asks question, asked question are all instances of the same word pair, ask - question; - syntactic information, in order to recognize a word pair even if subject to (complex) syntactic transformations: ask multiple question</context>
<context position="8972" citStr="Evert, 2004" startWordPosition="1383" endWordPosition="1384"> parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, thanks to the early work of Breidt (1993) and, more recently, to that of Krenn and Evert, such as (Krenn and Evert, 2001; Evert and Krenn, 2001; Evert, 2004) centered on evaluation. Breidt uses MI and t-score and compares the results accuracy when various parameters vary, such as the window size, presence vs. absence of lemmatization, corpus size, and presence vs. absence of POS and syntactic information. She focuses on N-V pairs2 and, despite the lack of syntactic analysis tools at the time, by simulating parsing she comes to the conclusion that “Very high precision rates, which are an indispensable requirement for lexical acquisition, can only realistically be envisaged for German with parsed corpora” (Breidt, 1993, 82). Later, Krenn and Evert (</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. The Statistics of Word Cooccurrences: Word Pairs and Collocations. Ph.D. thesis, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Rupert Firth</author>
</authors>
<title>Papers in Linguistics 1934-1951, chapter Modes of Meaning,</title>
<date>1957</date>
<pages>190--215</pages>
<publisher>Univ. Press,</publisher>
<location>Oxford</location>
<contexts>
<context position="17917" citStr="Firth, 1957" startWordPosition="2775" endWordPosition="2776">luate the adequacy of AMs for ranking collocations in each syntactic configuration, and find the most convenient mapping configurations - AMs. Once customized for a language, the extraction procedure involves: Stage 1. parsing the source corpus for extracting the lexical pairs in the relevant, language-specific syntactic configurations found in step B; Stage 2. ranking the pairs from each syntactic class with the AM assigned in step C. 5 A Multilingual Collocation Extractor Based on Parsing Ever since the collocation was brought to the attention of linguists in the framework of contextualism (Firth, 1957; Firth, 1968), it has been preponderantly seen as a pure statistical phenomenon of lexical association. In fact, according to a wellknown definition, “a collocation is an arbitrary and recurrent word combination” (Benson, 1990). This approach was at the basis of the computational work on collocation, although there exist an alternative approach — the linguistic, or lexicographic one — that imposes a restricted view on collocation, which is seen first of all as an expression of language. The existing extraction work (section 3) shows that there is a growing interest in adopting the more restri</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John Rupert Firth, 1957. Papers in Linguistics 1934-1951, chapter Modes of Meaning, pages 190–215. Oxford Univ. Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Firth</author>
</authors>
<title>A synopsis of linguistic theory,</title>
<date>1968</date>
<pages>1930--55</pages>
<editor>In F.R. Palmer, editor, Selected papers of J. R. Firth,</editor>
<publisher>Indiana University Press,</publisher>
<location>Bloomington.</location>
<contexts>
<context position="17931" citStr="Firth, 1968" startWordPosition="2777" endWordPosition="2778">quacy of AMs for ranking collocations in each syntactic configuration, and find the most convenient mapping configurations - AMs. Once customized for a language, the extraction procedure involves: Stage 1. parsing the source corpus for extracting the lexical pairs in the relevant, language-specific syntactic configurations found in step B; Stage 2. ranking the pairs from each syntactic class with the AM assigned in step C. 5 A Multilingual Collocation Extractor Based on Parsing Ever since the collocation was brought to the attention of linguists in the framework of contextualism (Firth, 1957; Firth, 1968), it has been preponderantly seen as a pure statistical phenomenon of lexical association. In fact, according to a wellknown definition, “a collocation is an arbitrary and recurrent word combination” (Benson, 1990). This approach was at the basis of the computational work on collocation, although there exist an alternative approach — the linguistic, or lexicographic one — that imposes a restricted view on collocation, which is seen first of all as an expression of language. The existing extraction work (section 3) shows that there is a growing interest in adopting the more restricted (linguist</context>
</contexts>
<marker>Firth, 1968</marker>
<rawString>J. R. Firth. 1968. A synopsis of linguistic theory, 1930–55. In F.R. Palmer, editor, Selected papers of J. R. Firth, 1952-1959. Indiana University Press, Bloomington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Fontenelle</author>
</authors>
<title>Collocation acquisition from a corpus or from a dictionary: a comparison.</title>
<date>1992</date>
<booktitle>Proceedings I-II. Papers submitted to the 5th EURALEX International Congress on Lexicography in Tampere,</booktitle>
<pages>221--228</pages>
<contexts>
<context position="1093" citStr="Fontenelle, 1992" startWordPosition="150" endWordPosition="151">, lemmatization, POS tagging, chunking or parsing) prior to the application of statistical measures. This paper provides a language-oriented review of the existing extraction work. It points out several language-specific issues related to extraction and proposes a strategy for coping with them. It then describes a hybrid extraction system based on a multilingual parser. Finally, it presents a case-study on the performance of an association measure across a number of languages. 1 Introduction Collocations are understood in this paper as “idiosyncratic syntagmatic combination of lexical items” (Fontenelle, 1992, 222): heavy rain, light breeze, great difficulty, grow steadily, meet requirement, reach consensus, pay attention, ask a question. Unlike idioms (kick the bucket, lend a hand, pull someone’s leg), their meaning is fairly transparent and easy to decode. Yet, differently from the regular productions, (big house, cultural activity, read a book), collocational expressions are highly idiosyncratic, since the lexical items a headword combines with in order to express a given meaning is contingent upon that word (Mel’ˇcuk, 2003). This is apparent when comparing a collocation’s equivalents across di</context>
</contexts>
<marker>Fontenelle, 1992</marker>
<rawString>Thierry Fontenelle. 1992. Collocation acquisition from a corpus or from a dictionary: a comparison. Proceedings I-II. Papers submitted to the 5th EURALEX International Congress on Lexicography in Tampere, pages 221–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina T Frantzi</author>
<author>Sophia Ananiadou</author>
<author>Hideki Mima</author>
</authors>
<title>Automatic recognition of multi-word terms: the C-value/NC-value method.</title>
<date>2000</date>
<journal>International Journal on Digital Libraries,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="8105" citStr="Frantzi et al., 2000" startWordPosition="1229" endWordPosition="1232"> Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. </context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Katerina T. Frantzi, Sophia Ananiadou, and Hideki Mima. 2000. Automatic recognition of multi-word terms: the C-value/NC-value method. International Journal on Digital Libraries, 2(3):115–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Philippe Goldman</author>
<author>Luka Nerima</author>
<author>Eric Wehrli</author>
</authors>
<title>Collocation extraction using a syntactic parser.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations,</booktitle>
<pages>61--66</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="6408" citStr="Goldman et al., 2001" startWordPosition="960" endWordPosition="963">able become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a series of problems that</context>
<context position="8141" citStr="Goldman et al., 2001" startWordPosition="1235" endWordPosition="1238">ks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ra</context>
<context position="10839" citStr="Goldman et al., 2001" startWordPosition="1673" endWordPosition="1676">h those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adverb, Det - determiner, Conj - conjunction, P - preposition. 3.3 French Thanks to the outstanding work of Gross on lexicon-grammar (1984), French is one of the most studied languages in terms of distributional and transformational potential of words. This work has been carried out before the computer era and the advent of corpus linguistics, while automatic extraction was later performed, for instance, in (Lafon, 1984; Daille, 1994; Bourigault, 1992; Goldman et al., 2001). Daille (1994) aimed at extracting compound nouns, defined a priori by means of certain syntactic patterns, like N-A, N-N, N-`a-N, N-de-N, N P Det N. She used a lemmatizer and a POS-tagger before applying a series of AMs, which she then evaluated against a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, G</context>
<context position="15801" citStr="Goldman et al., 2001" startWordPosition="2448" endWordPosition="2451">ot ensure the necessary coverage, an alternative proposal is to induce them from POS data and dependency relations, as in (Seretan, 2005). The morphoyntactic differences between languages also have to be taken into account. With English as the most investigated language, several hypotheses were put forth in extraction and became common place. For instance, using a 5-words window as search space for collocation pairs is a usual practice, since this span length was shown sufficient to cover a high percentage of syntactic co-occurrences in English. But — as suggested by other researchers, e.g., (Goldman et al., 2001) —, this assumption does not necessary hold for other languages. Similarly, the higher inflection and the higher transformation potential shown by some languages pose additional problems in extraction, which were rather ignored for English. As Kim et al. (1999) notice, collocation extraction is particularly difficult in free-order languages like Korean, where arguments scramble freely. Breidt (1993) also pointed out a couple of problems that makes extraction for German more difficult than for English: the strong inflection for verbs, the variable word-order, and the positional ambiguity of the</context>
<context position="18913" citStr="Goldman et al., 2001" startWordPosition="2932" endWordPosition="2935">raphic one — that imposes a restricted view on collocation, which is seen first of all as an expression of language. The existing extraction work (section 3) shows that there is a growing interest in adopting the more restricted (linguistic) view. As mentioned in section 3, the importance of parsing for extraction was confirmed by several evaluation experiments. With the recent development in the field of linguistic analysis, hybrid extraction systems (i.e., systems relying on syntactical analysis for collocation extraction) are likely to become the rule rather than the exception. Our system (Goldman et al., 2001; Seretan and Wehrli, 2006) is — to our knowledge — the first to perform the full syntactic analysis as support for collocation extraction; similar approaches rely on dependency parsers or on chunking. It is based on a symbolic parser that was developed over the last decade (Wehrli, 2004) and achieves a high level of performance, in terms of accuracy, speed and robustness. The languages it supports are, for the time being, French, English, Italian, Spanish and German. A few other languages are being also implemented in the framework of a multilingualism project. Provided that collocation extra</context>
</contexts>
<marker>Goldman, Nerima, Wehrli, 2001</marker>
<rawString>Jean-Philippe Goldman, Luka Nerima, and Eric Wehrli. 2001. Collocation extraction using a syntactic parser. In Proceedings of the ACL Workshop on Collocations, pages 61–66, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Gross</author>
</authors>
<title>Lexicon-grammar and the syntactic analysis of French.</title>
<date>1984</date>
<booktitle>In Proceedings of the 22nd conference on Association for Computational Linguistics,</booktitle>
<pages>275--282</pages>
<location>Morristown, NJ, USA.</location>
<marker>Gross, 1984</marker>
<rawString>Maurice Gross. 1984. Lexicon-grammar and the syntactic analysis of French. In Proceedings of the 22nd conference on Association for Computational Linguistics, pages 275–282, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Iosef Hausmann</author>
</authors>
<title>Kollokationen im deutschen w¨orterbuch. ein beitrag zur theorie des lexikographischen beispiels”.</title>
<date>1985</date>
<booktitle>In Henning Bergenholtz and Joachim Mugdan, editors, Lezikographie und Grammatik. Akten des Essener Kolloquiums zur Grammatik im W¨orterbuch., Lexicographica. Series Major 3,</booktitle>
<pages>118--129</pages>
<contexts>
<context position="2272" citStr="Hausmann, 1985" startWordPosition="330" endWordPosition="331"> collocation’s equivalents across different languages. The English collocation ask a question translates as poser une question in French (lit., ?put a question), and as fare una domanda, hacer una pregunta in Italian and Spanish (lit., to make a question). As it has been pointed out by many researchers (Cruse, 1986; Benson, 1990; McKeown and Radev, 2000), collocations cannot be described by means of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularl</context>
</contexts>
<marker>Hausmann, 1985</marker>
<rawString>Franz Iosef Hausmann. 1985. Kollokationen im deutschen w¨orterbuch. ein beitrag zur theorie des lexikographischen beispiels”. In Henning Bergenholtz and Joachim Mugdan, editors, Lezikographie und Grammatik. Akten des Essener Kolloquiums zur Grammatik im W¨orterbuch., Lexicographica. Series Major 3, pages 118–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Heid</author>
</authors>
<title>On ways words work together -research topics in lexical combinatorics.</title>
<date>1994</date>
<booktitle>Proceedings of the VIth Euralex International Congress (EURALEX ’94),</booktitle>
<pages>226--257</pages>
<editor>In W. Martin, W. Meijs, M. Moerland, E. ten Pas, P. van Sterkenburg, and P. Vossen, editors,</editor>
<location>Amsterdam.</location>
<contexts>
<context position="6616" citStr="Heid (1994)" startWordPosition="994" endWordPosition="995">S taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the colloca</context>
</contexts>
<marker>Heid, 1994</marker>
<rawString>Ulrich Heid. 1994. On ways words work together -research topics in lexical combinatorics. In W. Martin, W. Meijs, M. Moerland, E. ten Pas, P. van Sterkenburg, and P. Vossen, editors, Proceedings of the VIth Euralex International Congress (EURALEX ’94), pages 226–257, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chu-Ren Huang</author>
<author>Adam Kilgarriff</author>
<author>Yiching Wu</author>
<author>ChihMing Chiu</author>
<author>Simon Smith</author>
<author>Pavel Rychly</author>
<author>Ming-Hong Bai</author>
<author>Keh-Jiann Chen</author>
</authors>
<title>Chinese Sketch Engine and the extraction of grammatical collocations.</title>
<date>2005</date>
<booktitle>In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>pages</pages>
<location>Republic of</location>
<contexts>
<context position="11896" citStr="Huang et al., 2005" startWordPosition="1845" endWordPosition="1848">ed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-European languages pose for the existing alignment methods bas</context>
</contexts>
<marker>Huang, Kilgarriff, Wu, Chiu, Smith, Rychly, Bai, Chen, 2005</marker>
<rawString>Chu-Ren Huang, Adam Kilgarriff, Yiching Wu, ChihMing Chiu, Simon Smith, Pavel Rychly, Ming-Hong Bai, and Keh-Jiann Chen. 2005. Chinese Sketch Engine and the extraction of grammatical collocations. In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing, pages 48– 55, Jeju Island, Republic of Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
<author>Satoshi Shirai</author>
<author>Tsukasa Kawaoka</author>
</authors>
<title>Automatic extraction of uninterrupted collocations by n-gram statistics.</title>
<date>1995</date>
<booktitle>In Proceedings offirst Annual Meeting of the Association for Natural Language Processing,</booktitle>
<pages>313--316</pages>
<contexts>
<context position="12048" citStr="Ikehara et al., 1995" startWordPosition="1870" endWordPosition="1873">o English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-European languages pose for the existing alignment methods based on word- and sentence-length: in Chinese, for instance, most of the words are just one or two characters long, and there are no word delimiters. This</context>
</contexts>
<marker>Ikehara, Shirai, Kawaoka, 1995</marker>
<rawString>Satoru Ikehara, Satoshi Shirai, and Tsukasa Kawaoka. 1995. Automatic extraction of uninterrupted collocations by n-gram statistics. In Proceedings offirst Annual Meeting of the Association for Natural Language Processing, pages 313–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The Architecture of the Language Faculty.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2989" citStr="Jackendoff (1997" startWordPosition="441" endWordPosition="442">tion The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006</context>
</contexts>
<marker>Jackendoff, 1997</marker>
<rawString>Ray Jackendoff. 1997. The Architecture of the Language Faculty. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: Some linguistis properties and an algorithm for identification in text. Natural Language Engineering,</title>
<date>1995</date>
<contexts>
<context position="6237" citStr="Justeson and Katz, 1995" startWordPosition="930" endWordPosition="933">cal dispersion. Not only the data scattering modify the frequency numbers used by AMs, but it also alters the performance of AMs, if the the probabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organ</context>
<context position="7568" citStr="Justeson and Katz, 1995" startWordPosition="1145" endWordPosition="1148">ork. Then we highlight, in section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 20</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: Some linguistis properties and an algorithm for identification in text. Natural Language Engineering, 1:9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seonho Kim</author>
<author>Zooil Yang</author>
<author>Mansuk Song</author>
<author>Jung-Ho Ahn</author>
</authors>
<title>Retrieving collocations from Korean text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>71--81</pages>
<location>Maryland, U.S.A.</location>
<contexts>
<context position="11841" citStr="Kim et al., 1999" startWordPosition="1836" endWordPosition="1839">igault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-Europea</context>
<context position="16062" citStr="Kim et al. (1999)" startWordPosition="2488" endWordPosition="2491">guage, several hypotheses were put forth in extraction and became common place. For instance, using a 5-words window as search space for collocation pairs is a usual practice, since this span length was shown sufficient to cover a high percentage of syntactic co-occurrences in English. But — as suggested by other researchers, e.g., (Goldman et al., 2001) —, this assumption does not necessary hold for other languages. Similarly, the higher inflection and the higher transformation potential shown by some languages pose additional problems in extraction, which were rather ignored for English. As Kim et al. (1999) notice, collocation extraction is particularly difficult in free-order languages like Korean, where arguments scramble freely. Breidt (1993) also pointed out a couple of problems that makes extraction for German more difficult than for English: the strong inflection for verbs, the variable word-order, and the positional ambiguity of the arguments. She shows that even distinguishing subjects from objects is very difficult without parsing. 4.2 A Strategy for Multilingual Extraction Summing up the previous discussion, the customization of collocation extraction for a given language needs to take</context>
</contexts>
<marker>Kim, Yang, Song, Ahn, 1999</marker>
<rawString>Seonho Kim, Zooil Yang, Mansuk Song, and Jung-Ho Ahn. 1999. Retrieving collocations from Korean text. In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 71–81, Maryland, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihoko Kitamura</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Automatic extraction of word sequence correspondences in parallel corpora.</title>
<date>1996</date>
<booktitle>In Proceedings of the 4th Workshop on Very Large Corpora,</booktitle>
<pages>79--87</pages>
<location>Copenhagen, Denmark,</location>
<marker>Kitamura, Matsumoto, 1996</marker>
<rawString>Mihoko Kitamura and Yuji Matsumoto. 1996. Automatic extraction of word sequence correspondences in parallel corpora. In Proceedings of the 4th Workshop on Very Large Corpora, pages 79–87, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨oran Kjellmer</author>
</authors>
<title>A Dictionary of English Collocations.</title>
<date>1994</date>
<publisher>Claredon Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="7584" citStr="Kjellmer, 1994" startWordPosition="1149" endWordPosition="1150">n section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; </context>
</contexts>
<marker>Kjellmer, 1994</marker>
<rawString>G¨oran Kjellmer. 1994. A Dictionary of English Collocations. Claredon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting PP-verb collocations.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocations,</booktitle>
<pages>39--46</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="3376" citStr="Krenn and Evert, 2001" startWordPosition="496" endWordPosition="499">eed for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in te</context>
<context position="8935" citStr="Krenn and Evert, 2001" startWordPosition="1375" endWordPosition="1378">a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, thanks to the early work of Breidt (1993) and, more recently, to that of Krenn and Evert, such as (Krenn and Evert, 2001; Evert and Krenn, 2001; Evert, 2004) centered on evaluation. Breidt uses MI and t-score and compares the results accuracy when various parameters vary, such as the window size, presence vs. absence of lemmatization, corpus size, and presence vs. absence of POS and syntactic information. She focuses on N-V pairs2 and, despite the lack of syntactic analysis tools at the time, by simulating parsing she comes to the conclusion that “Very high precision rates, which are an indispensable requirement for lexical acquisition, can only realistically be envisaged for German with parsed corpora” (Breidt</context>
<context position="13669" citStr="Krenn and Evert, 2001" startWordPosition="2116" endWordPosition="2119">Issues As the previous section showed, many systems of collocation extraction rely on the linguistic preprocessing of source corpora in order to support the candidate identification process. Languagespecific information, such as the one derived from morphological and syntactic analysis, was shown to be highly beneficial for extraction. Moreover, the possibility to apply the association measures on syntactically homogenous material is argued to benefit extraction, as the performance of association measures might vary with the syntactic configurations because of the differences in distribution (Krenn and Evert, 2001). The lexical distribution is therefore a relevant issue from the perspective of multilingual collocation extraction. Different languages show different proportions of lexical categories (N, V, A, Adv, P, etc.) which are evenly distributed across syntactic types3. Depending on the frequency numbers, a given AM could be more suited for a specific syntactic configuration in one language, and less suited for the same configuration in another. Ideally, each language should be assigned a suitable set of AMs to be applied on syntacticallyhomogenous data. Another issue that is relevant in the multili</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb collocations. In Proceedings of the ACL Workshop on Collocations, pages 39–46, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>An algorithm for finding noun phrase correspondences in bilingual corpora.</title>
<date>1993</date>
<booktitle>In 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>17--22</pages>
<location>Columbus, Ohio, U.S.A.</location>
<contexts>
<context position="3422" citStr="Kupiec, 1993" startWordPosition="504" endWordPosition="505">ns in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora. Among the most often used types of</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Julian Kupiec. 1993. An algorithm for finding noun phrase correspondences in bilingual corpora. In 31st Annual Meeting of the Association for Computational Linguistics, pages 17–22, Columbus, Ohio, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lafon</author>
</authors>
<title>D´epouillement et statistique en l´exicometrie. Slatkine-Champion,</title>
<date>1984</date>
<location>Paris.</location>
<contexts>
<context position="10784" citStr="Lafon, 1984" startWordPosition="1667" endWordPosition="1668">modifiability) and compared their results with those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adverb, Det - determiner, Conj - conjunction, P - preposition. 3.3 French Thanks to the outstanding work of Gross on lexicon-grammar (1984), French is one of the most studied languages in terms of distributional and transformational potential of words. This work has been carried out before the computer era and the advent of corpus linguistics, while automatic extraction was later performed, for instance, in (Lafon, 1984; Daille, 1994; Bourigault, 1992; Goldman et al., 2001). Daille (1994) aimed at extracting compound nouns, defined a priori by means of certain syntactic patterns, like N-A, N-N, N-`a-N, N-de-N, N P Det N. She used a lemmatizer and a POS-tagger before applying a series of AMs, which she then evaluated against a domain-specific terminology dictionary and against a gold-standard manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the</context>
</contexts>
<marker>Lafon, 1984</marker>
<rawString>P. Lafon. 1984. D´epouillement et statistique en l´exicometrie. Slatkine-Champion, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lewis</author>
</authors>
<title>Teaching Collocations. Further Developments In The Lexical Approach. Language Teaching Publications,</title>
<date>2000</date>
<location>Hove.</location>
<contexts>
<context position="2318" citStr="Lewis, 2000" startWordPosition="337" endWordPosition="338">ages. The English collocation ask a question translates as poser une question in French (lit., ?put a question), and as fare una domanda, hacer una pregunta in Italian and Spanish (lit., to make a question). As it has been pointed out by many researchers (Cruse, 1986; Benson, 1990; McKeown and Radev, 2000), collocations cannot be described by means of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in lan</context>
</contexts>
<marker>Lewis, 2000</marker>
<rawString>Michael Lewis. 2000. Teaching Collocations. Further Developments In The Lexical Approach. Language Teaching Publications, Hove.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Extracting collocations from text corpora.</title>
<date>1998</date>
<booktitle>In First Workshop on Computational Terminology,</booktitle>
<pages>57--63</pages>
<location>Montreal.</location>
<contexts>
<context position="3352" citStr="Lin, 1998" startWordPosition="494" endWordPosition="495">edged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used </context>
<context position="6386" citStr="Lin, 1998" startWordPosition="958" endWordPosition="959">ntingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a s</context>
<context position="7612" citStr="Lin, 1998" startWordPosition="1153" endWordPosition="1154">s that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Extracting collocations from text corpora. In First Workshop on Computational Terminology, pages 57–63, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Lu</author>
<author>Yin Li</author>
<author>Ruifeng Xu</author>
</authors>
<title>Improving Xtract for Chinese collocation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of IEEE International Conference on Natural Language Processing and Knowledge Engineering,</booktitle>
<pages>333--338</pages>
<contexts>
<context position="11942" citStr="Lu et al., 2004" startWordPosition="1854" endWordPosition="1857">actic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-European languages pose for the existing alignment methods based on word- and sentence-length: in Chinese, f</context>
</contexts>
<marker>Lu, Li, Xu, 2004</marker>
<rawString>Qin Lu, Yin Li, and Ruifeng Xu. 2004. Improving Xtract for Chinese collocation extraction. In Proceedings of IEEE International Conference on Natural Language Processing and Knowledge Engineering, pages 333–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Dragomir R Radev</author>
</authors>
<date>2000</date>
<booktitle>A Handbook of Natural Language Processing,</booktitle>
<pages>507--523</pages>
<editor>Collocations. In Robert Dale, Hermann Moisl, and Harold Somers, editors,</editor>
<publisher>Marcel Dekker,</publisher>
<location>New York, U.S.A.</location>
<contexts>
<context position="2013" citStr="McKeown and Radev, 2000" startWordPosition="290" endWordPosition="293">ions, (big house, cultural activity, read a book), collocational expressions are highly idiosyncratic, since the lexical items a headword combines with in order to express a given meaning is contingent upon that word (Mel’ˇcuk, 2003). This is apparent when comparing a collocation’s equivalents across different languages. The English collocation ask a question translates as poser une question in French (lit., ?put a question), and as fare una domanda, hacer una pregunta in Italian and Spanish (lit., to make a question). As it has been pointed out by many researchers (Cruse, 1986; Benson, 1990; McKeown and Radev, 2000), collocations cannot be described by means of general syntactic and semantic rules. They are arbitrary and unpredictable, and therefore need to be memorized and used as such. They constitute the so-called “semi-finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applicatio</context>
</contexts>
<marker>McKeown, Radev, 2000</marker>
<rawString>Kathleen R. McKeown and Dragomir R. Radev. 2000. Collocations. In Robert Dale, Hermann Moisl, and Harold Somers, editors, A Handbook of Natural Language Processing, pages 507–523. Marcel Dekker, New York, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>A portable algorithm for mapping bitext correspondence.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Conference of the Association for Computational Linguistics (ACL’97),</booktitle>
<pages>305--312</pages>
<location>Madrid,</location>
<contexts>
<context position="3668" citStr="Melamed, 1997" startWordPosition="538" endWordPosition="539">of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora. Among the most often used types of lexical association measures (henceforth AMs) we mention: statistical hypothesis tests (e.g., binomial, Poisson, Fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two </context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997. A portable algorithm for mapping bitext correspondence. In Proceedings of the 35th Conference of the Association for Computational Linguistics (ACL’97), pages 305–312, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Collocations and lexical functions.</title>
<date>1998</date>
<booktitle>Phraseology. Theory, Analysis, and Applications,</booktitle>
<pages>23--53</pages>
<editor>In Anthony P. Cowie, editor,</editor>
<publisher>Claredon Press,</publisher>
<location>Oxford.</location>
<marker>Mel’ˇcuk, 1998</marker>
<rawString>Igor Mel’ˇcuk. 1998. Collocations and lexical functions. In Anthony P. Cowie, editor, Phraseology. Theory, Analysis, and Applications, pages 23–53. Claredon Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Collocations: d´efinition, rˆole et utilit´e.</title>
<date>2003</date>
<booktitle>In Francis Grossmann and Agn`es Tutin, editors, Les collocations: analyse et traitement,</booktitle>
<pages>23--32</pages>
<location>Amsterdam.</location>
<marker>Mel’ˇcuk, 2003</marker>
<rawString>Igor Mel’ˇcuk. 2003. Collocations: d´efinition, rˆole et utilit´e. In Francis Grossmann and Agn`es Tutin, editors, Les collocations: analyse et traitement, pages 23–32. Editions ”De Werelt”, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In WordNet and Other Lexical Resources: Applications, Extensions and Customizations (NAACL 2001 Workshop),</booktitle>
<pages>41--46</pages>
<location>Pittsburgh, U.S.A.</location>
<contexts>
<context position="8119" citStr="Pearce, 2001" startWordPosition="1233" endWordPosition="1234">Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>Darren Pearce. 2001. Synonymy in collocation extraction. In WordNet and Other Lexical Resources: Applications, Extensions and Customizations (NAACL 2001 Workshop), pages 41–46, Pittsburgh, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>An extensive empirical study of collocation extraction methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Student Research Workshop,</booktitle>
<pages>13--18</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4679" citStr="Pecina, 2005" startWordPosition="687" endWordPosition="688">s) we mention: statistical hypothesis tests (e.g., binomial, Poisson, Fisher, zscore, chi-squared, t-score, and log-likelihood ratio tests), that measure the significance of the association between two words based on a contingency table listing their joint and marginal frequency, and Information-theoretic measures (Mutual Information — henceforth MI — and its variants), that quantity of ‘information’ shared by two random variables. A detailed review of the statistical methods employed in collocation extraction can be found, for instance, in (Evert, 2004). A comprehensive list of AMs is given (Pecina, 2005). Very often, in addition to the information on cooccurrence frequency, language-specific information is also integrated in a collocation extraction system (as it will be seen in section 3): - morphological information, in order to count inflected word forms as instances of the same base form. For instance, ask questions, asks question, asked question are all instances of the same word pair, ask - question; - syntactic information, in order to recognize a word pair even if subject to (complex) syntactic transformations: ask multiple questions, question asked, questions that one might ask. The </context>
<context position="8219" citStr="Pecina, 2005" startWordPosition="1250" endWordPosition="1251"> 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated language, than</context>
</contexts>
<marker>Pecina, 2005</marker>
<rawString>Pavel Pecina. 2005. An extensive empirical study of collocation extraction methods. In Proceedings of the ACL Student Research Workshop, pages 13–18, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING</booktitle>
<pages>1--15</pages>
<location>Mexico City.</location>
<contexts>
<context position="2842" citStr="Sag et al., 2002" startWordPosition="418" endWordPosition="421">finished products” of language (Hausmann, 1985) or the “islands of reliability” (Lewis, 2000) on which the speakers build their utterances. 2 Motivation The key importance of collocations in text production tasks such as machine translation and natural language generation has been stressed many times. It has been equally shown that collocations are useful in a range of other applications, such as word sense disambiguation (Brown et al., 1991) and parsing (Alshawi and Carter, 1994). The NLP community fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja e</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2002), pages 1–15, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Eric Wehrli</author>
</authors>
<title>Accurate collocation extraction using a multilingual parser.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL</booktitle>
<note>To appear.</note>
<contexts>
<context position="18940" citStr="Seretan and Wehrli, 2006" startWordPosition="2936" endWordPosition="2939">ses a restricted view on collocation, which is seen first of all as an expression of language. The existing extraction work (section 3) shows that there is a growing interest in adopting the more restricted (linguistic) view. As mentioned in section 3, the importance of parsing for extraction was confirmed by several evaluation experiments. With the recent development in the field of linguistic analysis, hybrid extraction systems (i.e., systems relying on syntactical analysis for collocation extraction) are likely to become the rule rather than the exception. Our system (Goldman et al., 2001; Seretan and Wehrli, 2006) is — to our knowledge — the first to perform the full syntactic analysis as support for collocation extraction; similar approaches rely on dependency parsers or on chunking. It is based on a symbolic parser that was developed over the last decade (Wehrli, 2004) and achieves a high level of performance, in terms of accuracy, speed and robustness. The languages it supports are, for the time being, French, English, Italian, Spanish and German. A few other languages are being also implemented in the framework of a multilingualism project. Provided that collocation extraction can be seen as a two-</context>
<context position="20777" citStr="Seretan and Wehrli, 2006" startWordPosition="3227" endWordPosition="3230">ed by post-processing the output of syntactic tools. The candidate pairs identified are classified into syntactically homogenous sets, according to the syntactic relations holding between the two items. Only certain predefined syntactic relations are kept, that were judged as collocationally relevant after multiple experiments of extraction and data analysis (e.g., adjective-noun, verb-object, subject-verb, noun-noun, verb-preposition-noun). The sets obtained are then ranked using the loglikelihood ratios test (Dunning, 1993). More details about the system and its performance can be found in (Seretan and Wehrli, 2006). The following examples (taken from the extraction experiment we will describe below) illustrate its potential to detect collocation candidates, even if these are subject to complex syntactic transformations: 1.a) atteindre objectif (Fr): Les objectifs fix´es a` l’´echelle internationale visant a` r´eduire les ´emissions ne peuvent pas ˆetre atteints a` l’aide de ces seuls programmes. 1.b) accogliere emendamento (It): 44 Posso pertanto accogliere in parte e in linea di principio gli emendamenti nn. 43-46 e l’emendamento n. 85. 1.c) reforzar cooperaci´on (Es): Queremos permitir a los pases que</context>
</contexts>
<marker>Seretan, Wehrli, 2006</marker>
<rawString>Violeta Seretan and Eric Wehrli. 2006. Accurate collocation extraction using a multilingual parser. In Proceedings of COLING/ACL 2006. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
<author>Luka Nerima</author>
<author>Eric Wehrli</author>
</authors>
<title>A tool for multi-word collocation extraction and visualization in multilingual corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the Eleventh EURALEX International Congress, EURALEX 2004,</booktitle>
<pages>755--766</pages>
<location>Lorient, France.</location>
<contexts>
<context position="6431" citStr="Seretan et al., 2004" startWordPosition="964" endWordPosition="967">Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Church and Hanks (1990, 25), Smadja (1993, 151) and Heid (1994) — and given the recent development of linguistic analysis tools, it seems plausible that the linguistic structure will be more and more taken into account by collocation extraction systems. The rest of the paper is organized as follows. In section 3 we provide a language-oriented review of the existing collocation extraction work. Then we highlight, in section 4, a series of problems that arise in the transfer </context>
<context position="8204" citStr="Seretan et al., 2004" startWordPosition="1246" endWordPosition="1249">; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German German is the second most investigated</context>
<context position="21545" citStr="Seretan et al., 2004" startWordPosition="3346" endWordPosition="3349">ven if these are subject to complex syntactic transformations: 1.a) atteindre objectif (Fr): Les objectifs fix´es a` l’´echelle internationale visant a` r´eduire les ´emissions ne peuvent pas ˆetre atteints a` l’aide de ces seuls programmes. 1.b) accogliere emendamento (It): 44 Posso pertanto accogliere in parte e in linea di principio gli emendamenti nn. 43-46 e l’emendamento n. 85. 1.c) reforzar cooperaci´on (Es): Queremos permitir a los pases que lo deseen reforzar, en un contexto unitario, su cooperaci´on en cierto n´umero de sectores. The collocation extractor is part of a bigger system (Seretan et al., 2004) that integrates a concordancer and a sentence aligner, and that supports the visualization, the manual validation and the management of a multilingual terminology database. The validated collocations are used for populating the lexicon of the parser and that of a translation system (Wehrli, 2003). 6 A Cross-Lingual Extraction Experiment A collocation extraction experiment concerning four different languages (English, Spanish, French, Italian) has been conducted on a parallel subcorpus of 42 files from the European Parliament proceedings. Several statistics and extraction results are reported </context>
</contexts>
<marker>Seretan, Nerima, Wehrli, 2004</marker>
<rawString>Violeta Seretan, Luka Nerima, and Eric Wehrli. 2004. A tool for multi-word collocation extraction and visualization in multilingual corpora. In Proceedings of the Eleventh EURALEX International Congress, EURALEX 2004, pages 755–766, Lorient, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Violeta Seretan</author>
</authors>
<title>Induction of syntactic collocation patterns from generic syntactic relations.</title>
<date>2005</date>
<booktitle>In Proceedings of Nineteenth International Joint Conference on Artificial Intelligence (IJCAI</booktitle>
<pages>1698--1699</pages>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="15317" citStr="Seretan, 2005" startWordPosition="2372" endWordPosition="2373">figurations could be language-specific (like P-N-V in German, whose English equivalent is V-P-N). Yet other configurations might have no counterpart at all in another language (e.g., the French P-A pair a` neuf is translated into English as a Conj-A pair, as new). Finding all the collocationally-relevant syntactic types for a language is therefore another problem that has to be solved in multilingual extraction. Since a priori defining these types based on intuition does not ensure the necessary coverage, an alternative proposal is to induce them from POS data and dependency relations, as in (Seretan, 2005). The morphoyntactic differences between languages also have to be taken into account. With English as the most investigated language, several hypotheses were put forth in extraction and became common place. For instance, using a 5-words window as search space for collocation pairs is a usual practice, since this span length was shown sufficient to cover a high percentage of syntactic co-occurrences in English. But — as suggested by other researchers, e.g., (Goldman et al., 2001) —, this assumption does not necessary hold for other languages. Similarly, the higher inflection and the higher tra</context>
</contexts>
<marker>Seretan, 2005</marker>
<rawString>Violeta Seretan. 2005. Induction of syntactic collocation patterns from generic syntactic relations. In Proceedings of Nineteenth International Joint Conference on Artificial Intelligence (IJCAI 2005), pages 1698–1699, Edinburgh, Scotland, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayori Shimohata</author>
<author>Toshiyuki Sugio</author>
<author>Junji Nagata</author>
</authors>
<title>Retrieving collocations by co-occurrences and word order constraints.</title>
<date>1997</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>476--481</pages>
<location>Madrid,</location>
<contexts>
<context position="11786" citStr="Shimohata et al., 1997" startWordPosition="1825" endWordPosition="1828"> manually created from the extraction corpus. Similarly, Bourigault (1992) extracted nounphrases from shallow-parsed text, and Goldman et al. (2001) extracted syntactic collocations by using a full parser and applying the LL test. 3.4 Other Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994</context>
</contexts>
<marker>Shimohata, Sugio, Nagata, 1997</marker>
<rawString>Sayori Shimohata, Toshiyuki Sugio, and Junji Nagata. 1997. Retrieving collocations by co-occurrences and word order constraints. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 476–481, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Sinclair</author>
</authors>
<title>Collins Cobuild English Dictionary.</title>
<date>1995</date>
<publisher>Harper Collins,</publisher>
<location>London.</location>
<contexts>
<context position="7600" citStr="Sinclair, 1995" startWordPosition="1151" endWordPosition="1152">eries of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., </context>
</contexts>
<marker>Sinclair, 1995</marker>
<rawString>John Sinclair. 1995. Collins Cobuild English Dictionary. Harper Collins, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: a statistical approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="3453" citStr="Smadja et al., 1996" startWordPosition="508" endWordPosition="511">., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora. Among the most often used types of lexical association measures (</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Smadja, Kathleen McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: a statistical approach. Computational Linguistics, 22(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>177</pages>
<contexts>
<context position="3341" citStr="Smadja, 1993" startWordPosition="492" endWordPosition="493"> fully acknowledged the need for an appropriate treatment of multi-word expressions in general (Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been he</context>
<context position="5936" citStr="Smadja, 1993" startWordPosition="883" endWordPosition="884">with the problem of morphosyntactic variation, in order to improve the accuracy of frequency information. This becomes truly important especially for free-word order and for high-inflection languages, for which the token(form)-based frequency figures become too skewed due to the high lexical dispersion. Not only the data scattering modify the frequency numbers used by AMs, but it also alters the performance of AMs, if the the probabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, </context>
<context position="7543" citStr="Smadja, 1993" startWordPosition="1143" endWordPosition="1144">n extraction work. Then we highlight, in section 4, a series of problems that arise in the transfer of methodology to a new language, and we propose a strategy for dealing with them. Section 5 describes an extraction system, and, finally, section 6 presents a case-study on the collocations extracted for four languages, illustrating the cross-lingual variation in the performance of a particular AM. 3 Overview of Extraction Work 3.1 English As one might expect, the bulk of the collocation extraction work concerns the English language: (Choueka, 1988; Church et al., 1989; Church and Hanks, 1990; Smadja, 1993; Justeson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; </context>
<context position="12012" citStr="Smadja, 1993" startWordPosition="1866" endWordPosition="1867">ther Languages In addition to English, German and French, other languages for which notable collocation extraction work was performed, are — as we are aware of — the following: • Italian: early extraction work was carried out by Calzolari and Bindi (1990) and employed MI. It was followed by (Basili et al., 1994), that made use of parsing information; • Korean: (Shimohata et al., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-European languages pose for the existing alignment methods based on word- and sentence-length: in Chinese, for instance, most of the words are just one or two characters long, an</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics, 19(1):143– 177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Translation of words in context.</title>
<date>2003</date>
<booktitle>In Proceedings of Machine Translation Summit IX,</booktitle>
<pages>502--504</pages>
<location>New Orleans, Lousiana, U.S.A.</location>
<contexts>
<context position="21843" citStr="Wehrli, 2003" startWordPosition="3394" endWordPosition="3395">n parte e in linea di principio gli emendamenti nn. 43-46 e l’emendamento n. 85. 1.c) reforzar cooperaci´on (Es): Queremos permitir a los pases que lo deseen reforzar, en un contexto unitario, su cooperaci´on en cierto n´umero de sectores. The collocation extractor is part of a bigger system (Seretan et al., 2004) that integrates a concordancer and a sentence aligner, and that supports the visualization, the manual validation and the management of a multilingual terminology database. The validated collocations are used for populating the lexicon of the parser and that of a translation system (Wehrli, 2003). 6 A Cross-Lingual Extraction Experiment A collocation extraction experiment concerning four different languages (English, Spanish, French, Italian) has been conducted on a parallel subcorpus of 42 files from the European Parliament proceedings. Several statistics and extraction results are reported in Table 1. Statistics English Spanish Italian French tokens 2526403 2666764 2575858 2938118 sent/file 2329.1 2513.7 2331.6 2392.8 complete 63.4% 35.5% 46.8% 63.7% parses tokens/sent 25.8 25.3 26.3 29.2 extr. pairs 617353 568998 666122 565287 (tokens) token/type 2.6 2.5 2.3 2.3 LL is def. 85.9% 90</context>
</contexts>
<marker>Wehrli, 2003</marker>
<rawString>Eric Wehrli. 2003. Translation of words in context. In Proceedings of Machine Translation Summit IX, pages 502–504, New Orleans, Lousiana, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Un mod`ele multilingue d’analyse syntaxique.</title>
<date>2004</date>
<booktitle>Structures et discours - M´elanges offerts a` Eddy Roulet,</booktitle>
<pages>311--329</pages>
<editor>In A. Auchlin et al., editor,</editor>
<location>Qu´ebec.</location>
<contexts>
<context position="19202" citStr="Wehrli, 2004" startWordPosition="2983" endWordPosition="2984">sing for extraction was confirmed by several evaluation experiments. With the recent development in the field of linguistic analysis, hybrid extraction systems (i.e., systems relying on syntactical analysis for collocation extraction) are likely to become the rule rather than the exception. Our system (Goldman et al., 2001; Seretan and Wehrli, 2006) is — to our knowledge — the first to perform the full syntactic analysis as support for collocation extraction; similar approaches rely on dependency parsers or on chunking. It is based on a symbolic parser that was developed over the last decade (Wehrli, 2004) and achieves a high level of performance, in terms of accuracy, speed and robustness. The languages it supports are, for the time being, French, English, Italian, Spanish and German. A few other languages are being also implemented in the framework of a multilingualism project. Provided that collocation extraction can be seen as a two-stage process (where, in stage 1, collocation candidates are identified in the text corpora, and in stage 2, they are ranked according to a given AM, cf. section 4.2), the role of the parser is to support the first stage. A pair of lexical items is selected as a</context>
</contexts>
<marker>Wehrli, 2004</marker>
<rawString>Eric Wehrli. 2004. Un mod`ele multilingue d’analyse syntaxique. In A. Auchlin et al., editor, Structures et discours - M´elanges offerts a` Eddy Roulet, pages 311–329. ´Editions Nota bene, Qu´ebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>Collocation extraction based on modifiability statistics.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>980--986</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="10042" citStr="Wermter and Hahn (2004)" startWordPosition="1543" endWordPosition="1546">ble requirement for lexical acquisition, can only realistically be envisaged for German with parsed corpora” (Breidt, 1993, 82). Later, Krenn and Evert (2001) used a German chunker to extract syntactic pairs such as P-N-V. Their work put the basis of formal and systematic methods in collocation extraction evaluation. Zinsmeister and Heid (2003; 2004) focused on N-V and A-N-V combinations identified using a stochastic parser. They applied machine learning techniques in combination to the log-likelihood measure (henceforth LL) for distinguishing trivial compounds from lexicalized ones. Finally, Wermter and Hahn (2004) identified PP-V combinations using a POS tagger and a chunker. They based their method on a linguistic criterion (that of limited modifiability) and compared their results with those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adverb, Det - determiner, Conj - conjunction, P - preposition. 3.3 French Thanks to the outstanding work of Gross on lexicon-grammar (1984), French is one of the most studied languages in terms of distributional and transformational potential of words. This work has been carried o</context>
</contexts>
<marker>Wermter, Hahn, 2004</marker>
<rawString>Joachim Wermter and Udo Hahn. 2004. Collocation extraction based on modifiability statistics. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), pages 980–986, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Aligning a parallel English-Chinese corpus statistically with lexical criteria.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL 1994),</booktitle>
<pages>80--87</pages>
<location>Las Cruces (New Mexico), U.S.A.</location>
<contexts>
<context position="3432" citStr="Wu, 1994" startWordPosition="506" endWordPosition="507">(Sag et al., 2002). Collocations are particularly important because of their prevalence in language, regardless of the domain or genre. According to Jackendoff (1997, 156) and Mel’ˇcuk (1998, 24), collocations constitute the bulk of a language’s lexicon. The last decades have witnessed a considerable development of collocation extraction techniques, that concern both monolingual and (parallel) multilingual corpora. We can mention here only part of this work: (Berry-Rogghe, 1973; Church et al., 1989; Smadja, 1993; Lin, 1998; Krenn and Evert, 2001) for monolingual extraction, and (Kupiec, 1993; Wu, 1994; Smadja et al., 1996; Kitamura and Mat40 Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 40–49, Sydney, July 2006. c�2006 Association for Computational Linguistics sumoto, 1996; Melamed, 1997) for bilingual extraction via alignment. Traditionally, collocation extraction was considered a language-independent task. Since collocations are recurrent, typical lexical combinations, a wide range of statistical methods based on word co-occurrence frequency have been heavily used for detecting them in text corpora. Among the most often used types of lexical a</context>
<context position="12387" citStr="Wu (1994)" startWordPosition="1925" endWordPosition="1926">., 1997) used an adjacency n-gram model, and (Kim et al., 1999) relied on POS-tagging; • Chinese: (Huang et al., 2005) used POS information, while (Lu et al., 2004) applied extraction techniques similar to Xtract system (Smadja, 1993); • Japanese: (Ikehara et al., 1995) was based on an improved n-gram method. As for multilingual extraction via alignment (where collocations are first detected in one language and then matched with their translation in another language), most or the existing work concern the English-French language pair, and the Hansard corpus of Canadian Parliament proceedings. Wu (1994) signals a number of problems 42 that non-Indo-European languages pose for the existing alignment methods based on word- and sentence-length: in Chinese, for instance, most of the words are just one or two characters long, and there are no word delimiters. This result suggests that the portability of existing alignment methods to new language pairs is questionable. We are not concerned here with extraction via alignment. We assume, instead, that multilingual support in collocation extraction means the customization of the extraction procedure for each language. This topic will be addressed in </context>
</contexts>
<marker>Wu, 1994</marker>
<rawString>Dekai Wu. 1994. Aligning a parallel English-Chinese corpus statistically with lexical criteria. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL 1994), pages 80–87, Las Cruces (New Mexico), U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Zaiu Inkpen</author>
<author>Graeme Hirst</author>
</authors>
<title>Acquiring collocations for lexical choice between nearsynonyms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>67--76</pages>
<location>Philadephia, Pennsylvania.</location>
<contexts>
<context position="8170" citStr="Inkpen and Hirst, 2002" startWordPosition="1240" endWordPosition="1243">teson and Katz, 1995; Kjellmer, 1994; Sinclair, 1995; Lin, 1998), among many others1. Choueka’s method (1988) detects n-grams (adjacent words) only, by simply computing the cooccurrence frequency. Justeson and Katz (1995) apply a POS-filter on the pairs they extract. As in (Kjellmer, 1994), the AM they use is the simple frequency. Smadja (1993) employs the z-score in conjunction with several heuristics (e.g., the systematic occurrence of two lexical items at the same distance in text) and extracts predicative collocations, 1E.g., (Frantzi et al., 2000; Pearce, 2001; Goldman et al., 2001; Zaiu Inkpen and Hirst, 2002; Dias, 2003; Seretan et al., 2004; Pecina, 2005), and the list can be continued. 41 rigid noun phrases and phrasal templates. He then uses the a parser in order to validate the results. The parsing is shown to lead to an increase in accuracy from 40% to 80%. (Church et al., 1989) and (Church and Hanks, 1990) use POS information and a parser to extract verb-object pairs, which then they rank according to the mutual information (MI) measure they introduce. Lin’s (1998) is also a hybrid approach that relies on a dependency parser. The candidates extracted are then ranked with MI. 3.2 German Germ</context>
</contexts>
<marker>Inkpen, Hirst, 2002</marker>
<rawString>Diana Zaiu Inkpen and Graeme Hirst. 2002. Acquiring collocations for lexical choice between nearsynonyms. In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition, pages 67–76, Philadephia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R´emi Zajac</author>
<author>Elke Lange</author>
<author>Jin Yang</author>
</authors>
<title>Customizing complex lexical entries for high-quality MT.</title>
<date>2003</date>
<booktitle>In Proceedings of the Ninth Machine Translation</booktitle>
<location>Summit, New Orleans, U.S.A.</location>
<contexts>
<context position="5957" citStr="Zajac et al., 2003" startWordPosition="885" endWordPosition="888">em of morphosyntactic variation, in order to improve the accuracy of frequency information. This becomes truly important especially for free-word order and for high-inflection languages, for which the token(form)-based frequency figures become too skewed due to the high lexical dispersion. Not only the data scattering modify the frequency numbers used by AMs, but it also alters the performance of AMs, if the the probabilities in the contingency table become very low. Morphosyntactic information has in fact been shown to significantly improve the extraction results (Breidt, 1993; Smadja, 1993; Zajac et al., 2003). Morphological tools such as lemmatizers and POS taggers are being commonly used in extraction systems; they are employed both for dealing with text variation and for validating the candidate pairs: combinations of function words are typically ruled out (Justeson and Katz, 1995), as are the ungrammatical combinations in the systems that make use of parsers (Church and Hanks, 1990; Smadja, 1993; Basili et al., 1994; Lin, 1998; Goldman et al., 2001; Seretan et al., 2004). Given the motivations for performing a linguistically-informed extraction — which were also put forth, among others, by Chur</context>
</contexts>
<marker>Zajac, Lange, Yang, 2003</marker>
<rawString>R´emi Zajac, Elke Lange, and Jin Yang. 2003. Customizing complex lexical entries for high-quality MT. In Proceedings of the Ninth Machine Translation Summit, New Orleans, U.S.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Zinsmeister</author>
<author>Ulrich Heid</author>
</authors>
<title>Significant triples: Adjective+Noun+Verb combinations.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Computational Lexicography and Text Research (Complex</booktitle>
<location>Budapest.</location>
<contexts>
<context position="9764" citStr="Zinsmeister and Heid (2003" startWordPosition="1506" endWordPosition="1509">emmatization, corpus size, and presence vs. absence of POS and syntactic information. She focuses on N-V pairs2 and, despite the lack of syntactic analysis tools at the time, by simulating parsing she comes to the conclusion that “Very high precision rates, which are an indispensable requirement for lexical acquisition, can only realistically be envisaged for German with parsed corpora” (Breidt, 1993, 82). Later, Krenn and Evert (2001) used a German chunker to extract syntactic pairs such as P-N-V. Their work put the basis of formal and systematic methods in collocation extraction evaluation. Zinsmeister and Heid (2003; 2004) focused on N-V and A-N-V combinations identified using a stochastic parser. They applied machine learning techniques in combination to the log-likelihood measure (henceforth LL) for distinguishing trivial compounds from lexicalized ones. Finally, Wermter and Hahn (2004) identified PP-V combinations using a POS tagger and a chunker. They based their method on a linguistic criterion (that of limited modifiability) and compared their results with those obtained using the t-score and LL tests. 2The following abbreviations are used in this paper: N - noun, V - verb, A - adjective, Adv - adv</context>
</contexts>
<marker>Zinsmeister, Heid, 2003</marker>
<rawString>Heike Zinsmeister and Ulrich Heid. 2003. Significant triples: Adjective+Noun+Verb combinations. In Proceedings of the 7th Conference on Computational Lexicography and Text Research (Complex 2003), Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Zinsmeister</author>
<author>Ulrich Heid</author>
</authors>
<title>Collocations of complex nouns: Evidence for lexicalisation.</title>
<date>2004</date>
<booktitle>In Proceedings of KONVENS 2004,</booktitle>
<location>Vienna, Austria.</location>
<marker>Zinsmeister, Heid, 2004</marker>
<rawString>Heike Zinsmeister and Ulrich Heid. 2004. Collocations of complex nouns: Evidence for lexicalisation. In Proceedings of KONVENS 2004, Vienna, Austria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>