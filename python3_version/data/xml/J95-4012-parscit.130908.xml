<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001249">
<sectionHeader confidence="0.261463" genericHeader="abstract">
Briefly Noted
</sectionHeader>
<bodyText confidence="0.99264822826087">
Parallel natural language processing
Geert Adriaens and Udo Hahn (editors)
(University of Leuren and University of
Freiburg)
Norwood, NJ: Ablex Publishing Company,
1994, vi + 467 pp.
Hardbound, ISBN 0-89391-869-5, $79.50
($37.50 prepaid)
Parallel Natural Language Processing is an
application-oriented text addressing parallel
implementations of aspects of natural lan-
guage understanding. Although the focus is
not on any particular cognitive theory, at-
tention is paid to human performance data
throughout. The implementation issues and
difficulties considered provide a grounding
and a checkpoint to balance the existing body
of more theoretical work.
The book is a collection of papers, each
chapter standing on its own yet each also tied
in with several other chapters in the topics
addressed and the aspects examined. In gen-
eral, for each language aspect included, at
least two papers cover the topic from slightly
differing viewpoints. Additionally, most top-
ics are balanced by a contrasting point of
view; for example, formal context-free gram-
mars versus parsing of free speech with mis-
takes, and complete story understanding ver-
sus single noun-phrase shades of meaning.
Each chapter is focused and thus manage-
able, enabling the authors to make some use-
ful observations about their topic. The book
as a whole thus serves as a look at the en-
tirety of natural language understanding and
the editors have done a good job indeed of
encasing and covering this topic.
The first, rather lengthy, chapter provides
a good review and overview of the topic
and issues at hand. Starting with a look
at psycholinguistic and cognitive arguments
both for and against autonomous compo-
nents versus interactive models of natural
language processing, the editors conclude
that parallel implementations of language
processing should be further explored. This
is followed by a discussion of parallelism
from a computer science perspective: com-
puting models, architectures, operating sys-
tems, and programming languages. A review
of parallelism in natural language process-
ing follows, with an eye toward the issues
raised in the computer science review. A 24-
page bibliography provides a thorough ref-
erence for the plethora of topics covered in
this chapter.
The remaining 12 chapters of the book are
individually authored papers covering par-
allel natural language processing. The first
series of papers focuses on context-free pars-
ing, starting with a theoretical account of
the advantages obtained through parallelism,
and results of implementations on paral-
lel hardware. Further proposed implementa-
tions are presented using object-oriented sys-
tems and connectionist paradigms. Finally,
parsing is considered as a constraint satis-
faction and energy minimization problem.
The next series of papers refocuses on
the interaction perspective, considering var-
ious methodologies: connectionism, concur-
rent processes, frame-based actors and bul-
letin boards, and object-oriented functional
programming. Finally, the book closes with
an examination of language generation using
connectionist and parallel unification mod-
els. The interested reader may refer to Chap-
ter 1, Section 5.3 for a thorough overview of
individual chapter contents.
Due to the implementation focus, the
reader may need a strong computer science
background to get the most from this book,
which assumes more than passing familiar-
ity with a wide range of topics such as
object-oriented and functional programming,
deadlock avoidance techniques, and efficient
implementations of Cocke-Younger-Kasami
parsing. However, in general each concept is
briefly introduced so the attentive reader can
follow the specific topic even without a for-
mal understanding.—Jeanne Milostan, Univer-
sity of California, San Diego
</bodyText>
<figure confidence="0.362522666666667">
Natural language understanding
(second edition)
James Allen
(University of Rochester)
Redwood City, CA: Benjamin/Cummings,
1995, xv + 654 pp.
</figure>
<bodyText confidence="0.994734666666667">
Hardbound, ISBN 0-8053-0334-0, $56.95
In the latest ACL Survey of Computational
Linguistics Courses (Dorr 1994), the first edi-
tion (1987) of James Allen&apos;s textbook Natural
language understanding was by far the most
frequently cited reference, being mentioned
</bodyText>
<page confidence="0.994972">
604
</page>
<bodyText confidence="0.998823882882883">
Briefly Noted
more than twice as often as any other. The
publication of the second edition of this book
should consequently be welcome news for
faculty who teach courses using it as a re-
quired or recommended text or for selected
readings.
The book has been substantially revised
and expanded, with new chapters added,
and outdated material removed. The overall
organization remains intact, however, with
major divisions into three parts covering
syntactic processing, semantic interpretation,
and context and world knowledge. The orig-
inal Part IV, &apos;Response generation,&apos; has been
omitted, and the material in its two chapters
on question answering and generation has
been integrated into other chapters. There is
a new appendix on speech recognition and ,
spoken language.
A major change in Part I, &apos;Syntactic Pro-
cessing,&apos; is the switch from augmented tran-
sition networks to feature-based context-free
grammars as the primary formalism. In ad-
dition, a new chapter on statistical meth-
ods complements the existing material by
introducing basic probability theory, part-
of-speech tagging, and probabilistic context-
free grammars. The focus in Part II, &apos;Seman-
tic interpretation,&apos; is now more on underly-
ing principles and issues, and less on spe-
cific computational techniques. Allen has ex-
tended his logical-form language to handle
more-complex sentences, and a chapter on
ambiguity resolution has been added that
covers statistical word-sense disambiguation
and semantic preferences as well as rule-
based methods. Part III, &apos;Context and world
knowledge,&apos; has been generally updated to
reflect work that has been published since
the first edition appeared.
The software that accompanies this edition
features a bottom-up chart parser and a set
of grammars and lexicons that are keyed to
the examples in specific sections of Parts I
and II. Unix, Macintosh, and DOS versions
in standard Common Lisp are available by
anonymous ftp.
In the past twelve years I have taught
an introductory graduate course in com-
putational linguistics five times, most re-
cently in early 1995, using five differ-
ent textbooks: successively, Winograd (1983),
Grishman (1986), Allen (1987), Smith (1991),
and the book reviewed here. Offered this
year at the CUNY Graduate Center, the
class attracted students from computer sci-
ence, linguistics, and psychology, whose
backgrounds in linguistics and computation
ranged from practically none to solid. Allen&apos;s
new book was supplemented with recom-
mended readings from Grosz, Sparck Jones,
and Webber (1986) and suggested readings
from Pereira and Grosz (1994). Part I was
covered in its entirety along with selected
chapters in Parts II and III. The laboratory
component of the course required the stu-
dents to use existing software. Assignments
included a morphological processor, a tagger,
and several parsers, both those provided by
Allen and others accessed by e-mail.
Overall, Allen&apos;s second edition deserves
decent marks. The updated material, partic-
ularly the emphasis on feature-based CFGs
and the chapters on statistical methods, was
badly needed to bring the coverage in line
with current work in the field. The print qual-
ity is also a significant improvement over the
first edition. Asked to evaluate the text at the
end of the course, my students gave it an av-
erage 3.3 rating on a five-point scale with 5
at the top.
Two areas of remaining weakness are the
notational system and the software. The no-
tational system that Allen develops for de-
scribing grammars and logical form, while
used consistently throughout the book, is
not identical to any other in the literature
(a perennial problem). Its nuances are not
always explained adequately, and even the
best students found it obscure and hard to
follow at times.
For my class, the Unix version of Allen&apos;s
software was installed on a network of IBM
RS-6000s running AIX and CUSP, a freeware
Common Lisp. The parsers worked fine, but
the grammars and lexicons were primitive.
In some cases, the rules and vocabulary for
more advanced sections didn&apos;t include all of
the features of earlier sections, making it dif-
ficult to run a suite of test sentences repeat-
edly. Only the most dedicated hackers were
successful in enhancing the system by modi-
fying the grammars and lexicons. One stu-
dent managed to install the package on a
Macintosh, but it required an inordinate ef-
fort because the Unix format had not been
uniformly replaced in the Macintosh version.
The software package has been upgraded fre-
quently since it was tested early in 1995, and
one can hope that these deficiencies have
</bodyText>
<page confidence="0.993643">
605
</page>
<figure confidence="0.5406258">
Computational Linguistics Volume 21, Number 4
been remedied.—Virginia Teller, Hunter College
and the Graduate School, The City University of
New York
References
</figure>
<reference confidence="0.9337112">
Allen, James (1987). Natural language
understanding. Benjamin/Cummings.
Dorr, Bonnie J. (1994). Survey of computational
linguistics courses, second edition.
Association for Computational Linguistics.
Grishman, Ralph (1986). Computational
linguistics: An introduction. Cambridge
University Press.
Grosz, Barbara; Sparck Jones, Karen; and
Webber, Bonnie (editors) (1986). Readings
in natural language processing. Morgan
Kaufmann.
Pereira, Fernando and Grosz, Barbara
(editors) (1994). Natural language processing.
The MIT Press.
Smith, George (1991). Computers and human
language. Oxford University Press.
Winograd, Terry (1983). Language as a
cognitive process. Volume I: Syntax.
Addison-Wesley.
</reference>
<subsectionHeader confidence="0.681285">
Semantics and the lexicon
</subsectionHeader>
<bodyText confidence="0.939049807692308">
James Pustejovsky (editor)
(Brandeis University)
Dordrecht: Kluwer Academic Publishers
(Studies in linguistics and philosophy,
edited by Gennaro Chierchia, Pauline
Jacobson, and Francis J. Pelletier, volume
49), 1993, vii + 416 pp.
Hardbound, ISBN 0-7923-1963-X, $140.00,
£92.00, Dfl 225.–
&amp;quot;The goal of this book is to integrate the re-
search being carried out in the field of lex-
ical semantics in linguistics with the work
on knowledge representation and lexicon de-
sign in computational linguistics. Rarely do
these two camps meet and discuss the de-
mands and concerns of each other&apos;s fields.
Therefore, this book is interesting in that it
provides a stimulating and unique discus-
sion between the computational perspective
of lexical meaning and the concerns of the
linguist for the semantic description of lexical
items in the context of syntactic descriptions.
This book grew out of the papers presented
at a workshop held at Brandeis University in
April, 1988.&amp;quot;—From the preface
The contents of the volume are as follows:
</bodyText>
<reference confidence="0.99023425">
Part I: Fundamentals of lexical structure
&amp;quot;X-bar semantics,&amp;quot; by Ray Jackendoff
&amp;quot;The syntax of metaphorical semantic roles,&amp;quot;
by George Lakoff
&amp;quot;Levels of lexical representation,&amp;quot; by Malka
Rappaport, Mary Laughren, and Beth
Levin
&amp;quot;Case marking and the semantics of mental
verbs,&amp;quot; by William Croft
&amp;quot;Type coercion and lexical selection,&amp;quot; by
James Pustejovsky
Part II: Mapping from lexical semantics to
syntax
&amp;quot;Nominalization and predicative
prepositional phrases,&amp;quot; by Jane Grimshaw
and Edwin Williams
&amp;quot;Adjectives, nominals, and the status of
arguments,&amp;quot; by Robert J.P. Ingria and
Leland M. George
&amp;quot;Unaccusativity in Dutch: Integrating syntax
</reference>
<bodyText confidence="0.79464">
and lexical semantics,&amp;quot; by Annie Zaenen
&amp;quot;Verbs in depictives and resultatives,&amp;quot; by
T.R. Rapoport
&amp;quot;Explicit syntax in the lexicon: The
representation of nominalizations,&amp;quot; by
Tom Roeper
Part III: Computational models of lexical
knowledge
&amp;quot;Lexical structure and conceptual
structures,&amp;quot; by John F. Sowa
&amp;quot;Lexical semantic constraints,&amp;quot; by Dan Fass
&amp;quot;Lexical and conceptual structures for
knowledge based translation,&amp;quot; by Sergei
Nirenburg and Christine Defrise
&amp;quot;Models for lexical knowledge bases,&amp;quot; by
Branimir Boguraev and Beth Levin
&amp;quot;Providing machine tractable dictionary
tools,&amp;quot; by Yorick Wilks, Dan Fass,
Cheng-Ming Guo, James McDonald, Tony
Plate, and Brian Slator
</bodyText>
<page confidence="0.998441">
606
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.014224">
<title confidence="0.9980915">Briefly Noted Parallel natural language processing</title>
<author confidence="0.990826">Geert Adriaens</author>
<author confidence="0.990826">Udo Hahn</author>
<affiliation confidence="0.894109333333333">(University of Leuren and University of Freiburg) Norwood, NJ: Ablex Publishing Company,</affiliation>
<address confidence="0.690063">1994, vi + 467 pp. Hardbound, ISBN 0-89391-869-5, $79.50</address>
<abstract confidence="0.986158068965517">($37.50 prepaid) Natural Language Processing an application-oriented text addressing parallel implementations of aspects of natural language understanding. Although the focus is not on any particular cognitive theory, attention is paid to human performance data throughout. The implementation issues and difficulties considered provide a grounding and a checkpoint to balance the existing body of more theoretical work. The book is a collection of papers, each chapter standing on its own yet each also tied in with several other chapters in the topics addressed and the aspects examined. In general, for each language aspect included, at least two papers cover the topic from slightly differing viewpoints. Additionally, most topics are balanced by a contrasting point of view; for example, formal context-free grammars versus parsing of free speech with mistakes, and complete story understanding versus single noun-phrase shades of meaning. Each chapter is focused and thus manageable, enabling the authors to make some useful observations about their topic. The book as a whole thus serves as a look at the entirety of natural language understanding and the editors have done a good job indeed of encasing and covering this topic. The first, rather lengthy, chapter provides a good review and overview of the topic and issues at hand. Starting with a look at psycholinguistic and cognitive arguments both for and against autonomous components versus interactive models of natural language processing, the editors conclude that parallel implementations of language processing should be further explored. This is followed by a discussion of parallelism from a computer science perspective: computing models, architectures, operating systems, and programming languages. A review of parallelism in natural language processing follows, with an eye toward the issues raised in the computer science review. A 24page bibliography provides a thorough reference for the plethora of topics covered in this chapter. The remaining 12 chapters of the book are individually authored papers covering parallel natural language processing. The first series of papers focuses on context-free parsing, starting with a theoretical account of the advantages obtained through parallelism, and results of implementations on parallel hardware. Further proposed implementations are presented using object-oriented systems and connectionist paradigms. Finally, parsing is considered as a constraint satisfaction and energy minimization problem. The next series of papers refocuses on the interaction perspective, considering various methodologies: connectionism, concurrent processes, frame-based actors and bulletin boards, and object-oriented functional programming. Finally, the book closes with an examination of language generation using connectionist and parallel unification models. The interested reader may refer to Chapter 1, Section 5.3 for a thorough overview of individual chapter contents. Due to the implementation focus, the reader may need a strong computer science background to get the most from this book, which assumes more than passing familiarity with a wide range of topics such as object-oriented and functional programming, deadlock avoidance techniques, and efficient implementations of Cocke-Younger-Kasami parsing. However, in general each concept is briefly introduced so the attentive reader can follow the specific topic even without a forunderstanding.—Jeanne University of California, San Diego Natural language understanding (second edition)</abstract>
<author confidence="0.999845">James Allen</author>
<affiliation confidence="0.9779105">(University of Rochester) Redwood City, CA: Benjamin/Cummings,</affiliation>
<address confidence="0.615259">1995, xv + 654 pp.</address>
<note confidence="0.844599333333333">Hardbound, ISBN 0-8053-0334-0, $56.95 the latest ACL of Computational Courses 1994), the first edi-</note>
<abstract confidence="0.995702184210526">(1987) of James Allen&apos;s textbook understanding by far the most frequently cited reference, being mentioned 604 Briefly Noted more than twice as often as any other. The publication of the second edition of this book should consequently be welcome news for faculty who teach courses using it as a required or recommended text or for selected readings. The book has been substantially revised and expanded, with new chapters added, and outdated material removed. The overall organization remains intact, however, with major divisions into three parts covering syntactic processing, semantic interpretation, and context and world knowledge. The original Part IV, &apos;Response generation,&apos; has been omitted, and the material in its two chapters on question answering and generation has been integrated into other chapters. There is a new appendix on speech recognition and , spoken language. A major change in Part I, &apos;Syntactic Processing,&apos; is the switch from augmented transition networks to feature-based context-free grammars as the primary formalism. In addition, a new chapter on statistical methods complements the existing material by introducing basic probability theory, partof-speech tagging, and probabilistic contextfree grammars. The focus in Part II, &apos;Semantic interpretation,&apos; is now more on underlying principles and issues, and less on specific computational techniques. Allen has extended his logical-form language to handle more-complex sentences, and a chapter on ambiguity resolution has been added that covers statistical word-sense disambiguation and semantic preferences as well as rulebased methods. Part III, &apos;Context and world knowledge,&apos; has been generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing software. Assignments included a morphological processor, a tagger, and several parsers, both those provided by Allen and others accessed by e-mail. Overall, Allen&apos;s second edition deserves decent marks. The updated material, particularly the emphasis on feature-based CFGs and the chapters on statistical methods, was badly needed to bring the coverage in line with current work in the field. The print quality is also a significant improvement over the first edition. Asked to evaluate the text at the end of the course, my students gave it an average 3.3 rating on a five-point scale with 5 at the top. Two areas of remaining weakness are the notational system and the software. The notational system that Allen develops for describing grammars and logical form, while used consistently throughout the book, is not identical to any other in the literature (a perennial problem). Its nuances are not always explained adequately, and even the best students found it obscure and hard to follow at times. For my class, the Unix version of Allen&apos;s software was installed on a network of IBM RS-6000s running AIX and CUSP, a freeware Common Lisp. The parsers worked fine, but the grammars and lexicons were primitive. In some cases, the rules and vocabulary for more advanced sections didn&apos;t include all of the features of earlier sections, making it difficult to run a suite of test sentences repeatedly. Only the most dedicated hackers were successful in enhancing the system by modifying the grammars and lexicons. One student managed to install the package on a Macintosh, but it required an inordinate effort because the Unix format had not been uniformly replaced in the Macintosh version. The software package has been upgraded frequently since it was tested early in 1995, and one can hope that these deficiencies have</abstract>
<note confidence="0.675628272727273">605 Computational Linguistics Volume 21, Number 4 remedied.—Virginia Hunter College and the Graduate School, The City University of New York References James (1987). language Bonnie J. (1994). of computational courses, edition. Association for Computational Linguistics. Ralph (1986).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Natural language understanding.</title>
<date>1987</date>
<journal>Benjamin/Cummings.</journal>
<contexts>
<context position="6329" citStr="Allen (1987)" startWordPosition="953" endWordPosition="954">ge,&apos; has been generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by anonymous ftp. In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing software. Assignment</context>
</contexts>
<marker>Allen, 1987</marker>
<rawString>Allen, James (1987). Natural language understanding. Benjamin/Cummings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Survey of computational linguistics courses, second edition. Association for Computational Linguistics.</title>
<date>1994</date>
<contexts>
<context position="4022" citStr="Dorr 1994" startWordPosition="596" endWordPosition="597">e of topics such as object-oriented and functional programming, deadlock avoidance techniques, and efficient implementations of Cocke-Younger-Kasami parsing. However, in general each concept is briefly introduced so the attentive reader can follow the specific topic even without a formal understanding.—Jeanne Milostan, University of California, San Diego Natural language understanding (second edition) James Allen (University of Rochester) Redwood City, CA: Benjamin/Cummings, 1995, xv + 654 pp. Hardbound, ISBN 0-8053-0334-0, $56.95 In the latest ACL Survey of Computational Linguistics Courses (Dorr 1994), the first edition (1987) of James Allen&apos;s textbook Natural language understanding was by far the most frequently cited reference, being mentioned 604 Briefly Noted more than twice as often as any other. The publication of the second edition of this book should consequently be welcome news for faculty who teach courses using it as a required or recommended text or for selected readings. The book has been substantially revised and expanded, with new chapters added, and outdated material removed. The overall organization remains intact, however, with major divisions into three parts covering sy</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Dorr, Bonnie J. (1994). Survey of computational linguistics courses, second edition. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
</authors>
<title>Computational linguistics: An introduction.</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6315" citStr="Grishman (1986)" startWordPosition="951" endWordPosition="952">and world knowledge,&apos; has been generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by anonymous ftp. In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing softwa</context>
</contexts>
<marker>Grishman, 1986</marker>
<rawString>Grishman, Ralph (1986). Computational linguistics: An introduction. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>Readings in natural language processing.</booktitle>
<editor>Grosz, Barbara; Sparck Jones, Karen; and Webber, Bonnie (editors)</editor>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="6315" citStr="(1986)" startWordPosition="952" endWordPosition="952"> knowledge,&apos; has been generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by anonymous ftp. In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing softwa</context>
</contexts>
<marker>1986</marker>
<rawString>Grosz, Barbara; Sparck Jones, Karen; and Webber, Bonnie (editors) (1986). Readings in natural language processing. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<title>Natural language processing.</title>
<date>1994</date>
<editor>Pereira, Fernando and Grosz, Barbara (editors)</editor>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="6745" citStr="(1994)" startWordPosition="1016" endWordPosition="1016">ntroductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing software. Assignments included a morphological processor, a tagger, and several parsers, both those provided by Allen and others accessed by e-mail. Overall, Allen&apos;s second edition deserves decent marks. The updated material, particularly the emphasis on feature-based CFGs and the chapters on statistical methods, was badly needed to bring the coverage in line with current work in the field. The print quality is also a significant im</context>
</contexts>
<marker>1994</marker>
<rawString>Pereira, Fernando and Grosz, Barbara (editors) (1994). Natural language processing. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Smith</author>
</authors>
<title>Computers and human language.</title>
<date>1991</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6343" citStr="Smith (1991)" startWordPosition="955" endWordPosition="956">generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by anonymous ftp. In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to use existing software. Assignments included a m</context>
</contexts>
<marker>Smith, 1991</marker>
<rawString>Smith, George (1991). Computers and human language. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Language as a cognitive process. Volume I: Syntax.</title>
<date>1983</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="6298" citStr="Winograd (1983)" startWordPosition="949" endWordPosition="950">rt III, &apos;Context and world knowledge,&apos; has been generally updated to reflect work that has been published since the first edition appeared. The software that accompanies this edition features a bottom-up chart parser and a set of grammars and lexicons that are keyed to the examples in specific sections of Parts I and II. Unix, Macintosh, and DOS versions in standard Common Lisp are available by anonymous ftp. In the past twelve years I have taught an introductory graduate course in computational linguistics five times, most recently in early 1995, using five different textbooks: successively, Winograd (1983), Grishman (1986), Allen (1987), Smith (1991), and the book reviewed here. Offered this year at the CUNY Graduate Center, the class attracted students from computer science, linguistics, and psychology, whose backgrounds in linguistics and computation ranged from practically none to solid. Allen&apos;s new book was supplemented with recommended readings from Grosz, Sparck Jones, and Webber (1986) and suggested readings from Pereira and Grosz (1994). Part I was covered in its entirety along with selected chapters in Parts II and III. The laboratory component of the course required the students to us</context>
</contexts>
<marker>Winograd, 1983</marker>
<rawString>Winograd, Terry (1983). Language as a cognitive process. Volume I: Syntax. Addison-Wesley.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Part</author>
</authors>
<title>Fundamentals of lexical structure &amp;quot;X-bar semantics,&amp;quot; by Ray Jackendoff &amp;quot;The syntax of metaphorical semantic roles,&amp;quot; by George Lakoff &amp;quot;Levels of lexical representation,&amp;quot; by Malka Rappaport, Mary Laughren,</title>
<location>and Beth Levin</location>
<marker>Part, </marker>
<rawString>Part I: Fundamentals of lexical structure &amp;quot;X-bar semantics,&amp;quot; by Ray Jackendoff &amp;quot;The syntax of metaphorical semantic roles,&amp;quot; by George Lakoff &amp;quot;Levels of lexical representation,&amp;quot; by Malka Rappaport, Mary Laughren, and Beth Levin</rawString>
</citation>
<citation valid="false">
<title>Case marking and the semantics of mental verbs,&amp;quot; by William Croft &amp;quot;Type coercion and lexical selection,&amp;quot; by James Pustejovsky</title>
<marker></marker>
<rawString>&amp;quot;Case marking and the semantics of mental verbs,&amp;quot; by William Croft &amp;quot;Type coercion and lexical selection,&amp;quot; by James Pustejovsky</rawString>
</citation>
<citation valid="false">
<authors>
<author>Part</author>
</authors>
<title>Mapping from lexical semantics to syntax</title>
<marker>Part, </marker>
<rawString>Part II: Mapping from lexical semantics to syntax</rawString>
</citation>
<citation valid="false">
<title>Nominalization and predicative prepositional phrases,&amp;quot; by Jane Grimshaw and Edwin</title>
<location>Williams</location>
<marker></marker>
<rawString>&amp;quot;Nominalization and predicative prepositional phrases,&amp;quot; by Jane Grimshaw and Edwin Williams</rawString>
</citation>
<citation valid="false">
<authors>
<author>nominals Adjectives</author>
</authors>
<title>and the status of arguments,&amp;quot; by</title>
<marker>Adjectives, </marker>
<rawString>&amp;quot;Adjectives, nominals, and the status of arguments,&amp;quot; by Robert J.P. Ingria and Leland M. George</rawString>
</citation>
<citation valid="false">
<title>Unaccusativity in Dutch: Integrating syntax</title>
<marker></marker>
<rawString>&amp;quot;Unaccusativity in Dutch: Integrating syntax</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>