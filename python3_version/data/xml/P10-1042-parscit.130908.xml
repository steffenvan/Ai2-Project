<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.930838">
Sentiment Learning on Product Reviews via Sentiment Ontology Tree
</title>
<author confidence="0.998949">
Wei Wei
</author>
<affiliation confidence="0.982204">
Department of Computer and
Information Science
Norwegian University of Science
and Technology
</affiliation>
<email confidence="0.987626">
wwei@idi.ntnu.no
</email>
<sectionHeader confidence="0.997274" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999689318181818">
Existing works on sentiment analysis on
product reviews suffer from the following
limitations: (1) The knowledge of hierar-
chical relationships of products attributes
is not fully utilized. (2) Reviews or sen-
tences mentioning several attributes asso-
ciated with complicated sentiments are not
dealt with very well. In this paper, we pro-
pose a novel HL-SOT approach to label-
ing a product’s attributes and their asso-
ciated sentiments in product reviews by a
Hierarchical Learning (HL) process with a
defined Sentiment Ontology Tree (SOT).
The empirical analysis against a human-
labeled data set demonstrates promising
and reasonable performance of the pro-
posed HL-SOT approach. While this pa-
per is mainly on sentiment analysis on re-
views of one product, our proposed HL-
SOT approach is easily generalized to la-
beling a mix of reviews of more than one
products.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996123125">
As the internet reaches almost every corner of this
world, more and more people write reviews and
share opinions on the World Wide Web. The user-
generated opinion-rich reviews will not only help
other users make better judgements but they are
also useful resources for manufacturers of prod-
ucts to keep track and manage customer opinions.
However, as the number of product reviews grows,
it becomes difficult for a user to manually learn
the panorama of an interesting topic from existing
online information. Faced with this problem, re-
search works, e.g., (Hu and Liu, 2004; Liu et al.,
2005; Lu et al., 2009), of sentiment analysis on
product reviews were proposed and have become
a popular research topic at the crossroads of infor-
mation retrieval and computational linguistics.
</bodyText>
<author confidence="0.493034">
Jon Atle Gulla
</author>
<affiliation confidence="0.9560565">
Department of Computer and
Information Science
Norwegian University of Science
and Technology
</affiliation>
<email confidence="0.949733">
jag@idi.ntnu.no
</email>
<bodyText confidence="0.999048435897436">
Carrying out sentiment analysis on product re-
views is not a trivial task. Although there have al-
ready been a lot of publications investigating on
similar issues, among which the representatives
are (Turney, 2002; Dave et al., 2003; Hu and Liu,
2004; Liu et al., 2005; Popescu and Etzioni, 2005;
Zhuang et al., 2006; Lu and Zhai, 2008; Titov and
McDonald, 2008; Zhou and Chaovalit, 2008; Lu et
al., 2009), there is still room for improvement on
tackling this problem. When we look into the de-
tails of each example of product reviews, we find
that there are some intrinsic properties that exist-
ing previous works have not addressed in much de-
tail.
First of all, product reviews constitute domain-
specific knowledge. The product’s attributes men-
tioned in reviews might have some relationships
between each other. For example, for a digital
camera, comments on image quality are usually
mentioned. However, a sentence like “40D han-
dles noise very well up to ISO 800”, also refers
to image quality of the camera 40D. Here we say
“noise” is a sub-attribute factor of “image quality”.
We argue that the hierarchical relationship be-
tween a product’s attributes can be useful knowl-
edge if it can be formulated and utilized in product
reviews analysis. Secondly, Vocabularies used in
product reviews tend to be highly overlapping. Es-
pecially, for same attribute, usually same words or
synonyms are involved to refer to them and to de-
scribe sentiment on them. We believe that labeling
existing product reviews with attributes and cor-
responding sentiment forms an effective training
resource to perform sentiment analysis. Thirdly,
sentiments expressed in a review or even in a
sentence might be opposite on different attributes
and not every attributes mentioned are with senti-
ments. For example, it is common to find a frag-
ment of a review as follows:
</bodyText>
<footnote confidence="0.547155">
Example 1: “...I am very impressed with this cam-
era exceptfor its a bit heavy weight especially with
</footnote>
<page confidence="0.963567">
404
</page>
<note confidence="0.973485">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 404–413,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.973717571428571">
design and usability + weight interface design and usability - image quality + noise resolution image quality - lens + lens -
weight + weight - interface + menu button interface -
camera +
menu + menu - button + button -
design and usability image quality lens camera -
noise + noise - resolution + resolution -
camera
</figure>
<figureCaption confidence="0.7066654">
Figure 1: an example of part of a SOT for digital camera
extra lenses attached. It has many buttons and two
main dials. The first dial is thumb dial, located
near shutter button. The second one is the big
round dial located at the back of the camera...”
</figureCaption>
<bodyText confidence="0.99999">
In this example, the first sentence gives positive
comment on the camera as well as a complaint on
its heavy weight. Even if the words “lenses” ap-
pears in the review, it is not fair to say the cus-
tomer expresses any sentiment on lens. The sec-
ond sentence and the rest introduce the camera’s
buttons and dials. It’s also not feasible to try to
get any sentiment from these contents. We ar-
gue that when performing sentiment analysis on
reviews, such as in the Example 1, more attention
is needed to distinguish between attributes that are
mentioned with and without sentiment.
In this paper, we study the problem of senti-
ment analysis on product reviews through a novel
method, called the HL-SOT approach, namely Hi-
erarchical Learning (HL) with Sentiment Ontol-
ogy Tree (SOT). By sentiment analysis on prod-
uct reviews we aim to fulfill two tasks, i.e., label-
ing a target text&apos; with: 1) the product’s attributes
(attributes identification task), and 2) their corre-
sponding sentiments mentioned therein (sentiment
annotation task). The result of this kind of label-
ing process is quite useful because it makes it pos-
sible for a user to search reviews on particular at-
tributes of a product. For example, when consider-
ing to buy a digital camera, a prospective user who
cares more about image quality probably wants to
find comments on the camera’s image quality in
other users’ reviews. SOT is a tree-like ontology
structure that formulates the relationships between
a product’s attributes. For example, Fig. 1 is a SOT
for a digital camerae. The root node of the SOT is
</bodyText>
<footnote confidence="0.995601">
1Each product review to be analyzed is called target text
in the following of this paper.
2Due to the space limitation, not all attributes of a digi-
tal camera are enumerated in this SOT; m+/m- means posi-
</footnote>
<bodyText confidence="0.9308563">
a camera itself. Each of the non-leaf nodes (white
nodes) of the SOT represents an attribute of a cam-
erae. All leaf nodes (gray nodes) of the SOT rep-
resent sentiment (positive/negative) nodes respec-
tively associated with their parent nodes. A for-
mal definition on SOT is presented in Section 3.1.
With the proposed concept of SOT, we manage to
formulate the two tasks of the sentiment analysis
to be a hierarchical classification problem. We fur-
ther propose a specific hierarchical learning algo-
rithm, called HL-SOT algorithm, which is devel-
oped based on generalizing an online-learning al-
gorithm H-RLS (Cesa-Bianchi et al., 2006). The
HL-SOT algorithm has the same property as the
H-RLS algorithm that allows multiple-path label-
ing (input target text can be labeled with nodes be-
longing to more than one path in the SOT) and
partial-path labeling (the input target text can be
labeled with nodes belonging to a path that does
not end on a leaf). This property makes the ap-
proach well suited for the situation where com-
plicated sentiments on different attributes are ex-
pressed in one target text. Unlike the H-RLS algo-
rithm , the HL-SOT algorithm enables each clas-
sifier to separately learn its own specific thresh-
old. The proposed HL-SOT approach is empiri-
cally analyzed against a human-labeled data set.
The experimental results demonstrate promising
and reasonable performance of our approach.
This paper makes the following contributions:
</bodyText>
<listItem confidence="0.9991055">
• To the best of our knowledge, with the pro-
posed concept of SOT, the proposed HL-SOT
approach is the first work to formulate the
tasks of sentiment analysis to be a hierarchi-
cal classification problem.
• A specific hierarchical learning algorithm is
</listItem>
<bodyText confidence="0.603924">
tive/negative sentiment associated with an attribute m.
</bodyText>
<footnote confidence="0.972976">
3A product itself can be treated as an overall attribute of
the product.
</footnote>
<page confidence="0.998813">
405
</page>
<bodyText confidence="0.999384">
further proposed to achieve tasks of senti-
ment analysis in one hierarchical classifica-
tion process.
</bodyText>
<listItem confidence="0.892602666666667">
• The proposed HL-SOT approach can be gen-
eralized to make it possible to perform senti-
ment analysis on target texts that are a mix of
</listItem>
<bodyText confidence="0.994149">
reviews of different products, whereas exist-
ing works mainly focus on analyzing reviews
of only one type of product.
The remainder of the paper is organized as fol-
lows. In Section 2, we provide an overview of
related work on sentiment analysis. Section 3
presents our work on sentiment analysis with HL-
SOT approach. The empirical analysis and the re-
sults are presented in Section 4, followed by the
conclusions, discussions, and future work in Sec-
tion 5.
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999890853658537">
The task of sentiment analysis on product reviews
was originally performed to extract overall senti-
ment from the target texts. However, in (Turney,
2002), as the difficulty shown in the experiments,
the whole sentiment of a document is not neces-
sarily the sum of its parts. Then there came up
with research works shifting focus from overall
document sentiment to sentiment analysis based
on product attributes (Hu and Liu, 2004; Popescu
and Etzioni, 2005; Ding and Liu, 2007; Liu et al.,
2005).
Document overall sentiment analysis is to sum-
marize the overall sentiment in the document. Re-
search works related to document overall senti-
ment analysis mainly rely on two finer levels senti-
ment annotation: word-level sentiment annotation
and phrase-level sentiment annotation. The word-
level sentiment annotation is to utilize the polar-
ity annotation of words in each sentence and sum-
marize the overall sentiment of each sentiment-
bearing word to infer the overall sentiment within
the text (Hatzivassiloglou and Wiebe, 2000; An-
dreevskaia and Bergler, 2006; Esuli and Sebas-
tiani, 2005; Esuli and Sebastiani, 2006; Hatzi-
vassiloglou and McKeown, 1997; Kamps et al.,
2004; Devitt and Ahmad, 2007; Yu and Hatzivas-
siloglou, 2003). The phrase-level sentiment anno-
tation focuses sentiment annotation on phrases not
words with concerning that atomic units of expres-
sion is not individual words but rather appraisal
groups (Whitelaw et al., 2005). In (Wilson et al.,
2005), the concepts of prior polarity and contex-
tual polarity were proposed. This paper presented
a system that is able to automatically identify the
contextual polarity for a large subset of sentiment
expressions. In (Turney, 2002), an unsupervised
learning algorithm was proposed to classify re-
views as recommended or not recommended by
averaging sentiment annotation of phrases in re-
views that contain adjectives or adverbs. How-
ever, the performances of these works are not good
enough for sentiment analysis on product reviews,
where sentiment on each attribute of a product
could be so complicated that it is unable to be ex-
pressed by overall document sentiment.
Attributes-based sentiment analysis is to ana-
lyze sentiment based on each attribute of a prod-
uct. In (Hu and Liu, 2004), mining product fea-
tures was proposed together with sentiment polar-
ity annotation for each opinion sentence. In that
work, sentiment analysis was performed on prod-
uct attributes level. In (Liu et al., 2005), a system
with framework for analyzing and comparing con-
sumer opinions of competing products was pro-
posed. The system made users be able to clearly
see the strengths and weaknesses of each prod-
uct in the minds of consumers in terms of various
product features. In (Popescu and Etzioni, 2005),
Popescu and Etzioni not only analyzed polarity
of opinions regarding product features but also
ranked opinions based on their strength. In (Liu
et al., 2007), Liu et al. proposed Sentiment-PLSA
that analyzed blog entries and viewed them as a
document generated by a number of hidden sen-
timent factors. These sentiment factors may also
be factors based on product attributes. In (Lu and
Zhai, 2008), Lu et al. proposed a semi-supervised
topic models to solve the problem of opinion inte-
gration based on the topic of a product’s attributes.
The work in (Titov and McDonald, 2008) pre-
sented a multi-grain topic model for extracting the
ratable attributes from product reviews. In (Lu et
al., 2009), the problem of rated attributes summary
was studied with a goal of generating ratings for
major aspects so that a user could gain different
perspectives towards a target entity. All these re-
search works concentrated on attribute-based sen-
timent analysis. However, the main difference
with our work is that they did not sufficiently uti-
lize the hierarchical relationships among a prod-
uct attributes. Although a method of ontology-
supported polarity mining, which also involved
</bodyText>
<page confidence="0.995394">
406
</page>
<bodyText confidence="0.9999688">
ontology to tackle the sentiment analysis problem,
was proposed in (Zhou and Chaovalit, 2008), that
work studied polarity mining by machine learn-
ing techniques that still suffered from a problem
of ignoring dependencies among attributes within
an ontology’s hierarchy. In the contrast, our work
solves the sentiment analysis problem as a hierar-
chical classification problem that fully utilizes the
hierarchy of the SOT during training and classifi-
cation process.
</bodyText>
<sectionHeader confidence="0.986458" genericHeader="method">
3 The HL-SOT Approach
</sectionHeader>
<bodyText confidence="0.999955">
In this section, we first propose a formal defini-
tion on SOT. Then we formulate the HL-SOT ap-
proach. In this novel approach, tasks of sentiment
analysis are to be achieved in a hierarchical classi-
fication process.
</bodyText>
<subsectionHeader confidence="0.999239">
3.1 Sentiment Ontology Tree
</subsectionHeader>
<bodyText confidence="0.99862275">
As we discussed in Section 1, the hierarchial rela-
tionships among a product’s attributes might help
improve the performance of attribute-based senti-
ment analysis. We propose to use a tree-like ontol-
ogy structure SOT, i.e., Sentiment Ontology Tree,
to formulate relationships among a product’s at-
tributes. Here,we give a formal definition on what
a SOT is.
</bodyText>
<construct confidence="0.9595479">
Definition 1 [SOT] SOT is an abbreviation for
Sentiment Ontology Tree that is a tree-like ontol-
ogy structure T (v, v+, v−, T). v is the root node
of T which represents an attribute of a given prod-
uct. v+ is a positive sentiment leaf node associ-
ated with the attribute v. v− is a negative sen-
timent leaf node associated with the attribute v.
T is a set of subtrees. Each element of T is also
a SOT T′(v′, v′+, v′−, T′) which represents a sub-
attribute of its parent attribute node.
</construct>
<bodyText confidence="0.999950708333333">
By the Definition 1, we define a root of a SOT to
represent an attribute of a product. The SOT’s two
leaf child nodes are sentiment (positive/negative)
nodes associated with the root attribute. The SOT
recursively contains a set of sub-SOTs where each
root of a sub-SOT is a non-leaf child node of the
root of the SOT and represent a sub-attribute be-
longing to its parent attribute. This definition suc-
cessfully describes the hierarchical relationships
among all the attributes of a product. For example,
in Fig. 1 the root node of the SOT for a digital cam-
era is its general overview attribute. Comments on
a digital camera’s general overview attribute ap-
pearing in a review might be like “this camera is
great”. The “camera” SOT has two sentiment leaf
child nodes as well as three non-leaf child nodes
which are respectively root nodes of sub-SOTs for
sub-attributes “design and usability”, “image qual-
ity”, and “lens”. These sub-attributes SOTs re-
cursively repeat until each node in the SOT does
not have any more non-leaf child node, which
means the corresponding attributes do not have
any sub-attributes, e.g., the attribute node “button”
in Fig. 1.
</bodyText>
<subsectionHeader confidence="0.999773">
3.2 Sentiment Analysis with SOT
</subsectionHeader>
<bodyText confidence="0.99999">
In this subsection, we present the HL-SOT ap-
proach. With the defined SOT, the problem of sen-
timent analysis is able to be formulated to be a hi-
erarchial classification problem. Then a specific
hierarchical learning algorithm is further proposed
to solve the formulated problem.
</bodyText>
<subsubsectionHeader confidence="0.685815">
3.2.1 Problem Formulation
</subsubsectionHeader>
<bodyText confidence="0.996690892857143">
In the proposed HL-SOT approach, each target
text is to be indexed by a unit-norm vector x ∈
X, X = Rd. Let 9 = {1, ..., N} denote the fi-
nite set of nodes in SOT. Let y = {y1, ..., yN} ∈
{0,1}N be a label vector to a target text x, where
∀i ∈ 9 :
A label vector y ∈ {0,1}N is said to respect
SOT if and only if y satisfies ∀i ∈ 9 , ∀j ∈
A(i) : if yz = 1 then yj = 1, where A(i)
represents a set ancestor nodes of i, i.e.,A(i) =
{x|ancestor(i, x)}. Let Y denote a set of label
vectors that respect SOT. Then the tasks of senti-
ment analysis can be formulated to be the goal of a
hierarchical classification that is to learn a function
f : X → Y, that is able to label each target text
x ∈ X with classifier of each node and generating
with x a label vector y ∈ Y that respects SOT. The
requirement of a generated label vector y ∈ Y en-
sures that a target text is to be labeled with a node
only if its parent attribute node is labeled with the
target text. For example, in Fig. 1 a review is to
be labeled with “image quality +” requires that the
review should be successively labeled as related to
“camera” and “image quality”. This is reasonable
and consistent with intuition, because if a review
cannot be identified to be related to a camera, it is
not safe to infer that the review is commenting a
camera’s image quality with positive sentiment.
</bodyText>
<equation confidence="0.9891634">
{
0, if x is not labeled by the classifier of nod
yz =
e i.
1, if x is labeled by the classifier of node i,
</equation>
<page confidence="0.990041">
407
</page>
<sectionHeader confidence="0.7656" genericHeader="method">
3.2.2 HL-SOT Algorithm
</sectionHeader>
<bodyText confidence="0.993962173913044">
The algorithm H-RLS studied in (Cesa-Bianchi et
al., 2006) solved a similar hierarchical classifica-
tion problem as we formulated above. However,
the H-RLS algorithm was designed as an online-
learning algorithm which is not suitable to be ap-
plied directly in our problem setting. Moreover,
the algorithm H-RLS defined the same value as
the threshold of each node classifier. We argue
that if the threshold values could be learned sepa-
rately for each classifiers, the performance of clas-
sification process would be improved. Therefore
we propose a specific hierarchical learning algo-
rithm, named HL-SOT algorithm, that is able to
train each node classifier in a batch-learning set-
ting and allows separately learning for the thresh-
old of each node classifier.
Defining the f function Let w1, ..., wN be
weight vectors that define linear-threshold classi-
fiers of each node in SOT. Let W = (w1, ..., wN)⊤
be an N x d matrix called weight matrix. Here we
generalize the work in (Cesa-Bianchi et al., 2006)
and define the hierarchical classification function
f as:
</bodyText>
<equation confidence="0.8829845">
y = f(x) = g(W · x),
where x E X, y� E Y. Let z = W · x. Then the
function y� = g(z) on an N-dimensional vector z
defines:
Vi = 1, ..., N �
{ B(zi &gt; θi), if i is a root node in SOT
or yj = 1 for j = P(i),
0, else
</equation>
<bodyText confidence="0.999717666666667">
where P(i) is the parent node of i in SOT and
B(S) is a boolean function which is 1 if and only
if the statement S is true. Then the hierarchical
classification function f is parameterized by the
weight matrix W = (w1, ..., wN)⊤ and threshold
vector θ = (θ1, ..., θN)⊤. The hierarchical learn-
ing algorithm HL-SOT is proposed for learning
the parameters of W and θ.
Parameters Learning for f function Let D de-
note the training data set: D = {(r, l)|r E X, l E
YJ. In the HL-SOT learning process, the weight
matrix W is firstly initialized to be a 0 matrix,
where each row vector wi is a 0 vector. The thresh-
old vector is initialized to be a 0 vector. Each in-
stance in the training set D goes into the training
process. When a new instance rt is observed, each
row vector wi,t of the weight matrix Wt is updated
by a regularized least squares estimator given by:
</bodyText>
<equation confidence="0.997286333333333">
wi,t = (I + Si,Q(i,t−1)S⊤i,Q(i,t−1) + rtr⊤t )−1
xSi,Q(i,t−1)(li,i1, li,it, ..., li,iQ(z,t−1))⊤
(1)
</equation>
<bodyText confidence="0.994467285714286">
where I is a d x d identity matrix, Q(i, t − 1)
denotes the number of times the parent of node i
observes a positive label before observing the in-
stance rt, Si,Q(i,t−1) = , riQ(z,t−1)] is a d x
Q(i, t−1) matrix whose columns are the instances
ri1, ..., riQ(z,t−1), and (li,i1, li,it, ..., li,iQ(z,t−1))⊤ is
a Q(i, t−1)-dimensional vector of the correspond-
ing labels observed by node i. The Formula 1 re-
stricts that the weight vector wi,t of the classifier i
is only updated on the examples that are positive
for its parent node. Then the label vector yrt is
computed for the instance rt, before the real label
vector lrt is observed. Then the current threshold
vector θt is updated by:
</bodyText>
<equation confidence="0.998672">
θt+1 = θt + ϵ(yrt − lrt), (2)
</equation>
<bodyText confidence="0.994046857142857">
where ϵ is a small positive real number that de-
notes a corrective step for correcting the current
threshold vector θt. To illustrate the idea behind
the Formula 2, let y′t = yrt − lrt. Let y′i,t denote
an element of the vector y′t. The Formula 2 correct
the current threshold θi,t for the classifier i in the
following way:
</bodyText>
<listItem confidence="0.7423595">
• If y′i,t = 0, it means the classifier i made a
proper classification for the current instance
rt. Then the current threshold θi does not
need to be adjusted.
• If y′i,t = 1, it means the classifier i made an
improper classification by mistakenly identi-
fying the attribute i of the training instance
rt that should have not been identified. This
indicates the value of θi is not big enough to
serve as a threshold so that the attribute i in
this case can be filtered out by the classifier
i. Therefore, the current threshold θi will be
adjusted to be larger by ϵ.
• If y′i,t = −1, it means the classifier i made an
</listItem>
<bodyText confidence="0.7298544">
improper classification by failing to identify
the attribute i of the training instance rt that
should have been identified. This indicates
the value of θi is not small enough to serve as
a threshold so that the attribute i in this case
</bodyText>
<equation confidence="0.992512">
yi =
</equation>
<page confidence="0.987618">
408
</page>
<figure confidence="0.2938265">
Algorithm 1 Hierarchical Learning Algorithm HL-SOT
INITIALIZATION:
</figure>
<listItem confidence="0.9279268125">
1: Each vector wi,1, i = 1, ..., N of weight ma-
trix W1 is set to be 0 vector
2: Threshold vector O1 is set to be 0 vector
BEGIN
3: for t = 1, ..., |D |do
4: Observe instance rt E X
5: for i = 1,...N do
6: Update each row wi,t of weight matrix
Wt by Formula 1
7: end for
8: Compute yrt = f(rt) = g(Wt · rt)
9: Observe label vector lrt E Y of the in-
stance rt
10: Update threshold vector Ot by Formula 2
11: end for
END
</listItem>
<bodyText confidence="0.999916857142857">
can be recognized by the classifier i. There-
fore, the current threshold Oi will be adjusted
to be smaller by c.
The hierarchial learning algorithm HL-SOT is
presented as in Algorithm 1. The HL-SOT al-
gorithm enables each classifier to have its own
specific threshold value and allows this thresh-
old value can be separately learned and corrected
through the training process. It is not only a batch-
learning setting of the H-RLS algorithm but also
a generalization to the latter. If we set the algo-
rithm HL-SOT’s parameter c to be 0, the HL-SOT
becomes the H-RLS algorithm in a batch-learning
setting.
</bodyText>
<sectionHeader confidence="0.993603" genericHeader="method">
4 Empirical Analysis
</sectionHeader>
<bodyText confidence="0.999979">
In this section, we conduct systematic experiments
to perform empirical analysis on our proposed HL-
SOT approach against a human-labeled data set.
In order to encode each text in the data set by a
d-dimensional vector x E Rd, we first remove all
the stop words and then select the top d frequency
terms appearing in the data set to construct the in-
dex term space. Our experiments are intended to
address the following questions:(1) whether uti-
lizing the hierarchical relationships among labels
help to improve the accuracy of the classification?
(2) whether the introduction of separately learn-
ing threshold for each classifier help to improve
the accuracy of the classification? (3) how does
the corrective step c impact the performance of the
proposed approach?(4)how does the dimensional-
ity d of index terms space impact the proposed ap-
proach’s computing efficiency and accuracy?
</bodyText>
<subsectionHeader confidence="0.997547">
4.1 Data Set Preparation
</subsectionHeader>
<bodyText confidence="0.999857714285715">
The data set contains 1446 snippets of customer
reviews on digital cameras that are collected from
a customer review website4. We manually con-
struct a SOT for the product of digital cameras.
The constructed SOT (e.g., Fig. 1) contains 105
nodes that include 35 non-leaf nodes representing
attributes of the digital camera and 70 leaf nodes
representing associated sentiments with attribute
nodes. Then we label all the snippets with corre-
sponding labels of nodes in the constructed SOT
complying with the rule that a target text is to be
labeled with a node only if its parent attribute node
is labeled with the target text. We randomly divide
the labeled data set into five folds so that each fold
at least contains one example snippets labeled by
each node in the SOT. For each experiment set-
ting, we run 5 experiments to perform cross-fold
evaluation by randomly picking three folds as the
training set and the other two folds as the testing
set. All the testing results are averages over 5 run-
ning of experiments.
</bodyText>
<subsectionHeader confidence="0.969369">
4.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999925">
Since the proposed HL-SOT approach is a hier-
archical classification process, we use three clas-
sic loss functions for measuring classification per-
formance. They are the One-error Loss (O-Loss)
function, the Symmetric Loss (S-Loss) function,
and the Hierarchical Loss (H-Loss) function:
</bodyText>
<listItem confidence="0.955863333333333">
• One-error loss (O-Loss) function is defined
as:
LO(9, l) = B(1i : yi =� li),
</listItem>
<bodyText confidence="0.999556333333333">
where y� is the prediction label vector and l is
the true label vector; B is the boolean func-
tion as defined in Section 3.2.2.
</bodyText>
<listItem confidence="0.997161">
• Symmetric loss (S-Loss) function is defined
as:
</listItem>
<equation confidence="0.9739075">
LS(�y, l) = ∑N B(�yi =� li),
i=1
</equation>
<listItem confidence="0.9948455">
• Hierarchical loss (H-Loss) function is defined
as:
</listItem>
<equation confidence="0.8667135">
LH(y, l) = ∑N B(yi =� li A bj E A(i), yj = lj),
i=1
</equation>
<footnote confidence="0.654172">
4http://www.consumerreview.com/
</footnote>
<page confidence="0.999196">
409
</page>
<tableCaption confidence="0.999607">
Table 1: Performance Comparisons (A Smaller Loss Value Means a Better Performance)
</tableCaption>
<table confidence="0.927670666666667">
Metrics Dimensinality=110 Dimensinality=220
H-RLS HL-flat HL-SOT H-RLS HL-flat HL-SOT
O-Loss 0.9812 0.8772 0.8443 0.9783 0.8591 0.8428
S-Loss 8.5516 2.8921 2.3190 7.8623 2.8449 2.2812
H-Loss 3.2479 1.1383 1.0366 3.1029 1.1298 1.0247
Corrective Step Corrective Step
</table>
<figure confidence="0.999520615384615">
(b) S-Loss (c) H-Loss
S−Loss
H−Loss
1.045
1.035
1.025
1.05
1.04
1.03
1.02
0 0.02
0.04 0.06 0.08 0.1
d=110
di20
2.4
2.35
2.3
2.25
2.2
d=110
d=220
2.15
0 0.02
0.04 0.06 0.08 0.1
Corrective Step
(a) O-Loss
0.852
0.85
0.848
d=110
d=220
0.02 0.04 0.06 0.08 0.1
0.838
0
O−Loss
0.846
0.844
0.842
0.84
</figure>
<figureCaption confidence="0.999977">
Figure 2: Impact of Corrective Step c
</figureCaption>
<bodyText confidence="0.999991533333333">
where A denotes a set of nodes that are an-
cestors of node i in SOT.
Unlike the O-Loss function and the S-Loss func-
tion, the H-Loss function captures the intuition
that loss should only be charged on a node when-
ever a classification mistake is made on a node of
SOT but no more should be charged for any ad-
ditional mistake occurring in the subtree of that
node. It measures the discrepancy between the
prediction labels and the true labels with consider-
ation on the SOT structure defined over the labels.
In our experiments, the recorded loss function val-
ues for each experiment running are computed by
averaging the loss function values of each testing
snippets in the testing set.
</bodyText>
<subsectionHeader confidence="0.999105">
4.3 Performance Comparison
</subsectionHeader>
<bodyText confidence="0.99813575">
In order to answer the questions (1), (2) in the
beginning of this section, we compare our HL-
SOT approach with the following two baseline ap-
proaches:
</bodyText>
<listItem confidence="0.960428421052632">
• HL-flat: The HL-flat approach involves an al-
gorithm that is a “flat” version of HL-SOT
algorithm by ignoring the hierarchical rela-
tionships among labels when each classifier
is trained. In the training process of HL-flat,
the algorithm reflexes the restriction in the
HL-SOT algorithm that requires the weight
vector wi,t of the classifier i is only updated
on the examples that are positive for its parent
node.
• H-RLS: The H-RLS approach is imple-
mented by applying the H-RLS algorithm
studied in (Cesa-Bianchi et al., 2006). Un-
like our proposed HL-SOT algorithm that en-
ables the threshold values to be learned sepa-
rately for each classifiers in the training pro-
cess, the H-RLS algorithm only uses an iden-
tical threshold values for each classifiers in
the classification process.
</listItem>
<bodyText confidence="0.99997005882353">
Experiments are conducted on the performance
comparison between the proposed HL-SOT ap-
proach with HL-flat approach and the H-RLS ap-
proach. The dimensionality d of the index term
space is set to be 110 and 220. The corrective step
c is set to be 0.005. The experimental results are
summarized in Table 1. From Table 1, we can ob-
serve that the HL-SOT approach generally beats
the H-RLS approach and HL-flat approach on O-
Loss, S-Loss, and H-Loss respectively. The H-
RLS performs worse than the HL-flat and the HL-
SOT, which indicates that the introduction of sepa-
rately learning threshold for each classifier did im-
prove the accuracy of the classification. The HL-
SOT approach performs better than the HL-flat,
which demonstrates the effectiveness of utilizing
the hierarchical relationships among labels.
</bodyText>
<subsectionHeader confidence="0.999655">
4.4 Impact of Corrective Step c
</subsectionHeader>
<bodyText confidence="0.9990056">
The parameter c in the proposed HL-SOT ap-
proach controls the corrective step of the classi-
fiers’ thresholds when any mistake is observed in
the training process. If the corrective step c is set
too large, it might cause the algorithm to be too
</bodyText>
<page confidence="0.99153">
410
</page>
<figure confidence="0.999168">
O−Loss
S−Loss
H−Loss
50 100 150 200 250 300
Dimensionality of Index Term Space
(a) O-Loss
Dimensionality of Index Term Space
(b) S-Loss
1.045
1.04
1.035
1.03
1.025
1.02
1.015
1.01
50 100 150 200 250 300
Dimensionality of Index Term Space
(c) H-Loss
0.846
0.845
0.844
0.843
0.842
0.841
0.84
2.35
2.34
2.33
2.32
2.31
2.3
2.29
2.28
2.27
2.26
50 100 150 200 250 300
</figure>
<figureCaption confidence="0.999989">
Figure 3: Impact of Dimensionality d of Index Term Space (c = 0.005)
</figureCaption>
<bodyText confidence="0.999961954545455">
sensitive to each observed mistake. On the con-
trary, if the corrective step is set too small, it might
cause the algorithm not sensitive enough to the ob-
served mistakes. Hence, the corrective step c is
a factor that might impact the performance of the
proposed approach. Fig. 2 demonstrates the im-
pact of c on O-Loss, S-Loss, and H-Loss. The
dimensionality of index term space d is set to be
110 and 220. The value of c is set to vary from
0.001 to 0.1 with each step of 0.001. Fig. 2 shows
that the parameter c impacts the classification per-
formance significantly. As the value of c increase,
the O-Loss, S-Loss, and H-Loss generally increase
(performance decrease). In Fig. 2c it is obviously
detected that the H-Loss decreases a little (perfor-
mance increase) at first before it increases (perfor-
mance decrease) with further increase of the value
of c. This indicates that a finer-grained value of c
will not necessarily result in a better performance
on the H-loss. However, a fine-grained corrective
step generally makes a better performance than a
coarse-grained corrective step.
</bodyText>
<subsectionHeader confidence="0.995177">
4.5 Impact of Dimensionality d of Index
Term Space
</subsectionHeader>
<bodyText confidence="0.999994066666667">
In the proposed HL-SOT approach, the dimen-
sionality d of the index term space controls the
number of terms to be indexed. If d is set
too small, important useful terms will be missed
that will limit the performance of the approach.
However, if d is set too large, the computing ef-
ficiency will be decreased. Fig. 3 shows the im-
pacts of the parameter d respectively on O-Loss,
S-Loss, and H-Loss, where d varies from 50 to 300
with each step of 10 and the c is set to be 0.005.
From Fig. 3, we observe that as the d increases the
O-Loss, S-Loss, and H-Loss generally decrease
(performance increase). This means that when
more terms are indexed better performance can
be achieved by the HL-SOT approach. However,
</bodyText>
<figure confidence="0.9928413">
x 106
12
10
8
6
4
2
0
50 100 150 200 250 300
Dimensionality of Index Term Space
</figure>
<figureCaption confidence="0.999962">
Figure 4: Time Consuming Impacted by d
</figureCaption>
<bodyText confidence="0.999930285714286">
considering the computing efficiency impacted by
d, Fig. 4 shows that the computational complex-
ity of our approach is non-linear increased with
d’s growing, which indicates that indexing more
terms will improve the accuracy of our proposed
approach although this is paid by decreasing the
computing efficiency.
</bodyText>
<sectionHeader confidence="0.9890435" genericHeader="method">
5 Conclusions, Discussions and Future
Work
</sectionHeader>
<bodyText confidence="0.998484">
In this paper, we propose a novel and effec-
tive approach to sentiment analysis on product re-
views. In our proposed HL-SOT approach, we de-
fine SOT to formulate the knowledge of hierarchi-
cal relationships among a product’s attributes and
tackle the problem of sentiment analysis in a hier-
archical classification process with the proposed
algorithm. The empirical analysis on a human-
labeled data set demonstrates the promising re-
sults of our proposed approach. The performance
comparison shows that the proposed HL-SOT ap-
proach outperforms two baselines: the HL-flat and
the H-RLS approach. This confirms two intuitive
motivations based on which our approach is pro-
posed: 1) separately learning threshold values for
</bodyText>
<figure confidence="0.550954">
Time Consuming (ms)
</figure>
<page confidence="0.991165">
411
</page>
<bodyText confidence="0.99998435">
each classifier improve the classification accuracy;
2) knowledge of hierarchical relationships of la-
bels improve the approach’s performance. The ex-
periments on analyzing the impact of parameter
ϵ indicate that a fine-grained corrective step gen-
erally makes a better performance than a coarse-
grained corrective step. The experiments on an-
alyzing the impact of the dimensionality d show
that indexing more terms will improve the accu-
racy of our proposed approach while the comput-
ing efficiency will be greatly decreased.
The focus of this paper is on analyzing review
texts of one product. However, the framework of
our proposed approach can be generalized to deal
with a mix of review texts of more than one prod-
ucts. In this generalization for sentiment analysis
on multiple products reviews, a “big” SOT is con-
structed and the SOT for each product reviews is
a sub-tree of the “big” SOT. The sentiment analy-
sis on multiple products reviews can be performed
the same way the HL-SOT approach is applied on
single product reviews and can be tackled in a hier-
archical classification process with the “big” SOT.
This paper is motivated by the fact that the
relationships among a product’s attributes could
be a useful knowledge for mining product review
texts. The SOT is defined to formulate this knowl-
edge in the proposed approach. However, what
attributes to be included in a product’s SOT and
how to structure these attributes in the SOT is an
effort of human beings. The sizes and structures
of SOTs constructed by different individuals may
vary. How the classification performance will be
affected by variances of the generated SOTs is
worthy of study. In addition, an automatic method
to learn a product’s attributes and the structure
of SOT from existing product review texts will
greatly benefit the efficiency of the proposed ap-
proach. We plan to investigate on these issues in
our future work.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996542">
The authors would like to thank the anonymous
reviewers for many helpful comments on the
manuscript. This work is funded by the Research
Council of Norway under the VERDIKT research
programme (Project No.: 183337).
</bodyText>
<sectionHeader confidence="0.999577" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999660709090909">
Alina Andreevskaia and Sabine Bergler. 2006. Min-
ing wordnet for a fuzzy sentiment: Sentiment tag
extraction from wordnet glosses. In Proceedings of
11th Conference of the European Chapter of the As-
sociation for Computational Linguistics (EACL’06),
Trento, Italy.
Nicol`o Cesa-Bianchi, Claudio Gentile, and Luca Zani-
boni. 2006. Incremental algorithms for hierarchi-
cal classification. Journal of Machine Learning Re-
search (JMLR), 7:31–54.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: opinion extraction
and semantic classification of product reviews. In
Proceedings of 12nd International World Wide Web
Conference (WWW’03), Budapest, Hungary.
Ann Devitt and Khurshid Ahmad. 2007. Sentiment
polarity identification in financial news: A cohesion-
based approach. In Proceedings of 45th Annual
Meeting of the Association for Computational Lin-
guistics (ACL’07), Prague, Czech Republic.
Xiaowen Ding and Bing Liu. 2007. The utility of
linguistic rules in opinion mining. In Proceedings
of 30th Annual International ACM Special Inter-
est Group on Information Retrieval Conference (SI-
GIR’07), Amsterdam, The Netherlands.
Andrea Esuli and Fabrizio Sebastiani. 2005. Deter-
mining the semantic orientation of terms through
gloss classification. In Proceedings of 14th ACM
Conference on Information and Knowledge Man-
agement (CIKM’05), Bremen, Germany.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In Proceedings of 5th International
Conference on Language Resources and Evaluation
(LREC’06), Genoa, Italy.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of ad-
jectives. In Proceedings of 35th Annual Meeting
of the Association for Computational Linguistics
(ACL’97), Madrid, Spain.
Vasileios Hatzivassiloglou and Janyce M. Wiebe.
2000. Effects of adjective orientation and grad-
ability on sentence subjectivity. In Proceedings
of 18th International Conference on Computational
Linguistics (COLING’00), Saarbr¨uken, Germany.
Minqing Hu and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of 10th
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD’04), Seattle, USA.
Jaap Kamps, Maarten Marx, R. ort. Mokken, and
Maarten de Rijke. 2004. Using WordNet to mea-
sure semantic orientation of adjectives. In Proceed-
ings of 4th International Conference on Language
Resources and Evaluation (LREC’04), Lisbon, Por-
tugal.
</reference>
<page confidence="0.979949">
412
</page>
<reference confidence="0.999687133333334">
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In Proceedings of 14th Inter-
national World Wide Web Conference (WWW’05),
Chiba, Japan.
Yang Liu, Xiangji Huang, Aijun An, and Xiaohui Yu.
2007. ARSA: a sentiment-aware model for predict-
ing sales performance using blogs. In Proceedings
of the 30th Annual International ACM Special Inter-
est Group on Information Retrieval Conference (SI-
GIR’07), Amsterdam, The Netherlands.
Yue Lu and Chengxiang Zhai. 2008. Opinion inte-
gration through semi-supervised topic modeling. In
Proceedings of 17th International World Wide Web
Conference (WWW’08), Beijing, China.
Yue Lu, ChengXiang Zhai, and Neel Sundaresan.
2009. Rated aspect summarization of short com-
ments. In Proceedings of 18th International World
Wide Web Conference (WWW’09), Madrid, Spain.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of Human Language Technology Con-
ference and Empirical Methods in Natural Lan-
guage Processing Conference (HLT/EMNLP’05),
Vancouver, Canada.
Ivan Titov and Ryan T. McDonald. 2008. Modeling
online reviews with multi-grain topic models. In
Proceedings of 17th International World Wide Web
Conference (WWW’08), Beijing, China.
Peter D. Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of 40th Annual
Meeting of the Association for Computational Lin-
guistics (ACL’02), Philadelphia, USA.
Casey Whitelaw, Navendu Garg, and Shlomo Arga-
mon. 2005. Using appraisal taxonomies for senti-
ment analysis. In Proceedings of 14th ACM Confer-
ence on Information and Knowledge Management
(CIKM’05), Bremen, Germany.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of Hu-
man Language Technology Conference and Empir-
ical Methods in Natural Language Processing Con-
ference (HLT/EMNLP’05), Vancouver, Canada.
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating facts
from opinions and identifying the polarity of opin-
ion sentences. In Proceedings of 8th Conference on
Empirical Methods in Natural Language Processing
(EMNLP’03), Sapporo, Japan.
Lina Zhou and Pimwadee Chaovalit. 2008. Ontology-
supported polarity mining. Journal of the American
Society for Information Science and Technology (JA-
SIST), 59(1):98–110.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006.
Movie review mining and summarization. In Pro-
ceedings of the 15th ACM International Confer-
ence on Information and knowledge management
(CIKM’06), Arlington, USA.
</reference>
<page confidence="0.998986">
413
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910527">
<title confidence="0.999444">Sentiment Learning on Product Reviews via Sentiment Ontology Tree</title>
<author confidence="0.999987">Wei Wei</author>
<affiliation confidence="0.99866275">Department of Computer and Information Science Norwegian University of Science and Technology</affiliation>
<email confidence="0.964127">wwei@idi.ntnu.no</email>
<abstract confidence="0.997789652173913">Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product’s attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HL- SOT approach is easily generalized to labeling a mix of reviews of more than one products.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining wordnet for a fuzzy sentiment: Sentiment tag extraction from wordnet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06),</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="10023" citStr="Andreevskaia and Bergler, 2006" startWordPosition="1656" endWordPosition="1660">u, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentim</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006. Mining wordnet for a fuzzy sentiment: Sentiment tag extraction from wordnet glosses. In Proceedings of 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicol`o Cesa-Bianchi</author>
<author>Claudio Gentile</author>
<author>Luca Zaniboni</author>
</authors>
<title>Incremental algorithms for hierarchical classification.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research (JMLR),</journal>
<pages>7--31</pages>
<contexts>
<context position="7072" citStr="Cesa-Bianchi et al., 2006" startWordPosition="1171" endWordPosition="1174">mera itself. Each of the non-leaf nodes (white nodes) of the SOT represents an attribute of a camerae. All leaf nodes (gray nodes) of the SOT represent sentiment (positive/negative) nodes respectively associated with their parent nodes. A formal definition on SOT is presented in Section 3.1. With the proposed concept of SOT, we manage to formulate the two tasks of the sentiment analysis to be a hierarchical classification problem. We further propose a specific hierarchical learning algorithm, called HL-SOT algorithm, which is developed based on generalizing an online-learning algorithm H-RLS (Cesa-Bianchi et al., 2006). The HL-SOT algorithm has the same property as the H-RLS algorithm that allows multiple-path labeling (input target text can be labeled with nodes belonging to more than one path in the SOT) and partial-path labeling (the input target text can be labeled with nodes belonging to a path that does not end on a leaf). This property makes the approach well suited for the situation where complicated sentiments on different attributes are expressed in one target text. Unlike the H-RLS algorithm , the HL-SOT algorithm enables each classifier to separately learn its own specific threshold. The propose</context>
<context position="17483" citStr="Cesa-Bianchi et al., 2006" startWordPosition="2948" endWordPosition="2951"> node is labeled with the target text. For example, in Fig. 1 a review is to be labeled with “image quality +” requires that the review should be successively labeled as related to “camera” and “image quality”. This is reasonable and consistent with intuition, because if a review cannot be identified to be related to a camera, it is not safe to infer that the review is commenting a camera’s image quality with positive sentiment. { 0, if x is not labeled by the classifier of nod yz = e i. 1, if x is labeled by the classifier of node i, 407 3.2.2 HL-SOT Algorithm The algorithm H-RLS studied in (Cesa-Bianchi et al., 2006) solved a similar hierarchical classification problem as we formulated above. However, the H-RLS algorithm was designed as an onlinelearning algorithm which is not suitable to be applied directly in our problem setting. Moreover, the algorithm H-RLS defined the same value as the threshold of each node classifier. We argue that if the threshold values could be learned separately for each classifiers, the performance of classification process would be improved. Therefore we propose a specific hierarchical learning algorithm, named HL-SOT algorithm, that is able to train each node classifier in a</context>
<context position="27391" citStr="Cesa-Bianchi et al., 2006" startWordPosition="4718" endWordPosition="4721">inning of this section, we compare our HLSOT approach with the following two baseline approaches: • HL-flat: The HL-flat approach involves an algorithm that is a “flat” version of HL-SOT algorithm by ignoring the hierarchical relationships among labels when each classifier is trained. In the training process of HL-flat, the algorithm reflexes the restriction in the HL-SOT algorithm that requires the weight vector wi,t of the classifier i is only updated on the examples that are positive for its parent node. • H-RLS: The H-RLS approach is implemented by applying the H-RLS algorithm studied in (Cesa-Bianchi et al., 2006). Unlike our proposed HL-SOT algorithm that enables the threshold values to be learned separately for each classifiers in the training process, the H-RLS algorithm only uses an identical threshold values for each classifiers in the classification process. Experiments are conducted on the performance comparison between the proposed HL-SOT approach with HL-flat approach and the H-RLS approach. The dimensionality d of the index term space is set to be 110 and 220. The corrective step c is set to be 0.005. The experimental results are summarized in Table 1. From Table 1, we can observe that the HL</context>
</contexts>
<marker>Cesa-Bianchi, Gentile, Zaniboni, 2006</marker>
<rawString>Nicol`o Cesa-Bianchi, Claudio Gentile, and Luca Zaniboni. 2006. Incremental algorithms for hierarchical classification. Journal of Machine Learning Research (JMLR), 7:31–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>In Proceedings of 12nd International World Wide Web Conference (WWW’03),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2199" citStr="Dave et al., 2003" startWordPosition="343" endWordPosition="346"> this problem, research works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a di</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: opinion extraction and semantic classification of product reviews. In Proceedings of 12nd International World Wide Web Conference (WWW’03), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Devitt</author>
<author>Khurshid Ahmad</author>
</authors>
<title>Sentiment polarity identification in financial news: A cohesionbased approach.</title>
<date>2007</date>
<booktitle>In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics (ACL’07),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="10159" citStr="Devitt and Ahmad, 2007" startWordPosition="1679" endWordPosition="1682">ment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommende</context>
</contexts>
<marker>Devitt, Ahmad, 2007</marker>
<rawString>Ann Devitt and Khurshid Ahmad. 2007. Sentiment polarity identification in financial news: A cohesionbased approach. In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics (ACL’07), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
</authors>
<title>The utility of linguistic rules in opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of 30th Annual International ACM Special Interest Group on Information Retrieval Conference (SIGIR’07),</booktitle>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="9447" citStr="Ding and Liu, 2007" startWordPosition="1568" endWordPosition="1571">cal analysis and the results are presented in Section 4, followed by the conclusions, discussions, and future work in Section 5. 2 Related Work The task of sentiment analysis on product reviews was originally performed to extract overall sentiment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not necessarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, </context>
</contexts>
<marker>Ding, Liu, 2007</marker>
<rawString>Xiaowen Ding and Bing Liu. 2007. The utility of linguistic rules in opinion mining. In Proceedings of 30th Annual International ACM Special Interest Group on Information Retrieval Conference (SIGIR’07), Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Determining the semantic orientation of terms through gloss classification.</title>
<date>2005</date>
<booktitle>In Proceedings of 14th ACM Conference on Information and Knowledge Management (CIKM’05),</booktitle>
<location>Bremen, Germany.</location>
<contexts>
<context position="10051" citStr="Esuli and Sebastiani, 2005" startWordPosition="1661" endWordPosition="1665">05; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney,</context>
</contexts>
<marker>Esuli, Sebastiani, 2005</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2005. Determining the semantic orientation of terms through gloss classification. In Proceedings of 14th ACM Conference on Information and Knowledge Management (CIKM’05), Bremen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of 5th International Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="10079" citStr="Esuli and Sebastiani, 2006" startWordPosition="1666" endWordPosition="1669">et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised lear</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of 5th International Conference on Language Resources and Evaluation (LREC’06), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of 35th Annual Meeting of the Association for Computational Linguistics (ACL’97),</booktitle>
<location>Madrid,</location>
<contexts>
<context position="10115" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="1670" endWordPosition="1674">all sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to class</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of 35th Annual Meeting of the Association for Computational Linguistics (ACL’97), Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Janyce M Wiebe</author>
</authors>
<title>Effects of adjective orientation and gradability on sentence subjectivity.</title>
<date>2000</date>
<booktitle>In Proceedings of 18th International Conference on Computational Linguistics (COLING’00),</booktitle>
<location>Saarbr¨uken, Germany.</location>
<contexts>
<context position="9991" citStr="Hatzivassiloglou and Wiebe, 2000" startWordPosition="1652" endWordPosition="1655">d on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polar</context>
</contexts>
<marker>Hatzivassiloglou, Wiebe, 2000</marker>
<rawString>Vasileios Hatzivassiloglou and Janyce M. Wiebe. 2000. Effects of adjective orientation and gradability on sentence subjectivity. In Proceedings of 18th International Conference on Computational Linguistics (COLING’00), Saarbr¨uken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of 10th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD’04),</booktitle>
<location>Seattle, USA.</location>
<contexts>
<context position="1636" citStr="Hu and Liu, 2004" startWordPosition="256" endWordPosition="259">s of more than one products. 1 Introduction As the internet reaches almost every corner of this world, more and more people write reviews and share opinions on the World Wide Web. The usergenerated opinion-rich reviews will not only help other users make better judgements but they are also useful resources for manufacturers of products to keep track and manage customer opinions. However, as the number of product reviews grows, it becomes difficult for a user to manually learn the panorama of an interesting topic from existing online information. Faced with this problem, research works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005;</context>
<context position="9400" citStr="Hu and Liu, 2004" startWordPosition="1560" endWordPosition="1563">ment analysis with HLSOT approach. The empirical analysis and the results are presented in Section 4, followed by the conclusions, discussions, and future work in Section 5. 2 Related Work The task of sentiment analysis on product reviews was originally performed to extract overall sentiment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not necessarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreev</context>
<context position="11212" citStr="Hu and Liu, 2004" startWordPosition="1847" endWordPosition="1850">for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommended by averaging sentiment annotation of phrases in reviews that contain adjectives or adverbs. However, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product could be so complicated that it is unable to be expressed by overall document sentiment. Attributes-based sentiment analysis is to analyze sentiment based on each attribute of a product. In (Hu and Liu, 2004), mining product features was proposed together with sentiment polarity annotation for each opinion sentence. In that work, sentiment analysis was performed on product attributes level. In (Liu et al., 2005), a system with framework for analyzing and comparing consumer opinions of competing products was proposed. The system made users be able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also rank</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of 10th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD’04), Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mokken</author>
<author>Maarten de Rijke</author>
</authors>
<title>Using WordNet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of 4th International Conference on Language Resources and Evaluation (LREC’04),</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Mokken, de Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, R. ort. Mokken, and Maarten de Rijke. 2004. Using WordNet to measure semantic orientation of adjectives. In Proceedings of 4th International Conference on Language Resources and Evaluation (LREC’04), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>In Proceedings of 14th International World Wide Web Conference (WWW’05),</booktitle>
<location>Chiba, Japan.</location>
<contexts>
<context position="1654" citStr="Liu et al., 2005" startWordPosition="260" endWordPosition="263"> products. 1 Introduction As the internet reaches almost every corner of this world, more and more people write reviews and share opinions on the World Wide Web. The usergenerated opinion-rich reviews will not only help other users make better judgements but they are also useful resources for manufacturers of products to keep track and manage customer opinions. However, as the number of product reviews grows, it becomes difficult for a user to manually learn the panorama of an interesting topic from existing online information. Faced with this problem, research works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzio</context>
<context position="9466" citStr="Liu et al., 2005" startWordPosition="1572" endWordPosition="1575"> results are presented in Section 4, followed by the conclusions, discussions, and future work in Section 5. 2 Related Work The task of sentiment analysis on product reviews was originally performed to extract overall sentiment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not necessarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Seb</context>
<context position="11419" citStr="Liu et al., 2005" startWordPosition="1880" endWordPosition="1883">ses in reviews that contain adjectives or adverbs. However, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product could be so complicated that it is unable to be expressed by overall document sentiment. Attributes-based sentiment analysis is to analyze sentiment based on each attribute of a product. In (Hu and Liu, 2004), mining product features was proposed together with sentiment polarity annotation for each opinion sentence. In that work, sentiment analysis was performed on product attributes level. In (Liu et al., 2005), a system with framework for analyzing and comparing consumer opinions of competing products was proposed. The system made users be able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. Thes</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In Proceedings of 14th International World Wide Web Conference (WWW’05), Chiba, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Xiangji Huang</author>
<author>Aijun An</author>
<author>Xiaohui Yu</author>
</authors>
<title>ARSA: a sentiment-aware model for predicting sales performance using blogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th Annual International ACM Special Interest Group on Information Retrieval Conference (SIGIR’07),</booktitle>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="11870" citStr="Liu et al., 2007" startWordPosition="1955" endWordPosition="1958">gether with sentiment polarity annotation for each opinion sentence. In that work, sentiment analysis was performed on product attributes level. In (Liu et al., 2005), a system with framework for analyzing and comparing consumer opinions of competing products was proposed. The system made users be able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion integration based on the topic of a product’s attributes. The work in (Titov and McDonald, 2008) presented a multi-grain topic model for extracting the ratable attributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a go</context>
</contexts>
<marker>Liu, Huang, An, Yu, 2007</marker>
<rawString>Yang Liu, Xiangji Huang, Aijun An, and Xiaohui Yu. 2007. ARSA: a sentiment-aware model for predicting sales performance using blogs. In Proceedings of the 30th Annual International ACM Special Interest Group on Information Retrieval Conference (SIGIR’07), Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<booktitle>In Proceedings of 17th International World Wide Web Conference (WWW’08),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="2302" citStr="Lu and Zhai, 2008" startWordPosition="363" endWordPosition="366">t analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. However, a sentence like “40D handles no</context>
<context position="12110" citStr="Lu and Zhai, 2008" startWordPosition="1995" endWordPosition="1998">f competing products was proposed. The system made users be able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion integration based on the topic of a product’s attributes. The work in (Titov and McDonald, 2008) presented a multi-grain topic model for extracting the ratable attributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a goal of generating ratings for major aspects so that a user could gain different perspectives towards a target entity. All these research works concentrated on attribute-based sentiment analysis. However, the main difference with our work is </context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Yue Lu and Chengxiang Zhai. 2008. Opinion integration through semi-supervised topic modeling. In Proceedings of 17th International World Wide Web Conference (WWW’08), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
<author>Neel Sundaresan</author>
</authors>
<title>Rated aspect summarization of short comments.</title>
<date>2009</date>
<booktitle>In Proceedings of 18th International World Wide Web Conference (WWW’09),</booktitle>
<location>Madrid,</location>
<contexts>
<context position="1672" citStr="Lu et al., 2009" startWordPosition="264" endWordPosition="267">duction As the internet reaches almost every corner of this world, more and more people write reviews and share opinions on the World Wide Web. The usergenerated opinion-rich reviews will not only help other users make better judgements but they are also useful resources for manufacturers of products to keep track and manage customer opinions. However, as the number of product reviews grows, it becomes difficult for a user to manually learn the panorama of an interesting topic from existing online information. Faced with this problem, research works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang e</context>
<context position="12407" citStr="Lu et al., 2009" startWordPosition="2045" endWordPosition="2048">eatures but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion integration based on the topic of a product’s attributes. The work in (Titov and McDonald, 2008) presented a multi-grain topic model for extracting the ratable attributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a goal of generating ratings for major aspects so that a user could gain different perspectives towards a target entity. All these research works concentrated on attribute-based sentiment analysis. However, the main difference with our work is that they did not sufficiently utilize the hierarchical relationships among a product attributes. Although a method of ontologysupported polarity mining, which also involved 406 ontology to tackle the sentiment analysis problem, was proposed in (Zhou and Chaovalit, 2008), that work studied polari</context>
</contexts>
<marker>Lu, Zhai, Sundaresan, 2009</marker>
<rawString>Yue Lu, ChengXiang Zhai, and Neel Sundaresan. 2009. Rated aspect summarization of short comments. In Proceedings of 18th International World Wide Web Conference (WWW’09), Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Empirical Methods in Natural Language Processing Conference (HLT/EMNLP’05),</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2262" citStr="Popescu and Etzioni, 2005" startWordPosition="355" endWordPosition="358"> Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. </context>
<context position="9427" citStr="Popescu and Etzioni, 2005" startWordPosition="1564" endWordPosition="1567"> HLSOT approach. The empirical analysis and the results are presented in Section 4, followed by the conclusions, discussions, and future work in Section 5. 2 Related Work The task of sentiment analysis on product reviews was originally performed to extract overall sentiment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not necessarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Es</context>
<context position="11711" citStr="Popescu and Etzioni, 2005" startWordPosition="1930" endWordPosition="1933">timent. Attributes-based sentiment analysis is to analyze sentiment based on each attribute of a product. In (Hu and Liu, 2004), mining product features was proposed together with sentiment polarity annotation for each opinion sentence. In that work, sentiment analysis was performed on product attributes level. In (Liu et al., 2005), a system with framework for analyzing and comparing consumer opinions of competing products was proposed. The system made users be able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion integration based on the topic of a product’s attributes. The work in (Titov and McDonald, 2008) presented a multi-gr</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of Human Language Technology Conference and Empirical Methods in Natural Language Processing Conference (HLT/EMNLP’05), Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan T McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of 17th International World Wide Web Conference (WWW’08),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="2328" citStr="Titov and McDonald, 2008" startWordPosition="367" endWordPosition="370">ct reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. However, a sentence like “40D handles noise very well up to ISO 80</context>
<context position="12290" citStr="Titov and McDonald, 2008" startWordPosition="2026" endWordPosition="2029">oduct features. In (Popescu and Etzioni, 2005), Popescu and Etzioni not only analyzed polarity of opinions regarding product features but also ranked opinions based on their strength. In (Liu et al., 2007), Liu et al. proposed Sentiment-PLSA that analyzed blog entries and viewed them as a document generated by a number of hidden sentiment factors. These sentiment factors may also be factors based on product attributes. In (Lu and Zhai, 2008), Lu et al. proposed a semi-supervised topic models to solve the problem of opinion integration based on the topic of a product’s attributes. The work in (Titov and McDonald, 2008) presented a multi-grain topic model for extracting the ratable attributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a goal of generating ratings for major aspects so that a user could gain different perspectives towards a target entity. All these research works concentrated on attribute-based sentiment analysis. However, the main difference with our work is that they did not sufficiently utilize the hierarchical relationships among a product attributes. Although a method of ontologysupported polarity mining, which also involved 406 on</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan T. McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of 17th International World Wide Web Conference (WWW’08), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL’02),</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="2180" citStr="Turney, 2002" startWordPosition="341" endWordPosition="342">on. Faced with this problem, research works, e.g., (Hu and Liu, 2004; Liu et al., 2005; Lu et al., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. Fo</context>
<context position="9126" citStr="Turney, 2002" startWordPosition="1516" endWordPosition="1517"> different products, whereas existing works mainly focus on analyzing reviews of only one type of product. The remainder of the paper is organized as follows. In Section 2, we provide an overview of related work on sentiment analysis. Section 3 presents our work on sentiment analysis with HLSOT approach. The empirical analysis and the results are presented in Section 4, followed by the conclusions, discussions, and future work in Section 5. 2 Related Work The task of sentiment analysis on product reviews was originally performed to extract overall sentiment from the target texts. However, in (Turney, 2002), as the difficulty shown in the experiments, the whole sentiment of a document is not necessarily the sum of its parts. Then there came up with research works shifting focus from overall document sentiment to sentiment analysis based on product attributes (Hu and Liu, 2004; Popescu and Etzioni, 2005; Ding and Liu, 2007; Liu et al., 2005). Document overall sentiment analysis is to summarize the overall sentiment in the document. Research works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level se</context>
<context position="10657" citStr="Turney, 2002" startWordPosition="1758" endWordPosition="1759">i, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommended by averaging sentiment annotation of phrases in reviews that contain adjectives or adverbs. However, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product could be so complicated that it is unable to be expressed by overall document sentiment. Attributes-based sentiment analysis is to analyze sentiment based on each attribute of a product. In (Hu and Liu, 2004), mining product features was proposed togeth</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL’02), Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Using appraisal taxonomies for sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of 14th ACM Conference on Information and Knowledge Management (CIKM’05),</booktitle>
<location>Bremen, Germany.</location>
<contexts>
<context position="10404" citStr="Whitelaw et al., 2005" startWordPosition="1716" endWordPosition="1719">s to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommended by averaging sentiment annotation of phrases in reviews that contain adjectives or adverbs. However, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product </context>
</contexts>
<marker>Whitelaw, Garg, Argamon, 2005</marker>
<rawString>Casey Whitelaw, Navendu Garg, and Shlomo Argamon. 2005. Using appraisal taxonomies for sentiment analysis. In Proceedings of 14th ACM Conference on Information and Knowledge Management (CIKM’05), Bremen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Empirical Methods in Natural Language Processing Conference (HLT/EMNLP’05),</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="10430" citStr="Wilson et al., 2005" startWordPosition="1721" endWordPosition="1724">notation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommended by averaging sentiment annotation of phrases in reviews that contain adjectives or adverbs. However, the performances of these works are not good enough for sentiment analysis on product reviews, where sentiment on each attribute of a product could be so complicated th</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of Human Language Technology Conference and Empirical Methods in Natural Language Processing Conference (HLT/EMNLP’05), Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of 8th Conference on Empirical Methods in Natural Language Processing (EMNLP’03),</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="10191" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="1683" endWordPosition="1687">search works related to document overall sentiment analysis mainly rely on two finer levels sentiment annotation: word-level sentiment annotation and phrase-level sentiment annotation. The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text (Hatzivassiloglou and Wiebe, 2000; Andreevskaia and Bergler, 2006; Esuli and Sebastiani, 2005; Esuli and Sebastiani, 2006; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Devitt and Ahmad, 2007; Yu and Hatzivassiloglou, 2003). The phrase-level sentiment annotation focuses sentiment annotation on phrases not words with concerning that atomic units of expression is not individual words but rather appraisal groups (Whitelaw et al., 2005). In (Wilson et al., 2005), the concepts of prior polarity and contextual polarity were proposed. This paper presented a system that is able to automatically identify the contextual polarity for a large subset of sentiment expressions. In (Turney, 2002), an unsupervised learning algorithm was proposed to classify reviews as recommended or not recommended by averaging sentiment annotat</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of 8th Conference on Empirical Methods in Natural Language Processing (EMNLP’03), Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lina Zhou</author>
<author>Pimwadee Chaovalit</author>
</authors>
<title>Ontologysupported polarity mining.</title>
<date>2008</date>
<journal>Journal of the American Society for Information Science and Technology (JASIST),</journal>
<volume>59</volume>
<issue>1</issue>
<contexts>
<context position="2354" citStr="Zhou and Chaovalit, 2008" startWordPosition="371" endWordPosition="374">nd have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. However, a sentence like “40D handles noise very well up to ISO 800”, also refers to image q</context>
<context position="12981" citStr="Zhou and Chaovalit, 2008" startWordPosition="2134" endWordPosition="2137">tributes from product reviews. In (Lu et al., 2009), the problem of rated attributes summary was studied with a goal of generating ratings for major aspects so that a user could gain different perspectives towards a target entity. All these research works concentrated on attribute-based sentiment analysis. However, the main difference with our work is that they did not sufficiently utilize the hierarchical relationships among a product attributes. Although a method of ontologysupported polarity mining, which also involved 406 ontology to tackle the sentiment analysis problem, was proposed in (Zhou and Chaovalit, 2008), that work studied polarity mining by machine learning techniques that still suffered from a problem of ignoring dependencies among attributes within an ontology’s hierarchy. In the contrast, our work solves the sentiment analysis problem as a hierarchical classification problem that fully utilizes the hierarchy of the SOT during training and classification process. 3 The HL-SOT Approach In this section, we first propose a formal definition on SOT. Then we formulate the HL-SOT approach. In this novel approach, tasks of sentiment analysis are to be achieved in a hierarchical classification pro</context>
</contexts>
<marker>Zhou, Chaovalit, 2008</marker>
<rawString>Lina Zhou and Pimwadee Chaovalit. 2008. Ontologysupported polarity mining. Journal of the American Society for Information Science and Technology (JASIST), 59(1):98–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM International Conference on Information and knowledge management (CIKM’06),</booktitle>
<location>Arlington, USA.</location>
<contexts>
<context position="2283" citStr="Zhuang et al., 2006" startWordPosition="359" endWordPosition="362">., 2009), of sentiment analysis on product reviews were proposed and have become a popular research topic at the crossroads of information retrieval and computational linguistics. Jon Atle Gulla Department of Computer and Information Science Norwegian University of Science and Technology jag@idi.ntnu.no Carrying out sentiment analysis on product reviews is not a trivial task. Although there have already been a lot of publications investigating on similar issues, among which the representatives are (Turney, 2002; Dave et al., 2003; Hu and Liu, 2004; Liu et al., 2005; Popescu and Etzioni, 2005; Zhuang et al., 2006; Lu and Zhai, 2008; Titov and McDonald, 2008; Zhou and Chaovalit, 2008; Lu et al., 2009), there is still room for improvement on tackling this problem. When we look into the details of each example of product reviews, we find that there are some intrinsic properties that existing previous works have not addressed in much detail. First of all, product reviews constitute domainspecific knowledge. The product’s attributes mentioned in reviews might have some relationships between each other. For example, for a digital camera, comments on image quality are usually mentioned. However, a sentence l</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of the 15th ACM International Conference on Information and knowledge management (CIKM’06), Arlington, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>