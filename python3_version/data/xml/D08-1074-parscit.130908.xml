<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005136">
<title confidence="0.867057">
Automatic inference of the temporal location of situations in Chinese text
</title>
<author confidence="0.994034">
Nianwen Xue
</author>
<affiliation confidence="0.890512666666667">
Center for Computational Language and Education Research
University of Colorado at Boulder
Colorado, U.S.A.
</affiliation>
<email confidence="0.995236">
Nianwen.Xue@colorado.edu
</email>
<sectionHeader confidence="0.996612" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99979325">
Chinese is a language that does not have mor-
phological tense markers that provide explicit
grammaticalization of the temporal location of
situations (events or states). However, in many
NLP applications such as Machine Transla-
tion, Information Extraction and Question An-
swering, it is desirable to make the temporal
location of the situations explicit. We describe
a machine learning framework where differ-
ent sources of information can be combined to
predict the temporal location of situations in
Chinese text. Our experiments show that this
approach significantly outperforms the most
frequent tense baseline. More importantly,
the high training accuracy shows promise that
this challenging problem is solvable to a level
where it can be used in practical NLP applica-
tions with more training data, better modeling
techniques and more informative and general-
izable features.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999934955555556">
In a language like English, tense is an explicit (and
maybe imperfect) grammaticalization of the tempo-
ral location of situations, and such temporal location
is either directly or indirectly defined in relation to
the moment of speech. Chinese does not have gram-
maticalized tense in the sense that Chinese verbs are
not morphologically marked for tense. This is not
to say, however, that Chinese speakers do not at-
tempt to convey the temporal location of situations
when they speak or write, or that they cannot inter-
pret the temporal location when they read Chinese
text, or even that they have a different way of repre-
senting the temporal location of situations. In fact,
there is evidence that the temporal location is rep-
resented in Chinese in exactly the same way as it is
represented in English and most world languages: in
relation to the moment of speech. One piece of evi-
dence to support this claim is that Chinese temporal
expressions like 4-Jk, (“today”), RAT, (“tomorrow”)
and 0,k. (“yesterday”) all assume a temporal deixis
that is the moment of speech in relation to which
all temporal locations are defined. Such temporal
expressions, where they are present, give us a clear
indication of the temporal location of the situations
they are associated with. However, not all Chinese
sentences have such temporal expressions associated
with them. In fact, they occur only infrequently in
Chinese text. It is thus theoretically interesting to
ask, in the absence of grammatical tense and explicit
temporal expressions, how do readers of a particular
piece of text interpret the temporal location of situa-
tions?
There are a few linguistic devices in Chinese that
provide obvious clues to the temporal location of
situations, and one such linguistic device is aspect
markers. Although Chinese does not have grammat-
ical tense, it does have grammaticalized aspect in the
form of aspect markers. These aspect markers often
give some indication of the temporal location of an
event. For example, Chinese has the perfective as-
pect marker Tand it,, and they are often associated
with the past. Progressive aspect marker *, on the
other hand, is often associated with the present. In
addition to aspect, certain adverbs also provide clues
to the temporal location of the situations they are as-
</bodyText>
<page confidence="0.949067">
707
</page>
<note confidence="0.962144">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 707–714,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.996422311688312">
sociated with. For example, z or z�1 (”already”),
often indicates that the situation they are associated
with has already occurred and is thus in the past. /L,
another adverbial modifier, often indicates that the
situation it modifies is in the present. However, such
linguistic associations are imperfect, and they can
only be viewed as tendencies rather than rules that
one can use to deterministically infer the temporal
location of a situation. For example, while z in-
deed indicates that the situation described in (1) is
in the past, when it modifies a stative verb as it does
in (1b), the situation is still in the present.
(1) a. 4t� [z] T_ iA J&amp;quot;Aq
he already finish this project
.
”He already finished the project.”
”China already has the foundation to pro-
duce world-class software.”
More importantly, only a small proportion of verb
instances in any given text have such explicit tempo-
ral indicators and therefore they cannot be the whole
story in the temporal interpretation of Chinese text.
It is thus theoretically interesting to go beyond the
obvious and investigate what additional information
is relevant in determining the temporal location of a
situation in Chinese.
Being able to infer the temporal location of a situ-
ation has many practical applications as well. For
example, this information would be highly valu-
able to Machine Translation. To translate a lan-
guage like Chinese into a language like English in
which tense is grammatically marked with inflec-
tional morphemes, an MT system will have to in-
fer the necessary temporal information to determine
the correct tense for verbs. Statistical MT systems,
the currently dominant research paradigm, typically
do not address this issue directly. As a result, when
evaluated for tense, current MT systems often per-
form miserably. For example, when a simple sen-
tence like “&apos;(s/he 2 T,/tomorrow :i_9 W/return _L
*/Shanghai” is given to Google’s state-of-the-art
Machine Translation system1, it produces the out-
put “He returned to Shanghai tomorrow”, instead of
the correct “he will return to Shanghai tomorrow”.
The past tense on the verb “returned” contradicts
the temporal expression “tomorrow”. Determining
the temporal location is also important for an Infor-
mation Extraction task that extracts events so that
the extracted events are put in a temporal context.
Similarly, for Question Answering tasks, it is also
important to know whether a situation has already
happened or it is going to happen, for example.
In this paper, we are interested in investigating
the kind of information that is relevant in inferring
the temporal location of situations in Chinese text.
We approach this problem by manually annotating
each verb in a Chinese document with a “tense” tag
that indicates the temporal location of the verb2. We
then formulate the tense determination problem as
a classification task where standard machine learn-
ing techniques can be applied. Figuring out what
linguistic information contributes to the determina-
tion of the temporal location of a situation becomes
a feature engineering problem of selecting features
that help with the automatic classification. In Sec-
tion 2, we present a linguistic annotation framework
that annotates the temporal location of situations in
Chinese text. In Section 3 we describe our setup
for an automatic tense classification experiment and
present our experimental results. In Section 4 we
focus in on the features we have used in our exper-
iment and attempt to provide a quantitative as well
as intuitive explanation of the contribution of the in-
dividual features and speculate on what additional
features could be useful. In Section 5 we discuss
related work and Section 6 concludes the paper and
discusses future work.
</bodyText>
<sectionHeader confidence="0.966191" genericHeader="method">
2 Annotation framework
</sectionHeader>
<bodyText confidence="0.9999628">
It is impossible to define the temporal loca-
tion without a reference point, a temporal deixis.
As we have shown in Section 1, there is con-
vincing evidence from the temporal adverbials
like 0 T,(“yesterday”), 8 T,(“today”) and 2 T,
</bodyText>
<footnote confidence="0.995061">
1http://www.google.com/language tools
2For simplicity, we use the term “tense” exchangeably with
the temporal location of an event or situation, even though tense
usually means grammatical tense while temporal location is a
more abstract semantic notion.
</footnote>
<figure confidence="0.9992548">
b. +q
China
[z]
already
-1
produce
���
world-class
41#]*j
has
W#_
software
0 AJ�
DE foundation
.
</figure>
<page confidence="0.993886">
708
</page>
<bodyText confidence="0.999974106666667">
(“tomorrow”) that Chinese, like most if not all lan-
guages of the world, use the moment of speech as
this reference point. In written text, which is the pri-
mary source of data that we are dealing with, the
temporal deixis is the document creation time. All
situations are temporally related to this document
creation time except in direct quotations, where the
temporal location is relative to the moment of speech
of the speaker who is quoted.
In addition to the moment of speech or document
creation time in the case of written text, Reference
Time and Situation Time are generally accepted as
important to determining the temporal location since
Reichenbach (1947) first proposed them. Situation
Time is the time that a situation actually occurs
while Reference time is the temporal perspective
from which the speaker invites his audience to con-
sider the situation. Reference Time does not nec-
essarily overlap with Situation Time, as in the case
of present perfective tense, where the situation hap-
pened in the past but the reader is invited to look at
it from the present moment and focus on the state of
completion of the situation. Reference Time is in our
judgment too subtle to be annotated consistently and
thus in our annotation scheme we only consider the
relation between Situation Time and the document
creation time when defining the temporal location
of situations. Another key decision we made when
formulating our annotation scheme is to define an
abstract “tense” that do not necessarily model the ac-
tual tense system in any particular language that has
grammatical tense. In a given language, the gram-
matical tense reflected in the morphological system
may not have a one-to-one mapping between the
grammatical tense and the temporal location of a sit-
uation. For example, in an English sentence like “He
will call me after he gets here”, while his “getting
here” happens at a time in the future, it is assigned
the present tense because it is in a clause introduced
by “after”. It makes more sense to ask the annota-
tor, who is necessarily a native speaker of Chinese,
to make a judgment of the temporal location of the
situation defined in terms of the relation between the
Situation Time and the moment of speech rather than
by such language-specific idiosyncracies of another
language.
Temporal locations that can be defined in terms of
the relation between Situation Time and the moment
of speech are considered to be absolute tense. In
some cases, the temporal location of a situation can-
not be directly defined in relation to the moment of
speech. For example in (2), the temporal location of
k¿ (“intend”) cannot be determined independently
of that of ß3(“reveal”). The temporal location of
k¿ is simultaneous with ß3. If the temporal
location of ß3 is in the past, then the temporal
location of k¿ is also in the past. If the temporal
location of ß3 is in the future, then the temporal
location of k¿ is also in the future. In this spe-
cific case, the situation denoted by the matrix verb
ß3 is in the past. Therefore the situation denoted
by k¿ is also located in the past.
“He also revealed that Russia intended to pro-
vide weapons to Iran within the next ten years.”
Therefore in our Chinese “tense” annotation task,
we annotate both absolute and relative tenses. We
define three absolute tenses based on whether the sit-
uation time is anterior to (in the past), simultaneous
with (in the present), or posterior to (in the future)
document creation time. In addition to the absolute
tenses, we also define one relative tense, future-in-
past, which happens when a future situation is em-
bedded in a past context. We do not assign a tense
tag to modal verbs or verb particles. The set of tense
tags are described in more detail below:
</bodyText>
<subsectionHeader confidence="0.998463">
2.1 Present tense
</subsectionHeader>
<bodyText confidence="0.9087954">
A situation is assigned the present tense if it is true at
an interval of time that includes the present moment.
The present tense is compatible with states and ac-
tivities. When non-stative situations are temporally
located in the present, they either have an imperfec-
tive aspect or have a habitual or frequentive reading
which makes them look like states, e.g.,
f,31h
outdoors
“He often attends outdoors activities.”
</bodyText>
<figure confidence="0.99115884375">
(2) �
he
ß3
reveal
AÛ9
Russia
k¿
intend
3 in next
f�
ten years
�
also
P)
within
, ž04
to Iran
J*
provide
AS .
weapons .
,
►►677
��
often
(3) �
he
Ahu
attend
Til
activities
.
</figure>
<page confidence="0.959805">
709
</page>
<subsectionHeader confidence="0.995162">
2.2 Past tense
</subsectionHeader>
<bodyText confidence="0.999831333333333">
Situations that happen before the moment of speech
(or the document creation time) are temporally lo-
cated in the past as in (4):
</bodyText>
<figure confidence="0.944359055555556">
(6) &apos;,`R7
company
�l
version
�n it
personnel reveal
JQ-9 �
face the world .
FF4
soon
5N-5T_,2 6 5A it
“ Star 2 ” trial
(4) +Ti ,&apos;,--n 9 *A “The company personnel revealed that ‘Star 2’
Chinese personnel and Chinese nationals trial version would soon face the world.”
�c~ *l &apos;IF4 � 2.5 No tense label
safely withdraw from Chad .
“Chinese personnel and Chinese nationals
safely withdrew from Chad.”
</figure>
<subsectionHeader confidence="0.992229">
2.3 Future tense
</subsectionHeader>
<bodyText confidence="0.987489533333333">
Situations that happen posterior to the moment of
speech are temporally located in the future. Future
situations are not simply the opposite of past situa-
tions. While past situations have already happened
by definition, future situations by nature are charac-
terized by uncertainty. That is, future situations may
or may not happen. Therefore, future situations are
often linked to possibilities, not just to situations that
will definitely happen. A example of future tense is
given in (5):
(5) k all 3 hT,�k #TT �
conference next year in Singapore
hold .
“The conference will be held in Singapore next
year.”
</bodyText>
<subsectionHeader confidence="0.990013">
2.4 Future-in-past
</subsectionHeader>
<bodyText confidence="0.999946897959184">
The temporal interpretation of one situation is often
bound by the temporal location of another situation.
One common scenario in which this kind of depen-
dency occurs is when the target situation, the situa-
tion we are interested in at the moment, is embedded
in a reference situation as its complement. Just as the
absolute “tense” represents a temporal relation be-
tween the situation time and the moment of speech
or document creation time, the relative “tense” rep-
resents a relation between the temporal location of a
situation and its reference situation. Although theo-
retically the target situation can be anterior to, simul-
taneous with, or posterior to the reference situation,
we only have a special tense label when the target
situation is posterior to the reference situation and
the reference situation is located in the past. In this
case the label for the target situation is future-in-past
as illusrated in (6):
Modals and verb particles do not receive a tense la-
bel:
“Kosovo independence may cause riot. UN
personnel have already prepared to leave.”
The “situations” that we are interested in are ex-
pressed as clauses centered around a verb, and for
the sake of convenience we mark the “tense” on
the verb itself instead of the entire clause. How-
ever, when inferring the temporal location of a sit-
uation, we have to take into consideration the en-
tire clause, because the arguments and modifiers of
a verb are just as important as the verb itself when
determining the temporal location of the situation.
The annotation is performed on data selected from
the Chinese Treebank (Xue et al., 2005), and more
detailed descriptions and justifications for the anno-
tation scheme is described in (Xue et al., 2008). Data
selection is important for tense annotation because,
unlike POS-tagging and syntactic annotation, which
applies equally well to different genres of text, tem-
poral annotation in more relevant in some genres
than others. The data selection task is made eas-
ier by the fact that the Chinese Treebank is already
annotated with POS tags and Penn Treebank-style
syntactic structures. Therefore we were able to just
select articles based on how many constituents in the
article are annotated with the temporal function tag
-TMP. We have annotated 42 articles in total, and
all verbs in an article are assigned one of the five
tags described above: present, past, future, future-
in-past, and none.
</bodyText>
<figure confidence="0.998890818181818">
(7) &apos;t`f *
Kosovo
4A3L
independence
Jk,^CJ
UN
,&apos;,--n
personnel
C
already
��
prepare
*l �
withdraw .
�
41It
cause
4
riot
.
7Al
may
</figure>
<page confidence="0.983293">
710
</page>
<sectionHeader confidence="0.995997" genericHeader="method">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.99999001754386">
The tense determination task is then a simple five-
way classification task. Theoretically any standard
machine learning algorithm can be applied to the
task. For our purposes we used the Maximum En-
tropy algorithm implemented as part of the Mallet
machine learning package (McCallum, 2002) for its
competitive training time and performance tradeoff.
There might be algorithms that could achieve higher
classification accuracy, but our goal in this paper is
not to pursue the absolute high performance. Rather,
our purpose is to investigate what information when
used as features is relevant to determining the tem-
poral location of a situation in Chinese, so that these
features can be used to design high performance
practical systems in the future.
The annotation of 42 articles yielded 5709 verb
instances, each of which is annotated with one of
the five tense tags. For our automatic classification
experiments, we randomly divided the data into a
training set and a test set based on a 3-to-1 ratio, so
that the training data has 4,250 instances while the
test set has 1459 instances. As expected, the past
tense is the most frequent tense in both the training
and test data, although they vary quite a bit in the
proportions of verbs that are labeled with the past
tense. In the training data, 2145, or 50.5% of the
verb instances are labeled with the past tense while
in the test data, 911 or 62.4% of the verb instances
are labeled with the past tense. The 62.4% can thus
be used as a baseline when evaluating the automatic
classification accuracy. This is a very high baseline
given that the much smaller proportion of verbs that
are assigned the past tense in the training data.
Instead of raw text, the input to the classifica-
tion algorithm is parsed sentences from the Chinese
Treebank that has the syntactic structure information
as well as the part-of-speech tags. As we will show
in the next section, information extracted from the
parse tree as well as the part-of-speech tags prove to
be very important in determining the temporal loca-
tion of a situation. The reason for using “correct”
parse trees in the Chinese Treebank is to factor out
noises that are inevitable in the output of an auto-
matic parser and evaluate the contribution of syntac-
tic information in the “ideal” scenario. In a realistic
setting, one of course has to use an automatic parser.
The results are presented in Table 1. The overall
accuracy is 67.1%, exceeding the baseline of choos-
ing the most frequent tense in the test, which is
62.4%. It is worth noting that the training accu-
racy is fairly high, 93%, and there is a steep drop-off
from the training accuracy to the test accuracy al-
though this is hardly unexpected given the relatively
small training set. The high training accuracy never-
theless attests the relevance of the features we have
chosen for the classification, which we will look at
in greater detail in the next section.
</bodyText>
<table confidence="0.930114571428571">
tense precision recall f-score
present 0.51 0.62 0.56
past 0.75 0.81 0.78
future 0.33 0.45 0.38
future-in-past 0.76 0.18 0.30
none 0.86 0.83 0.84
overall 0.93 (train), 0.671 (test)
</table>
<tableCaption confidence="0.999227">
Table 1: Experimental results
</tableCaption>
<sectionHeader confidence="0.71238" genericHeader="method">
4 What information is useful?
</sectionHeader>
<bodyText confidence="0.986884583333334">
Our classification algorithm scans the verbs in a sen-
tence one at a time, from left to right. Features
are extracted from the context of the verb in the
parse tree as well as from previous verbs the tense
of which have already been examined. We view fea-
tures for the classification algorithm as information
that contributes to the determination of the temporal
location of situations in the absence of morpholog-
ical markers of tense. The features we used for the
classification task can all be extracted from a parse
tree and the POS information of a word. They are
described below:
</bodyText>
<listItem confidence="0.9433386">
• Verb Itself: The character string of the verbs,
e.g., 4M*(“own”), i_(“be”), etc.
• Verb POS: The part-of-speech tag of the verb,
as defined in the Chinese Treebank. There are
three POS tags for verbs, VE for existential
verbs such as *(“have, exist”), VC for cop-
ula verbs like i_(“be”), VA for stative verbs like
A(“tall”), and VV for all other verbs.
• Position of verb in compound: If the target
verb is part of a verb compound, the position
</listItem>
<page confidence="0.995949">
711
</page>
<bodyText confidence="0.918065333333333">
of the compound is used as a feature in com-
bination with the compound type. The possi-
ble values for the position are first and last, and
the compound type is one of the six defined in
the Chinese Treebank: VSB, VCD, VRD, VCP,
VNV, and VPT. An example feature might be
“last+VRD”.
• Governing verb and its tense: Chinese is an
SVO language, and the governing verb, if there
is one, is on the left and is higher up in the tree.
Since we are scanning verbs in a sentence from
left to right, the tense for the governing verb is
available at the time we look at the target verb.
So we are using the character string of the gov-
erning verb as well as its tense as features. In
cases where there are multiple levels of embed-
ding and multiple governing verbs, we select
the closest governing verb.
</bodyText>
<listItem confidence="0.982507">
• Left ADV: Adverbial modifiers of the target
verb are generally on the left side of the verb,
therefore we are only extracting adverbs on the
left. We first locate the adverbial phrases and
then find the head of the adverbial phrase and
use character string of the head as feature.
• Left NT: NT is a POS in the Chinese Treebank
for nominal expressions that are used as tem-
poral modifiers of a verb. The procedure for
extracting the NT modifers is similar to the pro-
cedure for finding adverbial modifiers, the only
difference being that we are looking for NPs
headed by nouns POS-tagged NT.
• Left PP: Like adverbial modifiers, PP modifiers
are also generally left modifiers of a verb. If
there is a PP modifier, the character string of
the head preposition combined with the char-
acter string of the head noun of its NP com-
plement is used as a feature, e.g., “ _+Aip7”
(“at+period”).
• Left LC: Left localizer phrases. Localizers
</listItem>
<bodyText confidence="0.5806786">
phrases are also called post-positions by some
and they function similarly as left PP modifiers.
If the target verb has a left localizer phrase
modifier and the character string of its head is
used as a feature, e.g., VA+-(“since”).
</bodyText>
<listItem confidence="0.942585315789474">
• Left NN: This feature is intended to capture the
head of the subject NP. The character string of
the head of the NP is used as a feature.
• Aspect marker. Aspect markers are grammati-
calizations of aspect and they immediately fol-
low the verb. If the target verb is associated
with an aspect marker, the character string of
that aspect marker is used as a feature, e.g.,
“T”.
• DER: DER is the POS tag for T-*, a charac-
ter which introduces a resultative construction
when following a verb. When it occurs together
with the target verb, it is used as a feature.
• Quantifier in object: When there is a quantifier
in the NP object for the target verb, its character
string is used as a feature.
• Quotation marks: Finally the quotation marks
are used as a feature when they are used to
quote the clause that contains the target verb.
</listItem>
<bodyText confidence="0.999858423076923">
We performed an ablation evaluation of the fea-
tures to see how effective each feature type is. Ba-
sically, we took out each feature type, retrained the
classifier and reran the classifier on the test data. The
accuracy without each of the feature types are pre-
sented in Table 2. The features are ranked from the
most effective to the least effective. Features that
lead to the most drop-off when they are taken out of
the classification algorithm are considered to be the
most effective. As shown in Table 2, the most ef-
fective features are the governing verb and its tense,
while the least effective features are the quantifiers
in the object. Most of the features are lexicalized
in that the character strings of words are used as
features. When lexicalized features are used, fea-
tures that appear in the training data do not neces-
sarily appear in the test data and vice versa. This
provides a partial explanation of the large discrep-
ancy between the training and test accuracy. In or-
der to reduce this discrepancy, one would have to
use a larger training set, or make the features more
generalized. Some of these features can in fact be
generalized or normalized. For example, a temporal
modifier such as the date “1987” can be reduced to
something like “before the document creation time”,
and this is something that we will experiment with in
</bodyText>
<page confidence="0.989743">
712
</page>
<bodyText confidence="0.9995825">
our future work. The training set used here is suffi-
cient to show the efficacy of the features, but to im-
prove the tense classification to a satisfactory level
of accuracy, more training data need to be annotated.
</bodyText>
<table confidence="0.999429933333333">
Feature accuracy (w/o)
Governing verb/tense 0.620
verb itself 0.635
Verb POS 0.656
Position verb in compound 0.656
left ADV 0.657
left NT 0.657
Quotation mark 0.657
left PP 0.663
left LC 0.664
Right DER 0.665
Aspect marker 0.665
left NN 0.665
Quantifier in object 0.669
overall 0.671 (test)
</table>
<tableCaption confidence="0.995414">
Table 2: Feature Performance
</tableCaption>
<bodyText confidence="0.99997256">
Features like adverbial, prepositional, localizer
phrase modifiers and temporal noun modifiers pro-
vide explicit temporal information that is relevant in
determining the temporal location. The role of the
governing verb in determining the temporal location
of a situation is also easy to understand. As we have
shown in Section 2, when the target verb occurs in an
embedded clause, its temporal location is necessar-
ily affected by the temporal location of the govern-
ing verb of this embedded clause because the tempo-
ral location of the former is often defined in relation
to that of the latter. Not surprisingly, the governing
verb proves to be the most effective feature. Quota-
tion marks in written text change the temporal deixis
from the document creation time to the moment of
speech of the quoted speaker, and the temporal lo-
cation in quoted speech does not follow the same
patterns as target verbs in embedded clauses. As-
pect markers are tied closely to tense, even though
the contributions they made are small due to their
rare occurrences in text.
The relevance of other features are less obvious.
The target verb itself and its POS made the most
contribution other than the governing verb. It is im-
portant to understand why they are effective or use-
ful at all. In a theoretic work on the temporal inter-
pretation of verbs in languages like Chinese which
lacks tense morphology, Smith and Erbaugh (2005)
pointed out that there is a default interpretation for
bounded and unbounded situations. Specifically,
bounded situations are temporally located in the past
by default while unbounded situations are located
in the future. The default interpretation, by defini-
tion, can be overwritten when there is explicit evi-
dence to the contrary. Recast in statistical terms, this
means that bounded events have a tendency to be lo-
cated in the past while unbounded events have a ten-
dency to be located in the present, and this tendency
can be quantified in a machine-learning framework.
Boundedness has many surface manifestations that
can be directly observed, and one of them is whether
the verb is stative or dynamic. The target verb it-
self and its POS tag represents this information. Re-
sultatives in the form of resultative verb compound
and the DER construction, quantifiers in the object
are other surface reflections of the abstract notion
of boundedness. The fact that these features have
contributed to the determination of the temporal lo-
cation of situations to certain extent lends support to
Smith’s theoretical claim.
</bodyText>
<sectionHeader confidence="0.99996" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.99977985">
Inferring the temporal location is a difficult problem
that is not yet very well understood. It has not been
studied extensively in the context of Natural Lan-
guage Processing. Olson et al (2000; 2001) realized
the importance of using the aspectual information
(both grammatical and lexical aspect) to infer tense
in the context of a Chinese-English Machine Trans-
lation system. They encoded the aspectual informa-
tion such as telicity as part of the Lexical Conceptual
Structure and use it to heuristically infer tense when
generating the English output. This rule-based ap-
proach is not very suited for modeling the tempo-
ral location information in Chinese. As they them-
selves noted, aspectual information can only be used
as a tendency rather than a deterministic rule. We
believe this problem can be better modeled in a ma-
chine learning framework where different sources of
information, each one being imperfect, can be com-
bined based on their effectiveness to provide a more
reasonable overall prediction.
</bodyText>
<page confidence="0.994498">
713
</page>
<bodyText confidence="0.999936428571428">
Ye (2007) did approach this problem with ma-
chine learning techniques. She used Chinese-
English parallel data to manually map the tense in-
formation from English to Chinese and trained a
Conditional Random Field classifier to make predic-
tions about tense. She used only a limited number of
surface cues such as temporal adverbials and aspect
markers as features and did not attempt to model
the lexical aspect information such as boundedness,
which we believe would have helped her system per-
formance. Her data appeared to have a much larger
percentage of verb instances that have the past tense
and thus her results are mostly incomparable with
that of ours.
</bodyText>
<sectionHeader confidence="0.992487" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999961411764706">
We have defined the automatic inference of the tem-
poral location of situations in Chinese text as a ma-
chine learning problem and demonstrated that a lot
more information in the form of features contributes
to the solution of this challenging problem than pre-
viously realized. The accuracy on the held-out test
is a significant improvement over the baseline, the
proportion of verbs assigned the most frequent tense
(the past tense). Although there is a large drop-off
from the training accuracy to the test accuracy due
to the lexical nature of the features, the high training
accuracy does show promise that this challenging
problem is solvable with a larger training set, bet-
ter modeling techniques and more refined features.
In the future we will attempt to solve this problem
along these lines and work toward a system that can
be used in practical applications.
</bodyText>
<sectionHeader confidence="0.998237" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99990175">
We would like to thank Hua Zhong and Kaiyun Chen
for their efforts to annotate the data used in our ex-
periments. Without their help this work would of
course be impossible.
</bodyText>
<sectionHeader confidence="0.999232" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99965796969697">
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
Mari Olson, David Traum, Carol Vaness Dykema, Amy
Weinberg, and Ron Dolan. 2000. Telicity as a cue to
temporal and discourse structure in Chinese-English
Machine Translation. In Proceedings of NAACL-
ANLP 2000 Workshop on Applied interlinguas: prac-
tical applications of interlingual approaches to NLP,
pages 34–41, Seattle Washington.
Mari Olson, David Traum, Carol Vaness Dykema, and
Amy Weinberg. 2001. Implicit cues for explicit gen-
eration: using telicity as a cue for tense structure in
a Chinese to English MT system. In Proceedings of
Machine Translation Summit VIII, Santiago de Com-
postela, Spain.
Hans Reichenbach. 1947. Elements of Symbolic Logic.
The MacMillan Company, New York.
Carlota S. Smith and Mary Erbaugh. 2005. Tempo-
ral interpretation in Mandarin Chinese. Linguistics,
43(4):713–756.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural Lan-
guage Engineering, 11(2):207–238.
Nianwen Xue, Zhong Hua, and Kai-Yun Chen. 2008.
Annotating “tense” in a tenseless language. In Pro-
ceedings of the Fifth International Conference on Lan-
guage Resources and Evaluation, Marrakech, Mo-
rocco.
Yang Ye. 2007. Automatica Tense and Aspect Transla-
tion between Chinese and English. Ph.D. thesis, Uni-
versity of Michigan.
</reference>
<page confidence="0.998181">
714
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.773578">
<title confidence="0.992668">Automatic inference of the temporal location of situations in Chinese text</title>
<author confidence="0.893611">Nianwen</author>
<affiliation confidence="0.970506">Center for Computational Language and Education University of Colorado at Colorado,</affiliation>
<email confidence="0.99621">Nianwen.Xue@colorado.edu</email>
<abstract confidence="0.997710047619048">Chinese is a language that does not have morphological tense markers that provide explicit grammaticalization of the temporal location of situations (events or states). However, in many NLP applications such as Machine Translation, Information Extraction and Question Answering, it is desirable to make the temporal location of the situations explicit. We describe a machine learning framework where different sources of information can be combined to predict the temporal location of situations in Chinese text. Our experiments show that this approach significantly outperforms the most frequent tense baseline. More importantly, the high training accuracy shows promise that this challenging problem is solvable to a level where it can be used in practical NLP applications with more training data, better modeling techniques and more informative and generalizable features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="16355" citStr="McCallum, 2002" startWordPosition="2696" endWordPosition="2697">MP. We have annotated 42 articles in total, and all verbs in an article are assigned one of the five tags described above: present, past, future, futurein-past, and none. (7) &apos;t`f * Kosovo 4A3L independence Jk,^CJ UN ,&apos;,--n personnel C already �� prepare *l � withdraw . � 41It cause 4 riot . 7Al may 710 3 Experimental results The tense determination task is then a simple fiveway classification task. Theoretically any standard machine learning algorithm can be applied to the task. For our purposes we used the Maximum Entropy algorithm implemented as part of the Mallet machine learning package (McCallum, 2002) for its competitive training time and performance tradeoff. There might be algorithms that could achieve higher classification accuracy, but our goal in this paper is not to pursue the absolute high performance. Rather, our purpose is to investigate what information when used as features is relevant to determining the temporal location of a situation in Chinese, so that these features can be used to design high performance practical systems in the future. The annotation of 42 articles yielded 5709 verb instances, each of which is annotated with one of the five tense tags. For our automatic cl</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari Olson</author>
<author>David Traum</author>
<author>Carol Vaness Dykema</author>
<author>Amy Weinberg</author>
<author>Ron Dolan</author>
</authors>
<title>Telicity as a cue to temporal and discourse structure in Chinese-English Machine Translation.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACLANLP 2000 Workshop on Applied interlinguas: practical applications of interlingual approaches to NLP,</booktitle>
<pages>34--41</pages>
<location>Seattle Washington.</location>
<contexts>
<context position="27672" citStr="Olson et al (2000" startWordPosition="4660" endWordPosition="4663">e target verb itself and its POS tag represents this information. Resultatives in the form of resultative verb compound and the DER construction, quantifiers in the object are other surface reflections of the abstract notion of boundedness. The fact that these features have contributed to the determination of the temporal location of situations to certain extent lends support to Smith’s theoretical claim. 5 Related work Inferring the temporal location is a difficult problem that is not yet very well understood. It has not been studied extensively in the context of Natural Language Processing. Olson et al (2000; 2001) realized the importance of using the aspectual information (both grammatical and lexical aspect) to infer tense in the context of a Chinese-English Machine Translation system. They encoded the aspectual information such as telicity as part of the Lexical Conceptual Structure and use it to heuristically infer tense when generating the English output. This rule-based approach is not very suited for modeling the temporal location information in Chinese. As they themselves noted, aspectual information can only be used as a tendency rather than a deterministic rule. We believe this problem </context>
</contexts>
<marker>Olson, Traum, Dykema, Weinberg, Dolan, 2000</marker>
<rawString>Mari Olson, David Traum, Carol Vaness Dykema, Amy Weinberg, and Ron Dolan. 2000. Telicity as a cue to temporal and discourse structure in Chinese-English Machine Translation. In Proceedings of NAACLANLP 2000 Workshop on Applied interlinguas: practical applications of interlingual approaches to NLP, pages 34–41, Seattle Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari Olson</author>
<author>David Traum</author>
<author>Carol Vaness Dykema</author>
<author>Amy Weinberg</author>
</authors>
<title>Implicit cues for explicit generation: using telicity as a cue for tense structure in a Chinese to English MT system.</title>
<date>2001</date>
<booktitle>In Proceedings of Machine Translation Summit VIII, Santiago de Compostela,</booktitle>
<marker>Olson, Traum, Dykema, Weinberg, 2001</marker>
<rawString>Mari Olson, David Traum, Carol Vaness Dykema, and Amy Weinberg. 2001. Implicit cues for explicit generation: using telicity as a cue for tense structure in a Chinese to English MT system. In Proceedings of Machine Translation Summit VIII, Santiago de Compostela, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Reichenbach</author>
</authors>
<title>Elements of Symbolic Logic.</title>
<date>1947</date>
<publisher>The MacMillan Company,</publisher>
<location>New York.</location>
<contexts>
<context position="8608" citStr="Reichenbach (1947)" startWordPosition="1370" endWordPosition="1371">languages of the world, use the moment of speech as this reference point. In written text, which is the primary source of data that we are dealing with, the temporal deixis is the document creation time. All situations are temporally related to this document creation time except in direct quotations, where the temporal location is relative to the moment of speech of the speaker who is quoted. In addition to the moment of speech or document creation time in the case of written text, Reference Time and Situation Time are generally accepted as important to determining the temporal location since Reichenbach (1947) first proposed them. Situation Time is the time that a situation actually occurs while Reference time is the temporal perspective from which the speaker invites his audience to consider the situation. Reference Time does not necessarily overlap with Situation Time, as in the case of present perfective tense, where the situation happened in the past but the reader is invited to look at it from the present moment and focus on the state of completion of the situation. Reference Time is in our judgment too subtle to be annotated consistently and thus in our annotation scheme we only consider the </context>
</contexts>
<marker>Reichenbach, 1947</marker>
<rawString>Hans Reichenbach. 1947. Elements of Symbolic Logic. The MacMillan Company, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlota S Smith</author>
<author>Mary Erbaugh</author>
</authors>
<title>Temporal interpretation in Mandarin Chinese.</title>
<date>2005</date>
<journal>Linguistics,</journal>
<volume>43</volume>
<issue>4</issue>
<contexts>
<context position="26345" citStr="Smith and Erbaugh (2005)" startWordPosition="4445" endWordPosition="4448">h of the quoted speaker, and the temporal location in quoted speech does not follow the same patterns as target verbs in embedded clauses. Aspect markers are tied closely to tense, even though the contributions they made are small due to their rare occurrences in text. The relevance of other features are less obvious. The target verb itself and its POS made the most contribution other than the governing verb. It is important to understand why they are effective or useful at all. In a theoretic work on the temporal interpretation of verbs in languages like Chinese which lacks tense morphology, Smith and Erbaugh (2005) pointed out that there is a default interpretation for bounded and unbounded situations. Specifically, bounded situations are temporally located in the past by default while unbounded situations are located in the future. The default interpretation, by definition, can be overwritten when there is explicit evidence to the contrary. Recast in statistical terms, this means that bounded events have a tendency to be located in the past while unbounded events have a tendency to be located in the present, and this tendency can be quantified in a machine-learning framework. Boundedness has many surfa</context>
</contexts>
<marker>Smith, Erbaugh, 2005</marker>
<rawString>Carlota S. Smith and Mary Erbaugh. 2005. Temporal interpretation in Mandarin Chinese. Linguistics, 43(4):713–756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="15104" citStr="Xue et al., 2005" startWordPosition="2489" endWordPosition="2492">independence may cause riot. UN personnel have already prepared to leave.” The “situations” that we are interested in are expressed as clauses centered around a verb, and for the sake of convenience we mark the “tense” on the verb itself instead of the entire clause. However, when inferring the temporal location of a situation, we have to take into consideration the entire clause, because the arguments and modifiers of a verb are just as important as the verb itself when determining the temporal location of the situation. The annotation is performed on data selected from the Chinese Treebank (Xue et al., 2005), and more detailed descriptions and justifications for the annotation scheme is described in (Xue et al., 2008). Data selection is important for tense annotation because, unlike POS-tagging and syntactic annotation, which applies equally well to different genres of text, temporal annotation in more relevant in some genres than others. The data selection task is made easier by the fact that the Chinese Treebank is already annotated with POS tags and Penn Treebank-style syntactic structures. Therefore we were able to just select articles based on how many constituents in the article are annotat</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha Palmer. 2005. The Penn Chinese TreeBank: Phrase Structure Annotation of a Large Corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Zhong Hua</author>
<author>Kai-Yun Chen</author>
</authors>
<title>Annotating “tense” in a tenseless language.</title>
<date>2008</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="15216" citStr="Xue et al., 2008" startWordPosition="2507" endWordPosition="2510">ed in are expressed as clauses centered around a verb, and for the sake of convenience we mark the “tense” on the verb itself instead of the entire clause. However, when inferring the temporal location of a situation, we have to take into consideration the entire clause, because the arguments and modifiers of a verb are just as important as the verb itself when determining the temporal location of the situation. The annotation is performed on data selected from the Chinese Treebank (Xue et al., 2005), and more detailed descriptions and justifications for the annotation scheme is described in (Xue et al., 2008). Data selection is important for tense annotation because, unlike POS-tagging and syntactic annotation, which applies equally well to different genres of text, temporal annotation in more relevant in some genres than others. The data selection task is made easier by the fact that the Chinese Treebank is already annotated with POS tags and Penn Treebank-style syntactic structures. Therefore we were able to just select articles based on how many constituents in the article are annotated with the temporal function tag -TMP. We have annotated 42 articles in total, and all verbs in an article are </context>
</contexts>
<marker>Xue, Hua, Chen, 2008</marker>
<rawString>Nianwen Xue, Zhong Hua, and Kai-Yun Chen. 2008. Annotating “tense” in a tenseless language. In Proceedings of the Fifth International Conference on Language Resources and Evaluation, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
</authors>
<title>Automatica Tense and Aspect Translation between Chinese and English.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Michigan.</institution>
<contexts>
<context position="28499" citStr="Ye (2007)" startWordPosition="4794" endWordPosition="4795">tion such as telicity as part of the Lexical Conceptual Structure and use it to heuristically infer tense when generating the English output. This rule-based approach is not very suited for modeling the temporal location information in Chinese. As they themselves noted, aspectual information can only be used as a tendency rather than a deterministic rule. We believe this problem can be better modeled in a machine learning framework where different sources of information, each one being imperfect, can be combined based on their effectiveness to provide a more reasonable overall prediction. 713 Ye (2007) did approach this problem with machine learning techniques. She used ChineseEnglish parallel data to manually map the tense information from English to Chinese and trained a Conditional Random Field classifier to make predictions about tense. She used only a limited number of surface cues such as temporal adverbials and aspect markers as features and did not attempt to model the lexical aspect information such as boundedness, which we believe would have helped her system performance. Her data appeared to have a much larger percentage of verb instances that have the past tense and thus her res</context>
</contexts>
<marker>Ye, 2007</marker>
<rawString>Yang Ye. 2007. Automatica Tense and Aspect Translation between Chinese and English. Ph.D. thesis, University of Michigan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>