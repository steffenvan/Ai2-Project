<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9882545">
Supervised and Unsupervised Methods in Employing Discourse Relations
for Improving Opinion Polarity Classification
</title>
<author confidence="0.687659">
Galileo Namata
</author>
<affiliation confidence="0.660691">
Univ. of Maryland
</affiliation>
<address confidence="0.675474">
College Park, MD 20742
</address>
<email confidence="0.989448">
namatag@cs.umd.edu
</email>
<author confidence="0.886252">
Swapna Somasundaran
</author>
<affiliation confidence="0.6755">
Univ. of Pittsburgh
Pittsburgh, PA 15260
</affiliation>
<email confidence="0.993444">
swapna@cs.pitt.edu
</email>
<author confidence="0.800775">
Janyce Wiebe
</author>
<affiliation confidence="0.6069755">
Univ. of Pittsburgh
Pittsburgh, PA 15260
</affiliation>
<email confidence="0.99228">
wiebe@cs.pitt.edu
</email>
<author confidence="0.935642">
Lise Getoor
</author>
<affiliation confidence="0.944826">
Univ. of Maryland
</affiliation>
<address confidence="0.846814">
College Park, MD 20742
</address>
<email confidence="0.998364">
getoor@cs.umd.edu
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999960153846154">
This work investigates design choices in
modeling a discourse scheme for im-
proving opinion polarity classification.
For this, two diverse global inference
paradigms are used: a supervised collec-
tive classification framework and an un-
supervised optimization framework. Both
approaches perform substantially better
than baseline approaches, establishing the
efficacy of the methods and the underlying
discourse scheme. We also present quan-
titative and qualitative analyses showing
how the improvements are achieved.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999889038461539">
The importance of discourse in opinion analy-
sis is being increasingly recognized (Polanyi and
Zaenen, 2006). Motivated by the need to en-
able discourse-based opinion analysis, previous
research (Asher et al., 2008; Somasundaran et al.,
2008) developed discourse schemes and created
manually annotated corpora. However, it was not
known whether and how well these linguistic ideas
and schemes can be translated into effective com-
putational implementations.
In this paper, we first investigate ways in which
an opinion discourse scheme can be computation-
ally modeled, and then how it can be utilized to
improve polarity classification. Specifically, the
discourse scheme we use is from Somasundaran
et al. (2008), which was developed to support a
global, interdependent polarity interpretation. To
achieve discourse-based global inference, we ex-
plore two different frameworks. The first is a
supervised framework that learns interdependent
opinion interpretations from training data. The
second is an unsupervised optimization frame-
work which uses constraints to express the ideas
of coherent opinion interpretation embodied in the
scheme. For the supervised framework, we use It-
erative Collective Classification (ICA), which fa-
cilitates machine learning using relational infor-
mation. The unsupervised optimization is imple-
mented as an Integer Linear Programming (ILP)
problem. Via our implementations, we aim to
empirically test if discourse-based approaches to
opinion analysis are useful.
Our results show that both of our implemen-
tations achieve significantly better accuracies in
polarity classification than classifiers using local
information alone. This confirms the hypothesis
that the discourse-based scheme is useful, and also
shows that both of our design choices are effective.
We also find that there is a difference in the way
ICA and ILP achieve improvements, and a simple
hybrid approach, which incorporates the strengths
of both, is able to achieve significant overall im-
provements over both. Our analyses show that
even when our discourse-based methods bootstrap
from noisy classifications, they can achieve good
improvements.
The rest of this paper is organized as follows:
we discuss related work in Section 2 and the
discourse scheme in Section 3. We present our
discourse-based implementations in Section 4, ex-
periments in Section 5, discussions in Section 6
and conclusions in Section 7.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998781454545454">
Previous work on polarity disambiguation has
used contextual clues and reversal words (Wil-
son et al., 2005; Kennedy and Inkpen, 2006;
Kanayama and Nasukawa, 2006; Devitt and Ah-
mad, 2007; Sadamitsu et al., 2008). However,
these do not capture discourse-level relations.
Researchers, such as (Polanyi and Zaenen,
2006), have discussed how the discourse struc-
ture can influence opinion interpretation; and pre-
vious work, such as (Asher et al., 2008; Soma-
sundaran et al., 2008), have developed annota-
</bodyText>
<page confidence="0.961481">
170
</page>
<note confidence="0.996595">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999948854166667">
tion schemes for interpreting opinions with dis-
course relations. However, they do not empiri-
cally demonstrate how automatic methods can use
their ideas to improve polarity classification. In
this work, we demonstrate concrete ways in which
a discourse-based scheme can be modeled using
global inference paradigms.
Joint models have been previously explored for
other NLP problems (Haghighi et al., 2005; Mos-
chitti et al., 2006; Moschitti, 2009). Our global in-
ference model focuses on opinion polarity recog-
nition task.
The biggest difference between this work and
previous work in opinion analysis that use global
inference methods is in the type of linguistic
relations used to achieve the global inference.
Some of the work is not related to discourse
at all (e.g., lexical similarities (Takamura et al.,
2007), morphosyntactic similarities (Popescu and
Etzioni, 2005) and word-based measures like TF-
IDF (Goldberg and Zhu, 2006)). Others use
sentence cohesion (Pang and Lee, 2004), agree-
ment/disagreement between speakers (Thomas et
al., 2006; Bansal et al., 2008), or structural adja-
cency. In contrast, our work focuses on discourse-
based relations for global inference. Another dif-
ference from the above work is that our work is
over multi-party conversations.
Previous work on emotion and subjectivity
detection in multi-party conversations has ex-
plored using prosodic information (Neiberg et al.,
2006), combining linguistic and acoustic infor-
mation (Raaijmakers et al., 2008) and combining
lexical and dialog information (Somasundaran et
al., 2007). Our work is focused on harnessing
discourse-based knowledge and on interdependent
inference.
There are several collective classification
frameworks, including (Neville and Jensen, 2000;
Lu and Getoor, 2003; Taskar et al., 2004; Richard-
son and Domingos, 2006; Bilgic et al., 2007). In
this paper, we use an approach by (Lu and Getoor,
2003) which iteratively predicts class values using
local and relational features. ILP has been used
on other NLP tasks, e.g., (Denis and Baldridge,
2007; Choi et al., 2006; Roth and Yih, 2004). In
this work, we employ ILP for modeling discourse
constraints for polarity classification.
</bodyText>
<sectionHeader confidence="0.827054" genericHeader="method">
3 Discourse Scheme and Data
</sectionHeader>
<bodyText confidence="0.999793542857143">
The scheme in Somasundaran et al. (2008) has
been developed and annotated over the AMI meet-
ing corpus (Carletta et al., 2005).1 This scheme
annotates opinions, their polarities (positive, neg-
ative, neutral) and their targets (a target is what
the opinion is about). The targets of opinions are
related via two types of relations: the same rela-
tion, which relates targets referring to the same
entity or proposition, and the alternative relation,
which relates targets referring to mutually exclu-
sive options in the context of the discourse. Ad-
ditionally, the scheme relates opinions via two
types of frame relations: the reinforcing and non-
reinforcing relations. The frame relations repre-
sent discourse scenarios: reinforcing relations ex-
ist between opinions when they contribute to the
same overall stance, while non-reinforcing rela-
tions exist between opinions that show ambiva-
lence.
The opinion annotations are text-span based,
while in this work, we use Dialog Act (DA) based
segmentation of meetings.2 As the DAs are our
units of classification, we map opinion annotations
to the DA units as follows. If a DA unit contains
an opinion annotation, the label is transferred up-
wards to the containing DA. When a DA contains
multiple opinion annotations, each with a differ-
ent polarity, one of them is randomly chosen as
the label for the DA. The discourse relations exist-
ing between opinions are also transferred upwards,
between the DAs containing each of these anno-
tations. We recreate an example from Somasun-
daran et al. (2008) using DA segmentation in Ex-
ample 1. Here, the speaker has a positive opinion
towards the rubbery material for the TV remote.
</bodyText>
<listItem confidence="0.95388">
(1) DA-1:... this kind of rubbery material,
DA-2: it’s a bit more bouncy,
DA-3: like you said they get chucked around a lot.
DA-4: A bit more durable and that can also be er-
gonomic and
DA-5: it kind of feels a bit different from all the
other remote controls.
</listItem>
<bodyText confidence="0.999917">
In the example, the individual opinion expressions
(shown in bold) are essentially regarding the same
thing – the rubbery material. Thus, the explicit
targets (shown in italics), it’s, that, and it, and the
implicit target of a bit more durable are all linked
</bodyText>
<footnote confidence="0.99980375">
1The AMI corpus contains a set of scenario-based meet-
ings where participants have to design a new TV remote pro-
totype.
2DA segmentation is provided with the AMI corpus.
</footnote>
<page confidence="0.995721">
171
</page>
<figureCaption confidence="0.7404495">
Figure 1: Discourse Relations between DA seg-
ments for Example 1.
</figureCaption>
<bodyText confidence="0.999583833333333">
with same target relations. Also, notice that the
opinions reinforce a particular stance, i.e., a pro-
rubbery-material stance. Thus, the scheme links
the opinions via reinforcing relations. Figure 1 il-
lustrates the corresponding discourse relations be-
tween the containing DA units.
</bodyText>
<sectionHeader confidence="0.989858" genericHeader="method">
4 Implementing the Discourse Model
</sectionHeader>
<bodyText confidence="0.9999505">
The hypothesis in using discourse information for
polarity classification is that the global discourse
view will improve upon a classification with only
a local view. Thus, we implement a local clas-
sifier to bootstrap the classification process, and
then implement classifiers that use discourse in-
formation from the scheme annotations, over it.
We explore two approaches for implementing our
discourse-based classifier. The first is ICA, where
discourse relations and the neighborhood informa-
tion brought in by these relations are incorporated
as features into the learner. The second approach
is ILP optimization, which tries to maximize the
class distributions predicted by the local classifier,
subject to constraints imposed by discourse rela-
tions. Both classifiers thus accommodate prefer-
ences of the local classifier and for coherence with
discourse neighbors.
</bodyText>
<subsectionHeader confidence="0.999085">
4.1 Local Classifier
</subsectionHeader>
<bodyText confidence="0.9968657">
A supervised local classifier, Local, is used to pro-
vide the classifications to bootstrap the discourse-
based classifiers.3 It is important to make Local as
reliable as possible; otherwise, the discourse rela-
tions will propagate misclassifications. Thus, we
build Local using a variety of knowledge sources
that have been shown to be useful for opinion anal-
ysis in previous work. Specifically, we construct
features using polarity lexicons (used by (Wilson
et al., 2005)), DA tags (used by (Somasundaran
3Local is supervised, as previous work has shown that
supervised methods are effective in opinion analysis. Even
though this makes the final end-to-end system with the ILP
implementation semi-supervised, note that the discourse-
based ILP part is itself unsupervised.
et al., 2007)) and unigrams (used by many re-
searchers, e.g., (Pang and Lee, 2004)).
Note that, as our discourse-based classifiers at-
tempt to improve upon the local classifications,
Local is also a baseline for our experiments.
</bodyText>
<subsectionHeader confidence="0.982332">
4.2 Iterative Collective Classification
</subsectionHeader>
<bodyText confidence="0.874441714285714">
We use a variant of ICA (Lu and Getoor, 2003;
Neville and Jensen, 2000), which is a collective
classification algorithm shown to perform consis-
tently well over a wide variety of relational data.
Algorithm 1 ICA Algorithm
for each instance i do {bootstrapping}
Compute polarity for i using local attributes
</bodyText>
<subsectionHeader confidence="0.386728">
end for
</subsectionHeader>
<bodyText confidence="0.8434632">
repeat {iterative}
Generate ordering I over all instances
for each i in I do
Compute polarity for i using local and re-
lational attributes
</bodyText>
<subsectionHeader confidence="0.480202">
end for
</subsectionHeader>
<bodyText confidence="0.993349035714286">
until Stopping criterion is met
ICA uses two classifiers: a local classifier and a
relational classifier. The local classifier is trained
to predict the DA labels using only the local fea-
tures. We use Local, described in Section 4.1, for
this purpose. The relational classifier is trained us-
ing the local features, and an additional set of fea-
tures commonly referred to as relational features.
The value of a relational feature, for a given DA,
depends on the polarity of the discourse neighbors
of that DA. Thus, the relational features incorpo-
rate discourse and neighbor information; that is,
they incorporate the information about the frame
and target relations in conjunction with the polar-
ity of the discourse neighbors. Intuitively, our mo-
tivation for this approach can be explained using
Example 1. Here, in interpreting the ambiguous
opinion a bit different as being positive, we use
the knowledge that it participates in a reinforc-
ing discourse, and that all its neighbors (e.g., er-
gonomic, durable) are positive opinions regard-
ing the same thing. On the other hand, if it had
been a non-reinforcing discourse, then the polar-
ity of a bit different, when viewed with respect to
the other opinions, could have been interpreted as
negative.
Table 1 lists the relational features we defined
for our experiments where each row represents a
</bodyText>
<page confidence="0.989231">
172
</page>
<bodyText confidence="0.9895891">
Percent of neighbors with polarity type a related via frame relation f&apos;
Percent of neighbors with polarity type a related via target relation t&apos;
Percent of neighbors with polarity type a related via frame relation f and target relation t
Percent of neighbors with polarity type a and same speaker related via frame relation f&apos;
Percent of neighbors with polarity type a and same speaker related via target relation t&apos;
Percent of neighbors with polarity type a related via a frame relation or target relation
Percent of neighbors with polarity type a related via a reinforcing frame relation or same target relation
Percent of neighbors with polarity type a related via a non-reinforcing frame relation or alt target relation
Most common polarity type of neighbors related via a same target relation
Most common polarity type of neighbors related via a reinforcing frame relation and same target relation
</bodyText>
<tableCaption confidence="0.631006333333333">
Table 1: Relational features: a E {non-neutral (i.e., positive or negative), positive, negative}, t E {same, alt},
f E {reinforcing, non-reinforcing}, t&apos; E {same or alt, same, alt}, f&apos; E {reinforcing or non-reinforcing, reinforcing, non-
reinforcing}
</tableCaption>
<bodyText confidence="0.996458">
set of features. Features are generated for all com-
binations of a, t, t&apos;, f and f&apos; for each row. For
example, one of the features in the first row is Per-
cent of neighbors with polarity type positive, that
are related via a reinforcing frame relation. Thus,
each feature for the relational classifier identifies
neighbors for a given instance via a specific rela-
tion (f, t, f&apos; or t&apos;, obtained from the scheme an-
notations) and factors in their polarity values (a,
obtained from the classifier predictions from the
previous round). This adds a total of 59 relational
features to the already existing local features.
ICA has two main phases: the bootstrapping
and iterative phases. In the bootstrapping phase,
the polarity of each instance is initialized to the
most likely value given only the local classifier
and its features. In the iterative phase, we cre-
ate a random ordering of all the instances and,
in turn, apply the relational classifier to each in-
stance where the relational features, for a given
instance, are computed using the most recent po-
larity assignments of its neighbors. We repeat this
until some stopping criterion is met. For our ex-
periments, we use a fixed number of 30 iterations,
which has been found to be sufficient in most data
sets for ICA to converge to a solution.
The pseudocode for the algorithm is shown in
Algorithm 1.
</bodyText>
<subsectionHeader confidence="0.995673">
4.3 Integer Linear Programming
</subsectionHeader>
<bodyText confidence="0.99996725">
First, we explain the intuition behind viewing dis-
course relations as enforcing constraints on polar-
ity interpretation. Then, we explain how the con-
straints are encoded in the optimization problem.
</bodyText>
<subsectionHeader confidence="0.592582">
4.3.1 Discourse Constraints on Polarity
</subsectionHeader>
<bodyText confidence="0.999271782608696">
The discourse relations between opinions can pro-
vide coherence constraints on the way their polar-
ity is interpreted. Consider a discourse scenario
in which a speaker expresses multiple opinions
regarding the same thing, and is reinforcing his
stance in the process (as in Example 1). The set
of individual polarity assignments that is most co-
herent with this global scenario is the one where
all the opinions have the same (equal) polarity. On
the other hand, a pair of individual polarity assign-
ments most consistent with a discourse scenario
where a speaker reinforces his stance via opinions
towards alternative options, is one with opinions
having mutually opposite polarity. For instance,
in the utterance “Shapes should be curved, noth-
ing square-like”, the speaker reinforces his pro-
curved stance via his opinions about the alternative
shapes: curved and square-like. And, we see that
the first opinion is positive and the second is neg-
ative. Table 2 lists the discourse relations (target
and frame relation combinations) found in the cor-
pus, and the likely polarity interpretation for the
related instances.
</bodyText>
<table confidence="0.9498874">
Target relation + Frame relation Polarity
same+reinforcing equal (e)
same+non-reinforcing opposite (o)
alternative+reinforcing opposite (o)
alternative+non-reinforcing equal (e)
</table>
<tableCaption confidence="0.8663265">
Table 2: Discourse relations and their polarity con-
straints on the related instances.
</tableCaption>
<subsubsectionHeader confidence="0.565353">
4.3.2 Optimization Problem
</subsubsectionHeader>
<bodyText confidence="0.999568">
For each DA instance i in a dataset, the local
classifier provides a class distribution [pi, qi, ri],
where pi, qi and ri correspond to the probabilities
that i belongs to positive, negative and neutral cat-
egories, respectively. The optimization problem is
formulated as an ILP minimization of the objec-
tive function in Equation 1.
</bodyText>
<equation confidence="0.807206">
�−1× �(pixi+qiyi+rizi)+ ��ij+ δij (1)
i i,j i,j
</equation>
<page confidence="0.982181">
173
</page>
<bodyText confidence="0.9818671875">
where the xi, yi and zi are binary class vari-
ables corresponding to positive, negative and neu-
tral classes, respectively. When a class variable
is 1, the corresponding class is chosen. Variables
Eij and δij are binary slack variables that corre-
spond to the discourse constraints between two
distinct DA instances i and j. When a given slack
variable is 1, the corresponding discourse con-
straint is violated. Note that the objective func-
tion tries to achieve two goals. The first part
(Ei pixi + qiyi + rizi) is a maximization that tries
to choose a classification for the instances that
maximizes the probabilities provided by the local
classifier. The second part (&amp;i,j Eij +&amp;i,j δij) is a
minimization that tries to minimize the number of
slack variables used, that is, minimize the number
of discourse constraints violated.
Constraints in Equations 2 and 3 listed below
impose binary constraints on the variables. The
constraint in Equation 4 ensures that, for each in-
stance i, only one class variable is set to 1.
xi ∈ {0, 1}, yi ∈ {0, 1}, zi ∈ {0, 1} , ∀i
Eij ∈ {0, 1}, δij ∈ {0, 1} , ∀i =6 j
xi + yi + zi = 1 , ∀i
We pair distinct DA instances i and j as ij,
and if there exists a discourse relation between
them, they can be subject to the corresponding po-
larity constraints listed in Table 2. For this, we
define two binary discourse-constraint constants:
the equal-polarity constant, eij and the opposite-
polarity constant, oij. If a given DA pair ij is
related by either a same+reinforcing relation or
an alternative+non-reinforcing relation (rows 1, 4
of Table 2), then eij = 1; otherwise it is zero.
Similarly, if it is related by either a same+non-
reinforcing relation or an alternative+reinforcing
relation (rows 2, 3 of Table 2), then oij = 1. Both
eij and oij are zero if the instance pair is unrelated
in the discourse.
For each DA instance pair ij, equal-polarity
constraints are applied to the polarity variables of i
(xi, yi) and j (xj, yj) via the following equations:
|xi − xj |≤ 1 − eij + Eij , ∀i =6j
|yi − yj |≤ 1 − eij + Eij , ∀i =6 j
−(xi + yi) ≤ −li , ∀i
When eij = 1, the Equation 5 constrains xi and
xj to be of the same value (both zero or both one).
Similarly, Equation 6 constrains yi and yj to be
of the same value. Via these equations, we ensure
that the instances i and j do not have the oppo-
site polarity when eij = 1. However, notice that,
if we use just Equations 5 and 6, the optimization
can converge to the same, non-polar (neutral) cat-
egory. To guide the convergence to the same polar
(positive or negative) category, we use Equation 7.
Here li = 1 if the instance i participates in one or
more discourse relations. When eij = 0, xi and xj
(and yi and yj), can take on assignments indepen-
dently of one another. Notice that both constraints
5 and 6 are relaxed when Eij = 1; thus, xi and xj
(or yi and yj) can take on values independently of
one another, even if eij = 1.
Next, the opposite-polarity constraints are ap-
plied via the following equations:
</bodyText>
<equation confidence="0.9994995">
|xi + xj − 1 |≤ 1 − oij + δij , ∀i =6 j (8)
|yi + yj − 1 |≤ 1 − oij + δij , ∀i =6j (9)
</equation>
<bodyText confidence="0.996429210526316">
In the above equations, when oij = 1, xi and xj
(and yi and yj) take on opposite values; for exam-
ple, if xi = 1 then xj = 0 and vice versa. When
oij = 0, the variable assignments are independent
of one another. This set of constraints is relaxed
when δij = 1.
In general, in our ILP formulation, notice that
if an instance does not have a discourse relation to
any other instance in the data, its classification is
unaffected by the optimization. Also, as the un-
derlying discourse scheme poses constraints only
on the interpretation of the polarity of the related
instances, discourse constraints are applied only to
the polarity variables x and y, and not to the neu-
tral class variable, z. Finally, even though slack
variables are used, we discourage the ILP system
from indiscriminately setting the slack variables to
1 by making them a part of the objective function
that is minimized.
</bodyText>
<sectionHeader confidence="0.999626" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999953636363636">
In this work, we are particularly interested in
improvements due to discourse-based methods.
Thus, we report performance under three con-
ditions: over only those instances that are re-
lated via discourse relations (Connected), over in-
stances not related via discourse relations (Single-
tons), and over all instances (All).
The annotated data consists of 7 scenario-based,
multi-party meetings from the AMI meeting cor-
pus. We filter out very small DAs (DAs with fewer
than 3 tokens, punctuation included). This gives
</bodyText>
<page confidence="0.996529">
174
</page>
<bodyText confidence="0.999629333333333">
us a total of 4606 DA instances, of which 1935
(42%) have opinion annotations. For our exper-
iments, the DAs with no opinion annotations as
well as those with neutral opinions are considered
as neutral. Table 3 shows the class distributions in
the data for the three conditions.
</bodyText>
<table confidence="0.9997605">
Pos Neg Neutral Total
Connected 643 343 81 1067
Singleton 553 233 2753 3539
All 1196 576 2834 4606
</table>
<tableCaption confidence="0.9842125">
Table 3: Class distribution over connected, single
and all instances.
</tableCaption>
<subsectionHeader confidence="0.931953">
5.1 Classifiers
</subsectionHeader>
<bodyText confidence="0.999942">
Our first baseline, Base, is a simple distribution-
based classifier that classifies the test data based
on the overall distribution of the classes in the
training data. However, in Table 3, the class distri-
bution is different for the Connected and Single-
ton conditions. We incorporate this in a smarter
baseline, Base-2, which constructs separate dis-
tributions for connected instances and singletons.
Thus, given a test instance, depending on whether
it is connected, Base-2 uses the corresponding dis-
tribution to make its prediction.
The third baseline is the supervised classifier,
Local, described in Section 4.1. It is imple-
mented using the SVM classifiers from the Weka
toolkit (Witten and Frank, 2002).4 Our super-
vised discourse-based classifier, ICA from Sec-
tion 4.2, also uses a similar SVM implemen-
tation for its relational classifier. We imple-
ment our ILP approach from Section 4.3 us-
ing the optimization toolbox from Mathworks
(http://www.mathworks.com) and GNU Linear
Programming Kit.
We observed that the ILP system performs bet-
ter than the ICA system on instances that are con-
nected, while ICA performs better on singletons.
Thus, we also implemented a simple hybrid clas-
sifier (HYB), which selects the ICA prediction for
classification of singletons and the ILP prediction
for classification of connected instances.
</bodyText>
<subsectionHeader confidence="0.688858">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999240571428571">
We performed 7-fold cross validation experi-
ments, where six meetings are used for training
4We use the SMO implementation, which, when used
with the logistic regression, has an output that can be viewed
as a posterior probability distribution.
and the seventh is used for testing the supervised
classifiers (Base, Base-2, Local and ICA). In the
case of ILP, the optimization is applied to the out-
put of Local for each test fold. Table 4 reports the
accuracies of the classifiers, averaged over 7 folds.
First, we observe that Base performs poorly
over connected instances, but performs consider-
ably better over singletons. This is expected as the
overall majority class is neutral and the singletons
are more likely to be neutral. Base-2, which incor-
porates the differentiated distributions, performs
substantially better than Base. Local achieves an
overall performance improvement over Base and
Base-2 by 23 percentage points and 9 percent-
age points, respectively. In general, Local outper-
forms Base for all three conditions (p &lt; 0.001),
and Base-2 for the Singleton and All conditions
(p &lt; 0.001). This overall improvement in Local’s
accuracy corroborates the utility of the lexical, un-
igram and DA based features for polarity detection
in this corpus.
Turning to the discourse-based classifiers, ICA,
ILP and HYB, all of these perform better than
Base and Base-2 for all conditions. ICA improves
over Local by 9 percentage points for Connected,
3 points for Singleton and 4 points for All. ILP’s
improvement over Local for Connected and All is
even more substantial: 28 percentage points and
6 points, respectively. Notice that ILP has the
same performance as Local for Singletons, as the
discourse constraints are not applied over uncon-
nected instances. Finally, HYB significantly out-
performs Local under all conditions. The signif-
icance levels of the improvements over Local are
highlighted in Table 4. These improvements also
signify that the underlying discourse scheme is
effective, and adaptable to different implementa-
tions.
Interestingly, ICA and ILP improve over Local
in different ways. While ILP sharply improves the
performance over the connected instances, ICA
shows relatively modest improvements over both
connected and singletons. ICA’s improvement
over singletons is interesting because it indicates
that, even though the features in Table 1 are fo-
cused on discourse relations, ICA utilizes them to
learn the classification of singletons too.
Comparing our discourse-based approaches,
ILP does significantly better than ICA over con-
nected instances (p &lt; 0.001), while ICA does
significantly better than ILP over singletons (p &lt;
</bodyText>
<page confidence="0.996999">
175
</page>
<table confidence="0.99729775">
Base Base-2 Local ICA ILP HYB
Connected 24.4 47.56 46.66 55.64 75.07 75.07
Singleton 51.72 63.23 75.73 78.72 75.73 78.72
All 45.34 59.46 68.72 73.31 75.35 77.72
</table>
<tableCaption confidence="0.989964">
Table 4: Accuracies of the classifiers measured over Connected, Singleton and All instances. Perfor-
</tableCaption>
<bodyText confidence="0.953278666666667">
mance significantly better than Local are indicated in bold for p &lt; 0.001 and underline for p &lt; 0.01.
0.01). However, there is no significant difference
between ICA and ILP for the All condition. The
HYB classifier outperforms ILP for the Singleton
condition (p &lt; 0.01) and ICA for the Connected
condition (p &lt; 0.001). Interestingly, over all in-
stances (the All condition), HYB also performs
significantly better than both ICA (p &lt; 0.001) and
ILP (p &lt; 0.01).
</bodyText>
<subsectionHeader confidence="0.999067">
5.3 Analysis
</subsectionHeader>
<bodyText confidence="0.999895787878788">
Amongst our two approaches, ILP performs bet-
ter, and hence we further analyze its behavior to
understand how the improvements are achieved.
Table 5 reports the performance of ILP and Local
for the precision, recall and f-measure metrics (av-
eraged over 7 test folds), measured separately for
each of the opinion categories. The most promi-
nent improvement by ILP is observed for the re-
call of the polar categories under the Connected
condition: 40 percentage points for the positive
class, and 29 percentage points for the negative
class. The gain in recall is not accompanied by
a significant loss in precision. This results in an
improvement in f-measure for the polar categories
(24 points for positive and 16 points for negative).
Also note that, by virtue of the constraint in Equa-
tion 7, ILP does not classify any connected in-
stance as neutral; thus the precision is NaN, recall
is 0 and the f-meaure is NaN. This is indicated as
* in the Table.
The improvement of ILP for the All condition,
for the polar classes, follows a similar trend for re-
call (18 to 21 point improvement) and f-measure
(9 to 13 point improvement). In addition to this,
the ILP has an overall improvement in precision
over Local. This may seem counterintuitive, as
in Table 5, ILP’s precision for connected nodes is
similar to, or lower than, that of Local. This is
explained by the fact that, while going from con-
nected to overall conditions, Local’s polar predic-
tions increase by threefold (565 to 1482), but its
correct polar predictions increase by only twofold
(430 to 801). Thus, the ratio of change in the total
</bodyText>
<table confidence="0.9996365">
Gold Local
Pos Neg Neut Total
Pos 551 113 532 1196
Neg 121 250 205 576
Neut 312 135 2387 2834
Total 984 498 3124 4606
Gold ILP
Pos Neg Neut Total
Pos 817 157 222 1196
Neg 147 358 71 576
Neut 358 147 2329 2834
Total 1322 662 2622 4606
</table>
<tableCaption confidence="0.7600005">
Table 6: Contingency table over all instances.
polar predictions to the correct polar predictions is
</tableCaption>
<bodyText confidence="0.966778">
3 : 2. On the other hand, while polar predictions
by ILP increase by only twofold (1067 to 1984),
its correct polar predictions increase by 1.5 times
(804 to 1175). Here, the ratio of change in the total
polar predictions to the correct polar predictions is
4 : 3, a smaller ratio.
The contingency table (Table 6) shows how Lo-
cal and ILP compare against the gold standard
annotations. Notice here, that even though ILP
makes more polar guesses as compared to Local, a
greater proportion of the ILP guesses are correct.
The number of non-diagonal elements are much
smaller for ILP, resulting in the accuracy improve-
ments seen in Table 4.
</bodyText>
<sectionHeader confidence="0.979601" genericHeader="method">
6 Examples and Discussion
</sectionHeader>
<bodyText confidence="0.999964071428571">
The results in Table 4 show that Local, which pro-
vides the classifications for bootstrapping ICA and
ILP, predicts an incorrect class for more than 50%
of the connected instances. Methods starting with
noisy starting points are in danger of propagating
the errors and hence worsening the performance.
Interestingly, in spite of starting with so many bad
classifications, ILP is able to achieve a large per-
formance improvement. We discovered that, given
a set of connected instances, even when Local has
only one correct guess, ILP is able to use this to
rectify the related instances. We illustrate this situ-
ation in Figure 2, which reproduces the connected
DAs for Example 1. It shows the classifications
</bodyText>
<page confidence="0.994093">
176
</page>
<table confidence="0.99986275">
Positive Negative Neutral
Local ILP Local ILP Local ILP
Connected-Prec 78.1 78.2 71.9 69.8 12.1
Connected-Recall 45.3 86.3 44.1 73.4 62.8 *
Connected-F1 56.8 81.5 54.0 70.7 18.5
All-Prec 56.2 61.3 52.3 54.6 76.3 88.3
All-Recall 46.6 67.7 44.3 62.5 83.9 81.5
All-F1 50.4 64.0 46.0 57.1 79.6 84.6
</table>
<tableCaption confidence="0.968124666666667">
Table 5: Precision, Recall, Fmeasure for each Polarity category. Performance significantly better than
Local are indicated in bold (p &lt; 0.001), underline (p &lt; 0.01) and italics (p &lt; 0.05). The * denotes that
ILP does not retrieve any connected node as neutral.
</tableCaption>
<figureCaption confidence="0.936628">
Figure 2: Discourse Relations and Classifications
for Example 1.
</figureCaption>
<bodyText confidence="0.99952255">
for each DA from the gold standard (G), the Local
classifier (L) and the ILP classifier (ILP). Observe
that Local predicts the correct positive class (+) for
only DA-4 (the DA containing bit more durable
and ergonomic). Notice that these are clear cases
of positive evaluation. It incorrectly predicts the
polarity of DA-2 (containing bit more bouncy)
as neutral (*), and DA-5 (containing a bit dif-
ferent from all the other remote controls) as
negative (-). DA-2 and DA-5 exemplify the fact
that polarity classification is a complex and diffi-
cult problem: being bouncy is a positive evalua-
tion in this particular discourse context, and may
not be so elsewhere. Thus, naturally, lexicons and
unigram-based learning would fail to capture this
positive evaluation. Similarly, “being different”
could be deemed negative in other discourse con-
texts. However, ILP is able to arrive at the correct
predictions for all the instances. As the DA-4 is
connected to both DA-2 and DA-5 via a discourse
relation that enforces an equal-polarity constraint
(same+reinforcing relation of row 1, Table 2), both
of the misclassifications are rectified. Presumably,
the incorrect predictions made by Local are low
confidence estimates, while the predictions of the
correct cases have high confidence, which makes
it possible for ILP to make the corrections.
We also observed the propagation of the correct
classification for other types of discourse relations,
for more complex types of connectivity, and also
for conditions where an instance is not directly
connected to the correctly predicted instance. The
meeting snippet below (Example 2) and its cor-
responding DA relations (Figure 3) illustrate this.
This example is a reinforcing discourse where the
speaker is arguing for the number keypad, which is
an alternative to the scrolling option. Thus, he ar-
gues against the scrolling, and argues for entering
the number (which is a capability of the number
keypad).
</bodyText>
<listItem confidence="0.447471">
(2) D-1: I reckon you’re gonna have to have a num-
</listItem>
<bodyText confidence="0.721205470588235">
ber keypad anyway for the amount of channels these
days,
D-2: You wouldn’t want to just have to scroll
through all the channels to get to the one you want
D-3: You wanna enter just the number of it , if you
know it
D-4: I reckon we’re gonna have to have a number
keypad anyway
In Figure 3, we see that, DA-2 is connected via an
alternative+reinforcing discourse relation to each
of its neighbors DA-1 and DA-3, which encour-
ages the optimization to choose a class for it that
is opposite to DA-1 and DA-3. Notice also, that
even though Local predicts only DA-4 correctly,
this correct classification finally influences the cor-
rect choice for all the instances, including the re-
motely connected DA-2.
</bodyText>
<sectionHeader confidence="0.9985" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99993775">
This work focuses on the first step to ascertain
whether discourse relations are useful for improv-
ing opinion polarity classification, whether they
can be modeled and what modeling choices can
be used. To this end, we explored two distinct
paradigms: the supervised ICA and the unsuper-
vised ILP. We showed that both of our approaches
are effective in exploiting discourse relations to
</bodyText>
<page confidence="0.994369">
177
</page>
<figureCaption confidence="0.999416">
Figure 3: Discourse Relations and Classifications for Example 2.
</figureCaption>
<bodyText confidence="0.999911">
significantly improve polarity classification. We
found that there is a difference in how ICA and
ILP achieve improvements, and that combining
the two in a hybrid approach can lead to further
overall improvement. Quantitatively, we showed
that our approach is able to achieve a large in-
crease in recall of the polar categories without
harming the precision, which results in the perfor-
mance improvements. Qualitatively, we illustrated
how, even if the bootstrapping process is noisy,
the optimization and discourse constraints effec-
tively rectify the misclassifications. The improve-
ments of our diverse global inference approaches
indicate that discourse information can be adapted
in different ways to augment and improve existing
opinion analysis techniques.
The automation of the discourse-relation recog-
nition is the next step in this research. The be-
havior of ICA and ILP can change, depending on
the automation of discourse level recognition. The
implementation and comparison of the two meth-
ods under full automation is the focus of our future
work.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997086">
This research was supported in part by the
Department of Homeland Security under grant
N000140710152 and NSF Grant No. 0746930.
We would also like to thank the anonymous re-
viewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.999646" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999826058823529">
N. Asher, F. Benamara, and Y. Mathieu. 2008. Dis-
tilling opinion in discourse: A preliminary study.
COLING-2008.
M. Bansal, C. Cardie, and L. Lee. 2008. The power of
negative thinking: Exploiting label disagreement in
the min-cut classification framework. In COLING-
2008.
M. Bilgic, G. M. Namata, and L. Getoor. 2007. Com-
bining collective classification and link prediction.
In Workshop on Mining Graphs and Complex Struc-
tures at the IEEE International Conference on Data
Mining.
J. Carletta, S. Ashby, S. Bourban, M. Flynn,
M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos,
W. Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln,
A. Lisowska, I. McCowan, W. Post, D. Reidsma, and
P. Wellner. 2005. The ami meetings corpus. In Pro-
ceedings of the Measuring Behavior Symposium on
”Annotating and measuring Meeting Behavior”.
Y. Choi, E. Breck, and C. Cardie. 2006. Joint extrac-
tion of entities and relations for opinion recognition.
In EMNLP 2006.
P. Denis and J. Baldridge. 2007. Joint determination
of anaphoricity and coreference resolution using in-
teger programming. In HLT-NAACL 2007.
A. Devitt and K. Ahmad. 2007. Sentiment polarity
identification in financial news: A cohesion-based
approach. In ACL 2007.
A. B. Goldberg and X. Zhu. 2006. Seeing stars
when there aren’t many stars: Graph-based semi-
supervised learning for sentiment categorization. In
HLT-NAACL 2006 Workshop on Textgraphs: Graph-
based Algorithms for Natural Language Processing.
A. Haghighi, K. Toutanova, and C. Manning. 2005. A
joint model for semantic role labeling. In CoNLL.
H. Kanayama and T. Nasukawa. 2006. Fully auto-
matic lexicon expansion for domain-oriented sen-
timent analysis. In EMNLP-2006, pages 355–363,
Sydney, Australia.
A. Kennedy and D. Inkpen. 2006. Sentiment classi-
fication of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110–
125.
Q. Lu and L. Getoor. 2003. Link-based classification.
In Proceedings of the International Conference on
Machine Learning (ICML).
A. Moschitti, D. Pighin, and R. Basili. 2006. Seman-
tic role labeling via tree kernel joint inference. In
CoNLL.
A. Moschitti. 2009. Syntactic and semantic kernels for
short text pair categorization. In EACL.
</reference>
<page confidence="0.980147">
178
</page>
<reference confidence="0.999840530612245">
D. Neiberg, K. Elenius, and K. Laskowski. 2006.
Emotion recognition in spontaneous speech using
gmms. In INTERSPEECH 2006 ICSLP.
J. Neville and D. Jensen. 2000. Iterative classifica-
tion in relational data. In In Proc. AAAI-2000 Work-
shop on Learning Statistical Models from Relational
Data, pages 13–20. AAAI Press.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In ACl 2004.
L. Polanyi and A. Zaenen, 2006. Contextual Valence
Shifters. Computing Attitude and Affect in Text:
Theory and Applications.
A.-M. Popescu and O. Etzioni. 2005. Extracting prod-
uct features and opinions from reviews. In HLT-
EMNLP 2005.
S. Raaijmakers, K. Truong, and T. Wilson. 2008. Mul-
timodal subjectivity analysis of multiparty conversa-
tion. In EMNLP.
M. Richardson and P. Domingos. 2006. Markov logic
networks. Mach. Learn., 62(1-2):107–136.
D. Roth and W. Yih. 2004. A linear programming
formulation for global inference in natural language
tasks. In Proceedings of CoNLL-2004, pages 1–8.
Boston, MA, USA.
K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008.
Sentiment analysis based on probabilistic models us-
ing inter-sentence information. In LREC’08.
S. Somasundaran, J. Ruppenhofer, and J. Wiebe. 2007.
Detecting arguing and sentiment in meetings. In
SIGdial Workshop on Discourse and Dialogue 2007.
S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008.
Discourse level opinion interpretation. In Coling
2008.
H. Takamura, T. Inui, and M. Okumura. 2007. Extract-
ing semantic orientations of phrases from dictionary.
In HLT-NAACL 2007.
B. Taskar, M. Wong, P. Abbeel, and D. Koller. 2004.
Link prediction in relational data. In Neural Infor-
mation Processing Systems.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the
vote: Determining support or opposition from con-
gressional floor-debate transcripts. In EMNLP 2006.
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT-EMNLP 2005.
I. H. Witten and E. Frank. 2002. Data mining: practi-
cal machine learning tools and techniques with java
implementations. SIGMOD Rec., 31(1):76–77.
</reference>
<page confidence="0.998804">
179
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.276644">
<title confidence="0.9944445">Supervised and Unsupervised Methods in Employing Discourse Relations for Improving Opinion Polarity Classification</title>
<author confidence="0.851913">Galileo Namata</author>
<affiliation confidence="0.999759">Univ. of Maryland</affiliation>
<address confidence="0.999915">College Park, MD 20742</address>
<email confidence="0.999639">namatag@cs.umd.edu</email>
<author confidence="0.786037">Swapna Somasundaran</author>
<affiliation confidence="0.999932">Univ. of Pittsburgh</affiliation>
<address confidence="0.999386">Pittsburgh, PA 15260</address>
<email confidence="0.94203">swapna@cs.pitt.edu</email>
<author confidence="0.686953">Janyce Wiebe</author>
<affiliation confidence="0.999898">Univ. of Pittsburgh</affiliation>
<address confidence="0.999204">Pittsburgh, PA 15260</address>
<email confidence="0.82921">wiebe@cs.pitt.edu</email>
<author confidence="0.798888">Lise Getoor</author>
<affiliation confidence="0.99145">Univ. of</affiliation>
<address confidence="0.981893">College Park, MD</address>
<email confidence="0.999417">getoor@cs.umd.edu</email>
<abstract confidence="0.999634071428571">This work investigates design choices in modeling a discourse scheme for improving opinion polarity classification. For this, two diverse global inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Asher</author>
<author>F Benamara</author>
<author>Y Mathieu</author>
</authors>
<title>Distilling opinion in discourse: A preliminary study.</title>
<date>2008</date>
<pages>2008</pages>
<contexts>
<context position="1163" citStr="Asher et al., 2008" startWordPosition="152" endWordPosition="155">s, two diverse global inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved. 1 Introduction The importance of discourse in opinion analysis is being increasingly recognized (Polanyi and Zaenen, 2006). Motivated by the need to enable discourse-based opinion analysis, previous research (Asher et al., 2008; Somasundaran et al., 2008) developed discourse schemes and created manually annotated corpora. However, it was not known whether and how well these linguistic ideas and schemes can be translated into effective computational implementations. In this paper, we first investigate ways in which an opinion discourse scheme can be computationally modeled, and then how it can be utilized to improve polarity classification. Specifically, the discourse scheme we use is from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse</context>
<context position="3820" citStr="Asher et al., 2008" startWordPosition="549" endWordPosition="552">e in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et </context>
</contexts>
<marker>Asher, Benamara, Mathieu, 2008</marker>
<rawString>N. Asher, F. Benamara, and Y. Mathieu. 2008. Distilling opinion in discourse: A preliminary study. COLING-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bansal</author>
<author>C Cardie</author>
<author>L Lee</author>
</authors>
<title>The power of negative thinking: Exploiting label disagreement in the min-cut classification framework.</title>
<date>2008</date>
<booktitle>In COLING2008.</booktitle>
<contexts>
<context position="5093" citStr="Bansal et al., 2008" startWordPosition="743" endWordPosition="746">Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several</context>
</contexts>
<marker>Bansal, Cardie, Lee, 2008</marker>
<rawString>M. Bansal, C. Cardie, and L. Lee. 2008. The power of negative thinking: Exploiting label disagreement in the min-cut classification framework. In COLING2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bilgic</author>
<author>G M Namata</author>
<author>L Getoor</author>
</authors>
<title>Combining collective classification and link prediction.</title>
<date>2007</date>
<booktitle>In Workshop on Mining Graphs and Complex Structures at the IEEE International Conference on Data Mining.</booktitle>
<contexts>
<context position="5862" citStr="Bilgic et al., 2007" startWordPosition="854" endWordPosition="857">that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a ta</context>
</contexts>
<marker>Bilgic, Namata, Getoor, 2007</marker>
<rawString>M. Bilgic, G. M. Namata, and L. Getoor. 2007. Combining collective classification and link prediction. In Workshop on Mining Graphs and Complex Structures at the IEEE International Conference on Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>S Ashby</author>
<author>S Bourban</author>
<author>M Flynn</author>
<author>M Guillemot</author>
<author>T Hain</author>
<author>J Kadlec</author>
<author>V Karaiskos</author>
<author>W Kraaij</author>
<author>M Kronenthal</author>
<author>G Lathoud</author>
<author>M Lincoln</author>
<author>A Lisowska</author>
<author>I McCowan</author>
<author>W Post</author>
<author>D Reidsma</author>
<author>P Wellner</author>
</authors>
<title>The ami meetings corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the Measuring Behavior Symposium on ”Annotating and measuring Meeting Behavior”.</booktitle>
<contexts>
<context position="6357" citStr="Carletta et al., 2005" startWordPosition="937" endWordPosition="940">luding (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a target is what the opinion is about). The targets of opinions are related via two types of relations: the same relation, which relates targets referring to the same entity or proposition, and the alternative relation, which relates targets referring to mutually exclusive options in the context of the discourse. Additionally, the scheme relates opinions via two types of frame relations: the reinforcing and nonreinforcing relations. The frame relations represent discourse scenarios: reinforcing</context>
</contexts>
<marker>Carletta, Ashby, Bourban, Flynn, Guillemot, Hain, Kadlec, Karaiskos, Kraaij, Kronenthal, Lathoud, Lincoln, Lisowska, McCowan, Post, Reidsma, Wellner, 2005</marker>
<rawString>J. Carletta, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, W. Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln, A. Lisowska, I. McCowan, W. Post, D. Reidsma, and P. Wellner. 2005. The ami meetings corpus. In Proceedings of the Measuring Behavior Symposium on ”Annotating and measuring Meeting Behavior”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>E Breck</author>
<author>C Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="6089" citStr="Choi et al., 2006" startWordPosition="893" endWordPosition="896">formation (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a target is what the opinion is about). The targets of opinions are related via two types of relations: the same relation, which relates targets referring to the same entity or proposition, and the alternative relation, which relat</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Y. Choi, E. Breck, and C. Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>Joint determination of anaphoricity and coreference resolution using integer programming.</title>
<date>2007</date>
<booktitle>In HLT-NAACL</booktitle>
<contexts>
<context position="6070" citStr="Denis and Baldridge, 2007" startWordPosition="889" endWordPosition="892"> linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a target is what the opinion is about). The targets of opinions are related via two types of relations: the same relation, which relates targets referring to the same entity or proposition, and the alternative re</context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>P. Denis and J. Baldridge. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. In HLT-NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Devitt</author>
<author>K Ahmad</author>
</authors>
<title>Sentiment polarity identification in financial news: A cohesion-based approach.</title>
<date>2007</date>
<booktitle>In ACL</booktitle>
<contexts>
<context position="3560" citStr="Devitt and Ahmad, 2007" startWordPosition="509" endWordPosition="513">rovements over both. Our analyses show that even when our discourse-based methods bootstrap from noisy classifications, they can achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods c</context>
</contexts>
<marker>Devitt, Ahmad, 2007</marker>
<rawString>A. Devitt and K. Ahmad. 2007. Sentiment polarity identification in financial news: A cohesion-based approach. In ACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A B Goldberg</author>
<author>X Zhu</author>
</authors>
<title>Seeing stars when there aren’t many stars: Graph-based semisupervised learning for sentiment categorization.</title>
<date>2006</date>
<booktitle>In HLT-NAACL 2006 Workshop on Textgraphs: Graphbased Algorithms for Natural Language Processing.</booktitle>
<contexts>
<context position="4957" citStr="Goldberg and Zhu, 2006" startWordPosition="723" endWordPosition="726">digms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (So</context>
</contexts>
<marker>Goldberg, Zhu, 2006</marker>
<rawString>A. B. Goldberg and X. Zhu. 2006. Seeing stars when there aren’t many stars: Graph-based semisupervised learning for sentiment categorization. In HLT-NAACL 2006 Workshop on Textgraphs: Graphbased Algorithms for Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>K Toutanova</author>
<author>C Manning</author>
</authors>
<title>A joint model for semantic role labeling.</title>
<date>2005</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="4429" citStr="Haghighi et al., 2005" startWordPosition="640" endWordPosition="643">et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagree</context>
</contexts>
<marker>Haghighi, Toutanova, Manning, 2005</marker>
<rawString>A. Haghighi, K. Toutanova, and C. Manning. 2005. A joint model for semantic role labeling. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kanayama</author>
<author>T Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domain-oriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In EMNLP-2006,</booktitle>
<pages>355--363</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3536" citStr="Kanayama and Nasukawa, 2006" startWordPosition="505" endWordPosition="508">hieve significant overall improvements over both. Our analyses show that even when our discourse-based methods bootstrap from noisy classifications, they can achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>H. Kanayama and T. Nasukawa. 2006. Fully automatic lexicon expansion for domain-oriented sentiment analysis. In EMNLP-2006, pages 355–363, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennedy</author>
<author>D Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>125</pages>
<contexts>
<context position="3507" citStr="Kennedy and Inkpen, 2006" startWordPosition="501" endWordPosition="504">ths of both, is able to achieve significant overall improvements over both. Our analyses show that even when our discourse-based methods bootstrap from noisy classifications, they can achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they d</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>A. Kennedy and D. Inkpen. 2006. Sentiment classification of movie reviews using contextual valence shifters. Computational Intelligence, 22(2):110– 125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Lu</author>
<author>L Getoor</author>
</authors>
<title>Link-based classification.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="5788" citStr="Lu and Getoor, 2003" startWordPosition="841" endWordPosition="844">elations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinio</context>
<context position="10932" citStr="Lu and Getoor, 2003" startWordPosition="1662" endWordPosition="1665">., 2005)), DA tags (used by (Somasundaran 3Local is supervised, as previous work has shown that supervised methods are effective in opinion analysis. Even though this makes the final end-to-end system with the ILP implementation semi-supervised, note that the discoursebased ILP part is itself unsupervised. et al., 2007)) and unigrams (used by many researchers, e.g., (Pang and Lee, 2004)). Note that, as our discourse-based classifiers attempt to improve upon the local classifications, Local is also a baseline for our experiments. 4.2 Iterative Collective Classification We use a variant of ICA (Lu and Getoor, 2003; Neville and Jensen, 2000), which is a collective classification algorithm shown to perform consistently well over a wide variety of relational data. Algorithm 1 ICA Algorithm for each instance i do {bootstrapping} Compute polarity for i using local attributes end for repeat {iterative} Generate ordering I over all instances for each i in I do Compute polarity for i using local and relational attributes end for until Stopping criterion is met ICA uses two classifiers: a local classifier and a relational classifier. The local classifier is trained to predict the DA labels using only the local </context>
</contexts>
<marker>Lu, Getoor, 2003</marker>
<rawString>Q. Lu and L. Getoor. 2003. Link-based classification. In Proceedings of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
<author>D Pighin</author>
<author>R Basili</author>
</authors>
<title>Semantic role labeling via tree kernel joint inference.</title>
<date>2006</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="4453" citStr="Moschitti et al., 2006" startWordPosition="644" endWordPosition="648">ran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (T</context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2006</marker>
<rawString>A. Moschitti, D. Pighin, and R. Basili. 2006. Semantic role labeling via tree kernel joint inference. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>Syntactic and semantic kernels for short text pair categorization.</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="4471" citStr="Moschitti, 2009" startWordPosition="649" endWordPosition="650">developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006</context>
</contexts>
<marker>Moschitti, 2009</marker>
<rawString>A. Moschitti. 2009. Syntactic and semantic kernels for short text pair categorization. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Neiberg</author>
<author>K Elenius</author>
<author>K Laskowski</author>
</authors>
<title>Emotion recognition in spontaneous speech using gmms.</title>
<date>2006</date>
<booktitle>In INTERSPEECH 2006 ICSLP.</booktitle>
<contexts>
<context position="5434" citStr="Neiberg et al., 2006" startWordPosition="794" endWordPosition="797">es (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tas</context>
</contexts>
<marker>Neiberg, Elenius, Laskowski, 2006</marker>
<rawString>D. Neiberg, K. Elenius, and K. Laskowski. 2006. Emotion recognition in spontaneous speech using gmms. In INTERSPEECH 2006 ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Neville</author>
<author>D Jensen</author>
</authors>
<title>Iterative classification in relational data. In</title>
<date>2000</date>
<booktitle>In Proc. AAAI-2000 Workshop on Learning Statistical Models from Relational Data,</booktitle>
<pages>13--20</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="5767" citStr="Neville and Jensen, 2000" startWordPosition="837" endWordPosition="840">ocuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This sc</context>
<context position="10959" citStr="Neville and Jensen, 2000" startWordPosition="1666" endWordPosition="1669">sed by (Somasundaran 3Local is supervised, as previous work has shown that supervised methods are effective in opinion analysis. Even though this makes the final end-to-end system with the ILP implementation semi-supervised, note that the discoursebased ILP part is itself unsupervised. et al., 2007)) and unigrams (used by many researchers, e.g., (Pang and Lee, 2004)). Note that, as our discourse-based classifiers attempt to improve upon the local classifications, Local is also a baseline for our experiments. 4.2 Iterative Collective Classification We use a variant of ICA (Lu and Getoor, 2003; Neville and Jensen, 2000), which is a collective classification algorithm shown to perform consistently well over a wide variety of relational data. Algorithm 1 ICA Algorithm for each instance i do {bootstrapping} Compute polarity for i using local attributes end for repeat {iterative} Generate ordering I over all instances for each i in I do Compute polarity for i using local and relational attributes end for until Stopping criterion is met ICA uses two classifiers: a local classifier and a relational classifier. The local classifier is trained to predict the DA labels using only the local features. We use Local, des</context>
</contexts>
<marker>Neville, Jensen, 2000</marker>
<rawString>J. Neville and D. Jensen. 2000. Iterative classification in relational data. In In Proc. AAAI-2000 Workshop on Learning Statistical Models from Relational Data, pages 13–20. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In ACl</booktitle>
<contexts>
<context position="5009" citStr="Pang and Lee, 2004" startWordPosition="731" endWordPosition="734">her NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on har</context>
<context position="10702" citStr="Pang and Lee, 2004" startWordPosition="1626" endWordPosition="1629">classifications. Thus, we build Local using a variety of knowledge sources that have been shown to be useful for opinion analysis in previous work. Specifically, we construct features using polarity lexicons (used by (Wilson et al., 2005)), DA tags (used by (Somasundaran 3Local is supervised, as previous work has shown that supervised methods are effective in opinion analysis. Even though this makes the final end-to-end system with the ILP implementation semi-supervised, note that the discoursebased ILP part is itself unsupervised. et al., 2007)) and unigrams (used by many researchers, e.g., (Pang and Lee, 2004)). Note that, as our discourse-based classifiers attempt to improve upon the local classifications, Local is also a baseline for our experiments. 4.2 Iterative Collective Classification We use a variant of ICA (Lu and Getoor, 2003; Neville and Jensen, 2000), which is a collective classification algorithm shown to perform consistently well over a wide variety of relational data. Algorithm 1 ICA Algorithm for each instance i do {bootstrapping} Compute polarity for i using local attributes end for repeat {iterative} Generate ordering I over all instances for each i in I do Compute polarity for i </context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACl 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Polanyi</author>
<author>A Zaenen</author>
</authors>
<title>Contextual Valence Shifters. Computing Attitude and Affect in Text: Theory and Applications.</title>
<date>2006</date>
<contexts>
<context position="1058" citStr="Polanyi and Zaenen, 2006" startWordPosition="136" endWordPosition="139">nvestigates design choices in modeling a discourse scheme for improving opinion polarity classification. For this, two diverse global inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved. 1 Introduction The importance of discourse in opinion analysis is being increasingly recognized (Polanyi and Zaenen, 2006). Motivated by the need to enable discourse-based opinion analysis, previous research (Asher et al., 2008; Somasundaran et al., 2008) developed discourse schemes and created manually annotated corpora. However, it was not known whether and how well these linguistic ideas and schemes can be translated into effective computational implementations. In this paper, we first investigate ways in which an opinion discourse scheme can be computationally modeled, and then how it can be utilized to improve polarity classification. Specifically, the discourse scheme we use is from Somasundaran et al. (200</context>
<context position="3691" citStr="Polanyi and Zaenen, 2006" startWordPosition="528" endWordPosition="531"> achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme</context>
</contexts>
<marker>Polanyi, Zaenen, 2006</marker>
<rawString>L. Polanyi and A. Zaenen, 2006. Contextual Valence Shifters. Computing Attitude and Affect in Text: Theory and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-M Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In HLTEMNLP</booktitle>
<contexts>
<context position="4897" citStr="Popescu and Etzioni, 2005" startWordPosition="713" endWordPosition="716">scourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>A.-M. Popescu and O. Etzioni. 2005. Extracting product features and opinions from reviews. In HLTEMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Raaijmakers</author>
<author>K Truong</author>
<author>T Wilson</author>
</authors>
<title>Multimodal subjectivity analysis of multiparty conversation.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="5508" citStr="Raaijmakers et al., 2008" startWordPosition="804" endWordPosition="807">Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 200</context>
</contexts>
<marker>Raaijmakers, Truong, Wilson, 2008</marker>
<rawString>S. Raaijmakers, K. Truong, and T. Wilson. 2008. Multimodal subjectivity analysis of multiparty conversation. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Richardson</author>
<author>P Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<pages>62--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="5840" citStr="Richardson and Domingos, 2006" startWordPosition="849" endWordPosition="853">ference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) a</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>M. Richardson and P. Domingos. 2006. Markov logic networks. Mach. Learn., 62(1-2):107–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL-2004,</booktitle>
<pages>1--8</pages>
<location>Boston, MA, USA.</location>
<contexts>
<context position="6110" citStr="Roth and Yih, 2004" startWordPosition="897" endWordPosition="900">ers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a target is what the opinion is about). The targets of opinions are related via two types of relations: the same relation, which relates targets referring to the same entity or proposition, and the alternative relation, which relates targets referring </context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Proceedings of CoNLL-2004, pages 1–8. Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sadamitsu</author>
<author>S Sekine</author>
<author>M Yamamoto</author>
</authors>
<title>Sentiment analysis based on probabilistic models using inter-sentence information.</title>
<date>2008</date>
<booktitle>In LREC’08.</booktitle>
<contexts>
<context position="3585" citStr="Sadamitsu et al., 2008" startWordPosition="514" endWordPosition="517"> analyses show that even when our discourse-based methods bootstrap from noisy classifications, they can achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to imp</context>
</contexts>
<marker>Sadamitsu, Sekine, Yamamoto, 2008</marker>
<rawString>K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008. Sentiment analysis based on probabilistic models using inter-sentence information. In LREC’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Ruppenhofer</author>
<author>J Wiebe</author>
</authors>
<title>Detecting arguing and sentiment in meetings.</title>
<date>2007</date>
<booktitle>In SIGdial Workshop on Discourse and Dialogue</booktitle>
<contexts>
<context position="5581" citStr="Somasundaran et al., 2007" startWordPosition="814" endWordPosition="817">6)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for po</context>
</contexts>
<marker>Somasundaran, Ruppenhofer, Wiebe, 2007</marker>
<rawString>S. Somasundaran, J. Ruppenhofer, and J. Wiebe. 2007. Detecting arguing and sentiment in meetings. In SIGdial Workshop on Discourse and Dialogue 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Wiebe</author>
<author>J Ruppenhofer</author>
</authors>
<title>Discourse level opinion interpretation. In Coling</title>
<date>2008</date>
<contexts>
<context position="1191" citStr="Somasundaran et al., 2008" startWordPosition="156" endWordPosition="159">l inference paradigms are used: a supervised collective classification framework and an unsupervised optimization framework. Both approaches perform substantially better than baseline approaches, establishing the efficacy of the methods and the underlying discourse scheme. We also present quantitative and qualitative analyses showing how the improvements are achieved. 1 Introduction The importance of discourse in opinion analysis is being increasingly recognized (Polanyi and Zaenen, 2006). Motivated by the need to enable discourse-based opinion analysis, previous research (Asher et al., 2008; Somasundaran et al., 2008) developed discourse schemes and created manually annotated corpora. However, it was not known whether and how well these linguistic ideas and schemes can be translated into effective computational implementations. In this paper, we first investigate ways in which an opinion discourse scheme can be computationally modeled, and then how it can be utilized to improve polarity classification. Specifically, the discourse scheme we use is from Somasundaran et al. (2008), which was developed to support a global, interdependent polarity interpretation. To achieve discourse-based global inference, we </context>
<context position="3848" citStr="Somasundaran et al., 2008" startWordPosition="553" endWordPosition="557">resent our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse relations. However, they do not empirically demonstrate how automatic methods can use their ideas to improve polarity classification. In this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al.,</context>
<context position="6272" citStr="Somasundaran et al. (2008)" startWordPosition="922" endWordPosition="925"> on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities (positive, negative, neutral) and their targets (a target is what the opinion is about). The targets of opinions are related via two types of relations: the same relation, which relates targets referring to the same entity or proposition, and the alternative relation, which relates targets referring to mutually exclusive options in the context of the discourse. Additionally, the scheme relates opinions via two types of frame relations: the reinforcing and non</context>
<context position="7763" citStr="Somasundaran et al. (2008)" startWordPosition="1161" endWordPosition="1165">ions are text-span based, while in this work, we use Dialog Act (DA) based segmentation of meetings.2 As the DAs are our units of classification, we map opinion annotations to the DA units as follows. If a DA unit contains an opinion annotation, the label is transferred upwards to the containing DA. When a DA contains multiple opinion annotations, each with a different polarity, one of them is randomly chosen as the label for the DA. The discourse relations existing between opinions are also transferred upwards, between the DAs containing each of these annotations. We recreate an example from Somasundaran et al. (2008) using DA segmentation in Example 1. Here, the speaker has a positive opinion towards the rubbery material for the TV remote. (1) DA-1:... this kind of rubbery material, DA-2: it’s a bit more bouncy, DA-3: like you said they get chucked around a lot. DA-4: A bit more durable and that can also be ergonomic and DA-5: it kind of feels a bit different from all the other remote controls. In the example, the individual opinion expressions (shown in bold) are essentially regarding the same thing – the rubbery material. Thus, the explicit targets (shown in italics), it’s, that, and it, and the implici</context>
</contexts>
<marker>Somasundaran, Wiebe, Ruppenhofer, 2008</marker>
<rawString>S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008. Discourse level opinion interpretation. In Coling 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Takamura</author>
<author>T Inui</author>
<author>M Okumura</author>
</authors>
<title>Extracting semantic orientations of phrases from dictionary.</title>
<date>2007</date>
<booktitle>In HLT-NAACL</booktitle>
<contexts>
<context position="4839" citStr="Takamura et al., 2007" startWordPosition="707" endWordPosition="710"> this work, we demonstrate concrete ways in which a discourse-based scheme can be modeled using global inference paradigms. Joint models have been previously explored for other NLP problems (Haghighi et al., 2005; Moschitti et al., 2006; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), com</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2007</marker>
<rawString>H. Takamura, T. Inui, and M. Okumura. 2007. Extracting semantic orientations of phrases from dictionary. In HLT-NAACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>M Wong</author>
<author>P Abbeel</author>
<author>D Koller</author>
</authors>
<title>Link prediction in relational data.</title>
<date>2004</date>
<booktitle>In Neural Information Processing Systems.</booktitle>
<contexts>
<context position="5809" citStr="Taskar et al., 2004" startWordPosition="845" endWordPosition="848">nference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent inference. There are several collective classification frameworks, including (Neville and Jensen, 2000; Lu and Getoor, 2003; Taskar et al., 2004; Richardson and Domingos, 2006; Bilgic et al., 2007). In this paper, we use an approach by (Lu and Getoor, 2003) which iteratively predicts class values using local and relational features. ILP has been used on other NLP tasks, e.g., (Denis and Baldridge, 2007; Choi et al., 2006; Roth and Yih, 2004). In this work, we employ ILP for modeling discourse constraints for polarity classification. 3 Discourse Scheme and Data The scheme in Somasundaran et al. (2008) has been developed and annotated over the AMI meeting corpus (Carletta et al., 2005).1 This scheme annotates opinions, their polarities </context>
</contexts>
<marker>Taskar, Wong, Abbeel, Koller, 2004</marker>
<rawString>B. Taskar, M. Wong, P. Abbeel, and D. Koller. 2004. Link prediction in relational data. In Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thomas</author>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from congressional floor-debate transcripts.</title>
<date>2006</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="5071" citStr="Thomas et al., 2006" startWordPosition="739" endWordPosition="742">6; Moschitti, 2009). Our global inference model focuses on opinion polarity recognition task. The biggest difference between this work and previous work in opinion analysis that use global inference methods is in the type of linguistic relations used to achieve the global inference. Some of the work is not related to discourse at all (e.g., lexical similarities (Takamura et al., 2007), morphosyntactic similarities (Popescu and Etzioni, 2005) and word-based measures like TFIDF (Goldberg and Zhu, 2006)). Others use sentence cohesion (Pang and Lee, 2004), agreement/disagreement between speakers (Thomas et al., 2006; Bansal et al., 2008), or structural adjacency. In contrast, our work focuses on discoursebased relations for global inference. Another difference from the above work is that our work is over multi-party conversations. Previous work on emotion and subjectivity detection in multi-party conversations has explored using prosodic information (Neiberg et al., 2006), combining linguistic and acoustic information (Raaijmakers et al., 2008) and combining lexical and dialog information (Somasundaran et al., 2007). Our work is focused on harnessing discourse-based knowledge and on interdependent infere</context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote: Determining support or opposition from congressional floor-debate transcripts. In EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP</booktitle>
<contexts>
<context position="3481" citStr="Wilson et al., 2005" startWordPosition="496" endWordPosition="500">corporates the strengths of both, is able to achieve significant overall improvements over both. Our analyses show that even when our discourse-based methods bootstrap from noisy classifications, they can achieve good improvements. The rest of this paper is organized as follows: we discuss related work in Section 2 and the discourse scheme in Section 3. We present our discourse-based implementations in Section 4, experiments in Section 5, discussions in Section 6 and conclusions in Section 7. 2 Related Work Previous work on polarity disambiguation has used contextual clues and reversal words (Wilson et al., 2005; Kennedy and Inkpen, 2006; Kanayama and Nasukawa, 2006; Devitt and Ahmad, 2007; Sadamitsu et al., 2008). However, these do not capture discourse-level relations. Researchers, such as (Polanyi and Zaenen, 2006), have discussed how the discourse structure can influence opinion interpretation; and previous work, such as (Asher et al., 2008; Somasundaran et al., 2008), have developed annota170 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tion schemes for interpreting opinions with discourse </context>
<context position="10321" citStr="Wilson et al., 2005" startWordPosition="1567" endWordPosition="1570">urse relations. Both classifiers thus accommodate preferences of the local classifier and for coherence with discourse neighbors. 4.1 Local Classifier A supervised local classifier, Local, is used to provide the classifications to bootstrap the discoursebased classifiers.3 It is important to make Local as reliable as possible; otherwise, the discourse relations will propagate misclassifications. Thus, we build Local using a variety of knowledge sources that have been shown to be useful for opinion analysis in previous work. Specifically, we construct features using polarity lexicons (used by (Wilson et al., 2005)), DA tags (used by (Somasundaran 3Local is supervised, as previous work has shown that supervised methods are effective in opinion analysis. Even though this makes the final end-to-end system with the ILP implementation semi-supervised, note that the discoursebased ILP part is itself unsupervised. et al., 2007)) and unigrams (used by many researchers, e.g., (Pang and Lee, 2004)). Note that, as our discourse-based classifiers attempt to improve upon the local classifications, Local is also a baseline for our experiments. 4.2 Iterative Collective Classification We use a variant of ICA (Lu and G</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT-EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data mining: practical machine learning tools and techniques with java implementations.</title>
<date>2002</date>
<journal>SIGMOD Rec.,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="22928" citStr="Witten and Frank, 2002" startWordPosition="3707" endWordPosition="3710">the test data based on the overall distribution of the classes in the training data. However, in Table 3, the class distribution is different for the Connected and Singleton conditions. We incorporate this in a smarter baseline, Base-2, which constructs separate distributions for connected instances and singletons. Thus, given a test instance, depending on whether it is connected, Base-2 uses the corresponding distribution to make its prediction. The third baseline is the supervised classifier, Local, described in Section 4.1. It is implemented using the SVM classifiers from the Weka toolkit (Witten and Frank, 2002).4 Our supervised discourse-based classifier, ICA from Section 4.2, also uses a similar SVM implementation for its relational classifier. We implement our ILP approach from Section 4.3 using the optimization toolbox from Mathworks (http://www.mathworks.com) and GNU Linear Programming Kit. We observed that the ILP system performs better than the ICA system on instances that are connected, while ICA performs better on singletons. Thus, we also implemented a simple hybrid classifier (HYB), which selects the ICA prediction for classification of singletons and the ILP prediction for classification </context>
</contexts>
<marker>Witten, Frank, 2002</marker>
<rawString>I. H. Witten and E. Frank. 2002. Data mining: practical machine learning tools and techniques with java implementations. SIGMOD Rec., 31(1):76–77.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>