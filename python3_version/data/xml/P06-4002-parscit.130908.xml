<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000213">
<title confidence="0.994371">
Is It Correct? - Towards Web-Based Evaluation of Automatic Natural
Language Phrase Generation
</title>
<note confidence="0.68455">
Calkin S. Montero and Kenji Araki
</note>
<title confidence="0.3480225">
Graduate School of Information Science and Technology, Hokkaido University,
Kita 14-jo Nishi 9-chome, Kita-ku, Sapporo, 060-0814 Japan
</title>
<email confidence="0.993245">
calkin,araki @media.eng.hokudai.ac.jp
</email>
<sectionHeader confidence="0.993737" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999977">
This paper describes a novel approach for
the automatic generation and evaluation of
a trivial dialogue phrases database. A tri-
vial dialogue phrase is defined as an ex-
pression used by a chatbot program as the
answer of a user input. A transfer-like ge-
netic algorithm (GA) method is used to
generating the trivial dialogue phrases for
the creation of a natural language genera-
tion (NLG) knowledge base. The auto-
matic evaluation of a generated phrase is
performed by producing n-grams and re-
trieving their frequencies from the World
Wide Web (WWW). Preliminary experi-
ments show very positive results.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99945956">
Natural language generation has devoted itself to
studying and simulating the production of writ-
ten or spoken discourse. From the canned text
approach, in which the computer prints out a
text given by a programmer, to the template fill-
ing approach, in which predetermined templates
are filled up to produce a desired output, the ap-
plications and limitations of language generation
have been widely studied. Well known applica-
tions of natural language generation can be found
in human-computer conversation (HCC) systems.
One of the most famous HCC systems, ELIZA
(Weizenbaum, 1966), uses the template filling ap-
proach to generate the system’s response to a user
input. For a dialogue system, the template filling
approach works well in certain situations, however
due to the templates limitations, nonsense is pro-
duced easily.
In recent research Inui et al. (2003) have used
a corpus-based approach to language generation.
Due to its flexibility and applicability to open do-
main, such an approach might be considered as
more robust than the template filling approach
when applied to dialogue systems. In their ap-
proach, Inui et al. (2003), applied keyword match-
ing in order to extract sample dialogues from a di-
alogue corpus, i.e., utterance-response pairs. Af-
ter applying certain transfer or exchange rules, the
sentence with maximum occurrence probability is
given to the user as the system’s response. Other
HCC systems, e.g. Wallace (2005), have applied
the corpus based approach to natural language ge-
neration in order to retrieve system’s trivial di-
alogue responses. However, the creation of the
hand crafted knowledge base, that is to say, a dia-
logue corpus, is a highly time consuming and hard
to accomplish task1. Therefore we aim to auto-
matically generate and evaluate a database of tri-
vial dialogue phrases that could be implemented as
knowledge base language generator for open do-
main dialogue systems, or chatbots.
In this paper, we propose the automatic gene-
ration of trivial dialogue phrases through the ap-
plication of a transfer-like genetic algorithm (GA)
approach. We propose as well, the automatic eval-
uation of the correctness2 of the generated phrase
using the WWW as a knowledge database. The
generated database could serve as knowledge base
to automatically improve publicly available chat-
bot3 databases, e.g. Wallace (2005).
</bodyText>
<footnote confidence="0.98772825">
1The creation of the ALICE chatbot database (ALICE
brain) has cost more that 30 researchers, over 10 years
work to accomplish. http://www.alicebot.org/superbot.html
http://alicebot.org/articles/wallace/dont.html
2Correctness implies here whether the expression is gram-
matically correct, and whether the expression exists in the
Web.
3Computer program that simulates human conversation.
</footnote>
<page confidence="0.908326">
5
</page>
<bodyText confidence="0.4207715">
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 5–8,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.503136" genericHeader="introduction">
2 Overview and Related Work
</sectionHeader>
<figureCaption confidence="0.996904">
Figure 1: System Overview
</figureCaption>
<bodyText confidence="0.999996142857143">
We apply a GA-like transfer approach to au-
tomatically generate new trivial dialogue phrases,
where each phrase is considered as a gene, and the
words of the phrase represent the DNA. The trans-
fer approach to language generation has been used
by Arendse (1998), where a sentence is being re-
generated through word substitution. Problems of
erroneous grammar or ambiguity are solved by re-
ferring to a lexicon and a grammar, re-generating
substitutes expressions of the original sentence,
and the user deciding which one of the genera-
ted expressions is correct. Our method differs in
the application of a GA-like transfer process in
order to automatically insert new features on the
selected original phrase and the automatic eval-
uation of the newly generated phrase using the
WWW. We assume the automatically generated
trivial phrases database is desirable as a know-
ledge base for open domain dialogue systems. Our
system general overview is shown in Figure 1. A
description of each step is given hereunder.
</bodyText>
<sectionHeader confidence="0.967112" genericHeader="method">
3 Trivial Dialogue Phrases Generation:
Transfer-like GA Approach
</sectionHeader>
<subsectionHeader confidence="0.999724">
3.1 Initial Population Selection
</subsectionHeader>
<bodyText confidence="0.999886444444444">
In the population selection process a small popu-
lation of phrases are selected randomly from the
Phrase DB4. This is a small database created be-
forehand. The Phrase DB was used for setting
the thresholds for the evaluation of the generated
phrases. It contains phrases extracted from real
human-human trivial dialogues (obtained from
the corpus of the University of South Califor-
nia (2005)) and from the hand crafted ALICE
</bodyText>
<subsectionHeader confidence="0.994458">
4In this paper DB stands for database.
</subsectionHeader>
<bodyText confidence="0.999811222222222">
database. For the experiments this DB contained
15 trivial dialogue phrases. Some of those trivial
dialogue phrases are: do you like airplanes ?, have you
have your lunch ?, I am glad you are impressed, what are
your plans for the weekend ?, and so forth. The initial
population is formed by a number of phrases ran-
domly selected between one and the total number
of expressions in the database. No evaluation is
performed to this initial population.
</bodyText>
<subsectionHeader confidence="0.998261">
3.2 Crossover
</subsectionHeader>
<bodyText confidence="0.9999675">
Since the length, i.e., number of words, among the
analyzed phrases differs and our algorithm does
not use semantical information, in order to avoid
the distortion of the original phrase, in our system
the crossover rate was selected to be 0%. This is
in order to ensure a language independent method.
The generation of the new phrase is given solely
by the mutation process explained below.
</bodyText>
<subsectionHeader confidence="0.991932">
3.3 Mutation
</subsectionHeader>
<bodyText confidence="0.992543291666666">
During the mutation process, each one of the
phrases of the selected initial population is mu-
tated at a rate of , where N is the total number
of words in the phrase. The mutation is performed
through a transfer process, using the Features DB.
This DB contains descriptive features of different
topics of human-human dialogues. The word “fea-
tures” refers here to the specific part of speech
used, that is, nouns, adjectives and adverbs5. In
order to extract the descriptive features that the
Feature DB contains, different human-human dia-
logues, (USC, 2005), were clustered by topic6 and
the most descriptive nouns, adjectives and adverbs
of each topic were extracted. The word to be re-
placed within the original phrase is randomly se-
lected as well as it is randomly selected the substi-
tution feature to be used as a replacement from the
Feature DB. In order to obtain a language indepen-
dent system, at this stage part of speech tagging
was not performed7. For this mutation process, the
total number of possible different expressions that
could be generated from a given phrase is ,
where the exponent is the total number of
features in the Feature DB.
</bodyText>
<footnote confidence="0.461410857142857">
5For the preliminary experiment this database contained
30 different features
6Using agglomerative clustering with the publicly avail-
able Cluto toolkit
7POS tagging was used when creating the Features DB.
Alternatively, instead of using POS, the features might be
given by hand
</footnote>
<page confidence="0.994786">
6
</page>
<table confidence="0.99965875">
Total no Phrases Gen Unnatural Usable Completely Natural Precision Recall
Accepted Rejected Accepted Rejected Accepted Rejected Accepted Rejected 0.550 0.815
80 511 36 501 18 8 26 2
Total 591 Total 537 Total 26 Total 28
</table>
<tableCaption confidence="0.998818">
Table 3. Human Evaluation - Naturalness of the Phrases
</tableCaption>
<subsectionHeader confidence="0.886943">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.999982">
In order to evaluate the correctness of the newly
generated expression, we used as database the
WWW. Due to its significant growth$, the WWW
has become an attractive database for differ-
ent systems applications as, machine translation
(Resnik and Smith, 2003), question answering
(Kwok et al., 2001), commonsense retrieval (Ma-
tuszek et al., 2005), and so forth. In our approach
we attempt to evaluate whether a generated phrase
is correct through its frequency of appearance in
the Web, i.e., the fitness as a function of the fre-
quency of appearance. Since matching an entire
phrase on the Web might result in very low re-
trieval, in some cases even non retrieval at all, we
applied the sectioning of the given phrase into its
respective n-grams.
</bodyText>
<sectionHeader confidence="0.502865" genericHeader="method">
3.4.1 N-Grams Production
</sectionHeader>
<bodyText confidence="0.876073935483871">
For each one of the generated phrases to evalu-
ate, n-grams are produced. The n-grams used are
bigram, trigram, and quadrigram. Their frequency
of appearance on the Web (using Google search
engine) is searched and ranked. For each n-gram,
thresholds have been established9. A phrase is
evaluated according to the following algorithm10:
if ,then “weakly accepted”
elsif ,then “accepted”
else “rejected”
where, and are thresholds that vary according
to the n-gram type, and is the fre-
quency, or number of hits, returned by the search
engine for a given n-gram. Table 1 shows some
of the n-grams produced for the generated phrase
“what are your plans for the game?” The fre-
quency of each n-gram is also shown along with
the system evaluation. The phrase was evaluated
8As for 1998, according to Lawrence and Giles (1999) the
“surface Web” consisted of approximately 2.5 billion doc-
uments. As for January 2005, according to Gulli and Sig-
norini (2005),the size of indexable Web had become approx-
imately 11.5 billion pages
9The tuning of the thresholds of each n-gram type was
preformed using the phrases of the Phrase DB
10The evaluation “weakly accepted” has been designed to
reflect n-grams whose appearance on the Web is significant
even though they are rarely used. In the experiment they were
treated as accepted.
as accepted since none of the n-grams produced
was rejected.
</bodyText>
<table confidence="0.999599">
N-Gram Frequency (hits) System Eval.
Bigram what:are 213000000 accepted
Trigram your:plans:for 116000 accepted
Quadrigram plans:for:the:game 958 accepted
</table>
<tableCaption confidence="0.9909945">
Table 1. N-Grams Produced for:
“what are your plans for the game?”
</tableCaption>
<sectionHeader confidence="0.77173" genericHeader="method">
4 Preliminary Experiments and Results
</sectionHeader>
<bodyText confidence="0.9997044">
The system was setup to perform 150 genera-
tions11. Table 2 contains the results. There were
591 different phrases generated, from which 80
were evaluated as “accepted”, and the rest 511
were rejected by the system.
</bodyText>
<table confidence="0.9988255">
Total Generations 150
Total Generated Phrases 591
Accepted 80
Rejected 511
</table>
<tableCaption confidence="0.99729">
Table 2. Results for 150 Generations
</tableCaption>
<bodyText confidence="0.8878032">
As part of the preliminary experiment, the ge-
nerated phrases were evaluated by a native English
speaker in order to determine their “naturalness”.
The human evaluation of the generated phrases
was performed under the criterion of the follow-
ing categories:
a) Unnatural: a phrase that would not be used dur-
ing a conversation.
b) Usable: a phrase that could be used during
a conversation,even though it is not a common
phrase.
c) Completely Natural: a phrase that might be
commonly used during a conversation.
The results of the human evaluation are shown
in Table 3. In this evaluation, 26 out of the 80
phrases “accepted” by the system were considered
“completely natural”, and 18 out of the 80 “ac-
cepted” were considered “usable”, for a total of 44
well-generated phrases12. On the other hand, the
system mis-evaluation is observed mostly within
the “accepted” phrases, i.e., 36 out of 80 “ac-
cepted” were “unnatural”, whereas within the “re-
jected” phrases only 8 out of 511 were considered
“usable” and 2 out of 511 were considered “com-
pletely natural”, which affected negatively the pre-
</bodyText>
<footnote confidence="0.764841666666667">
11Processing time: 20 hours 13 minutes. The Web search
results are as for March 2006
12Phrases that could be used during a conversation
</footnote>
<page confidence="0.998806">
7
</page>
<table confidence="0.999599571428571">
Original Phrase Generated Phrase
Completely Natural
what are your plans for the game ?
what are your plans for the weekend ? Usable
what are your friends for the weekend ?
Unnatural
what are your plans for the visitation ?
</table>
<tableCaption confidence="0.944964">
able 4. Examples of Generated Phrases
</tableCaption>
<bodyText confidence="0.959879416666667">
cision of the system.
In order to obtain a statistical view of the sys-
tem’s performance, the metrics of recall, (R), and
precision, (P), were calculated according to (A
stands for “Accepted”, from Table 3):
Table 4 shows the system output, i.e., phrases
generated and evaluated as “accepted” by the sys-
tem, for the original phrase “what are your plans
for the weekend ?” According with the criterion
shown above, the generated phrases were evalu-
ated by a user to determine their naturalness - ap-
plicability to dialogue.
</bodyText>
<subsectionHeader confidence="0.862695">
4.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999968074074074">
Recall is the rate of the well-generated phrases
given as “accepted” by the system divided by the
total number of well-generated phrases. This is a
measure of the coverage of the system in terms of
the well-generated phrases. On the other hand, the
precision rates the well-generated phrases divided
by the total number of “accepted” phrases. The
precision is a measure of the correctness of the
system in terms of the evaluation of the phrases.
For this experiment the recall of the system was
0.815, i.e., 81.5% of the total number of well-
generated phrases where correctly selected, how-
ever this implied a trade-off with the precision,
which was compromised by the system’s wide
coverage.
An influential factor in the system precision and
recall is the selection of new features to be used
during the mutation process. This is because the
insertion of a new feature gives rise to a totally
new phrase that might not be related to the orig-
inal one. In the same tradition, a decisive factor
in the evaluation of a well-generated phrase is the
constantly changing information available on the
Web. This fact rises thoughts of the application of
variable threshold for evaluation. Even though the
system leaves room for improvement, its success-
ful implementation has been confirmed.
</bodyText>
<sectionHeader confidence="0.998718" genericHeader="conclusions">
5 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.9999725">
We presented an automatic trivial dialogue phrases
generator system. The generated phrases are au-
tomatically evaluated using the frequency hits of
the n-grams correspondent to the analyzed phrase.
However improvements could be made in the eval-
uation process, preliminary experiments showed
a promising successful implementation. We plan
to work toward the application of the obtained
database of trivial phrases to open domain dia-
logue systems.
</bodyText>
<sectionHeader confidence="0.999419" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99931159375">
Bernth Arendse. 1998. Easyenglish: Preprocessing for MT.
In Proceedings of the Second International Workshop on
Controlled Language Applications (CLAW98), pages 30–
41.
Antonio Gulli and Alessio Signorini. 2005. The indexable
web is more than 11.5 billion pages. In In Proceedings
of 14th International World Wide Web Conference, pages
902–903.
Nobuo Inui, Takuya Koiso, Junpei Nakamura, and Yoshiyuki
Kotani. 2003. Fully corpus-based natural language dia-
logue system. In Natural Language Generation in Spoken
and Written Dialogue, AAAI Spring Symposium.
Cody Kwok, Oren Etzioni, and Daniel S. Weld. 2001. Scal-
ing question answering to the web. ACM Trans. Inf. Syst.,
19(3):242–262.
Steve Lawrence and Lee Giles. 1999. Accessibility of infor-
mation on the web. Nature, 400(107-109).
Cynthia Matuszek, Michael Witbrock, Robert C. Kahlert,
John Cabral, Dave Schneider, Purvesh Shah, and Doug
Lenat. 2005. Searching for common sense: Populating
cyc(tm) from the web. In Proceedings of the Twentieth
National Conference on Artificial Intelligence.
Philip Resnik and Noah A. Smith. 2003. The web as a paral-
lel corpus. Comput. Linguist., 29(3):349–380.
University of South California USC. 2005.
Dialogue diversity corpus. http://www-
rcf.usc.edu/˜billmann/diversity/DDivers-site.htm.
Richard Wallace. 2005. A.l.i.c.e. artificial intelligence foun-
dation. http://www.alicebot.org.
Joseph Weizenbaum. 1966. Elizaa computer program for the
study of natural language communication between man
and machine. Commun. ACM, 9(1):36–45.
</reference>
<page confidence="0.998487">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.753390">
<title confidence="0.9974515">Is It Correct? - Towards Web-Based Evaluation of Automatic Natural Language Phrase Generation</title>
<author confidence="0.998659">S Montero Araki</author>
<affiliation confidence="0.999996">Graduate School of Information Science and Technology, Hokkaido University,</affiliation>
<address confidence="0.955142">Kita 14-jo Nishi 9-chome, Kita-ku, Sapporo, 060-0814 Japan</address>
<email confidence="0.799052">calkin,araki@media.eng.hokudai.ac.jp</email>
<abstract confidence="0.998183625">This paper describes a novel approach for the automatic generation and evaluation of dialogue phrases A trivial dialogue phrase is defined as an expression used by a chatbot program as the answer of a user input. A transfer-like genetic algorithm (GA) method is used to generating the trivial dialogue phrases for the creation of a natural language generation (NLG) knowledge base. The automatic evaluation of a generated phrase is performed by producing n-grams and retrieving their frequencies from the World Wide Web (WWW). Preliminary experiments show very positive results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernth Arendse</author>
</authors>
<title>Easyenglish: Preprocessing for MT.</title>
<date>1998</date>
<booktitle>In Proceedings of the Second International Workshop on Controlled Language Applications (CLAW98),</booktitle>
<pages>30--41</pages>
<contexts>
<context position="4123" citStr="Arendse (1998)" startWordPosition="631" endWordPosition="632">e whether the expression is grammatically correct, and whether the expression exists in the Web. 3Computer program that simulates human conversation. 5 Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 5–8, Sydney, July 2006. c�2006 Association for Computational Linguistics 2 Overview and Related Work Figure 1: System Overview We apply a GA-like transfer approach to automatically generate new trivial dialogue phrases, where each phrase is considered as a gene, and the words of the phrase represent the DNA. The transfer approach to language generation has been used by Arendse (1998), where a sentence is being regenerated through word substitution. Problems of erroneous grammar or ambiguity are solved by referring to a lexicon and a grammar, re-generating substitutes expressions of the original sentence, and the user deciding which one of the generated expressions is correct. Our method differs in the application of a GA-like transfer process in order to automatically insert new features on the selected original phrase and the automatic evaluation of the newly generated phrase using the WWW. We assume the automatically generated trivial phrases database is desirable as a </context>
</contexts>
<marker>Arendse, 1998</marker>
<rawString>Bernth Arendse. 1998. Easyenglish: Preprocessing for MT. In Proceedings of the Second International Workshop on Controlled Language Applications (CLAW98), pages 30– 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Gulli</author>
<author>Alessio Signorini</author>
</authors>
<title>The indexable web is more than 11.5 billion pages. In</title>
<date>2005</date>
<booktitle>In Proceedings of 14th International World Wide Web Conference,</booktitle>
<pages>902--903</pages>
<contexts>
<context position="9736" citStr="Gulli and Signorini (2005)" startWordPosition="1556" endWordPosition="1560">ng algorithm10: if ,then “weakly accepted” elsif ,then “accepted” else “rejected” where, and are thresholds that vary according to the n-gram type, and is the frequency, or number of hits, returned by the search engine for a given n-gram. Table 1 shows some of the n-grams produced for the generated phrase “what are your plans for the game?” The frequency of each n-gram is also shown along with the system evaluation. The phrase was evaluated 8As for 1998, according to Lawrence and Giles (1999) the “surface Web” consisted of approximately 2.5 billion documents. As for January 2005, according to Gulli and Signorini (2005),the size of indexable Web had become approximately 11.5 billion pages 9The tuning of the thresholds of each n-gram type was preformed using the phrases of the Phrase DB 10The evaluation “weakly accepted” has been designed to reflect n-grams whose appearance on the Web is significant even though they are rarely used. In the experiment they were treated as accepted. as accepted since none of the n-grams produced was rejected. N-Gram Frequency (hits) System Eval. Bigram what:are 213000000 accepted Trigram your:plans:for 116000 accepted Quadrigram plans:for:the:game 958 accepted Table 1. N-Grams </context>
</contexts>
<marker>Gulli, Signorini, 2005</marker>
<rawString>Antonio Gulli and Alessio Signorini. 2005. The indexable web is more than 11.5 billion pages. In In Proceedings of 14th International World Wide Web Conference, pages 902–903.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuo Inui</author>
<author>Takuya Koiso</author>
<author>Junpei Nakamura</author>
<author>Yoshiyuki Kotani</author>
</authors>
<title>Fully corpus-based natural language dialogue system.</title>
<date>2003</date>
<booktitle>In Natural Language Generation in Spoken and Written Dialogue,</booktitle>
<publisher>AAAI Spring Symposium.</publisher>
<contexts>
<context position="1788" citStr="Inui et al. (2003)" startWordPosition="273" endWordPosition="276">h, in which predetermined templates are filled up to produce a desired output, the applications and limitations of language generation have been widely studied. Well known applications of natural language generation can be found in human-computer conversation (HCC) systems. One of the most famous HCC systems, ELIZA (Weizenbaum, 1966), uses the template filling approach to generate the system’s response to a user input. For a dialogue system, the template filling approach works well in certain situations, however due to the templates limitations, nonsense is produced easily. In recent research Inui et al. (2003) have used a corpus-based approach to language generation. Due to its flexibility and applicability to open domain, such an approach might be considered as more robust than the template filling approach when applied to dialogue systems. In their approach, Inui et al. (2003), applied keyword matching in order to extract sample dialogues from a dialogue corpus, i.e., utterance-response pairs. After applying certain transfer or exchange rules, the sentence with maximum occurrence probability is given to the user as the system’s response. Other HCC systems, e.g. Wallace (2005), have applied the co</context>
</contexts>
<marker>Inui, Koiso, Nakamura, Kotani, 2003</marker>
<rawString>Nobuo Inui, Takuya Koiso, Junpei Nakamura, and Yoshiyuki Kotani. 2003. Fully corpus-based natural language dialogue system. In Natural Language Generation in Spoken and Written Dialogue, AAAI Spring Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cody Kwok</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
</authors>
<title>Scaling question answering to the web.</title>
<date>2001</date>
<journal>ACM Trans. Inf. Syst.,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="8319" citStr="Kwok et al., 2001" startWordPosition="1319" endWordPosition="1322">ures might be given by hand 6 Total no Phrases Gen Unnatural Usable Completely Natural Precision Recall Accepted Rejected Accepted Rejected Accepted Rejected Accepted Rejected 0.550 0.815 80 511 36 501 18 8 26 2 Total 591 Total 537 Total 26 Total 28 Table 3. Human Evaluation - Naturalness of the Phrases 3.4 Evaluation In order to evaluate the correctness of the newly generated expression, we used as database the WWW. Due to its significant growth$, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al., 2001), commonsense retrieval (Matuszek et al., 2005), and so forth. In our approach we attempt to evaluate whether a generated phrase is correct through its frequency of appearance in the Web, i.e., the fitness as a function of the frequency of appearance. Since matching an entire phrase on the Web might result in very low retrieval, in some cases even non retrieval at all, we applied the sectioning of the given phrase into its respective n-grams. 3.4.1 N-Grams Production For each one of the generated phrases to evaluate, n-grams are produced. The n-grams used are bigram, trigram, and quadrigram. T</context>
</contexts>
<marker>Kwok, Etzioni, Weld, 2001</marker>
<rawString>Cody Kwok, Oren Etzioni, and Daniel S. Weld. 2001. Scaling question answering to the web. ACM Trans. Inf. Syst., 19(3):242–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Lawrence</author>
<author>Lee Giles</author>
</authors>
<title>Accessibility of information on the web.</title>
<date>1999</date>
<journal>Nature,</journal>
<pages>400--107</pages>
<contexts>
<context position="9607" citStr="Lawrence and Giles (1999)" startWordPosition="1536" endWordPosition="1539">gine) is searched and ranked. For each n-gram, thresholds have been established9. A phrase is evaluated according to the following algorithm10: if ,then “weakly accepted” elsif ,then “accepted” else “rejected” where, and are thresholds that vary according to the n-gram type, and is the frequency, or number of hits, returned by the search engine for a given n-gram. Table 1 shows some of the n-grams produced for the generated phrase “what are your plans for the game?” The frequency of each n-gram is also shown along with the system evaluation. The phrase was evaluated 8As for 1998, according to Lawrence and Giles (1999) the “surface Web” consisted of approximately 2.5 billion documents. As for January 2005, according to Gulli and Signorini (2005),the size of indexable Web had become approximately 11.5 billion pages 9The tuning of the thresholds of each n-gram type was preformed using the phrases of the Phrase DB 10The evaluation “weakly accepted” has been designed to reflect n-grams whose appearance on the Web is significant even though they are rarely used. In the experiment they were treated as accepted. as accepted since none of the n-grams produced was rejected. N-Gram Frequency (hits) System Eval. Bigra</context>
</contexts>
<marker>Lawrence, Giles, 1999</marker>
<rawString>Steve Lawrence and Lee Giles. 1999. Accessibility of information on the web. Nature, 400(107-109).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>Michael Witbrock</author>
<author>Robert C Kahlert</author>
<author>John Cabral</author>
<author>Dave Schneider</author>
<author>Purvesh Shah</author>
<author>Doug Lenat</author>
</authors>
<title>Searching for common sense: Populating cyc(tm) from the web.</title>
<date>2005</date>
<booktitle>In Proceedings of the Twentieth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8366" citStr="Matuszek et al., 2005" startWordPosition="1325" endWordPosition="1329">ses Gen Unnatural Usable Completely Natural Precision Recall Accepted Rejected Accepted Rejected Accepted Rejected Accepted Rejected 0.550 0.815 80 511 36 501 18 8 26 2 Total 591 Total 537 Total 26 Total 28 Table 3. Human Evaluation - Naturalness of the Phrases 3.4 Evaluation In order to evaluate the correctness of the newly generated expression, we used as database the WWW. Due to its significant growth$, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al., 2001), commonsense retrieval (Matuszek et al., 2005), and so forth. In our approach we attempt to evaluate whether a generated phrase is correct through its frequency of appearance in the Web, i.e., the fitness as a function of the frequency of appearance. Since matching an entire phrase on the Web might result in very low retrieval, in some cases even non retrieval at all, we applied the sectioning of the given phrase into its respective n-grams. 3.4.1 N-Grams Production For each one of the generated phrases to evaluate, n-grams are produced. The n-grams used are bigram, trigram, and quadrigram. Their frequency of appearance on the Web (using </context>
</contexts>
<marker>Matuszek, Witbrock, Kahlert, Cabral, Schneider, Shah, Lenat, 2005</marker>
<rawString>Cynthia Matuszek, Michael Witbrock, Robert C. Kahlert, John Cabral, Dave Schneider, Purvesh Shah, and Doug Lenat. 2005. Searching for common sense: Populating cyc(tm) from the web. In Proceedings of the Twentieth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="8279" citStr="Resnik and Smith, 2003" startWordPosition="1313" endWordPosition="1316">Alternatively, instead of using POS, the features might be given by hand 6 Total no Phrases Gen Unnatural Usable Completely Natural Precision Recall Accepted Rejected Accepted Rejected Accepted Rejected Accepted Rejected 0.550 0.815 80 511 36 501 18 8 26 2 Total 591 Total 537 Total 26 Total 28 Table 3. Human Evaluation - Naturalness of the Phrases 3.4 Evaluation In order to evaluate the correctness of the newly generated expression, we used as database the WWW. Due to its significant growth$, the WWW has become an attractive database for different systems applications as, machine translation (Resnik and Smith, 2003), question answering (Kwok et al., 2001), commonsense retrieval (Matuszek et al., 2005), and so forth. In our approach we attempt to evaluate whether a generated phrase is correct through its frequency of appearance in the Web, i.e., the fitness as a function of the frequency of appearance. Since matching an entire phrase on the Web might result in very low retrieval, in some cases even non retrieval at all, we applied the sectioning of the given phrase into its respective n-grams. 3.4.1 N-Grams Production For each one of the generated phrases to evaluate, n-grams are produced. The n-grams use</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah A. Smith. 2003. The web as a parallel corpus. Comput. Linguist., 29(3):349–380.</rawString>
</citation>
<citation valid="false">
<date>2005</date>
<institution>University of South California USC.</institution>
<note>Dialogue diversity corpus. http://wwwrcf.usc.edu/˜billmann/diversity/DDivers-site.htm.</note>
<contexts>
<context position="2367" citStr="(2005)" startWordPosition="368" endWordPosition="368">research Inui et al. (2003) have used a corpus-based approach to language generation. Due to its flexibility and applicability to open domain, such an approach might be considered as more robust than the template filling approach when applied to dialogue systems. In their approach, Inui et al. (2003), applied keyword matching in order to extract sample dialogues from a dialogue corpus, i.e., utterance-response pairs. After applying certain transfer or exchange rules, the sentence with maximum occurrence probability is given to the user as the system’s response. Other HCC systems, e.g. Wallace (2005), have applied the corpus based approach to natural language generation in order to retrieve system’s trivial dialogue responses. However, the creation of the hand crafted knowledge base, that is to say, a dialogue corpus, is a highly time consuming and hard to accomplish task1. Therefore we aim to automatically generate and evaluate a database of trivial dialogue phrases that could be implemented as knowledge base language generator for open domain dialogue systems, or chatbots. In this paper, we propose the automatic generation of trivial dialogue phrases through the application of a transfe</context>
<context position="5356" citStr="(2005)" startWordPosition="827" endWordPosition="827">ain dialogue systems. Our system general overview is shown in Figure 1. A description of each step is given hereunder. 3 Trivial Dialogue Phrases Generation: Transfer-like GA Approach 3.1 Initial Population Selection In the population selection process a small population of phrases are selected randomly from the Phrase DB4. This is a small database created beforehand. The Phrase DB was used for setting the thresholds for the evaluation of the generated phrases. It contains phrases extracted from real human-human trivial dialogues (obtained from the corpus of the University of South California (2005)) and from the hand crafted ALICE 4In this paper DB stands for database. database. For the experiments this DB contained 15 trivial dialogue phrases. Some of those trivial dialogue phrases are: do you like airplanes ?, have you have your lunch ?, I am glad you are impressed, what are your plans for the weekend ?, and so forth. The initial population is formed by a number of phrases randomly selected between one and the total number of expressions in the database. No evaluation is performed to this initial population. 3.2 Crossover Since the length, i.e., number of words, among the analyzed phr</context>
<context position="9736" citStr="(2005)" startWordPosition="1560" endWordPosition="1560">then “weakly accepted” elsif ,then “accepted” else “rejected” where, and are thresholds that vary according to the n-gram type, and is the frequency, or number of hits, returned by the search engine for a given n-gram. Table 1 shows some of the n-grams produced for the generated phrase “what are your plans for the game?” The frequency of each n-gram is also shown along with the system evaluation. The phrase was evaluated 8As for 1998, according to Lawrence and Giles (1999) the “surface Web” consisted of approximately 2.5 billion documents. As for January 2005, according to Gulli and Signorini (2005),the size of indexable Web had become approximately 11.5 billion pages 9The tuning of the thresholds of each n-gram type was preformed using the phrases of the Phrase DB 10The evaluation “weakly accepted” has been designed to reflect n-grams whose appearance on the Web is significant even though they are rarely used. In the experiment they were treated as accepted. as accepted since none of the n-grams produced was rejected. N-Gram Frequency (hits) System Eval. Bigram what:are 213000000 accepted Trigram your:plans:for 116000 accepted Quadrigram plans:for:the:game 958 accepted Table 1. N-Grams </context>
</contexts>
<marker>2005</marker>
<rawString>University of South California USC. 2005. Dialogue diversity corpus. http://wwwrcf.usc.edu/˜billmann/diversity/DDivers-site.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Wallace</author>
</authors>
<date>2005</date>
<note>A.l.i.c.e. artificial intelligence foundation. http://www.alicebot.org.</note>
<contexts>
<context position="2367" citStr="Wallace (2005)" startWordPosition="367" endWordPosition="368"> recent research Inui et al. (2003) have used a corpus-based approach to language generation. Due to its flexibility and applicability to open domain, such an approach might be considered as more robust than the template filling approach when applied to dialogue systems. In their approach, Inui et al. (2003), applied keyword matching in order to extract sample dialogues from a dialogue corpus, i.e., utterance-response pairs. After applying certain transfer or exchange rules, the sentence with maximum occurrence probability is given to the user as the system’s response. Other HCC systems, e.g. Wallace (2005), have applied the corpus based approach to natural language generation in order to retrieve system’s trivial dialogue responses. However, the creation of the hand crafted knowledge base, that is to say, a dialogue corpus, is a highly time consuming and hard to accomplish task1. Therefore we aim to automatically generate and evaluate a database of trivial dialogue phrases that could be implemented as knowledge base language generator for open domain dialogue systems, or chatbots. In this paper, we propose the automatic generation of trivial dialogue phrases through the application of a transfe</context>
</contexts>
<marker>Wallace, 2005</marker>
<rawString>Richard Wallace. 2005. A.l.i.c.e. artificial intelligence foundation. http://www.alicebot.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Weizenbaum</author>
</authors>
<title>Elizaa computer program for the study of natural language communication between man and machine.</title>
<date>1966</date>
<journal>Commun. ACM,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="1505" citStr="Weizenbaum, 1966" startWordPosition="229" endWordPosition="230">ry positive results. 1 Introduction Natural language generation has devoted itself to studying and simulating the production of written or spoken discourse. From the canned text approach, in which the computer prints out a text given by a programmer, to the template filling approach, in which predetermined templates are filled up to produce a desired output, the applications and limitations of language generation have been widely studied. Well known applications of natural language generation can be found in human-computer conversation (HCC) systems. One of the most famous HCC systems, ELIZA (Weizenbaum, 1966), uses the template filling approach to generate the system’s response to a user input. For a dialogue system, the template filling approach works well in certain situations, however due to the templates limitations, nonsense is produced easily. In recent research Inui et al. (2003) have used a corpus-based approach to language generation. Due to its flexibility and applicability to open domain, such an approach might be considered as more robust than the template filling approach when applied to dialogue systems. In their approach, Inui et al. (2003), applied keyword matching in order to extr</context>
</contexts>
<marker>Weizenbaum, 1966</marker>
<rawString>Joseph Weizenbaum. 1966. Elizaa computer program for the study of natural language communication between man and machine. Commun. ACM, 9(1):36–45.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>