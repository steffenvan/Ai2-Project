<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.997565333333333">
High Precision Analysis of NPs
with a Deep Processing
Grammar
</title>
<author confidence="0.969298">
António Branco
Francisco Costa
</author>
<affiliation confidence="0.96569">
Universidade de Lisboa (Portugal)
</affiliation>
<email confidence="0.991723">
email: Antonio.Branco@di.fc.ul.pt
</email>
<sectionHeader confidence="0.989174" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997228277777778">
In this paper we present LXGram, a general purpose grammar for the
deep linguistic processing of Portuguese that aims at delivering detailed
and high precision meaning representations. LXGram is grounded on the
linguistic framework of Head-Driven Phrase Structure Grammar (HPSG).
HPSG is a declarative formalism resorting to unification and a type sys-
tem with multiple inheritance. The semantic representations that LX-
Gram associates with linguistic expressions use the Minimal Recursion
Semantics (MRS) format, which allows for the underspecification of scope
effects. LXGram is developed in the Linguistic Knowledge Builder (LKB)
system, a grammar development environment that provides debugging
tools and efficient algorithms for parsing and generation. The implemen-
tation of LXGram has focused on the structure of Noun Phrases, and LX-
Gram accounts for many NP related phenomena. Its coverage continues
to be increased with new phenomena, and there is active work on ex-
tending the grammar’s lexicon. We have already integrated, or plan to
integrate, LXGram in a few applications, namely paraphrasing, treebank-
ing and language variant detection. Grammar coverage has been tested
on newspaper text.
</bodyText>
<page confidence="0.999639">
31
</page>
<note confidence="0.977139">
32 Branco and Costa
</note>
<sectionHeader confidence="0.993954" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998630607142857">
In this paper we present LXGram, a hand-built, general purpose computational gram-
mar for the deep linguistic processing of Portuguese, specially geared to high precision
processing of Noun Phrases. This grammar is based on the framework of Head-Driven
Phrase Structure Grammar (HPSG; Pollard and Sag (1994)), one of the most promi-
nent linguistic theories being used in natural language processing. Like several other
computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copes-
take et al. (2005)) for the representation of meaning.
LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copes-
take, 2002), a development environment for constraint-based grammars. This envi-
ronment provides a GUI, debugging tools and very efficient algorithms for parsing
and generation with the grammars developed there (Malouf et al., 2000; Carroll et al.,
1999).
Several broad-coverage grammars have been developed in the LKB. Currently, the
largest ones are for English (Copestake and Flickinger, 2000), German (Müller and
Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed
with the LKB are also supported by the PET parser (Callmeier, 2000), which allows
for faster parsing times due to the fact that the grammars are compiled into a binary
format in a first step. As the LKB grammars for other languages, LXGram is in active
development, and it is intended to be a broad-coverage, open-domain grammar for
Portuguese. At the same time, it produces detailed representations of meaning in
tandem with syntactic structures, making it useful for a wide range of applications.
In Section 2, we describe the framework foundations of the grammar. The major
design features of the grammar are introduced in Section 3. We talk about the coverage
of LXGram in Section 4. Section 5 presents some of the phenomena treated within
the NP domain and shows examples of implemented analyses relating to NP syntax
and semantics. In Section 6, results on the performance of the grammar are reported,
and in Section 7, we discuss applications where the grammar is or is being integrated.
Finally, the paper closes with concluding remarks in Section 8.
</bodyText>
<sectionHeader confidence="0.998484" genericHeader="introduction">
2 Foundations
</sectionHeader>
<bodyText confidence="0.999765666666667">
LXGram adopts the HPSG framework, a popular linguistic theory with a large body of
literature covering many natural language phenomena. These insights can be directly
incorporated in the implementation of a computational grammar.
</bodyText>
<subsectionHeader confidence="0.657686">
2.1 HPSG
</subsectionHeader>
<bodyText confidence="0.999674555555556">
HPSG resorts to a declarative formalism to model linguistic data. It employs a type
system (supporting multiple inheritance) and typed feature structures (recursive data
structures defining “has-a” relations) in order to describe the properties of linguistic
objects (words, phrases, rules). Unification of types and feature structures is central
to HPSG, used to ensure that the various elements have compatible properties. For
instance, the fact that a transitive verb takes an NP as its complement is captured in
HPSG by defining a lexical type for transitive verbs, say transitive-verb-lex(eme), with
constraints like the following (among others), presented in the Attribute-Value Matrix
(AVM) format widely employed in HPSG:
</bodyText>
<table confidence="0.9843065">
High Precision Analysis of NPs with a Deep Processing Grammar 33
transitive-verb-lex 
           
 * HEAD noun +
   &amp;quot; #  
  SYNSEM|LOCAL|CAT|VAL|COMPS LOCAL|CAT
   SPR hi   
 VAL COMPS hi
</table>
<bodyText confidence="0.997062166666667">
The NP complement of the verb is represented in this AVM as the value of the at-
tribute COMPS. This attribute takes a list as its value (indicated by the angle brackets).
In this case the sole element of this list describes an object with a HEAD feature of the
type noun and empty complements (the attribute COMPS) and specifier (the feature
SPR) (i.e. they have been saturated at the point where the verb combines with this
element), which is the HPSG description of an NP.
</bodyText>
<subsectionHeader confidence="0.989183">
2.2 MRS
</subsectionHeader>
<bodyText confidence="0.995526083333333">
Minimal Recursion Semantics (MRS) is used as the format of semantic representa-
tions that LXGram associates with expressions from Portuguese. MRS has several
properties that are interesting for applications. A relevant one is the use of pointers to
represent scope effects that are handled via recursion in traditional formal semantics.
This use of pointers (called handles) allows for the underspecification of scope rela-
tions, which avoids listing all scope possibilities for ambiguous sentences (although
they can still be computed on demand with the LKB machinery). This is a useful prop-
erty: scope does not need to be resolved in all applications (e.g. machine translation
does not require it), but at the same time scoped formulas can be obtained on demand
if required (e.g. for automated inference).
We provide an example MRS representation derived for the sentence “todas as
equipas podem vencer” (all teams can win) in Figure 1. This MRS describes the
</bodyText>
<equation confidence="0.99435178125">
 
_vencer_v_rel
 
  LBL h10
 , 

ARG0 e11
ARG1 x6

     
   
 + 
 
 
           
mrs
 LTOP h1 h
  INDEX e2 e
  
_todo_q_rel 
  
_poLd h8
er_v_rel
/ LBL h3 h_equipa_n_rel
RELS ( ARG0 x6 xLBL h7 hLB
\ , 
     ARG0 e2
 RSTR h5 h  ARG0 x6 ARG1 h9 h
 BODY h4 h
  / qeq qeq qeq \
HCONS ( HARG h1,HARG h5,HARG h9)
\LARG h8 LARG h7 LARG h10 /
</equation>
<figureCaption confidence="0.996557">
Figure 1: MRS for the sentence “Todas as equipas podem vencer” (all teams can win)
</figureCaption>
<bodyText confidence="0.964534">
two following scoped formulas, where the predicate _todo_q stands for a universal
quantifier:
</bodyText>
<listItem confidence="0.878247">
• _todo q(x6, equipa n(x6), poder v(e2, vencer v(e11,x6)))
• _poder_v(e2,_todo_q(x6,_equipa_n(x6),_vencer_v(e11,x6)))
34 Branco and Costa
</listItem>
<bodyText confidence="0.99965135">
The first reading is the one that says that each team has a chance to win, while the
second reading says that it is possible for there to be a situation in which all teams win
(false assuming common sense knowledge). A single MRS representation is obtained
for these two readings by instantiating the ARG1 feature of the relation _poder_v (can)
with the handle h9, which is related to the handle h10 labeling the relation _vencer_v
(win) via a qeq relation (equality modulo intervening quantifiers). This is the way of
saying that these two handles are the same (first reading) or that there is an intervening
generalized quantifier relation (second reading).
Semantic representations abstract from many grammatical and superficial details
of language, like word order, syntactic structure and morphology. As such, they are
very similar across different natural languages (modulo predicate names). This is also
true of MRS. Furthermore, semantic representations hide grammar implementation.
As such, they are the preferred grammar’s interface for applications, that do not need
any knowledge of the grammatical properties of Portuguese and may not need to look
at syntactic analysis.
The MRS format is also used with several other computational HPSGs, for other
languages. Several applications (e.g. Machine Translation) have been used with other
HPSGs that communicate with these grammars via the MRSs (Bond et al., 2004).
These applications can be easily integrated with grammars for different languages
that also use MRS: they are almost completely language independent.
</bodyText>
<sectionHeader confidence="0.997126" genericHeader="method">
3 Design Features
</sectionHeader>
<bodyText confidence="0.999748666666667">
Given the foundational options, LXGram adheres to a number of important design
features.
Bidirectionality LXGram is bidirectional. The formalism employed is completely
declarative. It can be used for parsing (yielding syntactic analyses and semantic rep-
resentations from natural language input) and also for generation (yielding natural
language from meaning representations). As such it can be useful for a wide range of
applications.
Precision LXGram aims at high precision of linguistic processing. Modulo bugs,
the grammar cannot parse ungrammatical input. Although this feature may have a
negative impact on robustness, it is an important aspect of the grammar when it is
used for generation, as it means it is not possible to generate ungrammatical strings.1
It is indeed possible to mark some rules and some lexical entries to only be used for
parsing and not for generation. In the configuration files for the LKB one can list these
rules and lexical items. We are currently using this feature in order to be able to parse
input that is not ungrammatical but is marked with respect to register, but preventing
the grammar from generating such strings.
Importantly, the fact that it cannot parse ungrammatical input also means that the
grammar will not produce impossible analyses for grammatical sentences.
Broad Coverage LXGram development is aimed at a broad coverage. We also
seek to make LXGram neutral with respect to regional variation as much as possi-
ble. Currently, the grammar accommodates both European Portuguese and Brazilian
</bodyText>
<footnote confidence="0.9861675">
1We believe that dealing with ill-formed input is best done via other means (rather than let the grammar
overgenerate so it can parse more), like partial parsing or the integration with/falling back to other tools.
</footnote>
<note confidence="0.366908">
High Precision Analysis of NPs with a Deep Processing Grammar 35
</note>
<bodyText confidence="0.997572291666667">
Portuguese. Aspects of variation that are accounted for include lexical differences
(merely affecting spelling or more substantial ones) as well as syntactic discrepancies
(e.g. definite articles before possessives, word order between clitic pronouns and the
verb).
Efficiency The processors on which LXGram runs (LKB, PET) are very efficient.
In addition, there are grammar engineering techniques that improve efficiency (e.g.
(Flickinger, 2000)) that are also exploited in our implementation.
Robustness The LKB and PET systems provide several ways to combine a grammar
with the output of shallow tools, like part-of-speech taggers. Such integration can
improve grammar coverage, as the grammar needs information about all words in the
input, and some words may be missing in the grammar’s lexicon. We have success-
fully combined LXGram with a part-of-speech tagger and a morphological analyzer
(more in Section 6). The grammar code includes mappings from the input format
(XML) to the feature structures that are manipulated by the grammar.
Availability A version of LXGram is publicly available at http://nlxgroup.di.
fc.ul.pt/lxgram. LXGram can be used by applications without any knowledge of
the grammar’s implementation or internal workings. The LKB allows for applications
to communicate with the grammar via sockets, accepting parser input in XML or raw
text and returning semantic representations in XML, for which a DTD is available. It
is also possible to automatically produce a list of all the predicates known by the gram-
mar together with their arity and argument types (from the lexicon and syntax rules),
that can be manually annotated with comments and examples. The predicates corre-
sponding to lexical items are however quite transparent once the naming conventions
that are used are explained.
</bodyText>
<sectionHeader confidence="0.999387" genericHeader="method">
4 Coverage
</sectionHeader>
<subsectionHeader confidence="0.999653">
4.1 Lexical Coverage
</subsectionHeader>
<bodyText confidence="0.999939222222222">
When one is using a lexicalist framework like HPSG, lexical coverage is a key issue
because all tokens in the input should be known by the grammar in order for the
grammar to produce a parse. Furthermore, the amount of information included in
the lexicon that is used by an HPSG is very large. Part-of-speech and morphological
information is not sufficient. For the correct assignment of semantic representations,
subcategorization frames as well as other information pertaining to semantics must
be correctly associated with every lexical item, something that cannot be known with
sufficient quality by just using shallower tools, like part-of-speech taggers.
In LXGram a hand-crafted lexicon containing several hundreds of nouns, adjectives
and verbs was developed. However, the manual creation of lexica with this amount
of information is time consuming and error prone. We are exploring methods to al-
leviate this problem. An option is to combine the grammar with shallower tools in
order to have access to some of the information needed and assume default values
for the information that cannot be obtained this way. We have already integrated
the grammar with a set of shallow tools (a part-of-speech tagger, a lemmatizer and a
morphological analyzer) in order to guess information about unknown words. Prelim-
inary results indicate an increase in coverage on unrestricted newspaper text from 2%
to 13%. Although this approach cannot guarantee correct semantic representations
</bodyText>
<note confidence="0.596665">
36 Branco and Costa
</note>
<bodyText confidence="0.998644">
(or even syntactic trees, since subcategorization frames constrain syntactic structure),
it can be useful in applications that only require some restricted amount of linguistic
information.
</bodyText>
<subsectionHeader confidence="0.989367">
4.2 Overall Grammatical Coverage
</subsectionHeader>
<bodyText confidence="0.9994135">
In order to get a quantitative overview of the grammar, it can be characterized as
follows:
</bodyText>
<listItem confidence="0.993932419354839">
• 24,484 lines of code, including comments and excluding the lexicon;
• 53 syntax rules;
• 40 lexical rules, mostly inflectional;
• 3,154 total types;
• 414 types for lexical items;
• 2,718 hand-built lexical entries.
For a qualitative overview, these are the linguistic phenomena covered so far:
• Declarative sentences
• Yes-no questions e.g.: “Portanto o Estado tem um gosto?” (So does the State
have preferences?)
• Imperative sentences e.g.: “Dá-me um desses bolos.” (Give me one of those
cakes)
• Some subcategorization frames of verbs, nouns and adjectives e.g.: “a Poló-
nia empatou com a França” (Poland tied with France); “eu já disse que pode ser
um dos mais baratos” (I told you already that it can be one of the cheapest);
“filho de um professor dos arredores de Viena” (son of a teacher from the out-
skirts of Vienna)
• Comparative constructions e.g.: “a vida é maior do que o cinema” (life is
larger than cinema)
• Noun phrase structure, including determiners, possessives, cardinal and
ordinal numerals, prepositional phrases, adjectives, etc. (examples in the
next section)
• Modification of verbal projections by prepositional and adverbial phrases
e.g.: “No CAPC termina hoje a exposição” (the exhibit ends today at CAPC);
• Relative clauses e.g.: “sete outros suspeitos que a polícia ainda procura” (seven
other suspects that the police are still looking for)
• Null subjects and objects e.g.: “Saímos depois do jantar.” ((We) left after
dinner); “Podemos comer lá perto.” (We can eat near there)
High Precision Analysis of NPs with a Deep Processing Grammar 37
• Floated Quantifiers e.g.: “os índices subiram todos” (the indices have all gone
up)
</listItem>
<bodyText confidence="0.9998064">
The development of the grammar is going on and this grammar is getting its cover-
age increased with important phenomena that are missing. In particular, for the near
future, we are working towards including more subcategorization frames for verbs,
nouns and adjectives, and implementing wh-questions, coordination and adverbial
subordination.
</bodyText>
<sectionHeader confidence="0.996284" genericHeader="method">
5 Noun Phrases
</sectionHeader>
<bodyText confidence="0.9986495">
A special design feature of LXGram is that it includes a comprehensive implementa-
tion of Portuguese Noun Phrase structure, covering:
</bodyText>
<listItem confidence="0.995683">
• Bare noun phrases (i.e. NPs lacking a determiner) e.g.: “boa gestão” (good
management); “imagens da bancada” (images of the seats)
• Determiners and predeterminers e.g.: “esta sua Ultima produção” (this last
production of his); “todos estes problemas” (all these problems); “todos os par-
tidos políticos” (all the political parties), “aquele tempo todo” (all that time)
• Word order constraints among NP elements e.g.: “as duas primeiras insti-
</listItem>
<bodyText confidence="0.987325875">
tuições” (the two first institutions); “os primeiros sete meses deste ano” (the
first seven months of this year); “sete outros suspeitos que a polícia ainda
procura” (seven other suspects that the police are still looking for); “os outros
três membros do conselho” (the other three members of the council); “os seus
dois primeiros anos polémicos na Casa Branca” (his first two polemic years
in the White House); “o primeiro grande conflito que aportava em Belém” (the
first great conflict that reached Berlin); “outro lugar qualquer” (any other place);
“um lugar qualquer” (any place); “qualquer outra solução” (any other solution)
</bodyText>
<listItem confidence="0.978536909090909">
• Prenominal and postnominal possessives e.g.: “o seu terceiro maior parceiro
comercial” (its third major commercial partner); “um adjunto seu que atendeu
ali o telefonema” (an assessor of his who answered the phone call there)
• Modification of adjectives e.g.: “os escritores mais importantes” (the most
important writers); “o discurso razoavelmente optimista” (the reasonably opti-
mistic speech)
• Missing nouns e.g.: “dois que são gémeos” (two who are twins)
• Word order between adjectives and complements of nouns e.g.: “o conhec-
imento essencial das pessoas” (the essential knowledge about people)
• Adjectives with the semantics of arguments of nouns e.g.: “o veto americano
à renovação do mandato” (the American veto to the renewal of the position)
</listItem>
<bodyText confidence="0.988162">
Precision was given a lot of attention. For instance, many items are constrained not
to appear more than once in a given NP (determiners, possessives, cardinals, ordinals,
etc.). Scope phenomena are also handled (motivated by semantics), as well as order
constraints. Agreement is enforced.
</bodyText>
<note confidence="0.725578">
38 Branco and Costa
</note>
<bodyText confidence="0.977446">
We present some examples of phenomena for which LXGram provides interesting
semantic representations and that we have not found in the literature pertaining to
implemented grammars.
</bodyText>
<subsectionHeader confidence="0.904591">
5.1 Floated Quantifiers
</subsectionHeader>
<bodyText confidence="0.754059">
The first example relates to floated quantifiers. For all the sentences in (1), which are
all grammatical in Portuguese, LXGram provides the MRS equivalent of
</bodyText>
<figure confidence="0.515974777777778">
all(x, price(x),will(go_up(x))):
(1) a. Todos os preços vão subir.
all the prices will go up
b. Os preços todos vão subir.
the prices all will go up
c. Os preços vão todos subir.
the prices will all go up
d. Os preços vão subir todos.
the prices will go up all
</figure>
<bodyText confidence="0.994294833333333">
In all of these cases we associate empty semantics to the definite article (“os”).
Semantic information is percolated around the syntactic trees so that the universal
quantifier, which can be realized at several different places, ends up being linked to
the semantics of the NP subject in the semantic representations for all these sentences.
We also make sure that definite articles always carry quantifier semantics when no
floated quantifier is present.
The implementation revolves around allowing floated quantifiers to attach to verbs,
resulting in verb-headed nodes that combine with NP subjects lacking quantifier se-
mantics. Raising verbs, like the form “vão” in this example, constrain their subject
according to the constraints of the subject of their VP complement. For instance, the
last example (1d) receives a syntactic analysis like the one described by the following
tree:
</bodyText>
<figure confidence="0.874973774193548">
&amp;quot; #
subj-head-phrase
SUBJ
❍
✟✟✟✟✟✟ ❍ ❍ ❍ ❍ ❍
 
head-comp-phrase
D E 
SUBJ 1
❍
✟✟✟✟✟ ❍ ❍ ❍ ❍
1
✟✟ ❍❍
Os
the
preços
prices
� D E~
SUBJ 1
vão
will
rSoated-quant-phrase
UBJ 1 NP�e,t�
✟✟✟ ❍ ❍ ❍
� D E~
SUBJ NP
subir
go up
todos
all
High Precision Analysis of NPs with a Deep Processing Grammar 39
</figure>
<bodyText confidence="0.999563111111111">
Here, NP abbreviates a feature structure that describes a noun phrase (of the se-
mantic type ((e,t),t)), and NP(e,t) abbreviates the constraints that describe an NP
introduced by a determiner lacking quantifier semantics (i.e. an NP with an MRS
representation that is similar to that of constituents with the the semantic type (e,t)).
In HPSG, the SUBJ feature encodes the constraints on the subject that a constituent
selects. We use a dedicated syntax rule to combine “subir” and “todos” (floated-quant-
phrase), that creates a node requiring an NP with the semantic type (e,t) as its subject.
The verb form “vão” is treated as a raising verb: in HPSG the syntactic requirements
on the subject of a raising verb are the same as the requirements on the subject of the
VP complement that that verb selects for. This is denoted by the boxed integers in this
tree (which represent unification).
In this example, the VP complement of “vão” is the phrase “subir todos”, as these
two constituents are combined via the head-comp-phrase rule (selection of comple-
ments is represented in a way similar to the selection of subjects, but via the feature
COMPS instead of the feature SUBJ). The subject of the head-comp-phrase is the sub-
ject of its head daughter (“vão”). The topmost node is the result of applying a syntactic
rule to project subjects to the left of their head (subj-head-phrase).
The example in (1c) is processed in a similar fashion:
</bodyText>
<figure confidence="0.968669214285714">
❍
✟✟✟✟✟✟✟ ❍ ❍ ❍ ❍ ❍ ❍
&amp;quot; #
subj-head-phrase
SUBJ ()
 
head-comp-phrase
D E 
SUBJ 2
❍
✟✟✟✟✟ ❍ ❍ ❍ ❍
2
✟✟ ❍❍
Os
the
preços
prices
rSoated-quant-phraseUBJ D 22NNP(e,t) E
� D E~
SUBJ 1
vão
will
� D E~
SUBJ 1 NP
subir
go up
todos
all
</figure>
<bodyText confidence="0.999625">
In this example, the complement of “vão” is the node spanning “subir”, which
selects for a quantified subject. The subject of the raising verb is accordingly also
a quantified NP. Here, the rule to project a floated quantifier applies lower than the
construction that projects complements, creating a node that requires a non-quantified
subject. The SUBJ feature of head-complement constructions comes from the head
daughter (the floated-quant-phrase node in this example). Therefore, the node pro-
duced by the head-comp-phrase rule also requires a non-quantified subject.
Note that the composition of semantics with MRS in based on the concatenation of
the RELS and HCONS lists associated to the various constituents and passing around
</bodyText>
<note confidence="0.679496">
40 Branco and Costa
</note>
<bodyText confidence="0.879032">
the values of the features LTOP and INDEX (see Figure 1). It is not based on function
application. The composition of semantics with MRS is quite flexible.
</bodyText>
<subsectionHeader confidence="0.994419">
5.2 Scope of Adjectives and Relative Clauses
</subsectionHeader>
<bodyText confidence="0.999925">
The second example that we show here relates to the semantic scope between different
elements of noun phrases. In particular, we can see a distinction in the interpretation
of the two following examples:
</bodyText>
<figure confidence="0.962708166666667">
(2) a. um possível médico chinês
a possible doctor Chinese
a possible Chinese doctor
b. um possível médico que é chinês
a possible doctor who is Chinese
a possible doctor who is Chinese
</figure>
<bodyText confidence="0.99737725">
In the first NP an entity is described as possibly being a Chinese doctor. The second
NP describes an entity as possibly being a doctor and certainly being Chinese. Ac-
cordingly, LXGram delivers slightly different semantic representations for these two
NPs. The first case produces something similar to
λP. a(x,possible(doctor(x) ∧chinese(x)),P(x)).
The second NP is treated along the lines of
λP. a(x,possible(doctor(x)) ∧chinese(x),P(x)).
These two different readings are derived simply by constraining the relative syntactic
scope of adjectives and relative clauses. Namely, LXGram forces prenominal adjec-
tives to attach higher than postnominal adjectives (2a) but lower than relative clauses
(2b). In this case, the scope differences in the semantic representations are simply
derived from the differences in syntactic scope:
</bodyText>
<figure confidence="0.98186025">
um
✟✟✟✟ ❍❍ ❍ ❍
que é chinês
✟✟ ❍
❍
possível médico
✟✟✟ ❍ ❍ ❍
um ✟✟✟ ❍ ❍ ❍
possível ✟✟ ❍ ❍
médico chinês
❍
✟✟✟✟✟ ❍❍ ❍ ❍
Of course, the following examples receive equivalent semantics:
(3) a. um médico chinês
a doctor chinese
a Chinese doctor
b. um médico que é chinês
a doctor who is Chinese
a doctor who is Chinese
High Precision Analysis of NPs with a Deep Processing Grammar 41
</figure>
<sectionHeader confidence="0.94129" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99996864">
Some evaluation experiments were conducted to test LXGram’s coverage. In one of
them, a corpus with newspaper text (self-reference) was used, with 145 sentences.
For this experiment, we used a part-of-speech tagger and a morphological analyzer
(self-reference) in order to guess some information about out-of-vocabulary words. A
default value was assumed for the missing subcategorization information (all unknown
verbs were treated as transitive verbs). The average sentence length was 22 words. In
this experiment, 13.1% of all sentences received at least one parse by the grammar.2
On the same test corpus, the average time it took for a sentence to parse was 1.1
seconds on a P4 machine at 3GHz. The average amount of memory required to analyze
a sentence was 145.5MB.
In another experiment, with 180,000 short sentences (5 to 9 words) selected ran-
domly from two newspaper corpora (CETEMPúblico and CETENFolha), LXGram
had achieved 26% coverage, using a similar approach to handle unknown words (self-
reference).
During the development of LXGram we maintain several test suites, consisting of
example sentences for the implemented phenomena. The test suites use a controlled
vocabulary. Also, several examples attest several phenomena, in order to test the
interaction of the different modules. They are very useful to test the syntax rules of
the grammar and the semantics that LXGram produces, and for regression testing. The
test suite for NPs contains 851 sentences (429 of which are negative examples, that
the grammar should not parse). The average sentence length is 5.3 words (2–16). On
this test suite LXGram has 100% coverage and 0% overgeneration. The average time
needed to analyze a sentence is 0.11 seconds, with an average memory requirement
of 15.5MB. Plotting parse time by sentence length, we see an approximately linear
increase in parse time with this test suite.
</bodyText>
<sectionHeader confidence="0.989699" genericHeader="evaluation">
7 Applications and Further Work
</sectionHeader>
<bodyText confidence="0.999964727272727">
We have used LXGram to automatically discriminate between texts written in Euro-
pean Portuguese and Brazilian Portuguese, with encouraging results, which match the
results obtained with other dialect detection methodologies. (self-reference).3
Additionally, we are working towards integrating it with an existing question an-
swering system (self-reference).4 This is in part the reason for the special focus on
NPs, as these constituents are often short answers to factoid questions.
Because the grammar is entirely bidirectional, a paraphraser is gained for free from
the implementation of LXGram: the grammar can simply be used to generate from the
semantic representations that it derives from an input sentence, thus producing para-
phrases of the textual input. We are also working to integrate the grammar, running
under this functionality, into the QA system.
</bodyText>
<footnote confidence="0.987663">
2Note that one of the HPSGs with the broadest coverage at the moment, the ERG, covers 17% of the
British National Corpus. The main cause of parse failure is out-of-vocabulary words.
3In particular, the results obtained with LXGram were quite similar to the results obtained with the
standard methods (based on character n-grams) that are used to identify the language in which a given text
is written, when used for this purpose.
4See (Bobrow et al., 2007) for a similar approach, where an LFG is employed in a question answering
system aiming at high precision.
</footnote>
<note confidence="0.836857">
42 Branco and Costa
</note>
<bodyText confidence="0.9999125">
On a par with the above lines of research, we are intensively using the grammar to
semi-automatically produce a treebank that contains syntactic representations and se-
mantic descriptions of the sentences in a newspaper corpus. LXGram has also served
in the past to implement and experiment with novel linguistic analyses of interesting
phenomena (self-reference). By making it freely available, we intend to encourage
this sort of experimentation also by other researchers. One can reap important bene-
fits from computationally implementing linguistic analyses: the debugging tools allow
for fast checking of correctness; the impact on other analyses that are already imple-
mented can be immediately assessed via regression testing, making it possible to test
the interaction between linguistic analyses for different phenomena; it is possible to
automatically compare different competing analyses for efficiency, based on test suites
or corpora.
</bodyText>
<sectionHeader confidence="0.999757" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9935548">
In this paper we presented LXGram, a computational grammar for the deep linguistic
processing of Portuguese. LXGram is implemented in a declarative formalism. It
can be used for analysis as well as generation. It produces high precision syntactic
analyses and semantic representations. LXGram supports the two main varieties of
Portuguese: European and Brazilian Portuguese. It is not dependent on a particular
domain or genre.
So far the focus of the implementation was on noun phrases and basic sentence
structure, a coverage that is being extended in ongoing work. The outcome of different
evaluation experiments shows scores that are in line with those obtained with similar
grammars for other languages.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997545975">
Bobrow, D. G., B. Cheslow, C. Condoravdi, L. Karttunen, T. H. King, R. Nairn,
V. de Paiva, C. Price, and A. Zaenen (2007). PARC’s bridge and question answer-
ing system. In T. H. King and E. M. Bender (Eds.), Proceedings of the GEAF07
Workshop, Stanford, CA, pp. 46–66. CSLI Publications.
Bond, F., S. Fujita, C. Hashimoto, K. Kasahara, S. Nariyama, E. Nichols, A. Ohtani,
T. Tanaka, and S. Amano (2004). The Hinoki treebank: Working toward text un-
derstanding. In S. Hansen-Schirra, S. Oepen, and H. Uszkoreit (Eds.), COLING
2004 5th International Workshop on Linguistically Interpreted Corpora, Geneva,
Switzerland, pp. 7–10. COLING.
Callmeier, U. (2000). PET — A platform for experimentation with efficient HPSG
processing techniques. Natural Language Engineering 6(1), 99–108. (Special
Issue on Efficient Processing with HPSG).
Carroll, J., A. Copestake, D. Flickinger, and V. Pozna´nski (1999). An efficient chart
generator for (semi-)lexicalist grammars. In Proceedings of the 7th European
Workshop on Natural Language Generation (EWNLG’99), Toulouse, pp. 86–95.
Copestake, A. (2002). Implementing Typed Feature Structure Grammars. Stanford:
CSLI Publications.
High Precision Analysis of NPs with a Deep Processing Grammar 43
Copestake, A. and D. Flickinger (2000). An open-source grammar development envi-
ronment and broad-coverage English grammar using HPSG. In Proceedings of the
Second conference on Language Resources and Evaluation (LREC-2000), Athens,
Greece.
Copestake, A., D. Flickinger, I. A. Sag, and C. Pollard (2005). Minimal Recursion
Semantics: An introduction. Journal of Research on Language and Computa-
tion 3(2–3), 281–332.
Flickinger, D. (2000). On building a more efficient grammar by exploiting types.
Natural Language Engineering 6(1), 15–28. (Special Issue on Efficient Processing
with HPSG).
Malouf, R., J. Carrol, and A. Copestake (2000). Efficient feature structure operations
without compilation. Natural Language Engineering 6(1), 29–46. (Special Issue
on Efficient Processing with HPSG).
Müller, S. and W. Kasper (2000). HPSG analysis of German. In W. Wahlster (Ed.),
Verbmobil: Foundations of Speech-to-Speech Translation (Artificial Intelligence
ed.)., pp. 238–253. Berlin Heidelberg New York: Springer-Verlag.
Pollard, C. and I. Sag (1994). Head-Driven Phrase Structure Grammar. Stanford:
Chicago University Press and CSLI Publications.
Siegel, M. and E. M. Bender (2002). Efficient deep processing of Japanese. In Pro-
ceedings of the 3rd Workshop on Asian Language Resources and International
Standardization. Coling 2002 Post-Conference Workshop, Taipei, Taiwan, pp. 31–
38.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.176749">
<title confidence="0.982115666666667">High Precision Analysis of NPs with a Deep Processing Grammar</title>
<author confidence="0.8645665">António Branco Francisco Costa</author>
<affiliation confidence="0.990243">Universidade de Lisboa (Portugal)</affiliation>
<abstract confidence="0.96859455">In this paper we present LXGram, a general purpose grammar for the deep linguistic processing of Portuguese that aims at delivering detailed and high precision meaning representations. LXGram is grounded on the linguistic framework of Head-Driven Phrase Structure Grammar (HPSG). HPSG is a declarative formalism resorting to unification and a type system with multiple inheritance. The semantic representations that LX- Gram associates with linguistic expressions use the Minimal Recursion Semantics (MRS) format, which allows for the underspecification of scope effects. LXGram is developed in the Linguistic Knowledge Builder (LKB) system, a grammar development environment that provides debugging tools and efficient algorithms for parsing and generation. The implementation of LXGram has focused on the structure of Noun Phrases, and LX- Gram accounts for many NP related phenomena. Its coverage continues to be increased with new phenomena, and there is active work on extending the grammar’s lexicon. We have already integrated, or plan to integrate, LXGram in a few applications, namely paraphrasing, treebanking and language variant detection. Grammar coverage has been tested on newspaper text. 31</abstract>
<intro confidence="0.472732">32 Branco and Costa</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>B Cheslow</author>
<author>C Condoravdi</author>
<author>L Karttunen</author>
<author>T H King</author>
<author>R Nairn</author>
<author>V de Paiva</author>
<author>C Price</author>
<author>A Zaenen</author>
</authors>
<title>PARC’s bridge and question answering system. In</title>
<date>2007</date>
<booktitle>Proceedings of the GEAF07 Workshop,</booktitle>
<pages>46--66</pages>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA,</location>
<marker>Bobrow, Cheslow, Condoravdi, Karttunen, King, Nairn, de Paiva, Price, Zaenen, 2007</marker>
<rawString>Bobrow, D. G., B. Cheslow, C. Condoravdi, L. Karttunen, T. H. King, R. Nairn, V. de Paiva, C. Price, and A. Zaenen (2007). PARC’s bridge and question answering system. In T. H. King and E. M. Bender (Eds.), Proceedings of the GEAF07 Workshop, Stanford, CA, pp. 46–66. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bond</author>
<author>S Fujita</author>
<author>C Hashimoto</author>
<author>K Kasahara</author>
<author>S Nariyama</author>
<author>E Nichols</author>
<author>A Ohtani</author>
<author>T Tanaka</author>
<author>S Amano</author>
</authors>
<title>The Hinoki treebank: Working toward text understanding. In</title>
<date>2004</date>
<booktitle>COLING 2004 5th International Workshop on Linguistically Interpreted Corpora,</booktitle>
<pages>7--10</pages>
<publisher>COLING.</publisher>
<location>Geneva,</location>
<contexts>
<context position="8376" citStr="Bond et al., 2004" startWordPosition="1365" endWordPosition="1368">. As such, they are very similar across different natural languages (modulo predicate names). This is also true of MRS. Furthermore, semantic representations hide grammar implementation. As such, they are the preferred grammar’s interface for applications, that do not need any knowledge of the grammatical properties of Portuguese and may not need to look at syntactic analysis. The MRS format is also used with several other computational HPSGs, for other languages. Several applications (e.g. Machine Translation) have been used with other HPSGs that communicate with these grammars via the MRSs (Bond et al., 2004). These applications can be easily integrated with grammars for different languages that also use MRS: they are almost completely language independent. 3 Design Features Given the foundational options, LXGram adheres to a number of important design features. Bidirectionality LXGram is bidirectional. The formalism employed is completely declarative. It can be used for parsing (yielding syntactic analyses and semantic representations from natural language input) and also for generation (yielding natural language from meaning representations). As such it can be useful for a wide range of applicat</context>
</contexts>
<marker>Bond, Fujita, Hashimoto, Kasahara, Nariyama, Nichols, Ohtani, Tanaka, Amano, 2004</marker>
<rawString>Bond, F., S. Fujita, C. Hashimoto, K. Kasahara, S. Nariyama, E. Nichols, A. Ohtani, T. Tanaka, and S. Amano (2004). The Hinoki treebank: Working toward text understanding. In S. Hansen-Schirra, S. Oepen, and H. Uszkoreit (Eds.), COLING 2004 5th International Workshop on Linguistically Interpreted Corpora, Geneva, Switzerland, pp. 7–10. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Callmeier</author>
</authors>
<title>PET — A platform for experimentation with efficient HPSG processing techniques.</title>
<date>2000</date>
<journal>Natural Language Engineering</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG).</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>99--108</pages>
<contexts>
<context position="2587" citStr="Callmeier, 2000" startWordPosition="378" endWordPosition="379"> in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Portuguese. At the same time, it produces detailed representations of meaning in tandem with syntactic structures, making it useful for a wide range of applications. In Section 2, we describe the framework foundations of the grammar. The major design features of the grammar are introduced in Section 3. We talk about the coverage of </context>
</contexts>
<marker>Callmeier, 2000</marker>
<rawString>Callmeier, U. (2000). PET — A platform for experimentation with efficient HPSG processing techniques. Natural Language Engineering 6(1), 99–108. (Special Issue on Efficient Processing with HPSG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>V Pozna´nski</author>
</authors>
<title>An efficient chart generator for (semi-)lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation (EWNLG’99),</booktitle>
<pages>86--95</pages>
<location>Toulouse,</location>
<marker>Carroll, Copestake, Flickinger, Pozna´nski, 1999</marker>
<rawString>Carroll, J., A. Copestake, D. Flickinger, and V. Pozna´nski (1999). An efficient chart generator for (semi-)lexicalist grammars. In Proceedings of the 7th European Workshop on Natural Language Generation (EWNLG’99), Toulouse, pp. 86–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars. Stanford: CSLI Publications. High Precision Analysis of NPs with a Deep Processing</title>
<date>2002</date>
<journal>Grammar</journal>
<volume>43</volume>
<contexts>
<context position="2038" citStr="Copestake, 2002" startWordPosition="296" endWordPosition="298">we present LXGram, a hand-built, general purpose computational grammar for the deep linguistic processing of Portuguese, specially geared to high precision processing of Noun Phrases. This grammar is based on the framework of Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag (1994)), one of the most prominent linguistic theories being used in natural language processing. Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the </context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake, A. (2002). Implementing Typed Feature Structure Grammars. Stanford: CSLI Publications. High Precision Analysis of NPs with a Deep Processing Grammar 43</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>An open-source grammar development environment and broad-coverage English grammar using HPSG.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="2422" citStr="Copestake and Flickinger, 2000" startWordPosition="350" endWordPosition="353">ge processing. Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Portuguese. At the same time, it produces detailed representations of meaning in tandem with syntactic structures, making it useful for a wide range of applications. In </context>
</contexts>
<marker>Copestake, Flickinger, 2000</marker>
<rawString>Copestake, A. and D. Flickinger (2000). An open-source grammar development environment and broad-coverage English grammar using HPSG. In Proceedings of the Second conference on Language Resources and Evaluation (LREC-2000), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>I A Sag</author>
<author>C Pollard</author>
</authors>
<title>Minimal Recursion Semantics: An introduction.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation</journal>
<volume>3</volume>
<issue>2</issue>
<pages>281--332</pages>
<contexts>
<context position="1915" citStr="Copestake et al. (2005)" startWordPosition="276" endWordPosition="280">nguage variant detection. Grammar coverage has been tested on newspaper text. 31 32 Branco and Costa 1 Introduction In this paper we present LXGram, a hand-built, general purpose computational grammar for the deep linguistic processing of Portuguese, specially geared to high precision processing of Noun Phrases. This grammar is based on the framework of Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag (1994)), one of the most prominent linguistic theories being used in natural language processing. Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars devel</context>
</contexts>
<marker>Copestake, Flickinger, Sag, Pollard, 2005</marker>
<rawString>Copestake, A., D. Flickinger, I. A. Sag, and C. Pollard (2005). Minimal Recursion Semantics: An introduction. Journal of Research on Language and Computation 3(2–3), 281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG).</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>15--28</pages>
<contexts>
<context position="2422" citStr="Flickinger, 2000" startWordPosition="352" endWordPosition="353"> Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Portuguese. At the same time, it produces detailed representations of meaning in tandem with syntactic structures, making it useful for a wide range of applications. In </context>
<context position="10818" citStr="Flickinger, 2000" startWordPosition="1740" endWordPosition="1741">generate so it can parse more), like partial parsing or the integration with/falling back to other tools. High Precision Analysis of NPs with a Deep Processing Grammar 35 Portuguese. Aspects of variation that are accounted for include lexical differences (merely affecting spelling or more substantial ones) as well as syntactic discrepancies (e.g. definite articles before possessives, word order between clitic pronouns and the verb). Efficiency The processors on which LXGram runs (LKB, PET) are very efficient. In addition, there are grammar engineering techniques that improve efficiency (e.g. (Flickinger, 2000)) that are also exploited in our implementation. Robustness The LKB and PET systems provide several ways to combine a grammar with the output of shallow tools, like part-of-speech taggers. Such integration can improve grammar coverage, as the grammar needs information about all words in the input, and some words may be missing in the grammar’s lexicon. We have successfully combined LXGram with a part-of-speech tagger and a morphological analyzer (more in Section 6). The grammar code includes mappings from the input format (XML) to the feature structures that are manipulated by the grammar. Ava</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Flickinger, D. (2000). On building a more efficient grammar by exploiting types. Natural Language Engineering 6(1), 15–28. (Special Issue on Efficient Processing with HPSG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malouf</author>
<author>J Carrol</author>
<author>A Copestake</author>
</authors>
<title>Efficient feature structure operations without compilation.</title>
<date>2000</date>
<journal>Natural Language Engineering</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG).</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>29--46</pages>
<contexts>
<context position="2257" citStr="Malouf et al., 2000" startWordPosition="326" endWordPosition="329">mework of Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag (1994)), one of the most prominent linguistic theories being used in natural language processing. Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Port</context>
</contexts>
<marker>Malouf, Carrol, Copestake, 2000</marker>
<rawString>Malouf, R., J. Carrol, and A. Copestake (2000). Efficient feature structure operations without compilation. Natural Language Engineering 6(1), 29–46. (Special Issue on Efficient Processing with HPSG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Müller</author>
<author>W Kasper</author>
</authors>
<title>HPSG analysis of German. In</title>
<date>2000</date>
<booktitle>Verbmobil: Foundations of Speech-to-Speech Translation (Artificial Intelligence ed.).,</booktitle>
<pages>238--253</pages>
<editor>W. Wahlster (Ed.),</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin Heidelberg New York:</location>
<contexts>
<context position="2456" citStr="Müller and Kasper, 2000" startWordPosition="355" endWordPosition="358">tional HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Portuguese. At the same time, it produces detailed representations of meaning in tandem with syntactic structures, making it useful for a wide range of applications. In Section 2, we describe the framewo</context>
</contexts>
<marker>Müller, Kasper, 2000</marker>
<rawString>Müller, S. and W. Kasper (2000). HPSG analysis of German. In W. Wahlster (Ed.), Verbmobil: Foundations of Speech-to-Speech Translation (Artificial Intelligence ed.)., pp. 238–253. Berlin Heidelberg New York: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar. Stanford:</title>
<date>1994</date>
<publisher>Chicago University Press and CSLI Publications.</publisher>
<contexts>
<context position="1714" citStr="Pollard and Sag (1994)" startWordPosition="247" endWordPosition="250">with new phenomena, and there is active work on extending the grammar’s lexicon. We have already integrated, or plan to integrate, LXGram in a few applications, namely paraphrasing, treebanking and language variant detection. Grammar coverage has been tested on newspaper text. 31 32 Branco and Costa 1 Introduction In this paper we present LXGram, a hand-built, general purpose computational grammar for the deep linguistic processing of Portuguese, specially geared to high precision processing of Noun Phrases. This grammar is based on the framework of Head-Driven Phrase Structure Grammar (HPSG; Pollard and Sag (1994)), one of the most prominent linguistic theories being used in natural language processing. Like several other computational HPSGs, LXGram uses Minimal Recursion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars </context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, C. and I. Sag (1994). Head-Driven Phrase Structure Grammar. Stanford: Chicago University Press and CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siegel</author>
<author>E M Bender</author>
</authors>
<title>Efficient deep processing of Japanese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization. Coling 2002 Post-Conference Workshop,</booktitle>
<pages>31--38</pages>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="2495" citStr="Siegel and Bender, 2002" startWordPosition="361" endWordPosition="364">sion Semantics (MRS; Copestake et al. (2005)) for the representation of meaning. LXGram is developed in the Linguistic Knowledge Builder (LKB) system (Copestake, 2002), a development environment for constraint-based grammars. This environment provides a GUI, debugging tools and very efficient algorithms for parsing and generation with the grammars developed there (Malouf et al., 2000; Carroll et al., 1999). Several broad-coverage grammars have been developed in the LKB. Currently, the largest ones are for English (Copestake and Flickinger, 2000), German (Müller and Kasper, 2000) and Japanese (Siegel and Bender, 2002). The grammars developed with the LKB are also supported by the PET parser (Callmeier, 2000), which allows for faster parsing times due to the fact that the grammars are compiled into a binary format in a first step. As the LKB grammars for other languages, LXGram is in active development, and it is intended to be a broad-coverage, open-domain grammar for Portuguese. At the same time, it produces detailed representations of meaning in tandem with syntactic structures, making it useful for a wide range of applications. In Section 2, we describe the framework foundations of the grammar. The majo</context>
</contexts>
<marker>Siegel, Bender, 2002</marker>
<rawString>Siegel, M. and E. M. Bender (2002). Efficient deep processing of Japanese. In Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization. Coling 2002 Post-Conference Workshop, Taipei, Taiwan, pp. 31– 38.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>