<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9945575">
Categorial Type Logic meets Dependency Grammar to annotate
an Italian Corpus
</title>
<note confidence="0.640540666666667">
R. Bernardi
KRDB,
Free University of Bolzano Bozen,
</note>
<address confidence="0.503677">
P.zza Domenicani, 3
39100 Bolzano Bozen,
Italy,
</address>
<email confidence="0.98728">
bernardi@inf.unibz.it
</email>
<author confidence="0.858216">
A. Bolognesi and F. Tamburini
</author>
<affiliation confidence="0.9120855">
CILTA,
University of Bologna,
</affiliation>
<address confidence="0.774371333333333">
P.zza San Giovanni in Monte, 4,
I-40124, Bologna,
Italy,
</address>
<email confidence="0.997752">
{bolognesi,tamburini}@cilta.unibo.it
</email>
<author confidence="0.551816">
M. Moortgat
</author>
<affiliation confidence="0.527264">
UiL OTS,
Utrecht University,
</affiliation>
<address confidence="0.920218666666667">
Trans 10,
3512 JK, Utrecht,
The Netherlands
</address>
<email confidence="0.993431">
Moortgat@phil.uu.nl
</email>
<sectionHeader confidence="0.997532" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9882363">
In this paper we present work in progress on the
annotation of an Italian Corpus (CORIS) devel-
oped at CILTA (University of Bologna). We in-
duce categorial type assignments from a depen-
dency treebank (Torino University treebank,
TUT) and use the obtained categories with an-
notated dependency relations to study the dis-
tributional behavior of Italian words and reach
an empirically founded part-of-speech classifica-
tion.
</bodyText>
<sectionHeader confidence="0.999391" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99778268">
The work reported on here is part of a project1
aimed at annotating the CORIS/CODIS 100-
million-words synchronic corpus of contempo-
rary Italian with linguistic information: first
part-of-speech tagging for the complete corpus,
and in a later stage syntactic analysis for a sub-
corpus.
We have been investigating existing Italian
treebanks in order to assess their potential use-
fulness for bootstrapping the CORIS/CODIS an-
notation tasks. We are aware of two such tree-
banks that are relevant to our purposes: the
TUT corpus developed at Torino University, and
ISST (Italian Syntactic-Semantic treebank) de-
veloped under the national program SI-TAL by
a consortium of companies and research centers
coordinated by the “Consorzio Pisa Ricerche”
(CPR)2.
ISST is a multi-layered corpus, annotated at
the syntactic and lexico-semantic levels. A user
interface is provided to explore the corpus. The
ISST corpus is rather competitive in terms of
size: it counts 305,547 word tokens (Monte-
magni et al., 2003). A drawback is that the
corpus is not publicly available yet. The TUT
</bodyText>
<footnote confidence="0.87892125">
1The project is funded under the FIRB 2001 action.
2The parnters of the consortium were: ILC-
CNR/CPR, Venice University/CVR, ITC-IRST, “Tor
Vergata” University/CERTIA, and Synthema.
</footnote>
<bodyText confidence="0.9998454">
corpus is rather small, consisting only of 38,653
words. There is no user interface for TUT but
the corpus is downloadable (http://www.di.
unito.it/~tutreeb/). Despite its small size,
TUT can serve as a training corpus for creating
larger annotated resources.
Our goal is to annotate CORIS with part-of-
speech (PoS) tags and semi-automatically build
a treebank for a fragment of it. To achieve this
two-fold task we start from TUT exploiting its
information on dependency relations. We are
still in a preliminary phase of the project and
so far attention has been focused on the first
task. However, the work done in this phase is
expected to play a role in our second task too.
In Section 2, we will describe in more detail
the problems which arise when working out the
first task. In Section 3, we briefly introduce the
formalisms we work with. In Section 4, we ex-
plain how we encode dependency relations into
categorial type assignments (CTAs), and how we
automatically induce these types from TUT de-
pendency structures. Finally, in Section 5 we
draw some preliminary conclusions and briefly
describe our action list.
</bodyText>
<sectionHeader confidence="0.927585" genericHeader="introduction">
2 PoS tagging for Italian
</sectionHeader>
<bodyText confidence="0.999067115384616">
Before embarking on our first task, we have
studied the current situation with respect to
PoS tagging for Italian. Italian is one of the
languages for which a set of annotation guide-
lines has been developed in the context of the
EAGLES project (Expert Advisory Group on
Language Engineering Standards (Monachini,
1995)). Several research groups have worked on
PoS annotation in practice (for example, Torino
University, Xerox and Venice University).
We have compared the tag sets used by these
groups with Monachini’s guidelines. From this
comparison, it results that though there is a
general agreement on the main parts of speech
to be used3, considerable divergence exists when
it comes to the actual classification of Italian
words with respect to these main PoS classes.
The classes for which differences of opinion are
most evident are adjectives, determiners and
adverbs. For instance, words like molti (tr.
many) have been classified as “indefinite deter-
miners” by Monachini, “plural quantifiers” by
Xerox, “indefinite adjectives” by the Venice and
Turin groups. This simple example shows that
the choice of PoS tags is already influenced by
the linguistic theory adopted in the background.
This theoretical bias will then influence the kind
of conclusions one can draw from the annotated
corpus.
Our aim is to derive an empirically founded
PoS classification, making no a priori assump-
tions about the PoS classes to be distinguished.
Our background assumptions are minimal and,
we hope, uncontroversial: we assume that
we have access to head-dependent (H-D) and
functor-argument (F-A) relations in our mate-
rial. We encode the H-D and F-A information
into categorial type formulas. These formulas
then serve as “labels/tags” from which we ob-
tain the desired empirically founded PoS classi-
fication by means of a clustering algorithm.
To bootstrap the process of type induction,
we transform the TUT corpus into a simpli-
fied dependency treebank. The transformation
keeps the bare dependency relations but re-
moves the more theory-laden annotation. In
Section 4, we describe how we use the simpli-
fied dependency treebank for our distributional
study of Italian PoS classification. First, we
briefly look at H-D and F-A relations as they
occur in the TUT corpus and in Categorial Type
Logic (CTL).
</bodyText>
<sectionHeader confidence="0.7970765" genericHeader="method">
3 Dependency and
functor-argument relations
</sectionHeader>
<subsectionHeader confidence="0.999972">
3.1 Dependency structures in TUT
</subsectionHeader>
<bodyText confidence="0.954759714285714">
The Turin University Treebank (TUT) is a cor-
pus of Italian sentences annotated by specifying
relational structures augmented with morpho-
syntactic information and semantic role (hence-
forth ARS) in a monostratal dependency-based
representation. The treebank in its current re-
lease includes 38,653 words and 1,500 sentences
</bodyText>
<tableCaption confidence="0.837408">
3The standard classification consists of nouns, verbs,
adjectives, determiners, articles, adverbs, prepositions,
conjunctions, numerals, interjections, punctuation and
a class of residual items which differs from project to
project.
from the Italian civil law code, the national
newspapers La Stampa and La Repubblica, and
from various reviews, newspapers, novels, and
academic papers.
</tableCaption>
<bodyText confidence="0.9282478">
The ARS schema consists of i) morpho-
syntactic, ii) functional-syntactic and iii) se-
mantic components, specifying part-of-speech,
grammatical relations, and thematic role infor-
mation, respectively. The reader is referred
to (Bosco, 2003) for a detailed description of the
TUT annotation schema. An example is given
below (tr. “The first steps have not been encour-
aging”). In this example, the node TOP-VERB is
the root of the whole structure4.
</bodyText>
<figure confidence="0.9733323125">
************** FRASE ALB-71 **************
1 I (IL ART DEF M PL)
[6;VERB-SUBJ]
2 primi (PRIMO ADJ ORDIN M PL)
[3;ADJC+ORDIN-RMOD]
3 approcci (APPROCCIO NOUN COMMON M PL)
[1;DET+DEF-ARG]
4 non (NON ADV NEG)
[6;ADVB-RMOD]
5 sono (ESSERE VERB AUX IND PRES INTR 3 PL)
[6;AUX+TENSE]
6 stati (ESSERE VERB MAIN PART PAST INTR PL M)
[0;TOP-VERB]
7 esaltanti (ESALTANTE ADJ QUALIF ALLVAL PL)
[6;VERB-PREDCOMPL+SUBJ]
8 . (#\. PUNCT) [6;END]
</figure>
<bodyText confidence="0.9902205">
Because we are interested in extracting
dependency relations, we can focus on the
functional-syntactic component of the TUT an-
notation, where information relating to gram-
matical relations (heads and dependents) is en-
coded.
The TUT annotation schema for depen-
dents makes a primary distinction between
(a) functional and (b) non-functional tags,
for dependents that can and that can-
not be assigned thematic roles, respectively.
These two classes are further divided into
(a’) arguments (ARG) and modifiers (MOD)
and (b’), AUX, COORDINATOR, INTERJECTION,
CONTIN, EMPTYCOMPL, EMPTYLOC, SEPARATOR
and VISITOR5; and furthermore, the arguments
</bodyText>
<footnote confidence="0.94749225">
4The top nodes used in TUT are TOP-VERB,
TOP-NOUN, TOP-CONJ, TOP-ART, TOP-NUM, TOP-PRON,
TOP-PHRAS and TOP-PREP
5The labels that require some explanation are: (i)
</footnote>
<bodyText confidence="0.92693825">
CONTIN, (ii) EMPTYCOMPL, (iii) EMPTYLOC and (iv) VISITOR.
They are used for expressions that (i) introduce a part
of an expression with a non-compositional interpreta-
tion (e.g. locative or idiomatic expressions and denom-
inative structures: “Arriv`o [prima]H [de]D ll’alba”, lit.
tr. “(She) arrived ahead of the daybreak”); (ii) link a re-
(ARG) and modifiers (MOD) are sub-divided as fol-
lowing
</bodyText>
<figure confidence="0.52377525">
ARG
SUBJ OBJ INDOBJ INDCOMPL PREDCOMPL
MODIFIER
RMOD
</figure>
<sectionHeader confidence="0.757129" genericHeader="method">
RELCLR RMODPRED
</sectionHeader>
<subsectionHeader confidence="0.996292">
3.2 Categorial functor-argument
structures
</subsectionHeader>
<bodyText confidence="0.99972896">
Categorial Type Logic (CTL) (Moortgat, 1997)
is a logic-based formalism belonging to the fam-
ily of Categorial Grammars (CG). In CTL, the
type-forming operations of CG are viewed as
logical connectives. As the slogan “Parsing-
as-Deduction” suggests, such a view makes it
possible to do away with combinatory syn-
tactic rules altogether; establishing the well-
formedness of an expression becomes a process
of deduction in the logic of the type-forming
connectives.
The basic distinction expressed by the cat-
egorial type formulas is the Fregean opposi-
tion between complete and incomplete expres-
sions. Complete expressions are categorized by
means of atomic type formulas; grammatical-
ity judgements for expressions with an atomic
type do not require further contextual informa-
tion. Typical examples of atomic types would
be ‘sentence’ (s) and ‘noun’ (n). Incomplete ex-
pressions are categorized by means of fractional
type formulas; the denominators of these frac-
tions indicate the material that has to be found
in the context in order to obtain a complete ex-
pression of the type of the numerator.
</bodyText>
<construct confidence="0.522447333333333">
Definition 3.1 (Fractional type formulas)
Given a set of basic types ATOM, the set of
types TYPE is the smallest set such that:
</construct>
<listItem confidence="0.920649333333333">
i. if A ∈ ATOM, then A ∈ TYPE;
ii. if A and B ∈ TYPE, then A/B and
B\A ∈ TYPE.
</listItem>
<bodyText confidence="0.9992095">
There are different ways of presenting valid
type computations. In a Natural Deduction for-
mat, we write F ` A for a demonstration that
flexive personal pronoun with particular verbal head (e.g.
“La porta [si]D [apre]H”, lit. tr. “the door (it) opens”);
(iii) link a pronoun with a verbal head introducing a sort
of metaphorical location of the head (e.g. “In Albania
[ci]D [sono]H molti problemi”, lit. tr. “In Albany there
are many problems”.); (iv) mark the extraction of a part
of a structure (e.g. “Cosidevi vedere questo argomento”,
lit. tr. “This way (you) must see this topic”).
the structure F has the type A. The statement
A ` A is axiomatic. Each of the connectives /
and \ has an Elimination rule and an Introduc-
tion rule. Below, we give these inference rules
for / (incompleteness to the right). The cases
for \ (incompleteness to the left) are symmetric.
Given structures F and Δ of types A/B and B
respectively, the Elimination rule builds a com-
pound structure F ◦Δ of type A. The Introduc-
tion rule allows one to take apart a compound
structure F◦B into its immediate substructures.
</bodyText>
<equation confidence="0.9956305">
F ` A/B Δ ` B F ◦ B ` A
F ◦ Δ ` A /E F ` A/B /I
</equation>
<bodyText confidence="0.986727684210526">
Notice that the language of fractional types
is essentially higher-order: the denominator of
a fraction does not have to be atomic, but can
itself be a fraction. The Introduction rules are
indispensable if one is interested in capturing
the full set of theorems of the type calculus.
Classical CG (in the style of Ajdukiewicz and
Bar-Hillel) uses only the Elimination rules, and
hence has restricted inferential capacities. It is
impossible in classical CG to obtain the validity
A ` B/(A\B), for example. Still, the classi-
cal CG perspective will be useful to realize our
aim of automatically inducing type assignments
from structured data obtained from the TUT
corpus thanks to the type resolution algorithm
explained below.
Type inference algorithms for classical CG
have been studied by (Buszkowski and Penn,
1990). The structured data needed by their
type inference algorithms are so-called functor-
argument structures (fa-structures). An fa-
structure for an expression is a binary branching
tree; the leaf nodes are labeled by lexical expres-
sions (words), the internal nodes by one of the
symbols 4 (for structures with the functor as
the left daughter) or No. (for structures with the
functor as the right daughter).
To assign types to the leaf nodes of an fa-
structure, one proceeds in a top-down fashion.
The type of the root of the structure is fixed (for
example: s). Compound structures are typed as
follows:
- to type a structure F 4 Δ as A, type F as
A/B and Δ as B;
- to type a structure F No. Δ as A, type F as
B and Δ as B\A.
If a word occurs in different structural environ-
ments, the typing algorithm will produce dis-
</bodyText>
<sectionHeader confidence="0.9768415" genericHeader="method">
APPOSITION
RELCLA
</sectionHeader>
<bodyText confidence="0.9931814">
tinct types. The set of type assignments to a
word can be reduced by factoring: one identi-
fies type assignments that can be unified. For
an example, compare the structured input be-
low:
</bodyText>
<figure confidence="0.7694474">
a. Claudia I parla
b. Claudia I (parla I bene)
Assuming a goal type s, from (a) we obtain the
assignments
Claudia: A, parla : A\s
and from (b)
Claudia: C, parla : B, bene: B\(C\s)
Factoring leads to the identifications A = C,
B = (A\s), producing for “bene” the modifier
type (A\s)\(A\s).
</figure>
<subsectionHeader confidence="0.8588005">
3.3 From TUT dependency structures
to categorial types
</subsectionHeader>
<bodyText confidence="0.994758866666667">
To accomplish our aims, we will have an oc-
casion to use two extensions of the basic cate-
gorial machinery outlined in the section above:
a generalization of the type language to multi-
ple modes of composition, and the addition of
structural rules of inference to the logical rules
of slash Elimination and Introduction.
Multimodal composition The intuitions
underlying the distinction between heads and
dependents in Dependency Grammars (DG) and
between functors and arguments in CG often
coincide, but there are also cases where they
diverge (Venneman, 1977). In the particu-
lar case of the TUT annotation schema, we
see that for all instances of dependents la-
beled as ARG (or one of its sublabels), the
DG head/dependent articulation coincides with
the CG functor/argument asymmetry. But for
DG modifiers, or dependents without thematic
roles of the class AUX (auxiliary)6 there is a
mismatch between dependency structure and
functor-argument structure. Modifiers would be
functors in terms of their categorial type: func-
tors where the numerator and the denominator
are identical. This makes them into ‘identities’
for the fractional multiplication, which explains
their optionality and the possibility of iteration.
AUX elements in DG would count as morpholog-
ical modifiers of the head verbs. From the CG
point of view, they would be typed as functors
</bodyText>
<footnote confidence="0.791308">
6And also COORDINATOR, INTERJECTION.
</footnote>
<bodyText confidence="0.999746225">
with non-identical numerator and denomina-
tor, distinguishing them that way from optional
modifiers, and capturing the fact that they are
indispensable to build a complete grammatical
structure.
To reconcile the competing demands of the
head-dependent and functor-argument classifi-
cation, we make use of the type calculus pro-
posed in (Moortgat and Morrill, 1991), which
treats dependency and functor-argument rela-
tions as two orthogonal dimensions of linguistic
organization. Instead of one composition oper-
ation o, the system of (Moortgat and Morrill,
1991) has two: ol for structures where the left
daughter is the head, and or for right-headed
structures. The two composition operations
each have their slash and backslash operations
for the typing of incomplete expressions:
- A/lB: a functor looking for a B to the right
to form an A; the functor is the head, the
argument the dependent;
- A/rB: a functor looking for a B to the right
to form an A; the argument is the head, the
functor the dependent;
- B\lA: a functor looking for a B to the left
to form an A; the argument is the head,
the functor the dependent;
- B\rA: a functor looking for a B to the left
to form an A; the functor is the head, the
argument the dependent.
The type inference algorithm of (Buszkowski
and Penn, 1990) can be straightforwardly
adapted to the multimodal situation. The inter-
nal nodes of the fa-structures now are labeled
with a fourfold distinction: as before, the tri-
angle points to the functor daughter of a con-
stituent; in the case of the black triangle, the
functor daughter is the head constituent, in the
case of the white triangle, the functor daughter
is the dependent.
</bodyText>
<construct confidence="0.5013296">
ad ah fd fh
fh J
fd
ah
ad
</construct>
<bodyText confidence="0.9552545">
The type-inference clauses can be adapted ac-
cordingly.
- to type a structure Γ J Δ as A, type Γ as
A/lB and Δ as B;
</bodyText>
<equation confidence="0.742048">
C
B
I
</equation>
<bodyText confidence="0.988930913043478">
- to type a structure Γ a Δ as A, type Γ as
A/rB and Δ as B.
- to type a structure Γ No. Δ as A, type Δ as
B\rA and Γ as B;
- to type a structure Γ D Δ as A, type Δ as
B\lA and Γ as B.
Structural reasoning The dependency rela-
tions in the TUT corpus abstract from surface
word order. When we induce categorial type
formulas from these dependency relations, as we
will see in Section 4.1, the linear order imposed
by ’/’ and ’\’ in the obtained formulas will not
always be compatible with the observable sur-
face order. Incompatibilities will arise, specif-
ically, in the case of non-projective dependen-
cies. Where such mismatches occur, the induced
types will not be immediately useful for parsing
— the longer term subtask of the project dis-
cussed here.
To address this issue, we can extend the in-
ference rules of our categorial logic with struc-
tural rules. The general pattern of these rules
is: infer Γ&apos; �- A from Γ �- A, where Γ&apos; is some
rearrangement of the constituents of Γ. These
rules, in other words, characterize the structural
deformations under which type assignment is
preserved. Structural rules can be employed
in two ways in CTL (see (Moortgat, 2001) for
discussion). In an on-line use, they actually
manipulate structural configurations during the
parsing process. Such on-line use can be very
expensive computationally. Used off-line, they
play a role complementary to the factoring op-
eration, producing a number of derived lexical
type-assignments from some canonical assign-
ment. With the derived assignments, parsing
can then proceed without altering the surface
structure.
As indicated in the introduction, the use of
CTL in the construction of a treebank for a part
of the CILTA corpus belongs to a future phase
of our project. For the purposes of this paper
we must leave the exact nature of the required
structural rules, and the trade-off between off-
line and on-line uses, as a subject for further
research.
</bodyText>
<sectionHeader confidence="0.9831555" genericHeader="method">
4 A distributional study of Italian
part-of-speech tagging
</sectionHeader>
<bodyText confidence="0.830351272727273">
In order to annotate the CORIS corpus with a
theory-neutral set of PoS tags, we plan to carry
out a distributional study of its lexicon.
Early approaches to this problem were based
on the hypothesis that if two words are syn-
tactically and semantically different, they will
appear in different contexts. There are a num-
ber of studies that, starting from this hypoth-
esis, have built automatic or semi-automatic
procedures for clustering words (Brill and Mar-
cus, 1992; Pereira et al., 1993; Martin et al.,
1998), especially in the field of cognitive sci-
ences (Redington et al., 1998; Gobet and Pine,
1997; Clark, 2000). They examine the distribu-
tional behaviour of some target words, compar-
ing the lexical distribution of their respective
collocates using quantitative measures of distri-
butional similarity (Lee, 1999).
In (Brill and Marcus, 1992) it is given a semi-
automatic procedure that, starting from lexical
statistical data collected from a large corpus,
aims to arrange target words in a tree (more
precisely a dendrogram), instead of clustering
them automatically. This procedure requires a
linguistic examination of the resulting tree, in
order to identify the word classes that are most
appropriate to describe the phenomenon under
investigation. In this sense, they use a semi-
automatic word-class generator method.
A similar procedure has been applied on Ital-
ian in (Tamburini et al., 2002). The novelty of
this work is that it derives the distributional in-
formation on words from a very basic set of PoS
tags, namely nouns, verbs and adjectives. This
method, completely avoiding the sparseness of
the data affecting Brill and Marcus’ method,
uses general information about the distribution
of lexical words to study the internal subdivi-
sions of the set of grammatical words, and re-
sults more stable than the method based only
on lexical co-occurrence.
The main drawback of these techniques is the
limited context of analysis. Collecting informa-
tion from a defined context, typically two or
three words will invariably miss syntactic de-
pendencies longer than the context interval. To
overcome this problem we propose to exploit the
expressivity of CTAs (with encoded core depen-
dency relations, as we saw in the section above)
by applying the clustering algorithms on them.
Below we sketch how we intend to induce CTAs
from the TUT dependency treebank, and the
clustering method we plan to implement. The
whole procedure can be summarized by the pic-
ture below.
</bodyText>
<figure confidence="0.46427375">
Treebank conversion
−−−−−−−→ CTL structures
↓ type resolution
PoS tagsetclustering ←−−−−−−Categorial Types
</figure>
<subsectionHeader confidence="0.997609">
4.1 Inducing categorial types from TUT
</subsectionHeader>
<bodyText confidence="0.999576294117647">
The first step is to reduce the distinctions
encoded in the TUT treebank to bare head-
dependent relations: the ARG type on the one
hand, and the MOD and AUX types on the other.
These relations are converted into fa-structures
built by means of the dependency-sensitive op-
erators 4, ►, a , D .
By means of example, we consider some sim-
ple sentences exemplifying the different rela-
tions.
Figure 1 shows a head-dependent structure
in which edges represent head-dependent rela-
tions and each edge points to the dependent of
each relation. In this example, each H-D rela-
tion agrees with the F-A relation, i.e. each head
corresponds to a functor and the dependents are
all labeled as arguments (or sub-tags of it).7
</bodyText>
<figure confidence="0.91178875">
SUBJ OBJ ARG
Alan mangia la mela
0 1 2 3
Alan eats the apple
</figure>
<figureCaption confidence="0.999886">
Figure 1: ARG: Functor and Head coincide
</figureCaption>
<bodyText confidence="0.96443925">
Figure 2 adds to the example from figure 1
the use of qualifying adjectives, which is an ex-
ample of a modifier, and past tense auxiliaries.
Considering the relation between “mela”(apple)
and “rossa” (red), and between “ha” (has) and
“mangiato” (eaten), we have the dependency
trees in Figure 2.
In the first case, the noun is the head and
the adjective is the dependent, but from the
functor-argument perspective, the adjective (in
general, the modifier) is the incomplete functor
component. A similar discrepancy is observed
for the auxiliary and the main verb, where the
auxiliary should be classified as the incomplete
functor, but as the dependent element with re-
spect to the main verb. In this case the absence
7The example follows TUT practice in designating the
determiner as the head of the noun phrases. We are
aware of the fact that this is far from controversial in
the dependency community. In preprocessing TUT be-
fore type inference, we have the occasion to adjust such
debatable decisions, and representational issues such as
the use of empty categories, for which there is no need
in a CTL framework.
</bodyText>
<figure confidence="0.9383235">
SUBJ AUX OBJ ARG
Alan ha mangiato la mela
0 1 2 3 4
Alan ate the apple
</figure>
<figureCaption confidence="0.999933">
Figure 2: MOD and AUX: Functors as Dependents
</figureCaption>
<bodyText confidence="0.999908333333333">
of the auxiliary would result in an ungrammat-
ical sentence. The relations of MOD and AUX ex-
hibit a different behavior than ARG, and hence
are depicted with different arcs.
Our simple example sentences could be con-
verted into the following fa-structures:
</bodyText>
<listItem confidence="0.785677">
- Allen ► (mangia 4 (la 4 mela)
- Allen ► (mangia 4 (la 4 (mela D rossa))
- Allen ► ((ha a mangiato) 4 (la 4 mela))
</listItem>
<bodyText confidence="0.999444777777778">
The second step is to run the Buszkowski-
Penn type-inference algorithm (in its extended
form, discussed above) on the fa-structures ob-
tained from TUT, and to reduce the lexicon
by factoring (identification of unifiable assign-
ments) and (in a later phase) structural deriv-
ability. Fixing the goal type for these examples
as s, we obtain the following type assignments
from the fa-structures given above:
</bodyText>
<figure confidence="0.700369428571429">
Allan A
mangia (A\rs)/lB
la B/lC
mela C
rossa C\lC
ha ((A\rs)/lB)/rD
mangiato D
</figure>
<bodyText confidence="0.991911055555556">
Notice that from the output in our tiny sam-
ple, we have no information allowing us to iden-
tify the argument assignments A and B. No-
tice also that from an fa-structure which takes
together “ha mangiato” in a constituent, we
obtain a type assignment for “mangiato” that
does not express its incompleteness anymore
— instead, the combination with the auxil-
iary expresses this. This is already an exam-
ple where structural reasoning can play a role:
compare the above analysis with the type so-
lution one would obtain by starting from an
fa-structure which takes “mangiato la mela”
as a constituent, which yields a type solution
(A\rs)/rE for the auxiliary, and E/lB for the
head verb. We are currently experimenting with
the effect of different constituent groupings on
the size of the induced type lexicon.
</bodyText>
<subsectionHeader confidence="0.996898">
4.2 Clustering Algorithms
</subsectionHeader>
<bodyText confidence="0.999934466666667">
Once we have induced the categorial type as-
signments for the TUT lexicon, the last step of
our first task is to divide it into clusters so to
study the distributional behavior of the corre-
sponding lexical entries. The advantage of us-
ing categorial types as objects of the clustering
algorithm is that they represent long distance
dependencies as well as limited distributional
information. Thus the categorial types become
the basic elements of syntactic information as-
sociated with lexical entries and the basic “dis-
tributional fingerprints” used in the clustering
process.
Every clustering process is based on a no-
tion of “distance” between the objects involved
in the process. We should define an appropri-
ate metric among categorial types. We believe
that a crucial role will be played by the depen-
dency relation encoded into the types by means
of compositional modes.
Currently, we are studying the application of
proper distance measures considering types as
trees and adapting the theoretical results on
tree metrics to our problem. The algorithm for
computing the tree-edit distance (Shasha and
Zhang, 1997), designed for generic trees, ap-
pears to be a good candidate for clustering in
categorial-type domain. What remains to be
done is to experiment the algorithm and fine-
tune the metrics to our purpose.
</bodyText>
<sectionHeader confidence="0.998864" genericHeader="conclusions">
5 Conclusions and Further Research
</sectionHeader>
<subsectionHeader confidence="0.695473">
In this paper we have presented work in progress
</subsectionHeader>
<bodyText confidence="0.99791725">
devoted to the syntactic annotation of a large
Italian corpus. We have just started working in
this direction and the biggest part of the work
has still to be done. We are currently evaluating
the TUT encoding of dependency information,
and identifying areas that allow optimization
from the point of view of CTL type induction.
A case in point is the heavy reliance of TUT
on empty elements and/or traces, which con-
flicts with our desire for an empirically-based
and theory-neutral representation of linguistic
dependencies. It seems that the trace artifact
can be avoided if one properly exploits the more
expressive category concept of CTL, allowing
product types for asyndetic constructions, and
higher-order types for multiple dependencies. In
parallel, we are looking for other sources of de-
pendency information for Italian, in order to
complement the rather small TUT database we
have at our disposal now.
</bodyText>
<sectionHeader confidence="0.999639" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.94107">
Our thanks go to FIRB 2001 project
RBNE01H8RS coordinated by prof. R. Rossini
Favretti for the funding supports. Thanks to
L. Surace and C. Seidenari for the detailed
comparison on Italian PoS classifications.
</bodyText>
<sectionHeader confidence="0.997008" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746472972973">
C. Bosco. 2003. A grammatical relation system
for treebank annotation. Ph.D. thesis, Com-
puter Science Department, Turin University.
E. Brill and M. Marcus. 1992. Tagging an un-
familiar text with minimal human supervi-
sion. In Proceedings of the Fall Symposium
on Probabilistic Approaches to Natural Lan-
guage, pages 10–16, Cambridge. MA: Ameri-
can Association for Artificial Intelligence.
W. Buszkowski and G. Penn. 1990. Categorial
grammars determined from linguistic data by
unification. Studia Logica, 29:431–454.
A. Clark. 2000. Inducing syntactic categories
by context distribution clustering. In Pro-
ceedings of CoNLL-2000 and LLL-2000 Con-
ference, pages 94–91, Lisbon, Portugal.
F. Gobet and J. Pine. 1997. Modelling the ac-
quisition of syntactic categories. In Proceed-
ings of the 19th Annual Meeting of the Cog-
nitive Science Society, pages 265–270.
L. Lee. 1999. Measures of distributional simi-
larity. In Proceedings of the 37th ACL, pages
25–32, College Park, MD.
S. Martin, J. Liermann, and H. Ney. 1998. Al-
gorithms for bigram and trigram word clus-
tering. Speech Communication, 24:19–37.
M. Monachini. 1995. ELM-IT: An Italian in-
carnation of the EAGLES-TS. definition of
lexicon specification and classification guide-
lines. Technical report, Pisa.
S. Montemagni, F. Barsotti, M. Battista,
N. Calzolari, O. Corazzari, A. Lenci, A. Zam-
polli, F. Fanciulli, M. Massetani, R. Raf-
faelli, R. Basili, M. T. Pazienza, D. Saracino,
F. Zanzotto, N. Mana, F. Pianesi, and R. Del-
monte, 2003. Building and using parsed cor-
pora, chapter Building the Italian Syntactic-
Semantic Treebank, pages 189–210. Lan-
guage and Speech series. Kluwer, Dordrecht.
M. Moortgat and G. Morrill. 1991. Heads
and phrases. Type calculus for dependency
and constituent structure. Technical report,
Utrecht.
M. Moortgat. 1997. Categorial type logics.
In J. van Benthem and A. ter Meulen, edi-
tors, Handbook of Logic and Language, pages
93–178. The MIT Press, Cambridge, Mas-
sachusetts.
Michael Moortgat. 2001. Structural equa-
tions in language learning. In P. de Groote,
G. Morrill, and C. Retor´e, editors, Logical As-
pects of Computational Linguistics, volume
2099 of Lecture Notes in Artificial Intelli-
gence, pages 1–16, Berlin. Springer.
F. Pereira, T. Tishby, and L. Lee. 1993. Dis-
tributional clustering of English words. In
Proceedings of the 31st ACL, pages 183–190,
Columbus, Ohio.
M. Redington, N. Chater, and S. Finch. 1998.
Distributional information: a powerful cue for
acquiring syntactic categories. Cognitive Sci-
ence, 22(4):425–469.
D. Shasha and D. Zhang. 1997. Approximate
tree pattern matching. In A. Apostolico and
Z. Galig, editors, Pattern matching algo-
rithms. Oxford University Press.
F. Tamburini, C. De Santis, and Zamuner E.
2002. Identifying phrasal connectives in Ital-
ian using quantitative methods. In S. Nuc-
corini, editor, Phrases and Phraseology -Data
and Description. Berlin: Peter Land.
T. Venneman. 1977. Konstituenz und Depen-
denz in einigen neueren Grammatiktheorien.
Sprachwissenschaft, 2:259–301.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.003093">
<title confidence="0.97584">Categorial Type Logic meets Dependency Grammar to an Italian Corpus</title>
<author confidence="0.321462">R</author>
<affiliation confidence="0.789175">KRDB, Free University of Bolzano Bozen,</affiliation>
<address confidence="0.747416">P.zza Domenicani, 39100 Bolzano</address>
<email confidence="0.996391">bernardi@inf.unibz.it</email>
<author confidence="0.698397">Bolognesi</author>
<affiliation confidence="0.975956">University of P.zza San Giovanni in Monte,</affiliation>
<address confidence="0.656393">I-40124,</address>
<email confidence="0.611955">M.</email>
<note confidence="0.427815">UiL Utrecht Trans 3512 JK, The Moortgat@phil.uu.nl</note>
<abstract confidence="0.986427">In this paper we present work in progress on the of an Italian Corpus develat of Bologna). We induce categorial type assignments from a dependency treebank (Torino University treebank, and use the obtained categories with annotated dependency relations to study the distributional behavior of Italian words and reach an empirically founded part-of-speech classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Bosco</author>
</authors>
<title>A grammatical relation system for treebank annotation.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science Department, Turin University.</institution>
<contexts>
<context position="6617" citStr="Bosco, 2003" startWordPosition="1014" endWordPosition="1015">ard classification consists of nouns, verbs, adjectives, determiners, articles, adverbs, prepositions, conjunctions, numerals, interjections, punctuation and a class of residual items which differs from project to project. from the Italian civil law code, the national newspapers La Stampa and La Repubblica, and from various reviews, newspapers, novels, and academic papers. The ARS schema consists of i) morphosyntactic, ii) functional-syntactic and iii) semantic components, specifying part-of-speech, grammatical relations, and thematic role information, respectively. The reader is referred to (Bosco, 2003) for a detailed description of the TUT annotation schema. An example is given below (tr. “The first steps have not been encouraging”). In this example, the node TOP-VERB is the root of the whole structure4. ************** FRASE ALB-71 ************** 1 I (IL ART DEF M PL) [6;VERB-SUBJ] 2 primi (PRIMO ADJ ORDIN M PL) [3;ADJC+ORDIN-RMOD] 3 approcci (APPROCCIO NOUN COMMON M PL) [1;DET+DEF-ARG] 4 non (NON ADV NEG) [6;ADVB-RMOD] 5 sono (ESSERE VERB AUX IND PRES INTR 3 PL) [6;AUX+TENSE] 6 stati (ESSERE VERB MAIN PART PAST INTR PL M) [0;TOP-VERB] 7 esaltanti (ESALTANTE ADJ QUALIF ALLVAL PL) [6;VERB-PR</context>
</contexts>
<marker>Bosco, 2003</marker>
<rawString>C. Bosco. 2003. A grammatical relation system for treebank annotation. Ph.D. thesis, Computer Science Department, Turin University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>M Marcus</author>
</authors>
<title>Tagging an unfamiliar text with minimal human supervision.</title>
<date>1992</date>
<journal>Artificial Intelligence.</journal>
<booktitle>In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language,</booktitle>
<pages>10--16</pages>
<publisher>American Association for</publisher>
<location>Cambridge. MA:</location>
<contexts>
<context position="18837" citStr="Brill and Marcus, 1992" startWordPosition="3078" endWordPosition="3082">ural rules, and the trade-off between offline and on-line uses, as a subject for further research. 4 A distributional study of Italian part-of-speech tagging In order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automati</context>
</contexts>
<marker>Brill, Marcus, 1992</marker>
<rawString>E. Brill and M. Marcus. 1992. Tagging an unfamiliar text with minimal human supervision. In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language, pages 10–16, Cambridge. MA: American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Buszkowski</author>
<author>G Penn</author>
</authors>
<title>Categorial grammars determined from linguistic data by unification. Studia Logica,</title>
<date>1990</date>
<pages>29--431</pages>
<contexts>
<context position="11818" citStr="Buszkowski and Penn, 1990" startWordPosition="1866" endWordPosition="1869">dispensable if one is interested in capturing the full set of theorems of the type calculus. Classical CG (in the style of Ajdukiewicz and Bar-Hillel) uses only the Elimination rules, and hence has restricted inferential capacities. It is impossible in classical CG to obtain the validity A ` B/(A\B), for example. Still, the classical CG perspective will be useful to realize our aim of automatically inducing type assignments from structured data obtained from the TUT corpus thanks to the type resolution algorithm explained below. Type inference algorithms for classical CG have been studied by (Buszkowski and Penn, 1990). The structured data needed by their type inference algorithms are so-called functorargument structures (fa-structures). An fastructure for an expression is a binary branching tree; the leaf nodes are labeled by lexical expressions (words), the internal nodes by one of the symbols 4 (for structures with the functor as the left daughter) or No. (for structures with the functor as the right daughter). To assign types to the leaf nodes of an fastructure, one proceeds in a top-down fashion. The type of the root of the structure is fixed (for example: s). Compound structures are typed as follows: </context>
<context position="15859" citStr="Buszkowski and Penn, 1990" startWordPosition="2552" endWordPosition="2555"> composition operations each have their slash and backslash operations for the typing of incomplete expressions: - A/lB: a functor looking for a B to the right to form an A; the functor is the head, the argument the dependent; - A/rB: a functor looking for a B to the right to form an A; the argument is the head, the functor the dependent; - B\lA: a functor looking for a B to the left to form an A; the argument is the head, the functor the dependent; - B\rA: a functor looking for a B to the left to form an A; the functor is the head, the argument the dependent. The type inference algorithm of (Buszkowski and Penn, 1990) can be straightforwardly adapted to the multimodal situation. The internal nodes of the fa-structures now are labeled with a fourfold distinction: as before, the triangle points to the functor daughter of a constituent; in the case of the black triangle, the functor daughter is the head constituent, in the case of the white triangle, the functor daughter is the dependent. ad ah fd fh fh J fd ah ad The type-inference clauses can be adapted accordingly. - to type a structure Γ J Δ as A, type Γ as A/lB and Δ as B; C B I - to type a structure Γ a Δ as A, type Γ as A/rB and Δ as B. - to type a str</context>
</contexts>
<marker>Buszkowski, Penn, 1990</marker>
<rawString>W. Buszkowski and G. Penn. 1990. Categorial grammars determined from linguistic data by unification. Studia Logica, 29:431–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clark</author>
</authors>
<title>Inducing syntactic categories by context distribution clustering.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000 Conference,</booktitle>
<pages>94--91</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="18988" citStr="Clark, 2000" startWordPosition="3107" endWordPosition="3108">order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure requires a linguistic examination of the resulting tree, in order to identify the word classes that are most appropriate to descr</context>
</contexts>
<marker>Clark, 2000</marker>
<rawString>A. Clark. 2000. Inducing syntactic categories by context distribution clustering. In Proceedings of CoNLL-2000 and LLL-2000 Conference, pages 94–91, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Gobet</author>
<author>J Pine</author>
</authors>
<title>Modelling the acquisition of syntactic categories.</title>
<date>1997</date>
<booktitle>In Proceedings of the 19th Annual Meeting of the Cognitive Science Society,</booktitle>
<pages>265--270</pages>
<contexts>
<context position="18974" citStr="Gobet and Pine, 1997" startWordPosition="3103" endWordPosition="3106">-of-speech tagging In order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure requires a linguistic examination of the resulting tree, in order to identify the word classes that are most approp</context>
</contexts>
<marker>Gobet, Pine, 1997</marker>
<rawString>F. Gobet and J. Pine. 1997. Modelling the acquisition of syntactic categories. In Proceedings of the 19th Annual Meeting of the Cognitive Science Society, pages 265–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th ACL,</booktitle>
<pages>25--32</pages>
<location>College Park, MD.</location>
<contexts>
<context position="19188" citStr="Lee, 1999" startWordPosition="3135" endWordPosition="3136">f two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure requires a linguistic examination of the resulting tree, in order to identify the word classes that are most appropriate to describe the phenomenon under investigation. In this sense, they use a semiautomatic word-class generator method. A similar procedure has been applied on Italian in (Tamburini et al., 2002). The novelty of</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>L. Lee. 1999. Measures of distributional similarity. In Proceedings of the 37th ACL, pages 25–32, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Martin</author>
<author>J Liermann</author>
<author>H Ney</author>
</authors>
<title>Algorithms for bigram and trigram word clustering. Speech Communication,</title>
<date>1998</date>
<pages>24--19</pages>
<contexts>
<context position="18881" citStr="Martin et al., 1998" startWordPosition="3087" endWordPosition="3090">and on-line uses, as a subject for further research. 4 A distributional study of Italian part-of-speech tagging In order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure requires a linguistic </context>
</contexts>
<marker>Martin, Liermann, Ney, 1998</marker>
<rawString>S. Martin, J. Liermann, and H. Ney. 1998. Algorithms for bigram and trigram word clustering. Speech Communication, 24:19–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Monachini</author>
</authors>
<title>ELM-IT: An Italian incarnation of the EAGLES-TS. definition of lexicon specification and classification guidelines.</title>
<date>1995</date>
<tech>Technical report,</tech>
<location>Pisa.</location>
<contexts>
<context position="3614" citStr="Monachini, 1995" startWordPosition="563" endWordPosition="564"> Section 4, we explain how we encode dependency relations into categorial type assignments (CTAs), and how we automatically induce these types from TUT dependency structures. Finally, in Section 5 we draw some preliminary conclusions and briefly describe our action list. 2 PoS tagging for Italian Before embarking on our first task, we have studied the current situation with respect to PoS tagging for Italian. Italian is one of the languages for which a set of annotation guidelines has been developed in the context of the EAGLES project (Expert Advisory Group on Language Engineering Standards (Monachini, 1995)). Several research groups have worked on PoS annotation in practice (for example, Torino University, Xerox and Venice University). We have compared the tag sets used by these groups with Monachini’s guidelines. From this comparison, it results that though there is a general agreement on the main parts of speech to be used3, considerable divergence exists when it comes to the actual classification of Italian words with respect to these main PoS classes. The classes for which differences of opinion are most evident are adjectives, determiners and adverbs. For instance, words like molti (tr. man</context>
</contexts>
<marker>Monachini, 1995</marker>
<rawString>M. Monachini. 1995. ELM-IT: An Italian incarnation of the EAGLES-TS. definition of lexicon specification and classification guidelines. Technical report, Pisa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Montemagni</author>
<author>F Barsotti</author>
<author>M Battista</author>
<author>N Calzolari</author>
<author>O Corazzari</author>
<author>A Lenci</author>
<author>A Zampolli</author>
<author>F Fanciulli</author>
<author>M Massetani</author>
<author>R Raffaelli</author>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>D Saracino</author>
<author>F Zanzotto</author>
<author>N Mana</author>
<author>F Pianesi</author>
<author>R Delmonte</author>
</authors>
<title>Building and using parsed corpora, chapter Building the Italian SyntacticSemantic Treebank, pages 189–210. Language and Speech series.</title>
<date>2003</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="1898" citStr="Montemagni et al., 2003" startWordPosition="278" endWordPosition="282">usefulness for bootstrapping the CORIS/CODIS annotation tasks. We are aware of two such treebanks that are relevant to our purposes: the TUT corpus developed at Torino University, and ISST (Italian Syntactic-Semantic treebank) developed under the national program SI-TAL by a consortium of companies and research centers coordinated by the “Consorzio Pisa Ricerche” (CPR)2. ISST is a multi-layered corpus, annotated at the syntactic and lexico-semantic levels. A user interface is provided to explore the corpus. The ISST corpus is rather competitive in terms of size: it counts 305,547 word tokens (Montemagni et al., 2003). A drawback is that the corpus is not publicly available yet. The TUT 1The project is funded under the FIRB 2001 action. 2The parnters of the consortium were: ILCCNR/CPR, Venice University/CVR, ITC-IRST, “Tor Vergata” University/CERTIA, and Synthema. corpus is rather small, consisting only of 38,653 words. There is no user interface for TUT but the corpus is downloadable (http://www.di. unito.it/~tutreeb/). Despite its small size, TUT can serve as a training corpus for creating larger annotated resources. Our goal is to annotate CORIS with part-ofspeech (PoS) tags and semi-automatically build</context>
</contexts>
<marker>Montemagni, Barsotti, Battista, Calzolari, Corazzari, Lenci, Zampolli, Fanciulli, Massetani, Raffaelli, Basili, Pazienza, Saracino, Zanzotto, Mana, Pianesi, Delmonte, 2003</marker>
<rawString>S. Montemagni, F. Barsotti, M. Battista, N. Calzolari, O. Corazzari, A. Lenci, A. Zampolli, F. Fanciulli, M. Massetani, R. Raffaelli, R. Basili, M. T. Pazienza, D. Saracino, F. Zanzotto, N. Mana, F. Pianesi, and R. Delmonte, 2003. Building and using parsed corpora, chapter Building the Italian SyntacticSemantic Treebank, pages 189–210. Language and Speech series. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
<author>G Morrill</author>
</authors>
<title>Heads and phrases. Type calculus for dependency and constituent structure.</title>
<date>1991</date>
<tech>Technical report, Utrecht.</tech>
<contexts>
<context position="14929" citStr="Moortgat and Morrill, 1991" startWordPosition="2385" endWordPosition="2388">ractional multiplication, which explains their optionality and the possibility of iteration. AUX elements in DG would count as morphological modifiers of the head verbs. From the CG point of view, they would be typed as functors 6And also COORDINATOR, INTERJECTION. with non-identical numerator and denominator, distinguishing them that way from optional modifiers, and capturing the fact that they are indispensable to build a complete grammatical structure. To reconcile the competing demands of the head-dependent and functor-argument classification, we make use of the type calculus proposed in (Moortgat and Morrill, 1991), which treats dependency and functor-argument relations as two orthogonal dimensions of linguistic organization. Instead of one composition operation o, the system of (Moortgat and Morrill, 1991) has two: ol for structures where the left daughter is the head, and or for right-headed structures. The two composition operations each have their slash and backslash operations for the typing of incomplete expressions: - A/lB: a functor looking for a B to the right to form an A; the functor is the head, the argument the dependent; - A/rB: a functor looking for a B to the right to form an A; the argu</context>
</contexts>
<marker>Moortgat, Morrill, 1991</marker>
<rawString>M. Moortgat and G. Morrill. 1991. Heads and phrases. Type calculus for dependency and constituent structure. Technical report, Utrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>Categorial type logics.</title>
<date>1997</date>
<booktitle>Handbook of Logic and Language,</booktitle>
<pages>93--178</pages>
<editor>In J. van Benthem and A. ter Meulen, editors,</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="8603" citStr="Moortgat, 1997" startWordPosition="1315" endWordPosition="1316">AS and TOP-PREP 5The labels that require some explanation are: (i) CONTIN, (ii) EMPTYCOMPL, (iii) EMPTYLOC and (iv) VISITOR. They are used for expressions that (i) introduce a part of an expression with a non-compositional interpretation (e.g. locative or idiomatic expressions and denominative structures: “Arriv`o [prima]H [de]D ll’alba”, lit. tr. “(She) arrived ahead of the daybreak”); (ii) link a re(ARG) and modifiers (MOD) are sub-divided as following ARG SUBJ OBJ INDOBJ INDCOMPL PREDCOMPL MODIFIER RMOD RELCLR RMODPRED 3.2 Categorial functor-argument structures Categorial Type Logic (CTL) (Moortgat, 1997) is a logic-based formalism belonging to the family of Categorial Grammars (CG). In CTL, the type-forming operations of CG are viewed as logical connectives. As the slogan “Parsingas-Deduction” suggests, such a view makes it possible to do away with combinatory syntactic rules altogether; establishing the wellformedness of an expression becomes a process of deduction in the logic of the type-forming connectives. The basic distinction expressed by the categorial type formulas is the Fregean opposition between complete and incomplete expressions. Complete expressions are categorized by means of </context>
</contexts>
<marker>Moortgat, 1997</marker>
<rawString>M. Moortgat. 1997. Categorial type logics. In J. van Benthem and A. ter Meulen, editors, Handbook of Logic and Language, pages 93–178. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Structural equations in language learning.</title>
<date>2001</date>
<booktitle>Logical Aspects of Computational Linguistics, volume 2099 of Lecture Notes in Artificial Intelligence,</booktitle>
<pages>1--16</pages>
<editor>In P. de Groote, G. Morrill, and C. Retor´e, editors,</editor>
<publisher>Springer.</publisher>
<location>Berlin.</location>
<contexts>
<context position="17547" citStr="Moortgat, 2001" startWordPosition="2873" endWordPosition="2874">ecifically, in the case of non-projective dependencies. Where such mismatches occur, the induced types will not be immediately useful for parsing — the longer term subtask of the project discussed here. To address this issue, we can extend the inference rules of our categorial logic with structural rules. The general pattern of these rules is: infer Γ&apos; �- A from Γ �- A, where Γ&apos; is some rearrangement of the constituents of Γ. These rules, in other words, characterize the structural deformations under which type assignment is preserved. Structural rules can be employed in two ways in CTL (see (Moortgat, 2001) for discussion). In an on-line use, they actually manipulate structural configurations during the parsing process. Such on-line use can be very expensive computationally. Used off-line, they play a role complementary to the factoring operation, producing a number of derived lexical type-assignments from some canonical assignment. With the derived assignments, parsing can then proceed without altering the surface structure. As indicated in the introduction, the use of CTL in the construction of a treebank for a part of the CILTA corpus belongs to a future phase of our project. For the purposes</context>
</contexts>
<marker>Moortgat, 2001</marker>
<rawString>Michael Moortgat. 2001. Structural equations in language learning. In P. de Groote, G. Morrill, and C. Retor´e, editors, Logical Aspects of Computational Linguistics, volume 2099 of Lecture Notes in Artificial Intelligence, pages 1–16, Berlin. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>T Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st ACL,</booktitle>
<pages>183--190</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="18859" citStr="Pereira et al., 1993" startWordPosition="3083" endWordPosition="3086">e-off between offline and on-line uses, as a subject for further research. 4 A distributional study of Italian part-of-speech tagging In order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure </context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>F. Pereira, T. Tishby, and L. Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st ACL, pages 183–190, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Redington</author>
<author>N Chater</author>
<author>S Finch</author>
</authors>
<title>Distributional information: a powerful cue for acquiring syntactic categories.</title>
<date>1998</date>
<journal>Cognitive Science,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="18952" citStr="Redington et al., 1998" startWordPosition="3099" endWordPosition="3102">al study of Italian part-of-speech tagging In order to annotate the CORIS corpus with a theory-neutral set of PoS tags, we plan to carry out a distributional study of its lexicon. Early approaches to this problem were based on the hypothesis that if two words are syntactically and semantically different, they will appear in different contexts. There are a number of studies that, starting from this hypothesis, have built automatic or semi-automatic procedures for clustering words (Brill and Marcus, 1992; Pereira et al., 1993; Martin et al., 1998), especially in the field of cognitive sciences (Redington et al., 1998; Gobet and Pine, 1997; Clark, 2000). They examine the distributional behaviour of some target words, comparing the lexical distribution of their respective collocates using quantitative measures of distributional similarity (Lee, 1999). In (Brill and Marcus, 1992) it is given a semiautomatic procedure that, starting from lexical statistical data collected from a large corpus, aims to arrange target words in a tree (more precisely a dendrogram), instead of clustering them automatically. This procedure requires a linguistic examination of the resulting tree, in order to identify the word classe</context>
</contexts>
<marker>Redington, Chater, Finch, 1998</marker>
<rawString>M. Redington, N. Chater, and S. Finch. 1998. Distributional information: a powerful cue for acquiring syntactic categories. Cognitive Science, 22(4):425–469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Shasha</author>
<author>D Zhang</author>
</authors>
<title>Approximate tree pattern matching.</title>
<date>1997</date>
<editor>In A. Apostolico and Z. Galig, editors,</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="25826" citStr="Shasha and Zhang, 1997" startWordPosition="4242" endWordPosition="4245">entries and the basic “distributional fingerprints” used in the clustering process. Every clustering process is based on a notion of “distance” between the objects involved in the process. We should define an appropriate metric among categorial types. We believe that a crucial role will be played by the dependency relation encoded into the types by means of compositional modes. Currently, we are studying the application of proper distance measures considering types as trees and adapting the theoretical results on tree metrics to our problem. The algorithm for computing the tree-edit distance (Shasha and Zhang, 1997), designed for generic trees, appears to be a good candidate for clustering in categorial-type domain. What remains to be done is to experiment the algorithm and finetune the metrics to our purpose. 5 Conclusions and Further Research In this paper we have presented work in progress devoted to the syntactic annotation of a large Italian corpus. We have just started working in this direction and the biggest part of the work has still to be done. We are currently evaluating the TUT encoding of dependency information, and identifying areas that allow optimization from the point of view of CTL type</context>
</contexts>
<marker>Shasha, Zhang, 1997</marker>
<rawString>D. Shasha and D. Zhang. 1997. Approximate tree pattern matching. In A. Apostolico and Z. Galig, editors, Pattern matching algorithms. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Tamburini</author>
<author>C De Santis</author>
<author>E Zamuner</author>
</authors>
<title>Identifying phrasal connectives in Italian using quantitative methods.</title>
<date>2002</date>
<booktitle>Phrases and Phraseology -Data and Description.</booktitle>
<editor>In S. Nuccorini, editor,</editor>
<location>Berlin: Peter Land.</location>
<marker>Tamburini, De Santis, Zamuner, 2002</marker>
<rawString>F. Tamburini, C. De Santis, and Zamuner E. 2002. Identifying phrasal connectives in Italian using quantitative methods. In S. Nuccorini, editor, Phrases and Phraseology -Data and Description. Berlin: Peter Land.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Venneman</author>
</authors>
<date>1977</date>
<booktitle>Konstituenz und Dependenz in einigen neueren Grammatiktheorien. Sprachwissenschaft,</booktitle>
<pages>2--259</pages>
<contexts>
<context position="13736" citStr="Venneman, 1977" startWordPosition="2205" endWordPosition="2206">). 3.3 From TUT dependency structures to categorial types To accomplish our aims, we will have an occasion to use two extensions of the basic categorial machinery outlined in the section above: a generalization of the type language to multiple modes of composition, and the addition of structural rules of inference to the logical rules of slash Elimination and Introduction. Multimodal composition The intuitions underlying the distinction between heads and dependents in Dependency Grammars (DG) and between functors and arguments in CG often coincide, but there are also cases where they diverge (Venneman, 1977). In the particular case of the TUT annotation schema, we see that for all instances of dependents labeled as ARG (or one of its sublabels), the DG head/dependent articulation coincides with the CG functor/argument asymmetry. But for DG modifiers, or dependents without thematic roles of the class AUX (auxiliary)6 there is a mismatch between dependency structure and functor-argument structure. Modifiers would be functors in terms of their categorial type: functors where the numerator and the denominator are identical. This makes them into ‘identities’ for the fractional multiplication, which ex</context>
</contexts>
<marker>Venneman, 1977</marker>
<rawString>T. Venneman. 1977. Konstituenz und Dependenz in einigen neueren Grammatiktheorien. Sprachwissenschaft, 2:259–301.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>